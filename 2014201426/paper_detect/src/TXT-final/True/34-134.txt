 scheme. 

this paper describes a lexical organization in which  senses  are represented in their own right  along with  words  and  phrases   by distinct data items. the objective of the scheme is to facilitate recognition and employment of synonyms and stock phrases by programs which process natural language. besides presenting the proposed organization  the paper characterizes the lexical  senses  which result. 
keywords: 
natural language processing lexical component 
synonymy 
on-line dictionary 
dictionary preparation 
1. introduction. 
this paper describes an internal lexical organization which is particularly designed to capture the facts about synonymy.besides recording the inclusion of each word in one or more synonym sets  identified with its various  senses    the scheme attempts to distribute attributes perspicuously between  senses    wordings   and the intersections of the two. in addition  there is provision to record multi-word idioms  stock phrases  and the like  and to include these as elements in synonym sets when appropriate. 
briefly   senses  are represented in their own right  along with 
 words  and  phrases   by distinct data items. each word or phrase is associated with a list of the  senses  which it can express; conversely  each  sense  is associated with a list of  alternative wordings . additionally  each word is associated with a list of phrases in which it occurs. 
grammatical category  features  selection restrictions  and the like are applicable at three different levels: to words or phrases as such  to  senses  as such  or to particular usages of words or phrases  equivalently  to particular wordings of  senses  . 
this lexical organization has been implemented at i b m research  
yorktown heights  n.y.  by a program - not to be described here - which builds such dictionaries in a very compact form  giving interactive assistance to the person making the entries. 
 for example  the program points out the possibility of merging  senses  whenever their wordings overlap and their attributes are compatible  and merges them if so directed.  there are suitable facilities for saving the results  retrieving them in various ways  and for altering such things as schemes of classification without scrapping previously prepared work. 
the ultimate intent is that the  dictionary of senses  should serve as the lexical component in a natural language fact-retrieval system. pending its incorporation in that role  it will be used to amass and organize information on the semantic relations among words and phrases. 
the balance of this paper comes in two sections: 
section 1 presents the proposed lexical data structures  and suggests how they are to be used. included is a sketch of how various section 1 discusses the character of the  senses  encoded in the resulting dictionary. reasons are advanced for regarding lexical  senses  as something far short of semantic primitives. at the same time  synonym sets are defended against the view that  true paraphrases are rare or nonexistent . 
1. the internal representation. 
it will be our purpose in this section to say just enough about internal representation to lay bare the organizing principles of the lexicon. the focus is on architecture and motivations; details of field layouts  internal codes  etc. are not at issue here. 
to make the discussion concrete  suppose we are interested in the senses of the word  change . assuming that none of the words are unfamiliar  the following should put us in mind of two senses: 
this  of course  is just a dictionary entry in the traditional format  though with synonyms offered in lieu of definitions . 
on the other hand  we might approach the same information from a different direction: starting with the two concepts  we might seek words to express them. it is difficult to picture this latter situation without assigning artificial labels to the concepts. call them concepts 1 and 1  and suppose for a moment that there were a practical way to look the concepts up  without having thought of either word for either concept . then the information to be retrieved might be envisioned this way: 
1. v 	change  alter 
1. n 	change  small coin 
it is this duality of viewpoint - that words have senses  while senses have wordings - that our lexical representation must reflect. 
the starting point  then  is that words  phrases  and  senses  are separately represented. there are three principal types of data item  plus a standard connector: 
1. a 	 key 	data 	item  	 kdi  represents a single word. 
1. a  phrase data item   pdi  represents a string of two or more words which are to serve as a unit in some context. 
1. a  sense data item   sdi  represents one distinct sense common to a set of words and/or phrases. in general  a word or phrase may be usable in more than one sense  while a given sense may have alternative  synonymous  wordings. both these types of variability are recorded making use of the next data item: 
1. a  sense link element   sle  is a connective item  to be explained shortly. 
three principal fields will engage our attention in each type of data item. fig. 1 summarizes the fields for each type. 
1 


each k d i  key data item  or pdi  phrase data item  contains an  alternative senses  link - a pointer to the first sle  sense link element  in a chain of sle's which represent the various senses of the word or phrase the sle's are chained via their own  alternative senses  links  and the final member points back to the k d i or pdi. thus  we shall speak of such a chain as a ring -specifically  an  alternative senses ring . if no senses are on record for a particular word or phrase  the  alternative senses  link in the k d i or pdi is self-referent. 
reciprocally  	each 	sdi 	 sense 	data 	item  	contains 	an 
 alternative wordings  link. this leads to a chain of sle's which represent more-or-less synonymous wordings that express the sense. these sle's are chained through their own  alternative wordings  links  and again the chain is closed into a ring - this time beginning and ending with the sdi. 
the structure that is shaping up may now be seen in fig. 1. the crucial point is that each sle represents the intersection between an  alternative senses  ring and an  alternative wordings  ring. from the standpoint of the word or phrase  it represents a particular sense; from the standpoint of the sense  it represents a particular wording. 
starting from a k d i or pdi  one gets to the sdi for a particular sense by advancing along the  alternative senses  ring to the relevant sle  then detouring along the ring which connects the latter to the sdi  as one of the sdi's  alternative wordings  . starting from an sdi  one gets to a particular wording by the reverse process. since each  alternative senses  ring contains exactly one k d i or pdi. while each  alternative wordings  ring contains exactly one sdl each sle is tied to exactly one sense of one word or phrase.  equivalently  it is tied to one wording of one sense.  
the next point of interest is that  attribute  fields are present in all four types of data item -- even in the connectors  sle's . the attributes which may be recorded in each  however  come from different bags. 
to begin with  the attributes found in an sdi characterize all the wordings of a given sense ~ whenever the wordings are used in that sense. in fig. 1  for example  sense   1   should be marked as a  verb  sense  while sense     1   is a  noun . one would not wish 

to record the attribute  verb  in the k d i for the word  change   for the k d i represents facts about the word itself  irrespective of sense  and  verb  does not hold for all uses of the word  change . on the other hand   verb  does characterize all wordings of sense   1     whenever they're being employed to express that sense. it would furthermore apply to any additional wordings which we might think of  such as  modify   provided they are really used in a synonymous way. 
as a matter of fact  it turns out that the traditional parts of speech - noun  verb  adjective  preposition  etc. - fit best in this scheme as global attributes of senses  recorded in the sdi's. 
a different sort of attribute may be recorded in a k d i   as a global feature of the word itself. for example  we may note of the word  change  that it is  regularly conjugated  that is  when used as a verb  it forms the third person singular by adding  s   and both past and past participle by adding  ed  to be sure  this  global  attribute applies only to the  verb  senses of  change ; but a moment's reflection will confirm that  change  has more than one  verb  sense  and the regularity of its conjugation is common to all of them. thus  it is useful to note this regularity as an attribute of the word itself.  contrast this with the behavior of the 
1 

word  can   which is regular when it means  to pack in cans   but irregular when it means  is able to   
various other attributes suggest themselves as global characterizes of the words themselves  to be recorded in the kdi's. for example  one might wish to note of  change  that it drops its final  e  when adding  ing   this is the normal rule   but of  singe  that it doesn't. 
still other attributes are appropriate when characterizing multiword units  in pdi's  a string of words whose meaning is not evident from the mere juxtaposition of its constituents  such as  give up   may be classified as an  idiom . a string of words whose meaning could be figured out from the meanings of its constituents  but which occurs with enough frequency to warrant inclusion in the dictionary  might be classed as a  stock phrase .  example:  drop dead   a string like  perform in a subordinate role   which one would not normally expect to encounter in its own right  might be classed as a  definition   for a certain sense of the word  accompany   difficult to reword except with a definition . 
perhaps the most unexpected site for recording attributes is in the connective elements  sle's . these are the logical place  though  to note features that apply to a specific sense of a word  without being global to either the sense or the word consider the following four sentences: 

suppose we choose to view this as a restriction upon the  surface  object of the verb:  stop   when applied to an action  must take a gerund as its object;  cease  can take either a gerund or an infinitive.  it wouldn't affect the point being made if we said that  stop  inhibits a certain grammatical transformation en route to surface structure  while  cease  permits it.  
now  we wouldn't want to mark  gerund object only  as a global attribute of the sense  for we have just shown that  cease  and  stop   two wordings of the sense  differ with respect to this restriction. on the other hand  it doesn't belong among the global attributes of the word  stop  as such  for  stop  has other verb senses  even transitive ones  to which the restriction is completely inapplicable.  consider  stop a hole in the dike    stop a catastrophe   etc.  that leaves the alternative we are suggesting: treat the restriction as an attribute of one particular usage of the word  equtvalently  one particular wording of the sense . 
besides having senses  individual words are involved in phrases  and this fact is also represented in our data structure. fig. 1 shows the plan of attack. in the kd1 for each word  there is a link connecting it to the pdi for the first phrase in which the word is known to occur  together with a number designating the position of the word  1st  1nd  1rd. etc.  in that phrase. in the pdi itself  there is a continuation link for each word of the phrase  together with its number in the next phrase. in the final pdi involving a given word  the link for that word points back to the k.di. thus  independent of its  alternative senses  ring  each kdi may have a 
 phrase involvements  ring. 
this structure makes it possible to retrieve all the idioms  stock phrases  definitions  etc.  in which a given word has made its appearance  anywhere in the dictionary. as the same structure is used to encode every multi-word unit  no occurrence of a word is ever lost sight of  and a phrase can be looked up via any of its constituent words. 
of the fields to which fig. 1 calls attention  we have discussed all but one. in the sdi for each  sense   there is a  sense chain  link field. this links the sdi to its successor in a global chain of  senses . using this chain  it is possible to make an exhaustive. 
non-duplicative list of all the  senses  recorded in the dictionary. the listing program has only to proceed down the chain  retrieve from each sdi its attributes  decode them  then chase around the  alternative wordings  ring of the sdi and list the wordings alongside the attributes. 
one more feature of the internal representation deserves mention: the data items for words occur as  leaves  in a lexical tree  fig. 1 . that is  the kdi for a word can be looked up letter-byletter  following a chain of pointers that correspond to successive letters. the chain ends at a kdi after following a substring sufficient to distinguish the word from the nearest thing like it in the dictionary. the lexical tree has the advantage that words can be looked up either at random or in sequence. 
recapitulating  these are the essential features of the representation: 
*1   senses  are represented separately from  wordings   and the mutual connections between them are made explicit in both directions. 
*1   wordings  may be either single words or multi-word phrases. these are represented by distinct types of data item  and may be subject to distinct schemes of classification  but they are on the same footing with regard to  sense  connections. with each word is associated an exhaustive list of the phrases in which it occurs. 
 1  classifiers and features  drawn from appropriate sets  may be attributed separately to words  to phrases  to senses  or to particular senses of words or phrases  i.e.  to particular wordings of senses . 
1 


*1  the data items which represent senses are globally chained  and may be exhaustively listed. 
 1  the data items which represent words are accessible as  leaves  of a lexical tree; hence they may either be retrieved by lookup  in response to presentation of the words  or volunteered in alphabetical order. 
given a commitment to represent a lexicon as suggested by points *1 through *1 above  various implementations would be possible. alternative implementations of individual points  though not of the scheme as a whole  have in fact been described by other writers. the lexical tree  *1   for example  is no great novelty: see  concerning a dictionary which uses a similar manner of organization for lookup. for that matter  it is reminiscent of feigenbaum's  discrimination tree.   
more interestingly  the separate representation of senses and wordings has been incorporated in other systems by r. f. simmons      and by larry r. harris  1 . this way of looking at matters led harris to remark some of the same points that we have been stressing: that senses have alternative wordings just as words have alternative senses; that multi-word phrases might occur on the same footing as individual words in the expression of a sense; and  interestingly enough  that part-of-speech information really adheres to the  sense   not to the  word . similarly  simmons associates his  deep case  information with lexical nodes representing  wordsenses   while words themselves are treated as  print image  attributes of the wordsenses. 
harris's dictionary was only a minor component in a small-scale model of concept acquisition. no great number of either words or concepts was required to illustrate the principles at stake  so harris programmed the dictionary as an array  with words represented by rows and  concepts  by columns. elements of the array were merely frequencies  indicating the strength of association between each word and each concept. 
needless to say  for a full-scale vocabulary of words and concepts  such an array is mostly empty; nobody would dream of expanding it in that form. from a programming standpoint  the only thinkable choice is some form of list structure. having decided in principle to use  some form of list structure   though  one might well ask: why chains  why rings  why not just include in each key data item a full list of pointers to the corresponding sense data items  and vice-versa  
the answer is simply one of convenience. it's easier to handle insertions and deletions when they don't require the movement of expanded items to new quarters  or the provision of ''overflow  pointers. it's easier to reclaim freed storage when deleted items come in a handful of standard sizes. as for  rings   they eliminate the need for two-way pointers  since one can break into a ring at any point and follow it to its source. 
it should be noted that to make rings an attractive representation  the details of the material being represented must cooperate. in particular  the rings must not become too long  or the processing required to follow them becomes excessive. it happens that  alternative senses  rings and  alternative wordings  rings are typically short -- rarely more than a dozen links per ring.  phrase involvement  rings  on the other hand  can become spectacularly long  especially for words like  a  and  to . in practice  it's necessary to provide these rings with short-cut links. 
any of these programming details could be altered  however  without abandoning the essence of the scheme  which is given in points m through *1 above. 
1. the character of lexical senses. 
perhaps the first thing to get straight about the  senses  represented in this dictionary is what they are not. they are not  concepts ; they are not a set of  primitives  into which human experience can be decomposed. no conjecture is put forward here that any such collection of discrete  atomic concepts even exists  let alone that it might be finite. 
rather  the  senses  of the dictionary are in the nature of fuzzy equivalence sets among words.  this is only a metaphor; we shall do more and more violence to the technical notion of an  equivalence set  as we proceed.  each  sense  groups a set of words which  in a set of appropriate contexts  might be used more or less interchangeably. that the equivalence sets are fuzzy  one can convince oneself with but the briefest immersion in the materials of the language - trying to decide whether particular words belong in particular groups  or justify the creation of new groups. 
consider  for example  the following set of words and phrases: 
 abandon  give up  surrender  relinquish  let go  desert  leave  forsake  abdicate  
clearly  there is a common theme that can run through all of these  given the right circumstances. it might be expressed as  reluctant parting from somebody or something . this can be seen by coupling the verbs with various possible objects: 
 abandon  give up  surrender  a town to the enemy 
 abandon  give up  all hope 
 give up  relinquish  one's claim to an estate 
 give up  let go  our entire stock at a loss 
 abandon  desert  leave  one's wife and children 
 desert  forsake  a friend in need 
 give up  abdicate  the throne 
1 
 abandon  desert  an exhausted mine 
 forsake  give up  all other  keeping tnee only to her/him 
 abandon  desert  leave  the area threatened by the storm 
should we  then  declare this group of words to be a  sense   there are difficulties. the various words carry nuances  which it may or may not be easy to ignore in a particular context.  forsake   for example  can suggest that there is something reprehensible about the action. it can also connote formal renunciation  and the above example from a marriage vow shows that the formality can be present without the reprehensibility.nuanc-
es get in the way of intcrchangeability; it would sound strange to substitute  desert  into the marriage vow. 
besides nuances  the individual words have conventional areas of application. one does not normally say that the doctors  deserted  all hope  or that an errant husband  surrendered  his wife and children. the minister officiating at a wedding would be considered daft if he adjured the bride and groom to  abdicate  all others  and a merchant would not advertize that he was  relinquishing  his entire stock at a loss.  somehow  the latter situation calls for more pedestrian language.  
at the opposite extreme  overawed by this lack of intcrchangeability  we might decide to respect the unique personality of each word  abolishing equivalence classes altogether. the inconvenience of such a cop-out is obvious: we then have to introduce some other mechanism for recognizing the equivalence of utterances that are intended synonymously  though they employ different words. but beyond being inconvenient  the exclusion of equivalence sets is a denial of linguistic facts - just as bad  in its own way  as the naive attribution of unconditional synonymy. 
for it is a commonplace of everyone's experience that the speaker and the listener agree to ignore the nuances of words  whenever nuances get in the way of communication. a writer who has used the word  give up  eight times in five lines will surely cast about for some alternative ways of saying the same thing. if  relinquish  and  abandon  would normally be too flowery  or i   surrender  would in other circumstances call to mind an armistice ceremony in a railway wagon  that will not deter the writer from tossing in a few occurrences of those words - once a context has been established that discourages the overtones. nor will the reader understand matters any differently. it is as if writer and reader conspired:  we're fed up with that word  let's hear another.  or  perhaps  the writer simply connives at jolting the reader awake with frequent changes of idiom  maybe even an occasional incongruity. in any case  synonymy is imposed upon the words  and this literary behavior merely exaggerates what people do habitually in common speech. 
not only can words be stripped of nuances normally present; they can take on colorations suggested by the context. the suggestion of  reluctance  conveyed by all the verbs of our example can be inferred  in at least one case  from the setting alone; and in this 
case  a variety of more neutral verbs could be used synonymously: 
 part with  take leave of  our entire stock at a loss 
one could even substitute the word  sell   and it wouldn't change the meaning that was already read into the utterance. but to admit context-dependent synonymy of this degree is to stretch the  equivalence sets  to the point of uselessness. 
it comes to this: neither the grouping nor the separation of words can be fully justified. grouping is nearly always conditional  and separation is often so. if one could anticipate all possible contexts in which a group of words could occur  one could perhaps enumerate all possible equivalence sets - one for each combination of word group with a set of contexts making the words interchangeable. anyone  however  can see the futility of that aspiration. 
in the end. one settles for messy compromises. words are grouped if a largish set of contexts in which they are interchangeable springs readily to mind. they are separated  into perhaps overlapping groups  if the imagination readily suggests contexts in which their meanings differ  significantly  - whatever  significantly  may mean. in doubtful cases  when words are grouped somewhat questionably  one promises oneself to add markings some day that wilt prevent misuse of the equivalence. when words are separated somewhat questionably  one promises oneself to add a mechanism some day that will recognize their relatedness. 
in the end  too  one assigns internal structure to the equivalence sets. that's the effect of assigning local attributes to the alternative wordings   animate subject    object a vehicle   etc. : constraints are imposed upon the intcrchangeability of the wordings. more radical structuring can be accomplished if. for example  one notes  government  as an alternative wording of the sense  govern  rule  control   with the attribute  nominalization  
the arbitrariness of the equivalence sets is not all that disqualifies them as  conceptual primitives . there is a much deeper difficulty in the fact that practically all  senses  can be paraphrased in terms of other  senses'* take  for example  the intransitive sense of  change   as in   m y   but you've changed!   surely  one would suppose  the concept of  change  must be primitive  change of state is what well-nigh a third of all verbs are about 
but if  change  is a  primitive   it's a peculiar sort of  primitive   for it can be paraphrased in a variety of ways: 
 change  become different  cease to be the same  assume new characteristics  make a transition into a new 
state  
note that the multi-word paraphrasals are not idioms  the individual words contribute their usual meanings to concatenated meanings which express the concept  change . 
but perhaps we were merely unlucky  perhaps we chanced upon a concept which looked elemental but actually turned out to be complex. maybe the real primitives are  become    be    cease    different    same   etc. let's dig into that possibility. 
what does it mean to  become x     where x is an adjective  the meaning can be variously expressed: 
 become x  come to be x  get to be x  get x  turn x  grow x  assume the characteristic x  
that's a discouraging number of ways for a  primitive  to be re-expressible - though if we choose to regard  come to be  and  get to be  as idiomatic concatenations of words  only one of the alternatives makes use of other concepts to explain the one at hand. 
as for  different   it implies a whole underlying anecdote about somebody making a comparison  after first making a judgment about relevant things to compare. in the combination of the two concepts -  become different  -  we furthermore drop mention of the objects being compared. it's simply understood that they arc certain attributes of the subject at two points in time. 
it is tempting to invent ad-hoc  transformational  explanations for these phenomena. one might conjecture  for example  that  the man changed.  is a surface realization of four underlying sentences: 
 man be x at time m. man be y at time n. x not equal y. time n greater-than time m.  
the trouble with explanations of this sort -- apart from the fact that they introduce growing complexity into the understanding of straightforward utterances - is that they assign arbitrary primacy to some concepts at the expense of others. why should 
 time n greater-than time m  
1 
be an assumed primitive  may we not equally well conjecture that  time n greater-than time m  is a surface realization of these : 
 time be m. time change. then time be n.  
for that matter  why not view 
    time elapsed  as a surface form of this : 
  a t least one thing in the universe changed.  
after all  what is  time  but a nominalized way of talking about the presence and partitioning of change  
the difficulty  it would seem  lies in the very notion of contextindependent  conceptual primitives . the metaphor itself is at fault: it calls to mind a fixed set of elements  like those of which matter is composed  out of which all ideas must be compounded. but where concepts are concerned  primitivity is a matter of focus. shift the perspective a little  and new elements swim into view as fundamentals  while former simples become complex 
a more promising metaphor is the analogy to a vector space. a set of basis vectors is  in a way  a set of  primitives  out of which all the entities in the space can be composed. these primitives have the appealing property that they are only primitive relative to one frame of reference rotate your point of view  and what used to come natural as basis vectors are now at an angle; they become easier to express as sums of vectors that lie along new axes. that bears a resemblance to what we have seen in the case of lexical  primitives . 
thus far and no further may the analogy be pushed  however. 
the elements which span  conceptual space  can be no such uniform set of objects as those in a vector space  while the rules of composition are coextensive with grammar - at a minimum. composition of concepts itself contributes to the meaning.  for that matter  it is arguable whether concepts are sufficiently separable to model them as discrete objects at all -- whether simple or composite.  moreover  as  conceptual space  must encompass all things thinkable  the rules of composition must themselves be part of the space. that is  the operators as much as the things operated upon lie within the space to be spanned. 
a seeming counterexample to these remarks may be found in the  primitive act's  of conceptual dependency theory  as propounded by schank  goldman  rieger  and riesbeck     1j  |1    . on a close reading  however  the  primitive act's  turn out to be verb paradigms -- powerful  semantically motivated generalizations about large classes of verbs. the names of these paradigms replace specific verbs as building blocks in the  conceptual  representation of an utterance. the effect is to provide strong guidelines for the inference of unstated information  for the comparison of related utterances  for paraphrasa   etc. 
to represent a particular verb in terms of these act's. however  it is necessary to augment each act with various substructures which detail the manner  the means  the type of actor or object  etc. no reduced set of representatives is as yet offered for the adverbs  nouns  adjectives  etc. in terms of which the  primitive act's  are qualified. if such additional condensation were attempted  the elaboration of a given utterance in terms of the full set of  primitives  might well ramify without practical end in other words  reduction of the set of names for nodes  and labels for arcs  must be purchased at the expense of extending the number of them required to represent each utterance. 
in conceptual dependency representation  just as in the  semantic networks  of quillian   simmons     1  . sloe urn  and others  reality ultimately appears as a shimmering web  every part of which trembles when any part of it is touched upon. taken in its totality  the system - as yet -- is entirely compatible with skepticism about a comprehensive set of  conceptual primitives . 
in any case  the verbal  senses  proposed here lie at a far lower level of generality than the  primitive act's  used in conceptual dependency theory. in terms of that theory  they come closest to the   c o n c e x i c o n entries  used by goldman in realizing surface expressions of a concept from its conceptual representation . given a primitive act  goldman narrows it down to a particular   c o n c e x i c o n   entry by applying the tests in a discrimination tree to the rest of the structure in which the a c t appears. 
our lexical  senses   therefore  are left with a humbled role. if they span anything  it might best be thought of as  communication space   not  conceptual space . even in this light  they are a hugely redundant basis  and a not at all unique one. they form no inventory of the experiences being communicated about;  meaning  is stil  a step removed  still evoked rather than embodied by the elements of this basis. 
if we persist in calling these things  senses   it is because that is the traditional term for what is brought to mind as the synonym sets of a given word are enumerated. the tie-in with meaning is tenuous  but the human user is able to supply it. there is at least this much justification for the term: synonym sets  more forcefully than words  direct attention to the points at which a tie-in must be made between the tokens of communication and the underlying representation of  world knowledge  
in a full-fledged system for processing natural language  then  we must envision the  dictionary of senses  as a component stretching vertically across the  upper  layers. its  sense data items  must link  in some way  to the deeper-lying data structures which encode  knowledge of the world   the  pragmatic component  . the  key data items  and  phrase data items  register tokens to be expected or employed in  surface  utterances. global and local attributes recorded in the various data items guide parsing and interpretation. where one takes it from there depends upon the linguistic approach to be used. 
