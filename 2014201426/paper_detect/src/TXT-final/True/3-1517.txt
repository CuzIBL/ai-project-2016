
this paper presents a novel form of dynamically constructed bayes net  developed for multi-domain sketch recognition. our sketch recognition engine integrates shape information and domain knowledge to improve recognition accuracy across a variety of domains using an extendible  hierarchical approach. our bayes net framework integrates the influence of stroke data and domain-specific context in recognition  enabling our recognition engine to handle noisy input. we illustrate this behavior with qualitative and quantitative results in two domains: hand-drawn family trees and circuits.
1 introduction
there is a gap between how people naturally express ideas and the ability of computers to use that information. for example  while sketching provides a natural way to record design ideas in many domains  sketches are  unavoidably  static pictures. computer aided design tools  on the other hand  offer powerful capabilities  but require designers to interact through buttons and menus. the hardware to draw on the computer exists; the missing element is the computer's ability to interpret hand-drawn symbols in a domain. to address this problem  we are constructing a general sketch recognition architecture applicable to a number of domains  and capable of parsing freely-drawn strokes in real time and interpreting them as depicting objects in the domain of interest.
　sketch recognition involves two related subproblems: stroke segmentation and symbol recognition. segmentation determines which strokes should be grouped to form a single symbol. symbol recognition determines what symbol a given set of strokes represents.
　the difficulty of doing segmentation and recognition simultaneously has led previous approaches to place constraints on the user's drawing style  or focus on tasks where assumptions can greatly reduce segmentation complexity. for example  the multimodal approach in  wu et al.  1  assumes that each symbol will be drawn independently  and that

 currently at harvey mudd college  claremont  ca  1
      this work was funded by the mit icampus project supported by microsoft and mit project oxygen.the user will often say the name of the symbol when drawing it. the approach in  kara and stahovich  1  assumes that the diagram  a feedback control system  consists of shapes linked by arrows  which is not true in other domains.
　while these systems have proven useful for their respective tasks  we aimed to create a more general system  independent of drawing assumptions in any one domain. our system is designed  instead  to be applied to a number of symbolic domains by giving it descriptions of shapes and commonly occurring combinations of shapes. we use these descriptions in a three-stage  constraint-based approach to recognition. our system first relies on a rough processing of the user's strokes to generate a number of interpretation hypotheses. in the second stage  the system uses a novel form of dynamically constructed bayes net to determine how well each hypothesis fits the data. in the third stage  it uses this evaluation to guide further hypothesis generation. this paper focuses specifically on the second stage  exploring hypothesis evaluation; the other two stages are described in  alvarado  1 .
　using bayes nets for hypothesis evaluation offers two advantages over previous constraint-based recognition approaches  e.g.   futrelle and nikolakis  1; hammond and davis  1  . first  our system can interpret drawings as they develop  identifying shapes before they are complete. second  the system's belief in a hypothesis can be influenced by both the strokes and the context in which the shape appears  allowing the system to cope with noise in the drawing.
　we constructed a sketch recognition engine and used it in two domains: family tree diagrams and circuit diagrams. we show that the bayes net successfully allows domain-specific context to help the system overcome noise in the stroke data  reducing interpretation errors compared to a baseline system.
1 dynamically constructed graphical models
while time-based graphical models  e.g.  dynamic bayes nets  have been widely used  they are not suitable for sketch understanding  for two reasons. first  we must model shapes based on two-dimensional constraints  e.g.  touches  rather than on temporal constraints  i.e.  follows . second  our models cannot simply unroll in time as data arrives: we cannot necessarily predict the order in which the user will draw the strokes  and things drawn previously can be changed.
　while it is not difficult to use bayes nets to model spatial relationships  static bayes nets are not suitable for our task

 line hypotheses l1  l1  l1 constraints:
c1 =  coincident line-fit s1 .p1 line-fit s1 .p1 
c1 =  coincident line-fit s1 .p1 line-fit s1 .p1  c1 =  equallength line-fit s1  line-fit s1  
c1 =  shorter line-fit s1  line-fit s1  
c1 =  acuteangle line-fit s1   line-fit s1  
c1 =  acuteangle line-fit s1   line-fit s1  

cs hypothesis cs1 subshapes: arrow hypothesis a1  ellipse hypothesis e1 constraints:
c1 =  contains ellipse-fit s1 shape-fit s1 s1 s1  
figure 1: a single current source hypothesis  cs1  and associated lower-level hypotheses.
because we cannot predict a priori the number of strokes or symbols the user will draw. for sketch recognition  as in related dynamic tasks  models to reason about specific problem instances  e.g.  a particular sketch  must be dynamically constructed in response the input. this problem is known as the task of knowledge-based model construction  kbmc .
　early approaches to kbmc focused on generating bayes nets from probabilistic knowledge bases  glessner and koller  1; haddawy  1 . a recently proposed representation uses generic template knowledge directly as bayes net fragments that can be instantiated and linked together at run-time  laskey and mahoney  1 . finally  koller et al. have developed a number of object-oriented frameworks  koller and pfeffer  1; pfeffer et al.  1; getoor et al.  1 . these models represent knowledge in terms of relationships among objects and can be instantiated dynamically in response to the number of objects in a particular situation.
　although these frameworks are powerful  they are not directly suitable for sketch recognition. first  because of the size of the networks we encounter  it is sometimes desirable to generate only part of a complete network  or to prune nodes from the network. in reasoning about nodes in the network  we must account for the fact that the network may not be fully generated or relevant information may have been pruned from it  see  alvarado  1  for details . second  these previous models have been optimized for responding to specific queries about a single node in the network. in contrast  our model must provide probabilities for a full set of possible interpretations of the user's strokes.
1 network structure
our bayes net model is built around hierarchical descriptions of shapes in a domain  described in a language called ladder  hammond and davis  1 . the basic unit in this language is a shape  which we use to mean a pattern recognizable in a given domain. shapes may be compound  i.e.  composed of subshapes fit together according to constraints. these subshapes also may be compound  but all shapes must be non-recursive. a shape that cannot be decomposed into subshapes  e.g.  a line   is called a primitive shape. primitive shapes may have named subcomponents that can be used when describing other shapes  e.g.  the endpoints of a line   p1  and  p1   used in figure 1.
　we refer to each shape description as a template with one slot for each subpart. a shape hypothesis is a template with an associated mapping between slots and strokes  generated during the recognition process. similarly  a constraint hypothesis is a proposed constraint on one or more of the user's strokes. a partial hypothesis is a hypothesis in which one or more slots are not bound to strokes.
　to introduce our bayes net model  we begin by considering how to model a current source hypothesis  cs1  for the stokes in figure 1. a current source is a compound shape  socs1 involves two lower-level shape hypotheses-e1  an ellipse hypothesis for stroke s1; and a1  an arrow hypothesis involving strokes s1  s1 and s1-and one constraint hypothesis-c1  indicating that an ellipse fit for stroke s1 contains strokes s1  s1  and s1. a1 is also compound and is further broken down into three line hypotheses  l1  l1 and l1  and six constraint hypotheses  c1 ... c1  according to the description of an arrow. thus  determining the strength of hypothesis cs1 can be transformed into the problem of determining the strength of a number of lower-level shape and constraint hypotheses.
　the bayes net used to evaluate cs1 is shown in figure 1. there is one node in the network for each hypothesis; each node represents a boolean random variable that is true if the corresponding hypothesis is correct. the probability of each hypothesis is influenced both through its children by stroke data and through its parents by the context in which it appears  allowing the system to handle noise in the drawing.
　the nodes labeled o1 ... o1 represent measurements of the stroke data that correspond to the constraint or shape to which they are linked. the variables corresponding to these nodes have positive real numbered values that we discretize in our implementation1. for example  the variable o1 is a measurement of the squared error between the stroke s1 and the best fit ellipse to that stroke. its raw value  later discretized  ranges from 1 to the maximum possible error between any stroke and an ellipse fit to that stroke. the boxes labeled s1 ... s1 are not part of the bayes net but serve to indicate the stroke or strokes from which each measurement  oi  is taken  e.g.  o1 is measured from s1 . p cs1 = t|ev   or simply p cs1|ev  1  where ev is the evidence observed from the user's strokes  represents the probability that the hypothesis cs1 is correct.
　the direction of the links may seem counterintuitive  but there are two important reasons why the links are directed from higher-level shapes to lower-level shapes instead of the opposite direction. first  whether a higher-level hypothesis is true directly influences whether a lower-level hypoth-

figure 1: a bayes net to verify a single current source hypothesis. labels come from figure 1.
esis is true. for example  if the arrow hypothesis a1 is true  then it is extremely likely that all three line hypotheses  l1 l1 l1  are also true. second  this representation allows us to model lower-level hypothesis as conditionally independent given their parents  which reduces the complexity of the data needed to construct the network.
　each shape description constrains its subshapes only relative to one another. for example  an arrow may be made from any three lines that satisfy the necessary constraints. based on this observation  our representation models a symbol's subshapes separately from the constraints between them. for example  node l1 represents the hypothesis that stroke s1 is a line. its value will be true if the user intended for s1 to be a
　line  any line regardless of its position  size or orientation. c1 separately represents the hypothesis that the line fit to s1 and the line fit to s1 are the same length.
　the conditional independence between shapes and constraints might seem a bit strange at first. for example  whether or not two lines are the same length seems to depend on the fact that they are lines. however  observation nodes for constraints are calculated in such a way that their value is not dependent on the true interpretation for a stroke. for example  when calculating whether or not two lines are the same length  we first fit lines to the strokes  regardless of whether or not they actually look like lines   then measure their length. how well these lines fit the original strokes is not considered in this calculation.
　the fact that there is no edge between the constraint nodes and the shapes they constrain has an important implication for using this model to perform recognition: there is no guarantee in this bayes net that the constraints will be measured between the correct subshapes because the model allows subshapes and constraints to be detected independently. for example  we want c1 in figure 1 to indicate that l1 and l1  the two lines in the head of an arrow  are the same length  not simply that any two lines are the same length. to satisfy this requirement  the system must ensure that o1 is measured from the same strokes that o1 and o1 were measured from. we use a separate mechanism to ensure that only legal bindings are created between strokes and observation nodes.
　the way we model shape and constraint information has two important advantages for recognition. first  this bayes
1
1
figure 1: a partial sketch of a family tree. quadrilaterals  q  represent males  m ; ellipses  e  represent females  f   and arrows  a  indicate a parent-child relationship.
net model can be applied to recognize a shape in any size  position and orientation. cs1 represents the hypothesis that s1 ... s1 form a current source symbol  but the exact position  orientation and size of that symbol is determined directly from the stroke data 1.
　second  the system can model competing higher-level interpretations for lower-level shapes. for example  the system may consider a stroke to be a line that is in turn part of either an arrow or a quadrilateral. because the line hypothesis does not include any higher-level shape-specific constraint information  both an arrow hypothesis node and a quadrilateral hypothesis node can point to this same line hypothesis node. these two hypotheses then become alternate  competing explanations for the line hypothesis. we further discuss how hypotheses are combined below.
1 recognizing a complete sketch
to recognize a complete sketch  we create a bayes net similar to the one above for each shape. we call each of these bayes nets a shape fragment because they can be combined to create a complete bayes net for evaluating the whole sketch.
　given a set of hypotheses for the user's strokes  hypothesis generation is described in  alvarado and davis  1  and  alvarado  1    the system instantiates the corresponding shape fragments and links them together to form a complete bayes net  called the interpretation network. to illustrate this process  consider a piece of a network generated in response to strokes 1 and 1 in the example of figure 1. figure 1 shows the part of the bayes net representing the hypotheses that the system generated for these strokes. low level processing recognizes strokes 1 and 1 as l-shaped polylines and breaks each into two individual lines  l1...l1  that meet.
1 linking shape fragments
when bayes net fragments are linked during recognition  each node hn may have several parents  s1...sm  where each parent represents a possible higher-level interpretation for hn. we use a noisy-or function to combine the influences of all the parents of hn to produce the complete conditional probability table  cpt  for p hn|s1 ... sm . the noisy-or function models the assumption that each parent can independently cause the child to be observed. for example  a single stroke might be part of a quadrilateral or an arrow  but both interpretations would favor that interpretation of the stroke as a line. we set p hn = f|sj = t  = 1 for all parents sj in which hn is a required subshape or constraint  and we set p hn = f|sk = t  = 1 for all parents sk in which hn is an optional subshape or constraint. a consequence of these values is that sj = t   p hn|s1 ... sm  = 1 for any sj in which hn is required  which is exactly what we intended.
　we experimented with a noisy-xor construct  implemented using a  gate node  similar to that described in  boutilier et al.  1   but found that noisy-or semantics were simpler and in fact produced better results. in effect  a noisy-or node in a bayes net with low prior probabilities behaves as a non-aggressive xor. the fact that one parent is true does not actively prohibit the other parents from being true  but it causes their probabilities to tend back to their prior values because of the  explaining away  phenomenon.
1 signal level noise
the bottom layer of the network deals with signal level noise by modeling the differences between the user's intentions and the strokes that she draws. for example  even if the user intends to draw l1  her stroke likely will not match l1 exactly  so the model must account for this variation. consider p o1|l1 = t   recall that o1 is a discretized continuous valued variable . if the user always drew perfect lines  this distribution would be 1 when o1 = 1  i.e.  the error is 1   and 1 otherwise. however  most people do not draw perfect lines  due to inaccurate pen and muscle movements   and this distribution allows for this error. it should be high when o1 is close to zero  and fall off as o1 gets larger. the wider the distribution  the more error the system will tolerate  but the less information a perfect line will provide.
　the other distribution needed is p o1|l1 = f  which is the probability distribution over line error given that the user did not intend to draw an line. this distribution should be close to uniform  with a dip around 1  indicating that if the user specifically does not intend to draw an line  she might draw any other shape  but probably won't draw anything that resembles an line. details about how we determined the conditional probability distributions between primitive shapes and constraints and their corresponding observation nodes are given elsewhere  alvarado  1 .
1 missing strokes
a1 is a partial hypothesis-it represents the hypothesis that l1 and l1  from stroke 1  are part of an arrow whose other line has not yet been drawn. line nodes representing lines that have not been drawn  e.g.  l1  are not linked to observation nodes because there is no stoke from which to measure these observations. we refer to these nodes  and their corresponding hypotheses  as virtual.
　the fact that partial hypotheses have probabilities allows the system to assess the likelihood of incomplete interpretations based on the evidence it has seen so far. in fact  even virtual nodes have probabilities  corresponding to the probability that the user  eventually  intends to draw these shapes but either has not yet drawn this part of the diagram or the

figure 1: a portion of the interpretation network generated while recognizing the sketch in figure 1.
correct low-level hypotheses have not yet been proposed  because of low-level recognition errors . a partial hypothesis with a high probability cues the system to examine the sketch for possible missed low-level interpretations during the hypothesis generation step.
1 implementation and bayesian inference
our system updates the structure of the bayes net in response to each stroke the user draws  using an off-the-shelf  open source bayes net package for java called bnj  bnj  1 .
　generating and modifying the bnj networks can be time consuming due to the exponential size of the cpts between the nodes. we use two techniques to improve performance. first  networks are generated only when the system needs to evaluate the likelihood of a hypothesis. this on-demand construction is more efficient than continuously updating the network  because batch construction of the cpts is often more efficient than incremental construction. second  the system modifies only the portion of the network that has changed between strokes  rather than creating it from scratch every time. we experimented with several inference methods and found that loopy belief propagation  loopy bp   weiss  1  was the most successful1. on our data  loopy bp almost always converged  messages initialized to 1  run until node values stable within 1 . we further limited the algorithm's running time in two ways. first  we terminated the algorithm after 1 seconds if it had not yet converged. second  we allowed each node to have no more than 1 parents  i.e.  only 1 higher-level hypotheses could be considered for a single hypothesis   ensuring a limit on the complexity of the graphs produced. these restrictions had little impact on recognition performance in the family tree domain  but for complex domains such as circuit diagrams  more efficient inference algorithms or graph simplification techniques are needed to improve recognition results.
1 application and results
we applied our implemented system to two non-trivial domains-family trees and circuits-and found that it is capable of recognizing sketches in both domains without reprogramming. qualitative and quantitative evaluation of our
1

	 a 	 b 	 c 
figure 1: part of three possible ground symbols.
system illustrates its strengths over previous approaches and suggests some extensions.
　applying our system to a particular domain involves two steps: specifying the structural descriptions for the shapes in the domain  and specifying the prior probabilities for toplevel shapes and domain patterns  i.e.  those that will not have parents in the bayes net. for each domain  we wrote a description for each shape and pattern in that domain. we handestimated priors for each domain pattern and top level shape based on our intuition about the relative prevalence of each shape. for example  in family-tree diagrams  we estimated that marriages were much more likely than partnerships  and set p mar  = 1 and p part  = 1. these priors represent the probability that a group of strokes chosen at random from the page will represent the given shape and  in most cases  should be relatively low. although setting priors by hand can be tedious  we found through experimentation that the system's recognition performance was relatively insensitive to the exact values of these priors. for example  in the circuit diagrams  increasing all the priors by an order of magnitude did not affect recognition performance; what matters instead is the relative values of the prior probabilities.
　our system is capable of recognizing simple sketches nearly perfectly in both the family-tree and circuit domains. we also tested its performance on more complex  real-world data. as there is no standard test corpus for sketch recognition  we collected our own sketches and have made them available online to encourage others to compare their results with those presented here  oltmans et al.  1 . in total  we tested our system on 1 family tree sketches and 1 circuit diagram sketches  with between 1 and 1 strokes each.
1 qualitative results
qualitative analysis reveals that the bayes net mechanism successfully aggregates information from stroke data and context  resolves inherent ambiguities in the drawing  and updates its weighting of the various existing hypotheses as new strokes are drawn. we show through an example that the bayes net scores hypotheses correctly in several respects: it prefers to group subshapes into the fewest number of interpretations  it allows competing interpretations to influence one another  it updates interpretation strengths in response to new stroke data  and it allows both stroke data and context to influence interpretation strength.
　to illustrate the points above  we consider in detail how the system responds as the user draws the three sets of strokes in figure 1  a ground symbol . to simplify the example  we consider a reduced circuit domain in which users draw

figure 1: the bayes net produced in response to the strokes in each ground symbol in figure 1. the shaded area shows the network produced in response to the first two strokes.
namep shape|
after 1 strokes
	 a 	 b 	 c stroke data  after 1 strokes
	 a 	 b 	 c wire-1.1.1.1.1.1.1wire-1.1.1.1.1.1.1wire-1n/an/an/a111battery-1.1.1.1.1.1.1battery-1n/an/an/a111ground-1.1.1.1.1.1.1table 1: posterior probabilities for part of the network in figure 1 for each sketch in figure 1.
only wires  resistors  ground symbols and batteries. figure 1 shows the bayes nets produced in response to the user's first two and first three strokes. after the first two strokes  the network contains only the nodes in the shaded area; after three strokes it contains all nodes shown. continuous variables corresponding to observation nodes were discretized into three values: 1  low error: stroke data strongly supports the shape or constraint   1  medium error: stroke data weakly supports the shape or constraint   and 1  high error: stroke data does not support the shape or constraint .
　posterior probabilities are given in table 1. for the relatively clean ground symbol  figure 1 a    the stroke data strongly supports all the shapes and constraints  so all shaded nodes in figure 1 have value 1. after the first two strokes  the battery symbol and the ground symbol have equal weight  which may seem counterintuitive: after two strokes the user has drawn what appears to be a complete battery  but has drawn only a piece of the ground symbol. recall  however  that the bayes net models not what has been drawn  but what the user intends to draw. after two strokes  it is equally likely that the user is in the process of drawing a ground symbol. after the third stroke  the ground symbol's probability increases because there is more evidence to support it  while the battery's probability decreases. the fact that the ground symbol is preferred over the battery illustrates that the system prefers interpretations that result in fewer symbols  okham's razor . interpretations that involve more of the user's strokes have more support and get a higher score in the bayes net. the fact that the battery symbol gets weaker as the ground symbol gets stronger results from the  explaining away  behavior in this bayes net configuration: each of the low-level components  the lines and the constraints  are effectively  explained  by the existence of the ground symbol  so the battery is no longer needed to explain their presence.
　another useful property of our approach is that a small amount of noise in the data is counteracted by the context provided by higher-level shapes. the slightly noisy second and third strokes in figure 1 b  cause the values of sqerr1 and sqerr-1 to be 1 instead of 1  all other shaded node values remain 1 . despite this noise  after three strokes the posterior probability of the ground symbol interpretation is still high  1   because line-1 and all of the constraints are still strongly supported by the data. in addition  the probabilities for line-1 and line-1 are high  both 1  not shown in table 1   indicating that the context provided by the ground symbol provides support for the line interpretations even when the evidence from the data is not as strong.
　on the other hand  if the data is too messy  it causes the probability of the higher-level interpretations to decrease. the sketch in figure 1 c  causes the value of sqerr-1 to be 1  and sqerr-1 to be 1  and results in a low posterior probability for ground-1  1  and a high posterior for battery-1  1   because the hypothesis line-1 is contradicted by the user's third stroke. for now  the third stroke remains uninterpreted.
1 quantitative results
we ran our system on all of the sketches we collected and compared its performance to a baseline constraint-based recognition system that used a fixed threshold for detecting shapes and constraints and did not reinterpret low-level shapes. we measured recognition performance by determining the number of objects identified correctly in each sketch. our system significantly outperformed the baseline system  p 1   correctly recognizing 1%  f=1  of the shapes in the family tree diagrams and 1%  f=1  of the shapes in the circuit diagrams  while the baseline system correctly recognized 1%  f=1  and 1%  f=1 .
　while not yet real time  in general our system's processing time scaled well as the number of strokes increased. however  it occasionally ran for a long period. the system had particular trouble with areas of the sketch that involved many strokes drawn close together in time and space and with domains that involve more complicated or overlapping symbols. this increase in processing time was due almost entirely to increase in bayes net complexity.
　we believe we can speed up loopy bp based on the observation that it repeatedly sends messages between the nodes until each node has reached a stable value. when a stroke is added  our system resets all messages to 1  essentially erasing the work done the last time inference was performed  even though most of the graph is unchanged. the algorithm should instead begin with the messages that remain at the end of the previous inference step.
1 conclusion
we have described a model for dynamically constructing bayes nets to represent varying hypotheses for the user's strokes. our model  specifically developed for the task of recognition  allows both stroke data and contextual data to influence the probability of an interpretation for the user's strokes. using noisy-or  multiple potential higher-level interpretations mutually influence each other's probabilities within the bayes net. the net result is a sketch recognition approach that brings us a significant step closer to sketching as a natural and powerful interface.
