 
this paper describes a partial reimplementation of doug smith's cypress algorithm design system within the soar problem-solving architecture. the system  cypress-soar  reproduces most of cypress' behavior in the synthesis of three divide-and-conquer sorting algorithms from formal specifications. cypress-soar is based on heuristic search of problem spaces  and uses search to compensate for missing knowledge in some instances. cypress-soar also learns as it designs algorithms  exhibiting significant transfer of learned knowledge  both within a single design run  and across designs of several different algorithms. these results were produced by reimplementing just the high-level synthesis control of cypress  simulating the results of calls to cypress* deduction engine. thus after only two months of effort  we had a surprisingly effective research vehicle for investigating the roles of search  knowledge  and learning in this domain.* 
i introduction 
　good human programmers have at least two remarkable abilities: they manage to produce programs in the face of incomplete knowledge  and they make use of previous experience in solving new problems. how could we get automatic programming systems to produce the same intelligent behavior  al-based performance systems in other domains compensate for incomplete knowledge by searching through a space of possible solutions  and there exist a variety of mechanisms for learning from experience. however  automatic programming research has so far produced only a few systems that either search or learn  and  to my knowledge  none that do both. this is true despite the field's growing acknowledgement of the importance of both search and learning  1 1 . 
　this paper describes a prototype system that both searches and learns while performing part of an automatic programming task. an algorithm design system  previously built within a special-purpose framework  was reimplemented in a more general problem-solving architecture with built-in search and learning capabilities. the previously implemented system is doug smith's cypress  1 1   which is most noted for its design of divide-and-conquer algorithms. the foundation for the reimplementation is soar  1   an architecture for general intelligence developed by john laird  
allen newell  and paul rosen bloom. the combined system  cypresssoar  produces the bulk of three of cypress' sorting algorithm derivations  and takes advantage of the properties of soar to search and learn while doing so. 
　in section ii  i describe cypress and its approach to the synthesis of divide-and-conquer sorting algorithms and in section iii i give an overview of the soar architecture. the remaining sections discuss cypress-soar  presenting the following results: 
  performance without fixed design strategies: cypresssoar uses any knowledge available at run-time to decide when algorithm refinement operators should be applied. if the knowledge is unavailable  cypress-soar automatically falls back on general problem-solving methods  initiating lookahead search to evaluate the possibilities. in contrast  design strategies control operator application in cypress  and any necessary search must be guided by an expert user.  section iv  
  transfer of learned knowledge: cypress-soar knows what goal it is working on  and caches the result of the goal for future use. because some goals show up more than once  this 
　*this research was supported in part by the national science foundation under grant dcr-1. and in part by the defense advanced research projects agency under contract f1-1 -k-1. work on cypress-soar was begun while the author was visiting kestrel learning mechanism reduces problem-solving effort  both within the design of a single algorithm  and on later designs of different algorithms. cypress does not learn  and consequently can not take advantage of repeated subgoals. 
 section v  
　section vi concludes with a discussion of several issues involved in extending the prototype cypress-soar system into a more general automatic algorithm designer. 
ii how cypress designs divide-and-conquer algorithms 
　cypress is a semi-automatic system that derives algorithms from formal specifications. it works by top-down refinement of program schemes  or templates  which represent abstractions such as divide-and-conquer and generate-and-test. a problem specification is matched against a program scheme  and with the aid of a design strategy  decomposed into specifications of simpler problems. this problem reduction process continues recursively until a specification can be solved directly by primitive operators known to the system. when more than one design strategy is applicable  or more than one operator matches a specification  the user makes a selection among alternatives. 
　cypress spends most of its time in calls to rainbow  its deduction engine. rainbow performs a generalized version of theorem-proving known as antecedent derivation . given a set of hypotheses  h and a goal formula  g  rainbow tries to give the weakest possible precondition  or antecedent  p such that the hypotheses in h conjoined with p imply g. if p is just true  then g is already a valid formula given h. in the context of algorithm synthesis  rainbow is used to reason backwards from output conditions to test if a specification is satisfied. if it is not satisfied  the derived antecedent is used as dictated by the active design strategy as the basis for further action. viewed in problem-solving terms  rainbow provides a sophisticated form of means-ends analysis. 
　the input to cypress is a formal specification of the problem to be solved  giving the input and output domains  types  or sets   and input and output conditions for the problem. a specification of the problem of sorting lists of natural numbers from  is 
s o r t : x = z such that bag:x=bag:z a ordered:z where sort: list n -- list n . 
the sort function maps the input x into the output z. an implicit input condition  true is assumed. the output condition is that the bag  multiset  of elements in x is the same as in z  and z is ordered. the specification assumes pre-existing knowledge of the terms  bag  and  ordered . 
　the sorting problem is amenable to a divide-and-conquer solution. the cypress scheme for divide-and-conquer is expressed in a typed functional programming language  a derivative of backus' fp : 
	f:x 	if 
primitive:x -  directly solve:x  
   --primitive:! -  compose     g x f     decompose:x fi 
the scheme abstractly specifics how to compute the value of f on input r. 
if x is a base-case input  then solve it directly; otherwise  decompose x into two subproblems  recursively solve one and apply an auxiliary function g to the other  then compose the results. 
	steier 	1 
　
　to instantiate this scheme for a given specification  cypress creates subspecifications for directly.solve  compose  and decompose  and then attempts to design algorithms for these subspecifications or to verify that known operators satisfy them. along the way  the auxiliary function g is refined  usually either to a recursive call to the top-level algorithm  or to the identity operator  id. the primitive control predicate is derived as the input condition to decompose. 
　the design strategies for instantiating the divide-and-conquer scheme allow the choice of either simple decomposition or simple composition operators. for sorting  choosing a simple decomposition operator leads to insertion-sort and mergesort  while a simple composition operator leads to selection-sort and quicksort. the algorithms for the top levels of the quicksort and partition algorithms are 

　the top level function for quicksort is a divide-and-conquer scheme that uses the simple composition operator append  while the partition algorithm called by quicksort is the scheme instantiated to use the simple decomposition firstrest  equivalent to returning the head and tail of a list . the top level function qsort is the conventional quicksort: if x is of length 1 or 1  it returns x. otherwise  it partitions x into two sublists  sorts them both and appends the results. the partition algorithm created by cypress differs from the standard partition algorithm in that it is a divide-and-conquer algorithm  and it does not use a partitioning element if there are only two elements in the list  it produces two singleton lists  with the smaller element in the first list. otherwise  it builds up two lists by recursively partitioning off the rest of the list  and adding each element in turn to the appropriate sublist as determined by its value. the functions implementing partition directly solve and partition compose for the partition algorithm were also produced by cypress  but are not shown here. 
ill soar 
　cypress-soar is built in soar  an architecture developed to study the computational mechanisms necessary for intelligent behavior  1 . soar is based on the hypothesis that all goal-directed cognitive activity can be represented as search in a problem space. a problem space is defined by a set of states  and a set of operators to move from state to state. soar uses knowledge  represented as productions  to generate and select problem spaces  states  and operators to move towards a goal state. the knowledge accumulates in the elaboration phase and is used as a basis for action in the decision phase of each decision cycle  the basic unit of problem-solving effort in soar-based systems. several productions may fire in accumulating the knowledge to make a given decision  about 1 productions per decision cycle for cypress-soar . 
　often the knowledge directly available in a given situation is insufficient to determine the next thing to do immediately. in soar  such situations are called impasses'  subgoals arise exclusively in response to these impasses. the types of impasses that may arise in soar systems are determined by the architecture. for example  a common impasse  operator-tie  occurs when several operators are proposed as acceptable for application to a given state  and there is insufficient knowledge to choose between them. the subgoal to resolve an operator-tie impasse would be satisfied when the system acquired knowledge indicating that one of the operators initially causing the tie is actually preferable to all other candidates. 
　when soar finishes working on a subgoal  it can learn from its experience by building productions called chunks for use in future problem solving. the conditions of a chunk are the features of the pre-impasse situation that were used to produce the results of the subgoal  where the results are those working-memory elements created in the subgoal  or its subgoals  etc.  that are accessible from a supergoal. the actions of a chunk are based on the results. at first glance one would expect chunking to yield nothing more than rote learning  but generalization does occur because chunks test only relevant attributes of the problem-solving context . 
　the soar architecture has by now been subjected to extensive study and experimental use in many applications. soar systems have solved problems and learned in domains ranging from the traditional ai toy problems such as the eight-puzzle to more complex knowledge-intensive tasks  such as the part of vax configuration performed by the rl expert system . other work has demonstrated that soar can exhibit the behavior of a wide variety of problem-solving methods . also  chunking  which was developed 
1 	knowledge acquisition 
from psychological models of human learning   has proven to be a powerful mechanism capable of improving performance in many applications. therefore  while soar is not yet a complete model for intelligent behavior  it already demonstrates many of the characteristics necessary for such a model. 
iv cypress-soar 
　one encodes a task in soar by writing productions implementing one or more task problem spaces. cypress-soar consists of 1 soar  version 1  productions. of these productions  1 contain soar's default search control knowledge  and the remaining 1  comprising about 1 lines of text  are task-specific. this section describes the problem spaces in cypress-soar implemented by the task-specific productions. the derivation of the quicksort algorithm discussed earlier is summarized to illustrate the operation of the system. 
　cypress-soar follows the same principles of  soarware engineering  used in the construction of rl-soar . the top level problem space attempts to apply a single operator  conf igure-backplane in rlsoar  synthesize in cypress-soar  to solve the problem. because no productions implement this operator directly. soar creates a subgoal to implement it  selecting a special problem space associated with this operator. this problem space in turn contains other operators which may be themselves implemented in other problem spaces  or else implemented directly by productions that fire in the appropriate context in this manner  tasks are decomposed into problem spaces in the same way that large conventional programs are broken up into modules. other problem spaces are evoked to handle search control  such as the selection of operators. 
　inn cypress-soar  the synthesize operator is implemented by subgoaling into the synthesize problem space. in this space  operators may be applied to synthesize either a divide-and-conquer algorithm  or a simple conditional. this paper focuses on the creation of divide-and-conquer algorithms  for which the states in the synthesize space arc the successive refinements of the divide-and-conquer program scheme. the initial state is a completely abstract scheme  and the desired state is a scheme with all of its parts refined to known operations. the specify-decompose  
specify-auxiliary  	specify-primitive  
specify-compose  and specify-directly-solve operators map directly onto the parts of the scheme that need to be refined. specify-ordering chooses a well-founded ordering on the input domain to be preserved by the decomposition operator; this is necessary to guarantee that the synthesized algorithm terminates. each of these operators is implemented in its own problem space  where the knowledge about divide-and-conquer taken from cypress is used for operator selection and implementation. in the specify-decompose  specify-compose  and specify-directly-solve problem spaces  the synthesize operator may be recursively invoked to satisfy specifications for complex algorithms. for example  the specify-decompose problem space is used to refine the divide-and-conquer algorithm's decompose operation. for decomposing lists  operators in this problem space might choose firstrest  which returns the element at the head of the list along with the rest of the list. however  suppose one desires an algorithm that uses a simple method of composing lists  say the cons operator. then firstrest will probably not suffice for the decomposition  because firstrest does not satisfy a strong enough output condition to guarantee correct results with the chosen composition method. the existence of such constraints imposed by already instantiated parts of the algorithm will make other refinement operators acceptable. in this case  cypress-soar uses an antecedent derived from the output conditions of the problem specification  the auxiliary operator  and the specification of cons in conjunction with knowledge about divide-and-conquer to find a stronger output condition for the decomposition specification. 
　a complete implementation of some of the operators in the synthesize space would require a separate space for deduction  the kind done by cypress' rainbow . in developing cypress-soar  we wanted to focus on the knowledge involved in making design choices  rather than on deduction  so we simulated rainbow's behavior without implementing it in soar. cypress-soar includes rules that return the results of calls to rainbow on the particular sets of premises and goal formulae needed for the sorting derivations. while this is inadequate for a fully general design system  it is sufficient for an investigation of search and learning at the design choice level  where the method of deduction does not affect the results. 
　for the sorting specification  cypress-soar currently has the knowledge to design insertion-sort  mergesort  and quicksort  though it could easily be extended to design selection-sort . figure 1 illustrates the behavior of cypress-soar during its synthesis of quicksort. the first column describes the major choices made in the design. the second column states the design alternative that cypress-soar selected  and the third column lists any alternatives that were rejected. the fourth column classifies the processes and knowledge involved in making the choices 
　
using the following categories: 
  lookahead: candidates are evaluated by trying them out to see if they lead to a complete algorithm. 
  derived antecedent'. an antecedent is derived from the con-straints imposed by previous design choices. 
  domain compatibility. the input or output domain of the proposed refinement be compatible with a domain commitment resulting from a previous design choice or from the specification. 
  operator match: the specification of a known operator matches the specifications set up for the subproblem being solved. 
  preselected preferences: preferences dictating some of the choices are set up beforehand in order to produce a specific sorting algorithm. extra attributes added to the specification for each different synthesis trigger these preferences. 
　the creation of divide-and-conqucr algorithms at two levels results from decisions #1 and #1. while the forms of these algorithms are chosen in decisions #1 and #1. the specification for the partition subalgorithm is first derived in decision #1  but the input condition must be strengthened in order for the specification to be satisfiable. in making decision #1  cypress-soar suggests candidates for the new input condition  rejecting the first two because they lead to an unsatisfiable subspecification for 
directly-solve. with the exception of the synthesis of directly-solve and compose for partition  which require knowledge about conditionals rather than just divide-and-conquer  and the details of the deduction  the behavior in designing quicksort is the same as that of cypress. 
　furthermore  this behavior was obtained without the fixed design strategies controlling the synthesis in cypress. cypress-soar has enough task knowledge so that it can exhibit the characteristic behavior of the design strategies  but it is not constrained to follow a fixed procedure. this is possible for the same reasons that soar can exhibit the behavior of the weak methods  such as steepest-ascent hill climbing  without having to be programmed explicitly to do so . soar-based systems propose applying an operator as soon as enough knowledge is available to apply it  as determined by the current state and the preconditions of the operator. the appropriate behavior is thus determined at run-time rather than system design time  by evaluating these operators. if cypress-soar goes into a subgoal to carrv out the evaluation process  the result of the subgoal will be saved as a chunk. such chunks may produce future behavior corresponding to the effects of one of cypress' design strategies. 
v search and learning in cypress-soar 
　because of the soar-based foundation of cypress-soar  we were able to run several experiments measuring the effects of search control knowledge and learning on the problem-solving effort required for algorithm design. for example  when cypress-soar has complete search control knowledge  the lengths of solutions reflect only the processing required to fill in all the details of the algorithm. it is possible to remove the search control knowledge from cypress-soar so that search is required as well  by removing 1 of the 1 productions. cypress-soar still yields correct algorithms under these conditions  albeit with greater problemsolving effort  a factor of 1 to 1 more decision cycles . 
　then using chunking  we can measure the effects on solution lengths of learning from experience  not only on different algorithms  but also with different levels of search control knowledge. in some cases  the effects of learning are more pronounced when search control knowledge is absent. this is true not only because the solutions from which effort can be saved are longer  but also because the larger number of impasses lead to more opportunities for learning. 
　figure 1 shows the effects of chunking in cypress-soar with the search control knowledge removed. the three clusters of bars give the lengths of syntheses of insertion-sort  mergesort  and quicksort under various learning conditions. the first bar in each cluster shows the number of decision cycles used by cypress-soar with no previous learning and learning off during the run. the second bar displays the solution length again with no previous learning  but with learning on during the run. the last three bars in each cluster give solution lengths with previous learning on each of the three algorithms  with learning off during the run.'' 
　the second bars of each cluster in figure 1 illustrate what is known as within-trial transfer  a relatively rare phenomenon in the machine learning literature. within-trial transfer results in cypress-soar because knowledge learned early in the design of an algorithm is applied productively later in the same design. in the runs with full search control  learning has little effect  since there is no search  and the operators perform distinct functions. however  in the runs with minimal search control  the search 

further experiments with learning on more than one algorithm or more than one learning 

	steier 	1 trial showed no noteworthy additional reductions. 


figure 1: effects of learning with minimal search control 
leads to a large number of similar situations and operator applications  and with the generalization performed by chunking  much redundant problemsolving effort can be saved. this is especially true in in the quicksort synthesis where the system needs to search for the right input condition for partition: the reduction in decision cycles from learning is close to 1%. 
　in cypress-soar  the majority of the within-trial transfer results from the need to actually apply an operator after it has been evaluated by lookahead. since evaluating an operator by lookahead implies computing the result of the operator in the process  after lookahead there will be a chunk that directly creates the new state once the operator is actually selected. the context in which the chunk fires is identical to the one in which the chunk was formed  so the transfer is not very surprising. 
　the remaining within-trial transfer occurs when an algorithm is synthe sized for a subproblem specification in one context  and the same specification shows up again later in another context in the same design. an example of this shows up in the quicksort derivation. in synthesizing partition  cypress-soar proposed three possible input conditions in searching for the correct one  each time retaining the same output condition. since the specification for the composition subalgorithm was unaffected by changes in the input condition  the same composition algorithm could be used on each attempt. with minimal search control  the savings from eliminating redundant syntheses of the composition amounted to about onefifth of the total problem-solving effort of the run without learning. in more complicated algorithms and specifications  one would expect the savings from learning to be even greater. 
　the last three bars show that cypress-soar also exhibits across-trial transfer  improving performance on subsequent designs of the same algorithm  and across-task transfer  applying knowledge learned from the design of one algorithm to subsequent designs of different algorithms. for example  with full search control and no learning  it took cypress-soar 1 decision cycles to synthesize insertion-sort. as one might expect  it took almost no effort to synthesize quicksort after learning on it  only 1 decision cycles  a savings of 1%. but some of the transfer also occurred after designing the other algorithms: 1 decision cycles after mergesort and 1 after quicksort  savings of 1% and 1% respectively. reductions of 1% in solution lengths were observed across all pairs of algorithms  in both the minimal and the full search control runs. 
　the transfer occurs mostly because all three algorithms solve the same problem  namely sorting. each sorting algorithm must decompose lists  and so the same well-founded ordering by list length can be preserved by all three top-level decomposition operators. other transfer occurs in implementing simple deduction operators  such as negating certain logical expressions. also  refining directly solve to id led to transfer between mergesort and quicksort  because in both cases the input is either a singleelement or null list. there is no transfer to insertion-sort  because there the input condition specifies only sorting null lists. the representation of the input condition would have to be changed for the matcher  which only fires chunks in the case of an exact syntactic match to the context  to detect that an operator that handled a certain type of input could also handle subsets of that input. 
vi discussion 
while a system that designs three algorithms is better than a system that 
1 	knowledge acquisition 
only designs one  cypress-soar is still not a general automatic algorithm designer  not even within the class of divide-and-conquer algorithms. this is mainly due to the special-case rules for deduction and conditional synthesis  a consequence of the strategic choice in this research to focus first on search and learning in a few divide-and-conquer algorithms. for a general system  one would need to implement additional problem spaces that would perform these functions. we foresee no theoretical barriers to such extensions. the major hurdles to be dealt with are the construction of better interfaces for working with logical formulae in soar  and the efficiency of a soar-based deduction engine. 
　perhaps most important is that with the existing chunks and the ability to precisely measure across-task transfer  cypress-soar forms a unique experimental vehicle with which to explore the potential for learning in this domain. the degree to which a soar-based system can apply chunks to improve its performance depends on how often similar situations are repeated as subgoals while problem-solving. the repetition may be less frequent than it could be because cypress-soar does not currently break 
down the deduction into subgoals. it is likely that more transfer would occur if the deduction engine were implemented completely within soar. more fundamentally the representation used by cypress-soar may need to capture abstractions common to the algorithms in the syntax of the representation language. on the other hand  it may be the case with these sorting algorithms that no further transfer is possible; that the design processes needed for their creation are just not very similar. 
　while much work remains to be done  it is encouraging that the current results were obtained in cypress-soar with only two months' work. this demonstration that a formal theory of design is fully compatible with a general framework for intelligent action was possible only because of the strong foundations available in the work on cypress and soar. it is also encouraging that the issues raised in the course of developing cypresssoar have seemed to be worthwhile research topics; in addressing them  we expect to gain useful insights about algorithms and the processes involved in their design. 
acknowledgements 
　i am most grateful to doug smith and the kestrel institute for providing me with the opportunity and the environment to begin this research  and to allen newell for numerous discussions during the development of 
cypress-soar. doug smith  allen newell  elaine kant  john laird  craig knoblock  dorothy setliff and oren etzioni also made useful comments on earlier drafts of this paper. 
