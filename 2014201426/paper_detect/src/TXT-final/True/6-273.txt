a visual-sensor model for mobile robot localisation 
	matthias fichtner 	axel grofimann 
department of computer science 
technische universitat dresden 
dresden  germany 

1 introduction 
due to recent advances in robot hardware  there is a great demand for vision-based robot localisation techniques  desouza and kak  1 . we present a probabilistic sensor model for camera-pose estimation in hallways and other known structured environments. given a 1d geometrical map of the environment  we want to find an approximate measure of the probability that a given camera image has been obtained at a certain place in the robot's operating environment. our sensor model is based on feature matching techniques that are simpler than state-of-the-art photogrammetric approaches. this allows the model to be used in probabilistic robot localisation methods  such as monte carlo localisation  mcl   dellaert et al  1 . we have combined photogrammetric techniques for feature projection with the flexibility and robustness of mcl. moreover  our approach is sufficiently fast to allow for sensor fusion. that is  by using distance measurements from sonars and laser in addition to the visual input  we may be able to improve localisation accuracy. we have used our sensor model with mcl to track the position of a pioneer 1 robot navigating in a hallway. possibly  our approach can be used also for localisation in cluttered environments and for shape-based object detection. 
¡¡in the next section  we briefly describe the components of the visual-sensor model. we conclude with a discussion of experimental results. 
1 sensor model 
a visual-sensor model describes the probability of obtaining a particular camera image given the camera's pose and a geometrical map of the environment. rather than comparing camera image and the expected view at the pixel level  we gained improved robustness using image features. we decided to use line segments because they can be detected comparatively reliably under changing illumination conditions. as world model  we use a wire-frame model of the operating environment  represented in vrml. the individual processing steps are depicted in figure 1. 
¡¡representation. each straight-line feature is represented as a single point in the 1d hough space given by where end-points are neglected. in 
this representation  truncated or split lines have similar coordinates. 

figure 1: processing steps of the visual-sensor model. 
¡¡similarity measures. the correspondence of image and model features is evaluated by a similarity measure. in general  such a measure may take into account the differences in orientation between corresponding line segments in image and model  or their distance and difference in length. in the following  we present two simple and efficient similarity measures. the first is solely based on the distance of line segments in the hough space. we consider only those image features as possible matches that lie within a rectangular cell in the hough space centred at the model feature. the matches are counted and the resulting sum is normalised. the mapping from the expectation  model features  to the measurement  image features  accounts for the fact that the measure should be invariant with respect to objects not modelled in the provided map or unexpected changes in the operating environment. invariance of the number of visible features is obtained by normalisation. specifically  this centred match count  cmc  measure scmc is defined as: 

where the predicate m defines a valid match using the distance parameters  and the operator # counts the number of matches. generally speaking  this similarity measure computes the proportion of expected model hough points that are confirmed by at least one measured image 
hough point falling within tolerance  note that neither endpoint coordinates nor lengths are considered here. the second measure is based on a comparison of the total length values of groups of lines  which we name grid length match  glm . split lines in the image are grouped together using a uniform discretisation of the hough space. this method is similar to the hough transform for straight 

poster papers 	1 


1 
poster papers 
