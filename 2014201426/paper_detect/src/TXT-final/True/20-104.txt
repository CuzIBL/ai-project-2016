 
　　one of the most highly touted virtues of knowledge-based expert systems is their ability to construct explanations of deduced lines of reasoning. however  there is a basic difficulty in generating explanations in expert systems that reason under uncertainty using numeric measures. in particular  systems based upon evidential reasoning using the theory of belief functions have lacked any facility for explaining their conclusions. in this paper we review the process whereby other expert system technologies produce explanations  and present a methodology for augmenting an evidential-reasoning system with a versatile explanation facility. the method  which is based on sensitivity analysis  has been implemented and a simple example of its use is described. 
	i 	introduction 
　　one of the most highly touted virtues of knowledge-based expert systems is their ability to construct explanations of deduced lines of reasoning. endowing such systems with an explanation facility has two major advantages . first  it contributes to the transparency of the program. that is  it allows the user to observe  and perhaps question  the individual inferences that contribute to the conclusions that are reached. this ability to examine the inner workings develops a sense of confidence in the mind of the user; he can become satisfied that the system really  knows  what it is doing and has not just happened upon a plausible conclusion. an explanation capability is thus an important ingredient in user acceptance of a knowledge-based system. secondly  explanations can be a useful tool for the knowledge engineer. information gained by questioning the system about its own knowledge base can be valuable for debugging and refining the stored knowledge. randall davis' teiresias is a good example of a system that exploits explanations for the purpose of knowledge engineering . 
　throughout the history of artificial intelligence research  there has been much interest in developing knowledge-based systems that can reason with information that is uncertain or inexact in one way or another. several technologies have been proposed for representing knowledge and deriving consequences from imperfect data: mycin's certainty factors   prospector's inference nets   fuzzy sets   bayesian nets   and dempster-shafer belief functions  are prominent examples. individual differences aside  all of these technologies have one thing in common: 
　　this research was sponsored by the u.s. army signal warfare center under contract daal1-c-1 and by the defense advanced research projects agency under contract no. n1-k-1 in conjunction with the u.s. navy space and naval warfare systems command. a basic difficulty in constructing explanations for a particular line of reasoning. 
　in this paper we review the process whereby current expert systems generate explanations  and identify the reasons why explanation generation is difficult in uncertain reasoning systems. we then propose an explanation facility for one class of automated reasoning systems that does incorporate uncertainty: evidential reasoning. implementation of this facility results in a knowledgebased system that has both a well-founded representation of uncertainty and a non-trivial ability to explain its inference paths. 
	ii 	explanation generation 
　　the successful generation of explanations in knowledge-based systems has three requirements-
1. an effective explanation can be based upon a recapitulation of actions taken by a program; 
1. the correct level of detail of those actions must be chosen; and 
1. there must be a shared vocabulary that makes the program's actions comprehensible to the user. 
　in a logic program  conclusions are deduced from a collection of facts and rules using the law of modus ponens . one can construct a proof tree that shows the derivation of a goal by recursively generating nodes at each invocation of a rule. once the proof tree has been constructed  an explanation of a given computation can be generated in a straightforward fashion. suitable 
justifications for conclusions can be produced by reciting the fact  or collection of facts  that triggered the rule. when additional detail is required  reiterating the rule may also be of use. mechanisms to control the depth to which the proof tree is explored are used to better satisfy the second requirement-choosing the correct level of detail. additionally  a more appropriate vocabulary can be used by augmenting each rule with a natural language description that is displayed in place of the rule itself-thus addressing the third requirement. many other techniques as well have been used to produce better justifications. 
   the need to represent uncertain or inexact information in some applications has forced system developers to implement new formalisms. the augmentation of rules with certainty factors  as in mycin   and the use of inference nets  as in prospector   are well-known examples. introducing uncertainty into a rule-based system can greatly expand the search required to reach a conclusion. in a binary-valued logic  any path from the goal to known facts is adequate to assert the truth of the goal  
	strat 	1 

but a rule-based system incorporating uncertainty must invoke all rules that unify with every subgoal in the search tree. while many systems have been written that successfully cope with the additional computation this paradigm requires  it presents substantial obstacles to the construction of suitable explanations. 
　tracing the arcs of an inference network is the analog of rule backtracing in a rule-based system to produce explanations. as with systems employing certainty factors  several evidence nodes may contribute to the belief in a hypothesis node  so an appropriate explanation may consist of several supporting reasons and the explanation mechanism must be able to separate those rules that argue for  against  or are indifferent to the hypothesis. in hydro  an expert system designed for water resource management problems   the prospector model was extended to allow multivalued predicates  and explanation generation became more difficult. for example: 

	do you viah to see additional information  	yes 
there ara two favorable factors; in ordar of importance: 1 . 1 : 1  intfw based on s o i l typa and vegetation  corractad for slope has a  alua batwaan .1 and .1 
	 ＊oat l i k a l y .1  	 certainty 1  
1 . 1 : 1  correction factor for gaology has a value between 1 and 1  most l i k a l y 1   cartainty 1  
this explanation was constructed by walking the inference net and computing the range of possible values given the evidence collected to that point. the presence of numeric measures of certainty render the explanation barely comprehensible  contradicting the third requirement. 
　prospector and hydro both possess additional features to produce a more sophisticated interpretation of the state of their knowledge base  such as abilities to perform a best and worstcase analysis of the possible effect of a missing piece of evidence. in a later version  a sensitivity analysis was performed by applying prospector in batch mode to a test case while systematically modifying the input data . this analysis was used primarily to identify areas of disagreement between the expert and the system. 
　the theory of belief functions  as originally conceived by dempster  and further developed ay shafer   is a generalization of probability theory that provides a representation of degrees of precision as well as degrees of uncertainty. its ability to express partial ignorance is of great value in the design of knowledge-based systems for real-world domains. presently  the most highly developed knowledge-based system that incorporates shafer's theory of belief functions for a wide range of application domains is gister . while gister performs tasks similar to those of expert systems based on other technologies  it  like all other systems based upon belief functions  has lacked an explanation capability. in the next section  we present an overview of the evidential-reasoning technology employed by gister. the derivation of a method for generating explanations within evidentialreasoning systems follows that. 
ill overview of evidential reasoning 
   we now give a brief review of evidential reasoning. the reader is referred to lowrance et.al.    for a fuller treatment of this technology. 
a. fundamentals 
　　the goal of evidential reasoning is to assess the effect of all available pieces of evidence upon a hypothesis  by making use of domain-specific knowledge. bodies of evidence are expressed as probabilistic opinions about the partial truth or falsity of statements composed of subsets of propositions from a space of distinct possibilities  called the frame of discernment . the theory allows belief to be assigned to individual propositions in the space or to disjunctions of propositions. belief assigned to a disjunction explicitly represents a lack of sufficient information to enable more precise distribution. this allows belief to be attributed to statements whose granularity is appropriate to the available evidence. 
　the distribution of a unit of belief over a frame of discernment is called a mass function. a mass function  m c   is a set mapping from subsets of a frame of discernment  into the unit interval: such that 

any proposition that has been attributed nonzero mass is called a focal element. one of the ramifications of this representation of belief is that the probability of a hypothesis x is constrained to lie within an interval  spt x   pls x   where 
  1  
these bounds are commonly referred to as support and plausibility. a body of evidence  boe  is represented by a mass function together with its frame of discernment. a boe that represents one of the available pieces of evidence is called primitive. all other boes are conclusions or intermediate conclusions. 
　in evidential reasoning  domain-specific knowledge is defined in terms of compatibility relations that relate one frame of discernment to another. a compatibility relation simply describes which elements from the two frames can simultaneously be true. a compatibility relation between two frames and is a set of pairs such that 

　evidential reasoning provides a number of formal operations for assessing evidence  including: 
1. fusion - to determine a consensus from several indepen-dent bodies of evidence. 
1. translation - to determine the impact of a body of evi-dence upon elements of a related  dependent frame of discernment. 
dence at some future  or past  point in time. 
1 	reasoning 1. projection - to determine the impact of a body of evi-
1. discounting - to adjust a body of evidence to account for the credibility of its source. 
several other evidential operations have been defined and are described elsewhere . 
　independent opinions are expressed by multiple bodies of evidence. dependent opinions can be represented either as a single body of evidence  or as a network structure that shows the interrelationships of several boes. the evidential reasoning approach focuses on a body of evidence  which describes a meaningful collection of interrelated beliefs  as the primitive representation. in contrast  all other technologies described in section ii focus on individual propositions. 
b. the analysis of evidence 
　　to make the description more concrete  we trace through the analysis of the following simplified problem. 
　　at 1 this morning i left my house in palo alto to come to the office. at 1 i received a phone call from a san mateo county police officer who informed me that someone in his district found my dog  rufus  running loose. at 1  a coworker arrived and said he saw a dog that looked like rufus cross hwy 1 on his way to work. rufus has run away 1 times before-only once did i find him in palo alto. 
where should i look for rufus  
　the first step is to construct the spaces of possibilities  the frames of discernment . for example  my dog rufus could possibly be in any of the following cities: 
	{atherton  	losaltos  	menlopark  
	mountainview  	paloalto  	sunnyvale  
other frames could also be constructed; we would probably want one for highways 

and one for counties as well 
	{sanmateo  	santaclara}. 
　the second step is to construct the compatibility relations that define the domain-specific dependencies between the frames. cities and counties are definitely related  so we might define the 
cities-counties relation graphically as shown in figure 1. the relationship between cities and highways is also shown there. a connection between two propositions a  and b  indicates that they may co-occur  in other words  
　time dependencies can also be expressed by compatibility relations. we can construct a state transition diagram describing how far rufus can wander. for example  suppose  that in one hour it is possible for a dog to go from my home in palo alto to los altos  menlo park  or mountain view. this information  along with travel times between other cities  can be expressed as the state transition graph in figure 1  where the time interval for each arc is one hour. this graph can be interpreted as a compatibility relation  where each arc connects elements of the city frame to those cities where the dog could possibly be one hour later. 


figure 1: compatibility relations. 
　once the frames and compatibility relations have been established  we can analyze the evidence. the goal of the analysis is to establish a line of reasoning from the evidence to determine belief in a hypothesis   e.g.  the present location of rufus . 
　the first step is to evaluate each piece of evidence relative to the appropriate frame of discernment. each piece of evidence is represented as a mass function  which is a distribution of a unit of belief over subsets of the frame. for example  the fact that rufus was at home when i left at 1 is pertinent to the cities frame at 1  cities s : 1  and i would attribute 1 to paloalto to indicate my complete certainty that he was there. the phone call from the policeman gives information about counties 1 :1  specifically that rufus was in sanmateo at 1. because this 

figure 1: compatibility relation showing a state transition diagram. 
	strat 	1 
information is not nearly as compelling as my knowledge of rufus' whereabouts at 1  it must be discounted to assess its true impact. assuming the report is 1% credible  we attribute .1 mass for sanmateo  and .1 for  anywhere . the third piece of evidence  that my coworker saw a dog like rufus cross hwy1  gave information about highways  1 and might be assessed as giving .1 support that it was rufus crossing the road  and .1 that my coworker couldn't see the dog well enough to identify him. the last piece of evidence  the historical data  is assessed as 1% sure that rufus is not in paloalto at 1  and 1% chance that he is. this evaluation of evidence can be quite subjective  and all systems that reason under uncertainty require subjective estimates in one form or another. for purposes in this paper  it is sufficient to accept some numeric estimate of belief  and we won't further discuss how these assessments are made. 
　the final step is to construct the actual analysis of the evidence  in order to determine its impact upon the hypothesis. the hypothesis is asking for an assessment of belief over elements in the cities frame at 1. the evidential operations can be used to derive a body of evidence providing beliefs about where rufus might be at 1. a good starting point might be to pool the san mateo police report with the fact that rufus was home at 1. before we can combine these two bodies of evidence  we must adjust them to a common frame  say cities c 1. 
　the translation of a boe from one frame to another is defined by 

　the projection operation is defined exactly as translation  where the frames are taken to be one time-interval apart. pro-
jecting the boe representing rufus being at home at 1 to the cities frame at 1 uses the delta-cities relation and yields 

　these two independent boes are now relative to a common frame and can be combined using the fusion operation  which is implemented via dempster's rule oi combination: 
		 1  
dempster's rule is both commutative and associative  meaning evidence can be fused in any order  and has the effect of focusing belief on those propositions that are held in common. fusing the two previous mass functions yields: 


figure 1: the completed analysis graph. 
　the remainder of the evidence is taken into account by translating  projecting  and fusing according to the analysis graph shown in figure 1. the result is a boe relative to the cities frame at 1  and gives the conclusions as to the current whereabouts of rufus. specifically  
i 
the hypothesis  {losaltos   has the greatest support  and it's belief interval is 

　all of the operations discussed above have been implemented within gister. frames and compatibility relations are represented as graphs  which can be constructed  examined  and modified interactively. having a mechanical means to compute a conclusion is necessary  but without some deeper explanation of why the conclusion is believed  may be difficult to accept. 
　the completed analysis graph can be seen to be the counterpart of the proof tree of logical deduction. each node represents an opinion and the arcs show the derivation of one opinion from other opinions and the knowledge contained in the compatibility relations. the complete graph shows the derivation of a conclusion from the primitive bodies of evidence. the next section presents a methodology that makes use of the analysis graph to explain evidential conclusions. 
iv generating explanations within evidential reasoning 
　　we have already seen how the analysis graph can be construed as the evidential analog of a proof tree. in this section we will use it as a data structure that defines the information flow from primitive sources of evidence to conclusions. the interpretation of an analysis graph as a data-flow model provides an intuitive appeal to the discussion that follows. 
　as was done with hydro  we will use sensitivity analysis as the basis for constructing explanations. because the belief function 

1 	reasoning 

representation provides a richer vocabulary for expressing uncertainties than was used in hydro  we will need a more sophisticated technique to identify the most significant justifications of a conclusion. 

　sensitivity analysis requires a systematic variation of inputs to determine a family of solutions in the output space . in hydro  the probabilities of each piece of evidence are the relevant input parameters. in gister  this is not feasible because the space of conceivable belief functions is exponentially large. fortunately  a more intuitive parameter space is available-one that is motivated by the data-flow interpretation of the analysis graph. in particular  the credibility of each primitive evidence can be varied and the effect upon a conclusion of interest ascertained. this is accomplished via the discounting operation. the new belief in a hypothesis can be computed by reevaluating the data-flow graph. discounting is defined as 
		 1  
where a is the credibility of the original boe. 
a. single hypothesis 
　　in this section  we develop the tools to explain why a  particular hypothesis was found to be strongly  or weakly  supported. for example  we seek an answer to the question   why do you believe rufus is in los altos at 1   
　the simplest case to consider is the fusion of two bodies of evidence as shown below: 


　to perform a sensitivity analysis of this graph  we insert a discounting node after each boe representing primitive evidence. for each such boe   we define a  to be the credibility of that evidence  so that 

obviously  if vi  a  = 1   then the computation in the modified analysis graph is the same as the ordinary fusion defined by the original graph. 



here  sptt a  is interpreted as the sensitivity of the support for a to boe   and likewise for plausibility. 
1. identify those boe  with the extreme values. 
the quantities in the preceding equations indicate the change in the support or plausibility relative to a change in the credibility of an evidence source. the partial derivative is evaluated at a  = 1 to assess the sensitivity of the conclusion  which was computed at a  = 1. 
　in theory these quantities can be computed algebraically or numerically; in practice numeric techniques are required. returning to the previous example  we find 

from this information  it is apparent that boe1 is strong evidence in support of a and boe1 weakly detracts from its support. 
　i n general  the q u a  n b e compared on the following scale: 

　it can also be informative to analyze spt a  and plst a  simultaneously by making use of a sensitivity space plot as seen in 
figure 1. plotting on this graph for each 
1 yields a scattergram that can be used to further analyze the results of the sensitivity computation. the farther a point from the origin of sensitivity space  the greater the impact of that boe upon the conclusion. entries in the northeast quadrant identify boes that support the conclusion  while the southwest quadrant indicates an argument against the conclusion. points in the northwest signify boes that add to the confusion about the hypothesis  while the southeast quadrant identifies boes that 
	strat 	1 

serve to decrease the ignorance without necessarily arguing for or against. 
　to this point  we have only given examples of a sensitivity analysis for a single fusion node. the techniques can be extended straightforwardly to apply across the full extent of an analysis graph. for example  the analysis in figure 1 can be augmented with discounting nodes after each primitive evidence node. when the resulting analysis graph is viewed as a data flow model  the discounting nodes can be seen to act as  valves   where lowering the a-value serves to diminish the flow of information through the valve. 
　by systematically setting each of the  for some small 1  and reevaluating the data flow  a discrete approximation 
to the quantities  can be obtained for any proposition in a conclusion node. this information then indicates the relevant import of each primitive evidence. plotting each point in sensitivity space yields a graphic illustration of the effect each evidence has upon the conclusion. 
returning to the rufus example  sensitivity analysis shows 

from this information  we can conclude that my knowing that rufus was at home at 1 had no bearing on the conclusion that he is probably in los altos now  while the remaining three reports were all necessary to the supporting argument. therefore  only those reports should be included in the explanation: 
why do you believe spt  los altos  ＊ .1  
because the police reported that rufus was seen in san mateo at 1  and ay coworker reported seeing a dog that looks l i k e rufus along highway 1  and rufus was found in palo alto once in the ten tiaes he ran away. 
another example uses the negativity of answer a question: 
is there any reason to believe that rufus is not in los altos  
yes. 
rufus was found in palo alto once in the ten tiaes he ran away. 
　if the user desires a more complete response than this  we could conceivably conjure an explanation from those compatibility relations that were used along any particular path in the graph. a natural language text that describes what the compatibility relation encodes might suffice  e.g.  delta-cities is  the limits on how far a dog can travel in one hour  ; otherwise  the identification of particular links in the relation  perhaps graphically  can help pinpoint a reason. 
　this analysis only indicates the effect of each primitive evidence individually; the joint effect of multiple evidences is not determined. to compute joint effects numerically  while straightforward theoretically  requires exploration of a combinatorically large parameter space. whether or not such a multivariate sensitivity analysis would be useful for real problems remains to be determined. 
1 	reasoning 

figure 1: the characterization of mass functions in terms of specificity and consonance. 
b. entire body of evidence 
　　explanations of a single hypothesis  such as those derived in the preceding section  are quite similar to those produced in systems based on certainty factors or inference nets. the notion of a body of evidence that is used in evidential reasoning permits a higher-level description of an inference chain. rather than asking a question about a belief in a particular proposition  the user can pose questions that search for the primitive pieces of evidence that were the most influential in general. 
　there have been numerous proposals for characterizing boes  that can be used as the basis for selecting informative explanations. while nearly any sound characterization will suffice for our present purposes  we will make use of several due to yager 
. 
　we have already noted that the theory of belief functions allows representation of varying degrees of precision as well as uncertainty. the relative precision of a boe can be characterized by the following expression for specificity: 
		 1  
where ||a;|| is the cardinality of the subset ar it is easy to show that 

roughly speaking  spec m  measures the degree of commitment of a belief function to precise propositions. the vacuous belief function  m : has the smallest possible specificity for any frame a mass function whose specificity is 1 is a probability distribution as well. 
　the relative uncertainty of a boe can be characterized by an entropy-like measure. yager defines 
		 1  
and shows that ent m  is just shannon's measure of entropy in the special case when m is a probability distribution. to use this measure to generate explanations  it will be more convenient to work instead with a measure of consonance: 
1 
	cons m  = l + ent m ' 	 1  


figure 1: sensitivity space for characterizations of a body of evidence. so that 
minimal consonance is thus maximal entropy  and exists whenever the focal elements of a mass function are mutually exclusive. consonance equal to 1 occurs when all the focal elements are nested and thus represents a possibility distribution as defined by fuzzy set theory . 
　to gain some intuition  it is useful to note that any boe is characterized by a point in the unit square shown in figure 1  which spans the space of all possible boes. the special cases of possibility distributions and probability distributions lie on the boundaries of the square. a boolean statement has cons m   the vacuous belief function has 
cons m1  = 1 and spec m1  = 1 and is represented by the upper-left corner of the square. starting with no information and gradually fusing pieces of evidence as they became available  we trace a path in the square that starts at the upper-left corner and wanders toward the right. the ideal analysis would reach a boolean conclusion  upper-right corner   but typically the path stops somewhere short. the intuition  then  is that pieces of evidence that move the path closer to the upper-right corner are the most sufficient ones for focusing the conclusion. 
　we are now in a position to select pieces of evidence as justification of an evidential-reasoning inference chain. as before  we will perform a sensitivity analysis to choose the components of the explanation  but this time we will measure the change in our two characterizations of a boe. we define 

 1  
as the sensitivity of specificity and consonance respectively  where a  is the credibility of boe  as before. once again  these measures can be computed for each primitive evidence and plotted in sensitivity space for comparison  see figure 1 . in this graph  the northeast quadrant represents those boes whose inclusion in an analysis forces the path to the upper-right  the boolean case  and are therefore important to the conclusion reached. the southwest quadrant contains boes whose inclusion decreases both the consonance and specificity-these are pieces of evidence that run counter to the consensus  and may be suggestive of an errorful source or a need to maintain multiple analysis paths. the other quadrants can be interpreted as labeled. once again  distance from the origin indicates the relative contribution of evidence to the conclusion. 
　sensitivity analysis for the boe that represents the conclusion from the lost-dog story reveals 

the sensitivities of support indicate that the fact that rufus was at home at 1 did not contribute to the conclusion  and that my coworker's report was the most important piece of evidence  albeit by a slim margin . on the consonance side  all the reports were in agreement except for the historical information; this permitted a small amount of belief to be attributed to paloalto  a proposition not supported by the consensus. 
c. using sensitivity results to generate explanations 
　　with these tools in hand  a number of different questions about an analysis can be answered: 
q: why do you strongly believe a  
a: choose the boe  for which  is greatest. 
q: why don't you believe b  
a: choose the boe  for which  is most negative. 
q: which pieces of evidence serve to focus the conclusion more precisely  
　a : choose those boes for w  e both positive. 
q: which piece of evidence most strongly disagrees with the consensus  
a: choose the boe  for which is most negative. 
q: which opinions can be safely ignored  
a: choose those boes for which 
q: what are the most crucial pieces of evidence that impinge upon t h i s conclusion  
a: choose those boes for which is greatest. 
　in summary  the three requirements of explanation generation from section ii have been satisfied: 
1. the difficulty of recapitulating program actions within sys-tems that use a numeric measure of uncertainty has been overcome by the use of sensitivity analysis. focusing on the credibility of bodies of evidence instead of individual probabilities makes this feasible for belief functions. 
1. the correct level of detail can be controlled in two ways. first  the depth of exploration of an analysis graph is selected exactly as for proof trees  but with a natural correspondence between arcs and meaningful inference steps. second  the number of justifications to be provided is adjusted by rank ordering the sensitivities and choosing the most important ones. 
1. a shared vocabulary is also provided in two forms. as with the other technologies  natural language text is associated 
	strat 	1 

with a primitive evidence node and displayed in place of the machine representation. second  the vocabulary is in terms of the high-level constructs of a set of related beliefs represented by a boe  instead of each proposition and its belief individually. this is likely to correspond more closely to human thought processes. 
v discussion 
　　the use of evidential reasoning provides a richer vocabulary for expressing belief about uncertain events than is available in other technologies  but confounds the ability to construct suitable explanations of a chain of inferences. the use of sensitivity analysis as described here not only permits the customary forms of explanation characteristic of rule-based systems  but also enables a variety of additional queries to be posed and answered. 
　the tools presented in this paper have several uses in addition to that of constructing explanations for a user. sensitivity information can be an important component of decision analysis. knowledge of the sensitivity of conclusions can suggest whether sufficient information is available  or whether additional information should be sought. it can also be used to focus informationcollection efforts. by hypothesizing the information that might be collected by a particular source  one can determine whether it could possibly have sufficient impact on the hypothesis to alter a pending decision. these ideas  while promising  have not as yet been investigated. 
　we have presented an approach to constructing an answer to various kinds of questions that can be asked about a conclusion derived through evidential reasoning. we have argued that the technique satisfies the three requirements for explanations. it also has the generality to be able to provide a variety of information about an evidential inference chain and can be used to further insulate the user from the cryptic numbers that are manipulated by the machine. coupling this mechanism with the evidential-reasoning techniques already developed allows the creation of a powerful knowledge-based system for reasoning under uncertainty that can explain its behavior in terms understandable by humans. 
vi acknowledgements 
　　the author wishes to thank the members of sri's artificial intelligence center who read and critiqued earlier drafts of this paper. in particular  tom garvey provided keen insight on the calculation and interpretation of the sensitivity measures. in addition to examining the theoretical approach  john lowrance provided valuable assistance in the implementation of the techniques. discussions with steve lesh were valuable for understanding the role sensitivity analysis might play in decision analysis  and lenny wesley illuminated the relationship between this paper and his work on evidential control. finally  joani ichiki is to be commended for the rapid and professional layout and production of this paper. 
1 	reasoning 
