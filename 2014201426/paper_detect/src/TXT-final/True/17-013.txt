ions as sets of  intelligent records  which may be thought of as capable of manipulating their own contents in parallel 
among the hardware features provided within the 
spe's to support these associative processing capabilities are 
1. logic allowing a string broadcast by the controlling lpe to be very rapidly matched against the contents of all spe's in parallel 
using the special non-von string matching instructions  a single-instruction inner loop for string matching may be implemented  allowing matching to occur at approximately 1 million bytes per second per spe in the new prototype now under construction a large active memory should thus be capable of matching at an aggregate rate of more than a trillion bytes per second 
	d. shaw 	1 
1 the inclusion of both eight-bit and one-bit registers and ram  allowing sets of data elements to be conveniently marked and manipulated in parallel in various ways such operations are facilitated by the alu  which provides highly efficient support for logical operations on one-bit flags 
1 a special one-bit register called the enable flag all spe's in which the 
enable flag is set to zero are disabled  and ignore all instructions until the subsequent execution of an enable instruction  which  awakens  all spe's this mechanism  variants of which have been used in a number of other parallel machines  facilitates parallel operations on selected sets of data elements identified on the basis of some aspect of their contents 
1 a multiple match resolution instruction called resolve  which may be used to mark a single member  the one which would occur first in an inorder traversal of the active memory tree  of a specified set of spe's together with the report instruction  which transfers data from a single enabled spe to the controlling lpe  this technique may be used to sequentially enumerate the members of an arbitrary marked set of data elements in time linear in the cardinality of the set 
　　　these associative processing mechanisms are employed in a number of the algorithms whose performance is reported in this paper further discussion of the use of non-von's active memory to 
support various associative processing techniques may 
be found in  shaw  1  
1 production systems 
　　　after several decades of research on artificial intelligence  rule-based production systems have emerged as one of the most important and widely employed tools for the implementation of expert systems and other ai software while the modularity  perspicuity  and ease of modification and augmentation which are characteristic of rule-based systems offer a number of potential advantages in the execution of many large-scale ai tasks  their use in such applications is in some cases very costly in execution time. this poses particular problems in the case of real-time applications and other tasks characterized by severe and inflexible time constraints the possibility 

　1 d. shaw of using parallel hardware to accelerate the execution of production systems is thus of considerable interest 
　　　forgy  considered the problem of executing production systems in parallel on the illiac iv  but was forced to significantly modify the production system paradigm in order to obtain reasonable performance stolfo and shaw  subsequently proposed a highly parallel machine called dado  which was intended specifically for the execution of production systems; an early prototype of the dado machine is presently operational more recently  members of the dado project have investigated a number of issues related to languages and algorithms for the parallel execution of production systems  stolfo  1  
　　　as a first step in evaluating non-von's performance in the domain of rule-based systems  we have implemented and analyzed an algorithm  hillyer and shaw  1  for the parallel execution of production systems implemented using the language ops1  forgy  1   which was developed by researchers at carnegie-mellon university ops1 was chosen as the vehicle for our investigations into parallel execution of production systems for several reasons 
1 it is widely known  and has been evaluated favorably by other researchers  hayes-roth  et al   1  
1 it has been used to build a large and successful commercial production system  mcdermott  1  
1 static and dynamic characteristics of six substantial ops1 production systems have already been measured  gupta and forgy  
1  
1. its speed can be increased significantly by parallel execution  despite the fact that the language was designed for sequential processing. 
　　　the non-von ops1 algorithm may be regarded as a parallel version of forgy's rete match  algorithm  which exploits the observation that firing an ops1 production causes only a few changes to working memory  and that these changes have few effects on the conflict set. this observation may be exploited  even on a sequential machine  if the production system is compiled into a dataflow graph  with state information saved at each node during execution. a change to working memory is entered into initial nodes of the graph consequent state changes then propagate through the graph  updating information stored in intermediate nodes state changes in terminal nodes of the graph represent changes to the conflict set. 
　　　the execution cycle for an ops1 production system has three phases match  select  and act in the rete match algorithm  the match phase has two steps first  intra.-condition tests are executed to check that attributes in a working memory element satisfy the specified relational operators  and that variables occurring more than once in a condition element are bound consistently subsequently  intercondition tests are performed to verify consistent binding of variables across multiple condition elements in a production's left-hand side the non-von ops1 algorithm  which was implemented and tested by 
bruce hillyer using the non-von instruction-level simulator  achieves its performance and cost/performance advantages primarily by accelerating the execution of these two components of the match phase in the case of working memory additions  and by replacing them with a more highly parallel associative step in the case of working memory 
deletions 
　　　the non-von ops1 algorithm is based on an algorithm by gupta   his algorithm 1  this algorithm was designed for the dado machine  stolfo and shaw  1   in a prototype configuration consisting of 1 identical  off-the-shelf  1-bit microprocessors the non-von algorithm assumes 1 lpe's  or 1 lpe's and one dedicated host machine   each of which is somewhat more powerful than a dado pe  and 1k spe's  which make possible a greater degree of associative parallelism the 1  nonhost  lpe's are assumed to be attached at the fifth level of the active memory tree  the lpe's that would be associated with the first through fourth levels in a fully general non-von machine are not required for the execution of this algorithm the high-bandwidth lpe network is also not required  and could be replaced with a simple bus without significantly degrading performance in the production systems 
application 
　　　in the non-von ops1 algorithm  intracondition testing is performed in the active memory using two massively parallel simd computation steps the first step simultaneously evaluates individual terms of all condition elements. the second step determines the satisfaction of all condition elements in a single parallel communication step  requiring time proportional to the number of terms in the longest 

condition element. the synchronous nature of simd execution was found not to limit the rate of processing in this phase 
　　　the more limited potential for parallelism embodied in the inter-condition testing step is captured using a multiple-simd execution discipline  in which independent instruction streams are broadcast to 1 separate active memory subtrees by the 1 lpe's pure simd processing would have been a serious constraint during this portion of the execution  since evaluation of the rete dataflow graphs presents a high degree of data sensitivity the use of active memory subtrees  on the other hand  significantly enhances the power of the lpe's by providing a fast associative search capability the select and act phases  which have little inherent parallelism in ops1  are performed sequentially by a single lpe  or by an attached host processor   although a modest speedup is obtained by overlapping a portion of these computations with the subsequent match phase 
　　　an experimental compiler and runtime system for the execution of opss on a one-lpe non-von has been written and tested on an instruction-level simulator in order to predict the algorithm's performance when executing real production systems  its running time was calculated based on measurements obtained by gupta and forgy  of the static and dynamic characteristics of six actual production systems  which had an average of 1 inference rules each by counting the number of non-von instructions  it has been possible to determine the number of clock cycles required for each of the simd processing steps under the assumptions implicit in gupta and forgy's data by adding approximate overhead values for non-overlapped execution in the lpe's1  we have been able to predict with reasonable accuracy the time required per production firing cycle1  and hence the rate of production system execution on non-von 
　　　according to these calculations  the non-von configuration outlined above should require 1 
   this can be improved to time logarithmic in the number of terms in the longest condition element with a worst-case 1% decrease in memory utilization  using techniques closely related to the allocation 
schemes for database records described by shaw and hillyer . 
   the figures given for host and lpe processing are estimates  unlike the spe figures  which are derived from actual code. 
   we have assumed that the only actions in the right-hand sides of productions are additions  deletions  and modifications of working memory elements. the right-hand side of a production expressed in ops1 can cause arbitrarily large amounts of i/o and can call any function written in lisp  but the time consumed by such operations does not provide any information about the performance of the production system inferencing engine. 
	d. shaw 	1 
microseconds per production firing  yielding an execution rate of 1 productions per second by way of comparison  a lisp-based ops1 interpreter executing the sequential rete match algorithm on a vax 1 typically fires between 1 and 1 rules per second  while a bliss-based interpreter executes between 1 and 1 productions per second  gupta  1  personal communication   the non-von machine configuration assumed in these calculations would embody 1 custom chips  each containing 1 spe's  and about 1 chips for the 1 lpe's the hardware cost of such a system is projected to be somewhere between that of a vax 1 and a decsystem-1 non-von's cost/performance ratio in executing ops1 production systems is thus estimated to be approximately two orders of magnitude better than that of a conventional sequential machine in practice furthermore  our analysis suggests that the machine's relative performance advantage should increase as the production system becomes larger 
　　　a detailed discussion of the assumptions underlying the above projections  and of the precise manner in which our results were derived  can be found in  hillyer and shaw  1  
1 computer vision 
　　　a number of operations performed by commercial and experimental image understanding systems are extremely time-consuming when executed on a conventional sequential machine for this reason  substantial efforts have already been made to develop special-purpose machines and algorithms adapted to various computer vision tasks the machines described in the literature may  for the most part  be divided into four general architectural categories 
1 pipelined 	architectures 	such 	as 	the 	nbs 
	pipelined 	image 	processing engine 	 kent  
	shneier 	and 	lumia  	1  	and 	the 
cytocomputer  sternberg  1   in which the task at hand is typically divided into a number of functions and each stage in the pipeline is configured by a control unit to perform one function 
1 mesh-connected architectures  unger  1   such as clip1  duff  1   mpp  potter  1   and the icl dap  marks  1   which are based on a rectangular array of  typically one-bit  processing elements  each connected to its nearest four or eight neighbors  and each corresponding to a either a single pixel or a small rectangular 

1 multiprocessor architectures  examples of which include pasm  siegel  et al  1  and zmob  kushner  et al  1   in which a number of general-purpose microcomputers cooperate to solve a given image understanding task  communicating through some form of processor interconnection network. 
1 hierarchical architectures  including cone and pyramid machines  uhr  1; hanson and riseman  1  dyer  1  tanimoto  1   in which the original image is progressively reduced through the application of successive transformations in a manner analogous to that apparently employed in the human visual system 
　　　the general non-von architecture provides efficient support for most of the parallel vision algorithms typically executed on each of the last three classes of architectures  in addition  many of the algorithms executed on pipelined vision machines may be transformed into simd algorithms amenable to execution within non-von's active memory while we expect non-von to prove highly useful for all levels of computer vision applications  from low-level signal processing and the extraction of primitive geometric properties through high-level object recognition and scene analysis  our work to date has concentrated largely on low- and intermediate-level computer vision tasks 
　　　a number of image understanding algorithms have been developed and tested using a functional simulator  and in some cases  the non-von machine instruction level simulator in particular  algorithms have been developed for 
1 image correlation 
1 image histogramming 
1 image thresholding 
1 union  intersection  and difference of two binary images 
1 connected component labeling 
1 euler number of connected components 
1 component area 
1 component perimeter 
 1. component center of gravity 1 component eccentricity 
1 the hough transform 
1 the  moving light display  problem 
　　　these tasks were chosen to span several levels of image understanding applications  and to assess nonvon's applicability to a number of different kinds of operations arising in the course of constructing integrated vision systems preliminary analytical and simulation results suggest that non-von should provide significant performance and cost/performance advantages over sequential machines for each of these tasks  and should in a number of cases improve on the best results reported in the literature for specialpurpose vision architectures and other highly parallel machines 
　　　two hierarchical data structures that may be implemented naturally on the non-von machine are employed in the non-von algorithms for these tasks the first is the multi-resolution pyramid  tanimoto and klinger  1   which represents the original  binary or gray-scale  image at a number of different levels of detail  each containing one quarter of the number of pixels present at the next highest level of detail multi-resolution pyramids are implemented on non-von by storing the original image in the  meshconnected  leaf spe's and the less detailed levels in the internal spe's the latter process is based on a straightforward mapping of the natural quartic tree interpretation of the multi-resolution pyramid onto the active memory's binary tree structure 
　　　the second data structure used to represent images in the non-von machine is a variant of the quadtree called the binary image tree  which was originally proposed by knowlton  as an encoding scheme for the compact transmission of image data the original binary image is again stored in the leaf spe's internal nodes  however  can take one of three values  which may be thought of as  black    white  and  gray  an internal node has the value black if its two children are both black  white if its two children are both white  and gray otherwise this data structure is used in most of the non-von algorithms that operate on binary image data 
　　　a number of aspects of the non-von machine architecture  exploited as part of several frequently used algorthmic techniques  are responsible for the machine's performance and cost/performance advantages in computer vision applications the simplest technique  which has also been employed on 

the original image. the connected component algorithm enumerates all of these black rectangles  using the resolve and report instructions  one by one in order of decreasing size  or equivalently  of increasing tree level  
　　　as each such rectangle ri is enumerated  it is assigned a new component number if not already labelled any rectangle rj. that is adjacent to ri is then assigned the same label  as are all other rectangles previously assigned the same component number as rj  note that this last operation requires only a single broadcast and assignment step  independent of the number of rectangles having the same component number as rj  since only one pass through the set of black rectangles in the binary image tree is required  ibrahim's algorithm executes in time proportional to the number of rectangles  which in real images is much smaller than the number of pixels  details of this and other geometric algorithms for non-von may be found in  ibrahim  1    
　　　the importance of non-von's mesh connections in computer vision applications is illustrated by such low-level signal processing operations as image correlation and various types of two-dimensional filtering the non-von algorithms for these operations rely on a considerable amount of communication among adjacent and nearly-adjacent neighbors in the mesh although ibrahim  has developed techniques to perform such operations on a  pure  tree machine that tend to minimize the need for such communication  non-von's mesh connections make possible a considerable increase in performance 
　　　other vision algorithms make use of the msimd execution capabilities of the general non-von architecture to partition a problem into a number of subproblems  each of which is solved in a different active memory subtree in many cases  several forms of parallelism are exploited in the same algorithm although work on high-level image understanding on the non-von machine is still in its earliest phases  our experience with the parallel execution of production systems suggests that significant opportunities exist for accelerating such applications as well 
1 knowledge base management 
　　　a number of  real world  ai applications require the construction and manipulation of large knowledge bases such applications tend to be characterized by the need to access the same data in a number of different ways  often in conjunction with some form of 
	d. shaw 	1 
such machines as mpp and the icl dap  involves the use of ordinary content-addressable arithmetic and logical operations to perform a single operation in parallel on all pixels this technique is illustrated in its simplest form by the algorithm for image thresholding  in which a gray-scale image is transformed to a binary image by setting all pixels whose intensities exceed a specified threshold value to one  and all other pixels to zero a non-von machine of size sufficient to store each pixel in its own processing element is capable of thresholding an entire image in less than two microseconds  independent of the size of the image  by broadcasting the threshold value to all pixels and executing a single parallel comparison followed by two parallel assignment operations  each executed by a separately enabled set of spe's 
　　　like a number of highly parallel machines developed by other researchers  non-von is thus able to achieve a speedup of many orders of magnitude  and a cost/performance improvement of approximately three orders of magnitude  by comparison with a vax 1 on simple associative operations of the kind exemplified by image thresholding the same general technique is used in the non-von algorithm for image histogramming  ibrahim  1   in which the bounds of a given intensity range are compared in parallel with all pixel values to identify those pixels whose values fall within a given intensity range  histogramming is often performed prior to the conversion of a gray-scale to a binary image in order to choose an appropriate threshold value   
　　　unlike the massively parallel mesh-connected machines  however  the tree-structured connections embedded in the non-von active memory permit a major reduction in the time required to determine the number of pixels falling within each histogram bin in the non-von algorithm  this quantity is computed through an o log n  level-by-level addition procedure  where n is the number of pixels in the image the running time of the algorithm is further reduced  however  by pipelining this computation for successive intensity ranges  resulting in an 1 b + log n  algorithm  where b is the number of histogram bins the non-von histogram algorithm is easily modified to produce a cumulative or normalized histogram 
　　　a different use of the active memory tree is illustrated by ibrahim's connected component algorithm for non-von  ibrahim  1  the algorithm begins by constructing the binary image tree representation of the original image data  which requires time logarithmic in the number of pixels it will be recalled that the binary image tree includes explicit representations of black rectangles of various sizes from 

inferencing. the need to flexibly access and deductively manipulate large knowledge bases has led a number of researchers to construct logic-based and knowledge-oriented database systems  gallaire and minker  1  wiederhold  et al  1  shaw  1  whose primitive operations are based on the relational model of data  codd  1  in addition  many knowledge-based systems that do not make explicit use of relational data structures or access primitives nonetheless employ equivalent or closely analogous representation formalisms and operations at some level 
　　　unfortunately  knowledge base management systems tend to rely heavily on such  difficult  operations as the relational join  whose execution may be extremely time-consuming on a sequential machine  particularly in the case of large databases several researchers  shaw  1  moto-oka and fuchi  1  have thus proposed using special hardware supporting the rapid execution of such database primitives in constructing systems designed for ai applications algorithms for a number of database primitives have been developed for the non-von machine  including 
1 select 
1 project 
1 join 
1 union 
1 intersection 
1 set difference 
1 aggregation 
1 various statistical operations 
　　　to evaluate non-von's applicability to the kinds of database operations most relevant to ai applications  a detailed analysis was performed of the machine's projected performance on a set of benchmark queries formulated by hawthorn and dewitt  these authors presented an analysis of the predicted performance of a number of database machine architectures  specifically  rap  ozkarahan  et al  1   cassm  copeland  et al  1   dbc  banerjee  et al  1   direct  dewitt  1   cafs  coulouns  et al   1   and associative disks  langdon  1  lin  et al  1  slotnik  1   on three relational database queries. 
　　　in evaluating non-von  we used the same three queries and similar techniques for performance analysis and for the adjustment of machine configuration to control for hardware cost. in particular  we assumed a non-von configuration having 1k spe's  1processor chips   1 disk drives  and a single lpe -- a configuration comparable in each relevant dimension to that of the other machines considered in the hawthorn and dewitt analysis 
　　　hawthorn and dewitt's first query is a simple relational selection operation their analysis predicted that all six of the architectures they examined would have roughly comparable performance on this query our analysis  using the same techniques  predicts that 
non-von should achieve slightly  but not significantly faster performance on this simple selection query the lack of a significant performance difference between non-von and the six database machines evaluated by hawthorn and dewitt is attributable to the fact that all seven machines are capable of the kinds of simple associative processing techniques required to achieve close to the maximum performance permitted by the aggregate disk transfer rate of their  costnormalized  banks of disk drives it is on the more demanding queries frequently found in al-onented applications that non-von is able to offer a greater relative advantage table 1 summarizes our results and those of hawthorn and dewitt for the first sample query. 

　　　the second query  which may have more immediate relevance to complex knowledge base management applications  involves a relational join operation on this query  non-von achieves a performance improvement of approximately an order of magnitude over the six database machines evaluated by hawthorn and dewitt  as indicated in table 1 
　　　there are three reasons for non-von's surprising speed  even by comparison with direct  which is the fastest of the other database machines on this query the first is that direct stores entire records in its cache when processing  while non-von 

d. shaw 	1 


projects over those attributes that are of interest  discarding the rest second  direct reads data from one of its 1  faster  disk drives  while non-von loads one of the argument relations in parallel through all 
1 heads of its  slower  drives  unlike non-von  direct would not benefit greatly from the use of parallel disk transfers  dewitt and hawthorn  estimate that parallel disk input would improve the join performance of architectures like direct by only 1%   third  direct performs a sequential search through one of the argument relations for each tuple of the other relation it considers  in contrast with non-von's associative matching followed by fast enumeration of responders using resolve and report instructions 
	the 	final 	query 	considered 	by 	dewitt 	and 
hawthorn involves an aggregation operation in which the tuples in the argument relation are divided into groups according to the values of two attributes  and the sum of the values of a third attribute is computed separately for each group using associative processing techniques  both internal and external   together with the capability for fast addition provided by the active memory's tree connections  non-von again achieves significant performance improvements over the other architectures evaluated by hawthorn and dewitt while the authors do not explicitly present the times required by the machines they studied for this query  a graph is provided from which these times were estimated comparative results for this query are presented in table 1 
　　　further details of the assumptions and analysis underlying the results presented above may be found in  hillyer  shaw and nigam  1  
1 conclusions 
　　　it is dangerous to attempt to draw firm conclusions about the range of applicability of a novel computer architecture over a wide range of applications on the basis of a relatively small number of benchmark tasks based on our research to date  however  it would appear that the general non-von architecture may offer significant performance and cost/performance advantages over both conventional and  in a number of cases  special-purpose machines in at least three superficially disparate artificial intelligence task areas 
　　　in particular  we have presented a number of algorithms  analytic performance projections  and simulation results suggesting that non-von is capable of rapid and cost-effective performance on a number of tasks in the areas of production system execution  low- and intermediate-level image understanding  and knowledge base management although the magnitudes of the projected performance and cost/performance advantages are different for different tasks  performance improvements of as much as two to five orders of magnitude  and cost/performance advantages of as much as two to three orders of magnitude  have been predicted in many cases 
　　　different aspects of the non-von architecture appear to be responsible for the machine's advantages in different problem areas it is nonetheless possible to identify a relatively small number of features  several of which are typically operative in the case of any single application  to which the machine's advantages may be attributed 
1 the effective exploitation of an unusually high degree of parallelism  which is made possible by the very fine granularity of the active memory 

1 the extensive use of broadcast communication  high-speed contentaddressable matching  and other associative processing techniques 
1. the use of the active memory tree to execute algebraically commutative and associative operations  such as sum and maximum  in logarithmic time 
1 the exploitation of other physical and logical interconnection topologies to support a number of problem-specific communication functions 
1 the capacity for simd  mimd and msimd execution  and for a mixture of synchronous and asyncronous execution within a single algorithm 
1 the simplicity and cost-effectiveness with which the machine can be implemented using currently available technology 
　　　although not all of these architectural features are relevant to every ai application  each is exploited in different ways in a number of different algorithms while it is difficult to rigorously explicate the intuitive notion of computational generality  non-von would seem to have many of the properties of a rather general machine having a number of widely applicable architectural features  as opposed to an amalgam of special-purpose subsystems  each performing a fixed  application-specific task 
　　　it is of course of interest that non-von may be able to exceed the performance of the fastest special-purpose machines described in the literature for the execution of some of the tasks considered in this paper of potentially greater practical significance than non-von's superior performance in any one particular task area  however  is the range of diverse ai tasks that would appear to be efficiently executable within a single machine. while there is still insufficient evidence to adequately evaluate the extent to which the non-von architecture might serve as the basis for a high-performance  general ai machine   the work described in this paper may represent an early  preliminary step toward the ultimate development of such machines. 
acknowledgements 
　　　bruce hillyer was directly responsible for implementing  simulating  and analyzing most of the database management and production system algorithms discussed in this paper the non-von image understanding work we have described is largely attributable to hussein ibrahim and john render more generally  the author wishes to acknowledge the direct and indirect contributions of the non-von hardware implementation team  under the direction of ted sabety  of dong choi  who was responsible for much of the simulation software used to obtain the results we have reported  and of the other ph d students and research staff members associated with the non-von project  without whose efforts this work would not have been possible 
