 
stochastic local search  sls  techniques are very effective in solving hard prepositional satisfiability problems. this has lead to the popularity of the encode & solve paradigm in which different problems are encoded as propositional satisfiability problems to which sls techniques are applied. in ai  planning is the main area in which this methodology is used. yet  it seems plausible that sls methods should perform better when applied to the original problem space whose structure they can exploit. as part of our attempts to validate this thesis  we experimented with lpsp  a planner that applies sls techniques to the space of linear plans. lpsp outperforms sls applied to encoded planning problems that enforce a similar linearity assumption because of its ability to exploit the special structure of planning problems. additional experiments  reported in a longer version of this paper  conducted on the hamiltonian circuit problem lend farther support to our thesis. 
1 introduction 
rapid improvement in the performance of stochastic local search  sls  methods for solving propositional satisfiability  sat  problems coupled with the naturalness with which many problems can be reduced to sat problems has led to the popularity of an encode & solve approach to problem solving. in this three phase approach  the original problem is reduced into a sentence in propositional logic; a satisfying assignment for the sentence is searched for using state of the art sls algorithms; and a solution  if found  is converted back into a solution to the original problem. this method has become increasingly influential in the area of classical ai planning  where it is known as the planning as satisfiability approach  pas   kautz and selman  1 . 
　but is it not more effective to apply sls methods directly to the original problem space  in this paper we report on our investigation into this issue in the context of planning problems. we describe the lpsp planner  linear plan-level stochastic planner  which uses sls on the space of linear plans to solve planning problems. we chose to explore the space of linear plans because we found it easier to formulate and program heuristics  metrics  and moves in this space. lpsp has a number of operators for moving in this space that 
1 	planning and scheduling 
holgerrhoos 
department of computer science 
university of british columbia 
vancouver  bc v1t 1  canada hoos cs.ubc.ca 
enable it to discover plans in a small fraction of the number of steps required by sls algorithms operating on the encoded planning problems. some of its moves are reasonably natural when projected to the encoded problem. others have no apparent equivalent  are motivated by the particular structure of planning problems  and are based on intuitions developed in classical work on partial-order planners  e.g.  causal links  threats  producers  consumers  plan repair . each move is considerably more expensive than moves made by  e.g.  walks at  selman et al  1   yet the overall performance is better than that of sat based algorithms operating on encoded planning problems that share the linearity assumption. 
our planner is not competitive with planners such as 
blackbox  kautz and selman  1  in domains in which parallel plans are much shorter than linear plans  e.g.  the logistics domain.1 because the search space size is exponential in the plan length  lpsp is in a considerable disadvantage in such cases. however  it performs better than sat based planners when the use of concurrency leads to little or no decrease in plan length. more generally  it does better than the sat based approaches when we use medic's  ernst et al  1  encodings in which the linearity assumption is enforced. we believe that this latter comparison is more valid when we come to examine the encoded vs. un-encoded formulations. in fact  we believe that these observations will apply when we extend this work to parallel plan structures. in section 1  we discuss evidence from current research supporting this view. overall  our results seem to support the thesis that sls methods applied to problem domains with sufficient structure can outperform the encode & solve approach. 
1 the planning as satisfiability approach 
given a planning problem and some natural number n  we can generate a propositional formula whose models correspond to n step solutions to the problem. there are a number of schemes for generating such a formula  see  e.g.   ernst et al  1    but the essential idea is that variables in this formula represent the value of the propositions describing the domain at different time points as well as the actions that are or are not applied at each time point. hence  these variables contain information about the dynamics of the world throughout the execution of the plan. the formula contains constraints that 


these variables most satisfy if they describe the state of the world during the execution of a valid plan. from the value assigned to variables representing actions in any satisfying assignment we can easily infer a valid plan. 
　we can extend this idea into a planning algorithm as follows. starting with some initial guess for n  we generate an appropriate formula. if it is satisfiable  we can get a plan by inspecting the satisfying assignment. otherwise  we increase n and repeat. 
　as shown in  kautz and selman  1   this approach can be quite efficient thanks to the availability of fast sls-based algorithms for sat problems such as walks at  selman et al.  1 . walks at starts by randomly picking a truth assignment. at each step  walks at randomly chooses an unsatisfied clause c and makes it satisfied by flipping the value of one of its variables v. if possible  v is chosen so that no currently satisfied clause becomes unsatisfied by this flip. otherwise  the variable is either chosen randomly or by selecting the flip that maximizes the number of satisfied truth assignments - called the assignment's score. 
1 the lpsp planner 
search space the lpsp planner performs sls on a space of fixed length linear plans. as in the pas approach  lpsp is given this length as part of its input. hence  the states of the search space consist of sequences of ground actions of length n  where n is an input parameter. null actions  i.e.  actions with no preconditions or effects  are allowed as part of the sequence. in principle  with the introduction of appropriate operators  it is a simple matter to let lpsp operate on plans of varying length  much like conventional planners. however  we have not experimented with this option  yet. scoring plans lpsp scores  or more accurately  penalizes  plans by a weighted sum of plan flaws. a flaw arises in a plan when an action a  the consumer  has a precondition p and the closest predecessor a' of a that influences the value of p  the cloberer  has -p as an effect. each flaw's weight is d  the distance between a' and a.  in some domains  a weight of d1 or d1  performs better.  each plan is penalized by the sum of the weights of all its flaws. naturally  a plan is valid iff it has no flaws and consequently has 1 penalty. 
　example 1: consider a blocks' world domain with four blocks and actions of the form move x  y  z  which takes block x from y and places it on z. its preconditions are on x  y   clear s   and clear z . its effects are on x  z   clear y   ~yon x z   -clear z . 
　suppose that initially c is on a  and that b and d are on the table  and we want to reach a goal state in which a is on b and b is on c. consider the following three step plan: move c a d   move b d c   and move a table b . this plan contains a single flaw: the on b d  precondition of move b d c . the closest predecessor of this action influencing on b d  is the initial action 1 which has -on b d  as an effect. in this case d =＊ 1 and so the plan's penalty is 1. moving around the search space since plan space is searched  we can use various operators for moving in this search space that do not have natural counterparts in the space 
　　1  we use the well known technique of inserting a  fixed  fictitious initial action that  sets-up  the initial state as its effects and a fictitious final action that has the goal as its precondition. 
of truth assignments. in particular  the use of special plan reordering operators is crucial to lpsp's success. without them  it usually does not find a solution. 
　 1  best-replacement. this operator scores all plans that differ from the current plan by a single action  i.e.  plans in which one of the current plan's steps was replaced. it returns the plan with the least penalty score among these.1 in example 1  we would consider plans in which one-of the current steps was replaced by some ground action. in particular  when we replace the move b d c  step with move b table c  we get a plan with no flaws. 
　 1  flaw-repair. this operator randomly chooses a flaw from the current plan flaws. it then scores all possible plans in which this flaw is repaired by replacing one plan step between the cloberer and the consumer. the new action must establish the precondition of the consumer destroyed by the cloberer. if none of these plans has a lower penalty score than the current plan  it examines plans in which the consumer is replaced by some other action. 
　flaw-repair is motivated by a similar strategy employed by walks at where a  flawed   i.e.  unsatisfied  clause is chosen and repaired by changing the value of one of its variables. 
　example 1: consider actions that repair the flaw of the plan in example 1  i.e.  actions that have on b d  as an effect. such actions are of the form move b  x d  and the best scoring plan is obtained when we use move b table d . 
the resulting plan will be: move b table c   move b d c   and move a table b . this plan has a single flaw: the clear a  precondition of the last action. the closest predecessor of the last action affecting clear a  is the initial action  and so this plan's penalty is 1  which is higher than the penalty of the original plan. consequently  we consider actions that replace the consumer  namely the second step  among them move b table c   which gives us a solution. 
　 1  reorder-1: we generate a directed graph whose vertices are the current plan steps. an edge exists from plan step a to step a1 if a  the producer  has an effect that is a precondition of a'  the consumer . first  we use this graph to throw out steps that are not useful  by replacing them with null actions . a step is useful if it has an effect that is part of the goal conjunct or an effect that is a precondition of a useful step. adjacent plan steps  between which we have edges in both directions  are deleted as well. now  we add additional edges to the graph that reflect a heuristic notion of threats'. if a  a' are nodes in the graph between which there is no edge  and if a clobers some precondition of a1 we say that a threatens a' and we add an edge from a' to a. 
　finally  we attempt to generate an ordering consistent with the graph  i.e.  such that step a will precede step a' if there is a path from a to a'. usually  this is not possible  and we heuristically order the edges as follows: one of the nodes with the minimal number of incoming edges is chosen as the first step. it is removed from the graph  and the next step is chosen from this revised graph in the same fashion. 
example 1: we have two stacks of blocks: a on b on 
c and d on e on f; our goal state is f on b on e and a on c on d; plan length is 1. suppose that our current plan is:  1  move a b table    1  move a table c    1  move e f table    1  m1ve b c e    1  move f table b    1  move d e c    1  move c table d . 
1  we break ties randomly. 
	brafman and hoos 	1 


figure 1: graphs generated in examples 1  left  and 1  right . 
solid edges stem from producer-consumer relation  broken edges stem from threats. 
　the producer/consumer pairs appears in figure 1  left  and are denoted by solid edges. according to this graph  all nodes are useful. next  we add edges reflecting threats  denoted by broken edges. now  we start reordering the nodes. the only node without incoming arcs is  1   and it is assigned to the first plan step. deleting it  we see four nodes with a single incoming edge  1   1   1   1   among which we can choose arbitrarily. suppose we chose  1 . removing it from the graph  we see that  1  has no incoming edges  and we choose it. next comes  1  and then either  1  or  1 . if we choose  1   we can next choose between  1  and  1 . hence  one possible resulting plan is:  1  move a b table    1  move d e c    1  move e f table    1  move b c e    1  move c table d    1  move f table b    1  move a table c . 
　example 1: here is a similar plan in which the correct plan steps are ordered incorrectly.  1  move a b table   
 1  move a table c    1  move e f table    1  move b  c  e    1  move f  table  b    1  move d  e  table    1  move c  table  d . the initial graph contains the solid edges in figure 1  right . all nodes are useful. when we add threat arcs we obtain the additional broken edges. nodes  1  and  1  have no incoming edges. either choice is correct. we choose  1 .  1  is still the only node without incoming edges  and we choose it next. node  1  comes next  followed by  1 . now we can choose between  1  and  1 . both choices are correct. if we choose  1  we can then choose  1  as well. whichever choice we made  we would get a correct plan. 
　 1  reorder-1: reorder-1 attempts to partition the set of actions into disjoint ranks such that  roughly  each rank is preceded by a rank containing actions that supply its preconditions. the actions within a rank are not needed by each other. after removing unneeded actions  we attempt to reorder actions within a rank based on whether they destroy each others' effects. a more detailed description is deferred to the full version of this paper 
　 1  reorder. applies reorder-1 with probability 1 and otherwise applies reorder-1. 
　initialization we initialize the plan by performing sto/chastic bi-directional search. that is  if n is the plan size  we run a standard regression algorithm in which branches are chosen stochastically for n/1 steps. this determines the latter half of the plan. then  we run stochastic forward search for n/1 steps  which generates the first half of the plan. 
　reachability analysis before we start the planning process  we perform a fast heuristic reachability analysis in order to prune the number of actions considered at each time step. first  we determine which actions are applicable at the initial state. let e1 be the set of effects of all these actions. clearly  actions that have a precondition outside e1 can be pruned as 
1 	planning and scheduling 

　notes: almost .solution holds if new  plans's penalty score is lower than opt.threshold  and we did not call re-
order in the previous step. we keep a tabu list of pairs  whose length is set to 1 in our experiments  containing the last two actions added and their respective positions. we disallow new plans in which an action is inserted in a position for which the corresponding action-position pair appear in the tabu list. 
　state of the planner lpsp is implemented in c++. it does not have a domain parser  yet. hence  for each planning problem we write a procedure that specifies the propositions that hold in the initial and goal state; and for each action schema we define a class whose parameters are the schema's parameters and a list of the appropriate preconditions and effects. in addition  we supply a procedure that  given an action identifier  which is simply some integer   returns an action object. these operations have negligible running times and we believe that the time required to parse a domain description into a more generic action representation will be inconsequential  and  most likely  smaller than the time required to encode the same problem into sat . 
1 experimental results 
we empirically compared lpsp to the pas approach on problem instances from three well-known planning domains: the blocks world and logistics domains  kautz and selman  1; ernst et a/.  1  and the artificial d1 domain  barrett 

and weld  1 .1 for the pas approach  the performance depends on three components:  i  the sat-encoding of the planning instances   ii  polynomial simplification algorithms which are applied to the sat formula before general sat solvers are invoked  and  iii  the sat algorithm used to solve the simplified encoded problem instance. all three components have a significant influence on the overall performance; in particular  the solver performance heavily depends on the encoding and simplification algorithms used to create the sat instance. considering that additionally the sat algorithms have several parameters which have to be tuned to achieve optimal performance  the number of choices over which one would have to optimize in order to get the best possible performance for the pas approach is too high to practically allow an exhaustive analysis. therefore  for this comparative study  we chose the following approach: 
  we used two linear sat encodings which are known to be good from the literature; for the blocks world domain  this is the linear encoding with operator splitting described in  kautz and selman  1j  for the logistics and d1 we used the  erse   explanatory frame axioms  regular operator splitting  sequential plans  full type elimination  encoding as described in  ernst et al.    1 . 
  we considered several simplification strategies  as pro-vided by jimmy crawford's compact simplifies besides  no simplification   -  these were unit propagation and pure literal elimination  p  plus the unary  u  and binary  b  failed literal strategies which are based on efficiently computing unary and binary implicates. for the blocks world domain  we also considered the simplifier based on unit propagation and subsumption  ps  which is part of the satplan system. 
  we focussed on stochastic local search algorithms for sat; in particular  we considered the four best-performing walks at variants described in  mcallester et al.  1  which are among the fastest existing sat solvers. to get an impression  how lpsp's performance compares to that of systematic sat algorithms  we also used satz  li and anbulagan  1   one of the best deterministic sat solvers. 
　for the stochastic solvers  we took great care to optimize the parameters  especially the noise parameter which is known to significantly affect performance  so that the overall time required for finding a solution was minimized. this was done for each sat instance independently  ensuring that for our comparison we got an approximately optimal performance. because for a given problem instance  the different types of local search steps in lpsp require a variable amount of time  and for the pas approach  the simplification and solving time have to be taken into account  we compared cpu times as measured on a pc with a 1mhz pentium ii processor and 1 mb ram running under linux  red hat 1 . for both lpsp and the stochastic sat solvers  our comparison is based on 1 tries  using maxjsteps settings high enough to guarantee that a solution was found in all tries. for lpsp  we left the value of many parameters fixed throughout the experiments  e.g  tabu list length 
1 the first two were chosen because of their use in the original 
satplan paper  and the third because  kautz and selman  1  mentions that it seems difficult for satplan. 
was 1 and down-thresh was 1  and varied the values of greedy jqf-almost  greedy if-notjvlmost  and opt thresh. 
the problem instances have the following characteristics: 
  blocks world: we used the instances described in  kautz and selman  1 ; these are: bw-large.a  1 blocks  1 steps minimal linear plan length   bw-large.b  1 blocks  1 steps   bw large.c  1 blocks  1 step plan   and bw large. d  1 blocks  1 step plan . 
  logistics: we used three instances in which there were 1 packages and 1 cities but only a small number of packages change their location. the instances are log. new. a  1 steps minimal linear plan lengdi   log.new.b 1 steps   and log.new. c  1 steps . 
  d1: we used domain sizes n = 1 and 1 and four instances per domain size: d l s l - n . a  1 steps minimal linear plan length   d l s l . b  1 steps   d l s l . c  1   and d l s l . d  1 steps . 
　in table 1  we report our experimental results. for lpsp  we report the mean and median cpu times over 1 successful tries  see above  as well as the variation coefficient  standard deviation / mean   which gives a scaling independent impression of the variability of the observed run-times. for pas/walksat  we report the cpu times for simplifying the formula and the mean cpu time required by walksat for solving the resulting simplified problem instance averaged over 1 successful tries. furthermore  we report the variation coefficient for the time used by walks at.1 note that here  we report only the best results we found for any simplification and walksat combination  using approximately optimal noise parameter settings for walksat.1 for pas/satz  as only deterministic algorithms are used  we report the cpu times for simplification and satz. 
　as can be seen from table 1  lpsp shows superior performance compared to pas/walksat as well as pas/satz on almost all problem instances. for the blocks world instances  
lpsp is between 1 and 1 times faster than pas/walksat. interestingly  for pas/walks at  the time required for simplifying the formula dominates the overall performance. since different from walksat  the implementations of the simplification algorithms are not optimized for speed  one might expect a significant reduction in overall performance when using optimized simplifiers. however  for the larger instances  lpsp shows superior performance even when  unrealistically  assuming that simplification would come for free. 
furthermore  lpsp requires much less tweaking then walksat  for which various simplification strategies must be considered  various heuristics  and various parameter tuning per heuristic. in addition  our lpsp implementation is certainly not fully optimized. 
　1  our actual experimental methodology is based on measuring run-time distributions  rtds  as outlined in  hoos and stiitzle  1 ; because of the limited space the rtds could not be reported here  but this data is available from the authors. 
　1 the best-performing walksat variants were tabu for the blocks world instances and novelty for all others. the approximately optimal noise settings varied between the instances and seemed to be strongly dependent on the simplification strategies applied before. 
	brafman and h1s 	1 


table 1: performance of lpsp versus pas using die best simplification and solver variants with approximately optimal parameters. for stochastic solvers  we report the mean run-times over 1 successful tries and the variation coefficient  vc = standard deviation/mean . for both pas approaches  we report the times required for simplifying  first number  and solving  second number  separately and also indicate which simplification method has been applied  see text for explanation  all run-times reported in cpu seconds;  *  indicates cases in which no solution was found in 1 cpu seconds  for sls algorithms  1 tries 

♀ 1 seconds were performed . for further details  see text. 
　the more complex sat-simplifications seem to be far more effective for the logistics domain than for the blocks world or d1 problems. here  the formulae obtained by simplifying with the  unary/binary failed clauses  options are almost trivial for walksat. however  although they have polynomial worst-case complexity  these simplifications are quite expensive in practice. so here  again  for pas/walksat the overall performance is dominated by the time required for simplification. comparing the overall performance  lpsp is between 1 and 1 times faster than pas/walksat. even assuming that the implementation of the simplifier could be considerably more optimized than lpsp  it is hard to imagine that pas/walks at could reach lpsp's performance on this domain. it should be noted  however  that for the logistics domain  most problem instances have significantly shorter parallel plans which are much easier to find than sequential plans. but since lpsp is a linear planner  it would be unfair to compare its performance to pas approaches which allow for parallel plans. finally  even for dlsi  a domain which has been noted to be difficult for satplan using sls for solving the sat instances  kautz and selman  1   lpsp shows better performance than pas/walksat. the only exception is instance d l s l 1. a  which is solved by simplification  unit propagation  alone. the reason for this is that the d l s l - n . a instances have a chaining structure of the goals and operators which is very regular  but  in our opinion  highly untypical for realistic planning problems. we also believe that lpsp's performance on this domain can be significantly improved by optimizing its parameter settings. 
　regarding the results on pas/satz  lpsp's performance is still considerably better on all instances except for instance dlsl-1. a  which in principle is solved by simplification  unit propagation  alone. nevertheless  for this particular instance  satz is actually faster then the simplification algorithm we use  probably because it is more efficiently implemented. interestingly  when compared to pas/walksat  
1 	planning and scheduling 
pas/satz shows a better performance for 1 of our 1 benchmark instances. for the biggest blocks world and logistics instances  as well as for one of the dlsl-1 instances  satz did not find a solution in 1 seconds - which could possibly indicate that satz does not scale as well as sls approaches 
 lpsp and pas/walksat . however  this issue needs to be further investigated  especially using newer  randomized systematic search algorithms  gomes et al.  1 . 
1 discussion 
the thesis that sls-based algorithms operating on unencoded problems can fare better than those operating on encoded problems cannot be proved experimentally. the performance of lpsp does  however  lend it greater credibility  especially when we compare the effort invested in it with that invested in work on sat-based sls algorithms in general and the pas approach specifically. 
　in a longer version of this paper  we describe experiments which we conducted on two additional problem domains: hamiltonian circuit and binary csps. the first domain has interesting  inherent structure  and we have been able to obtain better results using an sls-based algorithm applied to the graph description directly. the second problem domain is more general and closely resembles sat problems. there  we found that sat-based methods perform better than the sls-based algorithms we experimented with.1 
　of course  one could argue that in the area of planning in general  sls-based methods applied to encoded problems that do not enforce the linearity assumption have the upper hand. however  recent research is starting to show that the situation is a bit more complicated. tserina and gerevini  1  employ sls methods to search graphplan's planning graph. their algorithm outperforms pas based methods on some problems  and in particular  those in which concurrent 
1 see also  hoos  1 . 

plans are much shorter. our algorithm seems to outperform pas based approaches when concurrency is not an important factor  e.g.  the blocks' world instances . the best sat-based planner  blackbox {kautz and selman  1  relies more on traditional plan representations than the original s atplan planner  kautz and selman  1 . blackbox goes very far with the original planning problem before converting it into a prepositional formula: it first generates a planning graph and encodes this graph together with the mutual exclusion constraints it generated. more importantly  recent work  giunchiglia et al.  1  shows that better performance can be obtained if the variables describing state properties are treated as dependent variables  i.e.  one chooses an assignment for the action variables and this determines the value of the state variables . what this result mean is that it is better to search over the space of assignments to actions than over the whole space of truth assignments. the space of action assignments is very similar to lpsp's search space. 
　naturally  we have not heard the last word in sat algorithms  and recent work on exploiting variable dependences  kautz et al  1  may allow us to utilize knowledge about problem structure in solving the encoded problems. another promising direction in which little work has been carried out is the analysis of the encoded problems for useful features of search space structures  see also  hoos  1   or syntactic properties. such features may stem from deep properties of the encoded problem. to date  most sat solvers do not attempt to utilize such information  although it could be argued that formula simplification routines do something of this sort . but perhaps there are algorithms that can operate much better than the standard methods on sentences with special properties. this is particularly interesting if such properties are shared by all problems from a particular domain. if this turns out to be the case  then  indeed  the encode & solve approach may be our best bet.1 
to use chapman's terminology  lpsp is a somewhat 
 scruffy  planner. it would be nice to see a simpler  more principled and general planner based on sls techniques. however  it is already much easier to optimize than the pas based algorithms that have three distinct phases  translate  simplify  solve  each of which needs to be fine-tuned separately. moreover  it may be the case that good sls algorithms must be a bit involved if they are to exploit domain structure. lpsp's reordering operators are interesting in their own right and could possibly be integrated into plan reuse and plan repair algorithms. plan reordering has been considered in the past  see  backstrom  1  and references therein  but typically with the goal of optimizing the order of correct plans. the idea of repairing plans in general is not new either  and goes back at least to  sussman  1 . the heuristic  rather than more systematic  approach lpsp takes stems from the need to balance the desire for a better  and more sophisticated order analysis  which is likely to be intractable   and the need to maintain a low cost for each step. finally  we note that different types of domain specific knowledge can be used to focus the search process  e.g.  by using general variables rather than binary variable to specify state information  by restricting the type of operators that should be considered in various situations  etc. 
acknowledgments 
craig boutilier was-instrumental in the development of earlier versions of lpsp. the first author is partially supported by the paul ivanier center for robotics research and production management. 
