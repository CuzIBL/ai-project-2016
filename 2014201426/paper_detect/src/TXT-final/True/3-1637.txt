
in this paper we consider dynamical properties of simple iterative relational classifiers. we conjecture that for a class of algorithms that use label- propagationthe iterative procedurecan lead to nontrivial dynamics in the number of newly classified instances. the underlaying reason for this non- triviality is that in relational networks true class labels are likely to propagate faster than false ones. we suggest that this phenomenon  which we call two-tiered dynamics for binary classifiers  can be used for establishing a self-consistent classification threshold and a criterion for stopping iteration. we demonstrate this effect for two unrelated binary classification problems using a variation of a iterative relational neighborclassifier. we also study analytically the dynamical properties of the suggested classifier  and compare its results to the numerical experiments on synthetic data.
1 introduction
recently there has been a growing interest in relational learning and classification. while traditional learning approaches assume different data instances are independent and identically distributed  relational classification methods allows for the study of more complex data structures because it explicitly takes into account their existing links and relations. recently developed algorithms for relational classification have been used for learning probabilistic relational models  friedman et al.  1   hypertext classification  getoor et al.  1   web page classification  slattery and craven  1; macskassy and provost  1   link prediction  taskar et al.  1   discovery of authoritative information  kleinberg  1   studying relational structures in scientific publications  mcgovern et al.  1   etc.
　most of the existing methods for relational classification are iterative in nature  neville and jensen  1; macskassy and provost  1 . the intuitive assumption behind the iterative approach is that information inferred about one entity can be used to make inferences about other entities that are related to it. this allows class labels  or associated probabilities  to propagate throughout the system as newer instances are classified. although iterative classifiers have been shown to enhance prediction accuracy  neville and jensen  1; macskassy and provost  1   there is an associated risk: a few false inferences sometimes lead to a  snow-ball  effect  neville and jensen  1  cascading the number of misclassified entities as iteration proceeds. as a consequence  the final results will depend strongly on the accuracy of initially assigned class labels and on the classification criteria  i.e.  model parameters. more generally  it is known that many classification algorithms are sensitive to parameter settings. for example   keogh et al.  1  found that few popular data mining algorithms performed well on multiple problems without parameter adjustments.
　in this paper we argue that for a class of iterative classifiers the issue of parameter sensitivity can be addressed in a self consistent and elegant manner by examining the dynamics of the iterative procedure more closely. we illustrate this point for a simple iterative classifier that uses a threshold-based criterion for labelling data-instances  and propose a meta- heuristic for setting the optimal threshold value. our heuristic is based on the assumption that in relational networks true class labels are likely to propagate faster than false ones. we demonstrate that this phenomenon  which we call two-tiered dynamics  can serve as a natural criterion for both setting a threshold value and stopping the iteration. hence  our method reduces the dependency of iterative classification on model parameters.
　to illustrate our approach  we introduce a simple algorithm for relational binary classification. we consider the case when the relation between two data-instances is characterized by the weight of the link connecting them  so that the relational structure is fully determined by an adjacency matrix m. given an initial set of known instances of a class a  our algorithm then defines an iterative scheme with a simple threshold based rule: an instance will be classified as type a if it is connected to super-threshold number of classified or initially known instances of type a. the novelty of our approach is that we suggest a self-consistent way of setting the parameter of our model  the threshold: namely  we set it automatically to the value that produces the most pronounced two-tiered dynamics. we present empirical results that illustrate the use of this approach. we also develop an analytical framework for describing the dynamics of iterative classification of our algorithm  and compare its predictions with results obtained for synthetic  randomly generated networks.
　the rest of the paper is organized as follows. in the next section we provide a more detailed description of our algorithm. in section 1 we present results for two case studies that demonstrate the two-tier dynamics. in section 1 we present an analytical framework for studying the dynamical properties for a binary iterative classifier. discussion on our results and future developments are presented in section 1.
1 dynamics of for iterative classification
to understand the main idea behind our approach  we find it illustrative to frame the classification problem as an epidemic process. specifically  let us consider a binary classification problem defined on a network where data-instances  from classes a and b  correspond to nodes and the relations between them are represented by  weighted  links. we are given the correct classification of a small subset of nodes from class a and want to classify other members of this class. assume that we are using a simple  threshold based iterative relational classifier  such as one described below in fig. 1   for assigning class labels and propagating them through the system. now  if we treat the initially labelled data-instances as  infected   then the iterative scheme defines an epidemic model where at each time step new instances will be infected if the super-threshold classification criterion is met. clearly  the fixed point of this epidemic process will depend both on the value of the threshold and both inter- and intra-class link structure of the network. in the case where two classes are totally decoupled  i.e.  there are no cross-links between two sub-classes  the epidemics will be contained on the set a   and one can relax the classifier threshold to guarantee that all the instances of a will be correctly classified. if there are links between data-instances in different sub-classes  then there is a chance that the nodes from class b will be infected too  i.e.  misclassified . however  if the link patterns between two subclasses are sufficiently different  we can hope that the process of epidemic spreading in two systems will be separated in time. moreover  by tuning the classification threshold  we can control the rate of epidemic spreading in sub- population a  hence affecting the epidemic spread in sub- population b. the main idea of our approach is to tune the threshold parameter in order to achieve maximum temporal separation of epidemic peaks in two classes.
　we characterize the dynamics of an iterative classifier by the number of newly classified instances at each time step  e.g.  if n t  is the total number of classified a-instances at time t  then the relevantvariableis  n t  = n t  n t 1 . as it will be clear later  two-tiered dynamics arises whenever  n t  has two temporally separated peaks.
　to proceedfurther we now formallydefine ourbinaryclassification algorithm. let s be the set of data-instances to be classified  and let assume that s is composed of two subsets sa   s and s a = s   sa. initially  we know the correct class labels of a  small  subset of the instances of type a  sa1   and the problem is to identify other members of class sa given the characterizing relations between the entities across both types. we define mij as the weight of the link between the i-th and j-th entities.
we associate a state variable with each entity  si = 1
so that the state value si = 1 corresponds to type a. initially  only the entities with known class labels have si = 1. at each iteration step  for each non-classified instance we calculate the cumulative weight of the links of that instance with known instances of type a. if this cumulative weight is greater or equal than a preestablished threshold h  that instance will be classified as a type a itself. this is shown schematically in figure 1. note that our algorithm differs slightly from other simple relational classifiers  such as relational neighbor classifier  macskassy and provost  1   in two aspects: first  it directly assigns class labels and not probabilities  and second  it is asymmetric in the sense that if an instance was classified as type a it will remain in that class for the remainder of the run. this later property implies that the total number of classified a-instance is a monotonically non-decreasing function of time. if the number of iterations
input adjacency matrix m initialize si = 1  for initially known instances  si = 1 for the rest initialize a threshold h iterate t = 1 : tmax for i-th node with si t  = 1 calculate the weight wi of adversary nodes connected to it: wi = pmijsj t  if wi − h   si t + 1  = 1
end for loop
end
figure 1: pseudo-code of the iterative procedure
tmax is large enough  then a steady state will be achieved  i.e.  no instance will change its state upon further iterations. as we mentioned above  the final state of the system will depend on the threshold value and the adjacency matrix. if the threshold value is set sufficiently low then the system will evolve to a state where every instance has been classified as type a. on the other hand  if it is set too high  then no additional instances will be classified at all. as we will show below  for intermediary values of the threshold h the system will demonstrate two-tier dynamics.
1 case studies
in this section we test our hypothesis empirically on two distinct and unrelated data-sets: the first is a synthetic data generated by the hats simulator  cohen and morrison  1   and the second is cora  mccallum et al.  1   a large collection of research papers in computer science.
1 results for the hats simulator data
the hats simulator is a framework designed for developing and testing various intelligence analysis tools. it simulates a virtual world where a large number of agents are engaged in individual and collective activities. each agent has a set of elementary capabilities which he can trade with other agents if desired. most of the agents are benign while some are covert adversaries that intend to inflict harm by destroying certain landmarks called beacons. there also are agents known to be adversaries. agents travel for meetings that are planned by an activities generator. each agent belongs to one or more organizations that can be of two types  benign or adversary. each adversary agent belongs to at least one adversary organization  while each benign agent belongs to at least one benign organization and does not belong to any adversary organization. when a meeting is planned  the list of participants is drawn from the set of agents that belong to the same organization. hence  a meeting planned by an adversary organization will consist of only adversary  either known or covert  agents  whereas a meeting planned by a benign organization might contain all three types of agents.
　the type of data from the hats simulator is a sequence of lists containing unique hat id-s that have met with each other. given this sequence  one can unequivocally construct a graph  adjacency matrix  m of hats' meeting activities  where each entry mij describes the number of meetings between the i- th and j-th agents  note that the graph is not directed so the matrix is symmetric . in the simulations presented here we used hats data for n = 1 agents   nk = 1 known adversaries  nb = 1 benign  and nc = 1 covert  which was collected for the first 1 ticks of simulations.
　we tested our algorithm for small  large  and intermediate values of the threshold h. for small h most of the nodes in the network are infected after a short time  as expected  see fig. 1 . similarly  for large values of h  not shown here  the epidemic spreads through only a very small subset of nodes. in both cases the epidemics are characterized by one- tier dynamics. the situation is drastically different for intermediate values of the threshold  as the behavior of epidemic spreading demonstrates two-tiered structure. namely  after a sharp initial spread the epidemic seems to be saturated. however  upon further iterations  the number of infected nodes increases sharply  and all the nodes in the network are infected shortly thereafter. clearly  this corresponds to some kind of threshold-phenomenon in the whole network  where infection of certain nodes causes an epidemic in the whole system. this is illustrated in fig. 1 a  where we plot the number of infected actors vs time for h = 1 and h = 1.
as we mentioned in the introduction  this behavior suggests a natural criterion for stopping the iteration. more precisely  in fig. 1 b  we plot the number of newly infected nodes at each times step versus time  i.e.   n t  = n t  n t 1 . for the threshold value h = 1  not plotted  there is only a single peak in  n t . however  for h = 1 one can distinguish two well-separated peaks  denoted pa and pb which are indicative of two-tier dynamics in epidemic spreading. if we assume that pa corresponds to the epidemic spreading in the first  covert  sub-population  and pb corresponds to the rest of the network  then the iteration should be stopped right before the infection starts to spread in the rest of the system  i.e.  at t = 1 . in this particular example  we established that if the above mentioned criterion is used  then the algorithm correctly identifies 1 out of 1 covert adversaries  while at the same time misidentifying only 1 of the 1 benign nodes as adversaries. this is a surprising result especially taking into account the simplicity of the algorithm.
　more generally  our experiments with the hats data indicate that although the detection error rate of the algorithm varies depending on the particular structure of the network 

figure 1:  a  total number of infected nodes n t  for h = 1 and h = 1.  b  the number of newly infected instances vs time   n t  for h = 1. two separated peaks are a clear indication of two-tier dynamics.
the amount of the available data  as well as the presence of noise  its performance is rather robust as long as the two-tier dynamics is observed.
1 results for cora data
the cora data  mccallum et al.  1  contains a set of computer science research papers that are hierarchically categorized into topics and subtopics. each paper includes a label for a topic/subtopic/sub-subtopic  and a list of cited articles. following the previous studies  macskassy and provost  1   we focused on the papers on machine learning category  that contained seven different subtopics: case-based  theory  genetic algorithms  probabilistic methods  neural networks  rule learning and reinforcement learning. two papers are linked together by using common author  or authors  and citation.
　since our algorithm is for binary classification  we constructed separate classification problem for each topic. we varied the fraction of known instances from as high as 1% to as low as 1%. for each classification task  we did up to 1 different runs using random subsets of classified hats. note  that initially labelled set contained papers that belong to a class other than one we wanted to identify  the class label of all the papers in the initially labelled sets were fixed throughout iteration.
　after pruning out the isolated papers from the data-set  we were left with 1 unique titles. since we observed a large dispersion in the node connectivity ranging from 1 to more

than 1  we revised our threshold-based rule a little so that the threshold condition was established not only for the total weight  but also on the fraction of that weight.
　we observed that the structure of dynamics  i.e.  two- tier vs single-tier  varied from topic to topic. from the seven subtopics  the data that demonstrated the best manifestation of two-tiered dynamics was reinforcement learning subtopic: it robustly demonstrated two separate peaks from run to run for various fraction of initially known data as shown in fig 1 a . what is more striking  however  is that the accuracy of classification was remarkable even if the fraction of initially known instances were as low as 1% of the total number. indeed  as illustrated in fig 1 b   for 1% of initially known class-labels  and from which only 1 in the reinforcement learning topic  the f-measure at the iteration-stopping point t = 1 is fm 「 1. moreover  our experiments also suggest that increasing the number of initially labelled data does not necessarily improve the performance. although this seems counterintuitive  it makes sense from the perspective of our algorithm: indeed  the more labelled instances we have at the start  the better the chances that the epidemics will leave the sub-network and start to infect nodes from other classes. one could think of increasing the threshold would help  but it did not  probably because of large dispersion in node connectivity. of course  one can always sample from available known instances and choose to include only an appropriate number of them.
　we observed two-tier structures in most of the other topics too. although some of them were not as pronounce as for the previous case  they were robust in the sense that uprise of the second peak almost surely corresponded with the spread of label-propagation outside of that class. however  in some instances  notably for the neural networks subtopic  we did not observe any clear sign of this dynamics at all. our explanation is that this subcategory was vastly larger than the rl-one  1 compared to 1  so it was easier for the initial infection to propagate outside. this suggests that perhaps our method is best when one wants to identify a sub-class that is considerably smaller compared to the total number of instances.
1 analysis
in this section we present an analysis of our classification algorithm. specifically  we study the epidemics spreading as described by our algorithm. for the sake of simplicity  we consider a case of an unweighed graph when the entries in the adjacency matrix are either 1 or 1. generalization to the case of the weighed networks is straightforward. also  for clarity purposes we will retain the language of section 1 and refer to instances as agents.
　let us start by considering only one of the subnetworks in the system. namely  we neglect benign agents for now and consider a network consisting of covert and known adversaries only. we want to examine how the epidemic spreads through the covert population.
　we now consider the iterative procedure more closely. initially  all of the agents except known adversaries are classified as not-infected  si t = 1  = 1 i = 1 ..n. we define a

figure 1:  a   n t  for h = 1  with 1% of initially classified instances.  b  f-measure of predictive accuracy vs iteration step. at t = 1  the iteration stopping point   fm 「 1.
local field hi for the i-th agents as the number of its connections with known adversaries. we assume that hi-s are uncorrelated random variables drawn from a probability density function p h . let f h  = ph1−h p h1  be the the fraction of agents who are connected with at least h initially known adversary agents. also  let ki be the number of connections the i-th agent has with newly classified adversaries  note that ki excludes the links to the initially known adversaries  and assume that ki-s are described by a probability density function p k;t . in other words  p k;t  is the probability that a randomly chosen uninfected covert agent at time t is connected to exactly k infected covert agents. since the number of infected agents changes in time  so does the distribution p k;t . initially  one has p k;t = 1  = δk 1  where δij is the kroenecker's symbol.1.
　in the first step of the iteration  the agents who have a local field larger than or equal to the threshold value  hi − h  will change their states to 1. hence  the fraction of agents classified as adversaries at t = 1 is n t = 1  = f h . since these new adversary agents are connected to other non-classified agents  this will alter the local fields for non-classified agents. let us define a variable for each agent zi = hi +ki. then the distribution of zi is described by
	±	±
	p z;t 	= xxp k;t p h δz k+h
k=1 h=1
		 1 
clearly  the criterion for infection is zi − h. hence  the fraction of agents that will be classified as covert at time t+1 is
	±	±
	n t + 1  = x p z t  = xp k;t f h   k 	 1 
	z=h	k=1
note that the probability p k;t  of being connected to an infected agent depends on the fraction of infected agents  p k;t  = p k;n t   . hence  the equation 1 is in general a highly non-linear map. once the functions p k;t  and f h  are specified  equation 1 can be solved  at least numerically  to study the dynamics of epidemic spreading in a homogenous  single-population network. in particular  the final fraction of infected agents is given by its steady state n t ★± . the above framework is easily generalized for the case when there are two sub-populations in the network. we denote two sub-populations by c  covert  and b  benign . let fc h  fb h  be the fraction of c and b agents respectively that are connected to at least h known adversaries. also  let pcc k;t  and pcb k;t  be the probabilitythat a randomlychosen c agent is connected to exactly k infected c and infected b agents  respectively. similarly  we define pbb k;t  and pbc k;t  as the probability that a randomly chosen b agent is connected to k infected b and infected c agents  respectively. then the fraction of infected agents in each population nc t  and nb t  satisfy the following set of equations:

 1 
to proceed further we need to make assumptions about the distribution functions pcc k;t   pbb k;t   pcb k;t  and pbc k;t  i.e.  probability that a randomly chosen uninfected agent of type c  b  is connected to k infected agents of respective type. this is particularly easy to do when the graph is obtained by randomly establishing a link between any two agents/nodes with a fixed probability. specifically  let us assume that each covert agent is connected to covert and benign agents with corresponding probabilities pcc and pcb  while each benign agent has similarly defined probabilities pbb and pbc  note that pcb = pbc . hence  each covert agent in average is connected with γcc = pccnc covert and γcb = pcbnb benign agents  and each benign agent is connected with γbb = pbbnb benign and γbc = pbcnb benign agents.
　consider now a randomly chosen uninfected agent of either type  say  covert  at a certain time t  and denote it as c1. there are ncnc t  infected covert agents at time t  and c1 is connected with each of them with probability pcc. hence  the probability pcc k;t  that c1 is connected with exactly k infected covert agents at time t is given by a poisson distribution with a mean γccnc t . similar arguments hold also for

figure 1: analytical and simulation results for  a  n t  and  b   n t  for a random network. the results are averaged over 1 trials
pbb k;t   pcb k;t  and pbc k;t . hence  one obtains from
the equation 1nc t + 1 =〜fc h   k   j e γccnc t  γcbnb t  1 nb t + 1 =〜fb h   k   j e γbbnb t  γbcnc t  1 equations 1 and 1 are a system of coupled maps that governs the evolution of fraction of infected individuals in both sub-populations. the coupling strength depends on γcb and γbc   or in other words  average number of interconnections between two sub-populations. note that if one sets γcb = γbc = 1 the dynamics of two sub-populations are totally independent and one recovers the system equation1 with corresponding parameters for each sub-population. to validate the prediction of our analysis  we compared equations 1 and1 with experimentson randomlygeneratedgraphs. the results are shown in fig. 1 where we plot the fraction of the infected nodes n t  = nc t  + nb t  as well as the difference  n t  = n t + 1    n t  versus iteration number for a randomly generated graph of nc = 1 covert and nb = 1 benign nodes. the parameters of the graph are pcc = 1  pbb = 1 and pcb = 1. also  we chose the value of the threshold field such that to ensure two-tier dynamics. the results of the simulations were averaged over 1 random realization of graphs. clearly  the agreement between the analytical prediction given by equations 1 and 1 and the results of the simulations is quite good. in particular  these equations accurately predicts the two-tier dynamics observed in the simulations. we also note that the graphs are structurally very similar to the results from the hats simulator data in fig. 1. this suggests that despite the the explicit organizational structure in the hats data  its infection dynamics is well captured by a simple random-graph analysis model. note however  that this agreement might deteriorate for more complex organizational structure  e.g.  large overlap between different organizations   hence more sophisticated analytical models might be needed.
1 discussion and future work
we have presented a simple  threshold based iterative algorithm for binary classification of relational data. our algorithm can be stated in terms of epidemic spreading in networks with two sub-populations of nodes  data-instances  where infected nodes correspond labelled data-instances. we also presented a meta-heuristics that utilizes the differences in the propagation of true and false class-labels for setting the right threshold value in our algorithm. specifically  we demonstrated that if the threshold value is tuned appropriately  the dynamics of the number of newly classified instances will have a two-peak structure suggesting that the infection propagation in two sub-classes is time-separated. consequently  we suggested that the iteration should be stopped at the point when the second peaks starts to develop.
　our empirical tests  especially with cora  indicate that the two-tier dynamics is not an artifact  but is present in real world relational data. although we did not observe this dynamics in all the classification tasks in cora  our results nevertheless indicate that whenever the two-tier dynamics is present  it is indeed robust  and contains useful information that can be utilized by classification algorithm. in addition  our experiments  as well as qualitative arguments on epidemic spreading  suggest that the method presented in this paper should work best when the sub-class one wants to identify is a small fraction of the whole data-set  as there is a greater chance that the class-labels will propagate throughout the proper sub-population first before infecting instances of other classes.
　we also developed an analytical framework for studying the properties of iterative classification. in particular  we obtained a coupled of set discrete-time maps the describe the evolution infected/labelled individuals in both sub- populations. we compared our analytical results with numerical experiments on synthetic data and obtained excellent agreement. we would like to mention that the assumption of a random graph we used in our analysis is clearly an over-simplification. indeed  most of the real-world relational structures  e.g.  social networks  demonstrate smallworld phenomenon that is not captured by our random graph model. in our future work we intend to extend our framework to account for more general type of networks. note that in this scenario the probability of being infected will be strongly correlated with a degree of a node  i.e.  more links will imply more chances of being infected .
1	acknowledgements
we thank joshua moody for preparing the hats data.
