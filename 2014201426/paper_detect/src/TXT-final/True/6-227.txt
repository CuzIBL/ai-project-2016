learning to compete in heterogeneous web search environments  
rinat khoussainov and nicholas kushmerick 
department of computer science  university college dublin 
belfield  dublin 1  ireland 
{rinat  nick} ucd.ie 
　
1 introduction 
previous research in web search has mainly targeted performance of search engines from the user's point of view. parameters such as precision  recall  and freshness of returned results were optimised. on the other hand  a provider of search services is rather interested in parameters like the number of queries processed versus the amount of resources used to process them. we focus on performance optimisation of search engines from the service provider's point of view. 
　an important factor that affects the search engine performance is competition with other independently controlled search engines. when there are many engines available  users want to send queries to those that provide the best possible results. thus  the service offered by one search engine influences queries received by others. 
　competition is even more important in heterogeneous search environments consisting of many specialised search engines  which provide access to the so-called  deep  or  invisible  web . each specialised engine in such environment indexes only a subset of all documents  e.g. on a particular topic . each user query is only sent to a small number of the engines which can return the best results. selection between specialised search engines is done  semi automatically by meta-searchers  which rank engines for each user query. thus  parameters of specialised engines automatically affect their ranking and  hence  the queries they receive  and ultimately their profit. 
　we are examining the problem of performance-maximising behaviour for non-cooperative specialised search engines in heterogeneous search environments. in particular  we analyse how specialised search engines can select on which topic s  to specialise and how many documents to index on that topic. we provide a game-theoretic analysis of a simplified version of the problem and motivate the use of the concept of  bounded rationality . bounded rationality assumes that decision makers are unable to act optimally in the gametheoretic sense due to incomplete information about the environment and/or limited computational resources. we then cast our problem as a reinforcement learning task  where the goal of a specialised search engine is to exploit sub-optimal behaviour of its competitors to improve own performance. 
   *this research was funded by science foundation ireland and the us office of naval research. 
1 problem formalisation 
performance metric. we adopt an economic view on search engine performance. performance is a difference between the value of the search service provided  income  and the cost of the resources used to provide the service. in our simplified version of the problem we only take into account the cost of resources involved in processing search queries. under these assumptions  engine performance can be expressed as follows:  

where q is the number of queries received in a given time interval  d is the number of documents in the search engine index  and are constants. 
     represents the service value: if the price of processing one search request for a user is then would be the total income from service provisioning. represents the cost of processing search requests. if x amount of resources is sufficient to process q queries  then we need 1x to process twice as many queries in the same time. similarly  twice as many resources are needed to search twice as many documents in the same time. thus  the amount of resources  and  hence  the cost  is proportional to both q and d  and so can be expressed as where reflects the resource costs. the example of the fast search engine confirms that our cost function is not that far from reality  risvik and michelsen  1 . 
　environment model. let us assume that users issue queries on just a single topic  e.g.  cars . we will see later how this extends to multiple topics. it is reasonable to assume that users would like to send queries to search engines that contain the most relevant documents on the topic  and the more of them  the better. suppose that search engines have  ideal  web robots which for a given d can find the d most relevant documents on the topic. in this case  the user would simply have to send queries to the engine containing the largest number of documents on the topic. 
　this model can be extended to multiple topics  if the state of a search engine is represented by the number of documents that engine i indexes for each topic t  a query on topic t 
poster papers 	1 would be sent to the engine i with the largest  of course  such extension ignores possible overlaps between topics in both queries and documents. on the other hand  if we associate each topic with a search term  the whole engine selection model would closely reflect how some real-life engine selection algorithms work  callan et al  1 . 
　decision making process. for each time interval  the search engines simultaneously and independently decide on how many documents to index and allocate resources to process expected search queries  thus incurring the corresponding costs . as search engines cannot have unlimited crawling resources  we presume that they can only do incremental ad-
justments to their index contents that require the same time for all engines. the user queries are allocated to the engines based on their index parameters  as described above. 
　since a search engine cannot know the number of queries that users will submit  it may allocate less query processing resources than the number of queries it will receive. we assume that excess queries are discarded and the search engine does not benefit from them. then  performance of engine / over a given time interval can be represented as 
where 	is the expected number of queries 
across all topics for which the search engine is trying to compete  i.e. index at least one d o c u m e n t     i s the total number of indexed documents  is the total number of queries actually received by engine i  and 

is the share of queries in topic / received by engine i  and qt is the number of queries users submitted on topic t. 
1 	analysis and solution approach 
the decision-making process can be modelled as a multistage game. at each stage  a matrix game is played  where players are search engines  actions are values of  dt   and player i receives payoff pi  as above . if player    knew the actions of its opponents at a future stage k  it could calculate the optimal response as the one maximising its payoff pi k  at that stage. for example  in case of a single topic and a constant query stream it should play  if 
ply put  outperform opponents by 1 document if profitable  and do not incur any costs otherwise . 
　in reality  the players do not know the future. one possible way around this would be to agree on  supposedly  mutually beneficial  actions in advance. to avoid deception  players would have to agree on playing a nash equilibrium of the game  since only then there will be no incentive for them to not follow the agreement. agreeing to play a nash equilibrium  however  becomes problematic when the game has multiple such equilibria. players would be willing to agree on a nash equilibrium yielding to them the highest  expected  payoffs  but the task of characterising all nash equilibria of a game is np-hard even given complete information about the game  as follows from  conitzer and sandholm  1  . 
　np-hardness results and the possibility that players may not have complete information about the game lead to the idea of  bounded rationality   when players may not use the optimal strategies in the game-theoretic sense. our proposal is to cast the problem of optimal behaviour in the game as a learning task  where the player would have to learn a strategy that performs well against its sub-optimal opponents. 
　learning in repeated games has been studied extensively in game theory and machine learning. examples include fictious play and opponent modelling  robinson  1; carmel and markovitch  1 . we apply a more recent algorithm from reinforcement learning called gaps  peshkin et al  1 . in gaps  the learner plays a parameterised strategy represented by a finite state automaton  where the parameters are the probabilities of actions and state transitions. gaps implements stochastic gradient ascent in the space of policy parameters. after each learning trial  parameters of the policy are updated by following the payoff gradient. 
　gaps has a number of advantages important for our domain. it works in partially observable games. it also scales well to multiple topics by modelling decision-making as a game with factored actions  where action components correspond to topics . the action space in such games is the product of factor spaces for each action component. gaps  however  allows us to reduce the learning complexity: rather than learning in the product action space  separate gaps learners can be used for each action component. it has been shown that such distributed learning is equivalent to learning in the product action space. we call a search engine that uses the proposed approach cougar  which stands for competitor using gaps against rivals. 
1 	preliminary results 
we evaluated our approach in a number of simulation experiments  which demonstrated cougar's ability to compete successfully with different opponents. for the sake of brevity  we present here results from one such experiment with two competing search engines. one search engine was using a fixed strategy  called  bubble   the other one was cougar. the search engines could increase  decrease  by one   or keep the number of documents indexed on each topic. they could also observe the size of own index  the relative sizes of opponents' indices  and the number of user queries qt submitted for each topic  the last two observations can be obtained from the meta-searcher . the expected number of queries on topic t at future stage a; was calculated as  
　the experimental setup consisted of three components: the generator of search queries  the metasearcher  and the search engines. the state of a search engine's document index is represented by a vector  of the numbers of documents indexed by the search engine for each topic. this is the information used by the metasearcher to select search engines. 
　to simulate user search queries  we used http logs obtained from a web proxy of a large isp. we developed extraction rules individually for 1 well-known search engines. the total number of queries extracted was 1 collected over a period of 1 days. we associated topics with search terms in the logs. to simulate queries for t topics  we extracted the t most popular terms from the logs. the number of queries generated on topic t for a given day was equal to the number of queries with term t in the logs belonging to this day. 
　the  bubble  strategy tries to index as many documents as possible without any regard to what competitors are do-
　
1 	poster papers 
　

ing. as follows from our performance formula  section 1   such unconstrained growing leads eventually to negative performance. once the total reward falls below a certain threshold  the  bubble  search engine goes bankrupt  it shrinks its index to 1 documents and retires until the end of the trial . this process imitates the situation  in which a search provider expands its business without paying attention to costs  and eventually runs out of money  or an analogy with the   . com bubble  . an intuitively sensible response to the  bubble  strategy would be to wait until the bubble  bursts  and then come into the game alone. that is  a competitor should not index anything while the  bubble  grows and should start indexing a minimal number of documents once the  bubble  search engine goes bankrupt. 
　our simulation had two topics  and  bubble  was increasing  and decreasing  the number of documents indexed for each topic simultaneously. first  we trained cougar in a number of learning trials. once it reached a steady performance level  the resulting strategy was evaluated in a scries of testing trials. each simulation trial consists of 1 days  where each day corresponds to one stage of the multi-stage game played. the resulting performance in the whole trial is calculated as a sum of discounted rewards from each day. 
　figure 1 shows how cougar's performance improving during learning. figure 1 visualises a testing trial between the  bubble  and the cougar engines by showing the number of documents indexed by the engines on each day of the trial  the top half of y axis shows the number of documents for topic 1  the bottom half shows the number of documents for topic 1 . note that cougar has learned to wait until  bubble  goes bankrupt  and then to win all queries for both topics. 
　we also investigated effectiveness of our approach against evolving opponents. in particular  we evaluated performance of a cougar strategy learned in self-play against other learners  other cougars in our case . we observed that while cougar's performance can be quite stable against equally complex learners  it may still be sub-optimal  in the sense that a  cleverer  learner  e.g. a cougar with more policy states  can outperform it. 

figure 1:  bubble  vs cougar: sample trial 
1 	future work 
we do not claim to provide a complete solution for the problem of performance management in heterogeneous web search  but cougar is a promising first step. clearly  we have made many strong assumptions in our models. one future direction will be to relax these assumptions to make our simulations more realistic. another important direction would be to further study performance of the learning algorithm in self-play  as well as against other learners. 
　while we are motivated by the optimal behaviour for search services over document collections  our approach is applicable in more general scenarios involving services that must weigh the cost of their inventory of objects against the expected inventories of their competitors and the anticipated needs of their customers. for example  it would be interesting to apply our ideas to large retail e-commerce sites which must decide what products to stock. 
