 
　　　we address the problem of interpreting time-varying image velocity fields generated by a moving binocular observer viewing a stationary environment under perspective projection to obtain 1-d 
　　　information about the absolute motion of the observer  egomotion  and the absolute depth of environmental surface points. we conduct a numerical study of our algorithm  which involves solving nonlinear systems of equations  for best  random and worst case image velocity error. as well  we investigate how good the initial guess for the nonlinear system of equations has to be. other results include the presence of multiple solutions in time  how the algorithm performs when the underlying assumptions it is based on are violated and the effect of varying the spatial extent of the image points used  of varying the spatial baseline  separation of the left and right cameras  and of varying the temporal extents of the image points used  effectively varying the temporal baselines . as well  we investigate the use of convergent/divergent as opposed to parallel stereo camera setups. 
1 introduction 
　　　in this paper we present an algorithm for computing the motion and structure parameters that describe egomotion and environmental layout for a moving binocular observer viewing a stationary environment this algorithm is an extension of the monocular algorithm presented in  barron ct al 1a ; the two coincide when the left and right image sequences coincide and the temporal baselines at each time are unknown. the binocular motion and structure parameters are simply the monocular motion and structure parameters !/  the depth scaled ovulational observer velocity    the observer's rotational velocity and a  the normalized surface gradient of some planar surface  plus*   the absolute depth of some point on the surface. 
     our algorithm reconstructs observer motion and environmental structure by solving a nonlinear system of equations; each equation relates image velocity at some image point  in either the left or right image sequence to the underlying motion and structure parameters in the left image sequence at the solution point  
　　in general  monocular and binocular reconstruction have been considered two separate problems. monocular reconstruction typically involves solving systems of  nonlinear  equations relating image velocity  and possibly its and order spatial/temporal derivatives  to the underlying motion and structure parameters describing a surface in relative motion with an observer  see  barron 1  . the classical stereo paradigm proposes that 1-d depth be recovered by computing matching primitives in the left and right images of a stereo pair  establish correspondence between the appropriate primitives in the two images and then calculating 1-d depth using simple trigonometry.  barnard and fischler 1    jenkin 1  and  poggio and poggio 1  provide surveys of some of the current stereo techniques. 
     we believe that monocular and binocular vision have a lot in common and can be solved in a unified way. the algorithm presented in this paper is more in the favour of monocular reconstruction algorithms that interpret image velocity fields  for example  longuet-higgins and prazdny 1  or  waxman and ullman 1  then in the favour of the classical stereo paradigm described above. we also interpret image velocities fields; but we do so by sampling the image velocities at many discrete times in both left and right stereo image sequences. 
* alio  canadian instute for advanced research 
1 	perception       waxman and duncan 1  and  waxman and wohn 1  have also proposed that left and right monocular image velocity fields can be analyzed to compute depth. their algorithm involves the computation of relative flow  or binocular difference flow . as such stereo correspondence must still be computed. some researchers  such as  kanatani 1  and  aloimonos and rigoutsos 1   have advocated a correspondence-less approach for monocular reconstruction. 
     only a few researchers have begun to address the use of temporal information  such as temporal derivatives  in reconstruction  subbarao 1a    bandopadhay and aloimonos 1 . we note that others' use of temporal derivative information and our use of timevarying image velocities are approximately equivalent; image velocity fields  at least locally  can be derived from one image velocity and its 1* and/or 1nd spatial and temporal derivatives and vice-versa. indeed  image velocity fields are often used in the derivation of spatial and temporal image velocity information  waxman and wohn 
1 . 
     there has been little or no error analysis in previous monocular reconstruction work. some researchers  such as  waxman and ullman 1    buxton et al 1    aloimonos and rigoutsos 1    snyder 1  and  subbarao 1b  have begun to consider the inherent insensitivity of their algorithms for noisy input. their reports usually consist of a few runs of their algorithms with random noise in the input. 
1 underlying assumptions 
　　　in order to relate a stereo spatio-temporal distribution of image velocity to the motion and structure parameters at some image point  we make 1 assumptions: 
 a  1-d objects in the environment are rigid. the rigidity assumption ensures that the image velocity of an object's point is due entirely to the point's motion with respect to the observer and not due to changes in the object's shape. 
 b  1-d surfaces are planar. this local planarity assumption means curved surfaces can treated as collections of adjacent planes. 
 c  the observer rotates with a constant angular velocity for some small time interval. this is called the fixed axis assumption  webb and aggarwai1 . 
 d  all image velocities used in a particular calculation of motion and structure are measured with respect to the same 1-d planar surface. we call this the same surface assumption. 
 e  the observer's translational velocity is constant with respect to the scene frame of reference. 
these assumptions allow us to design our algorithm so that we do not have to solve point-to-point correspondence either in individual left and right image sequences or between stereo images  1 . 
1 algorithm description 
     in this section  we present a brief description of our algorithm. complete details are given in  barron 1 . 
1 notation 



	barron  jepton  and tsotsos 	1 

　　　in the fifth experiment  we also wary the relative orientation of the left and right cameras by varying 1 to have values  in radians  of -1  -1  -1. -1 1 1 1 and 1. and*  remain the orientation involves a simple rotation about the x1 axis. again  relative worst case image velocity error of 1.1% and a fixed temporal extent of 1 are used. results for the l* motion  table 1  show that both convergent and divergent stereo setups yield smaller output error than for the original parallel setup; the closer the setup becomes to being parallel  the worst the output error. 
     another result not included in this paper for lack of space shows that image velocity error caused by violation of the underlying 
assumptions produces less output error than similarly scaled random and worst case image velocity: it seems that violation of the various assumptions is less important than the accuracy of the input image velocities. 
1 conclusions 
     we have formulated a binocular reconstruction algorithm that uses a stereo spatio-temporal distribution of image velocities in left and right stereo image sequences but does not require point-to-point correspondence be solved in either the individual image sequences or between stereo image pairs. we have demonstrated that the addition of a temporal distribution of image velocity may increase the numerical stability of the solution technique. in addition  it allows us to analyze flow fields that may not be analyzable at one time. as well  increasing spatial extent can improve the algorithm's performance. other results suggest that convergent/divergent stereo setups can give better results than parallel stereo setups and that increasing the spatial baseline can have a similar effect. in all cases  we are effectively increasing the spatio-temporal extent. unfortunately  the greater the spatio-temporal extent the more likely the algorithm's underlying assumptions will be violated in realistic situations. we are able to report the existence of multiple solutions  a fact that is apparently overlooked by most other researchers. our results indicate mat reconstruction techniques are quite sensitive to input image velocity error  1% maximum input error in the image velocities will be very difficult to obtain  but relatively insensitive to initial 
guess error. we believe that this is the main stumbling block that reconstruction algorithms have to overcome before we can consider 
this part of machine vision solved. 
     we are investigating the relationship between error in image velocities and error in the spatio-temporal derivatives of the flow fields  barron et al 1b  and the improvement gained when a least 
squares formulation is used. these and other results will be reported in future papers. 
acknowledgements 
we gratefully acknowledge financial support from the national 
science and engineering research council of canada and the department of computer science at the university of toronto. 
bibliography 
 1  adiv g.  1   determining 1-d motion and structure from optictl flow generated by several moving objects   coins technical report 1  university of massachusetts  april. 
 1  aloimonos j y and i rigoutsos  1   determining the 1-d motion of a rigid planar patch without correspondence  under perspective projection  proc. workshop on motion: representation and analysis  may 1. 
 1  arfken g.  1  mathematical methods for physicists  1  edition  academic press. 
 1  bandopadhay a. and j.y. aloimonos  1   perception of rigid motion from spatio-temporal derivatives of optical flow   tr 1  dept. of computer science  university of rochester  ny  march. 
 1  barnard st. and m.a. fischler 1    computational stereo   acm computing surveys  vol. 1  no. 1  dec.  pp1. 
 1  barron  j.  1   a survey of approaches for determining optic flow  environmental layout and egomotion   rbcv-tr-1  dept of computer science  university of toronto  november. 
 1  barron  j.  1   determination of egomotion and environmental layout from 
noisy time-varying image velocity in monocular and binocular image 
sequences   forthcoming phd thesis  dept of computer science  university of toronto. 
 1  barron  j.l.  a.d. jepson and j.k. tsotsos  1a   determining egomotion and environmental layout from noisy time-varying image velocity in monocular image sequences   submitted for publication. 
1 perception 


