s in particular. in this paper we discuss three current areas of research involving researcher - the generalization of hierarchically structured representations; the use of long-term memory in text processing  specifically in resolving ambiguity; and the tailoring of answers to questions to the level of expertise of different users. 
1 i n t r o d u c t i o n 
   in  lebowitz 1a  we described the first stages of development of researcher  a prototype intelligent information system. researcher is intended to accept natural language input  patent abstracts in particular  and 1  understand the text  1  add the acquired information to a long term memory  generalizing as it docs so  and 1  answer questions from its memory. in this paper  we will present an overview of the new areas that we are using researcher to study. in each of these areas we apply techniques derived from cognitive modelling approaches to language and learning. we are using people as our model to help us achieve better performance on very hard tasks  which  in return  gives us insight into the human processing methods . 
1 g e n e r a l i z i n g h i e r a r c h i e s 
   the patent abstracts that we have been looking at describe the physical structure of complex objects. since such objects are most naturally represented as hierarchies of parts  our learning research has addressed the generalization of hierarchically structured descriptions. exl is part of a typical patent abstract. 
exl - p1; u. s. patent #1; higashiyama nobor et al. 
a magnetic head supporting mechanism equipped with a magnetic head positioning carriage of a interchangeable double side type flexible disc drive apparatus comprising a carriage having a pair of arms which is rotated in detachable to a double side type flexible disc and arms ... 
¡¡*this research was supported in part by the defense advanced research projects agency under contract 
n1-c-1 	many 	people 	have 	contributed 	to 
researcher. in particular  the work on generalizing hierarchies has largely been conducted by kenneth wasserman and the work on question answering by cecile paris  co-ad vised by professor kathleen mckeown. 
   our representation of patent abstracts such as this one includes three classes of information: 1  a parts hierarchy  that illustrates the components of each part; 1  intcrpart relations  physical and functional relations between various components; and 1  properties of the objects. we have concentrated on the parts hierarchy and physical relations  wasserman and lebowitz 1 . we are currently working on classification schemes for functional relations and object properties  such as size and composition . 
   full understanding requires that we integrate new representations with existing knowledge in memory. researcher has as one of its goals the incremental generalization of hierarchical descriptions of objects such as exl by finding similar examples in memory  comparing them with the new example  and abstracting out the similarities. 
   generalizing hierarchical representations presents a number of difficult problems. typical problems are: deciding how the components in the objects being compared correspond; dealing with differing levels of description of objects; and structuring memory so that maximally efficient inheritance of the sort used in semantic networks and frame systems  see  barr et al. 1   can be achieved automatically. in this paper  we will only give examples of how the generalization process works  and refer the reader to  wasserman 1  for more details. 
   we can break generalization into two phases - 1  when a new example is presented  deciding what other objects to compare it to  since researcher is not given examples designed to teach a specific concept   and 1  the comparison process itself  which abstracts out similarities. 
   we will look at the comparison process first  as it is involved in the search process. ex1 and ex1 are two simplified disc drive patents. 
ex1 - a disc drive comprising an enclosure surrounding the disc drive  said disc drive including a spinning assembly  a disc and a readwrite head  said spinning assembly including a 
spindle connected to a motor  said enclosure comprising a cover on top of a support member. 
ex1 - a disc drive comprising an enclosure surrounding the disc drive  said disc drive including a spinning assembly  a magnetic assembly and a readwrite head  said spinning assembly including a spindle connected to a motor  said magnetic assembly comprising a disc  said enclosure comprising a cover on top of a support member. 
   as human understanders  we can easily see that patents ex1 and ex1 describe similar objects. however  to begin to generalize the similarities  researcher must decide how the parts of the representations correspond -- for example  that the enclosure in ex1 corresponds to the enclosure in ex1  and not to the spinning assembly  the magnetic assembly or the readwrite head  which are all parts of the disc drive in ex1. here this is relatively easy  as the enclosures are identical  but we must be able to identify less perfect matches. researcher does this with a numerical scoring algorithm  similar to the one in  winston 1 . 
   figure 1 shows researcher's generalization of these objects  taken from  wasserman 1 . when researcher makes correspondences of the sort mentioned above  one problem arises in dealing with the discs. the disc in ex1 is described as part of the disc drive  while in ex1 the disc is part of a magnetic assembly which is part of the disc drive. to make the representations match  researcher must insert a  null'' part  which may or may not actually exist in any given object. the two input representations are stored as variants of the generalized object  recording only how they differ from it  basically  in this case  how the null object is resolved; in real examples there would usually be more differences . 

   even with just two hierarchical descriptions to compare  the matching process involves a number of problems in determining how the components of the hierarchies correspond. one such problem is the need to insert levels in a hierarchy to obtain a good match  as described above.  while the insertion of a null level by itself decreases the goodness of a match  it may increase the value of lower level matches.  the problem is that there are an exponentially large number of places where null levels can be inserted  each requiring a complex recursive match to test. we have used researcher to experiment with a variety of different algorithms for deciding where null levels should be inserted for optimal matching  concentrating on ones that only try the most obvious places near the top of the hierarchy. 
   since the examples given researcher are not expressly designed for learning specific concepts  as they would be for a system being taught concepts   the program must decide which examples to compare for the purpose of generalization. this is done using a generalization-based memory of the sort in  lebowitz 1b . a hierarchy of concepts is created in memory  a hierarchy of hierarchies  in this case  that organizes specific examples. 
   in using its generalization-based memory  researcher takes each new example and searches down the tree for the example or generalized concept most similar to it. this process involves matching generalized concept.-  with the new example in much the same way as ex1 and ex1 were matched. we begin by matching the new example with 
m. lebowitz 1 
each of the children of the generalization tree's root researcher selects the best match and looks at that node's children. as long as one of the children produces a better match than the parent node  researcher continues down the tree. eventually  it either reaches a leaf  an instance already in memory  or a maximally good generalization  i.e.  all of the subordinate nodes contain factors that decrease the quality of the match . 
   once the most similar previous example or existing generalization is found  researcher  factors out  similarities between these representations  and  if need be  creates a new generalization node. in any case  the new example is stored by recording how it differs from the generalizations in memory. this is an optimally spaceefficient method of storage  which also captures significant generalizations about the objects in the domain. 
   the current implementation of researcher's generalization scheme works quite well on modest-sized examples. in addition to disc drive patents  a modified version of the program  corporate-researcher  wasserman 1   has been tested on hierarchical descriptions of corporate organizations. 
1 t e x t p r o c e s s i n g u s i n g m e m o r y 
	since 	intelligent 	information 	systems 	such 	as 
researcher have available many examples in memory  it seems natural to make use of this information for text processing  beyond identifying lexical items . patent abstracts  despite being written in legalese are  like the rest of natural language  quite ambiguous. we can use memory to help resolve many ambiguities. 
   we feel that the best way to use detailed memory information during text understanding in the context of current systems is to identify specific tasks where a piece of information from memory will be useful. more general methods  such as using memory to determine the interesting aspects of a text to focus processing  we leave for the future. we have identified a set of  questions  that arise during text processing that can most easily be answered  and often can only be answered  by accessing long-term memory. 
   it is important to keep in mind that we are proposing using memory for understanding  as opposed to general semantic information about words or concepts. while such general information is crucial for our conceptually-based understanding methods  in order to resolve many ambiguities it will be necessary to look at very detailed information in memory -- in our case  how the objects described in patent abstracts are constructed and how their pieces relate to each other. the use of the information base also reduces the need to initially hand-code information for researcher. 
   ex1 illustrates two kinds of ambiguities that arise in patent abstracts. 
ex1 - a disc head supporting a spindle made of magnetic material. 
the first ambiguity in ex1 involves  disc head . 
although not syntactically ambiguous  an understanding system such as researcher must determine the conceptual relationship between the nouns. the phrase  made of magnetic material  is ambiguous in that we do 1 m. lebowitz not know whether it refers to the head or the spindle both of these ambiguities can only be resolved by looking at memory. in fact  it would be easy to construct scenarios where different states of memory would cause this example to be understood differently  e.g.  whether we knew about. magnetic heads or magnetic spindles . 
   researcher makes use of relatively simple  but. heavily memory-based  techniques for handling ambiguities of the sort in ex1. its conceptual analysis type text processing algorithm  described in  lebowitz 1a; lebowitz 1    involves identifying object descriptions  usually noun groups  and connecting them with various relational words  usually prepositions -- patent abstracts are quite short of verbs  which indicate the various physical  functional and assemblycomponent relations mentioned in section 1 within this processing algorithm  we have identified places where ambiguity can be identified and memory queried for resolution. memory is asked which of two possible physical constructions is more likely or what relation is likely to occur between two objects. questions in both classes are answered by looking for examples of the possible configurations that already exist in memory. 
   figure 1 lists some of the questions that researcher can currently ask memory for purposes of disambiguation. they primarily involve prepositional phrase attachment and noun groups with multiple nouns.* our analyses of these ambiguities shares much with the linguistic work of  levi 1  and the application of this work to ai in  finin 1 . however  our method of resolving the ambiguities - the use of a dynamic  long-term memory - is rather different. 
form: object-word 1 obiect-word1 example: an actuator housing ... 
question: what is the relation between object-word 1 and object-word1  
form: modifier object-word 1 object-word1 
example: a metal drive cover ... 
question: does the modifier better apply to object-word 1 or object-word1  
form: object-word 1 relation-word 1 object-word1 relation-word1 object-word1 
example: a coating; on a disc touching a spindle ... 
question: does relation-word1 connect object-word1 with object-word 1 or object-word1  
	figure 1: 	some disambiguation questions 
   the search for possible examples that answer a given question is a relatively simple one. researcher uses its dynamically created device hierarchies to look for possible constructions and relations. it begins its search with general object descriptions and searches through more specific descriptions until a relevant example is found. if several possible constructions  or relations  are found  the one associated with the most general description is used  as that represents researcher's most widely applicable information. researcher's memory search disambiguation process is described in more detail in  lebowitz 1 . 
¡¡*the word types used in figure 1 are functional  rather than syntactic. however  object words are usually nouns and relation words are usually prepositions  although not always in either case. 
   our disambiguation methodology bears resemblance to that of  small 1  and  hirst 1   except  crucially  it relies on information from a detailed  dynamic memory. our algorithm does have the side-effect of making understanding subjective  in the sense of  abelson 1; carbonell 1   since new examples will be interpreted to correspond to old ones  but we view this as inevitable if we wish to achieve robust understanding. 
   as an illustration of researcher's use of memory in text processing  we will show how it processes part of a real patent abstract  ex1  seen earlier. 
   although it may not be immediately obvious  the beginning of exl is extremely ambiguous.  it may not be obvious because people are so good at resolving ambiguity.  the internal structures of the various noun phrases and the determination of what is a part of what could all be resolved in several ways. without any information in memory  researcher would have to rely on general heuristics which might or might not work  and would  in any case  be quite ad hoc. instead  we will provide researcher with a few  admittedly somewhat artificial  examples that it can use specifically  we will give it the following descriptions: 
an apparatus with a support mechanism. 
an interchangeable double sided floppy disc within a drive which has a magnetic head. 
   having given researcher examples of support mechanisms and double sided floppy disc drives  we let it read exl  figure 1 . 
   a number of aspects of researcher's text processing are shown in figure 1. we will focus on its use of memory. each memory access is indicated by           the first such use occurs when processing the initial noun group   a magnetic head supporting mechanism . researcher uses a.  save and skip  strategy for noun groups - it saves words in a short term memory stack until the head noun is reached. then it works backwards processing the stacked words. here  it easily sets up two relations between the head and the mechanism  both from the word  supporting   indicating that the mechanism supports and is connected to the head. 
   next researcher must process  magnetic . it is syntactically ambiguous here whether the modifier applies to the head or the mechanism.  to see the other case  consider   a complicated head supporting mechanism .  so  researcher searches its memory for examples of magnetic heads or magnetic mechanisms. it finds the former  and appropriately resolves the ambiguity. 
   the processing of the next part of ex1   equipped with a magnetic head positioning carriage  is relatively sedate.  magnetic  is again ambiguous  but this time refers to an object already described in the patent. memory again becomes important in processing  a interchangeable double side type flexible disc drive apparatus . 
   the first problem arises in determining the relation between the drive and the apparatus  remember  noun groups are processed  in effect  backwards . here  since researcher has no examples in memory  it uses a 


	figure 1: 	researcher using memory 
heuristic to assume that since  apparatus  describes a rather vague assembly  the drive is probably a part of it. when  disc  is reached  the problem is more complex  since researcher must determine both whether the disc is related to the drive or the apparatus  and what the relation is. here  as always  memory is used. since researcher does not have an example of a relation between a disc and an apparatus  but knows of an example of a disc being 
m. lebowitz 1 
inside a drive  it assumes that the disc is inside the drive here. 
	when 	the 	modifiers  	 flexible   	 double 	side  
 researcher has a phrasal lexicon  and  interchangeable  are processed  the program must attach them to either the apparatus or the disc.  the drive is ruled out by syntactic considerations.  the processing is similar to the first noun group  using memory to resolve the conflict. note that the disambiguation search has a semantic basis  so that the 
 floppy  disc in memory resolves the ambiguity over 
 flexible . 
   finally  researched must decide whether the apparatus has as a part the carriage or the mechanism.  the  part of  relation is indicated by the word  of .  once again  the routine is the same - search memory for examples and find one that resolves the ambiguity in favor of the mechanism. different examples in memory would lead to a different resolution. 
   we have much left to do in our integration of text processing and memory. however  we feel our general approach is quite promising  as our work in building up memory has a positive synergistic effect on text processing robustness. the identification of specific questions to ask memory seems to be much more effective than looking for more general applications of memory to understanding. 
1 q / a i n r e s e a r c h e r 
once a substantial knowledge base has been built up by 
researcher  it is important that it can be queried intelligently. in  lebowitz 1a; paris 1  we described an early question answering module. recently  our work has concentrated on how researcher might tailor its answers for individual users. there are many elements to such tailoring  the goal of the user  for example  but here we will concentrate on just one factor - the user's expertise. we have tried to determine the sorts of basic answering strategies that would be appropriate for expert and naive users of the system* eventually  we will also look at how expertise affects other levels of processing  such as word choice  as well as other factors on answering. 
   in order to get an idea about the kinds of strategies that might be appropriate for various users  we have looked at texts that describe objects that are aimed at readers with different levels of expertise - several adult and junior encyclopedias. as described fully in  paris 1   the strategies used in the adult and junior encyclopedias are quite different -- the adult encyclopedias  presumably aimed at relative experts  tend to describe the part structure of objects  while the junior encyclopedias describe the processes that take place in the device. ex1 and ex1 show this distinction for descriptions of telephones. 
ex1 - the hand-sets introduced in 1 consist of a receiver and a transmitter in a single housing available in black or colored plastic. the transmitter diaphragm is clamped rigidly at its edges to improve the high frequency response. the diaphragm is coupled to a doubly resonant system - a cavity and an air chamber - which 
¡¡* actually  user expertise falls into two areas - familiarity with the system and familiarity with the domain. we are concerned here with the latter. 

1 m. lebowitz 
broadens the response...  collier's encyclopedia  
1  
   as we can see  ex1  taken from an adult encyclopedia  describes a telephone by presenting its parts. the description continues in this vein. it is using a construction quite similar to the constituency schema that mckeown used in her question answering work  mckeown 1   providing an almost tree-like description of the parts of the object. this is in contrast with a description aimed at younger readers  ex1. 
ex1 - when one speaks into the transmitter of a modern telephone  these sound waves strike against an aluminum disk or diaphragm and cause it to vibrate back and forth in just the same way the molecules of air are vibrating... 
 britannica junior  1  
   here the description is process-oriented. it traces the process of transmitting sound  introducing part descriptions only when necessary. this is clearly a different presentation strategy  one that our study of texts indicates is much more widely used in texts aimed at less experienced readers. we feel that a process-oriented answer would be appropriate for researcher to use when dealing with a novice user not likely to know what various parts are used for. 
   we are currently in the early stages of implementing these two different strategies for describing the same object. we have implemented simple techniques for producing ''expert  type responses using mckeown's constituency schema  although our low-level generation  even here  is quite basic . in addition to looking at the different generation strategies  we are also studying ways to determine the expertise of a user as well as mixed strategies that make use of elements of each generation technique. 
	1 	c o n c l u s i o n 
   we have described here three areas of investigation in the study of intelligent information systems focused around the program researchfer the generalization of hierarchical representations allows the system to learn about a wide range of complex objects and build up a rich memory. this memory is used extensively in textprocessing  primarily for disambiguation  to achieve robust performance. finally  awareness of the expertise level of a user will allow researcher to tailor it answers to each user. the sum of these three related areas of investigation should lead towards the development of powerful intelligent information systems. 
 carbonell 1  carbonell  j. g. subjective 
understanding- computer models of belief systems. umi research press  ann arbor  michigan  1. 
 finin 1  finin  t. w. the interpretation of nominal compounds  in discourse. technical report ms-cis-1  moore school of engineering  university of pennsylvania  1. 
 hirst 1  hirst  g. semantic interpretation against ambiguity. ph.d. thesis  department of computer science  brown university  1. 
 lebowitz 1a  lebowitz  m; researcher: an overview. proceedings of the third national conference on artificial intelligence  washington  dc  1  pp. 1 - 1. 
 lebowitz 1b  lebowitz  m. concept learning in a rich input domain. proceedings of the 1 international machine learning workshop  champaign-urbana  illinois  1  pp. 1 - 1. to appear in machine learning 1. 
 lebowitz 1  lebowitz  m. using memory in text understanding. proceedings of ecai-1  pisa  italy  1. 
 levi 1  levi  j. n. the syntax and semantics of complex nominals. mcgraw hill  new york  1. 
  mckeown 1  mckeown  k. r. generating natural language text in response to questions about database structure. ph.d. thesis  university of pennsylvania  1.  paris 1  paris  c. l. determining the level of expertise  
proceedings of the first annual workshop on theoretical 
issues in conceptual information processing  atlanta  georgia  1. 
 paris 1  paris  c. l. description strategies for naive and expert users. proceedings of the 1rd annual meeting of the association for computational linguistics  chicago  1. 
 small 1  small  s. word expert parsing: a theory of distributed word-based natural language understanding. 
technical report tr-1  university of maryland  department of computer science  1. 
 wasserman 1  wasserman  k. unifying representation and generalization: understanding hierarchically structured objects. ph.d. thesis  columbia university department of computer science  1. 
{wasserman and lebowitz 1  wasserman  k. and 
lebowitz  m.  representing complex physical objects.  cognition and brain theory 1  1  1   1 - 1. 
 winston 1  winston  p. h.  learning and reasoning by analogy.'' communications of the acm 1  1   1 - 1. 

r e f e r e n c e s 
 abelson 1  abelson  r. p. the structure of belief systems. in r. c. schank and k. colby  ed.  computer models of thought and language  w. h. freeman co.  san francisco  1. 
 barr et al. 1  barr  a.  cohen  p. r. and feigenbaum  
e. a.  eds. the handbook of artificial intelligence  
volumes 1 - s. william kaufmann  inc.  los altos  california  1. 
