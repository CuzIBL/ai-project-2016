 
we describe an interactive system which supports the exploration of arguments generated from bayesian networks. in particular  we consider key features which support interactive behaviour:  1  an attentional mechanism which updates the activation of concepts as the interaction progresses;  1  a set of exploratory responses; and  1  a set of probabilistic patterns and an argument grammar which support the generation of natural language arguments from bayesian networks. a preliminary evaluation assesses the effect of our exploratory responses on users' beliefs. 
1 introduction 
an ideal interactive argumentation system would allow a user to respond to an argument with a full counterargument  and it would allow the argumentation process to go on indefinitely  producing a series of arguments and counterarguments. in this paper  we describe an interactive version of our argumentation system nag  nice argument generator   which enables a user to explore the impact of different beliefs and propositions on arguments generated from bayesian networks  bns . such an exploratory capability constitutes a significant step towards allowing a user to interact freely with an argumentation system. 
　nag interacts with a user through a web interface. the interaction starts when nag presents to the user background information for a particular scenario and a hyper-text rendering of the argument generated by nag in support of a goal proposition. nag attempts to generate arguments that are nice  meaning that they are both normatively correct and persuasive for the target audience. to this effect it consults two models during argument generation: a normative model  which contains our best understanding of the domain of discourse  and a revisable model of the user's beliefs. these models are not necessarily synchronized  since the user and nag may have different beliefs and may apply different inference patterns. thus  operationally  a nice argument is one that achieves a desired degree of belief in the goal in each of these models. 
　after presenting an argument  nag allows the user to perform the following operations:  1  select a new goal proposition;  1  ask nag to argue for or against a proposition in the current argument;  1  ask nag to include or exclude a proposition;  1  ask nag a what about question  i.e.  to consider the effect of a proposition on the argument; and  1  ask nag a what  /question  i.e.  to consider a hypothetical change in the belief in a proposition. each response results in the generation of a  revised  argument which incorporates the user's request. the user can either retain this argument or revert to the previous situation. these operations enable the user to examine different aspects of an argument in piece-meal fashion. the argument generation process is described in  zukerman et al.  1; mcconachy et ah  1 . the focus of this paper is on the interactive capabilities of the system. in particular  we consider key features which support these capabilities:  1  an attentional mechanism which updates the activation of concepts as the interaction with the user progresses 
 section 1 ;  1  a set of operations for exploring the argument  section 1 ; and  1  a set of probabilistic patterns and an accompanying a rgument grammar  which extend patterns such as toulmin's  1  to enable the generation of natural language arguments from bns  section 1 . these features provide a foundation for enabling users to argue with nag. 
　in the next section  we show a sample interaction with nag. in section 1  we describe the argument generation process. we then consider nag's knowledge representation and attentional mechanisms  followed by its exploratory operations and argumentation patterns. finally  we discuss the results of a preliminary evaluation  review related research and present concluding remarks. 
1 sample interaction 
in this section  we describe an actual interaction with a user. our domain is a fictitious murder scenario  which was chosen to minimize the influence of a user's pre-existing beliefs. the interaction started when the user was given the following preamble  which contains all the available observables . scratchy  a notorious spy from vulcan  was found murdered in his bedroom  which is in the second storey of his house. indentations were found on the ground right outside 
scratchy's window  and they were observed to be circular. in addition  one set of footprints was found outside scratchy's window  but the bushes were undisturbed. 
itchy and scratchy were long-term enemies  and itchy's fingerprints were found on the murder weapon  a gun discovered at the scene and registered to itchy . 
itchy  who is the head of the ins  has a ladder with oblong supports  which he was planning to use to paint his house. poochie  the town 's mayor  has a cylindrically-supported ladder which is available only to him. 
　
1 	uncertainty and probabilistic reasoning 
　
　the user was then asked for his degree of belief in the goal proposition  itchy did not kill scratchy  and in itchy's means  opportunity and motive to kill scratchy  and also for his confidence in these judgments. the user indicated that it is rather likely that itchy had a motive  quite likely that he had the means  and less likely than not that he had the opportunity to kill scratchy or that he killed scratchy.1 nag then generated an initial argument in support of the goal  taking into account the user's beliefs. notice however  that the presented degrees of belief are nag's. 
very probable hatred between itchy and scratchy imply a very probable motive to kill scratchy 
itchy's firing of the gun and itchy's gun being used to kill scratchy imply a means to murder scratchy. 
circular indentations outside scratchy's window  cylindrical supports to poochie's ladder and availability of poochie's ladder only to poochie imply poochie almost certainly was outside scratchy's window  which together with itchy's ladder almost certainly not being outside scratchy's window and a single person being outside scratchy's window implies itchy very probably not being outside scratchy's window. 
the circular indentations outside scratchy's window imply scratchy very probably being shot from outside the window. 
this together with itchy very probably not being outside 
scratchy's window imply a very probable lack of opportunity to murder scratchy 
even though itchy very probably had a motive to kill scratchy and itchy had the means to murder scratchy  the very probable lack of opportunity to murder scratchy implies itchy's very probable innocence. 
　after this argument  the user retained his belief in itchy's motive to kill scratchy  but reduced his belief in itchy's means to kill scratchy to rather likely. he also reduced his belief in itchy's opportunity to murder scratchy and itchy's guilt to quite unlikely  which are closer to nag's normative beliefs than the user's initial beliefs after the preamble. 
　the exploratory interaction started with a request to exclude the proposition itchy fired the gun  which resulted in a stronger argument for itchy's innocence  where the paragraph regarding itchy's means to murder scratchy was omitted  and the concluding paragraph was replaced as follows. even though itchy very probably had a motive to kill scratchy and itchy could have had the means to murder scratchy the very probable lack of opportunity to murder scratchy implies itchy's almost certain innocence. 
　the user returned to the original argument  without retaining the exclusion   and asked nag to support the proposition only one person was outside scratchy's window. nag generated the following sub-argument. 
a single set of footprints outside scratchy 's window implies a single person being outside scratchy's window. 
　the user then requested that this sub-argument be included in the main argument  and asked a what if question which explored the effect of a belief of even chance in the proposition itchy was outside scratchy's window. this resulted in an argument which yielded a weak belief in the goal. 
itchy and scratchy very probably hated each other; therefore  itchy very probably had a motive to kill scratchy 

　　1 the descriptive names for the probabilities are based on those described in  elsaesser  1 . 
itchy fired the gun and itchy's gun was used to kill scratchy; hence  itchy had the means to murder scratchy circular indentations were found outside scratchy's window; hence  scratchy very probably was shot from outside the window. 
if itchy maybe was outside scratchy's window and scratchy very probably was shot from outside the window  itchy possibly had no opportunity to murder scratchy 
despite a very probable motive to kill scratchy and the means to murder scratchy  the possible lack of opportunity to murder scratchy implies itchy's possible innocence. 
　after the exploratory interaction  the user was asked posttest questions regarding his belief in the goal proposition and in itchy's means  opportunity and motive for killing scratchy. the user did not change his beliefs as a result of the interaction  but three of these beliefs were already close to nag's . 
1 argumentation process 
figure 1 shows the modules of nag. the strategist  which receives as input a goal proposition  drives the argumentation process and produces an argument in support of this goal.1 this process is influenced by the context  which changes at each turn in the interaction due to a user's request and the argument nag generates to address this request. 
　the argument generation process is composed of a sequence of generation-analysis cycles  zukerman et al.  1 . the strategist first invokes the attentional mechanism  section 1  to activate propositions which are related to the items that are currently salient  including the goal . these propositions form an initial argument graph - a network with nodes that represent propositions and links that represent the inferences that connect these propositions. this argument graph is passed to the generator  which consults the user model and the normative model to add information to the graph. the inferences and propositions that are compatible in both models and are related to the propositions in the current argument graph are incorporated into the graph. the resultant argument graph is then passed by the strategist to the analyzer in order to evaluate its niceness. 
　to assess the persuasive power of an argument represented by an argument graph  the analyzer determines its effect on the belief in the goal proposition in the user model  section 1 . the normative correctness of the argument is assessed by determining its effect on the belief in the goal in the normative model. if the analyzer reports that the argument graph is not nice enough  e.g.  the belief in the goal is not high enough in one or both of the models  the argument graph is returned to the strategist  and another generationanalysis cycle is performed: the strategist re-activates the attentional mechanism to expand the reasoning context  followed by a re-activation of the generator and then the analyzer. this process iterates until a nice argument graph is built  or nag is unable to continue  e.g.  because it failed to find further evidence. in this case  nag performs the following actions in turn. first  it tries to enhance the argument by including propositions that are believed only in the normative model. if the resulting argument achieves the intended belief 
　

user argument/inquiry/goal proposition 
figure 1: system architecture. 
　
in the goal in the normative model  it is retained. however  the added propositions are not immediately incorporated into the user model; they will be incorporated if the user accepts them implicitly  by failing to question their inclusion in the argument . if this argument fails  nag attempts to argue for the negation of the goal. to this effect  it first tries a nice argument  and then an argument which includes additional normative propositions. finally  if this fails too  nag selects the strongest argument it could generate  either for the goal or its negation. these actions were chosen  instead of simply giving up  based on suggestions made by users who tried a previous version of nag. note that failure can still happen if the user's requirements over-constrain nag  e.g.  the user demands the inclusion of a particular proposition in an argument for a goal that is not related to this proposition  section 1 . 
　once an argument is generated  the argument graph is passed to the presenter  which selects an argumentation strategy  e.g.  premise-to-goal or goal-to-premise  and removes  easily inferred  propositions from the argument  mcconachy et al.  1 . after each removal  the presenter activates the analyzer to check whether the belief in the goal proposition has not been significantly altered  and the attentional mechanism to determine whether the argument can still be followed by the user. after the presenter determines that no more propositions can be removed from the argument  it extracts bayesian reasoning patterns from the argument graph  and passes them to the interface  which uses the argument grammar to generate a textual version of the argument  and presents it in hyper-text form  section 1 . 
1 knowledge representation and attentional mechanism 
both the user model and the normative model rely on a bn as their primary representational tool  each model using a different bn. we have chosen bns because of their ability to represent normatively correct reasoning under uncertainty. during argument generation  the generator may draw upon additional knowledge bases  such as rule-based systems  to add information to the bns as needed. during argument analysis  the analyzer performs bn propagation on the portions of the normative and user models which correspond to the argument graph and are connected to the goal. 
　　1 it came late to our attention that the behaviour of our propagation algorithm departs from that of  for example  the bayesian in order to simplify the argument generation process and to model more accurately a user's cognitive abilities  we apply the attentional mechanism  which focuses upon the portion of the bn in each model that may be relevant to the current argument.1 hence  each of the user model and the normative model at any given time contains a single bayesian subnetwork that is in focus. the structural intersection of these subnetworks forms the argument graph. for example  consider a situation where nag's normative model believes that poochie's ladder was outside scratchy's window  pi  and that it is available only to poochie  p1 . in addition  the normative model has an inference pattern whereby these propositions have implications about poochie being outside scratchy's window  p1 . now  let us assume that the user model shares the normative model's belief in pi  is uncertain about p1  and also believes that poochie was seen at the local toy store on the night of the murder  p1 . further  the user model has an inference pattern whereby p1  p1 and p1 affect the belief in p1. in this example  p1 and p1 and their link to p1 are included in the argument graph  but p1 is excluded  since it does not appear in the normative model. when analyzing the argument graph  propagation is done twice  once for the bayesian subnetwork in the normative model and once for that in the user model  in our example  the probability calculations for the user model are marginalized over p1 to match the inference pattern in the normative model . thus  we assess the niceness of the same argument with respect to both the user model and the normative model  thereby determining its persuasiveness and normative correctness respectively. in this example  nag's argument for p1 will achieve a strong belief in this proposition in the normative model  but only a middling belief in the user model. 
　a plausible model of attentional focus requires nag to follow associative links that do not necessarily represent evidential or causal relationships. we incorporate such links into our user and normative models by building one hierarchical 
propagation algorithm in  pearl  1   in particular in its treatment of loops. this departure does not seem to affect nag's argumentative behaviour in the examples run to date. nonetheless  we shall implement the standard propagation procedure in the near future. 
　　1 as shown in  zukerman et al.  1   the attentional mechanism can greatly reduce argument generation times. for instance  generation times were halved for our sample bns  which contained between 1 and 1 nodes; the bns for the example discussed in this paper contain 1 nodes. 
　
1 	uncertainty and probabilistic reasoning 
　
semantic 
network 
bayesian 
network 
propositions  e.g.   itchy was outside scratchy's window  
figure 1: semantic network on top of a bayesian network. 
semantic network  sn  on top of the user-model bn  and one on top of the normative-model bn  figure 1 . when performing attentional modeling  links in both the sn and the bn are followed. however  the resulting argument graph contains only propositions and links from the bns. 
　to begin attentional simulation  nag obtains an initial set of salient concepts and propositions from the context of the argument  in our example  the initial context is the preamble describing the murder scenario . as the argument or interaction progresses  new propositions become salient. for example  if the user asks nag to include a proposition in an argument  this proposition and the concepts in it will become salient. we use activation with decay  anderson  1   spreading from the  clamped  salient objects to determine the focus of attention. this process passes activation through the nodes in the sn and bn in the user model and in the normative model  each node being activated to the degree implied by the activation levels of its neighbours  the strength of association with those neighbours  and its immediately prior activation level  reduced by a time-decay factor . this iterative process ceases when an activation cycle fails to activate a new node. any nodes in the sn or bn which achieve a threshold activation level at the end of this process are brought into the span of attention. 
　the context is dynamic  changing with each new request and resulting argument. in addition  the context for the user model may differ from that for the normative model  since nag's experiences and the user's differ. nag reasons about the argument and presents it  while the user reads it and reasons about it. after each request  the context for the normative model is composed of the proposition in this request and the propositions and concepts active upon completion of the reasoning process for the last argument. in addition to the proposition in the user's request  the context for the user model contains the propositions and concepts which were activated while the system simulated argument presentation  which nag does in order to select a presentation order for its argument  mcconachy et al.  1 . 
1 interacting with nag 
the interaction with the user influences nag's argument generation process by changing the attentional focus and the beliefs in nag's normative and user models. since nag has limited reasoning capacity  bayesian propagation is restricted to the portion of the argument graph that is connected to the goal and the kbs are not exhaustively searched   the beliefs in nag's user model and normative model may be affected by the additional bayesian updating performed when addressing a user's request. also  as indicated above  a request involving a particular proposition makes that proposition salient  which together with the argument generated to address this request modifies the context. as a result  when the user chooses to cancel his or her last request and revert to the previous argument  the argument generated by nag may be slightly different from the previous argument. 
　nag supports the following exploratory operations. selecting a new goal this operation allows the user to request nag to argue for any proposition known to it. currently  the available propositions  and their negations   i.e.  those in the normative and user models  are presented in a pull-down list. clearly  this requires the interface to know in advance all the propositions accessible to the argumentation process  and so does not scale up. nonetheless  this approach was adopted because it enables us to test exploratory interactions without introducing the complications attendant to accepting new goals presented in natural language. 
　as stated above  a newly selected goal is added to the reasoning context and passed to the strategist  which activates the generation-analysis cycles described in section 1. asking nag to argue for or against a proposition in the argument. here too the selected proposition is added to the reasoning context  and the generation-analysis process is activated to produce a sub-argument for or against this proposition. the presumption is that a new sub-argument for this proposition should be stronger than the current sub-argument. the user may then ask nag to incorporate the resultant subargument into the main argument or may retain the previous argument  possibly in a modified form . 
including/excluding a proposition. as when selecting a new goal  a proposition to be included in the argument is selected from the pull-down list. the inclusion of a proposition cancels any previous exclusion of this proposition or its negation. the proposition is added to the reasoning context  and the generation-analysis process is activated in an attempt to produce a revised argument which includes it. the resultant argument may differ substantially from the last argument  in particular if the included proposition has a detrimental effect on the goal  thereby requiring the introduction of additional sub-arguments to maintain the desired level of belief in the goal. if  despite the inclusion of the selected proposition in the context  nag generates a nice argument without this proposition  then nag activates additional generationanalysis cycles  currently two  to attempt to link this proposition to the argument. if the proposition still cannot be connected  nag reports this failure. 
　a proposition to be excluded is selected from the current argument. the exclusion of a proposition drops from consideration both the proposition itself and its negation  and cancels any previous inclusion of this proposition or its negation. nag then tries to construct an argument without the excluded proposition; that is  the proposition is removed from the bns  as are those of its ancestors that have no other connections to the argument . the children of the excluded proposition may then become premises  in which case uninformed priors for them are used. if the children have other parents  their conditional probabilities are marginalized over the excluded proposition  so that bayesian propagation can proceed without it. although any probabilistic impact of excluded propositions 
	zukerman et al 	1 
　
figure 1: sample bayesian network. 
is avoided  exclusion has the opposite effect on attentional processing; asking someone to not think of unicorns has the opposite effect. thus  excluded propositions are added to the reasoning context  which may induce nag to incorporate related propositions in the argument 
   as usual  the user may retain the resulting argument  or revert to the previous  possibly modified  argument. considering the effect of a proposition  what about . for this operation nag returns only the reasoning path which connects the selected proposition to the goal  rather than returning the entire argument for the goal . this allows the user to inspect the effect of an isolated factor on the goal. to perform this operation  nag adds the selected proposition to the reasoning context  and activates the generation-analysis process. the subgraph that connects the selected proposition to the goal is then returned for presentation. the user can choose to revert to the previous  possibly modified  argument  or to include the examined proposition in the argument. considering a hypothetical change in the belief in a proposition  what if . in this operation nag changes the degree of belief in the selected proposition and converts the proposition into a premise. these changes  which take place in both the user model and the normative model  are temporary  since the user is explicitly requesting hypothetical reasoning. after producing a revised argument in light of the hypothetical belief  nag reinstates the original beliefs in both the user model and the normative model and re-generates the previous argument. as usual  the change in context may result in the previous argument being modified. undoing changes. the user may undo the inclusion or exclusion of propositions and the incorporation of sub-arguments for or against a proposition. each undo operation brings a proposition into focus. after the user completes his or her undoing actions  the generation-analysis process is reactivated  and nag presents the resulting argument. 
1 	argumentation patterns and grammar 
the generation of natural language output from a bn requires the identification of probabilistic patterns which yield specific argumentation patterns. the patterns we have considered so far are: explain-away  pearl  1   neutralize  contradict  cause  evidence and imply  which is a generic pattern that is used when the others are not applicable . when the interface receives an ordered list of patterns  it activates the corresponding productions in our argument grammar to generate natural language output. the formulas presented below identify probabilistic patterns with reference to the simple bn in figure 1  a and b may be groups of nodes . explain away. reflects a situation where there are several potential explanations for a proposition  and finding out that one of these explanations is likely reduces the probability of the others. its probabilistic requirements are: 
and 	which means that a 
and b are potential explanations for c; and 
and 	which 
means that given c  a explains away b and vice versa. fi-
nally  we require 	threshold and 
threshold  where threshold is a probability indicative of an 
.strength   direction  ; 
antecedents ctypea     
antecedent 	  nominal  imply strength   direction  typec   consequent 	 typec  . 
given that the grass is wet  the fact that the sprinklers were on last night implies that it probably did not rain. 
strength   direction   cause   ; 
although itchy's fingerprints were found on the gun  itchy's a l i b i implies his innocence. figure 1: sample productions in the argument grammar. 
unlikely event; this ensures that the explaining-away effect has a useful impact on the argument 
neutralize. reflects a situation where some of the antecedents of an implication undermine the effect of others on the consequent  and the posterior belief in the consequent remains largely unchanged from its prior. that is  b neutralizes 
a if  
contradict similar to neutralize  but one of the antecedents wins. that is   
imply. reflects a situation where the current beliefs in the antecedents increase the belief in the consequent. that is  p c ab    p c . 
cause. like imply  but the relations have a  cause  tag. evidence. like imply  but the relations run in the opposite direction to the links in the bn. 
　figure 1 illustrates two productions in our argument grammar with reference to figure 1; the words in sans serif are invocations of production rules. explain-away takes as input two lists of propositions  and  and one singleton  which is the pivot on which the explanation hinges. contradict-short takes two lists of antecedents  against the consequents and  in favour   and one list of consequents  this production is used when contains only one or two propositions. the direction  and cause  parameters of the productions are obtained from tags in the bns. 
for example  and 'forward' indicate a 
causal relation  while direction = back ward' indicates an evidential relation. the strength  parameter is obtained from the normative-model bn  since nag states its own degrees of belief. 
　the argument grammar is feature-based. the productions in figure 1 illustrate the type feature  which indicates whether a proposition should be realized in sentential or nominal form. for instance  the  despite*' realization of although requires a nominal continuation  e.g.   despite itchy's hatred for scratchy    while as shown in figure 1  the  although  realization requires a sentential continuation. our grammar assumes that each proposition has at least one realization  nominal or sentential ; it can produce a nominal realization from a sentential one and vice versa by performing simple manipulations. to expedite the interaction  currently each node in the bns has a hand-generated sentential or nominal realization. these realizations may be replaced by appropriate calls to grammars such as surge  elhadad and robin  1 . 
　
1 	uncertainty and probabilistic reasoning 
　
1 evaluation 
we performed a preliminary evaluation of the interactive features of nag by testing the system with 1 current and former members of our department  using the murder scenario. the subjects reported their degrees of belief in four propositions and their confidence in their judgments immediately after reading the preamble  then after nag's initial argument for itchy's innocence  and after interacting with nag using our exploratory operations. the propositions considered pertained to itchy's guilt and his means  motive and opportunity to kill scratchy. the most substantial change in belief after interacting with nag concerned itchy's guilt: 1 people reduced their belief in itchy's guilt  while 1 people retained their belief that itchy was probably innocent and 1 people remained uncertain. the mean degree of belief dropped from 
1% after the initial argument to 1% after interacting with nag. even though these results are not statistically significant  due to the small sample size and high variance   they suggest that our exploratory interactions were helpful in persuading users to accept nag's arguments. we hypothesize that the modest effect of these interactions was partly due to nag's limited knowledge  several users indicated that additional factors should have been considered in nag's arguments . interestingly  the users' confidence dropped after the initial argument  possibly because nag's argument contradicted some of the users' intuitions   but increased overall after the exploratory interactions. in most cases  the increased confidence accompanied user beliefs which agreed with or moved towards the beliefs in nag's normative model. 
1 related research 
our work extends traditional explanation capabilities for expert systems  e.g.   buchanan and shortliffe  1   in that it uses bns as its main representation formalism and supports the exploration of arguments in ways that complement the 
justifications generated by earlier systems. 
　nag is most similar in scope to the interactive argumentation system iacas  vreeswijk  1 . like nag  iacas allows the user to add or remove information from its arguments. however  iacas does not model attentional focus or tailor its arguments to the user. 
　several researchers have incorporated context into dialogue systems  e.g.   jonsson  1 . however  since these are often information providing systems  they use context mainly to further specify the user's requirements. in contrast  nag uses the user's request and immediately preceding argument to determine the focus of attention  which in turn affects the argument generation process. 
　nag's analysis-generation cycle resembles the abductive mechanism used inlhobbs et al.  1  to infer implicit information  and the propose-evaluate-modify cycle used in  chucarroll and carberry  1  to initiate information-sharing subdialogues. however  unlike these systems  nag uses bayesian reasoning and generates complete arguments. 
1 conclusion 
we have described the interactive capabilities of our argumentation system  nag  which support the exploration of different aspects of its arguments. the integration of these exploratory operations into our system required the adaptation of nag's argumentation process to accommodate a user's requests  the incorporation of dynamic context changes into our attentional mechanism  and the identification of probabilistic patterns which support the selection of appropriate natural language patterns. 
　our preliminary evaluation shows that the exploratory operations presented in this paper can improve the understanding of nag's arguments. these operations provide a foundation for more elaborate forms of argumentation. 
acknowledgments 
this research was supported in part by grant a1 from the australian research council. 