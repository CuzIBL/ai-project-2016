 
gsat is a randomized local search procedure for solving propositional satisfiability problems  selman et al. 1 . gsat can solve hard  randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches such as the davis-putnam procedure. gsat also efficiently solves encodings of graph coloring problems  n-queens  and boolean induction. however  gsat does not perform as well on handcrafted encodings of blocks-world planning problems and formulas with a high degree of asymmetry. we present three strategies that dramatically improve gsat's performance on such formulas. these strategies  in effect  manage to uncover hidden structure in the formula under considerations  thereby significantly extending the applicability of the gsat algorithm. 
1 	introduction 
selman et al.  1  introduce a randomized greedy local search procedure called gsat for solving propositional satisfiability problems. experiments show that this procedure can be used to solve hard  randomly generated problems that are an order of magnitude larger than those that can be handled by more traditional approaches such as the davis-putnam procedure or resolution. gsat was also shown to perform well on propositional encodings of the n-queens problem  graph coloring problems  and boolean induction problems. 
   a common criticism is that gsat might not do as well on problems with a much more intricate underlying structure. similar criticism has been raised against other randomized local search type procedures  such as simulated annealing  johnson et al. 1 . in exploring this issue  we found that gsat indeed has problems on certain classes of highly structured formulas. examples are propositional encodings of blocks-world planning problems  kautz and selman 1   and graph coloring problems with a high-degree of asymmetry  ginsberg and 
j1nsson 1 .1 
1
we thank matt ginsberg and ari jonsson for bringing after studying gsat's difficulty on such problem instances  we discovered general  domain-independent extensions that dramatically improve gsat's performance. in effect  these extensions manage to uncover the underlying structure in the formulas. for certain problem classes  the extensions push gsat's performance beyond that of backtrack type procedures  whereas on other classes gsat becomes competitive with such procedures. the extensions therefore significantly the enlarge space of problems on which gsat performs well  making it a promising general approach for dealing with hard computational problems in artificial intelligence. 
   the paper is structured as follows. we first review the basic gsat procedure and briefly discuss its performance. we then introduce the various extensions and give experimental data showing the improved performance. 
1 	the gsat procedure 
gsat performs a greedy local search for a satisfying assignment of a set of propositional clauses.1 the procedure starts with a randomly generated truth assignment. it then changes  'flips'  the assignment of the variable that leads to the largest increase in the total number of satisfied clauses. such flips are repeated until either a satisfying assignment is found or a pre-set maximum number of flips  max-flips  is reached. this process is repeated as needed up to a maximum of max-tries times. see figure 1.  for a related approach  see gu  1 . also  see minton et al.  1  for a very successful application of local search to scheduling problems.  
   gsat mimics the standard local search procedures used for finding approximate solutions to optimization problems  papadimitriou and steiglitz 1  in that it only explores potential solutions that arc  close  to the one currently being considered. specifically  we explore the set of assignments that differ from the current one on only one variable. one distinguishing feature of gsat  however  is the we also allow flips that do not directly improve the assignment  i.e.  when the best possible flip these instances to our attention. 
　　1  a clause is a disjunction of literals. a literal is a propositional variable or its negation. a set of clauses corresponds to a formula in conjunctive normal form  cnf : a conjunction of disjunctions. 

procedure gsat 
input: set of clauses a  max-flips  and max-tries output: a satisfying truth assignment of a  if found 
begin for % := 1 to max-tries 
t := a randomly generated truth assignment for j := 1 to max-flips 
if t satisfies a then return t p := a propositional variable such that a change in its truth assignment gives the largest increase in the total number of clauses of a that are satisfied by t 
　　t :=t with the truth assignment of p reversed end for 
end for return  no satisfying assignment found  end 
figure 1: the gsat procedure. 
does not actually decrease the total number of satisfied clauses. as discussed in selman et al.  1   such flips are essential in solving hard problems. another feature of gsat is that the variable whose assignment is to be changed is chosen at random from those that would give an equally good improvement. such non-determinism makes it unlikely that the algorithm makes the same sequence of changes over and over. 
   the gsat procedure requires the setting of two parameters max-flips and max-tries  which determine  respectively  how many flips the procedure will attempt before giving up and restarting  and how many times this search can be restarted before quitting. as a rough guideline  setting max-flips equal to a few times the number of variables is sufficient. the setting of max-tries will generally be determined by the total amount of time that one wants to spend looking for an assignment  which in turn depends on the application. in our experience so far  there is generally a good setting of the parameters that can be used for all instances of an application. thus  one can fine-tune the procedure for an application by experimenting with various parameter settings. 
1 	summary of previous results 
in selman et al.  1   we showed how gsat substantially outperforms backtracking search procedures  such as the davis-putnam procedure  on various classes of formulas. for example  we studied gsat's performance on hard randomly generated formulas.  note that generating hard random formulas for testing purposes is a challenging problem by itself  see cheeseman et al  1 ; mitchell et al  1 ; larrabee and tsuji  1 ; and crawford and auton  1 .  table 1 summarizes the results. the table shows how gsat is indeed much faster than the davis-putnam  dp  procedure on such hard random formulas.1 
　　1 during the last year  we have collected data on other backtrack procedures. using special heuristics  the most efficient ones can handle up to around 1 variable formulas selman et al also showed that gsat performs well on propositional encodings of the n-queens problem  hard instances of graph coloring problems  johnson et al 1   and boolean induction problems  kamath et al 1 . results on encodings of blocks-world planning problems were not as good though  kautz and selman 1   especially compared with dp's performance. 
   the problem with the blocks-world planning formulas appears to be their highly structured character. such structure leads to large numbers of very fast unit propagations in backtrack search procedures  which dramatically reduces the search space.1 gsat has no explicit mechanism for handling unit propagation. its bit flipping strategy implicitly propagates unit clauses but not as efficiently as a specialized procedure. we tried to extend gsat with an explicit mechanism for handling unit propagation. this extension did not improve gsat's overall performance  presumable because the unit propagation mechanism does not match well with the randomized local search strategy. we did however find other extensions that do dramatically improve gsat's performance on the planning problems  and other challenging formulas. these extensions are described in the next section. 
1 	extensions and experimental results 
1 	adding weights 
ginsberg and j1nsson  1  supplied us with some instances of graph coloring where gsat did not manage to find a solution  even after a large number of tries each with many flips.1 their dependency-directed backtracking method could find solutions to these problems with little effort  jonsson and ginsberg 1 . 
   in running gsat on these problems  we discovered that at the end of almost every try the same set of clauses remained unsatisfied. as it turns out  the problems contain strong asymmetries. the effect of asymmetry is best illustrated with the graph shown in figure 1. consider trying to color this graph with three colors  using a local search procedure. initially each node is randomly assigned one of the three colors. the algorithm then starts adjusting colors in order to minimize the number of conflicts.  a conflict occurs when two connected vertices have the same color.  since the constraints between the large group of nodes and the single nodes at the bottom far outnumber the single constraint between the two bottom nodes  the algorithm gets quickly stuck in a state where the bottom two nodes have the same 
in about one hour  buro and kleine biining 1; crawford and auton 1  on a mips machine. nevertheless  the running time clearly scales exponentially  for example  hard 1 variable formulas are undoable. our current gsat runs over 
1 times faster than the one used for generating the data in table 1. moreover  using the random walk option discussed in section 1  we can now solve hard 1 variable formulas in under an hour. 
　　1 unit propagation is a efficient mechanism for dealing with horn clauses. a horn clause is a clause with at most one positive literal. 
1
　　a try is one execution of the outer-loop of the gsat procedure; see figure 1. 
	selman and kautz 	1 


table 1: results for gsat and dp on hard random 1cnf formulas. data from selman et a/.  1 .   choices  is the number of nodes in the dp search tree  and  depth  the average depth of the tree.  the timings reported here and in the rest of this paper are based on c implementations running on a mips r1  unless stated otherwise. 



figure 1: a gerrymandered graph. 
color and each node in the larger set has one of the other two colors. this coloring satisfies all but one constraint! in other words  the single constraint between the bottom two nodes simply gets out-voted by the other nodes. we call such graphs gerrymandered graphs. 
   to overcome asymmetries  we added a weight to each clause  constraint . a weight is a positive integer  indicating how often the clause should be counted when determining which variable to flip next. stated more precisely  having a clause with weight l is equivalent to having the clause occur l times in the formula. of course  we don't know exactly what weights to assign to the clauses. we use the following strategy for dynami-
cally adjusting the clause weights during the search.1 
strategy i: clause weights 
initialize all clause weights to 1. 
at the end of each try  increment by k the weights of those clauses not satisfied by the current assignment. 
we usually set k equal to 1. this strategy automatically  discovers  hidden asymmetries of the formula under consideration. using the weights  gsat solves a typical instance of ginsberg and j1nsson's asymmetri-
1
　　paul morris has independently proposed a similar approach  morris 1 . 
table 1: unsatisfied clause distribution for gsat with and without weights on an asymmetrical graph coloring problem  ginsberg and j1nsson 1 . it is a 1 node graph with a 1 coloring. the encoding has 1 variables and 1 clauses. 
cal coloring problems in 1 seconds  after only 1 tries with 1 flips per try . this is comparable with the time used by efficient backtrack style procedures. table 1 shows the distribution of the number of unsatisfied clauses that remain at the end of each try for gsat with and without weights. we used a total of 1 tries with 1 flips per try. for example  with weights  1 tries led to an assignment with only one unsatisfied clause  and 1 tries led to a satisfying assignment  no unsatisfied clauses . the results show a substantial improvement when using the weights. 
   using this weighing strategy  we can also easily solve the kinds of formulas discussed in section 1 of selman et al.  1 . those formulas were introduced to show some of the limitations of basic gsat. they were handcrafted to repeatedly steer gsat in the wrong direction. the weighing strategy again compensates quite easily. 
   figure 1 illustrates the effect the weighing strategy on the search space for gsat  gsat searches for a global minimum in the number of unsatisfied clauses as a function of the truth assignments. figure 1 abstractly represents this function  with the number of unsatisfied clauses along the vertical axis and truth assignments along the horizontal axis. the weights  in effect  are used to  fill in  local minima while the search proceeds. this general strategy may also be useful in avoiding lo-


figure 1: filling in local minima using clause weights. 
cal minima in other optimization methods. the strategy provides an interesting alternative to the standard use of random perturbations   noise   to escape from local minima  as used in  for example  in simulated annealing. for more discussion on the relation to simulated annealing  see selman and kautz  1 . 
1 	averaging in previous near solutions 
after each try  gsat picks a completely new random assignments as its next starting point. the following strategy is an attempt to use some of the information that may be contained in the previous near-solution  i.e.  the truth assignment at the end of the previous try . let ttinit and tibest be  respectively  the assignment at the beginning of the iih try and the best assignment  i.e.  fewest unsatisfied clauses  found during the ith try. 

the bitwise average of two truth assignments is an assignment which agrees with the assignment of those letters on which the two given truth assignments are identical; the remaining letters are randomly assigned truth values. after many tries in which averaging is performed  the initial and best states become nearly identical. we therefore reset the initial assignment to a new random assignment every reset-tries  useful reset values are between 1 and 1 .1 
   to evaluate this strategy  we consider some of the hardest problems in our test suite. these problems are based on hard graph coloring problems used by johnson et al.  1  to evaluate specialized graph coloring al-
gorithms. table 1 shows gsat's performance on these instances. 
   we see a marked improvement by using our averaging strategy. in particular  note that we were unable to solve at all two of the instances without using averaging.  our davis-putnam procedure cannot solve any of 
1
　　we thank geoffrey hinton and hector levesque for suggesting this strategy to us. the strategy has some of the flavor of the approaches found in genetic algorithms. 
these instances  and we do not know of any other backtrack style satisfiability procedure that can solve these problems.  
   the table also shows that gsat's performance compares favorably with some of the best specialized graph coloring algorithms as studied by johnson et a/.1 this is quite remarkable because gsat does not use any special techniques for graph coloring: it is basically unaware of the fact that it is dealing with encodings of graph coloring problems. 
1 	random walk 
consider the following algorithm for testing the satisfiability of cnf formulas. start with a random truth assignment; randomly select an clause not satisfied by this assignment; flip the truth assignment of one of the letters occuring in this clause  the clause becomes satisfied ; repeat the last two steps until the assignment satisfies all clauses. 
   papadimitriou  1  shows that such a surprisingly simple randomized strategy finds assignments of 1cnf formulas  satisfiable ones  of course   in 1 n 1   steps with probability approaching one  where n is the number of prepositional letters. his proof exploits properties of random walks  feynman et al. 1 . note the difference with gsat: simply flipping the assignment of any variable in some unsatisfied clause may actually increase the total number of unsatisfied clauses. we found that this strategy by itself does not solve the hard satisfiability problems  but it does provide a another useful mechanism for escaping local minima. 
strategy i i i : random walk 
with probability p  pick a variable occuring in some unsatisfied clause and flip its truth assignment. 
with probability 1 - p  follow the standard gsat scheme  
i.e.  pick randomly from the list of variables that gives the largest decrease in the total number of unsatisfied clauses. 
the probability p is fixed in advance; we used p = 1 in our experiments.1 we first consider the effect of the walk strategy on the boolean induction problems as studied by kamath et al.  1 . the task under consideration is to derive   induce   a logical circuit from its inputoutput behavior. kamath et al. encode this problem as a satisfiability problem. they give test results for various instances of this problem using a satisfiability 
　　1 we should note that we have not yet been able to solve the hardest coloring problem in johnson et al.  1 . this problem involves a 1 node graph  and was solved by only one of the johnson's coloring algorithms using many hours of cpu time. the very large size of the boolean encoding of this instance exhausts memory of our current hardware. 
1
　　note the difference between random walk and random noise as used in simulated annealing. random noise can perturb the truth assignments of any of the variables. in the random walk strategy  the perturbation is closely tied to the unsatisfied clauses  the  problem spots  . preliminary experiments show the latter to be much more effective. 
	selman and kautz 	1 


table 1: the effect of averaging in of previous near-solutions  strategy ii . the problems considered are propositional encodings of graph coloring problems  johnson et al. 1 . the  best methods  times are for the best and the second best specialized graph coloring algorithm as reported by johnson et al we have reduced johnson's times by a factor of 1 to compensate for differences in cpu speed.  johnson used a sequent balance 1.  


table 1: using the random walk stategy on boolean induction problems.  timings in seconds.  

table 1: using the random walk stategy on planning formulas. 

algorithm based on integer programming. we consider some of their hardest instances as are given in table 1 in kamath et al.  1 . in selman et al.  1   we showed how gsat's performance is competitive with their results. however  using our walk strategy  we can still substantially improve gsat's performance on these formulas  as is shown in table 1. 
   as a second example of the effectiveness of the walk strategy  we consider encodings of various blocks-world planning problems  kautz and selman 1 . as we discussed above  such formulas are very challenging for basic gsat. examination of the best assignments found when gsat fails to find a satisfying assignment indicates that difficulties arise from extremely deep local minima. for example  in the  towers of hanoi  problem  the initial state is encoded by a conjunction of propositional literals corresponding to the assertion that block a is on b  b is on c  and c is on peg 1; the final state is encoded by asserting that the blocks are stacked in the same order  except that c is on peg 1. in addition  there are clauses that ensure that all moves are legal: for example  that only clear blocks are moved  that a larger block is never placed on a smaller one  and so on. the basic gsat procedure would often find assignments that violated very few constraints  but were quite far from a satisfying assignment. for example  one such assignment would correspond to a plan which simply moved c directly to peg 1  with all the other blocks on top of it; this would only violate the clause that asserted that c must be clear in order to be moved. another such assignment just moves the top block back and forth a few times  and ends up with the final state the same as the initial state. this assignment violates the single clause asserting that c is on peg 1 in the final state. 
   the use of weights and averaging greatly improves the performance of gsat on these formulas  as many of the local minima are filled in or at least elevated. however  it still requires many more retries to solve these problems than is required for similar-sized random or coloring problems. as shown in table 1  combining the random walk strategy with both weights and averaging allows gsat to almost always climb out of the local minima and find a solution in a reasonable amount of time. the performance is comparable to that of basic backtracking search procedures  though highly optimized procedures with special heuristics can still solve these problems about a 1 times as fast. nevertheless  the table shows that these strategies come a long way in improving gsat's performance on problems that appear much more suited for the use of backtrack style search algorithms.1 
1 	conclusions 
we have described three strategies that greatly enhance the power and applicability of gsat  a randomized greedy local search procedure for propositional satisfiability testing. the effectiveness of these strategies was empirically determined.  we also tested a number of other intuitively plausible strategies which in practice failed to improve gsat's performance.  the clause weighing strategy and the random walk strategy are useful in escaping from local minima. the weighing strategy is particularly well-suited for dealing with problems with hidden asymmetries. the averaging-in strategy reduces the number of tries necessary to solve certain classes of 
   1 currently we are investigating alternative representations of planning problems that would be more amenable to a local search procedure  in that assignments that violated few constraints would be likely to be close to a satisfying assignment  in terms of the number of flips necessary to reach it. the overall goal is to develop representations that are less fragile than the  classic  logical representations developed by mccarthy and hayes  1  and extended to planning as satisfiability by kautz and selman  1 . 

instances. it does so by re-using some of the information present in previous near-solutions. each of these strategies  in effect  helps uncover hidden structure in the input formulas. given the success of these strategies and the fact that they are not very specific to the gsat algorithm  it appears that they also hold promise for improving other methods for solving hard combinatorial search problems  such as  simulated annealing and genetic algorithms  davis 1 . 
   in our future research we hope to develop a precise formal understanding of the benefits and applicability of each technique. while some theoretical results  such as those of papadimitriou  1  on random walks  suggest that the strategies are plausible  it is likely to be extremely difficult to prove formally that they are effective in practice.1 
   finally  we should note that we do not claim that gsat will be able to outperform backtracking search methods on all possible problems. we do  in fact  believe that certain highly structured problems lend themselves better for exhaustive search approaches and domainspecific heuristics  such as means-end analysis in planning . nevertheless  with the extensions described here  we have considerably enlarged the class of problems on which gsat performs well  thereby making gsat a viable general procedure for solving hard computational 
problems in artificial intelligence.1 
