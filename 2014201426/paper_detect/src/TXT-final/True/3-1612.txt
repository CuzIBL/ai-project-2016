
cutset conditioning is one of the methods of solving reasoning tasks for graphical models  especially when space restrictions make inference  e.g.  jointree-clustering  algorithms infeasible. the wcutset is a natural extension of the method to a hybrid algorithm that performs search on the conditioning variables and inference on the remaining problems of induced width bounded by w. this paper takes a fresh look at these methods through the spectrum of and/or search spaces for graphical models. the resulting and/or cutset method is a strict improvement over the traditional one  often by exponential amounts.
1 introduction
graphical models are a widely used knowledge representation framework that captures independencies in the data and allows for a concise representation. the complexity of a reasoning task over a graphical model depends on the induced width of the graph. for inference-type algorithms  the space complexity is exponential in the induced width in the worst case  which often makes them infeasible for large and densely connected problems. in such cases  space can be traded at the expense of time by conditioning  assigning values to variables . search algorithms perform conditioning on all the variables. cycle-cutset schemes  pearl  1; dechter  1  only condition on a subset of variables such that the remaining network is singly connected and can be solved by inference tree algorithms. the more recent hybrid w-cutset scheme  rish and dechter  1; bidyuk and dechter  1  conditions on a subset of variables such that  when removed  the remaining network has induced width w or less  and can be solved by a variable elimination  dechter  1  type algorithm.
　the and/or search space for graphical models  dechter and mateescu  1  is a newly introduced framework for search that is sensitive to the independencies in the model  often resulting in exponentially reduced complexities. the traditional way of doing search consists of instantiating the n variables of the problem as if they were all connected in a chain  which results in a search tree exponential in n. in contrast  and/or search is based on a pseudo tree which expresses independencies between variables  resulting in a search tree exponential in the depth m of the pseudo tree  where clearly m ＋ n.
　this paper applies the and/or paradigm to the cycle cutset method. we show that the and/or cycle cutset is a strict improvement of the traditional cycle cutset method  and the same holds for the extended w-cutset version . the result goes beyond the simple organization of the traditional cutset in an and/or pseudo tree  which would be just the straightforward improvement. the complexity of exploring the traditional cutset is time exponential in the number of nodes in the cutset  and therefore it calls for finding a minimal cardinality cutset c. the complexity of exploring the and/or cutset is time exponential in its depth  and therefore it calls for finding a minimal depth and/or cutset ao-c. that is  a set of nodes that can be organized in a start pseudo tree of minimal depth. so  while the cardinality of the optimal and/or cutset  |ao-c|  may be far larger than that of the optimal traditional cutset  |c|  the depth of ao-c is always smaller than or equal to |c|.
1 preliminaries
reasoning graphical models a reasoning graphical model is a triplet r =  x d f  where x is a set of variables  x = {x1 ... xn}  d = {d1 ... dn} is the set of their respective finite domains and f = {f1 ... ft} is a set of real-valued functions  defined over subsets of x. the primal graph of a reasoning problem has a node for each variable  and any two variables appearing in the same function's scope are connected. the scope of a function is its set of arguments. belief networks a belief network can be viewed as an instance of a reasoning graphical model. in this case the set of functions f is denoted by p = {p1 ... pn} and represents a set of conditional probability tables  cpts : pi = p xi|pai   where pai are the parents of xi. the associated directed graph g  drawn by pointing arrows from parents to children  should be acyclic. the belief network represents a probability distribution over x having the product form pb ．x  = p x1 ... xn  = Πni=1p xi|xpai . the moral graph of a directed graph is the undirected graph obtained by connecting the parent nodes of each variable and eliminating direction.
constraint networks a constraint network can also be viewed as an instance of a reasoning graphical model. in this

figure 1: and/or search tree
case the functions are denoted by c = {c1 ... ct}  and the constraint network is denoted by r =  x d c . each constraint is a pair ci =  si ri   where si   x is the scope of the relation ri that denotes the allowed combinations of values.
induced-graphs and induced width an ordered graph is a pair  g d   where g is an undirected graph  and d = x1 ... xn is an ordering of the nodes. the width of a node in an ordered graph is the number of the node's neighbors that precede it in the ordering. the width of an ordering d  denoted w d   is the maximum width over all nodes. the induced width of an ordered graph  w  d   is the width of the induced ordered graph obtained as follows: nodes are processed from last to first; when node x is processed  all its preceding neighbors are connected. the induced width of a graph  w   is the minimal induced width over all its orderings. the tree-width of a graph is the minimal induced width. the path-width pw  of a graph is the tree-width over the restricted class of orderings that correspond to chain decompositions.
1 and/or search spaces for graphical models
this section introduces the basics of and/or search spaces for graphical models as presented in  dechter and mateescu  1 . given a graphical model r =  x d f   its and/or search space is driven by a pseudo tree  freuder and quinn  1 :
definition 1  pseudo tree  given an undirected graph g =  v e   a directed rooted tree t =  v e1  defined on all its nodes is called pseudo tree if any arc of g which is not included in e1 is a back-arc  namely it connects a node to an ancestor in t.
1 and/or search tree
given a graphical model r =  x d f   its primal graph g and a pseudo tree t of g  the associated and/or search tree  denoted st r   has alternating levels of and and or nodes. the or nodes are labeled xi and correspond to the variables. the and nodes are labeled hxi xii and correspond to the value assignments in the domains of the variables. the structure of the and/or search tree is based on the underlying backbone tree t. the root of the and/or search tree is an or node labeled with the root of t.
　the children of an or node xi are and nodes labeled with assignments hxi xii that are consistent with the assignments along the path from the root  path xi  =

figure 1: context-minimal and/or search graph
 hx1 x1i hx1 x1i ... hxi 1 xi 1i . consistency is well defined for constraint networks. for probabilistic networks  consistent tuples have non zero probability.
　the children of an and node hxi xii are or nodes labeled with the children of variable xi in the pseudo tree t.
example 1 figure 1a shows a belief network. figure 1b shows a pseudo tree of the moral graph  together with the back-arcs  dotted lines . figure 1c shows the and/or search tree based on the pseudo tree  for binary valued variables.
　the and/or search tree can be traversed by a depth first search algorithm. the arcs from xi to hxi xii are associated with appropriate labels of the functions in f. the algorithm maintains values for each node  accumulating the result of the computation performed in the subtree below. the computation is dictated by the graphical model and task at hand  for example for belief networks  and nodes are associated with multiplication  of the values of the independent subproblems  and or nodes are associated with summation  over all the values of the variable . based on earlier work  freuder and quinn  1; bayardo and miranker  1; darwiche  1   it can be shown that:
theorem 1 given a graphical model r and a pseudo tree t of depth m  the size of the and/or search tree based on t is o n，exp m  . a graphical model of tree-width w  has an and/or search tree of size o exp w  ， logn  .
1 and/or search graph
the and/or search tree may contain nodes that root identical subtrees. these are called unifiable. when unifiable nodes are merged  the search space becomes a graph. its size becomes smaller at the expense of using additional memory. in this way  the depth first search algorithm can be modified to cache previously computed results  and retrieve them when the same nodes are encountered again. some unifiable nodes can be identified based on their contexts  darwiche  1 . the context of an and node hxi xii is defined as the set of ancestors of xi in the pseudo tree  including xi  that are connected to descendants of xi. it is easy to verify that the context of xi d-separates  pearl  1  the subproblem below xi from the rest of the network. the context minimal and/or graph is obtained by merging all the context unifiable and nodes.
example 1 figure 1 shows the context-minimal and/or search graph of the problem and pseudo tree from figure 1.
　it can be shown that  bayardo and miranker  1; dechter and mateescu  1 :

figure 1: traditional cycle cutset viewed as and/or tree
theorem 1 given a graphical model r  its primal graph g and a pseudo tree t  the size of the context minimal and/or search graph based on t is o exp wt   g     where w is the induced width of g  extended with the pseudo tree extra arcs  over the ordering given by the depth first traversal of t.
1 cycle cutset explored by and/or search
the and/or paradigm exploits the problem structure  by solving independent components separately. this fundamental idea can also be applied to the cycle cutset method  or reasoning by conditioning  pearl  1 .
definition 1  cycle cutset  given a graphical model r =  x d f   a cycle cutset is a subset c   x such that the primal graph of r becomes singly connected if all the nodes in c are removed from it. an optimal cycle cutset is one having the minimum number of variables.
　the cycle cutset method consists of enumerating all the possible instantiations of c  and for each one of them solving the remaining singly connected network by a linear time and space tree algorithm. the instantiations of c are enumerated by regular or search  yielding linear space complexity and o exp|c|  time complexity  therefore requiring a minimal cycle cutset to optimize complexity.
　a first simple improvement to the traditional cycle cutset scheme described above would be the enumeration of c by and/or search.
example 1 figure 1a shows two 1 〜 1 grids  connected on the side node a. a cycle cutset must include at least two nodes from each grid  so the minimal cycle cutset contains three nodes: the common node a and one more node from each grid  for example b and c. the traditional way of solving the cycle cutset problem consists of enumerating all the assignments of the cycle cutset {a b c}  as if these variables form the chain pseudo tree in figure 1b. however  if a is the first conditioning variable  the remaining subproblem is split into two independent portions  so the cycle cutset {a b c} can be organized as an and/or search space based on the pseudo tree in figure 1c. if k is the maximum domain size of variables  the complexity of solving figure 1b is o k1  while that of solving figure 1c is o k1 .
　we can improve the general cycle cutset method  based on the previous example: first find the minimal cycle cutset c; then find the minimal depth start pseudo tree made of nodes in c:
definition 1  start pseudo tree  given an undirected graph g =  v e   a directed rooted tree t =  v 1 e1   where v 1   x  is called a start pseudo tree if it has the same root and is a subgraph of some pseudo tree of g.

　if a cycle cutset of cardinality |c| = c is explored by and/or search  based on a start pseudo tree t over the set c  and the depth of t is m  then m ＋ c. therefore 
proposition 1 exploring a cycle cutset by and/or search is always better than  or the same as  exploring it by or search.
1 and/or cycle cutset
the idea presented in section 1 is a straightforward application of the and/or paradigm to cycle cutsets. in the following we will describe a more powerful version of the and/or cycle cutset.
definition 1  and/or cycle cutset  given a graphical model r =  x d f   an and/or cycle cutset ao-c is a cycle cutset together with an associated start pseudo tree tao-c of depth m. an optimal and/or cycle cutset is one having the minimum depth m.
example 1 figure 1 shows a network for which the optimal cycle cutset contains fewer nodes than the optimal and/or cycle cutset  yet the latter yields an exponential improvement in time complexity. the network in the example is based on a complete binary tree of depth r  the nodes marked aji shown on a gray background. the upper index j corresponds to the depth of the node in the binary tree  and the lower index i to the position in the level.
each of the leaf nodes  from ar1 to ar1r 1 is a side node in a 1 〜 1 grid. a cycle cutset has to contain at least 1 nodes from each of the 1r 1 grids. an optimal cycle cutset is c = {ar1 ... ar1r 1 b1r ... b1rr 1}  containing 1r nodes  so the complexity is o exp|c|  = o exp 1r  . we should note that the best organization of c as an and/or space would yield a pseudo tree of depth 1r 1. this is because all the nodes in {ar1 ... ar1r 1} are connected by the binary tree  so they all must appear along the same path in the pseudo tree  this observation also holds for any other optimal cycle cutset in this example . exploring c by and/or search lowers the complexity from o exp 1r   to o exp 1r 1  .
　let's now look at the and/or cycle cutset ao-c = {aji | j = 1 ... r; i = 1 ...  ... b  containing all the a and b nodes. a pseudo tree in this case is formed by the binary tree of a nodes  and the b nodes exactly in the same position as in the figure. the depth in this case is r + 1  so the complexity is o exp r + 1    even though the number of nodes is |ao-c| = |c| + 1r 1   1.
　the previous example highlights the conceptual difference between the cycle cutset method and what we will call the and/or cycle cutset method. in cycle cutset  the objective is to identify the smallest cardinality cutset. subsequently  the exploration can be improved from or search to and/or search. in and/or cycle cutset the objective is to find a cutset that forms a start pseudo tree of smallest depth.
theorem 1 given a graphical model r  an optimal cycle cutset c  its corresponding smallest depth start pseudo tree tc  and the optimal and/or cycle cutset ao-c with the start pseudo tree tao-c  then:
	|c| − depth tc  − depth tao-c 	 1 
there exist instances for which the inequalities are strict.
　we should note that strict inequalities in eq. 1 could translate into exponential differences in time complexities.
1 and/or w-cutset
the principle of cutset conditioning can be generalized using the notion of w-cutset. a w-cutset of a graph is a set of nodes such that  when removed  the remaining graph has induced width at most w. a hybrid algorithmic scheme combining conditioning and w-bounded inference was presented in  rish and dechter  1; larrosa and dechter  1 . more recently  w-cutset sampling was investigated in  bidyuk and dechter  1   and the complexity of finding the minimal w-cutset was discussed in  bidyuk and dechter  1 .
　the hybrid w-cutset algorithm performs search on the cutset variables and exact inference  e.g. bucket elimination  dechter  1   on each of the conditioned subproblems. if the w-cutset cw is explored by linear space or search  the time complexity is o exp |cw| + w    and the space complexity is o expw .
　the and/or cycle cutset idea can be extended naturally to and/or w-cutset. to show an example of the difference between the traditional w-cutset and the and/or w-cutset we refer again to the example in figure 1. consider each 1 〜 1 grid replaced by a network which has a minimal wcutset cw. the minimal w-cutset of the whole graph contains in this case 1r 1 ， |cw| nodes. if this w-cutset is explored by or search  it yields a time complexity exponential in  1r 1 ， |cw| + w . if the w-cutset is explored by and/or search it yields a time complexity exponential in  1r 1 + |cw| + w   similar to example 1 . in contrast to this  the and/or wcutset  which contains the a nodes and the w-cutsets of each leaf network  yields a time complexity exponential only in  r + |cw| + w   or possibly even less if the nodes in cw can be organized in a start pseudo tree which is not a chain  i.e. has depth smaller than |cw| .
1 algorithm description
the idea of w-cutset schemes is to define an algorithm that can run in space o expw . the and/or w-cutset algorithm is a hybrid scheme. the cutset portion  which is organized in a start pseudo tree  is explored by and/or search. the remaining w-bounded subproblems can be solved either by a variable elimination type algorithm  or by search with wbounded caching - in particular  and/or search with full caching is feasible for these subproblems.
1 improved and/or caching scheme
in  dechter and mateescu  1   the caching scheme of and/or search is based on contexts  darwiche  1   which are precomputed based on the pseudo tree before search begins. algorithm ao i  performs caching only at the variables for which the context size is smaller than or equal to i  called i-bound .
　the cutset principle inspires a more refined caching scheme for ao  which caches some values even at nodes with contexts greater than the i-bound. lets assume the context of the node xk is context xk  = {x1 ... xk}  where k   i. during the search  when variables x1 ... xk i are instantiated  they can be regarded as part of a cutset. the problem rooted by xk i+1 can be solved in isolation  like a subproblem in the cutset scheme  after the variables x1 ... xk i are assigned their current values in all the functions. in this subproblem  context xk  = {xk i+1 ... xk}  so it can be cached within i-bounded space. however  when the search retracts to xk i or above  the cache table for variable xk needs to be purged  and will be used again when a new subproblem rooted at xk i+1 is solved.
　this improved caching scheme only increases the space requirements linearly  compared to ao i   but the time savings can be exponential. we will show results in section 1.
1 algorithm ao-c i 
we can now define the different versions of and/or i-cutset algorithm that we experimented with. we chose to explore the cutset portion either by linear space and/or search  no caching  or by and/or search with improved caching. for the i-bounded subproblems  we chose either bucket elimination  be  or and/or search with full caching  which coincides with the improved caching on the bounded subproblems . the four resulting algorithms are: 1  ao-lc i  - linear space cutset and full caching for subproblems; 1  ao-lc-be i  - linear space cutset and be for subproblems; ao-c i  - improved caching everywhere; 1  ao-c-be i  - improved caching on cutset and be on subproblems.
1 finding a start pseudo tree
the performance of ao-c i  is influenced by the quality of the start pseudo tree. finding the minimal depth start pseudo tree for the given i-bound is a hard problem  and it is beyond the scope of this paper to address its complexity and solution. we will only describe the heuristic we used in creating the pseudo trees for our experiments.
　min-fill  kj aerulff  1  is one of the best and most widely used heuristics for creating small induced width orderings. the ordering defines a unique pseudo tree. the minimal start pseudo for an i-bound contains the nodes for which some descendant has adjusted context  i.e. context without the variables instantiated on the current path  greater than i. min-fill heuristic tends to minimize context size  rather than

i111111d ao-c 111111d c 111111|c|111111	gwca	1	1	1	1	1	1
table 1: cpcs 1 - cutsets comparison
pseudo tree depth. nevertheless  we chose to try it and discovered that it provides one of the best pseudo trees for higher values of i.
　min-depth we developed a heuristic to produce a balanced start pseudo tree  resulting in smaller depth. we start from a min-fill tree decomposition and then iteratively search for the separator that would break the tree in parts that are as balanced as possible  relative to the following measure: on either side of the separator eliminate the separator variables  count the number of remaining clusters  say n  and then add the sizes of the largest logn clusters.
　gwc  bidyuk and dechter  1  is a greedy algorithm to build a minimal cardinality cutset. in the process  we also arranged the minimal cardinality cutset as and/or cutset  to compare with the minimal depth cutset that we could find.
1 experimental evaluation
we investigated two directions. one was to empirically test the quality of the start pseudo trees  and the other was to compare actual runs of the different versions of ao-c i .
1 the quality of start pseudo trees
we report here the results on the cpcs 1b network from the uai repository. it has 1 nodes and induced width 1. table 1 shows the values of f i   which expresses the total complexity of a cutset scheme. for a cardinality cutset  f i  = i + |c| and for an and/or cutset of depth d  f i  = i + d. the row d ao-c  shows the depth of the best and/or cutset we could find. |c| shows the number of nodes in the best cutset found by gwc  and d c  shows its depth when organized as and/or cutset. gwca is taken from  bidyuk and dechter  1 . the best complexity  expressed by small values of f i   is always given by the and/or cutset  and for smaller values of i they translate into impressive savings over the cardinality cutset c.
　in all our experiments described in the following  we refrained from comparing the new cutset scheme with the old cardinality cutset scheme  equivalent to an or search on the cutset   because the latter was too slow.
1 performance of ao-c i 
we tested the different version of the ao-c i  family primarily on bayesian networks with strictly positive distributions  for the task of belief updating. this is necessary to grasp the power of the scheme when no pruning is involved in search.
　in all the tables n is the number of nodes  k is the maximum domain size  p is the number of parents of a variable  w  is the induced width  i is the i-bound  d is the depth of the i-cutset. for most problems  we tested a min-fill pseudo-tree  mf  and one based on the depth minimizing heuristic  md .
n=1  k=1  p=1  1 instances  w*=1ialgorithmsdtime sec # nodesmfmdmfmdmdmf1ao i 1111 1 1ao-lc i 111 1 1ao-c i 111 1 1ao-c-be i 11--1ao i 1111 1 1ao-lc i 1111ao-c i 1111ao-c-be i 11--1ao i 11111ao-lc i 1111ao-c i 1111ao-c-be i 11--n=1  k=1  p=1  1 instances  w*=1ialgorithmsdtime sec # nodesmfmdmfmdmdmf1ao-lc i 1111 1 1ao-c i 111 1 1ao-c-be i 11--1ao-lc i 1111 1 1ao-c i 111 1 1ao-c-be i 11--1ao-lc i 1111 1 1ao-c i 111 1 1ao-c-be i 11--table 1: random networks
the time and the number of nodes expanded in the search are shown for the two pseudo trees correspondingly.
　random networks. table 1 shows results for random networks  generated based on n  k and p and averaged over 1 instances. note that k=1  which makes the problems harder  even though w  seems small. for n=1 we see that the old scheme ao i  is always outperformed. using improved caching on the cutset is almost always beneficial. for i very close to w   caching on the cutset doesn't save much  and in some cases when no caching is possible  the extra overhead may actually make it slightly slower. also  for strictly positive distributions  switching to be is faster than running ao search with caching on the remaining problems.
　cpcs networks. cpcs are real life networks for medical diagnoses  which are hard for belief updating. table 1 shows results for cpcs 1 file  having induced width 1. for i = 1  ao-c-be i  is actually be. it is interesting to note that ao-lc-be i   for i = 1 is actually faster than be on the whole problem  while requiring much less space  exp 1  compared to exp 1    due to smaller overhead in caching  smaller cache tables  and a good ordering that doesn't require recomputing the same problems again. we also mention that ao i  was much slower on this problem and therefore not included in the table.
　in the above experiments  the values of d show that mf heuristic provided a better cutset for large values of i  while the md heuristic provided good cutsets when i was small.
　genetic linkage network. we include in table 1 results for the genetic linkage network ea1  fishelson and geiger  1 . this is a large network  with n=1  but relatively small induced width  w  = 1. this network contains a lot of determinism  zero probability tuples . we did not use in ao search any form of constraint propagation  limiting the algorithm to prune only the zero value nodes  their subproblems do not contribute to the updated belief . we note here that for i-bound 1 and 1  ao-c i  is faster than ao-c-be i  be-
cpcs 1b  n=1  k=1  w* =1ialgorithmsd  mf time# nodes1ao-lc i 1 11 1ao-lc-be i 1.1-ao-c i 1.1 1ao-c-be i 1.1-1ao-lc i 1.1 1ao-lc-be i 1-ao-c i 11 1ao-c-be i 1-1ao-lc i 1.1 1ao-lc-be i 1-ao-c i 11 1ao-c-be i 1-table 1: cpcs 1
ea1 - n=1  k=1  w*=1ialgorithmsdtime sec # nodesmfmdmfmdmdmf1ao i 1111 1 1ao-lc i 111 1 1ao-c i 1111 1ao-c-be i 11--1ao i 11111 1ao-lc i 1111ao-c i 1111ao-c-be i 11--1ao i 11111ao-lc i 1111ao-c i 1111ao-c-be i 11--table 1: genetic linkage network
cause it is able to prune the search space. we used a version of be which is insensitive to determinism.
　large networks. memory limitations are the main drawback of be. in table 1 we show results for hard networks  solved by ao-c-be i   where i = 1 is set to the maximum value that we could use on a 1 ghz pentium iv with 1 gb of ram. for n=1  the space requirements of be would be about 1 times bigger than the ram  note k=1   yet ao-c-be 1  could solve it in about six and a half hours  showing the scalability of the and/or cutset scheme.
1 conclusion
the paper presents the and/or w-cutset scheme  which combines the newly developed and/or search for graphical models  dechter and mateescu  1  with the w-cutset scheme  bidyuk and dechter  1 . theorem 1 shows that the new scheme is always at least as good as the existing cutset schemes  but it often provides exponential improvements. the new and/or cutset inspired an improved caching scheme for the and/or search  which is always better than the one used by ao i   dechter and mateescu  1   based on context.
　the experimental evaluation showed  first  that the theoretical expectations of getting exponential improvements over the traditional cardinality cutset are actually met in practice.
　second  it showed the power and flexibility of the new hybrid scheme. our conclusion is that improved caching on the cutset is in most cases beneficial. for the remaining problems  if the task is belief updating  or counting solutions  and there is little determinism  then switching to be is faster. in the presence of determinism  solving the remaining problems with search with full caching may be better. we leave for fu-
k=1  p=1; ao-c-be i   i=1
nw*d  mf time sec 111111 111table 1: networks with high memory requirements for be
ture work the investigation of using look-ahead and no-good learning in the presence of determinism for the and/or wcutset scheme.
　finally  the new scheme is scalable to memory intensive problems  where inference type algorithms are infeasible.
acknowledgments
this work was supported in part by the nsf grant iis1 and the muri onr award n1-1.
