an augmented state transition network analysis procedure 
         daniel g. bobrow bolt  beranek and newman  inc. cambridge  massachusetts 
bruce eraser 
language research foundation 
cambridge  massachusetts 

summary 
　　　a syntactic analysis procedure is described which obtains d i r e c t l y the deep structure information associated with an input sentence. the implementation u t i l i z e s a state t r a n s i t i o n network characterizing those l i n g u i s t i c facts representable in a context free form  and a number of techniques to code and derive additional l i n g u i s t i c information and to permit the compression of the network size  thereby allowing more e f f i c i e n t operation of the system. by recognizing identical constituent predictions stemming from two different analysis paths  the system determines the structure of this constituent only once. when two alternative paths through the state t r a n s i t i o n network converge to a single state at some point in the analysis  subsequent analyses are carried out only once despite the earlier ambiguity. use of flags to carry feature concordance and previous context information allows merging of a number of almost identical paths through the network. 
introduction 
　　　the present paper is an abbreviated account of a syntactic analysis system  stap   state transition analysis 
procedure  implemented in bbn-lisp  bobrow  murphy  teitelman 1  which is designed to take as i t s input a sentence of english written in normal orthography and produce as i t s output a form of deep structure representation of the sentence. we require that the analysis of an input sentence contain the information present in the transformational deep structure representat i o n of a sentence  making e x p l i c i t such relationships as logical subject  logical object  etc. 
　　　this is not a novel enterprise; reports of work with similar goals can be found in papers by petrick  1   
mitre  zwicky  et. al  1   kuno 
 1   and thorne  bratley  and dewar  1 . the f i r s t three actually produce a tree structure which purports to be a l i n g u i s t i c a l l y motivated deep structure in the form l i k e that de-
scribed by chomsky  1 . thorne  bratley and dewar attempt to capture this same information by appropriate labelling of nodes  and insertion of some dummy nodes in a surface structure analysis. the fctrick  mitre  and kuno analysis algorithms depend e x p l i c i t l y on a transformational grammar of some cannonical form. the analysis algorithm refers to this grammar during the analysis of an input s t r i n g . the petrick and mitre approaches are distinguished from that of kuno in that the former e x p l i c i t l y involve transformation reversal while the l a t t e r   once having found the surface structure representation of the sentence  goes directly to the deep structure. 
　　　it was after reading the paper by thorne  dewar and bratley that we became convinced that an e f f i c i e n t and l i n g u i s t i c a l l y interesting analysis system could be developed without e x p l i c i t reference to a transformational grammar. it i s   in f a c t   the thorne work which provided us with the general structure of stap: the notion of a state t r a n s i t i o n network for r e f l e c t i n g 
　　　immediate grammatical r e s t r i c t i o n s and the use of flags for carrying information relevant to other parts of the analysis. stap is an elaboration of the procedure described by thorne  bratley  and dewar  op  c i t.  ; the authors wish to gratefully acknowledge the generous time and assistance provided to us by thorne and dewar which permitted us to understand their system and thus attempt stap. 
-1-　　　the goals of these two systems d i f f e r : thorne et. a l . are concerned with the development of a psychologica l l y valid model of syntactic analysis u t i l i z i n g a limited dictionary  basically only function words  and a single pass algorithm. in stap we are primarily concerned with r e f l e c t i n g those deep structure relationships motivated within the framework of a transformational grammar and u t i l i z i n g a complete dictionary with f u l l y specified entries. in addition stap can transmit information back into a previously analyzed structure  a capability not provided in the thorne system. the stap system has the f u l l formal power of a turing machine; an important and n o n t r i v i a l question is 
whether the l i n g u i s t i c information in either the thorne or stap system can be introduced by some simple function operating on a transformational grammar such as one from the class of grammars described by petrick  op. c l t .  . this question has not yet been carefully i n vestigated but we anticipate an affirmat i v e answer. 
　　　in t h i s paper we attempt to charact e r i z e clearly and precisely  1  the form and content of our analysis of an input sentence; and  1  the nature of the algorithm that is u t i l i z e d . in no sense does t h i s analysis algorithm provide any semantic information  either of the sort found in katz  1  or that used by woods  1  as an i n t e r face to his system for querying a structured data base   i n his case the o f f i c i a l airlines guide . that i s   no l i n g u i s t i c a l l y or procedurally motivated semantic information is contained in the analysis. however  since both the katz and woods approaches to the semantic interpretation of a sentence u t i l i z e a deep structure representation equivalent to what stap produces  the stap analysis could serve as a f i r s t for such semantic analyses. 
the general structure of stap 
　　　s u p e r f i c i a l l y   stap resembles a f i n i t e state automaton. the analysis algorithm  s t a r t i n g at an i n i t i a l state s1  uses each word of the input s t r i n g 
　　　to cause a change of state through a state t r a n s i t i o n network. i f   at the end of the input s t r i n g   the system is in the f i n a l state  end  the input has been analyzed as a well-formed sentence. the history of the t r a n s i tions provides an analysis of the structure of the sentence. in short  the general strategy of the analysis procedure can be viewed as a series of state transitions with each t r a n s i t i o n signifying some additional successful subanalysis. 
　　　however  a s t r i c t f i n i t e state automaton with transitions dependent only on the next word is well-known to be inadequate as a model for the analysis of a natural language. stap obtains additional power from the capability of the t r a n s i t i o n i n t e r preter to save i t s current status and c a l l i t s e l f to analyze a substring by s t a r t i n g anew at some other state in the network. this recursive a b i l i t y of stap provides it with the power of a non-deterministic push-down store automata with a top-down parsing strategy; thus it is capable of recognizing an arbitrary context-free language with i n d e f i n i t e embedding of sentences. 
　　　however  stap goes beyond the a b i l i t y of the numerous context-free parsing algorithms already implemented to account for a range of l i n g u i s t i c 
　　　information contained in the deep structure analysis of a sentence. this capability of stap derives from the auxiliary operations performed during each state t r a n s i t i o n   and additional information which stap associates with the constituents of the analysis. the operations include the setting of f l a g s   the testing of previously set flags to enable or reject a t r a n s i t i o n   and the transferring of information determined by the current t r a n s i t i o n to some previous constituent s  of the analysis. 
the state transition network 
　　　there are two types of transitions between a pair of states of the state t r a n s i t i o n network. the f i r s t   the more straightforward  is where a single word s a t i s f i e s the input conditions and permits the state t r a n s i t i o n to occur. the second is where the next substring of the input must be analyzable as some constituent structure  e.g. a noun phrase  for the state t r a n s i t i o n to be permitted. we refer to these two types as l e x i c a l and structural t r a n s i t i o n s   respectively. in  1  we have shown an i l l u s t r a t i v e state t r a n s i t i o n network for stap. 
　　　the subpart in   i i     the top l e v e l   indicates that an input s t r i n g 
must be analyzed as a structure  s  followed by a terminal punctuation 
mark    .  or      that i s   we have f i r s t a structural t r a n s i t i o n and then a l e x i c a l t r a n s i t i o n . 
　　　in order to permit the structural t r a n s i t i o n from s1 to /s it is necessary for stap to save i t s current status and to reenter the network at the state s  shown in   l i i   . the transitions from the state s to the state c-lijd  constituent end  as shown in   l i i   specify the possible analyses for the constituent s. for example  a sentence can be analyzed as np-aux-vp  e.g. john can see mary  requiring the transitions from s to /np to /aex to c-end; or analyzed as sadv-np-vp  requiring t r a n s i t i o n s from s to /adv to /np to c-lnd  e.g. certainly the man is dead . 
　　　however  the t r a n s i t i o n from s to /np is of the structural rather than the l e x i c a l type  and requires that stp save i t s status and reenter the system 

-1-

anew  this time at the state np shown in   l i i i   . reentering the network in the way we have been describing is equivalent to going down a level in the constituent structure; that i s   separating the constituent being analyzed into i t s dominated constituents  e.g. up into det-adj-n . 
　　　we note here that there are certain syntactic categories such as np and aux which are satisfied by both a l e x i c a l item or a structural constituent. for example  the input word it  is analyzed as a np  and so is the string det-adj-n  the big man . such cases are combined in the network into a 
　　　single t r a n s i t i o n which is possibly both structural and l e x i c a l . 
the analysis procedure 
　　　two alternative strategies for parsing exist within the system. the choice between them depends in part on whether one wants to obtain one analysis or a l l possible analyses for each input sentence. for the single analysis case  at each node in the state t r a n s i t i o n network stap can try  in some suitably arranged order  each of the possible transitions u n t i l one succeeds  proceed to the state designated  and continue in this way u n t i l the input string has been completely examined. if in any state sj no t r a n s i t i o n is possible  stap must back up to the previous state sj    mark the t r a n s i t i o n from sj  to sj as blocked  and then try some other t r a n s i t i o n from si. left recursive grammar rules pose no d i f f i c u l t y if the t r a n s i t i o n which implies the l e f t recursion is t r i e d l a s t . to find a l l analyses  stap can remember a successf u l analysis at the state end  and then simulate a f a i l u r e . it w i l l then recursively traverse the network through a l l possible paths u n t i l no untried transitions are available from any reached state. with this technique  great care must be taken with l e f t recursion to prevent i n f i n i t e loops. 
　　　we are interested in obtaining a l l analyses  but do not use the recursion technique just described. rather  stap simulates the operation of a non-deterministic pushdown store  and simultaneously follows a l l possible transitions from a given state. thus at any time in the analysis of a sentence  a l l p a r t i a l analyses up to a 
　　　particular input word are available  though not necessarily with a l l of the f i n a l information associated with the constituents  and a number of paths through the network are active. a l l and only those paths which stay active through the last word of the input sentence and f i n i s h in the state end represent successful analyses. 
       in order to deal with the case of common predictions at a point in the i n put string  of which l e f t recursion is a special case   whenever stap must reenter the system during a structural t r a n s i t i o n   a check is made to see if this subconstituent has been expected previously at just this point in the input string analysis. for example  after analyzing through the word f l y i n g in the ambiguous sentence they are f ylrig planes  there would presumably be  just two analyses  both predicting that the next constituent could be a noun phrase. accordingly  the analysis of the mp is carried out only once. 
       a number of auxiliary techninues are used to compiless the size of the state t r a n s i t i o n network by storing information in other ways. for example  since only one sentence adverbial  sadv  is allowed per sentence  the two transitions shown in  1  requiring  sadv cannot both be allowed nor can more than one t r a n s i t i o n around the loop at state /np be permitted. we implement r e s t r i c t i o n s of this type by providing with each successful t r a n s i t i o n a capabili t y for setting flags. a parallel f a c i l i t y allows tests for appropriate flags before a t r a n s i t i o n is permitted. in the present example  either of the state transitions requiring a sentence adverbial causes a flag to be set 
indicating that an sadv had been analyzed at this l e v e l . in addition  a condition for the possiblity of such a state t r a n s i t i o n is that this sadv flag has not been previously set. thus  the f i r s t time a sentence adverbial is analyzed  the setting of the sadv flag precludes any further sentence auverblal analysis. the use of a flag as discussed thus allows compression of the network in the form shown as opposed to requiring two separate paths  one in which the sentence adverbial is in the i n i t i a l position  the other in which it is in the pre-aux position. we note here that the setting of the sadv flag also carries information which w i l l preclude the analysis of the sentence as a question. 
-1-       another set of transitions which are d i f f e r e n t i a l l y allowed by flags are those shown for vp. both vtr  transitive verb  and vin   i n t r a n s i t i v e   go to the same state  /v  but in the former case a noun phrase must follow while in the l a t t e r case it cannot. thus we associate with the vin t r a n s i t i o n the setting of a 
       flag which precludes the state t r a n s i t i o n /v to / i o . 
　　　we also allow a further f l a g setting mechanism based on the subcateg o r i z a t l o n of a word class. for example  the verb sleep has the subcategorizatlon features  +v  +voluntary action  -  np  associated with it in the dictionary. in analyzing this verb  various flags are set based on this information. for example  the syntactic feature - np sets a f l a g   c a l l it nodo  no direct object   which is tested by the /v to /io t r a n s i t i o n . the nodo f l a g set precludes t h i s t r a n s i t i o n . to consider another example  to distinguish between a single object verb such as h i t and a double object verb such as give set another f l a g . both the state transitions in   l l v   from /io to /io in analyzing to and from /io to c-end analyzing a noun phrase test for t h i s flag and are permitted only i f i t is set. 
　　　in addition to the preceding mechanisms  stap transfers information backwards to previously analyzed parts of the sentence. for example   when the t r a n s i t i o n from the state /io to i t s e l f occurs in the analysis of the preposition to it is possible to state d e f i n i t e l y that the noun phrase analyzed in the /v to /io t r a n s i t i o n is functioning as the direct object. as a part of t h i s t r a n s i t i o n   the information indirect object is added as a comment to the constituent np immediately following the verb. furthermore  if   t h i s t r a n s i t i o n has not occurred  then the /io to c-end state t r a n s i t i o n through a noun phrase derives the i n f o r mation that t h i s noun phraee is functioning as the direct object  and that the noun phrase immediately following the verb is functioning as the indirect object. this functional information is assigned to the relevant constituents as a result of t h i s t r a n s i t i o n . the actual information transfer s i t u a t i o n is of course more complex because one or both of these objects may have been moved to another position in the sentence. we emphasize again that it is t h i s type of information transfer technique that permits the claim that stap can capture the deep structure information associated with a sentence. 
　　　an alternative technique for determining the analysis of a c o n s t i t u ent is to make alternate predictions when the functional status or other information relevant to a constituent is not clear. in the double object case  for example  stap can make two a l t e r n a t i v e predictions concerning a noun phrase following a verb l i k e give/  one that the noun phrase was the direct object; the other that it was the indirect object. stap then supresses the analysis which turns out to be incorrect. the choice between these two mechanisms is dependent in each instance on the r e l a t i v e costs of maintaining extra analyses as opposed to the cost of searching back through the present analysis to find the appropriate place to store the informat i o n once it is derived. for a sentence l i k e who should the book have been given to yesterday  there are a number of active alternative analyses just after processing the noun phrase the book: one must allow who to be the direct or indirect object; and the book to be the direct object  the indirect object for a passive construction  or the subject of an active verb. some of these alternatives can be eliminated when the determination is made  after the have been given  that a passive sentence is being analyzed. only after the preposition tc has been analyzed is it possible to determine that the who is functioning as the indirect object 
a n c i  the book as the direct object. 
　　　in order to compress the state t r a n s i t i o n network  we allow state transitions which do not require using any of the input words. for example  the t r a n s i t i o n labelled nil in  lv  from state /n to c-end allows terminat i o n of the constituent aux after just one aspect  asp  word or one modal  m    or after each cycle through the asp loop. another such t r a n s i t i o n is the one labelled  np  from /io to c-end in   l i v   . this t r a n s i t i o n is used to insert into an analysis a marker i n dicating where the indirect object position was in the deep structure in a sentence such as which person did you show it to  a t r a n s i t i o n of the same type is used to mark the deep structure position of that part of the auxiliary which has been moved forward to form a question.  see  1  below . 
the form of the analysis 
-1-　　　the goal of stap is to determine for a given input sentence a deep structure analysis which r e f l e c t s the basic logical relationships of a 
　　　sentence necessary for i t s semantic i n t e r p r e t a t i o n .  the surface structure representation r e f l e c t s only the order and s u p e r f i c i a l relationships among the grammatical constituents of the sentence as produced by the speaker.  ambiguous sentences  of course  have more than one deep structure. quite c l e a r l y   a natural language analysis system cannot be put to any interesting use in the area of a r t i f i c i a l i n t e l l i gence unless the information present in the deep structure representation is determined. 
　　　basically there are three types of information in the deep structure analysis of a sentence:  1  categorial information specifying what syntactic categories are present and their hierarchical relationship;  1  functional information such as what constituent is functioning as the logical subject of the sentence  which as the direct object  e t c .   and  1  subcategorization information r e f l e c t i n g finer specification of the constituents present  the complex symbols as characterized by chomsky  1  e.g. that the noun cat is subcategorized as animate  non-human . however  in order to specify this information especially  1  and  1  above  the 
deep structure analysis usually does not resemble the surface structure in a variety of ways. the two most crucial differences between the deep and surface structure analysis of a sentence are  1  the order of t'he constituents in the one relative to the other  and  1  the additional structure present in the deep structure not found in the surface structure analysis. for example  a simple sentence such as the red dog is noisy has a deep structure ana~lyyis paraphrased roughly by the  dog which is red is no i sy where the r e l a t i v e order of  reel ana dog are reversed and a relative clause is present. 
　　　in stap  if the relative position of a constituent in the deep structure analysis is the same as in the input string  the surface structure   this is e x p l i c i t l y stated in our analysis. for those cases where the r e l a t i v e order is altered  this constituent is marked in the surface structure position as out of place and i t s o r i g i n a l position in the deep structure is indicated. in short  the general form of our analysis resembles the surface structure analysis of the sentence  with added indications of 
moved constituents and where they are 
located in the deep structure. cor e f e r e n t i a l l i t y is indicated by appropriate l a b e l l i n g . 
　　　we w i l l i l l u s t r a t e our analysis using the r e l a t i v e l y complicated sentence  1  was the man believed to have been shot by john 	and present i t s surface structure analysis 
 1   i t s usual deep structure analysis  1   and i t s stap deep structure analysis  1 . 	the form of the output is three columns: 	the f i r s t containing the categorial information; the second the functional information; and the t h i r d the subcategorial information. the f i r s t and t h i r d are usually combined into a tree  p-marker  in the l i n g u i s t i c l i t e r a t u r e but we have found the present adaptation more workable and equally as readable. it is important to recognize that the functional information associated with the surface structure analysis  1  is that determined from the surface structure i t s e l f and is usually referred to as the grammatical as opposed to the logical functional relationships  cf. chomsky  1  for a discussion of these terms.  
　　　let us now trace through the analysis of this sentence to see what the system does to produce the modified deep structure analysis  1  associated with  1   ignoring the numerous blind alleys which the analysis routine must follow. lssential to understanding this procedure is the notion that each constituent has only a few canonical forms in the deep structure   e.g. s may be adv-np-aux-vp or np-aux-vp; vp may be v  v-np  v-np-pp; etc.  and these facts are b u i l t into the state transitions in the same way as they are characterized by the phrase structure rewriting rules of the base component of a transformational grammar. thus  in terms of the analysis already performed and the present state  the system is always t r y i n g to 
meet one or more of these cannonical formats. 
-1-　　　looking now at  1   the analysis of was  as an aux is not an acceptable i n i t i a l constituent for a deep structure s and causes the marker # to be placed after aux signifying that it is not in i t s deep structure position relative to the other constituents in the sentence. the string the man is then analyzed as a np  but i t s function is l e f t unspecified  e.g. subject or object . the next word  believed  is a verb  according to the dictionary of stap  either of past tense or past p a r t i c i p l e form. the earlier presence of the was precludes the past tense analysis and furthermore indicates the passive construction. the past p a r t i c i p l e analysis of believed requires it to be the f i r s t constituent of a vp  we are ignoring the reduced r e l a t i v e clause analysis here  e.g. the man  who was  believed to be i l l .   ; at this point a f l a g is set to enable a t r a n s i t i o n within this current vp  believed to have been shot by john  to accept a logical subject of this sentence in the form by-np. the subject np-aux sequence preceding this vp  are introduced into the analysis by 
allowable n u l l t r a n s i t i o n s . each is followed by a * signifying that the actual constituents have been moved elsewhere. 
       the dictionary entry for believe provides subcategorization information which sets a f l a g which requires that this constituent be followed by an np. an np in stap may consist of an n  a det-n sequence  a det-n-s sequence  or simply an s. the presence of the to following believe eliminates a l l but the s analysis of the required following np. in reentering the system at the s l e v e l   stap provides content information depending on what has already been analyzed indicating that the type of s we can anticipate is a declarative  not an imperative or a question. moreover  to enter the s state after the verb requires an np  or a dummy np which has been moved elsewhere; thus  the np-* is introduced. 
       at t h i s point the system  knows  that the topmost sentence has been passivized with the grammatical subject  the man  coming from an embedded sentence in the deep structure. at issue now is the deep structure analysis of t h i s embedded sentence. 	the 
fact that the f i r s t asp  have  is followed by a second  been signals that t h i s embedded s is also in the passive form. thus  when the verb shoot is encountered  beginning a vp  the system again expects to find a by-np which functions as the logical subject of the sentence someplace within this vp. in a d d i t i o n   following the verb shoot is an np-* which represents the deep structure position of the l o g i c a l object of this embedded sentence. in this example  by john immediately follows the verb  s a t i s f i e s the agent requirement  and the analysis of the embedded vp is completed. 
　　　　at this point in the system the embedded s t r a n s i t i o n has been s a t i s f i e d and the analysis of the top s continues; the passive agent has yet to be accounted for. since there are no more words in the input s t r i n g   the system  assumes  that this subject np has been deleted and provides the appropriate analysis  namely  an i n d e f i n i t e np  represented by someone in the l i n g u i s t i c l i t e r a t u r e .   if the example in  1  were ambiguous between john 
doing the believing or the shooting  then a second analysis of the sentence would be i d e n t i c a l to that just described except that the embedded s would have the deleted np and the top s would have the by john associated with i t . 
       the reason we believe that a reasonable deep structure grammar can be written in this form is that there is very l i t t l e permissible d i s t o r t i o n to an underlying cannonical form that a particular s can endure. from a l i n g u i s t i c point of view  the number of transformations which can apply to a particular s is r e l a t i v e l y small  usually only two or three. moreover  for each type of distortion-movement of constituents to the right or l e f t   permutation of constituents  deletion of constituents  and various combinations of these-it appears to be possible to determine not only what has occurred but to reconstruct the deep structure analysis. 
       for example  extraposition of the that-s sequence to form the sentence it is obvious that henry is mad from the deep structure order it that henry is mad is obvious is signaled by the sentence i n i t i a l i t . the i n i t i a l i t doesn f t require that extraposition has occurred but must be present if it has. similarly  with sentences such as there seems to be something rotten around here. left 
movement of an np such as in the passive construction in r e l a t i n g the man was seen by everyone with everyone saw the man is v e r i f i e d as soon as the was-past p a r t i c i p l e signifying the passive construction is analyzed. that the grammatical subject  e.g. the man  need not be the logical subject of the top level sentence is clear1 from the example sentence in  1  and the subsequent discussion and we have i l l u s t r a t e d how i t s correct deep structure analysis can be effectively handled. the logical subject in the passive case  if present  is of course signaled by the preceding by. permutation such as in questions usually results in an order of c o n s t i t u ents not included in the l i s t of deep structure cannonical structure analyses. these cases appear to be the easiest to recognize and deal with since the constituents involved are adjacent both before and after the permutation. deletion poses a d i f f e r e n t sort of problem since what is deleted is usually not simply a word but an entire phrase. 
       a case such as verb phrase complementation where the deep structure subject np and aux have been deleted is analyzed in figure 1. note that the required deep structure c o - r e f e r e n t i a l i t y between the direct object of persuade and the subject of go  the np  john  is indicated by a generated name np-1 used as identical subcategorial features associated with the two constituents. the embedded np r e f l e c t s none of i t s structure in our analysis; it is 
-1-
actually redundant since the f i r s t 
object np-1 contains the identical information. 
conclusion 
       we have described a syntactic analysis system which obtains the deep structure information associated with an input sentence. we believe that for the analysis of a sentence to be useful in a r t i f i c i a l intelligence this level of analysis must be available. the implementation u t i l i z e s a state t r a n s i t i o n network characterizing l i n g u i s t i c facts representable in a context free form  and a number of techniques to coae ana derive additional l i n g u i s t i c information and to permit the compression of the network size thereby allowing more e f f i c i e n t operation of the system. by recognizing iaentlcal constituent predictions stemming- from two uifferent analysis paths the system can determine the structure of this constituent only once. this both increases the efficiency of the system operation and permits use of l e f t recursive context free rules. when two alternative paths through the state t r a n s i t i o n network converge to a single state at some point in the analysis  subsequent analyses are carried out only once despite the earlier ambiguity. use of flags to carry feature concordance and previous context information allows merging of a number of lamost identical paths through the network. 
