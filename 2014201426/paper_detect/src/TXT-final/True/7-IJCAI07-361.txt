
when animals  including humans  first explore a new environment  what they remember is fragmentary knowledge about the places visited. yet  they have to use such fragmentary knowledge to find their way home. humans naturally use more powerful heuristics while lower animals have shown to develop a variety of methods that tend to utilize two key pieces of information  namely distance and orientation information. their methods differ depending on how they sense their environment. could a mobile robot be used to investigate the nature of such a process  commonly referred to in the psychological literature as cognitive mapping  what might be computed in the initial explorations and how is the resulting  cognitive map  be used to return home  in this paper  we presented a novel approach using a mobile robot to do cognitive mapping. our robot computes a  cognitive map  and uses distance and orientation information to find its way home. the process developed provides interesting insights into the nature of cognitive mapping and encourages us to use a mobile robot to do cognitive mapping in the future  as opposed to its popular use in robot mapping.
1 introduction
in robot mapping  one is concerned with the development of efficient algorithms for the robot  with its particular sensors  to simultaneously localize and map its environment. the map  a robot created  is precise. by  precise   it is meant that each surface encountered is remembered and its position is known with a certain degree of accuracy. the robot also knows its position in the environment. in contrast  the humans'  and animals'  mapping process  referred to as cognitive mapping  produces fragmentary maps initially which later turn into a representation laden with one's own interpretations and experiences of the world. the map produced in such a process is known as a cognitive map.
　the idea that animals compute cognitive maps was first suggested by tolman   who conducted experiments with rats finding their way in a maze. since then  much has been said about the complex nature of cognitive maps  see
e.g.   golledge  1   and several computational theories of cognitive mapping have been proposed  chown et al.  1; kuipers  1; yeap and jefferies  1 . more recently  researchers began to use mobile robots to test ideas about cognitive mapping as opposed to robot mapping.
　for example  kuipers and his students have been experimenting with robots to find ways to compute his spatial semantic hierarchy from the ground up  see e.g.   piers and kuipers  1  . both the gateway construct in the plan model of cognitive mapping  chown et al.  1  and the use of exits in the asr-model of cognitive mapping  yeap and jefferies  1  were tested on a mobile robot  see e.g.   kortenkamp  1  for the former and  jefferies et al.  1  for the latter . ideas about cognitive mapping based upon neurological findings were also being tested using mobile robots. examples of such work include gaussier et al.  1; hafner  1 . however  many of these attempts produced algorithms that were more an inspiration from observations about cognitive mapping than a test-bed for theories of cognitive mapping. these researchers were concerned that their robots were able to map its environments successfully and they thus solved much of the robot mapping problem. for instance  they were keen that their robots  close the loops  and produce  real world slam results .
　in this paper  our goal differs. we note that different animals compute cognitive maps using different sensors and therefore our robot should be treated as a kind of animal with its own peculiar sensing capabilities. for some unknown reasons  humans do not remember a precise map after one or two visits to a new environment. we assume animals do not too and so neither should our robot. to investigate our robot's cognitive mapping process  it is thus best to have our robot compute an imprecise map first and then investigate animallike strategies for finding its way home using such a map. it is argued that the behavior of such a robot might shed light on cognitive mapping.
　to do so  we use a robot equipped with sonar sensors to compute a description of each local space visited. the robot's  cognitive map  is thus a network of such local spaces. following  yeap and jefferies  1  theory of cognitive mapping  we refer to each local spaces computed as an absolute space representation  asr . with sonar sensors  the description of each asr computed  or more precisely  the shape computed  is not accurate enough to allow its identification on its return journey. our robot is not programmedwith powerful heuristics such as those found in humans. however  lower animals have been observed to use distance and direction information encoded in their cognitive map to find their way. we implemented two such strategies for our robot  one utilizes distance information and the other relative orientation information.
　section 1 describes the way our robot computes its  cognitive map . section 1 describes the two strategies that our robot uses to find its way home. section 1 shows the results of our experiments and sect. 1 concludes with a discussion of the insights obtained from our experiments.
1 mapping the environment
when exploring the environment for the first time  the robot creates a  cognitive map  of its environment. this section gives a short description of the process involved; details have been presented by  schmidt et al.  1a; 1b .
1 data gathering and pre-processing
the mapping process used in our system  a wandering robot that records sonar data  is as follows: the robot acquires sonar readings while moving until it runs into an obstacle. at this point an obstacle avoidancealgorithmis used  after which the robot can move forward again. using this input we build a simplified geometric map containing the robot movement path as well as linear surfaces approximated from the sonar data. in the first step  the recorded sonar data is low-pass filtered and converted to surfaces  being a piecewise linear approximation of the sonar distances. these surfaces are simplified further by grouping them  thus removing small gaps.
1 generating asrs
the approach for generating asrs from the data gathered by the robot is based on a region split and merge algorithm. the pre-requisite for this algorithm is a geometric map that contains the robot movement path as well as surfaces in terms of line approximations of the original range sensor data. the objective is to divide the perceived information  which is in the form of a fuzzy metric map  into a network of asrs  thus effectively creating a topological map on top of a metric one. splitting is done along the robot movement path  using an objective function that computes the quality of a region  based on criteria such as the average room width  corridors are long and narrow compared to rooms  and overall direction  e.g.  a corridor is separated from another one by a sharp bend in the wall . additionally  a regularization term is used in order to avoid the formation of very small regions  which may originate from missing  gaps  or unreliable sensor data. examples of maps including asr splittings are shown in the experiment's section  see fig. 1 . the result of this mapping stage will be called the original map further on. this is the map the robot will use for returning home.
1 finding the way home
1 re-mapping
on its way home  the robot basically performs the same data gathering and processing steps as described previously. in contrast to pure mapping  where all data is gathered first  and processed only once at the final position  i.e.  the return point   on the return journey the robot performs a map processing and asr splitting each time it has to stop  which is normally because of an obstacle in its way. this means that at each of these intermediate stops  a new map of the environment as well as a new high-level representation in terms of asrs is available and can be used in combination with the original map for localization. the result of the localization step is the index of the asr the robot believes it is currently in  which is a rough estimate of its global position. as it is argued in  yeap and jefferies  1   this estimate is sufficient for navigation  and an accurate map will not be necessary as long the robot can find the exits to adjacent asrs.
　in the following  we will describe the strategies that we use for localization based on asr information  and a data fusion algorithm that allows for an overall position estimate computed from the single localization methods.
1 localization strategies
two different strategies for localizing the robot based on the original map generated on its way to the current position are presented in the following. each method computes a local confidence map that contains a confidence value between 1 and 1 for each asr of the original map. note that these confidence values are not probabilities  and they do not sum up to one; the interval has been chosen for convenience  and different intervals can be used as desired. the two strategies mentioned previously will be described in the following  together with the method for computing local confidence maps independently for each strategy. the fusion of all local confidence maps  which may have been generated by different robot localization methods with varying reliability  is based on the idea of democratic integration introduced in  triesch and von der malsburg  1 . it was developed for the purpose of sensor data fusion in computer vision and computes confidence maps directly on images. the original method has been extended and embedded into a probabilistic framework in  denzler et al.  1   still within the area of machine vision. we extend the original approach in a way that we do not use images as an input  but rather generate local confidence maps using various  more or less reliable  techniques for robot localization. a main advantage of this approach is that the extension to more than two strategies is straightforward  as is the replacement of a method by another.
distance
the first strategy is based on the idea of using the distance the robot traveled from its return point to the currentposition  just as humans have a rough notion of how far they walked. note that neither do we care about an exact measurement  nor do we use the actual distance traveled as provided by odometry. using the odometry data directly would result in very different distances for each journey  as the robot normally moves in a zig-zag fashion rather than straight. instead we use distance information computed from the asr splitting of the maps  i.e.  asr length  which is defined by the distance between the entrance and the exit the robot used when passing through a particular asr. in the maps shown in fig. 1  start and end points of an asr are depicted by dark dots  split points  located on a set of connected lines representing the path the robot took. the zig-zag movement of the robot in between two splits is clearly visible  and can be quite different from the line connecting start and end points. the basic strategy is now to compare the distance d traveled when returning home  measured in asr lengths taken from the intermediate map computed on the return journey  to the asr lengths taken from the original map computed during the mapping process.
　the local confidence map cdist （ irn  n being the total number of asrs in the original map  is computed as follows: the confidence for each asr depends on the overall distance d traveled on the return journey; the closer an asr is to this distance from the origin  the more likely it is the one the robot is in currently. as the distance traveled is an unreliable estimate  adjacent asrs should be considered as well  the more the closer they are to the most likely one. we decided to use a gaussian to model the confidences for each asr  the horizontal axis being the distance traveled in mm. the gaussian is centered at the current overall distance traveled d. its standard deviation σ is dependent on the distance traveled  and was chosen as σ = 1d. note that although a gaussian is used here  we do not try to model a probability density. a gaussian was rather chosen for a number of reasons making it most suitable for our purpose: it allows for a smooth transition between asrs  and the width can be easily adjusted by altering the standard deviation. this is necessary as the overall distance traveled gets more and more unreliable  due to slippage and drift  the farther the robot travels. the confidence value for an asr is determined by sampling the gaussian at the position given by the accumulated distances from the origin  i.e.  where the robot started the homeward journey  to the end of this asr. after a value for each asr is computed  the local confidence map cdist is normalized to the interval  1 .
relative orientation
the second method for computing estimates of the robot's position with respect to the original map is based on using relative orientation information generated while dividing the map into asrs. during its journey  the robot enters an asr at one location and exits at a different one  usually including zig-zag movements in between. we define the direction of an asr as the direction of the line connecting the entrance and exit points. certainly this direction information varies every time the robot travels through the environment but the overall shape between adjacent asrs is relatively stable. therefore  we propose to use angles between asr directions as a simple measure of the current position of the robot. note that this information is pretty much useless on its own  because the same angles  i.e.  direction changes  can be found in different locations of the environment. however  combining this strategy with others can help to decide between position estimates that would otherwise be indistinguishable. it has the advantage that angles between adjacent asr directions are a local measure of direction changes  thus keeping the influence of odometry errors due to drift and slippage to a minimum.
　the basic idea of the strategy is as follows: firstly  all angles α1 ... αn 1 between adjacent asrs in the original

figure 1: maps showing the actual layout of the building used for experiment 1  top  and experiment 1  bottom . the path the robot took while generating the original map is shown as a solid line  with 'x' marking the starting location of the experiment. the dashed line visualizes the path the robottook on the homeward journey and 'o' marks its starting point.
map are computed. this can be done offline  as this map is fixed during the homeward journey. in the re-mapping process while going home  new asrs are computed in the new map based on data gathered while the robot travels. using the direction information contained in this map  the angle β between the current asr and the previous one can be computed. comparing this angle to all angles of the original map gives a clue  or many  for the current location of the robot. the comparison of angles and conversion to confidence values is done by computing the cosine of the difference angle  and mapping the resulting values to the interval  1   which results in a local confidence map cdir:
cdir
this results in high values for similar angles and low values for dissimilar ones. the confidence map computed this way can already be used for further processing. since the overall reliability of the relative orientation strategy as described above is rather low compared to the confidence values from other methods  in this case using distance information   we currently reduce the confidence values by half.
1 fusion of strategies
we will now describe how to merge the separate local confidence map into a single global one based on the original democratic integration approach published by  triesch and von der malsburg  1 . the basic idea is straightforward  as the fusion is done by computing a weighted sum of all local confidence maps. the main advantage of using democratic integration becomes visible only after that stage  when the weights get adjusted dynamically over time  dependent on the reliabilities of the local map. given m local confidence maps cloci t  at time t  i.e.  as in our case two  namely cdist and cdir  generated using different strategies  the global map cglob t  is computed as:
	cglob	 	 1 
where wi t  are weighting factors that add up to one.
　an estimate of the currentposition of the robotwith respect to the original map can now be computed by determining the largest confidence value in cglob t . its position b in cglob t  is the index of the asr that the robot believes it is in. the confidencevaluecglobb at that index gives an impression about how reliable the position estimate is in absolute terms  while comparing it to the second best one  and maybe even third best one  shows the reliability relative to other asrs.
　in order to update the weighting factors  the local confidence maps have to be normalized first. the normalized map  is given by:
		.	 1 
the idea when updating the weights is that local confidence maps that provide very reliable data get higher weights than those which are unreliable. different ways for determining the quality of each local confidence map are presented in  triesch and von der malsburg  1 . we use the normalized local confidence values at index b  which has been determined from the global confidence map as shown above  i.e.  the quality qi t  of each local map cloci t  is given by locb . normalized qualities are computed by:
		.	 1 
the new weighting factors wi t + 1  can now be computed from the old ones:
		.	 1 
this is a recursive formulation of the average over all qualities from time zero to t. using this update equation and the normalization of the qualities in  1  ensures that the sum of the weights equals one at all times.
1 experimental results
to evaluate the performance of the algorithm proposed  we used a pioneer 1 robot from activmedia  equipped with sonar sensors and an odometer. as described earlier  the robot must first exploreand generate a representationof the environment  i.e.  a  cognitive map . the robot was then instructed to return home  home being the start point of the mapping process . the aim was to determine whether the robot can find its way back home using this inexact  cognitive map .
　we conducted various experiments in an office environment  two of which are presented in this paper. further experimental results can be found in  schmidt et al.  1b . figure 1 presents the layouts of the environment used. the paths that the robot took during mapping  solid line  and going home  dashed line  are both shown in fig. 1 as well. for the mapping stage  the robot started at the location marked by
1
1
1
1
figure 1: top: experiment 1  bottom: experiment 1. left: original maps  right: maps generated during the homeward journey. the black dots indicate the points where the map is split into separate asrs. the robot movement always starts at the origin. the origin of the homeward journey is  approximately  the same position as the end point coordinate of the respective original map; in particular this means  that the map of the homeward journey for experiment 1  bottom right  is upside-down compared to the original map  bottom right .
'x'  and was stopped at a random position  marked by 'o'   where it started returning home. the return journey stopped when the robot believed that it reached home  or  more precisely  the asr that contains the start location 'x'. it is important to note that we did not intervene with the environment at any point in time. that is  things that existed in the environment during the mapping process  such as rubbish bins  flower pots  cabinets  etc  may or may not be there during the return home journey; and doors may be open or closed depending on the time of the experiment.
　figure 1 shows the representations generated from the two experiments. the top row depicts the maps generated from the mapping and going home processes respectively for experiment 1; the bottom row are the maps generated from the mapping and going home processes respectively for experiment 1. comparing the maps generated during mapping and going home highlights the difficulty in using these maps directly for localization. each time  the robot goes through the same environment  it will generate different representations due to sensory inaccuracies. figures 1 and 1 show the confidence maps computed at four locations during the return home journey for experiments 1 and 1 respectively. the light dotted lines shows the asr estimate using the asr length information  distance method  and the dark dashed lines depicts the asr estimate using the angles between asrs  relative orientation method . the solid line is the overall asr estimate for the corresponding asr  horizontal axis . note that the confidences have values between 1 and 1  vertical axis  but do not sum up to 1. in fig. 1  the top left map shows a narrow peak for the overall confidence at asr 1  with cor-

figure 1: confidence maps at four locations during the return home journey for experiment 1: distance  light dotted   relative orientation  dark dashed   and overall map  solid . horizontal axis: asr number; vertical axis: confidence  1 to 1 .

figure 1: confidence maps at four locations during the return home journey for experiment 1: distance  light dotted   relative orientation  dark dashed   and overall map  solid .
responding peaks for both distance and relative orientation. the narrow peak signifies the robot being very confident of being in asr 1. the top right map however is quite different. it has two peaks  one slightly higher than the other. it shows that the robot is around the transition region between asr 1 and 1. the higher confident value for asr 1 shows that the robot feels that it has already moved into asr 1. the bottom left map shows a similar account except that this time  neighboring asrs  1 and 1  have higher values  resulting in a wider peak. finally  the bottom right map shows that asrs 1 and 1 pretty much have the same confidences  meaning the robot is unsure which of the two asrs it is in. figure 1 shows another set of confidence maps corresponding to four locations in experiment 1. figure 1 shows a sequence of four consecutive confidence maps from experiment 1. these confidences are taken from the period when the robot is traveling from asr 1 to asr 1. starting from top left figure  the robot is confident it is in asr 1. as it moves to the boundary between asrs 1

figure 1: four consecutiveconfidencemaps computedduring the return home journey for experiment 1 at the transition from asr 1 to 1: distance  light dotted   relative orientation  dark dashed   and overall map  solid .

figure 1: adjustment of weighting factors over time: asr length weights  solid  and asr angle weights  dashed .
and 1  it is unsure of where it is exactly  as depicted by the top right and bottom left images. and when it has moved away from the transition area  the confidence of asr 1 decreases dramatically and the peak is now centered on asr 1.
　figure 1 shows the distribution of weighting used on the localization strategies for calculating the overall confidence values. the solid line is the plot of distance method weights and the dashed line represents the weights of the relative orientation method. for the first three asrs  the weights for both distance and orientation are initialized to be 1 because we only start computations after the third asr. the asr distance weight then increases  because the confidence on asr distance is higher than the confidence computed from the orientation method. as time progresses  the weights of the distance method decrease due to a decrease in confidence  and vice versa for confidence from the orientation method.
　the results from the confidence maps show that the method proposed provides a consistent approach for using an inexact  cognitive map  to allow a mobile robot to find its way back home. it does not provide the exact pose of the robot in the environment  but rather an approximation  which we believe is sufficient for navigation and new exploration.
1 conclusion
we have implemented a very basic algorithm for the robot to find its way home  namely exploit asr-distance traveled to re-trace its movements to return home and comparing the relative orientation between adjacent asrs.
　anecdotal evidence suggests that one is aware of significant turns in a journey and we thus program our robot to extract such information from its cognitive map. it turns out that in the journeys experienced  such information does not provide much help for the robot to locate itself. in the future  we would like to investigate how the robot could orient itself from the home position and how such more general orientation could be used to find one's way home. much has been discussed with respect to the use of distance information in cognitive mapping. for example  numerous experiments with chickens and pigeons have shown that they are able to use both absolute and relative distance in their search for food  e.g.   cheng et al.  1  . experiments with bees and ants have shown that they can perform internal calculations of the distance and direction traveled to perform path integration  e.g.   cornell and heth  1  for a general discussion . most of these experiments were concerned with the actual distance traveled and how the individual species deal with the errors in their measurements  as do most work on robot mapping to date. using our robot  we have shown another way of using distance information  namely asr-distance traveled as opposed to actual distance traveled.
　asr-distance is obtained from the shape of the asr computed. in the past  there has been scant evidence that humans/animals do pay attention to the shape of each local environment or  in our terminology asr  very early on in their initial exploration of a new environment. however  the debate has now intensified and this is especially true in the animal literature where the problem is commonly referred to as geometry in animal spatial behavior  see  cheng and newcombe  1  . in many of these experiments  a relocation task utilizing a box-shaped environment is used  and the principal axes of the environment appear to be most useful. our work here emphasized yet another possibility  namely using a straight line distance between exits of interests in an asr. a remark is worth making regarding the surprisingly good results obtained in our experiment. although our robot was allowed to wander on its own during all the trials  it managed not to enter any of the rooms. consequently  the robot appears to be constantly moving forward along the corridor and this might have accounted for much of the success of the experiment. this was not planned. it would be interesting to see how the resulting asrs would be if the robot enters  say  the middle room and explores the space in it. nonetheless the current work has shown how we might use a mobile robot to investigate more cognitively oriented strategies in cognitive mapping.
