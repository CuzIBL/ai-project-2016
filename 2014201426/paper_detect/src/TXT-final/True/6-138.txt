 
we examine the approach of encoding planning problems as csps more closely. first we present a simple csp encoding for planning problems and then a set of transformations that can be used to eliminate variables and add new constraints to the encoding. we show that our transformations uncover additional structure in the planning problem  structure that subsumes the structure uncovered by graphplan planning graphs. we solve the csp encoded planning problem by using standard csp algorithms. empirical evidence is presented to validate the effectiveness of this approach to solving planning problems  and to show that even a prototype implementation is more effective than standard graphplan. our prototype is even competitive with far more optimized planning graph based implementations. we also demonstrate that this approach can be more easily lifted to more complex types of planning than can planning graphs. in particular  we show that the approach can be easily extended to planning with resources. 
1 introduction 
a powerful technique for solving planning problems  first used in  kautz and selman  1   is to impose a fixed bound on plan length. this converts the problem to one that lies in np. the resulting problem can then be solved by encoding it in any of a number of alternative np-complete formalisms  e.g.  sat  kautz and selman  1   integer programming  vossen et ai% 1   or constraint satisfaction 
problems  csps   van beek and chen  1; do and kambhampati  1   and then using the powerful algorithms that have been designed to solve these general problems. 
　in this paper we examine the approach of encoding planning problems as csps more closely. we use a very simple encoding to translate the planning problem into a csp. the advantage of using csps in general  and our encoding in particular  is that it preserves much of the structure of the original planning problem  and thus various transformations that utilize this specific structure can be applied to create a new csp that is easier to solve. 
　the utility of exploiting planning specific structure has been convincingly demonstrated by the blackbox  kautz and selman  1  and gp-csp  do and kambhampati  1  planners. these systems encode a transformed representation of the planning problem called the planning graph to sat and csp respectively. the planning graph is a planning specific construction  due to  blum and furst  1   that computes and represents some important additional structural information about the planning problem. thus by encoding the planning graph rather than the original planning problem  blackbox and gp-csp are able to capture more of the structure of the planning problem in their encoding  which results in a significant improvement in performance. 
　in our approach we bypass the construction of a planning graph. instead  we study techniques that can equally well exploit the structure of the planning problem and at the same time work directly on the csp encoding. we demonstrate that it is possible to develop transformations that uncover all of the additional structure obtained from planning graphs. 
　the advantage of our approach is that it works directly on a much richer and more robust representation. consequently we obtain at least three important advances over the planning graph construction:  1  our approach allows us to generalize planning graphs. in particular  we can enhance our approach to extract other kinds of structure to allow us to solve the planning problem more efficiently.  1  we can more easily extend our approach to more complex types of planning problems  e.g.  those involving resource usage.  1  since the final result is a csp we can automatically utilize csp solution techniques which can be more powerful than standard graphplan searching methods. in the paper we will provide evidence for all of these points. 
　first  we present our csp encoding of a planning problem. then we present a set of transformations that can be used to eliminate variables and add new constraints to the encoding  and show that these transformations subsume and generalize planning graphs. then we present empirical evidence to validate the effectiveness of our approach to solving planning problems. to demonstrate that our approach can be more easily lifted to more complex types of planning  we show how it can be easily extended to planning with resources. finally we close with some conclusions and a description of future work. 
1 generating the base-csp 
to encode a planning problem as a csp we impose a bound on the  size  of the plan. in this paper we will measure 
planning 
plan size by the number of graphplan-concurrent steps  gpsteps  in the plan. it will become apparent in the sequel what gp-steps means. 
　in k gp-steps each proposition or action can change at most k times. so to encode a k gp-step plan in a csp we can utilize fc -f 1 sets of propositional variables and k sets of action variables where s ranges from 1 to k for propositions and 1 to k - i for actions  and i and j range over the number of distinct propositions and action instances in the planning problem respectively. each of these variables will be boolean. intuitively  means that proposition p{ is true at graphplan step s  and means that action instance 
aj was executed at graphplan step s d e n o t e the opposite . 
　clearly by setting each of these variables we can capture any  gp-step plan and its effects. however  many illegal plans and nonsensical outcomes are also captured. we need constraints to ensure that any solution to the csp  i.e.  any setting of the variables that satisfies all of the constrains  is a legal plan. there are various possible sets of constraints that can serve our purpose. here we present one particular set: 
1. unary initial state and goal constraints. the dropositional variables from step zero  and from step are required to have values compatible with the initial and goal states of the planning problem. 
1. precondition constraints. an action  cannot be true unless its precondition is satisfied. this rives the constraint 
where pre precondition rela-
tive to gp-step s. 
1. successor state constraints. implicit in classical planning representations is the frame assumption: predicates not mentioned in the action's description are unaffected by the action. we can capture the effects of actions  including the implicit non-effects in a number of different ways. here we use reiter's formulation of successor state axioms  reiter  1 . in particular  for each propositional variable at gp-step s  a   1  we have a constraint between it and the same proposition at gp-step .s-1. the constraint says that is true if and only if some action made it true  or it was previously true and no action made it false. thus the successor state axiom constraints take the form: 

where creatc pl  and delete pt  are the set of actions that create and delete p{. it is easy to automatically generate a set of successor state constraints from a set of strips action descriptions. additionally  by using successor state constraints that mention additional propositions from step .s-1  it is easy to encode adl  pednault  1  operators as a set of successor state axioms.1 
   'note that the successor state constraints do not encode the action preconditions. these arc encoded as separate constraints. thus  the only complication with adl actions has to do with conditional effects. if pi is a conditional effect of action subject to the condition the successor state constraint will have a disjunct 
　　　　　 . that is  will be true if  was executed and condition held at the previous step. 
planning 
1. gp-concurrency constraints. the above successor state axiom allows the unintended model in which we have two actions at the same step  one creating a proposition and one deleting it. to avoid such unintended solutions we must restrict concurrent actions in some way. the most natural way is a serial constraint  which says that only one action variable can be true at any step.1 another type of constraint is one that imposes graphplan concurrency. basically it asserts that two actions cannot be simultaneously true if they interfere with each other. in this work we have chosen to use the graphplan  gp  concurrency constraints. 
1. non-null steps constraints. we impose the constraint that for every step s at least one action variable should be true. this blocks null steps in the plan  in contrast lblum and furst  
1  and  do and kambhampati  1  both allow null plan steps. 
　we will refer to this set of variables and constraints as the bask-csp. any solution to the basr-csp will contain a setting of the action variables that comprises a valid gpconcurrent plan. if the base-csp has no solution then no k gp-step plan exists for the problem. 
1 reduction of the base-csp 
given a base-csp representing a k-step planning problem we can use various transformations to modify it  generating a new csp that is empirically easier to solve  and that is equivalent to the base-csp in the sense that any solution to the new csp can easily be extended to a solution to the original base-csp. these transformations include inferring new constraints that can be added to the csp and eliminating various single valued variables. our transformations are related to the well known techniques of enforcing local consistency on a csp prior to solving it  freuder  1   however they are based on taking advantage of the specific logical form of the above set of constraints. 
1 adding graphplan mutex constraints 
a well known technique for making csps easier to solve is to add redundant constraints  e.g.   getoor et ai  1   which are constraints that make explicit additional relations between the variables. redundant constraints that are useful to add are usually determined by examining the structure of the particular csp. this is precisely what is done in planning graphs  where insights into the manner in which actions and propositions interact  are used to generate a new set of binary constraints called mutexes. 
　new binary constraints can be added to a csp by enforcing  consistency  freuder  1 . a csp is  consistent if 
for every valid assignment to a pair of variables  there is a set of values for every  additional variables such that the assignments satisfy all of the constraints over these variables. making a csp consistent can be very expensive as it involves testing all sets variables  and each test in the worst case takes time exponential in in planning problems there can be thousands of variables  so it would be impossible 

to make the entire base-csp consistent even for small the contribution of graphplan is that it demonstrated a technique that quickly achieves a very effective partial form of consistency over a limited collection of  variables. we can use the csp representation to directly compute the binary mutex constraints generated by planning graphs. in this manner we lift the mutex computation to a more general framework where it can be more easily generalized. 
mutexes in graphplan are generated by three simple rules: 
 1  base action mutexes. actions in the same gp-step with interfering effects and preconditions are mutex.  1  addi-
tional action mutexes. two actions in the same gp-step are mutex if there is a pair of propositions  one from each action's preconditions  that are mutex at this gp-step.  1  propositional mutexes. two propositions  and at the same gp-step  are mutex if every action that achieves is mutex 
with every action that achieves we can create all of these as in planning graphs  we can use the constraints added binary constraints by testing for very similar conditions in the at step to test for new mutex constraints at step the 
csp encoded planning problem: 	following result can then be easily proved  we omit the proof 
for reasons of brevity . 
base action mutexes. these mutexes are already present proposition 1 // the planning graph construction has dein the bash-csp; they are the gp-concurrency constraints. tected a mutex constraint between two variables and  action or propositional variables   then after transforming the bash-csp to add the above mutex constraints we will have that either both variables in the csp will have become single valued with not both being true or  h  there will be binary constraint in the csp between these variables that prohibits them from both being true. 
that is  the transformed csp will capture all of the planning graph mutexes. furthermore  it might contain more mutexes than those inferred by the planning graph. in the simplest case this can arise from the last case presented above where every action deletes one of or this can create a new mutex in the middle of the plan. in planning graphs  on the other hand  once and appear in the graph without a mutex between them  they can never become mutex again  due to the presence of no-ops and the possibility of null steps in the plan . 
propositional mutexes. for propositional mutexes we have one added complication  which is that our encoding  unlike planning graphs  does not utilize no-ops. nevertheless  a general condition for when two propositions and are mutex can be given by examining the three cases. 
　our translation from a planning problem produces a basbcsp in which every constraint c is represented symbolically by a logical formula. we can simplify this logical formula directly by replacing the single valued variable v by its value  and then performing standard logical reductions  e.g.  

false etc. this yields a new logical formula that represents the reduced constraint c . 
　in the case of the bash-csp we also know the form of its different constraints. this allows us to precompute many types of constraint reductions  so we can realize many types of single valued variable reductions more efficiently. 
　the reduction of a single valued variable  or the application of some of the other transformations described below  might generate new single valued variables that can in turn be reduced. it can also interact with the generation of mutex constraints  allowing new mutexes to be detected. for example  say that we have determined that a propositional variable 
	must be false. if 	appears in any conjunctive precon-
ditions  e.g.  	wc will also immediately infer 
i.e.  that. 	has also become single valued  false . with 
false it can no longer be a candidate for producing some other proposition   and we could possibly infer a new mutex involving since one of the ways of making it true is now blocked. with mutexes  single valued variable reduction subsumes reachability analysis of planning graphs. 
proposition 1 the variables that remain in the csp after single valued variables have been reduced  are a subset of the variables appearing in the planning graph. 
1 beyond graphplan 
besides subsuming  and slightly generalizing  the planning graph inferences  further transformations can be utilized on the csp. these transformations either add more constraints to the csp or cause further variables to become single valued. in either case  like the planning graph inferences  they are used to make the csp easier to solve. these additional constraints can also feed into the standard graphplan reductions described above  and thus generate even further mutexes. 
1 	additional binary constraints 
graphplan mutexes only prohibit the single pair of values for two variables  truh true . our representation treats negated propositions and actions in an entirely symmetric fashion. this means that the analysis for mutexes given above will allow us to compute mutexes between any two values. 
for example when applied t o b e i n g mutex with means that is  with i.e.  these variables must both be true or both be false. such binary constraints can be detected and added to the base-csp. 
1 single valued variable reduction beyond graphplan reachability 
as demonstrated above  single valued variable reduction is as powerful as the reachability analysis inherent in the planning graph construction. however  in the csp encoding it is more powerful  obtaining  for example  the following additional reductions: 
1. propositions that are never modified by any action  are propagated without change in the planning graph. since these propositions have no creators nor deletors  their successor state axiom reduces all of them to being equivalent to their status in the initial state  i.e.  they will all 
planning 
become single valued. thus they can be reduced from the csp prior to searching for a solution. 
1. if all possible actions at step s create proposition then is forced to be true. similarly if it is deleted by all possible actions then it is forced to be false  can then be reduced from the csp. this particular reduction is not possible in planning graphs due to the presence of no-ops. 
1. variables that are forced to be true further reduce all variables that are mutex with them to be false. this does not help reduce a planning graph since in planning graphs mutexes are monotonically decreasing and  other than the initial state variables  variables are never forced to be true.1 but in the csp encoding the previous rules for forcing a variable to be true  and for creating a new mutex when it did not exist at the previous step  enable additional single valued variable reductions. 
1 	sequence constraints 
there are some additional constraints that can be imposed on plans to rule out obvious inefficiencies. for example  it never makes sense in the plan to immediately follow an action by its inverse  e.g.  a load followed by an unload . adding this constraint allows eliminating different invalid combinations of actions by making mutex any inverse pairs of actions at consecutive time steps. 
　blocking the immediate sequencing of inverse actions also allows us to infer additional sequence constraints. say that actions and are inverses of each other  and that  is the only action that produces  while aj is the only action that deletes it. then another constraint that can be inferred from the mutex between and is that when first becomes true  it must remain true for at least one more time step: 
there is also a similar constraint for when first becomes false. 
　our system automatically detects action pairs that are inverses of each other as well as any predicates over which a sequence constraint can be imposed. 
1 	csp-plan: implementation 
based on the transformations explained before  we have developed a planner called csp-plan that will find a solution to a planning problem. csp-plan builds the base-csp incrementally up to step s  beginning with s = 1   and then sends it to a csp solver for its solution. if the solver reports no solution to it  then the bask-csp is constructed for s+l. this cycle can continue until some termination condition has been reached or a plan has been found. it is important to notice csp-plan solves these problems incrementally  thus ensuring that it finds a gp-step optimal plan. 
the csp solver used by csp-plan is efc  katsirelos and 
bacchus  1  which allows the use of different techniques 


problem gac gaccbj gacvscbj record nogoods bw-large-1 1 1 1 1 bw-large-a 1 1 1 1 rocket-a 1 1 1 1 rocket-b 1 1 1 1 dnverlog1 1 1 1 1 driver log1 1 1 1 1 |driver log1 1 1 1 1 drivcrlog1 1 1 1 1 dnverlog1 1 1 1 1 
| problem dom+deg bsearch bw-large-1 1 1 bw-lnrge-a 1 1 | rockct-a 1 1 rockct-b 1 1 dnverlog1 1 1 dnverl.og1 1 1 dnvcrlog1 1 1 driverlog1 1 1 dnvcrl.og1 1 1 i problem no redundant constraints inverse mutexes sequence constraints log-a 1 1 1 log-b 1 1 1 rockct-a 1 1 1 rockct-b 1 1 1 gripper-1 1 1 1 gripper-1 1 1 1 table 1: effect of changing the dvo heuristic on the performance of the csp solver for planning problems. experiments were run using gacvscbj+recordnogoods 
table 1: effect of adding mutexes between inverse actions and sequence constraints to the base-csp. 
dvo heuristics  the addition of redundant constraints  the removal of single valued variables  etc. the addition of redundant binary constraints  particularly mutexes  and the detection and removal of single valued variables has a clear and dramatic effect on the efficiency of csp-plan  even for simple problems. for example  on bw-large-1  the base-csp has 1 variables and 1 constraints  but only 1 variables and 1 constraints after single valued variables are removed. similarly  without the inferred mutex constraints and the removal of single valued variables  csp-plan required 1 sec. to solve the problem. adding the mutex constraints reduced this time down to 1 sec  and removing single valued variables brought the time down even further to 1 sees. the effect of some of the other planning specific techniques is described below. 
dvo heuristic: the order in which variables are instantiated during search greatly affects the solution times for a csp. table 1 shows the difference in performance between the standard csp heuristic  and our bsearch heuristic which was designed specifically to take advantage of the planning based structure of the csps that csp-plan is solving. these representative problems show that bsearch performs much better than dom+deg. 
redundant constraints: table 1 shows the performance of csp-plan when mutexes between inverse actions and sequence constraints are added to the base-csp. on these problems we see that there is a slight improvement in cspplan when mutexes between inverse actions are present. interestingly  adding sequence constraints did not help. minor improvements on some problems were negated by significant degradation on others. 
	1 	comparison with similar approaches 
the results in table 1 show how csp-plan  using the same setting for all problems 1 compares with graphplan  blum 

problem csp-plan g k a p h p l a n gr-csp black box lpp 1  dw-largc-a 1 1 1 1 1 bw-large-b 1 1 1 1 1 gripper-1 1 1 1 1 1 gripper-1 1 1 1   1hn . 1 1 1 log-a 1 1.1 1 1 1 log-b 1 1 1 1 1 rocket-a 1 1 1 1 1 roekct-b 1 1 1 1 1 depots1 1 1 1 1 1 depots1 1 1 1 1 1 drivcelog1 1 1 1 1 1 driverlog1 1 1 1 1 1 driverlog1 1 1 1 1 1 zcnotrave1 1 1 1 1 cnf zenotravel1 1 1 1 1 cnp zenotravei1 1 1 1 1 cnp zenotravel1 1 1 1 1 cnp zenotravel 1 1 1 1 1 1 cnp satellite 1 1 1 1 1 1 satclhle1 1 1 1 1 1 satellite1 1 1 1 1 1 1 1 freccelll 1 1 1 1 1 table 1: comparison of csp-plan with graphplan  gpcsp  blackbox and ipp on a set of problems from the 
strips domain.  cnf' means could not parse. lowest times are in bold. 
and furst  1   gp-csp  do and kambhampati  1   blackbox  kautz and selman  1  and ipp 1  koehler et al  1 . these planners have in common the construction of a planning graph. the planning graph is either then compiled into a csp  gp-csp  or a sat formula  blackbox   or searched directly for a solution  graphplan and ipp 1 . csp-plan  on the other hand  bypasses the planning graph construction and directly exploits the csp encoding of the problem as explained above. 
　it can be seen that csp-plan yields significantly better performance in almost all cases over the standard planning graph planners graphplan and gp-csp. this provides evidence of the effectiveness of the additional constraints and reductions computed by csp-plan. the results against blackbox are mixed. this version of blackbox utilizes the highly engineered zchaff  moskewicz et al  1  sat solver. zchaftutilizes very different heuristics and techniques for learning nogoods  clauses  than csp-plan and is more efficient that our current csp code on larger problems. nevertheless  there is considerable scope for making our cspplan implementation more efficient  and our heuristics are at this stage very simple. even so  our approach demonstrates its usefulness on problems like gripper. 
　similarly against ipp our results are mixed. a key component of ipp is a method for solving planning problems by dividing them into a set of smaller problems using a goal agenda  koehler  1b . this technique is particularly effective on domains like blocksworld  depots and gripper  and it can easily be recast in terms of csps. hence  csp-plan could be extended to utilize this technique. on other domains like logistics csp-plan is more effective. this is due particularly to the presence of mutexes between inverse actions in these domains that can be effectively used by csp-plan. on different domains. 
mirsopt level time steps acts res 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 c'sp-pl an 1 1 1 1 table 1: effect of changing the optimization value for mips. 
each value in this table is the sum of the results for driver-
log 1 to driverloglo.  res : resource usage   steps : number of gp-steps  and  acts : number of actions in the plan. 
1 extensions: planning with resources 
a major advantage of encoding planning problems as csps is that we can easily extend the encoding to represent more complex planning problems. for example  planning problems with resources can simply be represented as csps with numeric variables. to demonstrate the flexibility of our approach we implemented an extension of csp-plan to deal with such planning problems. previous approaches based on planning graphs  e.g.   koehler  1a   have had to develop from scratch methods for dealing with the resources variables in the planning graph  like interval arithmetic and bounds propagation. these techniques are already well known in the csp field. 
　to handle planning with resources we introduced the following into csp-plan:  1  mathematical operation constraints  e.g.   1  comparison constraints  e.g.  
 1  precondition constraints containing comparisons  
e.g.  fuel  truck   1  successor state constraints to define how the numeric variables could change between states  e.g.  if no action affecting it is true  its value cannot change;  1  and finally  additional concurrency constraints to block actions from simultaneously altering a numeric variable. these new constraints were very easy to add to the base-csp  and the reduction transformations described above were used almost unchanged to simplify the bask-csp. 
　we compared csp-plan with mips  edelkamp  1  1 to evaluate its performance on resource planning problems. mips combines two paradigms  model checking and heuristic search  to find totally ordered plans that are then made concurrent using a post-processing procedure. this combination of paradigms introduces additional complexity to the algorithm  in contrast with the uniform paradigm used in our approach. mips tries to minimize the number of steps in the final plan  using an optimization parameter that ranges from 1 to 1. table 1 shows this how parameter affects the quality of the final plans in mips. increasing the parameter causes mips to spend more time trying to find plans with fewer steps. however  this search is not always successful. in fact mips can spend more time and generate worse results. csp-plan  on the other hand  is an optimal planner always finding the shortest plan in terms of number of gp-steps. this is a sightly different optimization criteria from that used by mips. however  even under mlps's optimization criteria csp-plan s plans are much better than those found by mips.1 
　table 1 compares both planners  mips running with its optimization flag set to 1 . the results in this table show that 

csp-plan mips problem time steps acts res time steps acts res depotsl 1 1 1 1 1 1 1 1 depots1 1 1 1 1 1 1 1 1 driverlogl 1 1 1 1 1 1 1 1 driverlog1 1 1 1 1 1 1 1 1 driverlog1 1 1 1 1 1 1 1 1 driverlog1 1 1 1 1 1 1 1 1 driverlogs 1 1 1 1 1 1 1 1 dnvcrlog1 1 1 1 1 1 1 1 1 driverl.og1 1 1 1 1 1 1 1 1 driverlog1 1 1 1 1 1 1 1 1 driverlog1 1 1! 1 1 1 1 1 1 driver log1 1 1 1 1 1 1 1 1 table 1: performance comparison of csp-plan and mips on resource planning problems.  res    steps  and  acts  as explained in table 1. 
csp-plan has a performance comparable to mips  and in most cases  the quality of the plans  number of steps  is considerably better. however  csp-plan does not scale as well as mips  e.g.  it takes much longer than mips on driverlog l1. but is not surprising since csp-plan is an optimal planner while mips is not. achieving optimality quickly becomes very difficult. it is also important to note that our prototype implementation uses very simple techniques to propagate numeric variables. these techniques are far from the current state of the art in csps. nonetheless  we see that we still obtain results competitive with the competition version of mips. 
1 conclusions 
our implementation of csp-plan has demonstrated that the structure of planning problems can be exploited directly in a csp encoding. by lifting the planning problem to a csp we obtain a richer and more robust representation for which many sophisticated and effective solution techniques have been developed. in particular  we are able to capture and generalize the important inferences generated by planning graphs directly in the csp representation. this provides excellent performance for csp-plan in comparison with similar techniques. additionally  by showing how easily we can extend our representation to planning with resources  we have provided evidence for the benefits of lifting the problem to a csp encoding. 
　this work naturally leads to a number of future research topics. for example  the fastest current planners are based on local search. nevertheless  the heuristics used in these planners utilize notions from the planning graph construction. it seems feasible that instead of planning graphs  csp techniques could be utilized directly to compute better heuristics. this could be particularly beneficial for computing more informative admissible heuristics. better heuristics and additional transformations could also be explored. in particular  there is still much scope for improving the performance of this approach. finally  the approach is well suited to resource usage optimization using branch and bound techniques during the search  and this could be further investigated. 
extended to deal with resources in this competition. 
1note that neither planner is actually trying to optimize resource 
usage  just the size of the plan. 
