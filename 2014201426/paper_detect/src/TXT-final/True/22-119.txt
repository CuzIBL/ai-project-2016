 
 explanation-based learning  - i.e.  incorporating new redundant rules suggested by earlier problem solving experiences - is an attempt to speed up problem solving. unfortunately  the resulting systems are not always more efficient on subsequent problems. this paper describes  analytically  whether these new rules should be added  and if so  where they should appear in the overall derivation strategy. while this task is intractable in general  we present several interesting special cases which can be solved in time  essentially  linear in the number of rules in the system. 
1 	motivation 
general problem solving  a.k.a. deduction  is expensive. there can be a combinatorial number of potential  solution paths  for a given query/goal - as there can be many rules/operations which each reduce the goal to a new set of subgoals  and each of these subgoals can  itself  have many possible reductions  etc.  genesereth and nilsson  1 . 
　there are several approaches to this problem. one involves ordering the set of rules  so the first rule selected for a given  sub goal is the one viewed as most cost effective. for example  given the kbg knowledge base  whose rules appear in figures 1 and 1  we may specify that the rule rpm should be used before the rule rpf when determining abe's parent - i.e.  when seeking an x such that parent  abe x  holds. there can  of course  be many comprehensive  derivation strategies  - i.e.  many ways of searching this knowledge base  each guaranteed to find a solution  if one exists. our objective is to find the one which requires the least expected time. 
 we describe this  expected time  cost below.  
　another approach involves adding redundant information to the knowledge base  in the form of a  new  rule. using kbg again  we observe that the solution to the guardian  abe bart  query involved the fact father  abe bart  and the rules rgp and rpf. this suggests modifying our derivation system for subsequent 
    this research was supported by an operating grant from the national science and engineering research council of canada. 

queries: when asked to prove guardian  k y    for any k and 1   this  smarter  system will immediately perform the data base retrieval of father   k 1    and only if this fails  consider the other possible retrievals and rule-based reductions  e.g.  using rgp  etc. . this corresponds to combining the rules rgp and rpf to produce the new rule 

which is incorporated into the set of rules  forming kb'g  - kbg u {rgf}. furthermore  this  redundant  rule is placed first  in that this system will try this new rule first in subsequent queries  before the other rules are attempted. this is the basis for the recent explanationbased learning  ebl  systems  mitchell et a/.  1  dejong and mooney  1   as well as chunking  rosenbloom and newell  1   etc. 
　the objective of these learning systems is efficiency: to improve the overall future performance of the system. of course  this requires some information about these anticipated future events - especially about which questions will be posed and with what probabilities  and about the probability that certain assertions will be in the knowledge base  kb  when those queries occur. 
　many systems implicitly employ the  obvious  assumption that  the future will mirror the past  - that the future questions will correspond to the questions asked until now. this suggests preserving every observed rule-sequence as a new redundant rule. recent empirical evidence  minton  1   however  has exposed some of the problems inherent in this  save all redundant rules  approach: these new rules can slow down the overall performance of the complete system. that is  it is not always advantageous to incorporate a proposed redundant rule into an existing knowledge base. 
　this paper addresses this important issue: how to decide whether to add in a new redundant rule. it assumes  as given  the a priori likelihood that any given database retrieval will succeed.  we may know  for example  that there is a 1% chance that the data base 


	greiner and likuski 	1 




	greiner and likuski 	1 


　unfortunately  the above points show that redundant inference graphs  in general  need not have this nice property. that is  an optimal strategy found for an inferior s k  node may be completely irrelevant  when seeking the optimal strategy for its superior g k  node  meaning our algorithm would have backtrack to consider other possibilities  as it works its way up towards the top goal. we feel that this back-tracking is what leads to the intractability of the general task  which is why we expect there are efficient algorithms for finding optimal strategies only in situations where the decisions made at one node are  honored  at all superior nodes. 
1 	conclusions 
this concluding section first ties this work back into the framework of ebl systems in general  and then lists some obvious extensions to this work. 
tie to e b l systems: the positive result mentioned above - that a direct redundant rule  i.e.  the result of an ebl system  can never slow down a derivation system - should be viewed as only a partial vindication of ebl systems and techniques. below are four comments about this claim: 
  most ebl systems leave in both the direct rule  and the rules from which it was derived - e.g.  both the derived rgf and the pair rgp and rpf. we showed that this is never efficient  even for the query itself. 
  most ebl systems move this new rule to the beginning of the system's derivation strategy; this is not always the optimal place.  recall that we added rgf towards the back of the 1 strategy. in fact  the expected cost of the strategy which includes rgf in the front of the strategy is strictly worse than the original   ne-rgf strategy  1 !  
  section 1 mentioned two ways of improving the ex-pected cost of a derivation -  1  by determining the best strategy  and  1  by adding redundancies. as empirical evidence has shown that using  1  without  1  can produce arbitrarily inefficient systems  this report has examined ways of combining both of these. 
  this result applies only when the prior knowledge base is irredundant  and it only deals with a single query. as shown above  the situation is much more complicated when we consider multiple questions  and arbitrarily redundant knowledge bases. 
extensions: we have only scratched the surface of this analysis; there are many other areas to consider as well. the first obvious arena is handling conjunctive and recursive knowledge bases. another is to combine this approach with other control strategy mechanisms - including conjunct ordering  smith and genesereth  1  and forward chaining  treitel and genesereth  1 . the third is to obtain more accurate empirical values. for example  we have assumed that the costs of reductions and lookups  read   i   and  d''  are uniform. preliminary empirical observations show that these costs depend on the number of variables  etc. 
results: this report takes seriously the view that explanation-based learning is a method for improving the future performance of a reasoning system. this leads to the formal foundation for analysis presented in section 1  which is based on the expected cost for solving certain queries from a given knowledge base  based on a given distribution of facts . section 1 uses this framework to describe both the complexities  read  nphardness   inherent in this undertaking; and certain restricted situations where efficient algorithms  based on  smith  1 's work  are possible. section 1 uses this framework to understand why ebl systems do  and do not  succeed in their attempts to improve the performance of their underlying systems. 
