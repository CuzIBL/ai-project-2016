 
this paper introduces a partition of the possible forms of knowledge according to their relationship to the basic objective of an intelligent agent  namely to act successfully in response to its environment. the resulting classes of knowledge range from fully declarative to fully compiled. from these classes  it is possible to generate 1  a set of execution architectures  each of which combines some of the classes to produce decisions; and 1  a set of compilation methods  that transform knowledge into more efficient but  approximately  behaviourally equivalent  compiled forms. existing compilation methods can be understood within this framework  and new compilation methods and execution architectures are indicated. it is proposed that systems with the ability to learn  use and transform between all the types of knowledge may be able to achieve simultaneously higher levels of competence  efficiency and flexibility. 
1 	introduction 
artificial intelligence in general  and machine learning in particular  must find a route from raw perceptions of the world to successful actions within that world. in this paper  i try to identify a few more way-stations on this daunting route. in doing so in so small a space i will need to ride roughshod over some important questions  but the basic thesis is that there are several distinct kinds of knowledge that can be acquired from perceptions and used for acting  and therefore a multiplicity of execution architectures that effect the input/output mapping for an agent. the approach also helps one to understand the variety of existing execution architectures by pointing out the possibilities for compilation transformations that preserve behavioural equivalence. 
　the paper begins by motivating compilation as a useful notion in ai. in order to find out what kinds of compilation there are  i start from an uncompiled architecture and work down. to do this  i first describe what i mean by autonomy and hence what might be an uncompiled architecture for an autonomous intelligent agent. i then discuss the possible forms of knowledge  from fully declarative to fully compiled  and map out the compile tion paths linking them. finally  i discuss the resulting 
   *this work was supported by the lockheed ai center and the state of california micro program 
research agenda and speculate on why declarative knowledge is worth having. 
1 	why compilation  
it is a commonplace of artificial intelligence that perfect rationality  in the sense prescribed by decision theory  is unlikely to be computationally attainable by systems that explicitly solve the decision problem at each juncture. simon  1b  made clear the distinction between systems that compute the rational thing to do  procedural rationality   and systems that simply do the rational thing  substantive rationality . systems whose execution architectures are based on explicit use of declarative knowledge to reach decisions to act seem to suffer from a good deal of overhead  both in terms of time and extra cognitive machinery. a currently popular notion is that all this deliberation is a waste of time - why don't we 
just build agents that  do the right thing   brooks  1  agre and chapman  1   substantive rationality  however  does not come for free. although it means that an agent can be perfectly rational despite limited computational resources  it can only arise in one of three ways: 
1. by design  where the designer possesses the computational and informational resources required to find optimal solutions. 
1. by simple adaptation  that is  direct adjustment of behaviour in response to feedback from the environment. 
1. by deliberative self-design  where the agent itself carries out the required computations   perhaps incrementally  compiling them to ensure substantive rationality in future situations. 
many people in ai are interested in ultimately creating autonomous intelligent systems. below  we develop a 
simple notion of autonomy that makes the first of these three options less than desirable. at the conclusion of this paper  we offer speculation as to why the second option may also be inappropriate. the majority of researchers  including many advocates of substantive rationality  believe that the most promising route to achieving intelligence lies in systems capable of acquiring and using knowledge in a declarative form  and gradually compiling it for use in more efficient execution architectures. 
　there seems little doubt that such efficient execution architectures do exist. a clock does the right thing as a direct result of its fixed structure  with no significant perceptive ability. a pianola or 'player-piano' executes 
russell 
a behaviour by directly interpreting a stored sequence of action descriptions. state-free  feed-forward networks can implement more complex mappings from inputs to actions; agre and chapman  have advocated such systems as a reasonable architecture for intelligent systems. connectionist systems follow a similar design philosophy. all of these approaches to producing behaviour have significant advantages in terms of simplicity and computation time. in a sense  they all implement 'condition-action' rules  or productions  with the limitation that conditions must be computable directly from current sensory inputs. if we design systems using more declarative constructs  the performance demands of real environments will necessitate some mechanism for converting inefficient but general decision-making methods into a form that displays greater alacrity.1 
　essentially  compilation is a method for omitting intermediate computations in the input-output mapping. computations can be omitted when their answers are already known  so that subsequent computations can be modified to use those answers directly rather than having them recomputed first. compilation is only useful when an entire class of computations can be omitted  so that a whole class of decision-making episodes can be speeded up. therefore another view of compilation is as a means for taking advantage of regularities in the environment. for example  i have learnt  when driving to work  to turn left at the bright orange oscar's burgers sign. this is because the sign is always at the same street  and that street always leads to the parking lot; but this information is now only implicit in my performance. 
　researchers have found ways to add some form of compilation into whatever system they use as a performance element. the most usual forms of compilation involve collapsing operator sequences and collapsing implications in a logical system. anderson  developed knowledge compilation to speed up a production system. rosenbloom  developed chunking to compile the impasse resolution procedures in soar   also a production system. fikes and nilsson  developed the triangle-table method to form macro-operators to speed up problem-solving in strips. explanation-based learning  mitchell et a/.  1  compiles simple forms of rulebased inference. to date  the technique has only been applied to concept membership problems and what might be called 'existential' problem-solving  in which any action that eventually leads to a solution is acceptable. 
　it is possible to unify all these techniques as points in a well-defined space of possible compilation methods. the route we will take is to analyze the possible general classes of compiled knowledge  and then generate a space of compilation methods as routes for converting between and within these various knowledge classes. in order to do this  some notion of an uncompiled formulation for autonomous decision-making is needed. to motivate the choice of a decision-theoretic framework to fill this role  a brief digression on autonomous agents is in order. 
1
   subramanian and woodfill  have given an example of how a situation-calculus-based planner might generate propositional condition-action rules of the form used by agre and chapman. 
foundations 
1 	autonomy 
a system is autonomous to the extent that its behaviour is determined by its immediate inputs and past experience  rather than by its designer's. a system that operates on the basis of built-in assumptions will only operate successfully when those assumptions hold  and thus lacks flexibility. a truly autonomous system should be able to operate successfully in any universe  given sufficient time to adapt. the system's internal knowledge structures should therefore be constructive  in principle  from its experience of the world.1 
　for a notion of learning in such systems  the following definition seems acceptable: learning takes place when the system makes changes to its internal structure so as to improve some metric on its long-term future performance  as measured by a fixed performance standard  cf. simon's  definition . it also seems clear that the performance standard must ultimately be externally imposed  buchanan et a/.  1   particularly since  for the purposes of building useful artifacts  modification of the performance standard to flatter one's behaviour does not exactly fit the bill. 
there are three1 essential aspects of experience: 
1. perceptions that reflect the current state of the en-vironment. 
1. perception of the agent's own actions. 
1. information as to the quality of the agent's perfor-mance. 
the agent's perceptions may be partial  intermittent and unreliable. the truth of the agent's perceptions is irrelevant  or  to put it another way  each perception carries a guarantee of its own truth . what is important is that the perceptions be faithful in the following sense: there is a consistent relationship between the agent's perceptions and the performance feedback. the relationship can be arbitrarily complex and uncertain - the more so  the more difficult the learning problem. 
　given these basic categories of inputs  some obvious candidates for the constituents of the uncompiled architecture would include beliefs about the state of the world  beliefs about the effects of actions and beliefs about the relationship between the state of the world and the level of performance quality feedback. each of these can be 'explained' only by appealing to the agent's direct experience of the world or to prior knowledge of the same type  rather than being derivable from other knowledge structures  this point can be argued in a good deal more detail . an appropriate uncompiled architecture for an intelligent system would therefore seem to be decision-theoretic in nature. 
　the strongest alternative to this proposal is the goal-based architecture  as proposed by  for example  
　　1 don't wish to equate autonomous systems with tabula rasa systems  however  since this seems a somewhat impractical way to proceed. a reasonable halfway-point is to design systems whose behaviour is determined in large part  at least initially  by the designer's knowledge of the world  but where all such assumptions are as far as possible made explicit and amenable to change by the agent. this sense of autonomy seems also to fit in reasonably well with our intuitive notions of intelligence. 1 one might argue that perception of the agent's internal computations is also necessary for certain kinds of learning; these can be included in the 'environment' and 'actions'. 
newell  and the soar group  laird et a/.  1  . in such systems  the idea of a utility measure is replaced by the idea of a goal - an intensional description of a class of desirable states. it might be argued that goals and utility functions are equally valid alternative formulations; for example  one could construct a utility function from a goal by assigning high utility to goal states and lower utility to other states; and one could identify goals with classes of high-utility states from a given utility function. however  there are two significant ob-
jections to such a proposal. first  goal-based formalisms have a hard time dealing appropriately with conflicting goals  and thus cannot adequately model the desires of complex agents  who  for example  may want a jaguar and a new roof  but cannot afford both . utility functions can easily deal with such cases. the second  and perhaps more important  objection involves the nature of the performance feedback that an agent receives. it seems to me that this feedback must be essentially nonrepresentational the agent is not given goal descriptions or utility functions by the environment  only a series of point values from the external performance metric. in this way  the environment does not need to know the agent's representation scheme in order to 'train' it. there merely has to be agreement on what counts as 'warm' and what counts as 'cold'. in the case of evolution  the metric 'more offspring is better' is self-defining. in the ralph rational agents with limited performance hardware project at berkeley  the agents operate in a real-time  simulated environment where the performance feedback reflects the amount of food the agents find and consume  and their successful avoidance of enemies who might wound them. each ralph is designed to induce a utility function from the performance feedback data. however  this utility function will not  in general  reproduce the function that generates the performance signal. instead  it should converge to a function that predicts the long-term expectation of the performance signal  given the current state. in this way  the agent can use a simple  'greedy' decision procedure that avoids extensive lookahead. one would expect the utility function to be much more complex than the performance signal generator. 
1 	categories of knowledge 
to recap: the basic categories of knowledge in an uncompiled system  that is  a system operating with a decisiontheoretic formulation  are 
  knowledge about the state of the world  this in-cludes direct perceptions  and rules relating parts of the world state  such as 'if it is raining  the ground is usually wet' ; 
  knowledge about the results of actions  i.e.  con-straints on the world state after an action has been performed; 
  knowledge about the  relative  utility of a world state. 
decisions are made by selecting the action that results in the next state of highest expected utility. 
we will use an informal1 notation as follows: 
1
　　 readers interested in a more thorough and formal development of declarative formulations of agents are referred to doyle's recent work  doyle  1 . 

  condition state  represents an arbitrary predication on a world state; 
  utility state  value  represents an arbitrary predication about the absolute or relative utility of a world state; 
  result  action state  represents an arbitrary predication about the resulting state after taking an action in a given state; 
  best  action state  means that action is the best available in the given state. 
  currentstate refer to the state of the world in which the agent finds itself. 
a basic decision procedure derives conclusions of the form utility result action currentstate  value  for each available action  and uses the decision-theoretic principle to conclude best  action  currentstate  for one of them. in order to obtain these utilities  then  it will normally need to know some condition currentstate   allowing it to conclude condition result action  currentstate    from which it can infer the utility of taking the action. the four stages of 'static' knowledge are shown in figure 1  with the obvious abbreviations. 
　in the same notation  the forms of 'dynamic' knowledge needed to link these stages together are as follows: 
a: 	condition state  	=  	condition state  
b: condition state  =  condition  result action  state   
c: 	condition state  	=  	utility  state  value  
in addition  the decision-theoretic principle  labelled dt in the diagram  takes knowledge of the utility of actions and concludes that one is best. 
　the principle of compilation is to convert a formulation in which each of these kinds of knowledge is used explicitly into a formulation that results in the same decisions but is computationally more efficient. by examining the figure we can see the additional kinds of knowledge that can offer shortcuts for the decision procedure. they are as follows: 
  d: 	condition state  	=  	best action  state  
  e: 	condition state  	=  utility result action  	state   	value  
  f: 	condition result action  state   	=  best action  	state  
russell 
type d rules are the standard condition-action rules used in production systems; for example  ''if a car is coming straight for you then jump out of the way . such rules compile away any knowledge of the results of the action or of the reasons for those results' desirability. 
　type e rules could be called action-utility rules; for example  the value of a forking move in chess is typically the difference between the value of the lesser of the forked pieces and the value of the forking piece. such rules avoid explicit computation of the action's results. 
　type f rules are extremely interesting. consider the case of a type f rule with universal quantification over the action and state arguments: 
va  s condition result a  s   =  best a  s  . 
essentially  such a rule says that an action should be executed whenever the situation is such that the action will achieve a certain condition. an agent using such a rule thus believes the condition to be desirable independent of the side effects of its achievement on the rest of the agent's utility function. this is exactly the definition of a goal that is used in newell's knowledge-level agent architecture  newell  1 . goals are therefore compiled from a decision-theoretic formulation  when the agent believes that a condition is 'separately optimizable'. since goals allow backward-chaining rather than forward-chaining for selecting actions  they can provide huge efficiency gains  and their creation by compilation is an important  unstudied process. 
　in this context  an execution architecture is an interpreter that uses some combination of facts of various types to reach a decision. three basic architectures that can be implemented using knowledge of types a through f are as follows: 
1. decision-theoretic systems: knowledge of types a  b and c is combined to find the best action using the dt principle. 
1. production systems: knowledge of type d provides action choices directly. 
1. goal-based systems: knowledge of types a  b and f suggests actions that achieve the desired goal condition. 
systems based on combining knowledge of type e with the dt principle seem not to have been studied systematically. such systems organize their utility knowledge around actions rather than states. they are discussed further below. 
1 	the space of compilation methods 
the space of compilation methods can now be generated by looking at various ways in which all these forms of knowledge can be combined to produce more operational versions of the same underlying theory. there are two basic classes of compilation methods: homogeneous and heterogeneous. 
1 	homogeneous compilation 
the first two forms of uncompiled knowledge  a and b  have left and right-hand sides of the same form  and therefore allow indefinite chaining of inferences. the chained inferences can be compiled to make the calculation of the requisite basic forms of declarative knowledge more efficient: 
foundations 
  a + a -  a 
  b + b -  b 
these two compilation modes are already well-known in the literature. explanation-based learning is usually used to compress chains of inferences about the state of the world. for example  the first time a particular type of bridge is designed  very long computations are needed to predict its safe load from its structural description; the results are then saved as a rule about this class of bridges. macro-operator formation compresses inferences about the results of sequences of actions. after map-tracing and trial and error  i discover a good route to work; then i compile it into an automatic routine  or action sequence  to get me there. 
　the reason for the popularity of these forms of compilation is obvious: a uniform architecture  one based on just type a or just type b knowledge  is closed under these compilation methods. in other words  the same execution architecture applies to the compiled as to the uncompiled knowledge. although this simplifies matters  it probably places limits on the performance gains that can be obtained from compilation. getting any improvement at all has been a hard job  minton  1   
　because all of the forms b through f have left-hand sides consisting of conditions on states  type a knowledge can be used to conclude those conditions and these inferences can also be compiled: 
  a + x -  x 	for x = b  c  d  e  f. 
for example  if i have to build a bridge to cross a ravine to get to the office  calculations about its safety go towards a belief that the route using it gets me to work  rather than into the ravine. 
1 	heterogeneous compilation 
compilation methods resulting in knowledge of types d  
e  and f  which i have called condition-action rules  action-utility rules and goals  have received little attention in ai. the following remarks certainly do not constitute compilation algorithms  but serve to indicate some current and future directions for research. 
generating condition-action rules many of the 'reactive' architectures mentioned above  and production systems in general  use condition-action rules  that identify the conditions under which a given action is expected to be more valuable than all others.1 these rules can be generated by the following compilation routes: 
  b + f - d 
for example  if  b  meditating on a full stomach achieves nirvana  and  f  nirvana is always desirable  then  d  always meditate after meals. this method is straightforward  and can be simply implemented in an ebl  knowledge compilation  anderson  1  or chunking system  laird et a/.  1   it actually constitutes a reasonable characterization of the latter  since every impasse represents a readymade goal . 
  e + dt -  d this method is more problematic: conditional knowledge about the absolute and relative utilities of actions must be combined to find the 
　　1 production systems with a conflict resolution mechanism do not need to have exactly this strict semantics for their productions  but the same arguments apply. 
conditions under which one of them is optimal. in some cases  the utility information for the available actions is provided in parameterized form  allowing the system to compute the ranges of parameter values for which each action is optimal. this approach is common in decision-analytic  particularly multivariate  studies  fehling and breese  1  horvitz  1  howard  1 . more work is needed to establish efficient and general methods for this kind of reasoning. 
  b + c + dt -  d for example  if  b  smoking causes cancer  and  c  cancer is worse than anything  then conclude  d  one should not smoke. in other cases  the utility information will be less absolute  and compilation will be more complex. this compilation method is also problematic because it has to make the kinds of approximations  for the sake of efficiency  that are already hidden in goals and action-utility rules. consider applying an ebl system to the problem of finding a best action: it needs a proof to the effect that all other actions are guaranteed not to have better outcomes. in non-trivial situations  this proof can be arbitrarily complex - the intractable domain theory problem  mitchell et a/.  1 . the rule created will have a correspondingly huge number of qualificar tions  and will be essentially useless. a case in point: the concept of a forking move is often cited as the kind of concept that can be learned using ebl techniques  yet the preconditions for guaranteeing that the fork will actually win material  let alone be the best move  are endless. 
the only reasonable solution seems to be to produce condition-action rules that provide an approximate guarantee that their recommended action is more or less optimal. the rules can then be used as de-
faults in a hierarchy of execution architectures  so that further deliberation of a more explicit nature can over-rule the original recommendation  if time permits. learning such rules requires sophisticated  or adaptive} accuracy/resource tradeoffs in order to ensure rules that are not too rash yet can execute quickly. tadepalli  has built a program that learns approximate strategies for king-rook versus king endgames  and exhibits significant speedup as a result. research is needed to extend such systems to more complex environments. it may turn out that indirect routes  via action-utility rules and goals  are the only feasible approach. 
generating action-utility rules it will often be the case that the value of an action can be estimated  without having a corresponding belief in its optimality. action-utility rules are compiled from knowledge of the utility of states  and knowledge of the results of actions: 
  b + c - e 
this form of compilation seems relatively simple  because it does not need to refer to the utility of all available actions  yet there seems to have been little research on automating it. it would be interesting to write a program capable of learning a general rule for estimating the value of a forking move in chess. a chess program constructed using such rules would use them to quickly identify any material-gain or attacking possibilities and to order them for investigation  falling back on full-width search only as a last resort. similarly  a trading program could learn such rules as  if the current us market price of crude oil is m then buying a cargo of t tons in venezuela at price p will yield net profit f m t p   for some known f. 
creating goals 	the compilation method 
  c + dt -  f 
essentially finds separable aspects of the utility function that guarantee that achieving a given condition is always a good thing. even when this guarantee is conditional  the resulting goals may still have enormous computational benefits. for example  the ralph agents mentioned above can generate a conditional goal to be in the vicinity of food provided no enemies are too near  and can therefore select movement actions with little computational effort. similarly  a chess player can generate a temporary goal to actively seek a checkmate  thereby allowing a backward-chaining process to find a good strategy-
1 	conclusions 
a clear lesson from this brief investigation of compilation is that there is a rich variety of forms of compiled knowledge and of compilation routes. current methods  with some exceptions as mentioned above  cover only homogeneous methods in uniform architectures. research on building a mixed architecture  with a full variety of execution modes using different kinds of knowledge  is a high priority for the ralph project. one possible application might be in real-time robotics: a robot can learn declarative knowledge about the behaviour of its effectors and the behaviour of objects in its environment  but will need to compile these into effective routines for achieving basic manipulation goals. 
　when computations are viewed as actions  to be selected according to expected utility just as with ordinary actions in the world  then one can apply decision theory to provide a principled basis for metareasoning  russell and wefald  1 . one could also apply all of the above analysis to the compilation of metareasoning  especially since it is usually very expensive. an interesting application of such an analysis would be to provide a formal framework for metareasoning in a universal subgoaling architecture  laird  1 . currently  soar converts a fully declarative metalevel model into condition-action rules. another possibility  that does not seem to be envisaged in soar   is to create action-utility rules  type e  for computational actions. this method seems to be effective in controlling computations in a selective search procedure  russell and wefald  1 . 
　finally  one can speculate as to why we humans seem to bother with declarative knowledge. why not learn one of the more compiled forms of knowledge  even learn direct condition-action rules  rather than taking the indirect route  it may be due to a combination of storage requirements and learnability. essentially  any body of uncompiled knowledge capable of generating a given repertoire of behaviours in a particular environment could be compiled into a network of gated connections between sensors and effectors  with minimal state. the regularities in the network are much more compactly expressible using the declarative knowledge that explains them. but even assuming that space for the complete network is 
russell 

available  learning such a network may be infeasible. put simply  provided there is some regularity in the world  the smaller formulation in terms of uncompiled knowledge will be easier to learn  as shown by standard results in computational learning theory. moreover  it seems difficult to use prior knowledge in the form of conditionaction links to assist in the learning of new conditionaction links; how would we construct a radio telescope without any knowledge of the behaviour of the parts or the physics of electromagnetic waves  other than by lengthy trial and error  however  in sufficiently simple task environments  where simplicity depends on the utility function and sensorimotor apparatus  as well as the environment per se  the direct approach may succeed. termites build architecturally sound edifices thirty feet high with no explicit knowledge of anything much. it is an article of faith of declarativists that as the task environment complexity becomes asymptotically high  knowledge will eventually win out over instinct. finding the cross-over point is currently an empirical task  one we are undertaking in the ralph project. 
