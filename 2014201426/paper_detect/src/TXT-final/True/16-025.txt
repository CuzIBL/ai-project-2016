 
       native speakers of english show definite and consistent preferences for certain readings of syntactically ambiguous sentences. a user of a natural-language-processing system would naturally expect it to reflect the same preferences. thus  such systems must model in some way the linguistic performance as well as the linguistic competence of the native speaker. we have developed a parsing algorithm-a variant of the lalr l  shift-reduce algorithm-that models the preference behavior of native speakers for a range of syntactic preference phenomena reported in the psycholinguistic literature  including the recent data on lexical preferences. the algorithm yields the preferred parse deterministically  without building multiple parse trees and choosing among them. as a side effect  it displays appropriate behavior in processing the much discussed garden-path sentences. the parsing algorithm has been implemented and has confirmed the feasibility of our approach to the modeling of these phenomena. 
1. introduction 
　　　for natural language processing systems to be useful  they must assign the same interpretation to a given sentence that a native speaker would  since that is precisely the behavior users will expect. consider  for example  the case of ambiguous sentences. native speakers of english show definite and consistent preferences for certain readings of syntactically ambiguous sentences  kimball  1  frazier and fodor  1  ford ct al  1 . a user of a natural-language-processing system would naturally expect it to reflect the same preferences. thus  such systems must model in some way the linguistic performance as well as the linguistic competence of the native speaker. 
　　　this idea is certainly not new in the artificial-intelligence literature. the pioneering work of marcus  marcus  1  is perhaps the best known example of linguistic-performance modeling in ai. starting from the hypothesis that  deterministic  parsing of english is possible  he demonstrated that certain performance constraints  e.g.  the difficulty of parsing garden-path sentences  could be modeled. his claim about deterministic parsing was 
*this research was supported by the defense advanced research projects agency under contract no1-c-1 with the naval electronic systems command. the views and conclusions contained in this document are thone of the author and should not be interpreted as representative of the official policies  either expressed or implied  of the defense advanced research projects agency or the united states government. quite strong. not only was the behavior of the parser required to be deterministic  but  as marcus claimed  
the interpreter cannot use some general rule to take a nondeterministic grammar specification and impose arbitrary constraints to convert it to a deterministic specification  unless  of course  there is a general rule which will always lead to the correct decision in such a case .  marcus  1  p.1  
       we have developed and implemented a parsing system that  given a nondeterministic grammar  forces disambiguation in just the manner marcus rejected  i.e. through general rules ; it thereby exhibits the same preference behavior that psycholinguists have attributed to native speakers of english for a certain range of ambiguities. these include structural ambiguities  frazier and fodor  1  frazier and fodor  1  wanner  1  and lexical preferences  ford et a/.  1   as well as the gardenpath sentences as a side effect. the parsing system is based on the shift-reduce scheduling technique of pereira  forthcoming . 
       our parsing algorithm is a slight variant of lalr l  parsing  and  as such  exhibits the three conditions postulated by marcus for a deterministic mechanism: it is data-driven  reflects expectations  and has look-ahead. like marcus's parser  our parsing system is deterministic. unlike marcus's parser  the grammars used by our parser can be ambiguous. 
1. the phenomena to be modeled 
       the parsing system was designed to manifest preferences among structurally distinct parses of ambiguous sentences. it does this by building just one parse tree-rather than building multiple parse trees and choosing among them. like the marcus parsing system  ours does not do disambiguation requiring 'extensive semantic processing   but  in contrast to marcus  it does handle such phenomena as pp-attachment insofar as there exist a priori preferences for one attachment over another. by a priori we mean preferences that are exhibited in contexts where pragmatic or plausibility considerations do not tend to favor one reading over the other. rather than make such value judgments ourselves  we defer to the psycholinguistic literature  specifically  frazier and fodor  1    frazier and fodor  1  and  ford et ai  1   for our examples. 
the parsing system models the following phenomena: 
r i g h t association 
native speakers of english tend to prefer readings in which 

1 s. shieber 
constituents are  attached low.  for instance  in the sentence 
joe bought the book that i had been trying to obtain for susan. 
the preferred reading is one in which the prepositional phrase ''for susan  is associated with  to obtain  rather than  bought.  
m i n i m a l a t t a c h m e n t 
on the other hand  higher attachment is preferred in certain cases such as joe bought the book for susan. 
in which  for susan  modifies  the book  rather than  bought.  frazier and fodor  note that these are cases in which the higher attachment includes fewer nodes in the parse tree. our analysis is somewhat different. 
lexical preference 
ford et al.  present evidence that attachment preferences depend on lexical choice. thus  the preferred reading for 
the woman wanted the dress on that rack. has low attachment of the pp  whereas the woman positioned the dress on that rack. 
has high attachment. 
garden-path sentences 
grammatical sentences such as 
the horse raced past the barn fell. 
seem actually to receive no parse by the native speaker until some sort of  conscious parsing  is done. following marcus  marcus  1   we take this to be a hard failure of the human sentence-processing mechanism. 
       it will be seen that all these phenomena are handled in our parser by the same general rules. the simple context-free grammar used1  see appendix i  allows both parses of the ambiguous sentences as well as one for the garden-path sentences. the parser disambiguates the grammar and yields only the preferred structure. the actual output of the parsing system can be found in appendix ii of  shieber  1 . 
1. the parsing system 
　　　the parsing system we use is a shift-reduce parser. shiftreduce parsers  aho and johnson  1  are a very general class of bottom-up parsers characterized by the following architecture. they incorporate a stack for holding constituents built up during the parse and a shift-reduce table for guiding the parse. at each step in the parse  the table is used for deciding between two basic types of operations: the shift operation  which adds the next 
1 we make no claims as to the accuracy of the sample grammar. it is obviously a gross simplification of english syntax. its role is merely to show that the parsing system is able to disambiguate the sentences under consideration correctly. 
word in the sentence  with its preterminal category  to the top of the stack  and the reduce operation  which removes several elements from the top of the stack and replaces them with a new element-for instance  removing an np and a vp from the top of the stack and replacing them with an s. the state of the parser is also updated in accordance with the shift-reduce table at each stage. the combination of the stack  input  and state of the parser will be called a configuration and will be notated as  for example  

1 differences from the standard lr techniques 
　　　the shift-reduce table mentioned above is generated automatically from a context-free grammar by the standard algorithm  aho and johnson  1 . the parsing alogrithm differs  however  from the standard lalr l  parsing algorithm in two ways. first  instead of assigning preterminal symbols to words as they are shifted  the algorithm allows the assignment to be delayed if the word is ambiguous among preterminals. when the word is used in a reduction  the appropriate preterminal is assigned. 
       second  and most importantly  since true lr parsers exist only for unambiguous grammars  the normal algorithm for deriving lalr l  shift-reduce tables yields a table that may specify conflicting actions under certain configurations. it is through the choice made from the options in a conflict that the preference 
behavior we desire is engendered. 
1 preterminal delaying 
       one key advantage of shift-reduce parsing that is critical in our system is the fact that decisions about the structure to be assigned to a phrase are postponed as long as possible. in keeping with this general principle  we extend the algorithm to allow the assignment of a preterminal category to a lexical item to be deferred until a decision is forced upon it  so to speak  by an encompassing reduction. for instance  we would not want to decide on the preterminal category of the word  that   which can serve as either a determiner  det  or complementizer  that   until some further information is available. consider the sentences 
	that problem 	is 	important. 
	that problems are difficult to solve is 	important. 
instead of assigning a preterminal to  that   we leave open the possibility of assigning either det or that until the first reduction that involves the word. in the first case  this reduction will be by the rule np - det nom  thus forcing  once and for all  the assignment of det as preterminal. in the second case  the det nom analysis is disallowed on the basis of number agreement  so that the first applicable reduction is the comp s reduction to 1  forcing the assignment of t h a t as preterminal. 
       of course  the question arises as to what state the parser goes into after shifting the lexical item  that.  the answer is quite straightforward  though its interpretation vis a vis the determinism hypothesis is subtle. the simple answer is that the parser enters into a state corresponding to the union of the states entered upon shirting a det and upon shifting a t h a t respectively  in much the same way as the deterministic simulation of a nondeterministic finite automaton enters a  union  state when faced with a nondeterministic choice. are we then merely simulating a nondeterministic machine here  the answer is equivocal. although the implementation acts as a simulator for a nondeterministic machine  the nondeterminism is a priori 
s. shieber 1 
bounded  given a particular grammar and lexicon.1 thus  the nondeterminism could be traded in for a larger  albeit still finite  
set of states  unlike the nondeterminism found in other parsing algorithms. another way of looking at the situation is to note that there is no observable property of the algorithm that would distinguish the operation of the parser from a deterministic one. in some sense  there is no interesting difference between the limited nondeterminism of this parser  and marcus's notion of strict determinism. in fact  the implementation of marcus's parser also embodies a bounded nondeterminism in much the same way this parser does. 
       the differentiating property between this parser and that of marcus is a slightly different one  namely  the property of quasi-real-time operation.1 by quasi-real-time operation  marcus means that there exists a maximum interval of parser operation for which no output can be generated. if the parser operates for longer than this  it must generate some output. for instance  the parser might be guaranteed to produce output  i.e.  structure  at least every three words. however  because preterminal assignment can be delayed indefinitely in pathological grammars  there may exist sentences in such grammars for which arbitrary numbers of words need to be read before output can be produced. it is not clear whether this is a real disadvantage or not  and  if so  whether there are simple adjustments to the algorithm that would result in quasi-real-time behavior. in fact  it is a property of bottom-up parsing in general that quasi-real-time behavior is not guaranteed. our parser has a less restrictive but similar property  fairness  that is  our parser generates output linear in the input  though there is no constant over which output is guaranteed. for a fuller discussion of these properties  see pereira and shieber  forthcoming . 
       to summarize  preterminal delaying  as an intrinsic part of the algorithm  does not actually change the basic properties of the algorithm in any observable way. note  however  that preterminal assignments  like reductions  are irrevocable once 
they are made  as a byproduct of the determinism of the algorithm . such decisions can therefore lead to garden paths  as they do for the sentences presented in section 1. 
       we now discuss the central feature of the algorithm  namely  the resolution of shift-reduce conflicts. 
1 the disambiguation rules 
       conflicts arise in two ways: shift-reduce conflicts  in which the parser has the option of either shifting a word onto the stack or reducing a set of elements on the stack to a new element; reduce-reducc conflicts  in which reductions by several grammar rules are possible. the parser uses two rules to resolve these 
the boundedness comes about because only a finite amount of information is kept per 1tate  an integer  and the nondeterminism stops at the preterminal level  so that the splitting of states does not propogate. 
'i am indebted to mitch marcus for this observation and the previous comparison with his parser. 

1 s. shieber 
conflicts:1 	joe bought the book for susan. 
 1  resolve shift-reduce conflicts by shifting. 	demonstrates resolution of a reduce-reduce conflict. 	at some 
 1  resolve reduce-reduce conflicts by performing 	point in the parse  the parser is in the following configuration: 

in the case in which the verb is  positioned   however  the longer reduction does not yield the weak form of the verb; it will therefore be invoked  resulting in the structure: 
 sthe woman  v p positioned  np the dress  ppon that rack    
1 garden-path sentences 
       as a side effect of these conflict resolution rules  certain sentences in the language of the grammar will receive no parse by the parsing system just discussed. these sentences are apparently the ones classified as  garden-path  sentences  a class that humans also have great difficulty parsing. marcus's conjecture that such difficulty stems from a hard failure of the normal sentence-processing mechanism is directly modeled by the parsing system presented here. 
for instance  the sentence 
the horse raced past the barn fell. 
exhibits a reduce-reduce conflict before the last word. if the participial form of  raced  is weak  the finite verb form will be chosen; consequently   raced past the barn  will be reduced to a vp rather than a participial phrase. the parser will fail shortly  since the correct choice of reduction was not made. 
similarly  the sentence 
that scaly  	deep-sea 	fish 	should be underwater is important. 
will fail  though grammatical. before the word  should  is shifted  a reduce-reduce conflict arises in forming an np from either  that scaly  deep-sea fish  or  scaly  deep-sea fish.  the longer  incorrect  reduction will be performed and the parser will fail. 
　　　other examples  e.g.   the boy got fat melted   or  the prime number few  would be handled similarly by the parser  though the sample grammar of appendix i does not parse them  pereira and shieber  forthcoming . 
1. conclusion 
       to be useful  natural-language systems must model the behavior  if not the method  of the native speaker. we have demonstrated that a parser using simple general rules for disambiguating sentences can yield appropriate behavior for a large class of performance phenomena-right association  minimal attachment  lexical preference  and garden-path sentences-and that  morever  it can do so deterministically without generating all the parses and choosing among them. the parsing system has been implemented and has confirmed the feasibility of our approach to the modeling of these phenomena. 
s. shieber 1 
ford  m.  j. bresnan  and r. kaplan  1: ''a competence-based 
theory of syntactic closure   in the mental representation of grammatical relations  j. bresnan  ed.  cambridge  massachusetts: mit press . 
frazier  l.  and j.d. fodor  1:  the sausage machine: a new 
two-stage parsing model   cognition  volume 1  pp. 1. 
frazier  l.  and j.d. fodor  1:  is the human sentence parsing mechanism an atn   cognition  volume 1  pp. 1. 
gazdar  g.  1:  unbounded dependencies and coordinate structure   linguistic inquiry  volume 1  pp. 1. 
kimball  j.  1:  seven principles of surface structure parsing in 
natural language   cognition  volume 1  number 1  pp. 1. 
marcus  m.  1: a theory of syntactic recognition for natural language   cambridge  massachusetts: mit press . 
pereira  f.c.n.  forthcoming:  a new characterization of attachment p