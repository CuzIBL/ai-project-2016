
the paper describes a simple but effective framework for visual object tracking in video sequences. the main contribution of this work lies in the introduction of a case-based reasoning  cbr  method to maintain an accurate target model automatically and efficiently under significant appearance changes without drifting away. specifically  an automatic case-base maintenance algorithm is proposed to dynamically update the case base  manage the case base to be competent and representative  and to maintain the case base in a reasonable size for real-time performance. furthermore  the method can provide an accurate confidence measurement for each tracked object so that the tracking failures can be identified in time. under the framework  a real-time face tracker is built to track human faces robustly under various face orientations  significant facial expressions  and illumination changes.
1 introduction
object tracking in video sequences is important in applications such as video compression  surveillance  humancomputer interaction  hci   content-based video indexing  and others. however  robustly and accurately tracking objects remains challenging due to the various appearance changes caused by illumination changes  partial or full occlusions  pose variations  non-rigid shape deformations  camera view changes  and so on. therefore  a key task in object tracking research is to design a flexible and accurate model that can automatically cope with appearance changes.
　the template-matching based methods have been extensively used for object tracking by searching the image region that is most similar to an object template. in general  the template-matching based methods could be classified into three groups based on how the template is constructed. the first group extracts the first frame in a video sequence as the template  hager and belhumeur  1; li and chellappa  1; matthews et al.  1 . however  when new parts of the object come into view or the appearance of the object varies significantly during tracking  the template doesn't fit anymore thus the drifting issue becomes serious. in the second group  the preceding frame is extracted as the template  black and yacoob  1; papanikolopoulos et al.  1; ho et al.  1 . in this case  the tracker can inevitably use a wrong template due to partial occlusions or the accumulated errors from previous tracking steps  nguyen et al.  1 . the third group online updates the template from a number of previous frames or several key frames  morency et al.  1; vacchetti et al.  1; lim et al.  1; lee and kriegman  1; jepson et al.  1 . it could overcome some disadvantages of the previous two groups  however  the issue is how to combine the multiple tracked objects appropriately to generate the new template. furthermore  most of them ignore the potential errors associated with each tracked object. therefore once a tracked object view contains an error  it may be integrated into the updated template  and errors accumulate throughout the tracking. consequently  most of the existing tracking methods suffer from the well-known drifting issue  incapable of assessing the tracking failures or recovering from the tracking error.
　in this paper  based on our previous work in  zhu et al.  1   a robust object tracking framework based on casebased reasoning  cbr  is proposed to automatically provide an accurate 1d tracking model at each image frame. specifically  the 1d tracking model in each frame can be online adapted dynamically by combining the object extracted from current frame and the most similar image case retrieved from a case base. unlike our previous work  zhu et al.  1   where the case base is fixed  the case base is constructed and automatically maintained to be competent  representative  and with a reasonable size to make sure that an image case that is most similar to the tracked object can be retrieved quickly for each frame. under the framework  the appearance changes of the tracked object can be adapted dynamically via an adaption mechanism of cbr. as an result  an accurate 1d tracking model can be maintained online and thus the drifting issue that plagues most of the tracking techniques can be well handled. furthermore  under the cbr paradigm  since the tracked view is always adapted from its most similar case in the case base  an accurate similarity measurement can be easily obtained to characterize the confidence level of the tracked region  so that the failure situations can be detected in time.
　based on the proposed framework  we build a real-time face tracking system to track faces in video sequences. such a real-time face tracker can track faces robustly under significant appearance changes in illumination  scale  facial expression  occlusion  and head movement. experiments also demonstrate that the proposed case-base maintenance algorithm is able to automatically update the case base to include enough representative face views and delete redundant ones  so that to maintain the case base in a reasonable size with a good tracking performance. compared to the existing techniques  our proposed technique has the following advantages:
 1  handle the drifting issue well;  1  no need of a 1d model;  1  capable of tracking any object;  1  being able to assess the tracking failures with a confidence level; and  1  automatically update candidate templates based on a case base.
1 the mathematical framework
1 the 1d object tracking model
assume that an object o is moving in front of a video camera. at time t  the object is captured as an image view i xt  at position xt in the image frame it. then the task of 1d visual tracking is to search the image view i xt  of the object
o in each image frame it by using an object model imt . let  be the located image view  then the tracking error 
can be represented as the difference between the true image view i xt  and the located image view of the object:
. given the object model  if we
assume that its most similar image view can be successfully located in the image frame it  then apparently the tracking error  is mostly caused by the inaccuracy of the utilized object model. therefore  a key issue for a successful visual tracking technique is to obtain an accurate 1d tracking model of the object at each image frame it.
　we thus proposea case-based reasoning algorithmto maintain an accurate tracking model for each image frame so that the tracking errorcan be minimized during tracking. figure 1 illustrates the major steps of the proposed algorithm.

figure 1: the diagram of the proposed algorithm
　the first step is to locate the object in the image frame it+1 using the tracked 1d view i xt  as the initial object model. let be the located object view in the image frame it+1. due to image variations  i xt  may not be an accurate model for the image frame at t +1 so that the located image  is not accurate enough to reflect the current object. even though  usually contains information about the object appearance at the current time t +1 partially or completely. thus  the located image view represents an important information source that can be utilized to infer the true view of the object in the image frame it+1.
　then  in the second step   is used to find a new object model by searching a case base. the case base contains a set of representative 1d views of the object  where any unseen image view can be adapted from them with some image adaption strategy. therefore the obtained object model  is able to adapt to the appearance changes in the image frame it+1  and thus also includes essential information to infer the true object view.
　finally  are combined together to get the final image view i xt+1 . since both and contain important information about the object view and complementary to each other  a more accurate 1d tracking model can be obtained at each image frame. therefore  the drifting issue accompanied with most of the visual tracking techniques can be alleviated.
1 the cbr visual tracking algorithm
the above proposed solution can be well-interpreted and implemented in a case-based paradigm. case-based reasoning  cbr  is a problem solving and learning approach that has grown into a field of widespread interests in both academics and industry since the 1's  aamodt and plaza  1 . from a cbr perspective  the problem of visual object tracking in a video sequence can be solved by retrieving and adapting the previously seen views of the object to a new view of the object at each image frame. in the following  we demonstrate the cbr-based tracking algorithm with a face tracking system. more detail can be referred from our previous work at  zhu et al.  1 .

figure 1: the cbr cycle of the face tracking system.
　figure 1 illustrates a general cbr cycle for the built face tracking system  which consists of four processes  retrieve  reuse  revise  and retain.
　case retrieve: the retrieval process searches the most similar face images from a case base composed of the collected representative face images with the located view
. the magnitudes of a set of multi-scale and multiorientation gabor wavelets as in  lee  1  are used as the feature representation of the image appearance. thus the object searching is to find a case that is most similar to  in terms of the gabor response vectors.
　case reuse: the reuse process reuses the information and knowledge in the retrieved face image to refine the previously located face image by adapting to the face appearance changes. it consists of two steps. at the first step  the selected image view is utilized as a tracking model to perform a search starting at in the image frame it+1 for a most similar image view  called . subsequently the second step is to combine the tracked image views and  to obtain the final image view i xt+1  as follows:
		 1 
where is the cosine similarity measure between the gabor response vectors of i xt  and  and is the cosine similarity measure between the gabor response vectors of and. intuitively  it can be seen as a minimization of the sum of two errors  the error between the target view in the current frame and the tracked view in the previous frame  as well as the error between the target view in the current frame and the selected similar case view from the case base. in other words  the tracked target view possesses one important property: it must be similar to the tracked view in the previous frame as well as the selected case view in the case base. when the tracked view satisfies this property  the drifting issue can be well handled and thus the tracking has a high chance to succeed.
　case revision: the revise process evaluates the tracking result with a confidence measure. once the final image view i xt+1  is obtained  another search will be conducted in the case base to find the most similar case. a similarity score st+1 is derived after the searching is done. in practice  if the similarity score is high  tracking is usually successful; otherwise  it may fail. therefore  the derived similarity score st+1 is utilized as a confidence measure to characterize the final image view i xt+1 . the system automatically reports the confidence measure and stores those image views with low confidence level into a temporary database. such a temporary database will be used for case-base maintenance.
　case retain: the retaining process enriches the case base by adding new representative image views. to retain a new case  the image views in the temporary database have to be reviewed periodically  so that only the useful image views are selected and added into the case base. using this process  it is believed that the case base can include more and more representative 1d views of the objects. such a process is one important task in case-base maintenance  which will be presented in the next section.
1 case-base construction and maintenance
for the proposed case-base reasoning system  it is crucial to construct a good case base and maintain the case base automatically and systematically in order to keep or improve the tracking performance in response to object changes in the video sequences. for example  as time goes by  the case-base size may becometoo large  so that it becomesslow to retrieval a similar case. in addition  some cases may become obsolete so that they need to be replaced by more powerful cases. basically  case-base maintenance  cbm  can be referred as the task of adding  deleting  and updating cases  indexes and other knowledge in a case base in order to guarantee the ongoing performance of a cbr system  zhu and yang  1 .
　before we give the detailed algorithms for cbm  we first introduce how to construct the initial case base. the initial case base is generated through a training process combined with human intervention before the tracking system is formally used. specifically  around 1 face images coming from subjects of different ethnicity  gender  age  and face poses are collected. the similarity scores between any of two images have to be small otherwise one of them is regarded as redundant and is thus deleted. overall  the cases in the initial case base are representative  accurate  and diverse. each case is regarded as a cluster and itself is called key case  marked as ii . during cbm  each existing cluster would be enriched and new cluster would be added.
　the proposed cbm algorithm includes two processes: case-updating and case-deleting. case-updating is triggered after each tracking task if the tracking successful rate is lower than a predefined threshold  where the successful rate is defined as the percentage of the image frames that have high confidence scores over the whole image frames. casedeleting is triggered only when the size of the case base is too large so that the tracking speed cannot reach the real-time requirement. in the following  we present the two processes respectively.
1 case-base updating
the case-updating procedure consists of several steps. first  all the images with low confidence scores during tracking are put into a temporary database. second  an off-line multi-view face detector  wang and ji  1  is applied to identify all the face images. the non-face images are then deleted. the third step  also the key step  is to update the case base with the remaining images in the temporary database since the faces in these images are not covered by the current case base. however  we cannot simply add all the identified face images into the case base due to the limitation of the case-base size. also  it is not necessary to put all those images into the case base because most of the images are very similar to each other. by adding some of them into the case base is usually enough to track the remaining images successfully.
　let dt be the temporary database with only face images  do be the current case base. the goal of case-updating is to find a case set d  from the union of dt and do that achieves an optimal tradeoff between the tracking performanceand the overall size of the case base.
d  = arg
where di is any case subset in dt “ do  f di dj  is the tracking performance function  which is the tracking successful rate of using di as the case base to track the images in
dj  and g x  is the penalty function  which is defined as . basically g x  is a modified sigmoid function. when the size of di is very small or very large  the penalty increases little as the size of the case base increases; otherwise  the penalty increases more obviously as the size of the case base increases.
　however  it is an np-hard problem to find such an optimal case base. in practice  we use a greedy approach as shown in table 1 to find an optimal or near-optimal solution.
　the caseupdating function first finds the most similar image i  among the key cases to the face images obtained from the temporary database. if the largest similarity score is still not large enough    ts   it means that the tracking failure is caused by a new face that is not covered in the current case base. thus the caseadding function is called to select a set of images from the temporary database until the tracking performance cannot be improved by adding more cases with equation 1. these selected images are added into the case base as a new cluster and the first selected image during caseadding is marked as the key case. and the unselected images are stored in the testing pool associated with the new cluster.
　on the other hand  if the largest similarity score is large enough    ts   it means the current case base may already have the similar faces  however  the new faces may be different because of the variation of pose  size  facial expressions  or other factors. in that case  it is not necessary to add a new cluster. instead  the algorithm moves the images in the same cluster of i  in the case base as well as the images in the testing pool associated with i  into the temporary database. and then  the caseadding function is called to select a new cluster from the updated temporary database. such a new cluster replaces the previous cluster and a new key case is also generated for the updated cluster. figure 1 illustrates how a cluster is updated in the case base.
caseupdating do dt ts max ○  inf;
for each ii （ dt for each ij  （ do if similarity ii ij     max max ○ similarity ii ij  ;
　　　　　i  ○ ij  if max   ts
caseadding do dt ;
else
dp ○ the image set in the testing pool associated with i ;
di ○ the images in the same cluster of i  in do;
;
;
caseadding;caseadding do dt r1 =	 do	t     |do| |do|;
while	1 &	t = max ○ 1;
for each ii （ dt
do ○ do “ {ii};
r ii  = f do dt   ii    g |do| |do|;
if r ii    r1   max
;
　do ○ do   ii; r ○ r i  ;
	d	;
dt ○ dt   i ;table 1: algorithms of case-updating

figure 1: an illustration of how a cluster in the case base is updated. basically  the testing pool includes the images that the system fails to track in the past and the temporary database includes the images that the system fails to track recently. by considering the images from both the past and current  the updated cluster tends to achieve  global optimal  instead of  local optimal .
　obviously  the structure of the initial case base changes through the updating. in the beginning  each cluster only includes one case and such a case is the key case. and the testing pool is empty. as the updating goes on  more clusters will be added. also  some clusters will be enriched with more cases and the original key case may be replaced with another case or remain the same. in addition  each cluster is associated with a group of images in the testing pool  which are the images that can be handled by this cluster.
　with such an updating procedure  the new representative images that are not covered by the case base can be added automatically and timely. also  the less representative cases in the case base can be replaced with more powerful cases. furthermore  since the updating procedure is guided by the performance of the tracking system  it guarantees that the newly added cases always improve the tracking system.
1 case-base deleting
although the case-updating procedure performs both adding and deleting actions to the case base  it is still possible that the overall size of the case base may become too large so that the tracking speed is affected and slows down. if that happens  it is necessary to delete some cases.
　the case base includes two types of cases: key case  and non-key case  as defined in the updating procedure. we associate each case with a utility value. it is defined as the frequency that the case is selected as the most similar case during tracking. for each newly added case  the utility is set equal to the current lowest utility value in the case base  or 1 if the current minimal value is 1 . obviously  the higher the utility is  the more desirable to keep the case in the case base. the deletion procedure starts from the non-key case that has the lowest utility value. for the cases with the same utility value  the algorithm deletes them evenly from each cluster  to avoid that one cluster is almost empty while another one is full of cases. in fact  since the searching algorithm and computational methods are efficient in our system  the system can achieve a real-time performance even when the size of the case base is around 1. therefore the deletion procedure rarely happens.
　overall  with the proposed automatic cbm algorithms  the case base tends to include all the representative face views and delete redundant ones so that to maintain the case base in a reasonable size with a good tracking performance.
1 experimental results
based on the proposed cbr visual tracking framework  a real-time face tracking system is built. the whole system runs at 1 frame per second  fps  in a machine with a 1ghz cpu. when a person appears in the view of the camera  the person's face is automatically localized via the proposed frontal face detector  wang and ji  1  and tracked subsequently by our proposed face tracker. the initial case base includes 1 face images  which are automatically updated as more and more video sequences are tested. to test the performance of the built face tracking system  a set of face video sequences with several new subjects are collected. we first demonstrate the performance of the proposed case-base maintenance  cbm  algorithm  and then demonstrate the performance of the face tracker.
1 case-base maintenance
to test the performance of the proposed case-base maintenance algorithm  1 testing sequences from 1 novel subjects are collected. these subjects are not included in the initial case base  and with different races and gender. each of the testing sequence consists of 1 frames.
　figure 1 demonstrates the overall performance of the system with and without the cbm algorithm. as shown in the figure  without the cbm algorithm  the successful rates for most testing sequences are below 1 because the original case base cannot cover most of the new face images. with the cbm algorithm  the case base is enriched with the new faces gradually thus the system performance is continually improved. after around 1 testing sequences  the average successful rate is higher than 1  and the size of the case base converges and becomes stable  which implies that the current case base is competent for our current subject pool.

figure 1: comparison of the face tracking performance with cbm and without cbm: the curve marked with stars represents the number of cases; the curve marked with diamonds represents the tracking successful rate without cbm; the curve marked with squares represents the tracking successful rate with cbm.
　figure 1 i  gives an example of how the cbm works in a specific video sequence. the two curves represent the confidence measurements with and without cbm respectively. in most sequences  the faces can be tracked successfully  which can be reflected by the fact that most of the confidence scores are higher than 1. figure 1 iv  lists the three mostfrequently retrieved cases from the case base during the tracking. it shows that although the subjects in the three cases are different from the subject in the video sequence  they can still help to track the faces in most time  which demonstrates the robustness of the cbr-based method of our system. however  for the frames around a  b  c  d  and e  the tracking fails because the cases in the case base are not similar enough. figure 1 ii  lists the five images corresponding to a  b  c  d  and e in the video sequence  and figure 1 iii  lists the most similar cases that are retrieved from the case base. after adding the images in figure 1 ii  to the case base  all the faces are tracked well. since the newly added cases are very different in facial appearances or face poses from the cases in the case base  they increase the representativenessof the case base and thus can improve the system performance.
1 tracking performance
we first demonstrate the self-correction  drifting-elimination  capability of the proposed tracking scheme. two other popular tracking techniques are implemented to compare to our method. the first technique is the traditional two-framebased tracking method  matthews et al.  1   which utilizes the previously tracked face image to update the tracking model dynamically. the second one is the tracking technique with the incremental subspace learning  lim et al.  1   which dynamically updates the object model by incremental learning its eigen-basis from a set of previously tracked faces.
 i 
 ii 
 a   b 	 c 	 d 	 e 
  iii 
	 a.1 	 b.1 	 c.1 	 d.1 	 e.1 
		 iv 
figure 1:  i  comparison of the estimated confidence measurements before and after case updating;  ii  the corresponding images in the video sequence;  iii  the most similar cases retrieved from the case base before updating;  iv  the most-frequently retrieved cases from the case base during tracking.

	 a 	 b 
figure 1: comparisons of the tracked face position error between the proposed tracker and  a  the two-frame tracker;  b  the incremental subspace learning tracker.
　figure 1 compares the performance of the three face trackers for a face sequence under significant head movements and facial expressions. from figure 1  a   it is obvious that the tracking error of the two-frame tracker accumulates as the tracking continues. eventually it drifts away from the face and tracks the wrong object. figure 1  b  shows that the tracking technique with the incremental subspace learning also drifts and tracks the wrong object eventually. one possible reason is that because the tracked face view contains errors or non-face image pixels  they are learned and accumulated in the model throughout the video sequence and eventually lead to drifting. however  our proposed tracking method can eliminate the tracking error in each frame gradually during tracking  while still tracking the face robustly.
　in addition  when the two-frame tracker and the subspace learning tracker fail  they cannot automatically detect failures and still continue tracking. on the other hand  our proposed method can indicate the failures through confidence measurements. in practice  we found that when the confidence score is higher than 1  the tracking is usually successful.
　furthermore  the proposed method can perform well with different individuals  under significant illumination changes  different facial expressions  and various face orientations. as shown in figure 1  the appearance of the persons' faces changes drastically due to the illumination changes  face orientations  facial expressions as well as partial occlusions  which makes the tracking task extremely difficult. however  the proposed method can still track the faces well because of its capability of maintaining a good object model.

figure 1: the face tracking results with significant facial expression changes  head movements  occlusions  illumination changes  and multi-face presenting.
1 conclusions
in this paper  a simple but effective visual tracking framework based on cbr paradigm with confidence level is introduced to track faces in video sequences. under the proposed framework  different faces can be tracked robustly under significant appearance changes without drifting via the assistance of the most similar case retrieved from the case base. the case base is automatically maintained to be competent  representative  and with a reasonable size for real-time retrieval of useful cases. in addition  a confidence measurement can be derived accurately for each tracked face view so that the failures can be assessed successfully. it provides a nice framework to handle the drifting issue that has plagued the face tracking community for a long time. all of these merits of the proposed framework are demonstrated through a real-time face tracking system that can track human faces under various face orientations  significant facial expressions  and illumination changes. such a framework can be easily generalized to track other objects by only updating its case base.
acknowledgments
this project was supported in part by the air force of scientific research  afosr  under the grant number f1-1 and in part by the defense advanced research project agency  darpa  under the grant number n1-1.
