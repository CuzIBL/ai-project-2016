 
　　one of the most fundamental problems in vision is segmentation; the way in which parts of an image are perceived as a meaningful whole. 
　　recent work has shown how to calculate images of physical parameters from raw intensity data. such images are known as intrinsic images  and examples are images of velocity  optical flow   surface orientation  occluding 
contour  and disparity. while intrinsic images are not segmented  they are distinctly easier to segment than the original intensity image. segments can be detected by a general hough transform technique. networks of feature parameters are appended to the intrinsic image organization. then the intrinsic image points are mapped into these networks. this mapping will be many-to-one onto parameter values that represent segments. 
　　this basic method is extended into a general representation and control technique with the addition of three main ideas: abstraction levels; sequential search; and tight counting these ideas are a nucleus of a connectionist theory of low 'eve and m'ermediate-level vision. this theory explains segmentation in terms of massively parallel cooperative computation among intrinsic images and a set of parameter spaces at different levels of abstraction. 
　　the preparation of this paper was supported in part by the defense advanced research projects agency  monitored by the onr  under contracts n1-c1 & n1-1 -c-1. 
1. 	overview 
　　one of the most troublesome puzzles in vision is how parts of an image are seen as a meaningful whole or segment. this is known as the segmentation problem. the ambiguous use of segment  which means part  to denote a whole  arises from the fact that a segment is an intermediate component in a description which relates an object with an image. from the viewpoint of the object description  the segment is a part. from the viewpoint of a group of image points with common properties  the segment is a whole. 
　　parts of an image are seen as a segment if the corresponding physical object has common physical or geometric properties  or features. for example  if a 
　　connected component of the image has a single color  say red  then it may be seen as a segment. the patch of red arises from the physical object's surface reflectance. usually there are not one but several features which have the same spatial registration  lor example  consider a moving  red cube. 
　　many factors make segmentation difficult. for example  features are not always spatially registered. given a multicolored cube  which feature should be the most compelling  the color or the geometric lines indicating the cube'1 in the general case this answer depends on the goals of the perceiver. another common problem occurs when an object is occluded; a theory of low-level vision must be able to explain how an object is seen as a segment when the features are only partially registered or incomplete. real image data is also noisy and many segments are only perceived owing to the combination of weak evidence of several features the evidence may be so weak that each feature  if viewed in isolation  would be unuiterprelable. 
　　fvidence from psychology suggests that the minimum time for human beings to respond to a visual stimulus is approximately 1 ms. if the time constant for a neural unit is approximately  . ms  this means that about 1 cycles are available for the complete perceptual processing and motor response in ih   case. the human brain has about 1 ' neurons  any of which may be involved in the processing. if connections must go through intermediate units  the best strategies involve on the order of the logarithm of the number of neurons. thus there is little time to do more than link up the right neurons. arguments like these support connectionist theories of brain processing: 
　　 the connectionist view of brain and behavior is that all encodings of importance in the brain are in terms of the relative strengths of synaptic connections. the fundamental premise of connectionism is that individual neurons do not transmit large amounts of symbolic information. instead they compute by being appropriately connected to large numbers of similar units.   feldman and ballard  1  
　　we develop the nucleus of a connectionist theory of low-level and intermediate level vision which explains the above aspects of segmentation in terms of massively-parallel cooperative computation  rosenfeld et al.  1; zucker  1; marr  1  between two groups of networks. one group  intrinsic images  harrow and tenenbaum  1   can be computed primarily in terms of local constraints. the other  termed a feature space  can be computed primarily in terms of global mappings from intrinsic images to feature space  feature space is also distinguished from intrinsic image space in that it is not relinotopic. feature space itself may have many different levels of abstraction. 

1 

　　intrinsic images and feature spaces are collectively called parameter networks because they both have a common organization. that is  the network is an organization of basic units  each representing a value of a 
　　particular parameter. the basic element of a parameter network is a parameter unit. a parameter unit will represent a single parameter value and has an associated confidence. the value is a set of numerical measurements for the node; the confidence is a measure of their believability. for example  if there is an edge at  1  with orientation 1＜ and length 1 units  the vector value of the parameter node representing the edge is  x.y.o.s  -  1 1＜.1 . the associated confidence is a measure of the fuzziness of this estimate. one way a confidence may be increased is if there are nearby edges of the same orientation which align. thus in figure 1 the edges in  a  and  b  have the same value but we can be more confident in case  b . 

figure 1 
     collections of value units form networks. fach value unit is connected to a subset of other value units  and can alter only the confidence of those units. underlying physical principles determine the appropriate connection subsets. the confidence updating is done by non linear relaxation. 
in this formalism  a segment has a simple interpretation: // is a set of high-confidence units which are connected. the overall structure of the paper shows how abstractions of physical principles lead to connections in networks. the reader interested in more implementation details should consult  feldman and ballard  1 . the principal elements of the theory are the following. 
1  a lowest level of abstraction consisting of several intrinsic images which are computed simultaneously. 
recent work has shown how to calculate intrinsic images from intensity data. examples are images of velocity 
 optical flow   horn and schunck  1; ullman  1; 
1   surface orientation  horn and sjoberg  1; ikeuchi  1   occluding contour  prager  1; rosenfeld et al.  
1   and disparity  marr and poggio  1; barnard and thompson  1 . intrinsic images can be computed independently under special conditions  but in general they are interdependent. intrinsic images are in concert with the hypothesis that the visual system builds many intermediate descriptions from image data. these descriptions represent important parameters such as velocity  depth  surface reflectance explicitly  since in the explicit form they are easier to map into object descriptions. 
1  intermediate levels of abstraction consisting of feature spaces. 
if parts of the intrinsic image are organized in some way  this organization can be detected by a general hough transform technique  duda and hart  1; ballard  1a; kender  1; ohlander et al.  1  termed a constraint transform. this is done by describing the organization in terms of more abstract parameters and then mapping the intrinsic image points into parameter space. the transformation will be many-to-one onto parameter values which represent meaningful segments. major advantages of the hough transform are that it is relatively insensitive to occlusion and noise. 
1  hierarchies involving several levels of abstraction. the constraint transform is a way of seeing spatial information as a unit. however  if the unit has a complex structure the mapping from space to unit can be unmanageably complex. a way around this is to introduce 
units at several levels of abstraction  sabbah  1; ballard and sabbah  1; kender  1 . this reduces a complex transform to several simpler transforms between units at successively higher levels of abstraction. 
1  focus-ofattention tnecliantstns. 
visual focus of attention can be partly explained as the conjunction of two mechanisms: 1  the use of constraint transforms to modify sensor input; and 1  the sequential application of constraint transforms. 
1  coupling between intrinsic images and feature spaces. in general  intrinsic images cannot be computed without global parameters. at the same time  these global parameters are what we mean by seeing parts of the intrinsic image as a segment. in these cases the intrinsic image and parameters are said to be tightly coupled: although each cannot be computed independently  they can be computed simultaneously  ballard  1b; 1c . 
　　we re-emphasize that our interest is low-level vision. thus in item  1  above  focus of attention is interpreted in a narrow sense: visual features which are clear can help the recognition of other features  or perhaps direct eye movements . we do not attempt to explain general plans and goals. 
1. intrinsic linages 
　　an intrinsic image is an image of some important parameter that is in registration with the original intensity image  barrow and tenenbaum  1; marr  1   that is  each parameter is indexed by retinal coordinates. for example  in the velocity  optical flow  image  one is able to compute at each point in time and for each spatial position a local velocity vector v x t . figure 1 shows horn's example for a rotating sphere  horn and schunck  1 . intrinsic images may only be computable over certain parts of the image  and over those parts the parameters are continuously varying. while intrinsic images are not segmented into parts of objects  they are distinctly easier to segment than the original intensity image. 


　　somewhat surprisingly  intrinsic images can all be computed in a similar manner. two constraints  one derived from physical principles and the other from a constraint that the resultant images should be locally smooth  suffice to specify a parallel-iterative algorithm. table 1 shows this commonality but is not an exhaustive list of approaches. 

while the above algorithms work well on images which are constrained to satisfy the underlying assumptions  they may not work in the general case. almost always there are free parameters or boundary conditions which have to be determined independently. i or example  in the surface orientation  a boundary contour is necessary  bruss  1 . 
1 	multi-resolution relaxation methods 
one notion of  boundary condition  is image resolution. 
previous methods for computing intrinsic images have used a single image resolution  but in most situations this is unrealistic. what is the correct resolution  at high resolution:  1  noise is a factor;  1  convergence is slow; and  1  basic assumptions may not hold. to see the last point  imagine trying to compute shape from shading using a surface with a micro-texture. at low resolution the surface structure is blurred and simple reflectance models hold  but at high resolution the microstructure can render such models useless. low resolution may not always be appropriate  however. fven though noise is less of a factor 
and convergence is fast  basic assumptions may still not hold. the last point arises from the fact that most intrinsic images are computed from constraints which assume local variations are smooth. with increasing grid resolutions  these assumptions are less likely to be valid. 
　　hence a conjecture is that there is a range of resolutions for which the computations will be valid. furthermore  this range is expected to be spatially variant. a tool for exploring this conjecture is multigrid relaxation techniques  brandt  1   which have proven very useful for solving differential equations. this model  together with reasoning from physical first principles  should allow the determination of image dependent grid resolutions for which intrinsic image computations are valid. mulligrid techniques are of course related to pyramids  tanimoto and pavlidis  1; hanson and riseman  1; sloan  1 . 
1 	cooperative computation of multiple intrinsic images 
intrinsic images are logically computed simultaneously. 
in fact  they have to be; otherwise each intrinsic image is underdetermined in the general case.  only on certain synthetic images is the computation well-defined.  furthermore  they are highly interdependent  particularly at points of discontinuity  harrow and tenenbaum  1 . for example: 
* intensity edges can be indicative of depth discontinuities. thus the edge image is coupled to the disparity image; 
  surface orientation is also indicative of depth discontinuity and is thus related to the other two; and 
* different objects which are moving relative to each other produce discontinuities in the flow field. 
1 　　by incorporating these couplings in the intrinsic image computations  one should find general cases where the computations will converge. a separate issue is the behavior of the coupled computations in the face of conflicting information. 

marr and poggio. 1 ; and 1  a variable unit  ikeuchi. 
1; horn and schunck  1 . in the first model there is a unit for every value of every variable; in effect the representation has only constants. constant value units may have outputs which are confidences between zero and one. in the second model  each unit represents a variable which can take on values  the standard method is to use an array for these units . the output is the value; there is no explicit notion of confidence. 

　　note that the updating function is nonlinear  when the underlying physical relation r is nonlinear. if the relation r can be linearized then the cooperative computations can be shown to be equivalent to linear programming  hinton  1 . the linear case has also been analyzed by  hummel and zucker  1 . 
1. 	feature spaces 
　　what does it mean to perceive parts of an image as a segment1 in our theory  this perception takes place if there is a feature space such that each of the parts can have the same parameter value. this general idea is illustrated by the following examples. 
* parts of a color image may be seen as a segment if they have the same color. in this case the parameter space is a space of colors and the parts map into a common point representing the common color. 
* farts of an optical flow image may be seen as a 
segment if they are part of a rigid body that is moving. in this case the parameter space represents the rigid body motion parameters of transnational and rotational velocity and parts of the image map into a common point in that space. 
  parts of edge and surface orientation images may be seen as a segment if they are part of the same shape. this case is more complicated as there must exist some internal representation of the shape. given this representation  the parameter space represents the transformation  scale  rotation  translation  from the internal representation to the  viewer-centered  image representation. parts of the image which are seen as the shape have common values for these parameters. 
　　a general way of describing this relationship between parts of an image and the associated parameters is a connectionist 	interpretation 	of 	the 	hough 	transform 
 hough  1; duda and hart  1; kimmc et al. 1; shapiro  1  which we have termed constraint transforms. 
in our low-level vision theory  constraint transforms relate intrinsic image units to feature units at different levels of abstraction. if an intrinsic image parameter is a vector unit  x a x   in an intrinsic image space a and an element of feature space is a vector b in a feature space b then there is usually a physical constraint that relates a x  and b  i.e.  some relation f a b  such that f a b  = 1. the general form of f a b  is a table since f may not have an analytic form. 
　　the space a represents all possible intrinsic image values. a particular intrinsic image is described by a set of 
values . now the set  is only consistent with certain elements in the space b  owing to the constraint imposed by the relation f. this physical constraint can be exploited in the following manner. for each ak  compute the set 

　　bk is the set of nodes in the feature space network b that the ak unit must connect to. define h b  as the number of times the value b occurs in   the union of all sets bk . h b  is the constraint transform from the space a to the space b and is the number of points in intrinsic image space which are consistent with the parameter value b. h b  makes the most sense when the values both and b are discrete. hence the constant sb above is related to the quantization in the space b. h is also best normalized by defining . in that case  the value 
c b  can stand for the confidence that the segment with feature value b is present in the image. h b  can be thought 
of as a histogram and c b  a normalized histogram. 
　　concerning the implementation of constraint transforms in networks  is the subset of b units to which the unit ak hould be connected in the network. a separate hmax unit is needed for normalization. 
　　the constraint transform need not originate from intrinsic image space but can be defined between any two spaces a and b as long as there is some relation f a b  = 1 for  to avoid describing the above computations in detail  we use a shorthand notation for constraint transforms. each transform can be described as the triple  where the necessary computations are implicit. note that the order of a and b is important in the notation; in general   is not equivalent to  b a f . 
as a very simple example of a constraint transform  we describe how a patch of red in an image may be seen as a unit. for this to happen  an association is made between the spatially contiguous points in the image and the particular value  red  in a parameter space of colors. there are essentially three dimensions to color space. although r-g-b is widely used in computer applications  humans seem to use an opponents-process basis  r-g  y-b  white-black   hurvich and jameson  1 . denote this transformation by t. then the constraint transform is given by  a b f  where 


figure 1: segmentation in color space hanson and riseman . 
　　the transformation results in a set of very sparsely distributed high-confidence feature space units. in our own work  color space is represented by rgb units in a threedimensional space of 1 total units. only approximately 1% of the units have maximum confidence values. this figure is also typical of other modalities. in general  each ak and the relationship f will not determine a single unit in bk but there still will be isolated high-confidence units. figure 1 shows why this is the case: different ak units connect to common units in the feature space b. 

　　of course segmentation must involve ways of associating peaks in several different feature spaces and methods for doing this are discussed in section 1  but the cornerstone of the techniques are high-confidence units  histogram maxima  in the individual-modality feature spaces. 
　　one might think that this is a clustering technique presented with a different formalism. the constraint transform method is similar to clustering but differs in an important way. in general  feature space units are not independent but may interact through mutual connections. for example  consider l-joint units in an origami world feature space  sabbah  1 . opposing l-joint units increase the confidence of each other. these kinds of effects are disallowed in clustering models. 
table 1 shows some other constraint transforms. 
table 1: constraint transforms 
a: intrinsic image 
color 
disparity optical flow 
surface orient'n. 
occluding contour 
texels b: feature space 
  segments of constant color  ohlander et al.  1; hanson and riseman  1  
  surface orientation  kender  1  
  segments of constant disparity  fischler and barrett  1  
  heading  lawton  1; prager  
1  
  rotation of 1d rigid body  ballard  1c  
  illumination angle  ballard  1b    shape  ballard and sabbah  1  
  shape  kimme et al.  1; duda and hart  1  
  surface orientation  kender and 　　　　　　　　　　　　　kanade  1  to show how intrinsic images and parameter spaces may be related in more complicated ways  we briefly describe an example of how a specific two-dimensional shape is detected by specifying a constraint transformation from edge space  local linear edges delected with a standard edge detector  to a four-dimensional parameter space consisting of local origin coordinates  rotation and scale. both the color-space example and this one have the same solution at an abstract level. in each case there is a transformation from intrinsic image space to parameter space that segments the image. in the first case  points in the color image have the same color values. in the second case  points in the edge image have the same shape parameter values. 
1 	constraint transforms: two-dimensional shapes 
　　known two-dimensional shapes can be located in a primal sketch  marr  1  by encoding the shape information in a constraint table  ballard  1a . the problem reduces to finding the parameters of the transformation from the viewed shape to its internal representation. consider the case where an object being sought has no simple analytic form  but has a particular silhouette. suppose for the moment that the object appears in the image with known shape  orientation  and scale  so that its location is the only unknown parameter set.  if orientation and scale are unknown  they can be handled as additional parameters  as will be shown.  now pick a coordinate system for the silhouette and draw a line to the boundary from the coordinate system origin. at the boundary point  compute the gradient direction and length and store the reference point as a function of this information. thus it is possible to precompute the offset vector  r a  of the reference point from boundary points given the gradient angle. the basic strategy of the constraint technique for shapes is to compute the loci of 

1 


have different sets of associated radial line segments  f'ig. 1 . the same situation occurs with respect to optical flow due to pure translation. if the objects in the image are stationary with respect to a translating observer  then the implementation in parameter networks 
　　the earlier definition of the constraint transform assumed that the measurements ak all had confidence equal to show an example in detail  render's technique for detecting vanishing points in an images from oriented line segments  kender  1  is described. such line segments which are part of a given vanishing point form a radial field which emanates from the point. different vanishing points flow vectors will be emanating radially from a  focus-ofto unity. with higher level of abstraction constraint 
expansion   foe  in the direction of motion. objects transforms  this may no longer be the case. this is easily translating with respect to the observer's frame will produce 
their own flow emanating from a different foe  fig. 1 . 	handled by keeping track of the confidences in the set bk  

1 


1 

1 	multiple  spatially-registered features 
　　sequencing solves the problem of building up coherent groups of features  but poses other problems. for example  if the  blue    moving    horizontal  object were a  frisbee   one would like this percept to be triggered via a constraint transform. however  in the sequencing example  there is initial evidence for all light-blue objects  and this is a very large set. worse  the percept  frisbee  could be triggered by non-spatially registered groups of  blue  and  moving  inputs. there is a solution to these problems if one assumes that  in general  actual occurrences of features will be sparse. in other words  in a given image there should not be two very similar colors associated with different objects. if there are  our constraint transform model will only be able to concentrate on one of them at a 
time. 	1. 	tight coupling 

1 

　　it is important to remember that the boundary conditions in this problem have been provided a priori: in this case they are the orientation of the surface at the boundary of the bubble. generally  these will have to be determined by multiple intrinsic images relaxations  as 
mentioned in section 1. 
	1. 	discussion 
　　this paper introduces a connections theory to show how parts of an image are seen as a segment. the focal point of the paper is the notion of constraint transform  which is a generalization of the hough transform to nonanalytical relations. a key contribution is the decomposition technique that allows high-dimensional constraint transforms to be partitioned into sequential groups of lower dimensional constraint transforms. 
　　the other important ideas in this paper are summarized in the introduction. here we mention other ideas which do not fit easily under any one of the previous headings. 
　　1  the intrinsic image/feature space decomposition. distinguishing image fields and image features determines when relaxation is the more important tool and when the constraint transform is more important. 
　　1  unit/value. reducing the underlying primitives to units of extreme simplicity allows the algorithmic determination of the connection patterns to represent m-ary relations. 
　　1  massive parallelism. massive parallel computation reduces the need for sequential processing to more essential cases. for example  in section 1  sequential processing resolved real ambiguities in the input. 
　　1  extensibility. the representation is very general  being m-ary consistency relations  and can be extended to other domains besides vision  or to arbitrary levels of abstraction within vision. 
