
in this paper  we present a simple yet novel method of exploiting unlabeled text to further improve the accuracy of a high-performance state-of-theart named entity recognition  ner  system. the method utilizes the empirical property that many named entities occur in one name class only. using only unlabeled text as the additional resource  our improved ner system achieves an f1 score of 1%  an improvement of 1% in f1 score and a 1% error reduction on the conll 1 english ner official test set. this accuracy places our ner system among the top 1 systems in the conll 1 english shared task.
1 introduction
the named entity recognition  ner  task involves identifying and classifying noun phrases into one of many semantic classes such as persons  organizations  locations  etc. ner systems can be built by supervised learning from a labeled data set. however  labeled data sets are expensive to prepare as it involves manual annotation efforts by humans. as unlabeled data is easier and cheaper to obtain than labeled data  exploiting unlabeled data to improve ner performance is an important research goal.
　an empirical property of named entities is that many named entities occur in one name class only. for example  in the conll 1 english ner  sang and meulder  1  training set  more than 1% of named entity types have exactly one name class. this paper presents a novel yet simple method of exploiting this empirical property of one class per named entity to further improve the ner accuracy of a high-performance state-of-the-art ner system. using only unlabeled data as the additional resource  we achieved an f1 score of 1%  which is an improvement of 1% in f1 score and a 1% error reduction on the conll 1 english ner official test set. this accuracy places our ner system among the top 1 systems in the conll 1 english shared task.
1 system description
the ner system we implemented is based on the maximum entropy framework similar to the mene system of  borthwick  1 . each name class n is divided into 1 sub-classes: nbegin  ncontinue  nend  and nunique. since the conll 1 english ner shared task data has 1 name classes  person  organization  location  and miscellaneous   there is a total of 1 classes  1 name classes 〜 1 sub-classes + 1 not-aname class  that a word can possibly be assigned to.
1	maximum entropy
in the maximumentropyframework the best model is the one that has the highest entropy while satisfying the constraints imposed. these constraints are derived from training data  expressing some relationship between features and class. it is unique  agrees with the maximum-likelihood distribution  and has the exponential form  pietra et al.  1 :
 
where c refers to the class  h the history  or context   and z h  is a normalization function. the features used in the maximum entropy framework are binary-valued functions which pair a class with various elements of the context. an example of a feature function is
  word = john
generalized iterative scaling  gis  is used to estimate the parameters αj  darroch and ratcliff  1 .
1	testing
it is possible that the classifier produces a sequence of invalid classes when assigning classes to the words in a test sentence during testing  e.g.  personbegin followed by locationend . to eliminate such sequences  we define a transition probability between classes  p ci|cj   to be equal to 1 if the transition is valid  and 1 otherwise. the probability of assigning the classes c1 ... cn to the words in a sentence s in a document d is defined as follows:
 
where p ci|s d  is determined by the maximum entropy classifier. the sequence of classes with the highest probability is then selected using the viterbi algorithm.
1 feature representation
our feature representation is adapted from  chieu and ng  1   but without using any external name lists. we now give a general overview of the features used.
1	local features
local features of a token w are those that are derived from only the sentence containing w. the main local features are:
　zoning each document is segmented using simple rules into headline  author  dateline  and text zones. the zone is used in combination with other information like capitalization and whether the token is the first word of the sentence.
　lexical information strings of the current  previous  and next words are used in combination with their case information. words not found in a vocabulary list generated from training data are marked as rare.
　orthographic information such information includes case  digits  and the occurrence of special symbols like $ within a word.
　word suffixes for each named entity in the training data  1-letter word suffixes that have high correlation score with a particular name class are collected.
　class suffixes a list is compiled from training data for tokens that frequently terminate a particular name class. for example  the token association often terminates the organization class.
1	global features
global features are derived from other sentences in the same document containing w. the global features include:
　n-grams unigrams and bigrams of another occurrence of the token.
　class suffixes class suffix of another occurrence of the token.
　capitalizationthe case informationof the first occurrence of the token in an unambiguous position  non-first words in a text zone .
　acronyms words made up of all capitalized letters are matched with sequences of initial capitalized words in the same document to identify acronyms.
　sequence of initcaps for every sequence of initial capitalized words  its longest substring that occurs in the same document is identified.
　name class of previous occurrences the predicted name classes of previous tokens are used as features.
1 approach
1	one class per named entity
in the conll 1 english ner training data  we have observed that around 1% of the named entity types and 1% of the named entity tokens have exactly one class. incidentally  within natural language processing  there are similar observations proposed previously regarding the number of word senses of a collocation  one sense per collocation  yarowsky  1   and the number of word senses of occurrences of a word in a document  one sense per discourse  gale et al.  1  . table 1 shows the percentage of named entities that have exactly one class from the training datasets of several different shared tasks. it can be seen that this empirical property occurs in other languages as well.
1	motivation
consider the following sentence taken from a news article reporting soccer results in the conll 1 english shared task official test set:
ac milan   1   v udinese   1   1
　this sentence contains two named entities: ac milan and udinese are organization names. if these named entities have not been seen in the training data  it might be difficult to predict their name class due to poor contextual information. consider the following two sentences found in the english gigaword corpus:
ac milan  who beat udinese 1 at the san siro stadium  and lazio  who won 1 at cagliari  also have a maximum six points from two games.
milan needed a 1th minute own goal headed in by udinese defender raffaele sergio to get off the mark  and were pegged back on the hour by paolo poggi.
　it is easier to predict the named entities in the above sentences as tokens like beat and defender offer useful hints to the classifier.
　in a data set  different sentences contain differing amounts of useful contextual information. this results in a classifier predicting a mix of correct and incorrect labels for the same named entity. if we have a reasonably accurate classifier  there will be more correct labels assigned than incorrect labels in general.
　we propose a method of exploiting this empirical property of one class per named entity by using the most frequently occurring class of a named entity found in a machine-tagged data set. we call this most frequently occurring class of a named entity its majority tag.
1	baseline method
the conll baseline system  sang and meulder  1  first determines the majority class c of a named entity n found in the training data. the baseline system then labels all occurrences of n found in the test data with class c  regardless of context. any named entities in the test data which do not appear in the training data are not assigned any name class.
test atest ball nes11seen nes11table 1: f1 score of the baseline method for all named entities and for only named entities seen in the training data
languageshared tasktypestokensenglishconll 1%1%germanconll 1%1%dutchconll 1%1%spanishconll 1%1%english  biomedical bionlp 1%1%table 1: percentage of named entities that have exactly one class for several shared task training datasets.　table 1 summarizes the f1 score of the baseline method for all  seen and unseen  named entities and all seen named entities. in all tables in this paper  test a refers to the conll 1 development test set and test b refers to the conll 1 official test set. a named entity is seen if it exists in the training data. the baseline f1 score of the official test t ○ training dataset
u ○ unlabeled dataset e ○ test dataset
1. train classifier h1 on t
1. label u using h1
1. l ○ extract  ne majtag  pairs from u
1. train classifier h1 on t using l
1. label e with h1 using l
figure 1: pseudocode for the majority tag method
set is 1. however on closer examination  the f1 score is 1 when we only consider the named entities seen in the training data. unseen nes lower the f1 score since the baseline method does not assign any name class to named entities in the test set that are not found in the training data.
　this shows that the poor baseline performance is primarily attributed to unseen named entities. in addition  reasonable  though not great  performance can be obtained using this baseline method if all the named entities are seen  even though contextual information is not used. this suggests that the majority tag is valuable and can be exploited further if more unseen named entities in the test data can be discovered beforehand. one way to do this is to gather named entities in machine-taggedunlabeled text so as to increase the likelihood that a named entity found in the test set is seen beforehand. even though the ner system that labels the unlabeled text is not perfect  useful information could still be gathered.
1	the majority tag as a feature
there are some words like jordan that can refer to a person or a location depending on the context in which they are used. hence  if the majority tag is incorporated as a feature  a classifier can be trained to take into account the context in which a named entity is used  as well as exploit the majority tag.
　figure 1 gives the high-level pseudocode of our method which is based on the maximum entropy framework and involves two stages. first  an initial-stage supervised classifier h1 is trained with labeled data t. the classifier h1 then labels a large unlabeled dataset u to produce a machine-tagged data set u.
　next  the majority tag list l is produced by extracting the list of named entities with their associated majority tags from this machine-tagged data set  thus contains a list of  ne majtag  pairs  where majtag is the name class that occurs most frequently for the named entity ne in the machine-tagged data set  the case of named entities is retained  i.e.  whether a named entity appears in upper or lower case   and named entities that occur only once in u are pruned away from l.
　lastly  a final-stageclassifier h1 is trained with labeled data t and uses the majority tag list l to generate the new feature described as follows. during training or testing  when the h1 classifier encounters a sequence of tokens w1...wn such that  w1...wn nc  （ l  a feature mjtag-nc will be turned on for each of the tokens w1 ... wn in the sequence. if there is more than one matching sequence of different lengths  preference will be given to the longest matching sequence. for example  consider the following sentence:
udinese midfielder fabio rossitto has the flu.
　if  udinese org    fabio rossitto per   and  fabio loc  are present in the majority tag list  the features in the first column below will be turned on. notice the feature that is turned on for fabio is mjtag-per and not mjtag-loc  because the longest matching sequence is fabio rossitto.
featuretokenmjtag-orgudinese-midfieldermjtag-perfabiomjtag-perrossitto-has-the-flu1 experiments
our unlabeled data set consists of 1 million words from the ldc english gigaword corpus. for all experiments  features that occur only once in the training data are not used and the gis algorithm is run for 1 iterations. unlabeled data is randomly selected from the english gigaword corpus. the reported scores are the averagesof ten runs  and similar trends are observed over all runs.
1	results
table 1 shows the f1 scores of two systems trained with 1k and 1k labeled examples and exploiting increasing amounts of unlabeled data. the entire conll 1 labeled training set is used for the 1k runs. performance peaks at 1 million words of unlabeled data on the conll 1 official test set  test b  and drops slightly after that. the best f1 score for the official conll english test set is 1% using 1 million words of unlabeled data. this is an improvement of 1% in f1 score and an error reduction of 1%. the +1% improvement in the 1k system shows that the method is even more effective on a small labeled dataset. improvements on small labeled data sets are important for other resource-poor languages where labeled data is scarce.
　figure 1 and figure 1 show the accuracy improvements with increasing amounts of unlabeled data  using 1k and 1k labeled examples respectively. accuracy generally increases at a decreasing rate with additional unlabeled data for both systems.

figure 1: test b f1 score of our system trained with the full 1k labeled training dataset from conll and exploiting increasing amounts of unlabeled data.

figure 1: test b f1 score of our system trained with 1k labeled examples from the conll training dataset and exploiting increasing amounts of unlabeled data.
1	comparison with previous best results
figure 1 shows the performance comparison of our system against the systems in conll 1. the top system  florian et al.  1  uses an externally trained ner system as part of a combined system. the second best system  chieu and ng  1  uses external name lists and has a score of 1  but when not using any external name lists  its score drops to 1.
　note that the ner system reported in this paper does not utilize any external name lists. rather  the majority tag list was generated automatically from machine-tagged unlabeled data  without manual labeling of name class for names found in this list. in addition  the names found in our majority tag list may contain errors in general  since they are automatically determined. despite this  we have achieved performance at the third place. our results are encouraging given that we use unlabeled data as the only additional resource.
1 analysis
table 1 shows the number of named entities in test b discovered due to adding 1 million words of unlabeled data. in the rightmost column of table 1  named entities are considered seen if they are found in either the training data or the machine-tagged unlabeled data. the unlabeled data is labeled with a classifier trained with 1k labeled examples. it can be seen that adding unlabeled data has successfully led to a large proportion of named entities previous unseen to be discovered.
1 m1mseen nes1unseen nes1table 1: seen and unseen counts of named entities in test b before and after using 1 million words of unlabeled data. in this table  named entities are seen if they exist in the training data or machine-tagged unlabeled data. the classifier is trained with 1k labeled examples.
　table 1 shows the test b f1 score of the two systems before and after using 1 million words of unlabeled text.
 a  1k labeled training examples
1 m1 mchangeall11+1seen nes11+1unseen nes11+1 b  1k labeled training examples
1 m1 mchangeall11+1seen nes11+1unseen nes11+1table 1: breakdown of improvement in f1 score for seen and unseen named entities in test b using 1 million words of unlabeled text.

1k  all 1kmwordstest atest btest atest b1.1.1.1.111111.1.1.1.111111.1.1.1.111111.1.1.1.111111.1.1.1.11111max improvement+1+1+1+1table 1: f1 scores for different amounts of labeled and unlabeled data. unlabeled data are randomly selected from the english gigaword corpus. reported f1 scores are obtained using an average of 1 runs.

figure 1: comparison of f1 scores on the official test set against the systems in the conll 1 shared task. our system's performance is represented by the black shaded column at the third place.

the f1 scores for seen and unseen named entities are separately listed. in this table  a named entity is considered seen if it is present in the labeled training data. in both systems  the improvement of f1 score on unseen named entities is much greater than that of the seen named entities. this demonstrates that we are successful in what we set out to achieve: using unlabeled data to improve the accuracy of unseen named entities.
1 related work
 zhu  1  gave a comprehensive summary of recent work in learning with labeled and unlabeled data. there is much research on co-training  such as  blum and mitchell  1; collins and singer  1; pierce and cardie  1 . our work does not fall under the co-training paradigm. instead of using two cooperating classifiers  we use two classifiers in two stages. co-training produces a final system combining two different sets of features that outperforms either system alone. in our work  however  the final-stage classifier has the features of the initial-stage classifier with an additional majority tag feature.
　 ando and zhang  1  presents a semi-supervised learning paradigm called structural learning. this method identifies the common predictive structure shared by multiple classification problems  which can then be used to improve performance on the target problem. the auxiliary classification problems are automatically generated on unlabeled data. our proposed method in this paper to exploit unlabeled data is complementary to their proposed structural learning method.
　although prior research efforts on bootstrapping methods for ner  collins and singer  1; cucerzan and yarowsky  1  also rely on the empirical property of one class per named entity in some way  our work reported in this paper is different in that it exploits this property to make a very good ner system even better. in particular  its simplicity allows it to be easily applied to other resource-poor languages when labeled data is scarce.
1 conclusion
in this paper  we have presented a novel yet simple technique applied to the named entity recognition task using majority tags. by using unlabeled data as the only additional resource  we have achieved an error reduction of 1% and an f1 score of 1%. our ner system has achieved performance among the top 1 systems of the conll 1 shared task.
