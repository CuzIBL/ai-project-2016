p a n e l o n 
p a r a l l e l i n f e r e n c e m a c h i n e s 
w . bibel 
institut fur informatik  tu munchecn  postfach 1  d-1 muncfaen 1 
     
     the quest for ever more powerful computers has bumped up hard against the limits imposed by nature such as speed of light and electrons. however  scientists and industry agree that there is still a great potential for further speed-up by distributing computations among many processors rather than a single one. this is apparent for problems that can easily be broken down into many independent parts such as those to be tackled in graphics  signal processing  which includes radar  speech and vision analysis   structural analysis  fluid-flow dynamics  particle physics  and many others. first experiences with the new breed of parallel computers justify this optimism. 
     it is less obvious whether a multi-processor would bring a significant improvement in performance for problems such as inferencing. finding a correct chain of inferences requires searching through a space of different possible chains  a problem known to be hard  np-complete  and requiring exponential recources in worst cases according to our present knowledge. therefore one might argue that one thousand processors would provide relatively little improvement over a single one in worst  exponential  cases. from a more practical point of view  experiments seem to indicate that the possibilities for exploiting parallelism in rule-based systems might be rather limited. 
     there are more problems of detail arising in an attempt to parallelize inferencing. the different possible chains in the search space partially coincide in a way not known at compile time hence making it difficult to break the whole task down into many parts and distribute these in a well-balanced way. also  but not only  because of this overlap it seems attractive to exploit the parallelism inherent in each of these chains. but at present it is not clear at all whether this really pays since it might cause too much overhead in communication and anyway might have only a marginal effect in view of the more severe problem of np-completeness mentioned above. 
     some even put forward reasonable arguments to the effect that inferencing in practice is not needed at all. part of it could be substituted by exploiting data-base techniques even in the presence of recursion. or  machine reasoning could be founded on episodes from the past stored in a massively parallel memory rather than on rules and facts thus leading to a memory-based reasoning with a 
1 panels and invited talks 
parallelism radically different from the one discussed above; with this remark we scratch on the current discussion about connectionism. 
     much of what was pointed out above reflects the spirit of classical reasoning or even more specifically horn-clause  or production-rule-based  reasoning. as we know human reasoning has many flavors that might still cause  at least practical  problems with their integration into this classical deduction scheme. non-mono tonic  probabilistic  inductive reasoning are some of the keywords pointing to such additional aspects. little has been done in view of parallelizing such more complicated  though essential  inference techniques. 
     another controverse discussion is lead on the question to what extent the user should control the taskpartitioning and thus the parallelism. more generally  how should we program a machine with say 1k processors that operate in an asynchronous way  because of the differences in the various parts a synchronous behavior seems to be unrealistic . there is a whole spectrum of opinions on these programming language aspects that might reflect the different possible user levels  ranging from the software engineer to the casual user. 
     given so many questions about the nature of the task of inferencing in general and its inherent parallelism in particular  it is no surprise that we still lack a convincing proposal for an architecture of a parallel inference machine. what should be its topology  the power of its processors  the mechanisms of its communications  synchronization  and load-balancing  these are some of the questions that are currently studied in many laboratories around the world. 
     in this situation it was thought that a panel discussion would provide the appropriate forum to serve a number of functions. it might give a feel for the relevance of each of the controverse discussions mentioned above and the different standpoints taken in them. at best  it might even help to provide some answers to the questions of concern. in any case it will inform the al-community that much more is going on in this promising area than one might think from the relatively sparse publications  which is typical for any field during its initial phase of experimentation. 
