 
     a paradigm for automatic speech recognition using networks of actions performing variable depth analysis is presented. the paradigm produces descriptions of speech properties that are related to speech units through markov models representing system performance. 
     preliminary results in the recognition of isolated letters and digits are presented. 
1. introduction 
recent results on automatic speech recognition 
 asr  and speech analysis suggest that progress in designing recognition devices and in advancing speech science knowledge may arise from an integration of the 
so called cognitive and in formation-theoretic approaches . 
     the cognitive approach attempts to infer analytic knowledge about possible speech invariants and their relations. work by zue   klatt   stevens  and de mori et al.  are along this line. 
     the information theoretic approach is based on a performance model containing states and transitions between any pair of states . probabilities can be learned that the system is in any of the model states or is changing state through any of the allowed transitions. furthermore  the model generates in each state or in each transition  observable system parameters or descriptors according to some statistical distribution. 
     this paper proposes an attempt to integrate the two above mentioned approaches. 
     the idea is that of extracting speech properties using knowledge about acoustic correlates of linguistic units. for an abstract linguistic unit  the corresponding acoustic correlates have attributes which may differ from an instantiation to another due to the fact that different speakers produce different signals even if they intend to pronounce the same sound. attribute statistics of sound properties collected on a large variety of pronounciations of the same sound from different speakers are probably the best knowledge we can gather today for characterizing different speaking styles. furthermore  some expected acoustic properties can be missed in some cases and some unexpected properties can be detected in some other cases. these aspects can also be characterized by stochastic performance models. 
     an important problem arising when large vocabularies have to be recognized is that of identifying a possibly small set of speech units  su  with which all the possible words and word concatenations can be obtained by com pi lotion. the learning problem is then reconducted to the conception of a performance model for each su. 
1. 	a 	m o d e l 	f o r 	c o m p u t e r 
p e r c e p t i o n o f speech 

is applied which produces a . the relation r 1 may depend on the speaker  his/her mood  state of health and history. as  may produce several as for the same s  probability distributions for all the possible as can be derived using a generative model. 

	r1 	depends on 	the 	anatomy of the speaker. 
again  the same actions may produce different signals  because the speech production system is soft and its behavior is affected to some extent by the environment. 
     if the speaker does not read but generates a sentence from a set c of concepts  then a third relation is applied: 
		 1 . 
1 	perception r1 may depend on the speaker and his/her culture. statistical models can also be used for characterizing 
	1. 	p r o c e d u r a l n e t w o r k s 
     a procedural network  pn  can be described with a formalism similar to that used for an augmented transition network grammar  atng . this formalism has been successfully used for natural language and pattern recognition . a pn is a 1tuple 
 ii  
where is the network identifier  is a finite set of states  a is a finite set of directed arcs  is the initial state and is the final state. without any loss of generality we consider only pns with a single initial state and a single final state. 
each arc a  	is a 1 - tuple: 
 1  
           is the starting state of is the terminal state of is a measure associated to the arc  it can be a weight or a probability according to the scoring method used by the pn supervisor described later on   condition  is a condition and action  is an action; both of them are associated to the arc. the conditions can be categorized in two classes: 
cond n 
refers to a user defined condition n. 
default r 
refers to a default condition  it is satisfied only if no other condition of any arc whose starting state is  returns a measure greater than r . 
the actions are executed by the pn supervisor and can be categorized in five classes 
exen 
executes a user defined action; such an action is usually a  matcher  which performs some computations on the input data and returns a result. 
push i is defined as follows. let's assume that has an arc that contains push i. let be the process that executes . when the arc is reached whose associated action is push i  the execution of  is suspended. the state of  is pushed on the top of the stack of the pn supervisor. a new process  that executes pn  is created and executed. when the final state of pn  is reached  the last arc of pn  is considered. it has associated either a popabs f or a popcond f action. this action is executed. it returns scores computed by  these scores are passed to whose execution is resumed while  terminates. 
popabs f 
is associated to the final state of a pn. it stops the execution of the current network process and the result of the execution of the user defined function f is returned. 
popcond f 
this action is also associated to the final state of a 
pn. it has a synchronization capability that stops the execution of the current network if all the paths in the network leading to the final state have propagated their contribution to the computation of the scores the pn has to provide. if the condition is reached  then the result of the execution of the user defined function f is returned. 
jmp makes the score associated to  propagate to qt¡À without any change. 
each pn is associated a working memory  wm . 
actions associated with the arcs of a subnetwork produce descriptions stored into the subnetwork wm. when a push to a subnetwork is made  the network supervisor may link the subnetwork wm with other wm  thus establishing the viewpoint within which conditions are tested. most of the actions associated with arcs include plans  hidden-markov-models  hmm   local parsers  rule-based inference units. all these tools are used for extracting an unambiguous description d of a speech pattern and for computing an a-priori probability for an hvpothesis h: 
		 1  
     the pn supervisor keeps up to date a search space where each node is represented by the following four-tuple: 
 1  
where: 
 is a state of a with a buffer containing the information propagated by the actions executed before reaching it  
- context  is the context  viewpoint  in which the conditions and actions of the arcs starting at q have to be executed  
~t is the starting time of the speech signal for the execution of sensory procedures invoked by the actions associated with the arcs starting at q  
- score  is the score of the hypothesis contained in or implied by  context  up to t. composite scores can be evaluated as likelihoods: 
 1  
where 	is obtained by a language model. 
     the size of the search space can be kept small in spite of a large number of states in the pn if conditions and actions are properly chosen and placed in the network. 
1. an example of application 
     multi-speaker recognition of isolated letters and digits was performed on four  two male and two female  speakers. 
     the vocabulary used for this experiment is defined in table i. the speech utterance is segmented into 
acoustic segments  as  with an algorithm described in 
. 
	de mori  merlo  palakal  and rouat 	1 

model just outlined  d should be of variable duration because the articulatory actions  gestures  are of variable duration. 
     descriptions must refer to parameters  morphologies and properties that are characteristic for a sound and exhibit low variances when many speakers  different microphones and environments are considered. 
     in practice  fixed duration models have been developed and tested with a considerable degree of success mostly in speaker-dependent systems. in one of the most successful systems developed so far   d is a sequence of symbols obtained every 1 msecs. by vftptnr-qnunt.iration with a process that is speakerdependent and context-independent. 
   relation  has to capture two different types of knowledge. the first type of knowledge is a relation: 
		 1  
between a sequence u of speech units  su  and corresponding descriptions d . there are speech units like the plosive sound /b/ for which a large variety of different descriptions d are perceived as the same sound. relation  is many-to-one and it could be interesting to collect statistics of the elements of the universe of acoustic descriptions that produce the perception of the same linguistic sound. these statistics may represent distributions of acoustic patterns produced by a single or many speakers having the intention of producing the same sound. statistics may also take into account characteristics of background noise. 
a second type of knowledge is a relation: 
		 1  
where s is a linguistic entity like a sentence and u is a sequence of speech units.  can also contain statistics. 
l l1 may represent how different speakers may have different pronounciations of the same word. a stochastic model representing a word w in terms of sus can be built. 
     an interesting possibility  we would like to explore in this paper  is that of designing procedurally   through actions to be performed on x  t  in order to obtain d  u and s . 
¡¡¡¡¡¡it seems that variable depth descriptions can be very useful in complex tasks where a preliminary selection of hypotheses has to be done based on robust but simple descriptions and then a more detailed analysis has to be performed involving levels of depth depending on the competing hypotheses  or just on acoustic preconditions. 
     the entire perception model can be represented by procedural networks which invoke subnetworks at several levels. at each level  different types of units can be defined and statistics of their components can be collected. 


speech units contained in it. for this purpose  actions are introduced for describing the as head  its vocalic part  and its tail according to the pn shown in figure 
1. 

     speech units correspond in this example to phonemes and are characterized by  place and manner of articulation . 
     the as head is analyzed by attached procedures  actions  performing an elaboration-decision  ed  paradigm. there are two possible ed-actions for the head of an as  namely: 
-plosive head 
-fricative  including afficate  head 
the choice of the ed action is made by disjoint conditions associated to arcs. these conditions are regular expressions of primary acoustic cues introduced in   state ml in fig. 1. will be reached by only one arc. using techniques partially described elsewhere   hypotheses about the place and manner of articulation for the speech unit in the head subsegment are generated and scored by the following a-priori probability: 
after state m l   the ed-action  vocalic  is executed. it segments the vocalic part of as into stationary and transient units. 
let 

be such subsegments. for each segment vx spectral lines are considered as data  see  for details  and apriori probabilities about place and manner of articulation are obtained by hmms of spectral lines in the segment vt. for each subsegment and for each consistent  place-manner  pair  the following probability is computed. 
		 1 . 
     from state m1 to state m1  ed-actions for the tail of as are executed similar to those used for the head. 
a probability 
		 1  
scores the hypotheses of the tail subsegment. the data extracted in the head  the subsegments of the vocalic part and the tail -can be assumed to be independent. the  select  action associated to the popabs arc computes for each candidate hypothesis the probability pr  data /hyp  by multiplying the probabilities of the phonemes which appear in  hyp  : 

     preliminary results have been obtained on a test set of 1 utterances of words belonging to the alphabet defined in table i and pronounced by four speakers. the voices of these speakers were used for learning only head and tail statistics. an overall recognition rate superior to 1% was achieved. 
a c k n o w l e d g e m e n t s 
this work was supported by the national science and engineering research council of canada under grant 
a1. we would like to thank lorraine harper for her help in the final preparation and layout of the paper. 
