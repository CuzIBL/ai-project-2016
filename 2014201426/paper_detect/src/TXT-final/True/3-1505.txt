
we present the first tractable  exact solution for the problem of identifying actions' effects in partially observable strips domains. our algorithms resemble version spaces and logical filtering  and they identify all the models that are consistent with observations. they apply in other deterministic domains  e.g.  with conditional effects   but are inexact  may return false positives  or inefficient  we could not bound the representation size . our experiments verify the theoretical guarantees  and show that we learn strips actions efficiently  with time that is significantly better than approaches for hmms and reinforcement learning  which are inexact . our results are especially surprising because of the inherent intractability of the general deterministic case. these results have been applied to an autonomous agent in a virtual world  facilitating decision making  diagnosis  and exploration.
1 introduction
autonomous agents have limited prior knowledge of their actions' preconditions and effects when they explore new domains. they can act intelligently if they learn how actions affect the world and use this knowledge to respond to their goals. this is important when their goals change because then they can reason about their actions instead of trying them in the world.
﹛learning actions' effects and preconditions is difficult in partially observable domains. the world state is not known completely  actions' effects mix with each other  and it is hard to associate change in one feature with a specific action or situation. thus  it is not surprising that work so far has been limited to fully observable domains  e.g.   wang  1; pasula et al.  1   and to hill-climbing  em  approaches that have unbounded error in deterministic domains  e.g.   ghahramani  1; boyen et al.  1  .
﹛this paper presents an approach called slaf  simultaneous learning and filtering  for exact learning of action's effects and preconditions in partially observable deterministic domains. this approach determines a set of possible transition relations  given a sequence of actions and partial observations. it is online  and updates a logical formula that models the possible transition relations and world states with every time step. it finds exactly those transition relations when actions are strips  i.e.  no conditional effects  or they map states 1.
﹛our algorithms take polynomial time in the number of features  n  and the number of time steps  t  for many cases. their exact complexity varies with properties of the domain. for example  the overall time for learning strips actions' effects is o t ﹞ n . for other cases the update per time step takes linear time in the representation size. we can bound this size by o nk  if we approximate the representation with a k-cnf formula  yielding an overall time of o t ﹞ nk  for the entire algorithm.
﹛our experiments verify these theoretical results and show that our algorithms are faster and better qualitatively than related approaches. for example  we can learn strips actions' effects in domains of   1 features exactly. in contrast  work on learning in dynamic bayesian networks  e.g.   boyen et al.  1    reinforcement learning in pomdps  e.g.   littman  1    and inductive logic programming  ilp   e.g.   wang  1   either approximate the solution with unbounded error for deterministic domains  or take time   1n   thus  are inapplicable in domains larger than 1 features . section 1 provides a comparison with these and other works.
﹛our technical advance for deterministic domains is important for many applications such as automatic software interfaces  internet agents  virtual worlds  and games. other applications  such as robotics  human-computer interfaces  and program and machine diagnosis can use deterministic models as approximations. finally  understanding the deterministic case better can help us develop better results for stochastic domains.
in the following  section 1 defines slaf precisely  section 1 provides a deduction-based exact slaf algorithm  section 1 presents tractable model-update algorithms  section 1 gives sufficient conditions and algorithms for keeping the model representation compact  thus  overall polynomial time   and section 1 presents experimental results.
1 slaf semantics
we define our slaf problem with the following formal tools  borrowing intuitions from work on bayesian learning of hidden markov models  hmms   ghahramani  1  and logical filtering  amir and russell  1 . a transition system is a tuple hp s a ri  where
﹛  p is a finite set of propositional fluents;
﹛  s   pow p  is the set of world states;
﹛  a is a finite set of actions;
﹛  r   s ℅ a ℅ s is the transition relation. thus  a world state  s ﹋ s  is a subset of p that contains propositions true in this state  and r s a s∩  means that state s∩ is a possible result of action a in state s. our goal in this paper is to find r  given known p  s  a  and a sequence of actions and partial observations  logical sentences on any subset of p .
﹛a transition belief state is a set of tuples hs ri where s is a state and r a transition relation. let r = pow s℅ a ℅ s  be the set of all possible transition relations on s a. let s = s ℅ r. when we hold a transition belief state 老   s we consider every tuple hs ri ﹋ 老 possible. for example  consider the situation presented in figure 1. there  we have two rooms  a light bulb  a switch  an action of flipping the switch  and an observation  e  we are in the east room . the real states of the world  s1 s1∩  shown in the top part   are unknown to us.
﹛the bottom part of figure 1 demonstrates how our knowledge evolves after performing the action sw-on. 老1 老1 are our respective transition belief states. in 老1 we know that the possible world states are s1  s1  or s1  s1 s1 are arbitrary world states   with r1  r1  and r1  their respective transition relations. 老1 is the resulting transition belief state after action sw-on. action sw-on takes state s1 to s1∩ according to transition relation r1  so hs1∩ r1i is a pair 老1. similarly  it takes state s1 to one of s1∩ s1∩∩ according to transition relation r1  and it takes s1 to s1∩ according to r1. thus  hs1∩ r1i hs1∩∩ r1i hs1∩ r1i are in pair 老1. finally  observing e eliminates the pair hs1∩ r1i from 老1  if e is false in s1∩.
definition 1  slaf semantics  let 老   s be a transition belief state. the slaf of 老 with actions and ob is defined by
{hs∩ ri | hs a s∩i ﹋ r  hs ri ﹋ 老};
1.is true in s};
1.
.

figure 1: top: two rooms and flipping the light switch. bottom: slaf semantics; progressing an action  the arrows map state-transition pairs  and then filtering with an observation  crossing out some pairs .
step 1 is progression with a  and step 1 filtering with o.
﹛we assume that observations  and observation model relating observations to state fluents  are given to us as logical sentences over fluents after performing an action. they are denoted with o. when actions can be inexecutable or may fail  it is useful to assume that p contains a special boolean fluent  ok  whose value is the success of the last action attempted.
﹛transition belief state 老 generalizes version spaces  e.g.   wang  1   as follows: if the current state  s  is known  then the version space's lattice contains the set of transition relations 老s = {r | hs ri ﹋ 老}. it also generalizes belief states: if the transition relation  r  is known  then the belief state  set of possible states  is 老r = {s | hs ri ﹋ 老}  read 老 restricted to r   and
logical filtering  amir and russell  1  of belief state 考 and action a is equal to  thus  we define it as 
filter a  考  =  slaf a  {hs ri | s ﹋ 考}  r.
1 slaf via logical inference
learning transition models using definition 1 directly is intractable because it takes space   1|p|  in many cases. instead  in this section we represent transition belief states more compactly  sometimes  using logic  and compute slaf using general purpose logical inference.
﹛we represent every deterministic transition relation  r  with a language  l  of propositions afg whose meaning is  if g holds  then f will hold after executing a . we have afg ﹋ l for every action a ﹋ a  f a literal  possibly negated proposition  from p  and g a complete term over p  a conjunction of literals from p such that every fluent appears exactly once . we call f g the sets of effects  f  and preconditions  g  respectively. thus  we have 1|p| ﹞ 1|p| ﹞ |a| new propositional variables  in section 1 we decrease this number .
﹛define  r  the logical theory that represents r  by  1r = {afg ﹋ l |  hs a s∩i ﹋ r  s |= g   s∩ |= f} and  r =  1r ﹍ { afg | afg ﹋ l    1r}.
﹛some intuitive properties hold for this representation.  r is a complete theory for every r  a sentence or its negation is always implied from  r . also   r |=  afg   a gf  for every f ﹋ f g ﹋ g.
﹛thus  for every transition belief state 老 we can define a theory in l l ﹍ p  that corresponds to it:  老 = hs ri﹋老 s ＿  r . similarly  for every theory   in l l ﹍ p  we define a transition belief state 老  = {hs ri | s ﹋ s  s＿ r |=  }  i.e.  all the state-transition pairs that satisfy  . we say that theory   is a transition belief formula  if  老  √    note: 老 老 = 老 always holds .
﹛for a deterministic  possibly conditional  action  a  define the effect model of a for time t to be
teff a t  = vl﹋f g﹋g  at ＿ alg ＿ gt    lt+1  ＿ l﹋f	t+1 ＿ at    wg﹋g alg ＿ gt   
 l
 1 
where at asserts that action a occurred at time t  and we use the convention that  t is the result of adding subscript t to every fluent symbol of  . the first part of  1  says that if a executes at time t  and it causes l when g holds  and g holds at time t  then l holds at time t + 1. the second part says that if l holds after a's execution  then it must be that holds  with g corresponding to the current state. these two parts correspond to effect axioms and explanation closure axioms used in situation calculus.
﹛now  we are ready to describe our zeroth-level algorithm  slaf1  for slaf of a transition belief formula. denote by cnv     the set of consequences of   that are in vocabulary v   and let lt+1 = pt+1 ﹍ l the vocabulary that includes only fluents of time t + 1 and effect propositions from l. at time t we apply progression for the given action a and current transition belief formula   t  and then apply filtering with the current observations:
1. slaf1 a   t  = cnlt+1  t ＿ at ＿ teff a t   1. slaf1 o   t  =  t ＿ ot
﹛we can implement cnv     using consequence finding algorithms  such as resolution and some of its variants  e.g.   simon and del val  1  . the following theorem shows that this formula-slaf algorithm is correct and exact.
theorem 1 for   transition belief formula  a action 
slaf a  {hs ri ﹋ s | hs ri satisfies  }  =
{hs ri ﹋ s | hs ri satisfies slaf1 a    }
﹛our zeroth-level algorithm may enable more compact representation  but it does not guarantee it  nor does it guarantee tractable computation. in fact  no algorithm can maintain compact representation or tractable computation in general. slaf is np-hard because logical filtering is np-hard  eiter and gottlob  1  even for deterministic actions. also  any representation of transition belief states that uses poly |p|  propositions grows exponentially  in the number of time steps and |p|  for some starting transition belief states and action sequences.
1 efficient model update
learning world models is easier when slaf distributes over logical connectives. the computation becomes tractable  with the bottleneck being the time to compute slaf for each part separately. in this section we examine when such distribution is possible  and present a linear-time algorithm that gives an exact solution in those cases  and a weaker transition belief formula otherwise .
﹛distribution properties that always hold for slaf follow from set theoretical considerations and theorem 1:
corollary 1 for   肉 transition belief formulae  a action 
slaf a    ˍ 肉  √ slaf a     ˍ slaf a  肉 
|= slaf a    ＿ 肉    slaf a     ＿ slaf a  肉 
﹛stronger distribution properties hold for slaf whenever they hold for logical filtering.
theorem 1 let 老1 老1 be transition belief states.
r
	1	1 .
﹛we conclude the following corollary from theorems 1  1 and theorems in  amir and russell  1 .
corollary 1 for   肉 transition belief formulae  a action  slaf a   ＿肉  √ slaf a    ＿slaf a  肉  if for every relation r in 老  老肉 one of the following holds: 1. a in r maps states 1
1. a has no conditional effects  and we know if it fails   and   ＿ 肉 includes all its prime implicates.
1. the state is known for r: for at most one s  hs ri ﹋ 老  ﹍ 老肉.
﹛figure 1 presents procedure factored-slaf  which computes slaf exactly when the conditions of corollary 1 hold. consequently  factored-slaf returns an exact solution whenever our actions are known to be 1. if our actions have no conditional effects and their success/failure is observed  then a modified factored-slaf can solve this problem exactly too  see section 1 .
﹛if we pre-compute  and cache  the 1n possible responses of literal-slaf  then every time step t in this procedure requires linear time in the representation size of  t  our transition belief formula. this is a significant improvement over the  super exponential  time taken by a straightforward algorithm  and over the  potentially exponential  time taken by general-purpose consequence finding used in our zeroth-level slaf procedure above.
theorem 1 step-slaf a o    returns a formula  ∩ such that slaf a o     |=  ∩. if every run of literalslaf takes time c  then step-slaf takes time o | |c . finally  if we assume one of the assumptions of corollary 1  then  ∩ √ slaf a o    .
﹛we can give a closed-form solution for the slaf of a belief-state formula  a transition belief formulae that has no effect propositions afg . this makes procedure literal-slaf tractable  and also allows us to examine the structure of belief state formulae in more detail.
procedure factored-slaf hai oii1 i≒t   
 i  ai action  oi observation    transition belief formula.
1. for i from 1 to t do 
 a  set   ↘ step-slaf oi ai   .
 b  eliminate subsumed clauses in  .
1. return  .procedure step-slaf o a   
o an observation formula in l p   a an action    a transition belief formula.
1. if   is a literal  then return o＿literal-slaf a   .
1. if   =  1 ＿  1  return step-slaf o a  1 ＿stepslaf o a  1 .
1. if   =  1 ˍ  1  return step-slaf o a  1 ˍstepslaf o a  1 .procedure literal-slaf a    a an action    a proposition in lt or its negation.
1. return cnlt+1  t ＿ at ＿ teff a t  .figure 1: slaf using distribution over ＿ ˍ
theorem 1 for belief-state formula   ﹋ l p   time t  action a  ca = vg﹋g l﹋f alg ˍag l   and g1 ... gm ﹋ g all the terms in g such that gi |=   
m
slaf a   t  √  m   lit+1 ˍ ag lii  ＿ ca
l1 ... l ﹋f i=1
﹛proof sketch we follow the characterization offered by theorem 1 and formula  1 . we take  t ＿ at ＿ teff a t  and resolve out the literals of time t. this resolution is guaranteed to generate a set of consequences that is equivalent to cnlt+1  t＿at＿teff a t  . assuming  t ＿ at  teff a t  is logically equivalent to l﹋f g﹋g g|=  lt+1    gt   alg  . this follows from two observations. first  notice that  t implies that for any g ﹋ g such that g 1|=   we get
and   the antecedent does not hold  so the formula is true . second  notice that  in the second part of the original is equivalent  assuming.
﹛now  resolving out the literals of time t from  t ＿at ＿ teff a t |  should consider all the resolutions of clauses
 gt is a term  of the form and all the clauses of the form with each other.
this yields the equivalent to
	m	m
1 mi   gii gii t+1  l l
	 l	ˍ	 a	＿  a	  
g  ... g ﹋ g i=1 i=1   |= wim≒m gi
	l1 ... l	﹋ f
because to eliminate all the literals of time t we have to resolve together sets of clauses with matching gi's such that   |= wi≒n gi. the formula above encodes all the resulting clauses for a chosen set of g1 ... gm and a chosen set of literals l1 ... lm. the reason for including  is that we can always choose a clause with
gi li of a specific type  either one that includes  alg or one that produces a gl.
﹛finally  we get the formula in our theorem because afg √  a gf  g characterizes exactly one state in s   and the fact that there is one set of g1 ... gm that is stronger than all the rest  it entails all the rest  because g1 ... gm are complete terms. this set is the complete fluent assignments gi that satisfy  . 
﹛a consequence of theorem 1 is that we can implement procedure literal-slaf using the equivalence
theorem 1
       l ＿ slaf a  true  otherwise
notice that the computation in theorem 1 for   = l a literal is simple because g1 ... gm are all the complete terms in l p  that include l.
1 compact model representation
in theorem 1  m could be as high as 1|p|  the number of complete terms in g. consequently  clauses may have exponential length  in n = |p|  and there may be a super-exponential number of clauses in this result.
﹛in this section we restrict our attention to strips actions  fikes et al.  1   and provide an overall polynomial bound on the growth of our representation  its size after many steps  and the time taken to compute the resulting model. strips is a class of actions that has been at the focus of interest for the area of ai planning and execution for many years. it includes deterministic  unconditional  but sometimes not executable  actions.
1 actions of limited effect
in many domains we can assume that every action a affects at most k fluents  for some small k   1. it is also common to assume that our actions are strips  and that they may fail without us knowing  leaving the world unchanged. those assumptions together allow us to progress slaf with a limited  polynomial factor  growth in the formula size.
﹛we use a language that is similar to the one in section 1  but which uses only action propositions alg with g being a fluent term of size k  instead of a fluent term of size n in g . semantically .
theorem 1 let   ﹋ l p  be a belief-state formula  t time  and a a strips action with ≒ k fluents affected or in the precondition term. let gk be the set of all terms of k fluents in l p  that are consistent with  . then 
k
slaf a   t  √	 k	k   lit+1 ˍ a glii  ＿ ca
g1 ... g ﹋ g i=1 g1 ＿ ... ＿ gk |=  
l1 ... lk ﹋ f
﹛the proof  omitted  uses two insights. first  if a has only one case in which change occurs  then every clause in theorem 1 is subsumed by a clause that is entailed by slaf a   t   has at most oneper literal li  i.e.  li 1= lj for i 1= j  and gi is a fluent term  has no disjunctions . second  every with g term is equivalent to a formula on with gi terms of length k  if a affects only k fluents.
﹛thus  we can encode all of the clauses in the conjunction using a subset of the  extended  action effect propositions   with g being a term of size k. there are o nk  such terms  and o nk+1  such propositions. every clause is of length 1k  with the identity of the clause determined by the first half  the set of action effect propositions . consequently  slaf a   t  takes
o nk1+k﹞k1  space to represent using o nk1+k  clauses of length ≒ 1k.
1 always-executable actions
many times we can assume that our actions are always executable. for example  our sequence of actions does not include action failures when this sequence is chosen by a knowledgeable agent  e.g.  a human  that has better observations than we do.
﹛we use a language that is similar to the one in section 1  but which uses only action propositions al  l always holds after executing a  and al   l is not affected by a . semantically   and
.
﹛we assume that transition-belief formula   is fluentfactored  i.e.  it is the conjunction of  f such that each  f concerns only one fluent  f  and actions' effects on it. also  for every f   f √   fˍexplf ＿ fˍexpl f ＿af  with explf expl f af formulae over action propositions af  a f  and af   possibly multiple different actions . we call this format fluent-factored. the intuition here is that explf and expl f are all the possible explanations for f being true and false  respectively. also  af holds knowledge about actions' effects on f  knowledge that does not depend on f's current value. for example  if we know nothing about actions that affect f  e.g.  when we start our exploration   then  f =   f ˍ true  ＿  f ˍ true  ＿ true.
with this representation  slaf a   f  is
  fˍ afˍ af ＿explf   ＿ fˍ a fˍ af ＿expl f   ＿a
a similar formula holds for observations. this contributes to a much simpler algorithm  aestrips-slaf  that we present in figure 1. it computes slaf of a fluent-factored transition belief state in this form with a sequence of actions and observations.
theorem 1 let   be a fluent-factored transition belief formula  and assume a1 ... at are always-executable strips actions  and o1 ... ot are observation terms.
procedure ae-strips-slaf hai oii1 i≒t    ai actions  oi observations    = vf﹋p  f fluent-factored with  f =   f ˍ explf  ＿  f ˍ expl f  ＿ af.
1. for every f ﹋ p do: for i from 1 to t do 
 a  set  f ↘   f ˍ  af ˍ  af  ＿ explf    ＿  f ˍ
 a f ˍ  af  ＿ expl f    ＿ af.
 b  if oi |= f  we observed f   then set  f ↘   f ˍ true  ＿  f ˍ false  ＿ af ＿ explf.
 c  if oi |=  f  we observed  f   then set  f ↘   f ˍfalse ＿ f ˍtrue ＿af ＿ expl f.
1. eliminate subsumed clauses in   = vf﹋p  f.
1. return  t =  .figure 1: slaf with always-executable strips.
then  procedure ae-strips-slaf hai oii1 i≒t    returns  t √ slaf hai oii1 i≒t   1  in time o t ﹞ |p|   and | t| ≒ o t ﹞ |p| .
﹛the reason for the space bound on the end formula | t| is that at every time step we increase the size of the formula by adding to it at most 1 new elements per fluent. we can further improve the implementation to take time o t ﹞ |o|   for |o| the largest number of fluents observed at once. also  the bound on the space taken by  t can be improved in two ways. first  o |p| ﹞ 1|a|log|a|   for a our set of actions  is a bound on the cnf representation of  t because every part  tf of it is similar to . thus  if
|a| is small  then this bound is manageable. second  if every fluent f is observed at least once every k actions  or an action which affects f occurs  and we know its effect   then the cnf representation of  t takes space o |p| ﹞ |a|k . again  if k is small  this bound is useful.
1 action preconditions
unfortunately  a simple procedure such as ae-stripsslaf  figure 1  does not provide an exact solution in general. the reason is that action failure makes fluents co-dependent  each of them could have caused this failure . for instance  consider figure 1  and assume that we add the fluent ok which indicates that the last action succeeds. if we know only  on  the light is off   then slaf sw-on   on  ＿  ok  i.e.  sw-on failed  e.g.  because we are in the west room  implies a eok＿sw＿ lit  by theorem 1.
﹛instead  we compute the effect for every literal using theorem 1   assuming exactly k fluents are changed by action a  and then approximate by dropping all clauses with more than one fluent  other than ok . thus  we can augment step 1 a  in ae-strips-slaf with a condition that a succeeded  oi |= ok   and add that if a fails  then we use the following formula instead: set  f ↘   f ˍ  explf ＿expl ok f  ＿ fˍ expl f ＿expl ok  f  ＿af  for expl ok l = v g1 g1﹋ gk  agl1 ˍ a gok1  .
g ＿ g |= l
﹛the size of the resulting formula is larger by an additive o |expl ok l|  = o n1k  per fluent. thus  the result after t steps is a formula  t with | t| ≒ o t ﹞ |p|1k   which is polynomial and feasible for small k's.
1 using the model and adding bias
our algorithms compute a solution to slaf as a logical formula. we can use a sat solver to answer queries over this formula  such as checking if it entails af  for action a and fluent f. the number of variables in the result formula is always independent of t  and is linear in |p| for some of our algorithms  so we can use current sat solvers to treat domains of 1 features and more.
﹛many times it is also desirable to prefer some models over others. we can represent such bias using a preference model  e.g.   mccarthy  1   or a probabilistic prior over transition relations. we add this bias on top of our slaf result   t  and get an exact solution if we can run inference on the combined model. preferential bias is well studied and fits easily with logical formula  t  e.g.  we can use implementations of circumscription for inference with such bias .
﹛also  algorithms for inference with probabilistic bias and logical sentences are now emerging and can be used here too  hajishirzi and amir  1 . we can use these algorithms to apply probabilistic bias to the resulting logical formula. for example  given a probabilistic graphical model  e.g.  bayesian networks  and a set of propositional logical sentences  we can consider the logical sentences as observations. with this approach  a logical sentence   gives rise to a characteristic function 汛   ↙x   which is 1 when  ↙x satisfies   and 1 otherwise. for a conjunction of clauses we get a set of such functions  one per clause . thus  inference in the combined probabilistic-logical system is a probabilistic inference  such as variable elimination  e.g.   dechter  1    in which there are additional potential functions.
1 experimental evaluation
we tested our ae-strips-slaf algorithm in partially observable blocks-world domains. we generated random action-observation sequences of 1 steps from a description of the domain in pddl. our slaf algorithm receives no domain information besides the sequence of actions and observations that is given by the generator.
﹛we ran the algorithm with blocks-world domains of increasing sizes  1 to 1 features . we collected the time and space taken for each time step in the execution  starting with zero knowledge. the results are shown in figure 1. each of the graphs belongs to a different domain size. they show that the time per step approaches a  very small  order of   1 milliseconds  limit as the execution proceeds. the time that is taken to perform slaf of different domains grows linearly with domain size.

figure 1: ae-strips-slaf in the blocks world.
﹛also   hlubocky and amir  1  has included a modified version of this algorithm in their architecture and tested it on a suite of adventure-game-like virtual environments that are generated at random. these include arbitrary numbers of places  objects of various kinds  and configurations and settings of those. there  an agent's task is to exit a house  starting with no knowledge about the state space  available actions and their effects  or characteristics of objects. their experiments show that the agent learns the effects of its actions very efficiently. this agent makes decisions using the learned knowledge  and inference with the resulting representation is fast  a fraction of a second per sat problem in domains including more than 1 object  modes  and locations .
1 comparison with related work
hmms  boyen and koller  1; boyen et al.  1; murphy  1; ghahramani  1  can be used to estimate a stochastic transition model from observations. unfortunately  hmms require an explicit representation of the state space  and our smallest domain  1 features  requires a transition matrix of  1 entries. this prevents initializing hmms procedures on any current computer.
﹛structure learning approaches in dynamic bayes nets  dbns and also fhmms  use em and additional approximations  e.g.  using factoring  variation  or sampling   and are more tractable. however  they are still limited to small domains  e.g.  1 features  ghahramani and jordan  1; boyen et al.  1    and also have unbounded errors in discrete deterministic domains  so are not usable in our settings.
﹛reinforcement learning  rl  approaches compute a mapping between world states and preferred actions. they are highly intractable in partially observable domains  kaelbling et al.  1   and approximation  e.g.   kearns et al.  1  is practical only for small domains  e.g.  1 features  with small horizon time t.
﹛in contrast to hmms  dbns  and rl  our algorithms are exact and tractable in large domains    1 features . we take advantages of properties common to discrete domains  such as determinism  limited effects of actions  and observed failure.
﹛previous work on learning action models assumes fully observable deterministic domains. these learn parametrized strips actions using  e.g.  version spaces  gil  1; wang  1   general classifiers  oates and cohen  1   or hill-climbing ilp  benson  1 . recently   pasula et al.  1  gave an algorithm that learns stochastic actions with no conditional effects.  schmill et al.  1  approximates partial observability by assuming that the world is fully observable. we can apply these to partially observable learning problems  sometimes  by using the space of belief states instead of world states  but this increases the problem size to exponentially  so this is not practical for our problem.
1 conclusions
we presented a framework for learning the effects and preconditions of deterministic actions  and showed that in several common situations this can be done exactly in time that is polynomial  sometime linear  in the number of time steps and features. we can add bias and compute an exact solution for large domains  hundreds of features   in many cases.
﹛the results that we presented are promising for many applications  including reinforcement learning  agents in virtual domains  and hmms. already  this work is being applied to autonomous agents in adventure games  and exploration is guided by the transition belief state that we compute and information gain criteria. in the future we plan to extend these results to stochastic domains  and domains with continuous features.
1 acknowledgements
i wish to thank megan nance for providing the code and samples for the generator. i also wish to acknowledge support from daf air force research laboratory award fa1-1  darpa real program .
