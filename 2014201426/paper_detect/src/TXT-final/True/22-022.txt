: this paper describes a novel method for displaying and examining the execution space of a rule interpreter. this method provides both coarse-grained and fine-grained views. the coarsegrained view  based on temporal rather than logical dependencies  provides an abstraction of the execution history not available from text or tree based traces. the fine grained views allow the user to examine sections of the execution history in detail. a detailed scenario with screen snapshots is presented. 
acknowledgements: enrico motta  tim rajan  mark keane  rae sibbitt and tony hasemer provided extensive comments on both the content and style of this paper. this research is supported by a grant from british telecommunications  plc. 
1. 	introduction 
this paper presents the transparent rule interpreter  tri   a system that provides a graphical explanation of rule execution. tri is one part of keats-ii  motta et. al.  1; in press   a 
project with the overall aim of providing methodological and 
software support for all the stages of building very large knowledge based systems. such support includes the provision of a suite of tools for maintaining knowledge bases  collectively known as knowledge base maintenance tools  kbmts . in a host of different applications  e.g. eisenstadt & brayshaw  1; rajan  1; du boulay  o'shea & monk  1   the provision of a clear execution model has proved to be an essential tool for understanding a computational process; tri adheres to this approach by presenting a clear graphical execution model to the user. 
tri  implemented in symbolics tm  common lisp  has been built on top of the keats-ii forward and backward chaining production system interpreter. the forward chaining part uses a rete network  forgy  1   and the backward chaining part has a prolog-like inference mechanism. tri relies on exhaustive  but low-overhead  recordings of the history of execution to facilitate a precise 'replay' in an intuitively meaningful way. 
the rest of this paper is structured as follows. section 1 discusses the motivation for tri  in particular the problems found when programming with rules  previous attempts at solving the problems and our own approach. section 1 gives a brief 'tour' of the system using an example  section 1 reviews the principles behind tri and its extendability  and section 1 contains the conclusions. 
1 tracing rule execution 
1 problems 
there are two main types of problems in rule based programming. the first emerges from the inherent nature of rule based programming  i.e. the basic program coding unit is the rule. unlike other forms of programming  forward chaining rules do not facilitate any functional or procedural abstraction. 
the highest level of abstraction is a single rule. we will call these rule-unit problems. this abstraction issue results in serious problems with control. for example  taking rules from the existing rule set can have apparently no effect on how the program runs  and frequently it is not easy to predict which rule will fire next. this is because rules are an unordered  declarative way of expressing knowledge  and by their very nature are inherently non-procedural. the rule-unit problems listed above can lead to buggy programs. an antidote to these problems is to provide a transparent execution model. however  this is just where the other class of problems arise. 
the second class of problems arise from the typical manner in which rule execution is presented to the user  which we call 
problems with execution transparency. there are two ways one might wish to view a program in order to debug it. in a coarsegrained  high-level  view  one requires some idea of the overall pattern of execution of the rules in the program. from a finegrained  low-level  point of view  one requires detailed information about unification  instantiation and the state of working memory. both of these views are required and if either is absent  one of two difficulties may occur. first  without a coarse-grained view of execution it is very difficult to pinpoint the part of the execution space in which a bug has occurred. second  without a fine-grained view of execution  it is impossible to answer detailed questions about why a certain rule did not fire in a certain cycle. 
1 previous attempts to address problems 
two main approaches have been used in the past to present the execution space of rule systems: text based traces  e.g. ops1  forgy  1  and tree based traces  fickas  1; lewis  1; mott & brooke  1; poltreck et. al.  1; richer & clancey  1; kee tm   and nexpert tm  . 
both tree and text based traces provide a medium-level view of forward chaining. generally they do not display fine-grained information such as which conflict resolution strategy ruled out a particular rule instantiation  or why a particular rule failed to fire in a particular cycle  yet both types of traces are too detailed to be considered coarse-grained  a plain scale-factor 'zoom out' is not the same as a coarse-grained view . 
text based traces are difficult to read  because the different types of information displayed are not immediately distinguishable  e.g. information on which rules fired  the state of working memory and the state of the conflict resolution set . the display provides little  via indenting  or no information on the overall shape of the execution space  coarse-grained information . typically the user  who has a specific query  is given a large amount of information at once  most of which will not be appropriate to the query. 
	domingue and eisenstadt 	1 

although tree-based traces are suitable for backward chaining  we believe that they are not appropriate for displaying the execution of forward chaining because the dependencies among forward chaining rules are frequently temporal as well as  or indeed instead of  logical. for example  rulea may fire and add many things to working memory  one of which causes rule b to fire immediately  but it can be very awkward to consider rulea a logical 'precursor' or 'subgoal' of ruleb  and therefore display it with a special link from rulea to ruleb   precisely because of the 'spreading' effects of all of the other rules which rulea may have triggered. it is in the realm of this 'spreading' effect that the limitations of graphical forward-chaining rule tracers such as the ones used by kee and nexpert tm  become apparent. we therefore opt for a metaphor which is not tree-oriented  as described next. 
1 the tri approach 
our solution to representing the coarse-grained behaviour of a forward-chaining rule interpreter is to have an explicit representation of the time dimension  based on a 'musical score' metaphor  cf. videoworks tm   1 . each rule is analogous to a particular musical instrument  and the the individual execution cycles of the rule interpreter correspond to 'beats' or 'measures'. a simple example is shown in figure 1. 
given the style of display shown in figure 1  we can then provide facilities for the user to 'replay' execution  or to focus on particular moments of time and then to examine the finegrained view to answer particular questions. 

figure 1. a graph showing the execution of the rules rulea  ruleb and rulec over five cycles. the + means that a rule fired  a box means that a rule entered the conflict resolution set but did not fire. the rules fired in the order: ruleb  rulec  rulea  ruleb  rulec. rulea entered the conflict resolution set during the first 1 cycles only. 
the issue of what to display at a fine-grained level is much simpler  e.g. variable bindings  working memory contents   and in many ways has been addressed already by generations of textual-based tracers for production systems such as ops 1. however  tri provides two novel extensions to earlier  textualbased  fine-grained displays: 
  high selectivity: the user can select elements for fine-grained viewing in a range of ways  depending upon the time  the rule  the working memory pattern  or any combination; 
  synchronization with coarse-grained view; both views can be presented simultaneously  so that as the coarse-grained view is manipulated  e.g. 'played forward'   the finegrained view changes appropriately. 
1 scenario 
1 the rulebase and desktop 
suppose that a tri user has loaded a rulebase based on poltreck et. al.  1   which finds all the routes between two cities. the rules  shown in figure 1  are forward-chaining  with the exception of bl and b1  which are backward-chaining. 
the rules were run with initial working memory '     o r i g i n austin    d e s t i n a t i o n d a l l a s     producing the output: 
highway 1: austin -  1 -  temple -  1 -  waco -  
1 -  h i l l s b o r o -  1 -  dallas {mileage: 1} 
highway 1: austin -  1 -  san-antonio -  1 -  
	fredricksburg -  1 -  dallas 	{mileage: 	1} 
tools 
fact-1: 	if 	than 
 highway 1 
	  san-antonio a u s t i n 1  	 austin temple 1  
	 temple waco 1  	 waco h i l l s b o r o 1  
           h i l l s b o r o d a l l a s 1    fact-1: if t h e n 
 highway 1 
   austin san-antonio 1  
 san-antonio fredericksburg 1  
          fredericksburg d a l l a s 1    bl  backward :   a d j c i t i e s  h  cl  c1  d  if 
 highway  h   l i s t   
　　　　  : l i s p  member-of   c1  cl  d    l i s t     b1  backward :   a d j e i t i e s  h  cl  c1  d  if 
 highway  h   l i s t   
         : l i s p  member-of   cl  c1  d    l i s t     s t a r t : i f   o r i g i n   s t a r t   
	  d e s t i n a t i o n 	 end  
　　　　　 highway  h   l i s t   then   f i n d - r o u t e   s t a r t  end     h 1  add-clty-to-route: 
if 	  f i n d - r o u t e   s t a r t 	 end  path  road  n  then 	  : l i s p 	  e s t a b l i s h 	    a d j e i t i e s 	 road   s t a r t 
	 next  new distance   	: a l l t     
;;;the above e s t a b l i s h invokes backward-chainer  & finds all sol'ns  route-simple: 
   if 	  a d j e i t i e s 	 road   s t a r t 	 next 	 new-distance  then 	 route   s t a r t 	 next 	 road  new-distance  add-city-to-route1: 
	if 	  f i n d - r o u t e   s t a r t 	 end  path  road  n  
	 route   s t a r t  next 	 road  new-distance  
　　　　　　 any-total  t h e n 
	 path 	:- 	 append  path 	  start  new-distance   
	  t o t a l 	:- 	 +  n  new-distance  
	 route   s t a r t 	 next 	 road   t o t a l   
       f i n d - r o u t e  next  end  path  road   t o t a l   end: 	if 	  f i n d - r o u t e 	 x  x  path  road  n  
   d e s t i n a t i o n 	 x  then 	  p r i n t 	route  
figure 1 the rulebase taken from poltreck et. al.  1. the first iwo rules simply add assertions about the distances between some cities in texas on highway number 1 and highway number 1  respectively. 
the user then examines the execution history and after a few operations  the tri 'desktop' is in the state shown in figure 1. for clarity of exposition  figure 1 is only a schematic showing in outline form the contents of 1 separate windows. only window 1 is displayed initially  with the rest being generated on demand to satisfy specific user requests. details of specific windows are described in turn below. 


figure 1. close-up of the rule graph frame  window 1 in figure 1 . 
1 providing a coarse-grained view of the execution 
the coarse-grained view is provided by window 1  the rule graph frame  in the top left of figure 1. as well as an abstract view the rule graph frame provides two other facilities: 
  the ability to focus on various a slices of the execution space in detail  
  the ability to replay the execution. 
the actual appearance of window 1 is shown in figure 1. 
the largest pane in the rule graph frame shows a graph of the execution history  which we call the rule graph. the rule graph enables the user to view around fifty rules for fifty cycles at a glance  this could trivially be increased to one hundred cycles by decreasing the inter-cycle gap . horizontal and vertical scrolling extend the practical limits to hundreds of rules and hundreds of cycles. tri allows the user to collapse any set of rules into a 
single row  allowing robust forward chaining rules to be 'black boxed away. each row represents the execution space of one or more rules with each of the symbols indicating a particular type of event happening to one instantiation. each set of rules contains a corresponding set of instantiations  the set of instantiations created from working memory and the set of rules . the symbols denote the following: 
a - one of the instantiations in the set fired and backward chaining occurred  
+ - one of the instantiations in the set fired  and 
l..i - at least one instantiation entered the conflict resolution set and none of the instantiations in the set fired  
where there is no symbol  all of the rules in the set failed to match against working memory and no instantiations were created. 
the rule graph presents a picture of the overall 'shape' of the execution; we can see clumps consisting of a a followed by two + son the line immediately above and we can also see two diagonal lines consisting of + a++ a regular user of tri would recognise these patterns as cliches in the program and would be able to notice missing 'friendly' cliches and spot unwanted 'unfriendly' cliches. the rule route-simple fires immediately after the rule add-city-to-route  sometimes firing once and sometimes firing several times in succession. the rule add-city-to-route1 always fires immediately after the rule routesimple has fired one or more times. the rule fact-1 which deposits facts about highway 1  fires first  the rule fact-1 which deposits facts about highway 1 does not fire until after the rule end  which prints a route  has fired. the rule start fires only twice  each time immediately after one of the fact rules have fired. we see that the rule graph provides answers to coarsegrained questions such as  when is a rule is likely to fire     which rules fire together  . this sort of information is not readily available from text or tree based traces. 
1 fine grained views of the execution 
tri allows the user to view slices of the execution in detail. the full contents of working memory at any particular cycle can be shown in a separate window. for example  the state of working memory at cycle 1 in the current example is shown in figure 1 {not part of the user's desktop in figure 1 . this view window can be tailored to show the rules  predicates  or firing instantiation for a chosen execution cycle. indeed  any number of tailored variants of the window can be disnlaved at once. 

figure 1. contents of working memory  in cycle order  at cycle 1. 
a more specialized slice of working memory is chosen by selecting some predicates from a menu and then selecting the current cycle by clicking on one of the numbers in the rule graph. the predicate of a working memory pattern is the first part of the pattern  sofoo is the predicate of the working memory pattern ffoo xyz . windows 1  1  and 1  called 
predicate windows  at the right of figure 1 show three slices of 
working memory for the three predicates adjeities  find-route and route. each predicate window shows all the working memory patterns present at the current cycle  for the predicate. figure 1 shows the actual appearance of window 1 in detail. 

figure 1. the a d j e i t i e s predicate window  window 1 in figure 1 . 
the predicate has been omitted from each of the displayed working memory patterns as it is redundant  it is displayed as the title of the predicate window . the number before each of the patterns is the cycle during which the pattern was deposited in working memory. each pattern is mouse sensitive  enabling either the relevant node in the rule graph to be highlighted  or a more detailed description of the pattern to be displayed. 
	domingue and eisenstadt 	1 

a slice of the conflict resolution set is chosen by clicking on one of the nodes in the rule graph. windows 1 and 1 at the bottom left of the figure show two slices of the conflict resolution set. figure 1 shows the actual appearance of window 1. 

figure 1. close-up of node examination frame for rule route-simple  window 1 in figure 1 . winning instantiation is shown in italics. 
each frame  called a node examination frame  has two components. the top part of the frame contains the definition of the rule; the bottom part shows all the instantiations the rule had in the conflict set. this allows easy comparison of the instantiated rule with the source code. the bottom left frame was created by clicking on the + node in cycle 1 in the rule graph; it contains all the instantiations in the conflict resolution set at cycle 1 for the rule route-simple. the top instantiation is in italics indicating that this instantiation fired in cycle 1. each instantiation is mouse sensitive  allowing operations such as displaying or editing the deleting conflict resolution strategy. the second node examination frame  window 1   shown in detail in figure 1  was created by clicking on the triangle under the number 1 in the rule graph. 
we can see that the top  firing  instantiation is in italics. we can also see that the first  and only  clause in the consequent of the instantiation is in bold. the holding indicates that  when the rule fired  backward chaining occurred. clicking on this clause displays the proof tree  shown by the bottom right frame in figure 1  and in detail in figure 1. 
the tree represents the execution history of backward chaining rules. each node in the tree corresponds to a goal  which may or may not have been successful  within the execution. the display of proof trees is based on the transparent prolog machine  eisenstadt & brayshaw  1 : a white node indicates a success; a black node indicates a failure; grey indicates 'succeeded earlier but failed on backtracking'; circles indicate calls to primitives or lisp functions. it is possible to abstract the tree both by zooming out  it is possible to zoom in again  as has been done in figure 1  and by collapsing a predicate. when a predicate is collapsed the subtree of the predicate is not shown  allowing robust backward chaining rules to be 'black boxed' away  facilitating the display of thousands of nodes in a large proof tree. 
tools 

figure 1. close-up of node examination frame for rule add-city-to-route  window 1 in figure 1 . winning instantiation is shown in italics  and backward-chaining call is shown in bold italics. the rectangle surrounding the bold italic region indicates that it has just been selected by the mouse  yielding further detail as shown in figure 1. 

figure 1. close-up of backward-chaining proof tree for a d j c i t e s  window 1 in figure 1 . this snapshot is taken in the middle of 'replay'. 

each node in the tree is mouse sensitive. clicking on a node displays more detailed information  as can be seen in window 1 above the proof tree in figure 1  including: the rule the goal was called from; the source code version of the call; and the actual call  in which variables are likely to have been renamed. a screen snapshot of window 1 is reproduced below as figure 1. 

figure 1. close-up of detailed expansion of backward-chaining tree node  showing variable bindings  window 1 in figure 1 . 
1 replaying the execution 
the execution can be replayed using the replay panel  the menu containing the symbol  = in figure 1 . using the replay panel the user can choose to single step forwards or backwards  or to replay the history. as the execution is replayed  each cycle column in the rule graph is highlighted in turn  like a player piano roll  and all the currently displayed fine-grained views are updated. each of the fine-grained views acts as a measuring device  providing very detailed information on a specific part of the execution. 
1 assessing tri 
1 temporal dependencies vs. logical dependencies 
the key insight underlying tri has been the emphasis on temporal dependencies during forward chaining  providing in essence a 'musical score' metaphor for the coarse-grained view. this contrasts directly with an emphasis on logical dependencies  the display of which relies typically on a tree/net/link metaphor. it would be foolish for tri to ignore logical dependencies  especially in those cases where they are highly meaningful to an individual user  or simply more appropriate in a particular context. therefore  tri facilitates the display of logical dependencies in three ways:  a  the dependency between any working memory element  as shown in a specific 'predicate window'  for instance  and the rule which was responsible for depositing that element can be highlighted by the user with a single mouse-click on the chosen working memory element  resulting in a 'blink' of the ''+'' symbol at the appropriate 'culprit' spot in the rule graph display;  b  a 
dependency tree for any working memory element  including ones deposited during forward chaining  can be displayed upon request- the appearance is that of an and/or tree much like the one we use for backward chaining;  c  the backward chaining proof tree itself is of course a tree of logical dependencies  made easy for tri because of the restriction that backward chaining rules be expressed  like prolog  as pure horn clauses. 
logical dependencies have been de-emphasised in this paper  because and/or trees are not new. clearly  the individual user needs to have the freedom to choose the right abstraction for the right purpose  and that is precisely the mixture that tri was designed to provide. 
1 scaling up to large programs 
the acid test of a tracing/monitoring environment is its performance on real programs. tri is used daily on the keats-ii project  and its very conception and design is meant to facilitate the handling of very large programs. some recent runs of tri in keats-ii  which mostly uses frames rather than rules  yielded the following statistics: 
number of rules: 1 
number of working memory elements: 1 
number of competing rule instantiations on a given cycle: 1 
number of forward-chaining cycles: 1 
number of backward-chaining 'history' steps: 1 
number of nodes in backward-chaining proof tree: 1 
the large number of backward-chaining 'history' steps is due to the detailed record of backtracking which is kept by tri  where a 'step' corresponds to a 'call'  'exit'  'fail' or 'redo' operation analogous to those of prolog. 
the following features enable tri to scale up to large problems: 
clear conceptual distinction between coarse-grained and fine-grained views: the abstractions provided are genuinely different  not just those obtainable via physical 'scale factor' zooming. 
  chunking of rules into sets: entire rule sets may be 'expanded' and 'collapsed' in the left-hand column of the rule graph display  analogous to the operations of a hierarchical file directory browser. chunking can be provided automatically  according to rules which co-exist in separate 'rule contexts'  or manually  at the user's discretion. this allows the aggregate behaviour of many hundreds of rules to be seen at a glance. 
  collapsing of details into one node: in the backwardchaining proof trees  entire sub-trees which are either uninteresting or too space-consuming can be collapsed into a single node  which itself may be expanded and explored in a separate window. this enables trees with thousands of nodes and tens of thousands of execution steps to explored in a meaningful way. 
global view: the coarse-grained view of proof trees can itself be physically scaled  zoomed  in a separate window which provides a broader navigational perspective- this is the 'zoom' typical of existing environments  and is therefore not new to tri  but is provided for convenience and completeness. 
peformance overheads of tri's monitoring facilities are low  approximately 1% increase in execution time   which seems like a reasonable price to pay for being able to obtain a thorough view of execution for complex rule sets. the monitoring facilities can be disabled at the user's discretion. we are looking forward to future tests of tri's power on very large rule bases. 
1 conclusions and future work 
in this paper we have described tri  a system that provides a graphical explanation of both forward and backward chaining. our main aim in designing tri was to overcome the difficulty of providing an abstract view of the execution with easy access to low level views. our hope is that providing the rule based programmer with these two views will greatly decrease the time 
	domingue and eisenstadt 	1 

taken to discover the cause of bugs. we have witnessed this informally in our lab  and are planning a series of empirical studies to demonstrate the effect in a robust fashion. a further spinoff  consistent with other ongoing work in our lab  e.g. hasemer & domingue  1   is the provision of a transparent view of the inner workings of a machine ideally suited for helping to teach rule-based programming to novices. toward this end  we have incorporated the rule graph notation into an open university course on knowledge engineering  kahney  1 . 
we are currently extending tri to provide information on the performance as well as the behaviour of rule based programs in a unified display. in particular  iconic metering tools are being provided for both forward and backward chaining. keats-ii has a truth maintenance system  and tri is being extended to show dynamically the way in which making an 'in' assertion 'out'  for instance  propagates effects through a network of dependency links. we eagerly await the results of this new research. 
