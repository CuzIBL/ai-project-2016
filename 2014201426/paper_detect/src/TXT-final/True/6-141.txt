 
particle filters are used extensively for tracking the state of non-linear dynamic systems. this paper presents a new particle filter that maintains samples in the state space at dynamically varying resolution for computational efficiency. resolution within siatespace varies by region  depending on the belief that the true state lies within each region. where belief is strong  resolution is fine. where belief is low  resolution is coarse  abstracting multiple similar states together. the resolution of the statespace is dynamically updated as the belief changes. the proposed algorithm makes an explicit bias-variance tradeoff to select between maintaining samples in a biased generalization of a region of state space versus in a high variance specialization at fine resolution. samples are maintained at a coarser resolution when the bias introduced by the generalization to a coarse resolution is outweighed by the gain in terms of reduction in variance  and at a finer resolution when it is not. maintaining samples in abstraction prevents potential hypotheses from being eliminated prematurely for lack of a sufficient number of particles. empirical results show that our variable resolution particle filter requires significantly lower computation for performance comparable to a classical particle filter. 
1 introduction 
a number of problems in al and robotics require estimation of the state of a system as it changes over time from a sequence of measurements of the system that provide noisy  partial  information about the state. particle filters have been extensively used for bayesian state estimation in nonlinear systems with noisy measurements  isard and blake  1; fox et al.  1; doucet et al  1  . the bayesian approach to dynamic state estimation computes a posterior probability distribution over the states based on the sequence of measurements. probabilistic models of the change in state over time  state transition model  and relationship between the measurements and the state capture the noise inherent in these domains. computing the full posterior in real time is often intractable. particle filters approximate the posterior distribution over the states with a set of particles drawn from the posterior. the particle approximation converges to the true bayesian posterior in the limit as the number of samples go to infinity. for real-time state estimation it is impractical to have an infinitely large number of particles. with a small number of particles  the variance of the particle based estimate can be high  particularly when there are a large number of possible state transitions. 
　this paper presents a new particle filter  the variable resolution particle filter  vrpf   for tracking large state spaces efficiently with low computation. the basic idea is to represent a set of states1 rather than a single state with a single particle and thus increase the number of states  or hypotheses  that may be tracked with the same number of particles. this makes it possible to track a larger number of states for the same computation  but results in a loss of information that differentiates between the states that are lumped together and tracked in abstraction. we formalize this tradeoff in terms of bias and variance. tracking in abstraction at a coarser resolution introduces a bias over tracking at a finer resolution  but it reduces the variance of the estimator given a limited number of samples. by dynamically varying the resolution in different parts of the state space to minimize the bias-variance error  a finite set of samples are used in a highly efficient manner. initial experimental results support our analysis and show that the bias is more than compensated for by the reduction in variance from not eliminating potential hypotheses prematurely for lack of a sufficient number of particles. 
1 bayesian filtering 
we denote the multivariate state at time t as xt and measurements or observations as ot. as is commonly the case  we concentrate on the discrete time  first order markov formulation of the dynamic state estimation problem. hence  the state at time t is a sufficient statistic of the history of measurements  i.e. p xt xo:t-i  = p xt xt-   and the observations depend only on the current state  i.e. p ot xo.t  = p ot xt . in the bayesian framework  the posterior distribution at time t% p{x t 1 :t   includes all the available information upto time t and provides the optimal solution to the state estimation problem. in this paper we are interested in estimating recursively in time a marginal of this distribution  the filtering distribution  p xt oi:t   as the measurements be-
'or regions of a continuous state space 
come available. based on the markovian assumption  the recursive filter is derived as follows: 

　this process is known as bayesian filtering  optimal filtering or stochastic filtering and may be characterized by three distributions:  1  a transition model  1  an observation model and   1  an initial prior distribution  in a number of applications  the state space is too large to compute the posterior in a reasonable time. particle filters are a popular method for computing tractable approximations to this posterior. 
1 	classical particle filter 
a particle filter  pf   metropolis and ulam  1; gordon et al.% 1; kanazawa ex a/.  1  is a monte carlo approximation of the posterior in a bayes filter. pfs are nonparametric and can represent arbitrary distributions. pfs approximate the posterior with a set of n fully instantiated state samples or particles  as follows: 
 1  
where denotes the dirac delta function. it can be shown that as the approximation in  1  approaches the true posterior density  doucet and crisan  1 . in general it is difficult to draw samples from  instead  samples are drawn from a more tractable distribution  called the proposal or importance distribution. each particle is assigned a weight   to account for the fact that the samples were drawn from a different distribution  rubin  1; rubinstein  1 . there are a large number of possible choices for the proposal distribution  the only condition being that its support must include that of the posterior. the common practice is to sample from the transition probability  in which case the importance weight is equal to the likelihood  the experiments in this paper were performed using this proposal distribution. the pf algorithm is: 

1 variable resolution particle filter 
a well known problem with particle filters is that a large number of particles are often needed to obtain a reasonable approximation of the posterior distribution. for real-time state estimation maintaining such a large number of particles is typically not practical. however  the variance of the particle based estimate can be high with a limited number of samples  particularly when the process is not very stochastic and parts of the state space transition to other parts with very low  or zero  probability. consider the problem of diagnosing locomotion faults on a robot. the probability of a stalled motor is low and wheels on the same side generate similar observations. motors on any of the wheels may stall at any time. a particle filter that produces an estimate with a high variance is likely to result in identifying some arbitrary wheel fault on the same side  rather than identifying the correct fault. 
　the variable resolution particle filter introduces the notion of an abstract particle  in which particles may represent individual states or sets of states. with this method a single abstract particle simultaneously tracks multiple states. a limited number of samples are therefore sufficient for representing large state spaces. a bias-variance tradeoff is made to dynamically refine and abstract states to change the resolution  thereby abstracting a set of states and generalizing the samples or specializing the samples in the state into the individual states that it represents. as a result reasonable posterior estimates can be obtained with a relatively small number of samples. in the example above  with the vrpf the wheel faults on the same side of the rover would be aggregated together into an abstract fault. given a fault  the abstract state representing the side on which the fault occurs would have high likelihood. the samples in this state would be assigned a high importance weight. this would result in multiple copies of these samples on resampling proportional to weight. once there are sufficient particles to populate all the refined states represented by the abstract state  the resolution of the state would be changed to the states representing the individual wheel faults. at this stage  the correct hypothesis is likely to be included in this particle based approximation at the level of the individual states and hence the correct fault is likely to be detected. 

　for the variable resolution particle filter we need:  1  a variable resolution state space model that defines the relationship between states at different resolutions   1  an algorithm for state estimation given a fixed resolution of the state space   1  a basis for evaluating resolutions of the state space model  and  1  and algorithm for dynamically altering the resolution of the state space. 
probabilistic inference 	1 

1 	variable resolution state space model 
we could use a directed acyclic graph  dag  to represent the variable resolution state space model  which would consider every possible combination of the  abstract states to aggregate or split. but this would make our state space exponentially large. we must therefore constrain the possible combinations of states that we consider. there are a number of ways to do this. for the experiments in this paper we use a multi-layered hierarchy where each physical  non-abstract  state only exists along a single branch. sets of states with similar state transition and observation models are aggregated together at each level in the hierarchy. in addition to the physical state set the variable resolution model  m consists of a set of abstract states that represent sets of states and or other abstract states. 
		 1  
figure 1  a  shows an arbitrary markov model and figure 1  b  shows an arbitrary variable resolution model for 1 a . figure 1 c  shows the model in 1 b  at a different resolution. 
　we denote the measurement at time as 	and the sequence of measurement 	as 	from the dynamics  and 	measurement 	probabilities 	we com-
pute the stationary distribution  markov chain invariant distribution  of the physical states  behrends  1. 
1 	belief state estimation at a fixed resolution 
this section describes the algorithm for estimating a distribution over the state space  given a fixed resolution for each state  where different states may be at different fixed resolutions. for each particle in a physical state  a sample is drawn from the predictive model for that state  it is then assigned a weight proportional to the likelihood of the measurement given the prediction  for each particle in an abstract state  one of the physical states  that it represents in abstraction is selected proportional to the probability of the physical state under the stationary distribution  
　　　the predictive and measurement models for this physical state are then used to obtain a weighted posterior sample. the particles are then resampled proportional to their weight. based on the number of resulting particles in each physical state a bayes estimate with a dirichlet l  prior is obtained as follows: 
		 1  
where  represents the number of samples in the physical state and represents the total number of particles in the particle filter. the distribution over an abstract state 
	 1  
1 	bias-variance tradeoff 
 1  
where  
　the posterior belief state estimate from tracking states at the resolution of physical states introduces no bias. but the variance of this estimate can be high  specially with small sample sizes. an approximation of the sample variance at the resolution of the physical states may be computed as follows: 
 1  
 1  
the generalization to abstract states biases the distribution over the physical states to the stationary distribution. in other words  the abstract state has no information about the relative posterior likelihood  given the data  of the states that it represents in abstraction. instead it uses the stationary distribution to project its posterior into the physical layer. the projection of the posterior distribution of abstract state to the resolution of the physical layer is computed as follows: 
 1  
where  
　as a consequence of the algorithm for computing the posterior distribution over abstract states described in section 1  an unbiased posterior over physical states  is available at no extra computation  as shown in equation  1 . the bias introduced by representing the set of physical states in abstraction as is approximated as follows: 
 1  
it is the weighed sum of the squared difference between the unbiased posterior   computed at the resolution of the physical states and the biased posterior computed at the resolution of abstract state 
　an approximation of the variance of abstract state sj is computed as a weighted sum of the projection to the physical states as follows: 
 1  
   the relative importance/cost of the physical states may also be included in the weight 

 a  example 	 b  variable resolution 	 c  s1 at a finer resolution model 
figure 1:  a arbitrary markov model  b  arbitrary variable resolution model corresponding to the markov model in  a . circles that enclose other circles represent abstract states. s1 and s1 and s1 are abstract states. states s1  s1 and s1 form one abstraction hierarchy  and states 
s1  s1  s1  s1 and s1 form another abstraction hierarchy. the states at the highest level of abstraction are sl  s1 and s1   c  the model in 

 b  with states s1 and 1 at a finer resolution. 
the loss from tracking a set of states at the resolution of the physical states is thus: 
 1  
the loss from tracking the same set of states in abstraction as is: 
 1  
there is a gain in terms of reduction in variance from generalizing and tracking in abstraction  but it results in an increase in bias. here  a tradeoff between bias and variance refers to the process of accepting a certain increase in one term for a larger reduction in the other and hence in the total error. 
1 	dynamically varying resolution 
the variable resolution particle filter uses a bias-variance tradeoff to make a decision to vary the resolution of the state space. a decision to abstract to the coarser resolution of abstract state is made if the state space is currently at the resolution of states and the combination of bias and variance in abstract state is less than the combination of bias an variance of all its children 1   as shown below: 
on the other hand if the state space is currently at the resolution of abstract state and the reverse of equation  1  is true  then a decision to refine to the finer resolution of states is made. the resolution of a state is left unaltered if its 
bias-variance combination is less than its parent and its children. to avoid hysteresis  all abstraction decisions are considered before any refinement decisions. 
　each time a new measurement is obtained the distribution of particles over the state space is updated. since this alters the bias and variance tradeoff  the states explicitly represented at the current resolution of the state space are each evaluated for gain from abstraction or refinement. any change in the current resolution of the state space is recursively evaluated for further change in the same direction. 
1 experimental results 
the problem domain for our experiments involves diagnosing locomotion faults in a physics based simulation of a six wheel rover. figure 1 a  shows a snapshot of the rover in the darwin1k  leger  1  simulator. 
　the experiment is formulated in terms of estimating discrete fault and operational modes of the robot from continuous control inputs and noisy sensor readings. the discrete state  represents the particular fault or operational mode. the continuous variables  provide noisy measurements of the change in rover position and orientation. the particle set pt therefore consists of tv particles  where each particle is a hypothesis about the current state of the system. in other words  there are a number of discrete fault and operational states that a particle may transition to based on the transition model. each discrete fault state has a different observation and predictive model for the continuous dynamics. the probability of a state is determined by the density of samples in that state. 
　the markov model representing the discrete state transitions consists of 1 states. as shown in figure 1 c  the normal driving  nd  state may transition back to the normal driving state or to any one of six fault states: right front  rf   right middle  rm   right rear  rr   left front  lf   left middle  lm  and left rear  lr  wheel stuck. each of these faults cause a change in the rover dynamics  but the faults on each side  right and left   have similar dynamics. 
　given that the three wheels on each side of the rover have similar dynamics  we constructed a hierarchy that clusters the fault states on each side together. figure 1 d  shows this hierarchical model  where the abstract states right side fault  rs   and left side fault  ls  represent sets of states 
and respectively. the highest level of abstraction therefore consists of nodes  figure 1 e  shows how the state space in figure 1 d  would be refined if the bias in the abstract state rs given the number of particles outweighs the reduction in variance over the specialized states rf  rm and rr at a finer resolution. 
　when particle filtering is performed with the variable resolution particle filter  the particles are initialized at the highest 

probabilistic inference 	1 

figure 1:  a  snapshot from the dynamic simulation of the six wheel rocker bogie rover in the simulator   b  an example showing the normal trajectory  nd  and the change in the same trajectory with a fault at each wheel   c  original discrete state transition model. the discrete 
states are: normal driving  nd   right and left  front  middle and rear wheel faulty  rf  rm  rr  lf  lm  lr   d  abstract discrete slate 
transition model. the states  rf  rm and rr have been aggregated into the right side wheel faulty states and similarly lf  lm and lr into left side wheel faulty states  rs and ls .  e  state space model where rs has been refined. all states have self transitions that have been 

excluded for clarity. 
level in the abstraction hierarchy i.e. in the abstract states nd  rs and ls. say a rf fault occurs  this is likely to result in a high likelihood of samples in rs. these samples will multiply which may then result in the bias in rs exceeding the reduction in variance in rs over rf  rm and rr thus favoring tracking at the finer resolution. additional observations should then assign a high likelihood to rf. 
　the model is based on the real-world and is not very stochastic. it does not allow transitions from most fault states to other fault states. for example  the rf fault does not transition to the rm fault. this does not exclude transitions to multiple fault states and if the model included multiple faults  it could still transition to a  rf and rm  fault  which is different from a rm fault. hence  if there are no samples in the actual fault state  samples that end up in fault states with dynamics that are similar to the actual fault state may end up being identified as the fault state. the hierarchical approach tracks the state at an abstract level and does not commit to identifying any particular specialized fault state until there is sufficient evidence. hence it is more likely to identify the correct fault state. 
　figure 1 a  shows a comparison of the error from monitoring the state using a classical particle filter that tracks the full state space  and the vrpf that varies the resolution of the state space. the x axis shows the number of particles used  the y axis shows the kl divergence from an approximation of the true posterior computed using a large number of samples. 1 samples were used to compute an approximation to the true distribution. the kl divergence is computed over the entire length of the data sequence and is averaged over multiple runs over the same data set 1. the data set included normal operation and each of the six faults. figure 1 a  demonstrates that the performance of the vrpf is superior to that of the classical filter for small sample sizes. in addition figure 1 b  shows the kl-divergence along the y axis and wall clock time along the x axis. both filters were coded in matlab and share as many functions as possible. 
1 discussion and future work 
this paper presents a novel approach for state abstraction in particle filters that allows efficient tracking of large discrete  continuous or hybrid state spaces. the advantage of this approach is that it makes efficient use of the available computation by selecting the resolution of the state space based on an explicit bias-variance tradeoff. it performs no worse than a classical particle filter with an infinite number of particles 1. but with limited particles we show that its performance is considerably superior. the vrpf does not prematurely eliminate potential hypotheses for lack of a sufficient number of particles. it maintains particles in abstraction until there are a sufficient number of particles to provide a low variance estimate at a lower resolution. 
　the vrpf generalizes from current samples to unsampled regions of the state space. regions of the state space that had no samples at time t may acquire samples at time 1 on abstraction. this provides additional robustness to noise that may have resulted in eliminating a likely hypothesis.  koller and fratkina  1  addresses this by using the time samples as input to a density estimation algorithm that learns a distribution over the states at time t. samples at time are then generated using this generalized distribution.  ng et al  1  uses a factored representation to allow a similar mixing of particles. the vrpf uses a bias-variance tradeoff to generalize more selectively and efficiently. 
　we have presented the variable resolution particle filter for a discrete state space. we plan to extend it to a continuous 

	 a  	 b  
figure 1: comparison of the kl divergence from the true distribution for the classical particle filter and the vrpf  against  a  number of 

particles used   b  wall clock time. 
state space where regions of state space  rather than sets of states are maintained at different resolutions. a density tree may be used for efficiently learning the variable resolution state space model with abstract states composed of finitely many sub-regions. 
　the vrpf makes efficient use of available computation and can provide significantly improved posterior estimates given a small number of samples. however  it should not be expected to solve all problems associated with particle impoverishment. for example  it assumes that different regions of the state space are important at different times. we have generally found this to be the case  but the vrpf does not improve performance if it is not. another situation is when the transition and observation models of all the states are highly dissimilar and there is no possibility for state aggregation. 
1 acknowledgments 
we would like to thank geoff gordon  tom minka and the anonymous reviewers. 
