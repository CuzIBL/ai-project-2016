 
this paper proposes a new planning approach that authorizes an autonomous robot to reason about the inaccuracy of the world description and of its possible evolutions. we represent the uncertainty with the possibility theory; this allows us to distinguish between two types of nondeterminism: a non-determinism from insufficient modeling and a non-determinism from uncertainty. besides  we introduce perception actions as well as a model of the environment dynamics through  contingent events . finally  we present an implemented experimental planner  based on graphplan search paradigm. this planner is able to produce plans that are robust with respect to contingent events  and whose goal-achieving ability is evaluated a priori. the obtained plans can be conformant or conditional depending on the context and the user requirements. 
1 	introduction 
an autonomous robot system operating in an environment in which there is uncertainty and changes  needs to combine reasoning and reaction. to correctly plan in an uncertain and dynamic environment  the planner needs an accurate description of the world  of the actions which could be planned and a goal success definition. there is also a need to model non-determinism as well as contingent events. 
　one can classify actions into four types: deterministic actions  there is only one possible outcome   conditional actions  outcomes are context dependent   nondeterministic actions  several possible outcomes  and perception actions  one outcome out of n . in addition a perception action improves knowledge. 
　another key feature is the ability of the planning algorithm to concentrate on the exploration of the most  probable  courses of action and to evaluate the robustness and the goal achieving ability of a given plan. 
　this paper presents a planner which partially fulfills the requirements discussed above. to model the environment uncertainty we use the possibility theory  dubois 
1 	planning and scheduling 
and prade  1  which allows to represent complete ignorance as well as qualitative inaccuracy. a goal is described as a conjunction of possibilistic facts which can qualify the goal achievement necessity. it is important to note that with uncertain information  actions with conditional effects can be used as a class of actions with non-deterministic outcomes. consequently non-determinism can result from uncertainty  conditional actions  as well as from insufficient modeling  nondeterministic actions . our planner uses explicitly these two kinds of sources of non-determinism in planning as well as perception actions which allow to build conditional plans. 
　our planner can anticipate and oppose contingent events by avoiding situations where they can occur or by preparing an adapted reaction. however  this feature is limited to situations which are the result of previous robot action. 
　in the next sections we describe our representation of the world  of the robot actions and of contingent events. then we present an algorithm inspired from graphplan search  blum and furst  1  as well as some illustrative outputs produced by our planner. finally  we give an overview and a short conclusion. 
1 	an uncertain environment 
it is certainly useful to distinguish between several types of uncertainties: the complete ignorance of a fact  e.g. the robot does not know where the red test tube is   the qualitative inaccuracy of a fact  e.g. the robot only knows that the red test tube is probably on table   and the quantitative inaccuracy of a fact  e.g. the robot knows that the probability that the red test is on tablei is 1 . some planners like cgp  smith and weld  1  or cassandra  pryor and collins  1  use a set of distinct possible worlds which corresponds to our complete ignorance idea. the probabilistic approach  used especially in buridan  kushmeric et al.  1   is particularly interesting for describing the uncertainty associated to state transitions. however  probabilities do not allow to represent complete ignorance; besides  there are numerous situations where it is not possible to give to the robot planner probabilities based on statistical measures  but only qualitative information provided by the 

operator or deduced from previous missions. this is the reason why we use the possibility theory. 
1 	possibility background 
the possibility theory  zadeh  1; dubois and prade  
1j offers an uncertainty modeling framework where two values are associated to every fact a: 
  : the  possibility  for the fact a to be true  
  n a : the  necessity  for the fact a to be true. 
　the duality between necessity and possibility is expressed by the relation . for example if we do not know if the door is open or not  we can write: = 1 and 
= 1  the door may be open but not 
necessarily . if the red test tube usually is on    we can write: 	= 1 and 
= 1. note that this is a 
qualitative measure; only the order between the different possibility and necessity values is relevant. 
1 	t h e w o r l d representation 
we define a state as a conjunction of possibilistic facts. the closed-world assumption allows  when a fact a is false  to delete it from the state description. consequently we extend this assumption  in our context  and we only represent in the state the facts that are known in necessity terms; in other words we only insert facts which have a positive necessity. table 1 shows an example of an initial state. note that the possibility is missing; indeed  with the duality between possibility and necessity we could replace 	= 1 then and it will not be represented in the state description. in this example  we see that the light on top of table1 often works  whereas the light on top almost usually works. 

table 1: example of an initial state description 
　a goal for our planner is represented by a conjunction of facts with a strictly positive necessity  to avoid disjunctions . 
1 modeling robot actions 
we model the robot actions by possibilistic rules that change the state description. these rules are based on an extension of strips  fikes and nilsson  1  preconditions  add-lists and delete-lists. the computation of the necessities associated to action effects is based on the following propagation rule  fig. 1 : 
where bi is the ith effect  	is the ne-
cessity of having bi given the precondition is the necessity of the fact bi  before applying the 
action and 	is its value after applying the action. 
1 	deterministic actions 
a deterministic action changes a state into another in foreseeable way. for example the take withlight action may be represented by: 

if we apply this action in the initial state described in 
table 1  we obtain holding  redtesttube  with necessity 
           note that because there is uncertainty  the action may be executed in situations where its preconditions are not satisfied. we assume that in a such case  it will have no effect. however  if a more sophisticated model is necessary  one can use conditional actions. 
1 	non-deterministic actions 
non-deterministic actions may lead to several possible outcomes. an outcome is represented by a conjunction of facts  with their necessities  and a possibility-necessity measure of occurrence of that outcome  fig. 1 ; all possible outcomes must appear  to have n all outcomes =1  
　to keep consistency  the different worlds  that result from the application of a non-deterministic action must verify: 

　for example  when the take without light action is applied  we are sure to hold a test tube  but we do not know if it is red or green: 

	guere and ala-mi 	1 


figure 1: non-deterministic action model 
1 	conditional actions 
　in classical logic an action with conditional effects is deterministic. indeed when we plan this action we know the current state and we can decide which conditional effects will apply. with such a model  one can always change an action which has n conditional effects  each with m conjuncts  in 1nm actions1 

figure 1: conditional effects action model 
however  in our state model the different facts 
because of its conditional effects  is applicable in both worlds with different effects. this is what we call nondeterminism due to uncertainty. 
1 for more details about conditional effects associated to 
graphplan search see  koehler et a/.  1; anderson et a/.  1 . 
1 	planning and scheduling 
1 	perception actions 
perception actions allow to improve the robot knowledge about a given set of facts. it will allow the robot to know 
on which branch of the course of actions it is  fig  1   this will entail a higher necessity associated to the facts that have been observed. in the current implementation  we use a simple hypothesis: the perception is assumed perfect  and the necessity associated to the outcome is 1. one possible improvement can be the use of conditional effects  c-buridan  draper et al.   1  models that an observation can fail . 
　for example the perception action which determines if the robot has taken the red or the green test tube  can be represented by: 
figure 1: a perception action example 
1 an algorithm based on graphplan 
graphplan is a fast planner developed by  blum and 
furst  1  which plans with strips operators and uses a constraint propagation method. it performs in two steps: first  it builds a constraint graph expansion; and then it searches for the plan with a constraint resolution extraction. 
1 possibilistic treatment 
to compute the necessity of a fact in a given state we apply the propagation rule defined in section 1. the use and definition of mutex is the same as graphplan except for  interference : two actions  and are mutually exclusive if the effects contain the fact m  a1 preconditions contain 
. one advantage of graphplan is to keep on a level only one specimen of a fact. consequently if we want to keep this advantage  we must use at each level the most  pessimistic  path  lowest necessity  as for proposition mutex: if the fact a has the necessity 1 with a first path and 1 with a second one  we associate 1 to a  see for example at robottablei in figure 1 . the real fact necessity will be reevaluated during the graphplan backward phase. with a graphplan algorithm we cannot optimize the plan necessity  graphplan 

only optimizes the number of levels   but the necessity that we associate to the arcs  induced by the action models  can be used as a heuristic during backtrack. 
1 non-deterministic treatment 
during the graph expansion  the planner applies actions with n non-deterministic effects as n deterministic actions  but we associate a label with necessity and possibility to each branch as shown in figure 1 . the solution 

figure 1: a graph expansion with non-deterministic action  to simplify delete-lists are not drawn  
extraction is more complex; if the plan contains a nondeterministic branch then either the branch necessity is better than the goal necessity  and the plan is valid   or the branch necessity is lower. in this case  the planner must verify that the plan is also valid for the other branches. 
　for example on figure 1  the planner applies a nondeterministic action take which  creates  two possible worlds a n d . at this point  the robot will not be able to distinguish in which world it is. the next actions should be applicable both in and  e.g. move until a perception action allows to distinguish between the two  branches . 

figure 1: a plan with non-deterministic action 
1 	perception treatment 
the main difference between non-deterministic and perception action is that the robot will know after perception on which  branch  it is. the planner can then build 
a conditional plan. for example  in figure 1  the planner 
inserts a perception action  to distinguish if the robot is holding a red or a green test tube. note that i must be applicable in i and . after the wichone   action  the 
two plan  branches  are independent and involve different actions. this branches will be explored sequentially. this exploration is not necessary exhaustive. the planner will stop when it finds a plan that satisfies the goal necessity. 
this corresponds to two plan synthesis starting from 
 note that  the planner can re-use  in the second branch exploration  the graph expansion built during the first one. however  it will have to extend it. 

figure 1: a plan with a perception action 
1 a first step towards dealing with contingent events 
a key requirement for robot planning is to be able to reason about contingencies.we have introduced in our planner a capability that allows to deal with a subclass of external events. 
	indeed  	we distinguish between  actions  and 
 events ; while actions are operators over which the robot has full control  events are triggered whenever there is a situation that satisfies their preconditions. this model of the environment dynamics is based on extension of the nodep representation of contingent events  perret and alami  1 . similarly to action types  we have defined events with possibilistic  nondeterministic or conditional effects. 
　obviously  an elaborated reasoning on external events imposes temporal reasoning capabilities which are not included in our planner. however  we have chosen to exploit the number of plan steps as an estimation of durations. 
we distinguish two types of events: 
   immediate events  i.e events which apply immedi-ately after the situation which verifies their preconditions  one level in graphplan search   
  events with delay: an event with a delay of n time units will occur if its triggering situation lasts during n levels. 
　for example  our goal is to cool the red test tube. at the end of the plan  the red test tube must be at in the cold-room. but if the door stays open  will the cold-room continue to cool  after a moment the test tube which is in the cold-room will be damaged. this is modeled by an undesirable fact called fail  such an event can be modeled by: hightemperature 
	pre: 	opened door  

units the effect fail  with necessity n=1  will occur. 
　a  reasonable  robot should avoid such situations. a plan must be  safe . while applying the plan to the initial state of the world  given its foreseeable evolution modeled by external events  no situation shall arise where the  fail  fact appears. 
　we have extended our planning algorithm in order to fulfill such a requirement. during the graph expansion 
	guere and alami 	1 


figure 1: the frame's example 
phase  the planner fires all events whose preconditions are satisfied. and  at each backtrack state the planner tests if in this partial state an event has possibly caused a failure. if so  the state is declared unsafe and the plan is rejected. this method ensures a safe plan synthesis even if an event appears after achieving the goal. 
1 	results 
in this section  we present our planner capabilities through a realistic example and sample problems. the current version is implemented in   and it uses an algorithm based in graphplan. 
　as shown in figure 1  a robot stands beside table 1 in a room which contains two tables 
on each table a lamp is fixed: the first lamp often lights whereas the second one usually lights. at the initial state  a red test tube and a green one are on table1 . the goal is to cool the red test tube. a  dosed door separates the room from a cold-room in which there is a third table  table 1 . in order to cool a test tube  the robot must put it on table 1 the robot may move from a location to another  take a test tube  see what it holds  open and close the door and put. a test tube on a table. table 1 shows the initial state. 
　first  we require a plan which achieves the goal with tv  1:  t {on rcdte.stttibc  table1   = 1 / n{on rrdtcsttube  tablc     1 . the planner finds a solution with 1 actions in 1 msec: 

　an advantage of our planner is its capability of finding a better  but more complex  plan upon request; for example if its requested to find a plan that satisfies the same goal with higher necessity  n   1   the planner produces: 

　in this case  the planner has been obliged to use nondeterministic action as well as perception action to know which test tube it holds. note that  the light of tablet does not allow the robot to see the tube that it holds  and thus the robot must go to table1 so as to distinguish its color. in addition  we observe that the first three actions define a conformant plan  smith and weld  1 . 
　in the third example  we add two external events: if the cold-room door stays open too long  1 levels   the contents of the cold-room will be damaged; if the robot stays too long in the cold-room with the door closed it will be damaged. the planner finds a safe conditional plan  in 1 msec  that satisfies 


note that the door is only closed at  the end of the plan: close the door is not a reflex  it has been planned and inserted in the right place. 
　to upgrade our goal description  we will introduce  in further work  the notion of flexible goals as in posplan  da costa pereira et al  1  with qualitative utility  dubois and prade  1 . indeed the robot se-
curity can be more important than mission achieving  that we will model by 

　in table 1  we present set of a classical problems solved by our planner. note that the cpu time is not completely significant  because the current version was implemented only to validate our representation.  bomb 

table 1: some problem results  on an ultra-sparc 1  
in toilet  is a problem proposed by  mcdermott  1  with sensing action    medical  by  weld et a/.  1 

1 	planning and scheduling 

and  fetch another package  by  pryor and collins  
1  . 
1 	conclusion 
in this paper  we have represented the uncertainty with the possibility theory; this allowed us to distinguish between two types of non-determinism: a non-determinism from insufficient modeling and a non-determinism from 

uncertainty. besides  we have introduced perception actions as well as a model of the environment dynamics through  contingent events . finally  we have presented an implemented experimental planner which is able to produce plans that are robust with respect to contingent events  and whose goal-achieving ability is evaluated a priori. the obtained plans can be conformant or conditional depending on the context and the user requirements. 
1 related work 
warplan  warren  1  is the first plan ner wrn.cn works on the non-deterministic action and conditional effects. we can distinguish two planner types: the robot environment is uncertain and safe. for example buridan  kushmeric et al.  1  is a conditional probabilistic planner. the plan produced by bur1dan is a linear action sequence which achieves the goal whatever the initial world. posplan  da costa pereira et al.  1  is possibilistic planner which searches an optimal plan with uncertainty non-determinism. uwl  etzioni et al  1  introduces a formalism for conditional branches and observations with runtime variables. c-buridan  draper et al.  1  proposes perception actions with probabilistic outcomes  noisy sensors . the complete ignorance modeling is the main problem of these planners because of the probabilistic representation. cassandra  pryor and collins  1  is a non-deterministic planner with conditional effects which can only model the complete ignorance. sgp  weld et al.  1  is the most recent non-deterministic planner with complete ignorance modeling. it is an extension of the conformant planner cgp smith and weld  1  with sensing actions. sgp builds quickly plans using graphplan algorithm. we can note that sgp cannot produce new worlds during planning; moreover it can plan without sensing actions if the world is unobservable. the second type of planners deals with on dynamical environments as  kabanza  1  works about reactive planning. the environment is uncertain and dynamic  but observable. it has defined the safe situation notion to have secure planning. 
1 	future work 
our planner can build safe conditional plans involving non-deterministic actions and perception actions. mowever  it does not have the ability to concentrate on the exploration of the most  probable  courses of action and to anticipate the  safe  situations where it will have to replan if it detects an error during execution. as we mentioned it previously  we will also integrate  flexible  goals which will allow to model the robot safety as more important than the mission. another direction is to study more elaborate treatment of contingent events based on temporal reasoning. 
