 
identifying that parts of a knowledge base  kb  are irrelevant to a specific query is a powerful method of controlling search during problem solving. however  finding methods of such irrelevance reasoning and analyzing their utility are open problems. we present a framework based on a proof-theoretic analysis of irrelevance that enables us to address these problems. within the framework  we focus on a class of strong-irrelevance claims and show that they have several desirable properties. for example  in the context of horn-rule theories  we show that strong-irrelevance claims can be derived efficiently either by examining the kb or as logical consequences of other strongirrelevance claims. an important aspect is that our algorithms reason about irrelevance using only a small part of the kb. consequently  the reasoning is efficient and the derived irrelevance claims are independent of changes to other parts of the kb. 
1 	introduction 
control of reasoning is a major issue in scaling up problem solvers that use declarative representations  since inference is slowed down significantly as the size of the knowledge base  kb  is increased. a key factor for the slow down is the search of the inference engine through parts of the kb that are irrelevant to the query at hand. moreover  since a kb is designed for a variety of tasks  it is often at a level of detail that is too refined for a specific query. often  we have additional knowledge about the domain or about the kb that can be used to cut down drastically the space that the inference engine has to search. one important type of such knowledge consists of irrelevance claims stating that certain formulas are redundant with respect to  or will not be part of any derivation of a given class of queries  and consequently  those formulas can be removed. such irrelevance claims can be either given by the user or derived automatically by the system. 
* supported by a fellowship from shell oil company. 
1 	automated reasoning 
yehoshua sagiv 
dept. of computer science 
hebrew university 
jerusalem  israel 
 sagiv cs.huji.ac.il  
　effective use of irrelevance reasoning requires a formal understanding of the issues involved in such reasoning  as has been done in the context of probabilistic reasoning  pearl  1 . the work of  subramanian  1  presented a framework for stating irrelevance claims  and raised several issues concerning irrelevance reasoning. however  two issues remain largely open. the first is to find efficient methods for automatically deriving irrelevance claims. the second issue is to determine the utility of removing irrelevant knowledge  since removing irrelevant parts of a kb does not always improve efficiency. for example  redundant formulas  which may be considered irrelevant  can often speedup problem solvers 
　to address these issues  we first present a space of definitions of irrelevance  based on a proof-theoretic analysis of the notion. this space enables us to make finer dis unctions than those possible in the framework of  subramanian  1 . the main distinction we make is between weak-irrelevance claims and strong-irrelevance claims. roughly  a formula is strongly irrelevant to a query if it cannot appear in any of its derivations  whereas it is weakly irrelevant if it does not appear in some of its derivations. strong-irrelevance claims turn out to have some desirable properties. for example  in many cases it is possible to find efficiently formulas in the kb that are strongly irrelevant to a given query. in some cases it is even possible to find all strongly-irrelevant formulas. furthermore  unlike weak irrelevance  removing strongly-irrelevant formulas from a kb may only improve the performance  and sometimes the improvement is by orders-of-magnitude  as we will show . we investigate strong irrelevance in detail for horn-rule kbs and describe novel algorithms for efficiently deriving new strong-irrelevance claims from those given by the user. 
　our algorithms consider  in addition to the rules of the kb  only constraints on the ground facts that may possibly appear  e.g.  order constrr'nts  sorts   as opposed to looking at the ground facts themselves. consequently  if the ground facts change  the irrelevance claims still hold and  therefore  the cost of irrelevance reasoning is amortized over many queries. the main difficulty in irrelevance reasoning is finding properties satisfied by all possible derivations of a given query. to do so  we use a powerful tool  the query tree  first introduced in  levy and sagiv  1 . the query tree encodes finitely all possible derivations of the query  even when rules are re-
cursive . the query tree facilitates automatic derivation of irrelevance claims that follow from an examination of the kb and irrelevance claims supplied by the user. 
1 	formalizing irrelevance 

1
 we can return unknown if neither are derivable. 
however that does not affect our discussion. 
1
　　an alternative definition often considered is finding one variable binding that satisfies the query formula. however  this distinction does not affect our discussion. 
of definitions of irrelevance and investigate the different properties of various definitions within this space. 
　it should be noted that our analysis is not an attempt to formalize the common sense notion of irrelevance or argue for properties of such a notion  as done  for example  by  gardenfors  1  . our goal is to utilize the notion of irrelevance to speed inference and  therefore  we analyze the ways in which it can arise in inference. specifically  we analyze irrelevance in a prooftheoretic setting by considering the possible derivations  or more generally  paths  that an inference mechanism can pursue in answering a query. in contrast  the analysis of  subramanian  1  is meta-theoretic  i.e.  it considers only the formulas in the k b   not the possible derivations of the query. consequently  we are able to make finer distinctions than those made in subramanian's framework. 

1
　　given some criteria of minimality for derivations. see section 1 for a definition of minimality in the case of hornrule kbs. 
1
　　 we can also consider other ways of quantifying over a set of derivations  such as requiring that di holds for some percent of the derivations. in this paper  however  we consider only universal and existential quantifications. 


1 	automated reasoning 


practical and defeats the original goal of relevance reasoning. therefore  we would like to derive irrelevance claims that depend only on a small and stable part of the kb and are independent of changes to other parts of the kb. in many applications  the bulk of the kb consists of ground facts that are updated frequently  while the rules of the kb form a small and stable part. therefore  we are not going to examine the ground facts of kb directly. instead  we will use a set c of high-level constraints describing the ground facts that may possibly appear in the kb  e.g.  
　constraints may also appear in rules  in the form of interpreted predicates  such as the order predicates =   and    or sort predicates . many interactions between rules can be detected by analyzing the semantics of these interpreted predicates. furthermore  interpreted predicates play an important role in many applications  and often  reasoning with them can be done efficiently. note that in particular  the variable patterns in the rules can be viewed as constraints  using equality . 
　we would like our relevance reasoning to incorporate both the semantics of the interpreted predicates appearing in rules and the semantics of the constraints imposed on the possible ground facts. formally  it means that we have to consider the following problem. given a set p of rules  a set c of constraints on the ground facts  and a query q  find  some or all  rules and ground facts that are irrelevant to q in every kb of  where denotes the set of all kbs consisting of v and a set g of ground facts  such that g satisfy the constraints of c. 
　the distinctions made in our space of definitions also correspond to different answers to the above problem. first  we observe that determining weak irrelevance is undecidable  even in very restricted cases: 
proposition 1: determining whether a formula 1  is weakly irrelevant to a query q  with respect to  and the set of all derivations  is undecidable even if the rules of v contain no function symbols  c is empty and there are no interpreted predicates in rules. 
　this result is proved by a reduction from the ruleredundancy problem  shmueli  1 . algorithms that find some weakly-irrelevant formulas  but may fail to identify all of them  are described by  sagiv and yannakakis  1  and  sagiv  1 . 
　for strong irrelevance  the situation is much better. in  levy and sagiv  1   we have shown that strong 
irrelevance is decidable for function-free horn rules and interpreted predicates. the result shows that strong irrelevance is decidable when considering either the set of all derivations  or only the set of all minimal derivations.1 the algorithms cover a wide range of interpreted predicates  e.g.  order and sort constraints.1 
   when function symbols are introduced  determining strong irrelevance is undecidable for kb's with recursion. however  the algorithms described remain sound  i.e.  if they deem a formula irrelevant  then it is irrelevant. 
e x a m p l e 1 : let step  bigstep  bad point and good point be the edb predicates  where the rules are: 

the following constraints are known about the ground facts: 

   figure 1 shows that rule r1 is strongly irrelevant to the query goodpath x y   since the constraints on big step contradict those of the nodes that might be unified with the consequent of r1. moreover  we can also deem many ground facts strongly irrelevant  such as all badpoint x   where  where  and all the facts for big step. i 
　in the next section  we will describe an algorithm for deriving logical conclusions from irrelevance claims given by the user. the algorithm uses a powerful tool  called the query tree  first introduced in  levy and sagiv  1 . below  we briefly describe some aspects of query trees. 
1 	t h e q u e r y tree 
there are several difficulties in deriving irrelevance claims. first  we need to establish properties of the set of all derivations of the query without enumerating them. second  we are given the rules of the k b   but have only a partial knowledge about the ground facts in the kb. finally  we want to enforce the semantics of the interpreted predicates. the query tree provides a compact representation of precisely the set of all derivations of the query that satisfy the semantics of the interpreted predicates. 
　the query tree is a symbolic a n d - o r tree consisting of goal nodes and rule nodes  see figure 1 . the root of the tree is a goal node labeled with the query. a goalnode g has a child for every rule whose consequent unifies with g  and the actual child is the rule resulting from the unification with g. a rule node has a goal-node child for 
1
　　the algorithms for these two cases differ in their complexity 
1
　　formally  we require that the constraint language c satisfy several properties. we must be able to determine when two sentences in the constraint language are equivalent. furthermore  there must be a finite number of non-equivalent sentences when the number of variables is fixed. for full details  see  levy and sagiv  1 . 


every conjunct in its antecedent. if a kb has recursive rules  such a simple minded construction of the tree will not terminate. in order to get a finite representation of all possible derivations  we attach a label to each node in the tree. the label of a node contains the tightest constraint that needs to be satisfied by tuples generated in that node. the label is inferred by the constraint literals appearing in the rules and the constraints known about the possible ground facts that may appear in the kb. a goal node will be further expanded only if there is no other expanded node in the tree that has an isomorphic label. note that computing the labels of the nodes may require several phases of propagation through the nodes in the tree. 
　a query-tree t encodes a set of symbolic derivations. a symbolic derivation is like a derivation except that some constants are replaced by variables  and it represents the set of derivations that can be obtained by assigning constants to those variables. a symbolic derivation is encoded by the query tree if it can be constructed as follows. start from the root and choose one rule-node child and its subgoal nodes. inductively  let t be the tree created so far. if n is a leaf of t for an idb predicate  let n' be the goal node in t that has a label isomorphic to n and was expanded  n' may be n itself . expand n with one of the children of n'. 
　when the kb contains no function symbols  the query tree encodes precisely the set of derivations of the query that use formulas that satisfy the constraints. specifically: 
  for any derivation d that uses only ground facts that satisfy the constraints of c  there exists a symbolic derivation d and an assignment  r  such that  and d is encoded by the query tree. 
  for every symbolic derivation d encoded by the tree  there is a variable assignment such that  and the leaves of 
specifically  it requires rules that create in their conse-
　consequently  the query tree provides a sound and quents permutations of the variables from their antecedents complete inference mechanism for strong irrelevance 1 for example  this knowledge may be based on the fact  with respect to  specifically  a rule is strongly that the join of two relations is empty. 
1 	automated reasoning 

	1 	the utility of relevance reasoning 
removing strongly-irrelevant formulas  i.e.  rules and ground facts  effectively prunes many useless paths that a problem solver  such as a backward chainer  has to pursue. removing a large number of ground facts can particularly impact the performance  since much of the cost of a problem solver is in doing database lookups. the savings will be especially significant when the lookup involves uninstantiated variables. for instance  in example 1 we need to perform many lookups of the form step x y   where y is uninstantiated. removing all the ground facts for which y   1 will drastically reduce the search. 
　identifying irrelevant facts also yield savings when updates are done. for example  if the kb is updated with a fact that is known to be irrelevant  then we need not recompute the answer to the query. finally  identifying which facts are irrelevant to a query leads to space savings in storing the kb. this is especially significant when deciding which parts of a large kb should be brought into main memory. 
　we tested the impact of removing irrelevant facts for over 1 sets of queries taken from four domains. space limitations preclude the presentation of the complete results. table 1 presents a set of representative results. more detailed results can be found in  levy  1  rows 1 &: 1 use the rules given in example 1. rows 1 are taken from a travel kb  using real airline data  row 1 uses a kb describing compatibilities between wines and dishes  gleaning some knowledge from  rombauer and rombauer-becker  1    while the last row uses a kb describing relationships between students  advisors and institutions  using a database of ph.d. graduates in computer science . 
　in the table  filtering time is the time taken to build the query tree and to remove the irrelevant facts. percent irrelevant is the percent of facts that were removed 
from the kb. bc1 is the time taken to find all solutions to the query using the original kb  and bc1 is the corresponding time using the filtered kb.1 the results show significant speedups  usually in excess of 1  ranging up to 1  mean: 1  median: 1   while the time taken to build the query tree and filter the kb are usually insignificant. the speedups grew significantly as the percent of irrelevant facts grew. for example  using the same query as in row 1  the speedup was a factor of 1 when 1% of the ground facts were removed. furthermore  the speedups grew as the size of the kb grew  even when the percent of irrelevant facts remained the same. similar speedups were recorded when the number of nodes visited in the search was the performance measure  instead of the execution time  and when measuring the time taken to find just the first solution to the query. 
the experiments were performed on a ti explorer ii. 
1
        the performance of our backward chainer compared fathe theorem is proved by a reduction from the rule- vorably with that of epikit  a commercial implementation of redundancy problem  shmueli  1 . mrs  russell  1  . 


table 1: experimental results. 
1 	discussion 
relevance reasoning is a powerful method to control inference. we presented a general framework for stating knowledge about irrelevance and reasoning with it. we concentrated on the class of strong-irrelevance claims that has several desirable properties  such as existence of efficient algorithms for detecting irrelevant facts. removing strongly-irrelevant formulas may only improve the performance  and our experiments have shown that these savings are significant. furthermore  relevance reasoning is done with only partial knowledge about the contents of the kb and does not need to be repeated when certain changes occur in the kb. consequently  our methods are especially effective for kbs that contain many ground facts. 
   our analysis of irrelevance can be viewed as a refinement of the analysis in  subramanian  1 . the specific definitions considered by subramanian fall under weak irrelevance in our framework. subramanian defined the class of computational-irrelevance claims to be claims that lead to computational savings. our class of strong irrelevance is a prime example of computational irrelevance. it should be noted that  subramanian and genesereth  1  discusses a definition of strong irrelevance  but it is a variation on weak irrelevance and is not an instance of computational irrelevance. 
   the query tree encodes the space of possible derivations of the query. recently  the question of finding optimal methods to search that space has received a lot of attention  smith  1  greiner  1l ; a related issue is analyzing the utility of techniques in explanation based learning  etzioni  1  greiner and jurisica  1 . much of this work requires a graph-like representation of the search space under consideration. the query tree is such a representation that handles recursive theories in a principled manner and fully incorporates the interpreted constraints appearing in rules. 
1 	acknowledgements 
the authors would like to thank richard fikes  nir 
friedman  karen myers  pandu nayak and jeff van baalen for valuable discussions and comments on earlier drafts of this paper. 
