 
recently more and more researchers have been supporting the view that learning is a goaldriven process. one of the key properties of a goal-driven learner is introspectiveness - the ability to notice the gaps in its knowledge and to reason about the information required to fill in those gaps. in this paper  we introduce a quantitative introspective learning paradigm into case-based reasoning  cbr . the result is an integrated problem-solving model which will learn introspectively feature weights in a case base in order to be responsive dynamically to its users. in contrast to the existing qualitative methods for introspective learning  our model has the advantage of being able to capture accurate learning information in the interactions with its users. a cbr system equipped with quantitative introspective learning ability can allow the feature weights to be captured automatically and to track its users' changing preferences continuously. in such a system  while the reasoning part is still case-based  the learning part is shouldered by a quantitative introspective learning model. weight learning and evolution are accomplished in the background. the effectiveness of this integration will be demonstrated through a series of empirical experiments. 
1 	introduction 
case-based reasoning  cbr  is a problem-solving strategy which uses stored previous cases to solve current problems  kolodner  1 . it has enjoyed tremendous success for solving problems related to knowledge reuse  leake and ram  1 . usually in a case base a case's index is a set of important descriptors of the case. it can be used to distinguish a case from others. in many implementations  these descriptors are represented as feature-value pairs and usually a feature is associated with an importance value called feature weight to indicate how important it is in the case retrieval process. when a new problem is presented  its index will be extracted and used to trigger a search in the case base. the cases with the most similar indices will be retrieved for further consideration  kolodner  1 . 
　the performance of a cbr system depends on how to use appropriate features to index cases  and how to obtain an accurate measurement of the similarity between cases in the case retrieval process. therefore the feature weights play an important role in determining the success of cbr applications. how to choose and maintain an appropriate set of feature weights in a case base is a non-trivial problem in cbr research. in addition  the relative importance of the cases is changing with time  partly due to the uneven and changing distribution of the inherent problem space  also partly due to the changing interests of its users. how to evolve a case base continuously in an automated manner is also becoming an urgent task of the knowledge base industry. 
　one approach to tackling this problem is to use introspective learning  which has a representation of its own process in order to detect deviations that show when the learning is needed as well as what the learning needs  leake et a/.  1; ram and cox  1 . in the past  various introspective learning methods have been employed in feature weighting in cbr systems  fox and leake  1; leake et a/.  1; wettschereck et a/.  1; bonzano et a/.  1 . a main theme is to learn through qualitative introspective learning  whereby the feature weights are adjusted based on a rough estimate of the direction for a change: if the weights are too high  then adjust them so that they become lower  and vice versa. but how much has to be changed quantitatively is not sufficiently determined. in this work  we extend qualitative introspective learning to quantitative introspective learning within cbr. with the quantitative learning methods  we can adjust the weights not only in the right direction  but also in the right amount. we claim that such an extension provides a sound and promising continual weight introspective learning method in cbr. 
　this paper is organized as follows. in section 1  we introduce some related work on the application of introspective learning to feature weighting. section 1 presents a novel quantitative introspective learning model integrated into case-based reasoning. in section 1 we demonstrate the experimental results for evaluating the perfor-

mance of our integrated model. and also there we crossvalidate our work with others'. section 1 concludes our discussion  where we will also explore our future work. 
1 	qualitative introspective learning methods 
leake et al.  leake and ram  1  summarize in a symposium report the goal-driven learning process from various aspects. they indicate that one of the three key properties of a goal-driven learner is its introspectiveness  an ability to notice the gaps in its knowledge and to reason about the information needed to fill in those gaps. they also pinpoint that introspective learning acquires problem-solving knowledge by monitoring its run-time performance  seeking chances in this process to learn by itself. 
　in  fox and leake  1   fox et al. describe their experiences with introspective learning in cbr. the robbie system described is an application of an introspective model to the task of refining indexes used to retrieve cases. its goal is to improve reasoning process when encountering failures in its reasoning. the introspective learning component in the system monitors its reasoning process by comparing it with a declarative model which is used to describe the system's ideal reasoning process. once a failure is found  the model is used to create an explanation of the failure in terms of other failed assertions  and to suggest a repair. the authors claim that even under knowledge-poor initial conditions  the introspective learning of new feature indexes improves the success rate of the system. but they still indicate that there exists a problem with the ordering of the presentation of training cases to the system due to the inherent shortcoming of their learning mechanism. 
as a variation of a model that is introduced in  munoz-
avilz and huellen  1   bonzano et al.  bonzano ct a/.  
1  also propose introspective learning as an approach to feature weighting in cbr  demonstrating their system which combines introspective learning with cbr. they first pose the problem with their experience in constructing a cbr system for air traffic control. the problem encountered is that it is difficult to determine the important features and adjust their relative importance. the situation is further complicated by the fact that the features are highly context-sensitive; the predictiveness of a feature depends heavily on the current context. they use so-called pulling and pushing techniques to adjust the feature weights. given a target t and two cases a and b  if it is judged that a is a correct solution to t but b is not  the learning method will push b away from t  and pull a closer to t. as to its weight updating policy  their introspective learning method uses a decaying learning process as shown in the following two formulae. 
 1  
 1  
where kc represents the number of times that a case has been correctly retrieved  fc represents the number of times that a case has been incorrectly retrieved  and  determines the initial weight change. the ratio be-
tween fc and kc is used to reduce the influence of the weight update as the number of successful retrievals increases. we can observe that the timing of triggering the adjustment process is very important; when to trigger the adjustment of the weights using the above two formulae is a crucial issue yet to be further addressed in the work. this limitation makes it necessary to involve a human user in the learning process. in contrast  instead of relying on a domain-independent decaying factor  what we propose in this paper is a continual learning process in the lifetime of the case based reasoner. this extension releases the human manager of the decision to explicitly trigger a learning process. 
　the second limitation of the work by bonzano et al. is that it is qualitative in nature. while the direction of change in feature weights is indicated in the above two formulae  the amount of change is only influenced by the frequency of successes and failures and the decaying factor. a quantitative change would be needed to reflect the amount of adjustment in proportion to the error. 
　the third limitation  reported by the authors  is that the learning method does not work well for pivotal cases  as the redundancy in a case base is essential in such a learning process. a pivotal case is the one that provides coverage not provided by the other cases in a case base  smyth and keane  1 . in contrast  the quantitative introspective learning paradigm that we will present in this paper will allow not only pairs of cases to be compared  but also any number of cases to participate in the learning process. this is achieved through a process in which a user can provide feedback at any time to all topranking cases  not just to a few selected. in section 1  we will provide experimental comparisons between the quantitative and qualitative methods. 
1 a quantitative introspective learning paradigm 
1 problem statement 
using introspective learning  we wish to acquire feature weights in a case base in a changing and multi-user environment. in a changing environment  users and their preferences for what cases are the best for their problems also change with time. for example  in an electronic commerce application using cbr  cases may represent a configuration of a product  say a computer  model. the features then can represent various user specifications on the product  and the weights can indicate the level of interest of a user in a particular feature. since a user's preferences may change with time  there is a need to acquire and track her/his preferences. furthermore  in a multi-user environment  there is a strong need for catering to users with different needs. for example  an on-line computer vendor may have different sets of feature weights for students and teachers. it is desirable to adapt a cbr system with its users. 
	zhang and yang 	1 


figure 1: two-layer architecture of a case base 
　our assumptions for the research are as follows. we assume that our desired quantitative introspective learning model is given as an input a set of features where each feature has some values. some subset of the features and values may be relevant to a particular case at hand at any given time  but there is no prior knowledge on which ones are actually useful to the reasoner currently. our model monitors its running process through the interactions with its users. 
for a case base our learning task is of two folds: 
1. weight acquisition to acquire the feature weights after a user has used the system for a certain period of time; 
1. continual tracking to adapt the feature weights to a user's preference which may change with time  and to allow different users to have different preferences. 
1 	strategy for feature weighting 
the mechanism in our quantitative introspective learning process resembles that of a back-propagation neural network  which is a very popular learning paradigm in ai. for details on the mathematical foundation and applications of back-propagation neural networks  see  zurada  1; gupta and ding  1 . 
　more specifically  we use a two-layer architecture to model a case base. the front layer consists of a set of feature-value pairs. the back layer consists of a set of cases. a feature-value pair is associated with a case if it may exert influence on that case. furthermore  there is a weight attached to the association. although we use a two-layer feature weighting system in this paper  the architecture can be potentially extended to multiple layers which can include hidden layers. we address this situation in  zhang and yang  1 . 
　using two-layer architecture to model a case base is conceptually shown in figure 1 
　for a case base of j cases  suppose that there are n features. for each feature fi  there arc mi values  where i = 1         tv. there is a total of  featurevalue pairs. we label these feature-value pairs as   where i = 1  1         i. we use cj to represent each case  where jf = 1 1  ./. there is a weight  attached to the connection between case cj and feature-value pair fvi if there is an association between thern. 
computing a case's score 
a case's score is computed using the feature-value pairs selected by a user to represent an input query. for each case cj  its score is computed using the following formula: 
		 1  

figure 1: quantitative introspective learning in a cbr system 
where j= 1 1  j  sc  is the score of case cj  and xi is 1 if there is a connection between case cj and feature-value pair fvi and fvi is selected. otherwise xi is 1. 
learning feature weights 
after a query is presented  all the previous cases have been scored according to formula 1 with the promising ones at higher positions. if the user wants to feed back some information to the system as whether a case is desired or not  we then can employ the following formula to compute a new weight based on her/his feedback information. 
 where vp  is the new weight to be computed  is the old weight attached to the connection between case cj and feature-value pair fvi  dscj is the desired score for cj  so  is the score computed in formula 1  and 1 is the learning rate. xi is 1 if there is a connection between case cj and feature-value pair fvi and fvi is selected by the user. otherwise it is zero. 
　we have to emphasize that  in the above formula  the term  encodes the quantitative information  i.e.  the actual gap between the desired and computed behavior. on the other hand  in formulae 1 and 1 there is no such quantitative information encoded. although they try to use the number of retrieval success and failure in their weight learning  we consider that such a representation is not sufficiently accurate when compared with ours. 
1 	user's interaction model 
the introspective learning process in our integrated model is similar to that of a back-propagation neural network. an important difference between them is that our learning process is interactive rather than batching and automatic. in our learning process  there is no training data explicitly defined; the system is continuously being trained by its user throughout its lifetime. a user's responses to the system's behavior form an implicit source of training data. 
　after our introspective learning model is integrated into a cbr system  the problem-solving process is paradigmed in figure 1. the cbr system receives a 

user's current problem description and a set of selected feature-value pairs  label 1 . it will then access the weights  label 1  to compute the case scores  and present the result to the user for her/his judgment  label 1 . if the user feeds back some judgment to the system  label 1   the system will compute quantitatively the gap between the computed and the desired score  and if necessary  modify the weights accordingly  label 1 . 
1 	empirical tests 
the introspective feature-weight learning model is fully implemented and integrated in the framework of the casead visor tm  system  zhang and yang  1   which is a cbr system implemented by the case-based reasoning group at simon fraser university. right now the resultant caseadvisor tm  system from such an integration is able to learn the unpredictable information hidden in an end user's behavior. a user's interactions with the system provide the guidance in determining quantitatively not only what the right direction is for updating weights but also how much the weight should be updated quantitatively. 
　in this section  we will demonstrate that our proposed learning model conforms to our expectations. in particular  we wish to confirm through the experiments that the model could learn a user's queries after sufficient interactions with its users and could scale up to case bases with realistic sizes. this is shown in the first experiment suite which is conducted on different case bases from the repository of machine learning databases and domain theories l at the university of california at irvine  uci . furthermore  in the second experiment  we perform a comparison between the quantitative method and the qualitative method proposed by bonzano et al. we will demonstrate that the quantitative method can achieve better learning accuracy and faster convergence rate through continual updating. 
1 	experiment with case bases from uci 
we take the dermatology database and car database from the uci repository. we test our system on both databases and obtain the similar experimental results. for brevity  in the following we focus on the dermatology database. the experiments are conducted on a platform of sun sparcstation 1  sunos 1  with 1 mb memory. the dermatology database contains 1 instances  tuples  and 1 attributes. we divide this database into increasingly larger databases  which contain 1  1  1  1  1  and 1 instances  respectively  and test the performance of our learning model. in our experiment  we first adapt these databases into the case bases that our system can be applied by converting all rows into cases and all columns into features. the values for a feature are contained under each column. after conversion  these case bases contain 1  1  1  1  1  and 1 cases  respectively. for each case base  we generate a set of queries for testing  the size of which is half the number 
	1 	http://www.ics.nci.edu/mlearn/mlrepository.html 

of cases. for instance  for the case base with 1 cases  the number of queries is 1. note that in these tests  the score of a case is scaled to between 1 and 1. 
　the training process is composed of five rounds for all the case bases. figure 1 shows the error convergence chart  of 1 queries for the case base of 1 cases. the x-axis represents the training process while the yaxis represents the error ranging from 1 to 1. it can be found that  almost all the cases  after five training rounds  have their errors falling into an acceptable range  in our experiment this range is set to 1 . the error convergence for other five case bases also demonstrates the same trends. for brevity  we do not show them here. 
　we also measure the average cpu time required for the adjustments for individual cases in each of these six case bases. the result is shown in figure 1  where the x-axis represents the six case bases with different sizes measured in cases  while the y-axis represents the average running time for each case in cpu seconds. we can see that the increase of the running time is in proportion to the square of the number of cases in a case base. therefore we can say that our algorithm is fast enough to be used in real-world practice  in which usu-
	zhang and yang 	1 

ally the case base sizes are not very huge. this confirms the scalability conjecture we make about our learning model. 
1 	comparison with bonzano et al.'s approach 
a closely related work on introspective feature-weight learning is proposed by bonzano et al.  bonzano et ai  1   also discussed in section 1 . we implement their algorithm and examine the convergence and performance comparison between our two models. the case base involved is also converted from the dermatology database in uci repository. it contains 1 cases. 
　there are three types of case bases in bonzano et al.'s model. the first is the training case base  it is composed of a user's queries in our learning model   the second one is the case base itself and the third one is a test case base  in our model  there is no explicit test case base; it is implicit in the usage of the system . for the experiment using their method  we set the training case base and the test case base to be the same. this comparison experiment is also conducted on a platform of sun sparcstation 1  sunos 1  with 1 mb memory. 
　figure 1  a  shows the comparison on the errors between our two models. in the figure  the x-axis represents all the 1 test cases  while the y-axis represents the errors of these cases along the training process. from the figure  we can easily see that among the 1 test cases  our model produces smaller errors for 1 cases. 
　in order to make a further comparison on the convergence trends  we plot the error chart for the first five training rounds in figure 1  b   where the x-axis represents the training process  while the y-axis represents the average error for each case. the figure shows that at the very first five training rounds our model has already produced an optimal training result. most of the trained cases in our method show the trends to approximate their desired scores. 
　we now analyze the learning and adjustment formulae 1 and 1 used in bonzano et al.'s model. these formulae give an estimation of what should be done when a retrieval success or failure is encountered. however  such an estimation is not precise enough. for example  if the desired case has a higher  similarity  score than expected  the case is over ranked and we have to reduce the weights associated with its feature-value pairs in order for it to be properly ranked  rather than increasing its weights. in the two formulae  there is no quantitative estimate associated with these information. in contrast  our adjustment strategy not only decides when to do the adjustments  but also takes into account at a more detailed level the quantitative gap between the current score and the target score  thus resulting in better learning quality. 
　however  we have to indicate that a limitation of our learning model  as compared to the qualitative model  is that it might take longer time to learn for each individual case. on average our model takes about four cpu seconds while bonzano et al.'s uses approximately 1 cpu seconds to complete an individual learning task. 
1 	discussion 
our learning model allows incremental changes to be made to a case base. as shown in the above experiments  for a case base of 1 cases  our model takes about four cpu seconds  running on a sun sparcstation 1 with 1 
mb memory  to train an individual case. therefore for 1 queries  it takes about 1 cpu minutes to train the whole case base. this shows that it is practically possible to retrain the whole network after introducing a new case into the case base. 
　in our experiments  we also observe an interesting phenomenon among feature-value pairs. in the above case base of 1 cases  we find that not all the cases converge to their desired scores; in that experiment  five out of 1 cases in the 1 queries oscillate around their desired scores. we also find that no matter how long our training process undertakes  these five cases still cannot converge. we attribute this phenomenon to the interactions among feature-value pairs. definitely  removing 
such interactions from a case base will help increase the learning quality. how to detect and remove those interactions pose an interesting research problem we wish to address in our future work. 
　we have to emphasize again that the quantitative introspective learning in our model is a continuous process and can be triggered at any time if necessary. our system will respond to its user at any time. every time a user changes her/his behavior  the change will be captured  and reflected in the next work session. 
1 	conclusion and future work 
we have shown the empirical test results of our quantitative introspective feature-weight learning model. based on the discussions throughout the paper  we can find that our proposed quantitative learning model fulfills our expectations. it captures the interactions between the system and its end user  and seeks chances to evolve itself. in the experiments  the model quickly approximates a user's behavior within a number of iterations. 
　our work aims to introspectively learn feature weights in a dynamic context in the case retrieval process of cbr. the needs from practical application of cbr in a fielded diagnosis system motivate us to explore their dynamic nature. the research is also motivated by our desire that a cbr system be a responsive system; its behavior needs to simulate its end user's behavior  incorporating her/his preferences. furthermore  a user's behavior is changing  requiring that a cbr system keep its pace with the changes. the integration of an introspective learning network into a cbr system makes these expectations possible. 
　we also note that our learning model has some limitations. although in our experiments nearly all the cases converge to their desired scores  we actually encounter divergence several times due to the interactions among 


figure 1: comparisons between bonzano et al.'s model and our mode!  in  a   each case has two bars. the left bar corresponds to bonzano et al.'s model while the right bar corresponds to ours  

different features. the effects of such interaction could be possibly reduced by introducing stronger bias factors into the system. we are also seeking other efficient and effective techniques to deal with the problem. in addition  one of the assumptions of our learning model is that the user of our system should be consistently one person in a certain period. if a different user comes to use the system  s/he might not satisfy and thus destroy the previous optimal case retrieval result  requiring the whole case base be retrained. 
　we will further explore  for our model  the more accurate relationship between the average running time and the size of a case base  including the number of featurevalue pairs and cases . in the future  we hope to address these problems by introducing more effective learning and feedback control mechanisms and architectures into cbr. 
