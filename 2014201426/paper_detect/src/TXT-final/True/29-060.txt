 
because observing the same actions can warrant different conclusions depending on who executed the actions  a goal recognizer that works well on one person might not work well on another. two problems that arise in providing user-specific recognition are how to consider the vast number of possible adaptations that might be made to the goal recognizer and how to evaluate a particular set of adaptations. for the first problem  we evaluate the use of hillclimbing to search the space of all combinations of an input set of adaptations. for the second problem  we present an algorithm that estimates the accuracy and coverage of a recognizer on a set of action sequences the individual has recently executed. we use these techniques to construct adapt  a recognizer-independent unsupervised-learning algorithm for adapting a recognizer to a person's idiosyncratic behaviors. our experiments in two domains show that applying adapt to the boce recognizer can improve its performance by a factor of two to three. 
1 	introduction 
goal recognition  e.g.  kautz  1; carberry  1   is the task of inferring a person's intentions given a partial view of their actions. as noted in  maes and kozierok  1; bauer  1; ardissono and cohen  1   goal recognition is difficult  in part  because people do not all act alike. the same actions can warrant different conclusions depending on who executed them. for example  when i go to the college inn cafe the waitress invariably brings me my usual order  scrambled eggs and rye toast  without asking me what i want. with a few exceptions discussed in section 1  previous approaches can provide user-specific recognition only by having a human expert hand-tune the recognizer for each person. 
   *many thanks to sandra carberry  oren etzioni  keith golden  steve hanks  anna karlin  nick kushmerick  diane 
litman  dan weld  and the reviewers of the submission draft of this paper for comments and discussion. this research was funded in part by office of naval research grant 1-j1  by arpa / rome labs grant f1-1  by a gift from rockwell international palo alto research  and by national science foundation grant iri-1. 
　we present the adapt algorithm for automatically adapting a recognizer to perform well for an individual  given a goal recognizer  a set of adaptations that can be made to the recognizer  and a sample of the person's recent behavior. 
　we treat the person's recent behavior as training data  and attempt to find the combination of adaptations with which the recognizer performs best on the sample behavior. for tract ability  we use hillclimbing to search the space of all possible combinations of adaptations. the primary challenge we address is how to evaluate the performance of the input goal recognizer with a candidate set of adaptations on the input sample data. the input data is not annotated with the person's actual goals. 
　we perform unsupervised learning by treating goals as verifiable predictions of future behavior  as opposed to mental state  pollack  1  or explanations  hobbs et al  1 . for example  if the recognizer indicates that a computer user's goal is to delete all her backup files  then we view the recognizer's output as predicting that the user will delete all her backup files. this goal-prediction is correct if she does go on to delete her backup files. 
　we empirically evaluate adapt on the boce goal recognizer  lesh and etzioni  1; 1 . our experiments in two domains show that applying adapt to the boce recognizer can improve its performance by a factor of two to three. 
　we use two metrics to gauge the quality of recognition: accuracy  the probability a recognizer's inferences are correct  and coverage  the probability the recognizer will draw an inference. we formally prove a tradeoff exists between accuracy and coverage in goal recognition. our work makes the following contributions: 
1. we present a framework for formally characterizing and comparing the performance of various goal recognizers. 
1. we present an unsupervised algorithm for training a goal recognizer on samples of action sequences that: 
  learns to filter out spurious actions. 
  adapts to the particular distribution of goals that an individual pursues. 
  learns in the presence of noise  such as if the ob-served person occasionally abandons tasks. 

　in section 1  we define the adaptive goal recognition problem. in section 1  we prove there is a tradeoff between accuracy and coverage. in section 1  we present a function which estimates accuracy and coverage. in section 1  we present the adapt function. in section 1  we describe our experiments. in sections 1 and 1  we discuss related work  future work  and conclusions. 
1 	formulation 
we now define the adaptive goal recognition problem. 
1 	basic definitions 
let q be the set of all persons  q be the set of all possible goals  and a* be the set of all action sequences any person might execute. the exec and goal functions describe the two relevant relationships among persons  goals  and action sequences. let exec q  a  hold iff person q is observed to execute action sequence a. let goal q g  hold iff person q has goal g. for simplicity  in this paper  we assume people have one goal at a time. 
　a goal recognizer maps an action sequence to either a goal g  indicating g is the person's goal  or nil  indicating the recognizer can not determine the person's goal given the current observations. formally  a goal recognizer is a function from  while this definition is 
fairly broad  it does not allow for recognizers that output a probability distribution over goals  e.g.  pynadath and wellman  1  . 
　samples of people's behavior are stored as episodes. an episode is a pair  a  s  where a is an action sequence the person executed and s is the state of the world at the time the person began executing those actions. 
1 	adaptable recognizers 
we refer to adjustments that can be made to a goal recognizer as adaptations. notation ally  for any set of adaptations t  let rt be recognizer r with adaptations t. different types of adaptations will be appropriate for different goal recognizers. we now provide a simplified description of the boce goal recognizer  lesh and etzioni  1; 1  and two adaptations for boce. 
   boce recognizes goals based on an input set of action schemas act  a set of goal predicates  and a set of background goals bq. boce composes the actions in act into candidate plans and the predicates in  into candidate goals based on assumptions about 
what type of plans and goals people have. in particular  boce assumes  1  the person's goal is a conjunction of the input predicates  and  1  every action in the person's plan will either enable another action in that plan or enable the person's goal. the background goals in bq arc used to filter out actions that are not causally connected to the person's goal. for example  if bq contains the goal  have cash  then boce will essentially disregard observing a person stop at an automatic teller machine rather than conclude that getting cash is in service of her current goal. 
　two types of adaptations available for boce  which are discussed in greater detail in section 1  are: 
	lesh 	1 



inition for achieves  such as the modal truth criterion 
 chapman  1  for strips  fikes and nilsson  1 .1 
　we assume the recognizer will be called after each observed action until it infers a goal. for each episode  a s   the recognizer is fed incrementally longer prefixes of a until it produces some goal or outputs nil when given a. if the recognizer does produce a goal  we then determine if a achieves that goal from state s. in the following pseudo code  the inputs variable counts the number of calls to the recognizer and inferences and correct count the number of inferences and correct inferences  respectively  made by the recognizer: estimate recognizer r  episodes ♀  
calls to 
the average length of action sequences in 	we further discuss complexity and running time in section 1. 
　the experiments described in section 1 indicate that good estimates can be produced from reasonably small samples of behavior. we believe that in many domains collecting sample data is relatively cheap and easy. in software domains  for example  the commands executed by a computer user can be recorded. a key problem is task segmentation: how to know when a goal-solving episode starts and stops. it may be best that this problem is handled by the goal recognizer  since it will be difficult to perform task segmentation without also performing some form of goal recognition. in this case  the goal recognizer would be fed a continuous stream of goal solving behavior and output a sequence of goals. however  in our experiments and the current formulation of the problem  we assume the person's recent behavior is already segmented prior to adaptation. 
recognizer that always returns a goal that is achieved by the first action in a. modifying achieves to allow no irrelevant actions would be problematic in that we are interested in adapting goal recognizers to handle spurious  i.e. irrelevant actions. our current solution is to restrict the goal recognizer to output only legitimate top-level goals  corresponding to end events in kautz's plan hierarchies  kautz  1 . 
1
　　we do not actually need the full power of the modal truth criterion since a is a totally ordered set of actions. 
1 	an adaptive goal recognizer 
we now present an algorithm that tunes a given recognizer to perform well on a sample of a person's behavior. 
　let t be the set of all possible adaptations. adapt uses steepest ascent hill climbing to search the space of possible combinations of adaptations in set t. the starting point for the search is a recognizer without any adaptations. the neighbors of a recognizer are those recognizers with exactly one more  or one less  adaptation. in each iteration  we use estimate to evaluate the accuracy and coverage of the current best recognizer and all its neighbors. we then reset the current search point to the recognizer with the best combination of accuracy and coverage  as determined by the input score function. we repeat the process until we encounter a recognizer with a higher score than all its neighbors  and then return this recognizer's adaptations. the pseudo code is: 

　the adapt algorithm requires  t  x k calls to estimate where k is the number of iterations until a local maximum is found. although adapt is computationally intensive  our notion is that it would be allowed to run overnight  perhaps once a month  to adapt to changes in a person's behavior. furthermore  adapt can be interrupted at any time; set best will always be a set of adaptations with a higher estimated value than any set of adaptations previously considered. we believe that a small number of adaptations will often significantly improve recognition. finally  the adapt algorithm is highly amenable to parallelization. in any iteration  all the calls to estimate can be processed in parallel  and the estimate function itself is easily parallelizable. 
1 	experimental validation 
in this section  we describe experiments that measure how much our adaptive techniques improve recognition. 
　we apply adapt to data that contain different idiosyncratic behaviors. for example  one person might spuriously execute the unix command date while another might spuriously execute the pwd command. our hypothesis is that adapting the recognizer to each individual behavior will outperform applying any recognizer to all behaviors. we measure: 
  impact: what percentage of someone's work can be done by offering to complete the goal that the recognizer outputs  
  error: how often does the recognizer produce an in-correct goal  
	lesh 	1 

in all of our experiments  we use separate data for training and testing adapt. 
1 	spurious actions 
we ran the first set of experiments on action sequences generated by toast  agre and horswill  1   a reactive agent that solves goals such as making omelets  cleaning dirty dishes  or setting the table. to generate  noisy  behavior  we randomly insert actions into toast's behavior  such as causing toast to randomly add butter to a pan on the stove  or periodically wash its spatula. 
　the boce goal recognizer identifies toast's goal by ruling out all but one of the goals toast might have. boce rejects a goal if an observed action is not part of any plan to achieve the goal. for example  boce would reject the goal  make poached eggs  if toast adds butter to a pan. spurious actions can cause boce to reject toast's actual goal which can  in turn  cause boce to either fail to infer any goal or infer the wrong goal. 
　adding background goals can reduce the confusion caused by spurious actions. for example  adding a background goal  have butter in pans  will essentially cause boce to disregard any observations of toast adding butter to pans. boce must  however  add background goals judiciously because ignoring relevant actions can delay or even prevent boce from identifying toast's goal. in the extreme  if all possible background goals are added then boce will never output a goal. 
　we vary two parameters: the frequency of spurious actions and the number of distinct spurious actions. for example  if 1% of toast's actions are either a spurious washing of the spatula or a spurious adding of butter  then the frequency is 1 and there are 1 distinct spurious actions. in each trial  we train boce on 1 episodes and test boce on another set of 1 episodes. the numbers reflect averages from 1 trials. we use a score function that weights accuracy 1 times as much as coverage. 
in any given episode  boce outputs at most one goal. 
in our testing phase  we record the number of times 
boce makes no inference  correctly identifies toast's goal  and incorrectly identifies toast's goal. we also measure plan length  defined as the number of actions toast executes per goal. toast halts execution if boce correctly identifies  and presumably completes  its goal. 
　as shown in figure 1  the adapted recognizer performs significantly better than the unadapted recognizer when toast has 1 distinct spurious actions. as the frequency of spurious actions increases  the unadapted recognizer's performance degrades rapidly. in contrast  the adapted recognizer never mistakenly attributes a goal to toast. 
　as shown in figure 1  the performance of the adapted recognizer degrades as the number of distinct spurious actions increases. this happens because adapt must add more and more background goals  which interfere with boce's ability to identify toast's goals. note that the adapted case is still far superior to the unadapted case in that it does not make any incorrect inferences. 
the table in figure 1 shows that as the frequency of 

figure 1: learning to filter spurious actions. in each trial  there were 1 distinct spurious actions. 

figure 1: learning to filter spurious actions. in these experiments  the frequency of spurious actions was 1. 
spurious actions increases  the impact of adapting the recognizer grows considerably. 
frequency of spurious actions .1 .1 1 1 1 average plan length unadapted adapted 1 
1 1 
1 1 
1 1 
1 1 1 figure 1: impact of adapting the recognizer: in each trial run  there were 1 different spurious actions. 
　the results shown in figures 1 and 1 show that adapt improves recognition by a factor of two to three over unadapted recognition. 
1 	g o a l d i s t r i b u t i o n 
in the second set of experiments  we simulate people whose goals are to find an object with a conjunction of properties  such as finding a computer with no users working on it that has over 1 mb ram. we vary the probability with which goals include each predicate. 
　in our simulations  the person searches until she finds  or the recognizer suggests  an object that satisfies her goal. the recognizer can make one suggestion after each time the person polls an object. we measure plan length  the average number of objects polled by the person  and error  the average number of incorrect suggestions. 
　adapt adjusts the recognizer by adding or removing predicates from   the set of predicates with which boce forms goals. if lacks a predicate a person uses then boce can suggest a wrong object to the user. for example  the person might poll five computers with 1 mb ram but if  does not contain the large.memory predicate  then boce would suggest a computer with small memory. on the other hand  if contains too many predicates then boce will be 
delayed in suggesting a useful object to the person. 
　figure 1 compares 1 recognizers  each described by a point where the x-coordinate is the average plan length 

and the y-coordinate is the average error. a perfect recognizer would be positioned on the origin of the graph. 
　points u1 to u1 represent unadapted recognizers:  ji is a recognizer where  contains i random predi-
cates  out of 1 possible predicates. as the size of increases the number of errors decrease but the plan length increases. note that no unadapted recognizer has both better error and plan length than any other. 
t1  t1  and t1 describe recognizers trained on 
1  1  and 1 training examples. in these experiments  a recognizer trained on 1 or 1 examples saves the person twice as much work as any unadapted recognizer with comparable error  and has much less error than any unadapted recognizer that is nearly as effective. 
figure 1: 	learning which goals different people pursue: 
points t1  t1  and t1 represent a recognizer trained on 
1  1  and 1 training examples respectively. points ul through u1 represent 1 different unadapted recognizers. 
1 	adapting in the presence of noise 
we also measured the effect of one type of noise in the training data: we removed the second half of the executed plan from some of the input episodes. 
　we ran these experiments on actions collected from toast  as described in section 1. we varied the frequency with which toast would abandon its current goal after executing half its plan. essentially  corrupting the input data in this fashion causes adapt to add extraneous background goals in an effort to avoid mistakes in the tainted training cases. as shown in table 1  adapt performs reasonably well with up to 1% noise levels. we used 1 training examples in these experiments because the results were poor with 1 examples.1 note that although the percentage of correct inference goes down  boce still never makes an incorrect inference but rather outputs no goal in more cases. 
1 	related work 
there have been several other approaches to various aspects of the general problem of providing user-specific plan and goal recognition. 
　 maes and kozierok  1  apply machine learning techniques to detect recurrent patterns of behavior of computer users. their interface agents learn from observing the user  as we do  but also learn from user feedback and direct training sessions. they focus on predicting the user's next action by matching the current 
     1 gathering this many training examples may be infeasible in some domains. 
frequency of abandonment 1 .1 1 1 1 plan length 1 1 1 1 1 percent right 
' percent wrong 
  percent skipped 1 
1 
1 1 
1 1 
1 1 
1 1 
1 
1 figure 1: effect of noise in training data. the frequency of spurious actions was 1. and there were 1 distinct spurious actions per trial run. 
observations to the closest previously encountered situation. in contrast  we do not specifically analyze the past behavior of the observed person but instead evaluate how well a given recognizer  with various adaptations  performs on this behavior. note that our algorithm  adapt  might be used to adjust the parameters of interface agents to perform better on a sample of past behavior. 
　 elzer et al.  1; ardissono  1  integrate user modeling and plan recognition to support dialogue understanding. for example  if the user model indicates that john is terrified of flying  then the plan recognizer can reject the plan of flying to chicago when john says  i want to go to chicago . in principle  this work could allow a plan recognizer to take advantage of the many techniques developed by the user modeling community for acquiring user preferences and beliefs. while our work has similar motivation  our approach is more direct  or  low-level   in that we find a goal recognizer which works well on a person's recent behavior rather than infer a declarative model of that person's idiosyncrasies or beliefs. again  our approach could be used in conjunction with this work by adapting a recognizer that uses user-specific information or even adapting the way in which the recognizer reasons about the user model. 
our work most closely resembles that described in 
 bauer  1; 1 . bauer runs a plan recognizer on a set of input episodes from a typical user  just as we do   and then gathers statistical data based on the results of running the plan recognizer on the entire observable behavior in each episode. for example  bauer's techniques can learn that a particular computer user will save email with 1% certainty  unless the email is from her manager  in which case she deletes it with 1% certainty. this analysis enables a plan recognizer to reach the same conclusions with fewer observed actions. although we both treat past planning episodes as training data  we learn very different information: bauer learns statistical rules while we learn  for example  a good set of background goals. bauer's approach is restricted to recognizers that use probabilistic information while our algorithm is restricted to recognizers that produce a single goal  whether or not they use probabilistic information. additionally  we do not assume our recognizer will work well without adaptation. as shown in figure 1  when the frequency of spurious actions is 1  the unadapted recognizer correctly identifies only about 1% of the actor's goals and is wrong on about 1% of the goals. adapt improves the recognizer so that it correctly identifies 1% 
	lesh 	1 

of the goals and never makes a wrong prediction. 
　 mooney  1  employs explanation-based learning to add new plans to the plan library when a person is observed to execute a plan that is not in her known repertoire. they address the question of how to generalize the new plan so that structurally similar plans can be recognized in the future. one difference between this work and ours is that our adaptations can remove as well as add plans and goals from the plan library. 
　finally   caruana and freitag  1  examine several variations of hillclimbing to select which attributes a concept learner should use. attribute-selection is similar to predicate-selection  which we explore experimentally in section 1. they face different problems than we do in that they receive labeled training data while our algorithm performs unsupervised learning. furthermore  adding or removing goal predicates is just one of the adaptations that adapt considers. 
1 	future work and conclusions 
in future work  we will apply adapt to more types of adaptations and to other goal recognizers. we are interested in adapting a recognizer to better reflect characteristic mistakes that people make. for example  people sometimes have flawed domain operators. we could adapt for this by introducing a new adaptation that adds or removes a precondition or effect from the domain operators that boce forms plans from. we hypothesize that recognition will work best when boce builds plans based on what preconditions and effects the observed person believes actions have. another line of future work is to examine search strategies other than hillclimbing. 
　the primary contribution of this work is the adapt algorithm for adapting a goal recognizer to perform well on a sample of behavior. adapt is an unsupervisedlearning algorithm in that the sample data is not annotated with the person's actual goals. adapt is a recognizer-independent algorithm in that it can be applied to any goal recognizer for which there is an available set of adaptations. our experiments in two domains show that applying adapt to the boce recognizer can improve its performance by a factor of two to three. 
references 
 agre and horswill  1  p. agre and i. horswill. cultural support for improvisation. in proc. 1th nat. conf  on al  pp. 1  1. 
 ardissono and cohen  1  l. ardissono and r. cohen. on the value of user modeling for improving plan recognition. in proceedings of the workshop on the next generation of plan recognition systems: challenges for and insight from related areas of ai  pp. 1  august 1. 
 ardissono  1  liliana ardissono. dynamic user modeling and plan recognition in dialogue. phd thesis  department of information  university of torino  italy  1. 
 bauer  1  m. bauer. quantitative modeling of user preferences for plan recognition. in proceedings of the fourth international conference on user modeling  pp. 1  1. 
1 	planning and scheduling 
 bauer  1  m. bauer. acquisition of user preferences for plan recognition. in proceedings of the fifth international conference on user modeling  pp. 1  january 1. 
 carberry  1  s. carberry. incorporating default inferences into plan recognition. in proc. 1th nat. conf. on ai  vol. 1  pp. 1  july 1. 
 caruana and freitag  1  rich caruana and dayne freitag. greedy attribute selection. in proc. 1th int. conf. on machine learning  pp. 1  1. 
 chapman  1  d. chapman. planning for conjunctive goals. artificial intelligence  1 :1  1. 
 elzer et al  1  stephanie elzer  jennifer chu-carroll  and saundra carberry. recognizing and utilizing user p