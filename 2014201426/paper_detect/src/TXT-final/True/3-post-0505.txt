
supervised local tangent space alignment  sltsa  is an extension of local tangent space alignment  ltsa  to supervised feature extraction. two algorithmic improvements are made upon ltsa for classification. first a simple technique is proposed to map new data to the embedded low-dimensional space and make ltsa suitable in a changing  dynamic environment. then sltsa is introduced to deal with data sets containing multiple classes with class membership information.
1 introduction
in many pattern recognition problems  original data taken with various capturing devices are usually of high dimensionality. dimension reduction has emerged with an aim to obtain compact representations of the original data while reducing unimportant factors. it can make the resulting classification more efficient as fewer variables are being considered which reduces the complexity of the resulting classifier. ltsa proposed in  zhang and zha  1  is an unsupervised method for nonlinear dimension reduction. it does not make use of the class membership of each point to be projected and lacks generalization to new data. here we extend ltsa to a supervised version and make it suitable in a changing environment.
1 local tangent space alignment
ltsa maps a data set x =  x1 ... xn   xi （ rm globally to a data set y =  y1 ... yn   yi （ rd with d   m. the brief description of ltsa is presented as follows:
1. finding k nearest neighbors xij of xi  j = 1 ... k. set xi =  xij ... xik .
1. extracting local information by calculating the d largest eigenvectors g1 ... gd of the correlation matrix〔 xi   x．iet t xi   x．iet   and settingp gi =

 e/ k g1 ... gd . here x．i = k1 j xij  e is a kdimensional column vector of all ones.
1. constructing the alignment matrix b  please refer to  zhang and zha  1  for details  by locally summing with initial b = 1 as follows:

the neighborhood set ii represents the set of indices for the k nearest-neighbors of xi. i is an n 〜 n identity matrix.
1. computing the d+1 smallest eigenvectors of b and setting the global coordinates y =  u1 ... ud+1 t corresponding to the 1nd to d + 1st smallest eigenvalues.

figure 1:  a  and  b : mapping training samples with ltsa and sltsa respectively.  c  and  d : mapping unknown test samples to the spaces discovered by ltsa and sltsa.
1 supervised ltsa
our attempt is to adapt ltsa to a situation when the data come incrementally point by point. we assume that the dimensionality of the embedded space does not grow after projecting a new point to it  i.e.  d remains constant.
　the proposed technique is based on the fact that new points are assumed to come from those parts of the high-dimensional space that have already been explicitly mapped by ltsa. it implies that when a new point arrives  a task of interpolation should be solved. let x as an input. for a new point xn+1  its closest neighbor xj is looked for from x. if yj is the projection of xj to the embedded space  there must exist a point yn+1 around yj corresponding to xn+1.
　ltsa belongs to unsupervised methods; it does not make use of the class membership of each point. supervised ltsa  sltsa  is proposed for classification purposes. the term implies that membership information is employed to form the neighborhood of each point. that is  nearest neighbors of a given point xi are chosen only from representatives of the same class as that of xi. this can be achieved by artificially increasing the shift distances between samples belonging to different classes  but leaving them unchanged if samples are from the same class.
　in short  sltsa is designed specially for dealing with data sets containing multiple classes. the results obtained with the unsupervised and supervised ltsa are expected to be different as is shown in fig.1. the iris data set  blake and merz  1  includes 1-d data belonging to 1 different classes. here first 1 data points are selected as training samples and mapped from the 1-d input space to a 1-d feature space using ltsa  fig.1 b   and sltsa  fig.1 a    respectively. in fig.1 b   three class centers on the feature space are completely separated. however in fig.1 a  two classes  set 1 and 1  overlap such that their boundary cannot be accurately determined. fig.1 c; d  respectively show the mapping of unknown test samples to the two feature spaces discovered by ltsa and sltsa. in fig.1 d   test samples in different classes can be well distributed around class centers. thus the classification of test samples can be easily implemented on such space.
1 results
to examine its performance  sltsa has been applied to a number of data sets varying in number of samples  dimensions and classes.
　the binarydigits set discussed here consists of 1〜1pixel binary images of preprocessed handwritten digits. in our experiment only three digits: 1  1 and 1 are dealt with and some of the data are shown in fig.1 a . 1 of the 1 binary images are used as training samples and others as test samples. it is clear that the 1-dimensional binarydigits data contain many insignificant features  so removing them can make classification more efficient. the results after dimension reduction from 1 to 1 with ltsa and sltsa are respectively displayed in fig.1 b  and 1 c  where two coordinate axes represent the two most important features of the binarydigits data. the figures show that the feature space obtained with sltsa provides better classification information than ltsa. actually no cases of misclassification in the test samples occurred if using the sltsa method  but ltsa will result in the error rate of 1% in the best case.
　our experimental results confirm that sltsa generally leads to better classification performance than ltsa when combined with simple classifiers such as k-nn and lda. beside this  the performance of sltsa is comparable with supervised lle  kouropteva et al.  1  and finer than with pca  please refer to the supplementary document . maybe the reason is that those points on a high-dimensional input space are more likely to lie close on nonlinear rather than

figure 1: recognition of three digits: 1  1 and 1.  a  some of these three digits are shown. they are represented by 1〜1 binary images which can be considered as points on a 1dimensional space.  b  mapping these binary digits including training and test samples to a 1-dimensional feature space with ltsa  where these three clusters overlap and are unseparated.  c  the feature space obtained with sltsa  which provides better clustering information.
linear manifolds. thus  such linear methods as pca cannot perform well.
1 conclusions
the supervised version of ltsa was proposed here. it takes into account class membership during selecting neighbors. another enhancement to ltsa is to generalize it to new data and make it suitable in a changing  dynamic environment.
　we compare sltsa with ltsa  pca and supervised lle on a number of data sets  in order to gain insight into what methods are suitable for data classification. the sltsa method has been shown to yield very promising classification results in our experiments when combined with some simple classifiers.
