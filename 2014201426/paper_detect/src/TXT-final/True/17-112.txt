 
　　　in this paper  recent research results are presented which demonstrate the effectiveness of a rule learning system in two dynamic system control tasks. this system  called a learning classifier system  lcs   learns rules to control a simple lnertlal object and a simulated natural gas pipeline. 
　　　starting from a randomly generated state of mind  the learning classifier system learns string-rules called classifiers which match strings called messages. messages are sent by environmental sensors or by previously activated classifiers. each classifier's effectiveness is evaluated by an internal service economy complete with bidding and auction. furthermore  new rules are created by an innovative search mechanism called a genetic algorithm. genetic algorithms are search algorithms based on the mechanics of natural genetics. 
　　　results from computational experiments in both tasks are presented. in the inertial object task  the lcs learns an effective set of rules to center the object repeatedly. in the pipeline task  the lcs learns to control the pipeline under normal summer and winter conditions. it also learns to alarm correctly for the presence or absence of a leak. these results demonstrate the effectiveness of the learning classifier system approach and suggest further refinements 
which are currently under investigation. 
	i 	background 
　　　many industrial tasks and machines that once required human intervention have been a l l but completely automated. where once a person tooled a part  a machine tools  senses  and tools again. where once a person controlled a machine  a computer controls  senses  and continues i t s task. repetitive tasks requiring a high degree of precision have been most susceptible to these extreme forms of automated control. yet despite these successes  there are s t i l l many tasks and 
this paper describes work done at the university of michigan. it was partially supported by u. s. department of energy contract de-fg1er1  assistance from the mw goodrich fund  the h. w. king fund  the rackham school of graduate studies  and the u. m. office of energy research. 
mechanisms that require the attention of a human operator. piloting an airplane  controlling a pipeline  driving a car  and fixing a machine are just a few examples of ordinary tasks which have resisted a high degree of automation. what is it about these tasks that has prevented more autono-
mous  automated control  primarily  each of the example tasks requires  not just a single capabili t y   but a broad range of skills for successful performance. furthermore  each task requires performance under circumstances which have never been encountered before. for example  a pilot must take off  navigate  control speed and direction  operate auxiliary equipment  communicate with tower control  and land the aircraft. he may be required to do any or a l l of these tasks under extreme weather conditions or with equipment malfunctions which he has never faced before. clearly  the breadth and perpetual novelty of the piloting task  and similarly complex task environments  prevents the ordinary algorithmic solution used in more repetitive chores. in other words  d i f f i c u l t environments are d i f f i c u l t because not every possible outcome can be anticipated in advance  nor can every possible response be predefined. this truth places a premium on adaptation. 
　　　in this paper  we present research results from the application of a learning classifier system  lcs  to the control of two dynamic systems   an lnertlal object and a natural gas pipeline. a learning classifier system is a rule learning system which combines a computationally complete rule and message system  an apportionment of credit system based on a service economy analogue  and a genetic algorithm to form a system with sufficiently broad adaptability and efficiency to learn how to control each dynamic system starting from a random state of mind. 
　　　in the remainder of the paper we f i r s t examine the origins and structure of learning classifier systems. we examine its application to the control of an inertial object. finally  we observe i t s adaptation to normal summer and winter conditions  as well as abnormal leak events  in the control of a simulated natural gas pipeline. 
ii 	origins and structure of learning classifier systems 
　　　learning classifier systems are the latest outgrowth of holland's continuing work on adaptive systems. in 1  when holland outlined his 
theory of adaptive systems  he developed a general theory encompassing many adaptive systems  but ultimately he was addressing himself toward programmable machines that could reprogram themselves. 
　　　with this foundation more concrete suggestions emerged for classes of schemata processors  which in some limited respects resemble the present day lcs. this work has evolved into the intricately interesting  but as yet unimplemented broadcast language  a . the f i r s t practical implementation of a learning system based on these theories appeared in 1. holland and reitman  describe this f i r s t classifier system which learns a simple maze running task. though the task is simple  the achievement is remarkable because of its successful marriage of a rule-based knowledge system and a genetic algorithm for discovery of new rules. others have continued and extended this work in a variety of areas ranging from visual pattern recognition to draw poker 
 1 . 
　　　a learning classifier system  lcs  is an a r t i f i c i a l system that learns rules  called classifiers  to guide its interaction in an arbitrary environment. it consists of three main elements: 
1. rule and message system 
1. apportionment of credit system 
1. genetic algorithm 
　　　a schematic of an lcs is shown in figure 1. in this schematic  we see that the rule and message system receives environmental information through i t s sensors  called detectors  which decode to some standard message format. this environmental message is placed on a message l i s t along with a finite number of other internal messages generated from the previous cycle. messages on the message l i s t may activate classifiers  rules in the classifier store. if activated a classifier may then be chosen to send a message to the message l i s t for the next cycle. 
additionally  certain messages may call for 
environment 

figure 1. 	schematic - learning classifier system 
	d. goldberg 	1 
external action through a number of action triggers called effectors. in this way  the rule and message system combines both external and internal data to guide behavior and the state of mind in the next state cycle. 
　　　in an lcs  it is important to maintain simple syntax in the primary units of information  messages and classifiers. in the current study messages are 1-bit  binary  strings and classifiers are 1l-positlon strings over the alphabet {1 #}. in this alphabet the # is a wild card  matching a 1 or a 1 in a given message. thus  we maintain powerful pattern recognition capability with simple structures. 
　　　in traditional rule-based expert systems  the value or rating of a rule relative to other rules is fixed by the programmer in conjunction with the expert or group of experts being emulated. in a rule learning system  we don't have this luxury. the relative value of different rules is one of the key pieces of information which must be learned. to facilitate this type of learning  holland  has suggested that rules coexist in a competitive service economy. a competition is held among classifiers where the right to answer relevant messages goes to the highest bidders with this payment serving as s source of income to previously successful message senders. in this way  a chain of middlemen is formed from manufacturer  source message  to message consumer  environmental action and payoff . the competitive nature of the economy insures that the good rules survive and that bad rules die off. 
　　　in addition to rating existing rules  we must also have a way of searching for new  possibly better  rules. the primary mechanism for this type of creative learning within an lcs is the genetic algorithm. a genetic algorithm  ga  is a search algorithm based upon the mechanics of natural genetics. it combines a darwinian survival of the f i t t e s t among a population of a r t i f i c i a l chromosomes  string rules  and a structured  yet randomized  information exchange among randomly mated pairs of rules. ga simplicity of operation and power of effect have been demonstrated in function optimization  optimal control  as well as lcs domains. 
　　　taken together  the learning classifier system with i t s computationally complete and convenient rule and message system  an apportionment of credit system modeled after a competitive service economy  and the innovative search of a genetic algorithm  provides a unified framework for investigating the learning control of dynamic systems. in the remainder  we examine the application of the lcs to inertial object and gas pipeline control. 
	i l l 	inertial object control 
　　　we test the lcs and i t s ability to control an inertial object in the 1-d space depicted in figure 1. the object is frictionless and is governed by newton's second law. as shown  the 

1 	d. goldberg 
domain is bounded by inelastic walls  and the lcs receives perfect  yet crude and discrete  knowledge of the object's position  velocity  force  and reward in an eight b i t environmental message. the lcs has a simple behavioral repertoire: it can apply a force of given magnitude to the right or to the l e f t . 

	figure 1. 	inertial object domain - schematic 
　　　in these tests the lcs is rewarded if the action it has taken is consistent with the goal of centering the object  maximum point score = 1 . furthermore  a criterion count is incremented if the object is centered for 1 consecutive time steps. after this  the object is randomly disturbed by a large force to make the system try again. 
　　　starting from a randomly generated set of 1 rules we compare the performance of the lcs with genetic algorithm and without genetic algorithm to a random walk on the basis of time-averaged point count  totaleval/t  in figure 1. we note that both the lcs runs are much better than random performance. furthermore  case i1lcs.1  with ga  eventually overtakes and outperforms run i1lcs.1  without ga . in fact  while the differences appear small on this basis  the difference in physical control is much better in the case with genetic algorithm. 
　　　to see this we shift the basis of comparison to the more sensitive measure  time-averaged 
number of criterion achievements displayed as figure 1. again  lcs performance is far better than random. performance with the genetic algorithm is that much better than without. in fact  the run with genetic algorithm has found restoration and braking rules similar to those that might be programmed by a knowledgeable control engineer. the run without genetic algorithm has ineffective braking rules thereby limiting i t s capability* 
	iv 	gas pipeline control 
　　　a pipeline model  load schedule  and upset conditions are programmed and interfaced to the lcs. we briefly discuss this environmental model and present results of normal operations and upset tests. 
　　　a model of a pipeline has been developed which accounts for linepack accumulation and 

figure 1. 	time-averaged totaleval vs. time random rule set - runs i1lcs.1 and i1lcs.1 

figure 1. 	time-averaged goal count vs. time random rule set - runs i1lcs.1 and i1lcs.1 
frlctlonal resistance. user demand varies on a dally basis and depends upon the weather. different patterns may be used for winter and summer operation. in addition to normal summer and winter conditions  the pipeline may be subjected to a leak upset. during any given time step  a leak may occur with a specified leak probability. if a leak occurs  the leak flow  a specified value  is extracted from the upstream junction and persists for a specified number of time steps. 
　　　the lcs receives a message about the pipeline condition every time step. a template for that message is shown in figure 1. the system has complete  albeit imperfect and discrete  knowledge of i t s state including inflow  outflow  inlet pressure  outlet pressure  pressure rate change  season  time of day  time of year  and current temperature reading. 
　　　in the pipeline task  the lcs has a larger range of alternatives for actions it may take compared with the inertial object task. it may send out a flow rate chosen from one of four 


figure 1. pipeline lcs environmental message template 
values and it may send a message indicating whether a leak is suspected or not. 
　　　the lcs receives reward from i t s trainer depending upon the quality of i t s action in relation to the current state of the pipeline. to make the trainer ever-vigilant  a computer subroutine has been written which administers the reward consistently. this is not a necessary step  and reward can come from a human trainer. 
     under normal operating conditions we examine the performance of the learning classifier system 
with and without the genetic algorithm enabled. without the genetic algorithm  the system is forced to make do with its original set of rules. the results of a normal operating test are presented in figure 1. both runs with the lcs outperform a random walk  through the operating alternatives  . furthermore  the run with genetic algorithm enabled is superior to the run without ga. in this figure  we show time-averaged total evaluation versus time of simulation  maximum reward per tlmestep - 1 . 

	figure 1. 	time-averaged totaleval vs. time 
normal operations - runs p1lcs.1 
& p1lcs.1 
　　　more dramatic performance differences are noted when ve have the possibility of leaks on the 
	d. goldberg 	1 
system. figure 1 shows the time-averaged total evaluation versus time for several runs with leak upsets. once again the lcs is initialized with random rules and permitted to learn from external reward. both lcs runs outperform the random walk and the run with ga clearly beats the run with no new rule learning. to understand this  ve take a look at some auxiliary performance measures. in figure 1 ve see the percentage of leaks alarmed correctly versus time. strangely  the run without ga alarms a higher percentage of leaks than the run vlth ga. this may seem counterintuitive u n t i l 
ve examine the false alarm statistics in figure 1. the run without ga is only able to alarm a high percentage of leaks correctly because it has so many false alarms. the run with ga decreases its false alarm percentage  while increasing i t s leaks correct percentage. 

	figure 1. 	percentage of leaks correct vs. time 
runs polcs.1 & polcs.1 
	v 	conclusions 
　　　in this paper  we have applied a learning classifier system to the control of two different dynamic systems  an inertlal object and a natural gas pipeline. 
　　　in the tvo applications the lcs learns effective rules in normal and abnormal operating 

1 	d. goldberg 

figure 1  percentage of false alarms vs. time runs polcs.1 & polcs.1 
conditions alike. in the inertial object task  the lcs learns to center the object consistently. in the pipeline task  the lcs learns to operate the pipeline under normal summer and winter conditions. it also learns to alarm correctly with increasing accuracy for the presence or absence of a leak. 
　　　while the applications of the lcs in this paper have been necessarily specific  this work's implications for other research in a r t i f i c i a l intelligence are more far-reaching. the use of ruthlessly spartan syntax and simple  yet powerful learning heuristics drawn from nature may else-
where prove promising in our quest for programs which effectively reprogram themselves with better instructions. 
