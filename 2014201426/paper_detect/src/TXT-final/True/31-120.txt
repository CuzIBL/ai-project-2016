 
this paper investigates the problem of automatically learning declarative models of information sources available on the internet. we report on ila  a domain-independent program that learns the meaning of external information by explaining it in terms of internal categories. in our experiments  ila starts with knowledge of local faculty members  and is able to learn models of the internet service whois and of the personnel directories available at berkeley  brown  caltech  cornell  rice  rutgers  and uc1  averaging fewer than 1 queries per information source. ila's hypothesis language is compositions of first-order predicates  and its bias is compactly encoded as a determination. we analyze ila's sample complexity both within the valiant model  and using a probabilistic model specifically tailored to ila. 
1 	introduction and motivation 
the number and diversity of information sources on the 
internet is increasing rapidly. a number of tools such as gopher  wais  and web crawlers are available to help people search for the information they need. however  these tools are unable to interpret the results of their searches and are unable to use multiple information sources in concert. a number of more sophisticated ai systems have emerged  including sims  knoblock ei a/.  1   the information manifold at at&t  kirk ei a/.  1   and the internet softbot  etzioni and weld  1 . however  each of these ai systems requires sophisticated models of the different information sources it is able to access. as a result  there are two barriers that prevent ai approaches from keeping up with the 
   *we thank dayne freitag  craig knoblock  and tom mitchell for inspiring discussions that contributed to our problem formulation. we thank dymitr mozdyniewicz for his assistance with experiments  and anchana kullavanijaya for her transcription help. this research was funded in part by office of naval research grant 1-j-1 and by national science foundation grant iri-1. mike perkowitz is supported  in part  by an nsf graduate fellowship. 
1 	knowledge representation 
explosion of information sources on the internet. first  effort has to be devoted to hand coding a model of each source. second  sources unknown to the programmers associated with each ai system cannot be modeled. to enable the ai approaches to scale with the growth of the internet  we explore the problem of automatically learning models of information sources. this learning problem raises four fundamental questions: 
  discovery: how does the learner find new and unknown information sources   e.g.  a web page representing the brown phone directory has recently come 
on-line.  
  protocol: what are the mechanics of accessing an information source and parsing the response into tokens   the brown directory is searched by sending a string such as  kaelbling  to the brown server  and receiving back a string.  
  semantics: how does the learner come to understand the information available at the source   the tokens describe kaelbling's e-mail address  phone number  department  etc.  
  quality: what is the accuracy  reliability  and scope of the information source   the directory contains accurate information about people at brown  not elsewhere.  
　satisfactory answers to all of these questions would enable us to construct an autonomous internet learning agent able to discover and use information resources effectively. as a first step  this paper investigates the question of learning semantics. 
　our learning method is based on the following idea  due to st. augustine  wittgenstein  1 . consider how you might learn the latin term uxor by example. suppose i tell you  george washington's uxor was martha.  you might reason that  because  martha  was the name of washington's wife  perhaps  uxor  means  wife . if  however  you knew that washington also had a sister named  martha   you might wait until you saw another example  perhaps asking  who was jefferson's uxor   this method of learning relies on three key assumptions. 
first  you are familiar with george washington. second  you have a concept corresponding to uxor  e.g. wife. third  you are willing to establish a general correspondence between your concept wife and the concept uxor based on the example given. as we show below  this leap of faith can be viewed as an inductive bias and formalized as a determination. we refer to this determination 


	perkowitz and etzioni 	1 

hypotheses for the second field because etzioni's userid is his last name. to discriminate between the two hypotheses  ila will attempt to query with someone whose userid is different from her last name. if no discriminating query is possible  ila will attempt to find an objectthat has the potential to disconfirm the leading hypothesis. in the above example  if ila hypothesizes that the third field is phone-number  it will choose a person whose phone number is known over a person whose phone number is not. finally  if neither a discriminating nor a disconfirming query is possible  ila will query with an object about which it has much information  in order to increase the likelihood of recognizing some token in the response. discriminating queries typically accelerate ila's ability to converge on a satisfactory hypothesis; in the case of s t a f f dir  for example  when ila does not make use of discriminating queries  it requires 1% more queries to converge on the same hypotheses. 
   once a particular object is chosen  ila has to decide which query string to actually send to the is. initially  ila will try all known facts about the object as possible query strings  attempting to learn the appropriate query string for the is. the learning mechanism used is  in essence  the same as the one described below for learning to interpret the is's output. 
　once ila obtains a response from the external is  it attempts to explain each token in the response. an explanation is a chain of one or more model attributes composed into a relation between the object and the token seen. for example  in ila's model  people are associated with departments and departments associated with mailstops. the relation between a person and her mail-stop  then  is a composition of department and mail-stop - the mail-stop of p is mail-stop department p  . 
	we 	employ 	a 	variant 	of 	relational 	pathfinding 
 richards and mooney  1  to discover a relation between the query object and each response token. richards and mooney's pathfinding technique performs 
1 	knowledge representation 
a bidirectional breadth-first search in which constants are nodes in the graph and attributes on constants are edges between nodes. we use & fuzzy matcher to compare tokens from the is to constants in ila's model. our current matching function ignores punctuation and spacing and can allow substring matches  e.g.  the learner can recognize   1  1  and  1  as being the same token . consequently  our pathfinding is unidirectional  proceeding from the query object to fuzzilymatched tokens.1 
　suppose the agent starts with the model shown in table 1. it queries the is with the last name of object pi and gets the response oren etzioni 1 fr1. it will now try to explain each response token in turn. for example  in order to explain  fr-1   ila will start with pi and spread out one step through the model  e.g.  to cs and etzioni. since neither matches the target token  fr-1   ila will continue spreading out from the current frontier  retaining the path to each current node  e.g.  the attribute path from pi to cs is department x  . from cs  ila will get to fr-1. thus  the path to fr-1 is mail-stop department x  . since fr-1 matches the target  this path will be returned as an explanation. 
next  ila evaluates the hypothesized explanation. 
with respect to a particular query  a hypothesis may be explanatory  it predicted the output actually seen   inconsistent  it predicted something else   or consistent  it made no prediction . thus  a hypothesis h partitions the set of responses to queries into explanatory  inconsistent  and consistent subsets. we denote the number of elements in each subset by the ordered triple  e h   1 h   c h  . we refer to the triple as the score of the hypothesis h. since a hypothesis is only generated when it successfully explains some response  we know 
     1to perform bidirectional pathfinding  we would have to find the set of matching tokens in ila'b model  an expensive computation due to the size of the model. 

that  for any h  e h    1. 
　the predictions of a new hypothesis are compared against old responses to compute the hypothesis's score. overall  ila compares each hypothesis against each response exactly once  so learning time is linear in both the number of responses and the number of hypotheses. to determine whether one hypothesis is better than another  ila compares the number of inconsistent predictions by the two hypotheses. if the number of inconsistent predictions is equal  ila compares the number of explanatory predictions. more formally  we say that the hypothesis h is better than the hypothesis h' if and only if: 
better h h'  =  / h    i h'   v  1 h  = i h'  a e h    e h'   
that is  ila chooses the hypothesis with the lowest / score and uses e scores to break ties. this is a good policy when incomplete information is more common than incorrect information because the / score  how often the hypothesis was inconsistent  is a better indicator of the accuracy of the hypothesis. an inconsistency arises either when the hypothesis is inaccurate or when the information is incorrect. because incorrect information is rare in our domain  a bad  high  / score indicates an inaccurate hypothesis. a hypothesis may fail to explain an observation due to incomplete information  because if we lack the relevant fact  the hypothesis makes no prediction. since incomplete information is relatively common  a bad  low  e score does not necessarily indicate low accuracy of the hypothesis. therefore  1 h  is a better indicator of the quality of h than e h . suppose ila knows everybody's last name but only a few people's userid. when trying to learn the userid field  the userid hypothesis will explain only a few observations  because it will make very few predictions  but will never be inconsistent. in contrast  lastname will explain many observations but will be inconsistent on others. because ila prefers low 1 scores  it makes the right choice. 
   ila terminates the learning process when one of two conditions occur. one  it has run out of objects with which to query the is. two  its leading hypothesis is  significantly  better than its other hypotheses. the difference in i scores that is deemed significant is controlled by a parameter to ila. although ila's running time is exponential in the depth of the relational pathfinding search for an explanatory hypothesis  the maximal search depth is typically set to a small constant  keeping ila fast. as mentioned earlier  the running time is linear in the number of queries made and the number of explanatory hypotheses generated. in fact  as the experiments in table 1 show  ila's running time is dominated by internet transmission time. 
1 	experimental results 
in this section  we report on preliminary experiments designed to test whether our approach is viable in a realworld domain. we find that ila is able to learn models of simple information sources on the internet. 
　to factor out the issues of protocol  which we do not address in this paper   ila is provided with an interface that standardizes the interaction with the information sources used. each interface takes query strings as input and outputs a list of tokens which ila attempts to understand. in our first experiment  ila is provided with complete and correct models of faculty in the university of washington's  uw  computer science department  and is asked to learn a model of staffdir  the uw personnel directory. the first line of table 1 shows the results of this experiment. we see that in 1 queries ila was able to learn a correct model of staifdir. ila spent 1 seconds interacting with staifdir and 1 cpu seconds searching for  and evaluating  hypotheses. 
　below  we show the final scores of the leading hypotheses for interpreting the second field of staff dir's output: 
staffdir 1  x  = lastname x  expl: 1 incons: 1 staffdir 1  x  = userid x  expl: 1 incons: 1 
　we see that for eight people  both the lastname and userid hypotheses correctly explained the second field in the output of s t a f f d i r . however  for three people  the userid hypothesis failed  leading ila to consider lastname to be the correct hypothesis. 
　a general problem that arises in relying on token correspondence to infer type correspondence is the occurrence of puns. a pun occurs when matching tokens are not actually instances of the same concept. a hypothesis arising from a pun amounts to finding an incorrect composition of model attributes - one that is not true for all x and y. a pun is an instance of the general problem of an incorrect hypothesis resulting in a correct classification of a training example. one type of pun is entirely coincidental; a person's area code turns out to be the same as his office number. a spurious hypothesis resulting from a coincidental pun is easy to reject - it is unlikely to prove explanatory for more than a single example. however  we also encounter semi-regular puns where there is a correlation between the two concepts which gives rise to the pun. as pointed out above  many people's userids are also their last names. semi-regular puns may require many more queries to converge on the correct hypothesis  because both the correct and spurious hypotheses will make accurate predictions in many cases. discriminating queries aim to address this problem by finding examples where the correct and spurious hypotheses make different predictions. 
　no matter how regular a pun  there must eventually be a difference between the correct hypothesis and the competitor.1 how hard it is to choose the best hypothesis is a function of the learner's knowledge and the regularity of the pun. the system faces a tradeoff: it must balance time spent learning against confidence in the result. if ila collects more examples  it can be more confident in the correctness of its conclusions. the learner can never be fully certain it is not the victim of a particularly regular pun  but it will have some estimate of the likelihood that it has the right solution. we provide a quantitative analysis of this intuition in the next section. one possible criticism of ila is that it relies on an 
　　1  if there is no difference in extension between the two hypotheses  then they are equally good solutions to the learning problem. 
	perkowitz and etzioni 	1 

overlap between the individuals in its model and individuals in the is it is trying to learn. however  ila benefits from the presence of spanning information sources on the internet. a spanning information source is one that contains objects from a wide variety of information sources. for example  the internet service called whois reports information on individuals from a wide range of sites on the internet and will  for example  return people from a particular school when queried with that school's name. ila relies on its knowledge of local individuals to learn a model of whois  and then leverages its model of whois to learn models of a wide variety of remote sites on the internet. instead of relying on individuals from its model  ila will query whois for new individuals at the target site. for example  when trying to learn the brown directory  ila will query whois with  brown  to get information about people at brown and use its learned model of whois to interpret the output. our second experiment demonstrates this process  table 1 . the second line of the table shows the results of learning whois from knowledge of local people. given the learned model of whois  we report on ila's performance in learning models of the personnel directories available at berkeley  brown  cal-tech  cornell  rice  rutgers  and uci. as the results in table 1 demonstrate  ila is able to learn fairly accurate models of these information sources averaging fewer than 1 queries per source  most taking less than 1 minutes each  where the bulk of that time is spent in internet communication. the processing time for ila is less than three cpu minutes in most cases. slow network connections contributed to the unusually large internet times for whois and cornell. the size of the cornell directory and the generality of its matching contributed to the large processing time for that directory. 
1 	theoretical analysis 
we would like to understand how the accuracy of  and confidence in  ila's hypotheses scale with the number of queries it makes  the size of its hypothesis space  the correctness of its information  and so on. we consider both valiant's pac model and an alternative probabilis-
1 	knowledge representation 
tic model of ila. ila is not a standard concept-learning program - ila is learning a function from the query it issues to the response of the is. furthermore  the oracle used by ila is a generalized membership oracle. however  learnability results in function learning theory are specific to classes of functions learned  such as polynomial  or real-valued  auer et a/.  1 . similarly  although specific concept classes have been shown to be learnable under the membership oracle  angluin  1   we are not aware of any sample complexity results that apply directly to ila. for this reason  we chose to make a number of strong simplifying assumptions and analyze ila under the pac model. 
　the pac model provides a convenient framework for analyzing ila's behavior  under the simplifying assumption that queries to the is are random. ih| is the size of the hypothesis space explored by ila. we posit a probability distribution p over queries to the information source 1. the error e of a hypothesis h is the probabilistic weight of the queries on which the hypothesis h disagrees with the actual behavior of i: 

 tor simplicity  we consider an is with a single output field  where i o  is the token returned by the is  and h o  is the value predicted by h. haussler  haussler  1  derives a lower bound on the number of examples necessary for pac learning. if h is any hypothesis that agrees with at least n queries from /  where   then we have the following: 
　to apply this bound to ila  we have to assume that the information in / and in ila's model is error free  that a perfect model of / can be found in ila's hypothesis space  and that token matching is working perfectly. we can model the violation of these assumptions as random classification noise and use the bound due to  angluin and laird  1 :   where nb is an upper bound on the frequency of noisy classifications  and the learner chooses the hypothesis that is correct 

1
    in our model  if the two hypotheses have equal scores  they have equal probability of being chosen. 
1
 we assume independence between the errors of g and 1. 
also  under the worst-case assumption that n - 1 hypotheses all have accuracy at   a similar formula can be derived for a hypothesis space of size n  etzioni and perkowitz  1 . 
	perkowitz and etzioni 	1 

   as 1 shrinks  ila requires more queries to achieve high confidence. note though that when 1 is very small  discriminating between g and b is less important. furthermore  discriminating queries enable ila to converge on the high-accuracy hypothesis quickly even for small 1. to demonstrate the advantage of discriminating queries over random queries  figure 1 b  shows the number of random and discriminating queries necessary to achieve at least 1% confidence that the learner will prefer hypothesis g over hypothesis 1  again as a function of 1. the accuracy of g is fixed at 1. the randomqueries curve is derived from equation 1. due to lack of space  we omit the derivation and assumptions underlying the discriminating-queries curve  but see  etzioni and perkowitz  1 . when ag = 1 and 1 = 1  ila requires only a single discriminating query to have 1% confidence that it has found the better hypothesis. in essence  it is so unlikely for g to be wrong and for 1 to be right on the same query that one query is sufficient for ila to choose a hypothesis with high confidence. 
　in short  if there is a large gap between the best hypothesis and its closest competitor  or we are able to perform discriminating queries  our probabilistic model shows that relatively few queries are necessary to have high confidence in choosing the best hypothesis. the model helps to explain how  using a small number of queries  ila was able to learn accurate models of information sources in the experiments summarized in table 
1. 
1 	critique and future work 
our contributions include: formulating the category translation problem  developing ila's algorithm  and formalizing its bias as a determination. we have tested ila experimentally on a simple internet domain  and analyzed its sample complexity within the pac framework and using a specialized probabilistic model. 
　we have identified several problems that ila does not yet address. category mismatch occurs when ila fails to find categories corresponding to those of the external information source  wiederhold  1 . for example  the is records fax numbers  of which ila is ignorant. token mismatch occurs when  despite having appropriate categories  ila fails to find matching tokens due to a difference in representation. for example  ila may record prices in dollars  but a japanese information source may store prices in yen. finally  ila's conjunctive bias can prevent it from learning a category that corresponds to a disjunction of ila's categories. in future work we expect to test ila on substantially more complex internet domains  explore solutions to the above problems  and investigate the discovery and quality problems mentioned in the introduction. 
