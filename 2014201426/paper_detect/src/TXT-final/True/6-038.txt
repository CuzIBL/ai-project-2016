 
to model combinatorial decision problems involving uncertainty and probability  we extend the stochastic constraint programming framework proposed in iwalsh  1  along a number of important dimensions  e.g. to multiple chance constraints and to a range of new objectives . we also provide a new  but equivalent  semantics based on scenarios. using this semantics  we can compile stochastic constraint programs down into conventional  nonstochastic  constraint programs. this allows us to exploit the full power of existing constraint solvers. we have implemented this framework for decision making under uncertainty in stochastic opl  a language which is based on the opl constraint modelling language  hentenryck et a/.  1 . to illustrate the potential of this framework  we model a wide range of problems in areas as diverse as finance  agriculture and production. 
1 	introduction 
many decision problems contain uncertainty. data about events in the past may not be known exactly due to errors in measuring or difficulties in sampling  whilst data about events in the future may simply not be known with certainty. for example  when scheduling power stations  we need to cope with uncertainty in future energy demands. as a second example  nurse rostering in an accident and emergency department requires us to anticipate variability in workload. as a final example  when constructing a balanced bond portfolio  we must deal with uncertainty in the future price of bonds. to deal with such situations   walsh  1 has proposed an extension of constraint programming  called stochastic constraint 
programming  in which we distinguish between decision variables  which we are free to set  and stochastic  or observed  variables  which follow some probability distribution. this framework combines together some of the best features of traditional constraint satisfaction  stochastic integer programming  and stochastic satisfiability. 
　in this paper  we extend the expressivity of this framework considerably by adding multiple chance constraints  as well as a range of objective functions like maximizing the downside. we show how such stochastic constraint programs can 
constraints 
toby walsh 
cork constraint computation centre university college cork  ireland. email: tw 1c.ucc.ie. 
be compiled down into conventional  non-stochastic  constraint programs using a scenario-based interpretation. this compilation allows us to use existing constraint solvers without any modification  as well as call upon the power of hybrid solvers which combine constraint solving and integer programming techniques. we also propose a number of techniques to reduce the number of scenarios and to generate robust solutions. we have implemented this framework for decision making under uncertainty in a language called stochastic opl. this is an extension of the opl constraint modelling language ihentenryck et al  1 . finally  we describe a wide range of problems that we have modelled in stochastic opl that illustrate some of its potential. 
1 	stochastic constraint programs 
in a one stage stochastic constraint satisfaction problem 
 stochastic csp   the decision variables are set before the stochastic variables. the stochastic variables  independent of the decision variables  take values with probabilities given by a probability distribution. this models situations where we act now and observe later. for example  we have to decide now which nurses to have on duty and will only later discover the actual workload. we can easily invert the instantiation order if the application demands  with the stochastic variables set before the decision variables. constraints are defined  as in traditional constraint satisfaction  by relations of allowed tuples of values. constraints can  however  be implemented with specialized and efficient algorithms for consistency checking. 
　we allow for both hard constraints which are always satisfied and  chance constraints  which may only be satisfied in some of the possible worlds. each chance constraint has a threshold  1 and the constraint must be satisfied in at least a 
　fraction 1 of the worlds. a one stage stochastic csp is satisfiable iff there exists values for the decision variables so that  given random values for the stochastic variables  the hard constraints are always satisfied and the chance constraints are satisfied in at least the given fraction of worlds. note that iwalsh  1  only allowed for one  global  chance constraint so the definition here of stochastic constraint programming is strictly more general. 

1 

so that given random values for vsl  we can find values for vd1  so that given random values for vs1  the hard constraints are always satisfied and the chance constraints are again satisfied in at least the given fraction of worlds. note that the values chosen for the second set of decision variables vd1 are conditioned on both the values chosen for the first set of decision variables vd1 and on the random values given to the first set of stochastic variables vs1 this can model situations in which items are produced and can be consumed or put in stock for later consumption. future production then depends both on previous production  earlier decision variables  and on previous demand  earlier stochastic variables . 
　an m stage stochastic csp is defined in an analogous way to one and two stage stochastic csps. note that  walsh  1  insisted that the stochastic variables take values independently of each other. this prevents us representing a number of common situations. for example  if the market goes down in the first quarter  it is probably more likely to go down in the second quarter. a second stage stochastic variable representing the market index is therefore dependent on the first stage stochastic variable representing the maiket index. there is  however  nothing in the semantics given for stochastic constraint programs nor in the solution methods proposed in  walsh  1  that used this assumption. we therefore allow later stage stochastic variables to take values which are conditioned by the earlier stage stochastic variables. 
　a stochastic constraint optimization problem  stochastic cop  is a stochastic csp plus a cost function defined over the decision and stochastic variables. in  walsh  1   the only goal considered was to find a solution that satisfies the stochastic csp which minimizes or maximizes the expected value of the objective function. we now extend this to a much wider range of goals. for example  we might wish to limit the downside  i.e. maximize the least value of the cost function   or to minimize the spread  i.e. minimize the difference between the least and the largest value of the cost function . 
1 	scenario-based semantics 
in  walsh  1   a semantics for stochastic constraint programs is given based on policies. a policy is a tree of decisions. each path in a policy represents a different possible scenario  set of values for the stochastic variables   and the values assigned to decision variables in this scenario. to find satisfying policies   walsh  1  presents backtracking and forward checking algorithms which explores the implicit and/or graph. stochastic variables give and nodes as we must find a policy that satisfies all their values  whilst decision variables give or nodes as we only need find one satisfying value. 
　an alternative semantics  which suggests an alternative solution method  comes from a scenario-based view  birge and louveaux  1 . a scenario is any possible set of values for the stochastic variables. thus  a scenario is associated with each path in the policy. within each scenario  we have a conventional  non-stochastic  constraint program to solve. we simply replace the stochastic variables by the values taken in the scenario  and ensure that the values found for the decision variables are consistent across scenarios. note that certain decision variables are shared across scenarios. the first stage decisions are  for example  shared by all scenarios. the great advantage of this approach is that we can use conventional constraint solvers to solve stochastic constraint programs. we do not need to implement specialized solvers. of course  there is a price to pay as the number of scenarios grows exponentially with the number of stages. however  
our results show that a scenario-based approach is feasible for many problems. indeed  we observe much better performance using this approach on the production planning example introduced in  walsh  1 . in addition  as we discuss later  we have developed a number of techniques like latin hypercube sampling to reduce the number of scenarios considered. 
1 	stochastic opl 
we have implemented this framework on top of the opl constraint modelling language  hentenryck et al  1 . an opl model consists of two parts: a set of declarations  followed by an instruction. declarations define the data types   input  data and the  decision  variables. an opl instruction is either to satisfy a set of constraints or to maximize/minimize an objective function subject to a set of constraints. we have extended the declarations to include the declaration of stochastic variables  and the instructions to include chance constraints  and a range of new goals like maximizing the expectation of an objective function. 
1 	variable declaration 
we now declare both decision and stochastic variables. stochastic variables are set according to a probability distribution using a command of the form: 
stoch  type   id   dist ; 
where  type  is  as with decision variables  a data type 
 e.g. a range of values  or an enumerated list of values    id  is  as with decision variables  the variable name  and  dist  defines the probability distribution of the stochastic variable s . probability distributions include uniform  poisson  lambda   and user defined via a list of  not necessarily normalized  values. other types of distribution can be supported as needed. we insist that stochastic variables are arrays  with the last index describing the stage. here are some examples: 
stoch 1 . . 1 market years  u n i f o r m ; stoch 1..1 demand quarter  { 1   1   1 } ; 
in the first  we have a 1 variable in each year which takes either value with equal probability. in the last  we have a demand variable for each quarter  which takes the value 1 in 1 out of 1 cases  1 in 1 out 1 cases  and 1 in the remaining 1 cases. 
1 constraint posting 
we can post both hard constraints  as in opl  and chance constraints. chance constraints hold in some but not necessarily all scenarios. they are posted using a command of the form: 
prob  constraint   	 arithop   expr ; 
where 	 constraint  	is 	any 	opl 	constraint  
 arithop  is any of the arithmetically comparison operations  =          =  or  =  and  expr  is any arithmetic expression  it may contain decision variables or may 
just be a rational or a float in the range 1 to 1 . for example  the following command specifies the chance constraint that in each quarter the demand  a stochastic variable  does not exceed the production  a decision variable  plus the stock carried forward in each quarter  this auxiliary is modelled  as in conventional constraint programming  by a decision variable  with 1% probability: f o r a l l   i in 1..n  
prob demand i     = production i +stock i   
 = 1; 
constraints which are not chance constraints are hard and have to hold in all possible scenarios. for example  the stock carried forwards is computed via the hard constraint: f o r a l l   i i n 1..n  
stock i+1  = stock i  + production i  
- demand i ; 
1 	optimization 
stochastic opl supports both stochastic constraint satisfaction and optimization problems. we can maximize or minimize the expectation of an objective function. for example  in the book production example of  walsh  1   we can minimize the expected cost of storing surplus books. each book costs $1 per quarter to store. this can be specified by the following  partial  model: 
minimize expected cost  subject to 
cost = 
	sum i in l..n  	max stock i+1  1 ; 
	f o r a l l   i 	in 1..n  
stock i+1  = stock i  + production i  - demand i ; 
stochastic opl also supports a number of other optimization goals. for example: 
minimize spread profit  maximize downside profit  minimize upside cost  
the spread is the difference between the value of the objective function in the best and worst scenarios  whilst the downside  upside  is the minimum  maximum  objective function value a possible scenario may take. 
1 	compilation of stochastic opl 
these stochastic extensions are compiled down into conventional  non-stochastic  opl models automatically by exploiting the scenario-based semantics. the compiler is written in lex and yacc  with a graphical interface in visual c++. compilation involves replacing stochastic variables by their possible values  and decision variables by a ragged array of decision variables  one for each possible scenario. consider again the chance constraint: 
prob  
demand i   = production i +stock i    
 = 1; 
this is compiled into a sum constraint of the form: sum j 	i n scenarios  	p   j   * 
 demand i j   = p r o d u c t i o n   i   j   + s t o c k   i   j    
 = 1; 
where scenarios is the set of scenarios  p   j   is the probability of scenario j  demand   i   j   is the demand in scenario j and quarter i  etc. note that the bracketing of the inequality reifies the constraint so that it takes the value 1 if satisfied and 1 otherwise. 
　hard constraints are also transformed. consider  for example  the hard constraint: 
wealth t  = bonds t  + stocks  t  ; 
this is compiled into a forall constraint of the form: f o r a l l   j in scenarios  
wealth t j  = bonds t j  + stocks t j  
where wealth   t   j  is the wealth at time t in scenario j  etc. maximization and minimization instructions are also transformed. consider  for example  the optimization instruction: 
maximize expected wealth n   subject to . . . 
this is compiled into an instruction of the form: maximize sum j in scenarios  p   j   * w e a l t h   n   t   
subject 	t o 	. . . 
the rest of the stochastic opl model is transformed in a similar manner. 
1 	value of information and stochastic solutions 
for stochastic optimization problems  we compute two statistics which quantify the importance of randomness. the value of a stochastic solution  vss  is the difference in the objective function for the stochastic problem  call it the stochastic solution  ss  and the objective value for the deterministic problem computed by replacing stochastic variables by their expectations  call it the expected value solution  evs : vss = ss - evs. this computes the benefit of know-
ing the distributions of the stochastic variables. clearly  vss is non-negative. we also compute the expected value of the wait-and-see solution  wss . to calculate this  we give the stochastic variables values according to their probability distributions  and then find the best values for the decision variables. the difference between wss and ss is the expected value of perfect information  evpi : evpi = wss - ss. this measures how much more you can expect to win if you have perfect information about the stochastic components of the problem. in other words  evpi measures the value of knowing the future with certainty. this is therefore the most that should be spent in gathering information about the uncertain world. 

constraints 	1 


finally  we implemented a scenario reduction method used in stochastic programming due to dupacova  growe-kuska and romisch  dupacova et al  1 . they report power production planning problems on which this method offers 1% accuracy sampling 1% of the scenarios and 1% accuracy sampling just 1% of the scenarios. the method heuristically deletes scenarios to approximate as closely as possible the original scenarios according to a fortet-mourier metric on the stochastic parameter space. 
1 	some examples 
to illustrate the potential of this framework for decision making under uncertainty  we now describe a wide range of problems that we have modelled. in the first problem  we compare a scenario-based approach to the previous tree search methods for solving stochastic constraint satisfaction problems. in the next three problems  we illustrate the effectiveness of the different scenario reduction techniques. 
1 	production planning 
this problem comes from  walsh  1. the results in table 1 show that a scenario-based approach offers much better performance on this problem than the forward checking or backtracking tree search algorithms also introduced in this paper. the problem involves planning production over m quarters. in each quarter  we expect to sell between 1 and 1 copies of a book. to keep customers happy  we want to satisfy demand over all m quarters with 1% probability. this problem is modelled by an m stage stochastic csp there are m decision variables  xi representing production in each quarter. there are also m stochastic variables  y1 representing demand in each quarter. to limit stock carried forward  we use a simple heuristic which picks the smallest possible values for the decision variables. an alternative is to convert the problem into an optimization problem with a cost to keep books in store. we do not explore this option here  though it is very easy to implement in stochastic opl  as we cannot then compare our results with those of the forward checking or backtracking algorithms from  walsh  1 . 
1 portfolio management 
this portfolio management problem of  birge and louveaux  
1  can be modelled as a stochastic cop. suppose we have $p to invest in any of / investments and wc wish to exceed a wealth of $g after t investment periods. to calculate the utility  we suppose that exceeding $g is equivalent to an income of q% of the excess while not meeting the goal is equivalent to borrowing at a cost r% of the amount short. this defines a concave utility function for r   q. the uncertainty in this problem is the rate of return  which is a random variable  on each investment in each period. the objective is to determine the optimal investment strategy  which maximizes the investor's expected utility. 
　the problem has 1 stages and 1 scenarios. to compare the effectiveness of the different scenario reduction algorithms  we adopt a two step procedure. in the first step  the scenario reduced problem is solved and the first period's decision is observed. we then solve the full-size  non scenario reduced  problem to optimality with this first decision fixed. the difference between the objective values of these two solutions is normalized by the range  optimal solution  observed worst solution  to give a normalized error for committing to the scenario reduced first decision. in fig. 1  we see that dupacova et al's algorithm is very effective  that latin hypercube sampling is a small distance behind  and both are far ahead of the most likely scenario method  which requires approximately half the scenarios before the first decision is made correctly . 
1 	yield management 
farmers must deal with uncertainty since weather and many other factors affect crop yields. in this example  also taken from  birge and louveaux  1    we must decide on how many acres of his fields to devote to various crops before the planting season. a certain amount of each crop is required for cattle feed  which can be purchased from a wholesaler if not raised on the farm. any crop in excess of cattle feed can be sold up to the eu quota; any amount in excess of this quota 

inspired by robust optimization methods in operations re-

will be sold at a low price. crop yields are uncertain  depending upon weather conditions during the growing season. this problem has 1 stages and 1 scenarios. in fig. 1  we again see that dupacova et al's algorithm and latin hypercube sampling are very effective  and both are far ahead of the most likely scenario method  which requires approximately one third the scenarios before the first decision is made correctly . 
1 production/inventory control 
uncertainty plays a major role in production and inventory planning. in this simplified production/inventory planning example  there is a single product  a single stocking point  search  kouvelis and yu  1   stochastic opl also allows us to find robust solutions to stochastic constraint programs. that is  solutions in which similar decisions are made in the different scenarios. it will often be impossible or undesirable for all decision variables to be robust. we therefore identify those decision variables whose values we wish to be identical across scenarios using commands of the form: robust  var ; 
　for example  in production/inventory problem of sec.1 the decision variables  order-up-to-ievels  and  replenishment periods  can be declared as robust variables. the values of these two sets of decision variables are then fixed at the beginning of the planning horizon. a robust solution dampens the nervousness of the solution  an area of very active re-

constraints 	1 

search in production/inventory management. as the expected cost of the robust solution is always higher  the tradeoff between nervousness and cost may have to be taken into account. 
1 related and future work 
stochastic constraint programs are closely related to markov decision problems  mdps   puterman  1j. stochastic constraint programs can  however  model problems which lack the markov property that the next state and reward depend only on the previous state and action taken. the current decision in a stochastic constraint program will often depend on all earlier decisions. to model this as an mdp  we would need an exponential number of states. another significant difference is that stochastic constraint programs by using a scenario-based interpretation can immediately call upon complex and powerful constraint propagation techniques. 
　stochastic constraint programming was inspired by both stochastic integer programming and stochastic satisfiability  littman et al  1. it is designed to take advantage of some of the best features of each framework. for example  we are able to write expressive models using non-linear and global constraints  and to exploit efficient constraint propagation algorithms. in operations research  scenarios are used in stochastic programming. indeed  the scenario reduction techniques of dupacova  growe-kuska and romisch  dupacova et al.  1  implemented here are borrowed directly from stochastic programming. 
　there are a number of extensions of conventional constraint satisfaction problem to model constraints that are uncertain  probabilistic or not necessarily satisfied. for example  in probabilistic constraint satisfaction each constraint has a certain probability independent of all other probabilities of being part of the problem  fargier and lang  1  whilst in semi-ring constraint satisfaction each tuple in a constraint has a value associated with it  bistarelli et al  1 . however  none of these extensions deal with variables that may have uncertain or probabilistic values. stochastic constraint programming could  however  easily be combined with most of these techniques. 
1 conclusions 
to model combinatorial decision problems involving uncertainty and probability  we have extended the stochastic constraint programming framework proposed in  walsh  1j along a number of important dimensions. in particular  we have relaxed the assumption that stochastic variables are independent  and added multiple chance constraints as well as a range of objective functions like maximizing the downside. we have also provided a new  but equivalent  semantics for stochastic constraint programs based on scenarios. based on this semantics  we can compile stochastic constraint programs down into conventional  non-stochastic  constraint programs. the advantage of this compilation is that we can use the full power of existing constraint solvers without any modification. we have also proposed a number of techniques to reduce the number of scenarios  and to generate robust solutions. 
　we have implemented this framework for decision making under uncertainty in a language called stochastic opl. this is an extension of the opl constraint modelling language  hentenryck et al.  1 . to illustrate the potential of this framework  we have modelled a wide range of problems in areas as diverse as finance  agriculture and production. there are many directions for future work. for example  we want to allow the user to define a limited set of scenarios that are representative of the whole. as a second example  we want to explore more sophisticated notions of solution robustness  e.g. limiting the range of values used by a decision variable . 
acknowledgements 
this project was funded by epsrc under gr/r1  and the science foundation ireland. we thank the members of the apes research group and 1c lab for their feedback. 
