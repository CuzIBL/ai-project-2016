 
the problem of driving an autonomous vehicle in normal traffic engages many areas of ai research and has substantial economic significance. we describe work in progress on a new approach to this problem that uses a decision-theoretic architecture using dynamic probabilistic networks. the architecture provides a sound solution to the problems of sensor noise  sensor failure  and uncertainty about the behavior of other vehicles and about the effects of one's own actions. we report on advances in the theory of inference and decision making in dynamic  partially observable domains. our approach has been implemented in a simulation system  and the autonomous vehicle successfully negotiates a variety of difficult situations. 
1 	the bat project 
several government agencies and corporations in europe  
japan  and the us are currently undertaking research in ivhs  intelligent vehicle and highway systems  with the aim of substantially reducing congestion and accidents  which cost $1 billion/year and 1 lives/year  respectively. in the near future  several research projects expect to demonstrate prototype systems for automated highways in which vehicles travel in segregated lanes under centralized control using inter-vehicle negotiation and only minimal sensing. for example  path  partners for advanced transit and highways   an agency of the state of california  has designed a  platooning  scheme in which large groups of automated vehicles travel together with minute inter-vehicle spacing  thereby quadrupling highway capacity. this scheme forms the basis for a nationwide consortium funded by the us government. 
　the bat  bayesian automated taxi  project  although funded by path  takes an entirely different approach. the aim is to introduce autonomous vehicles into normal highway traffic. on the one hand  this approach: 
  eliminates the need for extensive highway rebuilding. 
  allows a gradual  evolutionary shift to fully automated highways. 
  eliminates the risk of widespread system failure. 
  improves integration with urban surface streets. 

on the other hand  whereas driving in a restricted  instrumented lane is primarily a problem in control theory  driving in normal traffic on an uninstrumented highway is more difficult and engages many areas of ai research. this is either a disadvantage or an advantage  depending on one's viewpoint. because the necessary low-level 
capabilities such as visual vehicle monitoring  huang et al  1  and lane-following  dickmanns and zapp  1; pomerleau  1j are reaching maturity  we have decided to confront this challenge. 
　the first phase of the project is a feasibility study to establish the computational and sensing requirements for driving and to investigate the nature of the necessary decision algorithms. we use a 1-d physical simulation that generates moderately realistic 1-d rendered video output  smartpath   which is passed to the bat  see figure 1 . using this information  the bat must understand the current traffic situation  select high-level actions such as braking  accelerating  and lane changing  and implement those actions using low-level control. 
　the ai problems involved in driving are legion: the bat must make decisions in real-time; its sensors are noisy- position errors are significant  and some vehicles may not be detected  especially at night or in poor weather conditions; sensor inputs must be integrated  and some sensors may fail altogether; the world is only partially observable-vehicles may be occluded  and other drivers' intentions are invisible; and the bat has only a stochastic model of the results of its own actions. finally  successful deployment requires a critical error rate below i in 1 seconds  i .e.  it must perform at least as well as a good driver. these considerations mean that the bat must  at least at  compile time   weigh up quantitative risks and benefits. the only  safe  policy is to stay in one's garage. 
　although there are dozens of projects worldwide with similar goals  descriptions of which can be found in the proceedings of many ivhs conferences  almost none have started from the premise that sensors and actuators are noisy and error-prone-a fact that has resulted in several deaths during testing of  advanced intelligent cruise control   aicc  systems. one exception is the work of niehaus and stengel  niehaus and stengel  1  who have recently incorporated a somewhat ad hoc form of probabilistic reasoning into their rule-based driving controller. since their system assumes worst-case outcomes in looking ahead  and does not integrate percepts over time in assessing the current state  its performance is limited. 
　the bat decision making architecture is multi-level  with a high level component in charge of overall trip planning and parameters such as desired cruising speed  which it passes down to a driving module in charge of the concrete task of driving the vehicle in traffic in real-time. this paper focuses on the latter task. the driving problem can be modelled formally as a pomdp  partially observable markov decision process . in a pomdp  the optimal decision is a function of the current belief state-the joint distribution over all possible actual states of the world.1 the problem can be divided into two parts: updating the current belief state  and making a decision based on that belief state. we begin this paper by showing how we use dynamic probabilistic networks to represent and update the belief state  and introduce temporally invariant networks and stochastic sampling as efficient methods for updating in real-time. we then describe three methods for making decisions: lookahead planning  explicit policy representations  and machine learning. finally  we illustrate the effectiveness of an implemented bat controller in a variety of scenarios designed to test the bat's ability to make fast  effective decisions in difficult situations. 
1 	maintaining the current belief state 
in order to make appropriate control decisions  an agent must have accurate information about its own stale and the state of its environment. for example  the bat must know its own position  velocity  and intentions  and it must monitor those of its neighboring vehicles. it must also monitor road and weather conditions  since they may significantly affect the bat's ability to drive. 
　the state of the bat's environment is only partially observable. sensor information for variables such as vehicle positions and velocities may be incomplete and noisy  while driver intentions and road conditions may not be directly measurable at all. thus  the bat cannot make decisions based 
   'because the belief state should reflect the integration of percepts over time in order to assess such unobservables as driver intentions  approaches such as pomerleau's alvinn that are based on feedforward neural networks cannot solve the full driving problem. 
merely upon the latest sensor readings. rather  it must maintain estimates for the random variables that together represent the state of the world  and it must make its decisions based upon the joint probability distribution over all those variables. in the rest of this section  we outline our approach to maintaining the current belief state. 
1 	dynamic probabilistic networks 
to maintain the bat's current belief slate  we employ dynamic probabilistic networks  dpns . probabilistic networks arc directed acyclic graphs in which nodes represent random variables  typically discrete  and arcs represent causal connections among the variables  pearl  1. associated with each node is a cpt  conditional probability table  that provides conditional probabilities of the node's possible states given each possible slate of its parents  or the prior probabilities if the node has no parents . probabilistic networks offer a mathematically sound basis for making inferences under uncertainty. the conditional probability tables provide a natural way to represent uncertain events  and the semantics of the updated probabilities are well-defined. knowledge of causal relationships among variables is expressed by the presence or absence of arcs between them. furthermore  the conditional independence relationships implied by the topology of the network allow the joint probability distribution of all the variables in the network to be specified with exponentially fewer probability values than in the full joint distribution. when specific values are observed for some of the nodes in a probabilistic network  posterior probability distributions can be computed efficiently for any of the other nodes using a variety of inference algorithms  pearl  1 . the extension to continuous variables is straightforward  and stochastic sampling provides a simple way to perform inference with such variables. 
　dpns allow for reasoning in domains where variables take on different values over time  dean and kanazawa  1. figure 1 shows the general structure of a dpn. typically  observations are taken at regular 'time slices ' and a given network structure is replicated for each slice. dpns model their domains as partially observable markov processes  so nodes can be connected not only to other nodes within the same time slice but also  and only  to nodes in the immediately preceding or immediately following slice. the markov property states that: 
p statet+1   statet  state -i statet-1  ＊ ＊ ＊  = p{state +  state   
　in other words  the future is independent of the past given the present. as long as the bat's representation of the world conforms to this property  the bat need not maintain the history of its percepts to predict the next state since the accumulated effect of its observations is captured in its current belief state. 
　the crts for the set of arcs proceeding from one time slice to the next form the bat's state evolution model. this model quantifies how the bat believes the actual state of the system will evolve over time. the cpts for the set of arcs proceeding into nodes whose values are typically observed at each time slice form the bat's sensor model. this model quantifies the likelihood of making a set of observations of the world given the actual state of the world. 
　since a given variable may be measured by more than one sensor  the bat must be able to integrate multiple sensor 
forbes  etal 

state evolution model 

figure 1: the structure of a dynamic probabilistic network. the ovals denote sets of state nodes or sensor nodes. the arcs going from one slice to the next form the state evolution model  and the arcs going into the sensor nodes form the sensor model. the shaded ovals denote observations available when predicting the state at time / + !. 
readings in computing its estimate of the variable's value. because sensors are usually conditionally independent of each other given the variable that they measure  bayesian updating within a probabilistic network easily fuses the readings from several sensors  automatically returning an updated posterior probability distribution for the value of the measured variable. 
1 	efficient updating 
as an agent goes about the world  performing actions  gaining sensor readings and going forward in time  it must efficiently update its model of the world. with dpns  the agent must go through a constant process of incorporating percepts  adding new time slices at the  leading edge  of the network  and discarding old time slices at the  trailing edge  to avoid a blow-up in the dpn structure. 
   because of the markov property  time slices corresponding to the past can be removed as new slices are added to the network. before a past slice is removed  its influence must be absorbed into the remaining part of the network by revising probability tables for nodes in the slice immediately following the slice to be removed. by rolling up the network in this fashion  evidence accumulated over time is always integrated into the current probabilistic network model. in general  the model for the current time slice along with the current percepts completely determines the current belief state. 
　clearly  real-time temporal inference requires efficient rollup. any exact method for rolling up one slice of a network is equivalent to performing a sequence of node eliminations  kjaerulff  1 . node elimination may introduce additional links into the network; thus the network structure may change as a result of rollup. this complicates maintaining the belief state in three ways. first  different node elimination sequences can result in drastically different connectivity in the resulting networks. connectivity in turn affects the time needed for inference using a network. second  modification of the network structure may force some inference algorithms  such as those based on junction trees  to perform expensive computations to modify or completely recreate internal data structures. third  modification requires more complex and computation-intensive code to manipulate the network. 
   to address these issues  we have developed two methods for efficient rollup: temporally invariant networks and stochastic simulation. we first introduce the temporally invariant network  and then briefly describe our approach to stochas-

temporally invariant networks 
a temporally invariant network is a dpn for which there exists a node elimination sequence which induces the same structure as the original network. figure 1 a  shows a temporally invariant network. although we do not have the space for a full exposition of the node elimination operations involved  it is easy to see that in this network  all information about a time slice is conveyed to a single node  the lop node  in the next slice. thus  intuitively  rollup should affect only this top node and not affect the other parts of the network. 
　by contrast  figure 1 b  shows a temporally variant network. in this network  information about each slice is conveyed to the next slice through two nodes. effectively  this means that those two nodes become dependent on each other  since knowing something about one of them implies something about the past  which in turn implies something about the other. thus  after rollup  the new leading edge slice contains an arc joining the two nodes. 
　a temporally invariant network has obvious advantages for real-time temporal inference. since the rollup operations are known in advance  there is no need to perform a potentially expensive run-time search for an elimination order. this can be done offline  as can open-coding of the cpt computations performed in the rollup. 
　one thing to notice is that in figure 1 b   we could have added the arc introduced by rollup to every slice from the beginning. then the resulting network would have been temporally invariant. thus  we can take a temporally variant network and convert it into a temporally invariant one. there is a cost associated with this conversion. while the example only involves the addition of one arc  this arc also makes every slice completely connected. in fact  it is easy to show that a network with completely connected nodes in each slice is always temporally invariant. however  a network with completely connected subcomponents may be very expensive to represent and to compute with  and it lacks many of the advantages of using probabilistic networks in the first place. 
　for a given temporally variant network  finding an optimal conversion that adds a minimal cost set of edges to create a temporally invariant network is likely to be an expensive operation. nevertheless  by precompiling it into a temporally invariant network  and by devoting significant resources to finding a good node elimination sequence  we may ease the run-time computation requirements of the network. 
stochastic simulation in dpns 
in much of our past work  we have taken advantage of a commercial implementation of the exact clique tree algorithm  the hugin system . in our applications  we have found that the clique tree algorithm is too expensive and that exact probabilities are not needed. furthermore  dpns seldom conform to the structural requirements required for the clique tree to handle continuous variables. we have therefore investigated the use of stochastic simulation algorithms  which often provide fast approximations to the required probabilities and can be used with arbitrary combinations of discrete and continuous distributions. even more importantly  the use of stochastic simulation makes unnecessary the expensive cpt manipulations involved in exact rollup. 
　in the context of dpns  stochastic simulation methods attempt to approximate the current belief state using a collection of samples representing  simulated realities   each describing one possible evolution of the environment. because the samples are a complete representation of our estimate of thr  joint distribution  there is no need to recompute cpts. the sample population and associated weighting factors integrate and reflect all available evidence  and they are all we need to form the estimate of any marginal or joint probability in a dpn. 
　the simplest simulation algorithm is logic sampling  henrion  1 . logic sampling stochastically instantiates the network  beginning with the root nodes and using the appropriate conditional distributions to extend the instantiation through the network. because logic sampling discards trials whenever a variable instantiation conflicts with observed evidence  it is ineffective for dpn-based monitoring where evidence is observed throughout the temporal sequence. 
　likelihood weighting lshachter and peot  1  attempts to overcome the general problem with logic sampling. rather than discarding trials that conflict with evidence  each trial is weighted by the probability it assigns to the observed evidence. probabilities on variables of interest can then be calculated by taking a weighted average of the values generated in the population of trials. it can be shown that likelihood weighting produces an unbiased estimate of the required probabilities. 
　the use of likelihood weighting in dpns reveals some problems that require special treatment. the difficulty is that a straightforward application generates simulations that simply ignore the observed evidence and therefore become increasingly irrelevant. consider a simple example: tracking a moving dot on a 1-d surface. suppose that the state evolution model is fairly weak-for example  it models the motion as a random walk-but that the sensor is fairly accurate with a very small gaussian error. figure 1 illustrates the difficulty. the samples are evolved according to the state evolution model  spreading out randomly over the surface  whereas the object moves along some particular trajectory that is unrelated to the sample distribution. the weighting process will assign extremely low weights to almost all of the samples because they disagree with the sensor observations. the estimated distribution will be dominated by a very small number of samples that are closest to the true state  so the effective number of samples diminishes rapidly over time. this results in large estimation errors. all this occurs despite the fact that the sensors can track the object with almost no error  in the case of traffic monitoring  we have discovered that a naive application of likelihood weighting results in a sample population of more or less imaginary traffic scenes that bear no relation to what is actually happening on the road. 

figure 1: a simple 1-d monitoring problem. an object starts in the centre of the disc and follows the path shown by the solid line. sensor observations are shown by crosses. the small circles show a snapshot of the population of samples generated by a naive application of likelihood weighting. snapshots for / = 1 and t = 1 are shown. 
　we have developed two methods that use the current sensor values to reposition the sample population closer to reality rather than allowing it to evolve as if no sensor values were available. the problems with likelihood weighting typically arise in situations  such as often happens with dpns  where nodes representing observed evidence have parents. evidence reversal is a method that restructures each time slice of a dpn so that evidence nodes have no unobserved parents. this method ensures that the sample population remains close to reality when extending it using the current evidence. survival of the fittest sampling is a method that uses the likelihood weights to preferentially propagate the most likely samples. this is related to genetic algorithms  except that there is no crossover . our experimental results confirm that our methods perform better than likelihood weighting in dpn-monitoring applications. the best results are obtained by combining both methods ikanazawa et al.y 1 . 
1 	network structure 
as implemented  the bat monitors each vehicle tracked by the sensor system with a separate dpn. each network contains nodes for sensor observations  such as vehicle position and velocity  as well as nodes for predicting driver intentions  such as whether the driver intends to make a lane change or to slow down. 
　like a kalman filter  each network computes probability distributions for a vehicle's position and velocity based on both its latest observations and its previous state estimate  which reflects the influence of all previously observed evidence . unlike a kalman filter  which is limited to gaussian distributions  the network predictions can be arbitrarily distributed. for example  if a vehicle were approaching some debris directly in front of it  the network could predict that the vehicle would move either to the right or to the left  but not straight  in order to avoid the debris. also  the network could easily incorporate additional sensor information. if the sensor system recognized that a vehicle was flashing its right turn signal  the network could make predictions that biased the vehicle's position towards the right. 
　an alternate  perhaps preferable  approach to vehicle monitoring would utilize one large scene network for all relevant ve-


figure 1: dynamic probabilistic network for one vehicle  including inter-slice arcs. the smaller nodes with thicker outlines denote sensor observations. 
hides. because this greatly increases the computational complexity of inference operations and requires run-time modifications to the network structure  we chose to use separate networks for each vehicle. to incorporate the influence of nearby vehicles  each network contains nodes corresponding to those vehicles. for example  the front clear and front speed diff nodes in figure 1 refer to  the space between this vehicle and the vehicle in front   and  the speed difference between this vehicle and the vehicle in front   respectively. since the vehicle in front of or behind a given vehicle may change  these indexical nodes do not correspond to a specific vehicle. instead  a preprocessing step using sensor data determines the spatial relationships among the vehicles and then sets the node states accordingly. figure 1 shows an example vehicle network for one time slice  along with the inter-slice links to the next time slice. 
1 	sensor models and sensor failure 
since adverse weather  road conditions  and extended use may cause the bat's sensor systems to degrade or fail  it must be able to dynamically estimate the reliability and accuracy of its sensors. by quantifying a sensor's expected performance under various operating conditions  we have been able to 
construct belief networks for sensor validation. 
   figure 1 shows an example of a network for monitoring the state of a single sensor  such as a video camera  based on observations for two cars. the sensor status node at each time slice specifies whether the sensor is performing well  performing at a degraded level  or completely inoperative. the cpt for each observation node specifies a distribution for the observation of a variable given its actual value and given the operating mode of the sensor. as the variation between predicted values and observed values increases  the sensor 
1 	reasoning under uncertainty 

figure 1: an example sensor validation network. sensor readings are entered at observation nodes  the smaller nodes with thicker outlines. the sensor status node can take on one of several different values to indicate whether the sensor is broken or is operating in some degraded mode. increased variance between predicted values and observed values may increase the belief that the sensoris performing less reliably  perhaps due to adverse weather conditions. 
validation network will correspondingly change its estimate of the sensor's reliability and accuracy  perhaps attributing it to adverse weather conditions. very high variance between observed and predicted values or no observed values at all may increase the belief that the sensor has failed completely. finally  the link going from the sensor status node in one slice to its instantiation in the next slice allows quantification of the persistence of the various sensor operating modes. 
1 	decision making in the bat 
in this section  we describe our approach to real-time bat decision making. as we noted earlier  the decision problem corresponds to a pomdp. computing the policy for pomdps is pspace-complete  and exact solutions can be obtained only for tiny state spaces. our approach to real-time bat decision making is to find approximate solutions. we are undertaking three separate approaches. they are  1  bounded lookahead using dynamic decision networks  which incorporate action nodes and an explicit utility function;  1  hand-coded  explicit policy representations  such as decision trees  that take as input the joint probability distribution encoded in the dpn; and  1  supervised learning and reinforcement learning methods for solving the pomdp  in which we learn a policy representation  a utility function on belief states  or an action-value function on belief-state/action pairs. 
1 	dynamic decision networks 
decision networks  or influence diagrams  extend probabilistic networks by including distinguished node types for actions and utility functions. they are solved to obtain optimal decisions by maximizing the utility function over the possible instantiations of the action nodes  given the available evidence. dynamic decision networks  ddns  resemble dpns  but have 

an action node for each time slice. if the utility function is time-separable  that is  the utility of a sequence of states can be computed by combining separate rewards for each state in the sequence   then the ddn can include a reward node with each slice. for example  the reward function might include positive components for progress made towards the destination and negative components for jerky motions  illegal actions  crashes  etc. a ddn can represent a finite-horizon decision problem by projecting forward the appropriate number of time steps  or can approximate an infinite-horizon problem  such as driving  by projecting up to an artificial horizon and then using an approximate utility function on the final state to estimate the expected reward for the rest of time. in this respect  ddns are similar to algorithms used in game-playing. in figure 1  we show a generic ddn with a three-step horizon. 
the sensor model in a ddn is similar to that in a dpn; the state evolution model  on the other hand  now includes the action node as a parent  and therefore represents the effects of the agent's actions. note also that we do not show the  informational links  that are used in influence diagrams to show the evidence available to the agent when each decision is made. instead  we enforce the convention that a decision at time t is made with all evidence gained up to and including time t  and we identify a particular set of the chance nodes as evidence nodes that will be instantiated at each time step. 

　tatman and shachter  tatman and shachter  1  provide an algorithm for computing the policy for a ddn. in the case of driving  which is a partially observable problem  only a subset of the variables in a given time slice will be instantiated as evidence. this means that as well as maximizing over action sequences  the algorithm must average over all possible percept sequences as well. although this enables generation of intelligent policies such as  moving over a bit to look around the car in front   it is expensive. it is possible to avoid generating an explicit representation of the policy  which resembles an enormous  conditional plan    but the time complexity still makes the process infeasible for a real-time agent using current hardware. using metalevel control and adjusting the horizon can mitigate this to some extent  and some success has been achieved in simple environments. currently  however  we envisage using ddn lookahead mainly for offline generation of optimal actions in large sets of training examples. the belief-state/action pairs can then be generalized using inductive methods to provide an efficiently executable policy representation. 
1 	decision tree policy representation 
our second approach combines the dpn state evolution model with a decision tree. the decision tree is a tree of binary ifthen-else constructs where the test predicates are computed from the joint distribution computed by the dpn. each leaf of the tree is a decision. this obviously yields an effective  real-time policy  but constructing the decision tree is a difficult task. other researchers  for example lehner and sadigh  lehner and sadigh  1   have examined the creation of decision trees from influence diagrams  but only for static problems. in such cases  the decision tree nodes test fully determined evidence variables. if this method is applied to dynamic problems  one may be forced to test the entire percept sequence. 
　our approach involves testing the current belief state instead. although this is potentially much smaller  optimality in a pomdp requires that the tests define regions in the joint probability space rather than regions in the marginal probability space for each variable. we have found this extremely unintuitive  and so have used tests on marginals of individual variables as an approximation. to date  this has been reasonably effective. we have implemented several handconstructed decision trees  which have the following general structure  each  predicate  here is actually a complex set of probability thresholds on specific variables  and each  action  a subsidiary decision tree ; 

1 	pomdp policy learning 
the last approach to decision making takes advantage of an observation we made earlier  namely  that the pomdp policy is a function from the current belief state to the optimal action  and that the current belief state is encoded in the dpn. in the preceding section  we proposed decision trees over the dpn distribution as one possible function to approximate the pomdp policy. here  we briefly describe how to learn the optimal value function for each action directly. 
　assume that the world is represented as a temporally invariant dpn. in the dpn  the belief state is determined by the cpts  evidence values  and topology of the current slice. however  since the topology and some of the cpts arc fixed due to temporal invariance  we need pay attention only to the time-varying cpts and the evidence when learning the actionvalue function. the time-varying cpt entries are identified during the compilation of the temporally invariant network. in this way  we can project down the complete joint probability space onto a much smaller subspace in which to learn the 

action-value function. since the decision problem is markov in this subspace  we can use standard reinforcement learning techniques such as q-1 earning to learn a generalized actionvalue representation. the details of this technique are described in a forthcoming paper. 
1 	scenarios and results 
in this section  we describe the result of testing the decisiontree-based bat controller on several sample traffic scenarios. we have built a working simulator to test various decision making modules for the bat. for each test  the simulator reads a scenario description file  which describes the volume of traffic and the behaviors of other vehicles traveling along the highway. at each simulator  clock tick   the simulator determines the trajectories of all the vehicles until the next tick; it passes current state information in the form of sensor readings  adding noise as necessary using sensor models  to each vehicle's controller  which in turn outputs its decision for the current time step. the simulator uses the vehicle's decision and a physical model to plot trajectories and to detect collisions and other significant events. 
   we have predefined a set of controllers for vehicles other than the bat  called  drones   that engage in a variety of behaviors simulating good drivers  antisocial  incompetent  and unsafe drivers  stalled vehicles  and so on. these controllers are configurable in terms of when and how often they undertake such behaviors  their speed  and so on; furthermore  the system is easily extensible to add more types of driving behavior. 
   in the results described here  the system is limited to having only one bat at a time. this is due largely to the current inference architecture  which uses the hugin belief network system. although our networks are not very large  the total number of nodes is on the order of 1   they are highly connected  which slows down the hugin system. a newer  implemented system uses stochastic simulation which is considerably faster for our problem  and we plan to have multiple bats driving at the same time. 
　the goal of the bat controller is to maintain a target speed in a target lane. when other vehicles interfere  the controller makes appropriate acceleration/deceleration and lanechanging maneuvers. we show five such situations: passing a slow-moving vehicle  figure 1   reacting to unsafe drivers  figure 1   avoiding a stalled car  figure 1   aborting a lane change maneuver  figure 1   and merging into another lane  figure 1 . we show the situations as discrete sequences of 1-d pictures  although of course they are actually continuous 1-d video sequences. in the figures  the bat is the shaded vehicle. 
1 	summary and future work 
we have described the overall structure and early theoretical and practical results of a long-term project on intelligent vehicles. in a short paper we cannot do full justice to either type of result  but we hope to have given something of the flavour of the ai problems involved and their solutions. specific contributions include the following: 
1 	reasoning under uncertainty 

figure 1: passing a slower car: this scenario demonstrates the 
bats ability to pass slow cars. as the bat approaches a slower vehicle  it decides to pass to the left so that it can maintain its target speed. because of another vehicle in that lane  the bat first maintains a safe following distance behind the slower car until the left lane is clear and then performs a left lane change maneuver and accelerates back to its target speed. 

figure 1: reacting to unsafe drivers: this scenario shows the bats ability to deal with aggressive and unsafe drivers. a car cuts in front of the bat and proceeds to slow down. when the probability of the other car making a lane change passes a threshold  the bat initiates a defensive lane change even before the other car is fully in the bat's lane. the bat first slows down to avoid the car and then accelerates back to its target speed. 
  the use of dynamic probabilistic networks  dpns  to solve the problems of noise and partial observability that arise in driving. 
  the decomposition of the overall dpn into separate ve-hicle networks linked by indexical variables in order to improve performance. 
  automatic diagnosis and accommodation of sensor degradation and failure. 
  the use of temporally invariant networks and stochastic simulation to achieve real-time updating. 
* the use of decision trees based on current belief state  and their successful application in a variety of difficult driving scenarios. 
clearly  much remains to be done. we are currently investigating the application of new learning algorithms to construct dpns automatically from time series data  russell et al.  1 . combined with our computer vision subsystem  this will allow the construction of human driver models from videotapes. in our network representation  we are working to incorporate continuous variables  thereby avoiding the combinatorial explosion caused by discretization. one topic requiring significant empirical research is the design of appropriate utility functions. even if the assumptions of time-separability 


figure 1: avoiding a stalled car: this scenario demonstrates the bat's ability to avoid a stalled car. the bat detects a stalled car in front based on the difference in their forward velocities. the bat realizes that the car is stalled  rather than stuck in traffic  because there are no cars in front of it. however  the lane to the left of the bat is not clear  so the bat slows down. once it determines that the left lane is clear  it initiates a lane change and begins accelerating up to its target speed. 

figure 1: aborting a lane change; this scenario describes an aborted lane change. initially  the bat is changing lanes to the left lane  but at the same time a car two lanes over tries to change lanes to the right. when the bat detects this by thresholding the probability that the other car is changing lanes  it decides to abort its own lane change by slowing down and going back to its original lane. 
and additivity are appropriate  we still need to assess relative weights of the various components. such research can of course be done independently of any specific design for a vehicle controller and will be of use in all such projects. finally  one of the most important topics in intelligent vehicle design is the question of validation-demonstrating that the vehicle will be sufficiently safe for deployment in the real world. as well as improving and assessing the verisimilitude of our simulation  we need to gather a vast library of real-world video footage to test the bat's response to real situations-
