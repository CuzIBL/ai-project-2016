 
this paper describes a mechanism for nonmonotonic temporal reasoning involving counterfactuals and disjunctions. the mechanism supports a method for exploring alternatives well suited to automatic planning. the application of these techniques to robot problem solving is discussed with an emphasis on reasoning about exclusive choices and monitoring the continued warrant and effectiveness of prevention tasks. 
i. introduction 
   a critical part of planning involves selecting a plan for achieving a particular task. a reduction type planner  e.g. noah    faced with the problem of formulating a plan for the conjunction of two or more nonprimitive tasks  is often forced to make plan selection decisions on the basis of incomplete knowledge. the planner cannot anticipate interactions with tasks whose reduction  or detailed specification  it has yet to explore. given that there exists no strong warrant for choosing one plan over another why should a planner make a choice at all  in certain situations it would seem that procrastination is appropriate. 
   the problem here is similar to one addressed by sacerdoti in developing the noah planner. noah employed a strategy known as least commitment and a data structure known as a procedural net to avoid making ordering decisions until they were warranted by interactions discovered in the course of planning. this was a reaction to previous planners' use of what is called the linear assumption: the tasks in a conjunction of tasks to be solved are assumed to be independent and hence there is no harm in committing to some arbitrary order for the purposes of planning. the problem was that by committing early  and arbitrarily  the planner might have to explore a large number of alternative orderings before finding one that worked. most planners    have made a similar assumption as regards plan selection; namely that in the absence of information to the contrary any plan for achieving a task will suffice. 
   in order to deal with the problems that arise as a result of making this assumption a number of strategies have been proposed. noah represented alternative plans for achieving a given task as a disjunction  implicitly exclusive  of plans. the planner expanded the current procedural net with each disjunct noting the type and number of interactions: this information served as the basis for choosing among the alternatives. a more general technique employing a context mechanism was proposed by wilkins . the problem with both of these approaches is that the planner is responsible for proposing descriptions of the world which follow from making certain decisions  choosing among alternatives . if a planner wanted to make sure it hadn't missed some fortuitous combination of choices it would have to construct and evaluate all such worlds  combinations of choices . the planner had no way of anticipating good and bad interactions without exploring the alternatives. what was really needed was an efficient method of discovering sets of choices to avoid  those that lead to problems  and sets of choices to consider seriously  those that consolidate effort . 
   if you are entertaining a number of apparently independent alternatives it seems reasonable that you are able to notice interactions  both advantageous and detrimental  involving sets of these alternatives. suppose that i have a task of mailing a package and i'm considering either driving to the local ups depot or using the regular mail service and walking to the post office. if i've recently thought about buying some stamps then i might want to take advantage of the opportunity of being at a location selling stamps afforded by the latter. of course some consolidations are not possible. a planner must have some means of ignoring deductions based on effects achieved by exclusive alternatives. if you are planning a weekend trip but undecided on whether to spend it in a rural or an urban setting it would be a bit silly to formulate a plan which closely couples a relaxing walk in the countryside with a broadway show. 
   in addition to reasoning about alternatives and aspects of the world that the planner has control over  a planner quite often finds itself in the position of reasoning about ways the world might have been had events turned out otherwise  counterfactuals . to reason about methods for preventing some predicted unpleasantness we have to be careful to distinguish the circumstances that prompted us to action from those brought about by our attempts to avoid the predicted events. i might plan to deposit a sum of money in my checking account to avoid the penalty from an overdraft. having determined to do so it is not likely i will be fined but this shouldn't somehow lessen my re-
   
solve to actually carry out the actions required to make the deposit. silly as this may sound  it requires some sophistication to avoid just such confusions. 
   this initial discussion was meant to outline some problems which have not been handled adequately by previous planning systems. the examples were meant to illustrate a class of situations which require reasoning about alternative  possibly exclusive  descriptions of the world. in the remainder of this paper i will describe a temporal reasoning module designed as part of a planning system which supports this sort of hypothetical reasoning. this short paper cannot hope to satisfy the curiosity of all and i encourage the interested reader to refer to  for a more complete exposition. 
ii. planning and temporal reasoning 
   this section outlines the module used for temporal reasoning in the forbin planner . this module is referred to as a time map manager  tmm   and is loosely based on the representation described in . a time map is a data structure which captures what is known about events occurring over time  e.g. their duration and relative ordering  and the effects of processes and actions  e.g. the persistence or the period of time over which such effects can be said to endure . the time map itself consists of a network whose nodes are points corresponding to the begin and end of what are called time tokens. a time token denotes an interval associated with the occurrence of an event or an instance of a fact being believed to become true and persist for some period. the points in the network are connected by arcs indicating constraints on the distance separating points. a constraint is represented as an interval on the real number line denoting an upper and lower bound on the distance separating two points in the time map. 
   the tmm p erforms a rather simple sort of temporal reason maintenance. the system uses data dependencies and constraint propagation to ensure that whenever two time tokens asserting contradictory facts  or mutually exclusive states  are ordered as to their beginning points the earlier will be constrained  or clipped  to end before the later. 
   plans generally have prerequisites or facts which must be true in order that the plan be applicable in a given situation. plan choice involves selecting a plan and an interval in which that plan's prerequisites are predicted to be true. having made such a selection the planner creates tokens corresponding to the plan steps  subtasks  and their effects  adds them to the time map along with associated constraints  and asserts that the plan is plausible. this assertion is however defeasible. other tasks might be introduced during subsequent planning that clip the persistence of a prerequisite fact thereby invalidating the plan. the tmm monitors the continued validity of plausibility assertions by setting up nonmonotonic data dependency justifications composed of assertions called called protections 
t. dean 1 
 after  . a fact q is said to be protected throughout an interval  ptl to pt1  just in case there exists a time token asserting q that begins before ptl and it's consistent to believe that it doesn't end before pt1. 
   if a protection fails then the tmm notifies the planner of any plans threatened by the failed protection. the failure is annotated in such a way as to facilitate corrective action. the tmm also anticipates possible protection failures and suggests ordering constraints to avoid undesirable interactions. 
hi. handling disjunctions 
   still the machinery outlined above won't allow us to represent protections of the form  a task t for preventing an event e is warranted just in case e would occur if t didn't . neither will it allow us to consider more than one reduction for a given task at a time. the latter involves reasoning about disjunctions. 
   the techniques supporting this sort of reasoning rely upon a method for computing the choices warranting assertions in the time map. choices  e.g. alternative plans or ordering decisions  are represented as boolean variables. each assertion is labeled with a boolean formula indicating under which choices the assertion is believed. labels are computed using a method similar to that employed in mcdermott's context mechanism . mcdermott's system was designed to reason about a large number of contexts sequentially. it demands that the user specify a particular context  set of choices  to consider. it is essential to our problem that we be able to reason about many sets of choices simultaneously. the mechanism must also be able to ignore certain sets of choices  e.g. those including exclusive alternatives . the tmm employs techniques similar to those used by dekleer  to reason about exclusive alternatives and disregard sets of choices no longer deemed worth considering. the algorithms are described in detail in . 
   to illustrate how the tmm works in reasoning about choices i'll provide an abbreviated example drawn from the machine shop domain. suppose that the robot operator in a job shop is contracted to machine a special order flange from a blank casting. the task requires that a certain diameter hole be drilled and one side of the casting be faced  i.e. cut or milled flush . these two subtasks can be performed in any order. both drilling and facing can be done on either the vertical mill or on the engine lathe. suppose that the robot chooses to expand the drilling task using two exclusive plans  one using the mill and another using the lathe. i'll ignore all subtasks except for prerequisite tasks responsible for installing attachments. initially the mill has the face milling attachment installed and the lathe has a collet chuck. drilling on the mill will require a fly cutting attachment while a four jaw chuck is required for drilling on the lathe. the facing task is expanded next and the robot  aided by the tmm  chooses to explore two options: use the 1 t. dean 
lathe  taking advantage of the fact that the four jaw chuck is already in place or use the mill  in this case requiring the collet chuck  and schedule the facing task before the task to install the fly cutter. at the time the facing task alternatives are submitted to the tmm it sets up the necessary protections to monitor the tasks' plausibility  and suggests a number of constraints to help avoid protection violations. notice that while the two tasks  drilling and facing  are still independent  the plans chosen for them are now very much interlinked. to face using the lathe requires that the robot choose to drill using the lathe. if the robot chooses to both drill and face using the mill then it must do the facing task first in order to avoid a protection failure. 
   this just begins to demonstrate the utility of temporal reasoning about choices. the tmm handles dependent choices  nested decisions  and provides considerable assistance at plan selection time in pointing out options that give rise to advantageous or disadvantageous interactions. this same machinery is also used for reasoning about counterfactuals and we'll consider how in the next section. 
iv. complex protections 
   for the most part  in reasoning about hypothetical situations  what we want is a virtual copy of some existing situation with just a few changes. for instance suppose that i'm concerned about a situation in which i ignore a dozen or so parking tickets and the city tows my car. so i consider another situation in which i bribe a city official to indefinitely postpone action on my case. my warrant for paying the bribe depends upon the immediate threat of having my car towed. if that threat evaporates  e.g. the news reports a backlog in the handling of traffic violations which has forced the city to issue amnesty for all offenders  then i should definitely question my motivation for giving money to that official. on the other hand if i discover that my method for handling the situation is ineffectual  e.g. the official has been dismissed having been indicted for accepting bribes  then i had better consider alternative methods. 
   this sort of reasoning has often been modeled along the lines of a conditional proof where introducing and discharging assumptions is considered analogous to pushing and popping contexts. there are a number of problems with this  most of them stemming from the nonmonotonic character of reasoning about beliefs changing over time. from a computational point of view conditional proofs cache deductions in order to ease the computational burden incurred by continually rederiving the same formulae. once one allows nonmonotonicity the process of caching is considerably complicated  as all deductions are potentially defeasible. a conditional proof in these circumstances must be represented as an ongoing computation. the tmm handles this in terms of reasoning about choices. 
   let's consider the plight of a maintenance robot in a factory who is informed at 1 am that osha  the u.s. government agency concerned with occupational health and safety  will make an inspection of his factory sometime after 1. the robot makes a critical assessment of his work space  mindful of the osha rules  notices that the main corridor is cluttered with scrap metal  and predicts that he will be fined for the safety hazard. the robot then determines to clean the aisles before noon in order to avoid the fine. in order to monitor the warrant for and effectiveness of the task to clean the aisles the tmm tags the token for the clean-up task as a choice. if the robot schedules work that will result in the corridor getting cluttered after the clean-up but before the inspection then the tmm will notice that the clean-up task is no longer effective. if on the other hand someone else cleans the corridor or the osha visit is called off then the clean-up task will no longer be warranted. the tmm monitors the continued warrant for prevention tasks essentially by considering a world in which the prevention task was never executed. 
v. conclusion 
   the tmm is applicable in planning domains in which for most tasks the planner has a number of alternative plans and the choice of alternative can make a significant difference in the efficiency of the composite plan. 
