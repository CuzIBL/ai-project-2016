
to enhance effectiveness in real world applications  autonomous agents have to develop cognitive competencies and anticipatory capabilities. here we point out their strong liaison with the functional roles of affective mental states as those of humanlike metaphor: not only the root elements for both surprise and anticipation are expectations  but also part of the effects of the former elicit efforts on the latter. by analyzing different kinds of expectations  we provide a general architecture enhancing practical reasoning with mental states  describing and empirically evaluating how mental and behavioral attitudes  emerging from mental states  can be applied for augmenting agent reactivity  opportunism and efficacy in terms of anticipation.
1 introduction
while cognitive systems are attending in growing interest for anticipatory behaviors  multidisciplinary studies remark liaisons between anticipatory mechanisms and functional role of emotions. otherwise is generally accepted that to enhance human-like effectiveness in real world applications  autonomous agents have to develop higher level cognitive competencies. in this paper we claim and explain how autonomous agents can be anticipatory  able to deal with future events  and how this is important not only for robotic but also for software agents. in particular  we define cognitive anticipatory agents not simply endowed with some statistical learning or prediction  but also with true expectations  related with their epistemic states  beliefs  and their motivational states  goals . from a computational viewpoint  we deal with world predictive representations and we refer to expectations that can be framed among internal state and knowledge-base. although adopting a bdi-like  rao and georgeff  1  approach  we do not introduce for expectations a new primitive  but we build them on the basis of beliefs and goals. expectations processing in real time requires monitoring  appraisal  revision and updating  while  along practical reasoning  bratman et al.  1   expectations are directly involved at various level in goal deliberation  planning  intention reconsideration  learning and action control.
　in addition  expectations have a foundational role in emotion life-cycle and expectation enabled agents are leaning to be 'surprised' according to a human-like behavioral metaphor. defining surprise as a function of the experienced mismatch between what is expected and the perceived data  at a given level of representation   expectations become  prerequisites  for surprise  thus different kinds of expectations holds to different kinds of surprise. here we point out that sources of surprise  generally speaking  the  unexpected  signals  can have either negative or positive consequences on purposive behaviors when they are considered in terms of penalties  costs rather than benefits  advantages.
　in sections 1 and 1 we give a reformulation of the problem from a cognitive perspective  in terms of mental states. we propose that different properties and outcomes of surprise can be modeled in terms of mental states/attitudes clustering suitable reactions and functional efforts. in particular  we analyze surprise outcomes in autonomous agents engaged in a foraging task in a risky world  where surprise attitudes are significant either to become cautious  prudent  careful in harmful circumstances  either for reinforcing expectations  for enhancing knowledge  for learning and appraisal processes. some of the functions that surprise plays for an adaptive behavior and an adaptive cognition can be seen in anticipatory terms of opportunistic adjustment to circumstances  of immediate 'reactions'  but also in terms of intention reconsideration  attention  belief revision  learning. specialization of above effects induces balancing of agent resources  introduces pay-offs in performances and may hold to domain dependent decision strategies. since a theoretical model  we design cautiousness  excitement  boredom and curiosity  giving them the special 'moods' that agent uses to adapt to unexpected chances and to anticipate the world. in section 1 an experiment discussion is proposed to evaluate how effectiveness  in terms of anticipation  is affected both by mental states and environment dynamics. final discussion is given in section 1.
1 expectations and practical reasoning
goal directed architectures focalize in deliberation process
among set of goals  but let intention making and execution of plans in a functional  even purely reactive form: agents process information reacting in a procedural way and choosing in repertoire the plan to execute according to filtering of conditions and belief formulae. no native support was defined for dealing with the future  e.g. future directed intentions   neither prevision models. even if the idea was to align agent performances to real worlds environments  soon the inadequacy of the model has shown drawbacks. real world applications face with dynamism  low accessibility of environment state and constraints.
　the main problem to be addressed in real-time  situated and goal-directed model of agency is narrownessboundedness in various aspects like computational power  time available to take decisions  knowledge and memory. originally proposed in practical reasoning by bratman  intention reconsideration is a costly and binding process: once goal is adopted  agent commits its intention to a given state of affairs  and devote resources for achieving it. traditionally optimization of intention reconsideration processes relies on the two levels of goal deliberation and plan selection: abstractly  agents should break plan and shift their intention if:  i  the related beliefs  context conditions  become false;  ii  the committed plan is no longer achievable and there are no alternatives;  iii  the root-goal  or the meta-level intention  is inhibited by other goals  or by other meta-intentions .  kinny and georgeff  1  analyzed different reconsideration strategies according to a 'degree of boldness'1. their experiments showed that cautious agents outperforms bold agents in cases of high world dynamism but  if the environment is static  all the costs for frequent intention reconsideration are wasted. in a successive work  kinny et al.  1  introduced the 'cost of sensing' and showed that agent effectiveness decrease with the increasing of the sensor effort. on the contrary  the optimal sensing rate increase along with the world dynamism. the experiments considered on the one side the time spared by early detection of changes  on the other side the costs for too frequent sensing.
　agents reasoning has to rely on uncomplete knowledge: their beliefs couple with the real world state at various grades of adherence  resulting inconsistent due to ignorance and uncertainty . unlike completely observable environments  in partially observable environment  poes  the observation at time t may not provide sufficient information to identify st1.
　further  disambiguation between internal 'drives' or motivations and goals is still an unsolved issue. for instance boltzmann selection techniques are used for controlling the trade-off between exploration and exploitation; other models consider environmentally mediated model of emotions1 or some functional role of affective states.1 many of these approaches show drawbacks in their cognitive model and generally lack in opportunism against unexpected events: anticipatory agents should have strong proactive capabilities in using uncertain beliefs within deliberation processes  strategies for adaptive intention reconsideration  kinny and georgeff  1  and sensing  disambiguation between motivations and goal hierarchy.
　in the next sections we propose a new approach  based on the high-level role of expectations  eliciting emotional states and attitudes. as we see  this can be reflected in design of reasoning and decision making processes affected by emotional signals.
1 expectations  surprise and anticipation
we refer to anticipation outcomes as agent changes on mental attitudes in decision making due to what is expected. while the association between internal state  processed input and deliberation process is generally defined in design time  anticipatory strategies for intentional  goal driven  behaviors requires agent to build some predictive representations. in  ortony and partridge  1  cognitive expectations are given in terms of practically deducible propositions  defined as symbolic beliefs that can be fully represented in memory  or logically inferred. our claim is that expectations in deliberative agents can be coupled with beliefs and goals: since these basic components  we attain expectations as a molecule expressing emerging attitudes   in part epistemic  to check whether the prediction really fits the world  to monitor the success of the behavior  in part motivational  the agent who build expectations is 'concerned' and some of its goal are involved   castelfranchi  1 . at a cognitive level  we distinguish here between high and low level expectations: expectationα: more explicit  consists of fully represented predictions about decision outcomes and can be associated with alternative courses of actions; expectationβ: dealing with those expectations with weak level of representation  due to lack of beliefs  uncertainty  ignorance. at a quantitative level  we refer to two independent dimensions:
1. belief strength  as degree of subjective certainty. the agent is more or less sure and committed about their content.
1. goal value  a subjective importance strictly dependent on context conditions and mental attitudes.
this kind of expectations already allow agent to experience surprise  elicited by the expectation resulting to be wrong after the fact  expectation invalidation . thus  expectations become 'prerequisites' for surprise: more precisely surprise is due to  and a signal of  a mismatch  an inconsistency between agent expectations  given by previous knowledge  and the incoming information  actual input   compared at a given level of representation  castelfranchi and lorini  1 .
　current computational models lack quantitative description of the functions that surprise play for an anticipatory behavior and an adaptive cognition. psychoevolutionary model of  meyer et al.  1  proposed that surprise-eliciting events holds to  i  appraisal of a cognised event as exceeding some threshold of unexpectedness;  ii  interruption of ongoing information processing and reallocation of resources to the investigation of the unexpected event;  iii  analysis/evaluation of that events;  iv  immediate reactions to that event and/or updating or revision of the  old  schemas or beliefs. recent works in neuroscience and neuroeconomics identify the important role of emotions in decision making and anticipatory goal deliberation processes. it has been showed that affective states help to  decide advantageously before knowing the advantageous strategy   bechara et al.  1 . to improve the speed of learning  regulate the trade-off between exploration and exploitation and learn more efficiently   ahn and picard  1  introduced decision making strategies using affective components given by affective anticipatory rewards. they proposed a cognitive system with affective biases of anticipatory reward  modeled by positive and negative valence of evaluation of expectation1.
　we propose that effects of the expectation processing can be seen beginning from the strength of its component  beliefs and goals  and can rely on the positive or negative consequences upon agent purposes. the prediction of possible world outcomes triggers a given anticipatory behavior  e.g. aimed at preventing threats . relatively to goals  we consider the 'goal failure' in terms of excitement or frustration  when the goal is achieved at more or less level than the one expected. relatively to beliefs  we consider the epistemic capabilities aimed at solving the inconsistency. we also guess that different kinds of expectations hold to different kinds of surprise. expectation α failure elicit updating of those explicit expectations coupled with goals  reinforcement in expected utility and exploitation of purposive behavior. on the other side  unexpected β signals elicit adaptation  reactiveness  backtracking  intention reconsideration  shift of motivations  opportunism  investment in resources. we distinguish between:
1. long-term and short-term effects  respectively related to decision making  learning and adaptive behavior  arousing  invoking and mobilizing resources attention.
1. mental and behavioral changes  affecting motivations  intention reconsideration  self-confidence  action execution and selection.
specialization of the above effects induces balancing of agent resources  introduces pay-offs in performances and may hold to domain dependent decision strategies.
1 foraging in risky world
to test agent performances so that different strategies can be significantly compared  we design a test-bed scenario. environment captures features of real world domains  allowing flexible control of the world dynamics. navigation capabilities are given with a repertoire of paths  defined as list of location to pass through  used to routinize crossing rooms and loi. agents move in a continuous 1d land map where walls  obstacles and doors  that can be open or close  delimit rooms  corridors and pathways. environment holds simulated time and guarantees consistency for entities  artefacts and world objects. belief base is built upon a shared ontology of world objects and artefacts: three locations of interest  loi  present symbolic reference points where three kind of food appear  with fixable frequency. each class of food has modifiable 'score' and a likelihood to appear near the corresponding loi. agent works for the terminal goal of foraging  composed of the following workflow of actions:  1  look for food with  supposed  best reward;  1  go to the identified food location and pick up it;  1  transport food  one at a time  from the original location to the repository and deposit it. releasing foods in the repository  agents obtain a 'reward' augmenting energy  calculated from the basis of the original food score decreased with a decay factor straight depending on the transport interval. decay is introduced to enhance cost in duration of actions. agents are characterized by the following tuple of dynamic resources:
		 1 
en indicating the instant amount of energy  r the range of vision where sensors can retrieve data  sr the sensor sample rate  and s the instant speed. we assume agent burning energy according to the combination of previous resource costs  e.g. the more speed and sensor-rate is high  the more agent will spend energy .
　along the presented workflow  agents can run up against dangerous entities. fires behave according to a two state lifecycle periodic function: in their first shape they are in a smoke 'premonitory' state  then they become real harmful flame. at the beginning of each period  fires change their location with discrete movements. moreover fires can rise with higher frequency in given dangerous areas. against fires collisions  agents have to reconsider their intention  e.g. adopting fire avoidance behavior   and they are constrained to experience a short-term reaction: actions and speed are constrained and further costs in term of energy have to be paid. agents expire when their energy goes to zero1.
1 design
as for the agent's kernel we adopt jadex engine1  a multi threaded framework for bdi agents where the architecture leads to a loosely coupled beliefs  goal  and plans  including their mutual relations  through agent descriptor  braubach et al.  1 . jadex deliberation is driven by the evaluation of logic formulae  put in form of belief formulae  and 'arcs of inhibition' between goals for dynamically resolving their priority. as explained below  to model expectations and effects of surprise at a system level  we pointed out that they take place at various level of reasoning and we modified the original bdi schema introducing α expectation processing  with expectation driven deliberation  and β expectation processing  with mental states designed for clustering attitudes for adaptive and anticipatory changes .
1 subjective expected utility
we relate α expectations with agent epistemic states  beliefs  and motivational states  goals . subjective expected utilities  defined in decision-theoretic accounts as a function of the agent's beliefs and desires  bratman et al.  1   are included at meta level reasoning as mechanisms for goal deliberation. along the foraging tasks  a working memory stores information about food  quality   reward on goal achievement and food type  and  quantity   frequencies  time-stamps and location of any food added in the belief base . these are the re-evocable traces of previously achieved actions: agents associate to each loi a seu value given by belrew  determined averaging rewards stored in a k-length memory for the last k delivered foods  multiplied with pfloi  indicating the likelihood to discover foods near the loi . through a feedback  actual results of purposive actions of depositing food are compared against expectations: once a food is located  agent will reinforce pfloi  correct expectation   otherwise  when a loi is visited and no foods are located  pfloi will be weakened  wrong prediction . at the meta-level-reasoning  agent chooses to look for foodx at the corresponding loix by comparing their seus and by adopting the epistemic goal toward best expected loi  according to a -greedy strategy. seu processing runs in  discrete time   upon goal achievement or at action completion. identifying with sensors a set of foods  agent adds them to the beliefbase and heads for the nearest one  observing topology  constraints and obstacle bounds. deliberation from searching to pickup action is triggered when a food is located  from pickup to homing when a valuable is carried. note that if a nearest food fj is located  a new intention inhibits the current plan. further transition to searching is caused when agent achieves the drop action.
　in addition  means-end reasoning processes are introduced when agents choose a path between the available ones  means   to reach a target location  end . the risk is a negative α expectation  a threat . quantitatively risk is a fully represented variable inside the paths that agents use to move and is augmented by unexpected negative events  e.g. fire or smoke threat .

figure 1: transition function for mental states uses two stacks for storing positive and negative events.
1 from reactiveness to anticipation
a reactive agent is one that makes decisions about what action to take relying on its current state and on input from sensors. in this case  states can be modeled by a  stochastic  finite state automaton  fsa  where each state represents an action -or a plan- the agent is executing  while transitions get it to other states. otherwise  generalized markov process evaluates the past k states: if an agent has instantaneous k-length knowledge of the world  it could dynamically change its internal state  allowing reasoning as a whole to adapt to changes1. in most situations  such global knowledge is impractical or costly to collect but for sufficiently slow dynamics  agents can correctly estimate the environment through local observations. this kind of agents can be described by a push down automaton  pda  where the stack stores the expectation invalidations items. by evaluating the cached items agent can foresee the current environment state  infer βexpectations  and consequently adapt its attitudes. items have both an informative content  e.g. timestamp  location  event type   and a semantic content  because they are coupled with the positive  benefits  or negative  disadvantages  effects that the event entails. hence  by using two distinct buffers to store these positive and negative events agents  the agent can observe the world in terms of positive opportunities and negative circumstances. starting from these series of local observations  a background process periodically define the mental state to adopt  through a transition function  see fig.1 .
1 mental states
after a series of positive surprises  unexpected opportunities and helpful novelties  agent may tend to reinforce beliefs: for instance  dropping food with unexpected good reward holds agent to become excited  reinforcing seu in looking food of that type near the respective loi. exciting surprises are internal signal for arousing the agent  for increasing the explorative activity and for searching for those good events. having registered a close series of harmful events may signify agent is in a dangerous area. the mental state coupling with alerting  negative  surprise is cautiousness  which gives the anticipatory effort of risk avoidance  i.e. anticipating threats . being cautious in a risky world  with hidden state  means to become prudent and to adopt safe behaviors. we design agent cautiousness distinguishing two aspects: firstly caution elicits arousal and alert  holds to become more vigilant  to look ahead  to check better while and before moving  prudence against risks ; secondly to be careful in doing dangerous actions  either augmenting the control or doing the action in less risky way  e.g using alternatives in repertoire . we suppose cautious agent able to escape from threats using its safest plans. the investment in resources is exploitable for adapting  learning  noticing world regularities and anticipating threats  but introduces pay-offs:  castelfranchi et al.  1  showed that mobilizing more resources for epistemic actions  actions explicitly directed to enhance knowledge  and attentive processes has direct effects in reducing promptness and speediness and side effects in bodily reactions  as further energy consumption. caution holds to behavioral and mental changes: we identify the following activities:  i  perceptive investment  reallocation of attentive resources s  sr  v  looking ahead  updating  focusing;  ii  belief revision  e.g. signalling a dangerous area  increasing the path risk;  iii  adapting of self-confidence in beliefs  and expectations ;  iv  intention reconsideration in the sense of selection of safe actions  e.g. selection of safest path . we design boredom as the mental state coupling with lack of surprising events  i.e. empty buffers . the transition function gets to boredom by persistence of empty buffers  where persistence is defined by heuristic thresholds . in the long run  further lack of surprise items produces a special 'mood'  curiosity  whose outcome is to shift from exploitation to exploration attitudes. in this case the agent activates the new goal of exploring and searching for unexpected event in less visited areas  in order to update knowledge and expectation models. curious agent uses an alternative searching policy: while the first strategy is based on evaluation of seu  according to which agent selects searching actions towards best expected loi  the second has the purpose to 'attain knowledge' in order to update internal world representations  predicting models and beliefs: anticipation is indirectly elicited by appraisal  beliefs and expectation revision. notice that curiosity implies abandoning risk
mental statesattitudesresourcesrsrsdefaultexploitation111excitementreinforcement111cautionprudence111curiosityexploration111table 1: mental states and weights for epistemic resources defined in  1 . note that the global amount of resources is limited to 1 for each state.
evaluation: it elicits the adoption of a new explicit epistemic goal  leading the agent towards those areas where it foresee to enhance knowledge.

figure 1: agent energy  a  and effectiveness  b  comparision
1 experimental results
we compared a benchmark agent with subjective expected utility  seu  and an agent adding to subjective expected utility processing also mental states  ms  module. experiments have been conducted in environment with different level of riskiness  indicated by the presence of more or less harmful objects  e.g. fires . our first series of experiments extracted the course of energy in function of time: as in  castelfranchi et al.  1   while with low presence of riskiness ms and seu agents have comparable energy trends  we noticed agent mean energy decay according to enhancing of risks. fig.1a shows the trial with the presence of 1 fires entities. it is interesting to note the discontinuities in slopes of the functions  caused by transitions of mental states and  consequently  by the different energy consumption due to resource allocation. peaks indicate goal achievement  food released in the repository  and consequent energy recharge; downfalls indicate damaging by fires. as we expected  ms agent outperformed seu agent  being able to adapt behavior and reduce harms. seu agent collided with more fires and this caused it to expire after 1 sim time. due to cautiousness  repertoire of safe actions and risk evaluation in choosing of paths  ms agent acted in safeness  succeeded to escape from threats and suffered less damages. in these cases ms agent is able to anticipate dangerous areas and collisions and negative effects are minimized until agent shift to the cautiousness mental state. it also been noticed that agent dynamics introduce payoffs. during their lifetime  seu achieved 1 forages while ms agent 1: seu boldness and commitment ensure higher speed and less time to accomplish the task. otherwise  trials with lower level of riskiness showed better ms agent performances in searching on the long term  due to curiosity. ms agent showed better exploration competencies  when food valuables near loi are consumed and the usual seu strategies lacks.
　although the course of energy in function of time gives instantaneous snapshots on the single trial  this metric gives weak contribute to define absolute performances because of dependencies on experiment length  independent random distribution for food  fires and dangerous areas  world dynamism and agent competition for valuables. as in  kinny and georgeff  1  we defined agent effectiveness as the number of achieved task  delivered foods  divided by the total amount of achievable task  total amount of food appearing in the trial . because of random variations in the environment  effectiveness has a fluctuating course before converging  hence individual trial has to be sufficiently long for the effectiveness to become stable. measuring effectiveness in function of time  for fixed amount of food  riskiness and world dynamism  we defined the standard trial length of 1 sim time. we defined agent characterization averaging performances of 1 trials. the decreasing curves presented in fig.1b resulted running characterizations in 1 conditions of growing risk. for both agents  effectiveness comparison shows maximums in the trials with no fires  safe environment . ms agent outperformed seu agents in all conditions for two main reasons: on the one side cautiousness enable ms agent to avoid fires in risky environment  on the other curiosity allows ms agent to move from static areas  poor of stimulus and valuables  to more dynamics areas  where the likelihood to discover foods -via surprise- is higher. global effectiveness is 1 for low riskiness: in these cases  the agents generally succeeded to collect the whole set of foods. mean riskiness represents the greatest difference in effectiveness. for greater presence of fires  some foods remain uncollected at the end of the trial either because seu agents expire before the end of the trial due to recurrent fire collisions  either ms agents pay growing costs for risk avoidance behavior and intention reconsideration.
1 discussion
this work discussed anticipation through expectations processing and affective efforts in goal driven agents. we examined a cognitive model for agents with mental states affecting reasoning processes; we experienced how related attitudes influence agent performances both on the basis of the environment features and of the cognitive model implemented. by providing a general architecture for intelligent agent clustering attitudes in mental states  we defined flexible domain-dependent decision strategies. particularly  we showed experiments in environments with growing level of riskiness  where agents with mental states outperforms agents with more traditional utility strategies. we consider these cognitive functions as a fundamental building block for the anticipatory behavior that is the real challenge for the future cognitive software agents and autonomous robots.
　this model can be extended in important directions  for instance social activities requiring high level modeling  like trust  delegation and reliance in cooperative or competitive tasks. as for mechanisms  we used pda for modeling mental states controller  anyway the system is designed for testing alternatives  e.g. salience models   may be resulting more effective.
