 
this paper describes a new idea to project a stripe pattern onto a time-varying scene to find moving objects and acquire scene features in the consecutive frames for estimating 1-d motion parameters. at f i r s t   a simple temporal difference method detects objects moving against a complex background. a 1/1 d representation of moving objects at each frame is then obtained by estimating surface normals from the slopes and intervals of stripes in the image. the 1/1 d image is further divided into planar or singly curved surfaces by examining the distribution of the surface normals in the gradient space. then  the rotational motion parameters of the objects are estimated from changes in the geometry of these surfaces between frames. determining translational ones is also discussed. 
1. introduction 
determining of 1-d motion parameters in a timevarying scene is a current problem in computer vision. interesting theories have been presented to estimate 1-d motion of objects from a sequence of images taken by a camera  1 . they  assuming the rigidity of objects  analyze changes in geometry of object's images in the consecutive frames to obtain 1-d motion cues. the results of applying these theories to real scenes  however  are very sensitive to noise and unsatisfactory in most cases. we  therefore  need a reliable method to obtain scene features from each frame in the image sequence. 
a method useful for acquiring 1-d information is to project the structured light to the scene. since the time for scanning a s l i t light  is too long for the dynamic scene analysis  we use a dense stripe pattern as the structured light. one advantage of this method is that a simple temporal difference method can easily detect objects moving against a very complex background  saving a considerable computing time. 
if the stripe is dense  finding of correspondence between each stripe pattern in image and light stripes in scene is difficult  especially when the scene contains many concave objects or discontinuous boundaries. as a result  our method cannot provide with the range information at each image point. surface normals as important scene features  however  are available at a number of points distributed densely in the image. 
the image acquisition system is arranged such that a l l light stripes in scene are almost parallel and the projection from scene to image is orthographic. thus  we can obtain a 1/1 d representation of the moving objects at each frame by estimating the surface normals from the slopes and intervals of the stripe. 
the 1/1 d image is further segmented into planar or singly curved surfaces by finding and examining clusters of the surface normals mapped onto the gradient space. although the estimate of each surface normal is somewhat inaccurate  we can obtain much better estimates of geometrical parameters of these surfaces by utilizing the continuity in each surface. the rotational movements of the objects are determined from changes in these parameters between consecutive frames. the estimation of the translational components from these changes is difficult  however  we could utilize cues to get the range 


 a  the 1nd frame. 	 b  the 1th frame. 
fig.1 the difference picture between 
	fig.l examples of input images. 	 a  and  b  in fig.l. 

1 m. asada and s. tsuji 


image. 
in order to obtain the surface normal  the system detects edge segments from the striped image of moving objects  see fig.1 . the location of edge point is estimated in a sub-pixel order by using the linear mixing model  of intensity around the boundary between dark and bright regions to reduce the effect of digitizing error. the system f i t s a line segment to seven successive edge points. those segments whose fitting error exceeds a threshold are discarded as discontinuous boundaries. from the slope and intervals of these line segments  we can calculate the surface orientations. fig.1  a  shows sampled surface normals on the moving objects obtained at the 1th frame. a histogram of these surface normals in the gradient space are shown in fig.1  b . 
1 motion analysis 
let us consider how we can utilize the 1 l/1 d images to estimate the 1-d motion parameters. at first  we map the obtained surface normals onto the gradient space in order to segment the 1/1 d image into planar or singly curved surfaces  see fig.1  b  . surface normals on a plane make a cluster in the gradient space. by mapping them from the gradient space into the 1/1 d image reversely  we obtain the planar region. its orientation is precisely estimated by calculating again with longer line segments and wider intervals. 
also  surface normals on a singly curved surface  for example  a cylindrical surface make a line-like cluster in the gradient space. the line parameters obtained by f i t t i n g a line to the cluster gives us the orientation of generating line of the cylindrical surface. its orientation makes the surface parameters more precise. 
since the lower surface of wedge is parallel to the generating line of the cylindrical surface  the cluster corresponding to it is merged in a line-like cluster  see fig.1  b  . therefore  we cannot detect the lower surface of wedge in the gradient space at first. the line--like cluster  however  is segmented into two surfaces by examining the surface continuity on the 1/1 d image. fig.1 shows the results of the segmentation. 
since each 1/1 d image is segmented into planar or singly curved surfaces  it is easy to find correspondence of these surfaces between consecutive frames. table 1 indicates the angles between the surfaces at the 1th and the 1th frames. the orientation of cylindrical surface is represented as the direction of generating line. little changes of them between frames shows the rigidity of object. assuming i t   we determine the accurate rotation parame-
ters from the precisely obtained surface properties at each frame. 
1. discussions 
we have determined the rotational movement of object from the changes of surface geometry between frames. they  however  can provide us with l i t t l e information on the translational movement. thus  let us consider how we can get the range information from such images as shown in fig.l to determine the m  asada and s. tsuji 1 
translation. 
shadow parts give us a very important cue to extract the depth information. utilizing the projections of light lines onto the image plane  which are equivalent to the epipolar line in stereo vision  we can label each stripe in image between two surfaces which are discontinuous as shown in fig.1. this figure displays the upper surface of the wedge and its shadow on the back wall in fig.l  b . then  the relative distance between them is obtained from the equations of light stripes in scene. 
if two surfaces are continuous  stripe edges in image are connected across their boundary. therefore  we hypothesize that the range is continuous between two surfaces where stripe edges in image are connected  although it is not always true. 
most parts of the image would be interpreted by propagating the consistent labeling of stripes with the shadow information and the cue of surface continuity. there would remain several candidates of interpretation for unknown portion of the image. 
