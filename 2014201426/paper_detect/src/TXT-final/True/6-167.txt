 
we propose a variable ordering heuristic for sat  which is based on a structural analysis of the sat problem. we show that when the heuristic is used by a davis-putnam sat solver that employs conflict-directed backtracking  it produces a divide-and-conquer behavior in which the sat problem is recursively decomposed into smaller problems that are solved independently. we discuss the implications of this divide-and-conquer behavior on our ability to provide structure-based guarantees on the complexity of davis-putnam sat solvers. we also report on the integration of this heuristic with zchaff- a state-of-the-art sat solver-showing experimentally that it significantly improves performance on a range of benchmark problems that exhibit structure. 
1 	introduction 
the class of boolean satisfiability  sat  problems has been of perpetual interest to researchers in many areas of computer science. although these problems have a potentially exponential complexity  fresh techniques have continued to be proposed and implemented  allowing an increasing number of  previously  intractable problems to be solved in reasonable amounts of time. 
most existing complete sat solvers are based on the 
davis-putnam  dp  procedure  davis and putnam  1; 
davis ct al  1   which formulates the sat problem as a systematic search problem in the space of variable instantiations  and uses depth-first search to find a solution. various techniques are employed by dp solvers in an attempt to prune the search space  or to focus it on regions that promise earlier discovery of a solution. it has been noted that  among other things  the order in which variables are instantiated has a great effect on the resulting complexity of the sat algorithm; see  li and anbulagan  1  for example. 
　we propose a new variable ordering heuristic for sat  which is based on a structural analysis of the sat problem. we show that when the suggested ordering heuristic is used by a dp solver that employs conflict-directed backtracking  silva and sakallah  1   it produces a divide-and-conquer behavior in which the sat problem is recursively decomposed into smaller problems that are solved independently. the general concept is that while the initial sat problem may not be decomposable  it can be broken into independent sub problems after instantiating a certain number of variables that can be determined structurally. hence  putting such a decomposing set of variables first in the ordering leads to an early decomposition of the problem. the key  however  is that this process can be repeated recursively  allowing one to recursively decompose the sat problem down to single clauses. the other key point which we establish analytically is that it is critical for the dp solver to employ conflict-directed backtracking for the suggested order to have this recursive decompositional effect.1 
　by way of experimentation  we incorporated this technique in the publicly available zchaff program  zchaff  url  and tested both the original and modified programs on a range of sat benchmarks. our results indicate a significant improvement in speed on the majority of the instances. 
　the rest of the paper is structured as follows. we start with a brief review of dp solvers in section 1. we then turn in section 1 to the proposed variable ordering heuristic  where we define it formally in terms of a graphical model  known as a dtree  decomposition tree . we then describe in section 1 our integration of the new heuristic with zchaff  zchaff  url   and provide experimental results that illustrate its effectiveness. we then consider a theoretical analysis of the proposed ordering heuristic in section 1  where we show that when coupled with conflict-directed backtracking  the proposed ordering generates a behavior which is equivalent to a divideand-conquer search algorithm that recursively decomposes the given sat problem all the way to single clauses. this correspondence allows us to provide some guarantees on the complexity of the resulting search  depending on the structure of the given sat problem. we finally close in section 1 with some concluding remarks. 
1 	davis-putnam  dp  search 
we start by reviewing the basic dp search for the satisfiability problem. as is customary  a propositional theory is expressed in conjunctive normal form  cnf . recall that to satisfy a 
   'sec  bayardo and pehoushek  1  for an example where  dynamic  decomposition is used  but in the context of model counting. 
algorithm 1 sat thcory : c  
1: if there is an inconsistent clause in c then 
1: 	return false  unsatisfiablc  
1: if there is no uninstantiated variable in c then 
1: 	return true  satisfiable  
1: select an uninstantiated variable v in c 
1: return sat{c v=true  v sat c v=false  
propositional theory in cnf each of its clauses simultaneously has to be satisfied. we will use to denote our target theory having m clauses where c{ denotes its zth clause. we will write  to represent the theory obtained by replacing the occurrences of variable v to true  false  in the theory c  algorithm 1 provides a recursive description of the basic dp algorithm except that it omits the use of unit propagation which we discuss later. 
　this algorithm is often implemented iteratively instead of recursively  where it explores the search space by instantiating variables one at a time  we will call these instantiations decisions and the corresponding variables decision variables . each of these decisions is pushed onto the decision stack and the theory is updated to reflect the new variable assignments. when inconsistency is discovered in the theory it goes back on the stack to the last decision whose variable has not been tried both ways  flips it  and proceeds therefrom. in case all previous decision variables have been tried both ways  it declares the theory as unsatisfiablc. the theory is declared satisfiable if all variables have been successfully instantiated  or if all clauses have been subsumed  satisfied by the current  possibly partial  variable assignment . 
　note that there is no need to attempt both recursive calls on line 1 in case one of the calls succeeds. hence  one opportunity for optimization is to first try the most promising disjunct in line 1. note also that we did not specify how to choose the next variable on line 1. in fact  a different chain of decisions can often lead to a remarkable difference in complexity  li and anbulagan  1 . 
　we describe in the next section a variable ordering heuristic based on a structural analysis of the sat problem. we then provide an experimental and a theoretical analysis of the heuristic in later sections. 
1 	a variable group ordering 
recall that  is our target propositional 
theory in cnf. we have alluded to our desire of decomposing c into disconnected components. however  if we simply split c into two arbitrary subsets these two subtheories will in general have some variables in common and hence not qualify as disconnected components. 
　to overcome this difficulty we propose the following method. let and denote the sets of variables men-
tioned in ci and cr  respectively. we start the dp search on 
cnf c  but insist that it only make decisions on variables in  at this stage. if unsatisfiable is declared during 
this process  we are done; otherwise all variables in will at some point have been instantiated. 
observe that the resulting sub-theories now 

figure 1: a dtree for a four-clause cnf. 
have disjoint sets of  uninstantiated  variables:  
 they are hence com-
pletely independent sub-problems. ordering one set of variables before the other therefore seems a good strategy from this point on. we have thus obtained a constraint on the order of variables: variables are processed first  followed by  and then 1 note that and can each be re-
cursively broken up in a similar fashion  until all variables are partitioned into a sequence of groups  which serves as our proposed variable ordering. within each of these groups  the algorithm is free to use any variable order. 
　to generate such a variable group sequence we will need to specify how the theory c is to be partitioned into sub-theories and   how the sub-theories in turn are to be partitioned  
and so on. a graphical model known as a dtree serves nicely for this purpose  as it allows us to offer guarantees on the complexity of the resulting search  darwiche  1 . 
　a dtree  decomposition tree  for a cnf c is a full binary tree whose leaves correspond to the clauses of c  see figure 1. each internal node represents a subset of c corresponding to all the leaves under it; the root in particular represents the original theory c. such a tree naturally induces a recursive decomposition scheme  partitioning a theory into two parts represented by the node's two children. 
　a number of properties can be defined for the nodes of a dtree  darwiche and hopkins  1 . 
definition 1 the variables of an internal dtree node is the set of variables mentioned in the clauses represented by the leaves under that node; the variables of a leaf node is the set of variables mentioned in the clause it represents. 
definition 1 the cutset of an internal dtree node is the intersection of its children's variables  minus all its ancestors' cutsets; the cutset of a leaf node is its variables minus all its ancestors' cutsets.1 
　figure 1 depicts a dtree for a four-clause cnf theory. the clauses are listed at the bottom below their corresponding leaves. the cutset is shown inside of each node. 
　　we assume the left-right order. choice between the two orders affords another opportunity for applying heuristics  but is beyond the scope of this paper. 
　　1  a cutset is usually not defined for a leaf node in a dtree  but we extend the definition here for convenience. 

1 	satisfiability 

　recall that each dtree node t corresponds to a part of the cnf theory; hence the variables of a dtree node are simply the variables of that part of the cnf theory; and the cutset represents all variables that need to be instantiated before the two sub-theories become disconnected  assuming that all cutsets of t's ancestors have been instantiated . the following two concepts will help formally state our proposed heuristic for ordering variables. 
definition 1 a variable group ordering of set v is a partition of variables v into an ordered sequence of subsets. 
　with respect to the set of variables in figure 1  the following is a possible variable group ordering:  
	which dictates that variables 	should be consid-
ered before and b e f o r e . note that a strict variable ordering is a special case of variable group ordering in which all groups have size one. 
definition 1 the variable group ordering  v.g.o.  induced by a dtree is one obtained recursively as fol-
lows: output the cutset of the root; output the v.g.o. of its left child; output the v.g.o. of its right child; discard empty sets. 
　our proposed variable ordering scheme can now be stated as simply the variable group ordering induced by the dtree. the variable group ordering induced by the dtree in figure 1  for example  is  
　so far we have not discussed how dtrees are to be constructed. there are obviously many distinct dtrees for any nontrivial cnf theory. to reduce the complexity of the sat algorithm we have adopted a heuristic that calls for relatively balanced dtrees with small cutsets. a good balance ensures a near-logarithmic tree height  which allows the recursive decomposition to finish faster. and smaller cutsets lead to minimizing the number of cases that may need to be considered for each decomposition. hence  both of these strategies will help reduce the overall complexity. 
　to generate dtrees with the above properties  we employ the same hypergraph partitioning technique as described in  darwiche and hopkins  1 . our hypergraph for a cnf theory c is constructed by having a node for each clause in c and having a hyperedge for each variable in c connecting all nodes  clauses  that mention the variable. the hypergraph partitioning tool recursively partitions the set of nodes into two  balanced  parts while attempting to minimize the number of edges across. a small number of crossing edges translates into a small number of variables shared between two sets of clauses. hence the resulting dtree is expected to have relatively small cutsets. the degree of balance is controlled by specifying what is called the balance factor. we have used a balance factor of 1 in our experiments  which tells the program not to let the ratio of the two partitions in size  large over small  exceed  the reader is refered to  darwiche and hopkins  1  for a more detailed description of this technique. 
1 	experimental results 
to evaluate the effectiveness of our proposed ordering technique  we decided to integrate it with an existing sat solver to see whether it would improve performance on a variety of benchmarks. our choice of sat solver is zchaft  zchaft  url  as it has ranked first in the recent  1 and 1  sat competitions  satex  url . 
　our additions and modifications to zchaft consist of 1  the package that implements dtree generation; 1  a separate chunk of code that extracts a variable group ordering from the dtree; and 1  change to the zchaft code such that the program is given the variable group ordering as a second input  the first being the cnf  and forced to select variables from the same group  one group at a time following the specified group order. within the same variable group  zchaff is left to use its own heuristic  known as the variable state independent decaying sum decision heuristic  moskewicz et ai  june 1 . the new code is in the form of add-on and replacement files that compile with the original zchaft package to produce the modified program; it is available for download at http://reasoning.cs.ucla.edu/dtree.sat/. 
　our experiments were carried out on a redhat system with a 1mhz cpu and 1mb of memory. the original zchaft program and its modified version  which we call dtree-zchaft  were run on the same sets of cnfs. we report in table 1 the comparative performance of these two programs. note that only those instances that were solved by both programs are included. instances on which dtreezchaft succeeded but zchaft ran out of memory are reported in table 1; the reverse case did not happen for the given test suite. some of our benchmarks are from  aloul  url ; others are from the satl1b website  satlib  url . 
　the times shown are in seconds and each represent the total time for all instances in the group. we generated two dtrees per cnf and chose the one with smaller width1. during the generation of each dtree  we repeated each hypergraph partitioning step twice and chose the smaller cut. the reported  dtree time  includes the time to thus obtain a dtree and that to compute a variable group ordering from it. adding  dtree time  and  dtree-zchaft time  gives the actual running time of dtree-zchaft  which is compared with that of the original zchaft. figures in bold highlight the benchmarks on which the proposed ordering lead to an improvment. scores on a single-instance basis are shown in the last column. considering whole groups  we observe that dtree-zchaft leads to improvement on seven out of the ten groups by a factor of between 1 and 1. considering individual instances  it also leads to improvement on the majority of them. for a more detailed picture  we have included in table 1 individual results on a select number of typical instances from each group. 
　we would like to point out that most of these cnfs are relatively  hard  instances for zchaft-they require more than a few seconds. on instances where zchaft finishes in a flash- such as til1  parl1  many of those in uf1  and some of those in pigeonhole-our proposed ordering was not helpful since generating the dtree alone could take more time than that needed by the plain zchaft to solve the sat problem. finally  to complete the picture  table 1 reports on instances 
 not included in the first two tables  on which zchaft ran out of memory but dtree-zchaft succeeded. we also note that 
　　1 thc notion of width captures both the cutset sizes and the degree of balance; a formal definition can be found in  darwiche  1 . 

table 1: overall results on all benchmarks 
benchmark sat/unsat dtrce time dtree-zchaff time zchaff time improved instances pigeonhole 1 unsat 1 1 1 1 fpga-unsat 1 unsat 1 1 1 1 urq 1 unsat 1 1 1 1 uuf1 1 unsat 1 1 1 1 uf1 1 sat 1 1 1 1 fpga-sat 1 sat 1 1 1 1 difp a 1 sat 1 1 1 1 difp.w 1 sat 1 1 1 1 iil1 1 sat 1 1 1 1 par 1 1 sat 1 1 1 1 
table 1: instances on which zchaff failed 
instance dtree dtrce-zchaff time time hole 1 1 1 1 hole 1 1 1 1 fpgal l1 uns rcr 1 1 1 urq1 1 1 1 urq1 1 1 1 urq1 1 1 1 urq1 1 1 1 
algorithm 1 sat thcory : c  dtreenode : t  
1: if there is an inconsistent clause in c then 
1: 	return 	 
1: if t is 	then 
1: 	return true 
1: if there is no uninstantiated variable in 	then 
1: 	return sat  
1: select an uninstantiated variable v in t.cutset 
1: return  

algorithm 1 sat theory : c  dtreenode : t  
1: if there is an inconsistent clause in c then 1: return false 

the total running time of all experiments was about 1 weeks. 
1 decompositional semantics of the heuristic 
　we show in this section that when the proposed variable ordering heuristic is integrated with a dp solver that employs conflict-directed backtracking  such as zchaff  it produces a divide-and-conquer behavior in which the solver recursively breaks down the sat problem into smaller sub-problems that are then solved independently. specifically  even though the solver is using a dp search method  we will show that it emulates algorithm 1  which explicitly uses the dtree to realize a divide-and-conquer search. one significance of this correspondence is that we can now offer structure-based guarantees on the complexity of dp solvers that use such orders. such guarantees have usually been restricted to dp solvers based on resolution  davis and putnam  1; dechter and rish  1   which have not been as influential for sat given their intractable space complexity  davis and putnam  1; davis et al  1 . 
1 
　given a cnf c and a corresponding dtree  recall that each dtree node t corresponds to a subset of the cnf c. from here on  we will use c : t to refer to the set of clauses in cnf c corresponding to node t. algorithm 1 takes two inputs: a cnf c and a corresponding dtree rooted at node t. the following invariant is maintained by the algorithm: clauses c : t are disconnected from other clauses. this is true trivially for the very first call to algorithm 1  and remains true for recursive calls since cutsets associated with ancestors of node t must be instantiated by the time the recursive call is made. algorithm 1 decomposes the clauses in c : t by setting variables in the cutset of node t to some value  specifically  clauses can now be decomposed into two smaller sets  a n d w h i c h are solved independently. if both of these sets of clauses are solved successfully for some instantiation a  the original cnf c is declared satisfiable. otherwise it is declared unsatisfiable. 
　note that cutset variables do not need to be instantiated simultaneously as given on line 1 of alogirthm 1- instantiating these variables one at a time leads to the variant algorithm 1. the order in which variables are instantiated by this algorithm is indeed consistent with the group ordering induced by the given dtree  as formalized by definition 1. in fact  the only key difference between algorithm 1 and a dp solver that uses the dtree group ordering is that when all cutset variables of dtree node t are instantiated  algorithm 1 will spawn two independent computations on 
and  however  the dp solver will sequence these two computations  potentially creating a dependence between them. that is  if a contradiction is reached while solving the second problem in the sequence  the search may backtrack to variables in the first problem  therefore 
satisfiability 

eliminating the benefit of decomposition. as we discuss next though  this is impossible to happen if the solver employs conflict-directed backtracking  as in zchaff. specifically  we will show that in such a case  the solver will effectively conduct two independent searches on the sub-problems corresponding to and hence  the combination of a 
dp solver  with our ordering heuristic  and conflict-directed backtracking corresponds to an iterative implementation of the divide-and-conquer search conducted by algorithm 1. 
instance table 1: r
 esults on selec 
sat/unsat t instances 
dtree 
time  s  dtree-zchaff time  s  zchaff time  s  hole 1 hole 1 hole 1 1 
1 
1 unsat unsat 
unsat 1 
1 
1 1 
1 
1 1 
1 
1 1 
1 1 unsat 
unsat 
unsat 1 
1 
1 1 
1 
1 1 
1 urq1 
urq1 urq1 1 
1 
1 unsat 
unsat 
unsat 1 
1 
1 1 
1 
1 1 
1 
1 uuf1 uu1 uuf1 uuf1 uuf1 1 
1 
1 
1 
1 unsat 
unsat 
unsat 
unsat 
unsat 1 
1 
1 
1 
1 1 
1 
1 
1 1 
1 
1 
1 
1 uf1 uf1 uf1 uf1 uf1 1 1 
1 
1 
1 sat 
sat 
sat sat 
sat 1 
1 
1 
1 1 
1 
1 
1 1 
1 
1 
1 
1 fpgal1 sat rcr fpgal1 sat rcr fpgal1 sat rcr 1 1 
1 sat 
sat sat 1 
1 
1 1 
1 
1 1 
1 
1 difp 1.arr rcr difp 1 arr rcr difp 1 arrj-cr 1 
1 
1 sat sat 
sat 1 
1 
1 1 
1 
1 1 
1 
1 difp 1 wal rcr difp 1 wal rcr difp 1 walrcr 1 1 
1 sat 
sat 
sat 1 
1 
1 1 
1 
1 1 
1 
1 iil1al 1 sat 1 1 1 par 1 1 sat 1 1 1 　we start by offering a brief description of conflict-directed  nonchronological  backtracking and refer the reader to  silva and sakallah  1  for more details. in a dp solver  a variable is instantiated either as a decision or as an implication through unit propagation. in the latter case  the assignments previously made and causing the clause to become unit are recorded as the causes of the implication. these recordings enable a backward construction of an implication graph when a conflict  contradiction  occurs. with careful analysis of the implication graph  conflict-directed backtracking chooses a decision variable such that  by backtracking to it  at least one of the causes of the conflict is eliminated. one key property of this form of backtracking is this. suppose that after instantiating variables v  we split the sat problem into two independent pieces: one involving variables  and the other involving variables vr. we solve the first problem by instantiating variables and then start solving the second problem involving variables only to realize that this problem is not satisfiable under the current settings of variables conflict-directed backtracking is guaranteed not to backtrack to any of the variables in  as it is clever enough to realize that none of these variables are contributing to the contradiction. instead  conflict-directed backtracking is guaranteed to immediately backtrack to some variable in v. hence  even though the two problems are sequenced  the resulting behavior is similar to that of line 1 of algorithm 1. 
　we will now present an important implication of this correspondence we just established . suppose that our cnf has a connectivity graph g  which is known to have a treewidth 
   it is known that a dtree must then exist whose height is log where is the number of clauses  and in which every cutset has size  darwiche  1 . it is also known that running a divide-and-conquer algorithm  such as algorithm 1  on such a dtree will lead to a time complexity of 
 this complexity will then apply to a dp 
solver that uses the group ordering derived from the men-
1 the connectivity graph g is obtained by including a vertex to 
g for each cnf variable  and then adding an edge between two vertices iff their variables appear in the same clause. treewidth is a positive integer that measures graph connectivity: the less connected the graph  the smaller the treewidth. trees have treewidth 1. 

tioned dtree  and employs conflict-directed backtracking.1 
　the time complexity of divide-and-conquer algorithms  such as algorithm 1  can be reduced by caching of results. specifically  each time a call is made to sat c t   the cutsets associated with ancestors of dtree node t are guaranteed to be instantiated to some a. moreover  c is a cnf that results from applying the instantiation a to the original cnf we started with. it is hence possible that the call sat c  t  will be made multiple times for the same c since the original cnf may lead to the same cnf c under different variable instantiations. in fact  if all results of sat c  t  are cached and their rc-computation is avoided  the complexity of the divide-andconquer algorithm given above drops to 1 nexp w    darwiche  1 . this is a linear complexity for any cnf whose connectivity graph has a bounded treewidth. 
　it is interesting to note  however  that for unsatisfiable subproblems  caching is already in place if the dp solver implements a conflict-based learning mechanism  as is the case with zchaff. hence  not only does the use of our ordering heuristic on top of zchaff correspond to the divide-andconquer algorithm 1  but also to a version of it where unsatisfiable sub-problems are cached so they are not conquered again. there is still an opportunity though to improve performance by caching solutions of satisfiable sub-problems  but that would require a more substantial modification to a dp solver  which is beyond the scope of this paper. 
　we close this section by a note on static versus dynamic variable ordering heuristics. a static heuristic is one which fixes the variable order before search has started. a dynamic heuristic computes the order during search and is more promising from a pruning viewpoint since the ordering of variables can be done in the context of existing variable settings. however  dynamic heuristics can incur substantial overhead. our proposed ordering heuristic is neither static nor dynamic  since the order of variables within a group is decided dynamically  while the order of groups is determined statically. a related static variable ordering heuristic is mince  aloul et al  nov 1   which is mostly for obdds but applies to sat problems as well. mince is also a structural heuristic  but has a different semantics than that of our heuristic. moreover  although the integration of mince with zchaff has been attempted  no experimental results are provided to this effect in  aloul et al  nov 1  except for saying  our preliminary experiments with the recently published chaff sat solver indicate that mince is not helpful on most standard benchmarks.  mince was shown to be quite helpful in conjunction with grasp  silva and sakallah  1  though  but the benchmarks used appear too easy for zchaff. in particular  mince did best on pigeonhole  iii 1 and par 1 which are among the more difficult problems tried  but they become easy problems for zchaff; see table 1. 
1 	conclusion 
we have proposed a structure-based variable ordering heuristic for use by sat solvers based on davis-putnam search. we have shown that when the ordering heuristic is used by a solver that employs conflict-directed backtracking  it leads to a divide-and-conquer behavior in which the sat problem is divided recursively into smaller problems that are solved independently. based on this decompositional behavior  one can then provide formal guarantees on the complexity of dp solvers in terms of the structure of given sat problems. we have implemented this heuristic on top of the fastest sat solver published-zchaff- -where we demonstrated its effectiveness in significantly boosting performance on a range of benchmarks. the proposed ordering works particularly well on the pigeonhole  fpga-unsat  and urq instances  all of which are unsatisfiable theories with structure. 
acknowledgment 
this work has been partially supported by nsf grant iis1 and muri grant n1-1. 
