 
　in expert systems  hierarchical reasoning can provide better accuracy and understandability. here  we develop a method of learning hierarchical knowledge from a case library  in which each training instance is described by low level features and high level concepts  e.g.  manifestations and diseases  but not by intermediate concepts  e.g.  disease states . learning intermediate knowledge involves exploiting the old partial intermediate knowledge or creating new intermediate concepts by observing the relationship between the low level features and high level concepts. experiments in the domain of diagnosing causes of jaundice validate the method. 
	i 	introduction 
　in expert systems  hierarchical reasoning can provide better accuracy and understandability. descriptions of intermediate states partially summarize and categorize subsets of the data and thus allow a reasoning system to reason from initial data to final conclusions in orderly stages. in mycin  for example  an inferred intermediate state of the patient is  compromised host   i.e.  a person whose immune system has been lowered. it is neither a piece of primary  observed data  called here a low level node  nor a final diagnostic category  called here a high level node . using intermediate nodes  in's  allows the reasoning to proceed in smaller steps. it also allows the system to exploit the familiarity of some in's for purposes of explanation  clancey 1 . finally  in's may provide a partial interpretation of the data that is useful even when insufficient data are available for a complete interpretation. the reasoning hierarchy may be diagramed as figure 1. 
intermediate nodes can be names of  a  generalized findings  e.g.  clinical syndromes  which often start out as almost arbitrary labels for collections of findings ;  b  generalized disease classes  e.g  mycin inferred  meningitis  before it inferred  bacterial meningitis  ;  c  intermediate concepts that are neither final solutions nor primary data  e.g.   compromised host  in mycin . 
　*this report describes work done in the computer science department at stanford university it was supported in part by the advanced research project agency under the contract darpa n1-c-1  national institute health under the grant nih rr-1. and national aeronautic space administration under the grant n ao-1. we are grateful for the computer time on the sumex-aim resource. 
　in building a knowledge base for an expert system  it is useful to include in's for the three reasons just cited. if the knowledge base is built through knowledge engineering  an expert can supply the appropriate in's. if it is constructed automatically  however  the learning program must be able to supply the in's if the cases from which it learns are described in terms of ln's and categorized in terms of hn's. thus the problem we are addressing in this paper can be described as; 

in the above formulation       represents a specific link in a training instance;   =     represents general inferential knowledge  a rule . that is  we intend to learn general intermediate knowledge from a set of very specific descriptions.  note that   l n   can be conjunction of more than one feature.  practically  this is an important issue and worthwhile to explore because  for instance  medical records are often described only by clinical manifestations and disease diagnoses  there is no or limited discussion of the involved intermediate mechanisms . 

l.-m. fu and b. buchanan 
　two sets of learning methods are described below to cover two important cases: 
1. intermediate nodes already exist in the initial vocabulary; 
1. intermediate nodes are not in the initial vocabulary. 
in the first situation  the learning task involves exploiting the old partial  incomplete  intermediate knowledge to learn new intermediate knowledge; the partial knowledge may exist between ln and in  or between in and hn  or both. the task in the second situation is comparatively more abstract and constructive  because it involves creating and defining new intermediate concepts which are not provided in the original vocabulary. in inductive concept learning  automatically adding new symbols is one way to mitigate the bias induced by the fixed language  utgoff 1|. 
　the link from manifestations to a disease  in =   hn  is called an inference  or diagnostic  rule  the opposite  hn =  in  is called a descriptive rule. we focus here on learning diagnosuc rules that include intermediate concepts  i.e.  ln =  in =  hn . we first describe the learning techniques when the intermediate concepts arc 
already in the initial language  and then describe the method when the intermediate concepts are not in the language. finally  we describe results in which learned rules are tested in the context of a program named jaundice  an expert system for diagnosing the causes of jaundice  see  fu 1  . 
	ii 	intermediate concepts in the 
initial vocabulary 
   in mis section  we assume there is some knowledge about the intermediate nodes  in  including partial but not complete knowledge about their relationship with other nodes at other levels  ln or hn . we also assume each training instance is characterized only by ln and hn and not by in. if each training instance is characterized with low level descripuons  ln  and the associated intermediate  in  and high level concepts  hn   we can apply machine learning algorithms level by level and discover new knowledge in different levels. 
   basically  two methods are used to search the space of connections of ln's to in's and in's to hn's: bottom-up and top-down. the bottom-up method relies on the existing knowledge of  ln   =   in ; the top-down method relies on the existing knowledge of  in   =   hn . therefore  if only knowledge of linkages between ln's and in's is available  only the bottom-up method can be used; likewise if only knowledge of linkages between in's and hn's is available  only the top-down method can be used. if both types of knowledge are available  but incomplete  otherwise there is nothing to be learned   both methods can be applied and the results will be the union of results from each method. a third method called  bidirectional extension  employs these two basic methods bidirectionally and sequentially in order to construct more complex hierarchical concepts. 
	a. 	bottom-up learning 
   if the knowledge about  ln =  in  is available  this method can be adopted. the task of learning under this situation is described as follows: 
given: 1. a set of training instances 
 or a set of ln -  hn ; 
1. rules linking ln and in  in the direction of ln =  in. 
find: rules of the form in =  hn  consistent with the training instances. 
fach training instance is represented as a set of ln's and is classified on the basis of some hn. remember that hn is a class name  or a disease in medicine . the basic idea behind this method is to generalize from instances of the same hn. in the jaundice experiments  a set of rules in the form of   i n =  hn  arc first learned  the method is not described here for reasons of space; it is described in  fu 1   from the given set of training instances; then we treat this set of rules as another set of training instances  more general than the original training set  of course  and apply the following procedure to learn intermediate rules. 
 suppose there arc n hn's: h1  h1 hi hn  in the set of final hypotheses. the algorithm proceeds as follows: 
for i = l to n  do: 
  step 1. label all instances associated with the class of h1 as positive instances and label other instances as negative instances. 
  step 1. generalize from positive instances by using the concept hierarchical tree. the generalization should: o be maximally specific to avoid over-generalnation; 
o be tested against negative instances. 
intermediate nodes are involved and intermediate links  in =  hn  are discovered during the process of generalization via hierarchy  see the following example . 
step 1 proceeds as follows: 
  substep 1 initialize the hypothesis space h with the set of all positive instances; i.e.  each positive instance represents one hypothesis in h. for example  if h1 is the first instance of class hi  we formulate one hypothesis in h as follows: h1 =  hi. kach hypothesis in h is associated with a degree of certainty  which is estimated from the statistics among instances. 
  substep 1 for each hypothesis hi in h  starting from the head of h   do the following: 
o form set h* by finding all hypotheses in h with the same range of degree of certainty  ＼..1  as hi  h excludes hi . 

o for each element hj in h*  find the common maximally specific generalization  called hk  of hi and hj. hk is plausible if it does not break the following constraints: its associated degree of certainty is at least  .1  and in the same range as hi's and it should not cover more than 1% of all negative instances.** if it is plausible  then retain it  hk   put it in the end of h  and prune hi from h. if no element in h* can form a plausible generalization  without breaking the constraints above  with hi or h* is an empty set  then output hi as a new rule and prune it from h. 
  substep 1 also  remove redundant hypotheses from h. 
  substep 1 repeat substeps 1 and 1 until h is empty. 
this data-driven algorithm differs from the version space approach 
 mitchell 1  in that this algorithm considers not only that there may be multiple rules for each concept but also that an instance may be covered by several rules instead of a single rule. 
   in the following simplified example  we assume that no uncertainty is involved and that two hypotheses are mutually exclusive.  both assumptions can be removed.  

	l-m. fu and b. buchanan 	1 
   in jaundice  for example  the two instances   esophageal varices =   hepatic cirrhosis  and  ascites =   hepatic cirrhosis   may be generalized into  portal hypertension =  hepatic cirrhosis  by using the existing knowledge   esophageal varices =  portal hypertension  and  ascites =   portal hypertension . 
　this technique is extended from the technique of climbing the generalization tree  which is used in other work  such as  winston 1  and  michalski 1a . however  we emphasize a concept hierarchy instead of a value hierarchy. moreover  uncertainty may be involved in the hierarchy. 
	b. 	top-down learning 
   if knowledge exists linking in's and hn's  the technique of topdown learning can be applied. the task is formulated as follows: 

in order to learn rules of the form of  ln =  in   we may first  based on the available knowledge of  hn =  in   re-label training 


　　we do not consider the minimal generality here because  as stated earlier  this method is applied to the set of rules learned; therefore they are already sufficiently general. 

instances such that they have new class names which are in instead of hn. the algorithm used in learning  ln =  hn  is then applied to the transformed instances  and the results will be  ln =  in  which is consistent with the training instances. 
in jaundice  for example  three diseases  acute hepatitis   
 chronic hepatitis   and  hepatic cirrhosis   can be transformed into a common intermediate pathological category   hepatocellular injury   and the inference rules for  hepatocellular injury  are learned from the same case library by the same learning method we use to learn the inference rules for each disease. 
	c. 	bidirectional extension strategy 
　this strategy combines the bottom-up and top-down methods to learn more complex hierarchical concepts. consider a four-level hierarchy as follows: 

l.-m. fu and b. buchanan 

figure1. diagram of the bidirectional extension strategy. solid links represent existing knowledge; dotted links represent knowledge to be explored. 

view this learning task as a search  it actually proceeds bidirectionally. whether the procedure starts bottom-up or top-down does not matter if we assume the training instances are correct and complete. in a domain without uncertainty  consider when inconsistency occurs in the following three instances  hi and h1 are mutually exclusive :  li & hi    li & h1   and  l1 & hi   and assume we have existing knowledge as follows: li =  ii  l1 =   ii  hi =  iii  and h1 =  1; then starting with the top-down method  we can first find the following consistent  i.e.  no inconsistency  intermediate knowledge: l1 =  iii  whereas starting with the bottom-up method  we find no consistent intermediate knowledge. in the current implementation  we ignore such inconsistency. 
key issue is when and how to create new intermediate concepts. two techniques are introduced: the technique of naming taxonomy points and naming switchover points. 
	a. 	technigue pf naming taxonomy points 
　we assume there are n classes of objects or concepts in the instance space. the algorithm proceeds as follows: 
  step 1. construct a taxonomy tree on the basis of a similarity or dissimilarity measurement. one way of measuring dissimilarity is based on the of  sum of  the absolute value  of the differences of weighted individual features   though non-linear functions can also be tried . first  based on the domain knowledge  select some important features and assign them weighung factors. second  calculate the difference between the average value of an individual feature for the given two classes. if the feature values arc not numerical  transform them into numerical values on the basis of domain knowledge. in medicine  this is a feasible approach because the clinical feature values can be quantized according to the clinical 
severity.  however  in some domains  symbolic measurements may be necessary. one example of clustering by a non-numerical technique is seen in  michalski 1b .  for example  in jaundice  the elevation of the serum enzyme is quantized into 1  1  1 and 1  representing normal  mildly-elevated  moderatelyelevated and highly-elevated. third  calculate the sum of the differences of weighted individual features. using different dissimilarity functions  i.e.  using different features or different weighting factors  may yield different results. so  it is possible to build more than one taxonomy tree. 

   in the example of a four-level hierarchy  we can still obtain the knowledge of all levels by using the bottom-up method alone if only the knowledge of  ln   =   inlevel and   i n     =   in | e v e l   is available  or by using the top-down method alone if only the knowledge of  inlevel =   hn  and  inlevel =   lnlevel1  is available. hence  it is possible to obtain even more complex hierarchical concepts by applying these two methods sequentially  depending on the available knowledge. 
　one example cited from jaundice is as follows. initially  there are three rules in the form of  ln =   hn :  malaise =   hepatitis    fatigue =  hepatitis   and  poor appetite =  hepatitis . these rules are generalized to the form of  ln l e v e l 1 =  hn  by using the bottom-up method:  constitutional symptoms =   hepatitis . this rule subsequently results in another rule in the form of  in l e v e l l =  inlevel1 by using the top-down method:  constitutional symptoms =   hepatocellular injury . 
	ill 	intermediate concepts not in the 
initial vocabulary 
　sometimes intermediate concepts arc not already specified in the initial vocabulary  so it is necessary to create and define them. the example 1. computation of dissimilarity between two diseases in a library of four cases. the weights of the two features used are assumed equal here for simplicity. 


	l-m. fu and b. buchanan 	1 
then we set up a criterion to group different classes in a 

common category if their mutual dissimilarities are smaller than a certain threshold. the criterion should be set in a way such that one class will not be grouped in two different categories. in a taxonomy tree  the tip nodes are hn in our terminology  and each non-tip node  excluding the root node  represents an in. 
  step 1. assign a symbol to every intermediate node in taxonomy tree  and thus create new intermediate concepts  in   see figure 1 . 

figure1. suppose a simple taxonomy tree is built for objects  the intermediate taxonomy points are named as goooa and g1b. 
  step 1. the taxonomy tree gives us the knowledge about  hn =  in . for example  in figure 1   if x is a member of class 1 then x is in category goooa . therefore  we can apply the top-down method  described previously  and learn the knowledge of the form  ln =  in . 
  step 1. learn knowledge of the form  in =  h n   which is the link from in  or mixed in and ln  to hn by the following procedures: 
o first  learn discrimination rules for different classes  hn  under the same intermediate category  i.e.  under a higher taxonomical category  after removing all instances which do not belong to it thus  these rules are  local  rules in the sense that they are only good for a certain intermediate category. for example  in figure 1  we may learn classification rules for class 1 and class 1 in the category goooa by removing all instances that are not in the category goooa. suppose we obtain such a classification rule for class 1 as follows: 
 if an object has attribute l1 then it belongs to class 1.  
o second  we actually can write a more specific rule as follows: 
 if an object is in category goooa and has attribute l1 
then it belongs to class 1.  

　in jaundice by applying this technique to 1 cases  we found five concepts  see table 1 . four symbols  after medical interpretation  were found to correspond to  hepatocellular injury    cholestasis    intrahepatic jaundice   and  extrahepatic jaundice  in the initial vocabulary of jaundice. a fifth term   hemo-gilb   was found because two diseases   hemolysis  and  congenital conjugation defect  e.g.  gilbert's disease   are similar and under the same taxonomy point though clinically meaningful  negative bilirubinuria   the symbol  hemo-gilb  bears little pathophysiological meaning. 

note that this technique is intended to discover new intermediate concepts  but the concepts may have already been in the vocabulary. hence  after new symbols are created  they should be checked whether they are equivalent to the old symbols semantically. of course  this depends on the size of the case library  so we may want to keep redundant concepts around for a while. 
	b. 	technique of naming switchover points 
　the development of this technique is motivated by the observation that intermediate concepts often serve as switchover points between subsets of nodes in a reasoning network. one heuristic rule behind this technique is: 
hrl: if i  there are subsets of n ln's and m hns such that all n ln's have  confirming  links to all m hn's  
ii  n l and m l and mnm. 
then it is worthwhile to define a common intermediate node. 
note that this is a cautious strategy in that every member of one subset is linked to every member of the other. we have not explored weaker forms of this heuristic that would increase the risk of incorrect inferences. this heuristic rule is also represented in figure 1. 

l-m. fu and b. buchanan 

figure 1. creating new intermediate nodes at switchover points. 
since if one set of ln's  call it set l  and one set of hn's  call it set 
h  satisfy this rule  then any subset of set l and any subset of set h can also satisfy this rule  we determine that the intermediate node be defined on the basis of the largest sets  subsets or supersets of set l and set h  of ln's and hn's which satisfy this rule. the second condition of this heuristic rule is  in fact the threshold of the complexity of the relationship between ln and hn for defining new symbols. we deliberately choose this threshold because of the fact that  for a given situation which satisfies this rule  descriptions of the inference behavior are simplified by adding a common intermediate node while all links from ln's to hn's are maintained via the intermediate node  i.e.. no links from ln to hn are added or removed . for example  in figure 1  there are 1 links  ln =  hn  initially and 1 links  ln =   in and in =  hn  after introducing an intermediate node. consider a case where there are 1 ln's and 1 hn's and 1=1 links initially; only 1 links are needed after introducing a common intermediate node. but if n = 1 or m= 1 or nm=1  e.g.  n=1 and m = 1   the descriptions of inference behavior will not be simplified by adding a common intermediate node. note that we can control the number of newly defined intermediate nodes  concepts  by adjusting the threshold of complexity for defining them  i.e.  adjusting the second condition of the described heuristic rule . 
　creating a new intermediate node will face another problem if uncertainty is involved. for the example shown in figure 1  the final degree of certainty of h1 and h1 concluded from l1  l1 and l1 should remain approximately the same before and after introduction of intermediate concepts. the degrees of certainty  or cf  are assigned to new links in such a way as to preserve these final degrees of certainty. see  fu 1  for details. 
　in our experiment  heuristic rule hr1 is applied to a set of rules  ln =  hn  which are learned from training instances  ln -  hn   and can be applied recursively  as long as there are plausible switchover points  to form a multi-level network. by applying this technique to the jaundice domain  totally there are nine symbols created  which are shown in table 1. medical terminology has been introduced by the user. this renaming and using existing terminology must be done carefully to avoid the confusion that usually arises when old terms are used in new ways. among these nine created symbols  four symbols are outside the initial  old  vocabulary and five symbols are semantically equivalent to some old symbols. it is also noticed that there is some overlap of the results from the technique of naming taxonomy points and from the technique of naming switchover points. the fact that most of the created symbols are medically meaningful is expected because an table1. new symbols created by the technique of naming switchover points. 
symbols medical interpretation* neosyml benign hepatic pathology* neosym1 cholestasis neosym1 chronic liver failure neosym1 complete b i l i a r y obstruction* neosym1 extrahepatlc jaundice neosym1 hepatobiliary pathology neosym1 liver cachexia* neosym1 inflammation* neosym1 hepatocellular 	injury  : the interpretation 1s made by observing the involved features  ln  and diseases  hn . 
+: these symbols are outside the i n i t i a l vocabulary. 
intermediate symbol is created only when there is a regular relationship between ln and hn  represented by the heuristic rule ; and most of these relationships have been discovered and named in the last 1 years. 
	iv 	results 
　this section describes the application of the developed method to constructing a hierarchical knowledge base for a rule-based system named jaundice  whose task is diagnosing causes of jaundice from 
clinical manifestations. 
the procedures are as follows: 
  step 1. learn the direct inference rules  ln =   hn  from the given set of training instances  the method is described in  fu 1  . 
  step 1. suiting from partial or no intermediate knowledge  explore the intermediate knowledge by all methods that include bottom-up  top-down  bidirectional extension  naming taxonomy point  and naming switchover point  as much as possible. two things are expected: first  some methods may not work because of incomplete knowledge  e.g.  the bottom-up method cannot be adopted when knowledge of the form  ln =  in  is missing; second  the results from different methods may be redundant. the first problem is handled simply by abandoning the methods that cannot apply. the second problem can be solved by checking and removing redundancy. the symbols created by naming taxonomy points and naming switchover points must be interpreted before checking redundancy with old symbols and new symbols already created. the interpretation can be made automatically by observing the involved ln and hn  see tables 1 and 1 . at this stage  the knowledge base under construction has knowledge of three types: ln =  in  
i n =   h n   a n d l n =   h n . 

  step 1. replace direct rules  ln =  hn  by intermediate rules  ln =   in  and in =  hn  if they are equivalent. by  equivalent   we mean the same conclusion  hn  with the same strength  degree of certainty  allowing an error of  1   can be reached  given a set of low-level features 
 ln . for instance  in jaundice  a direct rule  negative bilirubinuria and elevated urobilinogen =  hemolysis  can be replaced by the rule  negative bilirubinuria and elevated urobilinogen =  overproduction of bilirubin  and the rule 
 overproduction of bilirubin =  hemolysis . note that one direct rule may be replaced by several intermediate rules. 
after this procedure  the knowledge base contains hierarchical concepts  but will also contain some simple associations of the form  ln =   hn  which cannot be explained by intermediate concepts. 
   in the jaundice experiment  we constructed a hierarchical knowledge base from a training set of 1 jaundice cases collected from the medical literature. the automatically constructed knowledge base has 1 rules including 1 intermediate rules  rules involved with intermediate concepts . we then compared this new knowledge base with an old knowledge base of 1 rules  which was built by encoding medical knowledge from textbooks and journals and is also hierarchically structured. first  we tested each knowledge base on the original 1 cases; the diagnostic accuracy of the new vs. the old knowledge base is 1% vs. 1%. but since the new knowledge base is based on these 1 training cases  its better 
	l-m. fu and b. buchanan 	1 
performance is somewhat expected. therefore  we further tested the knowledge base on 1 other cases obtained from stanford medical center; these cases received liver biopsy in 1 and were not all diagnosable from clinical parameters alone. the diagnostic accuracy of the new vs. old knowledge base is  not every clinical case is clinically diagnosable because a disease may be in its incipient stage without full manifestation. thus we remove all nondiagnosable cases among these 1 cases  in which the pre-biopsy diagnosis made by the physician who sent the biopsy does not coincide with the biopsy diagnosis.  although some error may be introduced by using the diagnosis of the attending physician as a  gold standard   this is preferable to the bias that would have been introduced if we had selected the cases that were not diagnosable from clinical parameters alone.  on the 1 remaining diagnosable cases  the diagnostic accuracy is 1% vs. 1%. the result of  paired t test  shows  t= 1   which indicates the null hypothesis is accepted  or there is no significant difference between results obtained from the new kb and the old kb  see table 1 . the 1% difference in results may be ascribed to the fact that many more cases than 1 are needed to learn rules for even a well-circumscribed domain. textbooks  after all  encode summaries of considerably more experience. 


 : among the 1 test cases  1 cases are not diagnosable from clinical parameters alone  refer to text descriptions . 

l-m. fu and b. buchanan 
if we turn off the intermediate knowledge learner and learn only direct rules  i.e.  only step 1 described above is turned on   we obtain a knowledge base of 1  direct  rules; this knowledge base without intermediate knowledge can save execution time to some extent if 
compared with the knowledge base of 1 rules  recall that the average system execution time is roughly proportional to the number of rules in the knowledge base . but the diagnostic accuracy tested by the 1 diagnosable liver biopsy cases drops to 1%  vs. 1% if intermediate knowledge is added . here  we may notice there is a tradeoff between execution time and quality of performance. 
　we further notice that cases which can be diagnosed correctly by the knowledge base with intermediate knowledge and cannot be diagnosed correctly without intermediate knowledge are cases with incomplete data. it seems clear that intermediate knowledge can improve the system prediction power particularly if only partial information is available. moreover  intermediate knowledge provides much better understandability and explanation capability. for instance  in our experimental domain  the incorporation of intermediate knowledge can explain the underlying pathological and anatomical mechanisms of jaundice and make the diagnosis more convincing. 
	v 	related work 
related work on creating new descriptors or concepts includes 
eurisko lenat 1   bacon  langley 1   and  utgoff 1 . the principal difference is our explicit attempt to discover new intermediate concepts to construct a reasoning hierarchy. however  from the viewpoint of establishing a conceptual hierarchy  the most representative related work in ai is  michalski 1b . but it differs from our work in at least two aspects. first  our work deals with not only conceptual clustering but finding the intermediate links. second  because each training instance is also characterized by a high level concept besides low level descriptions  the search for the meaningful intermediate concepts is constrained bidirectionally  from ln and from hn . 
	vi 	conclusion 
　we expect the methods described here can be easily extended to non-medical domains. in learning intermediate knowledge  we use a general concept hierarchy; and the heuristics we use to discover intermediate knowledge are not specific to medicine. the major contribution of this idea is its capability of learning intermediate-level concepts from a set of training instances that are described only by low level features and high level concepts and not by any intermediate concept 
acknowledgments 
　we thank dr. gabriel garcia and dr. peter b.gregory for providing us with liver biopsy cases in stanford medical center  which were used to help validate the learning method presented here. 
