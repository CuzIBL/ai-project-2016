
unsupervised information extraction  uie  is the task of extracting knowledge from text without using hand-tagged training examples. a fundamental problem for both uie and supervised ie is assessing the probability that extracted information is correct. in massive corpora such as the web  the same extraction is found repeatedly in different documents. how does this redundancy impact the probability of correctness 
this paper introduces a combinatorial  balls-andurns  model that computes the impact of sample size  redundancy  and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. we describe methods for estimating the model's parameters in practice and demonstrate experimentally that for uie the model's log likelihoods are 1 times better  on average  than those obtained by pointwise mutual information  pmi  and the noisy-or model used in previous work. for supervised ie  the model's performance is comparable to that of support vector machines  and logistic regression.
1 introduction
information extraction  ie  is the task of automatically extracting knowledge from text. unsupervised ie  uie  is ie in the absence of hand-tagged training data. because uie systems do not require human intervention  they can recursively discover new relations  attributes  and instances in a rapid  scalable manner as in knowitall  etzioni et al.  1; 1 .
　a fundamental problem for both supervised ie and uie is assessing the probability that extracted information is correct. as explained in section 1  previous ie work has used a variety of techniques to address this problem  but has yet to provide an adequate formal model of the impact of redundancy-repeatedly obtaining the same extraction from different documents-on the probability of correctness. yet in massive corpora such as the web  redundancy is one of the main sources of confidence in extractions.
　an extraction that is obtained from multiple  distinct documents is more likely to be a bona fide extraction than one obtained only once. because the documents that  support  the extraction are  by and large  independently authored  our confidence in an extraction increases dramatically with the number of supporting documents. but by how much  how do we precisely quantify our confidence in an extraction given the available textual evidence 
　this paper introduces a combinatorial model that enables us to determine the probability that an observed extraction is correct. we validate the performance of the model empirically on the task of extracting information from the web using
knowitall.
our contributions are as follows:
1. a formal model that  unlike previous work  explicitlymodels the impact of sample size  redundancy  and different extraction rules on the probability that an extraction is correct. we analyze the conditions under which the model is applicable  and provide intuitions about its behavior in practice.
1. methods for estimating the model's parameters in boththe uie and supervised ie tasks.
1. experiments that demonstrate the model's improved performance over the techniques used to assess extraction probability in previous work. for uie  our model is a factor of 1 closer to the correct log likelihood than the noisy-or model used in previous work; the model is 1 times closer than knowitall's pointwise mutual information  pmi  method  etzioni et al.  1   which is based on turney's pmi-ir algorithm  turney  1 . for supervised ie  our model achieves a 1% improvement in average log likelihood over the noisy-or model  but is only marginally better than svms and logistic regression.
　the remainder of the paper is organized as follows. section 1 introduces our abstract probabilistic model  and section 1 describes its implementation in practice. section 1 reports on experimental results in four domains. section 1 contrasts our model with previous work; the paper concludes with a discussion of future work.
1 the urns model
our probabilistic model takes the form of a classic  ballsand-urns  model from combinatorics. we first consider the single urn case  for simplicity  and then generalize to the full multiple urns model used in our experiments. we refer to the model simply as urns.
　we think of ie abstractly as a generative process that maps text to extractions. extractions repeat because distinct documents may yield the same extraction. for example  the web page containing  scenic towns such as yakima...  and the web page containing  washington towns such as yakima...  both lead us to believe that yakima is a correct extraction of the relation city x .
　each extraction is modeled as a labeled ball in an urn. a label represents either an instance of the target relation  or an error. the information extraction process is modeled as repeated draws from the urn  with replacement. thus  in the above example  two balls are drawn from the urn  each with the label  yakima . the labels are instances of the relation city x . each label may appear on a different number of balls in the urn. finally  there may be balls in the urn with error labels such as  california   representing cases where the ie process generated an extraction that is not a member of the target relation.
formally  the parameters that characterize an urn are:
  c - the set of unique target labels; |c| is the number of unique target labels in the urn.
  e - the set of unique error labels; |e| is the number of unique error labels in the urn.
  num b  - the function giving the number of balls labeled by b where b （ c “ e. num b  is the multi-set giving the number of balls for each label b （ b.
　of course  ie systems do not have access to these parameters directly. the goal of an ie system is to discern which of the labels it extracts are in fact elements of c  based on repeated draws from the urn. thus  the central question we are investigating is: given that a particular label x was extracted k times in a set of n draws from the urn  what is the probability that x （ c 
　in deriving this probability formally below  we assume the ie system has access to multi-sets num c  and num e  giving the number of times the labels in c and e appear on balls in the urn. in our experiments  we provide methods that estimate these multi-sets in both unsupervised and supervised settings. we can express the probability that an element extracted k of n times is of the target relation as follows:
first  we have that
p xappearsk timesinndraws|x （ c  =

where s is the total number of balls in the urn  and the sum is taken over possible repetition rates r. then we can express the desired quantity using bayes rule:
p x （ c|xappearsk timesinndraws  =
p xappearsk timesinndraws|x （ c p x （ c 
		 1 
p xappearsk timesinndraws 
　note that these expressions include prior information about the label x - for example  p x （ c  is the prior probability that the string x is a target label  and p num x  = r|x （ c  represents the probability that a target label x is repeated on r balls in the urn. in general  integrating this prior information could be valuable for ie systems; however  in the analysis and experiments that follow  we make the simplifying assumption of uniform priors  yielding the following simplified form: proposition 1
p x （ c|xappearsk timesinndraws  =

1 the uniform special case
for illustration  consider the simple case in which all labels from c are repeated on the same number of balls. that is  num ci  = rc for all ci （ c  and assume also that num ei  = re for all ei （ e. while these assumptions are unrealistic  in fact  we use a zipf distribution for num b  in our experiments   they are a reasonable approximation for the majority of labels  which lie on the flat tail of the zipf curve.
　define p to be the precision of the extraction process; that is  the probability that a given draw comes from the target relation. in the uniform case  we have:

　the probability that a particular element of c appears in a given draw is then pc = |cp|  and similarly.
　using a poisson model to approximate the binomial from proposition 1  we have:
p x （ c|xappearsk timesinndraws  「

　in practice  the extraction process is noisy but informative  so pc   pe. notice that when this is true  equation  1  shows that the odds that x （ c increase exponentially with the number of times k that x is extracted  but also decrease exponentially with the sample size n.
　a few numerical examples illustrate the behavior of this equation. the examples assume that the precision p is 1. let |c| = |e| = 1. this means that rc = 1 〜 re- target balls are nine times as common in the urn as error balls.
now  for k = 1 and n = 1 we have p x （ c  =
1%. thus  we see that a small number of repetitions can yield high confidence in an extraction. however  when the sample size increases so that n = 1  and the other parameters are unchanged  then p x （ c  drops to 1%. on the other hand  if c balls repeat much more frequently than e balls  say rc = 1 〜 re  with |e| set to 1  so that p remains unchanged   then p x （ c  rises to 1%.
　the above examples enable us to illustrate the advantages of urns over the noisy-or model used in previous work  lin et al.  1; agichtein and gravano  1 . the noisy-or model assumes that each extraction is an independent assertion  correct a fraction p of the time  that the extracted label is  true.  the noisy-or model assigns the following probability to extractions:
pnoisy or x （ c|xappearsk times  = 1    1   p k
therefore  the noisy-or model will assign the same probability- 1%-in all three of the above examples. yet  as explained above  1% is only correct in the case for which n = 1 and rc = 1〜re. as the other two examples show  for different sample sizes or repetition rates  the noisy-or model can be highly inaccurate. this is not surprising given that the noisy-or model ignores the sample size and the repetition rates. section 1 quantifies the improvements obtained by urns in practice.
1 applicability of the urns model
under what conditions does our redundancy model provide accurate probability estimates  first  labels from the target set c must be repeated on more balls in the urn than labels from the e set  as in figure 1. the shaded region in figure 1 represents the  confusion region  - some of the labels in this region will be classified incorrectly  even by the ideal classifier with infinite data  because for these labels there simply isn't enough information to decide whether they belong to c or e. thus  our model is effective when the confusion region is relatively small. secondly  even for small confusion regions  the sample size n must be large enough to approximate the two distributions shown in figure 1; otherwise the probabilities output by the model will be inaccurate.
　an attractive feature of urns is that it enables us to estimate its expected recall and precision as a function of sample size. if the distributions in figure 1 cross at the dotted line shown then  given a sufficiently large sample size n  expected recall will be the fraction of the area under the c curve lying to the right of the dotted line.
　for a given sample size n  define τn to be the least number of appearances k at which an extraction is more likely to be from the c set than the e set  given the distributions in figure 1  τn can be computed using proposition 1 . then we have:
e truepositives  =

where we define  true positives  to be the number of extracted labels ci （ c for which the model assigns probability p ci （ c    1.
the expected number of false positives is similarly:
e falsepositives  =

　the expected precision of the system can then be approximated as:
e truepositives 
e precision  「 
e falsepositives  + e truepositives 

figure 1: schematic illustration of the number of distinct labels in the c and e sets with repetition rate r. the  confusion region  is shaded.
　for example  consider the particular num c  and num e  learned  in the unsupervised setting  for the film relation in our experiments. for the sample size n = 1 used in the experiments  expected number of true positives is 1 and expected precision is 1%  which is close to the actual observed true positives of 1 and precision of 1%. were we to increase the sample size to 1 1  we would expect that true positives would increase to 1  and precision to 1%. thus  urns and the above equations enable an ie system to intelligently choose its sample size depending on precision and recall requirements and resource constraints  even in the absence of tagged training data.
1 multiple urns
we now generalize our model to encompass multiple urns. information is often extracted using multiple  distinct mechanisms - for example  an ie system might employ several patterns for extracting city names  e.g.  cities including x  and  x and other towns.  it is often the case that different patterns have different modes of failure  so extractions appearing across multiple patterns are generally more likely to be true than those appearing for a single pattern. we can model this situation by introducing multiple urns where each urn represents a different extraction mechanism.1
　thus  instead of n total extractions  we have a sample size nm for each urn m （ m  with the extraction x appearing km times. let a x  k1 ... km   n1 ... nm   denote this event. further  let am x k n  be the event that label x appears k times in n draws from urn m  and assuming that the draws from each urn are independent  we have:
proposition 1

　with multiple urns  the distributions of labels among balls in the urns are represented by multi-sets numm c  and numm e . expressing the correlation between numm x  and numm1 x  is an important modeling decision. multiple urns are especially beneficial when the repetition rates for elements of c are more strongly correlated across different urns than they are for elements of e-that is  when numm x  and numm1 x  tend to be closer to each other for x （ c than for x （ e. fortunately  this turns out to be the case in practice. section 1 describes our method for modeling multi-urn correlation.
1 implementation of the urns model
this section describes how we implement urns for both uie and supervised ie  and identifies the assumptions made in each case.
　in order to compute probabilities for extractions  we need a method for estimating num c  and num e . for the purpose of estimating these sets from tagged or untagged data  we assume that num c  and num e  are zipf distributed  meaning that if ci is the ith most frequently repeated label in c  then num ci  is proportional to i zc. we can then characterize the num c  and num e  sets with five parameters: the set sizes |c| and |e|  the shape parameters zc and ze  and the extraction precision p.
　to model multiple urns  we consider different extraction precisions pm for each urn  but make the simplifying assumption that the size and shape parameters are the same for all urns. as mentioned in section 1  we expect repetition rate correlation across urns to be higher for elements of the c set than for the e set. we model this correlation as follows: first  elements of the c set are assumed to come from the same location on the zipf curve for all urns  that is  their relative frequencies are perfectly correlated. some elements of the e set are similar  and have the same relative frequency across urns - these are the systematic errors. however  the rest of the e set is made up of non-systematic errors  meaning that they appear for only one kind of extraction mechanism  for example   eastman kodak  is extracted as an instance of film only in phrases involving the word  film   and not in those involving the word  movie.  . formally  non-systematic errors are labels that are present in some urns and not in others. each type of non-systematic error makes up some fraction of the e set  and these fractions are the parameters of our correlation model. assuming this simple correlation model and identical size and shape parameters across urns is too restrictive in general- differences between extraction mechanisms are often more complex. however  our assumptions allow us to compute probabilities efficiently  as described below  and do not appear to hurt performance significantly in practice.
　with this correlation model  if a label x is an element of c or a systematic error  it will be present in all urns. in terms of proposition 1  the probability that a label x appears km times in nm draws from m is:

 1 
where fm x  is the frequency of extraction x. that is 
fm ci =pmqci zc forci （ cfm ei = 1   pm qei ze forei （ ein these expressions  i is the frequency rank of the extraction  assumed to be the same across all urns  and qc and qe are normalizing constants such that
	x	 zc x	 ze
	qci	=	qei	= 1
	ci（c	ei（e
for a non-systematic error x which is not present in urn m 
p am x km nm   is 1 if km = 1 and 1 otherwise. substituting these expressions for p am x km nm   into proposition 1 gives the final form of our urns model.
1 efficient computation
a feature of our implementation is that it allows for efficient computation of probabilities. in general  computing the sum in proposition 1 over the potentially large c and e sets would require significant computation for each extraction. however  given a fixed number of urns  with num c  and num e  zipf distributed  an integral approximation to the sum in proposition 1  using a poisson in place of the binomial in equation 1  can be solved in closed form in terms of incomplete gamma functions. this closed form expression can be evaluated quickly  and thus probabilities for extractions can be obtained efficiently. this solution leverages our assumptions that size and shape parameters are identical across urns  and that relative frequencies are perfectly correlated. finding efficient techniques for computing probabilities under less stringent assumptions is an item of future work.
1 parameter estimation
in the event that a large sample of hand-tagged training examples is available for each target relation of interest  we can directly estimate each of the parameters of urns. we use a population-based stochastic optimization technique to identify parameter settings that maximize the conditional log likelihood of the training data.1 once the parameters are set  the model yields a probability for each extraction  given the number of times km it appears in each urn and the number of draws nm from each urn.
　as argued in  etzioni et al.  1   ie systems cannot rely on hand-tagged training examples if they are to scale to extracting information on arbitrary relations that are not specified in advance. implementing urns for uie requires a solution to the challenging problem of estimating num c  and num e  using untagged data. let u be the multi-set consisting of the number of times each unique label was extracted; |u| is the number of unique labels encountered  and the sample size n = pu（u u.
　in order to learn num c  and num e  from untagged data  we make the following assumptions:
  because the number of different possible errors is nearly unbounded  we assume that the error set is very large.1

   1 specifically  we use the differential evolution routine built into mathematica 1.
　　1
　　in our experiments  we set |e| = 1 . a sensitivity analysis showed that changing |e| by an order of magnitude  in either direction  resulted in only small changes to our results.
  we assume that both num c  and num e  are zipf distributed where the ze parameter is set to 1.
  in our experience with knowitall  we found that while different extraction rules have differing precision  each rule's precision is stable across different relations  etzioni et al.  1 . urns takes this precision as an input. to demonstrate that urns is not overly sensitive to this parameter  we chose a fixed value  1  and used it as the precision pm for all urns in our experiments. 1
　we then use expectation maximization  em  over u in order to arrive at appropriate values for |c| and zc  these two quantities uniquely determine num c  given our assumptions . our em algorithm proceeds as follows:
1. initialize |c| and zc to starting values.
1. repeat until convergence:
 a  e-step assign probabilities to each element of u using proposition  1 .
 b  m-step set |c| and zc from u using the probabilities assigned in the e-step  details below .
we obtain |c| and zc in the m-step by first estimating the rank-frequency distribution for labels from c in the untagged data. from the untagged data and the probabilities found in the e-step  we can obtain ec k   the expected number of labels from c that were extracted k times. we then round these fractional expected counts into a discrete rank-frequency distribution with a number of elements equal to the expected total number of labels from c in the untagged data  pk ec k . we obtain zc by fitting a zipf curve to this rank-frequency distribution by linear regression on a log-log scale. lastly  we set |c| = pk ec k  + unseen  where we estimate the number of unseen labels of the c set using good-turing estimation   gale and sampson  1  . specifically  we choose unseen such that the probability mass of unseen labels is equal to the expected fraction of the draws from c that extracted labels seen only once.
　this unsupervised learning strategy proved effective for target relations of different sizes; for example  the number of elements of the country relation with non-negligible extraction probability was about two orders of magnitude smaller than that of the film and city relations.
　clearly  unsupervised learning relies on several strong assumptions  though our sensitivity analysis has shown that the model's performance is robust to some of them. in future work  we plan to perform a more comprehensive sensitivity analysis of the model and also investigate its performance in a semi-supervised setting.
1 experimental results
this section describes our experimental results under two settings: unsupervised and supervised. we begin by describing the two unsupervised methods used in previous work: the noisy-or model and pmi. we then compare urns with these methods experimentally  and lastly compare urns with several baseline methods in a supervised setting.
　we evaluated our algorithms on extraction sets for the relations city x   film x   country x   and mayorof x y   taken from experiments performed in  etzioni et al.  1 . the sample size n was 1 for city  1 for film  1 for country and 1 for mayorof. the extraction patterns were partitioned into urns based on the name they employed for their target relation  e.g.  country  or  nation   and whether they were left-handed  e.g.  countries including x   or right-handed  e.g.  x and other countries  . each combination of relation name and handedness was treated as a separate urn  resulting in four urns for each of city x   film x   and country x   and two urns for mayorof x .1 for each relation  we tagged a sample of 1 extracted labels  using external knowledge bases  the tipster gazetteer for cities and the internet movie database for films  and manually tagging those instances not found in a knowledge base. in the uie experiments  we evaluate our algorithms on all 1 examples  and in the supervised ie experiments we perform 1fold cross validation.
1 uie experiments
we compare urns against two other methods for unsupervised information extraction. first  in the noisy-or model used in previous work  an extraction appearing k times is assigned probability 1 qm（m 1 pm k  where pm is the extraction precision for urn m. we describe the second method below.
pointwise mutual information
our previous work on knowitall used pointwise mutual information  pmi  to obtain probability estimates for extractions  etzioni et al.  1 . specifically  the pmi between an extraction and a set of automatically generated discriminator phrases  e.g.   movies such as x   is computed from web search engine hit counts. these pmi scores are used as features in a naive bayes classifier  nbc  to produce a probability estimate for the extraction. the nbc is trained using a set of automatically bootstrapped seed instances. the positive seed instances are taken to be those having the highest pmi with the discriminator phrases after the bootstrapping process; the negative seeds are taken from the positive seeds of other relations  as in other work  e.g.   lin et al.  1  .
　although pmi was shown in  etzioni et al.  1  to order extractions fairly well  it has two significant shortcomings. first  obtaining the hit counts needed to compute the pmi scores is expensive  as it requires a large number of queries to web search engines. second  the seeds produced by the bootstrapping process tend not to be representative of the overall distribution of extractions. this combined with the probability polarization introduced by the nbc tends to give inaccurate probability estimates.
discussion of uie results
the results of our unsupervised experiments are shown in figure 1. we plot deviation from the ideal log likelihood- defined as the maximum achievable log likelihood given our feature set.
　our experimental results demonstrate that urns overcomes the weaknesses of pmi. first  urns's probabilities are far more accurate than pmi's  achieving a log likelihood that is a factor of 1 closer to the ideal  on average  figure 1 . second  urns is substantially more efficient as shown in table 1.
this efficiency gain requires some explanation. know-
itall relies on queries to web search engines to identify web pages containing potential extractions. the number of queries knowitall can issue daily is limited  and querying over the web is  by far  knowitall's most expensive operation. thus  number of search engine queries is our efficiency metric. let d be the number of discriminator phrases used by the pmi method as explained in section 1. the pmi method requires o d  search engine queries to compute the pmi of each extraction from search engine hit counts. in contrast  urns computes probabilities directly from the set of extractions-requiring no additional queries  which cuts knowitall's queries by factors ranging from 1 to 1.
　as explained in section 1  the noisy-or model ignores target set size and sample size  which leads it to assign probabilities that are far too high for the country and mayorof relations  where the average number of times each label is extracted is high  see bottom row of table 1 . this is further illustrated for the country relation in figure 1. the noisy-or model assigns appropriate probabilities for low sample sizes  because in this case the overall precision of extracted labels is in fact fairly high  as predicted by the noisy-or model. however  as sample size increases relative to the number of true countries  the overall precision of the extracted labels decreases-and the noisy-or estimate worsens. on the other hand  urns avoids this problem by accounting for the interaction between target set size and sample size  adjusting its probability estimates as sample size increases. given sufficient sample size  urns performs close to the ideal log likelihood  improving slightly with more samples as the estimates obtained by the em process become more accurate. overall  urns assigns far more accurate probabilities than the noisy-or model  and its log likelihood is a factor of 1 closer to the ideal  on average. the very large differences between urns and both the noisy-or model and pmi suggest that  even if the performance of urns degrades in other domains  it is quite likely to still outperform both pmi and the noisy-or model.
　our computation of log-likelihood contains a numerical detail that could potentially influence our results. to avoid the possibility of a likelihood of zero  we restrict the probabilities generated by urns and the other methods to lie within the

city film country mayorof
figure 1: deviation of average log likelihood from the ideal for four relations  lower is better . on average  urns outperforms noisy-or by a factor of 1  and pmi by a factor of 1.
cityfilmmayorofcountryspeedup1x1x1x1xaverage k1111table 1: improved efficiency due to urns. the top row reports the number of search engine queries made by knowitall using pmi divided by the number of queries for knowitall using urns. the bottom row shows that pmi's queries increase with k-the average number of distinct labels for each relation. thus  speedup tends to vary inversely with the average number of times each label is drawn.

figure 1: deviation of average log likelihood from the ideal as sample size varies for the country relation  lower is better . urns performs close to the ideal given sufficient sample size  whereas noisy-or becomes less accurate as sample size increases.
range  1  1 . widening this range tended to improve urns's performance relative to the other methods  as this increases the penalty for erroneously assigning extreme probabilities-a problem more prevalent for pmi and noisyor than for urns. even if we narrow the range by two digits of precision  to  1  1   urns still outperforms pmi by a factor of 1  and noisy-or by a factor of 1. thus  we are comfortable that the differences observed are not an artifact of this design decision.
1 supervised ie experiments
we compare urns with three supervised methods. all methods utilize the same feature set as urns  namely the extraction counts km.
  noisy-or - has one parameter per urn  making a set of m parameters  h1 ... hm   and assigns probability equal to
1   y  1   hm km. m（m
  logistic	regression	-	has	m	+ 1	parameters
 a b1 b1 ... bm  	and	assigns	probability	equal to
.
  svm - consists of an svm classifier with a gaussian kernel. to transform the output of the classifier into a probability  we use the probability estimation built-in to libsvm  chang and lin  1   which is based on logistic regression of the svm decision values.
　parameters maximizing the conditional likelihood of the training data were found for the noisy-or and logistic regression models using differential evolution. in the svm case  we performed grid search to find the kernel parameters giving the best likelihood performance for each training set - this grid search was required to get acceptable performance from the svm on our task.
　the results of our supervised learning experiments are shown in table 1. urns  because it is more expressive  is able to outperform the noisy-or and logistic regression models. in terms of deviation from the ideal log likelihood  we find that on average urns outperforms the noisy-or model by 1%  logistic regression by 1%  but svm by only 1%.
cityfilmmayorcountryaveragenoisy-or11111logistic regression11111svm11111urns11111table 1: supervised ie experiments. deviation from the ideal log likelihood for each method and each relation  lower is better . the overall performance differences are small  with urns 1% closer to the ideal than noisy-or  on average  and 1% closer than logistic regression. the overall performance of svm is close to that of urns.
1 related work
in contrast to the bulk of previous ie work  our focus is on unsupervised ie  uie  where urns substantially outperforms previous methods  figure 1 .
　in addition to the noisy-or models we compare against in our experiments  the ie literature contains a variety of heuristics using repetition as an indication of the veracity of extracted information. for example  riloff and jones  riloff and jones  1  rank extractions by the number of distinct patterns generating them  plus a factor for the reliability of the patterns. our work is intended to formalize these heuristic techniques  and unlike the noisy-or models  we explicitly model the distribution of the target and error sets  our num c  and num e    which is shown to be important for good performance in section 1. the accuracy of the probability estimates produced by the heuristic and noisy-or methods is rarely evaluated explicitly in the ie literature  although most systems make implicit use of such estimates. for example  bootstrap-learning systems start with a set of seed instances of a given relation  which are used to identify extraction patterns for the relation; these patterns are in turn used to extract further instances  e.g.  riloff and jones  1; lin et al.  1; agichtein and gravano  1  . as this process iterates  random extraction errors result in overly general extraction patterns  leading the system to extract further erroneous instances. the more accurate estimates of extraction probabilities produced by urns would help prevent this  concept drift. 
　skounakis and craven  skounakis and craven  1  develop a probabilistic model for combining evidence from multiple extractions in a supervised setting. their problem formulation differs from ours  as they classify each occurrence of an extraction  and then use a binomial model along with the false positive and true positive rates of the classifier to obtain the probability that at least one occurrence is a true positive. similar to the above approaches  they do not explicitly account for sample size n  nor do they model the distribution of target and error extractions.
　culotta and mccallum  culotta and mccallum  1  provide a model for assessing the confidence of extracted information using conditional random fields  crfs . their work focuses on assigning accurate confidence values to individual occurrences of an extracted field based on textual features. this is complementary to our focus on combining confidence estimates from multiple occurrences of the same extraction. in fact  each possible feature vector processed by the crf in  culotta and mccallum  1  can be thought of as a virtual urn m in our urns. the confidence output of culotta and mccallum's model could then be used to provide the precision pm for the urn.
　our work is similar in spirit to blog  a language for specifying probability distributions over sets with unknown objects  milch et al.  1 . as in our work  blog models treat observations as draws from a set of balls in an urn. whereas blog is intended to be a general modeling framework for probabilistic first-order logic  our work is directed at modeling redundancy in ie. in contrast to  milch et al.  1   we provide supervised and unsupervised learning methods for our model and experiments demonstrating their efficacy in practice.
1 conclusions and future work
this paper introduced a combinatorial urns model to the problem of assessing the probability that an extraction is correct. the paper described supervised and unsupervised methods for estimating the parameters of the model from data  and reported on experiments showing that urns massively outperforms previous methods in the unsupervised case  and is slightly better than baseline methods in the supervised case. of course  additional experiments and a more comprehensive sensitivity analysis of urns are necessary.
　urns is applicable to tasks other than ie. for example  pmi computed over search engine hit counts has been used to determine synonymy  turney  1   and for question answering  magnini et al.  1 . in the synonymy case  for example  the pmi between two terms is used as a measure of their synonymy; applying urns to the same co-occurrence statistics should result in a more accurate probabilistic assessment of whether two terms are synonyms. comparing urns with pmi on these tasks is a topic for future work.
acknowledgments
this research was supported in part by nsf grant iis-
1  darpa contract nbchd1  onr grant n1-1  and a gift from google. google generously allowed us to issue a large number of queries to their xml api to facilitate our experiments. we thank anna karlin  marina meila  and dan weld for helpful discussions  and jeff bigham for comments on previous drafts. also  thanks to alex yates for suggesting we consider this problem.
