 
we present a major variant of the graphplan algorithm that employs available memory to transform the depth-first nature of graphplan's search into an iterative state space view in which heuristics can be used to traverse the search space. when the planner  pegg  is set to conduct exhaustive search  it produces guaranteed optimal parallel plans 1 to 1 times faster than a version of graphplan enhanced with csp speedup methods. by heuristically pruning this search space pegg produces plans comparable to graphplan's in makespan  at speeds approaching state-of-the-art heuristic serial planners. 
1 motivation and approach 
despite the recent dominance of heuristic state-search planners over graphplan-style planners  the graphplan approach  blum and furst 1  is still one of the most effective ways to generate so-called  optimal parallel plans . while state-space planners are drowned by the exponential branching factors of the search space of parallel plans  graphplan excels due to the way it combines an ida* style iterative search  bonet and geffner  1  with a highly efficient csp-based  incremental generation of valid action subsets. we present here a system called pegg  that addresses weaknesses in graphplan's approach by employing available memory to: 1  reduce the redundant search graphplan conducts in consecutive iterations  and 1  more importantly  to transform graphplan's ida* search into iterative expansion of a select set of states that can be traversed any order. 
　a shortfall of the ida*'s approach to search is the fact that it regenerates many of the same nodes in each of its iterations. this can be traced to using too little memory in many cases; the only information carried over from one iteration to the next is the upper bound on the fvalue. given that consecutive iterations of search overlap significantly  we investigated using additional memory to store a trace of the explored search tree to avoid repeated re-generation of search nodes. with a representation of the explored search space  we can transform the way this space is extended during the next iteration. in particular  we can  a  expand search trace nodes in the order of their heuristic merit and  b  we may also consider iteratively expanding a select set of states. this strategy is too costly for normal ida* search  but graphplan's type of ida* search is particularly well-suited to these changes as the kth level planning graph provides a compact way of representing the search space traversed by the corresponding ida* search in its kth iteration. the state space view provided by the search trace allows us to transform graphplan's search from its depth-first default to a more informed traversal of the space. 
1 	design and experiments 
　as would be expected for ida* search there is great similarity  redundancy  in the search space for successive search episodes as the plan graph is extended. in fact  the search conducted at any level k+1 of the graph is essentially a replay of the search conducted at the previous level k with certain well-defined extensions. specifically  every set of subgoals reached in the backward search of episode n  starting at level k  will be generated again by graphplan in episode n+1 starting at level k+1. 

figure j. state space view of graphplan's search space: 
1 consecutive search episodes leading to a solution 
figure 1 depicts the state space tree structure corresponding to graphplan's search over three consecutive search iterations on a hypothetical problem. the dark shaded states are first produced during graphplan's attempt to satisfy the xyz goal at level 1. they are generated again in the next episode  each at one level higher  along with some new states  shown in lighter shade . finally  in the third episode graphplan regenerates the dark and lighter shaded states  attempting to satisfy xyz at level 1  and finds a solution. 

1 	poster papers 

　egbg  zimmerman  kambhampati  1  used memory to aggressively record the experience in each search episode  essentially avoiding all redundant effort. that approach confronted memory constraints on larger problems  but it suggests a more powerful use for a pareddown search trace: exploiting the snapshot view of the entire search space of a graphplan iteration to focus on the most promising areas. this transformation frees us from the depth-first nature of graphplan's search  permitting move-
ment about the search space to focus on its most promising sections first -or even exclusively. 
 a summary of pegg  for details;  zimmerman and kambhampati  1   relies on these definitions: search segment: a state generated during graphplan's regression search from the goal state  indexed to a specific plan graph level. it holds the state's goal list  a pointer to the parent search segment  and the actions assigned in satisfying the parent's goals. search trace  st : the linked set of search segments  states  representing the search space visited in a graphplan backward search episode. the sets of states in each of the three shadings of figure 
problem graphplan 1opegg cpu sec 
 steps/acts  pegg 
cpu sec 
 steps/acts   speedup i  pegg vs. 
gp-e  cpu sec  steps/acts  
stnd. 	gp-e bw-large-b 1 1 1  1 1  1  1x bw-large-d ~ ~  1  ~ 1  1 / 1   1x att-log-b -~ ~ 1  1   1x gripper-1 -- 	 1  1 1  1   1x gripper-1 ~ ~  1  ~ 1  1   1x tower-1 ~ ~  1  1 1 1   1x tsp-1 ~ ~  1  1 1  1   1x aips '1  '1  '1 competition problems 	  gripper-x-1 ~ 1  1  1 1  1  1x gripper-x-1 ~ -1 1  1   1x log-y-1 -1  1  1 1  1  1x blocks-1 -1  1  1 1  1  1x blocks-1 ~ -  1  ~ 1  1   1x logistics-1 -1  1  1 1  1  1x logistics-1 --1  1  1  1   1x freecell-1 1  1  1 1 1x depot-1 1 1 1 1 1x depot-1 ~ -  1  ~ 1  1   1x driverlog-1-1 -1  1  1 1 	 1  1x driverlog-1-1 ~ ~ ~ 1  1   1x ztravel-1a -~ 1  1  1  1   1x ztravel-1a -1  1  1 1  1  1x 1 can be seen as the st after each of the three episodes. transposition: the extant trace of search segments  states  after search episode n is transposed up one planning graph level for episode n+1 as follows: for each st search segment associated with graph level j associate it table j. pegg vs. graphplan and enhanced graphplan  gp-e  with level j+1 for episode n+1. visiting a search 
gp-e: enhanced graphplan  sec text  so-pegg step-optimal  search via 
segment: the goals of segment sp are memo the st. pegg: beam search on best 1% of search segments in st 
checked at their associated level and if valid  
- indicates failure in 1 min limit  cpu time 
pegg initiates graphplan's csp-style search to 
                                                           parentheses next to cpu time give # of steps/ # of actions in solution. satisfy them. the process is enhanced by a cadre of 
allegro lisp  runtimes  cxcl. gc time  on pentium 1 mhz  1 mb ram 

efficiency techniques such as a bi-level plan graph  domain preprocessing  explanation based learning  ebl   dependency directed backtracking  ddb   and goal & action ordering. whenever the goals of sp are validly assigned  a child segment is created containing sp's goals regressed over the assigned actions  and linked to sp  thus extending the st . 
 the pegg algorithm: the graph is built until the problem goals appear non-mutex  and the first regression search episode is conducted ala graphplan fashion. during this search  the initial trace is constructed  concisely capturing all 'states' generated during the search process. if no solution is found  the st directs the search process for future iterations. this search is 1-phased: select a promising st state  then graphplan's depth-first  csptype search on the state's subgoals is conducted. another st search segment is heuristically selected if search fails. 
since the st provides a state space view  pegg can use 'distance based' heuristics  c.f. hsp-r  bonet and geffner  1  and altalt  nguyen and kambhampati  1  . for results reported here  the 'adjusted sum' heuristic from the latter is used. 
　table 1 compares pegg against standard graphplan and a highly enhanced version  gp-e   which has been augmented with the efficiency methods mentioned above. two pegg modes of operation are reported; 1  so-pegg: make-span optimal  st search segments ordered according to a state space heuristic  all segments visited  1  pegg: ordering the st search segments as for 1  beam search on only the heuristically 'best' fraction. the first approach maintains graphplan's guarantee of step optimality while the latter sacrifices the guarantee of optimally in favor of pruning search in all search episodes and bounds the size of the search trace that is maintained in memory. empirically we find that optimal make-span plans are generally found by pegg regardless   one exception shown in bold  and speedups as high as two orders of magnitude over enhanced graphplan are achieved. 
