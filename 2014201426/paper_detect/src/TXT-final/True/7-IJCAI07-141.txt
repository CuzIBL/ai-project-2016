
an inescapable bottleneck with learning from large data sets is the high cost of labeling training data. unsupervised learning methods have promised to lower the cost of tagging by leveraging notions of similarity among data points to assign tags. however  unsupervised and semi-supervised learning techniques often provide poor results due to errors in estimation. we look at methods that guide the allocation of human effort for labeling data so as to get the greatest boosts in discriminatorypower with increasing amounts of work. we focus on the application of value of information to gaussian process classifiers and explore the effectiveness of the method on the task of classifying voice messages.
1 introduction
increased sensing and decreased storage costs are leading to the growing availability of large data sets. however  data resources are often unavailable for machine learning and reasoning because of the high cost of labeling cases. as an example  we may have access to several thousand voice messages stored on a server and wish to build a classification system that could automatically classify voicemail messages into different categories. unfortunately  performing supervised learning with the data set would require the manual effort of listening to voice messages and applying labels.
　unsupervised learning shows promise for reducing the effort required for tagging  such as its use in preparing data sets for supervised learning. however  pure unsupervised learning  based on notions of clusters and similarity  is often fraught with labeling errors.
　we believe that there is a rich space of opportunities within the realm of complementary computing  horvitz and paek  1  for machine learning. we focus on the ideal coupling of human supervision with unsupervised methods and we discuss selective supervision  the use of value-of-information to triage human tagging efforts. the active-learning method considers both the cost required to tag data as well as the costs associated with the use of a classifier in a real-world setting. we show how we can minimize the total cost associated with the construction and use of classification systems  where costs are measured in currencies such as monetary quantities or other valuable resources.
　given the cost of labeling previously unlabeled cases and the cost of misclassification-which may be different for different classes-we seek to quantify the expected gain in expected value associated with seeking information on an unlabeled data point. this expected gain  which corresponds to the value of information provided by labeling  is the guiding principle for the active learning framework. we shall show how we can employ this value of information in learning within the gaussian process classification framework and describe the applicability of the approach to both supervised and semi-supervised scenarios.
　after a review of some key work in active learning  we describe the active learning frameworkthat uses expected valueof-information  voi  criterion to triage labeling. then  we present concepts and computational issues with the use of gaussian process classification  and we show how the methods can be extended to handle semi-supervised learning. we highlight the effectiveness of the framework on the task of classifying voice messages and we conclude with experimental results and discussion.
1 background
interest has been growing in recent years in active learning. numerous heuristics and schemes have been proposed for choosing unlabeled points for tagging. for example  freund et al. 1 propose disagreement among the committee of classifiers as a criterion for active learning. tong and koller  1 explore the selection of unlabeled cases to query based on minimizing the version space within the support vector machines  svm  formulation. within the gaussian process framework  the method of choice has been to look at the expected informativeness of an unlabeled data point  mackay  1; lawrence et al.  1 . specifically  the idea is to choose to query cases that are expected to maximally influence the posterior distribution over the set of possible classifiers. additional studies have sought to combine active learning with semi-supervised learning  mccallum and nigam  1; muslea et al.  1; zhu et al.  1 .
　all of these methods inherently focus on minimizing the misclassification rate. we focus on the value of moving to a decision-theoretic framework in active learning  where we consider the costs and risks in real-world currencies and employ computations of expected value of information to balance the cost of misdiagnosis with the costs of providing labels.
1 decision-theoretic active learning
a linear classifier parameterized by w classifies a test point x according to: sign f x    where f x  = wtx. given a set of training data points xl = {x1 .. xn}  with class labels tl = {t1 .. tn}  where ti （ {1  1}  the goal of a learning algorithm is to learn the parameters w. most classification techniques focus on minimizing classification error. however  preferences about the relative numbers of false positives and negatives produced by a classification system can vary by person and task. these preferences can be expressed in terms of real-world measures of cost such as a monetary value and we can seek to minimize the expected cost for the use of a classifier over time. additionally  we have the cost of tagging cases for training  which can vary for cases in different classes or with other problem-specific variables.
　we aim to quantify the values of acquiring labels of different data points and to use computations of these values as a guiding principle in active learning. intuitively  knowing the label of one or more currently unlabeled points may reduce the total risk in the classification task. on the other hand  labels are acquired at a price. the difference in the reduction in the total expected cost of the use of the classifier  which we shall refer to as the risk  and the cost of acquiring a new label is the expected value of information for learning that label. the real-world cost associated with the usage of a classifier is a function of the number of times that a classifier will be used in the real world  so a probability distribution over usage is considered in the computation of expected cost.
　for simplicity  we shall focus in the discussion on twoclass discrimination problems. the methods discussed in the paper can be generalized in a straightforward manner to handle multiple classes. we note that the work presented here makes a myopic assumption  where we only seek to label one data point at a time. this can be generalized by applying lookahead procedures that consider the acquisition of labels for different sets of points.
　let us define the risk matrix r =  rij  （ ir1〜1  where rij denote the cost or risk associated with classifying a data point belonging to class i as j. we use the index 1 to denote the class -1. we assume that the diagonal elements of r are zero  specifying that correct classification incurs no cost. thus  given the labeled set xl with labels tl we can train a classifier f x  and compute the total risk on the labeled data points as:
		 1 
here  pi denotes the probability that the point xi is classified as class +1  i.e. pi = p sign f xi   = 1|xi . further  l+ and l  are the indices of positively and negatively labeled points respectively. note  that pi is the predictive distribution and depending upon the classification technique may or may not be available. predictive distributions are available for gaussian process classification  section 1  and other probabilistic classifiers  including probabilistic mappings of outputs of svms  platt  1 .
　beyond labeled cases  we also have a set of unlabeled data points xu = {xn+1 .. xn+m}  that we wish to classify. we seek to include the total risk associated with the unlabeled data points:
		 1 
here  pi  = p ti = 1|xi  is the true conditional density of the class label given the data point. as we do not have the true conditional  we cannot compute this expression exactly. however  we can approximate pi  with pi; thus  we approximate the total risk on the unlabeled data points as:
		 1 
now  let ci denote the cost of knowing the class label of xi. we assume that the costs ci and the risks r1 and r1 are measured with the same currency. this assumption does not impose significant constraints as different currencies can be transformed into a single utility by using appropriate realworld conversions.
　given the risks  jl and ju   we approximate1 the expected misclassification cost per point as. assuming a closed world  where the system only encounters the n + m points in xl “ xu  the expected cost is the sum of the total risk  jall =  n + m j．  and the cost of obtaining the labels:
		 1 
upon querying the new point  we may see a reduction in the total risk. however  a cost is incurred when we query a label and computing the difference in these quantities triages the selection of cases to label. formally  we define the voi of an unlabeled point xj as the difference in the reduction in the total risk and the cost of obtaining the label:
		 1 
here  uj and jallj denote the total expected cost and the total misclassification risk respectively if we consider xj as labeled. the voi quantifies the gain in utilities in terms of the real-world currency that can be obtained by querying a point; hence  our strategy would be to choose next for labeling the point that has the highest value of information. this results in minimization of the total cost u that consists of the total risk in misclassification as well as the labeling cost. we note that this approach differs from the earlier methods in active learning where the focus has been to minimize the classification error.
　now  let us consider xj for querying. note that we need to compute the expression for voi before we know the label for xj and the total risk jallj cannot be computed before we know the actual label tj. similarly  cj cannot be computed if the costs of labels are different for different classes. we approximate the terms jallj for the jth data point with an expectation of the empirical risk as: jallj 「 pjjj + + jj   1   pj . here jj + and jj   denote the total risks when xj is labeled as class 1 and class -1 respectively. these risks can be written as sum of risks on labeled and unlabeled data as following:
	jj + = jlj + + juj +	and	jj   = jlj   + juj  	 1 

figure 1: selection of points to query for label based on the value of information. the circles represent the unlabeled cases and the radii correspond to the voi of labeling each case. the squares  class 1  and the triangles  class -1  represent previously labeled cases. the different figures correspond to the following situations:  a  symmetry in the costs of both the risks and the labeling   b  asymmetric risk  and  c  asymmetric label costs. the cross corresponds to the selection of the next query. the curve denotes the decision boundary based on thecurrently available labels.
to calculate these risks we first compute pj +  the resulting posterior probability upon adding xj as a positively labeled example in the active set. now  using similar expressions to equations 1 and 1 we can compute jlj + and juj +  the risks on the labeled and the unlabeled data points when xj is assumed to be positively labeled. the corresponding computations follow for and as well. similarly  we can use expectation of cj if costs of labeling vary by class.
　thus  our strategy is to select cases for labeling that have the highest voi:
	jsel = argmaxv oi xj 	 1 
j（u
we note that whenever v oi xjsel  is less than zero  we have a condition where knowing a single label does not reduce the total cost; thus  this situation can be employed as a stopping criterion. stopping criteria for open-world situations would include the computation of gains in accuracy of the classifier over multiple uses  based on a probability distribution over expected cases and the lifespan of the system. we note that a greedy policy might indicate stopping when there is still potential for further reduction of the overall cost via querying a set of points.
　we now demonstrate the approach  starting with illustrations with a toy data set. we shall employ gaussian process classification  see section 1  within the active learning framework. figure 1 shows the selection of unlabeled points to query based on the voi criterion. the sample data consists of two half moons in a multidimensional space  where the top half belongs to class +1 and the bottom to the class -1. in the simulation  we start with a few cases that are already labeled and are represented as squares for class 1 and triangles for the class -1. the different graphs in the figure correspond to different settings of risks  r1 and r1  and labeling costs. we assume that c1 and c1 are the costs for querying points that belong to class +1 and  1 respectively. the unlabeled points are displayed as circles and the radii correspond to the voi of labeling these cases. the next case selected to be queried is marked with a cross. figure 1 a  shows the voi for all the unlabeled data points and the case selected for the next query when the risks and the cost of labelings are equal for both classes. for this situation  cases that are nearest to the decision boundary are associated with the highest voi. choosing cases that minimize the objective for overall cost corresponds to the selection of queries that would minimize the classification error; hence  the points at the decision boundary are the ones that are the most informative. figure 1 b  illustrates the situation where it is far more expensive to misclassify a point belonging to class -1. due to this asymmetry in risks  the points that are likely to belong to class -1  but that also lay close to the decision boundary  have the highest voi. figure 1 c  depicts the situation where obtaining a label for a point in class -1 is 1 times as expensive to obtain the label for a point belonging to class 1. the voi is highest for those points that are more likely to belong to class 1 and that are close to the decision boundary. the sample data set illustrates how voi can be used effectively to guide tagging supervision such that it minimizes both the operational and training costs of a classifier.
　we point out that we have assumed a closed system where both the set of the labeled and the unlabeled data are available beforehand. prior work on active learning includes studies that assume an open system  where the data points arrive one at a time. the methods discussed in this paper can be extended to handle the open system case by using the average empirical risk  as a guiding principle as earlier used by zhu et al.  1. note that this is not a transductive learning framework; the final classification boundary dependsonly on the labeled data. both the labeled and the unlabeled data points are used only to determine which cases to query. once trained  the classifier can be applied to novel test points  beyond the original set of labeled and the unlabeled points. we shall describe in section 1 extensions to handle the transductive case by using a semi-supervised learning algorithm to train the classifier. before that  we will pause to review gaussian process classification.
table 1: features extracted from voice messages
prosodic featuresmetadata information   includes max  min  mean and variance 
 
duration of voiced segmentis am on a work day absolute pitch is pm on a work day length of productive segment is after hours on a work day length of pause size in byteschange in pitch during productive segments size in secondsrate features  syllable  silence  productive segments  pauses is external caller 1 gaussian process classification
in this work  we explore active learning with the use of gaussian process  gp  classifiers. one of the advantages of using gp classification is that we directly model the predictive conditional distribution p t|x   consequently making it easy to compute the actual conditional probabilities without any calibrations or post-processing. gp methods provide a bayesian interpretation of classification. with the approach  the goal is to infer the posterior distribution over the set of all possible classifiers given a training set:
		 1 
here  p w  correspondsto the prior distribution over the classifiers and is selected typically so as to prefer parameters w that have a small norm. specifically  we assume a spherical gaussian prior on the weights: w ゛ n 1 i . the prior imposes a smoothness constraint and acts as a regularizer such that it gives higher probability to the labelings that respect the similarity between the data points. the likelihood terms p ti|w xi  incorporate the information from the labeled data and different forms of distributions can be selected. a popular choice is the probit likelihood: p t|w x  = Ψ t ， wtx . here  Ψ ，  denotes the cumulative density function of the standard normal distribution. the posterior prefers those parameters that have small norm and that are consistent with the training data.
　computing the posterior  p w|x t    is non-trivial and approximate inference techniques such as assumed density filtering  adf  or expectation propagation  ep  are typically required. the idea behind adf is to approximate the posterior p w|xl tl  as a gaussian distribution  i.e. p w|xl tl  「 n w． Σw . similarly  ep is another approximate inference technique. ep is a generalization of adf  where the approximation obtained from adf is refined using an iterative message passing scheme. we refer readers to minka  1 for the details.
　given the approximate posterior p w|x t   ゛ n w． Σw   a frequent practice is to choose the mean w． of the distribution as the point classifier. the mean  which is also called the bayes point  classifies a test point according to: sign w．tx . it is relatively straightforward to generalize to the non-linear case by using the kernel trick  where the idea is to first project the data into a higher dimensional space to make it separable  evgeniou et al.  1 .
　one of the byproducts of using the gp classification framework is that we obtain a predictive distribution p sign f x  |x :
w． tx
	p sign f x   = 1|x  = Ψ  	 1 
unlike other classifiers  the gp classification models the predictive conditional distribution p t|x   making it easy to compute the actual conditional probabilities without any calibrations or post-processing. probabilistic interpretations have been made of other kernel classifiers such as svm  sollich  1  and other attempts that map the output of the classifiers directly to the probability  platt  1 . our approach is to use this predictive distribution in the selective-supervision framework to compute expected risks and to quantify the value of information.
1 computational issues
as mentionedearlier  adf or ep can be used for approximate inferencein gp classification. however  the proposedscheme for selecting unlabeled points is computationally expensive. note  that computational complexity for ep is o n1   where n is the size of labeled training set. in the proposed method  we have to compute voi for every unlabeled data point  requiring us to perform ep twice for every point under consideration.
　a faster alternative is to use adf for approximating the new posterior over the classifier rather than computing ep. specifically  to compute the new posterior pj + w|xl“j {tl“+1}  we can compute the gaussian projection of the old posterior multiplied by the likelihood term for the jth data point. that is: pj + w|xl“j {tl “ +1}  「 n w．j + Σj w+   where w． j + and Σj w+ are respectively the mean and the covariance of p w|xl tl  ， Ψ 1 ， wtxj . this is equivalent to performing adf starting with the old posterior p w|xl tl  and incorporating the likelihood term Ψ 1 ， wtxj  and does not require o n1  operations to compute voi for every unlabeled data point. we can use similar computations to approximate pj   w|xl“j {tl “  1} .
1 from supervised to semi-supervised learning
the underlying classifier in the proposed framework is based on gaussian processes and it can be easily extended for the semi-supervised case  kapoor  1; sindhwani et al.  1 . specifically  at the core in the gp classification is the kernel matrix k  where entry kij encodes the similarity between the ijth and the jth data points. rather than using k as the

	 a 	 b 

	 c 	 d 
figure 1: comparison of different active learning schemes. graphs  a  and  b  show the error on unlabeled points versus the number of labels for classifying voicemails. graphs  c  and  d  show the total cost incurred versus the number of labels. voi criteria can provide good classification performance with significantly lower costs. the results are averaged over 1 runs and the error bars represent the standard error.similarity matrix for gp classification  we can use the inverse of the transformed laplacian:
	r Δ  = Δ + σi	where	Δ = d   k
here  d is the diagonal matrix where the diagonal elements are:  and σ   1 is added to remove the zero eigenvalue from the spectrum of r Δ . intuitively  rather than computing similarity directly via the kernel kij  the inverse of the transformed laplacian computes the similarity over a manifold. thus  the unlabeled data points help in classification by populating the manifold and using the similarity over the manifold to guide the decision boundary. the extension of gp classification to handle semisupervised learning has been recently studied  kapoor  1; sindhwani et al.  1  and is related to the graph-based methods for semi-supervised learning. the rest of the active learning framework can be used as it is on top of this semisupervised gp classification framework.
1 sample challenge: classifying voicemail
we shall now move to a challenging classification task that highlights the value of employing the selective supervision methods. specifically  our goal is to build a system that can classify voice messages in several ways  including whether the messages are urgent vs. non-urgent  the caller is personally close vs. not close to the person being called  and to detect if the caller is calling from a mobile phone. the classification task is related to prior work on the prioritization and routing of email messages with statistical classifiers  horvitz et al.  1 .
　given a set of voice messages  we first extract features that promise to be of value in discriminating among the target classes. specifically  we look at the prosody and metadata that accompanies the messages.
prosodic features: we consider multiple prosodic features including syllable rate  pause structure  and pitch dynamics. we employ a pitch tracker and then extract the prosodic features summarized in table 1.
message metadata: we also extract metadata from the voice messages. specifically  we extract features that indicate the day and the time of the call. additionally  we consider the size of the voicemail in bytes as well as the length of the message in seconds. we also extract features that indicate whether the caller is calling from outside the recipient's organization. several metadata features are shown in table 1.
　we now explore the selective supervision concepts applied to the voicemail classification challenge. the data set consists of 1 labeled voice messages received by a single user over a period of 1 months. we explore the use of the methods to guide the labeling efforts for supervised classification. annotating a voicemail is tedious and shorter voicemails can be labeled more quickly than the longer ones. thus  we use the asymmetric cost criterion where the cost of a label scales with the length of the voicemail. specifically  we assume that the cost of labeling voicemail is 1 us dollars per second of message length. further  for all of the experimentswe assume
table 1: average accuracy  standard error  on the unlabeled points and on the total cost when starting with one labeled point per class and choosing 1 other points. the bold figures indicate significant performance difference with 1% confidence.
taskaccuracycost	voi	random	voi	randomclose 1＼11＼11＼1	1＼1mobile 1＼11＼11＼1 1＼1urgent 1＼11＼11＼1	1＼1that misclassification costs r1 = r1 = 1 us dollars. for gaussian process classification  the polynomial kernel of degree 1 is used.
　we compare the selective-supervision strategy in supervised learning with three other schemes: 1  selecting points randomly  1  choosing the point where the classification is most uncertain  i.e.  jsel = argminj（u |pj   1|  and 1  choosing the point that is likely to change the posterior over w the most  mackay  1; lawrence et al.  1   i.e.  jsel = argmaxj（u pjΔj + +  1   pj Δj  . here  Δj + and Δj   are the differential entropy scores  lawrence et al.  1  when jth point is added as a positively and a negatively labeled point in the training set respectively. the term being maximized quantifies the expected change in the posterior over w when point xj is added to the training set.
　graphs  a  and  c  in figure 1 compare the different active learning schemes on the task of detecting if the caller is personally close to the person being called. similarly  graphs  b  and  d  in figure 1 show the plots for the task of classifying whether the voice messages originated from a mobile phone. for the studies  results are averaged over 1 runs  where  for each run  we select one case per class as labeled and the rest of the points are selected according to the different active learning policies. note  that  in the beginning  when there are a very few labeled data points  it is difficult to estimate the misclassification risk  rl + ru . however  with increasing numbers of labeled cases  the gaussian process classification will typically provide a better estimate of the posterior p sign f x  = 1|w x .
　we found that the voi policy results in significant gains over the other methods  both in terms of the accuracy as well as the cost. table 1 shows the average classification accuracy and the standard error on the unlabeled data points together with the total cost  the sum of the misclassification and training costs  incurred after querying1 points guided by the voi criterion and random selection policy. as indicated by the results  the voi criterion provides significant gains over random sampling in terms of cost and accuracy for classifying messages as personally close versus not close and mobile versus non-mobile. the voi criterion for selective supervision provides valuable guidance on labeling efforts under budget constraints. we found that the gain with the use of voi was not significant for detecting urgency. we hypothesizethat this is due to the poor separability of the data.
1 conclusion
we have investigated a decision-theoretic approach to classification  focusing on the use of value of information as the basis for guiding supervision. we showed how the risks of misclassification and cost of obtaining labels can be used to quantify the value of querying for labels of unknown cases. we applied and tested the ideas within the gaussian process classification framework. finally  we reviewed results obtained from applying the methods to the task of building predictive models for classifying voice messages  where the cost of labeling a voicemail scales with the length of messages. we are continuing to explore challenges with the efficient computation of voi and with studying the value of using the methods in triaging labeling effort in selective supervision.
