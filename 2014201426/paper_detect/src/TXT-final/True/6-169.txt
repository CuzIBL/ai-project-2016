 
maximum satisfiability  max-sat  is more general and more difficult to solve than satisfiability  sat . in this paper  we first investigate the effectiveness of walksat  one of the best local search algorithms designed for sat  on max-sat. we show that walksat is also effective on max-sat  while its effectiveness degrades as the problem is more constrained. we then develop a novel method that exploits the backbone information in the local minima from walksat and applies the backbone information in different ways to improve the performance of the walksat algorithm. we call our new algorithm backbone guided walksat  bgwalksat . on large random sat and max-sat problems as well as instances from the satlib  bgwalksat significantly improves walksat's performance. 
1 introduction 
satisfiability or sat is an archetypical combinatorial problem. 
a sat involves a set of boolean variables and a set of clauses in the form of a disjunction of literals  variables or their nega-
tions . a clause is satisfied if one of its literals is set to true  and the problem is satisfied if all clauses are satisfied. the problem is to decide if a variable assignment exists that satisfies all the clauses. when not all clauses are satisfiable  the goal is to maximize the satisfied clauses  and the problem becomes maximum sat or max-sat  an optimization problem. a sat  max-sat  with k literals per clause is denoted as k-sat  max-k-sat . it is known that k-sat with k greater than two is np-complete and max-k-sat with k being at least two is nphard . max-sat is more general and difficult to solve than sat. many real-world problems  such as scheduling  pattern recognition  and multi-agent cooperation and coordination  1; 1   can be formulated and solved as sat or max-sat. 
　recent years have witnessed significant progress made on sat and max-sat along two directions. the first is the understanding of properties such as phase transitions and backbones  1; 1; 1; 1; 1 . phase transitions refer to dramatic changes in a problem property when a critical parameter of a problem changes. the most important phase transition results on random 1-sat are that when the ratio of the number 
   *this research was supported in part by nsf grants iis-1 and itr/eia-1  and in part by darpa cooperative agreements f1-1 and f1-c-1. 
satisfiability 
of clauses to the number of variables  c/v ratio  increases beyond a critical value  around 1  random 1-sats begin to become unsatisfiablc  and the computational cost of the problem increases abruptly  1; 1; 1 . the backbone of a problem is a set of variables that have fixed values in all optimal solutions to the problem. the hardness of a sat or max-sat is determined by the backbone size of the problem . in addition  the backbones of random sat and max-sat also have small to large phase transitions . the second direction is focused on developing efficient sat solvers. the most noticeable results along this line are the walksat local search algorithm  and its variants   which are among the best sat solvers used in practice for problems such as planning. 
　a problem of fundamental interest and practical importance in algorithm design is how to utilize problem structure properties such as phase transitions and backbones to cope with high complexity and improve algorithm performance. the current research on this problem is limited.  developed a transformation method to exploit phase transitions of tree search.  designed a method to incorporate estimated backbone variables in a systematic search for sat.  proposed a heuristic backbone sampling method for generating initial assignments for a local search using an estimated backbone. this sampling scheme will also be studied in this research. 
　in this paper  we develop a novel method to exploit the structure of local minima reached by an effective local search algorithm  and an effective approach to utilize the structure information to improve the performance of a local search algorithm. we focus on max-sat in this research. 
　to develop our new method  we first study the performance of walksat  which was designed for sat  on max-sat  section 1 . we show that walksat is effective on random maxsat  finding many high quality local minima close to optimal. in addition  the local minima reached by walksat appear to form large clusters around optimal solutions. our results also show that the performance of walksat degrades when the constrainedness of max-sat increases. although we carry out this analysis for the purpose of developing a new method  the result is of interest and significance on its own. to our knowledge  walksat has only been analyzed on some overconstrained steiner tree problems . 
　the main contribution of this paper is an innovative method that exploits the solution structure of a combinatorial problem to improve the performance of a local search algorithm such as walksat  section 1 . it was inspired by the recent research on phase transitions and backbones of sat and max-sat  1; 
1 
1  and the performance results of walksat in the first part of the paper. we directly apply the new method to walksat. nevertheless  the ideas and techniques developed here are general and applicable to other combinatorial problems and local search algorithms. 
　briefly  our main ideas are to use backbone information to make biased moves in a local search  and use local minima to approximate optimal solutions for extracting backbone information. the frequencies of literals appearing in all local minima are called pseudo-backbone frequencies. our new approach applies pseudo-backbone frequencies as a heuristic for selecting a variable to flip in each step of the walksat algorithm. such biased moves guide the search toward regions possibly having optimal solutions. the effectiveness of this method is partially due to the effectiveness of walksat on finding optimal and high quality approximate solutions. we call the resulting algorithm backbone guided walksat or bgwalksat. we demonstrate and evaluate experimentally the effectiveness of bgwalksat on large random max-sat instances and real problems from satlib   section 1 . 
1 the walksat algorithm 
walksat is a randomized algorithm  it starts by creating an initial random variable assignment  which we call assignment generation . it then repeatedly makes a move by selecting a variable and flipping its value from true' to false or vice versa  until it finds a satisfying assignment or reaches a predefined maximal number of flips. each such attempt is called a try or restart. the procedure repeats until a maximal number of tries has been executed. 
　to select a variable  the effect of flipping a variable is assessed. flipping a variable may make some unsatisfied clauses satisfied. the number of clauses being made unsatisfied by flipping a variable is call the break-count of the variable at the current assignment. walksat attempts to flip a variable with zero break-count  trying not to make the next assignment worse than the current. to find a variable with zero break-count  walksat first selects an unsatisfied clause c  randomly  from all unsatisfied clauses. this is called clause pick. if c has a variable of zero break-count  walksat then picks such a variable  randomly  from the ones that qualify. if no zero break-count variable exists in c  walksat then makes a random choice. with probability p it chooses  randomly  a variable from the ones involved in c  called noise pick ; and with probability 1 - p it picks a variable with the least break-count  breaking the tie arbitrarily if multiple choices exist  called greedy pick . 
　a flow chart of one try of walksat is in figure 1. the four shaded rectangles contain the random choices we will analyze. walksat takes three parameters to run  the number of tries  the maximal number of flips in each try or cutoff parameter  and a probability or noise ratio for noise pick. 
1 performance of walksat 
we now turn to the effectiveness of walksat on max-sat  particularly max-1-sat. we measure a local minimum in two ways. the first is the cost difference between a local minimum and an optimal solution  which may have non-zero cost . the second measure is the hamming distance between a local minimum and the optimal solution nearest to it. we introduce the nearest hamming distance to capture the minimal number of flips required to turn a local minimum into an optimal solution. furthermore  to make these two quality measures on 
1 

two max-sat instances of different sizes comparable  we normalize them. for a given problem  we divide the hamming distance by the number of variables  resulting in the hamming distance per variable  and divide the cost difference by the number of clauses  giving the cost difference per clause. we then use these two normalized quality measures to construct the landscape of local minima reached by walksat. 
　to find the nearest optimal assignment  all optimal solutions are required  which are found by an extended dpll algorithm  for sat. since finding all optimal solutions is expensive  we restricted ourselves to relatively small max-sat problems. in our experiments  we used problems of 1 variables and c/v ratios of 1  1  1 and 1 to capture problems in different constrainedness regions. the problems were randomly generated by uniformly picking three literals without replacement for a clause  discarding duplicate clauses. for walksat  we set the noise ratio at 1  the number of tries per problem at 1  and the cutoff parameter at 1. we generated 1 problems at each c/v ratio. 
　the quality of local minima from walksat are summarized in figure 1. the x-y planes show the correlation between the normalized hamming distance and the normalized cost difference. the origins of the figures correspond to global minima. each point on the x-y plane represents a possible local minimum that may be visited by walksat. the vertical z axis measures the number of local minima reached by walksat  averaged over 1 instances on each of which 1 tries were run. 
　as shown in figures 1 a  and  b   walksat performs well on underconstrained and critically constrained problems  in that it can find global minima very often. this is shown by the points on z axes indicated by the arrows in the figures. therefore  walksat is effective at finding optimal solutions on underconstrained and critically constrained problems. however  the number of local minima which are also global minima decreases from 1 to 1  on average  as the c/v ratio increases from 1 to 1  indicating that the effectiveness of walksat decreases. this number decreases further to 1 and 1 on overconstrained problems with c/v ratios equal to 1 and 1  figures 1 c  and  d  . this result indicates that walksat becomes less effective in finding optimal solutions as problem constraints increase. 
　the distribution of local minima of walksat exhibits a bell surface on overconstrained problems  figures 1 c  and  d  . 
more importantly  the summit of such a bell surface shifts away 
satisfiability 

from optima  solutions  the  1  point on the x-y plane  as the problems are more constrained. as the c/v ratio increases  the number of optimal solutions decreases   which can become indistinguishable from a large number of suboptimal solutions. as a result  the search space becomes rugged  with more local minima in which walksat may be trapped. 
　despite the difficulty of overconstrained problems  walksat is still fairly effective in that it is able to reach local minima close to optimal solutions. for a c/v ratio of 1  figure 1 d    for instance  a large number of local minima landed on by walksat  the peak point of the bell surface  have a normalized cost difference to optimal solutions of 1 for 1 variable problems  which is equivalent to approximately eleven more constraints violated than an optimal solution on such overconstrained problems. since walksat is normally executed in multiple tries  the best local minimum it can reach is usually much better than such most frequent local minima. 
　a closer examination of the results in figures 1 c  and  d  indicates a nearly linear correlation between the cost difference and the hamming distance. this observation implies that a local minimum with a small cost is more likely to share a larger common structure with an optimal solution. a similar phenomenon on the traveling salesman problem was called the  big valley  . we will exploit this in our new search algorithm described in the next section. 
1 	backbone guided local search 
1 the main idea 
if all optimal solutions to a problem were known  they could provide a useful clue to how a variable should be set. for example  if a variable is a part of the backbone  i.e.  it has a fixed value in all optimal solutions  obviously the variable should be set to that value. in fact  we can extend the concept of backbone to backbone frequency. the frequency of a variable-value pair  or literal in sat  in all optimal solutions is an indication of how often the variable should take that particular value. this can be exploited as a heuristic for selecting variables and values in a local search such as walksat. in general  a variablevalue pair will be less likely to be swapped out of the current state if it has a higher backbone frequency than another pair. 
satisfiability 
　unfortunately  exact backbone frequencies are hard to come by without finding at least one optimal solution. the idea to bypass this problem was inspired by the effectiveness of high performance local search algorithms  such as walksat. our analysis on the performance of walksat  section 1  showed that walksat can find optimal solutions very often on underconstrained and critically constrained max-sat  and can also reach near optimal solutions very close to the optimal. such near optimal local minima also form large clusters around optimal solutions. thus  the local minima of walksat must have common structures  which may also be shared by optimal solutions. therefore  we can use the local minima as if they were optimal solutions to compute pseudo-backbone frequencies as an estimation of the true backbone frequencies. we call this general approach backbone guided local search or bgls. 
　the above ideas can be applied to almost all local search algorithms. however  actual application is problem and algorithm specific  since local search algorithms operate very differently on different problems. in this research  we consider max-sat and the walksat algorithm. 
1 	backbone guided walksat: bgwalksat 
the application of bgls to max-sat and walksat leads to the backbone guided walksat  bgwalksat  algorithm. similar to walksat  bgwalksat runs a total k tries. in addition  bgwalksat splits the total of k tries into two phases. the first  estimation phase  runs  tries of original walksat to collect local minima and compute pseudo-backbone frequencies  see 
section 1 . the second  backbone guided search phase runs 
 = k -  tries  in which variable selection is guided by pseudo-backbone frequencies. the newly discovered local minima can also be added to the pool of all local minima to update the pseudo-backbone frequencies. 
　we now consider backbone guided moves or biased moves. as discussed in section 1 and shown in figure 1  walksat makes five uniformly random choices. the first is the random initial assignment generation. instead of uniformly randomly choosing a variable and setting it to an arbitrary value  we can view the pseudo-backbone frequencies as an approximate probability distribution of variable assignments and take samples of variable assignments as initial assignments from this distribution. this scheme was called heuristic backbone sampling in . 
　the second random choice in walksat is the random clause pick for choosing an unsatisfied clause. to apply the idea of backbone frequencies  we extend it to the concept of pseudobackbone clause frequencies  which measure the frequencies that clauses are satisfied in all local minima. when picking a clause from the set of unsatisfied clauses  we choose one based on its pseudo-backbone clause frequency. for example  given three unsatisfied clauses and with pseudo-backbone 
frequencies 1 1 and 1  respectively  we choose 
with probability 	with proba-
bility 	and c1 with probability  
　the remaining three random choices involved selecting a 
　variable  uniformly  from a particular set. the first choice picks a variable from the set of zero break-count variables in the chosen clause c  the unshaded rectangle in figure 1   the second directly from the variables involved in c  and the third from the set of variables in c with the least break-count. rather than picking one variable uniformly from a particular set  we make a biased selection based on variables' pseudo-backbone 
1 
frequencies. consider an example of three literals and in the chosen clause c with backbone frequencies 1 1 and 1  respectively. we want to flip more than because literal appears more often than in all local minima  frequency 1 versus 1 . therefore  we pick and 
with frequencies and respectively. 
1 	pseudo-backbone frequencies 
the performance of backbone guided local search depends largely upon the quality of pseudo-backbone frequencies. there are at least two ways to compute pseudo-backbone frequencies. the first and simplest method is to consider all the available local minima as if they were global optima  and take the frequency of a variable-value pair  that appears in all local minima s as its pseudo-backbone frequency. 
specifically  we have frequency we call this method average counting. 
　it is imperative to note that not all local minima are of equal quality. a lower quality local minimum usually contains less backbone variables than one of a higher quality. therefore  the former is less reliable and should contribute less to the pseudo-backbone frequencies than the latter. thus  we must discount the contribution of a local minimum based on its cost. if a local minimum has cost we can compute the pseudo-backbone frequency of as 
in other words  
the pseudo-backbone frequency of i is reciprocally weighted by the costs of the local minima that i was involved with. we call this method cost reciprocal average counting. 
1 	walksat and bgwalksat with dynamic noise 
one limitation of the walksat family of algorithms is their dependence on a manually set noise parameter. so far  two mechanisms have been proposed to resolve this issue in sat. auto-waksat  uses a preliminary probing stage to estimate the optimal value for the noise parameter  while walksat with dynamic noise  automatically adjusts the noise level as the search progresses. we have successfully combined our method with the dynamic noise strategy  for sat and max-sat. 
　the idea of dynamic noise is simple: start search with the noise parameter equal to zero  and examine the number of violations in the current state every flips  where  is the number of clauses in the instance. if the number of violations has not decreased since the last time we checked  n flips ago   the search is assumed to have stagnated  and the noise level is increased to where is the current noise level. otherwise  the noise level is decreased to the discrepancy between the formulas for increasing and decreasing the noise level are based on the observations of how walksat behaves when the noise parameter is too high  compared with how it behaves when the parameter is too low . following   we have set and = 1  which have been found to be effective over a wide range of sat and maxsat instances. 
　dynamic noise was designed and tested with walksat's cutoff parameter set to infinity; i.e.  no random restarts. this is the setting we use for walksat with dynamic noise for all of our experiments in the next section. unfortunately  this setting is incompatible with backbone guided walksat  which requires random restarts in order to construct the pseudo-backbone. to overcome this  we have devised  compromise  parameter settings  which allow dynamic noise to function effectively  while 
1 
still constructing the pseudo-backbone. specifically  we run walksat with dynamic noise for 1 short runs to construct the pseudo-backbone  followed by 1 long runs of backbone guided local search  each of which is 1 times as long as a short run. 
 
1 	experimental results 
we now analyze the performance of bgwalksat on maxsat the benchmark suite for empirical evaluation consists of two different types of problems: randomly generated problems and problems converted from real-world applications in satlib . we included satisfiable and unsatisfiable problem instances. we used walksat implementation from henry kautz and developed bgwalksat on top of it. 
1 	random ensembles 
in these experiments  we investigate the effects of biased moves on random choices in walksat  section 1 . there are five places where walksat makes uniformly random choices  the five rectangles in figure 1 . our experimental results showed that the biased random choice of picking a variable of zero break-count in a selected clause c  the unshaded rectangle in figure 1  has almost no effect. the reason is that when a zero break-count variable exists  there is usually one available  meaning that a very few such biased moves occur. we will not consider this biased random choice in the rest of the paper. 
　in our experiments  we generated random max-1-sat instances with 1 variables and three different c/v ratios of 1  1 and 1. we generated 1 instances for each of the c/v ratios. we also tested various noise ratios  from 1 to 1 with an increment of 1  as well as walksat with dynamic noise. each run  regardless of its configuration  was allowed a total of one million flips. 
　for walksat with static noise  the cutoff parameter was set to 1 flips  so the algorithm was run from 1 different starting points . we tested different ratios of the lengths of the backbone estimation phase and the actual backbone search phase in bgwalksat. we found that a ratio of about 1 seems to provide the best results. in the results shown below  walksat was run on the first 1 tries to collect the initial set of local minima and obtain the pseudo-backbone frequencies. bgwalksat was run on the remaining 1 tries. new local minima were added to update pseudo-backbone frequencies every 1 tries. 
　we experimentally compared the two methods for computing pseudo-backbone frequencies  section 1 . the average counting  ac  method is generally worse than the cost reciprocal average counting  crac  method on random problems. due to space limitations here  we will only report the results from the crac method below. 
　there is little impact of biased moves when the c/v ratio is 1  because walksat is able to find optimal solutions in the first 1 tries in almost all problems. figure 1 shows the results on random max-sat with 1 variable and c/v ratios of 1 and 1  comparing walksat and bgwalksat with biased noise pick  biased greedy pick  and bias moves combining biased noise pick  greedy pick  clause pick  and assignment generation. the error bars in the figures correspond to  confidence intervals. as shown  biased greedy pick is effective at low noise levels  but leads to degraded performance on higher noise levels. biased noise pick  on the other hand  has a greater effect as the noise level increases  due to the direct relationship between the noise level and the frequency of noise picking. biased assignment generation and clause pick on their own  have 
satisfiability 


figure 1: quality improvement on random max-sat using biased noise pick  biased greedy pick  and the combination of biased noise pick  greedy pick  clause pick  and assignment generation  combined bias . 
little effect of walksat's performance  data not shown . however  when combined with other strategies  they can provide improvements  as shown. 
　we also tested walksat and bgwalksat with dynamic noise on the same instances  with good results. this is fairly unsurprising  since on this class of instances  walksat performs best with a low noise ratio  and dynamic noise begins with the noise ratio set to zero  and only raises it as needed. we found that the noise parameter fluctuated at low levels  with an average of 1 for both c/v=1 and c/v=1. the noise level never exceeded 1 at any time. the solutions found by walksat with dynamic noise were as good as the best solutions found by walksat with static noise for c/v=1  and only about 1% worse for c/v=1. when combining dynamic noise with bgwalksat  the average noise level was slightly lower  giving 1 for c/v=1 and 1 for c/v=1  due to the increased number of random restarts. this is because after every restart there is a period of rapid improvement  when the noise level remains at zero. the performance of bgwalksat with dynamic noise is similar to that of bgwalksat with best static noise for c/v=1 and slightly worst than that for c/v=1. 
1 	real problem instances 
we now investigate how bgwalksat improves upon walksat on the problems from satlib   when used in conjunction with dynamic noise. the test problems include sat-encoding instances from a random hard graph coloring problems and sat-encoded blocks world planning  bounded model checking  and the all interval series problem. the details of these 
problems can be found on the website. we only chose problems with more than 1 variables  and discarded those that can be easily solved by walksat and bgwalksat. 
　we considered satisfiable and unsatisfiable problems. we ran both walksat and bgwalksat  both using dynamic noise  with a total of 1 million flips  compared with 1 million for our results for random instances . interestingly  bgwalksat exhibited superior performance  over a wide range of real instances  with some of the methods of biased-moves utilizing the pseudo-backbone disabled. for the results presented here  we use backbone-guided noise pick and backbone-guided clause pick  with the average-counting  ac  method. results are for twenty runs for each algorithm and instance. experiments with the best static noise  not shown  produced similar results. 
　in viewing the results  we found it useful to divide the satisfiable instances into two categories  the easier instances  which were solved at least once  table 1   and the harder ones  which 
satisfiability 
table 1: walksat vs. bgwalksat on easier satisfiable problems. 
walksat and bgwalksat are the runs resulting in a satisfying solutions  out of 1  by these algorithms. the better results are underlined and in bold. 
bw large.c 1 1 l 1 i 	1 bw.large.d 1 1 1 1 par1 1 1 1 1 par1 1 1 1 1 par1 1 1 1 1 par1 1 1 1 1 par1 1 1 i 	- qg1 1 1 1 1 qg1 1 1 1 1 qg1 1 1 1 1 qg1 1 1 1 1 qg1 1 1 1 1 g1 g1 1 
1 1 
1 1 |1 
 	1 	problem 	  walksat i   bgwalksat 
were not solved by either method  in any of their runs  table 1 . results for unsatisfiable instances are presented in table 1. 
　as the results show  bgwalksat significantly outperforms walksat in most cases. on easier satisfiable instances  table 1   
bgwalksat finds more satisfying solutions than walksat for all parity  par  and quasigroup  qg  classes  and produces similar results to walksat on blocksworld instances. on harder satisfiable instances  table 1   bgwalksat outperforms walksat in all but two of 1 instances  where it is less than half a percent worse. in contrast  the overall average gain is 1%  and is over 1% in 1 of them. on unstatisfiable instances  table 1   bgwalksat produces impressive gains on longmult instances  and on ssa1  with an overall average gain of 1%. on unsatisfiable quasigroup instances  not shown   performance was similar to that of walksat. performance of bgwalksat is never more than 1% worse than walksat on any of the unsatisfiable instances we have studied. 
　the most glaring failure of bgwalksat is on the instances pl1 and g1. these instances are sat-encoded graph coloring problems  and serve to illustrate an important point. as described in section 1  we believe that our method is effective because it exploits the  big valley  structure of the solution space. however  graph coloring problems exhibit a particular type of symmetry in their solution structures which is opaque to local search methods such as walksat. for example  coloring all red nodes green  and all green nodes red  results in an identical solution  with a radically different encoding. thus  there is not a single  big valley   but several  which can bury the true backbone information and thus lead to degraded performance. presumably  bgwalksat's performance will suffer on all instances with this type of symmetry. 
1 	conclusions 
we developed a novel and general method that exploits backbone information for improving the performance of a local search algorithm. we demonstrated and analyzed the new method  called bgwalksat  on max-sat using the walksat algorithm  with both static and dynamic noise strategies. the main ideas are to extract backbone information from local minima and use it directly to fix the discrepancy between the current state and optimal solutions  so as to guide walksat toward the regions of the search space more likely to contain optimal solutions. in comparison  almost all existing local search methods focus on the costs of the states in the search space. there-
1 

table 1: walksat vs. bgwalksat on harder satisfiablc problems. walksat and bgwalksat are the average numbers of violations in the best solutions found by the algorithms for a given problem  averaged over 1 runs. gain is the percentage improvement of bgwalksat over walksat. the better results are underlined and in bold. 
  	problem #var #clause | walksat | bgwalksat i gam %  bmc-ibm-1 1 1 1 1. i-1 bmc-ibm-1 1 1 1 1 1 bmc-ibm-1 1 1 1 1 1 bmc-ibm-1 1 1 1 1 1 bmc-ibm-1 1 1 1 1 1 bmc-ibm-1 1 1 1 1 1 bmc-ibm-1 1 1 1 1 1 bmc-galileo-1 1 1 1 1 1 bmc-galileo-1 1 1 1 1 1 bmc-ibm-1 bmc-ibm-1 bmc-ibm-1 bmc-ibm-1 1 
1 1 1 
1 
1 | 1 
1 
1 
1 1 1 
1 
1 
1 |1 1 1 f1 1 1 i 1 1 i 1 par1-c 1 1 1 1 1 par1 1 1 ! 1 1 1 par1-c 1 1 j 1 1 1 1par1 1 1 1 1 1 par1-c 1 1 1 1 1 par1 1 1 1 1 1 par1-c 1 1 1 1 1 |par1 1 1 1 1 1 par1-c 1 1 1 1 1 par1 1 1 1 1 1 par1-c 1 1 1 1 1 par1 1 1 1 1 1 par1-c 1 1 1 1 -1 par1 1 1 1 1 1 par1-c 1 1 1 1 1 par1 1 1 1 1 1 par1-c 1 1 1 1 -1 par1 1 1 1 1 1 par1-c 1 1 1 1 1 par1 1 1 1 1 1 average 1 fore  the new algorithm focuses more on where the current state is within the search space and tries to fix possible problems in the structures of the state directly. 
　bgwalksat can significantly outperforms walksat on sat and max-sat  with both static and dynamic noise. on random max-1-sat problems  the more constrained the problems  the more improvement bgwalksat can provide. specifically  on random max-1-sat with 1 variables and a c/v ratio of 1  bgwalksat can satisfy approximately 1% more clauses on average than walksat  using dynamic noise . on satisfiable problems from the satlib  bgwalksat almost always significantly improves on walksat's results  with the exception of graph coloring problems which contains a type of symmetry  see section 1 . on unsatisfiablc satlib problems  bgwalksat substantially reduces the number of unsatisfied clauses across several instance classes. 
　in the process of developing bgwalksat  we also carried out a systematic experimental analysis of walksat on max-sat  again with both static and dynamic noise . our results show that although designed originally for sat  walksat is also effective on max-sat  even though its effectiveness degrades as the problem becomes more constrained. 
