ly  that they pose no constraints on the signal formats of their inputs. 


such as meta-dendral 1 and induce-plant   in which training examples are complete problem solutions by working with training examples that are single steps  leap circumvents many difficult issues of credit assignment that arise in cases where the training example corresponds to a chain of several rules. 
   while to first order  leap acquires training examples that correspond to single rule inferences  this is only approximately true we expect that leap will encounter training examples in which its existing rules will correspond to finer-grained decisions than the user thinks of as a single step for instance  the system may have a sequence of rules to implement a serial-
parallel converter by first selecting a shift register  then a general class of shift registers  e.g dynamic   and only then a specific circuit  while the user may think of the whole series of decisions as a single step  implementing the converter with a specific circuit. 
   in such cases  leap could just go ahead and learn the largergrained rule that will follow from the user's training example  but doing so could cause a number of problems one problem is that it will result in a rule set with rules of greatly varying grain. such inconsistency in grain is likely to lead to redundancy and lack of generality in the rules. a second potential problem associated with large-grain training examples is that our analytical methods of generalization may be too expensive to use on steps of large grain. since the methods depend on constructing a verification of the step  there is reason to fear the cost may grow very quickly as the size of the step gets large compared to the size of the transformations used in the verification process. 
   thus  the question of how to handle grain size mismatch may be an important issue for future research one possible direction would be to develop methods for examining a training example that corresponds to a large step  then determining which existing rules correspond to parts of this inference step  leaving only the task of acquiring the missing finer grain rules 
b. use of analytical methods for generalization 
   a second significant feature of the design of leap is that it uses analytical methods to form general rules from specific training examples  rather than more traditional empirical  dataintensive methods. leap's explain-then-generalize method  based on having an initial domain theory for constructing the explanation of the example  allows leap to produce justifiable generalizations from single training examples. this capability is particularly important for leap since it is not at all clear how leap could tell that two different training examples involving different circuit specifications and different resulting circuits  were in fact two examples of the same rule. 
   one significant advantage of the analytical methods involves learning in the presence of error-prone training data. an issue that seems central to research on learning apprentice systems  and one that leap must confront immediately  is that the users who  unwittingly  supply its training examples are likely to make mistakes. in particular  since we hope to first introduce leap to a user community of university students who are themselves learning about vlsi design  the issue of dealing with error-prone examples is a major one. our initial plan for dealing with this 
	t. mitchell et al. 	1 

that it explain an example circuit before it can generalize it  leap will be a very conservative learner since it will be unable to verify incorrect circuit examples that it encounters  there is little danger of it learning from incorrect examples******** this method of dealing with errorful data is attractive  but may be insufficient if we need to include empirical learning methods along with analytical methods for generalisation 
   while analytical generalization methods offer a number of advantages  they require that the system begin with a domain theory that it can use to explain/validate the training examples this requirement  then  constrains the kind of domain for which our approach can be used in the domain of digital circuit design  the required domain theory corresponds to a theory for verifying the correctness of circuits in certain other domains  such a theory may be difficult to come by for example  in domains such as medical diagnosis the underlying theory to explain/verify an inference relating symptoms to diseases is often unknown even to the domain experts. in such domains  the system would lack a domain theory to guide the analytical generalization methods  and would have to rely instead on empirical generalization methods that generalize by searching for similarities among a large number of training examples. in fact  our present methods for utilizing domain theories to guide generalization are limited to cases where there is a strong enough theory to  prove  the training example is correct. one important research problem is thus to develop methods for utilising more approximate  incomplete domain theories to guide generalisation  and for combining analytical and empirical generalization methods in such cases. one new research project that is interesting in this light is an attempt to construct a learning apprentice for well-log interpretation |1|. in this domain  the underlying theory necessary to learn new rules involves geology and response of well-logging tools. since these theories as inherently approximate and incomplete  that research project must face the issue of generating and utilizing approximate explanations of training examples to infer general rules. 
c. partitioning of control and basic domain knowledge 
   a third significant feature in the design of leap is the partitioning of its knowledge base into  1  implementation rules that characterize correct  though not necessarily preferred  circuit implementations  and  1  control knowledge for selecting the preferred implementation from among multiple legal options this partitioning is important because it helps in dealing with the common problem that when one adds a new rule to a knowledge base one must often adjust existing rules as well. 
   the first of these two parts of the knowledge base has the convenient property that its rules are logically independent; that is  when one adds a new implementation rule characterising a new implementation method  it does not alter in any way the correctness of the existing implementation rules. thus  when a 
   new implementation rule is added  the only portion of the knowledge base that might require an update is the control knowledge for selecting among alternative implementations. this 
　       even this it not quite true. since its domain theory is only approximate  at will probably be true for learning apprentice systems in general   there may be incorrect circuits that it succeeds in verifying  say  because is overlooks parasitic capacitances . 
1 	t. mitchell et al. 

when combining sets of rules that may have been learned from various users by different copies of the learning apprentice while the problem of combining multiple rule sets learned from different sources is in principle simply a matter of forming the union of the rule sets  in fact the resulting set of correct rules may be overly redundant and disorganized. thus  we anticipate that we may have to develop methods for merging and reorganizing sets of correct rules to make them more manageable. 
　　to date  we have only considered learning the first type of knowledge. in some sense  learning these rules is easier than learning the control knowledge  because the complexity of explaining a training example is much less for implementation rules than for control rules. to explain/verify an example of an implementation rule  the system need only verify the correctness of the circuit fragment mentioned in the training example. however  to learn a control rule that characterises when some implementation is preferred  it is necessary to compare this implementation with all the alternative possibilities. thus  the complexity of constructing the explanations is quite different in these two cases. in the longer term  we see learning of control knowledge as an important task for leap  and a task for which it can easily capture useful training examples. 
	i v 	conclusion 
	we 	have 	presented 	the 	notion 	of 	a 	learning 	apprentice 
system as a framework for automatically acquiring new knowledge in the context of an interactive knowledge-based consultant the initial design of a learning apprentice for vlsi design has been described. in particular  we have detailed the methods that l e a p employs for learning new implementation rules  and for generalizing both the left and right hand side of these rules. whereas previous attempts at automatic knowledge acquisition have met with little success  the proposed learning apprentice system differs in two important respects. it utilizes more powerful analytical learning methods  and it is restricted to interactive knowledge-based systems which can easily capture useful training examples. we are currently completing our initial implementation of leap  and intend to test it on a user community of students in a vlsi design course to gather data and further insights on this initial design. 
	v 	a c k n o w l e d g m e n t s 
　　we thank several people who provided useful criticisms of earlier drafts of this paper: rich keller  yves kodratoff  john mcdermott  jack mostow  reid smith  and timothy weinrich. 
we also thank the members of the rutgers a l / v l s i project for many useful discussions regarding the design of leap  and for creating the v e x e d system on top of which l e a p is being constructed. schlumberger-doll research has made the strobe system available as a representation framework in which v e x e d and l e a p are being implemented. this research is supported by the defense advanced research projects agency under research contract n1-k-1  and by the national science foundation under grant dcs1. 
