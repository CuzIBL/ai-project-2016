allophonic and phonotactic constraints are useful 
kenneth w. church 
ne1 
massachusetts institute of technology 
cambridge  ma. 1 
kwc mit-ml 

     this paper argues that allophonic and phonotactic cues are a source of constraint  not a source of noise as many speech researchers have assumed in the past. these constraints are formulated so that they can be exploited with well-known parsing techniques. 
1. parsing at the phonetic level 
     it is well known that phonemes have different acoustic/phonetic realizations depending on the context.1 for example  the phoneme /t/ is typically realized with a different allophone  phonetic variant  in syllable initial position than in syllable final position. in syllable initial position  e.g.  lorn   /t/ is almost always released  with a strong burst of energy  and aspirated  with /h/ like noise   whereas in syllable final position  e.g.  ca    /t/ is often unreleased and unaspirated. it is common practice in speech research to distinguish acoustic/phonetic properties that vary a great deal with context  e.g.  release and aspiration  from those that are relatively invariant to context  e.g.  place  manner and voicing .1 in the past  the emphasis has been on invariants; allophonic variation is traditionally seen as problematic for recognition. 
 1   in most systems for sentence recognition  such modifications must be viewed as a kind of 'noise' that makes it more difficult to hypothesize lexical candidates given an input phonetic transcription. to see that this must be the case  we note that each phonological rule  in an example to be presented below  results in irreversible ambiguity - the phonological rule does not have a unique inverse that could be used to recover the underlying phonemic representation for a lexical item. for example ... schwa vowels could be the first vowel in a word like 'about' or the surface realization of almost any english vowel appearing in a sufficiently destressed word. the tongue flap  ♀  could have come from a /t/ or a /d/.  klatt  mit   1  pp. 1  
this position is representative of much of the speech recognition literature  especially during the arpa speech project. one can find similar statements by cole and jakimik  cmu   and by jelinek  ibm  . i prefer to view both variant and invariant cues are helpful: variant cues reveal properties of the suprasegmental context and invariant cues reveal properties of the local segmental identity. this much has been observed elsewhere. for example  the following minimal pairs have been used by many authors to show that allophones of /t/ can be distinctive. 
 1a  a tease / at ease aspirated / flapped  1b  night rate / nitrate unreleased / retroflexed  1c  great wine / gray twine unreleased / rounded unfortunately  these allophonic constraints on syllable structure and word stress have never been adequately integrated into a practical recognition system. i have attempted to remedy this situation in   where i proposed  and partly implemented  a recognizer that exploited contextually dependent cues  e.g.  aspiration  by parsing the input utterance into syllables and other suprasegmental constituents using phrase-structure parsing techniques  e.g.  earley's algorithm  . invariant constraints were applied in the usual way to match portions of the utterance with entries from the lexicon. 

k. church 1 
1. an example of lexical retrieval 	fig. 1. did you hit it to tom  

illustrates: 
 1a  	palatalization of / d / before /y/ in did you 
 1b  	reduction of unstressed / u / to schwa in you 
 1c  	flapping of intervocalic iv in hit it 
 1d  	reduction of schwa and devoicing of / u / in to 
 1e  	reduction of geminate iv in it to 
it is very difficult for the recognition device to  undo  these phonological transformations. inverse transformational parsing is generally considered among computational syntacticians to be unlikely to succeed. even stan petrick  personal communication   one of the few proponents of inverse transformational parsing at the syntactic level  agrees that inverse transformational parsing methods are unlikely to work well with phonological rules. in particular  allophonic processes often appear to neutralize phonemic distinctions. for example  the voicing contrast between iv and 1  which is usually distinctive  is almost1 completely lost where both iv and 1 are realized in american english with a tongue flap  i . 
1. parsing and matching 
     as an alternative to inverse transformational parsing  i will factor the lexical retrieval problem into two  hopefully simpler  sub-problems:  a  parse the segment lattice into syllable structure  and  b  match the resulting constituents against the lexicon. as suggested above  variant phonological cues help constrain the parsing step; invariant cues restrict the matching process. 
1. the contrast is not completely lost. in general  vowels are longer before voiced consonants than before unvoiced consonants. thus  the underlined vowel in rider tends to be longer than the corresponding vowel in writer. 

1 	k. church 

     a demonstration parser has been implemented and tested on a set of linguistic transcriptions. the program performs as well as can be expected with these methods. the program finds the intended decoding and no others  except when there are errors in the lexicon  grammar  input transcription or when higher level 
constraints  e.g.  syntax  semantics  pragmatics  are required.1 the emphasis here has been on methodology  rather than bottomline performance. to focus on numbers at this early stage in speech research seems premature  especially in light of the fact that no machine to date is as good as a human listener  or a spectrogram reader  at producing the input transcriptions. 
1. concluding remarks 
　　　in the past  lexical retrieval has been viewed as a single step process. instead of parsing the input transcription into allophonically and phonotactically well-formed substrings and passing just those substrings onto the lookup routines  previous systems have tended to pass all n n-1 /1 substrings onto the lookup routines. my proposal is more efficient because it will discover that most of the substrings are ill-formed and need not be looked up in the lexicon.1 in addition  it may be easier to predict what will happen with very large lexicons  because my approach depends more on fundamental grammaticality constraints than accidental gaps in the lexicon. 
　　　in conclusion  the parsing and matching approach depends on the hypothesis that a syllable-like constituent structure is an appropriate intermediate level of representation. just as syntacticians have argued for the introduction of constituent 
1 for example  given a transcription of this is the cbs ...  the system will produce the word lattice this is the  or c see sea   or b be  1 see the appendix iv of  for some more sample output. 
1 of the n n-1 /1 possible substrings  it can be shown that  in many cases  only 1n 
of them can be allophonically and phonotactically well formed  1 ′1.1 . reducing the search space in this way results in substantial savings  assuming that lexical lookups are more expensive than testing for well formedness. the validity of this assumption depends on the size of the lexicon and the machine architecture. it might be a very reasonable assumption  if  for example  the lexicon is very large and a lexical lookup is very likely to induce a paye fault. 
structure on the grounds that noun phrases  verb phrases and sentences seem to capture crucial syntactic generalizations  e.g.  question formation  wh-movement   so too  i might argue  along with certain phonologists such as kahn   for the introduction of syllable structure because syllables  onsets and codas capture important allophonic and phonotactic generalizations such as aspiration  tensing and iaxing. if this constituency hypothesis is appropriate for the analysis of speech  then it seems natural to propose a syllable parser for processing speech  by analogy with sentence parsers that have become standard practice in the natural language community for processing text. 
