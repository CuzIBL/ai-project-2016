 
we examine an approach to multi-agent coordination that builds on earlier work on enabling single agents to control their reasoning in dynamic environments. specifically  we study a generalization of the filtering strategy. where single-agent filtering means tending to bypass options that are incompatible with an agent's own goals  multi-agent filtering means tending to bypass options that are incompatible with other agents' known or presumed goals. we examine several versions of multi-agent filtering  which range from purely implicit to minimally explicit  and discuss the trade-offs among these. we also describe a series of experiments that demonstrate initial results about the feasibility of using multi-agent filtering to achieve coordination without explicit negotiation. 
1 	introduction 
distributed artificial intelligence  dai  is concerned with effective interactions  and with the mechanisms by which these interactions can be achieved. broadly speaking  two main approaches have been proposed in the literature. the first involves explicit coordination; agents are designed to reason about their potential interactions  and negotiate with one another as needed. examples of this approach include  ephrati and rosenschein  1; 1; kraus  1; zlotkin and rosenschein  1 . a difficulty with explicit coordination and negotiation is that it can be extremely time-consuming  and in dynamic environments  agents may not be able to afford the time required. the second approach involves implicit coordination; agents are designed to follow  local  rules of behavior that lead to their acting in apparently coordinated ways; see  for example   shoham and tennenholtz  1; goldman and rosenschein  1 . this approach is motivated in part by a belief that one can design simple rules that are easy for an agent to follow  yet result in coordination. 
　in this paper  we take the second approach  examining an implicit coordination strategy. the strategy we study  multi-agent filtering  is an extension of a singleagent strategy for controlling reasoning in dynamic environments. the notion of single-agent filtering derives from the work of bratman  bratman  1 ; it involves an agent committing to the goals it has already adopted  and tending to bypass  or  filter out   new options that would conflict with their successful completion  bratman et a/.  1; pollack  1; pollack et a/.  1 . we and 
others have studied the effectiveness of filtering in domains with various characteristics kinny and georgeff  1; pollack et a/.  1 . 
　the original filtering strategy was designed as a method for an individual agent to focus its reasoning in a dynamic  but not necessarily multi-agent  environment. here  we generalize this strategy to multi-agent environments. where single-agent filtering means tending to bypass options that are incompatible with an agent's own goals  multi-agent filtering means tending to bypass options that are incompatible with any agent's known or presumed goals. 
　we examine several forms of multi-agent filtering  which range from implicit  in which agents have rules of legal action that lead to their avoiding conflict without ever reasoning explicitly about one another's goals  to minimally explicit  in which agents perform shallow reasoning to assess whether their actions are incompatible with the likely intended actions of other agents. in no cases do the agents engage in any explicit negotiation. it seems clear that if one agent  call it a  avoids interfering with the goals of a second agent  call it b  then b will be better able to achieve its goals. but what about a  won't its performance be worse  because it is subject to additional constraints on its behavior  if a is the only multi-agent filterer  it seems likely that its performance will suffer  but if a and b are both multi-agent filterers  then the effect is less obvious. what we need to ask is whether the advantage that a derives from b's multiagent filtering is sufficient to override any penalties a receives from its own multi-agent filtering. and we need to ask the same thing about b. the central questions we address in this paper are thus: what happens in multiagent environments in which all  or most or few or none  of the agents are multi-agent filterers  and do these effects depend  in any interesting and identifiable ways  on properties of the domain  to address these questions  we conducted a series of experiments using a multi-agent version of the tileworld system  pollack et a/.  1; joslin et al.  1   an abstract testbed for studying behavior in dynamic environments. 
　in the next section  we review the theory of filtering  and discuss its generalization to the multi-agent case. a brief overview of the experimental platform is provided in section 1. sections 1 through 1 present our experimental results on multi-agent filtering to date: section 1 describes experiments with extremely bold multi-agent filterers  section 1 describes the effectiveness of enriching the filter with an override mechanism  and section 1 considers the implications of multi-agent filtering in environments of self-motivated rational agents. the most interesting and surprising result is that  at least for the simple  abstract environments so far studied  multi-agent filtering is a dominant strategy: no matter what proportion of the agents in some environment choose not to filter  those that do filter perform better. we summarize our results in section 1. 
1 	filtering and multi-agent filtering 
our work on multi-agent filtering derives from our earlier work on filtering as a strategy that individual agents can use to focus their reasoning. the notion of filtering derives from the work of bratman  bratman  1   who argued that it is useful for resource-limited agents to adopt and commit to plans  tending to bypass  or  filter out  from consideration new options that would conflict with the successful completion of those existing plans. on this view  an agent's existing intentions frame its subsequent reasoning: the agent can focus on ways of achieving its current goals  and can  in general  bypass deliberation about the myriad of options that are incompatible with its current goals. 
　typically  filtering is augmented with some kind of override mechanism that enables the agent to deliberate about options that are prima facie important  even when they are incompatible with pre-existing options. a central challenge for the designer of an agent with a filtering mechanism is to construct an override component that embodies the right degree of sensitivity to the problems and opportunities of the agent's environment. 
　note that the filter-plus-override mechanism does not  by itself  determine what intentions the agent will adopt. when an option survives the filter  either because it is deemed compatible with existing plans or because it triggers an override  it is then subject to a deliberation process that selects the actions towards which the agent will form intentions. in other words  it is the deliberation process that performs the type of decision-making that is the focus of traditional decision theory. the filtering mechanism frames particular decision problems  which the deliberation process solves.1 
　in fact  in his original discussion of the role of commitment in resource-limited reasoning  bratman suggested two advantages that accrue to an agent who uses a filtering strategy. first  filtering can help the agent focus its reasoning  as described just above; this has been a 
l
   the filtering mechanism is meant to be only one part of a rich meta-level control structure. thus  for example  agent designers may also want to include mechanisms to filter from full consideration options that are especially unpromising  even if they are compatible with existing plans. 
1 	distributed al 
main concern in our previous work. second  filtering can help multiple agents coordinate their activities  because each agent can count on the other agents carrying out the plans to which they have committed. following this observation  we hypothesized that it was possible and desirable to extend the strategy of filtering for multiagent environments so that it could serve as a technique for coordination as well as for control. the basic idea is straightforward: not only should agents tend to bypass consideration of options that conflict with their own goals  but they should also tend to bypass consideration of options that conflict with the goals of other agents. 
　the precise interpretation of conflict depends on the relationships that hold among the goals of the agents in the environment. for example: 
1. the agents may have one common goal  but individual and distinct subgoals. in this case  avoiding conflict means avoiding actions that make it more difficult for another agent to achieve its subgoals. this situation underlies the work on social laws  moses and tennenholtz  1   where the  implicit  common goal is the maximization of the designer's reward  through the individual activities . 
1. the agents may have one common goal  but potentially overlapping subgoals. here   conflict  can mean achieving  or helping in the achievement of  a subgoal for another agent. to some extent  this situation underlies the work on cooperative statechanging rules  goldman and rosenschein  1 . 
1. the agents have distinct  possibly conflicting  goals. there may be competition not only for resources to achieve goals  but also for the goals themselves. this case would appear to pose the greatest challenge to a multi-agent filtering strategy. 
　as we discuss below  in conducting our experiments we addressed each of these variants. 
1 experimental platform 
the tileworld testbed is a lisp-based tool that was developed to support controlled experimentation with agents in dynamic environments. for the current project  we built a multi-agent version of the tileworld system  called ma-tileworld. we first briefly describe the ma-tileworld  and then discuss some details of the multi-agent filtering strategies. 
1 	the multi-agent tileworld system 
like the original tileworld  ma-tileworld is an abstract  dynamic  simulated environment  with embedded agents. it is obviously  and intentionally  a highly artificial environment. in keeping the environment divorced from any realistic application  our goal has been to provide a tool that allows researchers concerned with any application to focus on what they consider to be key features of that application's environment  without the confounding effects of the actual  complex environment itself. we have  in other words  traded realism-in the short run  at least-for sufficient control to allow for systematic experimentation.  cf.  hanks et a/.  1  . 
　the ma-tileworld environment consists of a rectangular  two-dimensional grid  on which are located a variety of objects  including holes  tiles  obstacles  etc.  and simulated agents. a trial is a single run of the matileworld system  defined by its duration and its experimental condition  user-specified parameter settings that establish agent and environment conditions. trials for the same experimental condition will  in general  differ from one another  because the system's performance depends stochastically on the parameter settings. 
　an example of an experimental condition is the rate at which objects  tiles  etc.  appear and disappear during the trial. when a ma-tileworld agent successfully fills a hole with tile s   it receives an reward  the size of which depends on the type of tiles that were used to fill the hole. the agent may carry one or many tiles at a time; however  the more tiles it carries  the more energy  or  gas   it expends; agents must be concerned not only with filling holes but also with maintaining sufficient energy. for further details see  pollack et al  1; joslin et a/.  1 . 
　the agents that are embedded in the ma-tileworld observe a filtering strategy. that is  they bypass consideration of options that are incompatible with their own goals except when those options trigger an override. the question of how easy it is for an option to trigger an override is put under the control of the experimenter  who specifies a override threshold t. when the agent recognizes an option o that is incompatible with its existing goals  it computes an estimated value v1 for o. for o to trigger a filter override  v1 must exceed the computed value of the current intentions by at least t. thus  the lower the threshold  the more likely the agent is to allow options to pass through the filter  and hence the more likely it is to engage in deliberation: in the terminology of  bratman et a/.  1   the more cautious the agent will be. in contrast  we say that an agent with a high threshold is bold. the threshold can be negative  to allow for full deliberation even about options that appear  upon original estimation  to be less valuable than the intention s  with which they conflict. in all the experiments described in this paper  the estimated value of a fill-hole option was set equal to the raw score of the hole  i.e.  the highest score that will be achieved if the hole is successfully filled with the best tiles ; the estimated value of getting gas is a function of the agent's current gas level; and the estimated value of the other options  such as stockpiling tiles and wandering  is a low constant. 
1 	operationalizing multi-agent filtering 
the filtering process as just described disposes agents to filter from consideration options that are incompatible with their own existing intentions. for our current purposes  we generalized this strategy to the multi-agent case. recall that our goal is to investigate filtering as an implicit coordination strategy  i.e.  a set of easily followed rules for behavior that result in coordinated action by multiple agents inhabiting some environment. thus  our implementation of multi-agent filtering had to observe strict limits on the amount of reasoning that each agent needs to do about the others. we implemented and investigated three different filtering methods: 
1. static geographical boundaries: the environment is divided into geographical regions. each agent is assigned a particular region  and filters out options to fill holes in other regions. because no two agents are assigned the same region  filtering automatically leads to conflict avoidance. 
1. dynamic geographical boundaries: the environment is not partitioned a priori. instead  each agent filters out options to fill holes that are nearer to some other agent than to itself. this leads to conflict avoidance  since every hole is nearest to a single agent. 
1. intention posting: the first two cases are clearly  implicit : the agents can follow those filtering strategies without any computations that directly take into consideration the goals of other agents. this third approach is slightly more explicit: here  agents post to a globally accessible data structure each intention they form to fill a hole. agents then filter from consideration hole-filling options that have already been declared by other agents. 
　note that in all cases  hole-filling is the only type of option that may lead to multi-agent filtering in these experiments; options like getting gas and stockpiling are never seen to be incompatible with another agent's goals. it is also important to remember that just because an option is subject to filtering  it does not mean that that option will necessarily be discarded from consideration. what it does mean is that it will be further considered only if it triggers a filter override  i.e.  it is deemed prima facie to be worthy of deliberation despite the fact that it conflicts with another agent's goals. if deliberation does occurs  it may result in adopting a new intention towards the option  but it may also result in bypassing the option. 
　in our first set of experiments  section 1   we studied agents that were extremely bold: they can be viewed either as having no override mechanism at all  or  equivalent   as having an override mechanism with an infinite threshold value.  this is  in fact  how they were implemented.  for these agents  options that were deemed incompatible with the options of other agents never triggered an override and thus were never subject to deliberation. note that the agents had a single override mechanism  which did not distinguish between options that conflict with their own existing plans and those that conflict with the plans of other agents. thus  the extremely bold agents also filtered out all options that were deemed incompatible with their own goals. as we will describe  the use of a multi-agent filtering strategy  even such a rigid  bold  one  improved the agents' overall performance. in a second set of experiments  section 1   we explored the effect of making the multi-agent filtering process more flexible  by including particular override strategies. the results demonstrate cases in which overriding is important. 
　in all these experiments  what we measured was the total effectiveness of the agents. effectiveness  for the 
　
single-agent tileworld  is defined to be a normalized measure of an agent's score: the score it actually received during a trial divided by the total full score of all the holes that appear during the trial. in the multiagent case  we compute  average  effectiveness by summing the scores received by all the agents and dividing by the total score of all the holes that appear during the trial. thus defined   average  effectiveness is an appropriate measure for first two types of multi-agent settings mentioned above: those in which all the agents share a common goal  and may or may not have potentially overlapping subgoals. for the third type of setting  in which the agents may have competing goals  we measured the average effectiveness of agents with each strategy. 
1 	rigid filtering 
in the first set of experiments  the strategy of extremely bold multi-agent filtering was studied. we examined each of the three filtering mechanisms defined above  static geographical boundaries  dynamic geographical boundaries  and intention posting . a fourth experimental condition involved extreme caution: agents deliberated about all options that appeared in the tileworld grid  regardless of whether they were potentially or actually incompatible with the goals. 
　this set of experiments was aimed at examining the effectiveness of multi-agent filtering in various environmental conditions. in the tileworld environment  the most influential parameters are the average rate of change in the world  the  world speed    and the average number of holes available to fill at any time. we therefore conducted two experiments; in the first one we varied the rate of change in the world  while in the second we held world speed constant and varied the average number of holes. 
　both experiments involved four agents on a 1 grid. their  thinking  speed was set to a baseline rate established in our earlier experiments  pollack et a/.  1 . the agent's  moving  speed was varied directly with the rate of world change  because our interest is in the relation between the agent's computation cycle time and the degree of dynamism in the world  not between the speed at which the agent can move and the degree of dynamism in the world. generated holes were were randomly assigned a score of between 1 and 1  again consistent with baselines established in our earlier experiments. 
　for each experimental condition  we ran 1 trials  where the length of each trial was 1 clock ticks  which is equivalent to the amount of time it takes an agent to move 1 units of distance . the number of trials per condition and the length of each trial are the same as in our earlier  single-agent experiments. 
　figure 1 describes the case where the the world speed was changed. there were a total of 1 experimental conditions  1 filtering strategies and 1 rates of dynamism . the x-axis shows the world speed: experimental results for the least dynamic worlds are shown at the origin  and speed increases across the x-axis. average effectiveness is plotted on the y-axis. as can be seen  all three multi-agent filtering strategies result in better performance than no filtering  regardless of the rate of change 
1 	distributed al 

in the world. among the filtering strategies  a society of intention posting agents performs better than a society of agents using either of the geographic strategies  both of which result in quite similar performance. 

figure 1: bold filtering with varied number of holes 
　figure 1 shows the experiment in which world speed is held constant at a baseline level  while the average number of holes in the world is varied between four and sixteen. effectiveness is again plotted on the y-axis. the results are similar to our first experiment: regardless of the average number of holes in the environment  the multi-agent filterers do best  and the best of the multiagent filtering strategies is intention posting. 
　we believe that the intention posting outperforms the other two filtering strategies because it is more accurate: agents will avoid goals that other agents actually intend to pursue  rather than avoiding goals that others might pursue. in addition  intention posting is computationally simpler than the dynamic geographic strategy: instead of calculating whether the goal is within the the agent's territory  the filter is triggered by an immediate lookup operation.  the additional computational overhead of the dynamic geographic strategy may also explain why it performs somewhat worse than the static geographical strategy.  these results suggests that in some cases  minimally explicit coordination strategies like intention posting may outperform implicit coordination. 
1 	filtering with overriding 
the first set of experiments involved extremely bold agents  who never deliberated about options that were deemed to be incompatible with the goals of other agents. but  as we noted above  such unconditional acceptance of other agents' goals may lead to inefficiencies in performance  just as unconditional acceptance of one's own goals may lead to inefficiencies. this is why we include an override mechanism along with filtering. in  pollack et a/.  1   we described conditions in which overriding was beneficial for the single-agent case. our next step was thus to investigate how overriding affects performance in the multi-agent setting. 
　what exactly does overriding amount to in the matileworld  recall that multi-agent filtering results in agents bypassing consideration of options that they believe would interfere with the goals of other agents; in other words  multi-agent filterers avoid  stepping on one another's toes.  but sometimes they should step on one another's toes. the reason is that the world is dynamic: opportunities don't last forever. sometimes the possibility of successfully filling a hole may disappear by the time it could be filled by the responsible agent-either the one in whose geographical area the hole lies or the one who has declared an intention to fill it. in some such cases  the opportunity may be captured by another agent who happens to be nearby. but this will only occur if that nearby agent can override the normal filtering of the option to fill the hole in question. 
　to operationalize the override mechanism in the matileworld  we used a threshold technique similar to that used in our single-agent experiments. the threshold t is set by the experimenter. the value of the conflicting  hole-filling  option o is then computed as the maximal score that will be awarded if the hole is filled  divided by the manhattan distance between the agent and the hole. we included overriding both in a static geographic strategy and an intention posting strategy; because the earlier experiment suggested that the overhead associated with the dynamic geographic strategy was too high  we did not include that in these experiments. 
　we further considered the question of whether the original agent-the one whose toes are being stepped on-should be notified of this fact. in the first two experimental conditions  agents are not notified when another agent takes over one of their goals. in the third experimental condition  intention posting with preemption  conflict is determined via intention posting  but  when an override occurs  the original agent is notified that its goal has been taken over  and so drops the goal and looks for an alternative. 
　in our earlier work  we determined that extreme boldness was a surprisingly good strategy in a wide variety of single-agent tileworld environments. overriding became beneficial in environments which can be characterized as presenting many opportunities that have relatively small payoff  and occasional critical opportunities  which have high payoff but short deadlines. under those circumstances  it seems natural to think that extreme commitment to existing goals would not be a good strategy  because the high-payoff opportunities  if they are to be successfully acted on  require a quick response. we therefore constructed an environment that had those characteristics. in particular  it had two types of holes.  common   c-type  holes were quite numerous  had low scores and long lifetimes  and took a long time to fill.  special   s-type  holes were rare  had high scores and short lifetimes  and took a short time to fill. we studied similar environments for the multi-agent case. 
　for this experiment  we again used a 1 grid with four agents  and held the world speed constant at a baseline value. the number of c-type holes varied in the range of 1 with a score of 1  while the number of s-type holes varied in 1 with score range of 1 . the results are summarized in figure 1  which shows the overall effectiveness  on the y axis  as a function of the filtering threshold  on the x axis . 

figure 1: overriding in the multi-agent tileworld 
　as the graph shows  overriding is indeed beneficial  at least in the environmental parameters that we have considered. moreover  the filtering threshold has a significant influence on the effectiveness of a specific filtering strategy. although there are several local maximas  for each filtering strategy there is a unique threshold value where the maximal effectiveness is attained. in none of the experimental conditions was either extreme boldness or extreme caution the optimal strategy. 
　perhaps more surprising was the relative performance of the various operationalizations of filtering in this environment. recall that in the uniform environments studied in the first set of experiments  intention posting was always the best method of filtering. here  the geographical-boundaries method is best  except when the override threshold is very high. this result led us to re-evaluate what is significant about the alternative filtering methods. what we realized is that what is particularly important in all the environments we studied is for the agents to maintain reasonable geographical separation from one another. in the uniform environments of the first set of experiments  all the filtering strategies lead to geographical separation. with geographical boundaries filtering  the agents focus on holes in distinct 
　
areas  and so tend to stay separated. with intention posting filtering  agents dynamically create separate regions because they tend first to form plans to fill nearby holes  and thus create territories that are avoided by other agents. moreover these territories tend to stay fixed  because filtering is absolute. 
　however  once overriding is introduced  the stability of these local areas decreases. with a relatively low threshold  posted intentions will frequently be overridden by other agents  and there is nothing to prevent the agents from becoming clustered in one area of the grid and thus missing many remote opportunities. in contrast  although geographical-boundaries filtering will also be subject to frequent overrides  once any particular out-of-region goal is completed  the agent will return to its original territory. 
　although this result in some sense is quite specific to the ma-tileworld environment  it can be related to a much more general claim about the importance of resource distribution in coordination. what is interesting about this case is that the resources are both goals and objects needed to satisfy those goals. 
1 	the effect of defectors 
the first two sets of experiments aimed at giving at least preliminary evidence that multi-agent filtering can be an effective means to achieve collaboration: it is an implicit strategy  requiring only that agents observe local rules of behavior  and it leads to overall improved performance  at least within the simulated environments we investigated. however  the fact that global performance is better if all the agents adopt a filtering strategy does not  in and of itself  guarantee that each agent will choose this strategy  if it has the choice. in some  and perhaps most  settings agents will have individual goals and utility functions: their concern is not with global performance  but with maximization of their private utility. we addressed these settings with experiments that abandon the assumption that agent will benevolently adopt the filtering coordinating mechanism. we assumed instead simply that agents are self-motivated  rational . 
　game theory has addressed many interactions similar to the ones considered here. such interactions have been analyzed to determine what an agent's chosen strategies would be  given the rules of the interaction. our aim is complementary; it is to design rules that would induce the agents to adopt some specific strategy that we consider to be desirable. in our case we would like to make cooperation be the individually desired strategy. that is  each agent should prefer  out of  selfish   rational  considerations  the filtering strategy over the other alternatives she might have. if all agents find cooperation to be their superior alternative it becomes an equilibrium point. in particular  a very strong claim would be that  regardless of whether the other agents are multiagent filterers  each agent should itself choose to be one  i.e.  multi-agent filtering is dominant to not filtering: 
definition 1 the strategy s* is a dominant strategy if it is an agent 's strictly best response to any strategies that the other players might pick  in the sense that whatever strategies they pick  his payoff is highest with si . 
1 	distributed al 
　a dominant strategy equilibrium is a strategy combination of each player's dominant strategy. 
　thus  a strategy combination that is a dominant strategy equilibrium is very desirable. the fact that there is no importance to the other agents' behavior does away with the need to reason about the other agents' strategies  knowledge  or even computational capabilities. the behavior of an agent depends solely on its own characteristics. 

　to explore the question of whether the filtering strategy is dominant  we conducted another experiment  using ma-tilewords populated by fifteen agents  only some of whom were cooperative. we varied the number of cooperative agents across trials  and measured the performance of the cooperative agents  the performance  average effectiveness  of the non-cooperative agents  and the global performance. we used the relatively weaker intention-posting method of filtering  and held world speed fixed at a baseline rate.1 the experimental results are summarized in figure 1. the x-axis indicates the number of filtering agents  out of the total population of fifteen   and the y-axis shows the effectiveness. 
　as can be seen from the graph  the higher the percentage of filtering agents  the better the global performance is. but more importantly  the graph shows that at any given ratio of filtering to non-filtering agents  the filtering agents are doing better. that fact implies that regardless of the other agents' behavior  each agent should choose to cooperate and thus guarantee itself a higher utility. that is  at least for the range of environments that we have examined  intention-posting multi-agent filtering is in dominant strategy equilibrium.1 
   1  other experimental parameters were: number of c-type holes=1  score of c-type holes=1  number of stype holes= 1  score of c-type holes=1. also  the grid was enlarged to 1  to accommodate the increased number of agents. 1  another phenomenon worth noting is that the effectiveness of the non-filtering agents improves as their proportion of the population decreases. this fact recalls the well-known parasite phenomenon of evolutionary game theory  and deserves further study. 
1 	conclusions 	