 
this paper is a comparison of abstrips  planning  as d e f i n e d in newell and simon  1  and gps. each of these methods has parameters chat contain h e u r i s t i c i n f o r m a t i o n which is problem dependent. these parameters are used to guide the methods1 search and u s u a l l y cause them to be incomplete in the sense t h a t they cannot solve some problems t h a t have s o l u t i o n s . we show t h a t the parameters of the methods serve the same f u n c t i o n in the f o l l o w i n g sense: given the parameters f o r one method we can formulate the parameters f o r the other two such t h a t a l l three can solve the same class of problem; i . e . those which have t o t a l l y ordered s o l u t i o n s . this r e s u l t is somewhat s u r p r i s i n g because the search spaces of the methods are d i f f e r e n t . the i m p l i c a t i o n s of t h i s r e s u l t to the e f f i c i e n c y of search is discussed at some l e n g t h . 
	1 . 	i n t r o d u c t i o n 
the purpose of t h i s paper is to compare 1 d i f f e r ent problem s o l v i n g methods: abstrips   s a c e r d o t i   1 ; planning  newell and simon  1  and gps  ernst and newell  1 + . the r e l a t i o n s h i p between planning and gps is reasonably w e l l understood  but t h e i r r e l a t i o n s h i p to abstrips has been much less understood. 
a l l three methods are incomplete in the sense that they cannot solve c e r t a i n problems t h a t have s o l u t i o n s . hence  it makes sense to attempt to c h a r a c t e r i z e the class of problems that they can s o l v e . this should allow one to answer such quest i o n s as   under what c o n d i t i o n s can gps solve any problem t h a t abstrips can solve   to answer such questions we w i l l b u i l d a formal model of abstrips 
this research was supported by the national 
science foundation under grants gj-1 and mcs1. 
 planning and gps were conceived of by al newell  c l i f f shaw and herb simon in the 1's. the references given here were chosen because they are more accessible than t h e i r o r i g i n a l p u b l i c a t i o n s . this use of the word ' p l a n n i n g 1 is somewhat d i f f e r e n t than i t s use i n r o b o t i c s research. 
and p l a n n i n g . the model deviates s l i g h t l y from the way abstrips r e a l l y works but it is a close approximation to abstrips. using t h i s model and the one f o r gps   e r n s t   1  we can answer the above q u e s t i o n . 
the formalisms are not in themselves p a r t i c u l a r l y i n t e r e s t i n g . however  they do reveal the r e l a t i o n s h i p among parameters of the three methods. that i s   each method has c e r t a i n h e u r i s t i c i n f o r mation as parameters to guide i t s search. in gps  the parameters are the d i f f e r e n c e s and d i f f e r e n c e o r d e r i n g ; in abstrips they are the c r i t i c a l i t y l e v e l s of the various p r e d i c a t e s . our analysis c l e a r l y shows the r e l a t i o n s h i p between these two kinds of parameters. in a d d i t i o n   since there are formal c o n d i t i o n s of  good  d i f f e r e n c e s f o r gps  ernst  1   these conditions should place cons t r a i n t s on  good  parameters f o r abstrips and p l a n n i n g . sacerdoti  1  gives some i n f o r m a l r u l e s that he uses in assigning c r i t i c a l i t y l e v e l s to predicates which are consistent w i t h the conditions of good d i f f e r e n c e s but the l a t t e r are cons i d e r a b l y stronger than h i s r u l e s . 
we s t a r t o f f w i t h a b r i e f d e s c r i p t i o n of abstrips and p l a n n i n g . this is followed by a f o r m a l i z a t i o n and analysis of abstrips and p l a n n i n g . the l a s t s e c t i o n contains a discussion of the three methods. 
	1. 	problem s p e c i f i c a t i o n 
a problem s t a t e of abstrips  and i t s predecessor strips  fikes and n i l s s o n   1   is a set of formulae i n f i r s t - o r d e r l o g i c . for example  i f the formula inroom  robot  rooml  were p a r t of the s t a t e   that would i n d i c a t e that the robot was in room 1 in the s t a t e . the set of desired states is also represented by a formula  w. any s t a t e which implies t h a t w is true is a desired s t a t e . 
the operators are r u l e s f o r transforming one s t a t e i n t o another. for example  if the robot wanted to 
move boxl to box1 it would use the operator pushb boxl  box1  where pushb is given in figure 1. for t h i s operator to be a p p l i c a b l e   the p r e conditions must be t r u e of the current s t a t e   
i . e .   the preconditions give the domain of the operator. the c u r r e n t s t a t e is modified by del e t i n g a l l o f the formulae l i s t e d under d e l e t i o n s and adding the formulae under a d d i t i o n s . for 

p r o b l e m - s o l v ! n f t - 1 : 	r a n o r j   
1 

example  if nextto boxl  doorl  was in the current state it would be one of the deletions and nextto boxl  box1  would be one of the additions in forming the new state resulting from applying pushb boxl  box1 . the $1 in figure 1 is just a variable. 
pushb  x y  preconditions: type y  object  
pushable x  
nextto robot x  
1r  lnroom robot r  & inroom y r  
　　　　　　　　& inroom x r   deletions: nextto robot $l  
nextto x $l  
   nextto $l x  additions: nextto x y  nextto y x  nextto robot x  
figure 1. 
the abstrips operator that pushes box x to object y. 
problem. 
robot 1   j    l.. b1 
r l   dl 
b1~ 
r1 i n i t i a l state: 
operators: c r i t i c a l i t y : pushb x y -push box x to object y. 
ptd x y -push box x through door y. 
gotob x -go to box x. 
pushd x y -push box x to door y. 
other operators are not given here because they are not necessary to 
solve this problem. 
level 1-type  pushable desired states: nextto bl b1  
level 1-inroom level 1-nextto 

for the purposes of this report the details of the problem specification are not important. the important thing is that each problem has a state space  an i n i t i a l state  a set of desired states  and a set of operators. each operator is a part i a l function from states into states. the domain 
of the operator is given by its preconditions. it should be noted that pushb is really a partial function schema; it becomes a partial function after values are specified for x and y  i . e .   pushb boxl  box1  is a partial function. the point is that abstrips is not dependent on the problem specification language but i t s underlying algebraic structure. hence  abstrips could be applied to problems specified in the other languages such as the one given in ernst  et al  1  in which states are represented by arrays. 
	1. 	description of abstrips 
abstrips assumes that each predicate in the preconditions of operators has a c r i t i c a l i t y level assigned to i t .  actually sacerdoti  1  has a  semi-automatic way of assigning c r i t i c a l i t y l e vels.  the intuitive idea behind c r i t i c a l i t y levels is that high level predicates are more d i f f i c u l t to change than low level predicates. 
a simple problem is given in figure 1 and abstrips1 solution is depicted in figure 1. 	it starts off by trying to transform the i n i t i a l state in figure 1 into one in which bl is next to b1. 	 this is subproblem 1 in figure 1.  abstrips notes that the operator pushb b1 b1  is relevant to this problem and applies i t   which solves the figure 1. 	a simple problem for abstrips. 
the reader w i l l quickly note that this is i l l e g a l because the i n i t i a l state is not in the domain of the operator. however  this subproblem is being solved at c r i t i c a l i t y level 1 which means that a l l predicates of level 1 or less are ignored. nextto has been designated as level 1 and inroom is level 1. hence  at level 1  abstrips considers the preconditions of pushb bl  b1   see figure 1  to be type b1  object  and pushable bl  which is true in the i n i t i a l state and consequently the operator is applied. normally  several operators w i l l 
be necessary to solve the problem but in this case one suffices. 
the next subproblem  #1 in figure 1  is to get from the i n i t i a l state to a state in which the level 1 and higher predicates of the preconditions of pushb bl  b1  are true. in figure 1 we have only listed the predicates which are false in the i n i t i a l state for purposes of exposition.  we are assuming that the variable r is assigned the value r1.  abstrips notes that ptd b1  dl  is relevant to this subproblem and applies it which solves the subproblem. the level 1 predicates in the preconditions of ptd b1  dl  are ignored because this subproblem is being solved at c r i t i c a l i t y level 1. 
next  pushb bl  b1  is applied to the result of this subproblem and this new state is transformed into a desired state. 	but is is already a desired state; 	i . e .   applying  ptd b1  dl   pushb bl  b1  to the i n i t i a l state results in a state which satisfies nextto bl  b1 . 	hence  no subproblem 

problem-solving: 	ranerji 
1 


figure 1. subproblems of the problem in figure 1. is created in this situation. this completes the activity at c r i t i c a l i t y level 1. 
the next discrepancy shows up at level 1 because the preconditions of ptd at this level are not satisfied. abstrips sets up subproblem 1 in figure 1  and notes that pushb bl  dl  is relevant. however  this operator is not directly applicable because the level 1 predicates in its precondition are not satisfied. gotob bl  rectifies this s i t uation and hence  gotob bl  pushd bl  dl   is applied to the i n i t i a l state which results in a state s in the domain of ptd dl . since this subproblem is solved  abstrips applies ptd dl  to s 
which yields a new state t and then attempts to transform t into the domain of pushb bl  b1 . a l l 
of the level 1 predicates in the preconditions of pushb bl  b1  are considered because this subproblem is being solved at c r i t i c a l i t y level 1. but  since t is already in the domain of pushb bl  b1   this subproblem is t r i v i a l l y solved. hence  pushb bl  b1  is applied to t and abstrips attempts to transform the result into the set of desired states. but the result is already a desired state and thus this subproblem also has a t r i v i a l   solution. since c r i t i c a l i t y level 1 is the smallest level  the solutions of the subproblems comprise a solution of the main problem. 
to summarize  abstrips sets out to solve a problem at a given c r i t i c a l i t y level by essentially removing from the preconditions of a l l operators  predicates whose level are less than the given level. after finding a solution it goes to the next level down and adds the predicates at this level back to the preconditions of the appropriate operators. this gives rise to subproblems that abstrips attempts to solve at the current c r i t i c a l i t y level  i.e.  with lower level predicates removed from operator preconditions. this process is repeated u n t i l the subproblems at the smallest c r i t i c a l i t y level  which is 1 in the above example  are solved. of course  there is search involved at a l l levels because at any given level a problem may have several different solutions some of which may generate unsolvable subproblems . 
	1. 	planning 
abstrips is quite similar to what newell & simon  1  call planning. abstrips and planning differ in 1 major respects: 
pi. planning uses an entirely new problem solving space-both states and operators. 
p1. planning uses only 1 level of abstraction while abstrips has one for each c r i t i c a l i t y level except the lowest which is the pro-
blem space i t s e l f . 
although planning does not presuppose c r i t i c a l i t y levels  they can be used to define the planning space. we w i l l apply planning to the example of the previous section to contrast the two methods. 
in the planning space of the problem in figure 1 a l l of the level 1 predicates are removed.  in this example nextto is the only level 1 predicate.  thus  a state in the planning space w i l l be described exclusively by level 1 and level 1 
predicates. all level 1 predicates are removed from operators to get the planning space operators. this includes the level 1 predicates in the addition and deletion l i s t s as well as in the preconditions of the operators. of course  removing these predicates causes some operators to become identity maps  e.g. pushb  in which case they are not used in the planning space. a l l level 1 predicates are removed from the formula that describes the desired states to get its analogue in the planning space. hence  the planning desired states must be given by inroom bl  r1  & inroom  b1  r1 . removing the level 1 predicates from the description of the desired states in figure 1  gives the null description which represents the set of a l l states. 
the solution to the problem in figure 1 in the planning space is the single operator ptd b1  dl . this generates 1 subproblems in the original problem space: transforming the i n i t i a l state into the domain of ptd  bl  dl   and transforming the result of applying ptd  bl  dl  to the solution of the f i r s t subproblem  into a desired state. 
in general  planning is a two phase process: the f i r s t phase is to solve the problem in the planning space. the second phase is to elaborate the solution so that it works in the original problem space. this is done by inserting operators into the solution that was found in the planning space. the operators to be inserted are found by solving subproblems of transforming the appropriate states into the domains of the appropriate operators. 
	♀. 	formalization of abstripsland plaiming 
our formal model of abstrips is based on two assumptions in addition to the above description. 

prnmpnn-solvinp-1: 	ranerj i 
kkk 


	problem-solving-1: 	ranerji 
1 



that abstrips or planning or any other process that can find a l l and only well stratified solutions can find. 
in ernst  1  a triangular table of connections was shown to be good difference information for gps and it appears that this also specifies good parameters for abstrips and planning. rather than giving a formal definition of a triangular table of connections we w i l l give an example of it using the fool's disks problem. figure 1 gives the i n i t i a l state of the fool's disks problem  in which there are 1 concentric disks each containing eight numbers. these numbers line up so as to form 1 columns radiating from the center of the disks. a move consists of rotating one of the disks independent of the others. the desired state is one in which each of the 1 radial columns sums to 1. 
a triangular table of connections for this problem is given in figure 1. a 1 entry in the table indicates that a difference is invariant over the operators. for example  the 1 in the upper right corner of figure 1 indicates that turning a disk 1 revolution does not change the sum of the horizontal and vertical diameters. note that figure 1 has a l l o's above the main diagonal and no o's on i t . the entries below the main diagonal are unimportant. the difference ordering is just the row order; i . e .   the top row heading is the most d i f f i c u l t difference while the bottom is the easiest. 
gps only uses the entries on the main diagonal to solve the problem. hence  f i r s t 1  1  1 and 1 revolution of disks are used to remove the most d i f f i c u l t difference  i.e. used to get 

the horizontal and vertical diameters to sum to 1. next  1 and 1 revolutions are used to get each diameters to sum to 1. and f i n a l l y the 1c moves are used to get a desired state. notice that once a difference is removed it is 
never reintroduced because of the triangularity of the table in figure 1. 
	1. 	discussion 
in the previous 1 sections we made a number of highly technical definitions ending with a somewhat cryptic theorem  but what can be concluded from a l l of this  there are 1 major points  listed below; they are followed by a more general discussion. 
point 1. given the  same  heuristic parameters planning  abstrips and gps  or at least our formal models which approximate them  can a l l solve precisely the same class of problems  i.e. those that have totally ordered solutions. the relationship of parameters of the different methods is described below but note that the di of section 1 are just differences for gps. this result is somewhat surprising because tne search space of gps is quite different than that of planning or abstrips. for example  for a l l states s generated by gps there is a path from the i n i t i a l state to s. this is not true for 
planning or abstrips because many of the subproblems may not be solvable. for any given problem probably one of the three methods is more e f f i cient than the others  but none is best for a l l 
problems. 
point 1. selecting heuristic parameters can have a much more drastic effect on the search e f f i ciency than selecting one of the three methods  as shown by the fool's disks example above. the 
reason for this is that a l l of the methods are 
designed to search efficiently for t o t a l l y ordered solutions; they w i l l not even consider subproblems that give rise to unordered solutions. totally-ordered is defined in terms of the parameters which are problem dependent  and hence the parameters determine whether the class of t o t a l l y ordered solutions is the same as the class of a l l solutions or whether the former is much smaller than the latter. in fact  one can view 
problem 	banerj 	i 

the problem of selecting good parameters as the problem of making the class of t o t a l l y ordered solutions as small as possible without eliminating a l l solutions to problems of interest. 
point 1. any parameters which are good  in the sense of guiding search  for one method w i l l have analogues which w i l l be good for the other methods. a triangular table of connections  see section 1  is a property of good difference i n formation for gps. another property of good differences is given in banerji and ernst  1 . these properties  after suitable translation  are also properties of good parameters of planning and abstrips. currently  we are implementing a program to discover difference information for gps which satisfies these properties. hence  this program effectively w i l l discover good parameters for planning and abstrips also. 
real abstrips. why might abstrips want to violate al and/or a1  the answer lies in the fact that the class of totally-ordered solutions may be a l i t t l e too restrictive because some solutions may not be totally-ordered. violating al and/or a1 allows abstrips to find solutions that are  almost but not quite  totally-ordered. we do not know how to measure the degree of unorderedness or what these violations due to the efficiency of search. to see how an unordered solution is generated note that abstrips' solution to the problem in figure 1 is unordered because the d i f f i c u l t y of the original problem is level 1 whereas the d i f f i c u l t y of some of the subproblems is level 1. this unordered solution is a result of violating a l . to have planning solve the problem in figure 1 the desired states had to be more completely specified as described in section 1 because planning adheres to al. 

we feel that point 1 is the most important of the three points. not much is known about the process of selecting good parameters. some i n i t i a l work on this topic is outlined under point 1 but more research is needed on this topic. 
to understand the above points  we need to know the relationship among the parameters of the 1 
methods. the d  of section 1 are just the differences of gps. that i s   subproblem  s  t  possesses difference d if d  s  t  where d corresponds to d.. the subscripts on the d's give the difference ordering  e.g.  the difference corresponding to d  in the example in figure 1 is the easiest  smallest  difference because 1 is the smallest c r l t i c a l i t y level. the table of connections indicate that the operators in h. should be used to reduce d.. note that in our formal models of both abstrips and gps an operator f may be relevant to d. but not in h . this w i l l happen when f e h for some j   1 which indicates that f is relevant to the more d i f f i c u l t difference d* and hence is used solely for the purpose of reducing d.. including f in h. would give rise to more search but not to more totallyordered solutions. 
planning  in many respects  looks like abstrips with 1 c r i t i c a l i t y levels. in fact our formal model of the previous section is really a hybrid of abstrips and planning; it has many levels of abstraction like abstrips  and like planning assumes al. the heuristic parameters of planning are basicly the difference information of gps. although planning requires a entire planning space as input  this information is really derived from the difference orderinc. in fact one of the innovations in abstrips is i t s a b i l i t y to automatically generate the various planning or abstracted spaces from the c r i t i c a l i t y levels of the predicates. 
our formal model of abstrips uses assumptions al and a1  section 1  which is a deviation from the what is the relationship of the properties of good differences in  ernst  1  to the parameters of abstrips  as mentioned above the c r i t i c a l i t y levels of predicates basically specify the differences and difference ordering. if the table of connections is generated as defined in section 1   i . e . use operators in h  to reduce d    then the properties of good differences are automatically satisfied except that some of the h  may be empty. what this means is that if a l l solutions of a problem contain subproblems of d i f f i c u l t y i  then the problem has no totally-ordered solution. in other words the c r i t i c a l i t y level assigned to predicates is not good. a better approach is to ask what assignment of c r i t i c a l i t y levels results in no empty h's. this is very similar to the approach in eavarone and ernst  1  . 
we feel that the biggest restriction in abstrips is i t s use of a very restrictive class of differences  i . e .   those defined by the predicates in the problem specification. most of the good ideas in abstrips apply to a more general class of d i f ferences; and we hope that the restriction is removed in the future. as an example of a difference not defined by a predicate in the problem specification  the logic task in newell and simon  1  uses the number of different proposition letters in an expression as a difference. figure 1 also contains some more complex differences. we believe that abstrips can be extended to a wider class of differences such as these. 
references 
1. banerji  r. b. and ernst  g. w.  some properties of gps-type problem solvers  report //1  computer engineering and information sciences dept.  case western reserve univers i t y   1. 
1. eavarone  d. s. and ernst  g. w.  a program that discovers good difference orderings and table of connections for gps  1 ieee systems science and cybernetics conference record. 1. 

problen-solving-1: ranerj i 

1. ernst  g. w.  banerji  r. b.  hookway  r. j .   
oyen  r. a. and shaffer  d. e.  mechanical 
discovery of certain heuristics  report #1  computer engineering department  case western reserve university  1. 
1. ernst  g. w.   sufficient conditions for the success of gps   journal of the acm  october  1. 
1. ernst  g. w. and newell  a.  gps: a case study in generality and problem solving  academic press  1. 
1. fikes  r. e. and nilsson  n. j .    strips: a new approach to the application of theorem proving to problem solving   a r t i f i c i a l intelligence  1  pp. 1. 
1. newell  a. and simon  h. a.  human problem solving  prentice-hall  1. 
1. sacerdoti  e. d.   planning in a hierarchy of abstraction spaces   a r t i f i c i a l i n t e l ligence  1  pp. 1. 
	problem 	-solving 	ranerj   
1 

a theory for the complete mechanization of a gps-type problem solver 
	r. 	b. banerji 
temple u n i v e r s i t y 
	p h i l a d e l p h i a   pa. 	1 
c. w. ernst 
case western reserve u n i v e r s i t y cleveland  oh. 1 
abstract 
       the data s t r u c t u r e that d r i v e s the general probl em solver is the connection table. this paper describes the t h e o r e t i c a l basis for the a u t o matic c o n s t r u c t i o n of t h i s table by computer p r o grams. the programs f o r t h i s purpose have been developed at the case western reserve u n i v e r s i t y . they b a s i c a l l y i s o l a t e c e r t a i n a t t r i b u t e s of the problem states which are i n v a r i a n t under c e r t a i n moves and then put those a t t r i b u t e s together to   t r i a n g u l a r i z e   the connection table. 
d e s c r i p t i v e terms 
　theory of h e u r i s t i c s   general problem solver 1 . 	i n t r o d u c t i o n 
       according to our view of mechanical problem s o l v i n g   there are a number of d i f f e r e n t problem s o l v i n g methods each of which has problem dependent parameters. for each method there is a cond i t i o n which s p e c i f i e s the p r o p e r t i e s the paramet e r s should have in order f o r the method to  work . hence  we view problem s o l v i n g as the two phase process shown in figure 1. in the f i r s t phase  the method's c o n d i t i o n is used to generate  good  parameters f o r the method. the input to t h i s phase is the problem s p e c i f i c a t i o n   since the parameters are u s u a l l y problem dependent. the output is e i t h e r good parameters or an i n d i c a t i o n t h a t t h i s method should not be used on the given problem. the second phase attempts to solve the problem  as s p e c i f i e d at the input to the f i r s t phase  using the method w i t h the parameters generated in the f i r s t phase. of course  there is a dicture l i k e figure 1 f o r each method  and if the 
f i r s t method is not a p p l i c a b l e   we merely move on to the next method and attempt to use i t . 
       so f a r   a l l the methods s t u d i e d t h i s way  coray  1   ernst 1   banerj1   seem to depend on the r e c o g n i t i o n of c e r t a i n a t t r i b u t e s of the problem s t a t e s which remain i n v a r i a n t under some of the moves. we have p r e v i o u s l y published two r e p o r t s on the design and implementation of a program which would i s o l a t e some of these a t t r i butes on the basis of the problem d e s c r i p t i o n 
        ernst e♀a l 1    oyen 1    . 
       our present e f f o r t deals w i t h the combination of the i n v a r i a n t p r o p e r t i e s to y i e l d the connect i o n table of gps  newell & simon 1   ernst & n e w e l l   1 1     . our e f f o r t s in using our previous theory   e r n s t   1 1     f o r the purpose of mechanizing the h e u r i s t i c were not s u c c e s s f u l   because a 
d i f f e r e n c e  good or bad  was a binary r e l a t i o n 
between states and sets of s t a t e s   i . e .   a subset of s x 1s where s is the set of problem s t a t e s   which is a complicated concept. 
in an attempt to s i m p l i f y matters we s a i d   
 what if a d i f f e r e n c e were j u s t a set of s t a t e s     in t h i s case  a s t a t e s possesses d i f f e r e n c e d  if s i d. with t h i s simple view we can v i s u a l i z e gps's s t r a t e g y as f o l l o w s  figure 1   . 

1. find a path from so to some state s 	d. 
1. find a path from s to some state s1 e d1 but the path must be entirely inside d. 
1. find a path from s1 to s o m e state s e w but the path must be entirely inside d'. 
in step 1 gps is removing the most d i f f i c u l t d i f ference d. in step 1 the second most d i f f i c u l t difference is being removed without reintroducing d. the easiest difference w is being removed in step 1 without reintroducing either d or d'. 
　　　a point ought to be made here about the o r i g inal gps which was a somewhat more general device than the one we are describing here in that  

 'i♀i:re 1 while removing an easier difference  a more d i f f i c u l t difference could get reintroduced. the only search pruning involved in this general case was that involved in the relevance of moves to differences  vide u l t r a   . the extra constraint we have introduced here  and one which also characterizes our previous work  ernst 1    constrains the search for greater efficiency  while at the same time it neglects a certain class of solutions. our present analysis follows the same line. 
　　it is probably somewhat counterintuitive that the most d i f f i c u l t difference contains a l l of the other differences as subsets. one would normally think that the larger the set of states  the easier it would be to  get  inside of i t . also  one does not normally think of w as a difference. but this somewhat unintuitive picture works quite well. 
consider  for example the fool's disk problem. 
figure 1 gives the i n i t i a l state of the fool's disk problem  in which there are 1 concentric disks each containing 1 numbers. 	these numbers line up so as to form 1 columns radiating from the center of the disks. 	a move consists of rotating one of the disks independently of the others. 	the desired state is one in which each of the 1 radial columns sums to 1. 

figure 1 
the i n i t i a l state in the fool's disk problem 
     this problem f i t s the above picture exactly. d' is the set of states in which each diameter sums to 1  while d is the set of states in which the sum of the n  e  s  and w radii is 1. to keep the path from s  to s1 in d  gps only considers moves which rotate disks 1＜. to get from s1 to s 1   gps rotates disks by 1＜ only. 
     one might be disturbed that each difference contains a l l of the easier differences. this is not a d i f f i c u l t y   because any set of differences not possessing this property can be converted to differences which have this property.  in fact  our theory  banerji &. ernst  1   does not require this  nesting  of differences.  consider  for example  the 1 disk tower of hanoi in which we are trying to move a l l disks to peg p1. let d. be the set of states in which disk i is on p1 where disk 1 is the largest disk. then  one might think 
*of using d   d1  and d1 as differences for this problem. these are essentially the differences that were given to gps for this problem. certainly these sets are not perfectly nested. however  this set of differences can be converted to the above picture by intersecting them together  i . e .   d   d     d' =dd1 n d     and w 1 n d1  d1 n d1 n dx. 
   a more disturbing feature of this set of d i f ferences is that they are only useful when the set of desired states is w. in the original gps  as well as in our previous work  the same set of d i f ferences served to characterize a l l subgoals including  make such and such a move applicable.  this is not the case anymore. i f   for example  the set of desired states is the domain of the 
operator which moves disk 1 from p1 to p1  the d1 seems to be a useless set of differences. the d i f f i c u l t y is that we have  built  w into the d i f ferences. we did this on purpose to simplify the differences to allow mechanization. our original theory had differences as binary relations bet-
ween states and sets of states. if we specify the latter to be w  then we are l e f t with a monadic relation on states which is just a set of states. but how are we going to accommodate goals other than w  
   the key to answering this question is that not only w but also the domains of operators can be the goals of subproblems. since the number of operators is usually quite small  we w i l l use a d i f -

problem-so1vinr -1: banerj   
1 

ferent set of differences for the domain of each ween s and t. the higher i i s   the larger the operator being the goal of a subproblem. difference i s .    these modifications were introduced in our theory of gps to make it easier for person or 
machine to discover  good  differences. an added advantage of the modified gps is that it can easi l y handle problems in which the sets of differences for subproblems with different desired states are truly different. 
   the above discussions w i l l   we hope  serve as a motivation for the changes we have introduced in the theory. we do not plan to give a formal counterpart to these motivations or exhibit a for-
mal connection between the old and the new theories. instead  we shall exhibit and motivate the new theory ab i n i t i o so that readers unacquainted with our previous work w i l l find the discussion self-contained. we shall  of course  assume that the reader has had former acquaintance with gps  ernst & newell 1. 
     in the next section we give a formal d e f i n i tion of good differences. this is followed by an example of good differences and how they are used by gps. section 1 characterizes the class of solutions that gps can find given the kind of d i f ferences described in section 1. 
1  	definition of good differences 
     since gps builds its solution to a problem by setting up subproblems  we cannot build this theory by defining what a problem is but rather by defining a larger structure in which a class of subproblems can be embedded. also  this structure should contain the concepts which reflect the idea of differences and the connection table. we shall call this structure the problem domain   domain  for short. as in the previous models  we start with a set s of states and a subset w of s  consisting of winning states. we also have a set c of partial functions  mapping subsets of s into s  which we shall call moves or operators. if f e g 
     is a move  we shall denote by sf i t s domain of def i n i t i o n   i . e .   states where f is an applicable 
move. since subgoals in gps have the form  make move f applicable   these sf  for various members f of g  serve as winning sets for subproblems just as w serves for a problem. the class of a l l these sets  w and sf for various f  we shall call x. for each set in this class we also define the d i f ferences which allow gps to work on them. that i s   for each t e x  t being either w or sf for some f e g  we define a class of sets t j   t     t1 .. t n with the property that tj n t n...t n  = t. the actual number n of specified differences of course depends on the set t chosen. so  instead of writing n we shall write n t  when there is any doubt as to which subproblem we are talking about. also  for reasons of convenience of discussion we shall often give the name tq to t and call s i t s e l f   t n   t   + 1 . 
　　it may be appropriate at this point to point out that the t  catches the idea of difference in that when a state s i t i $ a difference exists betpromerr -sol v 
　　　the next important concept in gps  of course  is that of relevance of a move to a difference. the major assumption on which gps theory is based is that a solution can be obtained by removing the higher   more d i f f i c u l t     differences before the lower differences and never reintroducing higher differences once they are removed. a d i f ference is considered higher than others  if fewer moves are available to remove i t . of course  s or t n   ' t   + i a r e the most d i f f i c u l t differences to remove  since no move changes a state to a nonstate. let h1 c g be the set of moves which  
when applicable  affects the position of the state with respect to t1. instead of making the very strong assumption that moves in h1 bring a l l states outside t1 into t   we shall make the more realistic assumption that these moves remove the states from ti when applied. this assumption seems  backward  to many  in spite of the fact that in most real problems  relevance of moves does appear that way and was used that way even in the original gps. in our difference-finding program  a state is characterized by giving the values of certain attributes for the state. a winning state is characterized by specifying that some of the attributes should have specific 
unique values. to find mechanically that a certain move is relevant to a certain difference t.  
we test whether the move changes the values of those attributes which characterize t.. 
　　　it is this  property-changing  characterization for moves which gives relevance the backward appearance. of the various values to which the attribute can change  only one characterizes the win states. hence  it is not to be expected that merely changing the value of a property yields a win value. on the other hand  if it already has a win value  changing it certainly changes it to a non-win value. 
     another important characteristic we demand of the moves in w＼  called triangularity of the d i f ference table in the previous theory  is that hi does not affect the differences higher than ti  
i . e .   is irrelevant to tj for j   i. thus  once a state is in t i   as long as we use moves in hj with j   i  t＼ w i l l not be reintroduced. 
　　　this effort shows up nicely in the difference transformation tables of gps. if we arrange the ti's from top to bottom in decreasing order of i and the h. from left to right in decreasing order  and mark the   i   j   cell with a 1 if moves in hj are relevant to t＼t then the upper right half of the table w i l l be blank. tables of this nature 
we call triangular tables  and differences which give rise to triangular tables we call good d i f ferences . 
　　　we define the maximum difference between t and s  m s  t   to be i i f s 1 t＼ and s t tj for a l l j greater than i. 
n p - 1 : 	banerjl 
1 
　　　implicit in the above definitions is an ordering of the t＼  and the hi  which corresponds to the difference ordering of gps. the most diff i c u l t difference is t n   while the easiest d i f ference is t＼. gps's basic problem solving strategy is to work on hard differences f i r s t and easy differences last. gps accomplishes this  as discussed in section 1  by using the following to guide its search: 
a state is a 1 place vector whose components are the monkey's position  the box's position  and the contents of the monkey's hand. 
a win is a state in which the bananas are in the monkey's hand. 
 walk  climb  push  grab  

1 to reduce the maximum difference t-j  use only operators in h . 
1 suppose a subproblem were generated to reduce difference t i 1 then do not use the operators in hj   i   j   n to solve the subproblem. 
rule si was in our previous theory. note that there may be many other operators besides h. which are relevant to t  because we have placed no conditions on hj for j   i. si causes gps to ignore such hj even though some of i t s operators may be relevant to tj . 
　　　the purpose of s1 is to require subproblems to be easier than the problem for which they are created. in our previous theory this was accomplished by requiring the differences of a problem to be harder than the differences of its subproblems. this is no longer possible  because we cannot compare subproblem differences to problem d i f ferences because they w i l l have different goals and hence different differences. however  s1 can be used  because a l l differences are reduced by the same operators. note that s1 is applied recursively. that i s   suppose fl and f1 are the sets of operators according to s1 that cannot be used on subproblems sp1 and sp1  respectively. if sp1 is a subproblem of sp1  then gps w i l l not use any operator in fl u f1 to solve sp1  because  the restrictions on spl are passed down to a l l of i t s subproblems. 
1. an example of good differences 
　　　the definitions above appear quite formidable and somewhat unlike gps. a simple example w i l l clarify things. for our example we have chosen that old chestnut about the monkey and the bananas  a formulation of which is given in figure 
1. we have chosen this example because it has  non-trivial  good differences  subproblems are created in solving i t   and it is simple. 
　　　one way to formalize the differences above is by positing that there is a separate table of connections for each goal which is either w or the domain of an operator. 	figure 1 illustrates monkey and bananas this way. 	the l's indicate which operators are relevant to which differences. 	the o's indicate irrelevance. 	a move is neither r e l evant nor irrelevant - we use a question mark. note that the bottom row heading of each table is just the goal and that each row is a subset of the row above i t . 	although our theory does not require these properties  they make things easier to visualize as discussed at the beginning of 
walk the monkey walks to someplace in the room. climb the monkey climbs onto the box  i . e .   the monkey's position becomes onbox. climb is applicable only when the monkey's position equals the box's position. push the monkey pushes the box to some in the room. push is applicable only when the monkey's position equals the box's position. grab the monkey grabs the bananas. 	grab is applicable only when the monkey is on the box  and the box is under the bananas. figure 1 
a formulation of the monkey and bananas problem 
section 1. 
　　　the row headings are the tj  in the d e f i n i tions of section 1  and the column headings are the hi. the definitions of the ta and the hi require that the tables of connection are triangular in the sense that the main diagonal and a l l entires above it are 1. in addition  the subdiagon-
al  the diagonal immediately below the main diagonal  contains a l l l ' s . 
　　　walk is a total function on s  hence i t s domain is s. we do not need a table of connections for such an operator  because a subproblem of getting into its domain w i l l never be created. we included the table of connection for walk in figure 1  because the degenerate case of a d e f i n i tion often helps one understand the definition. 
　　　if a column of an operator is a l l 1's  then that operator w i l l never remove a state from the 
goal set and w i l l never transform a state outside the goal set into the goal set. an a l l 1 row i n -
dicates that no operator w i l l add or remove a state to the t  which labels the row. 
　　　the above is an example of  difference i n formation  which satisfies our definition of good in section 1. the most important feature of the tables in figure 1 is that the triangularity constraint orders the rows  and the columns . this row ordering is the difference ordering - d i f f i cult differences are at the top of a table  and easy differences are at the bottom. of course  there may be several different row orderings 

prohler-solvin -1: 	banerj  u1 


figure 1 
　the table of connections for each goal in monkey and bananas 
which gives rise to a triangular table  in which case any one of them w i l l satisfy our formal def i n i t i o n of good. 
　　　now we can describe how gps solves monkey and bananas using the difference information in figure 1. suppose that in the i n i t i a l state s1 the 
monkey's hand is empty and the box is not under the bananas. then the largest difference  m s1 w   is that the monkey's hand is empty  hence gps 
attempts to apply grab. but so i sgrab  hence gps sets up the subprobiem of transforming s1 into sgrab  b u t grab cannot be used in solving the subproblem because of rule s1. 
　　　to solve the subprobiem  gps attempts to reduce the difference that the box is not under the bananas since this is m so  sgrat     hence  gps attempts to apply push which is not applicable  and the subprobiem of transforming sq into spush is generated  but s1 restricts the solution of this subprobiem to the operators walk & climb. the remaining part of solving this problem is quite straightforward and similar to the way the 
usual gps works. 
1. 	totally-ordered solutions 
　　　the above discussion raises the question   can gps solve a l l problems which have a solution   the answer is no  which can be shown quite easily   because'the differences  together with rules si and s1  prevent gps from looking at sequences of operators that may be necessary to find a solution. hence  the question becomes   can we somehow characterize the class of problems 
problem-sol ving;-1: banerj i 
1 



a solution whenever a triangular difference table exists; one has to be blessed with a totally ordered solution - totally ordered by the ordering 
mechanically or otherwise chosen in the connection table. we have had various problems in which more than one triangular connection table exist  and yet one can prove that some of the connection tables would not yield a solution. this problem has appeared in other  seemingly closely related  garbs in planning programs for robots  leading to the work on non linear plans  sacerdoti 1  . the analogous problem in our formalization would be the detection of the nonexistence of totally or-
dered solutions. one approach  that of the detection of  factorable subproblems   goldstein 1   
w i l l be reported on at a future date. 
1. 	acknowledgement s 
　　　the work described in this paper was supported by the national science foundation under grant mcs 1 to the case western reserve university. the preparation of the paper was partially supported by them under grant mcs1-1 to temple university. 
references 
1. banerji  r. b.  similarities in games and their use on strategy construction   proceedings of the symposium on computers and auto-
mata  pp. 1  polytechnic press of the polytechnic institute of brooklyn  1 . 
1. banerji  r. b. and ernst  g. w.   strategy construction using homomorphisms between games   a r t i f i c i a l intelligence  vol. 1  pp. 1  1 . 
1. banerji  r. b. and ernst  g. w. ernst   some properties of gps-type problem solvers   report #1  jennings computing center  case western reserve university   january  1 . 
1. coray  g.   an algebraic representation of a puzzle solving heuristic   publication 1  dept. d'informatique  university of montreal  1 . 
1. ernst  g. w.   sufficient conditions for the success of gps   journal of the acm  october  1 . 
1. ernst  g. w. and newell  a. gps: a case s udy in generality and problem solving  academic press  1 . 
1. ernst  g. w. et. a l .    mechanical discovery of certain heuristics   report #1-a  jennings computer center  case western reserve university  january  1 . 
1. goldstein  m.  unpublished research  1 . 
1. newell  a. and simon  h. a.   gps  a program that simulates human thought   computers and 
thought  e. feigenbaum & j. feldman  eds.  
pp. 1  mcgraw-hill  1 . 
1. oyen  r. a.   mechanical discovery of i n var iances for problem solving   report //1 jennings computing center  case western reserve university  june 1 . 
1. sacerdoti  e. d.   the non linear nature of plans   proceedings of the fourth international joint conference on a r t i f i c i a l i n t e l l i gence  pp. 1  1 . 

problem-solving-1: 	banerj i 1 

a general backtrack algorithm that eliminates most redundant tests 
john gaschnig 
dept. of computer science 
carnegie-mellon university pittsburgh  pa. 1 
　　　　we define a faster algorithm functionally equivalent to the classical backtrack algorithm for assignment problems  of which the eight queens puzzle is an elementary example  fillmore & williamson 1  knuth 1 . experimental measurements  figure 1  reveal reduction by a factor of 1 for the 1-queens puzzle  factor of 1 for 1 queens  in t  the number of pair-tests performed before finding a solution  i.e.  first solution . a pair-test in this case determines whether a queen on square   i j   j j   attacks a queen on square  1  j1  in c p u   seconds  net speedup is by a factor of 1 and 1 for 1and 1-queens  respectively. 1-queens was solved in 1 seconds on a pdp kl/1. the speedup can be attributed to the elimination of almost all redundant tests otherwise recomputed in many parts of the search tree  as indicated in figure 1  which shows the mean number of times  d  an arbitrary pair-test is executed. if d = 1 then all tests are distinct  no recomputation . note that each data point in the figures represents the mean over 1 or 1 problem instances that differ as follows: instead of instantiating queen 1  say  on square  1   then on  1  ...  then  1   these 1 squares are ordered randomly. a problem instance is defined by choosing a  legal squares ordering  for each queen. random ordering generally gives a smaller value of t  on the average  than the  natural  1 1 ... n ordering  for 1-queens  a factor of 1 smaller! . 
　　　　the algorithm exploits an advantageous time-space tradeoff and is defined below in general form by recursive sail procedure bkmark  swinehart & sproull 1 . the classical backtrack algorithm is defined the same  minus the underlined portions  except that  new var   in line 1 is replaced by  1  . the algorithm applies to any problem having nvars variables  1  for 1-queens   each variable xj having nvalsh  a priori possible values  1 squares for each queen  - one row of board   except 1 for queen 1 for symmetry reasons . an assignment vector 
assign 1:nvars  of values to variables is a solution iff 
pairtest1  assign i   j  assign j   	is 	true 	for 	all 
1   i   j   nvars  iff no queen can take any other queen . below  assign contains indices to the actual values. top level invocation for 1-queens takes the form 

tmp  - bkmarko  1  a  b  c  d  with array dimensions d 1:nvars  and c 1:nvars  l:k   where k is the maximum of the b i  values  -1 for 1-queens . initial values of a are irrelevant; c and d values are initially 1. bkmark returns 1  with solution in assign  or returns 1 if no solution exists. define pairtest for 1-queens and trace the execution  new vs. old versions  to see how it works.  suggestion: define an array values with same dimensions as mark  so that an element of values encodes a board location.  for brevity  the symbol st.ands for  comment . 

references 
1. fillmore  j.  and s. williamson   on backtracking: a combinatorial description of the algorithm   s1am j. computing  1   no. 1  march 1   pp. 1. 
1. knuth  d.   estimating the efficiency of backtrack programs   mathematics of computation  1   no. 1  jan. 1   pp. 1. 
1. swinehart  d.  and b. sproull  sail  stanford ai project operating note no. 1  january 1. 
this research was supported by the defense advanced 
research projects agency under contract no. f1c-1 and monitored by the air force office of scientific research. 


problem-sol v inr;-1: gasching 
1 

generality and computational cost 
a z r i e l rosenfeld 
computer science center 
university of maryland 
college park  maryland 	1 u.s.a. 
　　　the purpose of t h i s note is pedagogic a l . it discusses how one can reduce the computational cost of applying a set of operators  or predicates  by breaking them up into combinations of commonly occurring  simpler ones. this can be thought of as a process of generalization  in the sense that the common  simple operators are more  general  than the o r i g i n a l   more complex ones. we are thus suggesting that even when one has a p r i o r i knowledge of a specialized nature   i . e .   that the complex operators are applicable    it may s t i l l be desirable to use generalized operators in order to reduce computational cost. 
　　　to i l l u s t r a t e t h i s idea  suppose that we want to apply a set of predicates p-  ... p to an input i  and suppose that the cost of applying predicate pi is  proportional to  the c a r d i n a l i t y  of i t s set of support  thus the t o t a l 
cost of applying the p's is 
	for example  applying p. might 
involve a template-matching process  where pi is true i f f . a perfect match to the template is found in i. here i could be an image  or a s t r i n g  where the  template  is the right-hand side of a rule in a grammar   or a graph  where the  template  is a subgraph . in what follows  we w i l l use the image/template 
metaphor. 
     suppose now that there exists a set of subtemplates qj  	 qm such t h a t   for support. 	if we store the match positions in a new array i 1   then to test for p.  
we need only apply a template of cardina l i t y n i to i'. thus testing for a l l the 
 and the t o t a l cost of 
the two-step matching process is 

　　　under what circumstances is the twostep cost less than the brute-force cost  of applying the  d i r e c t l y   	we 
claim that t h i s depends on the degree to which the q's  generalize  the p's - 
i . e .   on how few q's are needed to construct a l l the p's. 	for concreteness  suppose that a l l the q.'s have the same support size | and that each p. 
consists of the same number  of 
thus each p. has support size 
and the costs of the brute-
force and two-step approaches are nrs and mr+ns  respectively. if there are few q's  they must be used repeatedly  and we have m    ns  m=ns would mean that each q is used only once ; thus mr+ns w i l l be much smaller than nrs. the fewer q's we need  the greater a saving mr+ns is over nrs. thus the more we can generalize the p's  the lower the computational cost. 
　　　this template example is certainly not a universal one. it would be desirable to extend this type of analysis to other s i t u a t i o n s .  on the advantages of hierarchical matching in the graph/subgraph case see barrow et a l .  1 .  however  our example does i l l u s t r a t e the idea that it may be advantageous to use generalized rather than specialized knowledge  see zucker et a l .  1    because this can lead to savings in comput a t i o n a l cost. 
