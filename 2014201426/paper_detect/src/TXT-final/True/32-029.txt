 
the paper reports on experiments in which autonomous visually grounded agents bootstrap an ontology and a shared lexicon without prior design nor other forms of human intervention. the agents do so while playing a particular language game called the guessing game. we show that synonymy and polysemy arise as emergent properties in the language but also that there are tendencies to dampen it so as to make the language more coherent and thus more optimal from the viewpoints of communicative success  cognitive complexity  and learnability. 
1 	introduction 
the goal of studying natural language semantics is to determine the systematic relations between language utterances  their meanings and their referents. speakers must conceptualise reality to find an adequate meaning  and they verbalise this meaning to yield an utterance transmitted to the hearer. the hearer must interpret the utterance to reconstruct the meaning and apply the meaning in this particular context to retrieve back the referent. one possible framework for studying these relationships is the theory of formal  denotational  semantics and its application to the treatment of natural language  montague 1 . in this framework  functions are defined for mapping natural language utterances into expressions in the predicate calculus  with suitable extensions  and for mapping logical expressions into their denotations. such a framework has been the basis of much work in computational semantics and has been used to formalise the communication systems of autonomous agents. 
　although this formal approach has many virtues  it makes a number of simplifying assumptions which are not valid for physically grounded evolving autonomous agents that are part of inhomogeneous populations operating in real world open environments. in such circumstances  it is first of all not possible to formalise 
1 	natural language processing 
frederic kaplan sony csl - paris lip1 universite paris vi - paris kaplan csl.sony.fr 
the model which acts as the domain of the denotational semantics. the physical environment produces an infinite set of unforeseeable situations  independent of the agent and not delineatable by an outside observer. because of the open-ended nature of the environment  the language cannot be designed  or pre-programmed  in advance but must expand or shrink to adapt to the changing task settings and evolving environments encountered by the agents. second  the agents have to learn autonomously the language used in their community  including its underlying ontology  the denotational semantics of the predicates . consequently  it cannot be assumed that this language is uniform throughout the population. there are going to be different degrees of detail in the different agents depending on the histories of interaction with the environment. agents cannot inspect each other's brain states nor is there a central controlling agency that oversees additions to the language  so that polysemy  one meaning having different forms  and synonymy  one form having different meanings  are unavoidable. finally  because the agents are situated and 
embodied in the environment  they must bootstrap their competence through strongly context and viewpoint dependent cases. for example  something that is to the left for one agent may be on the right for another one depending on their respective positions  which makes it hard to learn the meanings of ieft' and 'right'. 
　we have been developing a framework for studying situated grounded semantics that does not make the simplifying assumptions of classical formal semantics and is therefore more appropriate for studying human natural language communication or designing robotic agents. the framework consists of a theory on how agents could construct and acquire their individual ontologies  lexicons and grammars  and of tools for studying the macroscopic properties of the collective ontologies  lexicons and grammars that emerge in the group. these and similar efforts have been reviewed in  steels 1 . we are also conducting experiments with physically instantiated robotic agents  both mobile robots moving around in their en-

vironment with relatively weak sensors  steelsvogt 1  and immobile robots with active vision  steels 1 . the latter experimental infrastructure is used in the present paper and is known as the talking heads experiment. 
　one of the major themes of our research is that language can be studied as a complex adaptive system. the agents are carriers of individual linguistic knowledge which becomes overt behavior in local interactions between agents. there is no central coordination nor access of one agent to the internal states of another. the local interactions shape and continuously reshape the language. the overall dynamics should exhibit certain emergent properties  which have been observed as universal tendencies in natural languages  such as the emergence of a globally coherent linguistic system or the damping of synonymy and polysemy. given this broader framework  this research is strongly related to other efforts to understand how autonomous grounded agents may build up their intelligence  steelsbrooks 1   and particularly how they may bootstrap language  hurford  et.al. 1 . it draws on other research in the origins of complexity in natural systems  langton 1 . 
　the rest of the paper first briefly introduces the talking heads experiment. then general emergent properties of languages are reviewed. next  results from experiments in lexicon acquisition are shown and analysed with respect to the reaching of coherence and the damping of polysemy and synonymy. 
1 	the talking heads experiment 
the experimental setup consists of two  possibly more  
sony ev1 pan-tilt cameras in which different agents can be loaded  figure 1 . agents can travel through the internet and install themselves in robots in different locations. an agent can only interact with another one when it is physically instantiated in a body and thus perceive the shared environment. for the experiments to be reported here  the shared environment consists of a magnetic white board on which various shapes are pasted: colored triangles  circles  rectangles  etc. the interaction between agents takes the form of a language game  further called the guessing game. 
the guessing game 
　the guessing game is played between two visually grounded agents. one agent plays the role of speaker and the other one then plays the role of hearer. agents take turns playing games so all of them develop the capacity to be speaker or hearer. the objects located on the white board at the beginning of the game constitute the context. agents are capable of segmenting the perceived image into objects and of collecting various characteristics about each object  specifically the color  decomposed in rgb channels   grayscale  and position in pan/tilt coordinates. the speaker chooses one object 

figure 1: two talking head cameras and associated monitors showing what each camera perceives. 
from the context  further called the topic  and gives a linguistic hint to the hearer. 
　the linguistic hint is an expression that identifies the topic with respect to the other objects in the context. for example  if the context contains  a red square   a blue triangle  and  a green circle  then the speaker may say something like  the red one  to identify  as the topic. if the context contains also a red triangle  he has to be more precise and say something like  the red square . of course  the talking heads do not say  the red square  but use their own language and concepts which are never going to be the same as those used in english. for example  they may say  malewina  to mean  upper extreme-left low-redness . 
due to space limitations  this paper only considers situations where the meaning consists of a single perceptually grounded category and the form consist of a single word. based on the linguistic hint  the hearer tries to guess what topic the speaker has chosen  and he communicates his choice to the speaker by pointing to the object. a robot points by transmitting in which direction he is looking. the game succeeds if the topic guessed by the hearer is equal to the topic chosen by the speaker. the game fails if the guess was wrong or if the speaker or the hearer failed at some earlier point in the game. in case of a failure  the speaker gives an extra-linguistic hint by pointing to the topic he had in mind  and both agents try to repair their internal structures to be more successful in future games. 
　the architecture of the agents has two components: a conceptualisation module responsible for categorising reality or for applying categories to find back the referent in the perceptual image  and a verbalisation module responsible for verbalising a conceptualisation or for interpreting a form to reconstruct its meaning. agents start with no prior designer-supplied ontology nor lexi-
	steels and kaplan 	1 

fore two synonyms and   tisame  is polysemous; it can meanboth  gray-1 1  and  hpos-1 1 . three words are used to refer to object- 1 this kind of situation is typical in certain stages of our experiments and complexity rapidly increases when the same meaning is also used to denote other referents  which is obviously very common and indeed desirable . 
　as mentioned earlier  incoherence is not necessarily impinging on the communicative success of the language. the rmf-iandscape in 1 still leads to total success in communication whenever both meanings are equally adequate for picking out the referent. even if a speaker uses  tisame  to mean  gray-1 1  and the hearer understands  tisame  to mean  hpos-1 1   they still have communicative success. the goal of the language game is to find the referent. it does not matter whether the meanings are the same. the agents cannot even know this because they have no access to each other's brain states. 
　the degree of coherence of a language can be measured by observing the actual linguistic behavior of the agents while they play language games  more specifically  by collecting data on the frequency of co-occurrence of items such as the possible forms of a certain referent or all the possible meanings for a certain form. the relations are represented in competition diagrams  such as the rf-diagram in figure 1  which plots the evolution of the frequency of use of the referent-form relations for a given referent in a series of games. one co-occurrence relation will be most frequent  and this is taken as an indication how coherent the community's language system is along the dimension of the relation investigated. for example  if a particular meaning has only one form  then the frequency of that form in the mf-diagram will be 1  which means that there are no synonyms. 
　the remainder of this paper now looks at a particular case study performed with the talking heads as currently operational. to allow this investigation  we restrict the set of possible referents  by keeping the environment constant  so that we can indeed track the grounded semantic dynamics forming and deforming the semiotic landscape. 
1 	damping synonymy and polysemy 
figure 1 shows typical results for an experiment in which 1 agents start from scratch to build a new communication system  both the ontology  by the growing and pruning of discrimination trees  and the lexicon  by creating new words and adopting them from each other. as communicative success is reached  there is an evolution towards a unique form for each referent  as illustrated in figure 1. this is expected because the agents get explicit feedback only about this relation  not about any other one. this diagram shows that there must be a damping 
1 	natural language processing 

figure 1: this graph shows the average success per 1 games in a series of 1 games played by 1 agents. the agents evolve towards total success in their communication after about 1 games. a change in the environment induced after 1 games gives a decrease in average success which rebounds quickly. 

figure 1: this rf-diagram shows the frequency of each referent-form co-occurrence in 1 language games for a single referent. one word  va  comes to dominate. 
of synonymy as well  and it is even clearer if we look at the rm-diagram . 
　when we inspect the different meanings of  va   through the fm-diagram  figure 1   we clearly see that even after 1 games polysemy stays in the language. three stable meanings for  va  have emerged:  red1.1    blue-1 1   and  vpos-1 1 . they are all equally good for distinguishing the topic 
 va  designates  and there are no situations yet that would have allowed disentanglement. 
　in game 1  the environment produces a scene in which a category which was distinctive for the object designated by  va  is no longer distinctive. more precisely  we  as experimenters  have moved the object very close to another object so that the position is no longer distinctive. figure 1 shows first of all that success drops 
 meaning there have been some failures in the game   


figure 1: this fm-diagram shows the frequency of each form-meaning co-occurrence for   va  in a series of 1 games. a disentangling situation arises in game 1 causing the loss of one meaning of  va . 
but that it rebounds quickly. the agent's language and ontology is adaptive. what has happened is that a large part of the agents still keep using   va   because the colorbased categories are still applicable. but  va  no longer picks out the right object for those who believe that  va  means  vpos-1 1   so they have to learn an alternative meaning for  va   compatible with the new situation. the fm-diagram in figure 1 shows that the positional meaning of  va   namely  vpos-1 1   has disappeared. the other meanings  based on color  are still possible because they are not affected when the ob-
ject designated by  va  moved its position. 
　this case study illustrates the main points of the paper. the overt selectionist force on the language system is success in the game  which is maximised if the agents use the same word for designating the same referent  in the same context . this does not in itself imply that there are no synonyms nor polysemy because agents could prefer different words which they mutually know from each other and they could associate different meanings with a certain word which are nevertheless compatible with the environments they have seen. we have shown that nevertheless damping of synonymy and polysemy occurs. synonymy is damped because of the lateral inhibition of alternatives in lexicon use. this creates a positive feedback loop in which words that have a slight advantage will further gain in a winner-take-all process. polysemy is damped because there are situations disentangling incoherent form-meaning relations. 
1 conclusions 
the construction and acquisition of grounded languages poses specific difficulties for autonomous agents  causing their languages to exhibit partial incoherence. agents have to develop their own categories for approaching their world  and they cannot know which meaning has been intended by a speaker  even if they know the referent through extra-linguistic means. we have shown that a particular agent architecture can achieve the bootstrapping of a language system from scratch and that the collective dynamics it generates dampens synonymy and polysemy. 
1 	acknowledgement 
this research was conducted at the sony computer science laboratory. we are strongly indebted to angus mclntyre for creating the babel tool that is the technical backbone of our experiments and for technical support in the low level vision interfacing. 
1 