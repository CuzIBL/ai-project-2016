 
   multiple processors can be used to speed up a backward-chaining deduction by distributing or-parallel deductions. however  the actual speedup obtained is strongly dependent on the amount of communication required for the task allocation strategy. a variable supply model  vsm  is presented for multiple processors with replicated databases on a broadcast network. the term model refers to the set of procedures and messages required to perform the computation. vsm allows an infinite class of strategies with varying amounts of communication. the utility of vsm lies in the easy and powerful way it provides for selecung a strategy that works satisfactorily given certain communication constraints. all strategies in vsm use a dynamic task supply protocol  esp  that works better than other supply protocols described in the literature. 
i introduction 
   parallelism has been identified as a key to future high-performance reasoning machines - the fifth generation of computer systems  motooka  1 . multiple processors must be made to cooperate to speed up a computation. clearly  there is a need to identify parallel components of reasoning computations and there is a need to build multiprocessor hardware. in addition  there is a need to map parallel computations onto multiple processors  keeping in mind the constraints of communication. this last need is being largely ignored at the present time and may become the bottleneck in achieving high performance from multiple processors. the purpose of this paper is to address the last need  i.e.  to propose methods for task allocation that work well in the presence of communication constraints . 
   task allocation in a multiple processor system strongly affects the overall speedup obtained for a parallel computation  conway  1 . also  communication cost can be a significant part of the cost of the computation. therefore  a good task allocation strategy is needed and can be obtained only if both processing costs and communication costs are kept in mind. 
　the type of computation being considered in this paper is backwardchaining deduction  barr  1  with no side-crtects  and the parallelism employed is or-parallelism  conery  1.indstrom  1  ciepielewski  1 . in addition  all the processors can do backwardchaining deductions1 and are connected by a broadcast network. 
1this work was supported in part by arpa contract n1-c-1 
1they may. however  work at different speeds 
　1the multiple processor scenano applies to both multiple processors connected by a broadcast local area network  like the csma-cd ethernet  metcalfe. 1   or multiple processors connected by a broadcast network on a single chip as suggested by ullman 
 ullman. 1  
moreover  the database is replicated at each processor.1 the goal is to complete the deduction in as short a time as possible.1 the task allocation strategics presented in this paper do not assume any knowledge of the domain of application  i.e.  the database of facts and rules may be used only syntactically . the task allocation strategies can  however  use extra information to improve their performance. 
   previous approaches to parallel task allocation  lawler. 1  will not work well in this domain because of assumptions that are not reasonable here. most techniques can be eliminated as inapplicable because they assume that all tasks to be allocated are known beforehand along with their processing requirements  mayr  1 . another large class of techniques can be eliminated because communication cost is not considered or it is inaccurately modeled  lageweg  1 . more likely contenders will be considered later in the paper. 
　the importance of this paper lies primarily in providing two kinds of mechanisms to control communication cost. first  clever ways are found to reduce communication cost outright. ksp  a communication network protocol for transferring tasks among processors is more efficient than the announcement-bid-award protocol of contract net  davis  1  and enterprise  malone  1 . second  mechanisms are described to trade off communication cost and parallelism. the variable supply model  vsm  allows flexible usage of the interprocessor throughput in this respect. the term model refers to the set of procedures and messages required to perform the computation. throughput means the amount of data  in terms of messages  per unit time that can be sent on the communication network. vsm uses ksp as its communication protocol. 
   this paper is organized as follows. section ii explains how to view a backward-chaining deduction as a tree of or-parallel tasks. section iii contains a description of the multiple processor architecture. 
section iv then describes vsm and how it can be used to control communication. section v describes esp and how it can be used as an efficient task supply protocol for all the strategies in vsm. sections vi and vii contrast the results of using the two extremes of vsm - a supply-driven strategy and a demand-driven strategy. useful extensions to vsm and ksp and how they might fit into the current framework are described in section viii. that section also contains directions for future work and a summary. 
ii back-chaining as or-parallel computation 
   and-or trees  barr  1  can be used to represent the problemreduction in a backward-chaining deduction  barr  1 . in this paper  only or-parallelism is used; no and-parallelism is exploited. therefore  an or tree to represent a backward-chaining deduction  as described below  is of more interest than an and-or tree. backward-chaining is 
   there are two reasons for choosing this multiprocessor architecture first  it is a 
   practical way to utilize personal workstations when their owners are not using them  malone. 1   second  this paper can be a stepping stone to studying multiprocessors with more complex interconnection structures 
   1it is well known that optimal task allocation even for relatively simple problems is np-complete  mayr. 1  therefore  no attempt will be made to get an optimal solution 

1 	v. singh and m. genesereth 
used in the context of rule-based systems in which the data base consists of a dynamic set of first order predicate calculus  fopc  propositions and the rule base consists of a static set of fopc rules. in this paper  even the data base is kept unchanged as the deduction proceeds. all of the propositions in the data base are literals  i.e.. cither atomic propositions or negations of atomic propositions . all propositions in the rule base arc required to be written in one of the forms shown below  where alpha  beta  and alpha 1 alphan are all literals.1 
 //alpha beta  
 if  and alphar.alphan  beta  
   similarly  a goal to be proved must also be a literal or a conjunction of literals. in the rest of the paper  the term data base will be used to refer to the union of the rule base and the data base as described above. 
   each node in the or tree can be represented as a tuple of two sets  a set of goals and a set of bindings. the top-level node's set of goals contains one literal and its set of bindings is empty. if the set of goals of a node in the tree is non-empty  its children can be obtained in the following three ways:  1  take one of the goals in the goal set and backward-chain with all possible rules. a child is created for each of the rules that can be used to backward-chain from the parent. a child's goal set is obtained from the parents goal set by removing the goal that was backward-chained on  adding the antecedents of the rule applied  and applying the unifier from the backward-chaining to the resulting goal set. the set of bindings of the child is obtained by adding the unification bindings to the set of bindings of the parent.  1  unify a goal from the goal set of a parent node with a proposition in the data base. a proposition in the data base is treated as a rule in  1  with no antecedents.  1  if  1  and  1  cannot be used  no child can be created and this chain of backward-chaining ends in failure. 
   figure 1 presents an example of an or tree. a leaf represents a positive result if its set of goals is empty. 
   any node in the or deduction tree may be referred to equivalently as a task. a unit deduction is the expansion of a node into its children. the result of a deduction is the binding list that satisfies the proposition in question  if only one positive result is desired  or it is the list of binding lists that satisfy the proposition  if all positive results are desired. 
   notice that each of the subtasks of a task can be solved completely independently. no communication is required among the subtasks. also  notice that the grain of the tasks in the deduction tree can range all the way from i unit backward-chaining deduction to an arbitrarily large size. moreover  backward-chaining deductions are side-effect free1 
iii the multiple processor architecture 
　the goal of this paper is not to describe multiple processor architectures in any great detail. all we require is that the multiple processor architecture satisfy certain properties described below. 
　 1  many sequential processors are connected to a broadcast network;  1  the memory at each processor is large enough to store a complete copy of the database;  1  message-passing is the only form of inter-processor communication;  1  a message may be either point-topoint or broadcast; and  1  each processor has a unique processor number. an example of this kind of architecture is multiple symbolics 1 processors connected to a chaosnet  moon  1 . 
the local time at each processor is used for time-stamping messages. 
it is impossible to have all processor clocks completely synchronized but a close synchronization is desirable  and can be obtained by a standard distributed clock synchronization algorithm  marzullo  1  . 

iv variable supply model  vsm  
   vsm allows a class of strategies with varying amounts of communication. it will be shown later that the strategy with the highest communication cost will work best when inter-proccssor communication throughput is very plentiful relative to the message traffic that needs to take place. also  the strategy with the lowest communication cost will work best when the inter-processor communication throughput is very low. the utility of vsm lies in providing a unifying framework for an infinite set of strategics with varying amounts of communication  in the case of selection of these strategies  and in the demonstrated usefulness of the two extreme strategics. the use of intermediate strategies for intermediate communication conditions seems likely but is left unexplored in this paper. 


the notation for propositions is taken from  genesereth. 1  
   they are side-effect free at least in their pure form one could have side-effects  for example  by allowing caching  but that is not considered here 

figure 1: the variable supply model 

　vsm lays down a specific internal organization of the set of tasks known to each processor. this organization is shown in figure 1. current task is the task being worked on by the processor  actual 
work set is the set of tasks that the processor is committed to executing  and potential work set is the set of tasks that no processor is known to be committed to perform. the lines with arrows show the directions of transfer of tasks. any tasks that flow from left to right across the hypothetical commit line must be announced to other processors as being available so that they may place the task in their potential work sets. similarly  any tasks that flow from right to left across the commit line must be announced as being grabbed by this processor so that other processors may not also grab the same task. 
　ideally  the potential work sets of all the processors are the same at all times and each task is grabbed by one and only one processor. however  because of non-zero message delays  more than one processor may attempt to grab a task. a protocol understood by all the processors is required so that multiple grabs are resolved  results are properly handled  and tasks are killed when they are no longer needed. an efficient communication protocol  esp  to handle these problems is described in the next section. 
	in 	vsm  the mechanism 	for controlling the amount of 
communication lies in the fact that the tasks in the actual work set and the potential work set can be arbitrarily balanced. as will be seen later  if all newly generated tasks arc placed in the potential work set and grabbed only when absolutely needed  one obtains the supply-driven strategy with the highest communication cost. similarly  if all newly generated tasks are placed in the actual work set and only placed in the potential work set when absolutely needed  one obtains the demanddriven strategy with the lowest communication cost. this will be explained in greater detail in sections vi and vii. 
　for all the strategies in vsm  if a new current task is needed  it is picked out of the actual work set if it is non-empty. otherwise  the current task is picked from the potential work set. 
v efficient supply protocol  esp  
　hsp is the network communication protocol that is used by vsm to transfer tasks among processors. it may also be referred to as a task supply protocol. 
　first  this section presents a detailed description of hsp. next  the domain of application of hsp  which is larger than the present application alone  is described. finally  some previous work is contrasted with the work presented here. a. detailed description of esp 
this description consists of two parts: tasks and messages. 
1. tasks 
　each task has a globally unique name. attached pieces of information are: 
l.task description: {prop-set b-set all    where prop-set is the set of propositions to be proved  b-set is the set of bindings obtained so far  and all  is a boolean variable that means all positive results must be found  if true  or only one positive result must be found  if false  . 
1. parent task 
1. pending subtasks 
1. results: this is the set of results received so far for this task. 
in the current implementation. all  is always true 
	v. singh and m. genesereth 	1 
1. grabbed timestamp: this is the timestamp1 at which the task was grabbed. this can be revised if a future  grab  request for the same task  wins  out over a previous  grab  request. in a comparison between two  grab  requests  the one with the lower timestamp  wins . 
1. messages 
	hach 	message 	is 	described 	here 	with 	the 	syntax 
m essage-type{arguments . the following four message types are required: 
1. new task-name task-description : this is the message used to make the  task is available  broadcast mentioned in section iv. when a processor receives a new message  the processor sets up the appropriate book-keeping information for the task name and puts the task name in the potential work set. 
1. grabbed task-name timestamp : this is the message used to make the  task is grabbed  announcement mentioned in section iv. when a processor selects a certain task as the next current task for itself  it broadcasts a grabbed message for that task. when a grabbed message is received for a task  it is removed from the potential work set of the processor where the message is received and the book-keeping information for the task is revised  if required . if the task for which the grabbed message is received is the current task or even if the task is awaiting completion of its subtasks  then it will have to be aborted if the timestamp in the new grabbed message is lower than the previous timestamp for the task name. aborting a task also means aborting any pending subtasks for the task. a remote task is aborted by sending a kill message as explained below. 
1. kill task-name : a kill message is sent to abort tasks remotely. when a kill message is received  the task name is removed from the potential work set. in case the task in question is the current task  it is aborted and another current task is chosen. also  if the task is awaiting completion of some of its subtasks  the subtasks are recursively aborted. 
1. done task-name binding-list : this is sent when the answer for a remotely originated task is obtained. when a done message is received  the result is reported to the parent of the task in question. the result is added to the results already obtained for the parent task name. if there are no pending subtasks for the parent task name  then the combined result for the parent task is reported to the processor that originated the parent task.1 again  a done message may have to be used if the originator of the parent task was a remote processor. the entire computation is 

1 	v. singh and m. genesereth 
complete when all needed results  one or all  for the toplevel task are reported. 
1. heuristics 
　several heuristics  as described below  are used to reduce computation and communication. 
　when it is time for a processor to select a new current task out of the potential work set  locally generated tasks are preferred: this saves on sending a done message for that task when the task is completed. 
　backward-chaining within a processor is done in a depth-first fashion. this reduces the search  compared to breadth-first  if only one positive result is desired.1 
　to reduce the number of grabs for the same task  the following heuristic is used. grabs by processors are given some arbitrary but pre-specified priority order. by watching messages on the broadcast network  processors get hints about the status of other processors. for example  if a processor sends out a grabbed message  other processors know that the processor is busy. when a new task is made available  a processor will defer grabbing to a higher-priority processor if both arc free. 
　when deciding which tasks to move to the potential work set  the most costly is picked. also  when deciding which task to grab out of the potential work set. the most costly is chosen. this is done so that a free processor grabs the most costly task first out of the surplus tasks available from all the processors. the effect is that  in general  processors tend to remain busy longer between grabs and this reduces the message traffic. 
　if no information is available about the cost of deductions  the least one can go by is that deductions higher up in the deduction tree are  on the average  more costly. also  if the delays are not very high  all processors can be heunstically assumed to be at the same level in the tree. therefore  the order of announcement of new tasks on the broadcast network can be heunstically assumed to be in the more costly to less costly order. 
b. domain of application of esp 
　more than one processor can start executing a task at the same time therefore  either the tasks should be side-effect free as in the backward chaining case or repetitions of side-effects should be acceptable. examples of acceptable repetitions of side-effects include 1  side-effects designed only to increase efficiency but not to affect the correctness of the computation  e.g.  caching of propositions in the backward chaining 
case  and 1  idempotent computations. 
　as mentioned before  esp can handle a realistic failure set. details of this can be found in a technical report written by the authors  singh  1 . 
c. comparisons with previous work 
　contract net  davis  1  was one of the first efforts to address the problem of dynamically distributing tasks among processors. its supply protocol uses what is called an announcement-bid-award sequence. enterprise  malone  1  uses a similar supply protocol but with significant specializations. in the discussion below  abasp stands for the announcement-bid-a ward type of protocol used in the contract net and enterprise. 
　esp allows task execution to begin as soon as a bid is submitted  in a grabbed message . this can increase processor utilization compared to abasp in which task execution begins only when an award message is received. 
　also  no award message is required as in abasp. additionally  there is the potential of drastically reducing the number of grabbed messages. the equivalent of bid messages in the abasp case. the number of grabbed messages may  in the best case  be one per new task announced. this will happen if the first grabbed message is always sufficiently early to inhibit any other processor from making an attempt to  grab  the same task. also  recall that a heuristic to reduce the number of grabbed messages was presented earlier. 
　note  however  that there is one source of extra messages in the supply-driven strategy using esp. multiple executions of the same task are possible. in theory  these multiple executions can create multiple sub-tasks  with extra new messages  in parallel that have to be killed off by extra kill messages. in practice  experimental results indicate that this is not a problem when delays are reasonably short and throughput is not a constraint. short delays lead to a quick killing of replicated executions before extra sub-tasks can be generated and announced from the short-lived replicated executions. the throughput constraint case will create a problem for enterprise and contract net as well but they do not propose any specific solutions. this paper  however  presents vsm to deal with that case. 
　shapiro's bagel  shapiro  1  also deals with dynamic distribution of tasks in a multiprocessor system. however  shapiro deals with systolic problems where programmer determined mappings arc possible. similar assumptions in the present case would mean that one would know ahead of time how many subtasks were going to be 
generated from each task. this paper makes no such assumption. 
vi a supply-driven allocation strategy 
　imagine for a moment that the broadcast network can allow an infinite message throughput. this assumption is  of course  not practical but it serves to illustrate the extreme of very plentiful network throughput. a supply-driven strategy  in which all newly generated tasks are announced to all processors  might be appropriate in precisely such a situation. 
　in the supply-driven strategy  all processors place all newly generated tasks  except one task that is chosen as the current task  in the potential work set. of course  all tasks placed in the potential work set must be announced with new messages. a processor is allowed to grab a task from the potential work set only when it runs out of internally generated tasks. since all surplus tasks are announced as being available  this strategy needs the highest network throughput of all strategies included in vsm. 
a. experimental results 
all results reported here were obtained by implementing vsm and 
esp on a simulation of the multiple processor architecture described in section iii.1 the unit of time for the results reported is the time taken to do a unit backward-chaining deduction. 
　figure 1 gives some information about the or deduction tree that was experimented with. the database of each processor contains the behavioral and structural description of a piece of digital hardware - a 1-bit adder. it also contains the values of its inputs. the top-level proposition is a fact to be proved about one of the outputs of the adder. it turns out that the top-level proposition has no positive answer and  therefore  the entire deduction tree is searched in trying to prove the proposition. 
　the time taken for 1 processor to do the adder example is 1 unit deduction time units. figure 1 shows the results obtained for the adder example with 1 to 1 processors. for now  the reader's attention is directed to the curves labeled supply-driven  infinite throughput. 
	v. singh and m. genesereth 	1 
figure 1: data 
bottleneck. however  the performance can be quite bad if the throughput does become a bottleneck. 
　it is important to note here that most of the time  it was not really necessary to announce all surplus tasks when all processors were already busy. the next section offers an alternative that can reduce the amount of communication and thereby decrease overall task b. conclusions 
the supply-driven strategy works well when the throughput is not a 
　　if communication cost is ignored as in minsky's hypothesis  the speedup curves for the supply-driven strategy in the infinite throughput case will be asymptotically linear  as long as the size of the or deducuon tree ls large enough compared to the number of processors. communication cost certainly reduces speedup but there is no proof that speedups will be only logarithmic in the general case 
completion time for the throughput bottleneck case. 
vii a demand-driven allocation strategy 
　the supply-driven strategy always supplies any surplus tasks and. therefore  uses up a lot of throughput. the other extreme is to supply surplus tasks only when all previously announced tasks have been grabbed. this is the demand-driven strategy. as will be shown later  this can drastically reduce message traffic and lead to faster completion of tasks when the available throughput is a bottleneck. 
　all surplus tasks are not supplied and  therefore  not placed in the potential work set. the surplus tasks that are not supplied are put in the actual work set. more precisely  when a processor generates more 

1 	v. singh and m. genesereth 
than one task  it keeps one as its next current task  supplies a task to the potential work set if the potential work set is empty  and keeps the remaining tasks in its actual work set. with this strategy  the tasks are 
supplied only when they are demanded  i.e.. when the potential work set gets empty . 
a. comparison with supply-driven allocation strategy 
   not only does the demand-driven strategy use fewer messages than the supply-driven strategy  as explained above  but in some cases the number of messages can be provably an infinitesimal fraction of the supply-dnven case. one such case is when the deduction tree is a balanced  binary tree and the ratio of the number of tasks to the number of processors goes asymptotically to infinity. more details are provided in  singh  1 . in addition  experimental data presented later will show a dramatic reduction in messages in a practical case. 
   another attracuve property of the demand-driven strategy is that it requires less storage. most tasks are kept locally whereas in the supplydriven case  all processors keep a copy of tasks not being worked on. 
    here is  however  a disadvantage with using the demand-driven strategy. there may be  in general  a higher delay in transferring tasks among processors. this can happen when more than one processor becomes free at the same time: one processor can grab the single task in the potential work set but the others have to wait for some surplus task to be transferred to the potential work set. an example in which the behavior of the demand-driven strategy is  in fact  unboundedly worse is where the total rate of generation of tasks is equal to the total rate of 
consumption of tasks and the rate of generation and consumption is not uniform over all tasks. a high delay in such a situation would further 
compound the problem. 
b. experimental results 
　the curves labeled demand-driven  infinite throughput in figure 1 illustrate the performance of the demand-driven strategy for the adder example for unit delay and infinite throughput. 
as can be seen by comparing the curves labeled demand-driven. 
infinite throughput and supply-driven. infinite throughput  the time taken for 1 processors with the demand-driven strategy  1  is slightly more that the time taken with the supply-dnven strategy  1 . the extra time taken is due to the extra delay in supplying tasks. however  the number of messages sent with the demand-driven strategy  1  is much lower than the number of messages sent with the supply-dnven strategy  1 . therefore  it should be expected that the demand-dnven strategy will not degrade as much in the presence of the same throughput limitation imposed on the supply-driven strategy. this is  in fact  the case as illustrated by the curves labeled demand-driven. bottleneck throughput. the delay is one and the maximum throughput is 1. 
   for 1 processors  the time taken for the demand-driven strategy only increases from 1 to 1 by changing the maximum throughput from infinity to 1. in the bottleneck case  the demand-driven strategy  with a time of 1  completely outperforms the supply-driven strategy  with a time of 1 . 
c. conclusions 
　the demand-driven strategy can perform better than the supplydriven strategy in the presence of throughput constraints because it requires fewer messages. 
   it is possible that the tradeoff between delay in supplying tasks  high for the demand-driven case  and the message traffic requirements  high in the supply-driven case  may not have been optimally resolved in cither of the extremes. an increase in delay may also be viewed as a reduction in parallelism. vsm allows any intermediate strategy to be selected with great ease and it seems quite probable that intermediate strategics will be found useful for intermediate communication situations. however  no results are available at the present time about these intermediate strategies. moreover  no results are available on automating the selection of such a strategy. 
viii conclusions 
　this section contains a description of possible extensions  future work and a summary of the paper. 
a. extensions 
　the variable supply idea is actually more general than what its application so far in vsm  in conjunction with esp  might suggest. the extensions described in this section retain the essential goal of vsm  the ability to vary the supply of new tasks given that communication constraints may exist. 
1. extension to different task domains 
   in cases where side-effects are not acceptable  one can use a different supply protocol with vsm that docs not allow multiple instances of a task to start executing. for example  one could use the announcementbid-award supply protocol  of contract net or enterprise . 
1. extension to different processor interconnection structures 
   it is possible to apply vsm to cases where the interconnection structure is not a single broadcast network. essentially  broadcasts arc replaced by limited broadcasts. the subset of processors to which a limited broadcast is directed is determined solely by the originating processor of the task. more details can be found in  singh  1 . 
1. using additional information 
costs of deductions 
　so far costs of deductions have not been used because it is not easy to make accurate estimates. however  if one docs have a means to obtain reasonable estimates  several uses are possible. 
   an application of cost estimates can be to stop distribution of certain propositions if their costs are too low to justify the overhead of distribution to other processors. 
   also  estimates can be used to break ties between processors with different speeds in a more efficient way than by just comparing the timestamps at which grabs take place. timestamps based on completion time estimates will be more profitable. 
another application of estimates can be to do load balancing. 
probabilities of proving propositions 
　these probabilities  along with costs of proving those propositions  can be used to determine the best order of doing the tasks  barnett  
1  simon  1 . further  rosenschein and singh  rosenschein  1  place an upper bound on the amount of work that may be done to achieve the optimal order determined as above. it may be possible to generalize that upper bound result for an arbitrary number of tasks. on the other hand  the result may be more immediately useful in doing many pairwise redistributions in the hope of getting most of the power of a complete redistribution. 
b. future work 
   a major effort of future work  singh  1  will be to remove the two major bottlenecks present in the current method of distribution of deductions: the replicated database and the shared communication network. the architecture to be used will consist of large numbers of processors connected with local connections to neighbors  as in a hexconnected plane  for example . each processor will have a limited amount of local memory that can only store a small part of the entire database. 
and parallelism will also be taken advantage of in a limited way. 
taking full advantage of and parallelism is a very difficult problem. 
c. summary 
　controlling communication cost was seen to be crucial for the successful use of the multiprocessor used. esp allows communication cost to be reduced in comparison to other task supply protocols. vsm allows an easy and powerful mechanism to choose strategies that work best under different communication constraints. the two extreme strategies were shown to be useful by theoretical and experimental results. in addition  vsm and esp can be adapted for use with other tasks  interconnection structures  and additional information about tasks. 
acknowledgments 
   we wish to thank ernst mayr for many stimulating discussions and all others that commented on earlier drafts of this paper. 
