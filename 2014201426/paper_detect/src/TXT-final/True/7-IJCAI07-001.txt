
using the achievements of my research group over the last 1+ years  i provide evidence to support the following hypothesis:
by complementing each other  cooperating reasoning process can achieve much more than they could if they only acted individually.
most of the work of my group has been on processes for mathematical reasoning and its applications  e.g. to formal methods. the reasoning processes we have studied include:
proof search: by meta-level inference  proof planning  abstraction  analogy  symmetry  and reasoning with diagrams.
representation discovery  formation and evolution: by analysing  diagnosing and repairing failed proof and planning attempts  forming and repairing new concepts and conjectures  and forming logical representations of informally stated problems.
other: learning of new proof methods from example proofs  finding counter-examples  reasoning under uncertainty  the presentation of and interaction with proofs  the automation of informal argument.
in particular  we have studied how these different kinds of process can complement each other  and cooperate to achieve complex goals.
we have applied this work to the following areas: proof by mathematical induction and co-induction; analysis; equation solving  mechanics problems; the building of ecological models; the synthesis  verification  transformation and editing of both hardware and software  including logic  functional and imperative programs  security protocols and process algebras; the configuration of hardware; game playing and cognitive modelling.
1	introduction
 many hands make light work   john heywood 
　much research in artificial intelligence consists of inventing or developing a new technique: analysing and establishing its properties  implementing and testing it  comparing it with rival techniques for the same task  etc. other work consists of combining several techniques into a complex system that solves problems  models natural systems  etc. it is commonly observed that complementary techniques can assist each other  extending their range of automation and/or effectiveness. for instance  this was the theme of a previous ijcai paper of mine  bundy  1 . it is not just that different techniques are needed to tackle different aspects of a complex task; one technique can also assist another by addressing its shortcomings. in the current paper we examine this observation in more detail  giving examples of how techniques can complement each other: achieving more than the sum of their parts. the examples are drawn from the work of my research group  over more than 1 years  aimed at automating mathematical reasoning.
　this same point could be illustrated by many pieces of work. however  given the context of this paper and the space limitations of the ijcai-1 proceedings  i have limited myself to work in which i played some role  albeit a small one in some cases. my apologies to those people whose work i have not surveyed; profuse apologies to those i have not even cited.
1	object-level and meta-level inference
 not all who wander are lost.   john ronald reuel tolkien 
　much of our work has been on automatic inference  especially proving mathematical theorems. most work in this area builds on mathematical logic  which is used to represent the conjectures to be proved  the axioms of the theories in which they are to be proved  and the rules of inference with which they are to be proved. these logical formulae provide a search space of potential proof steps. typically  proof search is conducted backwards  starting with the original conjecture as the main goal and applying the rules of inference backwards to exchange each goal for a set of subgoals. navigating this search space is the major problem in automated theorem proving. it is called the combinatorial explosion  because the number of subgoals increases super-exponentially with the length of the proof  rapidly swamping the computer's memory for all but trivial problems.
　human mathematicians succeed in navigating these huge search spaces by stepping back from the low-level details and thinking at a higher-level about the nature of the problem and the suitability of their tools for solving such problems. we have been trying to emulate this high-level thinking in our automated provers. in particular  we have implemented proof search as simultaneous and cooperating inference at two levels: the object-level  in which the original conjecture  theory and rules are expressed  and the meta-level  in which the proof methods are specified and the conjectures analysed. in meta-level inference  the conjecture is analysed  a suitable proof method identified and applied  progress is measured and the process recurses. in this way  inference at the metalevel directs inference at the object-level  avoiding unproductive parts of the search space and making proof search computationally tractable.
　we have applied this two-level approach many times  but most notably in the domains of equation solving using the press1 system  bundy and welham  1; sterling et al.  1  and inductive theorem proving using clam/oyster1 bundy et al.  1; bundy  1 . the latest realisation of this idea is proof planning    bundy  1; 1   in which proofmethods are specified as strips-like plan operatorsand plan formation is used to custom-build a proof plan for each conjecture.
　to illustrate these ideas i will describe rippling  a proof method for reducing the difference between a goal and one or more givens  bundy et al.  1a . it frequently occurs in mathematics that the goal to be proved is syntactically similar to a  given   i.e. a hypothesis  assumption or axiom. this occurs  most notably  in inductive proof  where the induction conclusion and induction hypothesis have strong similarities by construction. rippling was originally developed for such inductive proofs  but we have found widespread applications in other types of problem. typically  we want to rewrite the goal in such a way as to separate the similarities and differences while preserving the similarities. this enables the given s  to be used to prove all or part of the transformed goal. we can visualise this process by annotating the goal and the given s  with their similarities and differences  see figure1 .


the example shows the step case of an inductive proof of the associativity of list append  where    is the infix notation for append and :: is the infix notation for cons.  separates the induction hypothesis  the given  from the induction conclusion  the goal . the formulae are annotated to show the differences and similarities between the given and the goal. the grey boxes indicate the parts of the goal which differ from the given. they are called wave-fronts. each wave-front has one or more waveholes indicating sub-terms of the wave-fronts which correspond to parts of the given. the parts of the goal outside the wave-fronts or inside the wave-holes  are called the skeleton. the skeleton always matches the induction hypothesis. the arrows indicate the direction of movement of the wave-fronts - in this case outwards through the goal until they completely surround the skeleton.
the rules are also annotated and annotation must also match when rules are applied. such annotated rules are called wave-rules. the main wave-rule used in this example is:
h :: t ●    l   h :: t    l ●
which is taken from the step case of the recursive definition of   .
note how the grey boxes get bigger at each wave-rule application with more of the skeleton embedded within them  until they contain a complete instance of the given.
figure 1: the associativity of append using rippling

　rippling successfully guides proof search by ensuring that the skeleton gets larger until it matches the givens. at this point the givens can be used to prove the goal. it has been successfully applied in induction  summing series  analysis and a variety of other areas. more importantly  if and when it fails  the nature of the failure can be used to suggest a way to patch the proof attempt and to recover from the failure  see ′1 .
　meta-level inference provides least-commitment devices  such as meta-variables  which can be used to postpone search decisions. for instance  in inductive proof  choosing an appropriate induction rule is an infinite branching point in the search: there is an induction rule corresponding to each well-ordering of each recursive data-structure  such as natural numbers  lists  trees  sets  etc. the key to a successful induction is often to choose an induction rule that inserts wave-fronts into the induction conclusion for which there are matching wave-rules  so that rippling is successful. we can turn this requirement on its head by postponing the choice of induction rule  inserting higher-order meta-variables into the induction conclusion to stand for the unknown wavefront  using higher-order unification to instantiate these metavariables during rippling  and retrospectively choosing an induction rule when the wave-fronts are fully instantiated. this significantly reduces the search problem by moving it from a place  the choice of induction rule  where the branching is infinite  to a place  rippling  where it is highly constrained. because we are effectively developing the middle of the proof before the beginning or the end  we call this search moving technique middle-out reasoning  in contrast to top-down or bottom-up reasoning.
　we have applied middle-out reasoning to the choice of induction rule in two phd projects. initially  ina kraan used it to select an appropriate induction rule from a pre-determined  finite set of rules  as part of a project to synthesise logic programs from their specifications  kraan et al.  1 . in this project  kraan also used middle-out reasoning to synthesise the logic program. more recently  jeremy gow extended middle-out reasoning to create and verify new induction rules  customised to the current conjecture  gow  1; bundy et al.  1b .
　proof planning is now a thriving research area  with many applications and extensions  for instance:
  the Ωmega proof planner  siekmann et al.  1   which has been applied to a wide range of areas in mathematics;
  applications to the combination and augmentation of decision procedures  janic・i＞c and bundy  1 ;
  multi-agent proof planning  benzmu：ller and sorge  1 ;
  reasoning about feature interaction in first-order temporal logic  castellini and smaill  1 
  multi-strategy proof planning  melis et al.  1 .
i have also proposed it as the basis for a  science of reasoning   in which proof plans provide a multi-level understanding of the structure of proofs  bundy  1 
　meta-level inference  and proof planning in particular  shows how two complementaryinference processes can interact to reduce the amount of search and overcome the combinatorial explosion. meta-level analysis matches object-level goals to the proof methods best suited to solve them  cutting out a lot of legal  but unproductive  object-level  rule applications. middle-out reasoning can rearrange the search space  postponing difficult search decisions until they are made easier as a side-effect of other search decisions. the object-level inference then provides the goals that form the ammunition for the next stage of meta-level analysis.
1	inference and fault diagnosis
 the best laid plans of mice and men gang aft aglay.   rabbie burns 
　like all plans  proof plans are not guaranteed to succeed. when they fail  recovery requires another kind of reasoning process: fault diagnosis. when standard object-level proof search fails  the usual response is for the proof search to backup to some earlier choice point and retry. proof planning enables a more productive use to be made of failure. the mismatch between the situation anticipated at the meta-level and the situation obtaining at the object-level provides an opportunity to analyse the failure and propose a patch. human mathematicians also make a productive use of failure. see  for instance   van der waerden  1  for an example of repeated plan failure and patching in an  eventually successful  attempt to prove a challenging conjecture.
　consider  as another example  a failure of the rippling method outlined in ′1. this might occur  for instance  because there is no rule available to ripple the wave-front out one more stage. from the meta-level inference that formed the rippling-basedproofplan  we can extract a partial description of the form that the missing wave-rule should take. this is best illustrated by an example. see figure 1.
　we have implemented this kind of fault diagnosis and repair within our proof planning framework using proof critics  ireland  1; ireland and bundy  1 . the original work explored ways to recover from different kinds of failure of rippling  suggesting  variously  new forms of induction  case splits  generalisations and intermediate lemmas. later work by ireland and his co-workers has extended this to discovering loop invariants in the verification of imperative programs  ireland and stark  1 . they have recently applied this work to industrial verification by extending and successfully evaluating praxis' automated prover  ireland et al.  1 . deepak kapur and m. subramaniam have also developed similar methods for lemma discovery in induction  kapur and subramaniam  1 . ra＞ul monroy has used critics for the correction of false conjectures  monroy et al.  1   which requires the additional reasoning process of abduction. more recently  monroy has applied his techniques to higher-order faulty conjectures  leading to the automatic formation of new theories  such as monoids  monroy  1 . andreas meier and erica melis have adapted their multi-strategy multi system to include failure analysis and the automatic proposal of  recommendations  to overcome them  meier and melis  1 .
　fault diagnosis of an earlier failure suggests the most promising alternative proof attempt. it removes the need for blind backtracking  removing legal  but unproductive choices from the search space and helping to defeat the combinatorial explosion. moreover  the proof patches often provide inter-

blocked
rev is a list reversing function. the example is taken from a failed proof that reversing a list twice will give you the original list. suppose that  initially  the only rule available is:
rev  h :: t ●    rev t      h :: nil  ●
the ripple attempt will fail because no rule matches the left hand side of the goal  so the wave-front cannot be moved one stage further outwards. however  by analysing the blocked ripple  fault diagnosis can work out that the missing wave-rule should take the form:
rev  x    y ●    f rev x  x y   ●
where f stands for some unknown function  represented by a higher-order meta-variable. if we allow the proof to continue using this missing wave-rule schema  then the proof will succeed  instantiating f u v w  to rev w     u in the process. we now discover the missing wave-rule to be:
rev  x    y ●    rev y      rev x  ●
which must be proved as a lemma to complete the proof. note that this lemma is a distributive law of    over rev  and is an interesting theorem in its own right  rather than just an arbitrary hack needed just to get the original proof to go through.
figure 1: lemma speculation using a rippling failure

esting information. as the example in figure 1 illustrates  lemma speculation often produces lemmas that are of mathematical interest in their own right and prove to be useful in future proofs. generalisation  which is another way of patching failed inductive proofs  also often generalises the original conjecture in a mathematically interesting way.
　in the other direction  the kind of fault diagnosis illustrated in figure 1 is only possible because of the interaction of metalevel and object-level inference. it is the discrepancy between the meta-level expectation and the object-level reality that focuses the fault diagnosis to suggest a patch that will resolve
this discrepancy and allow the original proof plan to be resumed. thus  again  we see complementary reasoning processes focus their attention to solve a problem that none of them could manage alone - nor even acting simultaneously but without interaction.
1	inference and learning
 to this day  we continue to find new techniques and methods. there's always something new to learn.   joseph cocking 
　we have seen the value of proof methods when used by meta-level inference or fault diagnosis to guide object-level proof search  but where do such proof methods come from  mostly  they have come from detailed analysis of a family of related proofs  and reflection on the thinking that informs experienced mathematical reasoners. but this is a time-consuming  highly-skilled and error-prone process. the proof methods that my group developed for inductive proof  for instance  took more than a decade to develop  evaluate and refine. it is necessary to maintain constant vigilance against quick  ad hoc fixes that will not have general utility and explanatory power. it would be much better if the process of developing new proof methods could be automated.
　my group has explored various machine learning techniques to automate the construction of proof methods. these start with successful object-level proofs whose meta-level structurethey try to analyse and abstract  in order to formulate new proof methods. our earliest attempt to do this was the application of explanation-based generalisation  ebg  to the equation-solving domain  silver  1 . silver's learning press system was able to learn  sometimes simplified  versions of all the proof methods that had been hand-coded into our press equation solving system  just by applying ebg to examples of successfully solved equations. later  desimone did the same for early versions of our inductiveproofmethods  desimone  1 .
　recently  we have explored the use of data-mining techniques to extract new methods1 from large corpuses of proofs  duncan et al.  1 . duncan's isanewt1 system first identifies frequently occurring sequences of proof steps using variable-length markov models  vlmm   ron et al.  1 . then it combines these sequences using genetic algorithms to join them with branching  repetition and macros  using a language developed in  jamnik et al.  1 . the resulting proof methods have been evaluated successfully by comparing proof success and timings on a large test corpus of proofs with and without the newly learnt tactics. currently  the learnt methods consist of simple  generic combinations of objectlevel rules. they do not approach the sophistication nor targeting of many hand-crafted methods  such as rippling. nor do they provide dramatic search reductions. however  this use of data-mining has made a promising start and has the potential for much more development.
　we have introduced a new class of reasoning processes from machine learning. these complement meta-level inference by constructing new proof methods from example proofs  thus enabling meta-level inference to guide objectlevel proof search. the learning methods are  in turn  informed by previous success of object-level inference in producing proofs. their analysis is informed by the patterns they identify in these proofs. thus we have a virtuous triangle of reasoning processes  each process in the triangle using information from one of its neighbours to assist the other neighbour.
　however  there is a missing process in this story: a learning process that can construct the meta-level language used to specify the proof methods. examples of such a language are the concepts of wave-fronts  wave-holes and skeletons  introduced and illustrated in figure 1. silver's and desimone's ebg-based systems assumed the prior existence of an appropriate meta-level language and used it in the analysis of the object-level proofs. duncan's isanewt does not assume the existence of such a meta-language  so is  thereby  restricted to an impoverished language for expressing proof methods. it cannot use conditional branching  since the conditions would have to be expressed in the missing meta-language. it uses non-deterministic branching instead. similarly  it cannot use until-loops  since again the exit condition would have to be expressed in the missing meta-language. it just uses repetition. it cannot combine the proof methods with proof planning or analyse failures with fault diagnosis  as the method specifications necessary to do this would need to be expressed in the missing meta-language. instead  it is reduced to conducting exhaustive search at the method level  which reduces search  but not in as directed a way as proof planning is capable of.
　current ai learning mechanisms appear not to be capable of performing the learning task required here: constructing a new ontology. there are plenty of mechanisms for defining new concepts in terms of old ones  but that is not sufficient to form a new meta-language. the concept of wave-front  for instance  cannot be defined in terms of the functions and predicates in the object-language. here's a hard challenge for the next generation of machine learning researchers. for a start on tackling this challenge  see ′1.
1	inference and representation formation
 once you know the formula  it's a guiding light that will give you everything you want to know. 
 mark lallemand 
　as discussed in ′1  the automation of inference requires that the axioms  rules and conjectures of a theory be represented in the computer. where do such representations come from  in most work in automated inference  either they are adopted/adapted from a textbook or from previous research  or they are the outcome of careful and highly-skilled handcrafting. however  developing an appropriate representation is one of the most important parts of problem solving. applied mathematics  for instance  mainly consists of exploring and developing mathematical representations of physical environments and problems. so  in a thorough investigation of automatic reasoning  the formation of formal representations ought to be a central concern.
　in the mecho1 project   bundy et al.  1   we addressed this issue by building a program for solving mechanics problems stated in english  with examples drawn from the english gce a-level  applied-mathematics papers  intended for 1 year old pre-university entrants. mecho took mechanics problems stated in english  parsed them  constructed a semantic representation in the form of first-order logic assertions  extracted equations from this logical representation and then solved them. this process is illustrated in figure 1.
　during this process  cooperation between representation formation and inference occurs at a number of levels and in several directions.
  the whole process of representation enables inference  in the form of equation solving  to solve the mechanics problem.
  a form of non-monotonic inference is needed to  flesh out  the explicit problem statement. real-world objects must be idealised  and this can be done in a variety of ways. for instance  a ship might be idealised as a particle on a horizontal plane in a relative velocity problem  but in a specific gravity problem it will be idealised as a 1d shell floating on a liquid. the string in a pulley problem is usually idealised as inelastic and the pulley as frictionless. mecho uses cues to recognise the problem type and then matches a problem-typeschema to the extracted assertions  which then provides the implicit  unstated assertions.
  mecho uses a form of plan formation1 to extract a set of equations from the assertions. a physical law is identified that relates the goals to the givens  e.g.  f = m.a. these equations may introduce intermediate variables  which must also be solved for  causing the planning process to recurse. preconditions of the physical laws relate the variables to the assertions  enabling the laws to be instantiated to equations describing the problem situation.   equation solving is used to express the goal variable in terms of the givens. this inferential process is implemented using meta-level inference  as described in ′1.   inference is also required during natural language processing  e.g.  to resolve ambiguities  such as pronoun reference. the meta-level inference mechanisms used in mecho were motivated by the problems of controlling inference both in problem-solving and semantic interpretation  and were successful in both areas. for instance  the inferential choices arising during semantic processing are limited by idealisation  especially by the framework imposed by problem-type schemata.
　the ideas from the mecho project were subsequently adapted to the eco program  which built an ecological simulation program in response to a dialogue with a user  robertson et al.  1 . eco incorporated a further example of collaborative reasoning: a meta-level analysis of the user's requirements was used to propose two kinds of idealisation. eco was able to suggest both idealisations of real world ecological objects  e.g.  animals  plants  environments  etc.  and idealisations of the processes by which they interacted  e.g. 

the input is a mechanics problem  posed in english  taken from an applied mathematics textbook. this is first parsed to identify its syntactic structure and then turned into a set of logical assertions by semantic analysis. these assertions must be  fleshed out  by cuing schemata to provide unstated  but implicit  default information. the givens and goals of the problem are identified and a planning process is used to instantiate general physical laws into a set of simultaneous equations from which the goals can be derived from the givens. the press equation solver is then used to express the goals in terms of the givens.
figure 1: representations used by the mecho program
logistic growth  predator-prey equation  competition equation  etc.
1	inference  fault diagnosis and ontology repair
 i shall try to correct errors when shown to be errors  and i shall adopt new views so fast as they shall appear to be true views   abraham lincoln  
　mecho and eco formed representations with the aid of natural language processing tools and inference  but from a fixed signature  by which i mean the variables  functions and predicates  along with their types  that were used to form the logical formulae. however  as we saw in ′1  it is sometimes necessary to invent new concepts and to create new functions  predicates  types  etc. with which to represent these new concepts.
1	repairing faulty conjectures
alison pease and simon colton's tm1 program   colton and pease  1   implements some ideas of lakatos  lakatos  1  for repairing faulty mathematical theories. in particular  it takes nearly true conjectures and repairs them into theorems. tm achieves this by orchestrating: the otter theorem prover  mccune  1 ; the mace counter-example finder  mccune  1  and the hr1 machine learning system  colton et al.  1; colton  1 .
　given a false conjecture  first mace is used to find both a set of counter-examples and a set of supporting examples. tm then implements lakatos's methods of strategic withdrawal and counter-example barring to modify the original  false conjecture into new conjectures that it hopes are true. in strategic withdrawal  hr finds a concept that describes a maximal subset of supporting examples and the theorem is specialised to just that concept. in counter-example barring  hr finds a concept that covers all the counter-examples and a minimal subset of supporting examples  then makes the negation of that concept a precondition of the revised theorem. these new conjectures are given to otter to verify. the tm system thus exhibits the interaction of three kinds of reasoning: model generation  concept formation and inference  to do something that neither of them could do alone: correcting faulty conjectures. an example is given in figure 1.

tm was given the following faulty conjecture in ring theory:
 x y. x1  y   x1 = e
where e is the multiplicative identity element.
mace found 1 supporting examples and 1 counterexamples to this conjecture. given these two sets of examples  hr invented a concept that can be simplified to:
 z. z1 = z + z
and used it for strategic withdrawal. otter was then able to prove the original conjecture for just those rings
with this new property.
figure 1: correcting a faulty conjecture in ring theory

   hr has also been used a component of a system for the automatic generation of classification theorems for algebra models up to isomorphism and isotopism   colton et al.  1; sorge et al.  1 . this system employs an intricate interplay of machine learning  computer algebra  model generation  theorem proving and satisfiability solving methods  and has produced new results in pure mathematics. for instance  it generated an isotopic classification theorem for loops of size 1  which extended the previously known result that there are 1. this result was previously beyond the capabilities of automated reasoning techniques.
1	repairing faulty signatures
however  note that hr does not extend the signature of the representation language. its new concepts are defined in terms of a fixed set of functions  relations and types. in contrast  fiona mcneill's ors1 modifies the underlying signature  e.g.  by changing the arity and types of functions and predicates  and by merging or separating functions and predicates  bundy et al.  1; mcneill  1 . ors is designed for a virtual world of interacting software agents. it achieves its goals by forming and executing plans that combine the services of other agents.
　however  these plans are fallible and may fail on execution. plan formation can be viewed as an automated proof of an existential theorem  where the witness of the existentially quantified variable is a plan  and the proof shows that this plan is guaranteed to achieve its goal. this plan may  nevertheless  fail to execute  because the planning agent's world model is faulty. in particular  its theory of the circumstances under which other agents will performcertain services are expressed as preconditions of action rules. however  the other agents may have different versions of these action rules. the planning agent must diagnose the fault with its version of the rule; repair the rule; and replan with the amended rule. this repair may just consist of adding or deleting a precondition  or it may go deeper  requiring a change to the signature with which the preconditions are expressed. an example is given in figure 1.

suppose that the planning agent's plan contains an action
to pay a hotel bill  represented as
　　 pay pa hotel $1  where pa is the planning agent. this action fails on execution. just prior to failure there is a short dialogue with the hotel agent. such inter-agent dialogues are the normal way to check those preconditions of whose truth value the service providing agent is unsure. the planning agent is expecting to be asked  money pa $1 
however  it is surprised to be asked
　　 money pa $1 creditcard  instead. this suggests that the hotel agent has a ternary version of the money predicate  rather than the planning agent's binary predicate. in order to communicate successfully with the hotel agent  the planning agent must change the arity of its money predicate accordingly and replan.
figure 1: repairing an ontology signature

   ors employs interactions between three kinds of reasoning process: inference in the form of plan formation; fault diagnosis of the failures of plan execution and any dialogue prior to this failure; and mechanisms for repairing faults in both the theory and the signature of its ontology. the fault diagnosis works by a simple decision tree  in which the notion of being asked a surprising question  or not  is a key diagnostic cue. it assumes a context in which there is a large measure of ontological agreement between interacting agents  but some critical differences that  uncorrected  will cause the agents' plans to fail. this context might arise  for instance  where the agents have tried to adhere to some ontological standard  but different versions and local customisation have created critical differences. it can help where the ontological differences only require localised repairs  but where such repairs must be done at runtime and without human intervention  for instance  where very large numbers of software agents are interacting over the internet.
　an agent can use inference to form plans to achieve its goals  but these are only guaranteedto succeed when its world model is perfect. since perfect world models are  in practice  unattainable  a successful agent must also be able to repair a faulty world model. this requires the interaction of inference with fault detection  diagnosis and repair. fault detection requires inference to provide a failed plan. fault diagnosis requires a fault to be detected and the failed plan for analysis  together with further inference about the state of the world and how it differs from the world model. fault repair requires a diagnosis of the fault. successful inference requires the repaired world model. these reasoning processes thus constitute a virtuous circle  which incrementally improves the success of the agent in attaining its goals.
1	conclusion
 come together   john lennon & paul mccartney 
in this paper we have been defending the hypothesis that:
by complementing each other  cooperating reasoning process can achieve much more than they could if they only acted individually.
we have presented evidence in favour of this hypothesisaccumulated over more than 1 years within my research group1. in particular  we have seen how processes of inference  at both object and meta-level  planning  fault diagnosis  learning  counter-example finding  representation formation and ontology repair can interact. it is not just that different processes deal with different parts of the task  but that the weaknesses in one process are complemented by strengths in another  leading to the more efficient and effective running of each process and of their combination. search that would overwhelm an inference process running on its own  is effectively guided when two inference processes run in tandem. faults that would otherwise remain undetected  are made manifest by the mismatching expectations of two inference processes. formal representations required to perform inference are formed with the aid of inference. new proofmethods needed to guide inference are created by learning from previously successful examples of inference. faulty world models are detected  diagnosed and repaired.
   ai has become fragmented over the last 1 years. the development of robust  scalable ai systems to emulate the many facets of intelligence has proven to be much more difficult than envisaged by the ai pioneers of the 1s and 1s. to make the task tractable  we divided ourselves into smaller  specialised communities  organised our own conferences and journals  and developed a separate series of techniques for each of the different facets of intelligence. we have made enormous progress. our techniques are theoretically well understood  robust and applicable to important practical problems. but  taken individually  they each suffer from severe limitations of range and autonomy.
　one lesson from this paper is that perhaps the time has come to reintegrate artificial intelligence; to discover how the limitations of one kind of technique can be overcome by complementing it with another; to realise that together we have already achieved much more than we had realised when we were apart.
