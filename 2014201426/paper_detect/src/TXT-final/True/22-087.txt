 
a cognitive model of student programmers is presented. the model is based on protocol studies of students writing pascal programs  and is implemented in a computer simulation program. the claim of this paper is that a computational cognitive model of student program generation fits within a generate-test-and-debug  gtd  problem solving architecture in which impasse/repair knowledge plays a key role. the claim is supported by showing how the model provides a useful descriptive account of the way students write alternative programs. 
1 introduction: motivation  goals  and overview 
our motivation for studying student programmers derives from three beliefs: 
 1  it is important to teach students design skills  i.e.  planning  constructing  and debugging artifacts    1  programming is an excellent vehicle for teaching design skills  and  1  computers by virtue of their ability to help students visualize and manipulate artifacts can play a unique role in supporting design activities. our short term goal has been to develop a simulation model of the way students write programs. 
since design tasks can be solved in many different ways  any attempt to understand the way students write programs runs head-long into the variability problem. unlike tasks such as subtracting numbers  i.e.  nondesign tasks  that have only a single correct answer  there are an enormous number of programs that solve any given programming task  just ask someone who has graded a couple hundred student programs! . when one considers alternative buggy programs as well as correct programs  the variability problem takes on truly staggering proportions  and bug diagnosis for tutorial purposes becomes quite difficult  js1 . in addition  tracking student program generation behavior for the purpose of providing tutorial assistance is complicated by student variability  abr1 . a student model for programming should provide an account of the program generation process and the individual differences between students that cause vari ibility. 
acknowledgements: this research was funded in part by the national 
science foundation  under nsf grant mdr-1. we wish to thank david littman for his comments on drafts of this paper. 
to develop a cognitive model of student programmers  we began an in depth study of students as they sat in front of computer terminals and wrote programs. a substantial amount of data -- both on-line protocols  the endproduct programs  and thinking-aloud protocols  complete problem solving behavior traces of the verbally reported planning  implemention  and debugging steps involved in writing a program  - were collected. based on an analysis of these data  a generate-test-and-debug  gtd  problem solving architecture  see  su1    ham1    si1   was adopted as an overall framework. 
during the generate phase  students use different generation mechanisms to write code to achieve the goals of the task specification. the students either 
 1  used previously acquired programming knowledge to write the code  or  1  created new programming knowledge by translating relevant nonprogramming knowledge into code. non-programming knowledge  see  bs1   corresponds intuitively to knowledge that would allow a student to easily do a calculation-by-hand. for instance  a student may be able to calculate the average of an arbitrary set of numbers by hand  but have a great deal of difficulty writing a program to do the same. during the test phase  students use different program testing mechanisms to detect one of a few types of problems  or impasses. the students either  1  compared a simulation of their programs to an internal model  or  1  checked for specific commonly occuring bugs. during the debug phase  impasses are fixed using one of small set of repairs. 
variability can arise in several ways in a gtd impasse/repair student model. 
one way variability can arise is when different students choose different repairs for the same impasse  bv1   bs1 . for instance  when we asked students to write a program that handled both valid and invalid input data  
1% of the students generated a program with an  output-after-error  bug. figure 1 shows a pseudo-code program with the bug and two repairs. in the buggy program  if the input is invalid  after printing the error message the output will be attempted. since the program should stop after printing the error message  a student might detect an impasse. the impasse is caused by an expectation violation - after the  error  goal   stop  was expected  but 
	spohrer and soloway 	1 
 output  was found  i.e.  bad-next-goal . some students chose to repair the impasse by moving the the output  i.e.  move-
encountered   while other students put a guard around the output  i.e.  insert-split . 
marcel is a simulation program that embodies the gtd impasse/repair model descibed in this paper. as shown in figure 1  marcel's inputs are a specification of a programming task and a description of a particular student. marcel's outputs are a pascal program and a behavior trace. a behavior trace corresponds to the main planning and debugging steps taken by a student writing a program. inside the process box in figure 1  three main components are identified:  1  model of individual differences   1  model of program generation  and  1  the contents of working memory. 
grapes  afs1  is another system that simulates students writing both correct and buggy programs for moderately complex introductory tasks. 
unlike marcel's gtd impasse/repair architecture  grapes uses a goalrestricted production system architecture and focuses on the way students learn to write short lisp functions  rather than on accounting for intersubject variability. in grapes  individual differences are modelled by using different production rules and manually changing the contents of working memory during processing. 
the remainder of this paper summarizes the four main results of this research:  1  categorization of student programming data   1  taxonomy of student programmer plan knowledge   1  model of student program generation  and  1  preliminary model of individual differences and variability. examples of student program generation and individual 
differences will be presented. 
1 	student programming data 

cognitive models the students under study were yale undergraduates taking their first pascal programming course. the stimulus material included three programming tasks. summaries of the tasks along with sample pseudo-code programs are shown in figure 1  familiarity with the tasks and programs is essential foi understanding this paper . the tasks are called arithmetic word programming tasks  see  kg1   mps1  for related non-programming 
tasks . 
the data  programs and behavior traces  were broken down into four categories of variability:  1  goals and plans - the goals  e.g.  input  validation  calculate  output  loop  etc.  and the alternative plans to achieve the goals with pascal code were catalogued  spl*1    1  bugs - nearly all of the programs contained bugs  and different student made different bugs  ssp1    1  goal orders - the order in which different students worked on the main goals in the program varied and so the different orders were catalogued  and  1  impasse/repair episodes - on average about once every three minutes while writing the programs  students would encounter difficulties or impasses that they would fix or repair  and so these episodes were catalogued. a coding scheme was developed  and the data were classified with 1% inter-coder reliability into over twenty different subcategories  see  s1  for details . 
1 	student programmer plan knowledge 
1. the electric bill task: calculate the electric bill for a customer {id  based on how many kilowatt hours of electricity the customer used  kwh . the charge is 1 cents for the first 1 kwh used  1 cents for the next 1 kwh used  1 cents for the next 1 kwh used  and 1 cents for all usage over 1 kwh.  implicit requirement from classroom lecture: the program should print an error message and stop if the kwh amount input is invalid.  
1. the reformatting task: read in raw data collected during an experiment and print out the reformatted data. the input is the subject number  problem type  'a'  'b' or 'c'   the start and end times of the experiment  in hours  minutes and seconds   and the subject's accuracy  v or '-' . the output should be the subject number  the problem type  the elapsed time in seconds  and the accuracy. perform valid-data-entry: if any of the input values are invalid  give the user a second chance to enter them and assume valid data will be entered the second time. the program should input and print out data for a series of subjects as long as the user has more data to process; stop when a sentinel value is entered. 
1. the rainfall task: read in a series of rainfall values stopping when the sentinel value  1  is entered. the sentinel value is a special value  indicating the end of the input data  and should not be included in the calculation. if the input is invalid  prompt the user again and again until the input is valid  vde . the program should print out the number of valid rainfall amounts entered  the number of rainy days  the maximum rainfall amount  and the average rainfall amount. input id.kwh  if invalid then error else begin calculation 
output id kwh cost  
end 
valid-data-entry  more-data  while not-sentinel more-data  do begin valid-data-entry raw-data  
calculation 
output reformatted-data  
valid-data-entry more-data  
¡¡¡¡end initialization; vde rain  if sentinel rain  then no-valid-input-error 
else begin while not-sentinel rain  do begin update; vde rain  
end 
calculation; output before considering the way marcel simulates inexperienced students  it is instructive to consider the knowledge that marcel requires to simulate experienced programmers. when marcel simulates an experienced programmer  it performs as an automatic programming system with a knowledge-base that is appropriate for arithmetic word tasks. programming plans  i.e.  multiple lines of code that work together in specific ways  are a 
key type of knowledge that programmers use when they write and read programs  sh1  mrrh1  se1 . evidence for plans can be found in 
protocol snippets  e.g.   ...same as  last  problem. i'm gonna have... two prompts to enter the value  one outside the loop... and then one inside the 
loop... . 
 two categories of plans have been identified:  1  information transfer or communication plans  e.g.  input/validation/output   and  1  information transmutation or calculation plans. one motivation for making this division is that a small set of very modular programming plans result  in which different calculation plans can be  plugged into  standard positions in communication plans. also  students have well developed non-programming knowledge in these two areas: communication between agents  p1 t and  calculations-by-hand   bs1 . 
the communication plans are broken down into two categories:  1  four input/output plans  i.e.   transform    alternate    compress   and  expand    and  1  four validation plans  i.e.   no-check    error-stop    one-retry   and  multiple-retry  . the input/output plans correspond to the four possibilities of the input/output being non-stream/stream  where a stream is a series of values. a non-stream is either an individual  a single value  or an 

figure 1: three tasks and pseudo-code programs. 

end 
	spohrer and soloway 	1 

aggregate  a small fixed set of values . figure 1 shows pseudo-code programs for the possible information transfer plans   error-stop  validation on right . referring back to figure 1  note that the electric bill task is of type  transform   error-stop   the reformatting task is  alternate   oneretry   and the rainfall task is  compress   multiple-retry . 
the calculation plans are indexed by a set of goals and objects. the goals consume objects and produce new objects. each calculation plan is composed of a small set of goals  e.g.  convert  combine  etc.  and objects  amount  count  etc. . the complete set of goals and objects along with supporting protocol evidence is provided in |s1j. 
1 model of program generation 
the marcel model of student program generation is an example of a generate-test-and-debug  gtd  problem solver. a gtd problem solver has three main phases:  1  a generate phase in which plans for goals are generated and implemented   1  a test phase in which impasses are detected  and  1  a debug phase in which impasses are repaired. fleshing out the model requires identifying specific mechanisms that underlie each phase and that could give rise to the observed behavior traces. in addition  it requires specifying the impasse/repair knowledge. 
during the generate phase  marcel uses two mechanisms to write programs:  1  plan instantiation  if a student knows a programming plan for 
cognitive models 
achieving a goal  and  1  plan translation  if a student does not know a programming plan  but does know a non-programming plan to achieve the goal by hand calculation. unlike programming plans which organize subgoals using pascal language constructs  non-programming plans organize subgoals in a domain general manner. non-programming plans order goals and specify the circumstances  or cases  in which a goal should be achieved. non-programming plans of this type are called goal-casenetwork  gcn  plans. a gcn plan is a directed and labeled graph  possibly with cycles  that represents information similar to that contained in a programming plan  but without using programming language constructs. a gcn plan for the electric bill task is shown in figure 1  note the black square box in the gcn plan is a stop goal  terminating the plan . 
a student solving the electric bill task starts by retrieving a template for the top-level program goal  see top of figure 1 . the goal for the body of the program is the next substantitive goal to be achieved. to achieve the body goal  a student may decide to instantiate a  transform  plan learned from solving a previous task  or translate the gcn plan from the specification. if a student instantiates a  transform   no-check  plan  i.e.  input  calculate  output   the calculation will be done on invalid input data  i.e.  bad-kind-to-consumer impasse . if the impasse is detected  it can be repaired by inserting a validation guard around the calculation goal  i.e.  insert-split repair . however  the repair results in the  outputafter-error  bug  the bug described previously in figure 1; in figure 1 the second box down from the top on the left . 

during the test phase  marcel employs two main mechanisms to test the program and detect impasses:  1  isonwrphism test  a student may use expectations derived from non-programming plan knowledge to simulate and match against the program to detect impasses  e.g.  bad-next-goal  objectused-but-not-produced  double-use  bad-source  over-write  and bad-kind-toconsumer   1  critics  a student may use a set of critics  or special purpose heuristics learned from textbooks or classroom instruction  to evaluate a program  e.g.  variable-used-but-not-declared  missing-begin-end  etc. . the iso-morphism test employs a simulate-and-compare mechanism to ensure that not only are goals being achieved in the correct order  but that appropriate object values are being produced and consumed by the goals. sometimes students use isomorphism tests that do not detect all impasses under all circumstances. for instance  figure 1 shows a pseudo-code program with an  output-after-error . the bug is not detected if the stop goal is not checked for after the error goal. however  if the stop goal is checked for then  after the error goal the student would expect to find a stop goal  but instead encounters an output goal  thereby detects an impasse  i.e.  bad-next-goal impasse; see third box down on left in figure 1  also see figure. 1 . 
during the debug phase  a repair is selected for an impasse. all of the repairs involve simple editing operations  insert  delete  move  change  duplicate  on a few basic types of program elements  producer  consumer  expected  encountered  object  test  split   defined when a particular impasse is detected in a particular program context. for instance  in figure 1  a bad-kind impasse is repaired with an insert-split repair. at the bottom of figure 1  as previously seen in figure 1   a bad-next-goal impasse is repaired with  in one case  a move-encountered repair  and in a second case  with an insert-split repair. after attempting a repair  the test phase is re-entered to see if the repair succeeds or gives rise to a new impasse. if the repair succeeds the generate phase is returned to  but if the repair gives rise to a new impasse  the debug phase is returned to and a new round of repairing will begin. by applying different repairs to an impasse  programs can be generated in different ways. 
1. model of individual differences 
three types of individual differences are considered in the current model:  1  specification understanding -- students interpret the same specification differently   1  domain-specific learning -- students learn different programming plans and then re-use them later  and  1  progress criteria 
	spohrer and soloway 	1 

 ns1  - students may use different criteria for evaluating what course of action will lead to progress. for example  consider writing a program that repeatedly processes different input values  stopping when a sentinel value is entered  e.g.  like the reformatting task . figure 1 shows correct and buggy 
pseudo-code programs based on the programs that students typically 
generate. 
specification understanding: the  missing loop  bug can be generated by assuming an alternative interpretation of the programming task. for instance  one student who left out the loop said  1 didn't  see  this the first time...    upon looking more closely at the problem speicification. marcel does not simulate the understanding process  but can be given  buggy  representations of the specification to work from. domain-specific learning: one way to simulate different students using different plans is to simply give different student models different plans. for instance  for dealing with repeately processing input  some students may have learned the  duplicate input  plan  others the  dummy inii' plan  and still others the  more data  plan. this assumes that the different progress criteria - relative impasse difficulty: another way in which the programs in figure 1 can be generated is based on different progress criteria. note that all but the  missing loop  program of figure 1  occur in the impasse/repair tree in figure 1   duplicate input  third column and first row   dummy init  second column and fifth row   more data  first column and fourth row   missing re-input  second column and first row  and  missing guard  second column and third row . given a tree of possible 
impasse/repair episodes  each program in die tree can be obtained by  1  a proper setting of the relative impasse difficulty parameters  controlling backtracking and pushing on   and  1  a properly designed isomorphism test that overlooks certain types of impasses  stops before reaching a correct program at a leaf in the tree . 
1 concluding remarks 
this paper describes a cognitive model of student programmers. parts of the model are implemented in a simulation program called marcel. this 


cognitive models 

research is important theoretically because it explores the use of a gtd impasse/repair problem solving architecture in a new domain  and important practically because of its educational implications for programming 
instruction. 
although the preliminary model for simulating variability is computational  it is still quite descriptive in nature  e.g.  it does not provide an answer to why different impasses are more or less difficult for different student  where dispositions come from  by what process students understand the task specification  how students learn different plans  and what the space of incomplete isomorphism tests is  etc. . another limitations is that the cognitive plausibility claim is supported by using qualitative protocol evidence. stronger evidence  a future goal  might require that the model generate  all and only  the observed bugs that students make with limits on the tailorability of the model  bv1   or accurately predict the relative difficulty and bug-proneness of specific tasks  hw1   or predict error rates and reaction times for tasks  cmn 1   or account in detail for a larger percentage of the protocol data  ns1 . 
