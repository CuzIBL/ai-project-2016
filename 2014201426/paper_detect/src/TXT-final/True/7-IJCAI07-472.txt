 
the recurring appearance of sequential patterns  when confined by the predefined gap requirements  often implies strong temporal correlations or trends among pattern elements. in this paper  we study the problem of mining a set of gap constrained sequential patterns across multiple sequences. given a set of sequences s1  s1 .  sk constituting a single hypersequence s  we aim to find recurring patterns in s  say p  which may cross multiple sequences with all their matching characters in s bounded by the user specified gap constraints. because of the combinatorial candidate explosion  traditional aprioribased algorithms are computationally infeasible. our research proposes a new mechanism to ensure pattern growing and pruning. when combining the pruning technique with our gap constrained search  gcs  and map-based support prediction approaches  our method achieves a speed about 1 times faster than its other peers. 
1 	introduction 
many real-world applications involve data characterized by continuous sequences and streams. examples include data flows in medical icu  intensive care units   network traffic data  stock exchange rates  and dna and protein sequences. since real-world events rarely happen independently but rather associate with each other  to some degree  discovering structures of interest in multiple sequences provides us an effective means to explore patterns trivial in a single data stream but significant when unifying all observed data into one view. for example  the information from multiple data streams in icu  such as the oxygen saturation  chest volume and hear rate  may indicate or predicate the state of a patient's situation  and an intelligent agent with the ability to discover knowledge from multiple sensors can automatically acquire and update its environment models  oats & cohen 1 . in microbiology  it is now well known that the genomes of most plants and animals contain a large quantity 
                                               
 
¡¡¡¡ this material is based upon work supported by the us national science foundation under grant no. 1. the support of nsf of china under grant no. 1 is also acknowledged. of repetitive dna fragments. examples include recurring short base pairs  bp  in protein coding dna and repetitive dna/rna motifs in genomes  where recurring patterns of different lengths and types are commonly found  at both genomic and proteomic levels  to have significant biological/medical values. for example  the 1 bp periodicities in complete genomes reflect protein structure and dna folding  herzel et al. 1  and some tandem repeats are now discovered to be influential to the bacterial virulence to human  belkum et al. 1 . studying correlations among multiple gene sequences  their associations with environments and disease phenotypes  thus provides a means of predicting and preventing fatal diseases  rigoutsos & floratos 1 .  
¡¡although recurring patterns convey important and useful knowledge  in reality  they rarely just reproduce and repeat themselves  but rather appear with a slight shift in the pattern letters. for example  the tandem repeats in dna or protein sequences often involve a phase shift incurred by the insertion or deletion of a short sequence  belkum et al. 1 . a practical solution is to allow the mining or search process to bear a certain degree of flexibility. consider sequences in fig. 1 a   where a pattern across three sequences repeats three times but with each appearance slightly different from the others. if we can allow that each time the pattern appears  any two of its successive pattern letters' appearances are within a range  rather than a fixed value  we may then be able to find the pattern in fig. 1 a . the introduction of a variable period  gap  thus provides a flexible way to capture interesting patterns hidden in sequences. 
¡¡mining recurring patterns from sequences essentially relies on a counting mechanism to check patterns' occurrences. this  however  is inherently complicated by the sequential order of the underlying sequences. considering sequence  aaagggttttcccttttcccttttcccc   to find the number of complete occurrences of pattern p=agtc  we ignore gap constraints at this stage   there are 1 ¡Á 1 combinations for  a  and  g   and 1¡Á1¡Á1¡Á1 combinations for  t  and  c . so in total  there are 1¡Á1 occurrences for agtc. although this number does not sound scary  considering complete occurrences  however  brings one of the most difficult challenges to our problem: the deterministic apriori theory  the support of a pattern cannot exceed the support of any of its sub-patterns  does not hold. considering s= agcttt   pattern p=agct appears three times in s  but p's subpattern agc appears once only. therefore  traditional apriori-based algorithms are computationally infeasible to handle our problem.  
¡¡motivated by the above observations  we propose mcpas to mine complex patterns across sequences with gap requirements. we will review related work in the next section  and state our research problem in section 1. in section 1  we will study pattern frequencies and propose a deterministic pruning technique for pattern mining. in section 1  we discuss our unique gap constrained search and map-based support prediction processes to accelerate the pattern mining process. based on the proposed pruning and searching techniques  we elaborate  in section 1  the mining algorithm details. comparative studies are reported in section 1  followed by the concluding remarks in section 1. 
 1     1   1    1    1     1    1    1   1    1    1   1  1  1s1    
 s1    
 sa    .   .    .   a    .    .    .    .    a    .    .    .    .
 .    e  g    .    .     .    .   e    g     .     .    e   .    g  .    .   1    .    .     .    .    .    1    .    .     .    .    1 1    
 a  
    1           1           1         1         1         1    . . . shyb     a . .   . e .    . g 1   . . .   a . .   . . .  . .  b 
figure 1.  a  patterns across three sequences;  b  the hybrid sequence generalized from the sequences in  a  
1 	related work 
existing research in mining patterns from data sequences can be distinguished into two categories.  1  mining patterns frequently appearing in a certain number of  relatively short  sequences with a boolean count  i.e.  whether a pattern occurs in the sequence or not. traditional pattern mining in market baskets  srikant & agrawal 1  pei et al. 1  zaki 1  and gene motif search  murray et al. 1  fall into this category.  1  mining recurring patterns from long sequences such as episode mining  yang et al. 1  m¨¦ger & rigotti 1  das et al. 1  and tandem repeats and base pair oscillation detection in dna sequences  herzel et al. 1 .  
¡¡any mining process will have to rely on a counting mechanism to check patterns' frequency information  from which frequent patterns can be found. it is worth noting that the selected counting mechanism crucially impacts on the mining approach. for research efforts relying on a boolean count  because a pattern's appearances are counted for only once w.r.t. each sequence  the deterministic apriori theory well holds  and is therefore commonly adopted in the mining process. on the other hand  when one has to determine a pattern's actual number of occurrences in the sequences  the situation becomes complicated  simply because the mining process won't follow apriori theory at all. existing efforts in the field have therefore proposed confined occurrence counting  such as minimal occurrences  mannila et al. 1   one-off occurrences  chen et al. 1   and windowing occurrences  mannila et al. 1 . the objective is to confine patterns' occurrences such that apriori theory can apply.  
¡¡when considering complex patterns across multiple sequences  the work relevant to our problem here comes from oates et al.  and mannila et al. . both efforts tried to search frequent episodes across sequences  as well as the prediction rules in the form of x indicating y  where x and y are the frequent episodes in the sequences. for example  after event a happens  exactly two time points later event b happens  and then exactly three time points later event c happens. notice that this is a very restrictive constraint  and we are trying to find episodes like: after event a happens  within two time points event b happen  and within three time points later event c happens. this loose constraint leaves a great flexibility to explore useful patterns.  
¡¡the problem of complex pattern mining across multiple sequences is similar to multi-dimensional sequential pattern mining  pino et al. 1   where a normal practice is to aggregate values from all sequences to form a single sequence  as shown in figure 1 b   so traditional sequential pattern mining methods can apply.  
¡¡in the domain of dna or protein sequences  blast  altschul 1  is one of the most famous algorithms. given a query sequence  pattern   it searches for a matching sequence from the databases  while what we are pursuing here is on mining the patterns. to find patterns  the teiresias algorithm  rigoutsos & floratos 1  is designed for pattern discovery from biological sequences with the number of wild-cards that can be present in the extracted patterns restricted and fixed by the users. similar approaches such as pratt  jonassen 1  is also proposed to mine restricted patterns  in terms of the maximum numbers of characters and wild-cards in each pattern  from a single sequence. 
1 	problem statement 
the sequences s1 ..  si  ..  sk from which we extract patterns are called a hyper-sequence  denoted by s  with each single sequence si called an element sequence. we use s i  to represent the characters at the ith time point of s. without losing the generality  we assume all element sequences share the same alphabet size  denoted by    and | | represents the size of  . for simplicity  we assume that all element sequences have the same lengths  denoted by l.
¡¡a wild-card  denoted by a single dot  .   is a special symbol that matches any character in  . a gap g is a sequence of wild-cards  bounded by the maximal and minimal 
values. the size of the gap refers to the number of wild-
gm
cards in it. we use n to represent a gap whose size is within the range  n  m . we also call w=m-n+1  the gap flexibility. a pattern  p=p1p1 ... gl-1pl  is a set of characters from different element sequences and gaps that begin and end with characters  where pj is an element pattern which consists of letters from element sequences. an element pattern should consist of at least one character. gj is the gap requirement between element patterns pj-1 and pj. figure 1 pictorially shows a pattern p with three element patterns. the number of element patterns in p  denoted by |p|  is called the length of p  i.e.  the wild-card symbols are not counted towards a pattern's length.  
¡¡the problem of mining complex patterns across multiple sequences is to find patterns of the following form: 
	p = p1g nm p1 g nm ... p l  1g nm p l   	 1 
which means that gaps between any two successive element 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡1 1 gm patterns are the same  i.e.  g =g =...=g = n . an occurrence of a pattern p in s is defined as a match between the characters of the element patterns and the element sequences  under the gap constraints. the occurrences are considered different  as long as the locations of one pair of the matched characters are different. for example  we consider p=atg appears 1 times in s= attg   w.r.t. g1  i.e.  1
sss and sss. the support of p in s  denoted by sup p   is the number of times p occurring in s.
¡¡given a length-l pattern p and a length-l hybrid-sequence s  we first calculate the total number of possible occurrences of a length-l pattern in s  ll  then we count the actual appearances of p  sup p . we consider p a frequent pattern  iff sup p /ll is larger than the user-specified threshold value .
	a	 . 	 . 
p = p1p1p1 	 	p1 =                      .	p1 =           e           p1= g   .  	 .   	 1 
pattern letters corresponding to element sequence s1
	p =  	.... 
pattern letters corresponding to element sequence s1
	p1	g1	p1
figure 1. a pattern denotation 
1 pattern frequency & deterministic pruning 
1 pattern frequency  
given pattern p=p1...pl and its support in a length-l hyper-sequence s  with l    l   sup p   to assess p's frequency  we need to find ll  the possible number of occurrences of p in s. considering pattern p with gap gnm   each time p appears in s  its actual spans in s vary from l+ l-1 n to l+ l-1 m  which correspond to the cases that whenever p appears in s  the gap between any two successive element patterns exactly equal to n and m respectively. assuming the first element pattern p1 matches s at s ¦Ä   then for element pattern p1  its valid occurrences may possibly appear in the range from s ¦Ä+n  to s ¦Ä+m   i.e.  with w=m-n+1 possibilities. the same situation holds for all other element patterns p1 ...pl. so in total  a length-l pattern p starting at s ¦Ä  may have wl-1 possible occurrences in s. assuming p1 has  possible appearances in s  the total number of possible appearances of p in s is ll= ¡¤wl-1. because the average span between successive element patterns is  n+m /1  the average span of p in s is  l-1 ¡¤  n+m /1 . then  the possible number of occurrences of p1 equals to  l- l1 ¡¤  n+m /1    where     means the maximal integer no larger than  . so the value of ll is defined by eq.  1 .  
	l l	w l  1    	 1  
eq  1  holds only if  l+ l-1  ¡¤m    l  i.e.  the maximal span of the pattern is less than the length of the hyper-sequence.  
1 deterministic pruning 
in this subsection  we derive one theorem and two lemmas for the deterministic pruning of our mining process. 
theorem 1. gien a length-l pattern p and its length l-1 subpatterns q  we have the supports of q and p satisfy the inequality sup p  ¡Ü sup q   w1 +w1
proof: because q is a length l-1 subpattern of p  denoting q by q1...ql-1  there are four possible relationships between them:  1  p=p1qpl-1pl;  1  p=p1qpl;  1  p=qpl-1pl-1pl; and  1  p=p1p1q. let's first prove that theorem 1 is true for  1 . 
the same proof applies to all other possibilities.  
¡¡assuming n=1 and the gap flexibility is w  the first element pattern of q  q1  appears at time slot s   . it is easy to know that p1 has w possibilities to appear between s  -w  and s  -1 . so the maximal support of p1q is sup p1q =w¡¤ sup q . now assuming further that the last element pattern of q  ql-1  appears at s  +    it is clear that pl-1 has w possibilities to appear at the range between s  + +1  and s  + +w   as shown in figure 1. if pl-1 indeed appears at s  + +w   the element pattern p1 will have w possibilities to appear between s  + +w+1  and s  + +1w . denoting this region by   if pl-1 appears at 
s  + +w-1   we know that pl may possibly appear between s  + +w  and s  + +1w-1 . notice that s  + +w  has been reserved for the possible appearance of pl-1  so the number of possible appearances of pl  w.r.t. to pl-1 at s  + +w-1   is w-1  unless pl-1 and pl are the same  which is not a generic case in reality. similarly  the number of possible appearances of pl  w.r.t. to pl-1 at s  + +w-1   is w-1. as a result  for all possible w appearances of pl-1 between s  + +1  and s  + +w   the sum of their possible matching pl's occurrences is  l 1=w+w-1+w-1...+1=w w+1 /1.
so the maximal support for length-l pattern p=p1qpl-1pl is 
w¡¤sup q ¡¤ l 1 =sup q   w1 +w1  1  that is  sup p    sup  q      w 1 + w 1   1 .
   +1... + + +1 + +1... + +w   + +w+1 + +w+1 ... + +w+w ...  x    x    ...  x        x             x        ...  x           x              ...    x                  x              .... 
	w	w
	pattern q	pl-1	pl
figure 1. pattern growing  
lemma 1. given a threshold   we say that a length-l pattern p is frequent iff sup p /ll   . if p's any length l-1 subpattern q's frequency  freq q   is less than l    l  1    ¦Ø+1   ¦Ñ 
l    l   1   ¦Ø+ 1 
where ¦Ø= n+m /1  then p cannot be a frequent pattern.  proof: 
because 	freq q =sup q /ll-1  	we 	know 
sup q  ¡Ü l    l  1   ¦Ø+1   ¦Ñ  	since 	ll 1 = l  l 1   ¦Ø+1   wl 1 
ll 1	l    l   1   ¦Ø+1 
we have sup q     l    l  1   ¦Ø+1   w l 1  ¦Ñ
because q is a length l-1 subpattern of p  according to 
theorem 1  we know that sup p  ¡Ü sup q   w1 +w1
1 	pattern search with gap requirements 
1w
sup p 	1 = sup p    ¦Ñ w +1      1  
 l    l  1   ¦Ø+1   w l 	ll	1wcomplexity is o l wl-1   which is linear w.r.t. l  but exponential w.r.t. w and l. in the case that s consists of k element sequences  this complexity increases to o k l wl-1 .so until all possible locations starting from x have been 
	=  l    l  1    ¦Ø+ 1    w  	 ¦Ñ	checked  then it moves one step forward  x+1 . the time 
because the gap flexibility w  1  we know  w +1  1w ¡Ü1 
i.e.  sup p ll  ¦Ñ. therefore  p is not frequent.           	     1 	  gap constrained search  gcs   consider a length-l pattern p with a gap flexibility w  an exhaustive search will start from the first pattern letter p1 to find its first match in s. denoting this matching location by x  the search process then starts from x to match p1 within the range  x+1  x+w . such a process iteratively repeats 


lemma 1: if the average span of the longest pattern in s is less than  w  1  l1w   i.e.  about a half of a length-l hypersequence s  given a length-l pattern p  for any length l-1 subpattern of p  q  if freq q  is less than l    l   1     ¦Ø+ 1    ¦Ñ 
l    l   1     ¦Ø+ 1 
where ¦Ø= n+m /1  then patterns  with p as their subpatterns  are not frequent. 
justification: 
according to lemma 1  we know that given the conditions in lemm1  a length-l pattern p will not be frequent. now assume pattern p is a subpattern of a length-l+k pattern f. according to eq.  1   we know sup p    ¦Ñ ll   w +1w   for any length-l+k pattern f  with p as its subpattern  the maximal support of f is less than wk times of sup p . 
so sup f  wksup p  ¦Ñ w +1 ll  wk . the frequency of f is 
1w
freq  f   = sup  f     ¦Ñ  w + 1   l l	 w k
	l l + k	1w	l l + k
freq f   ¦Ñ w +1   l  l 1   ¦Ø+1     where  l + k  1    ¦Ø+1  is the 
¡¡¡¡¡¡¡¡1w  l  l +k  1   ¦Ø+1   average span of the length-l+k pattern. given that the longest pattern is less than  w   1    l 1w   we have freq 
	= ¦Ñ   w + 1   1w	  l    l   1     ¦Ø + 1    ¦Ñ
	1w	w + 1	l
so pattern f is not frequent. 
¡¡in reality  we may not know in apriori that whether the average span of the longest pattern in s is less than  w  1  l1w or not  since the longest patterns are yet to be found   so lemma 1 does not seem to be useful in the mining process. nevertheless  because we are dealing with a long hyper-sequence s  it is almost certain that the average span  even the maximal span  of the longest pattern in s is less than a half of |s|. for the dna sequences we are using  in section 1   the average span of the longest pattern is less than 1 percent of the sampled length-1 sequence s. so we can safely assume that this prerequisite always holds. 
in this subsection  we propose a dynamic programming  bellman 1  oriented search mechanism  which is able to achieve a linear time complexity in gap constrained pattern search. the algorithm consists of three steps. given a length-l pattern p= p1 ...pl  we first build a length l list for each of the element patterns pl  denoted by opl . we initiate the value of opl to 1 before the search process  for easy understanding  we pictorially show a simple example in figure 1 with p=agtc and gap g1  . 
1. gcs sequentially scans s from the left to right. for any current position x  if s x  matches the first element pattern p1  set the value of op1  x  to 1.  
1. at any location x  if s x  matches any element pattern pj  j l  i.e.  excluding the first element pattern   we update the value of opj to op j =vmax =1  x w   op j 1 x v .
as shown in figure 1  when x=1  s matches p1  which is g   then the value of og is updated to the sum of oa and oa. the above process indicates that for any matches of the element pattern letter  pj j 1  at location x  we backtrack w steps to find the number of times pj's last successive pattern letter pj-1 has ever appeared. if all element patterns  pj  j 1  were able to iteratively regulate and update their lists opj in such a way  then the value in opj  x  will indicate the number 
of times that pattern p1...pj ever ends at position x.
1. we iteratively repeat the above process  until we finish the whole sequence s. then we sum up all elements inopl   which is the number of times p=p1...pl appears in s. in addition  the values in opl  x  will indicate the number of times p ending at position x.
the time complexity of gcs consists of two parts:  1  scanning the whole sequence l  and  1  at each location x  comparing s x  with all element patterns  and backtracking w steps if necessary. because each backtracking can be achieved through a sum operation  so the total time complexity is o kl l-1    which is linear w.r.t. l  l  and k  and much more efficient than the exhaustive search o klwl-1 .  
1     1      1      1    1      1    1     1    1   1    1   1   1   1   1   1   1   1   s    a   a   g   g   c   a   t   c   t   c   a   g    a   t    c   t   t   c   a    1    1    1    1    1   1    1    1   1    1    1    1    1   1    1    1   1   1   g    1    1    1    1    1   1    1    1   1    1    1    1    1   1    1    1   1    1   t    1    1    1    1    1   1    1    1   1    1    1    1    1    1    1   1    1   1    c    1    1    1    1    1   1    1    1   1    1    1    1    1    1    1   1    1   1  figure 1. gap constrained pattern search  gap constraint g1   1
1 map-based support prediction 
notice that each time we grow a length-l pattern p to a length l+1 pattern f  we will have to check f's frequency by searching its occurrences in s again. this reexamination mechanism costs a considerable amount of system runtime  as there are possibly millions of candidates. nevertheless  if we can reuse p's occurrence information  we may be able to speed up the search process dramatically. for this purpose  after we find pattern p's occurrences  we generate a rearmap  rm  for p which records the number of times p appears in s and all its ending positions  this rm is actually the opl list in the above section . as shown in figure 1  if p ever ends at position x  the value of rm x  will indicate the number of times p ends at x; otherwise  rm x  equals to 1.  
¡¡with the rm of pattern p=plp1...pl  denoted by the rmp1... pl  x   we may just search p's rm  instead of scanning the whole sequence s  to find the number of times f appearing in s. this can be achieved by a simple production and sum procedure. more specifically  for pattern f= plp1...plpl+1  if we can build a head-map  hp  which records locations and times of the length-1 pattern plpl+1's starting information  where hppl pl+1 x  indicates the number of times plpl+1 starts at position x  then  the support of pattern f is determined by eq.  1  
sup p1 p1...pl+1  = lx=1 rm p1.. pl  x   hppl pl+1 x     1  
as shown in figure 1  when predicting the support of agtc  we first find rmagt and hmtc  the production and sum of the corresponding elements of these two lists will exactly equal to agtc's support.  
1     1      1      1    1      1    1     1    1     1    1   1   1   1   1   1   1   1       s       a   a    a   g   c   g   t   c   t    c   a   g   g   t    c   t   t   c   rmagt   1    1     1    1    1   1    1    1   1    1    1    1    1    1    1    1    1   1   hm tc   1    1     1    1    1   1    1    1   1    1    1    1    1    1     1    1    1   1  rmagtc  1    1     1    1    1   1    1    1   1    1    1    1    1    1     1    1    1   1 figure 1. map-based support prediction  gap constraint g1   1
1 	algorithm 
the system framework of mcpas is shown in figure 1. mcpas first generates all length-1 patterns  denoted by c1. after the first step  mcpas begins pattern growing and pruning. assuming now at a certain step  we have generated a set of length-l candidates from length-l-1 patterns  on line 1 in figure 1   then a length-l candidate's support can be easily predicted by plugging its length-l-1 patterns' rm and the corresponding length-1 patterns' hm into eq.  1   without rescanning s. for all generated length-l candidates in cl 
we calculate a value l¡ä =l+1 and a threshold   
	 	 	 	 	 	 1  
all length-l candidates with their frequencies larger than ¦Ñ are forwarded to a frequent set fl. if any length-l candidate's frequency is less than ¦Ñ¡ä  we mark it as  suspicious   which means that this pattern is unlikely to grow further  so we will keep an eye on it. meanwhile  for any length-l candidate p in cl  if any of p's length-l-1 subpattern is suspicious  we will remove p from the candidate set cl  on lines 1 to 1 in figure 1 . according to lemmas 1 and 1  if a pattern q is suspicious  then any length-l patterns with q as their length l-1 patterns are not going to be frequent. therefore  if p's length-l-1 subpattern is suspicious  then any length l+1  and beyond  patterns containing such subpatterns are not going to be frequent. so there is no need to put them into the candidate set cl for growing. as a result  we may safely remove p from the candidate set cl.
¡¡after mcpas prunes out candidates from cl  it builds rm for all remaining length-l patterns in cl by rescanning s  on line 1 in figure 1 . mcpas grows length-l+1 candidates by using all patterns in cl  on line 1 in figure 1 . this can be achieved through the following two techniques:  1  trying all combinations by attaching any possible element pattern to the patterns in cl  or  1  using the popular apriori candidate generation procedure.  
input:  1  hyper-sequence s and gap gnm    1  # of element sequences k;  1  alphabet  ; and  1  frequency threshold 
output: frequent pattern set  
1. w	m-n+1 
1. build length-1 pattern set c1  build bm and hm maps for all patterns in c1.
1. l	 1 
1. while  cl-1   ¦Õ 
1. cl	patterngen cl-1 ;  
1. predict support values for all candidates in cl
 eq.  1   
1. l¡ä=l+1 and calculate threshold ¦Ñ¡ä
1. for any pattern y in c
1. if freq y        thenl	   flfl ¡È y
1. if freq y    ¦Ñ¡ä   then   ysuspicious
1. if  any length l-1 subset of y is suspicious
1. then  clcl   y
1. rescan s and build rm for all patterns in cl
1. l  l +1;  
1. return  f1 ¡È f1...¡Èfl-1 
figure 1. mcpas algorithm 
1 	experimental results 
the data used in our experiments are nucleotide dna sequences downloaded from the national center for biotechnology information website  ncbi   we choose four dna sequences as our test bed  ax1  ax1  ax1  and ax1 . when using multiple sequences to form a hyper-sequence  we truncate sequences into equal length ones. because we use dna sequences  the alphabet for all element sequences is ¦²={a  c  t  g}. for comparisons  we implement the mppm method in  zhang et al. 1  in finding frequent patterns with gap constraints. this mppm is the most relevant  and most recent as well  method we can find from all other peers.  
table 1 candidate numbers scanned by different methods  
pattern enumerate allmppm mcpaspruning mcpas c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 c1 1 1 1 1
1 pruning efficiency comparison 
we provide in this subsection a pruning efficiency comparison with mppm by using a single dna sequence ax1  by randomly sampling a l=1 subsequence . 
¡¡in table 1  we report the experimental results  by the average results of 1 executions   where the first column means the candidate pattern set with different lengths. the second column indicates the number of candidates one has to evaluate  if enumerating all combinations. the third column means the number of candidates evaluated by mppm. because mcpas uses two approaches  map-based support prediction and lemma 1  for pruning  we'd like to assess their efficiency separately. we first discard the map-based support prediction in the algorithm by replacing line 1 with line 1 in figure 1. the results are denoted by mcpasprunning.
after that  we use both map-based support prediction and lemma 1 for pruning  with results denoted by mcpas.
¡¡when comparing mcpasprunning and mppm  we find that mcpasprunning has about 1% or fewer candidates than mppm. a further study on mcpasprunning and mmpm reveals that they have opposite pruning mechanisms. in mcpasprunning  patterns are growing and pruned orderly  which means that we generate length-l candidates  prune out unlikely ones  grow candidates and repeat the algorithm until the candidate set is empty. on the other hand  mppm uses reverse pruning mechanisms. it first determines the maximal length of the frequent pattern n  and based on this value  works out the minimal support values for different lengths of patterns. not only the value n might be determined inaccurately  an inaccurate n will therefore reduce the pruning efficiency   even if n is perfectly determined  it will leave the selected threshold  for length n-1  n-1  ...  1  to be relatively small  because it has to consider the worst scenarios.  
¡¡when combined with the map-based frequent prediction mechanism  mcpas makes dramatic improvement in reducing the number of candidates in cl. for example  the number of patterns needs to be scanned in c1 is 1  which is about 1% less than the number of patterns scanned by mmpm.
1 pattern search efficiency comparison 

figure 1. pattern search efficiency  w=1  l=1  ax1  

figure 1. pattern mining performance from single sequence 
¡¡to assess the performances of the proposed gcs mechanism in comparison with exhaustive search  we sample a length l=1 subsequence from ax1  then use two search mechanisms and record their average search time  in seconds  for every 1 patterns  and report the results in figure 1  the average results of 1 executions . in figure 1  the x-axis denotes the length of the patterns  the dash line indicates the results of exhaustive search  corresponding to the y-axis on the left side of the figure   and the solid line with crosses represents the results from gcs  corresponding to the y-axis on the right side of the figure .  
¡¡comparing to exhaustive search  gcs is normally 1 to 1 times faster in searching  depending on the actual length of the patterns . because exhaustive search's time complexity exponentially increases along with the pattern length and the gap flexibility  gcs can possibly achieve more improvements for longer patterns or larger gap constraints.  
1 pattern mining performance comparison 
to assess overall pattern mining performances  we first use a single sequence ax1 with a fixed value w=1. we randomly sample a length l=1 subsequence from ax1  then use mppm and mcpas to mine the results by specifying different threshold values ¦Ñ. we report the average runtime  from 1 executions  in figure 1  where the x-axis means the value of ¦Ñ  the dash line indicates the results from mppm and the solid line with crosses denotes the results from mcpas  corresponding to the y-axis on the left and right side of fig. 1 respectively .  
¡¡both mppm and mcpas nonlinearly respond to the threshold ¦Ñ with pretty similar shapes. this is because the value of ¦Ñ nonlinearly determines the number of candidates of the system. on average  mcpas is about 1 times faster than mppm  with its improvement mainly comes from three aspects:  1  an ordinal pruning from lemma 1;  1  mapbased support prediction; and  1  gcs based search. gcs alone can enhance the search speed for about 1 times  comparing to exhaustive search   and the other two aspects will generally contribute a speed improvement of about 1 times.  
¡¡in figure 1  we report the results from the hyper-sequence consisting of one to up to four sequences  due to the intensive time consumption  we were only able to run the programs for only one time for 1 or 1 sequences . the x-axis in figure 1 represents the number of element sequences  and the y-axis denotes the average runtime of mcpas. because mppm and mcpas have huge runtime differences  we report mppm's runtime in a small table in figure 1. meanwhile  for a hyper-sequence with k=1 element sequences  mppm's runtime is too big  so we omit the value at this point.  

figure 1. pattern mining performance from multiple sequences 
the results in figure 1 show that mcpas's runtime exponentially increases by the number of element sequences k. although this sounds disappointing  to understand the challenge of our problem  let's assume that s merely consists of two dna element sequences  then each element pattern pi has  |¦²|+1-1= 1 1=1 possibilities  excluding the one consisting of wildcards only . so the number of length-1 candidate patterns is 1  if no pruning techniques are involved. although we can transform element sequences to form a hybrid sequence and apply mppm to solve the problem  because of the large alphabet size and the less effective reverse pruning technique  most of the length-1 candidates are going to be treated as frequent and used to grow next level candidates. mcpas on the other hand  will start to prune candidates from length-1 candidates  and for length-1 patterns it will reduce about 1% of candidates  if s consists of 1 element sequences . the above observations make us believe that although mcpas is nonlinear w.r.t. the number of element sequences k  when mining complex patterns from hyper-sequences  it is much more practical in reality.  
1 	conclusions  
we have studied in this paper the problem of mining complex patterns across multiple sequences with gap requirements  where patterns repetitively appear in multiple sequences and their matching appearances are flexibly confined by users' gap requirements. because of the exponential candidate explosion  traditional apriori-based solutions are technically infeasible to solve the problem. we have proposed mcpas with three unique features to fulfill the task:  1  an apriori-like mining framework which allows pattern generation and growing to be conducted step by step;  1  map-based support predication to predict candidates' frequency without rescanning; and  1  a gap constrained linear-time pattern search. experimental comparisons have shown that each of the above techniques has made a contribution  and the overall performances of mcpas have been about 1 times faster than its other peers. 
