
we present a new incremental knowledge acquisition approach that incrementally improves the performance of a probabilistic search algorithm. the approach addresses the known difficulty of tuning probabilistic search algorithms  such as genetic algorithms or simulated annealing  for a given search problem by the introduction of domain knowledge. we show that our approach is effective for developing heuristic algorithms for difficult combinatorial problems by solving benchmarks from the industrially relevant domain of vlsi detailed routing. in this paper we present advanced techniques for improving our knowledge acquisition approach. we also present a novel method that uses domain knowledge for the prioritisation of mutation operators  increasing the ga's efficiency noticeably.
1	introduction
searching for good or even optimal solutions for complex combinatorial problems has been a challenge in artificial intelligence research ever since ai's earliest days.
　while it has been long recognized that the effectiveness of a particular search approach depends on the chosen representation as well as certain characteristics of the problem to be solved  to date there is no systematic approach available that allows one to efficiently engineer a special-purpose search strategy for a given search problem.
　in this paper we present an approach that allows humans to articulate their intuition about how to search effectively for a given search problem. this appears to be a promising approach as humans often have good intuitions about how to find acceptable or good solutions to search problems  if they had to search manually.
　we embedded our approach in the probabilistic search framework of genetic algorithms  ga . while gas have a reputation as being general purpose  in practice it requires usually substantial adaptation effort to the search problem at hand. for complex problems this process may well take months in order to allow the ga to find an acceptable solution within reasonable time.
　we chose a probabilistic search algorithm in which to embed the problem specific knowledge about effective search strategies as this allows one to stop the knowledge acquisition process at any time. a smaller knowledge base  kb  results in a less effective search process  but may still find a
　satisfactory or near satisfactory solution for less challenging problem instances. incremental additions to the kb improve the effectiveness of the search.
　as part of our discussion  we present a novel technique of varying ga mutation strategy based on execution history  having implications beyond our work for gas in general.
　for the knowledge acquisition process we build on the idea of ripple down rules   which allows us to incrementally refine the given  initially empty  knowledge base. ripple down rules  rdr  ensure that a knowledge base is only amended in a way that does not deteriorate its accuracy on previously seen instances.
　our variant of rdr is a significant extension of the rdr approach. we also introduce an expanded knowledge acquisition process in which we help the expert find examples in past search history where the quality of the kb needs attention. this work is based on .
　in section 1 we provide a short overview of genetic algorithms and rdr. this is followed by section 1 where we describe our framework heureaka!. section 1 introduces a case study of how heureaka! was applied to detailed routing  an industrially relevant problem in vlsi design. we discuss our experiments and results to these in section 1  demonstrating that our approach is successful. the conclusions follow in section 1.
1	background
before we discuss our approach to combining gas and knowledge acquisition  we start with a brief summary of these two areas:
1	probabilistic search with genetic algorithms
a number of evolutionary algorithms exist; we base our approach on genetic algorithms which is one such algorithm. basic gas are relatively easy to implement. a solution candidate for the given problem instance is encoded into a genome. a set of genomes makes up a population of potential solutions. the ga performs a search through the solution space by modifying a population of genomes  guided by an evolutionary heuristic. when a suitable solution has been identified  the search terminates.
　gas usually start with a randomly initialized population of individuals  and guide their search by a fitness function of the individuals. in a probabilistic fashion  using operators for selection  mutation and crossover  the ga attempts to direct the search to promising areas. i.e. the ga maintains a certain population size by replacing less fit individuals by newly generated ones. the new individuals are generated by mutation or cross-over based on parent individuals of high fitness.
　due to their generality and flexibility  gas have been applied in many domains  demonstrating their effectiveness on hard problems  1; 1 . in very complex domains there are significant challenges where generic ga techniques do not scale well. this includes high sensitivity to problem encoding and operator formulation  selection strategies  as well as selection of operator weightings  population size and running time 1; 1; 1 . thus in practice substantial tuning of the ga is necessary to augment the generic algorithms.
　in our approach  we do not use an encoding of our problem into a binary code as is often seen with conventional gas. instead  our encoding is a direct representation of a solution  see below for a better description . our crossover operator is designed for this representation and thus is very effective in maintaining sub-solution coherence in the genome  and also identifying which areas of the genome appear fitter than others. we have a simple yet effective crossover operator  and chose to concentrate our work on the mutation operator - mainly because it was better suited to our the knowledge acquisition approach.
　our approach integrates with the ga a knowledge base where humans can codify their intuition about useful search steps and strategies for the given type of problem.
　in addition  we present a novel method that uses domain knowledge for the prioritisation of mutation operators  increasing the ga's efficiency noticeably. because we have sufficient domain knowledge in our fitness function  we can identify parts of the genome that are desirable or undesirable and use that knowledge to influence mutation strategy. we also show how using the mutation history of these identified characteristics to change mutation selection strategy.
1	knowledge acquisition using ripple down rules
rdr  allows one to add rules to a knowledge base incrementally without compromising the previously shown satisfactory performance of the kb. an extension of rdr allows hierarchical structuring of rdrs -  nested rdr   nrdr  . nrdr allows the re-use of definitions in a kb  as well as the abstraction of concepts  which allows for more compact kbs.
　single classification ripple down rules  scrdr  use a binary tree where the root node is also called the default node. to each node in the tree a rule is associated  with a condition part and a conclusion which is usually a class - in our case it is an operator application though. a node can have up to two children  one is attached to an except link and the other one is attached to the so-called if-not link. the condition of the default rule in the default node is always true and the conclusion is the default conclusion. when evaluating a tree on a case  the object to be classified   a current conclusion variable is maintained and initialised with the default conclusion. if a node's rule condition is satisfied  then its conclusion overwrites the current conclusion and the except-link  if it exists  is followed and the corresponding child node is evaluated. otherwise  the if-not link is followed  if it exists  and the corresponding child node is evaluated. once a node is reached such that there is no link to follow the current conclusion is returned as a result. indicates the path taken & rule executed  v   for ade  box indicates how action z would be added for
.
　figure 1 shows a simple rdr tree structure. in bold is a rule that a user might have added for the case where conditions adghij hold  causing action z to be executed  instead of w.
　for the purpose of integrating with the genetic algorithm  in our approach each case is a genome and conclusions are actually a sequence of actions that can be applied to the genome. in typical rdr implementations  any kb modification would be by adding exception rules  using conditions which only apply to the current case for which the current knowledge base is inappropriate. by doing this  it is ensured that proper performance of the kb on previous cases is maintained.
　nesting rdrs allows the user to define multiple rdrs in a knowledge base  where one rdr rule may use another  nested rdr tree in its condition   and in heureaka! as part of an action  see section 1 . i.e. the nested rdr tree is evaluated in order to determine whether the condition is satisfied. a strict hierarchy of rules is required to avoid circular definitions.
1	heureaka! - our framework for improving search with domain knowledge
the heureaka!  heuristic evolutionary algorithm with knowledge acquisition  framework is composed of a general ga scheme and a knowledge acquisition  ka  component.
　each genome in the ga population represents a potential solution to the problem to be solved. while searching  the ga needs to perform a fitness evaluation and the mutation of a genome. for this it uses the two knowledge bases  the mutation kb and fitness kb. the ga presents a genome to the relevant kb  which responds by suggesting a mutation or fitness score.  the crossover function is handled differently  more details below .
　the ka module handles maintenance of the kbs  which contain collections of nrdrs. the nrdrs are incrementally developed by the expert through the addition of rules  the next section contains a detailed description of this process .
　the fitness kb contains rules based on past examples given by the expert about desirable and undesirable traits of genomes. the ga requires a fitness value  so the rules contain various calculations the expert adds to reflect these traits.
　the mutation kb similarly contains rules accumulated from expert recommendations. each rule contains an action to be executed under certain conditions. each action is one or more commands which can modify the genome. the kb contains a set of nrdrs which contain these rules. when a genome is presented to the mutation kb  it is evaluated against these nrdrs. in accordance to the rdr algorithm  actions which satisfy the relevant conditions are selected for execution. a non-deterministic element is introduced by letting the expert attach probabilistic weights to selected nrdrs and letting a random procedure pick which one to execute. this allows the expert leeway to speculate about what the best actions might be  effectively letting the gas heuristics  decide  the most appropriate action.
　as opposed to other methods related to case-based reasoning and gas  e.g.  or    the expert uses past cases to formulate rules to explain improvements  rather than using past examples or similar solutions injected into the evolutionary process  or trying to extract the rules automatically.
　the overall architecture of heureaka! is domain neutral. the implementation contains kb management modules  ga  a graphical user interface as well as range of utilities supporting the expert evaluate past searches. this is complemented with a smaller component that needs to be implemented for each problem domain containing a relevant solution representation. the user interface also requires a small addition to translate this representation for visualisation.
　a general purpose language is extended with primitives to make it suitable for describing the domain specific representation. rules entered by the expert are specified using this simple language  which is loosely based on  c  syntax. the rule conditions use logical expressions while actions include a range of commands  including variables  loops and references to other nrdrs which are evaluated analogously to function calls. section 1 gives examples of rule specification.
1	the knowledge acquisition process in heureaka!
the overall approach allows the user to run the genetic algorithm with the current kbs and monitor or inspect afterwards whether the fitness function computed for an individual as well as the applied mutation operator where appropriate/promising steps to do.
　to do that  the genetic algorithm can be started  stopped and reset via a graphical user interface. a snapshot of the ga population is presented visually  from which the user can pick an individual for closer inspection.
　figure 1 shows an individual genome being inspected. a user can step through the process of mutation and evaluation of that genome as if the solution was part of the ga population. given non-deterministic elements of operator selection  the interactive debugger maintains complete state descriptions  allowing the user to step forward and backwards in execution history and also recreating conditions for repeated testing.
　the expert can review actions applied to the genome and make modifications to the kb if he/she feels they are needed. the modifications are typically done by adding exceptions to the nrdr  in accordance with rdr methodology described above   but may also be an edit of an existing rule or the addition of a new nrdr.
　in the traditional ripple down rules approach it is assumed every rule entered is correct and has its reason to be there  modification of a rule may have undesirable side effects which are often difficult to control. while these are valid reasons for not modifying rules  our experiments suggest that it is sensible to modify rules at the beginning of building a knowledge base. in particular  for the definition of mutation operators it proved useful to have this option to modify rules.

figure 1: the interactive screen allows the user to inspect the individual genome  step through rule application  and amend the kb as needed.
1	advanced features for supporting knowledge acquisition
once a sufficiently large kb has been created based on smallscale evaluation  more automated methods are needed to support a user's interaction:
　genome visualisation: one of the strengths of using rdr is that the approach is successful in eliciting tacit knowledge   since rules are formulated while the system is in use and with the justification of an example. with complex problems  such as is described in section 1   the visualisation of a solution is very important in allowing the user to form an intuitive understanding. in the evaluation module  there is immidiate visual feedback when rules are applied.
　trigger functions: during the execution of the ga  thousands or even hundreds of thousands of rule applications to all manner of genomes are made. it is not possible for the expert to supervise each case. the user can define a trigger function which is applied to each genome during the execution of the ga. if the function's condition is met  an exception is thrown  halting the ga's execution  providing a pointer to the individual along with an execution trace of recently applied rules.
 avg. run for: layout: 1 pin  1 tracks  density comparing different kbs1 
	1 total mutations / population size1	1	1
 note: this axis is abridged for compactness;  only the large kb reaches 1 conflicts 
figure 1: nrdr usage in genome. the legend shows the number of conflicts  less is better . arrow: an nrdr which is much less useful after an error was introduced by the expert  the top graph is before the error  the lower one after .figure 1: the  minimal  kb and  small  kb are unable to solve problem. the more mature kb can solve it effectively.　nrdr usage profile: execution statistics are kept for each nrdr execution  recording the frequency of use over many ga runs. comparing the profile of aggregate use of nrdrs by successful vs less successful genomes  judging by their fitness function and how soon they were eliminated from the ga population   provides some impression of an nrdrs  usefulness  and role in gas lifetime. figure 1 shows the frequency of a few selected nrdrs relative to the genome's age  the examples are from the vlsi case study discussed in the next section .
　in the less fit genomes  some operators have a high count compared to the fitter genomes. these operators turn out to be  high churn  operators - they can affect large sections of a genome. in the earlier stages of a ga these nrdrs support high entropy and thus allow the search to cover more search space. when the genome is closer to the ideal solution  i.e. has more desirable characteristics in place  these nrdrs disrupt established  good  configurations. their relative usage frequency in fitter populations is thus lower.
　the characterisation of nrdr utility can only provide the expert with a rough idea of its  usefulness . in that context it did contribute somewhat to the intuition the expert developed when doing ka. where it was found to be quite useful though  was when the expert introduced some modification to the nrdr which inhibited it from functioning as well as previously - meaning that it was much less used in arriving at fit genomes. this helped catch at least a few of errors. in figure 1 the arrow indicates such an nrdr.
　tuning probabilistic weighting of nrdrs: in section 1 we mentioned the notion of using probabilistic weightings to affect the ga's selection of nrdrs. this allows the expert to  tune  the kb when he/she has a good intuition as to what action might be useful  but is not entirely sure.
　in our experiments we identified a set of nrdrs which would probably be useful for various types of problems. for these we created weightings giving preference to the relevant nrdrs. this was in the final stages of refining our kb  where we allowed 1 of all modifications to be decided randomly  and 1 based on the probabilistic weightings based on problem classifications. with this we saw a measurable improvement in our search results.
　in the experiments conducted in our test domain  we saw a measurable improvement in our search.
　identifying genome modifications of interest: sometimes a genome mutation plays a role in the long term success of that genome  but the immediate result of the mutation is a
　reduction or no change in its fitness. in general  gas cope with this by having a large enough population pool and preventing premature fitness convergence  so as not to throw out such genomes too soon. in traditional gas it is hard to otherwise account for these cases. given that we have an expert who can make judgment on individual examples using intuition and hindsight  the fitness function can be augmented to bridge the interval needed to see a promising mutation come to fruition.
　the problem comes with identifying these candidate mutations in order to present them to the expert. we identified all the mutations falling into a window size of 1 actions prior to a fitness improvement exceeding a given threshold. these were collected for review for the expert's consideration. in practice we found there was too much data to effectively judge the cases by hand.
　we then tried using a discounted reward scheme  and some other methods to help reduce the candidate space  but have not yet been able to improve matters. this aspect of the project are currently being worked on.
1	advanced features for use in knowledge acquisition
preferences in choosing parts of the genome to mutate: as hinted at in the genetic algorithms section  1   we have introduced a novel method of choosing parts of a genome for mutation. in our fitness function we are able to identify parts of the genome that are undesirable.
　we keep track of the modification of those parts over time  and give a higher preference weighting to newly arising problem areas. this is done by keeping a list of existing problem areas and discounting their preference weighting after each fitness evaluation. when it comes to choosing a part of the genome to mutate  we normalise these weights and make a probabilistic choice of the identified problems. this results in newer problem areas having a higher chance of being picked. with this scheme we allow some continuity in search direction  potentially overcoming local minima in the search space.
　in the context of our experimental domain  we empirically found a 1% discount factor gave the best results. compared with no discount scheme  giving all identified problem areas equal chance  the number of successful ga trials was 1% higher  and the successful trials took on average half the time to complete.
　mutation look-ahead: we added a feature that allows the expert to make use of a  mutation look-ahead  function in the rule specification. this function allows for the comparison of a genome before and after a mutation has been made. this effectively allows a local search in the mutation nrdr  similar to a lamarckian learning mechanism in evolutionary algorithms .
　our knowledge base incorporated local search by comparing the fitness of a genome before and after a candidate mutation. this can be used in an rdr at any point  but was most successfully used for a generalised mutation lookahead. here  for each mutation a series of 1 steps  each recommended by the mutation kb was used  while the fitness values were recorded. the point of highest fitness value in the sequence was picked as the final mutation.
　when using the look-ahead mechanism  ga trials had a significantly higher success rate. each successful trial was also faster to converge on a solution  as measured in overall execution time .
1	case study - detailed vlsi routing
in order to demonstrate that genetic algorithms enhanced with knowledge acquisition can be used to develop algorithms for solving complex combinatorial problems  detailed channel routing as well as switchbox routing  both industrially relevant problems within the realm of vlsi design  were chosen to demonstrate the approach.
1	domain specifics
a channel routing problem  crp  is given by a channel of a certain width. on both sides of the channel are connection points. each connection point belongs to a certain electrical net and all connection points of the same net need to be physically connected with each other by routing a wire through the channel and  of course  without two nets crossing. the width of the channel determines how many wires can run in parallel through the channel. the length of the channel determines how many connection points on both sides of the channel there may be. furthermore  the layout is done on a small number of different layers  e.g. 1 to 1 layers   to make a connection of all nets without crossing possible at all. two adjacent layers can be connected at any point using a so-called via.
　the switchbox routing problem  srp  is similar to the crp but usually more difficult  as it deals with connections on all four sides rather than only two. a solution to the crp and srp will be referred to as a layout.
　genome encoding: a genome describes the layout of a crp or srp solution. this takes the form of a list of straight wire segments.
　initially  a genome will usually not represent a valid solution as some wires are usually crossing. only when all those crossings have been eliminated and not more than the prescribed number of layers are used would the fitness value of a genome reach a satisfactory level.
　genome operations: individuals in the ga are initialised with a random wire layout without regard to conflicts. the ga operates on a genome by crossover  mutation and evaluation. however  the ga's crossover operation is currently not controlled by a knowledge base. the crossover for our layout problems groups wires into mutually exclusive sets  one of those sets is exchanged between parents  i.e. the corresponding wires are exchanged . the crossover operator is thus highly sensitive to the structure of the problem  as well as interaction between its elements. the formulation of the crossover operator is domain specific  and we plan to make it part of the knowledge acquisition cycle in future versions.
　evaluation is done using the evaluation kb. typically the user uses as a fitness criteria the number of layers and conflicts in a layout. the length of wires  number of vias and possible cross-talk  electronic interference occurring in parallel wires  are also useful fitness criteria.
　the mutation kb contains rules designed to manipulate the layout  typically they would describe the resolution of a conflict identified using the .findconflict command  a primitive function returning a conflict found in the layout .
　example of rules applied to the switchbox routing problem: initially  a kb is built up defining operators using primitives based on node and wire manipulation. these form the foundation for more high-level concepts which can be used intuitively by an expert.
　assuming we start with a kb with relatively high-level actions defined  e.g. moveverticalsegmentright  and movehorizontalsegmentup. when applied to the example in figure 1  it seems that the action moveverticalsegmentright is unlikely to lead to a promising solution. the expert can amend the kb to suggest an alternative action.  see nodes labeled n1 and n1 in figure 1 . in this case  the user will find that moveverticalsegmentright is undesirable  and formulate a rule with condition is vertical n1  && is horizontal n1  && rightof n1.next n1   and action movehorizontalsegmentup n1.prev . this rule would be added as an exception in the kb. the operators referenced here are defined as rdrs elsewhere in the kb. is vertical n1  returns true if the segment between n1 and its succeeding node is vertical  change in row   is horizontal n1  returns true if the segment between n1 and its successor is horizontal  change in column . right of n1.next n1  will return true if the node succeeding n1 lies to the right of n1.

figure 1: an exception is created by the expert  replacing the action moveverticalsegmentright suggested by the kb  with the action movehorizontalsegmentup n1.prev .  the tags n1 and n1 are referenced in the text .
1	experiments and results
experiments: in order to test our approach and the implemented tool  a kb was created. initial tests were done with a kb containing 1 rdrs and 1 rules  later tests were run with 1 rdrs and 1 rules and 1 rdrs and 1 rules.
　in order to show that the introduction of domain knowledge improved the search  we tested three different kbs: a  minimal  kb with 1 rules  a  small  kb containing 1 rules  and a  large  kb containing 1 rules. using the first two  the ga was unable to solve the given problem  while using the third  it was. fig.1 shows progressive improvement in search with kb size.
　a kb containing 1 rdrs and 1 rules was created. initial rules were low-level in nature  dealing with manipulation of nodes and wires. this technical work required frequent editing and debugging. using the validation module with trigger functions  described above  was helpful at this stage.
　after the low level rules were defined  rules could be defined at a higher level of abstraction. because this was a more intuitive abstraction level  it was easier to formulate rules and required less revision. the high level nrdrs were used by the mutation kb  for what the probabilistic algorithm was intended: choosing from the different high level strategies in an attempt to resolve conflicts.
　results: we were able to solve well recognised benchmarks from the domain of switchbox and channel routing. these included burstein's difficult channel routing problem  burstein's switchbox routing problem  the dense switchbox and the joo 1 problem  amongst others. the solutions found were comparable to others' attempts  including those of the weaver  silk  packer and monreale routers    
.
figure 1:
figure 1: solution to burstein's a sample channel routing switchbox problem. solution.
　we found it initially difficult to complete some of the more challenging benchmarks until we used the techniques listed in sections 1 and 1
　on average rules took approximately 1 minutes each to formulate  taking about 1 hours for the formulation of a viable knowledge base. the formulation of effective crp and srp algorithms has been the subject of much study and industry-standard algorithms took many years to develop . in our case ka was done by a novice  using mainly intuition and being able to incrementally specify rules in a natural way on the knowledge level. thus the effort and expertise required was significantly less than commercial routing solutions.
1	conclusion
we have presented an approach to solving complex combinatorial problems by using a generic search algorithm and incrementally introducing domain knowledge in order to make the search tractable. we use knowledge acquisition that supports the exploratory development of solutions  which  when combined with a ga  makes it easier to tackle difficult problems than having to design a conventional algorithm.
　while gas have been successfully used in many domains  in practice they often require considerable augmentation to make the generic architecture effective in complex domains. the unconventional ka technique of rdr formalises this adaptation process  allowing an expert to intuitively develop a domain-specific solution. in order to use rdr for integration with gas  we have introduced new methods to make them work with probabilistic search.
　we have also presented a number of advanced techniques that enhance the ka process. these include the use of trigger functions  nrdr usage profiles and weightings  mutation look-aheads and automatic case identification.
　as part of our mutation operators  we have identified a
　promising technique for improving probabilistic search by using the mutation history of a genome to bias the search into more recent areas of exploration. we have found this heuristic to return promising results.
　the application of our framework in the well understood domain of detailed channel routing and switchbox routing  enables us to compare our results against industrially used algorithms. we have shown that we are able to solve accepted benchmarks competitively  using far less effort than needed for the development of conventional algorithms.
　in future work we will investigate the application of our techniques to a different domain. another worthwhile direction would be to explore the applicability of our advanced ka techniques to more traditional ka domains outside of search. 