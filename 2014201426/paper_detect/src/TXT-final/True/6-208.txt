 
this paper presents two methods for improving the performance of the distributed breakout algorithm using the notion of interchangeability. in particular  we use neighborhood partial and full interchangeability techniques to keep conflicts localized and avoid spreading them to neighboring areas. 
our experiments on distributed sensor networks show that such techniques can significantly reduce the number of cycles required to solve the problems  therefore also reduce communication and time requirements   especially on difficult problems. moreover  the improved algorithms are able to solve a higher proportion of the test problems. 
1 introduction 
distributed constraint satisfaction  discsp  is a powerful paradigm applicable for a wide range of coordination and problem solving tasks in distributed artificial intelligence. 
　among the distributed algorithms that were developed for this kind of problems   yokoo et al.  1    the distributed breakout algorithm  dba  received quite some interest  e.g. 
 zhang et al.y 1   because of a number of properties that this algorithm exhibits  simple  efficient  low overhead  linear memory requirements  good anytime characteristics . 
　dba is an extension of the original centralized breakout algorithm   morris  1  . this algorithm is a local search method  with an innovative technique for escaping from local minima: the constraints have weights  which are dynamically increased to force the agents to adjust their values while in a local minimum. during the execution of the algorithm  each agent proposes improvements to the current state by changing it's variable value such that the cost of violated constraints is decreased as much as possible. 
　while having the interesting properties that we enumerated above  local search algorithms also have a common problem: choosing indiscriminately between the possible values of the local variable  only considering the cost of the immediate constraint violations  can lead to  chain-reactions   one conflict originating in one part of the constraint graph needlessly propagates throughout the whole graph  only to  hopefully  be resolved in a completely different part of the graph . 
　we analyzed these phenomena  and drew the conclusion that using interchangeability techniques  one can determine what values from the local domain will not cause such conflict propagations  and use one of those values as the next variable assignment. in this way  we look for a  local resolution  to all conflicts  in the sense that we keep them contained as much as possible  and only involve  external parties  when there is no other way. 
　we discovered that techniques based on interchangeability  freuder   1   both neighborhood partial and/w// interchangeability  choueiry et al  1   can improve the performance of this algorithm. 
1 preamble 
problem description and formalization 
　the distributed sensor network problem   gomes et al  1   consists of a sensor field composed of n sensors  and m targets to be tracked. each sensor has its own visibility range. the sensors can communicate among themselves  but not necessarily every sensor with every other sensor. 
　some restrictions apply: 1 sensors have to be assigned to each target  and they must be able to communicate among themselves; each sensor can only track one target at a time. 
　in our approach  one agent corresponds to a target; each agent has 1 local variables  the sensors to be assigned to each target   and the domain of each variable is the set of sensors that can track the respective target. 
　there are two types of constraints: intra-agent constraints  the variables belonging to one agent must be assigned to different sensors  and the sensors assigned to one agent must have a communication link between themselves   and interagent constraints  no 1 variables from any 1 agents can be assigned the same value - a sensor can track a single target  interchangeability background 
　the concept of interchangeability informally means equivalence between values of a csp variable: 
  neighborhood interchangeability: 1 values a and b of a variable vi are a1 if they are equivalent for every constraint involving vi; 
  neighborhood partial interchangeability: a weaker form of ni  defined for a subset of values from the local domain with respect to a set of neighbors  where the 

poster papers 	1 


figure 1: percentage of solved problems 

figure 1: average no. of rounds spent on each problem size 
impact of the change of the local variable is limited to the reference set of neighbors. 
1 	algorithms 
due to lack of space  we will present here only a high-level overview of the algorithms that we developed. 
　ni-dba: the idea is that if we find the nl-sets for the local variables  we can safely assign values from those sets  being certain this won't cause any conflicts with the neighboring agents. the nl-sets are determined during the pre-processing phase  based on the domains of the neighbors  and are used at runtime like this: if an agent has a conflict with a neighbor  it will search for an improvement in it's local domain giving 
preference to the values from the nl-set. this avoids any future conflicts with any neighbor. 
　npi-dba: the npl-sets are computed at runtime  w.r.t. the set of the neighbors that we already have conflicts with. when searching for a local improvement  we give preference to the values from the npi-sets  thus not risking to cause future conflicts with neighbors that are not already involved  therefore keeping conflicts contained. 
1 	evaluation 
we made our evaluations in these settings: a sensor field with 1 sensors in total  and randomly generated solvable problems with 1  1  1  1  1  1  1 and 1 simultaneous targets meaning three times as many variables . 
　we collected these results: problem solved/not solved  a problem is declared unsolved after the number of cycles reaches a threshold of 1 cycles   and solving effort  time spent and number of cycles required . 
　for small numbers of targets  all the algorithms performed well; the differences increased with the problem difficulty  and peaked at 1 targets  most difficult problems   where npi-dba solved more than 1% of the problems  whereas 
standard-dba solved less than 1%  see figure 1  both the average number of rounds and the solving time for standard dba are bigger than those for npi-dba  and close to the ones of nl-dba. we see in figure 1 that for difficult problems  the number of required rounds for npi-dba is about 1% smaller than the one of standard dba. a similar diagram for the time is available  but not included here. 
　we developed a visual interface that allows us to monitor the solving process  thus giving us clear indications that using the strategies based on ni/npi greatly inhibits the propagation of conflicts around the constraint graph. 
　the initialization of the variables was random  as in standard dba  in order to keep the algorithms comparable  and see the improvements that the search strategy brings. initialization with values from the nl-sets yields even larger improvements  leading us to believe that both the  informed  initialization of the variables and the subsequent search strategy play a role in the performance of the algorithm. 
　overall  our results have shown that npi-dba is much better than ni-dba. this is due to the fact that in dense problems  there is usually little or no ni at all  whereas npi  being a weaker form of nl is still computable. 
1 	conclusions and future work 
the techniques presented here can be easily generalized beyond inequality constraints and resource allocation problems. 
　npi-dba clearly outperforms standard dba for difficult problems  and ni-dba shows comparable performance. further speedups can be obtained with  informed  initializations  based on the nl data available after the preprocessing phase. 
　further improvements could also be obtained by allowing multiple simultaneous changes of the local variables at each step  and by trying a hierarchical approach  where certain agents are delegated as  local authorities  for solving a particularly difficult local problem. it would be interesting to study in more detail the scalability of these algorithms. 
