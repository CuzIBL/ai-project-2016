 
introspective reasoning about a system's own reasoning processes can form the basis for learning to refine those reasoning processes. the robbie1 system uses introspective reasoning to monitor the retrieval process of a case-based planner to detect retrieval of inappropriate cases. when retrieval problems are detected  the source of the problems is explained and the explanations are used to determine new indices to use during future case retrieval. the goal of robbie's learning is to increase its ability to focus retrieval on relevant cases  with the aim of simultaneously decreasing the number of candidates to consider and increasing the likelihood that the system will be able to successfully adapt the retrieved cases to fit the current situation. we evaluate the benefits of the approach in light of empirical results examining the effects of index learning in the robbie system. 
1 	introduction 
a number of studies have examined the use of metareasoning to control the application of system domain knowledge and to guide acquisition of domain knowledge  e.g.   bradzil and konolige  1; davis  1  . a more recent use of introspective reasoning is to monitor a system's own reasoning processes in order to refine those processes by failure-driven learning  e.g.   collins et a/.  1; ram and cox  1; cox and freed  1  . this paper presents an approach to introspective reasoning for refining the case retrieval criteria of a case-based planning system. 
　in the approach we are investigating  an introspective reasoning component monitors the processing of a case-based reasoning system and evaluates that processing in comparison to expectations for the ideal performance of the case-based reasoning process  for example  the expectation that the case retrieved will be the 
　*this work was supported in part by the national science foundation under grant no. iri-1. 
1 re-organization of behavior by introspective evaluation one that is easiest to adapt to the new situation . failures are detected and learning occurs when performance deviates from the ideal. the failure is explained  an appropriate repair is identified  and the underlying system is modified to correct the failure. we have developed a system that applies this process to refine the indices used for case retrieval in a case-based planning system. our program  robbie  combines a case-based planner as its performance system with an introspective reasoning component which monitors its reasoning and guides introspective learning  fox and leake  1; 1 . 
　applying introspective reasoning to cbr is novel in that learning in cbr systems is generally focused on acquiring domain knowledge  by acquiring new cases. robbie learns new cases  but its primary focus is on the use of introspective reasoning to refine how its cases are applied. the component described in this paper  which refines indexing  is fully implemented. our ultimate goal is to apply introspective learning to all parts of the cbr process-retrieval  adaptation  and evaluation of cases. 
　this paper has two parts. the first describes the robbie system and its approach to introspective learning. the second presents an evaluation of the effects of introspective reasoning on robbie's learning process. the desired effect is an improved ability to focus on relevant cases: a decreased average number of candidate cases retrieved  and the ability to retrieve cases that the system is more likely to adapt successfully. we evaluate system performance in light of these goals and briefly sketch the new costs that introspective reasoning entails and how the benefits balance against them. we close by relating our approach to other work on re-indexing and learning at a meta-level  and describing future directions for the robbie project. 
1 motivations 
case-based reasoning systems use stored past experiences to solve current problems  and learn by storing new solutions for future use  kolodner  1; riesbeck and schank  1 . when a new problem is presented  its description is used to create indices to guide retrieval; the cases in memory with the most similar indices are retrieved. the retrieved cases are adapted to fit the new situation and the resulting solution is stored in memory 
	fox and leake 	1 
a adaptation will finish in less than  max-steps-taken  number of steps 
b similarity assessment will rank cases cor-rectly  the truth of this assertion is defined by the truth of three specific assertions it is linked to  
c the retrieved case will be correctly formed  this also depends on more specific assertions for its truth  including d  
d the retrieved case will contain some plan steps  this communicates its truth up to c: the value is found by examining underlying knowledge structures  
table 1: assertions from the robbie model for use under similar circumstances in the future. 
　the performance of any cbr system depends on using the right features for indexing cases  and having a measure of similarity that correctly selects adaptable cases from memory. if the wrong case is retrieved  adaptation may be costly or even impossible  depending on the cbr system's adaptation capabilities. the problem of determining feature relevance and good measures of similarity for retrieving cases may be difficult and time-consuming for the system designer. 
　one aim in combining an introspective reasoner with a case-based reasoning system is to allow the cbr system itself to determine when and how to refine its indexing criteria. robbie can improve its assessment of similarity over time by learning the correct features to use in indexing  and extensions are underway to enable it to improve other parts of the cbr process as well  such as case adaptation . 
1 the robbie system 
robbie has two main parts  a case-based planning system that develops plans for traveling through an unfamiliar city  and applies them through simulated execution   and an introspective model-based reasoner  as shown in figure 1. the planner carries out its low-level task and interacts with the simulated world  and in parallel the introspective reasoner monitors the planner's reasoning processes. if a problem is detected  the introspective reasoner may suspend planning while it repairs the reasoning problem  or it may permit the planner to continue and wait until more information becomes available to make a repair. 
1 the performance task: pedestrian navigation 
the performance task of robbie is to navigate around a simulated set of city streets as a pedestrian. robbie is given a starting location and a goal location and must create a plan for getting from the one to the other. because the system does not have a perfect map nor a perfect retrieval mechanism  generation of a candidate plan does not assure successful execution. after plans are generated  robbie executes them  using a simulated robot based on firby's reactive planner  firby  1 . this plan execution serves as a means of evaluating the quality of the cbr-created plan  as well as permitting robbie to arrive at a solution despite flaws in the cbr-produced plan  providing a way to augment its case base. in addition  the reactive planner handles facets of the simulated world that cannot be predicted by the cbr system  such as traffic lights and blocked streets. 
　the plans in memory are indexed by their starting and ending locations  as well as other features robbie has learned to use through its introspective reasoning. plan retrieval in robbie is a two-stage process: first robbie gathers a pool of generally similar candidate cases  then it selects the best candidate from that pool. plans describe navigational actions in terms of high-level plan steps such as  move north on oak to birch  or  turn east on fir.  these steps are then used as sequential goals for reactive execution  which breaks the problem down into individual steps for the simulated robot to execute. 
1 the introspective task 
the higher level task for robbie is to improve its reasoning processes in response to detected reasoning failures. robbie's approach uses an explicit  declarative model describing the underlying system's reasoning processes  fox and leake  1; birnbaum et a/.  1; freed and collins  1 . the model provides expectations about the ideal reasoning behavior of the system; the actual reasoning of the system is compared to this ideal as a means of detecting reasoning failures. once a reasoning failure is detected the model is used to create an explanation of the failure and to suggest a repair  see  fox and leake  1  for a discussion of robbie's failure detection . currently  robbie can learn new features to use in indexing memory  and can re-index its memory to pay attention to those features. 
　the introspective model consists of a structured set of  assertions  about portions of the cbr reasoning process. each assertion describes a feature that would be true of an ideal cbr system. table 1 lists a few of the assertions from the model for robbie. assertions range in specificity from implementation details of robbie  such as assertion a in table 1  to abstract descriptions of the cbr process and the flow of control between its 

components  such as assertions b and c. 
　the assertions are organized by the component to which an assertion refers  by the level of specificity of the assertion  and by connections to other related assertions. dividing by component facilitates monitoring; the only assertions which must be monitored refer to the current component of processing. assertions are arranged hierarchically to simplify the task of updating the model. each assertion is linked to the other assertions which are related to it: as an abstraction  a specification  coming in sequence  or because a failure in one suggests a failure in the other. these links are used in explaining failures and finding repairs by focusing on the most fruitful areas of inquiry. assertions c and d in table 1 show an abstract assertion and its specification. the vocabulary for representing assertions uses simple predicate calculus formulations. in  fox and leake  1  we provide a detailed description of the model and the representation it uses  and describe in more detail the need for a hierarchy of assertions. 
　after generating a successful solution  most cbr systems will simply store the solution and stop processing  while robbie evaluates its retrieval process by retrieving the case in memory with the closest solution. if it is not the case that was retrieved originally  a retrieval failure occurred during the original retrieval. in repairing a retrieval failure robbie must determine what  if any  relevant feature was overlooked. robbie currently considers a pre-defined set of feature types such as  starts at location x    ends on street z   or  moves straight along street y   which are ranked by a fixed feature hierarchy. robbie uses the feature types to compare the new solution with the closest solution in memory  and explains the failure according to the missing features. in the future we plan to expand this mechanism to more general features using explanation-based generalization. 
1 	an example 
in this section we will present an implemented example illustrating the model of introspective reasoning we are developing and its benefits. figure 1 shows the portion of the world map relevant to this example. the goal is to get from location l1 to location l1. robbie has in memory plan a for going from li to l1  turn south  move south to south side of birch  turn west  
move west to l1  and plan b for going from l1 to l1  turn east  move east to l1 . using only starting and ending locations to judge similarity  plan a appears to be the closest because it shares the same ending location  robbie's retrieval criteria do not include reversals of known routes . plan a is selected and adapted to create plan c  dashed line in figure 1 : turn south  move south to south side of birch  turn west  move west to l1. 
　during this process  the introspective reasoner monitors the system's behavior but detects nothing wrong. when the plan is executed  however  the wasted plan steps will be eliminated  producing a straight-line plan: turn west  move west to l1. when this resulting plan is stored into memory  a reasoning failure is detected: the final solution's steps are most similar to a plan  plan b  other than the retrieved case. 
　in explaining the cause of this failure  robbie reconsiders related assertions in its model of the desired system behavior: that retrieval will operate successfully; that the index for retrieval will produce the closest case; that the index will include all the relevant features to retrieve the closest case. in re-testing the last assertion  in the context of a failure   the system discovers a feature of the case it had not used before: that each involves moving straight east or west. this failed assertion suggests a repair: add  moving east or west  to the features used in the index  and re-index all cases in memory to include the new feature. 
1 	empirical evaluation of re-indexing 
there has been little evaluation of the quantitative effects on performance from introspective reasoning; arguments for introspective reasoning have tended to focus on the capabilities provided in principle illustrated by particular examples. although such work is important  we believe it is also important to define concrete measures which demonstrate the benefit of introspective reasoning  and weigh those against the costs of additional processing. for adding introspective reasoning to case-based reasoning  this requires examining whether isolated examples map onto a general trend of improvement beyond that accounted for by case acquisition alone. 
　we ran a series of tests on the robbie system to evaluate introspective learning versus case learning alone.1 we looked at two measures of robbie's performance: the number of successfully completed plans at the end of a test run and the percentage of cases in memory considered for each retrieval. the number of successful plans provided a comparative measure of the level of success  and we predicted that introspective reasoning and reindexing should enable robbie to be more successful on a sequence than case learning alone. the percentage of plans considered during retrieval measured the efficiency of robbie's processing over the course of a test run; we expected that the percentage should drop with re-indexing as new features allowed finer-grained distinctions between cases. in sum  we expected introspective 
　1robbie was presented with a total of 1 goals: 1 sequences  each 1 goals long; and 1 runs with introspection  1 without. 
	fox and leake 	1 
re-indexing to increase the success of robbie at the same time as it decreased the work done in considering cases for retrieval.1 
　the experiments were designed to test performance from a knowledge-poor starting point  the most difficult situation for both case-based and introspective learning. robbie started with an extremely small initial case base  spanning only three cases. the model used during testing contained a restricted set of assertions  to streamline the diagnosis process. 
　robbie treats a sequence of locations as sequential goals: it starts at the first position  plans from there to the second  from the second to the third  and so on. for the purposes of these tests  when robbie fails to reach a goal and is unable to recover  robbie's location is set to the failed goal and the sequence continues from that point. when this occurs  no case is added to the case base: the size of the case base therefore matches the number of successes robbie has. 
　we used a set of 1 randomly-created locations as goals for this experiment. these locations did not correspond exactly to locations in any plan in the initial case base. from these locations  we generated a set of 1 test sequences; each sequence was an ordering of the 1 locations with each location appearing exactly once. one sequence was designed by hand to extend the case base a little bit at a time: it started with goal locations similar to those in the case base  and gradually moved to goals further away from the initial cases. from the handmade sequence we created five groups of five sequences each  where each group varied from the handmade sequence by a different amount  1%  1%  1%  and 1% permuted; 1% permuted means 1% of the locations in the sequence were randomly swapped with other locations . in addition  we generated 1 completely random sequences to avoid any residual bias of the original sequence. 
　robbie chooses at random between two candidate cases which appear equally similar. it is often the case  however  that the two cases produce different results which may affect later processing: one might fail or cause a new feature to be learned. to factor out these differing results  we ran each sequence twenty times with introspective re-indexing and twenty times without. 
1 empirical results 
1 	success rate 
we will first consider the success rate with and without re-indexing  defined by the number of successfully completed plans for a run. figure 1 shows a breakdown of the results. the numbers for each sequence were averaged across the twenty runs; the averages for a particular sequence with and without re-indexing are side by side with the darker shaded bars indicating introspective re-indexing and the lighter shaded  no re-indexing. 
for all but one sequence  robbie with introspective 
　1it would also be possible for introspective learning to cause retrieval to become too restrictive  decreasing success; verifying that this is not commonly the case is another reason for empirical tests. 

learning did succeed more often than robbie with only case learning  as we expected. this reflects the retrieval of more appropriate cases. the average of successful cases varied widely across the sequences  as did the difference between runs with introspective reasoning and those with case learning alone. in some cases  the difference between the two was very large; in others  very small. in one anomalous sequence  introspective reasoning performed slightly worse than case learning alone. that unexpected result is clearly troublesome  and we will return to discuss the anomaly after considering the second measure of robbie's performance. 
1 improved retrieval efficiency we will now consider the second measure of robbie's performance  the extent to which learning new indices improves the efficiency of its retrieval. we measured this by considering what percentage of stored plans robbie considered similar for each retrieval made during a test run. we graphed the course of the run on the x-axis as a time measure by counting each successive retrieval as the next point in time. the percentage of memory considered at each retrieval was graphed on the y-axis. 
　the effect of re-indexing can be seen in figure 1  where we graphed a run with re-indexing alongside a representative sample of runs without it. the heavy line shows the percentage of cases considered in retrieval with introspective learning; each point where introspective learning took place is marked with an asterisk. the light lines are five runs without introspective learning. the runs without re-indexing varied from each other only in minor ways  which is why often only one line is visible . the introspective run began in the same way but the percentage of cases considered dropped sharply after learning the first new feature. while the percentage considered rose in some instances to match the runs without re-indexing  it returned to a consistently low level at other points. early in the sequence  and again around retrieval 1  the trends in percentages considered mimicked the rise and fall of the runs without re-indexing  but at a much lower level. it is interesting to note that most of the learning took place at low points instead of peaks. this suggests that at the low points  retrieval might have been over-restricted  and new features are 

learned to bring other cases into consideration. it also suggests that when no cases in memory are similar to a goal  large percentage retrievals are appropriate. 
　as is clear from figure 1  the percentage considered from one goal of a sequence to the next fluctuated between very high and very low levels. this fluctuation made it difficult to analyze the trend of retrievals. we gained a better perspective by graphing  successive averages  of the percentage considered: the x-axis represents the course of the run as before  but each value on the yaxis is the average of the percentages from the beginning of the sequence to that point. figure 1 shows typical results: twenty runs with introspective re-indexing on the left and twenty without it on the right. the averages with re-indexing declined over time to a much lower level than those without: 1% instead of 1%. a similar pattern of decline appeared in every sequence except the anomalous one. in some cases the decrease was much more dramatic  both in how low the percentage became and in how consistently runs displayed that low percentage. the best performance correlated with sequences with higher overall success rates  and with those having a greater difference between the success rates with and without re-indexing. 
1 	the anomalous sequence 
the most compelling explanation for the anomalous sequence is that the introspective learning simply did not create new features which would be useful in later situations. this is supported by the anomalous sequence's retrieval efficiency with and without re-indexing: the average percentage considered in retrieval did not change significantly with or without introspective re-indexing. this suggests that  for this case  the new features learned introspectively did not apply to later situations and so could not provide any benefit. consequently  the features learned through introspective reasoning did not group together useful cases  but rather caused an occasional additional failure by restricting retrieval so that a useful case might not be considered at all. this limiting effect of re-indexing would be magnified by the small size of the initial case base  together with the fact that few cases were being learned during the course of the run. because robbie's re-indexing depends on having a case in memory which shares important features with the current solution  the fewer the cases in memory  the less likely a good match will be found and a useful feature learned. characterizing sequences like this one further and determining their frequency is an important task for the future. 
1 	summary of benefits and costs 
from the results discussed above  we can conclude that introspective reasoning does provide a tangible benefit under most circumstances  though further study is needed to characterize its failure for one sequence. in the other trials  the benefits we expected were demonstrated across a broad set of examples. robbie generated more successful plans when using re-indexing  while at the same time improving the efficiency of its retrieval. while the percentage of cases considered in retrieval with re-indexing remained at a high level for goals which were dissimilar to cases in memory  the average percentage declined to a significantly lower level than with case learning alone. 
　we must address the other side of the coin: the costs of introspective reasoning. monitoring for failures and explaining them require some amount of processing overhead; if it were sufficiently high it might make applying introspective reasoning infeasible. re-indexing also takes time to reconsider cases in memory. however  in robbie we have seen no severe performance degradation because of the use of introspective reasoning. introspective reasoning can improve the efficiency of the system's reasoning  in this case by reducing the effort of considering similar cases. if robbie's plans were executed in the real world  the execution time lost by selecting the wrong plan and recovering could overwhelm the cost of introspective reasoning which would avoid repeating such failures. combining these advantages with the extension of the set of problems the system can solve  introspective reasoning seems highly promising.1 
1 	relationship to previous research 
there has been a significant amount of work in the past few years on methods for implementing introspective reasoning. our work was inspired by the proposals for using model-based reasoning to improve the performance of cbr systems made by  birnbaum et a/.  1 . in a similar spirit  freed implements an introspective model in rapter  a reactive planning system  freed and collins  1 . rapter focuses on analysis of the reasoning trace of the planner  using  justification structures  which trace the chain of assumptions made by the system used to determine what to repair. 
　stroulia uses a  structure-behavior-function  model  a form originally designed for diagnosis of device failures  
　　1 the cost in development time expended to construct the introspective model is another issue  see  fox and leake  1  for a detailed discussion of model transfer. 
	fox and leake 	1 

to perform introspective reasoning about an underlying system stroulia and goel  1 . her introspective reasoner  autognostic  has been applied to two underlying systems  showing that transfer of introspective models is feasible. the sbf model provides strategies for assigning blame for the failure  and provides information about the device being modeled beyond that included in robbie's model. robbie's model is designed to support failure detection as well as recovery  and facilitates that process through the types of assertions included and their organization. 
　oehlmann integrates introspective reasoning with the overall domain task in iulian: discovering answers to questions through experience or experimentation  oehlmann et a/.  1 . iulian contains plans for solving domain tasks  and introspective plans for controlling its reasoning process. it learns by applying these plans to its domain and reasoning tasks  and remembering the resulting successes or failures. 
cox implements introspective reasoning in meta-
aqua by maintaining a set of reasoning trace templates  meta-xps  that describe different reasoning failures  and detecting reasoning failures that match a template ram and cox  1 . meta-xps provide the means for determining the failure and suggestions for repairs. 
　in cbr research outside of introspective reasoning  multiple methods have been proposed for determining relevant indices. for example  explanations are often used to determine the relevance of features when assigning indices to new cases  e.g.   barletta and mark  1; leake and owens  1; ram  1  . however  less attention has been devoted to the central questions addressed by robbie: when and how an existing case in memory should be re-indexed. some approaches alter indices in response to external feedback  redmond  1; veloso and carbonell  1 ; robbie instead uses afterthe-fact introspective analysis of its reasoning performance to determine whether new indices should be learned. in addition  when robbie chooses new indices  it uses knowledge of both the faulty retrieval and the case that should have been retrieved to guide the choice of new indices. this allows it to select indices that are useful to discriminate between the cases currently in its memory  fox and leake  1 . 
1 	conclusions 
the robbie system combines introspective reasoning with a case-based planner to create a system that not only learns new plans in response to its experiences  but also learns to plan better by learning new features to use in indexing. robbie uses a declarative model of the case-based reasoning process which provides expectations about its reasoning performance through assertions about the ideal reasoning and results. this model contains both general and specific assertions; the framework is designed to be applicable to other underlying systems and failures  fox and leake  1 . 
　in previous research  little has been done to quantitatively evaluate introspective reasoning beyond isolated examples. we have performed empirical analysis of robbie to determine its performance by measuring the success rate and the reasoning efficiency. we discovered that across a range of inputs  robbie with introspective re-indexing improved the efficiency of its retrieval process by learning features to constrain the cases considered and to focus on the best cases. with one exception  robbie was also more successful in creating plans when using introspective re-indexing than when doing case learning alone. 
　many questions still remain to be answered. perhaps most important is a detailed analysis of the reasons for robbie's successes  and its failure. we must characterize the sequence which caused robbie to perform worse with introspective re-indexing  and determine how common such a failure might be. we believe that the failure is due to the sparse introspective learning opportunities with a small case base that remained small due 

to many failures over time  combined with the possible over-constraining of the retrieval process due to learning irrelevant features. 
　as future research  we plan to expand the model of robbie to include diagnosis and repair of other portions of the cbr system  such as the weighting of features in retrieval  the choice of strategies for adaptation  and the choice of plan execution steps. we plan eventually to transfer the introspective framework we have developed to other underlying systems  and to consider more qualitative measures of robbie's introspective reasoner such as the quality of reasoning  the quality of plan produced  and its value as a cognitive model. 
　while much work remains to be done in creating the best method for introspective reasoning and evaluating its performance  the work described here clearly demonstrates that learning based on introspective reasoning is a feasible addition to a case-based planning system such as robbie and provides a tangible benefit over fixed reasoning. we are encouraged by robbie's success to expect introspective learning to provide more advantages for cbr and elsewhere in the future. 
