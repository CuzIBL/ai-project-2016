 
compilation to boolean satisfiability has become a powerful paradigm for solving ai problems. however  domains that require metric reasoning cannot be compiled efficiently to sat even if they would otherwise benefit from compilation. we address this problem by introducing the lcnf representation which combines propositional logic with metric constraints. we present lpsat  an engine which solves lcnf problems by interleaving calls to an incremental simplex algorithm with systematic satisfaction methods. we describe a compiler which converts metric resource planning problems into lcnf for processing by lpsat. the experimental section of the paper explores several optimizations to lpsat  including learning from constraint failure and randomized cutoffs. 
1 	introduction 
recent advances in satisfiability  sat  solving technology have rendered large  previously intractable problems quickly solvable  crawford and auton  1; selman et ai  1; cook and mitchell  1; bayardo and schrag  1; li and anbulagan  1; gomes et ai  1 . sat solving has become so successful that 
many other difficult tasks arc being compiled into propositional form to be solved as sat problems. for example  sat-encoded solutions to graph coloring  planning  and circuit verification are among the fastest approaches to these problems  kuitz and selman  1; selman et ai  1j. 
　but many real-world tasks have a metric aspect. for instance  resource planning  temporal planning  scheduling  and analog circuit verification problems all require 
   *we thank people who provided code  help  and discussion. greg badros  alan borning  corin anderson  mike ernst  zack ives  subbarao karnbhampati  henry kautz  jana koehler  tessa lau  denise pinnel  rachel pottinger  
bart selman  and the blind reviewers. this research was funded in part by office of naval research grant n1-1  by the arcs foundation barbara and tom cable fellowship  by national science foundation grants iri1 and iis-1  and by a national science foundation graduate fellowship. 
1 	challenge papers 

figure 1: data flow in the demonstration resource planning system; space precludes discussion of the grey components. 
reasoning about real-valued quantities. unfortunately  metric constraints are difficult to express in sat encodings1. hence  a solver which could efficiently handle both metric constraints and propositional formulae would yield a powerful substrate for handling ai problems. 
　this paper introduces a new problem formulation  lcnf  which combines the expressive power of propositional logic with that of linear equalities and inequalities. we argue that lcnf provides an ideal target language into which a compiler might translate tasks that combine logical and metric reasoning. we also describe the lpsat lcnf solver  a systematic satisfiability solver integrated with an incremental simplex algorithm. as lpsat explores the propositional search space it updates the set of metric requirements managed by the linear program solver; in turn  simplex notifies the propositional solver if these requirements become unsatisfiable. 
   we report on three optimizations to lpsat: learning and backjumping  adapting lpsat's core heuristic to trigger variables  and using random restarts. the most effective of these is the combination of learning and backjumping; lpsat learns new clauses by discovering explanations for failure when a branch of its search terminates. the resulting clauses guide backjumping and constrain future truth assignments. in particular  we show that analysis of the state of the linear program solver is crucial in order to learn effectively from constraint conflicts. 
　to demonstrate the utility of the lcnf approach  we also present a fully implemented compiler for resource planning problems. figure 1 shows how the components fit together. their performance is impressive: lpsat solves large resource planning problems  encoded in a 
   encoding each value as a separate boolean variable is a simple but unwieldy solution; bitwise-encodings produce smaller formulae but ones which appear very hard to solve  ernst et ai  1 . 


figure 1: 	portion of a tiny lcnf logistics problem 
 greatly simplified from compiler output . a truck with load and fuel limits makes a delivery but is too small to carry all load available  the allloaded constraint . italicized variables are boolean-valued; typeface are real. 
variant of the pddl language  mcdermott  1  based on the metric constructs used by metric ipp  koehler  1    including a metric version of the att logistics domain  kautz and selman  1g . 
1 	the lcnf formalism 
the lcnf representation combines a propositional logic formula with a set of metric constraints. the kev to the 
encoding is the simple but expressive concept of triggers - each propositional variable may  trigger  a constraint; this constraint is then enforced whenever the trigger variable's truth assignment is true. 
   formally  	an 	lcnf 	problem 	is 	a 	five-tuple 	in which r is a set of real-valued variables  v is a set of propositional variables   is a set of linear equality and inequality constraints over variables in r   is a propositional formula in cnf over variables in v  and t is a function from v to  which establishes the constraint triggered by each propositional variable. 	we require that  contain a 
   special n u l l constraint which is vacuously true  and this is used as the t-value for a variable in v to denote that it triggers no constraint. moreover  for each variable v we define 
　under this definition  an assignment to an lcnf problem is a mapping     from the variables in r to real values and from the variables in v to truth values. given an lcnf problem and an assignment  the set of active constraints is 
we say that an assignment satisfies the lcnf problem if and only if it makes at least one literal true in each clause of  and satisfies the set of active constraints. 
　figure 1 shows a fragment of a sample lcnf problem: a truck  which carries a maximum load of 1 and fuel level of 1  can make a delivery by executing the move action. we discuss later why it cannot have a goodtrip. 
1 	the lpsat solver 
our first step in constructing the lpsat engine was to choose solvers to use as the foundation for its metric and propositional solving portions. the choice was motivated by the following criteria: 
1. it must be easy to modify the propositional solver in order to support triggers and handle reports of inconsistency from the constraint reasoner. 
1. the metric solver must support incremental modi-fications to the constraint set. 
1. because a simplex solve is more expensive than setting a single propositional variable's value  the propositional solver should minimize modifications to the constraint set. 
　these principles led us to implement the lpsat engine by modifying the relsat satisfiability engine  bayardo and schrag  1  and combining it with the cassowary constraint solver  borning et a/.  1; badros and borning  1  using the method described in  nelson and oppen  1 . relsat makes an excellent start for processing lcnf for three reasons. first  it performs a systematic  depth-first search through the space of partial truth assignments; this minimizes changes to the set of active metric constraints. second  the code is exceptionally well-structured. third  relsat incorporates powerful learning and backjumping optimizations. cassowary is an appropriate simplex solver for handling lcnf because it was designed to support and quickly respond to small changes in its constraint set. 
　in order to build lpsat  we modified relsat to include trigger variables and constraints. this required four changes. first  the solver must trigger constraints as the truth assignment changes. second  the solver must now check for a solvable constraint set to ensure that a truth assignment is satisfying. third  the solver must report in its solution not only a truth assignment to the boolean variables  but an assignment of real values to the constraint variables1. finally  since even a purely positive trigger variable may  if set to true  trigger an inconsistent constraint  pure literal elimination cannot act on positive trigger variables1. figure 1 displays pseudocode for the resulting algorithm. 
1 	incorporating learning and backjumping 
lpsat inherits methods for learning and backjumping from relsat  bayardo and schrag  1 . lpsat's depth-first search of the propositional search space creates a partial assignment to the boolean variables. when the search fails  it is because the partial assignment is inconsistent with the lcnf problem. lpsat identifies an inconsistent subset of the truth assignments 
   1 while the assignment to the constraint variables is optimal according to cassowary's objective function  it is not guaranteed to be the globally optimal assignment to the real variables by the same measure; a different assignment to the propositional variables might provide a better solution. so  the specific function used is not vital  we use cassowary's default which minimizes the slack in inequalities . 
   1 this restriction falls in line with the pure literal elimination rule if we consider the triggers themselves to be clauses. the trigger  from figure 1 would then become the clause maxload v  load   1   and maxload could no longer be purely positive. 
	wolfman and weld 	1 


figure 1: core lpsat algorithm  without learning or backjumping . bad  denotes a check for constraint inconsistency; solve returns constraint variable values. t u  returns the constraint triggered by u  possibly null . e u  denotes the result of setting literal u true in e and simplifying. 

figure 1: possible search tree for the constraints from 
figure 1. each node is labeled with the variable set at that node; branchpoints have true  t  and false  f  branches. ＼ indicates an inconsistent constraint set. the bold variables are members of the conflict set. 
in the partial assignment  a conflict set  and uses this subset to learn in two ways. first  since making the truth assignments represented in the conflict set leads inevitably to failure  lpsat can learn a clause disallowing those particular assignments. for example  in the problem from figure 1 the constraints triggered by setting minfuel  maxfuel  maxload  and allloaded to true are inconsistent  and minfuel  maxfuel  and allloaded form a conflict set. so  lpsat can learn the clause . second  because continuing the search is futile until at least one of the variables in the conflict set has its truth assignment changed  lpsat can backjump in its search to the deepest branch points at which a conflict set variable received its assignment  ignoring any deeper branch points. figure 1 shows a search tree in which minfuel  maxfuel  
maxload  and allloaded have all been set to true. using the conflict set containing minfuel  maxfuel  and allloaded  lpsat can backjump past the branchpoint for 
maxload to the branchpoint for minfuel  the deepest member of the conflict set which is a branchpoint. 
　however  while lpsat inherits methods to use conflict sets from relsat  lpsat must produce those conflict sets for both propositional and constraint failures while 
1 	challenge papers 

figure 1: graphical depiction of the constraints from 
figure 1. the shaded area represents solutions to the set of solid-line constraints. the dashed allloaded constraint causes an inconsistency. 
relsat produces them only for propositional failures. 
thus  given a propositional failure lpsat uses relsat's conflict set discovery mechanism unchanged  learning a set based on two of the clauses which led to the contradiction  bayardo and schrag  1 . for a constraint conflict  however  lpsat identifies an inconsistent subset of the active constraints  and the propositional triggers for these constraint compose the conflict set. we examine two methods for identifying these inconsistent subsets. 
in our first method  called global conflict set discovery  
lpsat includes the entire set of active constraints in the conflict set. this mechanism is simple but often suboptimal since a smaller conflict set would provide greater pruning action. indeed  preliminary experiments showed that - while global conflict set discovery did increase solver speed over a solver with no learning or backjumping facility - the conflict sets were on average twice as large as those found for logical conflicts. 
　in our second method  called minimal conflict set discovery  lpsat identifies a  potentially  much smaller set of constraints which are responsible for the conflict. specifically  our technique identifies an inconsistent conflict set of which every proper subset is consistent. 
figure 1 illustrates the constraints from the example in 
figure 1. the constraints maxload  maxfuel  and minfuel and the implicit constraints that f u e l and load be non-negative are all consistent; however  with the introduction of the dashed constraint marked allloaded the constraint set becomes inconsistent. informally  lpsat finds a minimal conflict set by identifying only those constraints which are  together  in greatest conflict with the new constraint. we now discuss how lpsat discovers the conflicting constraints in this figure and which set it discovers. 
	when 	lpsat 	adds 	the 	allloaded 	constraint 	to 
cassowary's constraint set  cassowary initially adds a  slack  version of the constraint which allows error and is thus trivially consistent with the current constraint set. this error is then minimized by the same routine used to minimize the overall objective function  badros and borning  1 . in figure 1  we show the minimization as a move from the initial solution at the upper left corner point to the solution at the upper right corner point of the shaded region. the error in the solution is the horizontal distance from the solution point to the new constraint allloaded. since no further progress 

within the shaded region can be made toward allloaded  the error has been minimized; however  since the error is non-zero  the strict constraint is inconsistent. 
　at this point  lps at uses  marker variables   which cassowary adds to each original constraint  to establish the conflict set. a marker variable is a variable that was added by exactly one of the original constraints and thus identifies the constraint in any derived equations. lpsat examines the derived equation that gives the error for the new constraint  and notes that each constraint with a marker variable in this equation contributes to keeping the error non-zero. thus  all the constraints identified by this equation  plus the new constraint itself  compose a conflict set. 
　in figure 1 the minfuel and maxfuel constraints restrain the solution point from coming closer to the allloaded line. if the entire active constraint set were any two of those three constraints  the intersection of the two constraints' lines would be a valid solution; however  there is no valid solution with all three constraints. 
	note 	that 	another 	conflict 	set 	 allloaded 	plus 
maxload  exists with even smaller cardinality than the one we find. in general  there may be many minimal conflict sets  and our conflict discovery technique will discovery only one of these  with no guarantee of discovering the global minimum. some of these sets may prove to have better pruning action  but we know of no way to find the best minimal conflict set efficiently. how-
ever  the minimal conflict set t.s at least as good as  and usually better than  any of its supersets. 
　a brief proof that our technique will return a minimal conflict set appears in the longer version of this paper  wolfman and weld  1 . 
1 	the resource planning application 
in order to demonstrate lpsat's utility  we implemented a compiler for metric planning domains  starting from a base of ipp's  koehler et a/.  1  and b l a c k box's  kautz and selman  1  parsers  which translates resource planning problems into lcnf form. after lpsat solves the lcnf problem  a small decoding unit maps the resulting boolean and real-valued assignments into a solution plan  figure 1 . we believe that this translate/solve/decode architecture is effective for a wide variety of problems. 
1 	action language 
our planning problems are specified in an extension of the pddl language  mcdermott  1 ; we support pddl typing  equality  quantified goals and effects  disjunctive preconditions  and conditional effects. in addition  we handle metric values with two new builtin types: float and fluent. a float's value may not change over the course of a plan  whereas a fluent's value may change from time step to time step. moreover  we support fluent- and float-valued functions  such as  distance nagoya stockholm  . 
　floats and fluents are manipulated with three special built-in predicates: test  set  and influence. test statements are used as predicates in action preconditions; set and influence are used in effects. as its argu-

figure 1: two actions which can execute in parallel  but which cannot be serialized. 
ment  test takes a constraint  an equality or inequality between two expressions composed of floats  fluents  and basic arithmetic operations ; it evaluates to true if and only if the constraint holds. set and influence each take two arguments: the object  a float or fluent  and an expression. if an action causes a set to be asserted  the object's value after the action is defined to be the expression's value before the action. an asserted influence changes an object's value by the value of the expression  as in the equation object :- object + expression  multiple simultaneous influences are cumulative in their effect  falkenhainer and forbus  1 . 
1 	plan encoding 
the compiler uses a regular action representation with explanatory frame axioms and conflict exclusion  ernst et a/.  1 . we adopt a standard fluent model in which 
time takes nonnegative integer values. state-fluents occur at even-numbered times and actions at odd times. the initial state is completely specified at time zero  including all properties presumed false by the closed-world assumption. 
　each test  set  and influence statement compiles to a propositional variable that triggers the associated constraint. just as logical preconditions and effects are implied by their associated actions  the triggers for metric preconditions and effects are implied by their actions. 
　the compiler must generate frame axioms for constraint variables as well as for propositional variables  but the axiomatizations are very different. explanatory frames are used for boolean variables  while for real variables  compilation proceeds in two steps. first  we create a constraint which  if activated  will set the value of the variable at the next step equal to its current value plus all the influences that might act on it  untriggered influences arc set to zero . next  we construct a clause which activates this constraint unless some action actually sets the variable's value. 
　for a parallel encoding  the compiler must consider certain set and influence statements to be mutually exclusive. for simplicity  we adopt the following convention: two actions are mutually exclusive if and only if at least one sets a variable which the other either influences or sets. 
　this exclusivity policy results in a plan which is correct if actions at each step are executed strictly in parallel; however  the actions may not be serializable  as demonstrated in figure 1. in order to make parallel actions arbitrarily serializable  we would have to adopt more restrictive exclusivity conditions and a less expressive format for our test statements. 
	wolfman and weld 	1 


figure 1: solution times for three versions of lpsat in the metric logistics domain. no learning or backjumping is performed in the line marked  no learning.  global conflict sets and minimal conflict sets use progressively better learning algorithms. note that the final point on 
each curve reaches the resource cutoff  one hour . 
1 	experimental results 
there are currently few available metric planners with which to compare lpsat. the zeno system  penberthy and weld  1  is more expressive than our system  but zeno is unable even to complete easy-1 our simplestmetric logistics problem. there are only a few results available for koehler's metric ipp system  koehler  1   and code is not yet available for direct comparisons. 
　in light of this  this section concentrates on displaying results for lpsat in an interesting domain and on describing the heuristics and optimization we used to enhance lpsat's performance. we report lpsat solve time  running on a pentium ii 1 mhz processor with 1 mb of ram  averaged over 1 runs per problem  and showing 1 percent confidence intervals. we do not include compile time for the  unoptimized  compiler since the paper's focus is the design and optimization of lpsat; however  compile time can be substantial  e.g.  twenty minutes on log-c . 
   we report on a sequence of problems in the metric logistics domain  which includes all the features of the att logistics domain  kautz and selrnan  1 : airplanes and trucks moving packages among cities and sites within cities. however  our metric version adds fuel and distances between cities; airplanes and trucks both have individual maximum fuel capacities  consume fuel to move  the amount is per trip for trucks and based on distance between cities for airplanes   and can refuel at depots  log-a through log-d are the same as the att problems except for the addition of fuel  easy-1 through easy-1 are simplifications of log-a with more elements retained in the higher numbered problems. we report on highly successful experiments with learning and back-
jumping as well as two other interesting optimizations. 
1 	learning and backjumping 
the results in figure 1 demonstrate the improvement in solving times resulting from activating the learning and backjumping facilities which were described in section 1. runs were cut off after one hour of solve time  the minimal conflict set technique ran over an hour only on log-d . without learning or backjumping lpsat quickly 
1 	challenge papers 

figure 1: solution times for two types of random restarts. tuned cutoff uses raw experimental data to select a constant cutoff. cutoff doubling starts with a cutoff of one second and doubles it on each run. 
exceeds the maximum time allotted to it. with learning and backjumping activated using global conflict sets  the solver handles larger problems and runs faster. our best method  minimal conflict sets  quickly solves even some of the harder problems in the metric logistics domain. 
1 	splitting heuristic 
line 1 of the lpsat pseudocode  figure 1  makes a nondeterministic choice of variable v before the recursive call  and the splitting heuristic used to guide this choice can bias performance. we expected the standard relsat heuristic to perform poorly  due to a overly strong preference for trigger variables  for two reasons: 1  the trigger itself is an implicit clause which is resolved when a trigger variable is set  and 1  each time the solver modifies a trigger variable  it may call cassowary  and these calls often dominate runtime. we tried several methods of including information about the trigger variables in the splitting heuristic  including adding and multiplying the score of trigger variables by a user-settable preference value. to our surprise  however  we were unable to achieve significant improvement  although increasing the preference for trigger variables did slow execution . these results lead us to suspect that either that lcnf problems are generally insensitive to our heuristics or that our compilation of metric planning domains already encodes information about trigger variables in the structure of the problem. further experiments will decide the issue. 
1 	random restarts 
because lpsat uses a randomized backtracking algorithm and because early experimental results showed a small percentage of runs far exceeded the median runtime  we experimented with random restarts using a process similar to the one described in  gomes et a/.  1 . we cut off solving at a deadline which can be either fixed beforehand or geometrically increasing - and restart the solver with a new random seed. 
　figure 1 shows the results of these experiments. we first ran the algorithm twenty times on each problem to produce the  raw  entries1. then  we calculated the 
     1  all three sets of runs use minimal conflict sets  learning  and backjumping. 

cutoff time which minimized the expected runtime of the system based on these twenty runs. finally  we reran the problems with this tuned cutoff time to produce the  tuned cutoff  data. 
　while this technique provides some speedup on log-b and impressive speedup on log-c  it requires substantial  preliminary research into the difficulty of the problem  in order to determine the appropriate cutoff time . unless lps at is being used repeatedly to solve a single problem or several very similar problems  the process of finding good restart times will dominate overall runtime. 
　therefore  we also experimented with a restart system which requires no prior analysis. this  cutoff doubling  approach sets an initial restart limit of one second and increases that limit by a factor of two on each restart until reaching a solution. we have not yet performed any theoretical analysis of the effectiveness of this technique  but figure 1 demonstrates a small improvement. more interesting than the average improvement  however  is the fact that this method improved the consistency of the runtimes on the harder problems; indeed  on log-c five of the twenty  raw  runs lasted longer than the longest  cutoff doubling  run. 
1 	related work 
limited space precludes a survey of propositional satisfiability algorithms and linear programming methods in this paper. see  cook and mitchell  1  for a survey of satisfiability and  karloff  1  for a survey of linear programming. 
　our work was inspired by the idea of compiling probabilistic planning problems to ma.jsat  majercik and littman  1 . it seemed that if one could extend the sat  virtual machine  to support probabilistic reasoning  then it would be useful to consider the orthogonal extension to handle metric constraints. 
　other researchers have combined logical and constraint reasoning  usually in the context of programming languages. clpr may be thought of as an integration of prolog and linear programming  and this work introduced the notion of incremental simplex  jaffar et a/.  1 . saraswat's thesis  saraswat  1  formulates a family of programming languages which operate through the incremental construction of a constraint framework. chip  van hentenryck  1  augments logic programming with the tools to efficiently solve constraint satisfaction problems  e.g.  consistency checking   but deals only with variables over finite domains. numerica extends this work by adding a variety of differential equation solvers to the mix  van hentenryck  1 . hooker et al. describe a technique for combining linear programming and constraint propagation  hooker et a/.  1 . 
　blackbox uses a translate/solve/decode scheme for planning and satisfiability  kautz and selman  1 . zeno is a causal link temporal planner which handled resources by calling an incremental simplex algorithm within the plan-refinement loop  penberthy and weld  
1 . the g r a p h p l a n  blum and furst  1  descendant ipp has also been extended to handle metric reasoning in its plan graph  koehler  1 . sipe  wilkins  1  and oplan  currie and tate  1  are industrial strength planners which include resource planning capabilities. two recent systems address the metric planning problem using compilation to integer programming  kautz and walser  1; vossen et a/.  1 . 
1 	conclusions and future work 
lps at is a promising new technique that combines the strengths of fast satisfiability methods with an incremental simplex algorithm to efficiently handle problems involving both propositional and metric reasoning. this paper makes the following contributions: 
  we defined the lcnf formalism for combining boolean satisfiability with linear  in equalities. 
  we implemented the lpsat solver for lcnf by com-bining the relsat satisfiability solver  bayardo and schrag  1  with the cassowary constraint reasoner ibadros and borning  1 . 
  we experimented with three optimizations for lpsat: adapting the splitting heuristic to trigger variables  adding random restarts  and incorporating learning and backjumping. using minimal conflict sets to guide learning and backjumping provided four orders of magnitude speedup. 
  we implemented a compiler for resource planning problems  lpsat's performance with this compiler was much better than that of zeno  penberthy and weld  1 . 
　much remains to be done. there are many ways we could improve the compiler: improving its runtime by optimizing exclusion detection  exploring new exclusion encodings  optimizing the number of constraints used for influences  and improving our handling of conditional effects. in addition  we wish to investigate the issue of tuning restarts to problems  including a thorough investigation of exponentially growing resource limits. it would also be interesting to implement an lcnk solver based on a stochastic engine. we hope to add support for more expressive constraints by adding nonlinear solvers. 
