ing and optimizing: a transformational approach 
jack mostow and armand e. prieditis* 
department of computer science 
rutgers university 
new brunswick  nj 1 
　
abstract 
we present an implemented model for discovering a class of state-space search heuristics. first  abstractions of a state-space problem are generated by dropping information from the problem definition. an optimal solution path for any such abstracted problem gives a lower bound on the true distance to the goal. this bound can be used as an admissible evaluation function for guiding the base-level search. moreover  if the abstracted goal is unreachable from an abstracted state  the original state can safely be pruned. however  using exhaustive search to evaluate the abstracted problem is generally too slow. therefore  optimization is used to speed up the computation of the lower bound  or solvability test   for example by factoring the abstracted problem into independent subproblems. we analyze the conditions under which the resulting heuristic is faster than brute force search. our implementation  named a b s o l v e r   has several general transformations for abstracting and simplifying state-space problems  including a novel method for problem factoring. a b s o l v e r appears to be the first mechanical generator of heuristics guaranteed to find optimal solution paths. we have used it to derive known and novel heuristics for various state space problems  including rubik's cube. 
　　*the research reported here was supported in part by the defense advanced research projects agency  darpa  under contract number n1-k-1  in part by the national science foundation  nsf  under grant number d m c 1  and in part by the center for computer aids to industrial productivity  caip   an advanced technology center of the new jersey commission on science and technology  at rutgers university  piscataway  new jersey. the opinions expressed in this paper arc those of the authors and do not reflect any policies  either expressed or implied  of any granting agency. we thank saul amarel  tony bonner  alex borgida  christina chang  jan chomicki  william cohen  mukesh 
dalai  richard korf  michelle kraus  pat langley  sridhar 
mahadevan  tom mitchell  stan raatz  lou steinberg  chris tong  and bob webber for their helpful comments. 
1 	introduction 
finding optimal  least cost  solutions to large statespace problems is generally intractable without good admissible heuristics  evaluation functions that return lower-bound estimates of distance to goal . w h e n coupled w i t h search algorithms that ensure optimality  like a*  nilsson  1  or iterative-deepening a*  ida*  
 korf  1a   such heuristics can reorder the search so that solutions are found much earlier. they can also reduce search by pruning states that lie more than a specified distance from the goal. this distance may be the exact solution length for problems where it is known a priori  an upper bound on acceptable solution length  
or just infinity  in which case the predicate tests whether the goal is reachable at all from a given state. 
   however  good admissible heuristics can be hard to find. for example  after extensive study  k o r f was unable to find a single good heuristic evaluation function for rubik's cube  korf  1b . he concluded that  if there does exist a heuristic  its form is probably quite complex.  
   the long-term goal of our research is to develop a system that can discover good admissible heuristics automatically  or at least with less user effort than discovering them by hand. the main contribution of this paper is a model for discovering such heuristics  and its partial implementation in a system called a b s o l v e r . we next describe how it works  and then evaluate it as an explanatory model  as a generative model  and as an automatic discovery engine. 
1 	a b s o l v e r 
our approach  illustrated in figure 1  derives admissible heuristics from abstractions of a state-space problem. a b s o l v e r is initially given a strips-like representation of a problem class. the distinction between a problem class and a problem instance is important because the effort of discovering a heuristic can be amortized over all instances of the problem class. 
   a b s o l v e r generates abstractions by dropping information from this description via a series of abstracting transformations chosen from a catalog. an optimal solution path for any resulting abstracted problem gives a lower bound on true distance to goal. this lower bound can then be used as an admissible evaluation function 
　

1 	machine learning 
　
1
	1 	using heuristics 
　
in total time 1 n  . 
　if we use the cartesian representation  we can obtain further speedup by applying drop .precondition to xloc in the yrnove operator and yloc in the xmove operator  and factoring into separate subproblems for the x and y dimensions. the resulting problem has 1 - 1 independent subproblems  one for each tile and each dimension. for example  the first subproblem has the goal xloc a  1  and the restricted operator xmove a  x  x' . each subproblem has a search space of size n  corresponding to the number of columns  or rows . thus the total time to evaluate manhattan distance is reduced to 1 n1 . in comparison  the standard closed-form formula for manhattan distance takes time o n1   the number of tiles. 
1.1 	testing factorability 
　the factor transformation partitions the goal into mutually independent sets of subgoals  and identifies the operators relevant to each set. the independence property ensures that the sum of the optimal solution costs for achieving each set is optimal for achieving their union  and is therefore admissible. 
　thus in order for factor to be practical  we need an efficient way to check that two sets of goals  g1 and g1  since the cost-effectiveness of heuristics derived by absolver is generally difficult to predict  they must be evaluated empirically. absolver's performance element inputs an initial state  a problem to solve  and optionally a heuristic. the problem is represented as a list of one or more subproblems  each consisting of a subgoal and a set of operators with which to achieve it. the ida* search algorithm is used to solve each subgoal  guided by the heuristic  or breadth-first if none is given . 
the heuristic is represented as an abstract problem. 
it is evaluated by recursively invoking the same search procedure on the abstract problem and returning the length of the optimal solution. thus the computation of the heuristic can itself be guided by a hierarchy of successively more abstract problems. 
　to illustrate  consider the  x-y heuristic   which is derived by factoring an abstracted cartesian representation of the eight puzzle into two subproblems  one for each dimension. however  instead of dropping the blank predicate to achieve factorability  the drop-precondition transformation is used to drop information about the x dimension from the subproblem for the y dimension  
　
and vice versa. in effect  each subproblem projects the puzzle onto one dimension. thus a horizontal move is allowed only into the column containing the blank  and a vertical move is allowed only into the row containing the blank. x-y is therefore more accurate than manhattan distance  which ignores the blank completely. 
　although x-y yields a base-level branching factor of only 1 for the eight puzzle  on a set of 1 random instances   it requires a considerable amount of search to compute. this search can be guided by manhattan distance. unfortunately  even with such guidance the overall search time turns out to be about six times slower than using manhattan distance alone. it remains to be seen whether additional optimizations can make xy better than manhattan distance  which is the best known heuristic for eight puzzle. 
1 	evaluating absolver 
we now evaluate absolver from three perspectives: first  as an explanatory model that can rationally reconstruct existing heuristics  thereby verifying admissibility by construction; next  as a generative model  helpful for suggesting new heuristics; and finally  as an automatic 
discovery 	engine. 
1 	absolver as an explanatory model 

an explanatory model should be evaluated by its generality and coverage. a general model applies to a wide class of domains. within that class  a good model covers a large proportion of the phenomena to be explained. we tested absolver's generality by applying it to several puzzle domains. we tested its coverage by trying to rederive all published heuristics for three of them: the eight 
1 	machine learning 
pussle  towers of hanoi  and mutilated checkerboard. the results are summarized in table 1. 
　this evaluation simultaneously tested the model at three different levels of specificity. first  it tested the generality and coverage of the particular catalog of transformations across several domains. since we knew our initial catalog was incomplete  we were also interested in identifying useful new transformations. in fact  these problems served as our  training data  for developing the catalog in table 1  so they should not be taken as a test of its coverage  though they do demonstrate the generality of the transformations used in multiple domains. second  it tested the problem representation language  since some heuristics might not be derivable in that representation. finally  it tested the general model of abstraction plus optimization  which might fail to explain some heuristics. 
　what does it mean to rederive a heuristic  clearly  it is not necessary to rederive specific code. on the other hand  functional equivalence alone is insufficient  since an abstraction-based heuristic computed using search may be much less efficient than the original version. we therefore compared their computational complexity. 
　the results can be summarized as follows. we were able to rederive functional equivalents with absolver for 1 of the 1 published heuristics  though with varying efficiency relative to the original versions. 
　the derived versions of # of misplaced tiles  # of misplaced disks  and colored squares were all computationally equivalent to the originals. 
　three of the derived heuristics were less efficient than the original versions  owing to limitations in the chosen problem representations and deficiencies in the catalog of optimizing transformations. the derived manhattan distance was slower by 1 n   for n by n puzzles  because it uses search to compute the number of moves needed to get from row % to row i''. we have derived the closed form expression  i - i'| on paper  but only by exploiting the numerical relationships implicit in the adj relation to induce a recurrence relation. implementing this derivation in absolver would require a more sophisticated representation and an optimizing transformation capable of inducing the recurrence relation. similarly  the derived versions of n-maxswap and n-swap are slower by 1 n1!  because they search for an ordered permutation instead of counting the number of swaps performed by an efficient sorting algorithm. a challenging direction for future work is automatically recognizing when an abstracted problem can be solved by adapting a known algorithm. 
two of the heuristics have the wrong form: sequence 
score is non-admissible  and alternating disks is a heuristic on moves  not states. 
　euclidean distance breaks our model in an interesting way  because it comes from adding knowledge about geometry. our current model only generates abstractions by dropping information from the problem definition. 
　the blocking disks heuristic is defined only for states in which two of the pegs are empty. it was originally derived by analyzing a recursive algorithm for towers of hanoi to compute the exact number of moves required. 
　
ing each pentomino once-or to prove that it cannot be done. when we attacked this problem  we believed it was still open. after proving it impossible  we found a published proof that relies on remarkably similar techniques  golomb  1 . 
　
how good is our model at suggesting new heuristics  table 1 attempts to answer this question for several domains. for each of these domains only  good  heuristics are listed; several other heuristics were derived but appeared worse in terms of overall search time. 
　we were able to discover the first known  non-trivial  admissible heuristic for the 1x1 rubik's cube. for this problem  we started with a represention that partitions the cubies into center  edge  and corner ones. dropping the edge predicate allows the operators to be factored into those that affect corner cubies and those that affect center cubies. 
　how good is this center-corner heuristic  for 1 problems randomly scrambled to depth 1 or less  it reduces the branching factor from 1  for breadth-first search  to 1. the heuristic is computed by solving the two subproblems. the subproblem for the six center cubies has three operators and is cheap to solve. the subproblem for the eight corner cubies is equivalent to a 1x1 version of rubik's cube. since our prolog implementation of ida* only expands about 1 states per second  we have not yet evaluated the center-corner heuristic on deep random solvable instances of the cube. 
　we were also able to derive some new admissible heuristics for the eight puzzle. we have already described the x-y heuristic  which is more accurate than manhattan distance. similarly  # out of column + # we started with a problem representation that partitions the squares into those in the interior of the jagged square  those bordering the outer edges  and those bordering the inner  hole.   we later added  corners  . next  we applied the count transformation to each partition. unfortunately  it turned out that the resulting admissible heuristic was not strong enough to prove the problem impossible  i.e.  the abstracted initial state appeared solvable. we then hand-generated every possible placement of the four most constraining pentominoes; taking symmetry into account  there were only a dozen or so. finally  we executed exhaustive search in the abstract space on each of these partial layouts to show the impossibility of completing any of them. 
　table 1 also lists novel heuristics derived for some gps domains  ernst and goldstein  1 : fool's disk  instant insanity  and think-a-dot. 
　one lesson of these examples is the frequent importance of clever partitioning in the initial problem representation: the border and interior squares in jagged square; the corner  center  and edge cubies in rubik's cube; and the red and black squares in mutilated checkerboard. at present such partitioning is supplied as part of the initial representation. 
1 	a b s o l v e r as an a u t o m a t i c discovery engine 
as an automatic discovery engine  absolver must be evaluated by the tractability of finding good heuristics 
　
in the space defined by the catalog of transformations. there is a tradeoff between tractability and coverage  since enlarging the catalog expands the space of derivable heuristics but makes it costlier to explore. 
　the full space defined by absolver's current catalog of transformations is far too huge to explore exhaustively. for example  the drop transformations alone can be applied to any combination of subgoals and operator preconditions. for our nine-operator representation of the 1x1 rubik's cube  there are 1 subgoals and 1 preconditions: the number of combinations is astronomical. 
　as a compromise between coverage and tractability  we implemented an exhaustive generator using the coarser-grained drop-predicate as the only abstracting transformation and factor as the only optimizing transformation. for the eight puzzle  it took this generator a few cpu seconds to test all combinations of dropped predicates. for the three-predicate  single-operator representation  the only combinations with more than one factor yielded manhattan distance and # out of place tiles  subject to the efficiency limitations discussed in section 1 . the five-predicate  two-operator cartesian representation yielded more heuristics: horizontal distance  vertical distance  manhattan distance  their sum   analogs of all three for distance of blank  # out of column + # out of row  and blank out of column + blank out of row. for our three-predicate  nineoperator representation of rubik's cube  the generator took over five hours  since our independence test for factorability currently takes time quadratic in the size of the largest transitive closure formed by the symbolic backchaining step described in section 1.1. somewhat surprisingly  there is only one factorable combination- the center-corner heuristic. 
　to escape from the coverage-tractability tradeoff  we must use a better strategy than exhaustive generate-andtest to find efficiently computable abstractions. we arc investigating the use of means-ends analysis to identify which abstracting transformations will enable optimizations. in particular  if we can efficiently identify which applications of dropsubgoal and drop precondition will make it possible to apply factor  we will be able to find the factorable abstractions without generating and testing all combinations of dropped goals and preconditions. 
1 	relation to previous w o r k 
figure 1 relates several previously reported properties that can hold between abstractions and heuristics  nilsson  1  pearl  1 . 
　the relation of certain abstractions to state-space search heuristics was first suggested by guida and somalvico  guida and somalvico  1  and gaschnig  gaschnig  1   who described how such heuristics might arise by using the depth of solutions in edge supergraphs of the original state-space search graph as lower-bounding heuristics. such edge supergraphs naturally arise from dropping operator preconditions. later  valtorta  valtorta  1   pearl ipearl  1   and kibler  kibler  1  each proved that abstractions such as those resulting from dropped operator precondi-
1 	machine learning 

tions would guarantee monotone  and hence admissible  heuristics. our abstracting transformations extend the edge supergraph model of abstraction to include nodemerging. 
　valtorta proved that using a dropped-precondition abstraction directly as a heuristic will always expand more total states in the two spaces than simply using breadthfirst search in the base space  valtorta  1 . pearl later pointed out that this liability might be overcome by factoring the abstracted problem into independent or serializable subproblems  which might be possible even when the original problem is not factorable  pearl  1 . factoring reduces the total search complexity from the product of exponentials to their sum. though elegant  these methods were not implemented: the abstracting and optimizing transformations were performed by hand. 
　some work has been done on automatic generation of abstractions in planning  sacerdoti  1  knoblock  1  unruh et a/.  1   but not for the class of admissible heuristics addressed here. for example  abstrips used abstract solutions as skeletons for base solutions  which tends to reduce planning time but can produce sub-optimal plans. furthermore  abstrips discards abstract solutions that cannot be refined into more concrete ones. in contrast  absolver uses abstractions solely to compute lower bounds and check solvability  thereby not discarding potentially valuable information from non-refinable abstract solutions. other systems have been reported for serializing gps subgoals  ernst and goldstein  1   but they do not guarantee the optimally of the solution paths. 
　in sum  while a few techniques have previously been reported for abstracting and simplifying state-space problems  absolver constitutes a novel attempt to automate  integrate  extend  and evaluate these tech-
niques. 
1 	conclusion 
absolver appears to be the first mechanical generator of state-space heuristics guaranteed to find optimal solution paths. it achieves this admissibility property by decomposing the problem of discovering heuristics into generating abstractions and optimizing their evaluation. absolver can be viewed at more than one level. 
first  its transformational model provides a unifying framework for characterizing and exploring a broad class of admissible heuristics and understanding when they are actually useful. second  we have grounded the model by implementing a catalog of abstracting and optimizing transformations and using them to derive a number of heuristics. third  we have demonstrated an automatic generator that uses two of these transformations to find efficiently computable heuristics. 
　as an explanatory model  absolver's coverage is encouraging in one sense but deficient in another. while its small catalog of abstracting transformations is adequate to derive functional equivalents for many of the published heuristics we looked at in several puzzle domains  its optimizing transformations are too weak to compute some of them as efficiently as the originals. we do not claim the catalog is complete  and in fact expect it to grow as we try to improve evaluation cost  derive more heuristics  and explore other domains. the few heuristics that did not match absolver's underlying model suggest interesting directions in which to extend it. 
　as a generative model  absolver has yielded some novel heuristics  notably the first non-trivial admissible heuristic for rubik's cube  and an interesting eight puzzle heuristic that is more accurate than the best known  though somewhat less cost-effective. although all the transformations reported here are fully implemented  the techniques used in absolver are useful for generating heuristics even when applied by hand. in fact  that is how we actually discovered most of the novel heuristics  and how we proved the impossibility of a published layout problem we thought was still open. subsequent implementation of the derivations served to verify their correctness and to expose the use of additional techniques. thus the implementation is actually of secondary importance for discovering new heuristics  except to the extent that it makes the techniques easier to apply. 
　as an automatic discovery engine  absolver is limited by the intractability of exploring the space generated by its full catalog of transformations. its exhaustive generator uses only one abstracting transformation and one optimizing transformation  thereby achieving tractability at the cost of coverage. nonetheless  it finds interesting heuristics in more than one domain. 
of the many possible directions for extending ab-
solver  two seem especially compelling. first  meansends analysis may make it possible to explore a richer space of possible heuristics automatically. second  absolver's sensitivity to the initial problem representation  and the importance of clever partitioning in discovering novel heuristics  suggest that a few transformations for representation-shifting might significantly enrich the space of discoverable heuristics. 
