 
     the complexity of finenciel decision-making problems is such that automation of the reasoning process by conventionel approaches is often incomplete or inadequete. this paper describes credex. s knowledge-based system which is being developed to assist bank-loan officers in interpreting end evaluating the activities of firms applying for a loan. credex is written in snark. it integrates shallow and deep knowledge through e multi-level structure driven by e mete-expert. the system builds on psychological research on informetion processing and handles risk assessment through a combination of four multi-attribute models. 
i introduction 
this paper describes e knowledge-based system. 
credex  credit expert  which is aimed et helping bank-loan officers assess the degree of risk inherent to small business loans. 
     a variety of knowledge-based systems have been developed to model such finencial decisions as evaluation of clients' allowances for bad debts  e.g. dungan 1 . estate plenning  e.g. michaelsen 1 . interpretation of ratios from a company's income statement and balance sheet  e.g. kerschberg end dickinson 1; aucoin and micha 1 . more recent systems developed by banking institutions and consulting companies include finenciel advisor consists of simple heuristics end experientiel rules which allow financial experts to accept or reject a loan request.  deep  knowledge corresponds to a more detailed and deeper understanding of those characteristics of the applicant firm which determine the level of risk involved in granting the requested loan. as indicated by fink  1 . deep knowledge 
 ... seems to require a different approach to ntation than a set of functional primitives.  
　　a good deal of research in cognitive psychology end decision science suggests evidence for what might be called phased evaluation strategies. a phased strategy is one in which an initial phase of evaluating the sub-domains of the applicent firm is followed by a secondary choice phase where a combination of multi-attribute aggregation rules are applied  hwang and yong 1: brehmer et al 
1 . 
　　the unique feature of credex are its multi-stage deduction end judgment process driven by a mete-expert and its use of multi-attribute informetion processing models. 
ii credex architecture overview 
credex is composed of three types of independent experts  see fig. 1  : 


 palladien . plan power  apex . personal financial 
planner 	 arthur 	d. 	little . 	lending 	advisor 
 syntelligence . just to name a few  see friis 1 . 
     although these models provide considerable insight into the financial eveluetion problem  they heve not fully addressed some of the difficulties encountered in domeins requiring complex risk assessment  hart 1: reboh and risch 1 . whereas existing models have traditionally formalized uncerteinty assessment through the use of probabilistic approaches  buchanan and shortliffe 1: duda and reboh 1 . experience has proven that domain experts are usually unable to provide certainty factors  nisbett and ross 1; buchanan and shortliffe 1. rather they seem to use information processing rules that depart from the probabilistic research paradigm  einhorn and hogarth 1: kahneman et al 1 . 
     another difficulty has to do with the fact that loan officers  es well as any human experts  combine two different kinds of knowledge  chandrasekaran and mittal 1 .  shallow    surface  knowledge 
1 	knowledge representation 

. the experiential experts which infer the weaknesses and strengths of each function or subdomain of the applicant firm and generate  elementary  risk scores: 
. the judgmental experts which use multi-attribute information processing models to first aggregate the  elementary  risk scores for each subdomain and then yield an overall risk score for the firm requesting a loan; 
. the meta-expert which controls the whole reasoning process. 
     in its curent form. credex contains four independent  experiential experts corresponding to the commercial  production and operations  human resources and financial functions  respectively. to shorten the interactive process with the user  the meta-expert requests only basic information about the company. more specific information is asked by each experiental expert whenever needed in the reasoning process. 
ill uncertainty handling 
     contrary to mycin-like systems where certainty factors are used  uncertainty is formalized in credex as a degree of risk measured on a five-point interval scale  very high. high  average  low. very low . as indicated earlier  loan officers find it difficult to give certainty factors as well as other types of coefficients which have been suggested in the literature  e.g. farreny and prade 1; shafer 1 . in credex. the level of risk involved in each loan requested is determined through a multi-step process using the factual information provided by the experiential experts: 
. each major function or subdomain j of the company is assigned a weight gj on a seven-point interval scale  from  very important  to  not really important  . this weight measures how important the function is perceived to be in making up the overall riskiness of the loan. the gj's are either interactively given by the user or inferred by the meta-model as a function of the bank policy b and the loan officer l: gj - f b.l . 
. within each function j. weights wij are assigned to the function's characteristics by the weighting rules of the experiential expert. these weights represent the perceived importance - on a three-point interval scale - of each characteristic in determining rj. i.e. the partial risk attached to function j. 
. each function can be further broken down in subfunctions for which elementary risks rkj can be calculated following the same procedure as above. to illustrate  the commercial function can be decomposed into such subfunctions as the products and clients functions. similarly  each subfunction can be further analyzed at a more detailed level  say. at the level of each product. 
iv knowledge representation 
     credex is a rule-based system. it uses snark  lauriere 1  as inference engine. the knowledge is represented as first-order predicate logic. the rule bases of each expert are expressed through binary relations of the form r x  op  y . where  x  and  y  are instanciated by the facts of the working memory and then propagated in the conclusions of the rules. this formalism makes the working memory isomorphic to a semantic network where inheritance properties  default values  transitivity are defined by rules. in the working memory objects and associations between objects are represented as triples  object relation value  where  relation  and  value  can also be objects. this representation is close to the schema one of srl  fox 1 . the simplicity of the representation results in a very high-speed interpreter. furthermore. snark allows metaknowledge primitives to dynamically activate  hold back and examine tasks considered as subsets of rules. demons can be used to give absolute priority to a task or to divert flow of control when exceptional conditions arise. 
a. the meta-expert 
　　the meta-expert  lenat et al 1  has been designed to direct the entire problem-solving process. more specifically  it manages the agenda of tasks  creates the data structure used by experts to communicate  interacts with the user and stops the reasoning process whenever the information sought has been obtained. figure 1 shows part of the semantic network used by experts for exchanging informations. this network involves n registers  one for each function. each register contains the following relations: weight of the function and a measure of the partial risk attached to it as well as the elementary judgments related to the subfunctions. it is dynamically updated during the reasoning process of the experiential experts and aggregated by the judgmental experts. 

　　figure 1 depicts the operations scheduled by the meta-expert using its metaknowledge. knowledge of the firm's components  functions  subfunctions...  is represented as a hierarchical structure. the experiential experts and the correspondig tasks are activated on the basis of their weights gj - the most important task being triggered first. the judgmental experts are activated following activation of the corresponding experiential experts. some of the tasks are decomposed into subtasks to allow focalisation of the reasoning process. the meta-rule which controls the agenda is a  super-demon  which has the top priority whereas the activation/disactivation rule is a local  anti-demon   bourgine and lauriere 1   i.e. a rule which is used only when no other task-related rules can be triggered. 
	pinson 	1 


figure 1. operations graph 
b. experiential experts 
     each experiential expert has its own knowledge base. its working memory contains the description of the applicant firm's functions in the form of a semantic network. the interesting feature of credex is that it allows to analyze time-varying data over a flexible period of time. for example  the financial ratio debt/sales called ff/caht is represented as: 

     four different kind of rules are used: a  weighting rules:  b  computation rules for deriving numerical values: c  temporal rules for inferring the evolution of the firm performance ratios: and d  assessment rules for arriving at the firm's strengths and weaknesses. 
c. judgmental experts 
     the judgmental experts combine the elementary risk scores fkj to yield a partial risk for each function  and then an overall risk. in credex. four types of judgmental experts are available to the mete-expert to select from. they are the linear additive model. the lexicographic model  the conjunctive model  and the disjunctive model. these models have received the most attention in the psychological literature on decision theory  attitude formation and clinical judgment  hogarth. 1. each model implies a completely different evaluation process: 
1 	knowledge representation 
  in a linear additive model  weights are assigned to the importance of each attribute and ratings assigned to the entity under study according to how satisfactorily it possesses this attribute. all the attribute values are collapsed into a single score by some additive weighting function. 
. the lexicographic model assumes that the analyst considers the attributes in a sequential fashion. the attributes are first ordered in importance. the analyst first looks at the most important attribute. if he/she cannot reach a conclusion  he/she considers the second most important attribute  and so on. 
. the disjunctive model is called a maximum evaluation function since the entity is judged on its best ability  regardless of its other attributes. in other words  the evaluation of an entity depends on its maximum attribute value. applied to risk analysis  the model would mean that the evaluation is completed as soon as a very low level of partial risk is inferred. 
. the idea behind the conjunctive model is that a loan  so as to be accepted  must have a certain maximum value on each relevant attribute. this implies a multiple cutoff procedure and a dichotomy 
between acceptable and non-acceptable loans on all attributes. in order to obtain a degree of risk  it is necessary to combine the conjunctive model with the linear weighting model. 
　　psychological research on usage of these different information processing models suggests the existence of task and individual difference factors  bettman 1: hogarth i1  such as time pressure  task familiarity  reliability of data  amount of information available. in the current version of credex  the meta-expert chooses among the four information processing models on the basis of the following criteria: amount of money requested  reliability of data available and familiarity with the applicant firm. more research on this is under way. 
v conclusion 
credex exhibits a way of providing a flexible control over the management of different kinds of experts that embody the diverse types of knowledge about financial risk evaluation problems. with the metaexpert  numerous control strategies  obtained from different analysts or banks  can be integrated into a single system. the concept of phased evaluation strategy as well as the use of multi-attribute information processing models allow to handle uncertainty and contradictory data for risk assessment in a completely declarative way. future work will include efforts to generalize the analysis on time-
varying data. also under scrutiny are top-level control strategies with respect to exactly when to use each of the judgmental experts. it is a difficult problem since it involves the question of which information processing strategies ere actually used rather than reported - by individuals when confronted with evaluation tasks. empirical research on this issue is sparse  and more theoretical work is obviously called for. 

