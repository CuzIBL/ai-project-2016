 
a number of heuristics have been developed which greatly reduce the search space a learning program must consider in its attempt to construct hypotheses about why a failure occurred. these heuristics have been implemented in the handicapper system  salzberg 1  atkinson & salzberg 1   in which they significantly improved predictive ability while demonstrating a remarkable learning curve the rationalization process has been developed as a verification system for the hypotheses suggested by the heuristics. rationalization uses the causal knowledge of the system to ascertain whether or not a hypothesis is reasonable. if the hypothesis is not supported by causal knowledge  it is discarded and another hypothesis must be generated by the heuristics. the resulting learning system  by integrating causal knowledge with heuristic search  has quickly gone from essentially random predictive accuracy to a system which consistently outperforms the experts at predicting events in its problem domain. 
1. introduction: why we need heuristics in inductive learning 
part of this work was dona at yale univtrsity under tht support of contract f1-k-1 of tht u.s. air force office of scientific rasaarch. 　　　inductive learning systems are often faced with a common problem  which is that of how to search a 
　　　large space efficiently to find a new rule that will improve their performance  mitchell 1  michalski 1 . in particular  this paper is concerned with systems that predict events in a given domain  and revise their rules whenever those predictions fail. the problem can be stated succinctly as: given that a set of events s occurred  that the system predicted a result r1  and that the actual result was r1  how can the system revise its own rules so that  in the future  it will predict r1 when it sees s or something similar to s  the reason this rule-revision process is difficult  as has been pointed out a number of times  e.g.  soloway& riseman 1  salzberg 1   is that the number of potential new rules can be astronomical if the domain is even mildly complex. any event or combination of events in s could be hypothesized as the cause of the mistaken prediction. if the set of events s includes only ten items  over 1 possible hypotheses exist  and as s increases  the number of hypotheses increases exponentially  to be precise  if n is the number of events in s  the number of hypotheses is therefore al needs to apply its own special techniques to the problem of narrowing down the search space. one of the most well-known and most successful techniques for controlling search is through the use of heuristics  lenat 1   and one purpose of this paper is to describe some new  general heuristics that proved to be remarkably useful and efficient in an inductive learning system. these heuristics have been suggested in some instances by psychological research which points out certain heuristics that people commonly use when faced with the task of understanding a complex problem. the task of the learning system  handicapper  is to predict the winners of thoroughbred horse races. in earlier papers  e.g.  atkinson & salzberg 1   this system was described as one which kept track of horses and made predictions based on similarities between new horses and ones in its memory. the system has now been completely re-written and relies on an episodic memory which contains races it has seen previously  rather than horses. because predictions are based on similarities between races  and because races have a large number of features  about 1  which can contribute to judgments of similarity  the number of possible hypotheses about what rules to change after a 
　　　failure is much larger than in the earlier system. therefore the heuristics currently used by 
handicapper had to be implemented before the system could perform even tolerably well. as we shall show  the system with its heuristics in place performs much better than that. 
　　　the second major point of this paper is the introduction of a new technique  one called rationalization. rationalization is an integral part of the learning algorithm of handicapper. its purpose is to provide a check on the hypotheses generated by the heuristics in the system. after a hypothesis is generated  it is passed to the rationalization module which checks the system's causal knowledge  this knowledge is hand-fed to the system  in an attempt to explain why the new hypothesis might be a reasonable correction to the system's developing model of the domain. rationalization ascertains  via forward inferencing  i.e.  forward in handicapper  but not necessarily in any system   that if the new hypothesis 

1 	s. salzberg 
had been present prior to the incorrect prediction  a correct prediction would have been made  and it also ascertains that this new hypothesis is consistent with what the system already knows. if a hypothesis is rejected by rationalization  then control is passed back to the heuristic search routines  which must then find a 
new hypothesis. this loop continues until a reasonable explanation of the failure has been found and added to the knowledge base. 
1. the heuristics 
first  let me just list the heuristics developed for 
handicapper. a number of the heuristics in the list below have been designed but not implemented  and they are marked n.i. all will be explained in the text that follows. 
1. unusualness 
1. inconsistency 
1. uncertainty 
1. conservatism 
1. strength adjustment 
1. faultiness n.i  
1. occam's razor  n.i.  
1. ambivalence  n.i.  
1. proximity 
an example application of each heuristic will be given along with its explication  and  wherever appropriate  evidence for the psychological validity of the heuristics will be presented. 
1 unusualness 
　　　one of the first things that people look for when trying to explain an unexpected event is something unusual in the situation. unusual feature are simply features that do not occur as often as other features within a given context. the following example will help to illustrate. if  while i were sitting in my office  one of the window panes suddenly shattered  i would expect to find a rock or some other dense object that had hit it with considerable force. if no such feature  which my default causal model requires  were present to my senses  i would look for other unusual features. perhaps one of my office mates had just clapped his hands loudly - if that were the only unusual event just prior to the window's breaking  then i might have to give serious thought to whether or not it could have caused the window to break. if he clapped his hands together another time and another window broke  then i would begin to feel strongly that something about his clapping action was breaking the windows. to clarify this example a bit more  let me discuss for a minute what i meant above by the phrase  default causal model.  before using unusualness to locate a feature in the current scene which might have caused the window to break  i had to consult my knowledge of physical actions to see what actions normally result in broken windows. the body of knowledge which i call a default causal model is undoubtedly very large  but it can be organized so that searching it is very efficient. in this case  i would look at an entity in memory representing the action  glass breaking   and then trace backwards down whatever causal links i had attached to that entity to find possible causes.  the cause might also be found by looking elsewhere in a 
frame-like structure  minsky 1   if the processing model were using such structures.  if none of those causes were present in the current scene  then i would have to turn to my heuristics to find a potential cause. in the example above  i might have considered the possibility of a sonic boom after consulting my default causal model  although i would immediately discard it since i had not heard any loud booms when the window broke. having failed to find a match between the suggestions of my causal model and the realities of the scene  i would use heuristics to decide that the clapping of someone's hands  which occurred immediately before the window broke  might have been the cause. 
　　　unusualness is determined in handicapper by keeping statistics on how frequently every feature appears on any horse. in other words  the program keeps track of such things as how often the values of horses change  how often they get new jockeys  and so on. when a prediction fails  and the causal model cannot suggest an explanation  the feature of the predicted winner which is the most unusual is chosen as the first candidate to explain why that horse lost. likewise  the most unusual feature of the unexpected winner is chosen to explain why it won. the most unusual feature out of a set of feture is the one which occurs least often. if a horse or a race has a particularly unusual feature  according to some threshold   then  that feature will be chosen as a likely cause of the failure. in future races  if that feature appears again in a similar context  it will be monitored closely to see if the earlier hypothesis about it was correct. 
1 inconsistency 
　　　when a program uses a reasonably large set of feature and rules to make its predictions  as programs in real world domains often do  it is quite possible that it can use rules to support its predictions that are inconsistent with one another. in other words  two of the reasons for the same decision may be contradictory in some way  in which case it is possible that neither of the rules should have been used in the first place. a learning program must remember these inconsistencies when they arise and avoid making the same mistakes again. the argument could be made that such contradictions could be noticed beforehand and 

avoided. to notice everything of this nature  though  a program would have to check every possible interaction beforehand. with a large feature set  one does not want to have to examine how all features might conceivably interact: for one thing  it will often be the case that two features which are inconsistent will never appear together precisely because of their contradictory nature  and thus any time spent worrying about them is wasted. furthermore  if there are many feature  the amount of wasted work might be prohibitively expensive. it seems better  rather  to let prediction failures guide the emendations to rules and memory. 
　　　an example of inconsistency and how it is used in handicapper can be found in  salzberg 1 . in summary  that example describes how a horse with two good features lost  because the interaction between those features was bad. the horse in question was  1  dropping down in value  which is good because it means the horse will be competing against easier competition  and  1  recently bought by a new owner  which is usually good because the new owner must have seen something good in the horse to buy it. however  since the owner dropped the horse to a lower class of race soon after buying it  exposing himself to a financial loss  something must have been wrong with the horse  so despite the two good features  the horse 
lost the race. 
1 uncertainty 
　　　if you have to decide which of many features was responsible for a prediction failure  and you think your reasoning was sound in using each of those features  then another heuristic available for choosing one is the uncertainty heuristic. the uncertainty heuristic says to choose the feature you know the least about and assign responsibility for the failure to that feature. the amount you know about each feature depends  for example  on how many times you have seen it. the rationale for this rule is that if you do not know very much about a feature - if you know very little about what it causes  what causes it  what other features usually appear with it  etc. - then it is more likely that it caused something unexpected  i.e.  the prediction failure  than some other feature with which you are more familiar. the unusualness heuristic is based on a similar principle. 
　　　to illustrate  let's take an example. suppose the domain is the stock market  and the task is to predict the movement of stock in a high technology company. suppose further that the stock was predicted to increase 1 points  and that in fact it only increased 1 points. among the many features considered relevant to the prediction were:  1  the announcement of a new product by the company   1  the election of a new  
s. salzberg 1 
more conservative president of the u.s.  and  1  a steadily increasing market for the products the company had been producing. of these three factors   1  and  1  might be quite familiar  occurring with regularity in stock market analysis and having fairly consistent effects. on the other hand   1  only happens very infrequently: new presidents are only elected once every four or eight years  and only half of those  on the average  are more conservative than their predecessors. so although the business community  and the stock market experts in particular  might believe that a more conservative president should boost prices in high technology stock  perhaps because he will give more money to the defense industry   it is quite possible that the opposite will occur  or that  as in this example  the effect will not be as large as expected. the reason is that we were simply less certain about the effects of a new conservative president on stock prices because we were basing our knowledge on very few experiences. 
　　　features single out by the uncertainty heuristic  then  are chosen precisely because they have not been observed many times. it is possible for handicapper  after a feature has been assigned credit for a failure by the uncertainty heuristic  to observe that feature many more times and no longer be uncertain about it  but the first few times a feature is observed one cannot be certain whether or not its effects will recur consistently. 
1 conservatism 
　　　the conservatism heuristic says to choose the new hypothesis which requires the smallest changes to the domain model. this heuristic partly explains why ptolemaic astronomers preferred building epicycles to adopting copemican theory. for one thing  it is usually simpler and easier to make a modification to an old theory rather than start over with a new one  and often that is the correct approach. however  when too many modifications have already been made  the old theory starts to be so cumbersome that throwing it out makes explanations simpler  and that is the point where occam's razor  another heuristic  should apply. on the other hand  when you have a reasonably simple theory  you usually want to modifiy it slightly rather than start from scratch. as was pointed out to me  this heuristic is equivalent to  trusting the known  while some of the others are more like  distrusting the unknown.  look at the copernican model again  for example. after it was first suggested that the planets revolve in circles around the sun  evidence accumulated through the observations of tycho brahe that their motion was not circular. the correct solution  drawing upon the conservatism heuristic  was to retain the heliocentric model but to posit elliptical  rather than circular  orbits for the planets. that solution  in fact  was suggested  by johannes kepler  and future astronomers used the modified model. 

1 s. salzberg 
　　　this heuristic has its basis in psychological data on biases  e.g.  nisbett & ross 1   which show that people tend to cling to beliefs once they have formed them. much of the psychological data is designed to show that people cling to biases inappropriately  but as the example just given shows  the conservatism heuristic can be useful. in handicapper this heuristic is implemented as an  unwillingness  to throw out old hypotheses unless no simple modification is workable. for example  a horse may be predicted to win because its speed rating has increased for the last two races and it placed second its last time out. suppose the horse loses: the program could throw out its old beliefs about speed rating and recent performances  or it could modify those beliefs by making them weaker  or it could find entirely new reasons why the horse lost. the last is the preferred hypothesis formation technique  but when nothing new can be found  the program simply reduces the strength of the rules concerning speed ratings and recent performances. unless something happens which indicates that those rules were completely off base in the first place  the conservatism heuristic produces the most reasonable new hypotheses. a final note: over-reliance on this heuristic will result in hill climbing behavior  since small modifications to the current rule set will make a system hover around local maxima. 
1 strength adjustment 
　　　the strength adjustment heuristics  sah  are weaker than the heuristics described so far  because they do not narrow down the search space as much. however  they are useful in handicapper in conjunction with the other heuristics. there are actually two main rules included as part of the sah:  1  weaken features which were responsible for an incorrect match  and strengthen features which would have prevented the match; and  1  strengthen features which  if they had been stronger  would have resulted in a correct match  and weaken features which contributed to preventing the correct match. carbonell  carbonell 1  and hayes-roth 
 hayes-roth 1  use very similar heuristics as the bases for their learning algorithms. in fact  these heuristics are the basis of much of al concept learning work in general. what is meant by a  match  in the above statements can be explained as follows: for any new race  handicapper tries to find the best match of that event with a previous event  for a more detailed description of the weighting algorithm  see  salzberg 1  . predictions are made based on the outcome of the earlier event rule  1  above comes into play when an event is matched that predicts the wrong outcome: if the match had not occurred in the first place  another  perhaps better  prediction would have been made. rule  1  applies when an event was present in episodic memory which would have led to the right prediction  but the new event failed to match it because the features the two events shared were not considered important enough. any system that bases its learning on being reminded of events in episodic memory has to worry about how one event matches another; finding exactly the right event is the trick that will allow the system to make the best possible predictions. 
1 faultiness 
　　　one common phenomenon among people trying to figure out how some domain or object works is to place the blame for mistakes on things that have caused problems before. in other words  the faultiness heuristic says to choose the feature which was at fault most recently or which is at fault most often. this heuristic could also be known as the  it always breaks on mondays  heuristic  that is  the tendency we all have to attribute the blame to some feature we thought might have been at fault the last time something went wrong. there are times when this rule is wrong  of course  but there are also times when it is extremely useful at pointing out the precise problem with something while allowing you to ignore other features. 
1 occam's razor 
       occam's razor is an old scientific heuristic  with a sound basis in human behavior. this heuristic claims that  given a choice among explanations  one should choose the simplest one  which usually means the one with the fewest conjunctive conditions  this rule often works in opposition to the conservatism heuristic . there are many famous examples of this heuristic  most of them from the history of science  and probably the most famous one is the defeat of the ptolemaic  geocentric  model of the solar system by the simpler  more elegant copemican  heliocentric  model. particular details of the former theory  such as epicycles  which were necessary to explain the retrograde motion of the planets in the geocentric model  were unnecessary in the heliocentric model. in fact  epicyclic movement was nicely explained by the copemican model without any more complicated motion than the revolution of the planets around the sun.  actually  this is not quite true. the copemican model was originally more complicated than the ptolemaic model  and it was kepler who simplified things  by using elliptical orbits.  
1 ambivalence 
　　　ambivalence is a heuristic which says to look for the rule with the weakest or most ambivalent basis  here again the idea is to  distrust the unknown  . for example  i once predicted that an opponent of mine was bluffing in a poker game  based on three factors which any experienced player will no doubt recognize: 
 1  the cards he had showing indicated that it was unlikely he had a good hand  the game was stud poker ;  1  the cards i had showing were weak enough to lead him to believe that he might win  and  1  he avoided my eyes when i looked at him. it turned out that he was not bluffing  and i explained the failure by 
 1  above. of the rules listed   1  is the most ambivalent - the failure to make eye contact might mean that someone is bluffing  but it might also mean that he has a good hand and he does not want to give it away with his eyes. 
1 proximity 
　　　there is a wealth of psychological data pertaining to the proximity heuristic  summarized and explicated in  nisbett & ross 1  . in fact  this heuristic is really two heuristics  the temporal proximity heuristic and the spatial proximity heuristic. the idea behind them both is the same: when looking for a place to assign responsibility for some event  choose the event closest in time  and prior  or closest in space  at the time of the event  to the event itself. 
　　　for example  spatial proximity is most useful when questions of physical causality are involved. if some physical object behaved in an unexpected way  then perhaps you should look for some other physical object near it as the cause. when you notice a scratch on your car door in a parking lot  the first thing you are likely to do is to look at the car next to you. if that car is parked closely  and if its door is in a position to indicate that it would have hit yours where the scratch is  then you attribute responsibility to the person who last opened the door of the other car. if some paint from the other door has scraped off onto yours  and the colors match  then you will probably feel quite certain that the other car has caused the scratch. spatial proximity is a heuristic that is used often not only because it works  but also because it is easy to use. it is only natural when something unexpected happens for a person to look around for possible causes. objects in physical proximity to the unexpected event are likely to be the first candidates in the search for explanations. 
　　　meteorologists' attempts to explain tornadoes are a classic example of the joint use of the temporal and spatial proximity heuristics. the actual causes of tornadoes are not yet well understood  so groups of meteorologists in texas and oklahoma  part of the u.s.  tornado belt   spend their time chasing around storms to find out exactly what happens before a tornado. they keep track of all the meteorological cues they can while on a  hunt   including visual observations as well as measurements of pressure  temperature  wind speed and direction  humidity  and 
s. salzberg 1 
more. they hope that by tracking all the events that fit some relevancy criterion which occur in the proximity  temporal and spatial  of a tornado  they will be able to isolate the set s  of events that cause the tornado. since they do not have a good causal model of how a tornado develops  the temporal and spatial proximity heuristics are the best tool they have for focusing their observations. 
1. which heuristic to use first  
　　　the question of how to decide the best order in which to apply these heuristics  in a given domain after a particular prediction failure  remains an open problem. my suggestion  and the implementation i have chosen for handicapper  is to apply them in order of usefulness. the advantage of this approach should be clear: the most useful heuristics are the ones which most often suggest a good hypothesis for why a failure occurred  while less useful heuristics will suggest hypotheses not quite as good  where  good  means they frequently make correct predictions in the future . for the current implementation  i was guided by experts in deciding which heuristics were the most useful  and the performance of the program  described later  supports the ordering chosen. 
　　　a more objective method of determining usefulness would be to have the program initially use the heuristics randomly  giving them all weights but starting with the weights equal. as time went by  the weights could be adjusted so that the heuristics which succeeded most often were assigned the greatest values. if the context in which a heuristics was used successfully were saved along with the fact that the rule worked  then even more specific knowledge about when the heuristic is applicable would be available. in this way  over time  a program would be able to apply its heuristic knowledge more and more appropriately  and the hypotheses it chose to explain its failures would steadily improve. 
1. rationalization 
　　　once the heuristics have selected a feature as the potential cause of a prediction failure  that feature is passed to the rationalization module  which checks to make sure that the hypothesis is consistent with the program's causal knowledge. rationalization works by forward chaining from the feature itself until a stopping point or dead end is reached. all features are connected in a bi-directional network which expresses how they may cause each other  and which includes other facts about horse racing. stopping points in the network are explicitly marked: most of them are facts like  the horse is more likely to win  or  the horse is more likely to lose.  other features point to these facts  and the rationalization module forward-chains 

1 	s. salzberg 
 breadth first  until it either reaches one of these facts or it cannot chain any more  markers are placed to prevent looping . here is an example of a rationalization that handicapper produced  for the horse gallant herb  in a race which it had predicted a different horse would win: 
gallant-herb has been dropping down in value of the last five 
races  therefore 
the competition this horse is running against is gradually getting easier  therefore 
the performance of this horse should be improving  therefore this horse is better than others at this level  therefore this horse will win over others at this level. 
     the important role of rationalization in the overall learning/explanation algorithm is that if handicapper fails to find a rationalization for some feature  it must return to the heuristics to find another hypothesis. in other words  suppose the heuristics suggest a feature that caused a horse to lose. if the rationalization module cannot find an inference chain which leads to the same conclusion  then control is passed back to the heuristics  which attempt to suggest another feature as the cause of the loss. this control loop continues until a good hypothesis is found or until the heuristics cannot suggest anything more  if this latter instance occurred  handicapper would consider the failure to be anomalous  but it has not happened yet . rationalization  then  is the manner in which causal knowledge is used to insure that hypotheses generated by the system are plausible explanations of the observed results. 
1. handicapper's performance 
　　　handicapper has been tested on a base of 1 races  and then re-tested on another 1 races. initially it has no episodic memory  and the first race is used to establish one. the program's initial knowledge is constrained to a list of approximately 1 features  with no knowledge of how good or bad each feature is  and to the heuristics described in this paper. as processing continues  it makes generalizations whenever it makes a correct prediction  and it constructs new rules when it fails. generalizations are of the form: if features a  b  and c occur on one horse  then that horse has a 1% probability of winning against a set of horses none of which have those same features. since it began with very little knowledge  its performance on the test database was at first poor  but it quickly improved and easily outperformed the experts  a group of experts publish their predictions daily in the daily racing form  
the standard horse racing newspaper  over the entire set of races. 
     in the course of running through all 1 races  no prediction was made on the first race   handicapper predicted 1 out of 1 correctly  or 1%. the experts were only correct 1% of the time. if one considers the first 1 races as  training  races  handicapper does even better: 1 out of 1 correct  or 1%  which indicates that the program was learning. on the second database of 1 races  which came from a different track  the program  with no tuning to account for the differences in data from a different track  did slightly worse  but still substantially better than the experts. apparently the heuristics described here  coupled with the rationalization procedure  combine to produce an algorithm which learns very successfully despite the complexity of the domain. 
　　　from a theoretical standpoint  more work needs to be done the bases of these heuristics. certain underlying assumptions are common to several of them  and it might be the case that there is a smaller set of more general heuristics which could be isolated. the question of whether a system could learn the heuristics needs to be examined  as well. the next steps in the development process must be first of all to implement the remaining heuristics  and then to apply the algorithm to other  perhaps even more complex domains. success in other domains will lend greater support to the claim that the application of general heuristics must be an integral part of inductive learning algorithms. 
acknowledgements 
     thanks to david atkinson for many months of useful discussions and exciting ideas on inductive learning. thanks also to eduard hovy and larry birnbaum for incisive and enlightening comments on a draft of this paper. at apex  thanks to jim stansfield for additional comments and suggestions. 
