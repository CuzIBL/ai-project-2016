 
 if you have planned to achieve one particular goal in a stochastic delayed rewards problem and then someone asks about a different goal what should you do  what if you need to be ready to quickly supply an answer for any possible goal  this paper shows that by using a new kind of automata caily generated abstract action hierarchy that with n states  preparing for all of n possible goals can be much much cheaper than n times the work of preparing for one goal. in goal-based markov decision problems  it is usual to generate a policy mapping states to actions  and a value function  mapping states to an estimate of minimum expected cost-to-goal  starting at  in this paper we will use the terminology that a multi-policy 
  for all state-pairs  maps a state  
to the first action it should take in order to reach with expected minimum cost and a multi-valuefunction  is a definition of this minimum cost. building these objects quickly and with little memory is the main purpose of this paper  but a secondary result is a natural  automatic  way to create a set of parsimonious yet powerful abstractactions for mdps. the paper concludes with a set of empirical results on increasingly large mdps. 
1 	introduction 
in goal-based markov decision problems  it is usual to generate a policy and a value function for a single goal. in 1  kaelbling introduced the hdg  hierarchical 
distance to goal  algorithm  kaelbling  1   which considered the more general formalism of arbitrary goal states as well as start states. given n states  hdg considered the question of how to generate and execute an approximation to the multi-policy without requiring   memory for the data structures. 
　in this paper we introduce new data structures and algorithms that exploit this insight while automatically choosing where to place landmarks  points to aim for   and choosing which states belong to which landmark  without requiring pre-defined distance metrics  such as the euclidean heuristic of the original paper  or predefined partitions. instead  the measure of closeness used is the true minimal expected cost measure. generating these locations  partitions  and policies from scratch in volves some interesting  chicken and egg  problems  especially if we need to exploit the hierarchy whilst building it  necessary if we are to save not only memory but also computation . we will describe how this can be addressed with a new branch-and-bound procedure in combination with prioritized sweeping  moore and atkesbn  1   an algorithm for improving value functions in the face of small alterations in an mdp structure. 
　another motivation is to help answer the two questions   where should abstract actions come from  . is it necessary to have some high-level prior understanding of the class of tasks at hand in order to decide which abstractions are beneficial  this may be of use to re-
cent algorithms that attempt to exploit abstract actions but require them to be predefined  such as  precup and sutton  1; singh  1; dayan and hinton  1; dietterich  1  and hdg itself . 
1 	the airport hierarchy 
this algorithm takes  as input  an mdp which is specified by a set of n states  and for each state a set of actions  and for each state-action pair  a set of outcomes along with the outcome probabilities. the outcomes   set of a state-action-pair is the set of states such that p  next state this state = x} this action we make the strong assumption that the mdp is sparse: for all states the number of actions is  n and for all state-action pairs  the number of outcomes is  n. this assumption is very frequently true in navigation  dynamics and inventory mdps. furthermore  recent work  reams et al.  1  indicates that even non-sparse mdps may usually be transformable to sparse mdps with little loss in optimality  in addition to the state transition probabilities  the algorithm also inputs the non-negative onestep cost function specifying the penalty we pay for applying a in state note that conventional dynamic programming theory tells us that the optimal policy and multi value function must obey 
a

1 	uncertainty and probabilistic reasoning 

 the new structure is called the airport hierarchy. it differs from hdg and is more similar to feudal learning  dayan and hinton  1  in that each state is a member of many partitions; some large and abstract  others small and specific. it differs from feudal learning and other partitioning structures  such as g-leaming  chapman and kaelbling  1  and partigame  moore  1   in that junior partitions are not necessarily subsets of their seniors  and many partitions are overlapping. we will begin by defining the properties that we do require from these partitions  before proceeding to execution and generation algorithms that exploit these properties. proofs will be included in a later version of this paper. 
1 	formalities 
we define  for a given state  that we have decided to turn into an airport: 
	states that know how to get to 	 1  
any member of  will have  cached away in the airports structure  knowledge of the truly optimal first action to take in getting to y and the true minimum expected cost of getting to define 
	level  = the  level  of airport 	 1  
where level  = 1 means that  is a maximally senior airport: the larger the level  the lower the seniority. as part of the construction we will insist that 
		 1  
thus  if y is a level  airport then there are at least  states that know the optimal value and policy for reaching  we also insist that 
		 1  
thus  the set of states that knows how to get to are the states with minimal expected cost to get to our final two requirements are 
  if  1 then includes at least senior airports  x is senior to if and only if  
  there are  airports at level 1  at level 1  at level 1  etc  with the number of airports doubling at each level until we run out of states. 
because the number of airports doubles at each level  the maximum level rises logarithmically with  the total amount of memory needed to represent all knowledge about all level i airports is thus  in the best case  per airport times  level i airports  which is and so the total amount of memory needed 
over all levels is  in the best case. 
example: figures 1 and 1 depict aspects of the airport hierarchy for a simple grid-world. 
1 	choosing actions 
how is  approximated by the airport hierarchy  call the approximation  to choose the first action to take if we hope eventually to reach cheaply  we use the hdg insight. if  is far enough from that it 
figure 1: a simple maze constructed with = 1 top-level airports. the light gray areas are cells in which transitions are completely random  to a random neighbor . in white 
cells  there is a 1 probability that we'll move in the direction we request  and chance we'll move to a random neighbor. the disks denote the airports: the larger the disk  the more senior the airport. 
figure 1: each figure shows an airport   circled  and 
  dark grey . the airport levels are 1  1 and 1 respectively. the = 1 senior airports that can reach the targets are also shown. 
doesn't know how to get to  directly  i.e.  if we pick some intermediate target that we do know how to get to  and from which we will be able to make progress towards  the only remaining question is how to choose a good target from the airport hierarchy. 
　to do this  we must define one extra object  called  a special set of states that know how to get to y by travelling through increasingly less senior airports. define 
in t o 
we can define the target that 
deal in turn with three cases: states that immediately know how to get to  states that are in  and all other states. 
	  if 	and 
these values can be read  
in constant time  from the information cached in the airport hierarchy. 
	moore  baird  and kaelbling 	1 



common  cannot be empty because  must contain a level 1 airport. 
　intuitively  the process of creating  can be seen as dynamically creating a goal-state-dependent set of landmarks  using hdg terminology  for getting to 
 this set of landmarks is useful specifically for  because it has a higher density of landmarks closer to y  with closeness defined in terms of minimal expected cost . by construction  easy to prove  this set is small: 

　figure 1 shows the set of airports considered during one such decision. although the policies resulting from this scheme may be suboptimal  we can prove that they will always reach the goal in finite time  and empirically the regret  mean loss compared with truly optimal behavior  is very small. 
               planning the next action from the centrally circled state. the start state is the cell surrounded by the lower large circle. the goal is surrounded by the 
upper large circle. the set are depicted by small discs  with radii proportional 
1 	efficiently building the airport hierarchy 
we say a state is unassigned if it is not an airport at any level in the hierarchy. the airport construction al-
gorithm begins with all states unassigned  and ends with no states unassigned. whenever an airport y becomes assigned  is chosen  and for all 	are computed. all this information is cached permanently away in the airport hierarchy for future use during the remaining airport construction and policy execution. 
　we will now discuss the add airport operation  which picks one state and assigns it. 
1 	step one: choose  
we defer discussion of this step until section 1. 
1 	step t w o : choose  level 
this step is trivial. is simply given the most senior airport level available  subject to the constraint that there are no more than  airports at level l. thus  if so far  m airports have been assigned  
1 	step three; construct  
to understand the job we must do here  we will begin by considering two simplified scenarios: an inefficient method for non-deterministic mdps and an ef-
ficient method for deterministic mdps  	finally  we'll 
tackle the efficient non-deterministic case. 
constructing  inefficiently 
we would simply take the following steps: 
1. run an mdp solver such as value iteration  policy iteration  or modified policy iteration  bertsekas and tsitsiklis  1  to compute  for all states  in the mdp. 
1. define the set  is among the t lowest values. }  with ties broken arbitrarily to ensure t elements in the set. define  to be the minimum such that  and contains at least k senior airports. 
then simply select and store the values in the airport hier-
	archy only for those 	for which  
　the objection to this approach is that it is too expensive: after having computed the  set for every in the mdp  we will have needed to perform  full dynamic programs  meaning  operations in total 
to build the hierarchy  where kcrit is the average number of value iterations needed for dynamic programming convergence. 
constructing  for deterministic systems 
this too would be simple. we can perform uniform-cost breadth-first search back from y until the set of states added during the search become sufficiently large and contains the required number of senior airports. now the work per airport would be small for junior airports with small  state sets  resulting in an algorithm that in the best case could be as cheap as  
the efficient non-deterministic case 
again  we will work backwards from y  incrementally adding states. the problem is that for a nondeterministic system there is always a probability that the system being controlled will leave the set of states added so far. how  then  can we compute the optimal value function that takes into account the possibility of such exits  
　let us briefly take a break from the larger question of computing  and instead focus on a simpler question given an incomplete portion of a goal-based mdp  

1 uncertainty and probabilistic reasoning 

bow can we approximate over the states in this incomplete portion  which we will call figure 1 gives an example of such a problem  with five states  including the goal state   constituting and several outcomes that lead to states outside this set marked with   symbols. we will find an optimistic lower bound  and a pessimistic upper bound  so that  
		 1  
figure 1: an example of a sub-mdp in the process of construction from five states 
the thick polygonal arrows denote actions. the thin arrows denote the possible stochastic outcomes if the action is taken. assume that all outcomes cost 1 unit  and for a given stateaction pair  all depicted outcomes are equiprobable. 
constructing  
we will construct a new  small  mdp made up of the states in  plus one new state this construction will be guaranteed not to overestimate  
　before proceeding  we will partition into two subsets of states. define 
internals 
borders  
where 	preds    means  z is an immediate predecessor of 	  so that 	preds x  ~ 1 a such that p  next state 	this state 	and action  
　border states have some predecessor outside while internal states are ones in which all predecessors are in-
side 1. in figure 1  assume that  and  are all internal states  and  and  are border states. 
　for each of the   symbols in figure 1  what is the best thing that could happen  the first thought is that they might head straight to a state outside  paying their one-step outcome cost  and then this state might be able to jump to the goal with zero cost. but this is not possible. if the goal is an internal state  then no state outside can jump directly to the goal  nor indeed to any other internal state. so the best thing that could happen is that they jump to some state outside  and then with zero cost jump to the most favorable of the border states. we model this by adding a new  fake  state called  to the system  which can with zero cost jump to any of the border states that it chooses. the   symbols all jump to  figure 1 shows this construction for our example. having added this extra state  we run an mdp solver to compute its value function  which we define to be  
constructing  
we must now ask  what is the worst thing that can 
pigure1: the optimistic interpretation of the submdp of figure 1. 
happen at any of the   symbols  . unfortunately  it is arbitrarily bad. even if there were an upper bound on a single transition cost in the mdp  hard-to-escape loops  caused by a probability-of-transition-to-self very close to 1  could create arbitrarily expensive expected costs to the goal. 
　the good news is that if we may be able to take advantage of information cached in the partially constructed airport hierarchy. this requires that at least one state in have already been added to the hierarchy as an airport  and that one or more other states in know how to get to this airport. 
     if there exists and  such that  is an airport and then we will add an extra action to  with cost  which we can look up in the hier-
archy  and with next state  with probability 1. adding this action simply expresses the already established fact that we know we can get to  from  by some  not necessarily explicitly known  means  and the expected cost of doing so is  expressing this fact cannot cause the system to underestimate the cost of travelling from  adding these new fake actions can have a dramatic effect on the worst case cost estimates. in figure 1  the worst case value for all states other than y is infinite. but suppose we add the extra knowledge that we already know that travelling from to costs  say  an expected 1 units  see figure 1 . then the optimal policy in the supplemented mdp will have costs 

constructing  
we now return to the question of constructing  the algorithm is: 
1. let 
1  compute 
	moore  baird  and 	kaelbling 	1 

	1. define the set 	such that 
is among the lowest values define to be the minimum t  if it exists  such that  and contains at least senior airports. 
if such a exists  check the tightness on our lower and upper bounds on  for all states in  if 
  1  
then halt  adding y into the airport hierarchy  along with its chosen level  and  
and remembering for future use all the  
	values for 	a p p r o x i m a t i n g b y 
1. if we did not halt  grow pick the border state with minimum add all its predecessors into  and borders. check which states have all their immediate predecessors in  and promote them into internals. goto 1. 
remarks: 
each time and  are recomputed  few of the states in change their values significantly  except for newly added states and their neighbors. to take advantage of this  we use prioritized sweeping  moore and atkeson  1 . this was used in the experiments reported in section 1  and without it  the computational costs were empirically 1 to 1 times slower. 
in order to access the immediate predecessors in the 
mdp  we must create a backwards model  which is an array which  for each state  maps  to  this can be built once  with a construction cost linear in the number of states. 
　why should we expect that the upper and lower bounds on the value function will be tight  not all domains will provide tightness: for example  expander graphs are likely to be problematic. but domains with a notion of locality are likely to achieve tight bounds on states close to the goal quite early on. 
1 	choosing airport locations 
when the hierarchy is being built  level 1 airports are assigned first  then level 1  etc. the location of a new airport is always chosen to be the state furthest from any previous airport  in terms of expected cost . because of the construction of the hierarchy  this can always be found efficiently. notice that no prior assumptions  such as euclidean distance  are needed for airport determination: it is fully automatic. 
1 	results 
table 1 presents results on various stochastic gridworlds and an inventory management problem. the gridworlds all obey the same rules as our initial example. problems expandl through expandl1 are gridworlds of increasing size  produced by gluing together a short fat maze on top of itself. this allows us to see how torts increase as the maze size increases linearly  one way  middle of figure 1  is a maze with one-way wails  and serves to demonstrate that it is not necessary for actions to be reversible for airports to be applicable. the table compares the memory needed if a ml  table were used to that needed by the airport hierarchy. it compares the time needed to build the airport hierarchy conventionally with the time needed using our algorithm. and it shows the mean regret  loss due to using our approximate pol instead of the optimal policy   to give the regret some context it also shows the mean path cost. figure 1 graphically depicts the tradeoff as the number of states is increased. further empirical results  
 
for which there is no room here  show that the algorithm work over a wide range of stochasticity  that there is not strong sensitivity to the e threshold  and that clever placement of the airports is beneficial. 
figure 1: topleft: the medium maze. topright: 
	the 	one way maze 
 state transitions are permitted rightwards through the grey vertical bars  but not leftwards . bottomleft: the expandermaze of size five. 
figure 1; the relative performance of using versus not using airports for different sizes of the expand maze of figure 1. top graph: number of times by which the airports are faster than nonairports in computing  and 
 middle graph: the number of times more memory that non-airports need. bottom graph the average regret of the airports policy  expressed as a fraction of path length. 
1 	conclusion 
this paper has been about efficiently computing and caching a hierarchy that allows us to approximate for all pair of states  when is 

uncertainty and probabilistic reasoning 

num slow airports memory slow airporti speed mean airports fraction name states memory memory saving time time  up mean regret  words   word.  
1 
1 factor  secs   secs  factor cost regret small 
medium 1 
1 1 
1 1 
1 1 
1 　1 1 
1 1 
1 1 1 1 
1 big 1 1 1 1 1 1 1 1 1 1 one way 1 1 1 1 1 1 1 1 1 1 inventory 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expand1 1 1 1 1 1 1 1 1 1 1 expand1 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expands 1 1 1 1 1 1 1 1 1 1 expands 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expands 1 1 1 1 1 1 1 1 1 1 expands 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expandl1 1 1 1 1 1 1 1 1 1 1 expand 1 1 1 1 1 1 1 1 1 1 1 expandl1 1 1 1 1 1 1 1 1 1 1 table 1: results on vanous problems. in these experiments    the number of senior airports  is 1   the stopping criterion of equation 1  is 1 and pcand  the probability of the requested move in the maze being replaced by a random move  i  1. the small maze is shown in figure 1. medium  

big  oneway and expand1 are all shown in figure 1. 
this ability to access  and  useful  cer-
tainly in domains in which we must perform multiple sequential tasks  and in which we need to very quickly switch from task to task. but we believe the greatest use will come in hierarchical control systems in which a higher level controller wishes to not merely call one of a set of atomic lower level controllers  but instead one of a set of lower level controllers that can be parameterized with a subgoal. the full paper and presentation of this work includes an example of hierarchical control of hunters and prey which would not have been otherwise computationally feasible. 
　multi-values are primitive in comparison with parr's approach  parr and russell  1   which permits arbitrary reward functions instead of merely arbitrary goals. however  multi-value functions may be more computationally practical on large problems. like other hierarchical rl algorithms  airports uses abstract actions  and can be thought of as creating an entire plan  and then replanning on each time step. but airports differs from other algorithms such as maxq  dietterich  1  in the nature of those abstract actions  and this can be seen by looking at the plans produced. in maxq  the problem is solved by a sequence of level-1 actions. each level-1 action is  in turn  a sequence of level-1 actions  and so on down to the level of primitive actions. the cost of a level-1 action is unknown until the lower levels have computed. in airports  the plan at a given time might be a single level-1 action   go to this level-1 airport/'   then a 
　single level-1 action  then a single level-1 action. the sequence is constrained to always be in increasing numerical order  decreasing levels of abstraction   with at most one action at each level  guaranteeing short plans. each abstract action is composed directly of primitive actions  not lower-level abstract actions  and the complete hierarchy of abstract actions-what they do and where they are applicable-is constructed automatically and parsimoniously. this restriction means that a good plan to get from state  to state  can be found by exhaustively searching all legal plans  and this is fast enough to be done in real time on every step. it might be interesting to combine airports with maxq or with precup's and sutton's abstract actions  precup and sutton  1   using the abstract actions generated by airports as some of the  primitive  actions in the other algorithm. 
