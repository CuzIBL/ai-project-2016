 
       we describe work in progress on an automatic theorem prover for recursive f u n c t i o n theory that we intend to apply in the analysis   i n c l u d i n g v e r i f i c a t i o n and transformation  of u s e f u l computer programs. the mathematical theory of our theorem prover is extendible by the user and serves as a l o g i c a l basis of program s p e c i f i c a t i o n  analogous t o   say  the predicate c a l c u l u s   . the theorem prover permits no i n t e r a c t i o n once given a g o a l   but many aspects of i t s behavior are influenced by p r e v i o u s l y proved r e s u l t s . thus  i t s performance on d i f f i c u l t theorems can be r a d i c a l l y improved by having it f i r s t prove relevant lemmas. we describe several ways t h a t the theorem prover employs such lemmas. among the i n t e r e s t i n g theorems proved are the correctness of a simple o p t i m i z i n g compiler f o r expressions and the correctness of a   b i g number  a d d i t i o n a l g o r i t h m . 
       the research reported here has been supported by the o f f i c e of naval research under contract nooo1-c-1  the national science foundation under grant dcr1a1  and the a i r force o f f i c e of s c i e n t i f i c research under contract f1-c-1. 
	i 	introduction 
       this paper presents work in progress on an automatic theorem prover designed f o r use in the a n a l y s i s of computer programs. like our e a r l i e r lisp theorem prover   1       1       1       the new system proves theorems in a v e r s i o n of r e c u r s i v e f u n c t i o n t h e o r y ; however  the new v e r s i o n   which is considerably r i c h e r than the o l d   i s a x i o m a t i c a l l y e x t e n d i b l e and can serve as a l o g i c a l basis of program s p e c i f i c a t i o n  analogous to predicate c a l c u l u s   . of course  the new theory is t a i l o r e d t o programming languages i n the sense t h a t i t i s easy to model  say  arrays and other data objects in i t . but e x a c t l y how one attaches meaning to programs   e . g . w i t h the f u n c t i o n a l approach of mccarthy and b u r s t a l l or w i t h the i n d u c t i v e 
       a s s e r t i o n approach of floyd and hoare . is the business of the program v e r i f i c a t i o n system  not the mathematical theory or the theorem proving system.  for example  we have r e c e n t l y formalized in our theory a v e r s i o n of the pernas-robinson   1   
h i e r a r c h i c a l program design methodology using the floyd approach to program correctness.  
       the approach we have taken towards automating proofs in the theory is to model our system on the way we prove theorems: we s i m p l i f y the conjecture whenever p o s s i b l e   applying relevant axioms and theorems; we s p l i t the problem i n t o as many independent subgoals as p o s s i b l e ; we c a r e f u l l y apply various h e u r i s t i c s   such as e q u a l i t y s u b s t i t u t i o n s   e l i m i n a t i o n of undesirable or i r r e l e v a n t terms  and g e n e r a l i z a t i o n ; and then we formulate the cleanest possible i n d u c t i o n f o r each subgoal based on a thorough analysis of how the f u n c t i o n s behave. we also monitor our progress by comparing subgoals w i t h one another. for example  we look for i n d i c a t i o n s of looping and for o p p o r t u n i t i e s to subsume a subgoal w i t h a more general subgoal. our basic approach to theorem proving  then  is much in the s t y l e of bledsoe  as described  f o r example  in  and   1     . 
       we designed the new system to be e n t i r e l y automatic. however  u n l i k e our e a r l i e r lisp theorem prover  which was b u i l t to demonstrate completely automatic i n d u c t i o n proof techniques  the new system can take advantage of p r e v i o u s l y proved r e s u l t s t o a l t e r d r a m a t i c a l l y i t s behavior. with proper   t r a i n i n g   it can construct proofs of q u i t e complicated theorems. the basic idea is to be able to do simple proofs a u t o m a t i c a l l y w h i l e a l l o w i n g the user to s t r u c t u r e d i f f i c u l t proofs by s t a t i n g relevant lemmas to be proved beforehand. the o p t i m i z i n g compiler proof  discussed below  i l l u s t r a t e s how the user can s t r u c t u r e a   d i f f i c u l t   theorem by suggesting several   s i m p l e   lemmas. 
       aubin  and cartwright   1   have r e c e n t l y produced r e l a t e d automatic theorem provers f o r versions of r e c u r s i v e f u n c t i o n theory. 	we h i g h l y recommend t h e i r theses to anyone i n t e r e s t e d in mechanizing r e c u r s i v e f u n c t i o n 	theory. 
       this paper is organized as f o l l o w s . we f i r s t present a d e s c r i p t i o n of the theory w i t h which the theorem prover d e a l s . we then describe in some d e t a i l the system's automatic proof of the correctness of a simple o p t i m i z i n g compiler f o r expressions. next we discuss some of the ways lemmas are employed to guide the theorem prover. that s e c t i o n discusses lemma d r i v e n s i m p l i f i c a t i o n   g e n e r a l i z a t i o n   and an i n t e r e s t i n g use of lemmas to j u s t i f y i n d u c t i o n s . the discussion of i n d u c t i o n summarizes one of the system's proofs about   b i g 

t h e o r e m 	p r o v l n g - 1 : 	royer 
1 

number  arithmetic. the paper has two appendices. the f i r s t presents the definitions of recursive functions referred to in the paper. the second presents the system's output during a proof of a simple theorem about a tree-flattening algorithm. we include this proof both as an example of the theorem prover's behavior end because the recursion  1nd induction  in the tree-flattening algorithm is similar to that used by the compiler. because of space limitations we cannot ennumerate the theorems the system has proved. such a l i s t w i l l be sent upon request. we also welcome requests for the source code of our system. 
	ii 	the new theory 
　　　the theory we now use admits arbitrary recursive definitions.  our earlier lisp theorem prover is limited to primitive recursion.  we regard definitional equations as axioms which are used only to expand function calls.  one might use recursive functions as a logical basis for induction arguments. however  we derive our induction principles solely from proven lemmas in a way described below. of course  we use the recursive structure of the functions in our theorems to suggest which principle of induction is most appropriate.  
　　　the domain of objects is partitioned into an i n f i n i t y of disjoint  type classes.  the user is free to define axiomatically the properties of any class. because the free variables in a conjecture are understood to range over a l l objects  even objects not yet distinguished by the axiomatization of their containing classes   theorems remain theorems even when a new class is axiomatized. of course  variables in a theorem may be constrained with axiomatically or recursively defined predicates. unlike the languages of aubin  and cartwright   1     our language is not typed; we do not have typed variables in our theorems or type constraints on the input or output of our functions. 
　　　the i n i t i a l objects are true and false  the sole members of their respective classes. the i n i t i a l functions are if and equal.  if x y z  is z if x is false and y otherwise.  equal x y  is true if x is y and false otherwise. 
　　　arithmetic over the non-negative integers  the l i t e r a l atoms  l i s t s   push-down stacks  characters  and strings of characters &re examples of classes that have been added axiomatically. there is a  meta-  f a c i l i t y called add.shell for automatically axiomatizing new classes of objects with properties virtually identical to burstall's structures  and close to the style of clark and tarnlund . 
　　　the theory also contains a version of the principle of induction called the generalized principle of induction  noetherian induction  in burstall . the principle allows one to induct over any well-founded partial ordering. 
	i l l 	an example 
　　　let us now consider the system's proof of the correctness of a very simple optimizing compiler for expressions. although this proof f a i l s to exercise many of the new heuristics in the system  it does i l l u s t r a t e the use of lemmas and the system's general competence at handling significantly larger problems than our earlier lisp theorem prover could. a detailed presentation of the proof  complete with the set of a l l axioms used  the system's very readable commentary on the proof  end a discussion of several bugs discovered in earlier attempts to write the compiler  is available in . 
　　　suppose we have axiomatically introduced as distinct classes the non-negative integers  atomic symbols  l i s t structures  end push-down stacks. for simplicity  suppose we want to optimize and compile numerically valued expressions composed of integers  variables  and binary function symbols. we w i l l represent such expressions as s-expressions 
 e.g.   1   x    y  is represented as  times  plus 1 x  y     . the recursive predicate formp recognizes such forms.  all of the functions mentioned in this section are formally defined in appendix a.  
　　　the main theorem we wish to prove is that executing the  optimized end  compiled code for a form in the context of some stack and environment is equivalent just to pushing onto the stack the value of the unoptimized form in the environment. that i s : 
correctness.of.optimizing.compiler: 
 formp x  -   exec  compile x  pds envrn  
 push  eval x envrn  pds . 
the compiler  compile  works in two passes. 
it f i r s t uses optimize to perform constant folding 
 e.g.   times  plus 1  y  is optimized to  times 
1 y  if  apply 'plus 1 were to have the value 1 . after optimizing  the compiler calls codegen to generate a l i s t of instructions to be executed  in reverse order .  codegen form insj generates a l i s t of instructions for form  treating ins as the l i s t of instructions previously  laid down . if form is a number or variable  codegen lays down a pushi or pushv instruction  by consing it onto ins .  pushi n  causes the  hardware  to push n onto i t s stack.  pushv x  causes it to push the value of the variable x in the current environment. if the form is not a number or variable  then codegen assumes it is an s-expression such as  fn argl arg1 . it f i r s t lays down the code for argl  then the code for arg1  and then the instruction fn  which means to the hardware  pop two things  apply fn to them  and push the result.  
　　　the reader is encouraged to inspect the definition of codegen in appendix a. note  in particular  that the compilation of arg1 takes place with ins being the sequence produced by a recursive call of codegen on argl. 
　　　as an example of codegen  i t s  reversed  output for the form  times 1  plus x y   i s : 

theorem 	p r o v l n r - l : b o y e r 
1 
　this p i c k i n g 
so the proof 
and 
t h p o r o m 	p r o v i n g - l : 	b o y e r 
1 

b u r s t a l l uses. 	a f t e r producing t h i s proof and w r i t i n g  we received a copy of aubin's t h e s i s   1   . 	in it he presents an automatic proof of a theorem extremely s i m i l a r to our 
correctness.of.codegen employing a s i n g l e lemma analogous to sequential.execution. 
       readers f a m i l i a r w i t h the o l d lisp theorem prover may be i n t e r e s t e d in knowing how t h a t system f a i l s 	to prove the correctness of our o p t i m i z i n g 
       compiler. 	there are f i v e basic inadequacies: 	i t s theory is too simple to permit a n a t u r a l 	statement of the problem; 	it could not formulate the r i g h t i n d u c t i o n f o r codegen; 	its 	type handling is 
inadeaurte t o s i m p l i f y the i n d u c t i o n arguments; 	i t 
would run out of l i s t space because it would not s p l i t o f t e n enough; and it could not have made s u f f i c i e n t use of lemmas. 
	iv 	how lemmas are used 
       the new system uses lemmas in many ways; in t h i s s e c t i o n we explain three of them. 
a. 	lemmas. 	for 	rewriting 
       the most common use of axioms and lemmas is as r e w r i t e r u l e s during s i m p l i f i c a t i o n . of course  the s i m p l i f i e r uses f u n c t i o n d e f i n i t i o n s as r e w r i t e r u l e s to  open up  a f u n c t i o n c a l l by r e p l a c i n g it w i t h i t s d e f i n i t i o n  when the r e s u l t i s simpler i n some sense . but more g e n e r a l l y   the theorem prover i n t e r p r e t s a l l axioms and lemmas as r e w r i t e 
       r u l e s in the f o l l o w i n g way. 
       given any formula  axiom or lemma  consider a l l o f the sequents 
   h1 & h1 & . . . & hn ~  c one can deduce from it by p r o p o s i t i o n a l c a l c u l u s . we c l a s s i f y each sequent according to the form of 
c. if c is of the form  not u  then the r u l e can be used to r e w r i t e any term which u n i f i e s w i t h u to false  provided the i n s t a n t i a t e d hi can be e s t a b l i s h e d . if c is of the form  equal u v  it can be used to r e w r i t e u to v  again provided the i n s t a n t i a t e d hi can be e s t a b l i s h e d . otherwise  if c is just u  where u is boolean  then it can be used to r e w r i t e u to true  under the same p r o v i s i o n . 
       when the s i m p l i f i e r has decided to use a given r e w r i t e i t t r i e s t o e s t a b l i s h the h i b y 
  r e c u r s i v e l y   	s i m p l i f y i n g them   t o non-false . this was i l l u s t r a t e d above in the discussion of the proof of correctness.of.optimizing.compiler when the hypothesis  formp  optimize x     was established   i . e .   	r e w r i t t e n t o true . 
	care is taken 	to avoid i n f i n i t e regression 
  e . g .   repeated a p p l i c a t i o n s of a commutativity r e w r i t e or  pumping  up a term w i t h a r e w r i t e l i k e the c o n t r a p o s i t i v e of formp.optimize.  for example  we avoid the f i r s t problem by r e f u s i n g to apply a r e w r i t e of the form  equal u v  when u and v ere v a r i a n t s unless the r e s u l t is l e x i c o g r a p h i c a l l y less than the o r i g i n a l formula. 
thus  	the lemmas 
    plus i j  =  plus j i  and and 
	theorem p r o v l n g - l : t h e o r e m 	p r o v 	boyer 
1  

trick  then  to finding an appropriate induction for a conjecture is to find a well-founded partial order on n-tuples and an n-tuple of variables in the conjecture  such that if one were to open up some of the function calls in the conjecture one would find subexpressions occurring that could be obtained by instantiating the conjecture i t s e l f with smaller n-tuples chosen from the ordering. thus  one is lead naturally to the question:  what are some plausible well-founded orderings on ntuples of variables that a given recursive function descends through in i t s recursion   
　　　　　　to answer this question  our system imposes a basic responsibility upon the user to assume or to prove certain lemmas that we term  measure lemmas . measure lemmas state that certain terms are less than other terms under wellfounded orderings such as lessp  on the nonnegative integers.  our induction f a c i l i t y then uses such lemmas at the time a recursive function is defined to determine some induction principles appropriate to that function. of course  this induction mechanism is capable of examining a l l subsets of arguments to find appropriate principles. it also recognizes lexicographic orderings induced by existing orderings and chains together measure lemmas using t r a n s i t i v i t y  for example  to derive that  sub1  sub1 x   is less than x from the fact that  sub1 x  is less than x.  
　　　　　　as an example of the use of such  measure lemmas  consider  big number  arithmetic. the problem is to represent and manipulate  in our case  add  integers that are larger than the word size of the host machine. the obvious solution is to represent them as sequences of digits in some chosen base  and to add them with the algorithm we a l l learned in the third grade. two examples of the use of that  or similar  algorithms in computing are the  big number  arithmetic of 
maclisp  where the base is 1   and the binary representation of integers on most machines  where the base is 1 . 
　　　　　　to state and prove the correctness of a big number addition algorithm one must define the mappings from integers to big numbers and back. consider the f i r s t : to convert an integer i to a 
　　　　　　big number in base base  if i is less than base  then write down the digit i and stop  otherwise divide i by base  write down the remainder as the least significant d i g i t   1nd obtain the more significant digits by  recursively  converting the quotient to a big number in base base. this algorithm is embodied in the function power.rep  for  power series representation   in appendix a  where big numbers are represented as l i s t s of integers with least significant digit in the car. 
　　　　　　note that the algorithm above recurses on the quotient of i divided by base. what is the measure lemma that justifies this recursion  or  analogously  the induction necessary to unwind i t     i t i s : 
 i i 1  &  j i 1  &   sub1 j  i 1  
-   
 quotient i j    i   
　　　　　　that i s   the quotient of i divided by j is less than i if i is not 1  and j is neither 1 nor 1  actually  in our untyped language  arithmetic on non-integers is legal and a l l nonintegers are treated as though they were 1  thus  sub1 j  i 1 is stronger than j i v  it implies that j is neither 1 nor a non-number . 
           thus  if one wanted to prove by induction a theorem of the form p  power.rep i base    and one were cognizant of the above lemma  a plausible induction to perform would be: 
 i = 1  -  p  power.rep i base   
& 
 base = 1  -  p  p1wer.rep i base   
& 
  sub! base  = 1  -  p  power.rep i base   
& 
  i i  1  a  base i 1  1   sub1 base  i 1  h p  power.rep  quotient i base  base    
-   
pupower.rep i base   
           note that the induction hypothesis is an instance of the theorem being proved  that the instantiation takes the tuple  i  into the smaller tuple   qu1tient i b se    according to the above 
measure lemma  and that the term  power.rep  quotient i base  base  appearing in the hypothesis w i l l reappear when we open up the conclusion. finally  observe that by employing proved measure lemmas we not only allow the theorem prover to be extended but we insure that it is done soundly.  our f i r s t attempt to state the induction principle for quotient l e f t out the j i 1 case and would have produced unsound inductions had it been either explicitly assumed or wired into the theorem prover program.  
　　　　　　the system has proved the measure lemma above. the proof involves a similar induction by difference  note in appendix a how quotient i t s e l f recurses  which in turn was justified by a  proved  measure lemma stating that i-j is less than i under certain conditions. once the quotient measure lemma has been proved the system  in accepting the definition of power.rep  w i l l pre-process it to discover the plausible induction scheme above. that scheme is precisely the one the system uses to prove that the mapping back from big numbers to integers  power.eval in appendix a  is the  inverse   modulo non-numbers  of power.rep: 
 equal  power.eval  power.rep i base  base   if  numberp i  i 1  . 
           the above lemma is crucial to the system's proof that a big number addition algorithm  big.plus in appendix a  is correct: 
 equal  power.eval  big.plus  power.rep i base  
 power.rep j base  
                         1 base  base   plus i j     . 
theorem p r o v i n p - 1 : rover 
1            as a second example of a measure lemma  consider: 

	1. 	choosing the right instances 
　　　　　　if one has a well-founded order on ntuples then it can t r i v i a l l y be extended to a wellfounded order on n+k-tuples  where the last k elements are simply irrelevant. thus  once the system has found a plausible well-ordering that accounts for how n of the arguments change in recursion  it is free to throw in the remaining k arguments and let them change a r b i t r a r i l y . one example of this occurs in the compiler proof. recall that codegen has two arguments  form and ins  and that during recursion it changes form by digging out one of i t s sub-expressions. however  while in one of i t s recursive calls ins  the instructions thus far laid down  is unchanged  in the other call ins is arbitrarily larger. this is acceptable since the behavior on form induces a well-founded order. thus  the system knows that in a conjecture involving  codegen form ins  an induction on the structure of form leaves it free to choose any instantiation it wants for ins.  for an example of such a choice in a simpler situation see appendix b.  however  in a conjecture involving  codegen form nil   where the ins argument is not a free variable  the system s t i l l knows it is sound to induct on form. 
appendix a 
function definitions 
　　here we present the definitions of the functions involved in the optimizing compiler proof  the big number discussion  and the proof in appendix b. several axiomatically specified primitives are used.  numberp x  is true if x is a number and false otherwise.  l1stp x  is true if x is a cons and false otherwise.  push x pds  returns a stack with x pushed onto pds.  top pds  returns the top-most element of a stack  and  pop pds  returns the popped stack. getvalue and apply are undefined  but apply is axiomatically specified to be numeric - a fact crucial to correctness.of.optimize . 

　　　　　　we originally tried to avoid such a deep and lemma driven analysis of the well-founded orderings used by functions by using subgoal induction   where  provided one assumes a function terminates  one can use the conditional structure of the function plus i t s recursive calls to define a well-founded order on the n-tuple of a l l of i t s arguments. however we found that in many theorems it was crucial to be able to induct on some subset of the arguments  knowing that they alone were sufficient to define an ordering  and 1 that the conditional structure of most functions unnecessarily clutters inductions  which may seem like a mere inconvenience but often sets up toorestricted subgoals for subsequent inductions . 
	v 	remarks 
       we would l i k e to r e i t e r a t e t h a t t h i s paper r e p o r t s work in progress  both on the features of our theory and the proof techniques . 	while the ourrent system is c l e a r l y not yet s u i t a b l e as the theorem prover for p r a c t i c a l program a n a l y s i s   we are encouraged by our success at extending the theory of the our e a r l i e r lisp theorem prover w i t h o u t loss of proof-power. 	we b e l i e v e we w i l l be able to develop the system i n t o a useful t o o l . 
t h e o r e m 
1 




　　a l l of the commentary in the above proof was mechanically produced by the theorem prover in response to the user command to prove  equal  mc.flatten x y   append  flatten x  y     . several a d d i t i o n a l comments are in order. 
       the base case of the i n d u c t i o n argument is formula * 1 . i and the i n d u c t i o n step is   1 . 1 . note that in both cases the conclusions are the same  namely the theorem to be proved  and that in * 1 . i i the two i n d u c t i o n hypotheses are instances of the theorem to be proved. one sends the t u p l e  x y  i n t o   cdh x  y  and the other sends  x y  i n t o   car x   mc.flatten  cdr x  y    both of which are smaller than  x y  according to the measure t h a t compares only the f i r s t elements and uses the t r a d i t i o n a l o r d e r i n g on l i s t s t r u c t u r e s . the i n s t a n t i a t i o n picked for y in the second hypothesis was chosen because such a term would reappear when the conclusion was opened up. 
       formula * 1 . i s i m p l i f i e s to true and 	is thus proved. 	formula * 1 . i i 	s i m p l i f i e s t o * 1 . i i i   which is proved by r e - a s s o c i a t i n g one of the append terms  to produce * i . i v   and then doing a   c r o s s f e r t i l i z a t i o n .   	 the r e s u l t o f   c r o s s - f e r t i l i z i n g y for x in  implies  equal x y  q   is q w i t h some occurrences of x replaced 	by y .   
       if the a s s o c i a t i v i t y of append had not been p r e v i o u s l y proved  the theorem prover would have a u t o m a t i c a l l y produced it  from * 1 . i v   by two c r o s s - f e r t i l i z a t i o n s   a g e n e r a l i z a t i o n   and an e l i m i n a t i o n of an i r r e l e v a n t hypothesis  and then proved it by i n d u c t i o n . 
