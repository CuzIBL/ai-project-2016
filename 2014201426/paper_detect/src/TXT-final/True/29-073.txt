 
the class of algorithms for approximating reasoning tasks presented in this paper is based on approximating the general bucket elimination framework. the algorithms have adjustable levels of accuracy and efficiency  and they can be applied uniformly across many areas and problem tasks. we introduce these algorithms in the context of combinatorial optimization and probabilistic inference. 
1 	overview 
bucket elimination is a unifying algorithmic framework that generalizes dynamic programming to enable many complex problem-solving and reasoning activities. among the algorithms that can be accommodated within this framework are directional resolution for propositional satisfiability  dechter and rish  1   adaptive consistency for constraint satisfaction  dechter and pearl  1   fourier and gaussian elimination for linear inequalities  lassez and mahler  1   and dynamic programming for combinatorial optimization  bertele and brioschi  1 . many algorithms for probabilistic inference  such as belief updating  finding the most probable explanation  finding the maximum a posteriori hypothesis  and computing the maximum expected utility  also can be expressed as bucket-elimination algorithms  dechter  1 . 
　the main virtues of this framework are simplicity and generality. by simplicity  we mean that extensive terminology is unnecessary for complete specification of bucket-elimination algorithms  thus making the algorithms accessible to researchers working in diverse areas. more important  their uniformity facilitates the transfer of ideas  applications  and solutions between disciplines. indeed  all bucket-elimination algorithms are 
    this work was partially supported by nsf grant iri1 and by the air force office of scientific research  afosr 1  rockwell international  and amada of america. 
similar enough to make any improvement to a single algorithm applicable to all others in its class. 
　normally  an input to a bucket-elimination algorithm is a knowledge base specified by a collection of functions or relations  over subsets of variables  e.g.  clauses for propositional satisfiability  constraints and cost functions for constraint optimization  conditional probability matrices for belief networks . bucket-elimination algorithms process variables one by one in a given order. in its first step  given a variable ordering  the algorithm partitions these functions into buckets  where the bucket of a particular variable contains the functions defined on that variable  provided the function is not defined on variables higher in that ordering. the next step is to process the buckets from top to bottom. when the bucket of variable x is processed  an  elimination procedure  is performed over the functions in its bucket  yielding a new function defined over all the variables mentioned in the bucket  excluding x. this function summarizes the  effect  of x on the remainder of the problem. the new function is placed in a lower bucket. for illustration we include directional resolution  a bucket-elimination algorithm similar to the original davis-putnam procedure for satisfiability  figure 1  and elim-bel  a bucketelimination algorithm for belief updating in probabilistic networks  figure 1 . 
　an important property of variable-elimination algorithms is that their performance can be predicted using a graph parameter  w*  called the induced width  dechter and pearl  1   also known as tree-width  arnborg  1   which is the largest cluster in an optimal treeembedding of a graph. in general  a given theory and its query can be associated with an interaction graph. the complexity of a bucket-elimination algorithm is time and space exponential in the induced width of the problem's interaction graph. the size of the induced width varies with various variable orderings  so each ordering has a different performance guarantee. although finding the optimal ordering is hard  arnborg  1   heuristics and approximation algorithms are available  robertson and 
	dechter 	1 

is acyclic if it has no directed cycles. in an undirected graph  the directions of the arcs are ignored: 
and  are identical. an ordered graph is a pair  g  d  where g is an undirected graph and d - is an ordering of the nodes. the width of a node in an ordered graph is the number of the node 's neighbors that precede it in the ordering. the width of an ordering d  denoted w d   is the maximum width over all nodes. the induced width of an ordered graph  w* d   is the width of the induced ordered graph obtained by processing the nodes from last to first; when node x is processed  all its earlier neighbors in the ordering are connected. the induced width of a graph  w*  is the minimal induced width over all its orderings; it is also known as the treewidth  arnborg  1 . the moral graph of a directed graph g is the undirected graph obtained by connecting the parents of all the nodes in g and then removing the arrows. 

1 	approximating optimization 
in  bertele and brioschi  1   the non serial dynamic programming algorithm for the discrete optimization problem is presented. this algorithm can be rephrased within the bucket-elimination scheme  as shown in figure 1. given a partitioning of the cost functions into their respective buckets  algorithm elim-opt processes buckets from top to bottom. when processing x p   it generates a new function by taking the minimum relative to x p   over the sum of the functions in that bucket. the time and space complexity of elim-opt is exponential in the induced width to* of the cost graph. thus  when its induced width is not small  we must resort to approximations. 
　since the complexity of processing a bucket is tied to the arity of the functions being recorded  we propose to approximate these functions by a collection of smaller arity functions. let h1 ...  hj be the functions in the bucket of xp  and let s1 ... sj; be the subsets of variables on which those functions are defined. when elim-opt processes the bucket of xp  it computes the function hp: 
 instead  we can use a brute-force 
approximation method to generate another function gp by migrating the minimisation operator inside the sumalgorithm approx-opt is described in figure 1. it is parameterized by two indexes that control the partitionings. 
definition 1 let h be a collection of functions h1... lhj on subsets  a partitioning of h is canonical if any function whose arguments are subsumed by another belongs to a mini-bucket with one of its subsuming functions. a partitioning q is an  i  m  - partitioning iff the following three conditions are met: the partitioning is canonical  at most m nonsubsumed functions participate in each mini-bucket  and the total number of variables mentioned in each minibucket does not exceed i. 
theorem 1 algorithm approx-opt i m  computes a lower bound to the minimal cost in time 1 m   exp 1i   and space 
in general  as ra and i increase we get more accurate approximations. the two parameters  although dependent  allow flexibility in bounding performance. 
example 1 consider the network in figure 1. we use ordering  a  b  c  d  e  f  g  h  i  to which we apply both elim-opt and approx-opt m = 1  with unbounded i. 
	dechter 	1 

	figure 1: 	algorithm approx-opt i m  	

1
	dechter 	1 

1 	related work 
the bucket-elimination framework provides a convenient and succinct language in which to express elimination algorithms across many areas. most of these algorithms are widely known. in addition to dynamic programming  bertele and brioschi  1   constraint satisfaction  dechter and pearl  1   and fourier elimination  lassez and mahler  1   there are variations on these ideas and algorithms for probabilistic inference in  canning et al.  1; tatman and shachter  1; shenoy  1; zhang and poole  1 . 
	mini-bucket 	approximation 	algorithms 
parallel consistency-enforcing algorithms for constraint processing  in particular those enforcing directional consistency. specifically  relational adaptive-consistency is a full bucket-elimination algorithm whose approximations  directional-relational-consistency i  m   en-
forces bounded levels of consistency  dechter and van beek  1 . for example   denoting a generic minibucket algorithm by elim-approx  directional relational arc-consistency  drc 1   corresponds to elim-approx m = 1   directional path-consistency  .drc1  corresponds to elim-approx m = 1 ; and so on. 
　using mini-bucket approximations as heuristics for search parallels pre-processing by local consistency prior to backtrack search for constraint solving. in propositional satisfiability  where the original davisputnam algorithm  davis and putnam  i1  is a bucket-elimination algorithm  bounded-directionalresolution with bound b  dechter and rish  1  corresponds to elim-approx i - b . 
　finally  a collection of approximation algorithms for sigmoid belief networks was recently presented  jaakkola and jordan  1  in the context of a recursive algorithm similar to bucket elimination. upper and lower bounds are derived by approximating sigmoid functions by gaussian functions. this approximation can be viewed as a singleton mini-bucket algorithm where gaussian functions replace the min or max operations applied in each mini-bucket. 
1 	conclusion 
we present a collection of parameterized algorithms that approximate bucket-elimination algorithms. the basic idea is to partition each bucket into mini-buckets in order to control complexity. due to the generality of the bucket-elimination framework  such algorithms and their approximations will apply uniformly across areas such as constraint optimization  satisfiability  probabilistic reasoning  and planning. here we introduced the algorithms in the context of deterministic and probabilistic inference tasks. 
　many questions need to be investigated in the context of our proposal. for example  given that there are many  i  m -partitionings  and that each may result in different accuracy  how do we determine a good partitioning  such questions should be investigated empirically  and will  we hope  yield domain-independent and domaindependent heuristics. 
acknowledgements 
thanks to irina rish for commenting on an earlier version of the paper. 
