 
real-time algorithms need to address the time constraints  e.g. deadlines  imposed by applications like process control and robot navigation. furthermore  dependable realtime algorithms need to be predictable about their ability to meet the time constraints of given tasks. a real-time algorithm is predictable  if it can decide the feasibility of meeting time constraints of a given task or an arbitrary task from a task set well ahead of the deadline. lastly  a real-time algorithm should exhibit progressively optimizing behavior  i.e. the quality of the solution produced should improve as time constraints are relaxed . we propose a new algorithm  sarts  that is based on a novel on-line technique to choose the proper values of parameters which control the time allocated to planning based on the time constraints. sarts also provides criteria to predict its ability to meet the time constraints of a given task. the paper provides theoretical and experimental characterization of sarts as a dependable real-time algorithm. 
1. introduction 
　　real-time systems are increasingly being used in important applications such as avionics  process control  robot and vision systems  and command and control. these applications are characterized by attributes  such as strict time constraints posed as deadlines on the time by which the system is expected to produce a solution to a given problem  or the time by which the system is expected to predict deadline violation  in order to avoid the catastrophic consequences of violating deadlines. another attribute of most of the above applications is that they require dynamic problem solving due to the lack of complete a priori information at compile time. many realtime computing problems such as task scheduling on uniand multi-processor architectures  are hard optimization problems for which finding solutions are computationally prohibitive  particularly if such problem solving is to take place on-line. thus  dynamic problem solving in real-time is faced with the tradeoff between sub-optimal solutions and the time allocated to find such solutions. techniques addressing dynamic problem solving in realtime are often required to progressively optimize rather than to optimize  namely they are expected to find the best answer within the allotted time  and improve upon it if additional time is allocated. 
　　many combinatorial optimization problems  including those in real-time computing  can be formulated as the search for an answer in the space of all partial and complete solutions  such that the answer minimizes  or maximizes  an objective function  1 . most search-theoretic approaches to combinatorial optimization problems have addressed only the static version of the problem. there has been a recent rise in research on search techniques for dynamic  on-line  optimization  1 . the problem with most of the dynamic optimization techniques is that they take an ad-hoc approach to handling the time allocated to optimization. in dynamic real-time computing  controlling the time to find a solution is as important as the time it takes to execute that solution. the total response time of a system to a problem instance  in such domains  is the sum of the time to search for the solution  and the time to execute that solution. another major drawback of the existing algorithms is that presently they do not provide guarantees on meeting deadlines  as shown by the experimental analysis in. such algorithms have not provided tests to predict the possibility of missing a given deadline. furthermore  these algorithms do not provide a mechanism to monitor the progress of the algorithm in meeting a deadline and to signal an alarm as soon as it is discovered that the deadline will not be met. such mechanism is very useful in many applications where failure to meet a deadline is catastrophic. in such applications deadline violation should be signaled as soon as possible  in order for some contingency actions to be undertaken to prevent disaster. one of the main reasons for these limitations is that the existing approaches  1  do not adequately address the allocation of time to plan in context of the remaining time to deadline. 
　　this paper examines an on-line parameter tuning approach to address the above problems. this approach uses the information available for the current problem instance at various stages of the planning procedure to control the time allocated to planning. based on this technique we introduce a new algorithm called self-adjusting real-time search algorithm  sarts  and characterize its effectiveness theoretically. a major contribution of sarts is its ability to adapt the parameters of the search  planning  process based on the remaining time to deadline  i.e. slack  and on the estimated execution costs  in order to improve deadline compliance. feasibility tests are provided that enable the algorithm to predict deadline violation prior to the deadline. sarts is able to continue monitoring the progress of the problem solving effort towards the goal during problem solving. this capability enables this algorithm to detect initially inconclusive tasks that turn out to be infeasible. sarts is a progressively optimizing algorithm in the sense that it will continue to improve the solution quality as the time constraints are relaxed. the algorithm finds the optimal solution if adequate planning time can be allocated in presence of larger slacks. the paper also provides methodologies for analyzing the predictive power of real-time search algorithms. 
　　the remaining sections of this paper are organized as follows. section 1 contains a formal statement of the problem addressed in this paper. section 1 provides the specification and theoretical analysis of sarts. section 1 provides experimental evaluation of sarts. finally  section 1 provides a set of concluding remarks. 
1. problem statement 
　　a state space can be represented by a graph g v e  that consists of a set of nodes v  and a set of edges e connecting some of the nodes in the graph. a node viev in the graph represents a certain configuration of the environment called a state. an edge  vi  vj ee in the graph represents a transformation function in the state space that transforms a node vi  at one end of the edge to the node vj at the other end of that edge. based on the size of the state space  availability of information and the nature of the problem solving  the complete state space may not be generated and stored prior to the start of problem solving. associated with each edge  vi  vj ee is an execution cost cev|v  which is regarded as the cost of transforming vi  to vj  or the cost of traversing the edge  vi  vj; . 
　　problem solving in many important applications can be modeled as a problem of searching for and executing a path p in g before deadline d  that connects  transforms   via edges in g  the start node  s  to the goal node  g . associated with the search phase  also referred to as planning  is a cost cpp that signifies the time that was taken by the search algorithm to find path p. associated with the execution phase is a cost cep that signifies the time that was taken by the system to execute path p. the total response time tresp of performing a task is defined as the sum of the costs of planning and execution phases  i.e. tresp -cp + ce . the planning phase of a task consists of generating and evaluating a set of nodes in the state space  in order to find a solution path for a given problem instance. expansion of a node in g by the search algorithm refers to the process of generating the successors of that node in the graph. the successors of a node vt are the set of all the k nodes  v| ... vk  which are connected to vi via direct edges  vi  vj  ...  v  vk . a heuristic function h n g  is a function that provides an estimate of the distance between node  n  and the goal node  g . evaluation of a node  n  in g by the search algorithm refers to the process of examining certain characteristics of the node such as its actual distance from  s'' or its estimated distance from  g'' via a heuristic function h n g   and possibly ordering a set of nodes based on those characteristics. the execution phase of a task consists of applying the transformation functions associated with each edge on a solution path p  in order to reach the goal node  g  from the start node  s . using the above definitions  the underlying problem of performing a task in this model can be specified formally as follows. 
given a graph g v e   a start node  s   a goal node 
 g  and a deadline d  a real-time problem solver needs to search 	for 	and 	execute 	a 	path 	p 	= 
  s v    v  v1    vm g   that connects  s  and  g''. to maximize the following objectives in decreasing order of priority: 1  predict possible deadline violation as soon as possible  i.e. well before the deadline d arrives   1  maximize the probability of searching and executing the path p before the deadline d  i.e. maximize  t. tresp   d    and 1  if time permits  continue to improve the solution. 
　　in this paper  we concentrate on analyzing the effectiveness of sarts in accomplishing the first two objectives. the discussion of the behavior of sarts in terms of the third objective has been covered elsewhere  and is  thus  omitted from this paper. we show that the predictability of sarts is related to the accuracy of its heuristic functions and that the expected value of its predictability improves as the accuracy of the heuristic estimates increases. in our analysis of sarts's ability to comply with deadlines  we separate different features of sarts in different algorithms  in order to observe the effect of each feature in isolation. 
1. self-adjusting real-time search  sarts  
to perform real-time tasks by their deadlines  
sarts plans partial solutions for a task and executes those partial solutions in interleaved planning and execution phases. the plan-execute phases are repeated until a goal is reached  or until deadline violation is predicted. sarts uses a novel on-line parameter tuning and prediction technique to determine the time of a planning phase  and to predict deadline violation ahead of time. the allocated time to planning in this search algorithm is selfadjusted based on what is known on-line about the nature of the problem and the problem instance. the algorithm continually self-adjusts its parameters based on the remaining time to deadline. to determine the maximum time allowable for planning  sarts estimates the slack  i.e. the difference of remaining time to deadline and the estimated execution time to reach the goal . the larger the slack  the greater is the allocated time to planning. slack can also be used to detect infeasible problem instances based on the predicted maximum time allowed for planning  e.g. negative values . slack-based determination of planning time is useful for improving the dependability via prediction of deadline violation. it also makes the algorithm progressively optimizing for many application domains where solution quality can improve monotonically with additional planning effort. in these domains  larger slacks lead to larger planning times which  in turn  result in improved solution quality. 
　　during the plan phase of cycle i  a partial path from the start node s i  towards the goal is planned. the plan phase of a cycle is terminated when allocated time to plan runs out  i.e. cp i    ace i   1 . this stopping criterion controls the planning cost incurred in the current cycle  cp i   as a fraction  a  of the execution cost  ce i  to be incurred in the current cycle. parameter a can change the behavior of sarts in interesting ways. large value of a may allow adequate planning time in the very first cycle to plan the optimal path obviating the need of additional cycles. small values of a may restrict the planning time to a minimal in each cycle  reducing 
	hamidzadeh and shekhar 	1 

sarts to a greedy algorithm. besides controlling planning cost  criterion  1  is also effective in achieving near optimal response time in sequential plan and execute paradigms. 
　　cp i  may represent elapsed time and may depend on the number of nodes expanded during the ith cycle. the expanded nodes are those  whose descendants were generated and were added  in the correct order  to the open list during cycle i. ce i  represents the execution cost of a path s i   s i+l    where s i+l  is the most promising frontier node found by the planning in cycle i. the most promising node refers to a node that has the best potential to be on the shortest path to goal. the most promising node found in a cycle becomes the start node of the next cycle. ce i  in sarts is calculated by adding the length of the edges on the current partial path s i  s i+l   = 

　　at the end of planning in cycle i  sarts leaves a special number at the s i . this number represents the second best choice at each node on the traversed path. as the node with the best heuristic estimate is traversed  the heuristic value of the second best node at that decision point is left as the new heuristic estimate of the traversed node. a later cycle may utilize the result of a prior cycle via this special number to avoid looping in cycles indefinitely 1 . 
　　during the execution phase  the partial path planned in the plan phase of the current cycle is executed. the partial path may consist of one or more edges in the graph. the execution phase of a cycle in sarts may consist of traversing the entire partial path. planning carried out in each cycle consists of several iterations. an iteration of the sarts algorithm is similar to an iteration of a* . each iteration removes the most promising node from a list of unexplored nodes  i.e. the open list   generates the immediate children of that node  expanding a node   adds those children to the open list  and sorts the new list with the most promising node first. the iterations of sarts are treated as atomic  i.e. each iteration will carry out ail of the above mentioned tasks. 
　　we note that ce i  is undefined before the first iteration in cycle i. after an iteration in cycle i  ce i  represents the execution cost of path s i  n   where n is the most promising node at the end of the iteration. the stopping criteria for cycle i is examined after each iteration. the minimal planning in a cycle is an iteration  which makes sarts behave like a greedy local gradient descent algorithm. such a cycle is called greedy cycle. during the plan phase  greedy cycle only expands the current node s i . the set of s i 's descendants make up the open list. the most promising descendant is thus chosen at the end of planning. the execute phase consists of traversal of a single edge 
1. self-adjustment 
　　planning time is controlled as a fraction of total execution time via the parameter in sarts. the value of  may be determined at compile time to remain constant from cycle to cycle. however  in many applications  it is desirable to adjust a from cycle to cycle  as additional information becomes available. self-adaptation of a is useful in order to respond to a wide variety of deadlines in an progressively optimizing fashion or to respond to changes in the world at run-time. we define a set of basic concepts and explain how sarts self-adjusts the parameter to control planning lime based on slack. 
   let be the remaining time to deadline at the beginning of the ith cycle.  can be expressed as where d is the absolute deadline by which time 
sarts is required to plan and execute path s g   and ts i  is the starting time of cycle i. let  be the true execution time of executing a path from s i  to the goal node. is estimated at the beginning of cycle i with help from a heuristic function . note that can be expressed as the sum of ce i  over forthcoming cycles i  i+1  ...  k where goal is reached in cycle k. let 
i denote the time that sarts will allocate to plan the complete path s i  g .   can be expressed as a sum 
of cp i  over forthcoming cycles 	in general  
estimating planning time is a non-trivial problem  and can be as difficult as finding path s i  g . sarts does not attempt to estimate the value of . instead sarts controls the maximum values for planning times cp i  and  on the basis of available slack. 
lemma 1: if all cycles of sarts are non-trivial  i.e. cp i  and ce i  are large with respect to the cost of a single sarts iteration   the stodding criterion of sarts allocates approximately time for planning  i.e. for a proof see . 
　　let slack  represent the remaining time to deadline after a path from s i  to g is executed. slack provides an upper bound on the time that can be allocated to 

tions are interesting since they provide upper bounds on the possible time to plan. equations 1a and 1b show that the upper bound on the value of alpha{i  is directly proportional to slack and that shorter slack causes a reduction in the value of a i . intuitively  small slack means that there is little time for planning and that the planning process of sarts approaches a greedy local gradient descent search. we also note that the atomicity of sarts iterations imposes lower bounds on the values of a i   since the smallest amount of planning carried out by sarts in any cycle is equal to that in an iteration of a*. selfadjustment of parameter a i  must observe these bounds. it has been shown  that sarts reduces to a* for large deadlines  and that sarts reduces to a greedy local gradient descent search  if deadlines are tight leading to small slacks. 
1. prediction of deadline violation 
   a unique aspect of sarts relates to the tests that it provides to classify tasks into feasible  and infeasible tasks  based on the knowledge about the nature of the heuristic function. sarts may not accept a task  if the infcasibility tests show that the deadline cannot be met. since infeasibility tests cannot discriminate between feasible tasks and inconclusive tasks  sarts continues to monitor a task from cycle to cycle to guard against the danger of an inconclusive tasks becoming an infeasible task as time goes by. using the tests  sarts is able to predict the possibility of deadline violation ahead of time. given an application domain  feasibility tests may be designed based on the domain knowledge. infeasibility test: given an admissible heuristic function h1 s g   sarts considers a task to reach the goal node g from a start node s i  at the beginning of cycle i to be infeasible 	a negative value for shows that sarts may not be able to meet the deadline  since the slack is negative. negative slack times are indicative of the fact that the estimated total execution time is larger than the remaining time to deadline  making the task infeasible. 
feasibility test: given a perfect heuristic function h  s g   sarts considers a task to reach goal node g from a start node s i  at the beginning of cycle i to be feasible i f w h e r e a i s the cost of one iteration of a* and n is an estimate of the number of edges  decision points  to goal. the number of decision points to goal  n  depends on the distribution of execution cost per edge. for example  in a graph with the same execution costs for all edges  n can be estimated by the heuristic function  h. in general  an interval or an upper bound estimate for n can be derived from the distribution of edge execution costs for a given confidence level. we note that estimation of n does not need any assumptions about the planning cost. 
lemma 1: given h*  sarts will find and execute a solution to a problem instance within the problem's given deadline  if the problem is classified as feasible. for a proof see . 
　　note /that the discussions on a perfect heuristic are included here to argue that the correctness and predictability of the feasibility tests are correlated with the power of heuristics available for the particular domain  and that the expected utility of the tests increases with the accuracy of the heuristics. 
1. experimental evaluation 
　　in our experiments we have compared different versions of sarts with each other and with rta* n  1 . the problem instances of the experiments consist of graphs that represent the state space of all partial and complete solutions. each version of sarts focuses on a single characteristic of sarts  in order to test the effect of that particular characteristic on the performance of sarts  in isolation. 
　　we will review the basic steps of rta* n  to facilitate interpretation of our observations. at each cycle  rta* n  first creates the successor nodes of the current state. the current state is the actual position of the system. as each successor node is created  its estimated distance from the goal  i.e. h   the cost from the current node  i.e. g   and the sum of h and g  i.e. f are calculated. the euclidean distance formula is used to calculate the heuristic values. this heuristic formula is monotonic  and is guaranteed to produce optimal solutions in a*. in the case of rta*. this heuristic formula allows substantial pruning of frontier nodes without loss of valuable information in reaching a partial solution. notice that  unlike a* in which g is the value of the total cost so far  namely from the start node to the current successor node  in rta*  g is the value of the cost from the current node to each of its successor nodes. the h values are calculated via look-ahead search. the general rule of thumb is that the larger the number of look-aheads  i.e. the larger the n   the better the estimated f value  i.e. g+h  will be. however  we encountered cases in which the greater lookaheads led the algorithm to more costly solutions. also  one must note that while greater look-aheads are generally helpful in finding shorter paths to the goal  i.e. lower execution cost   they require more processing and planning  i.e. higher planning cost . once all the successor nodes and their f values are determined  the algorithm sorts these nodes with respect to their f values. the successor node with the smallest f value is chosen as the next physical move for the rta* algorithm. this process is repeated until a solution is reached. while this algorithm can not guarantee termination in the case of graphs with no solutions  it does guarantee that it will not get stuck in local minima and graph cycles. this is done by penalizing cyclic and dead-end paths  and by leaving the h value of the second best path at each decision point . the greedy algorithm is a special version of rta* n  in which the search algorithm examines only the immediate neighbors of the current node  without any look-ahead search  to make a decision about its next move. 
　　the different versions of sarts that are tested in the experiments of this section are as follows. the fl n  algorithm performs a fixed number of iterations during each scheduling cycle  starting from the current node of the cycle as the start state. during the execution cycle  this algorithm traverses the whole partial path that was planned during the scheduling cycle  i.e. fl n  may traverse more than one edge at each execution cycle . note that this algorithm is not capable of controlling the scheduling effort at run time. fl n  is also not sensitive to the remaining time to deadline. fl n  differs from rta* n  in that it performs the look-ahead search starting from the current node rather than having a separate lookahead search for each neighbor of the current node. the fa algorithm differs from fl n  in that it uses a stopping criterion similar to that of sarts  inequality 1 of section 1  to terminate a scheduling cycle. the parameter a in the stopping criterion of fa   however  is fixed from one cycle to the next. this algorithm does not adjust the scheduling effort based on the remaining time to deadline. during an execution cycle  fa traverses all edges in the partially planned path of the previous scheduling cycle. the ss algorithm is that version of sarts which traverses a single edge during each execution cycle. its scheduling phase differs from fa 's in that the parameter of ss's stopping criterion is adjusted at each cycle  based on the remaining time to deadline. table 1 summarizes different algorithms' characteristics in terms of their 
	ham1dzadeh and shekhar 	1 

forms as well as or better than rta* n   n=1 1 1  for most n. the performance of fl n  is improved over rta* n   due to the fact that fl n  expands fewer nodes by performing a top-level search starting from the current 
　　　　　　　　　　　　　　　　　　node at each cycle. figure 1 compares fl n  and fa comparison of and f a   was performed to evaluate the effect of a constant look-ahead bound versus that of a look-ahead bound that is a function of the execution costs. using a look-ahead bound as a function of the  execution costs aims at controlling the planning effort based on its tradeoff with execution cost to address minimized total response times. as is shown in the figure  performs the same as fl n  for  =1 and 1. shows much improved performance  however  for and 1. the improved performance is due to the fact that fa uses a stopping criterion that accounts for scheduling effort as well as the execution cost. 
　　comparison of sarts and fa would reveal the effect of self-adjusting parameter a based on the remaining time to deadline versus a fixed a that is insensitive to the progress of the algorithm towards meeting its deadline. in comparing the sarts and the ss algorithm we count the ratio of tasks whose deadlines were met over all 1 

　　figures 1  1  and 1 demonstrate the results of the experiments on sarts  ss  fa a   fl n   and rta* n   where n is the fixed look-ahead depth. figure 1 compares the fl n  with rta* n . this comparison was performed to evaluate the effect of a uniform-breadth look-ahead search for every neighbor of a current node versus that of an overall partial a* search which explores  more in depth  the more promising frontier nodes. rta* n  may lead to shorter paths in terms of execution costs. this algorithm  however  incurs larger planning costs than fl n . as is shown in the figure  fl n   n=1 1 1  perpossible problem instances. this formula concentrates on finding the fraction of complied deadlines over all tasks. this comparison was mainly done to evaluate the effect of partial path traversal versus single-edge traversal during each execution phase. one of the consequences of singleedge traversal is that there will be more plan-execute cycles which allow the algorithm to monitor progress towards the goal. the drawback of single-edge traversal  however  is that it does not take full advantage of the planning effort in a cycle. this approach thus leads to increased overall planning for each problem instance. figure 1 demonstrates the results of the experiment com-

paring the sarts algorithm with ss  fl 1  and fa o.l . as is shown in the figure  sarts performs as well as the best fa by self-adjusting based on slack. the ss algorithm was found to predict many more deadline violalions and incurred a larger number of false alarms than sarts. the large number of false alarm predictions in sarts caused a poorer overall deadline compliance over all problem instances. 
1. deadline violation prediction 
　　we examine the use of negative a in the infeasibility test of sarts as an indicator of possible deadline violation in this sub-section. we also examine the effect of different heuristics on predictability of sarts. we use true-negative  tn   false-negative  fn   false-positive fp  and true-positive  tp  categories  in order to evaluate the test. the prediction accuracy of the test is measured as 
 we note that the two measures of 
accuracy and true positivity together signify the dependability of an algorithm. the accuracy measures the predictive power of an algorithm. true-positivity  on the other hand  measures the deadline-compliance ability of an algorithm  since it represents the number of accepted problem instances which met their deadlines. 
　　to explore the effect of different heuristics in predicting deadline violation  we ran a set of experiments on a grid world. in a grid  the nodes are arranged to form a rectangular grid in which each inner node with coordinates  i j  is connected to all its neighboring nodes  ij+1   via an edge  where w is the 
width of the grid. an inner node is defined to be a node that is not on the periphery of the grid. for these experiments  a 1 x 1 grid was generated. 1  start  goal  pairs were examined  where each start and goal node was selected to be an inner node. 
table 1: deadline compliance of sarts with euclidean-distance function for 1 problem instances. 

　　four different heuristics were examined in these experiments. manhattan distance was used as an exact estimator of the remaining distance to goal in the grid world. as an over-estimator of the distance  we used twice the manhattan distance as one of our inadmissible heuristics. euclidean distance was used as the underestimator of the distance. the fourth heuristic is also an inadmissible estimator based on the manhattan distance with introduced error that is randomly added to or subtracted from the exact estimate each time. in the figures  the plots corresponding to different heuristics are labeled as follows.  perfect  denotes manhattan distance heuristic   admissible  denotes euclidean distance   inadmissible  denotes double manhattan distance  over-estimate   and  noisy  denotes error distance. 
　　we expect the underestimating heuristic to have no false-positive instances over all deadlines. this is due to the fact that the true planning and execution costs incurred by the algorithm are expected to exceed the estimated value provided by the underestimator. in using the exact estimator of the remaining distance  we expect to see high degrees of predictability. the overestimator is expected to provide an upper bound on the true planning and execution costs incurred by the algorithm. thus  a problem instance that is predicted to meet a deadline  using this heuristic  is expected to do so. the expected behavior of the algorithm with a noisy heuristic estimator is lower prediction accuracy. 
table 1: deadline compliance of sarts with double-manhatlandistance function for 1 problem instances. 

　　tables 1 through 1 show the results of these experiments. the row heading d  in the tables  denotes deadline values  and the row heading ace. denotes the accuracy. table 1 provides the data for sarts with a euclideandistance heuristic. as expected  this heuristic provides a good infeasibility test  i.e. a problem instance that was predicted to be infeasible  did in fact miss its deadline . table 1 provides the data for sarts with doublemanhattan-distance heuristic. this estimate due to its pessimistic nature  provides 1% accuracy for all problem instances over all deadlines. this kind of heuristic is useful when missing deadlines can have highly undesirable effects. note that all problem instances that were predicted to miss their deadlines  in this experiment  did in fact do so  i.e. 1% tn's . table 1 provides the data for sarts with a manhattan-distance heuristic. this estimate provides very high prediction accuracies for all problem instances  over all deadlines. we note that the few number of deviations in predicting deadline violations are due to the cost of a single iteration  i.e.   that can be incurred in a sarts cycle when the stopping criterion is met. examining the problem instances that were not correctly predicted by sarts  using a manhattan distance heuristic  revealed that the deadlines were missed by one time unit  i.e.  in this experiment  in all cases. as is shown in the tables  the manhattan-distance heuristic produced the highest percentage of true-positive cases  which signifies the higher degree of deadline compliance for this heuristic. finally  table 1 provides the data for sarts with a noisy-manhattan-distance heuristic. as expected  this heuristic produced predictions with lower accuracy and lower deadline compliance even for larger deadlines. figures 1 and 1 demonstrate the effect of different heuristics on the dependability of the sarts algorithm. as is shown in figure 1  the perfect heuristic outperforms the other heuristics in its effect on deadline compliance of sarts. figure 1 demonstrates the effect of different heuristics on the predictability of sarts. according to 
	hamidzadeh and shekhar 	1 

the figure  the overestimating heuristic enables sarts to provide 1% predictability. the perfect and the admissible heuristics perform similarly. the perfect heuristic  however  reaches 1% predictability sooner  at smaller deadlines  than the admissible heuristic. 
table 1: deadline compliance of sarts with manhattan-distance function for 1 problem instances. 

1. conclusion 
　　dependable real-time algorithms should strive to meet the time-constraints of a given set of tasks. these algorithms should also provide tests to detect possible deadline violations ahead of time. finally  a real-time algorithm should account for its own planning time as well as the execution cost of the solution it produces  in order to meet deadlines. sarts is a new real-time search algorithm. it allocates time for planning based on the strictness of deadline and estimated slack. the selfadjustment and monitoring of planning time is a unique 
1 
feature of sarts. for very loose deadlines and large slack  it behaves like a* and finds high quality solutions. for tight deadlines and small slack  it behaves like a greedy algorithm in the hope of reducing the planning time. sarts also provides an infeasibility predicate  which is monitored continuously to predict possible deadline violation ahead of time. experiments show that sarts provides higher deadline compliance than a wellknown real-time search algorithm. the infeasibility test is found to be reasonably accurate in the experiments for various deadlines and its effectiveness is related to the accuracy of the heuristic functions used. 
