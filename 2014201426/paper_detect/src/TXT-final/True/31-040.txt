 
new types of test-instance generators have been developed for generating random cnf  conjunctive normal form  formulas with controlled attributes. in this paper  we use these generators to test the performance of localsearch-based sat algorithms. for this purpose  the generator which produces formulas having exactly one satisfying truth assignment is especially desirable. it is shown that  i  among several different strategies of local search  the weighting strategy is overwhelmingly faster than the others and that  ii  local search works significantly better for instances of larger clause/variable ratio  which allows us to come up with a new strategy for making local search even faster. 
1 	introduction 
it is needless to say that selecting good test instances is crucial when evaluating the performance of combinatorial algorithms empirically. as a common practice  we usually include into the benchmark set both random and natural instances because both types of test instances have their own merits  and demerits . natural instances of course reflect the real world but they often lack the generality. by contrast  random instances can be obtained in relatively simple ways  by which we can know the average performance of algorithms and its growth ratio as the size of instances grows. however  critics always say that they are too artificial. 
　in the case of local search algorithms for satisfiability testing  gu  1; selman et a/.  1   the nature of local search particularly makes difficult to use random test instances. the reason is not unique: local search is incomplete algorithms  so we cannot use unsatisfiable predicates for testing. it inherently works very well for formulas having many satisfying truth assignments  solutions . henceforth we should select instances having very few solutions to test its critical performance  but it is essentially hard in the case of random instances. the only way of trying to do so is to select formulas from the so-called cross-over region  the clause/variable 
1 	automated reasoning 
ratio ~ 1 ~ 1 in the case of 1sat formulas  see e.g.   cheeseman et a/.  1l  . however  no one knows reasonable ways of proving that such instances actually have sufficiently few solutions.  by simple experiments for formulas of 1 variables  we found that formulas at the cross-over region have usually ten or more solutions if they are satisfiable.  thus one can hardly deny the criticism that random instances are too easy and are inadequate for local search algorithms. ironically  many papers claim the merit of local search mainly using random instances  morris  1; selman and kautz  1a; 1b; selman et a/.  1 . 
　new types of test-instance generators  called aim generators  asahiro et a/.  1   have been developed to an-
swer such criticism about random sat instances. they are also random generators but accept several parameter values to control attributes of the generated instances. in the present situation  the most important attribute is the number of solutions. aim generators include the generator  called k onesat-gen  which produces ksat formulas having exactly one solution over a wide range of clause/variable ratio. also  another aim generator  called ibsat-gen  can generate satisfiable instances at the clause/variable ratio when the ordinary random generator can never generate satisfiable instances. 
　in this paper  we use these new types of random instances for testing the performance of several algorithms based on local search. two major results are as follows: 
　 1  among several different strategies of local search  the weighting strategy is overwhelming faster than the others. 
　 1  our test instances made clear that local search works better for instances of larger clause/variable ratio even though the number of solutions is very few. to exploit this nature  we propose a new strategy  namely  to modify given instances so that they will become easier for local search. 
　in the next section  we survey existing strategies of local search. in section 1  aim generators are briefly described. in sections 1 and 1  we present our experimental work and show the two major results mentioned above. 


	cha and iwama 	1 
 1  select  again randomly  a pair of clauses a and b in such that a covers b  if any . we remove the  same or smaller  clause b from 
 1  construct a random clause a and add a into 
step 1. note that each of  1 - 1  keeps unsatisfiability of and therefore  is always unsatis-
fiable. so  repeat step 1 as many times as we wish  for example  until all clauses include three literals and sufficient number of clauses are generated. 
　konesat-gen can be obtained by modifying satgen as follows: we start with a simple initial formula having only one solution instead of  similarly as ksat-gen  konesat-gen first creates a random cell cans. then it constructs the initial formula such that it has exactly one solution which is induced by cans. 
let  for example  	for variables . then the initial formula is finitial = 
 one can easily verify that fnow becomes 
true only if one sets 
1 .  ii  just as sat-gen  konesat-gen repeats to apply the four rules appropriately until the parameter values of the formula fit the specified one. it should be noted that these rules never increase the number of 
solutions. however  rules  1  and  1  may decrease the number of solutions  i.e.  may change the formulas into unsatisfiable ones. therefore  we have to be careful when applying those rules. actually several details are needed to make the formula 1sat and to make it satisfy the literal distribution. see  asahiro et a/.  1  for those details. 
　instance generators based on the same idea  i.e.  generating instances with controlled attributes  especially with predetermined solutions  have been developed for 
other problems like the hamiltonian circuit problem  iwama and miyano  1a  and the logic optimization problem  iwama and hino  1 . all these generators generate instances from their solutions. so  if one can reverse this solution-to-instance process  then it might allow  cheating . we have developed how to guarantee the security of generators in this sense  iwama and miyano  1; 1b . 
	1 	strength of clause weighting 
we tested several local search algorithms using the random formulas described in the previous section. random formulas are denoted by   where t is r  pure random generation   o  generated by 1nesat-gen  or y  generated by 1sat-gen   n is the number of variables  and r is the clause/variable ratio. for example  ol1.1  means random formulas of 1 variables  of 1 ratio and generated by 1nesat-gen  i.e.  having exactly one solution. 
table 1 shows the performances of several algorithms. 
each entry shows the average number of cell moves  the upper portion  and the average cpu time in second over 
sparc station 1  the lower portion . the average was 
1 	automated reasoning 

taken for 1 instances. if an algorithm does not stop within specified max cell moves for some instances  we also give the percentage of successful computation after the number of cell moves. the max cell moves is 
1 1 for o1.1   1 for ol1 all ratio  and 1 for the others. since our implementation of algorithms was not so polished  the figures for cpu time should be used only for relative comparison. 
　since the local search algorithms depended on luck in principle  we cannot avoid a large diversity of computation time. to observe this diversity we conducted three experiments: fig. 1 a  shows the distribution of cell-move steps for 1 different ol 1.1  instances. the rightmost shaded bar represents the number of instances that need more the 1 moves  which are three between 1 and 1  six between 1 and 1 and the worst one took almost 1 moves. fig. 1 b  shows the same distribution for a single instance where 1 searches from randomly selected initial cells are carried out. fig. 1 c  is also for a single instance where 1 searches are carried out from the same initial cell.  note that we still use randomization for tie break in moving downward.  it might be interesting that three distributions are fairly alike. 
　the first four columns of table 1 show the performance of the four existing algorithm described in section 1. one can conclude that: 
　 1  most importantly  weight is much faster than the other three algorithms. 
　 1   selman and kautz  1b  claims that gsat + rwalk is faster than gsat  but it is only for pure random instances of 1 ratio. when the ratio is larger  it is slower than gsat for y instances. 
　 1  not surprisingly  single-solution instances are much harder than other types of instances. no algorithms but weight can cope with 1-variabie instances which is of surprisingly smaller size than the result obtained using pure random instances  morris  1; selman and kautz  1a; 1b; selman et a/.  1 . 
one should note that it is a merit that we can use smaller-sized instances to test algorithms since they make it easier to analyze the behavior of algorithms for the purpose of possible improvements. 
　 1  generally speaking  local search works better for instances of larger clause/variable ratio. this will be more considered in the next section. 
　since weight is overwhelmingly good in its basic form  it is natural to try to seek its improvement rather than to try to find completely new strategy. the fifth column of table 1  w+mflip  is the combination of weight and restart. the last column  w+rcell  is combination of weight with prohibiting recent cells  i.e.  when moving to a neighboring cell  the cells that have been visited in the last ib rounds are excluded from the candidate. revisiting the same cell many times appears to be redundant  which is suppressed by this rule. unfortunately both attempts do not seem to be successful. we learned by experiment that weight occasionally moves forward and backward between two cells until the number of overlaps at both cells increases sufficiently large. this action appears to be important  which is prohibited if one imposes the prohibiting-recent-cell rule.  note that in the case of gsat  this rule certainly shortens the computation time as much as 1%.  
　we also experimented with different weighting mechanisms. the basic type is  i  to add a unit weight  1  to each clause covering the current cell. other ways experimented are:  ii  add 1 to each clause   iii  add a real value to each clause that is minimum enough to get rid of the current local minimum   iv  add a random value between 1 and 1 to each clause and  v  add 1 to a single clause selected at random. again we were not able to see any important difference in the performance. for example   steps  cpu time  success percentage  of 
 v  for o1.1  is  1  1  1  against  1  1  1  of the basic method above mentioned. 
1 	increasing clause/variable ratio 
as discussed in the previous section  weight is much better than the other local search algorithms but its further improvement seems to be hard. then what about changing not the algorithm but the instances so as to become easier for the algorithm  this might be hope-
ful if we can exploit the fact that local search generally works better for formulas of large clause/variable ratio. 
　before discussing the way of increasing the ratio  what is the reason for the above fact  fig. 1 shows the transition curve of the number of overlaps  without counting the weight  during the course of traversing the cells. 
 the curve was first used by selman et al.  selman and kautz  1b . in that paper  the curve is only decreasing for unknown reasons. in the present case it is no longer decreasing but includes many ups and downs.  in fig. 1   a  is the curve for ol1.1  and  b  is for ol1.1 . note that the average overlaps at each cell for  a  is 1 since a single clause of three literals covers 1 out of the total cells and there are 1 clauses in an ol1.1  instance. this average number is 1 for  b . see fig. 1 a . the number of overlaps becomes under 1 very quickly and never becomes more than 1 after that until it gets to the solution. this few overlaps should be very rare  since the average is 1. 
　hence one would first speculate that the algorithm only searches a small number of cells by moving back and forth. that is not very true: we counted the number of new cells  cells that have never been visited before  at each period of the execution of weight for ol1.1  instances. in near-average cases which need roughly 1 cell-moves  the ratio of new cells is 1% for 1th moves  1% for 1th-1th moves  1% for 1th-1th moves and 1% for 1th-1th moves. thus it seems that there exists ''a narrow valley  which eventually reaches the solution. figs. 1 a  and 1 b  show the transition of the hamming distance between the current cell and the solution corresponding to figs. 1 a  and 1 b   respectively. one can see that this valley is quite long. 
	cha and iwama 	1 
in the case of high clause/variable ratio  as shown in 
fig. 1 b   this  valley  is not so deep or the number of overlaps in the valley is as large as between 1 and 1. therefore  there seems to be a nice  slope  down to the solution which begins from a fairly distant place from the solution. thus the probability of running across this slope is much higher than fig. 1 a  where the valley is quite flat. 
　in order to increase the number of overlaps  the simplest way is to add random clauses. however  one should be careful because adding clauses destroy many solutions. what we propose in this paper is to add resolvents: suppose that clauses a and b include exactly one common variable x and x appears affirmative in a and negative in b. then  the resolvent of a and b is the clause which includes the literals of a except x and those of b except x. it is well known that adding resolvents does not destroy any solution. 
　for experiment  we used o 1.1 . the number of added resolvents  mostly clauses of four literals  is changed from 1 to 1. then the number of added clauses v.s. the number of cell-move steps and cpu time of weight is as follows: 
	1 	1 /1 
1 	1 /1 	1 /1 
	1 	1 /1 
　thus there is a clear tendency that weight runs faster as the number of added resolvents increases. it would be reasonable to claim that the number of cell moves  1 when 1 resolvents are added  is significantly less than 1 of table 1  since it was very hard to improve the figure by  say  even 1%  by many other attempts described in section 1  most of them increased the number of steps . one can notice  however  that the cpu time increases because it takes more time to compute the number of overlaps at neighboring cells. we need more experiments to claim that the decreased number of cell moves will become more important than the increase of computation time necessary in each cell move. thus this approach is somehow hopeful. however  we should try to find better ways of adding clauses: see fig. 1 which illustrates  just as fig. 1  the transition curve of overlaps when 1 resolvents are added. although a lot of clauses are added  the  depth  of the valley is still very deep or we can find very little improvement from fig. 1. actually we tried some attempts such as adding a clause a + b for two clauses a and b such that they overlap with each other and the number of overlaps there is much less than the average. however  no good results are obtained at this moment. 
1 	concluding remarks 
our requirement for good test instances is twofold: one is that they can make clear the performance difference of different algorithms. the other  which might be more helpful  is that they can give us some hint to improve the algorithms. the main purpose of this paper is to claim 
1 	automated reasoning 
that our new type of random instances can play both roles  section 1 for the first role and section 1 for the second role . of course  there remain a lot of possibilities for further work in both roles. 
　an important question is whether local search is really better than davis-putnum-type algorithms and for what kind of instances it is so. for example  csat developed by dubois et al.  dubios et al  1   runs in almost the same number of branches for ol1.1  as the number of cell-visits of weight. answering this question would be one of the most urgent requirement in this field. 
