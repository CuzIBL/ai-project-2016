 
localization is the problem of determining the position of a mobile robot from sensor data. most existing localization approaches are passive  i.e.  they do not exploit the opportunity to control the robot's effectors during localization. this paper proposes an active localization approach. the approach provides rational criteria for  1  setting the robot's motion direction  exploration   and  1  determining the pointing direction of the sensors so as to most efficiently localize the robot. furthermore  it is able to deal with noisy sensors and approximative world models. the appropriateness of our approach is demonstrated empirically using a mobile robot in a structured office environment. 
1 	introduction 
to navigate reliably in indoor environments  a mobile robot must know where it is. over the last few years  there has been a tremendous scientific interest in algorithms for estimating a robot's location from sensor data. a recent book on this issue  borenstein et al  1  illustrates the importance of the localization problem and provides a unique description of the state-of-the-art. 
　the majority of existing approaches to localization are passive. passive localization exclusively addresses the estimation of the location based on an incoming stream of sensor data. it rests on the assumption that neither robot motion  nor the pointing direction of the robot's sensors can be controlled. active localization assumes that during localization  the localization routine has partial or full control over the robot  providing the opportunity to increase the efficiency and the robustness of localization. key open issues in active localization are  where to move  and  where to look  so as to best localize the robot. 
　this paper demonstrates that active localization is a promising research direction for developing more efficient and more robust localization methods. in other sub-fields of artificial intelligence  such as heuristic search and machine learning   the value of active control during learning 
1 	robotics 
and problem solving has long been recognized. it has been shown  both through theoretical analysis and practical experimentation  that the complexity of achieving a task can be greatly reduced by actively interacting with the environment. for example  choosing the right action during exploration can reduce exponential complexity to low-degree polynomial complexity  as for example shown in koenig's and thrun's work on exploration in heuristic search and learning control  koenig  1; thrun  1 . similarly  active vision  see e.g.   ballard and brown  1   has also led to results superior to passive approaches to computer vision. in the context of mobile robot localization  actively controlling a robot is particularly beneficial when the environment possesses relatively few features that enable a robot to unambiguously determine its location. this is the case in many office environments. for example  corridors and offices often look alike for a mobile robot  hence random motion or perpetual wall following is often incapable for determining a robot's position  or very inefficient. 
　in this paper we demonstrate that actively controlling the robot's actuators can significantly improve the efficiency of localization. our framework is based on markov localization  a passive probabilistic approach to localization which was recently developed in different variants by  burgard et aiy 1; kaelbling et al.  1; nourbakhsh et al.t 1; simmons and koenig  1 . at any point in time  markov localization maintains a probability density  belief  over the entire configuration space of the robot; however  it does not provide an answer as to how to control the robot's actuators. the guiding principle of our approach is to control the actuators so as to minimize future expected uncertainty. uncertainty is measured by the entropy of future belief distributions. by choosing actions to minimize the expected future uncertainty  the approach is capable of actively localizing the robot. 
　the approach is empirically validated in the context of two localization problems: 
1. active navigation  which addresses the questions of where to move next  and 
1. active sensing  which addresses the problem of what 
sensors to use and where to point them. 
our implementation assumes that initially  the robot is given a metric map of its environment  but it does not know where it is. notice that this is a difficult localization problem; most existing approaches  see  e.g.   borenstein et al  1   concentrate on situations where the initial robot location is known and are not capable of localizing a robot from scratch. our approach has been empirically tested using a mobile robot equipped with a circular array of 1 sonar sensors. the key experimental result is that the efficiency of localization is improved drastically by actively controlling the robot's motion direction and by actively controlling its sensors. 
1 	related work 
while most research has concentrated on passive localization 
 see e.g.   borenstein et al  1    active localization has received considerably little attention in the mobile robotics community. this is primarily because the majority of literature concerned with robot control  e.g.  the planning community  assumes that the position of the robot is known  whereas research on localization has mainly focused on the estimation problem itself. in recent years  navigation under uncertainty has been addressed by a few researchers  nourbakhsh et al.  1; simmons and koenig  1   who developed the markov navigation paradigm. however  both their approaches do not aim at actively localizing the robot. localization occurs as a side effect when operating the robot under uncertainty. moreover  as argued by kaelbling  kaelbling et al.y 1   there exist conditions under which the approach reported in  simmons and koenig  1  can exhibit cyclic behavior due to uncertainty in localization. 
　on the forefront of localization driven navigation   kuipers and byun  1   used a rehearsal procedure to check whether a location has been visited while learning a map. in  kleinberg  1  the problem of active localization is treated theoretically in finding  critical directions within the environment  under the assumption of perfect sensors. 
　in  kaelbling et a/.  1   acting in the environment is modeled as a partially observable markov decision process  pomdp . this approach derives an optimal strategy for moving to a target location given that the position of the robot is not known perfectly. in  kaelbling et al.  1  this method is extended by actions allowing the robot to improve its position estimation. this is done by minimizing the expected entropy after the immediate next robot control action. while this approach is computationally tractable  its greediness might prevent it from finding efficient solutions in realistic environments. for example  if disambiguating the robot's position requires the robot to move to a remote location  greedy single-step entropy minimization can fail to make the robot move there. in our own work  thrun et al  to appear   we have developed robot exploration techniques for efficiently mapping unknown environments. while such methods give better-than-random results when applied to localization  their primary goal is not to localize a robot  and there are situations in which they will fail to do so. 
1 	active localization by entropy minimization 
1 markov localization 
this section briefly outlines the basic markov localization algorithm upon which our approach is based. the key idea of markov localization is to compute a probability distribution over all possible locations in the environment. let  denote a location. the distribution  denoted by bel l   expresses the robot's subjective belief for being at /. initially  bel l  reflects the initial state of knowledge: if the robot knows its initial position  bel l  is centered on the correct location; if the robot does not know its initial location  bel l  is uniformly distributed to reflect the global uncertainty of the robot-the latter is the case in all our experiments. 
bel l  is updated whenever... 
... the robot moves. robot motion is modeled by a conditional probability  denoted by denotes the probability that action a  when executed at /'  carries the robot to /. in the remainder of this section  actions a are of the type  move to a location 1 meter in front and 1 meters to the right.  applied to is centered around the 
 1  
in our implementation  model of the robot's kinematics. 
... the robot senses. let s denote a sensor reading  and p s | /  the likelihood of perceiving s at i. p s   i  is usually referred to as map of the environment  since it specifies the probability of observations at the different locations in the environment. when sensing s  bel l  is updated according to the following rule: 
		 1  
here p s  is a normalizer that ensures that the bel  i  sum up to 1. 
in general  bel l  can be represented by kalman filters 
 smith et al.  1  or discrete approximation  burgard et al.  
1; nourbakhsh et a/.  1; simmons and koenig  1; kaelbling et al.  1 . p s | /   the map of the environment  is a crucial component of the update equations. it specifies the likelihood of observing s at location /  for any choice of s and /. in  moravec  1  and our previous work 
	burgard  fox  & thrun 	1 

 burgard et al.  1   p{s | i  is obtained from a metric model of the environment  and a model of proximity sensors. whereas our approach is able to exploit arbitrary geometric features of the environment   nourbakhsh et al  1; simmons and koenig  1; kaelbling et al..  1  first scan sensor data for the presence or absence of certain landmarks. 
　while our description of markov navigation is brief  it is important that the reader grasps the essentials of the approach: the robot maintains a belief distribution bel l  which is updated upon robot motion  and upon the arrival of sensor data. probabilistic representations are well-suited for mobile robot localization due to its ability to handle ambiguities and to represent degree-of-belief. recently  markov localization has been employed successfully at various sites. however  markov localization is passive. it does not provide means to control the actuators of the robot. 
1 active localization 
to eliminate uncertainty in the position estimate bel l   the robot must choose actions which help it distinguish different locations. the entropy of the belief  obtained by the following formula 
		 1  
　measures the uncertainty in the robot position: if h = 1  bel l  is centered on a single position  whereas h is maximal  if the robot is completely uncertain and bel l  is uniformly distributed. the general principle for action selection can be summarized as follows: actions are selected by minimizing the expected future entropy. 
　to formally derive the expected future entropy upon executing an action a  we have to introduce two auxiliary notations: let bela l  denote the belief after executing action a  and let denote the belief after executing o and sensing s. both   and can easily be computed 
from bel l  using the markov positioning update equations  1  and  1 . the expected entropy  conditioned on the action  can then be expressed by the following term: 

the expression  1  is obtained from the definition of the entropy  by integrating over all possible sensor values a  weighted by their likelihood  and by applying the update rule  1 . this simple  greedy principle-minimizing the expected future entropy-is the cornerstone of our active localization methods. for example  in active sensing  different actions a 
robotics 
correspond to different pointing direction of the robot's sensors. whenever the robot senses  this pointing direction is determined by minimizing the expected entropy ea h . 
1 active navigation 
active navigation addresses the problem of determining where to move so as to best position the robot. at first glance  one might use simple motor control actions  such as  move 1 meter forward   as basic actions in active navigation. however  just looking at the immediate next motor command is often insufficient. for example  a robot might have to move to a remote room in order to uniquely determine its location  which might involve a long sequence of individual motor commands. 
　for this reason  we have chosen to consider arbitrary target points as atomic actions in active navigation. target points are specified relative to the current robot location  not in absolute coordinates. for example  an action a = move 1m  1m  will make the robot move to a location 1 meter ahead and 1 
　meters to the left  relative to its current location and heading direction. additionally we take into account the cost of reaching a target point  which substantially depends on the length of the path and the obstacles on the path. the remainder of this section specifies the computation of the costs  the costoptimal path  and demonstrates how to incorporate costs into action selection. 
occupancy probabilities: our approach rests on the assumption that a map of the environment is available  which specifies which point / is occupied and which one is not. let pocc l  denote the probability that location / is blocked by an obstacle. the robot has to compute the probability that a target point a is occupied. recall that the robot does not know its exact location; thus  it must estimate the probability that a target point a is occupied. this probability will be denoted 
　　　simple geometric considerations permit the  translation  from  in real-world coordinates  t o   i n robot coordinates : 
		 1  
　here fa l  is the coordinate transformation for transforming a from robot-centered coordinates to global coordinates  assuming that the robot is at /. in essence   1  computes  for any /  the point a into real-world coordinates fa l  then considers the occupancy of this point . the expected occupancy is then obtained by averaging over all locations j  weighted by the robot's subjective belief of actually being there bel  i . the result is the expected occupancy of a point a relative to the robot. 
cost and cost-optimal paths: based on pocc a   the expected path length and the cost-optimal policy can be obtained through value iteration  a popular version of dynamic programming  see e.g.   littman et al.  1  for details . value iteration assigns to each location a a value v a  that represents its distance to the robot. initially  v a  is set to 1 for the location a =  1   which is the robot's location   and for all other locations o. the value function v a  is then updated recursively according to the following rule: 
		 1  
　here v b  is minimized over all neighbors of a  i.e.  all locations that can be reached from a with a single  atomic motor command.  1  assumes that the costs for traversing a point a is proportional to the probability that a is occupied  pocc a  . iteratively applying  1  leads to the cost function for reaching any point a relative to the robot  and hill climbing in t;  starting at a  gives the cost-optimal path from the robot's current position to any location a. 
action selection: armed with the definition of the expected entropy and the expected costs  we are ready to set the policy for selecting actions in active localization. at every point in time  the robot chooses the action a* that maximizes 
 1  
　here determines the relative importance of certainty versus costs. the choice of a depends on the application. in our experiments  was set to 1. 
　this completes the description of active navigation with the purpose of localization. note that active sensing is realized simply by pointing the sensor into the direction which minimizes the expected entropy of the action a = move q 1 . to summarize  actions represent arbitrary target points relative to the robot's current position. actions are selected by minimizing a weighted sum of  1  expected uncertainty  entropy  and  1  costs of moving there. costs are considered because they may vary drastically between different target points. 
1 	efficient implementation 
the active navigation and sensing methods described here have been implemented and tested using position probability grids  burgard et ai  1 . this technique represents the location of the robot by a discrete three-dimensional grid. to achieve the level of accuracy necessary for predicting robot motion  the resolution of robot orientation is typically in the order of 1＜  and the resolution of longitudinal information is often as small as 1cm. 
　while position probability grids are capable of approximating most probability functions of practical interest  they are computationally too expensive for active navigation. the complexity of computing the expected entropy is in 1  l  * |s|   where l denotes the set of grid-cells in the position probability grids  and s the set of distinguishable sensations. for example  for a mid-size environment of size 1  
 l  = 1 1 for the resolution specified above. if the number of possible sensations is large  computing the expected entropy is infeasible in real-time. 
　we have modified the basic algorithm in a variety of ways  to ensure all necessary quantities can be approximated in realtime. most importantly  instead of integrating over all locations l  only a small subset of l is considered  assuming that l can be approximated by a set lm of m gaussian densities with means  the center of the gaussians  are computed at runtime  by scanning locations whose probability bel l  exceeds a certain threshold. our simplification is somewhat justified by the observation that in practice  bel l  is usually quickly centered on a small number of hypothesis and approximately zero anywhere else. without this modification  action selection could not be performed in real-time. 
1 	experimental results 
the central claim of this paper is that by selecting actions thoughtfully  the results of localization can be significantly improved. the experiments described in this section were carried out using the mobile robot rhino  an rwi b1 equipped with 1 sonar sensors. 
1 	active navigation 
active navigation was tested by placing the robot in an office environment  see fig. 1 . notice that the corridor in this environment is basically symmetric and possesses various places that look alike  making it difficult for the robot to determine where it is. in this particular case  the robot must move into one of the offices  since only here it finds distinguishing features. 

fig. 1. environment and path of the robot 
　in a total of 1 experiments  random wandering and/or wall following consistently failed to localize the robot. this is because our wandering routines are highly unlikely to move the robot through narrow doors  and the symmetry of the corridor made it impossible to uniquely determine the location. in more than 1 experiment using the active navigation approach presented here  the robot always managed to localize itself in a considerably short amount of time. 
　fig. 1 shows a representative example of the path taken during active exploration  and also defines the positions and office names  1  1  1  a  b  c  used in the text. in this particular run we started the robot at position 1 in the corridor facing south-west. the task of the robot was to determine its position within the environment  and then to move into room a  so that we could see that localization was successful . after about ten meters of robot motion  it reached position 1 
	burgard  fox  & thrun 	1 

fig. 1. occupancy prob. p1cc a  at pos. 1 fig. 1. expected 

fig. 1. belief bel l  at pos. 1 
shown in fig. 1. fig. 1 depicts the belief bel l  at this point in time  more likely positions are darker . the positions and orientations of the six local maxima are marked by the six circles. the expected occupancy probabilities p1cc{a   obtained by  1   are depicted in fig. 1. high probabilities are shown in dark colors. note that this figure roughly corresponds to a weighted overlay of the environmental map relative to the different local maxima  where the weights are given by the probabilities of the local maxima. fig. 1 also contains the origin of the corresponding coordinate system. in this coordinate system a coordinate  x y  represents a target point x meters in front of the robot and y meters to the left. fig. 1 shows the expected entropies of the target points  according to  1 . as can be seen there  the expected entropy of locations in rooms is low  making them favorable for localization. it is also low  however  for the two ends of the corridor  since there the uncertainty can be further reduced. finally  fig. 1 displays the expected costs for reaching the different target points   c.f.   1  . based on the entropy-cost trade-off c.f.  fig. 1   the robot decided at first to move to the end of the corridor and progressed to position 1. 
　at this point it is important to notice that the trajectory to the target point cannot be computed off-line. this is due to unavoidable inaccuracies in the world model and to unforeseen obstacles in populated environments such as our office. these difficulties are increased if the position of the robot is not known  as is the case during localization. to overcome these problems the robot must be controlled by a reactive collision avoidance technique. in our implementation a global planning module uses dynamic programming as described in 
robotics 
	ea h  at pos. 1 	fig. 1. expected costs v a  at pos. 1 

fig. 1. ea h  + v a  at pos. 1 
section 1 to generate a cost minimal path to the target location  see  thrun and bucken  1  . intermediate target points on this path are sent to our reactive collision avoidance technique described in  fox et al  1 . the collision avoidance then generates motion commands to safely guide the robot to these targets. an overview of the architecture of the navigation system is given in  buhmann et al.  1; thrun et al.  to appear . 

fig. 1. belief bel l  at pos. 1 
　after reaching the end of the corridor  position 1  the belief state contained only two local maxima  see fig. 1 . note that this kind of ambiguity can no longer be resolved without leaving the corridor. accordingly the expected entropy of target points in the corridor is high compared to the expected entropy of actions which guide the robot into the rooms. because of the state of the doors  which only influences the cost of reaching target points  the overall payoff  displayed in fig. 1  is maximal for target points in rooms b and c. this is why the robot decided to move into the room behind him 

on the right  which in this case turned out to be room b. after resolving the ambiguity between the rooms b and c the robot moved straight to the target location in room a. fig. 1 shows the belief state at this final target point. 


　in addition to runs in our real office environment we did extensive testing in simulated hallway environments taken from  kaelbling et al.  1 . our active navigation system successfully localized the robot in every case by automatically detecting junctions of hallways and openings as crucial points for the localization task  and was uniformly superior to passive localization. the exact results are omitted for brevity. 
1 active sensing 
our positive results were confirmed in the context of active sensing. here we placed the robot in the corridor shown in fig. 1. this corridor   1m x 1m  all doors closed  is symmetric except for a single obstacle on its side. thus  to determine its location  the robot has to sense this obstacle. 

fig. 1. corridor of the department 
　to simulate active sensing  we allowed the robot to read only a single sonar sensor at any point in time. as a passive method  we chose a sensor at random  a new sensor was chosen randomly for every reading  which was the best passive approach out of a number of alternatives that we tried . this passive method was compared to our active approach  where sensors are chosen by minimizing entropy. 

fig. 1. entropy of belief states 
　the results are depicted in figures 1 and 1. fig. 1 plots the entropy of bel l  as a function of the number of sensor measurements  averaged over 1 runs  along with their variances  bars . as can be seen here  the entropy  uncertainty  decreases much faster when sensors are selected actively. of course  minimizing entropy alone is not an indicator of successful localization; even a low-entropy estimate could be wrong. 

fig. 1. estimation error 
　fig. 1 plots the error in localization  measured by the l1 norm  weighted by bel  i   for both approaches as a function of the number of sensor measurements. here  too  the active approach is more efficient than the passive one. these results demonstrate the benefit of active localization. 
1 	conclusions 
this paper advocates a new  active approach to mobile robot localization. in active localization  the robot controls its various effectors so as to most efficiently localize itself. based on markov localization  burgard et ai  1; kaelbling et al.  
1; nourbakhsh et a/.  1; simmons and koenig  1; smith et a/.  1   a popular passive approach to mobile robot localization  this paper describes an approach for determining the robot's actions during control. in essence  actions are generated by minimizing the future expected uncertainty  measured by entropy. this basic principle has been applied to two active localization problems: active navigation  and active sensing. in the case of active navigation  an extension has been developed that incorporates expected costs into the action selection  and also determines cost-optimal paths 
	burgard  fox  & thrun 	1 
under uncertainty using a modified version of dynamic programming. both approaches have been verified empirically using an rwib1 mobile robot. 
the key results of our experiments are: 
1. the efficiency of localization is increased when actions are selected by minimizing entropy. this is the case for both active navigation and active sensing. in some cases  the active component enabled a robot to localize itself where the passive counterpart failed. 
1. the relative advantage of active localization is particularly large if the environment possesses relatively few features that enable a robot to unambiguously determine its location. 
despite these encouraging results  there are some limitations that deserve future research. one of the key limitations arises from the algorithmic complexity of the entropy prediction. while a mixed-gaussian approximation made the computation of the entropy feasible for the type environments studied here  more research is needed to scale the approach to environments that are significantly larger  e.g.  looomx 1m . a second limitation arises from the greediness of action selection. in principle  the problem of optimal exploration is np hard  and there exist situations where greedy solutions will fail. however  in none of our experiments we ever observed that the robot was unable to localize itself using our greedy approach  something that often happens using only random motion during localization. 
