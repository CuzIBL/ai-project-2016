 
　　　attempts at automatic speech recognition have known several waves. 
　　　early efforts were based on the faith that speech is a string of phonemes that can be isolated and recognized one by one. this wave broke when it became clear that the physical realization of a phoneme is smeared in time and mingled with that of its neighbors  and also context and speaker-dependent. 
　　　next came the invention of the highly successful time-warping dp-matching methods  in which whole words are matched by templates. this wave is still going strong  at least in japan  but it may have reached a high mark. 
     to probe this question  we investigate the case of the  jion''  a subset of character readings that  generates  a large subset of japanese. this set has low redundancy and contains many minimal pairs. error analysis of dp-matching shows that most errors occur between pairs that differ only in their initial consonant  especially if it belongs to groups such as plosives or nasals. 
　　　combining dp-matching with limitedscope phoneme recognition could break through present limits. 
i introduction 
　　　when we listen to speech in an analytic frame of mind  we hear it  or we think we hear it  as a succession of phonemes. it seems to us that we could pick out each 
 phoneme  if only they didn't flow past quite so quickly. this view now seems naive  repp 1   but it was natural enough when speech recognition began. 
　　　systems based on phoneme recognition run into a variety of troubles. first  the boundary between successive  phonemes  is elusive  the segmentation problem . 
second  once a phoneme segment is fenced off  it is found that it bears little ressemblance to the same phoneme uttered elsewhere in the speech stream  or in isolation  the co-articulation problem . worse still  the range of possible realizations may overlap that of a different phoneme. finally  even if a taxonomy of all phonemes in context is attained  it proves different from speaker to speaker  the speaker-dependency problem . 
　　　the task of designing systems to reliably extract and sort out all  phoneme  cases and cues is thus formidable. it drained the energy of early researchers  and the results were disappointing. 
　　　the invention of dynamic programming time-warp matching came as a relief because it provided a simple  elegant  and immediately appliable method of recognizing whole words. many variants of dp-
matching have been proposed  continuous  multiple level  augmented  etc.  and its efficiency has been improved to cope with large vocabulary  multiple speakers  etc.. 
       dp-matching continues to be the object of much research in japan  1 papers out of 1 on speech at the 1 meetings of the asj . however  it may be that the efficiency of dp-matching has reached its maximum. the fundamental drawback is that the discriminating distance is calculated over a whole word. if two words differ by just one phoneme  minimal pair   the difference is  diluted  and may be masked by small variations over the rest of the word. 
　　　this is particularly so for  short  phonemes  eg plosives  in long words. these are likely to cause problems if they occur in an application's word list. 
　　　dp-matching scores are often evaluated on lists of city names. the results cannot easily be extrapolated because of the inhomogeneity and redundancy of cues in such sets. for this reason  we chose instead to perform our experiments on a set of words  the  jion   that are highly 1 s. kitazawaetal. 
representative and have low redundancy. 
　　　the word   j i o n   means  character sound   and designates the sounds that the  chinese  readings of sino-japanese characters can assume. many words in japanese are b u i l t up of   j i o n     so combinations of   j i o n   cover most of the language. many   j i o n   are minimal p a i r s   and these are representative of longer minimal pairs in which they occur. 
　　　the   j i o n   set is thus a good evaluation set  and we used it to t r y to situate the l i m i t s of dp-matching recogni t i o n methods. as expected  the score attained by dp-matching on the j i o n set is much lower than on a c i t y name l i s t . in addition  an analysis of the errors provided interesting results that we discuss here. 
	ii 	phonological structure of  jion  
     the   j i o n   correspond o r i g i n a l l y to an old chinese syllabary consisting of 1 kinds of sounds  excluding toneme difference . this syllabary was japanized and reduced when chinese characters were introduced in japanese. 
　　　the   j i o n   set has thus the following chacteristics : 
a  the number of segments is l i m i t e d ; 
b  there 	are 	only 	1 	kinds 	of 
phonological structures   i f one excepts i n i t i a l phoneme ; 
c  there are many minimal pairs   for example  /baku/ and /daku/ . 
	i l l 	dp-matching of 1  jion s 
	one male 	speaker produced the set of 
1  jion s twice. we made the f i r s t set of them the templates and the second set the object of recognition. waveforms were f i r s t low-pass f i l t e r e d at 1 khz and then sampled at 1 khz. the parameteri z a t i o n   a 1th-order lpc analysis  was carried out over 1-ms hamming windows shifted every 1-ms. 
　　　lpc cepstrum distance is used as inter-frame distance. using these local distances  the distance between the input pattern and the reference pattern is calculated by means of a dynamic programming time warping technique. as a result 
1% 	recognition 	rate 	was 	achieved. 

　　　to i l l u s t r a t e t h i s point  suppose we build a system that can recognize only the vowel parts of a word. if we input the sounds of the 1   j i o n   s   the average number of symbols confused 
 recognized 	as 	the 	same 	word  	is 
1. if we input instead a set of 1 c i t y names  the average number of confusions is 1. 
　　　table 1 shows the recognition rates of d i s t i n c t i v e features in the morphemei n i t i a l consonant. the rate for   s t r i dent  was 1%  and that for  sharp  and   f l a t   were comparatively good.  compact  was the worst  at 1%. however this result does not necessarily r e f l e c t the recognizability of the i n i t i a l consonant  as there are constraints within the set that aid recognition. for example  strident  is a feature which opposes a f f r i c a t e s / t s / and / d z / to simple stops / t / and / d / . but / t s / and / d z / can precede only / u /   and / t / and / d / only a vowel among / a /   / e / and / o / . 

the   j i o n   set experiment showed that 
dp-matching scores can be rather low on a 
word set containing many minimal pairs. it is not a worst-case set  and one could 
expect performance to be even worse if the set contained more minimal pairs or longer words  as might occur in an application. 
　　　however  the experiment also showed that the errors occur in a very limited number of configurations: mainly confusions of minimal pairs d i f f e r i n g by i n i t i a l consonants belonging to the same group  for example nasals or plosives . this suggests that combining a l i m i t e d scope phoneme discrimination method with dp-matching might d r a s t i c a l l y improve recognition scores. 
s. kitazawa et al. 1 
　　　over the last few years our laboratory has been working on obtaining high quality discrimination of consonants. our f i r s t results were on plosive discrimination  kitazawa et al 1   and nasals  kitazawa et al 1 . 
　　　the method used is based on s t a t i s t i c a l analysis of spectral parameters gathered over several consecutive frames. the method calculates canonical vectors that can be considered as optimal linear combinations of the parameters. the reader interested in the details should refer to the papers quoted. discrimination results are t y p i c a l l y 1% and 1% for plosives and nasals  respectively. 
　　　developing similar discrimination methods for a l l possible d i s t i n c t i v e features  and combining them into a phoneme recognition system would be impractical. however  by concentrating on a limited set of features  it should be possible to 
improve results of dp-matching. 
	it 	can 	be 	argued 	that 	speech 
features are 	designed to be recognized by humans rather 	than by machines. 	a human relies heavily 	on syntax  	semantics and context to 	supplement the 	acoustic cues  and a 	machine that 	cannot do the same is sure to be limited in performance. 
　　　however  our opinion is that there is s t i l l much that can  and should be improved in bottom-up speech recognition before we should give up and l e t top-down methods take over. 
ack nowledg ements 
　　　authors wish to express their thanks to dr.alain de cheveigne for his c r i t i c i s m and suggestions. 
