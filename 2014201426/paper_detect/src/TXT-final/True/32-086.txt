 
users' waiting time for information on the www may be reduced by pre-sending documents they are likely to request  albeit at a possible expense of additional transmission costs. in this paper  we describe a prediction model which anticipates the documents a user is likely to request next  and present a decisiontheoretic approach for pre-sending documents based on the predictions made by this model. we introduce two evaluation methods which measure the immediate and the eventual benefit of pre-sending a document. we use these evaluation methods to compare the performance of our decision-theoretic policy to that of a naive pre-sending policy  and to identify the domain parameter configurations for which each of these policies provides a clear overall benefit to the user. 
1 	introduction 
users typically have to wait for information they require from the world wide web  www . excessive waiting increases user dissatisfaction. we propose to address this problem by means of a system placed on a single server site  which presends documents to a user. a decision-theoretic approach is taken  where documents that yield the highest expected positive benefit are pre-sent. this requires the consultation of a predictive model that anticipates a user's document requests from the www site  zukerman et al.  1 . the calculation of the benefit to the user takes into account the increased cost of transmitting documents that are not requested versus the reduction in waiting time for documents that are requested. 
　in preliminary work  nicholson et al.  1   we used a simple time markov prediction model and evaluated the presending system only in terms of its immediate benefit to the user. the contributions of this paper are:  1  the evaluation of the eventual benefit to the user as a result of pre-sending a 
　document  for different operating conditions;  1  the comparison of the decision-theoretic pre-sending policy with a naive policy which pre-sends the document that is most likely to be requested  bestavros  1 ; and  1  the incorporation of a hybrid prediction model  zukerman et al.  1  into both pre-sending policies. 
　in the next section we discuss related research. we then consider the features of our domain  followed by a description of our prediction model. in section 1  we describe the decision-theoretic model used for pre-sending documents. in section 1  we consider our evaluation methods  followed by the presentation of our results  and concluding remarks. 
1 related research 
the recent growth in the www and on-line information sources has inspired research on agents that help users derive the most benefit from the vast quantities of available facilities and information. these agents may be broadly classified into recommender systems  which recommend facilities or information items likely to be of interest to the user  e.g.   lieberman  1; joachims et al.  1   and action systems  which go one step further  performing actions on the user's behalf  e.g.   bestavros  1; balabanovic  1; nicholson et al.  1 . both types of systems use prediction models which anticipate a user's preferences  including documents of likely interest  e.g.   maes and kozierok  1; lieberman  1; bestavros  1; joachims etal.  1 . 
　the action system described in this paper is most closely related to the system described in  bestavros  1   which pre-sends documents to a user by consulting a prediction model obtained from the behaviour patterns of the general population. our system differs from bestavros' in two aspects:  1  we consult a hybrid prediction model which combines four markov models  zukerman et al.  1   compared to bestavros' simple time markov model; and  1  we use a decision-theoretic model for pre-sending documents  while bestavros uses a naive strategy which pre-sends the document with the highest probability of being requested. 
1 domain features 
the most salient features of the www are its large size and constant variation. the first feature suggests that a presending system  such as that developed here  should use approximate models to predict a user's requests. the second feature suggests that such a system should dynamically adapt to changes  or at least be easily modifiable. further  since we are modeling a single server site  a feature particular to our system is that our observations of the user's document requests constitute a partial record of the user's movements through the internet. this is because not all the user's movements to external locations are observed  and requests for documents already in the client's cache are not observed. 
　the pre-sending system described in this paper requires a predictive model which anticipates a user's document requests on the www. the predictive model presented in the next section takes into account the above features as follows. 

1 	uncertainty and probabilistic reasoning 

it is based on markov models which approximate users;' document requests on the www. these models represent external or unseen locations  and are trained from data collected over a period of time  and can be easily re-trained . 
　the training data was obtained by logging our web server over a 1 month period. the results presented in this paper are based on a 1-day time window of these logs. 
　the collected data points were pre-processed  see  zukerman et al  1  for details  and divided into sessions. each session contains the temporal sequence of requests from a single client  where a request takes the form {referer requesteddoc time size}. the ref erer is the current internet location  http address  of the user. this location may be a local  previously requested  web page on the server site  an external web page on another internet site  or * '-'  empty  when the information has not been provided. the reques teddoc is the http address of the document being requested by the client. the time is a time stamp  in seconds  indicating when the request was received. the size is the number of bytes in the requested document 
　after pre-processing  our data consisted of 1 1 document requests  where 1 clients at 1 referer locations requested 1 different documents  one session per client ; 1 of the referers were requested documents  and there were 1 different referer/document combinations. 
1 prediction model 
we estimate  previous requests   where  is the next document requested and  is the time of this request. to make the prediction problem computationally tractable  we assume that the distribution of the time for requesting a document is independent of the document that is requested  that the next document requested depends only on the previous documents  and that the time of the next request depends only on the time of the last request  tr. this last assumption over-simplifies our domain  since the size of a document affects both its transmission time and the user's reading time  thereby influencing the time of the next request. in the future  we intend to factor the size of a document into the estimation of the time of the next request. according to our assumptions  
 previous requests  = 
 previous documents  
　　the estimation of is described in section 1  and that of previous documents  in section 1. 
1 next document is requested at time t for our current database  based on 1 days of data   the time between successive requests from a client ranges from 1 to 
1 1 seconds 
　figure 1 shows the cumulative frequency distribution of the inter-arrival time between consecutive requests  plotted against a log scale . this distribution indicates that approximately 1% of document requests from a client are made within 1 seconds of the previous request  1% are made within 1 seconds  and 1% within 1 seconds. as shown in figure 1  a combination of three functions provides a good fit for the data  these functions were found using a weighted least-squares method . therefore  we use the following fitted probability function to estimate the probability of receiving a request at a particular time. 

figure 1: cumulative frequency distribution of document requests plotted against a log scale of the inter-arrival time be-
and fitted with three functions. 
1 a particular document is requested next to predict the document requested next  we use a hybrid model called maxhybrid  which combines four basic markov prediction models: time  second-order time  space and linked space-time. the time-based models consider temporal information only. the time markov model predicts a user's next request based only on the document that was requested last  and the second-order time markov model makes this prediction based on the last two requested documents. the space markov model  which was motivated by the observation that normally people follow links on web pages  adds structural constraints to the time markov model. in the space markov model  the probability of a document being requested depends only on the referring document  which has a link to the requested document. the linked space-time markov model also combines temporal and structural information. in this model  the probability of a client requesting a document depends on both the last requested document and the referring document of the last requested document. a detailed description of these markov models and their training procedure appears in  zukerman et al.  1 . 
　the maxhybrid model was built based on empirical evidence obtained from the performance of these four basic models. its performance in predicting the next requested document was compared with that of the basic models and other hybrid models  producing significantly more accurate predictions than any of these models  zukerman et al.  1   
　after receiving a request for document dr  the maxhybrid model consults the four markov models  and makes its prediction using the model which made a prediction with the highest probability  this may be a different model after each observation . the decision-theoretic model then uses the probabilities obtained from the selected model to calculate the expected benefit from pre-sending a document. 
1 decision-theoretic model 
the decision-theoretic model selects for pre-sending the document whose transmission has the highest positive expected immediate benefit. this benefit is the difference between the 
	albrecht  zukerman  and nicholson 	1 


figure 1; time line for a request-pre-send sequence. 
expected additional cost of pre-sending a document that is not requested next and the expected reduction in waiting cost due to the pre-sending of a document that is requested next. 
　our decision-theoretic model considers for pre-sending documents that may be requested next by a user  rather than documents that may be requested subsequently. this may be justified by examining the circumstances under which the benefit of pre-sending a subsequently requested document is higher than the benefit of pre-sending a next requested document. this would happen when there is high uncertainty regarding the document to be requested next  but many subsequent requests converge on the same document. a preliminary inspection of our www site shows that only 1% of the pages can be reached by more than one path of length 1 or 1. hence  our decision-theoretic model  which considers only paths of length 1  is justified as a promising initial approach. in the future  we intend to investigate policies which consider pre-sending documents that may be requested later by a user  and to compare their performance with that of our current policy. 
expected additional transmission cost 
let be the document requested by the client at time and the document selected for pre-sending.1 the actual pre-sending is done at time and the next document  is requested at time   figure 1   the additional cost of pre-
is1 
　the top line of this formula reflects a situation where no further requests are made by the user  dr1  = 1  or the document which was pre-sent is not the one requested next. the second line reflects a situation where the pre-sent document is requested next  hence no unnecessary costs are incurred. 
　therefore  the expected additional cost of pre-sending a document ds at time ts is 
ec ds ts  	~ 	cpb x size ds x 
              pt drl = 1  + pr dr1 = ds & dr1 = 1     where the probabilities are obtained from the maxhybrid prediction model  section 1 . 
expected reduction in waiting cost 
if the system pre-sends the document the client requests next  then the waiting time is reduced or even removed. since the benefit of pre-sending a document is formulated in terms of cost  we multiply the formulas for the reduction in waiting 
   *ln principle  more than one document may be selected for presending. however  at present we consider only a single document. 
1
   ts - tr was empirically found to be about 1 milliseconds  section 1 . 
time by a cost per second  cps   which reflects the inconvenience caused to the user from having to wait for a document. 
represent the reduction in the 
cost of waiting for the desired document where bps is the transmission rate  expressed in bytes/sec. that is  if no further requests are made by the user  then the reduction in waiting cost is zero. if the pre-sent document is requested next  but has not arrived in its entirety when the request is made  the user will have to wait only for the portion of the document that still remains to be sent. if the pre-sent document is requested next and is fully in the cache at the time the request is made  then the user will save the time it takes for the entire document to arrive. finally  if the pre-sent document is not the one that is requested next or the next request arrives before the system decides which document to pre-send  then the user will have to wait for the entire document  so there is no reduction in waiting time. 
　therefore  the expected reduction in the cost of waiting for after document ds was pre-sent at time ts is 
where p is the density function for requesting a document at time t  derived from the probability function described in section 1  and the document-request probabilities are obtained from the maxhybrid prediction model  section 1 . 
expected immediate benefit 
the system pre-sends the document which has the highest expected immediate benefit  provided it is positive  doing noth-
ing has an expected benefit of 1 . expected-immediate-benefit  
1 	evaluation methods 
we consider two methods for the comparative evaluation of our decision-theoretic model versus the naive pre-sending policy: immediate benefit and eventual benefit. the immediate benefit method operates under the no-memory/nextrequest scenario  while the eventual benefit method operates under the 1-hours/cache and oo/cache scenarios. the first scenario  which was also used in  zukerman et ah  
1   was designed to assess the performance of a prediction model regarding the next requested document only. the second and third scenarios assume that the client has a cache and the server keeps track of the cache's contents. in the second scenario  a pre-sending action is considered successful if the 

1 	uncertainty and probabilistic reasoning 

pre-sent document is requested within 1 hours of being present  1 hours appoximates one work day; 1% of the sessions last up to 1 hours . in the third scenario  a pre-sending action is considered successful if the pre-sent document is requested at any time after it was pre-sent. 
　these scenarios also affect the documents considered for pre-sending. since for the no-memory/next-request scenario the server does not keep track of previous events  a presending policy may decide to pre-send a just-visited page  which adversely affects its performance. in contrast  a memory of 1 hours indicates that it is unnecessary to pre-send documents that were sent  either requested or pre-sent  in the last 1 hours  since they are still in the client's cache. similarly  a memory of oo indicates that any previously sent document should not be pre-sent. it is important to note that documents which are not considered for pre-sending are not ignored  in the sense that the probabilities of the remaining documents are not normalized. this is because normalization would artificially increase the probability that a document will be requested  which in extreme cases may result in the pre-sending of documents which have a slim chance of being requested. 
immediate benefit 
the immediate benefit method computes the difference between the savings due to a reduced waiting time for documents that are requested next and the cost of pre-sending documents that are not requested next. to compute this benefit we assume that the system receives a sequence of document requests from a client at times 
  after receiving and satisfying a user's 
request for document the system may pre-send a document at time 
and 
eventual benefit 
the eventual benefit method computes the difference between the savings due to a reduced waiting time for documents requested eventually during their lifetime in the cache  and the cost of pre-sending documents that are never requested during their lifetime in the cache. to compute this benefit we assume that the client has a cache of virtually infinite capacity  and consider the above-mentioned 1hours/cache and oo/cache scenarios. 
eventual-benefit= 
is the time when document 
is the additional cost due to pre-sending a docu-
ment that was never requested during a particular time span  and  is the reduction in the cost of waiting for a pre-sent document that the client requested later. 


figure 1: constructed example showing an event sequence. 
where trs. is the time ds  is requested  and memoryspan is a particular time span since a document was pre-sent  we consider two values for memoryspan  1 hours and oo  depending on the scenario . according to this formula  the user incurs an unnecessary expense when a pre-sent document is never requested or when it is requested either before it is actually pre-sent or after a time which is not realistically considered part of the session. 

that is  if no more documents are requested by the client  the waiting cost is not affected. if dri is in transit  the user will not have to wait for the portion of the document that has already arrived at the time the request is made. if the requested document is in the cache  and memoryspan has not lapsed   then the user will save the time  and cost  corresponding to waiting for the entire document. finally  if the requested document is neither in the cache nor in transit  or its transit time is larger than memoryspan  or it is requested after memoryspan has lapsed  then there is no reduction in waiting time. 
example 
we now illustrate the operation and evaluation of our presending system with a simple constructed example. consider the sequence of events in figure 1. the client requests  req  document d1  which is then sent. the decision-theoretic system is given two candidate documents for the next request  d1 and d1  each with probability 1  and calculates the expected benefits of these documents  1 and 1 respectively . d1  the document with the highest expected benefit  is pre-sent  pre   which immediately incurs a transmission cost  -1  that reduces both the cumulative immediate and eventual benefits. the next request is for document d1. the only candidate for pre-sending this time is d1  but it has a negative expected benefit  -1   so nothing is pre-sent. next  d1 is requested. since it was previously pre-sent  the eventual benefit is incremented by the reduction in waiting cost  1  and by the transmission cost  1 - to cancel the previous cost  since the transmission proved necessary . the system then pre-sends d1  the transmission cost yields -1 benefit   which is the next request  so both cumulative benefits increase by 1 - the reduced waiting cost  plus 1 - to cancel the transmission cost. the final total benefits are -1 using immediate benefit and 1 using eventual benefit. 
	albrecht  zukerman  and nicholson 	1 


 b  precision. 
figure 1: performance of the maxhybr id model. 
1 	results 
as indicated above  the results in this section were obtained from 1 days of data logged by our server. all the models were tested using 1% of the sessions for training and 1% for testing. differences noted in the results for the various prediction models are significant at the 1% level. 
　we are interested in two aspects of predictive performance:  1  recall - the percentage of requested documents that were previously pre-sent; and  1  precision - the percentage of present documents that are subsequently requested. figure 1 a  depicts the recall predictive performance of the maxhybrid model for each of our three scenarios  under the assumption that the system pre-sends the document with the highest probability of being requested next  this is effectively the behaviour of the naive pre-sending policy described in  bestavros  1  . the x-axis shows the number of documents requested by a client during a session.1 the y-axis shows the average percentage of requested documents that were pre-sent within the event memory span of each scenario  1  1 hours or oo . for example  when 1 documents are requested  the maxhybrid model has an average recall of about 1% for both cached scenarios  1 hours and oo   and an aver-

1
　　　to smooth the graph  each point on the x-axis represents a group of clients  such that the clients in each group have requested a similar number of documents. each of the first nine groups consists of 1% of the clients  while each of the remaining ten groups has 1 % of the clients. the x-value for each data point is the midpoint of the range of numbers of documents requested by the clients in a group. the final data point  has been excluded from the graph in order to view the data more clearly; this still leaves 1% of the data. 
age recall of 1% for the no-memory/next-rffeqfueat scenario. after 1 requests  the performance of the pne-sending policy under this scenario is independent of the number of requested documents. as expected  the recall performance of the maxhybrid model improves when the evaluation is in terms of its eventual benefit rather than its immediate benefit. however  its performance for the oo/cache and the 1hours / cache scenarios is essentially equivalent 
　as for recall  the precision performance of the maxhybrid model is higher for the eventual benefit evaluation method than for the immediate benefit method  figure 1 b  . in sessions where more than 1 documents were pre-sent  which constitutes 1% of the data   the precision under the oo/cache scenario rises over the precision under the 1-hours/cache scenario. this happens because in the 1% of these sessions which take longer than 1 hours  the decision-theoretic policy pre-sends more documents under the 1-hours/cache scenario than under the oo/cache scenario  where the cache holds every previously sent document . 
　since modelling a cache over more than 1 hours does not improve the recall predictive performance at all  and improves the precision predictive performance only slightly for a small portion of the data  we now compare the performance of our two pre-sending policies  naive and decisiontheoretic  only for the no-memory/next-request and 1hours/cache scenarios. we assess these policies in terms of their total benefit to a client over a session under these scenarios  while taking into account different configurations of the domain parameters described in section 1. figure 1 a  shows the average total benefit  y-axis  achieved by the pre-sending policies in terms of the number of requests in a session  xaxis  for the no-memory/next-request scenario  and figure 1 b  displays these results for the 1-hours/cache scenario  the data points on the x-axis are grouped as described for the results in figure 1 . the parameter configurations were chosen to enable a comparison between the reduction in waiting  which depends on cps/bps  and the cost of unnecessary pre-sending  which depends on cpb . this is achieved by fixing cpb and bps to 1 and 1 respectively  1 bps is a common transmission rate   and varying only cps from 1  cps/bps = 1 cpb  to 1  cps/bps =1 cpb . each line in figure 1 is labelled with a cps value and a tag that indicates the pre-sending policy  d for decision-theoretic and n for naive . for example  in figure 1 a  for 1 requests  when cps = 1  the average total benefit for the naive pre-sending policy is 1  compared to 1 using the decision-theoretic policy; when cps = 1  the corresponding average total benefits are -1 and -1 respectively. 
　we are interested in two inter-related factors:  1  the relative performance of the decision-theoretic and naive presending policies  and  1  the impact of the domain parameters. for the no-memory/next-request scenario  the decision theoretic policy consistently outperforms the naive policy. for the 1-hours/cache scenario  the naive policy performs better than the decision-theoretic policy when the relative cost of waiting becomes high enough  e.g.  cps = 1 . this is because for this cost  the naive policy  which pre-sends a document after every request  sometimes achieves a large eventual reduction in waiting cost  which offsets its losses from its unnecessary transmissions. in contrast  the decisiontheoretic policy  which is more conservative  does not always pre-send these large-payoff documents. for a lower 

1 	uncertainty and probabilistic reasoning 


figure 1: effect of the pre-sending policy and domain parameter configuration on the average total benefit. 
cost of waiting  e.g.  cps = 1   the two pre-sending policies give similar results. when the cost of waiting decreases further  e.g.  cps  1   the decision-theoretic policy gives a greater average total benefit than the naive policy. in some cases  e.g.  cps = 1   the decision-theoretic policy gives a positive average total benefit  while the naive policy yields an overall negative benefit. for our lowest waiting cost  cps = 1   the decision-theoretic policy gives a small negative total benefit in both scenarios  compared to much larger negative total benefits for the naive policy for cps  1. since our decision-theoretic policy does not pre-send when it computes a negative expected benefit  this overall small negative total benefit can be explained by the fact that our prediction model is only an approximation. 
　the effect of the pre-sending policy  the scenario and the domain parameters can also be seen in the average percentage of requests for which the system pre-sends a document. under the no-memory/next-request scenario  the naive pre-sending policy pre-sends a document 1% of the time  it fails to pre-send only when the request was unseen in the training data . under the 1-hours/cache and oo/cache scenarios  it pre-sends only 1% and 1% of the time respectively  nothing is pre-sent when all the candidates are already in the client's cache . the decision-theoretic policy pre-sends much less often than the naive policy  becoming more conservative as the importance of the waiting time decreases. for example  for cps=1  documents are pre-sent 1% of the time for the no-memory/next-request scenario and 1% for the 1-hours /cache scenario  dropping down to 1% and 1% respectively for cp$ = 1. 
　for the test data used to generate these results  the decisiontheoretic pre-sending system makes a decision in about 1 milliseconds of cpu time on a sgi indy r1  compared to about 1 milliseconds for the naive pre-sending system  due to the extra time taken to compute the benefits . the off-line training time to build the four markov models used by the hybrid prediction model is about 1 millisecond per request. 
1 conclusion 
we have presented two systems for pre-sending documents on the www  one based on a decision-theoretic model  and another based on a naive approach. both systems consult a markov-based model which predicts the next document request. we have compared the performance of these systems using two evaluation methods  immediate benefit and eventual benefit  and considering several domain parameter configurations. our evaluation shows that the decision-theoretic approach generally outperforms the naive approach  except when the penalty for waiting for a document is extremely high  cps/bps =s 1 cpb  and the evaluation is done using the eventual benefit method. in addition  it is better to use the decision-theoretic approach for pre-sending documents  rather than doing nothing  in all situations where the waiting time is relatively important to the user 
acknowledgments 
this research was supported in part by grant a1 from the australian research council. 
