bacon: a production system 
that discovers empirical laws 
patrick w. langley 
carnegie-mellon university 
pittsburgh  pennsylvania 1 
introduction 
　　　in recent years researchers have produced a number of programs capable of scientific-like behavior. each of the systems  dendral feigenbaum and lederberg  1   meta-dendral buchanan  feigenbaum and sridharan  1   mycin 
 davis  buchanan and shortliffe  1  and am  lenat  1  could arrive at rules that explained observed data. in this paper i discuss another system  bacon  which discovers simple empirical laws like those found by early physicists. 
task environment 
　　　bacon's task environment is an a r t i f i c i a l two-dimensional universe in which labeled objects interact. the program has direct access to a set of primitive attributes  such as the x-coordinate  color and velocity  specified by the programmer. the values of these attributes change across objects and across time according to a set of laws determined by the programmer. such a law might be that the third differential of each object's distance from the center of the universe is a constant  with a different constant for each object . 
program structure 
　　　bacon is implemnted in the production sytem language ops  forgy and mcdermott  1 . the production system framework's advantage in this task is that it allows one to write a small set of general  regularity detectors . these search in parallel through the data the program has collected  in the form of attribute-objecttime-value 1-tuples  and which are s t i l l in 
working memory. if one of the described regul a r i t i e s is present in the data  it  leaps out  at the system and appropriate action is taken. if the regularity is a constancy  a generalization across the relevant dimension  time  objects  or both  is made and tested. if the value of an attribute consistently increases or decreases over time  a new attribute defined in terms of the old attribute's change over time is constructed  e.g.  acceleration is constructed from velocity  and considered further. if the value of one attribute goes up as the value of another goes down  a new attribute defined as their product is considered. eventually  a higher level attribute employing a l l the a t t r i butes mentioned in the programmer's law is constructed and discovered to have a constant value; this is bacon's version of the law. 
　　　along the way  whenever some generalization about the value of an attribute is confirmed  bacon adds productions that enable prediction of the value and  if the attribute is nonprimitive  prediction of some of i t s component's values in terms of other component's values. the system can also qualify its hypotheses. if counterexamples are found to a generalization  r e s t r i c t ions can be added in the form of exceptions if the generalization was across objects and in the form of exceptions and upper and lower bounds if the generalization was across time. in fact  once an hypothesis is formed  it is never rejected. it is always stored in the permanent production memory  though perhaps in greatly qualified form. 
　　　i n i t i a l l y   the data collection process is unintelligent. attributes are generated randomly and their values examined across a number of objects and times. however  once regularities have been detected  these regularities serve to direct the search. 
conclusions 
　　　in summary  bacon discovers empirical laws by using two complementary techniques. the f i r s t is the detection of regularities in data  for which production system formalisms seem ideally suited. this technique leads to useful generalizations  but it also directs the second technique  the construction of new attributes in terms of more primitive ones. together the two lead the search for more data which could lead to further generalizations. 
　　　as implemented  bacon has a number of limitations as a law discoverer. first  it cannot formulate conditional laws  in which the conditions are restrictions on the values of related attributes; however  it seems plausible that the regularity detection technique could be used here as well. second  the system has special knowledge that time and objects are useful dimensions to generalize over; a more general discovery program would be able to do without such help. finally  the current system cannot deal with noise in i t s data; however  a minor change in the ops pattern matching routine for numbers 
would deal with this. in conclusion  although the present system has some drawbacks  it seems easily extendable and shows promise of more interesting things to come. 
