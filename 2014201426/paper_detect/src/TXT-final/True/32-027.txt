 
this article explores the advantages and one potential implementation of a new style of computation in which multiple lines of symbolic processing are pursued at different speeds within a hybrid multi-agent system. the cognitive architecture dual consists of small hybrid computational entities called dual agents. each agent has a symbolic processor capable of simple symbol manipulations. there is also an activation level associated with each agent. activation spreads according to connectionist rules. the speed of each symbolic processor is proportional to the activation level of the corresponding dual agent and varies dynamically. thus multiple candidate-solutions to a given problem can be explored in parallel. more computational resources are dedicated to the more promising candidates and the degree of 'promise' is reevaluated dynamically. this allows for flexible and efficient behavior of the system as a whole. the exact relationship between symbolic speed and connectionist activation is based on an energetic analogy. the symbolic processor is conceptualized as a machine converting connectionist activation into symbolic work. a language for implementing variable-speed symbol manipulations using delayed evaluation is introduced: s-llsp. a small example from a dual-based cognitive model illustrates variablespeed marker passing in a semantic network. 
1 introduction 
there are two challenges that any computational system operating in a complex environment must face- 
flexibility and efficiency. stated in general terms  the environment presents some problems  or tasks  to the system  which in turn has to generate solutions  or behaviors . under this formulation  flexibility implies that the set of potential solutions to any given problem should be as large and open-ended as possible. no options should be ruled out a priori. at the same time  the pressure for efficiency restricts the number of candidate-solutions that can actually be considered in any particular case. 
　each of these requirements is hard enough in itself but the conjunction of the two is even more demanding because they push in opposite directions. this dual challenge has been addressed in various ways ranging from the exhaustive backtracking of the early ai programs  to heuristic search  newell and simon  1  and hill climbing  to the elaborate control strategies of modern cognitive architectures such as act-r  anderson and lebiere  1  and soar  newell  1 . 
one approach  hofstadter  1; hofstadter  1; 
kokinov  1a  to the flexibility/efficiency challenge rests on the following four ideas:  i  multiple candidatesolutions are considered in parallel   ii  there is a very cheap mechanism that calculates rough on-line estimates of the 'promise' of each candidate.  hi  the computational resources of the system are allocated unevenly among the candidates  favoring the more promising ones.  iv  promise estimates are updated constantly  taking into account whatever new information becomes available and re-allocating the computational resources accordingly. 
　spreading activation is one mechanism that seems ideally suited for points  ii  and  iv  above. it is cheap  runs continuously  and can poll information from various sources dynamically. on the other hand  many tasks require complex  structured  and hierarchically organized representations. taken together  this suggests a hybrid symbolic/connectionist system. such hybrid systems have a number of desirable properties  dinsmore  1; sun and alexandre  1 . 
this article builds on the hybridization idea  kokinov  
1  and concentrates on the interface between the symbolic and the subsymbolic. the main idea is to have multiple symbolic processors running at variable speed. the speed is proportional to the activation level attached to each processor and estimating the 'promise' of the candidate-solution that the processor is working upon. this concretizes the general point  hi  above. the speed varies dynamically  as the activation level varies. 
　the next section begins with a brief overview of some alternative proposals from the literature. the variablespeed idea is then described in detail  followed by an illustrative example from an implemented simulation. 

1 	machine learning 

1 variable-speed symbolic processing 
symbol manipulation is done in discrete steps. the algorithm describing a symbolic process usually involves branching and loops  but during the execution it unfolds into a linear sequence of steps. as a first approximation  it may be assumed that all steps are of equal 'length'.  this approximation will be refined later on . thus the speed of a symbolic process can be defined as the number of steps advanced during a given time interval. 
　conventional multi-tasking operating systems support multiple processes running in parallel. a single physical processor serves all processes in turn by time-sharing. different priorities can be assigned to control the number of time slices allotted to a given process. this scheme can easily be adapted to use activation levels as priorities. however  it requires a centralized task manager and hence hinders the self-organizing kind of parallelism that is of interest here. 
in production systems  newell  1  1; anderson  
1   the equivalent of a symbolic step is called a production. there are production systems that use the notion of activation  anderson  1; just and carpenter  
1 . the cognitive architecture act-r  anderson and lebiere  1  is a representative example. productions in act-r operate on declarative memory elements called chunks. there is an activation level associated with each chunk and a strength value for each production. these subsymbolic parameters are used by the conflict resolution mechanism to select  stochastically  which production fires on a given cycle. moreover  the time to execute a production depends on the activation of the chunk s  that have matched its condition s . this temporal relationship is used to predict reaction time data from psychological experiments. the timing  however  is not used to control the processing within the architecture itself. the control is based on a goal stack and only the productions that match the chunk at the top of the stack are considered for firing. thus there is little parallelism at the level of global symbolic processes. rather  a single process is carried out by manipulating the single goal stack. 
　in the models of douglas hofstadter and his collaborators  hofstadter  1  1; mitchell  1; french  1  the equivalent of a symbolic step is called a codelet. many such codelets wait in a repository called the coderack and vie for a chance to run. codelets tend to form chains-when a codelet is executed  it posts one or more successors to the coderack. each such chain corresponds to a symbolic process. the coderack contains codelets belonging to different chains  thus emulating parallelism. an urgency value is assigned to each codelet these urgencies depend on various things  including activation levels. on each cycle  a codelet is chosen from the coderack and run. the choice is probabilistic but not uniformly random-it is biased in favor of codelets with higher urgencies. when this sampling is repeated many times  the overall effect is that all symbolic processes  i.e. chains  advance in parallel at speeds proportional to the average urgency of the respective codelets. 
　a very interesting 'feature of this scheme is the socalled computational temperature. it is a global parameter controlling the degree of randomness in the system. the temperature modulates the strength of the bias that the urgencies introduce into the coderack. at intermediate temperatures the probability of selecting a given codelet is roughly linearly related to its urgency. at high temperatures  however  all codelets have approximately equal chances to run regardless of their urgencies. by contrast  at low  freezing  temperatures the bias becomes overwhelming and the most urgent codelet is chosen almost deterministically. there are specialized codelets that measure the temperature and change it dynamically. 
　restated in terms of speed  the hofstadter's proposal allows for parallel symbolic processes running at different speeds. the speed can be controlled both by local factors  urgencies  and a global one  temperature . both kinds of factors vary dynamically. 
　sometimes  however  a phenomenon called urgency explosion occurs in the coderack  french  1 . it is analogous to inflation in economics and occurs when many new codelets of high urgency are posted to the coderack  thus inflating the urgencies of the old codelets waiting therein. the urgency explosion has undesirable consequences and special measures must be taken to prevent it  french  1 . 
　finally  the task of designing a system in which parallel symbolic processes run at variable speed may be addressed in a straightforward manner. the cognitive architecture dual  kokinov  1a  1b  represents such an attempt. it consists of a population of small computational entities called dual agents. each agent is hybrid and has a symbolic and a connectionist aspect. the symbolic aspect consists of a micro-frame and a symbolic processor. the connectionist aspect is analogous to a unit in a neural network. hie micro-frame is a bundle of labeled slots filled with references to other agents. the agent interacts with the agents referenced in its micro-frame by sending them messages and activation. an activation level is associated with each dual agent and the interactions between the agents can be regarded as links. the activation level of a given agent represents the system's internal estimate of its relevance to the problem being solved  the surrounding context  etc. it changes dynamically as these factors change. a threshold is imposed on the activation so that the agents that fail to reach some minimal degree of relevance are kept dormant. 
　the symbolic processor of each agent runs at a speed proportional to its activation level. thus very active agents run rapidly and determine the overall flow of computation  moderately active agents run slowly  and inactive agents do not run at all. all agents above the threshold run in parallel and there is no central executive in the system to coordinate their work. rather  coordination and global consistency are achieved by massive local interactions: both symbolic  exchange of messages  and connectionist  exchange of activation . the behavior of 
	petrov and kokinov 	1 

the system as a whole emerges out of these local activities. this style of dynamic emergent computation allows for great flexibility  efficiency  and context sensitivity  kokinov et al.  1 . 
　the presentation so far simply postulated that the symbolic processors in dual run at a speed proportional to the activation level of the corresponding agent. the next two sections concretize this abstract specification. 
1 the energetic analogy: activation as power 
the exact relationship between symbolic speed and connectionist activation in the architecture dual rests on die following energetic analogy: the manipulation of symbols can be conceptualized as work and the connectionist activation as power. doing work requires energy  which is supplied to the symbolic processor by the connectionist aspect of the agent. the energy is calculated by integrating the power over time. the speed of the symbolic computation depends on the power  i.e. the activation level . the same amount of work is completed rapidly when there is plenty of power  slowly when power is scarce  and not at all if it is lacking completely. 
　the symbolic processing in the architecture can be categorized into segments of increasing complexity  petrov  1 .  1 a symbolic operation is the smallest unit of symbol manipulation. the operations are simple  atomic  and deterministic. they are the elementary instructions of the symbolic processor   if  a symbolic step is a sequence of operations performed by a single agent without intervening symbolic interactions with other agents.  iii  a rigid symbolic process is a fixed and a priory specified sequence of steps performed by a single agent. there may be intervening interactions   rv  an emergent symbolic process is distributed over a coalition of interacting agents. it does not have any complete a priory specification. rather  the course of computation is determined dynamically by the interplay of various pressures  kokinov et al. 1 . 
　each symbolic operation is characterized by some consumption c. this is a real number specifying the amount of symbolic work embedded in the operation. different operations may have different consumptions. they are free parameters of the particular model and may be fixed on theoretical grounds and/or estimated from empirical data. this scheme offers considerably more freedom than the alternative proposals that typically assume equal consumption for all operations. 
　if a fine-grained analysis at the level of individual operations is not warranted  consumptions may be specified at the level of symbolic steps. the latter are often more convenient due to their larger grain size. a symbolic step is performed by a single agent and by definition there is no symbolic exchange with other agents during the step. thus as far as the inter-agent communication is concerned  steps can be treated as units  disregarding the constituent operations. what matters is the final outcome 
1 	machine learning 
 in the form of a message send to another agent  and the timing of its appearance. 
　each symbolic processor acts as a machine that transforms connectionist energy into symbolic work. not all energy  however  is converted into useful work. there is some overhead for covering the internal needs of the processor itself. the efficiency coefficient x  is defined as the ratio of the useful work a to the total energy input e: n=a/e. this coefficient characterizes the symbolic processor. different processors can have different efficiencies. in a cognitive model  for instance  processors performing highly automated tasks have n close to 1 while processors performing novel tasks have low efficiency. the efficiency can even be adjusted dynamically by some kind of learning-the basic rule is that it increases with practice. 
　suppose a symbolic processor starts working on some operation  or step  at time t1. the amount of energy needed for the operation can be calculated in advance-it is e c/tl  where c is the consumption of the operation. this energy must be provided by the connectionist aspect of the agent. this takes time  as the rate of supply is limited. the energy function that describes the accumulation of energy in time is defined by the integral: 
t 
e t  = ja t dr 
to 
where a t  is the activation level. activation levels in dual must be above some positive threshold in order for the symbolic processor to work.  if a f  drops below the threshold even for a moment  the symbolic processing is aborted and ail intermediate results are lost  because a t  is always positive  e t  is an increasing function and thus has an inverse e 1. the inverse function expresses the time needed to produce a given amount of energy. 
　putting all pieces together  the exact moment in which the symbolic operation is completed is t = t1 + e-1 cft  . the outcome of the operation becomes available at that moment. it may be a message sent to another agent or a modification of the internal micro-frame. then the processor moves to the next operation as prescribed by the algorithm and the whole cycle repeats. 
　when the symbolic processor is idle  all energy produced by the connectionist aspect of the agent goes unused. it cannot be accumulated. in other words  it is not allowed to amass energy 'on store' and then expend it all at once  thus attaining very high peak power. 
the energetic analogy offers the following advantages: 
 /  it provides for variable-speed symbolic computation and hence for all associated benefits. indeed  it is clear that the specification described in this section implies that die more active agents run more rapidly   ii  the activation levels can change dynamically and all changes have instant effect   iii  the architecture dual has a well-defined notion of time. it is measured on a 
continuous scale and frames the occurrence of all symbolic events.  iv  the speed of each dual agent is defined independently of that of the other agents. thus 

the architecture can be run without any modification on parallel hardware.  v  the relationship between symbolic speed and connectionist activation is specified without recourse to any particular implementation   v/  symbolic processes can be finely parameterized and the parameters have straightforward interpretation-consumptions and efficiency coefficients. 
1 s-lisp: a language for variable speed symbolic computations 
the dual architecture has been fully implemented. all programs are written in common lisp using clos1. an extension of lisp called s-llsp  'suspendable' lisp  has been developed  petrov  1  for the purposes of the variable-speed symbolic computations. a rudimentary compiler translates s-llsp programs into 'plain' lisp. this section outlines the main features of the language and the principles of its implementation. 
　s-lisp is an extension of common lisp. its main difference from plain lisp is that it supports four additional special operators: s-progn  s-eval  s-values  and suspended-value-bind. they are 'suspendable' analogs to the respective lisp operators. s-llsp also supports most  but not all  'plain' lisp primitives such as progn  if  let  and setq. the language also supports function calls and recursion  which in turn allows for loops. 
　s-progn establishes a sequence of symbolic steps to be executed at variable speed by the processor of some dual agent called a host. the complementary suspension primitive  s-eval  signals that a given s-lisp form is suspendable and announces the amount of energy needed for it. the two suspension primitives go together  s-eval may appear only within the lexical scope of an s-progn; it is an error elsewhere. conversely  *-progn is like an ordinary progn in all respects except the treatment of s-eval and the other suspension primitives. a very simple s-llsp program is illustrated below: 

　the remaining two suspension primitives  s-values and suspended-value-bind  are used to export and import values from functions defined via s-progn. 
　the implementation of s-progn and s-eval is based on delayed evaluation. while the theoretical specification of dual postulates that symbolic processes run smoothly and at variable speed  the implementation carries them out in instantaneous jumps. pauses are imposed between the jumps to produce the timing postulated by the theory. 
　when a processor begins working on some symbolic operation  it does not actually execute it. instead  it wraps it in a closure and stores it on a stack. one such stack is 
1  the foil source code and the accompanying documentation are available from the authors upon request. 
maintained for each processor  i.e. dual agent . there is an energy balance associated with each stack. the energy balance is equal to the difference between supplied and consumed energy. when the balance is negative  the processor waits until it becomes positive. on each con-   nectionist cycle  the connectionist machinery increases the balance with some small amount depending on the activation level and the efficiency coefficient of the host after some time  the balance becomes positive and the top closure on the stack is popped and executed. 
　the s-llsp compiler analyzes the source code  traps all occurrences of  and replaces them with 'plain' lisp forms that generate closures and arrange them on the stack. the stack is established by the enclosing  progn form. the top-level loop of the implementation checks the stacks of all active dual agents and pops die ones with positive energetic balance. this scheme also supports the parallel work of multiple agents. 
   s-lisp programs should be written with care because many intuitions from 'plain' lisp are violated. in particular  s-progn does not return any useful value. this is because a call to s-progn does not execute die forms in its body; it delays them. thus the value that die programmer expects will be computed later  long after the original call to s-progn is over  s-values must be used to export a value out of a suspendable function and this value must be bound via suspended-value-bind. 
　a mailbox technique is used to transfer suspended values through destructive operations executed as side effects. a mailbox is a data structure containing a field that can be modified destructively. the job of s-values is to make a new empty mailbox and to arrange that the suspended value  or multiple values  will be stored in it when the suspended computation is completed. the job of suspended-value-bind is to catch the mailbox  open it at the appropriate time  and bind the values to local variables accessible within its lexical scope. 
1 variable-speed symbol processing at work: an example 
this final section provides an example of variable-speed symbolic processing in action. it also illustrates the utility of symbolic/connectionist hybridization. the material for the example is taken from actual simulation experiments widi a dual-based cognitive model called ambr 
 kokinov  1a; petrov  1 . in these simulations ambr tries to solve simple everyday problems such as:  there is some milk in a teapot there is also a hot plate. the goal is to heat the milk.  the model solves these problems by analogy to previous cases. the long-term memory of the system contains a number of past problems with solutions. it also contains semantic knowledge about general regularities in the domain. when faced with a new target problem  ambr attempts to retrieve an appropriate source analog  map it to the target  and transfer the solution. several such retrievals and mappings are attempted in parallel and at variable speed. 
	petrov and kokinov 	1 

　ambr  like all dual-based models  consists entirely of dual agents. they carry out all representational and computational functions in the system. the long-term memory is just a population of interacting agents. some of than  the so-called concept-agents  represent classes of objects such as milk  water  and liquid. these agents form the backbone of ambr's semantic memory. there are also instance-agents standing for individual instances such as milk-1. the agents form coalitions to represent propositions  e.g. in-1  milk-1  teapot-1   and episodes. finally  hypothesis-agents are created during the problem-solving process to represent tentative correspondences such as milk-1 - water-1. 
　note that these are not passive data structures. rather  each agent is a semi-autonomous entity that heavily interacts with its peers. for instance  the agent milk sends symbolic messages and connectionist activation to the agent liquid. the symbolic processor of liquid then handles and re-sends these messages at variable speed according to the principles discussed above. 
　for the sake of concreteness  the example here concentrates on one of the several computational mechanisms used in ambr. the marker passing mechanism stems from the semantic network tradition  see  hendler  1  for an overview . in its most basic form it is a tool for answering the question:  given two nodes in a semantic network  is there a path connecting them   the underlying idea is simple-the two nodes of origin are marked. they then mark their neighbors  which in turn mark further. if the two 'waves' of markers intersect  a path is found. ambr uses these intersections to build hypotheses about similarity-based correspondences between instance agents. consider the following coalition: 

the words in the figure denote agents. the lines denote interactions  usually bi-directional. the agents at the bot-
tom row are instances; all others are concepts. note that milk treats two different agents as 'parents'. 
　marker passing in ambr goes hand in hand with spreading activation. suppose milk-1 is a newly created agent participating in the representation of the target problem and that all other agents in the figure are dormant  i.e. with zero activation  in the long-term memory. milk-1  being related to the goal  is a strong activation source. it spreads this activation to the agents referenced in its micro-frame. one such agent is the parent concept milk. this input from milk-1 brings its activation level above the critical threshold and it enters the working memory  wm  of ambr. in turn  milk activates other agents. the coalition gradually enters the wm: 


　note that the two branches of the hierarchy receive unequal amounts of activation. this is due to both permanent and transient factors. the permanent factors reflect domain knowledge and are embodied in the 'weights' of die interactions. for example  milk may send more activation to beverage than to dairy-prod. the transient factors are due to goal-related  context  and priming effects. in the above example  the target problem involves a teapot that indirectly activates liquid via the liquid-bolder agent  not shown in the figure . all these factors vary across and within problem-solving episodes. the pattern of activation over the population of agents changes dynamically  as the estimated relevance of each agent varies. 
　the stage is now ready for the marker-passing mechanism per se. whenever an instance-agent enters die working memory it sends a marker to its parent concepts . the concept-agents in turn spread the markers to their superclass es . each marker carries a reference to the instance-agent that originated it as well as a color tag indicating whether the origin is a target agent. the following transcript illustrates the marker passing process: 

　when two markers of different colors meet in some concept-agent  the latter detects the intersection and initiates a sequence of interactions with various agents that ultimately results in creating a new hypothesis. in our example this would be milk-1 - wat#r-1. alternative hypotheses  e.g. milk-1 - broad-l1  are being constructed in parallel. the respective agents  however  are less active and hence handle their markers more slowly. the net effect is that the population of agents as a whole explores various paths in parallel at speed proportional to their dynamically estimated 'promise'. in a different context  die same agent milk-1 could be mapped to another instance-agent retrieved from some other past episode. there is a vast number of possibilities but only a few of them are considered in any given case. 

1 	machine learning 

　one of the biggest issues in marker-passing systems is the attenuation of the marking. without such attenuation there would be too many intersections  most of which are 

useless and overwhelm the useful ones. several attenuation strategies have been explored over the years  reviewed by  hendler  1  : limitation of the number of links each marker can traverse  checks of die outbranching factor of 'promiscuous nodes'  etc. in ambr there is no need for any ad-hoc attenuation mechanism as it follows naturally from the architectural principles of dual. two such attenuation factors are relevant here:  i  the markers cannot reach the agents that have been left totally inactive by the spreading activation mechanism.  if  marker passing  as any other symbolic activity in the architecture  depends on the speed of the symbolic processors handling the markers. as a consequence  the markers move rapidly through the 'promising' portions of the semantic memory and then slow down as they reach the periphery of the area delineated by activation levels. the net effect of these and other similar factors is that marker intersections are reported in a temporal order reflecting their potential usefulness for the particular task and the particular context. 
　it is worthwhile to stress that the global marker passing is a dynamic emergent process. a whole coalition of dual agents is needed to cooperatively produce the final result. each individual agent does local marker passing only. the overall result is determined by a multitude of factors  or 'pressures'  each of which has relatively minor impact on its own. moreover  the strength of these factors varies dynamically in response to various external and internal events. the variable-speed symbolic processing and the energetic analogy presented in this paper are instrumental for these desirable properties. 
