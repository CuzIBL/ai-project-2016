 
in this paper  wo develop a computational learning framework to build a hierarchy of 1 consumer photo categories for semantic retrieval. two levels of visual semantics are learned for image content and image category statistically. we evaluate the average precisions at top retrieved photos on 1 heterogeneous consumer photos with very good result. 
1 	introduction 
research on image categorization has received more attention lately. in particular  the efforts to classify photos based on contents have been devoted to: indoor versus outdoor  bradshaw  1   natural versus man-made  bradshaw  1; vailaya et al.  1   and categories of natural scenes  vailaya et al.  1 . in general  the classifications were made based on low-level features such as color  edge directions etc and  vailaya et al.  1  presented the most comprehensive coverage of the problem with a hierarchy of 1 categories. 
　in this paper  we deal with a more comprehensive hierarchy of 1 categories  fig. 1  for 1 consumer photos. these photos  fig. 1   including photos of bad quality  present a real spectrum of complexities when compared to the photos used in previous works  bradshaw  1; vailaya et al.  1   which are mainly professional photos from the corel stock photo library. furthermore  only 1% of our test collection is used for training and we evaluate our approach in terms of average precisions  over 1 runs  of semantic retrieval at top retrieved photos which is important for practical usage. our approach is unique that we compute uniform semantic features at both image content and image category levels using a computational learning framework instead of low-level features crafted for different categories. 
　at the image content level  salient image regions that exhibit semantic meanings are adopted as training examples to construct semantic support regions  ssr  that span a new indexing space. local image regions of a 
　photo is projected into this space as linear combinations of the ssr and further aggregated spatially to form image content signature for similarity matching. at the 

figure 1: a hierarchy of consumer photo categories 
image category level  we learn image category models with small number of labeled photos to compute the relevance measure of photos in a winner-take-all approach. 
1 	learning semantic support regions 
ssr are salient image patches that exhibit semantic meanings to us. a cropped face region  a typical grass patch  and a patch of swimming pool water etc can all be treated as their instances. to compute the ssr from training instances  we adopt support vector machines. we extract suitable features such as color and textures for a local image patch and denote this feature vector as x. a support vector classifier si devoted to a class i of ssr is treated as a function on x  sl x . then the posterior probability of class i can be computed as 
		 1  
for the experiments described in this paper  since we are dealing with heterogeneous consumer photos  we adopt color  means and standard deviations of each color channel  and texture features  means and standard deviations of gabor coefficients  to characterize ssr. 
　to detect ssr with translation and scale invariance in an image  the image is scanned with windows of different scales. to reconcile the detection maps across different resolutions onto a common basis  we adopt the following principle: if the probability of the most probable class of a region j at resolution k is less than that of a larger 

poster papers 	1 

region  at resolution k+ 1  that subsumes region j  then the classification probabilities of region j should be replaced by those of the larger region at resolution k -f 1. to aggregate the classification probabilities of the reconciled detection map for a spatial area x that comprises of x small equal regions with feature vectors 
we compute the expected value of 	over x1 as 
 since p xj  are equal for all small regions 
j. the similarity between two corresponding blocks x1 in image x and yj in image y is computed as cosine between the probability vectors and  
the overall similarity between x and y is the average of the cosine values over all blocks. 
1 	learning semantic image categories 
a photo category mi is also learned using support vector machines. the input patterns to mi are the indexes of the images  the support vector learning computes the support images for the categories from a set of labeled photos. given an unlabeled photo of index z  the output of a category mi is s{mj z . with the winner-take-all approach  we compute the winner k as a: = argmaxis mi  z . then the relevance measure of 
z to category m  is defined as 
		 1  
1 	empirical evaluation 
from the 1 photos  we define ground truth lists for the 1 categories. their sizes are listed in table 1 as breadth-first order of fig. 1 and examples are shown in fig. 1. we designed 1g classes of ssr: people  face  figure  crowd  skin   sky  clear  cloudy  blue   ground  floor  sand  grass   water  pool  pond  river   foliage  green  floral  branch   mountain  far  rocky   building  old  city  far   interior  wall  wooden  china  fabric  light . we cropped 1 image regions from 1 images and used 1 of them as training data for support vector machines to compute the ssr and the remaining 1 as test data to gauge generalization performance. among all the kernels tried  a polynomial kernel with degree 1 and constant 1 gave the best result on precision and recall. 

figure 1: two sample photos for each category  top-
down  left-to-right : indr  outd  misc  inpp  inob  city  natr  pool  strt  wtsd  park  mtrk 
　we used 1% of the 1 photos for training. we generated 1 different sets of positive training samples from the ground truth list for each category based on uniforrr random distribution. the negative training samples ofa given category are positive training samples from other categories that do not overlap with the category. the evaluation of retrieval precision is carried out hierarchically with respect to the category tree in fig. 1. the test data for the category of a child node of a run is the ground truth list of its parent node minus the training samples used for learning the category of the child nodein the run. for example  to evaluate the retrieval performance of nature  natr  photos  the ground truth list of outdoor less the training sample for building the nature category is taken as the test data. the learning and retrieval of each category were performed 1 times and the average precisions  over 1 runs  of te p retrieved images are given in table 1. 
table 1: average precisions at te p numbers of photos 
  avg.prec. size top 1 top 1 top 1 indr 1  1 1 1 outd 1 1 1 1 inpp 1 1 1 1 inob 1 1 1 1 natr 1 1 1 1 city 1 1 1 1 park 1 1 1 1 mtrk 1 1 1 1 wtsd 1 1 1 1 pool 1 1 1 1 strt 1 1 1 	1 	| 　from table 1  we observe that up to first 1 images  a user  on average  gets almost all relevant photos of the respective categories except less so for categories interior/object  inob  and waterside  wtsd   and even less sc for categories mountain/rocks  mtrk  and swimming poo! 
 pool . the reasons for poorer performance are 1-fold first these categories have much fewer positive training samples  i.e. 1 1 . next  they comprise images of varied contents  c.f.fig. 1: objects plus interior  mountain and rocks  lakeside plus beach  pool wit! and without water as focus . we believe that with more training samples  their performance would be raised. 
