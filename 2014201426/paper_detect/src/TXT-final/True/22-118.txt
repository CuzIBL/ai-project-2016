 
this paper highlights a phenomenon that causes deductively learned knowledge to be harmful when used for problem solving. the problem occurs when deductive problem solvers encounter a failure branch of the search tree. the backtracking mechanism of such problem solvers will force the program to traverse the whole subtree thus visiting many nodes twice - once by using the deductively learned rule and once by using the rules that generated the learned rule in the first place. we suggest an approach called utilization filtering to solve that problem. learners that use this approach submit to the problem solver a filter function together with the knowledge that was acquired. the function decides for each problem whether to use the learned knowledge and what part of it to use. we have tested the idea in the context of a lemma learning system  where the filter uses the probability of a 
subgoal failing to decide whether to turn lemma usage off. experiments show an improvement of performance by a factor of 1. 
1. introduction 
　　most of the work in the field of machine learning has concentrated on trying to create programs that acquire knowledge which is used by some performance system. the main emphasis in this work has been on the acquisition process  and the general belief has been that for correct knowledge  the system's performance improves monotonically as a function of the added knowledge. 
　　recent works  minton 1; tambe & newell 1; markovitch & scott 1a 1b  have drawn attention to the possibility of correct knowledge being harmful  in the sense that the system's performance without it would be better than the 
1 	machine learning paul d.scott 
center for machine intelligence 
1  commonwealth blvd.  
ann arbor  michigan 1 
performance with it. one type of knowledge that has been associated with harmfulness is redundant knowledge. redundant knowledge is not always harmful - all learning systems that use deductive processes for acquiring knowledge are introducing intentional redundancy into the knowledge base. such redundancy can improve the system's performance significantly by saving the need to deduce again what has been deduced in the past. the reason that redundant knowledge can be harmful is that there are costs as well as benefits associated with using such knowledge. if the costs associated with an element of the knowledge base are larger than its benefits  this element is considered harmful. 
　　this paper is concerned with a particular type of harmful redundancy that occurs in deductive problem solvers that employ backtracking in their search procedure  and use deductively learned knowledge to accelerate the search. the problem is that in failure branches of the search tree  the backtracking mechanism of the problem solver forces exploration of the whole subtree. thus  the search procedure will visit many states twice once by using the deductively learned rule  and once by using the search path that produced the rule in the first place. 
　　one existing approach to avoiding harmful knowledge is not to acquire it at the first place  e.g. minton 1 . the learner tries to estimate whether a newly learned knowledge element is potentially harmful  and rejects it if it is estimated as such. such an approach is termed selective learning. another approach is to delete part of the knowledge base which is estimated to be harmful based on past experience  e.g. holland 1; samuel 1; minton 1 . that approach is sometimes termed forgetting  markovitch & scott 1a . the problem with these approaches is that they are basically averaging processes - they must decide whether a knowledge element is harmful with respect to the whole problem space that the performance system faces. however  the backtracking problem is an example where the usefulness of knowledge depends much on the context in which it is being used. forgetting and selective learning can not account for the case where knowledge is harmful in one context and is beneficial in another. 
　　in  markovitch & scott 1a  we introduce a new framework for classifying methods for reducing harmfulness of learned knowledge called information filtering . information in a 
　　learning system flows from the experiences that the system is facing  through the acquistion procedure to the knowledge base  and thence to the problem solver. an information filter is any process which removes information at any stage of this flow. 
　　information filters can filter the set of experiences that the learning program faces 
{selective experience  or the set of features that the program attends to within a particular experience {selective attention . 
　　when the filters process information before it has been transformed to a representation that the problem solver understands we call them data filters - the two above filters are data filters. when the filters process information after it has been processed by the knowledge acquisition procedure  we call then knowledge filters. selective learning is a knowledge filter which is inserted between the acquisition procedure and the knowledge base  we call it selective acquisition . forgetting can be viewed as a filter whose input and output are both connected to the knowledge base  we call it selective retention . 
　　the method that we suggest for reducing the harmfulness of deductive knowledge when used by backtracking systems falls under the third class of knowledge filters called selective utilization. utilization filter is a filter which is inserted between the problem solver and the learned knowledge base. knowledge that is not in the space used by the problem solver can not have detrimental effects on the performance of the problem solver. the utilization filter activates only a subset of the knowledge base before solving a problem  trying to deactivate knowledge elements which are estimated by the filter to be harmful within the context of the specific problem. 
　　information filters can be built into the system  or can be learned. we call the process of acquiring such filters secondary learning to differentiate it from the primary learning - the process of acquiring knowledge to be used by the problem solver. 
　　we will introduce an instantiation of the backtracking problem in the context of the lemma learning module of the syllog system. we will then describe an implementation of a utilization filter that is used to reduce the harmfulness of lemmas. 
　　section 1 contains discussion of the harmful aspects of deductive learned knowledge  in particular the backtracking problem and possible remedies to the backtracking problem. section 1 describes our implementation of a knowledge filter to reduce the harmfulness of lemmas in a prolog system. section 1 describes the experiments done with the implementation and the results obtained. 
1. the inherent harmfulness of deductively learned knowledge 
1. 	deductive learning 
　　a deductive problem solver is a program whose basic knowledge is a set of assertions and a set of derivation rules to derive new assertions. thus  logic systems are deductive - the set of assertions are the axioms  and the derivation rules are the logical inference rules. a grammar is a deductive system where the basic assertion is the start symbol  and the derivation rules are the grammar derivation rules. a state space search program is a deductive system where the set of initial states are the basic assertions and the operators are the derivation rules that allow the program to derive new states. 
　　any deductive problem solver can form the basis of a deductive learning program. a deductive learning program transfers knowledge from its implicit form to its explicit form. if the problem solver derives b from a set of assertions a 
　　using a sequence of applications of the program's derivation rules  the learner memorizes that b can be derived from a by adding a specialized derivation rule that specifies that fact explicitly. 
　　there are many learning programs that are deductive by nature. all the explanation based learning programs and macro learning programs use such a scheme  e.g. fikes 1 ; minton 1; minton 1; laird et al. 1; korf 1; prieditis & 
mostow 1; mitchell et all1; dejong & mooney 
1; markovitch & scott 1a . the programs that use generalization are basically equivalent to the more simple schemes  except that they learn sets of explicit derivation rules instead of one rule at a time. 
　　the basic idea behind deductive learning is that by adding the explicit derivations which the system had experienced in the past  the problem 
	markovitch and scott 	1 
solver will be able to solve problems more rapidly in the future. the problem is that the added knowledge has costs in addition to its potential benefits  and if these costs exceed the benefits  then the knowledge is harmful. 
1. 	the backtracking anomaly 
　　assume that a search program performs a depth first search  with backtracking  in the space illustrated in figure 1. assume that the program is given a problem to get from state a to state d. assume that during this search  the learning program learned a new macro - it is possible to get from b to c  we will call this macro/rule b-c . assume that the problem solver receives another problem - to get from a to e. assume that there is no route from b to e. the problem solver will get to b and use the macro b-c to get to state c. the search from c will not lead to e  thus the problem solver will backtrack to b. since there is no route from b to e  the problem solver is bound to search the whole subtree of b  including the search that generated b-c in the first place. the whole subtree under c will be searched twice because the problem solver will get to c twice - once by using the macro b-c  and once by going through the path that generated b-c. thus  the system would be better off not using the macro in the first place. 

then the interpreter will use lemmas of the type q c   where c is a constant  to generate bindings for x. if r x  rejects all the bindings generated by q  then q will be forced to reinvoke the rules that generated the lemmas in the first place. in addition to the fact that the execution of q x  by itself will be more costly than it would have been without using lemmas at all  r x  will be invoked twice on every binding that was generated by q's lemmas  since the same binding will be generated again using the rules . thus the system performance will be harmed by using the lemmas instead of being benefited. 
　　the backtracking anomaly should not be taken lightly. almost every problem solver spends a large portion of its search time exploring failure branches. when prolog is used as it meant to be used - as a declarative language - the rate of failures during the proof process is very high. the lemmas learned by our lemma learning system described in section 1 were found to be harmful in many cases when the rate of failure within a proof was high. all rule systems which use depth first search  with backtracking  are bound to have similar problems if they use deductively learned knowledge. 
1. 	possible solutions 
　　
1 	machine learning 
　　
　　in this section we will explore several possible solutions to the backtracking problem. 
　　one possible solution is to add to the problem solver a procedure that checks whether a node has been visited before . in a case like the search problem of figure 1  that will save the program the second search of the subtree of c. there are two problems with adding such a check to the problem solver. the first is that such a test has potentially very high costs in terms of both memory and time. the second problem is that it does not eliminate the problem - only reduces the costs that are caused by the problem  the problem solver would still get to state c twice . 
　　prolog itself has no facility for implementing such a feature. we modified a prolog interpreter to allow a version of such a check: whenever a child of an or node was returned successfully  the bindings that were generated by the child were compared to the bindings that had been generated before by its siblings. if two sets of bindings were identical  the interpreter marked the new child as failure and went to the next alternative. such a mechanism would not stop q x  from generating the same bindings twice  but would save r the necessity to run again with the same bindings . the check improved the performance of the 
　　
interpreter by a factor of two compared with the performance without the check. 
　　a second possible solution is to use what we term  lemma groups . the idea behind lemma groups is that if an or node had failed during learning time  the learner can be sure that all possible bindings to the subgoal were found  and can learn them all as a group together with a lemma that says  and these are all the possible bindings   by using the prolog cut operator . in such a case  there will be no need to go to the rules if all the axioms fail  since the interpreter knows that the rules can not generate new bindings that have not already been tried yet. 
　　lemma groups can be very beneficial especially for problems with high failure rate. in some cases  for problems that required very large space trees with a high rate of backtracking  using lemma groups made execution up to 1 times faster. 
　　unfortunately  lemma groups have their own disadvantages. it is extremely hard to maintain lemma groups in a system that is changed over time. if a new axiom is added to the database  there is a possibility that the lemma group is not valid anymore. 
　　the third solution is to use a knowledge filter in order to reduce the probability that lemmas will be used where they can be harmful. since using lemmas in a subtree of a goal which fails is bound to be harmful  the filter tries to turn off lemma usage when it estimates that the probability for such a failure is high. 
1. implementing knowledge filters 
　　we have investigated the idea of knowledge filters within the context of the lemma learner of our syllog system . the learning system uses inductive and deductive learning mechanisms to accelerate proof generation in prolog databases. lemma learning  kowalski  1; loveland 1  is one deductive mechanism used to increase the execution speed  and the anomaly described above was encountered during experimentation with lemmas. our lemma learner differs from prolearn  prieditis & mostow  1  in that it does not perform generalization over the lemmas that are learned. 
　　we have implemented a filter function that decides whether to use lemmas or not whenever a new or node is created and added to the search tree. basically the filter tries to minimize the use of lemmas in the subtree below a subgoal that is likely to fail. using lemmas in a subtree that fails is bound to have detrimental effect on the search time because backtracking will force the interpreter to search the whole subtree. 
　　since it is impossible to know in advance whether a goal will fail  the filter estimates the probability of failure from past experience. in the current scheme  if the probability of a goal failing is above some threshold  the filter disables lemma usage for the subtree below the goal. 
　　the probabilities are updated during the learning phase. currently  there are four types of failure probabilities that the system maintains: 
1. the probability of a goal with a specific predicate failing. 
1. the probability of goal with a specific predicate and specific arguments bound failing. 
1. the probability of a specific goal within a specific rule body failing. 
1. the probability of a specific goal within a specific rule body and with a specific arguments bound failing. 
the reason that the context of the rule is taken into account is that many times a subgoal within a 
rule body will succeed at first  but will eventually fail because a subsequent subgoal in the rule body keeps rejecting the bindings generated by the subgoal. for example assume that a database of the living members of a family contains the following rule: 
greatgrandfather x   - male x  & parent x y  & grandparent y z  if the rule is used to find a greatgrandfather  i.e. greatgrandfather x  is called with unbound x   then the probability of parent x y  failing within this rule is very high. the reason is that male x  will generate males  parent x y  will succeed in finding children of the given males  but grandparent x y  will keep failing because most living people are not greatgrandparents. on the other hand  the probability of parent x y  failing by itself is lower since a substantial portion of the people in the database are parents. this example demonstrates why it is preferable to use more specific information. 
　　the binding information specifies which arguments are bound and which are not 
 regardless of the values that arguments are bound to . the above example illustrates why bindings can be significant to the probability to fail. a goal greatgrandfather x  is likely to succeed when x is not bound assuming that there is at least one greatgrandfather in the database. however  the probability of greatgrandfather c   where c is some constant  failing is very high since most people in the database are not greatgrandparents. 
	markovitch and scott 	1 
　　
　　whenever a subgoal is called  an or node is created   the learning program updates 1 call counters associated with the 1 types of probabilities described above. whenever a subgoal fails  has tried all its or branches thus exhausting the whole search subtree   the learning program updates 1 fail counters. a probability is computed by dividing the fail counter by the call counter. 
　　during problem solving  whenever the interpreter creates a new or node for a subgoal  it consults the failure probability to decide whether to append the lemmas for the subgoal predicate to the database axioms for it. if the probability of failure is above a preset threshold  lemmas will not be used  and a flag will be propagated down the subtree of the or node to turn off lemma usage for the whole subtree. 
　　the probability that is taken into account is the most specific one that is available  i.e. it first looks for probability type 1  if not available  it looks for probability type 1 etc. 
1. experimental results 
the domain used for the experiments is a 
prolog database which specifies the layout of the computer network in our research lab. it contains about 1 rules and several hundreds facts about the basic hardware that composes the network and about connections between the components. the database is used for checking the validity of the network as well as for diagnostics purposes. 
　　the problems for learning and for testing were generated randomly from a given problem space. for the experiments described in this section we have used a problem space specified as a list of three elements. the first element is a list of domain names with their associated domains  where each domain is a list of constants from the database. the second element is a list of 
predicates with a domain specified for each of their arguments. the third elements is a list of problem templates with associated weights. a problem template is a list consisting of a predicate name and a list of flags  one for each argument. a flag of value 1 means that the argument in a problem that satisfies that template should be bound to a constant. a flag of value 1 means that the corresponding argument should be a variable. 
　　to generate a problem from a problem space a problem template is selected with probability proportional to its weight. then a problem is generated by selecting a random member of the appropriate domain for each of the bound arguments. 
1 	machine learning 
　　an experiment comprises two phases: a learning phase followed by a performance & testing phase. visiting-check and lemma groups were turned off for the whole duration of this experiment. during the learning phase  a training set of 1 problems was randomly generated in the way described above  and the problem solver was called to solve those 1 problems. during the learning phase the learning program generated two types of information: positive lemmas  and failure probabilities. 
　　during the performance phase  a set of 1 problems was randomly generated using the same method and the same problem space specifications as in the learning phase. the batch of 1 problems was solved  varying values of the probability threshold  the values tried were 1  1  1  1  1  1  1  1  1  where 1 threshold means never use lemmas  and 1 means always use lemmas . 

figure 1. 
the results of the experiments are shown in 
figure 1. a number of features of the result graph are worthy of note. first  the performance with lemmas  and no filter  was slightly worse than the performance with no lemmas at all. this is another example of knowledge that is harmful. second  the performance was substantially improved by using knowledge filtering. the performance with filter of 1 threshold is three times better than the performance without filter  and also three time better than the performance without lemmas . 
　　the u shape of the graph makes it clear that filtering should not be taken to the extremes. if the filter is too refined  knowledge will not be used where it could be useful  if the filter is too coarse  knowledge will be used where it could be harmful. 
　　
1. conclusions 
　　the problem of inherent harmfulness of deductive knowledge when used within failure branches of the search tree was presented. the existing solutions for reducing harmfulness of knowledge  selective learning and forgetting  could not cure this problem  because the question of whether a piece of knowledge will be harmful does not depend in this case on the knowledge itself  but on the context in which it is being used. 
　　we suggested a different approach  called utilization filtering to reduce the harmfulness of deductive knowledge. the filter that we have implemented uses probability estimates of a goal failing to decide whether to disable lemma usage for the search subtree of that goal. 
　　the experiments we have conducted have shown that utilization filtering is a very effective mechanism for reducing the harmful effects of knowledge caused by the backtracking problem. the average performance of the system was improved by a factor of 1 using the filter. 
　　the threshold method used here is rather primitive  and we are currently working on a more sophisticated ways of using the failure probabilities. these methods consider the expected benefit from using lemmas in case of a success  and the expected cost of using lemmas in case of failure. in order to use lemmas  the probability of failing multiplied by the expected cost should be lower than the probability of succeeding multiplied by the expected gain. 
　　utilization filtering is not limited to deductive learning systems. the syllog system also contains an inductive component that uses statistics about the costs of executing goals to reorder subgoals in order to increase efficiency  markovitch & scott 1b . dynamic ordering is usually needed in such cases  because the expected cost of executing a subgoal depends on what arguments are bound. the problem with dynamic ordering is that it has high cost. a utilization filter turns ordering off if the expected cost is higher than the expected benefit. 
