
this goal of this paper is to defend the plausibility of the argument that passing the turing test is a sufficient condition for the presence of intelligence. to this effect  we put forth new objections to two famous counter-arguments: searle's  chinese room  and block's  aunt bertha.  we take searle's argument to consist of two points: 1  intelligence is not merely an ability to manipulate formal symbols; it is also the ability of relating those symbols to a multi-sensory real-world experience; and 1  intelligence presupposes an internal capacity for generalization. on the first point  while we concede that multi-sensory real-world experienceis not captured by the test  we show that intuitions about the relevance of this experience to intelligence are not clear-cut. therefore  it is not obvious that the turing test should be dismissed on this basis alone. on the second point  we strongly disagree with the notion that the test cannot distinguish a machine with internal capacity for generalization from a machine which has no such capacity. this view is best captured by ned block  who argues that a sufficiently large look-up table is capable of passing any turing test of finite length. we claim that  contrary to block's assumption  it is impossible to construct such a table  and show that it is possible to ensure that a machine relying solely on such table will fail an appropriately constructed turing test.
1 introduction
the poet james whitcomb riley  1  is often remembered for his formulation of the  duck criterion :  when i see a bird that walks like a duck and swims like a duck and quacks like a duck  i call that bird a duck. 
　with a similarly practical attitude  many ai researchers would say a machine that talks intelligently and behaves intelligently should be called intelligent. this assumption was formalized by alan turing who proposed a behavioral test for determining whether a machine can think  turing  1; turing et al.  1 . in its original formulation  the turing test is an imitation game  in which a machine does its best to imitate a human participant in free-flowing conversation with a judge. at the end of the game  the judge is asked to point out the human participant. if under repeated sessions of the game  the judge is at chance  the machine should be considered intelligent.
　it is fairly obvious that passing the turing test is not a necessary condition of intelligence. for one  most humans have never been subjected to such a test. furthermore  an intelligent agent might fail the test due to temporary impairments  such as being sleepy  hungry or on drugs. finally  an intelligent machine might fail the turing test because it may believe it is in its best interest not to show how intelligent it is.
　thus  the turing test debate in the literature has centered around the question of whether the test represents a sufficient condition for intelligence. turing himself is fairly unconvinced on this issue. his skepticism derives from the conclusion that the question of machine intelligence is very much alike the question of other minds. it is impossible  the solipsist argument goes  to know for sure whether there exist any other conscious beings apart from one's self  since one only has direct access to one's own consciousness. thus  rather than directly arguing in favor of his test as a sufficient condition  he claims that the test is simply a good approximation to some true characteristic of intelligence  which is both currently unknown and impossible to observe.
　but despite turing's reluctance to adopt a strong stance  philosophers have taken this position seriously in both defending and disproving it  and for a good reason. in the absence of this strong assertion  the power of the turing test as a diagnostic is severely limited  and its status is reduced to a dubious replacement for the true definition of intelligence. in other words  why would we take the turing test more seriously than any other arbitrarily formulated criterion  its only advantage appears to be that it would pick out all humans  who constitute- by assumption- the pool of known intelligent entities. however  we can achieve similar success by replacing the definition of intelligence with the definition of featherless biped. countless other criteria would do the same  while having little to do with our intuition of what intelligence is as a trait. that is why it is important to figure out the extent to which turing's criterion can be deemed sufficient for ascertaining intelligence.
　just like riley's duck criterion  turing's intelligence criterion is attractive because the decision is based on purely observable  external characteristics. thus  without having to know how intelligence arises or what it is made of  we can ascertain its presence purely by observing its interactions with the environment. this gives rise to the foundational claim of ai and cognitive science - that intelligence can be understood and reproduced in an abstract computational device.
　but the turing test's most attractive aspect is precisely the one open for most criticism. powerful objections have been raised to the effect that the definition of intelligence requires access to the inner workings of the computational mechanism used by the machine  rather than its behavior per se. the objections are illustrated by two famous thoughtexperiments: searle's chinese room and block's aunt bertha.
1 the chinese room
searle  1 imagines a monolingualenglish speakerlocked in a room with chinese symbols and a large set of instructions in english about mappingsequences of these symbols to other sequences. his interrogators outside come up with a chinese story along with a set of questions about the story. they hand the story and the questions to the person inside the room  who then looks up the sequence of symbols in the instruction manual and produces what his interrogatorsmight view as a reply. despite performing adequately on the verbal chinese test  the person inside the room does not understand chinese. instead  s/he merely appears to understand chinese  i.e. simulates understanding of chinese. similarly  searle argues  a machine can fake its way out of the turing test without satisfying our deep intuition of what it means to be truly intelligent.
1 previous objections to the chinese room
there have been a number of objections to the chinese room over the years. we will briefly review here the ones most relevant to our current discussion.
　the  systems reply  states that even if the person inside the chinese room does not understand chinese  the room with all its content  does. in effect  the person is to the room like the cpu is to the computer  rey  1 . therefore the correct level of analysis is the room as a whole.
　while the  systems reply  by itself may be insufficiently effective  it is an important step. intelligence is perceived by modern science to be an emergent property of a system  rather than a property of an essential component. therefore  the correct level of analysis of the chinese room is  indeed  the room.
　since it is generally very difficult to have the right intuition about the perceived intelligence of rooms  it is to our advantage to reformulate the setup. searle's counter-reply allows us a way out: assume that the person was not locked inside a room  but instead had memorized the rules and symbols completely inside his head. despite this change  we would still be reluctant to say that s/he understands chinese. we will call this version of the experiment  the chinese impostor .
　the  english reply  states that even if the person does not understand chinese  s/he understands something - the rulebook  for example. however  searle claims that this fact is irrelevant since the chinese room test is about understanding of chinese in particular  rather than general understanding  chrisley  1 .
　finally  the  robot reply  concedes that the chinese room or the person inside it cannot claim to possess human-level intelligence because it does not interact with the real world. the solution is to let the room receive input from the real world. searle's objection is that there is no way for the input from the real world to be experienced in a way that a human experiences it  boden  1 .
　the latter two replies pertain to what we will call  the information content  part of searle's argument.
1 two challenges from the chinese room
searle's thought experiment appears to conflate two issues  and it is worth teasing those apart. one issue is the issue of information content. the formal symbol stands for an entity in the real world. obviously  any machine which has no access to the mapping from the formal symbol to the entity cannot be said to understand what the formal symbol means.
　the other issue is the type of information storage and access. it is our intuition that there is something profoundly unintelligent about interacting with the environment through a look-up table  or by following an externally generated sequence of steps. the problem with this scenario is that the intelligence observed in the behavior of the agent originates outside of the agent  which is in and of itself incapable of generating novel behavior. this is the issue of generative incapacity.
1 objection to the argument from information content
the question of information content is really the question of the nature of meaning  or real-world knowledge  and its pertinence to our intuition about intelligence. meaning is the relationship between a formal symbol and the entity  or event  it stands for. obviously  if one is without access to sensory input from the world  or the correspondence relation between the world and the formal symbols  one cannot claim access to meaning. we will not argue this point.
　however  we take issue with searle's assumption that meaning is central to our notion of intelligence. to clarify  let us suppose that locked in the chinese room is a chinese speaker  who by some accident of fate has never encountered a hamburger. the interrogators hand him a story involving hamburgers  and ask him questions  which s/he answers to the best of his/her abilities. when asked about properties of hamburgersthat cannot be inferred from the story  s/he claims ignorance or makes a guess. obviously  it would not be reasonable for us to claim that the chinese speaker does not understand chinese simply because s/he does not know the properties of hamburgers. if anything  we would say that s/he understands chinese  but not the world of american diners.
　similarly  the fact that the machine does not understand what a formal symbol's relationship to the world does not necessarily imply that it should be labeled  unintelligent.  rather  the design limitation of the machine  its different embodiment and experience make it differ from a human in ways irrelevant to the question at hand  just as a chinese person who has not been exposed to hamburgers differs from a american speaker of chinese.
　of course  we could claim that knowledge of the real world is essential to human intelligence  and that anyone who exhibits verbal behavior without accompanying knowledge does not qualify as intelligence. however  such an assertion is controversial  and can hardly be held to form a central part of our common sense intuition. for example  we usually consider congenitally blind individuals to be just as intelligent as the rest of us  even though they are deprived from a certain type of knowledge of the real world. their inability to relate visual-based concepts to the real world is an accident  and does not bear on their intrinsic intelligence. if we accept that blind  or deaf  individualsare intelligent  the question becomes  how much real world deprivation can an entity handle while still be considered intelligent. would we be willing to set some arbitrary threshold  for example  such that blind people are intelligent  but deaf and blind people are not  or that deaf and blind people are intelligent  but deaf and blind people with no haptic sensation are not  while imagining this gruesome scenarios is difficult  it would help us understand searle's objection.
　our intuition regarding the intelligence of individuals who lack any non-verbal stimulation is far from obvious. for example  what if a subject of a profoundly unethical cognitive science were raised confined to a bed  blindfolded and fed through an iv  but verbally taught to do mathematics  the question whether such a person is intelligent is difficult to answer  but the intuition is not as clear-cut as searle would like us to believe.
1 the argument of generative incapacity
in addition to the symbol-grounding problem  sealre's thought experiment raises another issue: to what extent are the inner workings of the computing mechanism relevant to intelligence  the intuition that the chinese room lacks intelligence is partially due to the absence of data compression and generalization in the symbol manipulation process.
　let us say that two chinese impostors that differ only in the type of instruction manual they have committed to memory. the first impostor's manual lists all stories in chinese of finite length  and all questions about them  in a giant lookup table. the second impostor on the other hand has memorized a much leaner manual  which instructs the person to analyze the questions and build answers in a combinatorial fashion. while we may be reluctant to say that either person understands what chinese words mean  it is clear that the latter understands something about how chinese works  which the formerdoes not. thus  ourintuitions aboutthe chinese room experiment also depend on the way in which - we are told information is represented and accessed.
1 the aunt bertha thought experiment
the concern is legitimate from the point of view of ai. while different people might have different intuitions regarding the contribution of real-world knowledge to intelligence  we believe that most ai researchers would find a look-up table approach to question-answering unintelligent. this intuition is best clarified by ned block in his aunt bertha argument.
　imagine that the length of the turing test is known to us in advance  e.g. one hour. now imagine that block have a machine with extremely large storage capacity  and programs it to converse by looking up the answer to any question in a giant look-up table. this is possible  block claims  because the number of questions that can be asked in a 1-hour turing test is finite  and of finite length. he will construct the table by consulting an actual human-aunt bertha on all possible conversations of some length l. obviously  the performance of the machine on the test would not constitute a proof of its intelligence-it would merely be a testimony to aunt bertha's intelligence. hence  block argues  passing the turing test cannot be thought of as a sufficient condition for intelligence.
　to use a differentmetaphor: one wouldn'twant to administer the turing test to a walkie-talkie  which is remotely tuned in to aunt bertha. obviously  while the answers coming from the walkie-talkie are intelligent  it is not. essentially  a machine that recorded the answers of aunt bertha is merely a mechanism for transmitting aunt bertha's intelligence  and does not itself possess intelligence.
　what is missing in both cases is informationcompression and generalization on the part of the device whose intelligence we are probing. the aunt bertha machine can only respond to the questions for which it was programmed  and the answers to related questions are related only because they were so in the mind of aunt bertha. despite this unintelligent organization of information however  the aunt bertha machine is claimed to be capable of passing the turing test.
　thus  one option is to amend turing's definition of intelligence as follows:
   if an agent has the capacity to produce a sensible sequence of verbal responses to a sequence of verbal stimuli  whatever they may be  and without requiring storage exponential in the length of the sequence  then it is intelligent  shieber  1 .
the problem with the revised definition is that it is no longer purely behavioral  because it requires us to examine the internal workingsof the candidateentity. therefore block argues  the turing test is not a sufficient condition of intelligence.
1 why a look-up table cannot pass the turing test
we devote the rest of this paper to arguing against the assertion that the turing test can be passed by a look-up table. there are  in fact  two interpretations of this argument. one interpretation is that a look-up table can be constructed such that it would be guaranteed to satisfy the turing test. this formulation ignores the complication that no entity  even if it is intelligent  is guaranteed to pass the turing test  due to the natural fallibility of judges. the second interpretation is that  for any look-up table  regardless of its sophistication  there is always a  very small  probability of a false positive result  if the test questions just happen to be the ones recorded in the table.
1 the possibility-of-construction fallacy
we begin by attacking the first interpretation of this argument  namely  that it is possible to construct a look-up table which can definitely pass a non-trivial turing test. by non-trivial we mean a test which is sufficiently long to allow the judge to conclude that a human possesses human intelligence.
　to clarify  let us examine the notion of test length  and its influence on the argument. it is obvious that the shorter the test is  the easier it is for a machine to pass. in fact  if the test is sufficiently short  it will be passed by any machine. suppose the test is as short as one second. no human would be able to say anything in one second  and neither would the machine. hence  the judge would be at chance on a forced choice. obviously  this type of failure of the turing test is not a reason for eliminating it as a sufficient condition for the presence of intelligence. we tacitly assume that the turing test has to be administered for a reasonable period of time.
　this is the first step toward exposing the possibility-ofconstruction fallacy. we will show that ned block's argument's relies on the unwarranted assumption that real-world time and space limitations are not a factor in the turing test. given that we accept - and we certainly have to - that the turing test is only meaningful beyond some minimal length  it becomes an important question whether an appropriate lookup table can be constructed to pass it.
　let us review ned block's proposed way of constructing the aunt bertha machine. he suggests to exhaustively conduct with aunt bertha all conversations of length one hour. presumably  aunt bertha would devote her lifetime to this process. but even if aunt bertha lives extraordinarily long  this is impossible. suppose that block somehow manages to record not only aunt bertha's one hour conversations  but all hour long conversations that took place since humans got the ability to speak. it is clear that even in this case  the look-up table would not contain all possible one hour conversations. this is because a  the set of possible conversations depends on the natural  social and cultural environment and evolves with it and b  because future conversations can always reference those conversations that have previously occurred. for example  while a conversation like:
-have you heard the new federline rap song  -yes  i have it on my ipod.
is fairly common nowadays  it would have been impossible just five years ago. similarly  a conversation about plato's dialogues would have been impossible when plato was five years old. thus  while it is true that the set of all possible conversations of fixed length is finite at any given point in time  it is not true that it is the same set. crucially  the set of all hourlong conversations would change from the time when aunt bertha'a recordings would have ended to the time when the turing test would begin.
　in fairness  block does anticipate this counter argument  block  1   but dismisses it on the grounds that the turing test is not a test of knowledge  but of intelligence  and therefore ignorance of current events does not constitute grounds for failing:
a system can be intelligent  yet have no knowledge of current events. likewise  a machine can imitate intelligence without imitating knowledge of current events. the programmers could  if they liked  choose to simulate an intelligent robinson crusoe who knows nothing of the last twenty-five years.
however  block's reply to this challenge is inadequate. while an intelligent system need not have knowledge of current events  it should be capable of learning about them and subsequently commenting on them in the context of the test. a machine which relies on a finite look-up table will not be able to accomplish this  because it is unable to add previously nonexisting entries.
　the same argument holds even if the length of the test is not measured in time but in number of questions. suppose that block knows the test is going to contain a single question. now he is faced with uncertainty about the length of the question  which he has to assume. suppose he assumes that the longest question the judge can ask is the length of his/her lifetime. unfortunately  since the judge is still alive  block would have to estimate the length of the judge's lifetime from the length of the longest living human to date. let us grant block some way of generating all possible questions of that length  for example  by generating all possible strings of that length . now he needs to provide human-like answers to them for his look-up table. thus let us also assume that many human beings from this time on would spend their entire lives reading one question of length one lifespan and providing the answer. even then  the machine is not guaranteed to pass the turing test. this is because  while we know that the judge has a finite lifespan  his lifespan is unbounded. for example  there is no a priori reason to believe that the judge will not live as long as the longest living human today plus one day. if he does  block's machine will fail the test.
　finally  let us assume that there is some maximal length of a question  which greatly surpasses a human lifespan  e.g. a question can be at most two hundred years long. if block could create a table with all questions and answers of this length  he would surely win! not so fast: one should not forget that each of the questions of the look-up table should be given an answer by an actual human being. since no human being can answer a question which exceeds its own particular lifespan  it follows that the length of any question in block's table cannot exceed the life lifespan of the longest-living human to date. therefore  it is impossible for block to construct his look-up table.
　what these arguments go to show is that block's assertion that a look-up table machine is guaranteed to pass a turing test of a given length is based on two improper assumptions: 1  that the set of possible finite conversations of given length is constant in time  and 1  that the length of the questions is bounded in advance. thus  his argument:
if the turing test is sufficient condition for intelligence  all entities that are not intelligent should fail the test.
premise 1: a look-up table machine is not intelligent.
premise 1: a look-up table machine can pass the
turing test.
therefore  the turing test is not a sufficient condition for intelligence.
is flawed due to the fallacy of the second premise for any turing test of unbounded length.
　if the length of the test must be limited in advance  the question becomes what constitutes a reasonable length  see  shieber  1  . of course  if we severely limit the length of the turing test  or if the length of questions is known a priori  it might be possible to construct a look-up table with guaranteed success. however  imposing such a limitation is unwarranted  as it would trivially invalidate the test. in fact  if the limit is severe enough  the turing test would be passed by a rock! it is worth saying that the length of the test factors into validity of the first premise as well  since intelligence is a feature of a system embeded in space and time. an abstract mathematical construct manifested by a cosmic accident is difficult to relate to the common sense behind the notion of inteligence.
the limitations of a thought experiment
it is possible to defend the second premise of block's argument by appealing to the idea that a thought experiment is not subject to the ordinary space-time limitations of the natural world. thus  what if we imagine that block can record not only all past  but also all future conversations of length one hour  such a question is ill posed and causes the debate to rapidly depart the realm of usefulness. we are interested in whether or not the turing test is a sufficient condition for intelligence in this universe  which has the limitation that time only goes forward. indeed  it is completely unclear what the concept of intelligence would be in a universe in which we had access to the future as well as the past. if intelligence is the capacity to generate novel behavior from past observations  it might not exist as a concept in a universe in which novelty would be as absent from the future  as it is from the past.
　our point is that a thought experiment is like any other model of reality. it is an abstraction which preserves some characteristics of reality and gets rid of those characteristics which are irrelevant for the question at hand. for example  a papier-mache model of the solar system is useful if we are interested in exploring the relative sizes of planets  but is utterly useless if we are interested in exploring their gravitational fields. similarly  a thought experiment which is meant to aid us in the question of whether the turing test is a sufficient condition for intelligence is only useful if it preserves the kind of real-world characteristics which are relevant to intelligence  namely  space-time limitations.
1 the very small probability argument
the second interpretation of block's argument is that for any look-up table  there is always a probability of a false positive result. in other words  we do not have to record all possible one hour conversations. it is enough for us to record one such conversation. there is always a chance that the judge will lead our machine into this exact conversation  and falsely conclude on the basis of the machine's verbal behavior  that the machine possesses human intelligence.
　this interpretation is in some ways trivial  because the turing test has always had a probabilistic element to it. obviously  whenever a forced choice situation is set up among two alternatives  the response might simply reflect the judge's prior. turing discussed the necessity to set up that prior properly  so that positive answers are not inherently favored:
   we had better suppose that each jury has to judge quite a number of times  and that sometimes they really are dealing with a man and not a machine. that will prevent them from saying  it must be a machine  every time without proper consideration  newman  turing  jefferson and braithwaite 1 .
however  it is true that this occasional fallibility of the test makes it an insufficient condition for intelligence. furthermore  what is interesting about this particular possibility of a false positive  is that it is not in any way traceable to the fallibility of the judge. that is to say  the judge has no reason to believe that he has picked the only set of questions which the machine has on record. hence  the judge's conclusion would be entirely reasonable on the basis of the machine's performance
　it is worth thinking about whether there is a way to guarantee that the turing test cannot be passed by a look up table  again  leaving aside the issue of judge fallibility . we suggest that the answer is yes  provided that the test is developed with reference to the moment in which the machine is considered complete. in a sense  we are reversing block's approach. in his thought experiment  he first fixed the length of the test  and then went about constructing his machine. here  we argue that there is a way to prepare the test after the machine is complete such that the look-up table can be guaranteed to fail.
　the argument hinges on the assumption that we know what propertiesa look-uptable constructed at time t can and cannot have. for example  the longest question such a table can contain must be shorter than t. thus  all it takes for us to make sure that the machine is not merely using a look-up table is to ask a question which is longer than t. obviously  this strategy could be very impractical for the reasons discussed earlier. if the time it took to construct the machine was greater than one lifetime  we might not be able to use a question longer than a lifetime in the test period  unless we have an exceptionally dedicated and longlived judge . also  we might be unable to ascertain the time it took to construct the machine. in these cases however  it is possible to use other consequences of the observation that the set of all possible questions is dynamically evolving. for example  it is possible to ask the machine questions about events which happened after the machine was completed. note that the machine need not observe the events-it is sufficient that the events are described to it by the judge. a human-like intelligent entity would be able to answer questions about such stories  but not a look-up table machine.
　it appears that it is at least theoretically possible to make sure that any aunt bertha device will fail the turing test. the question of how this could be done in reality is interesting and merits further consideration. however  it is important to bear in mind that the turing test in practice is like any scientific measurement  in that it allows for experimental error. therefore  it is impossible to argue that passing any particular version of the turing test is a sufficient condition of intelligence. rather  it is the capacity to pass an ideal error-free turing test  which is still a candidate for a sufficient condition on intelligence.
1 conclusion
the idea that the presence of genuine thought can be conclusively determined by the ability of an entity to engage in verbal discussions can be traced back at least to descartes discourse on method  who writes:
   if there was a machine shaped like our bodies which imitated our actions as much as is morally possible  we would always have two very certain ways of recognizing that they were not  for all their resemblance  true human beings. the first of these is that they would never be able to use words or other signs to make words as we do to declare our thoughts to others. ...  o ne cannot imagine a machine that arranges words in various ways to reply to the sense of everything said in its presence  as the most stupid human beings are capable of doing.
nearly four centuries later  it is difficult to underestimate the foundational importance of the turing test to the fields of artificial intelligence and cognitive science. however  the extent to which a test on verbal behavior can be taken to represent a sufficient condition for intelligence is highly controversial.
　this paper assessed the validity of existing arguments against the turing test. we presented two of the most persistent objections: the objection frominformation contentand the objection from generative incapacity. while we agree that the turing test has little to say about the extent to which the formal symbols manipulated by the machine relate to the real world  we showed that our intuition about the importance of this fact are not clear-cut. on the issue of generative incapacity  we argued that a machine with a finite information store could not be constructed in such a way as to be guaranteed to pass the turing test. we also suggested that a turing test can be constructed in such a way as to guarantee that a machine with a finite information store will fail it.
