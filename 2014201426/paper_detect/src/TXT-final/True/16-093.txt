 
this paper develops a simple and robust procedure for recovering sensor motion parameters from image sequences induced by unconstrained sensor motion relative to a stationary environment. difference vectors of optic flows approximate the orientations of the translational field lines in image areas in which there is depth variance between the corresponding environmental points and sufficient angular separation from the translational axis. this is developed into a procedure consisting of four steps: 1  locally computing difference vectors from an optic flow field; 1  thresholding the difference vectors; 1  minimizing the angles between the difference vector field and a set of radial field lines which correspond to a particular translational axis; and 1  extracting the translational and rotational component fields given the translational axis. this procedure does not require a priori knowledge about sensor motion or structure of the scene. it depends critically on sufficient variation in depth along some visual directions to endow the flow field with discontinuities. we present results of applying the procedure to sparse and low resolution displacement fields. 
introduction 
　　　the motion of an observer/sensor is in general composed of a translation and a rotation. it generates an optic flow field in the image plane of the sensor due to changes of visual directions of details in the environment over time  gibson et. al. 1 . the translation of the sensor induces a radial flow in the image with the intersection of the translational axis and image plane as its center. sensor rotatation induces a rotational field in the image that is purely direction dependent  that is  a function of image position only . 
     the translational component  and its spatial and temporal derivative fields  contains  e.g.  information about the shape of objects  koenderink and van doom 1   about the relative depth properties of the environment  lee 1  prazdny 1   or about motion parameters for navigating along curved trajectories  rieger 1 . processing optic flows induced by observer/sensor motion can be done by decomposing a flow field into its rotational and translational components and then recovering the environmental information from the translational component. techniques for doing this generally require high resolution image displacements as input and are sensitive to the noise and error that current techniques for determining image motions typically produce. they can also involve solving complex equations and require significant computation. 
　　　the recovery of sensor motion parameters can be simplified considerably by making use of the geometrical structure of optic flows in regions corresponding to environmental depth changes. in such regions the difference vectors that have been computed over some neighborhood are oriented approximately along translational field lines. this can be seen easily for the case of details that are located exactly in the same direction from an observer/sensor but are at different depths  such as points along occluding boundaries  as observed by longuet-higgins and prazdny  1   such points will differ in their image velocity vectors by the difference of their translational components only. this is because the rotational components of optic flows are purely direction dependent and thus equal for flow vectors positioned at the same image point. the axis of sensor translation can then be obtained from the intersection of radial fieldlines which are determined by such difference vectors. given the axis of translation  the rotational and translational component fields are strongly overdetermined. 

1 j. rieger and d. lawton 


recovery of motion parameters and depth 
　　　in order to compute difference vectors from image displacement fields formed over discrete time intervals  as opposed to continuous intantaneous image velocity fields   we have to be careful to describe all quantities with respect to the same reference system. suppose two environmental points lie along the same ray of projection in an image at time t. translating and rotating the sensor will displace the projections of these points to new positions in the image at time t + 1. in the image at time t + 1  the image points will be separated due to the translational component of the sensor motion  unless they are located on the translational axis . the separated image points and the intersection of the translational axis with the image plane will be collinear at time t + 1. this is the discrete analog of the fact that difference vectors at discontinuities of an instantaneous optic velocity field are oriented along translational field lines. thus  given image displacements dl and d1 at positions pi and p1  the difference vector between points 1 and 1 is obtained by subtracting d1 from dl and positioning the resulting vector at pi + dl. 
     two thresholds are used in evaluating difference vectors. the separation threshold determines the maximal allowable distance between displacement vectors in determining difference vectors. the neighborhood of a given displacement vector contains all other displacement vectors which lie within a distance determined by the separation threshold. the length threshold determines the minimal allowable length for a difference vector. for a given difference vector and a set of radial field lines  the error angle is the angle between the difference vector and the fieldline at that position. 
　　　we have found that reducing the number of difference vectors by increasing the length threshold and decreasing the separation threshold improves the fit of the difference vector field to the set of correct field lines up to a certain degree. this is because short difference vectors  compared to the local average magnitude  are more likely to deviate from the correct field lines and computing difference vectors 
j. rieger and d. lawton 1 
over larger neighborhoods increases the noise components. if  however  thresholding eliminates too many difference vectors the fit detonates  since the signal of the difference vector field becomes less distinguished for a decreasing number of vectors. 
　　　for each image displacement vector a set of difference vectors of sufficient length is determined over its neighborhood. for the resulting field of difference vectors  processing involves finding a translational axis and the corresponding set of radial field lines which minimizes the sum of the magnitude of the error angles. the procedure used is basically that used in lawton  1  1  to determine the translational axis from noisy displacement fields induced by rectilinear sensor motion. the error measure is defined on a half sphere  where points on the half sphere are possible candidates for the translational axis. the advantage of using a sphere as a domain is that it allows for a uniform  global sampling of the error function. the search process itself consists of a global sampling of the error measure to determine its rough shape using a generalized hough transform  ballard 1  o' rourke 1  followed by a local search to find a minimum. 
　　　the computation of the sensor rotation  scaled by focal length  from the original flow field and the radial  translational  fieldlines is straightforward. note that the components of the flow perpendicular to the radial fieldlines are induced by sensor rotation. introducing  for convenience  a polar coordinate system  r 1  in the image plane centered at pt we have a system of overconstrained linear equations of the type  in the three unknowns  and 
     knowing the rotational parameters yields the translational and rotational component fields of the orginal flow field. the translational component is directly related to the relative depth of a scene  i.e. the depth scaled by the sensor displacement in depth 
1z  by the relation    where ut is a translational flow vector in the image. if the frame rate is known the relative depth of an environmental point corresponds to its temporal separation from the sensor  under constant approach velocity . biological systems seem to exploit this optical relation for a variety of navigational tasks  lee 1  wagner 1 . 

1 j. rieger and d. lawton 

j. rieger and d. lawton 1 


　　　several experiments with simulated displacement fields have confirmed the expected effects of environmental depth variance and displacement vector density and demonstrated robust performance with respect to various kinds of noise. the procedure has also successfully determined the translational axis from displacement fields obtained from low resolution image sequences from a solid state camera. for such image sequences with large environmental depth variances the translational axis has been determined within a few degrees of visual angle  rieger and lawton 1 . 
     we thank frank glazer for pointing out a bug in this paper. this research was supported by darpa grant n1-k-1 to the motion group at umass. 
