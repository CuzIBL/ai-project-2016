 
	we propose to use an 	extended 	gaussian 	imap e 
 egi  for interpreting 1/1-d representations for recognition of 1-d objects. the egi is constructed by mapping each surface normals of an object to the gaussian sphere. 
　　　the freedom in viewer directions caused by incomplete observation is greatly reduced by applying constraints derived from a global distribution of surface normals on the egi. one constraint on the viewer direction is derived from the ratio of the projected area to the original surface area. the other constraint comes from the direction of the principal axis. after reducing the possible viewing directions with these constraints  we w i l l apply a matching function to esls of a candidate set for a final decision. 
　　　we also propose an algorithm for reconstruction of the original shape of a convex polyhedron from its egi. this algorithm is based on the analysis-by-synthesis method. 
1
 what is the extended gaussian image 
	a 	collection 	of 	local 	surface 	normals 
 1 1 1   sometimes referred to as a 1/1-d representation of an object   is often provided by machine vision at the low level. for example  an algorithm based on the propagation-of-constraints technique  provides local surface orientation from shading and occluding information. the same algorithm can also produce surface orientation from apparent distortion of known patterns based on a regular-pattern gradient map  a   the distortion of these small circles on the golf ball in fig. 1 can be used to recover local surface orientation. 

　　　in the above cases  the next problem encountered is how to interpret these local representations for a global recognition of an object. one of the most important issues in this process is how to convert a local representation based on the viewer-centered coordinate system into a global description based on the object-centered coordinate system such as the generalized cylinder  1  or the spike model . each local representation depicted as a needle in the above example is obtained at a particular point expressed in viewer-centered coordinate system on the image plane. on the other hand  an object model is expressed in a particular coordinate system usually based on an object center and natural axis of the object. these two coordinate systems are independent each other. it is quite difficult to recover the original object-centered coordinate system from the 1/1-d representation observed in the viewer-centered coordinate system. we propose to use the extended gaussian image  egi  as a tool for this conversion process. 
　　　an egi of an object may be derived from a spike model of the object . a spike model is a collection of surface normals on each surface patch in the 1-d world. let us assume that there is a fixed number of surface patches per unit surface area and that a unit normal is erected on each patch. the collection of these normals is called a 
　　　spike model of the object. these normals are like porcupines's quills . these normals on surface patches in a spike model are moved to a common point of application. the locus of points consisting of their end points lies on the surface of a unit sphere. this mapping is called the gauss map; the unit sphere is called the gaussian sphere. if we attach a unit mass to each end point of the normal vector  we w i l l observe a distribution of mass on the gaussian sphere. this distribution of mass w i l l be normalized. the resulting distribution of mass on the gaussian sphere is called the extended gaussian image  egi  of the object  1 . 
　　　an egi is independent on both the position of the origin and the scale of axes of the coordinate system. a coordinate system may be characterized using three components; the position of origin  the direction of coordinate axes  and a scale factor of a coordinate axis. among these three components  an extended gaussian image is independent on both the position of the origin and the scale factor of coordinate axis. an egi is independent on the position of the origin  because surface normals on patches w i l l be projected on the gaussian sphere in parallel transformation without regarding the position of the origin. also the representation is independent on the scale of the coordinate. for example  a 1x1-inches cube has the same 
representation as a l x l x l inches cube  provided that total mass of distribution on the sphere is 

1 

normalized. namely  both images from these cubes consist of impulses of 1 u n i t mass at the north pole  the south pole  and each quarter point on the equator of the gaussian sphere. 
　　　the egi may be regarded as a unique d e s c r i p t i o n   on t r e a t i n g only convex objects. an object has a unique eg1  when the object is a convex polyhedron   1   . minkowski showed that: two convex polyhedra are i d e n t i c a l if each pair of corresponding faces has an equal area and the same surface normal. 
it recognition of an object using an egi 
a. 	data structure 
　　　we have to t e s s c l l a t e the gaussian sphere i n t o meshes  when we t r e a t objects which have continuous surfaces  eg. c y l i n d e r   s p h e r e   . . .   . a continuous surface has a continuous d i s t r i b u t i o n of i n f i n i t e l y many points on the gaussian sphere. we have to convert a continuous d i s t r i b u t i o n i n t o a discrete d i s t r i b u t i o n . 
　　　for t e s s e l l a t i o n   we have to divide the surface of the gaussian sphere in a uniform manner. since we look at an object from d i f f e r e n t d i r e c t i o n s   a t e s s e l l a t i o n method is required to have the same r e s o l u t i o n of angle in every d i r e c t i o n . in other words  each c e l l on the tessellated sphere is required to have the same area and the same distance from i t s adjacent c e l l s . 
　　　one way to s a t i s f y t h i s condition is to use a regular polyhedron to divide the gaussian sphere i n t o meshes   1   . a regular polyhedron has faces of equal area. also a regular polyhedron has faces evenly d i s t r i b u t e d in d i r e c t i o n w i t h respect to the center of g r a v i t y . thus  we can divide a sphere i n t o meshes of a fixed area by p r o j e c t i n g edges of a regular polyhedron inscribed in the sphere onto the surface of the sphere w i t h respect to the center of the sphere. the r e s u l t i n g t e s s e l l a t i o n on the sphere is called as a geodesic dome   1   . 
　　　since we have no polyhedron of higher order than the icosahedron  we use a semi-regular geodesic dome constructed from a two frequency dodecahedron.  see f i g . 1.  our t e s s e l l a t e d sphere also has a h i e r a r c h i c a l s t r u c t u r e . each c e l l on one level contains both pointers to sub-cells on the next l e v e l and the d i r e c t i o n of the center point of the c e l l . distance measures between c e l l s is also maintained in t h i s s t r u c t u r e . since we use a two frequency dodecahedron for t e s s e l l a t i o n   the top l e v e l c e l l contains pointers to twelve surfaces of a 
　　　geodesic dome based on a dodecahedron. the second l e v e l has 1 t r i a n g l e areas which come from a one frequency dodecahedron. the lowest l e v e l contains 1 t r i a n g l e c e l l s of a two frequency dodecahedron. 
　　　quantization of an object in a l l d i r e c t i o n s uniformly is also required when making a prototype. for example  if you sample surface o r i e n t a t i o n s of an e l l i p s o i d along i t s long axis at every observed p i c t u r e element  you w i l l obtain very rough information on the view from the d i r e c t i o n of the long axis even though you get f i n e information on 

f i g . 1 data s t r u c t u r e . each c e l l   depicted as a c i r c l e   contains both pointer to sub-cells on the next l e v e l and the surface o r i e n t a t i o n there. 
the view from the d i r e c t i o n perpendicular to the long a x i s . thus  t h i s sampling method is q u i t e unsuitable in t h i s case. we w i l l use the tessellated sphere for sampling d i r e c t i o n s when making prototypes as w e l l as for r e g i s t r a t i o n of the egi. the tessellated sphere samples the whole s p a t i a l d i r e c t i o n s in an even manner.  this schema w i l l give an even sampling with respect to every d i r e c t i o n . 
　　　note that two spheres are used; one for sampling s p a t i a l d i r e c t i o n s and the other for r e g i s t e r i n g an egi on i t s spherical surface. the former sphere for sampling is assumed to be located at the center of g r a v i t y of an o b j e c t . surface o r i e n t a t i o n of patches on an object are sampled at every d i r e c t i o n corresponding to each c e l l on the tessellated sphere. in other words  the surface normal on each c e l l of the sampling sphere is extended u n t i l it reaches the surface of the o b j e c t . at that surface patch where the extended surface normal h i t s   surface o r i e n t a t i o n of the object is measured. the measured surface area w i l l be registered on the corresponding c e l l of tessellated gaussian sphere for expressing the egi of the o b j e c t . thus  the cumulative image on the sphere for r e g i s t r a t i o n is constructed as the egi for the prototype of the o b j e c t . 
b. 	constraints on viewer directions 
1 　　　matching an egi from observed data w i t h i t s prototype involved three degrees of freedom  since there are three degrees of freedom to a l t i t u d e of an object in space. if the whole surface of an object was v i s i b l e   the d i r e c t i o n s of the three p r i n c i p a l moments of i n e r t i a would determine the s p a t i a l alignment of the object   1     unfortunately  however  the t y p i c a l s i t u a t i o n s allow us only a p a r t i a l observation of an unknown o b j e c t . this p a r t i a l observation causes three degrees of freedom in a l t i t u d e of the o b j e c t . viewer d i r e c t i o n gives two degrees of freedom; that i s   there are two degrees of freedom corresponding to which c e l l on the gaussian sphere of a prototype is perpendicular to the d i r e c t i o n of the l i n e of s i g h t . the remaining degree o  freedom comes from r o t a t i o n of 
the gaussian sphere of the prototype around the line of sight when matching the prototype with the observed sphere. 
     we w i l l use two kinds of constraints to reduce the search space for matching. although a brute force technique  such as search through the space of possible attitudes  can be applicable to matching directly  we w i l l reduce this search space using constraints before beginning comparison. one constraint reduces the freedom of viewing direction. this constraint is derived from a ratio of visible area projected onto a plane perpendicular to the line of sight against surface area. the other one constrains freedom of rotation. this constraint for rotation of the sphere is based on the symmetry axis on the plane perpendicular to the line of sight. 
　　　the ratio of area projected onto the image plane against the original surface area is a constraint on the viewing direction. for example  observing an ellipsoid from the direction of the long axis gives a smaller projected area than looking at the same ellipsoid from the direction perpendicular to the axis. yet the surface area is the same. 
	projected area is normalized by 	surface 	area. 
the area is calculated at each triangle v before comparison. see fig. 1. this ratio is denoted as 
av = sum  zi x mi  / sum  mi   
where the summation is done only if the mesh i is visible from the mesh v  mi is mass at the cell i  and zi is a inner product between the viewer direction v and the surface normal at the cell i. this ratio is calculated only over a visible hemisphere from the viewing direction v. this ratio removes only one degree of freedom just like the reflectance ratio on the gaussian sphere   thus  even though this constraint reduces the possible set of of viewer directions  we s t i l l have to search for the real view point on the gaussian sphere along one of these iso-ratio lines observed from an image. for example  fig. 1 denotes iso-ratio contours drawn on the stereographic plane for graphical clearness. this diagram is used when finding viewer direction in the same way as the reflectance map is used to recover the 1/1-d representation from a brightness value. 
　　　we also must find the rotation of the egi of a prototype around each candidate cell for the viewer direction. we use the direction of the principal axis of inertia over a hemisphere from the viewer direction. we w i l l use the 1-d axis rather than the 1-d axis for simplicity of calculation. in other words  we use the direction of the axis of least inertia on the tangential plane at cell v  or the image plane on seeing the object from the direction of v . 
　　　the following calculation w i l l give the direction of this axis. before calculation  each cell i is projected onto the tangential plane at the cell v. let  xi yi  be the coordinate obtained on the plane. we w i l l use 
ixx = sum  mi x xi x xi    ixy - sum  mi x xi x yi    lyy = sum  mi x yi x yi    where these summation are also done only if cell i is visible from the c e l l . from these values of ixx ixy lyy  the principal direction of inertia is obtained. 
	α 	= atan 1lxy/ iyy-ixx   /1  
this α is the direction of the principal axis on the tangential plane. 
　　　this direction may be regarded as a symmetry axis of the object observed from the direction denoted with the cell v. note that  if the object has a symmetry axis in the 1-d space  the principal direction of inertia in 1-d obtained above w i l l correspond to the direction of 1-d symmetry axis projected onto the plane   in other words  the direction is unique at each cell in almost a l l case. thus  this direction uniquely determines the manner in which way a prototype should be aligned on comparing the prototype with an observed data. in this case  the constraint reduces the possible area perfectly; there is no need for search involved. in fig. 1 the direction of principal axis of inertia at each viewing direction is depicted as a needle on each cell v. these needles constraint the rotation of prototype around the line of sight. 
　　　so far each cell on the gaussian sphere has to contain three kinds of information; how much weight the cell contains  mass   how much an object has projected area on being viewed from the direction of the cell  surface ratio   which way the axis of inertia exists  axis . the second one  surface ratio  and the third one  axis  constrain freedom of viewing direction before matching. the f i r s t one 

where gl and g1 are coefficients. in other words  if a cell in the prototype has some contents  the algorithm checks around the cells in the observed data to see whether the observed data contains similar amounts of mass or not. in case there exists a similar amount of mass within a neighboring area  a weight w i l l be added to the point-total for the prototype. after calculating this point-total for a l l candidates  the candidate obtaining highest 
point-total 	w i l l 	be 	determined 	as 	the 	object observed  
d  	an illustrative example 
	consider the simple 	example 	of 	an 	ellipsoid 
 x1-y1-y1 z/1 *-l  observed from the direction inclined from z axis by angle 1 degrees. the surface normal w i l l be derived analytically and used to generate a needle diagram. the algorithm w i l l be applied to the synthesized needle diagram. the result w i l l be used as a basic basis for judging the performance of the algorithm. 
　　　for the example  a 1 x 1 synthesized needle-diagram was generated. at each image point  elementry calculus gave an outer surface normal of the ellipsoid. for graphical clearness  each surface normal is depicted as a needle. 
　　　the f i r s t task is to obtain an egi from this needle diagram. each surface normal at an image point is determined to which cell on the gaussian sphere the surface normal corresponds. then  its surface area is added to the c e l l . since each image point is assumed to have the same area  
corresponding surface area is calculated as 
  1 / cos α . 
where of is the angle between the surface normal and che direction of the viewer. after obtaining surface areas  cumulative values registered on cells of the gaussian sphere are normalized by the surface area observed. fig. 1 showes the resulting egi obtained from fig. 1. 
　　　we also determine the ratio of the projected area to the surface area  while making the egi from 

fig. 1 a synthesized fig. 1 the obtained egi needle diagram. from fig 1 
the needle diagram. this ratio reduces possible viewer directions as mentioned above. the surface area is calculated simply by summing up   1 / cos α    while the projected area is as same as the number of image points within the occluding boundary. 
s t r iy use the points within a boundary when obtaining the surface area  because points near the occluding boundary cause a dramatic effect to this value. for example  if a point sits at the occluding boundary    1 / cos α  becomes infinite; we cannot obtain the real surface area. 
　　　fortunately  the constraint  the ratio of the projected area to the surface area  also works within some boundary. more precisely  the ratio is a function of both a spatial angle on the gaussian sphere and the viewer direction. for example  if we take into account a l l points on a hemisphere of the gaussian sphere  the ratio is the constraint to the viewer direction as the one mentioned above. on the other hand  if we use only points within a c e l l   the constraint is identical to the judgment whether the cell contains some amount of mass or not. between these two extremes  we can also derive various kinds of constraints  depending upon which area on the gaussian sphere we use for calculation. in this example  we use the ratio of the projected area to the surface area whose corresponding points on the gaussian sphere have azimuth angles less than 1 degrees based on the direction of the viewer    
   1  . we obtained 1 as the ratio within the boundary in this illustrative example. 
　　　we prepared two kinds of egis as candidates for matching. one is from the ellipsoid and the other one is from an cylinder whose radius is 1 and hight is 1. their egi is shown in fig.1. 

　　　the ratio of the projected area to the surface area  1+1  reduces 1 possible viewer directions to 1 directions in the case of the ellipsoid and to 1 directions in the case of the cylinder. since both objects have symmetry axes  the constraints from the axis determines the direction of alignment uniquely. 
in the ellipsoid case  cell 1  and cell 1 	the opposite side of 1  has the highest value  1 

and cell 1  1 has the becond largest value 1. in the cylinder case  cell 1 nas the largest value 1. namely  the algorithm tells us that the cell number 1 of the ellipsoid is most likely as the viewer direction. this cell has the direction  1  -1  1  based on the direction of the long axis of the ellipsoid. in other words  the algorithm successfully tells us that it is most likely that the ellipsoid is observed from the direction inclined by 1 degrees from the long axis of the ellipsoid   
i i i reconstruction of a convex polyhedron from its egi 
　　　if an object is a convex polyhedron  it is possible to reconstruct the original shape from its egi. this result can be predicted from minkowski's theorem . this theorem is quite important. because of i t   we need not store the adjacency relationships among faces. only the surface orientation of each face and its area need be remembered. actually  this fact is the basic 
motivation for using an extended gaussian image. 
unfortunately  minkowski's proof of the theorem 
is not constructive and does not provide an algorithm for reconstruction. we propose here an algorithm for this reconstructing of a convex polyhedron from its egi. our algorithm for reconstruction is based on the analysis-by-synthesis method. 
the problem for reconstructing a shape from its 
egi 	is 	to 	obtain 	the 	distances 	of 	the 	faces 
 co .... cn  from an origin  provided that we have known areas  mo ... mn  of faces and the surface orientations   xo yo zo  ...  xn.yn.zn  . we may set co=1 without loss of generality  because a polyhedron can be put at an arbitrary place in a 
particular coordinate system without altering its shape. 
　　　we can divide the problem into n cases.  there always exists a maximum value c-max among gl .. cn. that is  there is a farthest face from the origin among face 1   . . . face n. thus  we w i l l consider n sub problems. namely  in case i  we assume ci has the maximum value; face i is the farthest face from the origin. we set the farthest distance  ci - 1  in case i. the reason for dividing the problem into n cases is to fix the possible values of the ci between 1 and 1. otherwise  ci may take a value from 1 through an infinite value. since we do not know which case is true amonp  the n cases  we w i l l check a l l n cases to see whether the case contains a solution point or not. for each case  we w i l l quantize the remaining n-1 dimensional space into cells where c1 .. ci-l ci+l ... cn changes from 1 through 1. then  it is possible to calculate mo ... mn at each mesh point  co ... cn  and to compare with the given values. 
	we 	w i l l 	show 	how 	to 	calculate 	mo 	as 	an 
illustration. obviously  another face area mi can be obtained in the same way. 
	for 	simplicity  	we 	assume 	 xo yo zo  
 1 1 1   	where 	 xo yo zo  	denotes 	the unit normal vector corresponding to the surface orientation of face 1. this can be established by rotating the gaussian sphere so that the vector  xo yo zo  points to the north pole. in other words   t  xo yo zo   -  1 1 1   where t is a matrix which corresponds to one of the suitable rotations. 
　　　the other points on the gaussian sphere should also be rotated in the same way;i.e. 
 t  xi yi zi  . in the following part we denote t  xi yi zi  by  xi yi zi  for the sake of simplicity. 
　　　we next determine whether one intersection line constitutes an edge of the face for  xo yo zo  or not. every face corresponding to  xi yi zi  has an intersection line with the infinite plane corresponding to  xo yo zo . the desired face corresponding to  xo yo zo  consists of a partial plane cut out from the infinite plane by some segments of these intersection lines. 
　　　since a face of a convex polyhedron is also convex  the algorithm can connect only those segments which constitute a convex figure. if a small bug is assumed to travel along edges of a convex figure counter-clockwise  the bug would always turn to the left at each corner of the convex figure. in other words  the normal vector from each edge  and also the projection of the surface normal of a face which intersects the infinite plane constituting the edge  also rotates clockwise. for this  we w i l l order the intersection line according to the azimuth angle  atan yi/xi   of the normal vector  xi yi zi  of each face i.  we w i l l denote the n-th intersection line as ln   then the bug w i l l v i s i t intersection lines in the order sometimes skiping some lines. 
　　　we calculate the intersection point between the n-th line and the n+l-th line  we w i l l denote this point pn n+1 . these points are candidates for vertices on the face of the polyhedron. we w i l l connect pn-l n with pn n+1. in other words  we w i l l cut out a segment sn between pn-l n and pn n+1 from the intersection line ln  where  sn  has the direction from pn-l n to pn n+1. 
---  we w i l l connect sn from p1 m in sequence. if sn+1 turns around pn n+1 counter-clockwise  based on the direction of the segment  sn   then the segment  sn is an edge of the face. if sn+1 turns around pn n+1 clockwise  then sn+1 is not an edge of the face. we call this segment sn+1 as an imaginary edge and do the imaginary-edge operation in order to find a real edge. 
　　　the imaginary-edge operation recalculates a segment which causes an imaginary-edge. let us assume that si is detected as an imaginary-edge. it means that the last segment si-1 should be  also re-calculated  because the last segment si-1 is assumed to intersect with si but si is not a real edge. the imaginary-edge operation w i l l recalculate each intersection point between li-1 and l j   where j is larger than i and make a new segment. the imaginary-edge operation will find a segment s'i-1 
whose length is smaller than si-1 for the f i r s t time after li along the sequence.  see fig. 1.  this segment s'i-1 between p i - 1   i - l and pi-l j is 

r a t i o representing how much a surface is projected on a plane perpendicular to a viewing d i r e c t i o n   and the d i r e c t i o n of a symmetry axis r e l a t i v e to the viewing d i r e c t i o n . a f t e r reducing the possible d i r e c t i o n s of observation  a matching function is applied to the observed d i s t r i b u t i o n of mass w i t h the prototypes of candidates o b j e c t s . the best f i t t i n g candidate w i l l be selected as the object observed at that time. 
       even though a couple of non-convex objects among a candidate set may have the same egi   1     an egi is s t i l l a h e l p f u l t o o l ; a f t e r reducing the possible set of candidates and also determining possible s p a t i a l alignments of the candidates by using the egi  the i n t e r p r e t e r can make a f i n a l decision based on the other features such as p o s i t i o n i n f o r m a t i o n   which the egi discards in order to overcome the discrepancy between the viewer-centered coordinate system and the object-centered coordinate system. 
acknowledgments 
　　　the author would l i k e to extend his sincere appreciation to dr. y. shirai of etl and prof. b.k.p. horn of mit for t h e i r h e l p f u l discussions. 
thanks 	go 	to 	the 	referees 	to 	t h e i r 	h e l p f u l comments. 
