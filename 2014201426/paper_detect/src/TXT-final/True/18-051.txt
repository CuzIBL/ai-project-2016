 
   measurements on image texture interpreted under an approximate perspective image model can be used with an iterative constraint propagation algorithm to determine surface orientation. an extension of the ideas allows their robust application to natural images of textured planes. the techniques are demonstrated on synthetic and natural images. 
1. introduction 
   the recover  of 1-d  shape  information from a two dimensional image is an important task in image understanding.  shape from ...  algorithms exist for intensity  motion  contour  and texture. this work extends work on shape from texture. the shape from texture problem has been studied extensively. gibson  1  first proposed the texture density gradient as the primary basis of surface perception by humans. following gibson's ideas  bajcsy and lieberman  1  tried a heuristic use of the two dimensional fourier spectrum to detect the gradient. 
   to formalize the shape from texture problem requires a model for the image formation system. up to now three kinds of projections have been used: orthographic  perspective and spherical projection. kender  1   kanade  1  and witkin  1  studied the problem under orthographic projection  and kender  1  and ohta  1  address the problem under perspective projection. ikeuchi  1  used spherical projection. in his work the texture elements had to be known and symmetrical. 
   our algorithm determines surface orientation from the apparent distortion of patterns on the image  provided that: 
    1  the surface in view is smooth and is covered with uniformly repeated texture elements. all the texture elements on the surface are identical. these texture elements we call texels. the shape of the texels is of no importance for our theory. 
    1  bach texture element is assumed to lie on a plane  i.e. we assume that the surface in view is locally planar . this means that the size of the texels on the surface has to be small compared with a change of surface orientation there. 
    1  the scene texture is imaged under an approximation to perspective projection similar to that of ohta  1 . this projection preserves important perspective distortions but is computationally tractable. 
   under the above assumptions  we develop a new gradient map that will enable us to define a  textural reflectance function. . our theory is very similar to earlier work on shape from shading  horn  1; ikeuchi  1   with the image intensity at a point replaced with the area of the image texel at that point. 
1. mathematical preliminaries 
   in this section we define a way to approximate the distortion of a texel under perspective projection by a 1-d affine transformation. 
1 approximation of the perspective projection by a 1t  affine transformation 
   let a coordinate system oxyz be fixed with respect to the camera  with the -z. axis pointing along the optical axis  and o the nodal point of the eye  center of the lens . the image plane is assumed to be perpendicular to the 1 axis at the point  1 -1    i.e. focal length = 1 . 
   under perspective projection  a point of the object surface is projected onto the image plane by a projecting ray defined by that point and the center of the lens. 
   our approximation is done by dividing the projection process into two steps.  see figure 1 . consider a textured surface s in the world and a texel t on the surface  lying in a local plane q with orientation given by the surface gradients  p q . consider also a plane y  parallel to the image plane and just in front of the surface s. the plane y has distance b from the origin   i.e. its equation is -z - ji . 

figure 1 

   the steps of the projection process of the texel t onto the image plane are as follows: 
　　 1  the surface texel is projected onto the plane y. this projection is performed parallel to the ray og  where g is the mass center of the texel t.  thus the image of the mass center of the texel is on the projected mass center of the texel  and the projection is parallel to the direction  a b -1  where  a b  is the image of the mass center of the texel t . 
　　 1  the image on the plane y is projected perspectively onto the image plane. since the plane y is parallel to the image plane  this perspective transformation is just a reduction by a factor of  /p. 
   step 1 skews the image to account lor foreshortening  and step 1 scales the image in a location-depth dependent manner  as does perspective. the combined process is an affine transformation. 
　to represent the original pattern of the surface texel  we use an  a b c  coordinate system  with its origin at the mass center of the texel and the  a b  plane identical to the plane q to represent the pattern of the image texel  we use an  a b c'  coordinate system  with its origin the point  a b  1   i.e. the mass center of the image texel  and the axes a' b c' parallel to the axes x y z respectively. then the transformation from  a b  to  a b'  with the two step projection process of previous section is given by the 
j. aliomonos and m. swain 1 
v   + p' + q' 
where i is the intensity   p q  the gradient of the surface point whose image has intensity 1  a is the albedo at that point and  a b 1  the direction of the light source  horn  1; ikeuchi  1 . 
   thus equation  1  can be used to recover surface orientation  using methods that have been discovered for the solution of the shape from shading problem  ikeuchi  1 . 
1 a gradient map 
equation  1  of the previous section can be written as : 
           / - r p q  	 1  where / is the textural intensity  i.e. the area ol an image texel with mass center  a b   and 
　　　　　y-ap bq r p.q  - a. 
with a the textural albedo  i.e. the quantity sw-/b and  p q  the gradient of the plane on which the world texel lies. the function r p q  we call textural reflectance. if we fix the albedo a  and the position  a b  of the texel on the image  then equation  1  can be represented conveniently as a series of contours of constant textural intensity. figure 1 illustrates such a simple textural reflectance map. 

affine transformation. 1 j. aliomonos and m. swam 


j aliomonos and m. swain 1 
r p-qi j.  is a function on a four-dimensional space  

unlike the r p q  of orthographic shape from shading. the shading r p q  can be determined empirically  but the textural reflectance r pirqtj  is an analytic  geometrical entity arising from imaging geometry  and thus only the global constant  texture  albedo varies from texture to texture and scene to scene. 
1. experiments 
　　the algorithm was tested on artificial images of a plane  cylinder and sphere. there are four distinct steps into which the program may be broken down: 
1  location of texels 
1  minimum triangulation of the texel centers 
1  calculation of initial orientations and textural albedo. 
1  iterative process. 
in 1   the connected regions in the image are detected. 
their centers of gravity are taken to be the locations of the texels. their size is recorded and the texels which are in the boundary are marked  ballard & brown  1 . in 1   the points denoting the centers of the texels are triangulated so that the sum of the length of the lines is minimum  aho  hopcroft & ullman . in 1   the initial orientations were calculated using the method in section 1. the estimate of a was calculated from the local orientation with the lowest value of p and q. due to curvature of the surface  convex objects tend to give an overestimate of a while concave objects tend to give an underestimate. these errors are minimized when the surface of the object is most nearly perpendicular to the image plane. the algorithm is quite insensitive to initial orientations given to texels whose orientations were allowed to vary through the iterative process. boundary texels were not allowed to change. the error in calculating their values was the predominant factor in influencing the total error. the iterative process took under 1 iterations. the process always converged for our synthetic images. the final error values were 

   finally  azmuthal equidistant coordinates  ahc  were used through the iterative process instead of the gradient space p and q  since ahc change linearly with change in orientation. higure 1 shows the image of a sphere which is covered with a repeated pattern  higure 1 shows the reconstructed sphere using the algorithms of sections 1 and 1  and higure 1 shows the reconstructed sphere after the relaxation. figures 1  1  and 1 and 1  1  and 1 show the analogous pictures for a cylinder and plane respectively. 
1. an extension to natural images 
   in natural images  the assumption that the world surface is covered with the same texels is not very realistic. this section refers to recent work by aloimonos and chou 
 1  on shape from the images of textured planes  based on the uniform density assumption under strong segmentation  identification of texels  and weak segmentation  edge finding . consider a world plane - / px + qy -f c  and the plane y passing through the center of mass of a small area s of the world plane. if we consider an area s1 in the image  then in order to find the area in the world plane whose projection is .s1  we must multiply the area s1 with the factor 

1 j. aliomonos and m. swain 

   the above equation represents a line in p-q space. any two regions in the image constrain  p q  to lie on a line in the gradient space. thus  taking any two pairs of regions we can solve explicitly for p and q.  to overcome undesirable results due to errors from the digitization process and the density fluctuations of the regions  we employed a least-square-fit mechanism by considering several image pairs. a hough transform estimation method might also be appropriate.  figure 1 is the image of a plane parallel to the image plane  covered with random dots  texels . figure 1 is the image of the dotted plane rotated and translated with tilt - 1＜ and slant - 1＜. our program  based on the scheme described above  recovered tilt = 1＜ and slant = 1＜. 

1 solving the problem with a weaker segmentation 
   in the previous section a method was developed to recover the orientation of a textured plane from its image  based on the assumption of uniform texel density; by uniform density  we mean that the number of texels per unit area of the world plane is the same. application of this method to natural images did not seem to work very well  because no good methods have been developed up to now that can identify texels in an image  and this algorithm depends critically on the number of texels per unit area. on the other hand  in the recent literature  bandyopadhyay  1; ballard & brown  1; marr  1  there are several methods for the computation of partial boundaries of the texels  edges  at every point in a textured image. fet us redefine density to be the total length of the texel boundaries per unit area. the uniform densitv assumption states that this density is the same everywhere in the world plane. this assumption is not far from the previous one and seems to be true for a large 
subset of natural images  in contrast with witkin's isotropy assumption  which does not seem to hold true for many natural images. aloimonos & chou  1  describe a method that finds the orientation of the world plane under the new assumption and below we describe expriments based on that method. figure 1 presents the image of a 
plane parallel to the image plane  covered with random line segments. figure 1 presents the image of this plane rotated with tilt 1＜ and slant - 1＜. the program recovered tilt = 1＜ and slant - 1＜. figure 1 presents the image of a plane  parallel to the image plane  covered with randomly generated small circles. figure 1 presents the image of this plane rotated with tilt - 1＜ and slant - 1＜. the program recoverd tilt - 1＜ and slant = 1＜. the natural images used were first preprocessed to find the boundaries of texels  edges  by applying the modified frei-chen operators introduced by bandopadhyay  1 . figure 1 shows the photograph of a textured floor with slant = 1＜ and tilt - 1＜. figure 1 shows the edges after the preprocessing. the algorithm produced slant = 1＜ and lilt = - 1＜. finally  figure 1 shows the photograph of a part of a grass field with slant = 1＜ and tilt -- 1＜. figure 1 shows the images of its edges after the preprocessing. the program recovered slant - 1＜ and tilt 1＜. 



	figure 1 	figure 1 
   aloimonos and chou  1  present a theoretical analysis of the error introduced by the affine approximation to the perspective projection. 
conclusion 
   in tins paper we gave a method for  shape from texture  computation that extends results in the literature. our algorithm can work in a richer domain than already published methods. for reasons involving the cosine foreshortening law  the result here is similar to the original shape from shading constraint applied to lambertian surfaces. we believe that this may have some important implications  since for example the same hardware may be used for shape recognition  regardless of whether we use shading or texture. finally  an extension of the algorithm to a form that works well for many natural images was presented. 
