 
   tools for building production systems encounter the problem of low performance  and many researchers are working on the improvements of performance of these tools. this paper proposes a distributed approach for inferring production systems. the resulting distributed production systems are expected to be built over distributed systems with broadcast capability  and production rules on different sites work in a cooperative way with only a few communications between them. working memory on a local site is made visible to rules on remote sites. a tool for building distributed production systems  called dps  has been implemented. dps not only supports elegant constructs for expressing the capacity of distributed inference but also provides the facilities for building clusters of rules. with these facilities  dps allows users to make the inference engine focus on a particular set of rules. this paper also describes the knowledge representation 
and other features about dps. 
i. introduction 
   the development of tools for building rule-based systems has evolved in several directions. consultation-based tools use the backward-chaining reasoning mechanism   together with questioning-and-answering facilities to achieve goals. systems and tools with blackboard architecture  1 1  emphasize on the integration of complicated heuristic control and uncertain knowledge. there are also researches focusing on the architecture of forward-chaining reasoning mechanism  especially those derived from rete algorithm  1 . 
   the major advantages of production system tools such as ops1  and orbs  are derived from the elegance  expressiveness and moderate complexity of their knowledge constructs. users can create lists of attributes about concepts and a set of production rules each of which has condition elements to match against user-defined concepts  and actions to take when conditions are satisfied. the fact that condition elements of each rule join the relationship between concepts suggests more powerful expressiveness than other tools do. however  they pay for the expressive power of production rules. for example  ops1 has to do more work on complex pattern-matching. rete algorithm  for many-pattern /many-object pattern match problems was introduced to resolve the problem. nevertheless  low performance is still a disadvantage of ops1. so far  several approaches have been proposed to improve it  such as rewriting ops1 into ops1  in c  improving the inference mechanism of ops1 by eliminating unnecessary matching and supporting more powerful constructs for building production rules   and introducing parallel architectures  1  1  to exploit the parallelism of pattern-matching and rule-firing. 
1 	architectures and languages 
   in this paper  we propose a model for distributed processing of production systems. in this model  a production system  which can be constructed as a virtual integrated rete network   is distributed over a distributed system or a local area network. knowledge distribution is done by users. subsystems on different sites are almost autonomous  and they can cooperate with each other. this greatly exploits the parallelism between subsystems since unrelated subsystems can run in parallel. a tool named dps is constructed under this model. moreover  we also support other features to improve the performance of production systems  including the split of rete network on a single site into a cluster of subnets  object-based knowledge representation  and enhanced rule facilities. 
ii. knowledge representation 
   the attraction of expressive power of knowledge representation in ops1 has a great influence on the scheme of knowledge representation of dps. we found that one of the reasons that make ops1 popular comes from the semantic meanings of production rules. since a rule consists of a condition part  lhs  and an action part  rhs   a rule can join the relationship between different concepts described in lhs  and then execute responding actions in rhs. the representative manner and complexity of such rules are at similar level of human thoughts  and hence facilitates the work of knowledge engineering. 
   in general  dps has ops1-like syntax of rules. in addition to the lhs and rhs  each rule of dps may be given an attribute. when rules are interpreted  those with the same attribute arc constructed as a sub-rete-network which is used to narrow the inference space during execution of the systems. moreover  users are allowed to use a prefix     or    site-name  in a condition element to represent a condition element which matches against the working memory on remote sites. such condition elements arc called remote condition elements. this will be described later in more details. 
   dps allows users to define object-based concepts   i.e.  each concept is described as a list of attributes and is associated with any number of methods which are invoked by passing messages to an instance  working memory element  or wme  of the concept. the following is an example to illustrate the general form of knowledge representation in dps. 
 remote-site sensing-station  	; declare the remote sites 
 object manager name location situation  ; declare object  manager  
;whose attributes include  name    location  and  situation  
 object store-house location material  status safe   ; declare object 
;  store-house    safe  is default value of  status  attribute 
 object material name stock property  	; declare object  material  

 method manager emergency  name cause  ; a method of  manager  
  usp code for noticing and ; a method can be invoked solving emergent events    ; by message-passing ; here  emergency  is a message name   name  and  cause  ; are arguments passed by the calling action. 
 p setting-store-house-status 	; the third condition 
 store-house material:  x  status: safe  ; element matches against 
 material name:  x  property: volatile ; the working memory on 
  sensing-station 	; remot site  sensing-
 circumstance temperature-in-house:   1  ; station  
-  
 modify store-house status: dangerous 
cause: temperature-too-high  
	 focus emergent-ecent  	; make the inference 
; engine focus on rules 
	::: sensing-events  	; about emergent events. 
 p emergency-manipulating 
 person   manager name:  x  
location:  y  situation: on-business  
 store-house location:  y  status: dangerous cause:  z   
-  
 send-message  person  emergency:  x   z   
; invoke the method associated with message 
         emergency  to solve emergent events ::: emergent-event   
　　the rhs of a rule allows an action to invoke a lisp procedure by message-passing. this procedure not only accepts arguments passed from calling actions  but also uses as variables the attributes in the matched wme. compared with the  call  action in ops1 which demands the special treatment of passed arguments  message-passing of dps simplifies the use of procedure calls. the rhs of a rule also allows actions to control inference engine and manipulate working memory. 
rule clustering 
　　the orbs production system  and blackboard systems such as hearsay-ii  1  1   hasp  and age  allow rules to be grouped into related collections. there is generally a pointer that designates the current collection. only rules from the current collection are allowed to match against working memory. there are several attractive language properties of rule clustering: it allows a complex space to be broken into more understandable pieces; it tends to simplify rule debugging because the debugging space can be narrowed to one rule cluster instead of the whole rule base; and it allows the system developer to reuse components  the rule clusters  found to be useful in the past. 
   in dps  a rule can be given an attribute at the field indicated by the symbol ::: . rules with the same attribute are grouped together. a subsystem on one site has a working memory and a number of rules grouped into a number of clusters  if needed. the inference engine may focus its inference space on one or more rule clusters. the switching of inference space among these clusters is guided by the selection of appropriate rule attribute. fig.l shows two rule clusters mentioned above and the working memory they share on the local site. when the rule setting-store-house is fired  the execution of  focus emergent-event  changes the inference space to the emergent-event cluster to manipulate emergent events. 

   furthermore  since systems like ops1 and its various derivatives use the rete algorithm for the pattern match function  part of the efficiency comes from sharing pattern matching test which are identical among all the rules that have the tests. however  the ops1 rete shares results of join tests only if the patterns are the same starting from the first one. thus it is hard to get the benefits of shared tests. when a new working memory element is created  all the beta join nodes of satisfied tests should be modified. if later the working memory element is removed  these beta nodes should be modified all over again. it will be wasteful if very few of these rules are fired during the addition-then-deletion of the same working memory element. 
   here  we allow the rules to be grouped into several collections  only rules from the current collection are allowed to match. in this way  the addition-then-dcletion of the same woring memory element will not cause the beta-node modification in other clusters. this tends to improve the performance. an example is given later in section iv. 
m. distributed inference of production rules 
   in dps  users at one site of a local area network can share the knowledge resident on remote sites  and production rules on different sites can interact with others according to the shared knowledge. dps is expected to provide elegant syntax to express the distributed inference of production rules. 
   there are two major reasons why dps supports the capacity of distributed computation. first  knowledge distribution can be done by users. since a single rule is the grain-size of a predictable action sequence and knowledge distribution should be based on knowledge  researchers who worked on the exploitation of parallel production systems on parallel computers  have found that it is difficult to automatically distribute knowledge over processors. the distributed system approach  allowing users to distribute knowledge as they wish  can do better distribution of knowledge with the guideness of users. hence  it exploits higher parallelism than the parallel approach on parallel computers. second  with appropriate distribution of knowledge  systems written in dps can solve distributed problems with two forms of cooperation between working sites: task-sharing and result-sharing . several nodes can participate in a single job and partial results between nodes can be shared to produce further results. 
   the distributed production systems built by dps are expected to be divided into several autonomous subsystems  each of which resides on a single site and can proceed match-action cycles concurrently with each other. dps 
	hsu  wu andwu 	1 

supposes only a few communications are needed among these subsystems. in order to exploit the capability of distributed inference easily  dps supports several facilities as elegant as possible. as an example shown in fig. 1  users can build and distribute rules on a nework which consists of sites x  y  and z. 
fig. 1 rules distributed over a network. 
 ..  means  visible to  
	  	-....  means  invisible to  
   the symbol      means the specified condition element is a remote condition element which matches against working memory on remote sites  and    site   matches against the working memory on the specified remote site. the remove-local action is used to make the specified wme invisible to the local site; and if the removed wme was created on the same local site  then its effect is the same as that of remove action  i.e.  that wme is invisible to all sites. the make action creates a new wme visible to all sites. the make-local action is similar to make action except that the visibility of the newly created wme is limited in the local site. it is used to hide a private working memory from other sites. in addition  the action part of a rule may also include a remote method invocation by sending a message to the matched remote wme. with these facilities  users can manage private and shared working memory and respond to remote situations. 
iv. implementation 
     in general  dps interpreter acts in matching-action cycles like ops1  but remote condition elements and additional tasks must be considered. the system architecture of dps is shown in fig.1. working memory  wm  collects data which production rules will match against. visible remote working memory contains data  received from remote sites  that satisfy remote condition elements of rules on the local site. remote condition test is the set of condition elements extracted from remote rules which match against wm on the current site. let's consider the example shown in fig. 1. during the session of rule interpretation on site y  the remote condition element  b  in rule r1 is broadcast to remote sites. site x will receive condition element  b  and then build it in remote condition test. whenever a wme that satisfies  b  is newly created on site x  it will be automatically transmitted to the visible remote wm on site y. this saves communications during the execution of systems. wm controller is responsible for maintaining the consistency of data between the wm on the local site and visible wms on remote sites. 

iv. 1 rule clustering 
   in dps  there is an activity pointer which designates the current cluster. the initial value of the pointer is given by users at the beginning of execution. each time when the rhs actions of a rule arc executed  it may cause some variation in working memory. since the working memory is shared by the clusters on the site  new working memory elements should be known to the noncurrent clusters. here  we go around the problem with a simple and clear approach. 
fig. 1. an example of addition-then-delction of the same wme 
1 	architectures and languages    dps gives each cluster a last-time-tag  which records the last working memory time tag for current cluster when switching to another cluster. when later this cluster is selected as the current cluster  it should match the working memory elements since the one whose time tag is immediately greater than last-time-tag. in this way  each cluster  when behaving as the current cluster  knows the variation since it switched to another cluster. thus the addition-then-deletion of the same working memory element may affect only current cluster because noncurrent ones do not know the occurrence of addition-then-deletion event. all they can see are the elements exist in the working memory. for example  consider the two clusters in fig.1. 

   if current cluster is cluster1 and at first rules is fired   i e there exist working memory elements a and c that satisfies condition elements  a  and  c .  then new working memory elements d and c are added to working memory. next  if rule1 is fired  working memory element b is added to working memory. finally  rule1 is fired and clusterl is selected to be the current cluster. the working memory so far is shown in fie 1 a . 
   in clusterl  ruiel and rule1 are satisfied and added to conflict set. according to the resolution strategy  rulel is fired first and it adds element a to working memory. this causes an instantiation of rule1 to be added to conflict set. next  rule1 is fired and element f is added to working memory. finally  rule1 is fired  and element a is deleted. the instantiation of rule1 should be deleted from conflict set. later when cluster1 is selected as the current cluster  all it can see is working memory element f  as in fig. 1 b  . the addition-then-deletion of working memory element a has no effect on cluster1. this improves performance significantly when there are many 
identical condition elements among the clusters. 
iv.1 distributed inference 
   the remote condition elements of rules are examined during the time of rule interpretation. dps interpreter creates a special rule in the target site s  for each remote condition element. the syntax of a special rule is: 
 p  special-name  
  the remote condition element  
--  
if a firing rule causes an execution of  make-local  
  remove-local   action  the working memory element is added to  removed from  working memory   and may trigger another inference cycle. if the action is  make   which allow a new working memory element to be visible to remote sites  then the working memory element should be matched not only by the rules in current cluster but also by the special rules in remote-condition- test cluster on local site. this seems natural because the working memory elements created by  make  actions are visible globally and may be tested by some remote rules. the  remove  action removes working memory elements visible to remote sites  so it must be implemented in a special way. 
   dps system maintains a task queue on each site  which orders the tasks generated by the inference engine and the communication unit. we have four kinds of tasks. they are 1  remote-test rule building  1  message passing  1  remote deletion or modification of working memory element task  1  rhs actions of selected rules. 
 send 1  target-site  : cluster  : address of corresponding &mem node  task for each remote condition element and puts them in the    when interpreting a rule containing remote condition elements  dps interpreter creates a remote-test rule building 

:::  remote-condition-test   
   once the special rule is built  it can match against the working memory on remote sites. if the special rule is fired by a remote dps system  then its rhs action is executed and the result is sent back to the local site. when received by the local dps system  the matched data will be put into the visible remote wm and then copied to the specified &mem node. this makes rete networks  which distributed over cooperating sites  form a virtual integrated rete network since there exist virtual channels between special rules in target sites and &mem node in the local site; i.e.  local rules sense changes on remote wm immediately after they occurred. for example  the rule  which contains a remote condition element  in site-a: 
 p remote-condition-example 
 a  
 b  
  site-b  c  
	--  	; 
results in the rete networks shown in fig. 1. 
task queue. when selected by the task scheduler  the task will be sent to the communication unit and then the remote sites  then executed by remote dps interpreter. for the balance of dps system  rules in the execution set resulting from conflict resolution are not evaluated immediately. they are grouped into a task  put into the task queue and rated by the task scheduler. they cannot be executed until selected by the scheduler. when the communication unit receives a request for building a special rule for remote condition element  the request is also treated as a task and must be put into the task queue. rules in the remote-condition-test cluster are conditions received from remote dps systems  along with a rhs action which sends the matched wme to a target site. if anyone of them is satisfied  its rhs action should be executed immediately instead of being put into the task queue  since the execution has no effect on the local working memory. 
iv.1 consistency maintenance 
let's consider the previously mentioned example in fig. 
1. after rule rl on site x has fired  it may happen that the condition parts of rule r1 on site x and rule r1 on site y are both satisfied  and rule r1 may remove wme b just before rule 
	hsu wu andwu 	1 

fig. 1. inconsistency occurs between site x and site y 
r1 fires. here  inconsistency arises between working memory on site x and site y. other situations may result in similar inconsistency. dps solves this problem by accessing the shared working memory elements  wmes  via locks. working memory controller is responsible for the manipulation of locks of wmes according the following disciplines. 
. before a rule  whose condition part contains remote condition elements  would fire  dps has to request the write locks of matched remote wmes if these wmes are to be changed by the rule  and the read locks if these wmes are not to be changed. 
. read locks are shared  and many rules on different sites may concurrently read a wme. write locks are exclusive  and no other rules may access a locked wme while its write locks is held by a rule. 
. dps requests locks for a rule only when the lhs of this rule is satisfied and its rhs is placed in the task queue. 
. a rule can fire only after the involving locks are available  and all locks held by a rule are released until the end of execution of the rule. 
. write lock requests made to read-locked wme are queued until all read locks are released. 
. wm controller serves lock requests with first-come-firstserve scheme. 
. when the write lock of a wme is held by a rule  wm controller refuses all lock requests made to the same wme until the lock is released  since this wme is modified or no longer exists . hence  a rule task in the task queue is canceled if one of lock requests made by it is refused. 
. modification of a shared wme is made visible to involving remote sites. 
these disciplines guarantee the consistency of visible wm between cooperating sites. 
v. performance evaluation 
   since dps leaves the work of initial knowledge distribution to users  the performance of dps is conceivably related to the way how users distribute their knowledge on cooperating sites. according to our experiments  if an overall production system is partitioned into n appropriate subsystems  each of which excutes almost autonomously on one site with only a few communications to/from other sites  then the performance would approximate n times higher than that of the original system that executes on a single site. however  if an 
1 	architectures and languages 
	r1 	r1 	1 ratio 
fig. 1 performance speedup as a function of the ratio of the number of remote-matching to the number 
of total matching. 
overall system is partitioned into subsystems in such a way that rules on each site always match remote working memory elements  and hence rules on different site can only fire sequentially  then the performance would greatly degrade  even worse than that of the original system that executes on a single site. fig.1 illustrates speedup and degeneration for the performance of dps  where x-axis means the ratio of the total number of satisfied remote condition elements during execution to the total number of satisfied condition elements  and n means the number of subsystems. the curve marked 'n=l' is illustrated as comparison. the values of threshold ratios rl and r1 for curve 'n=1' and 'n=1' are closely related to communication cost. the less the communications cost  the higher the ratios are; hence  higher speedup would be achieved. vi. conclusion 
   in order to improve the performance of production systems  a number of reseaches focus on the parallel processing of production systems. in this paper  we propose an approach for building distributed production systems. we have attempted to show the development model used to build dps programs and the environment that surrounds the language. one of the major objectives of dps is to enhance performance of production systems. dps supports elegant constructs for users to express the distributed inference of production rules. rules on different sites work in a cooperative way and only a few communications are needed. another objective of dps is to propose a model for distributed inference. since condition tests for remote condition elements are built on remote sites during interpretation session  communications needed in matching-action cycles are minimized. in addition  dps also supports facilities to split inference engine on a local site into a number of subsets  each of which would focus on the inference about a particular event. 
the prototype of dps system is now implemented in 
common lisp on a hp lan which connects three hp 
1 workstations. due to the lack of efficient facilities to support interprocess communication  communication cost has influence on performance of this prototype. in current stage  dps does not consider the ability of dynamic migration of knowledge. users are required to divide the entire application into partitions  and spread them on appropriate sites on a distributed system. inspite of this little inconvenience  dps  with elegant constructs and a powerful distributed inference mechanism  is a useful tool for building distributed production systems. 

