 
a constraint satisfaction problem  or csp  can be reformulated as an integer linear programming problem. the reformulated problem can be solved via polynomial multiplication. if the csp has n variables whose domain size is m  and if the equivalent programming problem involves m equations  then the number of solutions can be determined in time 1 nm1m--n . this surprising link between search problems and algebraic techniques allows us to show improved bounds for several constraint satisfaction problems  including new simply exponential bounds for determining the number of solutions to the n-queens problem. we also address the problem of minimizing m for a particular csp. 
1 	introduction 
we are interested in solving certain search problems that arise in combinatorics and in artificial intelligence. these problems are called constraint satisfaction problems  csp's   and include such familiar tasks as graphcoloring and the n-queens problem. typically  such problems are solved via exhaustive search. we propose an alternative method  based on converting the csp into an integer linear programming problem  which can be solved via polynomial multiplication. 
¡¡in section 1 we describe constraint satisfaction problems and show how they can be converted into integer linear programming problems. we describe how to solve integer linear programming problems via polynomial multiplication in section 1  and analyze the time requirements of this approach. in section 1 we give an example of our method  applying it to the n-rooks problem  and show some surprising similarities with standard search techniques. in section 1 we address the problem of finding a good integer linear programming equivalent of a csp  while in section 1 we describe some extensions to our techniques. finally  in section 1  we derive new simply exponential bounds for the n-queens problem and the toroidal n-queens problem. 
1 	search 

can do provably better than backtrack search for some problems  in the following sense. backtracking counts the number of solutions by enumerating them  and hence must take at least as much time as the number of solutions. our techniques can determine the number of solutions without actually enumerating them  so the number of solutions is not a lower bound on our running time. 
1 converting csp's into integer linear programming problems 
our basic approach is to turn a csp into an integer linear programming problem. for every possible assignment vi  - dj we introduce a variable xij. then for every 
csp variable vi  we have an equation 
		 1  
this expresses the fact that every csp variable has exactly one value. in addition  for every set of assignments that the constraints prohibit  we have an inequality which states that no more than one of these assignments can hold at once. for example  if the pair of assignments  is forbidden by the constraints  we will have the inequality 
		 1  
now consider the problem of finding all solutions to the equations of the form  1  and  1  over the non-negative integers.  it is clear that any solution will assign every variable xj either 1 or 1.  this is an integer linear programming problem  which corresponds to the original csp. there are nm variables xj  and a solution to the set of equations with xj = 1 corresponds to a solution to the csp containing the assignment vi - --dj. 
1 	solving csp's by multiplying polynomials 
an integer linear programming problem is a set of linear diophantine inequalities. we can use an approach based on generating functions to determine the number of solutions. this involves multiplying out a certain polynomial  and gives us a way of solving the original csp. 
1 	solving linear diophantine equations 
a set of m linear diophantine equation in n unknowns has the form 
		 1  
the xj's are the unknowns  and the wij's and s 's are non-negative integers. the problem at hand is to determine the number of solutions over the non-negative integers. 
consider the generating function 
		 1  
the formal parameters of this function are the variables 
y1 y  and on such variable is associated with each equation. we need one non-trivial bit of mathematics: the number of solutions to equation  1  is the coefficient of 

in   this fact was proved in  euler  1   and is discussed in  schrijver  1  pages 1 .  
1 	applications to integer linear programming 
now consider the integer linear programming problem corresponding to a csp. every wi will be either 1 or 1. assume for the moment that all the equations are of the form  1   hence si = 1.  we will relax this restriction shortly.  we can count the number of solutions by finding the coefficient of the monomial y = y1 y1       ym in . we apply the identity 

to equation  1   giving 

¡¡we can further simplify this if we remember that we are only interested in the coefficient of y. we can therefore ignore any term divisible by the square of any yi 
 terms that are not so divisible are called square free . by a slight abuse of notation we will refer to the square free part of the generating function as . we next note that 

where these latter terms are not square free and so can be discarded. this gives us an expression for ¦µ as a product of binomials  namely 
		 1  
all we need do in order to find the number of solutions to the system of equations is compute the coefficient of y in equation  1 . 
¡¡the obvious way to solve this problem is to simply multiply out ¦µ and look at the correct term of the result. we can do this iteratively: we multiply the first two binomials of ¦µ and throw away the terms that are not square free  then repeat with the next binomial  etc. 
¡¡we can now relax our assumption that all the equations are of the form  1 . suppose that instead we have exactly one diophantine inequality 
		 1  
	rivin and zabih 	1 

this implicitly defines two equalities  one of which has 1 on the right hand side  and one of which has 1. the number of solutions to the inequality is the sum of the number of solutions to the two implicit equalities. 
¡¡at first glance  it would seem that solving a system with ¦Á inequalities would require solving 1¦Á implicit systems of equalities. however  a closer look at the generating function shows that we only need to solve one of these implicit systems. suppose that we replace each inequality with an equality that has a 1 on the right hand side and examine the square free part of $. the number of solutions to each of the 1¦Á implicit systems of equalities will be the coefficient of the appropriate term of 
for example  suppose that there are three equations 
yo  y1 and y1  and one inequality 
	¦Á 1 	 1  
where ¦Á is a sum. the inequality  1  implicitly asserts 
	¦Á = 1 	 1  
or 
	p=l. 	 1  
the number of solutions to the original system  which included  1   is the sum of the number of solutions when 
 1  is replaced by  1  plus the number of solutions when 
 1  is replaced by  1 . 
¡¡however  suppose that we simply replace  1  by  1  and calculate ¦µ. let y1 be the generating function variable associated with  1 . the number of solutions is the coefficient of y1y1 in ¦µ. however  the number of solutions when  1  is replaced by  1  is also part of ¦µ  namely the coefficient of y1y1. we thus do not need to calculate separate generating functions for both systems of equalities implicitly defined by  1 . we can simply replace the inequality by an equality with 1 on the right hand side and calculate ¦µ. at the end  we add together coefficients for the implicit systems of equalities to determine the number of solutions to the original problem. 
¡¡to summarize  we can replace the inequalities with equalities and calculate the square free part of ¦µ. the total number of solutions will no longer be the coefficient of y  but rather the sum of 1 coefficients of different terms. this justifies our earlier assumption that the integer linear programming problem consisted entirely of equalities of the form  1 . 
1 	t i m e requirements 
the time required to solve the csp is the time to multiply out the polynomial ¦µ. we can do this in n iterations  where on each iteration we multiply a binomial by a polynomial that represents the product thus far. two polynomials can be multiplied in time proportional to the product of their size  so we need to bound the size of the intermediate results. 
¡¡naively  there could be as many as nm terms  since there are m y's  and the degree of each one is potentially as high as n. however  remember that at each stage we will discard all the terms that are not square free. 
1 	search 
 in algebraic terminology  this is described as doing the computation over the polynomial ring z y1 ... ym / y1 ... y1m  
instead of z y 1  ...  ym .  this gives a better bound on the number of terms. every y will have degree 1 or 1  hence there are no more than 1m terms. 
	summarizing  if we compute 	iteratively we will do 
n multiplications  where each multiplication computes the product of a binomial and a polynomial with no more than 1m terms. each multiplication will take time 1m+1  which is 1m . this puts a bound of 1   n 1 m   on the total time complexity of our algorithm.1 we will show in section 1 how to reduce the exponent to m - n in the worst case. 
¡¡it is worth noting that we cannot expect to find a polynomial time method for determining the value of an arbitrary coefficient of ¦µ.  schrijver  1  proved that integer linear programming is np-complete even when the coefficients involved are restricted to be 1 or 1. 
1 	an example of our approach 
the n-rooks problem consists of placing n rooks on an n-by-n chessboard so no two rooks attack each other. while it is clear that the solutions to this problem are the n! permutations of n elements  this problem has a particularly simple encoding as an integer linear programming problem  and is therefore a useful example of our approach. 
¡¡there are n1 assignments vi -dj for this csp  so we will convert it into a programming problem with n1 variables xij. there will be 1n equations.1 the equations specify that there is exactly one rook in each row and each column. a typical equation is x1 + x1 + . . . + x1 n = 1   1  which encodes the fact that there is exactly one rook in the 1nd column. we can number these 1n equations so that equation i says that there is exactly one rook in the i'th column  and equation n+i says that there is exactly one rook in the i'th row. the formal parameter y  of the generating function corresponds to the f'th constraint equation. 
¡¡applying equation  1   ¦µ is a product of n1 binomials. there will be one binomial for every square on the chessboard  and the binomial for the square in row t and column j will be 
the number of solutions is the coefficient of 
y = y1       yn yn+1       y1n 
in the expansion of ¦µ. 
1
¡¡¡¡this analysis ignores the time required for scalar multiplication. we can take this into account by noting that the size of the coefficients will be bounded by mn  hence their length is 1 n log m . so the scalar multiplication can be done in time 1 nl og mlog n  og m  og ag n log m    aho et a/.  1 . 1
in section 1 we will discuss how to find good encodings. 
¡¡surprisingly  there is a way of multiplying out ¦µ that corresponds closely to backtrack search. suppose that we attempt to find all combinations of binomial terms whose product is y. we can start by picking the second  i.e.  non-constant  term of  1 + yn+iyj . this forces us to pick the first  constant  term of every binomial whose second term includes either yn+1 or yj  to ensure the product is square free. now we can pick the non-constant term of some other binomial and continue  until we have produced y. the number of such combinations will be the coefficient of y in the expansion of ¦µ.  it is also possible that the combination of terms selected guarantees that no selection of terms from the remaining binomials will produce y. the simplest example of this occurs when a term has been selected from all but one binomial without producing y  where the remaining binomial's non-constant term does not contain the missing y. this phenomenon  which does not occur in the n-rooks problem  will be used to improve our performance guarantee in section 1.  
¡¡this whole process corresponds closely to a simple search of the original csp. choosing the non-constant term of the binomial  1 + y n   i y j   places a rook on the equivalent square  while choosing the constant term means there is no rook on that square. the process described above corresponds to placing a rook on the chessboard square in row i and column j  and thus ensuring there is no rook in any other square in that row or column. at the end  we will have satisfied every constraint and produced a solution. the alternative outcome  where we cannot satisfy every constraint  corresponds to a failure in backtrack search. 
¡¡note that the expansion of ¦µ does not explicitly represent the solutions. in fact  which assignments constitute a particular solution is lost by this approach  as the identity of the binomials is not recorded. we will show how to explicitly represent solutions in section 1. however  the fact that solutions are not explicitly represented is an advantage of our approach  as the number of solutions is no longer a lower bound to our running time. applying the analysis of section 1  for this problem we have n = n1 and m = 1n  so our running time is 1 n1n . this is significantly smaller than n!  the number of solutions  which is about 1  n log n . 
¡¡we have just described a correspondence between a way to compute the coefficient of y in the expansion of ¦µ and a simple search technique for solving the original csp. however  searching all the combinations of binomial terms is not our intended method. we believe it would be better to multiply ¦µ out iteratively  as described earlier. while this does not correspond in any obvious way to applying backtrack search to the original problem  it does seem to have some similarity to breadth-first techniques. it may thus be susceptible to parallel implementation techniques like those described in  dixon and de kleer  1 . 
1 	finding a good encoding 
a potential difficulty with our approach is that the running time is exponential in m  the number of equations needed to encode the csp. there can be many such encodings  and it is important to be able to find a good one. clearly m must be at least n  as there is an equation of the form  1  for each csp variable. the remaining equations come from the constraints. the problem is to find a way of encoding the constraints as small number of equations. 
¡¡in the simplest encoding  there is an equation like  1  for every pair of assignments that the constraints rule out. however  this can be quite a lot of equations  as the following example illustrates. in the case where all pairs of assignments are ruled out this will result in n1 equations  while  as we will see  there is an encoding that results in only 1 equation. 
¡¡let us define the assignment graph corresponding to a particular csp. the nodes of the assignment graph represent assignments  and there is an edge between two nodes if their assignments are ruled out by the constraints. a clique c in this graph corresponds to a set of pairwise incompatible assignments. the transformation described in section 1 will produce a variable xi.j for every node  and will use     equations  with the equation 

expressing the fact that these two assignments are incompatible. however  we can describe the fact that all the assignments in c are pairwise incompatible with the single equation 

so we really only need one equation for every clique. if all pairs of assignments are incompatible  the entire assignment graph is a clique  and so the constraints can be represented with 1 equation instead of needing n1. 
¡¡for the n-queens problem  the assignment graph has a node for each square on the chessboard. two nodes are connected if queens on the two corresponding squares would attack each other. the maximal cliques correspond to the columns  rows  diagonals and antidiagonals of the chessboard. 
¡¡we can therefore reduce the size of m by encoding every clique as a single equation. in an optimal encoding  m can be as small as the size of the smallest covering by cliques of the assignment graph. because the problem of covering a graph by cliques is np-complete  garey and johnson  1   finding an optimal encoding would take exponential time. for special cases like the chessboard problems described above  it is easy to find an optimal encoding  but  in general we would have to settle for a sub-optimal encoding. it is also possible to phrase the problem as finding a small vertex cover for the assignment graph  and this can also reduce m. 
1 	w h i c h csp's have good encodings  
one obvious question is whether there is a better characterization of the csp's that have good encodings. while we do not have a very good answer to this question  an observation due to bob floyd suggests that there may be a relationship between the number of solutions to the csp and the smallest possible value for m. floyd has pointed out that a solution to the csp corresponds to 
	rivin and zabih 	1 
an n-clique in the complement of the assignment graph  equivalently  an independent set of size n in the assignment graph . it is possible that work in combinatorics will produce a relationship between the number of independent sets of fixed size in a graph and the size of the smallest vertex cover. such a relationship would produce a characterization of the csp's where our algorithm can be expected to work well  in terms of the number of solutions. 
1 	some extensions 
the method described above relies on multiplying out the polynomial ¦µ defined in equation  1 . a simple modification to ¦µ allows us to solve the enumeration problem instead of the counting problem. it is also possible to reduce the running time of our algorithm by carefully arranging the order in which the binomials comprising ¦µ are multiplied out. 
1 	solving the enumeration problem 
suppose that instead of determining the number of solutions to our csp  we are interested in enumerating these solutions. we can still convert the csp into an integer linear programming problem  and solve it via polynomial multiplication. the only difference is that we now need to consider a slightly different function than ¦µ. 
   recall that we start by converting our csp into a set of equations in n = rnn variables  one variable per assignment vi -dj. let us introduce n different variables 
	  	now consider a slight variation of ¦µ  
namely 
		  i i   
we can solve the enumeration problem by determining the coefficient of y in the expansion of ¦µ  just as we did with ¦µ. 
¡¡suppose we multiply out ¦µ by selecting terms from different binomials. the a ; 's will keep track of which binomials had their non-constant side selected. when we have a solution  the coefficient of y will the product of a number of the j's  which will encode a solution. when ¦µ is multiplied out completely  iteratively or otherwise   the coefficient of y will not be an integer  but rather the sum of a number of different products of atj's. every such product is a solution to the csp  and all solutions appear as such products. 
1 	reducing the running time 
an observation due to john lamping can be used to reduce the running time of our algorithm from 1 nm1m  to 1   n m 1 m   n   . suppose that before we multiply out ¦µ we first try to identify a subset s of the binomials comprising ¦µ and a variable y such that   y never appears outside of the binomials in s  and 
  some other variable y1 does not appear in s. 
if we had such an s and y  we could effectively reduce the number of variables by 1. 
1 	search 
¡¡we can do this by first computing the product of the binomials in 1. this can be grouped into terms based on the highest power of y that divides each term 

where si is not divisible by y  and as usual we can discard the non square free terms. if y is contained in the coefficient s  corresponding to solutions to the csp  then we can replace s by s . we can then forget about y  as it never appears in the remaining part of ¦µ. since y' did not appear in s  this reduces the number of variables by 
1. 
¡¡reducing the number of variables reduces the running time of our algorithm as well  which is exponential in the number of variables. it turns out that we are guaranteed that there exist at least n such pairs of 1's and y's. this enables us to reduce the number of variables from m to m - n  which in turn reduces our running time to 1 nm1m-n . 
¡¡there are n such s and y pairs because the encoding of a csp will have a single equation for each csp variable  representing the fact that the variable must be assigned exactly one value.1 let y correspond to the equation which constrains the csp variable v to have exactly one value  and consider the binomials in ¦µ that contain y. these are exactly the binomials that correspond to possible values for v  so there can be only m of them. furthermore  this set of binomials forms an appropriate 1  since no y' corresponding to another csp variable can appear. there are n such y's  one per csp variable  and these y's will always appear in the coefficient s  that we need to calculate. 
¡¡it is even possible to take advantage of such 1's and y's when y does not necessarily appear in the required coefficients.  recall that this is a result of the integer linear programming equation that corresponds to y actually representing an inequality  as discussed at the end of section 1.  if this happens  we can replace 1 by so + s  and still discard y. this has the effect of summing the coefficients that stand for the solutions to the two implicit systems of equalities early in the computation  rather than waiting to multiply ¦µ out before calculating this sum. 
¡¡we can thus reduce the number of variables by at least n. as we saw in section 1  each binomial corresponds to a possible assignment vi+-dj. the ordering that is guaranteed to reduce the number of variables by n corresponds to considering all the assignments for a fixed vi before moving on to the next csp variable. on the n-queens problem this is equivalent to multiplying out the binomials in row-major order. 
1 	some new bounds 
an additional advantage of our approach is that we can produce non-trivial upper bounds for solving certain constraint satisfaction problems. so far  we have confined out attention to csp's based on placing pieces on a chessboard. 
1
¡¡¡¡an encoding that does not have this property corresponds to a csp whose unsatisfiability can be easily detected via arc consistency  mackworth  1 . 

¡¡the classic such problem is the n-queens problem  which was known to gauss. the n-queens problem consists of placing n queens on an n-by-n chessboard so that no two queens attack. a variation of this problem is the toroidal n-queens problem  where lines of attack between queens are considered to 'wrap' as if the board were a torus. the toroidal n-queens problem has strictly fewer solutions than the  regular  n-queens problem. 
¡¡to our knowledge there is no known bound for csp search algorithms for this problem  beyond the trivial bound of n n . in fact  there is some evidence that the number of solutions to the toroidal problem  and hence to the regular problem  is larger than exponential  rivin and vardi  1 . 
¡¡the toroidal n-queens problem can be formulated as a simple set of equations. there are n1 variables xj. there are also an equations  one for each column  row  diagonal  top to bottom  and anti-diagonal. so we have m = 1n  n = n 1 . applying the above results  our algorithm can determine the number of solutions in time 1 n 1 n  . 
¡¡for the regular n-queens problem  again n = n 1   but this time there are 1n - 1  inequalities for the diagonals. this gives us m = 1n - 1  and a running time of 1 n 1 n  . 
¡¡however  if we do the multiplication in row-major order  it turns out that only 1n variables will need to be active at once. this can be seen by noting that the top row involves 1n constraints. moving to the next row adds a new row constraint and removes the old row constraint. the far left square of the new row eliminates an antidiagonal constraint  all the squares involved in that constraint have been eliminated   and adds a new diagonal constraint  while the far right square eliminates a diagonal constraint and adds a new antidiagonal constraint. this gives us a much better bound of 1 n 1 n  . our preliminary experiments with this algorithm have been promising. 
1 	conclusions 
we have shown a surprising connection between solving search problems and multiplying certain polynomials. the performance is very simple to analyze  and we can show new bounds for several constraint satisfaction problems. 
¡¡our approach also holds our the possibility of applying sophisticated algebraic techniques to constraint satisfaction problems. for example  it is possible that the coefficient of y in ¦µ can be estimated  thus providing an approximate count of the number of solutions. also  complex mathematical results like those in  anshel and goldfeld  1  can be used to provide an upper bound on the number of solutions by studying the generating function directly  using the theory of modular forms. 
¡¡our algorithm also shares some surprising properties with seidel's method  seidel  1 . like seidel  we produce a method which is easy to analyze  and which gives a bound that is exponential in a certain parameter of the problem. seidel's parameter / is a property of the topology of the constraint graph  which can be shown to be 1 n  for planar graphs. our parameter m is a property of the way the problem gets encoded as an integer linear programming problem  which can be shown to be linear for variants of the n-queens problem 
¡¡seidel faces the problem of making / small  which in general requires exponential time. similarly  we face the problem of making m small  which requires solving an np-hard problem involving graph cliques. the similarities between our algorithm and seidel's  as well as lamping's observation described in section 1  suggest that our algorithm may be viewed as dynamic programming. we are currently exploring this possibility  rivin and zabih  1 . 
1 	acknowledgements 
we are indebted to john lamping and han vardi for useful suggestions. support for this research was provided by darpa under contract number n1-c-1. ramin zabih is supported by a fellowship from the fannie and john hertz foundation. 
