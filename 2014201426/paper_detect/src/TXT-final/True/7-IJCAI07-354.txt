
depth estimation in computer vision and robotics is most commonly done via stereo vision  stereopsis   in which images from two cameras are used to triangulate and estimate distances. however  there are also numerous monocular visual cues- such as texture variations and gradients  defocus  color/haze  etc.-that have heretofore been little exploited in such systems. some of these cues apply even in regions without texture  where stereo would work poorly. in this paper  we apply a markov random field  mrf  learning algorithm to capture some of these monocular cues  and incorporate them into a stereo system. we show that by adding monocular cues to stereo  triangulation  ones  we obtain significantly more accurate depth estimates than is possible using either monocularor stereo cues alone. this holds true for a large variety of environments including both indoorenvironments and unstructured outdoor environments containing trees/forests  buildings  etc. our approach is general  and applies to incorporating monocular cues together with any off-the-shelf stereo system.
1 introduction
consider the problem of estimating depth from two images taken from a pair of stereo cameras  fig. 1 . the most common approach for doing so is stereopsis  stereo vision   in which depths are estimated by triangulation using the two images. over the past few decades  researchers have developed very good stereo vision systems  see  scharstein and szeliski  1  for a review . although these systems work well in many environments  stereo vision is fundamentally limited by the baseline distance between the two cameras. specifically  the depth estimates tend to be inaccurate when the distances considered are large  because even very small triangulation/angle estimation errors translate to very large errors in distances . further  stereo vision also tends to fail for textureless regions of images where correspondences cannot be reliably found.
　beyond stereo/triangulation cues  there are also numerous monocular cues-such as texture variations and gradients 

figure 1: two images taken from a stereo pair of cameras  and the depthmap calculated by a stereo system. colors in the depthmap indicate estimated distances from the camera.
defocus  color/haze  etc.-that contain useful and important depth information. even though humans perceive depth by seamlessly combining many of these stereo and monocular cues  most work on depth estimation has focused on stereo vision  and on other algorithms that require multiple images such as structure from motion  forsyth and ponce  1  or depth from defocus  klarquist et al.  1 .
　in this paper  we look at how monocular cues from a single image can be incorporated into a stereo system. estimating depth from a single image using monocular cues requires a significant amount of prior knowledge  since there is an intrinsic ambiguity between local image features and depth variations. in addition  we believe that monocular cues and  purely geometric  stereo cues give largely orthogonal  and therefore complementary  types of information about depth. stereo cues are based on the difference between two images and do not depend on the content of the image. the images can be entirely random  and it will generate a pattern of disparities  e.g.  random dot stereograms  blthoff et al.  1  . on the other hand  depth estimates from monocular cues is entirely based on prior knowledge about the environment and global structure of the image. there are many examples of beautifully engineered stereo systems in the literature  but the goal of this work is not to directly improve on  or compare against  these systems. instead  our goal is to investigate how monocular cues can be integrated with any reasonable stereo system  to  hopefully  obtain better depth estimates than the stereo system alone.
　depth estimation from monocular cues is a difficult task  which requires that we take into account the global structure of the image.  saxena et al.  1a  applied supervised learning to the problem of estimating depth from single monocular images of unconstrained outdoor and indoor environments.  michels et al.  1  used supervised learning to estimate 1-d distances to obstacles  for the application of driving a remote controlled car autonomously. methods such as shape from shading  zhang et al.  1  rely on purely photometric properties  assuming uniform color and texture; and hence are not applicable to the unconstrained/textured images that we consider.  delage et al.  1  generated 1-d models from an image of indoor scenes containing only walls and floor.  hoiem et al.  1  also considered monocular 1-d reconstruction  but focused on generating visually pleasing graphical images by classifying the scene as sky  ground  or vertical planes  rather than accurate metric depthmaps.
　building on  saxena et al.  1a   our approach is based on incorporating monocular and stereo cues for modeling depths and relationships between depths at different points in the image using a hierarchical  multi-scale markov random field  mrf . mrfs and their variants are a workhorse of machine learning  and have been successfully applied to numerous applications in which local features were insufficient and more contextual information must be used.1 taking a supervised learning approach to the problem of depth estimation  we designed a custom 1-d scanner to collect training data comprising a large set of stereo pairs and their corresponding ground-truth depthmaps. using this training set  we model the posterior distribution of the depths given the monocular image features and the stereo disparities. though learning in our mrf model is approximate  map posterior inference is tractable via linear programming.
　although depthmaps can be estimated from single monocular images  we demonstratethat by combiningboth monocular and stereo cues in our model  we obtain significantly more accurate depthmaps than is possible from either alone. we demonstrate this on a large variety of environments  including both indoor environments and unstructured outdoor environments containing trees/forests  buildings  etc.
1 visual cues for depth perception
humans use numerous visual cues for 1-d depth perception  which can be grouped into two categories: monocular and stereo.  loomis  1 
1 monocular cues
humans have an amazing ability to judge depth from a single image. this is done using monocular cues such as texture variations and gradients  occlusion  known object sizes  haze  defocus  etc.  loomis  1; blthoff et al.  1; saxena et al.  1a . some of these cues  such as haze  resulting from atmospheric light scattering  and defocus  blurring of objects not in focus   are local cues; i.e.  the estimate of depth is dependent only on the local image properties. many objects' textures appear different depending on the distance to them. texture gradients  which capture the

figure 1: the filters used for computing texture variations and gradients. the first 1 are laws' masks  and the last 1 are oriented edge filters.
distribution of the direction of edges  also help to indicate depth.1
　some of these monocular cues are based on prior knowledge. for example  humans remember that a structure of a particular shape is a building  sky is blue  grass is green  trees grow above the ground and have leaves on top of them  and so on. these cues help to predict depth in environments similar to those which they have seen before. many of these cues rely on  contextual information   in the sense that they are global properties of an image and cannot be inferred from small image patches. for example  occlusion cannot be determined if we look at just a small portion of an occluded object. although local information such as the texture and colors of a patch can give some information about its depth  this is usually insufficient to accurately determine its absolute depth. therefore  we need to look at the overall organization of the image to estimate depths.
1 stereo cues
each eye receives a slightly different view of the world and stereo vision combines the two views to perceive 1-d depth. an object is projected onto different locations on the two retinae  cameras in the case of a stereo system   depending on the distance of the object. the retinal  stereo  disparity varies with object distance  and is inversely proportional to the distance of the object. thus  disparity is not an effective cue for small depth differences at large distances.
1 features
1 monocular features
in our approach  we divide the image into small rectangular patches  and estimate a single depth value for each patch. similar to  saxena et al.  1a   we use two types of features: absolute features-used to estimate the absolute depth at a particular patch-and relative features  which we use to estimate relative depths  magnitude of the difference in depth between two patches .1 we chose features that capture three types of local cues: texture variations  texture gradients  and color  by convolving the image with 1 filters  1 laws' masks  1 oriented edge filters  and 1 color filters  fig. 1 .  saxena et al.  1b 

figure 1: the absolute depth feature vector for a patch  which includes the immediate neighbors  and the distant neighbors in larger scales. the relative depth features for each patch compute histograms of the filter outputs.　we generate the absolute features by computing the sumsquared energy of each of these 1 filter outputs over each patch. since local image features centered on the patch are insufficient  we attempt to capture more global information by using image features extracted at multiple spatial scales1 for that patch as well as the 1 neighboring patches.  fig. 1  this results in a absolute feature vector of  1 + 1    1   1 = 1 dimensions. for relative features  we use a 1-bin histogram for each filter output for the pixels in the patch  giving us 1   1 = 1 values yi for each patch i. therefore  our features for the edge between patch i and j are the difference yij = |yi   yj|.
1 disparity from stereo correspondence
depth estimation using stereo vision from two images  taken from two cameras separated by a baseline distance  involves three steps: first  establish correspondences between the two images. then  calculate the relative displacements  called  disparity   between the features in each image. finally  determine the 1-d depth of the feature relative to the cameras  using knowledge of the camera geometry.
　stereo correspondences give reliable estimates of disparity  except when large portions of the image are featureless  i.e.  correspondences cannot be found . further  the accuracy depends on the baseline distance between the cameras. in general  for a given baseline distance between cameras  the accuracy decreases as the depth values increase. this is because small errors in disparity then translate into huge errors in depth estimates. in the limit of very distant objects  there is no observable disparity  and depth estimation generally fails. empirically  depth estimates from stereo tend to become unreliable when the depth exceeds a certain distance.
　our stereo system finds good feature correspondences between the two images by rejecting pixels with little texture  or where the correspondence is otherwise ambiguous.1 we use the sum-of-absolute-differences correlation as the metric score to find correspondences. forsyth and ponce  1  our

figure 1: the multi-scale mrf model for modeling relation between features and depths  relation between depths at same scale  and relation between depths at different scales.  only 1 out of 1 scales  and a subset of the edges  are shown. 
cameras  and algorithm  allow sub-pixel interpolation accuracy of 1 pixels of disparity. even though we use a fairly basic implementation of stereopsis  the ideas in this paper can just as readily be applied together with other  perhaps better  stereo systems.
1 probabilistic model
our learning algorithm is based on a markov random field  mrf  model that incorporates monocular and stereo features  and models depth at multiple spatial scales  fig. 1 . the mrf model is discriminative  i.e.  it models the depths d as a function of the image features x: p d|x . the depth of
pg d|x;θ σ  = 1	 1	 di 1    xitθr 1	 di s    dj s  1    1 
	 d|x;θ λ  = 1	|	|di 1    xti θr|	1	|di s    dj s |    1 
pla particular patch depends on the monocular features of the patch  on the stereo disparity  and is also related to the depths of other parts of the image. for example  the depths of two adjacent patches lying in the same building will be highly correlated. therefore  we model the relation between the depth of a patch and its neighbors at multiple spatial scales.
1 gaussian model
we first propose a jointly gaussian mrf  eq. 1   parameterized by θ and σ. we define di s  to be the depth of a patch i at scale s （ {1 1}  with the constraint di s + 1  =
. i.e.  the depth at a higher scale is
constrained to be the average of the depths at lower scales. here  ns i  are the 1 neighbors  including itself  of patch i at scale s. m is the total number of patches in the image  at the lowest scale ; xi is the absolute feature vector for patch i; di stereo is the depth estimate obtained from disparity;1 zg is the normalization constant.
　the first term in the exponent in eq. 1 models the relation between the depth and the estimate from stereo disparity. the second term models the relation between the depth and the multi-scale features of a single patch i. the third term places a soft  constraint  on the depths to be smooth. we first estimate the θr parameters in eq. 1 by maximizing the conditional likelihood p d|x;θr  of the training data; keeping σ constant.  saxena et al.  1a  we then achieve selective smoothing by modeling the  variance  term σ1rs in the denominator of the third term as a linear function of the patches i and j's relative depth features yijs. the σ1r term gives a measure of uncertainty in the second term  which we learn as a linear function of the features xi. this is motivated by the observation that in some cases  depth cannot be reliably estimated from the local monocular features. in this case  one has to rely more on neighboring patches' depths or on stereo cues to infer a patch's depth.
modeling uncertainty in stereo
the errors in disparity are modeled as either gaussian  das and ahuja  1  or via some other  heavier-tailed distribution  e.g.  szelinski  1  . specifically  the errors in disparity have two main causes:  a  assuming unique/perfectcorrespondence  the disparity has a small error due to image noise  including aliasing/pixelization   which is well modeled by a gaussian.  b  occasional errors in correspondence causes larger errors  which results in a heavy-tailed distribution for disparity.  szelinski  1 
　we estimate depths on a log scale as d = log c/g  from disparity g  with camera parameters determining c. if the standard deviation is σg in computing disparity from stereo
images  because of image noise  etc.   then the standard deviation of the depths1 will be σd stereo 「 σg/g. for our stereo system  we have that σg is about 1 pixels;1 this is then used to estimate σd stereo. note therefore that σd stereo is a function of the estimated depth  and specifically  it captures the fact that variance in depth estimates is larger for distant objects than for closer ones.
　when given a new test image  map inference for depths d can be derived in closed form.
1 laplacian model
in our second model  eq. 1   we replace the l1 terms with l1 terms. this results in a model parameterized by θ and by λ  the laplacian spread parameters  instead of gaussian variance parameters. since ml parameter estimation in the laplacian model is intractable  we learn these parameters following an analogy to the gaussian case.  saxena et al.  1a  our motivation for using l1 terms is three-fold. first  the histogram of relative depths  di   dj  is close to a laplacian distribution empirically  which suggests that it is better modeled as one. second  the laplacian distribution has heavier tails  and is therefore more robust to outliers in the image features and errors in the training-set depthmaps  collected with a laser scanner; see section 1 . third  the gaussian model was generally unable to give depthmaps with sharp edges; in contrast  laplacians tend to model sharp transitions/outliers better.  see section 1.  given a new test image  map posterior inference for the depths d is tractable  and is easily solved using linear programming  lp .
1 experiments
1 laser scanner
we designed a 1-d scanner to collect stereo image pairs and their corresponding depthmaps  fig. 1 . the scanner uses the sick laser device which gives depth readings in a vertical column  with a 1  resolution. to collect readings along the other axis  left to right   we mounted the sick laser on a panning motor. the motor rotates after each vertical scan to collect laser readings for another vertical column  with a 1  horizontal angular resolution. the depthmap is later reconstructed using the vertical laser scans  the motor readings and known position and pose of the laser device and the cameras. the laser range finding equipment was mounted on a
lagr  learning applied to ground robotics  robot. the

  derived from a second order taylor series approximation of f x .
1
　　one can also envisage obtaining a better estimate of σg as a function of a match metric used during stereo correspondence   scharstein and szeliski  1  such as normalized sum of squared differences; or learning σg as a function of disparity/texture based features.


figure 1: results for a varied set of environments  showing one image of the stereo pairs  column 1   ground truth depthmap collected from 1-d laser scanner  column 1   depths calculated by stereo  column 1   depths predicted by using monocular cues only  column 1   depths predicted by using both monocular and stereo cues  column 1 . the bottom row shows the color scale for representation of depths. closest points are 1 m  and farthest are 1m.  best viewed in color 


figure 1: the custom 1-d scanner to collect stereo image pairs and the corresponding depthmaps.
lagr vehicle is equipped with sensors  an onboard computer  and point grey research bumblebee stereo cameras  mounted with a baseline distance of 1cm.
　we collected a total of 1 stereo pairs+depthmaps  with an image resolution of 1 and a depthmap resolution of 1. in the experimental results reported here  1% of the images/depthmaps were used for training  and the remaining 1% for hold-out testing. the images consist of a wide variety of scenes including natural environments  forests  trees  bushes  etc.   man-made environments  buildings  roads  trees  grass  etc.   and purely indoor environments  corridors  etc. . due to limitations of the laser  the depthmaps had a maximum range of 1m  the maximum range of the laser scanner   and had minor additional errors due to reflections and missing laser scans. prior to running our learning algorithms  we transformed all the depths to a log scale so as to emphasize multiplicative rather than additive errors in training.
1 results and discussion
we evaluate the performance of the model on our test-set comprising a wide variety of real-world images. to quantitatively compare effects of various cues  we report results from the following classes of algorithms that use monocular and stereo cues in different ways:
 i  baseline: the model  trained without any features  predicts the mean value of depth in the training depthmaps.  ii  stereo: raw stereo depth estimates  with the missing values set to the mean value of depth in the training depthmaps.  iii  stereo  smooth : this method performs interpolation
and region filling; using the laplacian model without the second term  which models depths as a function of monocular cues  in eq. 1  and also without using monocular cues to estimate λ1 as a function of the image.
 iv  mono  gaussian : depth estimates using only monocutable 1: the average errors  rms errors gave similar results  for various cues and models  on a log scale  base 1 .
algorithmallcampusforestindoorbaseline.1.1.1.1stereo.1.1.1.1stereo  smooth .1.1.1.1mono  gaussian .1.1.1.1mono  lap .1.1.1.1stereo+mono  lap .1.1.1.1lar cues  without the first term in the exponentof the gaussian model.
 v  mono  lap : depth estimates using only monocular cues  without the first term in the exponent of the laplacian model.
 vi  stereo+mono: depth estimates using the full model. table 1 shows that the performance is significantly improved when we combine both mono and stereo cues. the algorithm is able to estimate depths with an error of .1 orders of magnitude 1 which represents a significant improvement over stereo  smooth  performance of .1.
　fig. 1 shows that the model is able to predict depthmaps  column 1  in a variety of environments. it also demonstrates how the model takes the best estimates from both stereo and monocular cues to estimate more accurate depthmaps. for example  in row 1  fig. 1   the depthmap generated by stereo  column 1  is very inaccurate  however  the monocularonly model predict depths fairly accurately  column 1 . the combined model uses both sets of cues to produce a better depthmap  column 1 . in row 1  stereo cues give a better estimate than monocular ones  and again we see that using our combined mrf model  which uses both monocular and stereo cues  results in an accurate depthmap  column 1   correcting some mistakes of stereo  such as some far-away regions which stereo predicted as close.
　we note that monocular cues rely on prior knowledge learned from the training set about the environment. this is because monocular 1-d reconstruction is an inherently ambiguous problem. thus  the monocular cues may not generalize well to images very different from ones in the training set  such as underwater images or aerial photos. in contrast  the stereopsis cues we used are are purely geometric  and therefore should work well even on images taken from very different environments. to test the generalization capability of the algorithm  we also tested the algorithm on images  e.g. containing trees  buildings  roads  etc.  downloaded from the internet  images for which camera parameters are not known . the model  using monocular cues only  was able to produce reasonable depthmaps on most of the images.  however  not having ground-truth depthmaps and stereo images for images downloaded from the internet  we are unable to give quantitative comparisons for these images.1 
in fig. 1  we study the behavior of the algorithm as a func-

figure 1: the average errors  on a log scale  base 1  as a function of the distance from the camera.
tion of the 1-d distance from the camera. at small distances  the algorithm relies more on stereo cues  which are more accurate than the monocular cues in this regime. however  at larger distances  the performance of stereo degrades; and the algorithm relies more on monocular cues. since  our algorithm models uncertaintiesin both stereo and monocularcues  it is able to combine stereo and monocular cues effectively.
　we also carried out an error analysis  to identify the cases when the algorithm makes mistakes. some of its errors can be attributed to limitations of the training set. for example  the maximum value of the depths in the training and test set is 1m; therefore  far-away objects are all mapped to the one distance of 1m. the monocular algorithm fails sometimes to predict correct depths for objects which are only partially visible in the image  e.g.  fig. 1  row 1: tree on the left . for depth at such a point  most of its neighbors lie outside the image area  hence the relations between neighboring depths are not effective. however  in those cases  stereo cues often help produce the correct depthmap  row 1  column 1 .
1 conclusions
we have presented a hierarchical  multi-scale mrf learning model for capturing monocular cues and incorporating them into a stereo system so as to obtain significantly improved depth estimates. the monocular cues and  purely geometric  stereo cues give largely orthogonal  and therefore complementary  types of information about depth. we show that by using both monocular and stereo cues  we obtain significantly more accurate depth estimates than is possible using either monocular or stereo cues alone. this holds true for a large variety of environments  including both indoor environments and unstructured outdoor environments containing trees/forests  buildings  etc. our approach is general  and applies to incorporating monocular cues together with any offthe-shelf stereo system.
acknowledgments
we thank andrewlookingbillfor help in collectingthe stereo pairs. we also thank larry jackel and pieter abbeel for helpful discussions. this work was supported by the darpa lagr program under contract number fa1-c-1.
