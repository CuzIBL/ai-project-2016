 
finding adequate semantic models of deductive reasoning is a difficult problem  if deductions are to be performed efficiently and in a semantically appropriate way. the model of reasoning provided by possible-worlds semantics has been found deficient both for computational and intuitive reasons. existing semantic approaches that were proposed as alternatives to possible-worlds semantics either suffer from computational intractability or do not allow agents to have meta-beliefs. this work  based on relevance logic  proposes a model of belief where an agent can hold met a-beliefs and reason about them and other world knowledge efficiently. it is also shown how the model can be extended to include positive introspection without losing efficiency. 
	i. 	introduction 
most knowledge based systems can perform some form of deductive reasoning on their knowledge bases  which contain explicit representations of some aspect of the world. those systems or agents are usually thought of as knowing or believing1 some fact about the world  if they are able to deduce the fact  or  more precisely  its representation  from the knowledge base. for important tasks such as planning actions  it is generally not sufficient that agents have beliefs only about some application domain but also about their own knowledge. for example  only after realizing that one does not know a friend's phone number one would go about finding out what it is  see moore  moor1  and konolige  kono1  for further examples on the importance of meta-knowledge and  for that matter  meta-reasoning . 
     independent of what beliefs are about  actual reasoning must obey certain computational constraints. for example  resource limitations are a fact of life  and when interacting with the environment  systems can afford to spend only so much time  thinking  before they are forced to act. 
     we are interested in models of reasoning that give rise to good computational performance  even in the presence of meta-beliefs. in addition  these models should give a semantic account of reasoning  that is  relate it to the notion 
　　1  for the purposes of this paper  the distinction between knowledge and belief is not important  and we use both terms interchangeably. 
1 	knowledge representation 
of truth in a way that conforms as much as possible with our intuitions. 
     the framework for our investigations are logics of knowledge and belief and their model theories  which have been convenient tools in the study of reasoning for two reasons. for one  they allow us to address meta-beliefs in a direct and elegant way. secondly  models that predict what beliefs follow from a given set of beliefs can be viewed as a knowledge level specification of a reasoner that has somehow represented those beliefs internally. 
     one of the best understood models of knowledge and belief is provided by possible-worlds semantics. it dates back to hintikka  hint1   with more recent investigations in  moor1  and  leve1   for example. the major problem with this approach is that it prescribes reasoning that is closed under logical implication  which is strongly believed to be computationally intractable  co-np hard  even for propositional logics  and is known to be undecidable for first-order logic. even on intuitive grounds  closure under logical implication has been found much too demanding for real agents  a problem often referred to as logical omniscience. for example  logical omniscience has an agent believe all valid sentences  something we are more than willing to give up in return for better performance. 
     there are mainly two approaches that try to avoid the shortcomings of possible-worlds semantics. one essentially assumes that beliefs are sentences in some syntactically specified belief set. examples of such models are  eber1  and  mohe1 . a more sophisticated approach can be found in  kono1 . as pointed out by levesque  leve1   a major drawback of this syntactic approach is the fact that the kinds of sentences believed can be quite arbitrary because they depend on the form of sentences. 
     the appeal of possible-worlds semantics  despite its problems  is that it avoids relying on syntactic form by defining belief with respect to the classical notion of truth. researchers following the so-called semantic approach have therefore tried to retain these properties while at the same time avoiding logical omniscience by adopting a modified notion of truth. levesque  leve1  was among the first to follow this route. his model of belief employs non-standard worlds  resulting in a kind of tractable inference closely related to relevance logic  anbe1   see section ii. for more details . fagin and halpern develop a logic in  faha1  which adds a concept of awareness of primitive proposi-
tions to the standard notion of truth1. 
　　in a model by vardi   vard1    the belief set of the syntactic approach is replaced by a set of propositions  where propositions are modelled as sets of certain states of affairs. however  this still forces an agent who believes a to believe all sentences that are equivalent to a.  for a comprehensive overview of models of belief in the literature  see  mcar1 .  
　　the semantic approaches mentioned above still leave one important question unanswered  namely whether there are models that allow agents to reason with their meta-belief1 in a tractable way. even though vardi and fagin and halpern overcome the problem of logical omniscience and allow for meta-beliefs  reasoning still appears to be intractable  see section d. for more details . on the other hand  levesque  who does provide an efficient algorithm to determine whether certain beliefs imply others  does not allow the agent to have beliefs about itself  precluding any form of meta-reasoning  which is a serious limitation. 
　　the main contribution of this work is that it offers a plausible semantics for the beliefs of an agent who can hold meta-beliefs and is able to draw inferences from them efficiently. the paper is organized as follows: in section 1 we give a general outline of the model discussing its origins and motivations. section 1 introduces the language c and the logic blk. in addition to a formal semantics  proof theory  and a discussion of its properties  the main tractability result is presented. section 1 outlines changes to the semantics that allow an agent to do some introspection on its beliefs without losing tractability  resulting in the logic bl1 . we conclude with a short summary and an outlook on open questions and future work. 
	i i . 	t h e a p p r o a c h 
the model of belief proposed in this paper is an extension of levesque's model in  leve1  which is derived from possible-worlds semantics  also referred to as kripke structures . 
　　a standard kripke structure consists of a set of worlds and a binary accessibility relation  r  between worlds. the main characteristic of a world is that it determines the truth of a global set of propositions. an agent at a world w is then said to believe a proposition p if p is true in all worlds accessible from w. this is the basic model for what is usually referred to as the logic k  see  hamo1  or  hucr1  for an introduction to modal logics . restrictions on r result in models for certain introspective abilities of an agent. if r is transitive  for example  we get positive introspection  that is  if an agent believes p then it believes that it believes p  the logic weak s1 . if  in addition  r is euclidean1  the agent can perform negative introspection  
   1  their logic of general awareness where an agent can be aware of arbitrary sentences  however  has a strong syntactic flavour. 
1
 r is euclidean iff for all w1  w1  and w1  if w1 w1 and w1 rw1  
that is  if it does not believe p  it believes that it does not believe p  the logic weak s1 . 
　　in levesque's work the major deviation from standard kripke structures is the use of situations rather than worlds. in contrast to a world  where everything is either true or false  a situation can support the truth of a proposition  the falsity  both  or neither. intuitively  only those propositions that are relevant to a situation are supported. a situation in which proposition p has both true and false support  can be interpreted as providing evidence both for the truth of p and for its falsity. an agent believes a proposition p in a situation s  if p has true support in all situations accessible from s.1 a more detailed picture of the properties of levesque's model will follow from the discussion of the logics presented in this paper  which subsume his model. besides its attractiveness from a computational point of view  it is worth mentioning that  although implication retains the usual properties  believing a implies believing b holds if and only if a tautologically entails b. tautological entailment was proposed by relevance logicians as a more intuitive account of implication  anbe1 . in a sense  the agent in levesque's model believes all the relevant implications of its beliefs. 
　　our goal is to extend levesque's semantics in a natural way to allow for meta-beliefs. in particular  beliefs about beliefs should have properties analogous to those that are just about the world. this means that the agent should not be logically omniscient with respect to its own beliefs  and in addition  its reasoning abilities should not 
be any more powerful when reasoning about itself.1 
　　a key feature underlying levesque's logic is the fact that an agent on the one hand may have no opinion at all about some aspect of the world  and on the other hand  its opinion about something may be unrelated to an opinion about its negation. the extension we propose to this property is to let that  something  also apply to the agent's beliefs about itself. 
　　this is the idea: whenever the agent in a situation s wants to confirm a belief a  it does so by making sure that a is supported in all elements of some set of situations. whenever it disconfirms a belief /   it is because b is not supported by some member of a set of accessible situations. the crucial point is that the sets in both cases need not be the same. it is as if the agent is in  potentially  different modes of thinking when it comes to positive versus negative beliefs of its own. caveat: we certainly do not want to suggest that humans actually behave like this. rather  this is an attempt to provide a semantically motivated account for an arguably weak artificial agent. another aim is then w1rw1. 
　1  actually  since levesque does not consider meta-beliefs  he dispenses with the accessibility relation altogether replacing it with a set of possible situations that are visible from any situation. 
　1  both criteria are violated in the obvious extension to levesque's logic  which simply allows nested beliefs without changing the semantics. in fact  this would lead to a reasoner with the power of weak s1 with respect to meta-beliefs. 
	lakemeyer 	1 


1 	knowledge representation 


	lakemeyer 	1 


1 	knowledge representation this paper is that reasoning about beliefs in the sense of deciding bkb ba is tractable  assuming a certain normal form . this is true even in the case of meta-beliefs on either side of the implication. furthermore  adding positive introspection does not change the complexity. 
　　there are still many issues left open. one  which is probably more of theoretical interest  is how to allow the agent to know about implicitness. for example  one might want to model the property that the agent thinks it knows exactly what is implicit  i.e.  one might want bba  bla and to be valid.  see also  faha1   where b is valid in the logic of awareness.  straight forward extensions of blk and bl1 do not have these properties. 
other issues concern the fact that the logics blk and 
bl1 are arguably very weak. for one  they have no notion of consistency  not even with respect to meta-beliefs. for example  the sentence is satisfiable  which is a version of g. e. moore's famous problem  see  hint1  . in  lake1  we show that consistency requirements of this form can be accommodated without sacrificing tractable reasoning. furthermore  the language c itself is not expressive enough for many knowledge representation purposes. therefore  we are now looking at first-order versions of explicit beliefs. in particular  we are investigating how the results in this paper can be combined with those in  lake1 . 
　　nevertheless  the logics blk and bl1 demonstrate already that reasoning about object and meta-beliefs can be done efficiently within a reasonable semantic framework. 
i am indebted to hector levesque for his patience and enthusiasm during our weekly meetings and his comments on earlier drafts of this paper. i would also like to thank jim des rivieres and diane horton for their suggestions concerning style and contents of the paper. this work was financially supported by a government of canada award and the department of computer science at the university of toronto. 
r e f e r e n c e s 
 anbe1  anderson  a. r. and belnap  n. d.  entailment  the logic of relevance and necessity  princeton uni-
 eber1  eberle  r. a.  a logic of believing  knowing and inferring  synthese 1  1  pp. 1. 
 faha1  fagin  r. and halpern  j. y.  belief  awareness  and limited reasoning: preliminary report  proc. int. joint conf. on ai  august 1  pp. 1. 
 hamo1  halpern  j. y. and moses  y. o.  a guide to the modal logics of knowledge and belief  proc. int. joint conf. on artificial intelligence  los angeles  ca  august 1  pp. 1. 
	lakemeyer 	1 
 hint1  hintikka  j.  knowledge and belief: an introduction to the logic of the two notions  cornell university press  1. 
 hucr1  hughes  g. e. and cresswell  m. j.  an introduction to modal logic  methuen and company ltd.  london  england  1. 
 kono1  konolige  k.  belief and incompleteness  sri artificial intelligence note 1  sri international  menlo park  1. 
 lake1  lakemeyer  g.  steps towards a first-order logic of explicit and implicit belief  proc. of the 
conf. on theoretical aspects of reasoning about knowledge  asilomar  california  1  pp. 1. 
 lake1  lakemeyer  g.  ph.d. thesis  department of computer science  university of toronto  forthcoming. 
 leve1  levesque  h. j.  a formal treatment of incomplete knowledge bases  tech. report no. 1  fairchild lab. for ai research  palo alto  1. 
 leve1  levesque  h. j.  a logic of implicit and explicit belief  tech. rep. no. 1  fairchild lab. for ai research  palo alto  1. 
 mcar1  mcarthur  g.  reasoning about knowledge and belief: a review  to appear in: computational intelligence  1. 
 mohe1  moore  r. c. and hendrix  g.  computational models of beliefs and the semantics of beliefsentences  technical note 1  sri international  menlo park  1. 
 moor1  moore  r. c  reasoning about knowledge and action  technical note 1  sri international  menlo park  1. 
 pate1  patel-schneider  p. f.  a decidable first-order logic for knowledge representation  proc. int. joint conf on ai  august 1  pp. 1   also available as: ai tech. report no. 1  schlumberger palo alto research . 
 vard1  vardi  m. y.  on epistemic logic and logical omniscience  proc. of the conf on theoretical aspects of reasoning about knowledge  asilomar  california  1  pp. 1. 
1 	knowledge representation 
