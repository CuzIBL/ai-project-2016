 
this paper presents a new hybrid method for solving constraint optimization problems in anytime contexts. discrete optimization problems are modelled as valued csp. our method  vns/lds+cp  combines a variable neighborhood search and limited discrepancy search with constraint propagation to efficiently guide the search. experiments on the celar benchmarks demonstrate significant improvements over other competing methods. vns/lds+cp has been successfully applied to solve a real-life anytime resource allocation problem in computer networks. 
1 	introduction 
it is today indisputable that constraint programming  cp  fulfills industrial needs of optimization off-line. many systems which use this technology are already operational in different fields of activity  such as planning  scheduling and resource allocation. in on-line optimization context  problems dynamically change according to the evolution of the external environment  and their resolution must respect strong temporal constraints  anytime contexts . however  cp is not yet adapted for solving such on-line problems : no guarantee is supplied on the execution times  and current cp solvers do not lend themselves to the combination with other search methods which seem better adapted to respect temporal constraints  such as stochastic search methods. 
　our objective is to conceive anytime algorithms based on cp and to guarantee the following main properties : to produce in a very short time solutions of good quality  and more importantly to improve them gradually as computation time increases. to our knowledge  our proposal is one of the first attempt to efficiently address the problem of building anytime algorithms with constraint programming. 
　this paper presents a new hybrid method  called vns/lds+cp  dedicated to the efficient computation of high quality solutions  possibly suboptimal  in an anytime context. our method combines a variable neighborhood search  hansen and mladenovic  1   it performs moves like local search   and a limited discrepancy search  harvey and ginsberg  1  with constraint propagation to efficiently guide the search. 
　f-1 caen cedex - france patrice.boizumault info.unicaen.fr 
　section 1 describes the general context in which we take place. section 1 reviews the hybridization of search algorithms and justifies our first choices. section 1 details our proposal  vns/lds+cp . section 1  gives computational experiments on celar benchmarks ; both mechanisms of vns/lds+cp are then finely studied. section 1 shows how vns/lds+cp has been successfully applied to solve a difficult network problem. finally  we conclude and draw a few perspectives. 
1 	anytime constraint optimization context 
1 anytime algorithms 
the term anytime algorithm was coined by dean and boddy in the mid-1s in the context of their work on timedependent planning  boddy and dean  1 . contrary to a standard algorithm  where no result is available until its ending  an anytime algorithm can be stopped  at any time  to provide a solution of increasing quality over time. 
　performance profiles describe the evolution of the solution quality  produced by the algorithm  as a function of the computation time. they provide a more precise description of the performances and of the behavior of an algorithm than the best known solution reported by usual algorithms. in the sequel of this paper  we consider mean performance profiles : such curves are built empirically by collecting statistics on the performance of the algorithm over many input instances. there are two kinds of anytime algorithms  namely  interruptible and contract algorithms  zilberstein  1 . a contract algorithm requires that the computing time must be known prior to its activation. it must produce a solution within a contract of time  and if it is interrupted before the end of the contract  there is no guarantee about the quality of the solution. however  for an interruptible algorithm  no information is  a priory  available about the allowed computation time  and a solution may be asked for at any time. the algorithm must always provide a good solution  and more importantly  continue to refine it. 
　in this paper we are interested by the design of interruptible algorithms  since every interruptible algorithm is trivially a contract algorithm  but the converse is not so immediate. 
1 valued constraint satisfaction problems 
the valued csp  vcsp   bistarelli et al.  1; schiex et al.  
constraints 	1 1  framework is an extension of the csp  constraint satis-
faction problem  framework  which allows over-constrained problems or preferences between solutions to be dealt with. 
more formally  whereas a csp is defined as a triplet 
 v  v  c   where v is a set of variables  v a set of finite domains associated to the variables and c a set of constraints between the variables  a vcsp can be defined as a csp provided with a valuation structure s and a valuation function 
 the valuation structure s is a triplet  e    where ♀ is a valuation set   a total order on e  and mum and the minimum element in e and   a binary operation closed on e. the valuation function defined from c to e  associates a valuation to each constraint; the valuation of a constraint denotes its importance. 
　let a be an assignment of all the variables and be the set of the constraints unsatisfied by a. the valuation of a is the aggregation of the valuation of all the constraints in 
　the objective is to find a complete assignment with minimum valuation. specific frameworks depend on the retained operator  classical csp  a ; possibilistic csp  max ; lexicographic csp  u on multi-sets ; weighted csp . as many real-life problems use an additive criterion  we only consider weighted csp  wcsp  in the sequel of this paper. from an algorithmic point of view  wcsps are generally the most difficult to solve  schiex et al.  1 . 
1 hybridizations of algorithms 
1 complete search vs local search 
exact  or complete  tree search methods  such as branch and bound  are able to produce both an optimal solution  and a proof of optimality. but  because of their exponential worstcase behavior  they may be extremely time consuming. moreover  it has been experimentally observed that  due to their systematic way of exploring the search space  the quality of their intermediate solutions is usually very poor. 
　due to their opportunistic way of exploring the search space  approximate  or incomplete  methods  based on stochastic local search  as simulated annealing  tabu search   can provide good solutions within a reasonable computing time. but  such methods do not guide fast enough the search towards the best neighbor solutions. indeed  they may waste a lot of time trying to improve the current solution with no success ; this is the case when they remain blocked in local minima during a prohibitive time. such situation is not suitable in an anytime context  since the quality of solutions has to be improved gradually as fast as possible  as the computing time increases. moreover  pure local search algorithms generally require a lot of time to adjust their noise parameters ; their efficiency strongly depends on the value of these parameters  which are generally application-dependent. 
1 hybrid algorithms 
hybrid algorithms  focacci et al    provide appropriate compromises between both kinds of search. more precisely  they are very efficient by combining the advantages of both constraint propagation  complete search  and opportunistic exploration of the search space  local search . 
　intertwined hybridizations are the most attractive and relevant hybridizations of algorithms where both complete and local search are closely mingled during computation. the first kind of such hybrid algorithms belongs to the family of local search methods and uses ideas from cp in order to make large neighborhoods  lns  shaw  1   more tractable. a second kind belongs to the family of exact search and uses some local search principles to improve the partial solutions at each node of the search tree  prestwich  1  or to explore a set of solutions close to the greedy path in a search tree  caseau et al  1 . 
1 hybrid algorithms for anytime contexts 
vns/lds+cp is an intertwined hybridization algorithm. 
from local search  we have retained a variable neighborhood search  vns  which extends the principle of large neighborhoods  lns  by dynamically adjusting the neighborhood size  when the current solution is a local optimum. this choice will partially remedy to the weaknesses of pure local search methods. indeed  the more the neighborhood is potentially large the more there are chances that it contains good solutions and thus improves quickly the current solution. however  as neighborhoods grow larger  finding the best neighbor may require a too expensive computational effort. so  we have selected the lds partial search combined with constraint propagation  lower bounds computation  to efficiently explore these neighborhoods. 
1 the vns/lds+cp method 
vns/lds+cp is basically a local search method  as depicted in algorithm 1. it differs from classic local search methods by the size of the neighborhoods  which is adjusted dynamically during the search. it starts with an initial complete assignment .s*; then  at each move  it relaxes  or unassigns variables  a large part of the current solution s and then rebuilds it  reassigns variables  by selecting the best neighbor that strictly improves the cost of the current solution. the algorithm ends when the maximum number of local moves  maxmovhs  is reached. 
　lds explores the neighborhood defined by the relaxed part of the solution. it benefits from constraint propagation based on lower bounds computation  and on dynamic heuristics for variable and value ordering. moreover  only judicious neighborhoods  related to conflict variables  i.e. variables occur-

ing in violated constraints   are considered. such a choice prevents lds from modifying the value of conflict variables. 
1 relaxing a solution 
algorithm 1 describes how to select the variables to be relaxed. the function of line  1  computes the set v of current variables candidate to relaxation  according to a strategy sir. a basic strategy is to select all the variables that are in conflict  size elements of v are randomly chosen to constitute rd the set of variables to be relaxed. this choice enables a balance between choosing variables according to a specific strategy and completely at random. experiments have shown that the introduction of some randomness enables the search to escape quickly from local minima. 
1 control of the neighborhood size 
initially  the neighborhood size  size  takes a minimum value. 
to control the neighborhood size  different strategies have been implemented. the best strategy we have found  increases systematically size by one  each time the method does not improve the cost of the current solution. 
1 rebuilding a solution 
algorithm 1 defines the function rebuild. the global variables ub and lb record the upper and lower bounds of the problem optimum. lb s .r   computes a lower bound of the subproblem  limited to the variables after i  i included   discrep sets the maximum number of choices that we can diverge from the heuristic  discrepancies . 
limited discrepancy search 
the idea of lds  harvey and ginsberg  1  is to explore heuristically good solutions that might be at a limited distance from greedy solution. lds ensures a more balanced exploration of the search tree  and speeds up the reconstruction step  thus improving the performance profile of our method. lds starts from the solution computed by the value heuristic  and successively explores solutions by increasing the number of discrepancies  until the fixed maximal number of discrepancies is reached. 
　we have used a generalized version of lds for n-ary trees. the discrepancy is measured according to the rank of the value chosen for every variable in the order given by the heuristic on values. we count a single discrepancy for the second cheapest value of one variable  two discrepancies for either the third cheapest value of one variable  or the second cheapest value of two variables  and so on. we only perform one iteration of lds  for a fixed discrepancy. this prevents re-visiting leaf nodes. 
constraint propagation 
one of the main strengths of our approach lies in the use of constraint propagation to prune useless sub-trees and to guide the choice of values during the reconstruction  while keeping this step fast enough. at each node of the search tree  lower bounds are computed in order to locally exclude all partial solutions which cannot lead to complete assignments of better valuation than the current best solution. to our knowledge  no method based on large neighborhoods  in particular vns  uses such a mechanism. 
　to compute lower bounds  we have adapted the following algorithms llarrosa et al.   1  for wcsps :  i  partial forward checking and directed arc consistency  pfc-dac   all the constraints are directed  and dac are computed from a directed constraint graph  we have used specific data-structures to relax the condition of static variable ordering on dac  ;  ii  reversible  zfc pfc-rdac   constraints directions can change dynamically during search  looking for a good directed graph causing a high lower bound ;  iii  maintaining reversible dac  pfc-mrdac   dac are maintained during search  propagating the effect of value pruning. 
variables and values heuristics 
our heuristic for variable ordering first selects the variable having the lowest ratio domain cardinality divided by future degree. constraint propagation  based on forward checking + directed arc consistency  allows us to use a dynamic minimum inconsistency count value ordering. during search  for each value  so-called inconsistency counts  ic  and directed arc consistency counts  dac  which record the look-ahead effects on future  unassigned  variables  are computed. values are selected by their increasing ic + dac. 
1 experimentations on celar benchmarks 
1 	instances of celar 
the celar  french centre d 'electronique de i'armement  has made available a set of 1 i instances of the radio link frequency assignment problem  rlfap   cabon et al.  1 . most of them can be naturally cast as binary wcsps. for our experiments  we have selected instance 1  which involves 1 variables  having an average of 1 values in their domain  and 1 constraints   instance 1  which involves 1 variables  

constraints 	1 


having an average of 1 values in their domain  and 1 constraints   and instance 1-sub 1  which involves 1 variables  having an average of 1 values in their domain  and 1 constraints  extracted from instance 1. these instances  1 and 1  are the most difficult ones. whereas the optimum of instances 1 and 1-sub 1 are known  respectively 1 and 1   the optimum of instance 1 is still unknown; the best known upper bound is equal to 1. 
1 	experimental methodology 
our method has 1 parameters : the maximum number of local moves  maxmoves   the initial neighborhood size  size   the number of discrepancies  discrcp   and the propagation scheme. for all experiments  maxmoves has been set to 1 and size to 1 ; it is the best value we have found among the following set of values : {1 1 1}. we carried out experiments with different values of discrepancies  discrcp e {1 1}  and with three different propagation mechanisms : pfc-dac  pfc-rdac and pfc-mrdac. 
　for each combination of parameter settings  we ran vns/lds+cp 1 times on the considered instances. during each run  the best cost of the current solution has been recorded at regular time intervals  1 seconds . all plotted figures are mean performance profiles over the 1 runs. the methods have been implemented in choco  laburthe  1 . 

1 	setting parameters for vns/lds+cp 
number of discrepancies 
figure 1  top  shows the performance profiles obtained with pfc-dac  for different settings of discrcp on instance 1. performance profiles for discrcp - 1 and 1 are almost the same. we give only the curve associated to discrcp - 1. results indicate  as expected  that the number of discrepancies has a great impact on the quality of the computed solutions. lds with  discrcp = 1  gives the best results. the poor results for  discrcp   1  are probably due to the fact that our value ordering does not make so many mistakes. indeed  we exploit the propagation scheme to guide the value choices. thus  few discrepancies are necessary to repair heuristic errors. in contrast  for low discrepancies  discrcp   1   the value heuristic too closely limits the solutions we can find  and so  it provides poor guidance to good solutions. for the instance 1  discrcp = 1 is also the best value. 
propagation mechanism 
we turn now to choose the propagation scheme which produces significant lower bounds and  as global effect  leads to a better behavior of our method. figure 1  bottom  reports the performance profiles obtained for the three propagation algorithms  with discrep = 1 on instance 1. lds with pfcdac leads to very substantial profits. because of the overhead of propagation over small neighborhoods these benefits decrease clearly when using stronger propagation  pfc-


rdac and pfc-mrdac . indeed  compared to pfc-dac  the two other propagation schemes perform more work per node to finally obtain results very close to pfc-dac. so  the more complex and time-consuming propagation schemes do not pay-off for this context. 
1 	comparisons and discussion 
we have compared vns/lds+cp  discrap =  1 with pfcdac  with lns/cp/gr  lobjois et al  1   another hybrid method which also relies on solving vcsps in an interruptible context  and also with two standard versions of simulatedannealing  sa  : quick and medium. 
　lns/cp/gr is based on the principle of lns with neighborhood size being constant during all the search. to rebuild the relaxed variables  it uses a greedy algorithm combined with constraint propagation. but this propagation  performed variable per variable  is only used for selecting the best values for each variable  which is fundamentally different from our cp based on usual propagation for wcsp. for instances 1 and 1  the percentage of unassigned variables represents 1% of the total number of variables  lobjois et a/.  1 . 
　figure 1 compares the performances of the four methods. the performance profile of vns/lds+cp is always better than those of the two versions of sa. at the beginning  the profile of vns/lds cp is very close to that of lns/cp/gr. but after few seconds of computation    1 seconds on instance 1 and   1 seconds on instance 1   vns/lds+cp becomes very effective and always provides solutions of better quality  thus clearly outperforming lns/cp/gr on both instances. this behavior can be explained by the fact that  at the beginning  the size of the neighborhood is relatively small and consequently the benefits of constraint propagation are poor. but as soon as this size becomes sufficiently large  our propagation mechanism  lower bounds computation  produces more pruning  and becomes very effective. this leads to a better compromise between quality and time for vns/lds+cp. this confirms our choice for computing significant lower bounds. note however  the good anytime behavior of lns/cp/gr compared with those of sa. 

figure 1: comparing vns and lns on instance o-.1-subl. 
1 	study of mechanisms vns and lds+cp 
in order to evaluate the contribution of each component of 
vns/lds+cp we have carried out experiments on instance 
1-subl  with max moves - 1  and size = 1 ; the two other instances being out of reach from complete searches. five methods have been compared : the depth first branch and bound  dfbb   lds with only one iteration  two variants of lns  lns/cp/gr and lns/lds+cp  which mainly differ by their reconstruction mechanism  and vns/lds +cp. for the two variants of lns  the best percentage of unassigned variables represents 1% of the total number of variables. 
　once again  discrcp = a constitutes the best parameter setting for vns/lds+cp. the behavior of vns/lds+cp is quite similar to those observed on instances 1 and 1  which clearly offers better performance profiles than the other competing methods. on this instance  vns/lds+cp almost finds the optimum in a very short time at each run. we can draw some remarks : 
  pure lds  or only one iteration of lds  is completely inefficient in an anytime context  even if lds leads to better performance profiles than dfbb. 
  the efficiency of vns/lds+cp is certainly partly due to the reconstruction mechanism. indeed  the comparison between performance profiles of lns/cp/gr and lns/lds+cp show that  with an effective propagation 
 lower bounds computation  combined with lds  lns obtains a gain in quality of 1% after 1 seconds. 
  the use of variable size neighborhoods is a key point in the efficiency of vns/lds+cp. indeed  it produces better performance profiles than lns/lds+cp. after 1 seconds  vns obtains a gain in quality of 1% ; this gain reaches a value of 1% after 1 seconds. this amelioration comes from the speed of the exploration of relatively small neighborhoods  in particular during the first moves of vns . this greatly improves the quality of the computed upper bound which will enable a better pruning at the next reconstruction step. this is not the case for lns  which needs much more time to obtain good upper bounds  due to the important size of the neighborhoods. 
　to evaluate the improvement speed of the quality of solutions provided by vns and lns  figure 1 compares 

constraints 	1 

vns/lds+cp and lns/lds+cp  in term of the average percentage of improvement  qp t   with respect to the initial cost  co  and in term of the number of attempted moves  in percentage . qp t  = 1 .  c1 - c /  /c1  where c{t  is the valuation of the best solution found at each instant t. 
　as depicted in figure 1  vns/lds+cp provides the better improvement of the initial cost co. this difference in quality  in favor of vns  is very significant during the first instants. after only 1 seconds of computation  vns improves co by 
1%  with a percentage of attempted moves equal to 1% of maxmoves. for comparison  lns needs 1 seconds and practically three times more of local moves  ~ 1%  to reach the same improvement of quality. moreover  the number of moves attempted by lns grows larger with time  while for vns this number remains low and quasi constant. 
1 	resource allocation in atm networks 
vns/lds+cp has been successfully applied to a real-life anytime resource allocation problem. this application  developed for france telecom r&d  takes place in an atm  asynchronous transfer mode  network administration context. the problem consists in planning demands of connection over a period of one year. reservations must be computed within at most one minute per demand. 
　a new demand is accepted if both bandwidth requirements and quality of service are satisfied. if not  we try to reroute some already accepted connections in order to find a route for the new demand. if rerouting fails  the demand is re-
jected. first  a routing heuristic computes shortest paths which minimize capacity violations on the links. from these violations  a sub-area of the network that can be modified by rerouting some already accepted connections is determined and modelled as a vcsp. then  rerouting is performed with vns/lds+cp. experimental results show that rerouting with vns/lds+cp enables to admit an average of 1% of demands that are rejected with a greedy algorithm without rerouting  loudni et al  1 . 
1 	conclusions and further work 
vns/lds+cp is a new hybrid method for solving constraint optimization problems  modelled as vcsps  in an anytime context. it has been successfully applied to a real-life anytime resource allocation problem in atm networks  1% of rejected demands are now accepted . 
　experiments on the celar benchmarks have shown that vns/lds+cp provides better performance profiles than the other competing methods. moreover  our method is robust : for all considered instances  the best parameters setting is always the same. finally  vns-lds+cp is stable : the distribution of the medians 1  1 and 1 shows that the variation of the evolution of solution quality is negligible within the fifty runs. however  the difference between the best run and those of the medians is relatively distant for instance 1. 
　from an anytime point of view  in addition to the properties of monotonicity  interruptibility and measurable quality  our performance profiles also verify the important property of diminishing returns  which guarantees that the improvement in solution quality is larger at the early stages of computation. 
　performance profiles show a decelerating phase leading to a quasi stable plateau. to escape from this plateau  we intend to study two possibilities : to cooperate with other efficient pure local search method  voudouris and tsang  1  or to re-start our method. 
　in this paper we have mainly focused on the design of anytime algorithms. works remain to be done concerning techniques for monitoring and control  see  hansen and zilberstein  1  . we are currently investigating such techniques for meta-level control. the use ofnogoods would help to obtain more relevant neighborhoods. 
