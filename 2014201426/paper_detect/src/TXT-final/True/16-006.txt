 
       a research project for improving the recognition of fluently spoken german speech is presented. the work is in progress at present.* 
       it should be investigated  how far aspects of semantics and inferences could improve the automatic speech recognition. the work is part of a speech recognition system that receives speech signals  converts them into forms suitable for further actions and finally puts out the spoken text in characters. the system i t s e l f operates at three stages. within the f i r s t one the signal analysis is performed using a well-known method. this analysis segments the signal into certain subword units and  for each segment  produces a set of weighted candidates. at the second stage these candidates are used to generate weighted word hypotheses with the aid of an extensive lexicon. the hypotheses have to be verified or falsified within the following processing steps at the third stage. thereby the algorithm uses a best-first strategy  hypotheses with highest weight f i r s t   . 
       besides syntactic/grammatical aspects  semantic analysis and inferences mentioned above are the 
methods  that should lead to a certain text-com-
prehension. 
	i 	introduction 
       this paper presents the basic concept of a speech recognition system for fluently spoken ger-
man speech. the goal is to improve recognition using methods from the field of artifical i n t e l l i gence. 
       the system operates at three stages   f i g . 1 . the f i r s t one performes the signal analysis. the speech signals are segmented into certain subword units and  for each segment  a set of weighted candidates is produced. this is described in chapter i i . the second stage uses these candidates to generate weighted word hypotheses. chapter i i i explains how the word hypotheses are produced. the third stage produces a set of weighted sentence hypotheses and performs the recognition. the algorithm is described in chapter iv. 
* this work is supported by the deutsche forschungsgemeinschaft  dfg . 
       an extensive lexicon is necessary to execute the last two stages. the chapters i i i .a and iv.a describe the lexicon entries. 
       from the wave form of the speech signal we pick out a section which we call the signal window or window. at present  we presuppose that the size of the window exactly corresponds to one spoken sentence. 

	ii 	signal analysis 
       the speech signals received by the speech recognition system have to be converted into forms suitable for further actions. the signal analysis uses a well-known method  dettweiler  1; ruske and schotola  1 . 
       the analysis segments the signal into certain subword units  socalled demisyllables. a syllable contains a vocalic nucleus with an i n i t i a l conconant cluster preceding and a final consonant cluster following the vowel. now a demisyllable is defined as one or the other part of a syllable  if the syllable is cut into two parts somewhere during the vowel. 
       regarding this method  there exists an inventory of about 1 demisyllables for unrestricted german speech  if all i n i t i a l consonant clusters are combined with all possible vowels  about 1   and all possible vowels are combined with all final consonant clusters  about 1  too . 
       by means of this method the speech signal is segmented into demisyllables  and for each segment  a set of weighted candidates is produced. for demonstration we presuppose that this set of weighted candidates is a complete one. 
       so  at the end of the analysis  a chain of complete sets of weighted candidates for each 

1 	j. mudler 
possible position is given  that can be used for 	iv 	intelligence the next stage of the recognition system   f i g . 1 . 


	i l l 	word hypotheses 
a. 	lexicon entries 
       within the lexicon there exist some entries that are used for generating word hypotheses  regarding the weighted demisyllable segmentation of the preceding stage. for each word in the lexicon  its phonetic transcription using demisyllables and its number of syllables are listed. 
b. 	generation of word hypotheses 
       to generate word hypotheses the lexicon is passed through successively word by word. taking one word out of the lexicon its weight is calculated for each possible position within the chain of demisyllables using the weights of the respective subword units. 
       if we have n syllables within the chain  that means 1n demisyllables   a word with the length of one syllable could appear at n positions  a twosyllable word at  n-l  positions and so on. having processed all words of the lexicon  this method leads to a complete set of word hypotheses for the contents of the respective window   f i g . 1 . 

a. 	lexicon entries 
       besides the entries mentioned above  the lexicon also contains syntactic/grammatical and se-
matic informations for each word. the words are classified into categories  e.g. noun  adjective  preposition  verb  auxiliary verb. the inflectable 
words have a set of possible grammatical forms as an entry  and  perhaps  a semantic marker description. when a certain word hypothesis is processed  the information taken from the lexicon is used to 
answer pending requests or to produce inferences concerning other possibly appearing words or structures within a sentence. 
b. 	algorithm 
       as regards the weighted word hypotheses  now the purpose is to attain correct and meaningful sentences by finding pathes from the beginning to the end of the section of the window. 
       to start with the algorithm the best word hypothesis is selected. the respective lexicon entries of this word  the structure hypotheses and their requests  are transferred to a request f i l e 
which is part of the intelligence stage as shown in figure 1. the structure of the request f i l e is tree-oriented. within this tree pathes must be traced that could lead to the acceptance or rejection of the actual hypothesis. 

       in addition  the length of the window and the  relative  positions of word hypotheses are always known. in the following the recognition algorithm 

performs an expectation-based analysis  riesbeck and schank  1 . 
       supposing the selected word as a noun the request f i l e could have an entry like: 
can an adjective precede the noun directly  
       if there could be at least one adjective the path leads us to requests like: 
are the adjective and the noun grammatically congruent  
and 
are the adjective and the noun semantically congruent  
       a request as an inference from the lexicon could look at the pending word hypotheses or at a hold l i s t   where recognized parts of a sentence  e.g. noun phrases  are listed. in the f i r s t case the request generally concerns word categories. such a request could look l i k e : 
which words with category cat could precede  or follow  the actual hypothesis up to position  i   or starting from position  j    
 the actual hypothesis starts at position  i  and ends at position  j  . 
       if the request could be satisfied the next requests would concern the grammatical and semantical congruences  taking the answer with the best weight f i r s t . 	if any request is rejected the path that led to this request is removed from the request f i l e up to that point where an alternative path can be traced. at all points  answers to a request are only regarded  if they have a certain 
minimal weight in order to limit the number of the following requests. whenever a word hypothesis or a structure hypothesis can be verified in the described way that fact leads to a new selection of the s t i l l pending hypotheses. if any part of the 
section within the window had been verified starting at any word hypothesis  and if there are s t i l l pending hypotheses  respectively - with other 
words - so far there exist only parts of a way from the beginning to the end of the window  then the actually best weigthed word hypothesis has to be considered next. the processing ends if there exists at least one path through the word hypotheses that is accepted. generally  there would be 
more than one. each path has a weight  that is calculated from the word weights   f i g . 1 . 

j. mudler 1 
       if no path could be found because of the supposed minimal weigth  this threshold has to be reduced and a new t r i a l has to start. 
       so  f i n a l l y there had been a transformation from sets of weighted word hypotheses to a set - an essentially smaller one - of possible sentences. the recognition algorithm takes that sentence for granted that has the best weigth. the spoken text can be printed in characters. 
	v 	conclusion 
       in this paper an overview of an automatic speech recognition system is presented. the system receives speech signals and performs the recognition of the fluently spoken german texts. 
       some remarks should complete the description of the recognition system. they show what aspects should be investigated in addition. 
       it is possible to limit the sets of word hypotheses by taking only those words that exceed a certain threshold. for this case it becomes necessary to have a feed-back to the subword level  because it is possible that only such a word can satisfy a path that did not exceed the threshold and that had not been considered within the hypotheses so far. 
       it is planned not to limit the window size. so  the window could also contain only a part of a sentence  parts of more than one sentence or more than one sentence. 
       there are a lot of methods to realize the weighting of demisyllables  words and sentences. 
       because of an internal knowledge representation that could be used to handle inferences a 
       question-answering system could be attached to the system. the representation follows the ideas of schanks conceptual dependency theory  schank  1 . 
