 
the focus of this paper is the technique of recur1 on analysis. recursion analysis is used by the boyer-moore theorem prover to choose an appropriate induction schema and variable to prove theorems by mathematical induction. a rational reconstruction of recursion analysis is outlined  using the technique of proof plans. this rational reconstruction suggests an extension of recursion analysis which frees the induction suggestion from the forms of recursion found in the conjecture. preliminary results are reported of the automation of this rational reconstruction and extension using the clamoyster system. 
1 	introduction 
the work described in this paper is part of a project to explore the use of proof plans for the automatic guidance of mathematical proofs. in particular  we are developing proof plans for the proofs by mathematical induction that are required in the automatic synthesis of computer programs from their specifications. given a conjecture  the clam plan formation program constructs a proof plan to solve it from existing proof tactics. this proof plan is then used to guide the oyster proof development system   horn  1   in a proof of the conjecture. oyster is a prolog re-implementation of nuprl   constable et a/.  
1 . they are both proof checkers for intuitionistic type theory  a logic based on the work of martin-lof. 
　oyster reasons backwards from the conjecture it is trying to prove  using a sequent calculus formalism which includes rules of inference for mathematical induction. the search for a proof must be guided either by a human user or by a prolog program called a tactic. the oyster search space is very big  even by theorem proving standards. there are hundreds of rules of inference  many of which have an infinite branching rate. so careful search is very important if a combinatorial explosion is to be avoided. 
   *the research reported in this paper was supported by serc grant gr/e/1  alvey/serc grant gr/d/1  an serc senior fellowship to the first author and an serc postgraduate studentship to the last author. we are grateful to the other members of the mathematical reasoning group at edinburgh for many useful discussions and to an anonymous ijcai-1 referee for extensive feedback. 
　our aim is to develop a collection of powerful  heuristic tactics that will guide as much of the search for a proof as possible  thus relieving the human user of a tedious and complex burden. these tactics need to be applied flexibly in order to maximise oyster's chances of proving each theorem. proof plans provide this flexible application. each tactic is partially specified by a method  which is a description  in a meta-logic  of the preconditions and effects of the tactic. clam reasons with these methods to build proof plans. a proof plan for a conjecture defines a tactic tailor-made to generate a proof of that conjecture. 
　the state of the art in inductive theorem proving is the boyer-moore theorem prover   boyer and moore  1   henceforth bmtp . it is  thus  natural for us to try and represent the heuristics embedded in the bmtp as oyster tactics.  bundy  1  contains an analysis of some of these heuristics. we have used this analysis to implement a number of oyster tactics for inductive proofs and have successfully tested them on some simple theorems drawn from the literature   bundy et a/.  1 . 
1 	recursion analysis 
recursion analysis is the name we have given to the process  embedded in bmtp  of analysing the recursive structure of a conjecture and deciding what form of induction to use to prove it. this choice is critical to the success of the proof attempt. recursion analysis picks one out of several induction suggestions. an induction suggestion consists of an induction schema and some induction variables1. the form of the recursive functions contained in the conjecture is used to construct raw induction suggestions. these are then combined together into a final induction suggestion  which is the one used in the proof. in this section we will explain the rational reconstruction of recursion analysis given in  stevens  1 . in later sections we will see how to realise this rational reconstruction within proof plans and how to extend it. 
　we can best explain how recursion analysis works by example. consider the conjecture: 
		 1  
where the recursive definitions of -f and even are given in the top left hand corner of figure 1. formulae of the 
however  in subsequent sections we will restrict ourselves 
to single variable inductions. 
bundy  van harmelen  hesketh  smaill and stevens 	1 
　
form x:t are to be read as ''x is of type t   and pnat is the type of peano natural numbers. note that the definition of + steps down in single steps  whereas the definition of even steps down in double steps. the number of steps is determined by the term occurring in the recursive argument position in the head of the step formula of the definition. these terms are emphasised with an underbrace in the definitions of + and even in figure 1. we will call them recursion terms. the recursive function in the body of the definition is emphasised by an overbrace. 
　to each recursion schema there corresponds a dual induction schema. for instance  the induction schema dual to 1 step recursion is: 

where p x  ranges schematically over formulae which 
contain x1. to emphasise the duality between induction and recursion  the induction terms of each schema are also underbraced. note that we have renamed the induction variable  x  to x' in the induction hypothesis and conclusion  cf. the renaming of x to x' in figure 1. this renaming is necessary for soundness  since t may contain x. 
　recursion analysis locates the recursive functions in the conjecture. each occurrence of a recursive function  f1  with a variable  x  in its recursive argument position  gives rise to a raw induction suggestion. the induction variable suggested is x. the induction schema suggested is the one dual to the form of recursion used to define f. applied to the conjecture 1 this produces the raw induction suggestions given in table 1. 

　note that each occurrence of x gives rise to a raw induction suggestion. unfortunately  the two occurrences suggest two different induction schemata: a 1 step and 1 step schema. fortunately  the 1 step schema subsumes the 1 step schema. this is because the recursion term of the 1 step schema consists of repeated nestings of the recursion term of the 1 step schema. thus the 1 step  x 
　　1  but it may also contain other variables  and is not necessarily unary. 1 f is a meta-variable ranging over object-level functions. we use the conventions that: object-level variables are represented as meta-level constants  only meta-level variables start with an upper case letter  and the word 'function' is used in the lambda calculus sense to include predicates and connectives. 
1 	automated deduction 
schema is adopted as the single schema for x  replacing both itself and the 1 step  x schema. in general  there may not be an already suggested schema for a variable that subsumes all the others  but it may be possible to find a new schema that does. stevens' recursion analysis   stevens  1   finds such all-subsuming schemata by merging one or more raw induction suggestions. for instance  a 1 step and 1 step induction would be merged to give a 1 step schema that subsumed both1. 
　the end result of merging is a set of suggestions covering every distinct  i.e. non-subsumed  induction schema that can be derived from the raw induction schemata. in our example we would have a 1 step schema for x and a 1 step schema for y. all that remains is to choose which one should become the final induction suggestion. note that the 1 step  x schema will produce an induction conclusion with the term s s x'   replacing each occurrence of x  and that  by design  a recursive definition will match the term immediately dominating each of these occurrences in the induction conclusion  namely even s s x'    and s s x'   + y. the same is not true of the 1 step  y schema. the second occurrence of y did not play a role in formation of this induction suggestion  and no recursive definition will match the term x + s $ y'   which it gives rise to in the induction conclusion. the replacement of the second occurrence of y with s s y'   is regarded as unsuitable. boyer and moore classify such suggestions as flawed1. flawed suggestions are rejected if any unflawed ones remain  so that in the example above  the 1 step  x suggestion is the one that is finally chosen. in the event of a tie the induction subsuming the largest number of raw suggestions is chosen. 
　bmtp and  stevens  1  use recursion analysis to construct induction schemata at run time  and hence must prove them well-founded after construction. we have not reconstructed this aspect of recursion analysis  and so do not discuss it further here. our induction suggestions must be formed from those schemata for which oyster currently has induction rules of inference. 
　the bmtp only uses the final induction suggestion generated by recursion analysis. note that this makes its choice dependent on the forms of recursion found in the conjecture. for instance  it could not prove the classic version of the prime factorisation theorem1. this uses a form of induction in which the induction term is p x x'  where p is a prime number. no p x x' recursion occurs in the theorem itself  or can be constructed by merging recursions in the theorem. 
　nevertheless  recursion analysis is extraordinarily successful. for many simple theorems  the final form of induction it suggests leads to a proof. why is this  
1
　　the original bmtp deals with subsumption as a situation distinct from  as opposed to subsumed by  merging. one consequence is that it is unable to deal with the 1 step situation and others like it. 
   1 see  boyer and moore  1  or  stevens  1  for a full definition of unsuitable replacements and flawed suggestions. 
   1  bmtp does prove a non-classic  'verification' version of this theorem which  in the place of an existentially quantified variable  includes a function  defined by p x x' recursion  which returns the prime factors of a natural number. in the classic version  see ′1 below  these factors are merely asserted to exist. because the classic version includes an existential quantifier  it cannot even be stated in the bmtp logic. 
　
1 	a proof plan for inductive proofs 
we believe that the bmtp succeeds so often because many inductive proofs have the same overall shape. the bmtp heuristics combine to produce proofs of this overall shape. in particular  the final induction suggestions of recursion analysis initiate proofs of this type and generate subgoals that the other heuristics are designed to solve. we believe that proof plans provide a good notation for describing this overall shape and accounting for the way that the heuristics combine together   bundy  1 . proof plans can be used to predict and account for the successes and failures of the bmtp. they also suggest ways of improving and extending the bmtp heuristics. in particular  we will show how to use proof plans to account for the success of recursion analysis  and to extend it to make it independent of the forms of recursion found in the conjecture. 
　we can best explain the overall shape of bmtp proofs by example. figure 1 is an outline of the proof of conjecture  1  which is generated by our oyster program using our rational reconstruction of the bmtp heuristics. the oyster notation has been slightly simplified for expository reasons. 
　each formula is a sequent of the form h i- g  where iseparates the list of hypotheses  h  from the goal  g. the first sequent is a statement of the conjecture. each successive sequent is obtained by rewriting a subexpression in the one above it. the subexpression to be rewritten is underlined and the subexpression which replaces it is overlined. only newly introduced hypotheses are actually written in successive sequents; sequents are to be understood as inheriting all those hypotheses above them in the proof. in the spaces between the sequents are the names of the tactics which invoke the rewriting. 
　the proof is by backwards reasoning from the statement of the conjecture. the induction tactic applies the 1 step induction schema to the conjecture: replacing x by 1 and 1  in the two base cases  and by x' in the induction hypothesis and s s x'   in the induction conclusion of the step case. the base and step tactics then rewrite the base cases and the step case  respectively  using the base and step formulae of the recursive definitions of + and even. the two applications of base rewrite both the base cases to tautologies  which the sym eval tactic reduces to true. the four applications of step raise the occurrences of the successor function  s  from their innermost positions around the x's until they are absorbed by the application of the step formula of even. the induction conclusion is then identical to the induction hypothesis. the fertilize tactic uses the latter to deduce the former. 
　ripple.out is a super-tactic which is responsible for the repeated application of step to the induction conclusion - raising the recursion terms  ind strat  which is an abbundy  van harmelen  hesketh  smaill and stevens 1 
　
breviation of induction strategy  is a super-super-tactic for guiding the whole of this proof  apart from the two sym eval applications. it is defined by combining the sub-tactics induction  base  ripplejout and fertilize in the order suggested by the proof in figure 1. sym eval  which is an abbreviation of symbolic evaluation  puts expressions in normal form by unpacking definitions  eliminating quantifiers  applying reflexivity and recognising tautologies. it is also a super-tactic which repeatedly applies step  base  identity  intro and tautology. a large number of inductive proofs can be understood as a combination of ind strait and sym eval  although not always in the combination illustrated in figure 1. for instance  there are often several nested applications of ind strat before sym eval is used to finish off the proof. 
　note how ripple out acts as a bridge between the induction and fertilise tactics  induction makes the induction conclusion differ from the induction hypothesis by the insertion of induction terms for the induction variable. these induction terms form a barrier to fertilizers use of the induction hypothesis to prove the induction conclusion  ripplejout removes this barrier with a series of steps which raise the induction terms out of their inner-most positions. recursion analysis ensures that the induction terms inserted will have just the right form for the first wave of steps1 to succeed  i.e. those steps that raise the induction terms past the innermost functions that dominates them. the raw induction suggestion made by each recursive function occurrence proposes an induction term which is a syntactic variant of that recursive function's recursion term. so if this induction term is inserted then step is guaranteed to succeed on this occurrence. if the final induction suggestion is unflawed and subsumes all the raw suggestions  then step is guaranteed to succeed on all the occurrences  although repeated steps may be required to completely lift the final induction term. this is the reason for choosing an induction schema based on the recursive schemata used to define the functions in the conjecture. these conditions only guarantee the success of this first wave of steps  not the whole ripple out tactic. 
1 	fitting proof plans to conjectures 
we have implemented each of the tactics illustrated above by a prolog program which can guide the oyster proof checker to make the appropriate logical steps. furthermore  we have specified each of these tactics with a method. clam uses these methods to build a tactic tailor-made to prove the whole of each conjecture. 
　a method is represented as a frame of 1 slots which between them describe the conditions under which its tactic is applicable and the effect if this application is successful. 
　all that will concern us in this paper are the input formula slot and the preconditions slot of the ind strat method. 	consider the preconditions of the version of the 	ind strat 	method described in an early version of our program. 	with some minor generalisations  these were: 

	recur 	sive fterm  	x  	rterm  	 1  
where conj is the input formula  x ranges over objectlevel variables  fterm ranges over object-level terms  rterm ranges over object-level recursion terms  n is a natural number and posn is a position. these metavariables are all universally quantified globally1 to the method. a position is a list of argument numbers  e.g.  1 1  would represent the 1st argument of the 1nd argument of the 1rd argument of an expression. exp at{exp  posn  = subexp means that subexp is the subexpression found at position posn in expression exp. recursive fterm  x  rterm  means fterm is a term whose dominent function is recursively defined with the variable  x  in its recursive argument and with recursion term  rterm  e.g. the information that even is defined recursively with recursive term s s {/   is represented by the meta-assertion recursive even u   u  s s u   1. recursion terms contain the crucial information that clam needs to pick an induction schema from those available to oyster. the final induction suggestion will consist of an recursion term and a recursion argument. clam picks an induction schema with an induction term that matches this recursion term. induction schemata are indexed by their induction terms. 
　part of the process of planning involves fitting methods to the current conjecture. to fit a method  the input formula is matched to the conjecture and then the preconditions are checked to see if they are satisfied and to instantiate their meta-variables. for instance  fitting these preconditions to the conjecture   l   above  produces the variable instantiations given in table 1. comparison of these with table 1 will show that what this method fitting process does is to generate the raw induction suggestions. 

1 extending plan fitting to perform recursion analysis 
two questions arise naturally. 
  the preconditions   1   above only guarantee the success of one application of the step tactic for one occurrence of x. can they be extended to at least guarantee the success of the first wave of steps'! 
  the fitting of the preconditions   1   above only gen-erates raw induction suggestions. can they be extended to do recursion analysis  i.e. to generate final induction suggestions  
1 so the quantifiers do not appear within the preconditions 
　
1 	automated deduction 
　
slot   1   above. 1
　　note the use of the meta-variable u ranging over objectlevel variables  which will be instantiated to whatever x is instantiated to when recursive fterm x  rterm  and recursive even u  u  s s u    are unified. 
　
　the answer to both these questions is yes. the beautiful part of these answers is that the same extensions to the preconditions suffice in each case  i.e. in extending the preconditions to guarantee the success of later parts of the plan  the processes of flaw checking  subsumption checking and merging are generated naturally as a sideeffect. their presence and success in bmtp is thereby explained. 
the extended preconditions are: 
  
where subsumes  rterm  rterm!  means that rterm subsumes rtcrm1  e.g. subsumes s s x   s x  . only those meta-variables whose scope is restricted to the preconditions are quantified within them. the others  e.g. rterm  are universally quantified globally to the method. 
　these revised preconditions extend the original preconditions to every occurrence of every variable  x  in the conjecture  conj. they check firstly that each such occurrence is at the recursive argument position of a recursive function and secondly that there is a term  rterm  that subsumes all the recursion terms of these recursive functions. the instantiations of rterm and x constitute the final induction suggestions and the instantiations of rterm1 and x the raw induction suggestions. care has been taken in our implementation so to define subsumes that attempts to satisfy it  with its second argument instantiated and its first argument uninstantiated  efficiently produce minimal subsuming schemata. 
　fitting these preconditions to the conjecture 1 above  produces the variable instantiations given in table 1. the first line of this table is the required final induction suggestion. 

table 1: fitting the new ind strat method to the even+ 
example 
　the second line of the table is a suggestion that actually /at/1 the preconditions   1 . we have included it and the status column for the sake of the following discussion. an induction suggestion that meets all the preconditions may not always be available  e.g. both x and y are flawed in x + y = y + x . in such cases we may want to follow bmtp and settle for the suggestion that meets most of them. we can classify the variables in the con-
jecture as follows. those variables which occur only in recursive positions will be called unflawed and those that occur in non-recursive positions will be called flawed. those variables for which there is a schema that subsumes all the schemata of its recursive occurrences will be called compatible and the rest will be called incompatible. thus only unflawed-compatible variables completely meet the preconditions  1 . note that an instantiation of rtcrm can only be given for compatible variables. suggestions are preferred in the order: unflawedcompatible  flawed-compatible  unflawed-incompatible  flawed-incompatible. ideally  our method fitting process would be flexible and accept partially fitting methods if fully fitting ones are not available. however  in the current implementation we have adopted the short term expedient of building this flexibility into the preconditions themselves. see  bundy et al.  1  for details. 
1 	the use of lemmas in rippling-out 
the step tactic  which is restricted to using rewrite rules based on the step formula of recursive definitions  is not always strong enough to enable ripple out to succeed. consider the following expression: 

where x is defined by: 

step applies to this once  to produce the expression: 

but the argument of even is not of the form s s ...    so step will not apply a second time; ripple out will fail what would permit another ripple  moving even adjacent to x x y  is the application of theorem  1  as a rewrite rule1  i.e. applying: 
		 1  
produces the expression: 

which contains even x x y  as required. 
　in general  we want to extend step to a new tactic wave  which uses rewrite rules of the form: 
		 1  
where u ranges over object-level variables  f ranges over object-level functions and b and c range over objectlevel terms. we will call rewrite rules of the form  1  wave rules  where f u  is the wave function  u is the wave argument and b u  is the wave term by analogy to recursive function  recursion argument and recursion term  respectively. the wave terms in wave rules are 
　1 this definition of flawing corresponds in spirit to the boyer-moore definition  but differs from it in minor ways. 
　1  recall that the proof is constructed by backwards reasoning  so that an implication of the form p -  q should be used as a rewrite rule q =  p. 
bundy  van harmelen  hesketh  smaill and stevens 	1 
　
underbraced and the wave functions are overbraced. the braces in rule  1  above show that it is a wave rule in two ways: one for each occurrence of the wave function on the right hand side of the rule. the wave tactic allows us to ripple out through non-recursive functions  non-recursive argument positions of recursive functions  and recursive argument positions that do not contain the appropriate constructor functions. 
　step formulae of recursive definitions are usually wave rules. in addition  each theorem that oyster proves can be tested to see if it has the right form and  if so  it can be stored as a wave rule for future use. 
1 	extending recursion analysis 
now that we have generalised ripple out beyond the use of step formulae of recursive definitions  it is natural to consider generalising the preconditions of the ind strat method to meet the new opportunities this provides. 
   the key observation is that the induction term does not have to be derived from just the recursion terms of recursive functions in the conjecture. more generally  it can be derived from some wave rules' wave terms. we require only that its insertion would cause those wave rules to match subexpressions of the induction conclusion. the recursion terms of recursive functions are candidates  but they are not the only ones. 
　to illustrate this  consider the conjecture that every natural number can be factorized into a product of primes. we will formalise this as: 

where prod is defined by: 

note that this definition is not based on a pxx' recursion. now consider the rewrite rule: 
		 1  
as indicated by the braces  it is a wave rule whose wave function is prod tl  = u and whose wave term is hd x u. prod xl  - x in the conjecture  1  matches this wave function and has a variable  x  in the wave argument position. if induction used the induction term  p x x'  suggested by this wave term then the wave rule would ripple the induction term out one wave. this suggests a form of induction that substitutes p x x ' for x  in wnich x' is the induction variable. the pxx' form of induction: 

 has just this property. the only other raw induction suggestion that clam can extract by matching available wave rules to this occurrence of x  is the very similar  and also successful  x' x x  schema. there are no other 
1 	automated deduction 
occurrences of x in conjecture  1   so no other raw induction suggestions to consider. 
　using this p x x' induction the first wave of rippling out is done with the wave rule  1   as expected. the remaining rippling out is done with some standard logical manipulation rules. the induction conclusion is then identical to the induction hypothesis  so fertilize finishes the proof of the step case. 
　the generalisation of the preconditions   1   of ind strat required in order to use wave rules to suggest inductions is: 
		 1  
where wave rule  fterm!  x  b'  means that there is a wave rule with wave function  fterm  wave argument  x  and wave term  b'  e.g. since  1  is a wave rule with wave function prod ul  = u  wave argument u and wave term hd x u  then wave rulelprod ul  = u u hdxu   cf. recursive {even{u  u s{s u    . 
　these preconditions check that each occurrence of x is in the an argument position of a function for which there is a matching wave rule  and that there is a term  1  that subsumes each of the wave terms  b';  of these rules. b then determines the induction schema and x is the induction variable. 
　if the only wave rules known to clam are step cases of recursive definitions then preconditions  1  generate exactly the same final induction suggestions as preconditions  1 . if clam-oyster proves theorems that have the form of wave rules and if the existence of these rules is recorded by wave rule meta-assertions then additional induction suggestions are possible. however  in practice  the probability that a wave rule will match each conjecture is quite low  so only a few final induction suggestions will be made even when a large number of wave rules and induction schemata are available. several of these few suggestions may succeed - leading to different proofs of the conjecture - so that some of the increase in search space is benign. our experience so far is that the new preconditions substantially increase the number of con-
jectures for which clam can find proof plans  without substantially increasing the size of the search space1. this situation may change as the number of wave rules increases  but there is no reason at present to suppose that it will. 
1 	implementation and results 
the ideas discussed in this paper have been implemented in and tested on the clam-oyster system. this required the following modifications. 
  the only primitive induction schemata provided in oyster are 1 step schemata for natural numbers  
   1 although search time does increase  since non-matching wave rules must be tried and rejected. 

  the oyster tactics and methods have been up-graded to use these more general forms of induction. the step tactic and method have been replaced with the wave ones. 
  we have added a new tactic  existential  for instantiating existentially quantified variables. it substitutes a meta-variable for the existential variable when eliminating the existential quantifier during the planning process. unification then instantiates this to an appropriate object-level term as the planning process progresses  e.g. during rippling-out. when the ind strat tactic is applied this object-level term is substituted for the existential variable at the time of existential quantifier elimination. 
  the preconditions of the ind strat method have been upgraded to those given in meta-formula  1  above  but with modifications to permit partial fitting where total fitting is not possible. 
  plans and proofs for the even+ theorem   1   and the prime factorization theorem   1   have been automatically generated. fitting the new preconditions of the ind strat generates the recursion analysis described above for each of these two examples. 
  the improvements in the methods and tactics has enabled simpler proofs to be found for some theorems. for instance  the proof of the commutativity of times  x x y = yx i  which previously required 1 nested applications of s x  induction  now only requires 1 nested inductions  1 of which are x1 + x  inductions. 
1 	conclusion 
we have analysed recursion analysis by showing how the inductive proofs obtained by the boyer-moore theorem prover have a common overall shape  and how recursion analysis selects an induction schema and variable that increases the chances that a proof of this shape will be found. we have shown how to describe this overall shape using the technique of proof plans and  hence  both how to rationally reconstruct recursion analysis within proof plans and how to explain its success formally. our analysis has suggested a natural extension to recursion analysis which frees the choice of induction schema from the forms of recursion present in the original conjecture. in fact  recursion need not be present at all for induction to be used. this is vital if we are to specify programs without making any premature procedural committment  e.g. by anticipating the form of recursion to be used in the program  and yet have this procedural commitment made during the synthesis process. 
　the importance of this rational reconstruction of recursion analysis is illustrated by the following points. 
  the neat way that it relates flaw checking  subsump-tion checking and merging as different aspects of fitting the same preconditions. 
  the way in which it suggests an interesting ex-tension of recursion analysis  enabling our theorem prover to find proofs that are beyond the capacity of bmtp. 
　we have implemented a theorem proving system  clam-oyster  based on our rational reconstruction and shown that this system can find proofs which are beyond the ability of bmtp. whether this success is brought at the price of an unacceptable increase of the planning search space it is not possible to tell without further emirical testing. the initial empirical results reported in bundy et a/.  1  are very encouraging  however. the planning search space on simple examples is several orders of magnitude smaller than the object-level search space  and the ratio improves with more complex theorems. 
　the research reported above is in the context of recursive functions with a single recursion variable and a single step formula. this has served to simplify the discussion but the underlying ideas are not limited to such functions. we plan to extend the tactics and methods to more general recursive functions. only then will we be able to test clam-oyster on the full list of conjectures proved by the bmtp and similar theorem provers. 
