 
　　　the study of v i s i o n   in both man and machine  is viewed as the discovery of c o n s t r a i n t s . computa t i o n a l constraints often imply assumptions necessary for achieving a problem's s o l u t i o n   while psychological and neurophysiological ones r e s t r i c t the manner in which such solutions can be achieved. these ideas are i l l u s t r a t e d by several examples of research related to the early processing of visual information. the development of the paper takes 
place h i s t o r i c a l l y   s t a r t i n g with helmholtz and mach  as w e l l as comceptually  from the concrete to the abstract  and anatomically  from the eye to the 
b r a i n . 
	i 	introduction 
       computer v i s i o n and human perception - two r e a l i z a t i o n s of the process of seeing  one embedded in computers and the other in people. clearly there is a metaphorical level in which these two a c t i v i t i e s have much in common. but is it only a metaphorical l e v e l   with fundamental differences always keeping them separate  or is there r e a l substance to the metaphor  so t h a t each side could benefit from i n t e r a c t i n g w i t h the other. we s h a l l argue  in t h i s paper  for the l a t t e r . our p o s i t i o n is t h a t   since the process of v i s i o n is an immensely complex one  theories at many d i f f e r e n t levels of abstraction must be u t i l i z e d . as marr and poggio  1  have s t a t e d :  the cns needs to be understood at four nearly independent levels of d e s c r i p t i o n :  1  that at which the nature of the computation is expressed;  1  that at which the algorithms t h a t implement a computation are chara c t e r i z e d ;  1  t h a t at which an algorithm is committed to p a r t i c u l a r mechanisms; and  1  t h a t at which the mechanisms are r e a l i z e d in hardware.  t r a d i t i o n a l l y   computer v i s i o n operates at the computational level of d e s c r i p t i o n   while the study of human perception has been more concerned w i t h input/output or neurophysiological d e s c r i p t i o n s . 
　　　investigations of the problems of v i s i o n rarely y i e l d complete t h e o r i e s . rather  t h e i r c o n t r i -
bution r e s u l t s in the 	formulation of constraints for shaping any theory. 	such constraints stand 
whether or not the parent t h e o r e t i c a l framework 
the preparation of t h i s paper was supported by the national sciences and engineering research council. 
harold hubschman  peter sander  and demetri terzopoulos provided c o n s t r u c t i v e   c r i t i c a l   and ocassionally complimentary comments. 
changes. the e v o l u t i o n of our understanding of these constraints is the p r i n c i p l e theme running through t h i s paper; t h i s is what we take to be progress in understanding v i s i o n . as we s h a l l i l l u s t r a t e   constraints have been discovered that f a l l i n t o three main categories: computational  
behavioural  and implementational. 
　　　computational constraints are the most abs t r a c t . given a statement of a v i s u a l problem  these are the constraints t h a t must be in e f f e c t for a p a r t i c u l a r s o l u t i o n of that problem to be c o r r e c t . mathematically they are required to transform underdetermined s i t u a t i o n s i n t o determined onec/. in the broadest sense  the need for constraints can be seen from the image formation process. a view of a three-dimensional scene is projected onto our two-dimensional r e t i n a s ; to recover a description of the scene  somehow the loss in t h i s degree of freedom must be overcome. this requires the i n t r o d u c t i o n of c o n s t r a i n t s . discovering what these constraints can  and should / be  is a subtle process; instances of it w i l l occupy 
much of t h i s essay. for example  each ray of light impinging on our retinas is obtained from a c e r t a i n product of i l l u m i n a t i o n and surface r e f l e c t a n c e . when t h i s r e l a t i o n s h i p is expressed mathematically  there are c l e a r l y i n f i n i t e combinations that could s a t i s f y i t . but  if i l l u m i n a t i o n is assumed to be constant and d i s t a n t   then the pattern of perceived i l l u m i n a t i o n becomes p r o p o r t i o n a l to surface r e flectance. and  if the surface is f u r t h e r assumed to be uniformly r e f l e c t i v e   then it becomes p r o p o r t i o n a l to surface o r i e n t a t i o n . as each of these assumptions is understood as a constraint on the s o l u t i o n   a u n i t of progress is made toward understanding which constraints could be active for the general v i s i o n problem. 
　　　the other two classes of constraints manifest themselves less as assumptions and more as r e s t r i c t i o n s . they specify what the v i s u a l system has available for implementing s o l u t i o n s   as w e l l as intermediate states encountered while achieving them. they may be characterized in terms of the available  machinery   as in the case of neurophysiology  or they may be characterized behaviourl y   as in the case of psychology. 
　　　because of the complexity of v i s i o n   it is our p o s i t i o n that each of these d i f f e r e n t kinds of constraints is needed  or the l i k e l i h o o d of d i s covering the correct explanation is seriously diminished. without the computational theories and c o n s t r a i n t s   one is faced w i t h the problem of i n f e r r i n g what staggering numbers of neurons are 

1 

doing  without a suitable language for describing e i t h e r them or t h e i r scope. the problem is perhaps even more d i f f i c u l t than i n f e r r i n g what a d i g i t a l computer is doing in terms of the e l e c t r o n i c s . imagine  for example  t r y i n g to i n f e r the scheduling algorithm  or even the need for a scheduler or operating system  without our present computational background. as another example  r e c a l l chomsky's c l a s s i c a l c r i t i q u e o f skinner's behaviourism: t r y to express the notion of attack underlying a p a r t i c u l a r chess strategem in terms of conditioned c o l l e c t i o n s of neurones. to appreciate the need for the other  behavioural c o n s t r a i n t s   j u s t r e c a l l how many d i f f e r e n t techniques there are for solving systems of p a r t i a l d i f f e r e n t i a l equations  or optimization problems. such constraints could p a r t i c i p a t e in the decision to use a simplex or a gradient algorithm  running on a p a r a l l e l or a sequential machine. 
　　　while constraints shape theories  they rarely do so to the point of uniqueness. such underdetermined theories specify competency  or sufficency of a system; they state what could be happening   not necessarily what is happening. as a d d i t i o n a l constraints are added  however  the theories become sharper and more focused  p a r t i c u l a r l y when the constraints span several descriptive l e v e l s . in the l i m i t   we b e l i e v e   enough constraints w i l l become known at each l e v e l so that a complex of s u f f i c e n t theories w i l l become  or i n s p i r e   the correct one. 
       in summary  the other general points of the paper are that 
       1. computer vision can provide a language for posing theories of v i s u a l information processing  and such languages are e s s e n t i a l ; 
       1. computer vision can provide a c a p a b i l i t y for carrying out experiments that are e s s e n t i a l l y impossible to perform without confounding w i t h i n the human v i s u a l system; 
       1. evidence about human perception can provide clues for computer v i s i o n that would not be obvious otherwise  and vice versa; 
       1. theories at d i f f e r e n t descriptive levels are i n s t r u c t i v e   if not necessary  to r e s t r i c t experimental and t h e o r e t i c a l scope at a l l levels of explanation  whether one is concerned with computer or human perception or both. in t h i s paper  however  we s h a l l p r i m a r i l y be concerned with human perception. 
　　　while some of the above points have taken on new importance given the current development of computation  the most basic theme -- the necessity for m u l t i p l e - l e v e l s of description - is a classi c a l one. this theme is evident when one looks across the w r i t i n g s of the great v i s i o n s c i e n t i s t s   and we s h a l l i l l u s t r a t e it with b r i e f  and perhaps overly s i m p l i f i e d   views of hermann von helmholtz and ernst mach. the progression that we s h a l l f o l low w i l l be both h i s t o r i c a l and conceptual  with helmholtz portrayed as a physicist and mach as a neural modeler. we s h a l l then return to helmoltz  because of his strong p o s i t i o n on the role of  unconscious inferencing  in perceptual processing. conceptually we s h a l l progress from the eye to the 
b r a i n   and the concrete to the abstract. the e x i 
amples w i l l be chosen from early v i s u a l informat i o n processing. the current paradigm for v i s i o n we take to be a loose  but l o g i c a l   development from the e a r l i e r p o s i t i o n s   although it does subs t a n t i a l refinement of them. helmholtz and mach were both serious philosophers  p h y s i c i s t s   and mathematicians  as w e l l as psychologists. thus t h e i r views about vision spanned many of the des c r i p t i v e levels to which we have r e f e r r e d . 
1.  the earliest constraint 
physical imperfections in the eye 
　　　parmenides  ca. 1 b.c.  explained the e x i s t ence of v i s u a l i l l u s i o n s by observing;  the eyes and ears are bad witnesses when they are at the service of minds that do not understand t h e i r 
language . 	we shall begin our discussion of v i s i o n 
with a discussion of the e a r l i e s t possible 
 language  in the visual understanding process - the optics of the eye. as a medium  we s h a l l use the mueller-lyer i l l u s i o n   one of the most extensively-studied  but s t i l l not completely understood  geometric i l l u s i o n s . and h. von helmholtz w i l l provide the conceptual viewpoint for our i n v e s t i g a t i o n . 
	in his t r e a t i s e on physiological optics 	   
helmholtz sketched a theory of v i s i o n in which the eye acted as a transducer of l i g h t i n t o the nervous system  which then performed  unconscious inferences  in order to compose i n t e r n a l versions of percepts. such unconscious inferences we s h a l l take to mean computations  a notion that helmholtz was  unfortunately  rather vague about. the only language that he had for t a l k i n g about them was that of  conscious inferences   or the logic of premises and conclusions. other portions of h i s investigations were incredibly concrete and c l e a r   however  such as his study of the transduction properties of the eye  and it is t h i s with which we s h a l l now be concerned. perhaps inspired by his work in physics  he countered a rather widespread b e l i e f that the eye was a  perfect  o p t i c a l instrument by actually measuring i t s o p t i c a l p r o p e r t i e s . he observed  as is commonly known today  that the eye is far from p e r f e c t . it e x h i b i t s the many d i f f e r e n t forms of spherical aberration and d i s t o r t i o n to which p h y s i c a l l y - r e a l i z e d systems are susceptable. 
　　　the r e s u l t of such o p t i c a l imperfections in the eye is that images do not f a l l on the r e t i n a in perfect focus  but are b l u r r e d   regardless of how well the lens is functioning. helmholtz 
looked for perceptual consequences of such b l u r r i n g   and found many  one of which he believed to be the mueller-lyer i l l u s i o n ; see f i g . 1. his reasoning was as follows. on a figure such as the mueller-lyer  the areas between the lines forming the acute angles w i l l be f i l l e d in   i . e .   blurred  more than the areas w i t h i n the obtuse ones  t h e r e by stretching the lines i n t o the acute angles more than the obtuse ones. such a d i s t o r t i o n is p r e cisely in the d i r e c t i o n of the i l l u s i o n   and was  for helmholtz  i t s causal explanation. 

1 

　　　such is v i s u a l t h e o r i z i n g of the best s o r t . a problem is posed  what are the o p t i c a l properties of the eye   and solved in a t h e o r e t i c a l fashion that is consistent with empirical data  the s p h e r i cal abberation was a c t u a l l y measured . f i n a l l y   the theory was applied to explain observed phenomena  such as the mueller-lyer i s s u s i o n   . 
　　　helmholtz was correct in observing that the eye is an imperfect o p t i c a l instrument. but he was wrong  in p a r t   in t h a t h i s explanation of the mueller-lyer i l l u s i o n cannot account for the e n t i r e e f f e c t . this has been determined very recently using an elaborate o p t i c a l technique  an a r t i f i c i a l p u p i l   to p r o j e c t a h i g h l y focused image onto the r e t i n a  1 . such techniques indicate that o p t i c a l b l u r r i n g accounts for roughly 1% of the i l l u s o r y e f f e c t . nonetheless  the constraints stand as cont r i b u t o r s .  we s h a l l discuss other contributions to the mueller-lyer l a t e r in the paper.  
	1. 	lateral inhibition and neural models 
　　　we now t u r n from a phenomenon of b l u r r i n g to one of sharpening  from explanations in terms of o p t i c a l mechanisms to ones embodied in neural networks  and from helmholtz to ernst mach. the phenomenon of sharpening t h a t we s h a l l discuss is commonly known as mach bands - it is the addition of subjective b r i g h t and dark l i n e s  bands  on e i t h e r side of an i n t e n s i t y edge  see f i g . 1   . such bands indicate that the eye responds not only to image i n t e n s i t i e s   but also to t h e i r   f i r s t and second  d e r i v a t i v e s . 
　　　mach bands give a clear i n d i c a t i o n that the subjective impression of brightness and of contrast is h i g h l y dependent on s p a t i a l context. that i s   our impressions of brightness and of contrast are not isomorphic with the i n t e n s i t y of l i g h t impinging on our r e t i n a s   but rather are derived - or computed - from i t . 
　　　mach's t h e o r e t i c a l p o s i t i o n was based on a b e l i e f that psychophysical laws  such as the ones underlying brightness and contrast phenomena  had t h e i r proper explanation in terms of properties of neural networks  not in terms of pure physics or purely 'psychical e v e n t s ' .  the psychophysical law h o l d s . . . f o r the r e l a t i o n of the primary stimulus and the l a s t nerve e x c i t a t i o n with which the conscious sensation goes. indeed  t h i s is p r e c i s e l y 
because the e x c i t a t i o n s in the sense organs are 
f i l t e r e d through a complicated web of nerves.   1-1  
　　　the p a r t i c u l a r s of mach's explanation were posed mathematically in terms of  a r e c i p r o c a l i n t e r a c t i o n of neighboring areas of the r e t i n a    1 . he c i t e d  then  current neuro-anatomical data by r i t t e r t h a t postulated a regular arrangement of c e l l s on the r e t i n a   and characterized the function of these c e l l s mathematically. thus he was concerned w i t h possible constraints from the  wetware*. and he postulated t h a t the r e s u l t of the neural i n t e r a c t i o n s between these c e l l s was a  sensation surface  on which the brightness e f f e c t s were present. thus mach  in discussing such surfaces  was t a l k i n g d i r e c t l y about representations. 
　　　while mach was able to i n f e r the nature of processing taking place immediately a f t e r the r e t i n a   it was not u n t i l a revolutionary innovation in neurophysiology - the development of microelectrodes for single c e l l recording - t h a t his inferences could be v e r i f i e d experimentally. this was f i r s t done in the eye of the horseshoe crab ' l i m u l u s '   and has led to much more accurate mathematical models. such models are said to e x h i b i t l a t e r a l i n h i b i t i o n   or a regular structure in which the response at a p a r t i c u l a r r e t i n a l point is derived from e x c i t a t o r y contributions at t h a t p o i n t together w i t h i n h i b i t o r y i n t e r a c t i o n s from neighboring points - see f i g . 1. notice  in p a r t i c u l a r   the regular neural a r c h i t e c t u r e for im-
plementing l a t e r a l i n h i b i t i o n   in which the same ' l o c a l ' structure is repeated across the s p a t i a l array. viewed s p a t i a l l y   the l a t e r a l i n h i b i t o r y sturcture looks c i r c u l a r l y symmetric  with an exc i t a t o r y c e n t r a l area surrounded by a negative  or i n h i b i t o r y   area. or  in other words  the response at a r e t i n a l point is a function of the context around that p o i n t . 
　　　an essential aspect of t h i s context is the presence of i n t e n s i t y changes in the v i s u a l array. such changes are important because they often i n dicate the presence of physical object contours  one of the most fundamental constraining r e l a t i o n ships between the physical and the v i s u a l worlds. in f a c t   the f u n c t i o n a l significance of mach bands has often been a t t r i b u t e d to t h e i r edge-enhancement e f f e c t -- if we are to navigate through the p h y s i cal world on the basis of sensory i n f o r m a t i o n   we c e r t a i n l y need to locate object contours. but t h i s kind of explanation is pure teleology. it almost implies t h a t there should be a l i t t l e  homonculus  inside our heads whose job was to look at the v i s ual   r e t i n a l   image to locate edges. enhancement would then make his job easier. 
　　　lateral i n h i b i t i o n may be one of the most u b i quitous mechanisms in b i o l o g i c a l v i s i o n systems. it plays a clear role in regulating the dynamic range of the eye  and otherwise performing a sort of l o c a l sharpening  or maxima s e l e c t i o n   at the neural l e v e l . but these are a l l very lowlevel functions; whether it a c t u a l l y helps the 
human v i s u a l system to f i n d edges s t i l l remains an open question. 
	1. 	edges and features: 	can they be detected  
　　　neurophysiology  in addition to v e r i f y i n g 
　　　l a t e r a l i n h i b i t i o n i n c e r t a i n animals  also i n spired a revolutionary theory of how the early v i sual system functions. in a s t r i k i n g series of observations  hubel and wiesel  measured the r e ceptive f i e l d s o f d i f f e r e n t c e l l s i n the l a t e r a l geniculate nucleus and the v i s u a l cortex of the cat and monkey.  the receptive f i e l d is the arrangement of r e t i n a l c e l l s - rods and cones - which  when stimulated w i t h a pattern of l i g h t   influence the a c t i v i t y of the c e l l under measurement. the l a t e r a l geniculate nucleus is the f i r s t major processing s t a t i o n between the r e t i n a l ganglia and the v i s u a l cortex.  the structure of these receptive f i e l d s  with respect to c e r t a i n of t h e i r d e f i n i n g c h a r a c t e r i s t i c s   was s t r i k i n g ;  roughly four 

1 

classes of c e l l s can be d i s t i n g u i s h e d   in a series of ascending c o m p l e x i t y . . . these are termed ' c i r c u l a r l y symmetric'  ' s i m p l e '   'complex'  and 'hypercomplex*. we assume that c e l l s at each stage receive t h e i r major input from c e l l s at the previous stage  w i t h the c i r c u l a r l y symmetric c e l l s r e ceiving t h e i r inputs predominantly from geniculate c e l l s . c i r c u l a r l y symmetric c e l l s   as t h e i r name i m p l i e s   show no preference to any o r i e n t a t i o n of l i n e s   and indeed  seem s i m i l a r in t h e i r propert i e s to geniculate c e l l s . simple c e l l s are the f i r s t in the hierarchy to show o r i e n t a t i o n s p e c i f i c i t y   so that the rearrangements responsible for o r i e n t a t i o n s p e c i f i c i t y are presumed to take place between the c i r c u l a r l y symmetric and the simple c e l l s . a simple c e l l responds to an o p t i m a l l y orientated l i n e in some narrowly defined p o s i t i o n : even a s l i g h t displacement of the l i n e to a new pos i t i o n   without change in o r i e n t a t i o n   renders the l i n e i n e f f e c t i v e . a complex c e l l   on the contrary  is probably j u s t as s p e c i f i c in i t s o r i e n t a t i o n r e quirements as the simple c e l l   but is far less part i c u l a r about the exact p o s i t i o n i n g of the l i n e hypercomplex c e l l s   f i n a l l y   resemble complex c e l l s in a l l respects but one: extending the l i n e beyond the region from which responses are envoked produces a marked reduction or complete a b o l i t i o n of the response.   1  p. 1   . the structure of these receptive f i e l d s is as shown in f i g . 1   and the i n t e r p r e t a t i o n of the simple c e l l s by the psycholog i c a l community was immediate:   i t takes l i t t l e imagination to describe these simple c o r t i c a l f i e l d s as edge detectors and l i n e detectors.  h b   p . 1 . 
　　　while such neurophysiological observation is s t r i k i n g   and c e r t a i n l y introduces strong cons t r a i n t s on what the v i s u a l system is doing  as w e l l as how it is doing i t   is the jump from observation to a theory of edge and l i n e detection correct  that i s   do the simple c e l l s detect lines and edges  we pose t h i s conjecture to h i g h l i g h t one of the main contributions of computer v i s i o n to the understanding of human perception - in a d d i t i o n to providing c o n s t r a i n t s   it provides us w i t h a means of t e s t i n g them. in t h i s case  computer v i s i o n can test a version of the above conjecture: are simple c e l l s a s u f f i c i e n t mechanism for detecting lines and edges  the answer  it turns out  is no  at least for the manner in which our i n t u i t i o n s 
f i r s t i n d i c a t e d . while simple c e l l s can detect lines and edges in c e r t a i n clearcut s i t u a t i o n s   they are not s u f f i c e n t to accomplish the task in a r b i t r a r y ones. see f i g . 1. such computational experiments also reveal the problem w i t h simple c e l l s and other such  feature-detector  theories - t h e i r response is ambiguous. they respond not only to lines and edges  but to other 'noise' patterns as w e l l . as we s h a l l show  however  it does look as if they are involved in the edge f i n d i n g p r o cess  but are not the whole s t o r y . 
	1l 	intensity edges and physical contours 
　　　to more properly appreciate the complexity of the edge-finding problem  consider how the underl y i n g physical events constrain the image i n t e n s i t i e s . a physical edge can be said to e x i s t if there is a change in surface r e f l e c t a n c e   
o r i e n t a t i o n   or i l l u m i n a t i o n . the r e s u l t a n t image p r o f i l e s have been examined by binford   who found  for edge-like patterns  that there are three 
primary classes: step  roof  and spike. thus edges come in many d i f f e r e n t guises  or f u n c t i o n a l forms  certain properties of which can be r e l a t e d back to physical configurations. horn  found  e . g .   that step edges are l i k e l y to correspond to occluding surface boundaries  but t h a t these i n verse constraints are rather weak ones. thus the search for a s i n g l e   p e r f e c t   one-step edge detector  l i k e the simple c e l l s   begins to feel e l u s i v e . furthermore  edge  events   such as surface r e flectance or o r i e n t a t i o n changes  can take place at many d i f f e r e n t scales . highlights are usually sharp  and shadows b l u r r y . an i n t e n s i t y gradient a r i s i n g from a curved surface and a single l i g h t source w i l l span a much wider physical distance than the abrupt s h i f t caused when one surface occludes another. any general purpose edge-finding scheme must take such functional and scale dependence i n t o account. 
　　　to make matters worse  there are s t i l l other confounding constraints. if we view the c i r c u l a r l y symmetric center surround c e l l as a discrete approximation to a laplacian   i . e .   second s p a t i a l derivative  operator  then numerical analysis t e l l s us that the more smoothing incorporated i n t o the operator  the more stable i t s performance. such smoothing is necessary to counteract many forms of ' n o i s e '   such as that which is introduced by the sampling process. but as more smoothing is i n c o r porated  the l i k e l i h o o d of evaluating the operator across an image of d i s t i n c t   but small  physical edges increases. such events make the response of the operator even less r e l i a b l e . 
　　　one s o l u t i o n to these c o n f l i c t i n g c o n s t r a i n t s   developed for computer vision systems  is the use of hierarchies of operators at d i f f e r e n t sizes   i n c r e d i b l y   it now seems that a form of t h i s solution is used by the human v i s u a l system as w e l l . a rather large body of psychophysical evidence  beginning with the work of campbell and robson  1    and summarized i n t o a clean d e s c r i p t ive theory recently by wilsen and bergen 1 i n dicates that v i s u a l information is decomposed  very e a r l y   i n t o a number  perhaps 1 or 1  of separate channels  each of a d i f f e r e n t s p a t i a l r e s o l u t i o n . the finest such channel carries informa t i o n l i m i t e d by the actual placement of receptor c e l l s in the fovea  while the broadest carries highly smoothed information. marr and h i l d r e t h  have used t h i s observation  together w i t h the observed properties of the f i r s t of the hubel/ wiesel c e l l s  the c i r c u l a r y symmetric ones   to propose a new theory of how the human v i s u a l system actually begins to f i n d edges. based on the assumption that the f i r s t stage of edge f i n d i n g should be d i r e c t i o n a l l y i n s e n s i t i v e   they proposed a f i r s t stage of the edge finding process based on operators that model the channel b l u r r i n g followed by the laplacian; an image of such an operator is shown in f i g . 1. note that there is a hierarchy of f i v e such operators. the response of these operators  since they correspond to second d e r i v a t i v e s   the responses across edges are zero crossings  is shown in f i g . 1. 

1 

	i i . 	further consequences of  neural  blurring 
　　　the marr/hildreth zero-crossing scheme makes e x p l i c i t assumptions about the existence of dist i n c t channels  each of which implements a c e r t a i n degree of b l u r r i n g . our b e l i e f in the existence of these channels would c e r t a i n l y be strenghtened if we could f i n d other perceptual e f f e c t s that were also consistent w i t h such b l u r r i n g . the o r i g i n a l conjecture was in fact based on a wealth of such e f f e c t s - contrast s e n s i t i v i t y in the perception of g r a t i n g s . these  however  are h i g h l y t e c h n i c a l   and our present goal is to search for more r e a d i l y observable ones. 
　　　the f i r s t example is one that we are already f a m i l i a r w i t h - the mueller-lyer i l l u s i o n . we have discussed helmholtz's observations about b l u r r ing and have noted that they can only account for a small f r a c t i o n of the i l l u s o r y e f f e c t . we now have another possible source of b l u r r i n g - the s p a t i a l frequency l i m i t e d channels in the e a r l y v i s u a l system. experiments in our laboratory indicate that the smallest amount of channel b l u r r i n g possible  t h a t from a h y p o t h e t i c a l channel for high v i s u a l acquity  would correspond to approximately 1% of an i l l u s o r y e f f e c t for a p e r f e c t image  - see f i g . 1. the larger channels would  of course  imply more of a d i s t o r t i o n in the d i r e c t i o n of the i l l u s i o n . during normal viewing of the i l l u s i o n   it seems clear t h a t the o p t i c a l and channel b l u r r ings should be a d d i t i v e . 
　　　the next example is also v i s u a l l y s t r i k i n g . it can be obtained by taking a normal checkerboard p a t t e r n and s h i f t i n g every other row a f r a c t i o n of a cycle - see f i g . 1. note that the l i n e s of the checkerboard no longer appear s t r a i g h t ; r a t h e r   they are skewed s l i g h t l y o f f the h o r i z o n t a l . this phenomenon was f i r s t studied by munsterburg   a f t e r it was brought to his a t t e n t i o n by a weaving i n s t r u c t o r who could not understand why h i s students could not weave a s t r a i g h t l i n e i more recentl y   a variant was discovered by gregory  1 . 
       related phenomena were known to helmholtz  who r e f e r r e d to t h e i r cause with the term   i r r a d i a t i o n   . can our smoothing and d i f f e r e n t i a t i o n constraints be held accountable again  the answer is yes - see f i g . 1. the zero-crossing contours describe trapezoids  not rectangles; smoothing followed by d i f f e r e n t i a t i o n does introduce d i s t o r t i o n of the r i g h t k i n d . conversely  if we were to avoid the smoothing and d i f f e r e n t i a t i o n c o n s t r a i n t s   e . g .   by presenting the cafe w a l l image as a random dot stereogram  1   then we would expect the i l l u s i o n not to be present. experiments in our laboratory  with a  1 x 1  d i g i t a l stereogram  do indicate t h i s to be the case. 
　　　as a f i n a l example  we can pose a converse conjecture. if edge events are signaled by i n t e n s i t y arrays whose p r o f i l e changes  then  if the p r o f i l e were changing slowly enough  the d i f f e r e n t i a l operator should miss i t . i n p a r t i c u l a r   the channel theory allows an estimate of the largest operators  so that we can derive a lower bound for perceivable edge p r o f i l e s . the constraint t h a t edge p r o f i l e s change more slowly than t h i s may 
underlie some of the c l a s s i c a l lightness i l l u s i o n s   such as the cornsweet-1*brien  . we have begun to investigate t h i s conjecture in our laboratory  and preliminary t e s t s seem to h o l d . in any case  evidence seems to be accumulating in the r i g h t d i r e c t i o n . 
　　　but a l l is not done. while the zero crossings give a strong i n d i c a t i o n of where some edges l i e   and separate some scale e f f e c t s   they do not r e spond always  and only  to edges. and the r e sponses from the d i f f e r e n t size operators have to be u n i f i e d i n t o a single coherent edge d e s c r i p t i o n   rather than the series of decomposed estimates.  this is not to say that there is no information in the d i f f e r e n t channels  or t h a t t h i s decomposed i n formation is not u s e f u l . in f a c t   we s h a l l see examples of where t h i s is p r e c i s e l y the case.  to state matters another way  we cannot take the r e sponse of the l o c a l operators as d e f i n i t i v e ; the responses s t i l l need to be i n t e r p r e t e d . furthermore  even if we could f i n d perfect l o c a l i n d i c a t i o n s of where edges l i e   they s t i l l have to be grouped   i . e .   joined up  i n t o longer contours. in the case of the cafe wall i l l u s i o n   for example  the sides of the trapezoids have to be grouped i n t o long l i n e s . we s h a l l examine possible approaches to grouping following a discussion of m t e r p r e t a t i o n . 
1. interpreting the zero crossings 
　　　while the marr/hildreth operators answer some of the problems associated w i t h the l o c a t i o n of i n t e n s i t y changes  they are only a f i r s t step t o ward the s o l u t i o n - they do carry information usef u l in t h i s task  but only in the form of a signal or measurement - they must s t i l l be i n t e r p r e t e d j u s t l i k e the simple c e l l s discussed previously. computer v i s i o n has developed a wide range of such i n t e r p r e t a t i o n schemes  two of which we s h a l l now consider through the use of simple c e l l s . the d i f ference w i t h the e a r l i e r discussion of simple c e l l s is t h a t now they w i l l be used to i n t e r p r e t the zero-crossings  rather than i n t e r p r e t i n g the raw i n t e n s i t i e s . in a sense  then  the edge f i n d i n g 
problem has become one of l i n e f i n d i n g . 
　　　we s h a l l take the problem of i n t e r p r e t i n g the zero-crossings to be one of asserting the underl y i n g edge segment signaled by the zero crossings. there may  of course  a c t u a l l y be none. perhaps the simplest such i n t e r p r e t a t i o n scheme begins w i t h the evaluation of the responses of a number of simple c e l l s at d i f f e r e n t o r i e n t a t i o n s centered on a given image p o i n t   and selects the l o c a l o r i e n t a t i o n at that p o i n t to be the one d i f i n e d by the simple c e l l with the strongest response. such an i n t e r p r e t a t i o n scheme is purely l o c a l   and amounts to thresholding  or maxima s e l e c t i o n . it is the kind of computation that can be accomplished  e . g .   by a l a t e r a l i n h i b i t o r y network. because the available information is l i m i t e d in scope  however  i f the strongest response i s u n c e r t a i n   then i t i s not clear how much f a i t h we should place in the r e s u l t of l o c a l maxima s e l e c t i o n . 
　　　a stronger i n t e r p r e t a t i o n strategy would be one in which an external c r i t e r i o n were imposed onto the process: 	s e l e c t   for example  the i n t e r p r e t a t i o n that y i e l d s the minimal t o t a l curvature 

1 

for the edge segments. except for universes such as bubble chamber photographs  however  t h i s cons t r a i n t is too a r t i f i c i a l . human  and most machine  perception must be much more general purpose  1 . another c r i t e r i o n can be obtained by examining the manner in which zero-crossings are imaged through the simple c e l l s . small ones give a response t h a t is i n d i c a t i v e of the presence of l i n e s   but not d e f i n i t i v e   because t h e i r s p a t i a l extent is too l i m i t e d . the larger channels  on the other hand  
have more context but are a b i t too coarse for accurate fine measurements. putting these two sources of information together  however  y i e l d s the c a p a b i l i t y for specifying context  w i t h the larger masks  and d e t a i l s   w i t h the smaller ones. it gives r i s e   in optimization terms  to a c r i t e r i o n in which the small mask responses are i n t e r p r e t e d to make them as consistent as possible with the responses of the larger masks. or  more p r e c i s e l y   the goal of the optimization process can be stated as f o l l o w s : f i n d the underlying pattern which is most l i k e l y to give the measured responses  both small and large 
 . it is i n t e r e s t i n g to note that the development of such a c r i t e r i o n suggests that the channels should increase in size by a factor of two  which is in fact the observed r e l a t i o n between them. also  the development of such computational i n t e r p r e t a t i o n strategies suggests novel roles for the simple c e l l s . for example  it has long been known from the neurophysiology that termination p o i n t s   of lines and edges  are important and probably exp l i c i t . if they are also to be found from the zero-crossings  as would seem l o g i c a l   then we 
would l i k e to suggest t h a t t h i s may be accomplished by using the  edge  mask  or d i r e c t i o n a l f i r s t der i v a t i v e simple c e l l s   to signal zero-crossings that stop. within the context of the above s t r a t egy for i n t e r p r e t i n g the zero-crossings  t h i s would simply amount to adding a few more masks to the same process. stepping back  the role of the masks can thus be said to add empirical constraints to the edge-finging process  p a r t i c u l a r l y to the zerocrossing i n t e r p r e t a t i o n s . 
	1. 	back to unconscious inference 
and hypothesis formation 
     at t h i s point in our discussion we would l i k e to stress a change in our o r i e n t a t i o n . rather than looking at e f f e c t s whose explanation l i e s in a clear mechanism  such as the o p t i c a l imperfections of the eye or neural networks implementing l a t e r a l i n h i b i t i o n   now we are considering much more abs t r a c t questions: how  for example  can the zerocrossings be interpreted  i n t e r p r e t a t i o n is a symbolic a c t   whos'e explanation is most l i k e l y to be found in computational terms. once these are understood  then the l i k e l i h o o d of f i n d i n g the underlying neural implementation would seem much higher. 
     such symbolic acts of i n t e r p r e t a t i o n are an example of what we believe helmholtz had in mind when he spoke about unconscious inference  although they are probably at a much lower l e v e l than he believed necessary. he was concerned that there was a   f a l s e assumption that the mental operations we are discussing take place in an undefined  obscure  halfconscious fashion; that they a r e   so to speak  mechanical operations  and thus subordinate to conscious thought  which can be expressed in language. i do not believe that any difference in kind between the two functions can be proved   1  p. 1 . a more modern champion of t h i s p o s i t i o n is richard gregory  who has regarded perception  as a matter of b u i l d i n g up and t e s t i n g hypotheses   1  p.1   or the induction of hypotheses from information that is often highly underconstraining. 
     if we compare helmholtz  and gregory  w i t h mach  the difference in t h e i r positions  at least so far as they have been portrayed here  becomes apparent: helmholtz was s t r i v i n g towards constraints on the algorithmic s o l u t i o n l e v e l   while mach was s t r i v ing towards constraints on the implementation l e v v e l . this immediately raises the question of r e d u c i b i l i t y between l e v e l s : are theories expressed in the language of computation uniquely expressible in the language of hardware  such as the physics of transducers. this is sometimes p o s s i b l e   as for example the reduction of thermodynamics to s t a t i s t i c a l mechanics   or the computation of the smoothing and d i f f e r e n t i a t i o n operations discussed in sec. 1 d i r e c t l y in terms of models for the x and y c e l l s . this l a t t e r example is e x p e c i a l ly e x c i t i n g   because it d i r e c t l y spans the bridge between two levels  one addressed by computer v i s ion and one addressed by neurophysiology. but in general it is not possible; at some p o i n t   information processing becomes i n t e n t i o n a l   that i s   it depends on the abstract state t h a t the machine is i n . precisely where t h i s occurs in percept i o n is s t i l l an open question  perhaps made more decidable by the p o s s i b i l i t y of computational mode l s . 
     computational models of perception have two essential components - representational languages for describing information  and mechanisms that 
manipulate those representations. one important mechanism is c l e a r l y the creation of d e s c r i p t i o n s   and the i n f e r e n t i a l side of perception makes the need for t h i s e x p l i c i t . constraints may be a c t i v e   as we s h a l l see  on both what is represented  and on how it is manipulated; i . e .   constraints are active on both representations and mechanisms. 
     one of the strongest arguments for having exp l i c i t abstract representations is the fact that they provide explanatory terms for otherwise d i f f i c u l t   i f not impossible  notions. perhaps the clearest example of t h i s is a subjective f i g u r e   or a structure constructed purely from context. 
	1. 	edges can be subjective 
     the edges that we have been t a l k i n g about up to now have a l l had manifestations in the image i n t e n s i t i e s . i t i s possible  however  t o create the impression of edges in contexts where there are no actual i n t e n s i t y differences; see f i g . 1 for examples due to kanisza . such subjective edges  and other figures  are so compelling that apparent i n t e n s i t y differences across them can actually be measured psychophysically. more imp o r t a n t l y   however  these subjective edges appear to be associated w i t h depth changes  as if they were the r e s u l t of i n f e r r e d surface 

1 

d i s c o n t i n u i t i e s 	  1   . 	1. grouping in space and grouping in time 

       should subjective edges  once formed  be considered as the same kind of abstract e n t i t y as i n t e n s i t y edges  that i s   can subjective edges behave in a manner s i m i l a r to i n t e n s i t y edges. the answer is yes  and it can be i l l u s t r a t e d by another geometric i l l u s i o n - the poggendorf. it is present whether or not the defining edges are subjective  see f i g . 1   . in representational terms  then  it would seem that edges ought to be considered as symbolic descriptive e n t i t i e s   whether or not they are subjective. such a p o s i t i o n is further consistent with our previous discussion about i n t e r p r e t i n g the zero-corssings; the r e s u l t of the i n t e r p r e t a t i o n process is the establishment of these symbolic e n t i t i e s . 
　　　once symbolic e n t i t i e s have been created  they can serve as input to l a t e r processes. some of the clearest i l l u s t r a t i o n s of t h i s occur in perceptual grouping. 
	l1. 	grouping and the construction 
of abstract entities 
　　　grouping is a generic name for a class of processes that take l o c a l e n t i t i e s of one kind and j o i n   or combine  or  group  them i n t o another one. it is i l l u s t r a t e d nicely with the following examp l e . consider an array of random dots. if a copy of t h i s dot array is f i r s t rotated and then superimposed on the o r i g i n a l   the resultant pattern is not only one with twice the density of dots; it also e x h i b i t s clear structure   see f i g . 1 . such patterns are called random dot moire patterns. 
　　　how s h a l l we model grouping phenomena  if we view the l o c a l e n t i t i e s as dots  then one p o s s i b i l i t y would be to specify a r e l a t i o n over the dots that describes which ones p a r t i c i p a t e in the agglomerative s t r u c t u r e . technically such a r e l a t i o n can be viewed as a   v i r t u a l l i n e   ; i . e .   a r e l a t i o n t h a t indicates which p a i r s of dots define the apparent c i r c l e s . the process of grouping  in t h i s case  thus r e s u l t s in the establishment of v i r t u a l l i n e s . 
　　　while grouping in the case of random dot moire patterns i s c l e a r l y constructive  t h a t i s   i t imposes structure not present in the i n t e n s i t i e s   
it is important to realize that the agglomeration of l o c a l edge and l i n e segments i n t o long l i n e s and curves is no less so. the e a r l i e s t stages of v i s ual processing decompose the r e t i n a l array i n t o d i s c r e t e   local pieces  at some of which l i n e  or edge  segments are signaled. nor is it necessary for the e n t i t i e s p a r t i c i p a t i n g in the grouping to 
be e x p l i c i t in the i n t e n s i t i e s -- subjective f i g ures can be grouped as w e l l  fig. 1 . the picture of low level v i s u a l processing thus beginning to emerge is one of many levels of descriptive e n t i t y construction and grouping  with i n t e r a c t i o n taking place between processes when warrented by the i n d i v i d u a l constraints undergoing s a t i s f a c t i o n . precisely what these constraints might be  as w e l l as how they may be s a t i s f i e d   are considered with the next t o p i c s . 
　　　the examples of grouping that we have considered up u n t i l now have a l l been grouping in space  such as the l i n k i n g of s p a t i a l l y neighboring dots. an analagous form of grouping takes place in time  and can be used for motion computations. such grouping establishes a correspondence between des c r i p t i v e e n t i t i e s at d i f f e r e n t times   e . g .   derived from temporal image sequences  t h a t   presumably  denote the successive representations of the same physical event. once such a correspondence has been established  it becomes possible to obtain the structure of r i g i d objects undergoing euclidean motions . 
　　　consider  again  a random dot array  t h i s time with the dots moving. since the motion of each dot in the array does not normally influence the motions of the others  ullman  has argued that a viable assumption at the base of the human correspondence process in that a l l motions be considered independently. he has f u r t h e r argued  given t h i s assumption  that the appropriate correspondence r e l a t i o n s between tokens can be found by minimizing a functional   i . e .   a sum  of   a f f i n i t i e s   between tokens. such a f f i n i t i e s are p r o p o r t i o n a l   e . g .   to the length and o r i e n t a t i o n differences between l i n e segments  or to the distance between dots. the motion correspondence process  then  requires machinery for minimizing functional c r i t e r i a   a process to which we shall r e t u r n . 
	1. 	further constraints on grouping 
　　　what are the appropriate models for guiding grouping  since the goal of v i s i o n is to produce descriptions of the three-dimensional structure of the world  it would seem that constraints about t h i s 1-d structure should enter the grouping process. curves in the image are  a f t e r a l l   the 
p r o j e c t i o n of a space curve denoting a physical edge contour. constraints about the d i f f e r e n t i a l geometry of space curves therefore matter  and have been studied by barrow and tenenbaum   1    huffman   stevens   1     and witkin . but the f u l l nature of grouping processes is s t i l l largely unknown. recall t h a t   while discussing the cafe w a l l i l l u s i o n  fig. 1     we produced trapezoids that eventually formed  we claimed  ess e n t i a l data for generating the ' t i l t e d * l i n e s . the mechanism responsible for grouping these local segments i n t o global lines is unclear  but behaviour ly it would appear to be the same as the one responsible for the fraser s p i r a l  see f i g .  . undoubtedly  there is a smoothness constraint l u r k ing somewhere. 
　　　while curves carry clues about physical contours  or the joins between surfaces  information about surface o r i e n t a t i o n i n t e r n a l to these boundaries is carried by t e x t u r e . texture may be viewed as a summary of the descriptions computed by the various grouping processes  some of which may agglomerate tokens across surfaces   1   . it was f i r s t a c t i v e l y studied by a psychologist -j . j . gibson  - as a source of depth informat i o n   and is only now producing algorithms for i n f e r r i n g local surface o r i e n t a t i o n from t e x t u r a l 

1 

cues   1   . for the scope of descriptive structures possibly underlying t e x t u r e   see  1 1 . 
　　　a t h i r d source of information about surfaces comes from stereopsis  our b u i l t - i n range finder. several models have been proposed to describe the human stereopsis model  one cooperative  see sec. 1   1  and the other sequential . this sequential model  by the way  makes use of the zero-crossing information from the separate channels i n d i v i d u a l l y   with the course channels achieving a match before the fine ones attempt t o ; for computational experiments w i t h t h i s matcher  see 
 . the fact that both of these modeling classes work c o r r e c t l y   to a large extent  raises an important question: how can two computational models  so d i f f e r e n t in s t r u c t u r e   both solve the same problem. the answer can be found d i r e c t l y in terms of the levels discussed in the i n t r o d u c t i o n . an ess e n t i a l part of the stereo problem is determining which tokens in each eye's description correspond to the same physical event. once t h i s is determined  trigonometry can be used to obtain depth. the two algorithms perform t h i s match d i f f e r e n t l y . 
but  at a more abstract l e v e l   one can hypothesize the existence of a c r i t e r i o n or suitable f u n c t i o n   underlying the match. the two algorithms are then j u s t d i f f e r e n t ways of optimizing t h i s c r i t e r i o n . the s p e c i f i c a t i o n of t h i s c r i t e r i o n s t i l l remains  as does the refinement of neurophysiological and psychophysical constraints that w i l l permit us to decide between these two algorithmic implementat i o n s   or to derive another one  cf.  . 
　　　stereo is not  however  the only way to obtain d i r e c t information about surfaces. when objects move  or an observer moves  o p t i c a l flow provides 
another r i c h source. 
	1. 	optical flow 
       the discussion so far has moved from i n t e n s i t i e s to abstract descriptions derived from them  such as edges and subjective figures. however  i n t e n s i t i e s carry much more information than we have exploited so f a r   such as information coded i n t o t h e i r temporal changes. such changes give r i s e to a vector f i e l d   which  if could be computed exactly  would be s u f f i c e n t for i n f e r r i n g a great deal about the motion of surfaces . this  by the way  is another of gibson's early c o n t r i b u t i o n s . consider  for example  moving toward a uniform f i e l d of dots. the vector f i e l d associated with differences in p o s i t i o n between the dots across time would point r a d i a l l y outward. 
　　　to get a feel for o p t i c a l flow  consider the mueller-lyer i l l u s i o n again. we have already established b l u r r i n g as a causal factor in the i l l u s i o n   and have noted that increases in b l u r r i n g increase the subjective strength of the i l l u s i o n . now  suppose the b l u r r i n g takes place in real time; that i s   suppose you were to watch the image go successively in and out of focus. what kinds of object motions would you see  we have performed the experiment  and have discovered two . the f i r s t of these is a motion of the insides of the convex arrows moving toward one another. it r a p i d ly a t t r a c t s one's a t t e n t i o n   and appears to be a grouping phenomenon of the sort discussed in 
1 
sec. 1. i n t e r e s t i n g l y   the i d e n t i c a l motion of the concave arrows is not perceived. 
　　　the second perceived motion is completely d i f ferent. it is of an object moving in depth. as the figure becomes more b l u r r e d   it appears to approach the observer  and  as the figure becomes f o cused  it receedes. insight i n t o t h i s percept can be obtained from the o p t i c a l flow vector f i e l d . 
　　　horn and schunck  have derived an algorithm for computing o p t i c a l flow by assuming that the brightness of each point in the image is constant within a world of smooth surfaces  constant i l l u m i n a t i o n   and constant shading. this gives r i s e to a d i f f e r e n t i a l equation  the rate of change of brightness at a point is 1     which is s a t i s f i e d approximately. the algorithm attempts to s a t i s f y t h i s equation everywhere by minimizing an expression for the deviation from zero in the image-based estimates. the results of applying t h i s algorithm to successively blurred versions of the muellerlyer i l l u s i o n are shown in f i g . 1. 
	1. 	representations and data structures 
　　　a quick glance at the o p t i c a l flow pattern in fig. 1 immediately suggests a data structure for representing it - generalized cylinders. indeed  t h i s has been one of the most widely used threedimensional representational structures since they were f i r s t introduced by binford   1   . more rece n t l y   marr  gave them additional c r e d i b i l i t y by discovering t h a t   under certain smoothness assumptions  generalized cylinders embodied the information contained in topological contours; 
i . e .   the properties invariant under p r o j e c t i v e transformations. it remains an open problem  however  as to whether they are the best such representation   for h e u r i s t i c arguments  see       . 
　　　part of the appeal of generalized cylinders is that they provide a coarse 1-d representation intermediate to the requisite indexing i n t o r i c h e r   and more d e t a i l e d   families of models. one of the p r i n c i p l e lessons learned by computational models of perception so far is that such intermediate structures should p r o l i f e r a t e throughout low-level v i s i o n as w e l l . the idea is a c l a s s i c a l one; dewey understood the use of organization to deal with complexity when he designed the l i b r a r y ' s decimal system. and researchers in computer v i s i o n have stressed the importance of e x p l i c i t l y computing  or maintaining  representations of i n t e n s i t i e s   i l l u m i n a t i o n   depth  surface o r i e n t a t i o n   e t c .   1   1   since each of these properties can be defined l o c a l l y   it makes sense from a computational point of view to organize them as arrays indexed by a retinal-centered coordinate system  as mach d i d . marr has termed one such representation the  primal sketch . whether t h i s is a dense enough representation to encompass a l l of grouping s t i l l remains to be seen  as does the manner in which such abstract descriptions are represented by the wetware of the b r a i n . undoubtedly  many new c o n s t r a i n t s   s t i l l to be discovered  are required to decide the issue. 

	1  	cooperative computation and optimization 
　　　at several points in our discussion we have been faced with decisions in the face of ambiguous situations; we had to decide which tokens correspond to identical physical events  we had to decide which dots correspond to the subjective circles in random dot moire patterns  we had to decide whether our zero crossings were indicating local edge elements  and what the orientation of these edge elements might be. most of these dec* isions have already been characterized in terms of constraints represented as criteria to be minimized  so we shall now turn our discussion to how such minima might be found. that i s   having discussed representations  we shall now discuss algorithms and mechanisms. 
　　　as is well known  the field of minimization and optimization algorithms is a large  welldeveloped one   most of these algorithms are not of immediate relevance for us  however  because  with our stated interest in vision  we must always be concerned with possible constraints from other levels. some of the tightest of these constraints come from the implementation level; whatever a l gorithm we develop must be implementable on the hardware available. for the early visual system  this amounts to rather regular arrangements of sparsely interconnected units  such as neurones  each of which can perform a simple computation. such arrangements are attractive evolutionaryly  because they make the construction of complex systems possible from simple components . and they are attractive for computer vision  because they are one of the few design methodologies currently available for vlsi technology . 
     the most convenient form of sparselyinterconnected computational networks for our purposes is one in which processors are arranged spatially so that each one interacts only with its spatial neighbors. the class of computations performable in such networks may seem  at f i r s t   to be 
quite limited. if each node can only use data available to itself and to its neighbors  then there is no way that data from larger distances can exert any influence on the outcome of the computation. but  if we permit iteration in the network  then data can  in effect  propagate its influence over larger areas. metaphorically  myopia is conquered by permitting neighbors to glimpse neighbors by iteration  and so on. for certain computations  the units can a l l operate in a lock step  parallel fashion  iterating toward a common result. this is what we shall refer to as cooperative computation. 
　　　is it possible to perform minimization in cooperative networks  the answer is yes  as we shall now demonstrate by introducing one of the most widely studied cooperative networks - relaxation 
labeling processes. 
	1. 	relaxation labeling processes 
　　　consider a graph in which the nodes represent entities  and the edges indicate which entities constrain each other. 	now  let a set of labels be attached to each entity  each of which represents possible interpretations for that entity. finally  let a measure of confidence be associated with each label  indicating how likely that label is for the associated node. 
　　　given this i n i t i a l structure  the problem is to select a labeling for the graph which is most likely given a model of how the entities f i t together. 	perhaps the earliest such example in computer vision occured in the blocks world of convex polyhedra  in which programs attempted to label the sides of line drawings with the physical edge configuration that they were representing. 	sharp local constraints existed between pairs of lines 
meeting at a junction within this universe  because physical edges can f i t together only in certain ways  1 ; 	for a recent review  see   1   . 	for example  within this universe  a line denoting two surfaces meeting to form a convex fold could not join a line denoting two surfaces forming a concave 
one  but it could meet one denoting an occluding surface  consider a triangular flap of cardboard bent up; the bend is the convex junction  and on either of its sides is an occluding one . the constraints in this world  then  were tables of which pairs  or triples  etc.  could form physically meaningful configurations. 
     within the blocks world  this constraint i n formation was used to restrict the search for legal labelings. the basic idea  as developed by waltz 
   1u   was that labels need not be considered in the global search if they were not consistent  according to the constraint tables  with their neighbors. he thus filtered the possible labels according to the following rule: discard a l l labels that did not have at least one label on each of their neighbors with which they were consistent. the rule could be applied in parallel to each nodelabel pair  and  since the label sets change after 
each application  it could be iterated until no further changes took place. it is  therefore  a cooperative computation. 
     although waltz filtering was developed in this discrete  symbolic manner  it can be reformulated in optimization terms. if we view labels as either 
being present or absent  and constraints as either being true or false   i . e .   1 or 1  for both labels and constraints   then the effect of a label's context is to add support to the label. 	since each neighboring node must have at least one consistent label  we can define the support from a node as one 
when the condition is satisfied  otherwise zero. the goal of waltz f i l t e r i n g   then  is to maximize support for each label; otherwise  they w i l l be discarded. 
　　　discrete waltz filtering can be generalized to continuous optimization by generalizing the certainty measure attached to each label from {present  absent} to the continuum  1    and similarly for the logical constraints. thus ullman's affinities  e.g.  become the constraints. the problem  then  becomes one of how to extend the definition of support to this continuous case  and finally of how to maximize it in a cooperative fashion. these problems have been solved by hummel and zucker   using the tools of variational calculus. in short  their algorithm is one of gradient ascent; it 

1 

operates by computing a d i r e c t i o n for the i t e r a t i o n t o   say  maximize an increase in the value of a f u n c t i o n a l   and then taking a step in t h i s d i r e c t i o n . i t i s i n t e r e s t i n g t o note t h a t   although t h i s algorithm was derived for optimization purposes  it solves a much richer class of problems. i t i s i n t i m a t e l y related t o the algorithms for solving systems of   p a r t i a l   d i f f e r e n t i a l equations  such as the one discussed previously for computing o p t i c a l flow. 
	1. 	labeling lines and links 
　　　as a demonstration of the relaxation labe l i n g process  r e c a l l the problem of i n t e r p r e t i n g the responses of oriented simple c e l l s . in p a r t i c u l a r   l e t us suppose that the simple c e l l s are t r y i n g to i n t e r p r e t the zero-crossing contours i n t o l o c a l l y - s t r a i g h t segments  called edges  with an associated o r i e n t a t i o n . how s h a l l we constrain the i n t e r p r e t a t i o n process  our general goal  as 
previously s t a t e d   is to f i n d the l a b e l s   i . e .   the edge segments  which were most l i k e l y to give the observed response for  at least two levels of  the observed simple c e l l responses. while t h i s can be done   it would require more space than we have here to develop i t . rather  l e t us consider a simp l e r c o n s t r a i n t : minimize a measure of curvature  so that curves are continued as smoothly as possi b l e across i n t e r s e c t i o n s . such a constraint could be said to implement the gestalt law of good cont i n u a t i o n   a summary of observational experience  but hardly a theory of c o n s t r a i n t   . 
       given that we wish to minimize curvature  how might  the visual system obtain suitable a f f i n i t i e s   or constraints  one approach is to use the simple c e l l s ' receptive f i e l d s not only as operators for signaling edges  but also as e x p l i c i t representat i o n a l descriptions of them. then  constraints for o r i e n t a t i o n good continuation can be derived by using the information i m p l i c i t in the arrangement of the receptive f i e l d s . that i s   by overlaying receptive f i e l d s of d i f f e r e n t o r i e n t a t i o n s   and then counting the amount of overlap between them  cons t r a i n t s between pairs of edges can be derived. for example  for a v e r t i c a l o r i e n t a t i o n of one mask  the a f f i n i t y to the other mask would drop o f f  roughly  exponentially as it were rotated away from the v e r t i c a l . these constraints are actually 
p r o p o r t i o n a l to the l i k e l i h o o d of a long v e r t i c a l zero-crossing segment represented by two fine masks  in the context of a larger mask i n d i c a t i n g a strong v e r t i c a l segment in the same area  see sec. 1  see f i g . 1 . the f u l l system of c o n s t r a i n t s   of course  must take both the o r i e n t a t i o n and the r e sponse of the larger masks i n t o account. 
1. multi-level cooperative systems 
　　　as we have i n d i c a t e d   early visual processing seems to involve many d i f f e r e n t representations  from zero crossings to subjective f i g u r e s . the issue of s a t i s f y i n g constraints between representa t i o n a l l e v e l s   as w e l l as across them  therefore a r i s e s . and  given the underdetermined nature of many of these problems  it seems most l o g i c a l that as many constraints as possible should be considered concurrently. m u l t i - l e v e l relaxation systems thus seem a natural s o l u t i o n   and in t h i s section we s h a l l discuss one for both labeling and l i n k i n g edges. as before  the system presented is s i m p l i f i e d   but  we believe  of the r i g h t sort for many forms of grouping. 
     the f i r s t level of our system is i d e n t i c a l to the one j u s t presented; it labels the response of s i m p l e - c e l l - l i k e operators with assertions about oriented edge segments. the second l e v e l groups these segments into longer curves by labeling a r e l a t i o n over s p a t i a l l y neighboring segments as e i t h e r connected or not-connected. the connected r e l a t i o n joins segments analogously to the way in which v i r t u a l lines joined the dots in random moire patterns. the constraints for t h i s second l e v e l come from the i n t e n s i t i e s ; the l i k e l i h o o d of edges being connected is proportional to the s i m i l a r i t y between t h e i r i n t e n s i t y p r o f i l e s . the r e s u l t s are shown in f i g . 1 . 
     the results of these two relaxation examples should be viewed as computational experiments. they permit one to develop both the p r a c t i c a l f e e l of a p a r t i c u l a r approach  and the p o s s i b i l i t y of performing mathematical analyses of i t . most importantly for the study of human perception  however  they expand the modeling vocabulary of. the visual t h e o r i s t s u b s t a n t i a l l y . previously  neurophysiologists have spoken of l a t e r a l i n h i b i t o r y interactions between o r i e n t a t i o n detectors to overcome ambiguities in the n u l l f i r i n g rate of neurons ; such mechanisms implement a l i m i t e d form of enhancement. now we have the c a p a b i l i t y of d i s cussing implementations that achieve optimal cons t r a i n t s a t i s f a c t i o n . when one looks at the det a i l s   the required machinery is not s i g n i f i c a n t l y d i f f e r e n t . there is even a p a r t i a l conceptual s i m i l a r i t y as w e l l . when the structure is clear enough everywhere  cooperative algorithms can become equivalent to local maxima selection . that i s   choosing local maxima everywhere may r e s u l t in a global one. but in general  t h i s is not the case. 
1. summary and conclusions 
     in t h i s essay we have trie d to follow three paths simultaneously: an h i s t o r i c a l one  from helmholtz and mach to the present; an anatomical one  from the eye to the b r a i n ; and a conceptual one  from the concrete to the abstract. because the process of vision is so complex  explanations can be put forward at many d i f f e r e n t l e v e l s   from assumptions necessary to solve abstract v i s i o n problems  to r e s t r i c t i o n s on the machinery t h a t w i l l implement the s o l u t i o n . we have i l l u s t r a t e d constraints at each of these l e v e l s   because  when they are taken together  we believe that they demonstrate the way in which progress can be made in understanding vision in general. if constraints at any of these levels were missing  we argued  the remaining ones would be too underconstrained for viable t h e o r i z i n g . this was i l l u s t r a t e d in 
the p a r t i c u l a r instance of cooperative algorithms  the need for which came from computational t h e o r i e s   but the form of which came from implementation cons t r a i n t s . 
1 the essay concentrated on early perception  in 
part because t h i s is the most w e l l understood component  but more to i l l u s t r a t e the need for computer vision in the understanding of human perception. for it is here t h a t the explanations would presumably be most concrete. while t h i s is true for the physics of the eye  it does not seem to be so for as fundamental a process as the location of edges; t h i s requires  we argued  an i n t e r p r e t a t i v e component to decipher the transducers' signals. by the time the v i s u a l system begins to hypothesize surfaces and volumes  the language of computations and representations seems even more necessary. while the computational l e v e l may not be s t r i c t l y necessary to understand the r e f l e x - l i k e mechanisms in lower organisms l i k e the f l y   it would appear that both helmholtz and mach were r i g h t about the human v i s u a l system - inferences take place  and they are realized by mechanisms implemented in neurones. they were simply theorizing at d i f f e r e n t descriptive or explanatory  l e v e l s . we argued t h i s point by developing the need for optimal i n t e r p r e t a t i o n s t r a t e g i e s   and then showing how they could be r e a l i z e d   at least in p r i n c i p l e . 
　　　although computational theories are necessary  in the sense that we have argued  they may never be unique. there are often several d i f f e r e n t   but equivalent  ways in which the same phenomenon can be explained; soap f i l m s   for example  can be described p h y s i c a l l y as the surface with minimal area  a global c h a r a c t e r i z a t i o n   or l o c a l l y in terms of t h e i r d i f f e r e n t i a l geometry. in t h i s essay we saw several examples from v i s i o n : l a t e r a l i n h i b i t i o n can be viewed as an enhancement process  or as im-
plementing the receptive f i e l d s of center-surround c e l l s . they may even play a role in the s p a t i a l frequency l i m i t e d channels. and simple c e l l s were 
viewed t e l e o l o g i c a l l y as edge and l i n e f i n d e r s   and as approximations to f i r s t and second  spatial  d e r i v a t i v e s . f i n a l l y   we encountered two separate stereo algorithms. but each of these a l t e r n a t i v e theories was i n s t r u c t i v e   i l l u s t r a t i n g   once again  how important d i f f e r e n t explanatory points of view can be . 
