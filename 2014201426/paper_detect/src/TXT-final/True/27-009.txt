 
autonomous mobile robots need very reliable navigation capabilities in order to operate unattended for long periods of time this paper reports on first results of a research program that uses par tially observable markov models to robustly track a robot s location in office environments and to direct its goaj-onented actions the approach explicitly maintains a probability distribution over the possi ble locations of the robot taking into account var ious sources of uncertainly including approximate knowledge of the environment and actuator and sensor uncertainty a novel feature of our approach is its integration of topological map information with approximate metric information we demon stcate itw robustness of this appiorch    controlling an actuaj indoor mobile robot navigating corridors 
1 	introduction 
we are interested in the task of long term autonomous navigation in an office environment  with corridors foyers and rooms  while the slate of the art in autonomous office navigation is fairly advanced it is not generdlly good enough to permit robots lo traverse corridors for long periods of time without getting lost evidence for this can be seen in recent aaa1-sponsored robot competitions  konolige 1 simmons 1  where the robots often got confused as to where they were and had difficulty relocalizing once that occurred 
　we contend that navigation can be made more reliable by having the robot explicitly represent spatial and sensor uncertainty to this end we have developed a navigation technique that uses markov models lo robustly track the robot's position and direct ils course a partially observable markov decision process  pomdp  model is constructed from topological information about the connectivity of the environment  approximate distance information plus sensor and actuator characteristics the markov model estimates the position of 
    thii research was supported in part by nasa under contract nagw 1 and by the wnght laboratory and arpa under grant number f1 1 the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies either expressed or implied of nasa the wright laboratory or the united stales government 
1 	learning 
the robot in the form of probability distributions the probabilities are updated when the robot reports that it has moved or turned  and when it observes features such as wails and corridor junctions to direct the robot s behavior  a planner associates a directive  e g turn or stop  with every markov stale whenever the probability distribution of the markov model is updated the total probability mass for each directive is calculated  and the robot executes the one with the largest probability mass 
　our approach has several features that make it well-suited for the office navigation task it explicitly accounts for uncertainty in actuation sensor data and their interpretation and the robot s position it can utilize all available sensor informa lion to track position and is particularly amenable to adding new sources of sensor information it seamlessly combines topological and metric map information enabling the robot to utilize as much or as little metric information as nhas avail able it is also very reactive - once the robot believes it has strayed from the nominal  optimal  path it will automatically execute corrective actions on the other hand n is relatively immune lo temporary uncertainly in position for example even if the robot does not know for certain which of two parallel comdors it is traversing h does not stop and replan as long as the control directives associated with both corridors are the same in this way it can continue making progress towards its desired goal while at the same lime collecting sensor readings to help disambiguate its true location 
　an important aspect of this work is that it must run in real time on board an actual robot problems include not only how to model the navigation problem as a pomdp but also how to deal with memory and time constraints while still preliminary our experimental results both in simulation and on the actual robot  are encouraging in particular they indicate that the approach produces very robust navigation even when using estimates of the actual sensor and action models while  to date  we have concentrated more on imple mentation and validation aspects of the approach our work opens up new application areas for more theoretical results in the area of planning with markov models  including some of our own group s work tchnsman  1  goodwin  1 koenig and simmons 1  
1 	related w o r k 
most recent work in robolic office navigation has used a landmark based approach that relies on topological maps 

whose nodes correspond to landmarks  locally distinctive places  such as corridor junctions and whose edges indicate how the robot should navigate between nodes  kortenkamp and weymouth  1 kuipers and byun  1  this ap proach is attractive because it does not depend on geometric accuracy and is reactive to sensed features of the environment  the landmarks  it suffers however  from problems of sensors occasionally not detecting landmarks and of sensor aliasing  not being able to distinguish between similar landmarks  on the other hand  using purely metric maps is vulnerable to inaccuracies in both the map making and dead-reckoning abilities of the robot while some researchers augment topological maps with approximate metric information such information is primarily used to resolve topological ambiguities  kuipers and byun 1 mataric 1 simmons  1  in contrast our markov model approach seamlessly integrates topological landmark-based informa lion and approximate metric information 
　some navigation techniques represent uncertainly in position using models that presume a certain probability distribution typically gaussian  kosake and kak  1  smith and cheeseman 1  while such models are efficient to encode and update they are not ideally suited for office navigation in particular due to sensor aliasing one often wants to encode the belief that the robot might be in one of a number of non-conliguouslocations this cannot be represented precisely using gaussian distributions but is quite easy for our markov models on the other hand we need to lessellale space into discrete states  rather than representing position using real numbers thus there is a tradeoff between the precision and expressiveness of the different models we contend that for office navigation however that die added expressiveness of the markov models outweighs the decrease in precision from discretization 
like our own work several researchers have investigated 
bayesian approaches for probabilistic planning and execution monitoring in office navigation  nourbakhsh el al 1  use a partially observable markov model approach similar to ours but do not utilize any metric information the states of the robot are either at a topological node or somewhere in a connecting comdor in contrast our approach can use estimates of how far the robot has traveled and sensor reports that occur within a corridor to further constrain the robot s location for example knowing that two corridor junctions are approximately 1 meters apart enables the robot to estimate when it is in the vicinity of the second junction even if it misses seeing the junction 
　most of the other bayesian approaches rely on metric maps  kirman a al  1  and  nicholson and brady 1  use approaches based on temporal belief networks with such methods the size of die models grows linearly with the amount of temporal lookahead  which limits their use to rather small lookaheads  dean et al 1  use robot navigation as an example to describe a planning and monitoring algonmm dial uses a totally observable markov model which assumes that the location of the robot is always known precisely  hu and brady  1  use bayesian techniques to detect unforeseen obstacles in an otherwise completely known environments 

figure 1 augmented topological map 
1 	constructing the m a r k o v models 
before describing how we construct markov models of an office environment  we introduce some terminology a finite markov model consists of a finite set of states s a finite set of actions a a set of actions a s   for each state that can be executed in that state  and transition probabilities and  the probability that 
the new stale is y if action a is executed in slate s  we also define a set of sensors the sensors are characterized by observation probabilities 
 the probability that sensor / reports feature o when the robot is in state s  note that markov models assume that the transition and observation probabilities are determined only by the current state of the robot  the  markov assumption   
　in our case  the markov model is partially observable be cause the robot may never know exactly which slate it is in instead it maintains a belief of its current state in form of a probability distribution p{s  over die slates  the probability distribution is updated in two ways when an action report a is received indicating a move or turn  the new probabilities become 

where a!  is a normalization factor to ensure that the probabil iiies all sum to one  this is necessary because not all actions are defined for all states  when a sensor report o is received from sensor i indicating that a feature has been detected the probabilities become 

　the markov model is constructed from three sources of information the topology of the environment  which we presume can be easily obtained  general knowledge about office environments  such as that corridors are straight and perpendicular to each other  and approximate metric knowledge  obtained either from rough measurements or from general knowledge  such as the fact that  in our building  corridors are two meters wide and all doorways are between two and ten meters apart  
　the map information is initially encoded as a graph of nodes and edges  figure 1  a node represents a junction between corridors  and/or doorways or foyers  nodes are connected by a pair of directed edges which are augmented widi approximate length information in the form of a probability distribution over possible lengths rooms and foyers  not shown  are also represented in the map 

figure 1 group of four markov states 
　the rest of this section describes how the augmented topological map is compiled into a markov model 
modeling locations 
each markov state encodes both the orientation and location of the robot to insulate the model from low-level control aspects  such as turning to avoid obstacles  we encode the commanded heading of the robot rather than its instantaneous orientation since our corridors are straight and perpendicular to each other it is sufficient to discretize orientation into the four compass directions north south  east  west the spatial locations of the robot are also discretized while more fine-grained discretizations yield more precise models they also result in more memory requirements and more timeconsuming computations we use a resolution of one meter which we have found to be sufficient 
　since our markov states encode both orientation and lo cation four states are needed lo fully represent each spatial location three actions are modeled turning right 1 de 
grees  r  turning left 1 degrees  /  and going forward one meter  /  right and left turn actions are defined for every state  figure 1  since they correspond lo changes in commanded heading and not to changes in position  we have found it sufficient lo model them determinislically some states also have  forward' actions defined for transitioning from location to location  note that forward actions are not defined for stales that face walls  dead-reckoning uncertainty is modeled by a self-transition that is  the forward action transitions with some probability from a male into itself 
modeling corridors 
our representation of topological edges is a key to our approach if the edge lengths are known exactly  it is simple lo model the ability to traverse a corridor with a markov cain that has forward actions between those states whose onenta lions are parallel to the corridor axis  figure 1a  the model becomes more complex when only approximate edge lengths are known while one approach is to represent a corridor edge by a single markov state  nourbakhsh et al 1  this loses die ability lo utilize dead-reckoned information in doing position estimation 
　another approach is lo model an edge as a set of parallel markov chains  each corresponding to one of the possible lengths of the edge  figure 1b  the transition probabilities into the first state of each chain are the same as the probability distribution over edge lengths associated with the topological map  see figure 1  each forward transition after that is deterministic  modulo dead-reckoning uncertainly - note that the identity transitions are not shown in these figures  while this representation best captures the actual structure of the environment it is relatively inefficient the number of stales is quadratic in the maximum length of the edges 
　as a compromise between fidelity and efficiency  our current implementation models edges by collapsing the parallel chains in a way that we call the come from  semantics  figure1c  in this representation thespattal location of amarkov 
1 	learning 

l come from semantics  if the edge length is not known exactly  

figure 1 representations of topological edges 
state is known relative to the topological node from which the robot comes  but its location relative to the end of the chain is uncertain  c g stale b is 1 meter from a  but is between 1 and 1 meters from c  for each stale the forward transition probabilities are derived from the edge length probability dis tnbutions when edge length uncertainty is large the come from semantics can save significant space over the 'parallel chains ' representation for example for an edge between 1 and 1 meters long the come from semantics needs only 1 stales to encode the edge compared lo 1 for the  parallel chains 
　each edge in the come from  semantics is actually repre sented using two chains one for each of the comdor directions thus  if the robot travels some distance and then turns around the model limits the positional uncertainty as the robot travels back to the last topological node this is particularly useful when the robot realizes it has missed a junction  and turns around to head back 
modeling junctions and doorways 
unfortunately we cannot represent comdorjunctions simply with a single group of four markov states since the spatial resolution of a markov state is one meter but our corridors are two meters wide 


 for claniy only actions from the highlighted nodes arc shown  
figure 1 representation of corridor junctions 
while one approach would be to represent junctions using 
 our  two by two  groups of four markov stales each we achieve nearly the same result with four groups of two states each which both saves space and makes the model simpler  figure 1  the basic idea is that turns within a junction are non deterministic with equal probability of transitioning to one of the two slates of the appropriate orientation in the lunction for example in entering the junction of figure 1 from the south the robot would first encounter slate a then stale b if it continues to move forward if it then turns right it would be facing east and would transition to either stales c or d with equal probability this models agrees with how the robot actually behaves in junctions in particular it captures the uncertainty thai arises due to the facr that the robol turns with a non zero turn radius 
　doorways can be modeled much more simply since the width of our doors is approximately the resolution of the markov model a single exact-length edge  figure la  leads ihrough a door into a room similarly lo  nourbakhsh el al 1  doorway edges have an associated probabilityp mat the door is open then the observation probabilities associated with seeing a doorway are 
j 
modeling foyers and rooms 
we arc developing adequate models for large open spaces  layers and rooms  currently we lessellale a foyer into a matrix of locations from each location  the forward action has some probability of transitioning straight ahead but also some probability of self-transitioinng and moving to diagonally adjacent states while this model corresponds well with our observations about how the robot actually performs in such spaces it is deficient in that it requires the exact length and width of the foyer although this model could also be used to represent rooms it is probably overly complex for that purpose wc are currenlly leaning towards representing rooms using a single group of four slates each of which has a high probability of self-transitiomng 
1 	the navigation system architecture 
the overall system architecture consists of five main components  figure 1  the robot controller performs local obstacle avoidance while trying to travel along a commanded heading 

figure 1 navigation system architecture 
the sensor lnlerpretation component converts raw data from the wheel encoders and sonar into higher-level action reports  heading changes and disiance traveled  and sensor reports  features delected  position estimation uses these reports and the markov model lo maintain a belief about the current location of the robot action selection uses this probability distribution along with a goal-directed policy produced by the planner to choose directives which arc sent to the controller to change the robot s heading or make it stop these directives are also fed back lo sensot interpretation  since interpretation of features is often heading specific 
　to dale the work reported here has focused on position estimation and action selection the robol controller and sensor interpretation components are essentially the same as those used in our previous work in landmark based navigation  simmons 1  and wc have not yet pul significant effort into the planner 
robot controller 
the main task of the robot controller is to head in a given direction while avoiding obstacles to do that  it uses a po  ential field approach larkin 1  in which obstacles arc represented as repulsive forces and the desired heading is an attractive force the robot sums the force vectors and locally moves in that direction modulating its speed if necessary lo avoid collisions 
　the directives supplied to the controller are to make it stop go and change heading while the markov model represents turns and moves as discrele actions in reality the robol does not stop to turn  but continually moves forward even while turning in addi'ion heading changes are cumulative so that two successive right turn directives for instance results in a smooth 1 degree turn 
sensor interpretation 
the task of the sensor interpretation component is lo convert the continual motion of the robot into discrete action reports and to produce sensor reports from the raw sensor data that indicate the observation of high-level features such as walls and corridor openings 
　the sensor interpretation component periodically receives reports from the robot s dead reckoning which uses internal sensors  wheel encoders  lo estimate position and orientation this information is combined with the robol s commanded heading to produce a virtual odomeler that keeps track of the distance traveled along that heading this is needed so that the distance the robol travels in avoiding obstacles is 


figure 1 occupancy grid with corridor features 
not counted in determining how far it has traveled along a corridor after each meter of cumulative travel the sensor interpretation reports that one forward action has occurred similarly  the robot controller reports when us commanded heading has changed and this is reported  in units of 1 degree turns  to the position estimation component 
　sonar readings are bundled into three virtual sensors' that report observations of walls and openings of various sizes  small medium and large  in front of the robot and to its immediate left and right an occupancy grid  elfes 1  which probabilistically combines sonar sensor readings taken over time as the robot travels is used lo filter noisy sensor readings and produce a more global view of the robot s surroundings  figure 1  the occupancy grid is processed by projecting a sequence of rays perpendicular to the robot s commanded heading  thus  it is independent of the robot's actual orientation  until they intersect an occupied grid cell the rays are then analyzed geometrically if the end points of the rays can be fit to a line reasonably well 1 e with a small chi-squared statistic  then a wall has been detected with high probability an opening is indicated by a contiguous sequence of long rays 
position estimation 
the virtual sensor and action reports are used to update the probability distribution over the markov slates according to the update rules shown in section 1 these rules need the tran silion probabilities for actions i   a   and the observation probabilities for virtual sensors   the transition probabilities are derived from edge length distributions in the map plus knowledge of dead-reckoning uncertainty the observation probabilities must be estimated or learned to simplify the problem rather than characterizing each individual state  we characterize classes of states  such as w a l l open  corridor junctions   closed-door and open-door then we create a table containing feature/state class pairs that encode the probability that the sensor reports a given feature when the robot is next to that particular class of states for example the left virtual sensor is partially characterized by 
1 	learning 

　these probabilities indicate that junctions are most commonly delected as medium-sized openings but can often be seen as large or small openings  although they are hardly ever confused for walls  the observation probabilities of the feature n o t h i r g which is used to indicate that a sensor has made no determination are chosen so that if the sensors reports n o t h i n g the overall probability distribution is unaffected while these values represent our best guesses  we have implemented learning algondims to determine action transition and observation probabilities more precisely 
　in general forward actions tend to increase positional uncertainty due to non deterministic transitions  while observa nons tend to decrease it in certain cases however  the effects of a forward action can dramatically decrease uncertainty this occurs when there is some probability that the robot is in slates with no forward actions  such stales are prevalent - for instance all states within a corridor whose orientation is perpendicular to the axis of the corridor  see figure 1  in practice  this effect can be seen when the robot turns at an intersection before the turn there is often some probability thai the robot has not yet reached the intersection after the robot has turned and successfully moved forward a bit the probability that it is still in the original corridor drops to zero we believe this is a major factor in keeping the positional uncertainty low  even when the robot travels long distances 
　when incorporating sensor reports  care must be taken to preserve the markov assumption since reports by the same sensor at the same location are not independent  since they depend on the same occupancy grid cells   multiple reports cannot be aggregated instead we retract the old sensor report before updating with the new report which can be done easily as long as no action updates occur between the two reports 
action selection 
to control the robot s goal-directed behavior our planner  see below  associates a directive d s  ~ with each markov state 
 note these should not be confused with the set of actions a{s  defined for the markov model  the four directives are change heading by 1 degrees  turn right  -1 degrees  turn left  1 degrees  go forward  and stop the action selection component chooses new directives based on the probability distribution of the markov model 
　a straightforward strategy is to choose the directive as sociated with the stale s that has the highest probability  nourbakhsh el al 1  while this strategy may be ade quate when each topological entity is associated with a single markov stale  it does not work well in our models for example  since comdor junctions are modeled using several states for each orientation  it is reasonable to consider all of their recommendations when deciding which directive to issue 
　a selection strategy with this property is the  best-action strategy in which the probability mass of each directive is calculated and the one with the highest total probability is chosen 


　a variation on this is the 'best-above threshold' selection strategy which chooses the best directive only if its probability mass is above some threshold otherwise the current directive remains in effect we have investigated this strategy because we thought it would reduce the chances of making wrong moves due to spunous false positive sensor reports experimental evidence  however  both in simulation and with the real robot  indicate that the 'best-action' strategy is in fact superior in reducing the number of erroneous moves 
reinforcement learning researchers such as  chnsman  
1 tenenberg et al 1 often use other voting schemes  suc.h as the following let gd s d  be the shortest distance from state to the goal if the robot executes directive and then behaves optimally the strategy chooses 
ihe directive with the smallest expected goal distance 

this scheme allows one for example to choose the second best action if all stales agree on the second best action but disagree on the best action while this scheme is attractive wc did not implement it because it would require substantial changes to our path planner 
planning 
while opportunities abound for applying probabilistic planning techniques to this problem we currently use a very sim pie symbolic path planner a variant on the one used for our landmark based navigation 
　the planner uses a* search in the augmented topological map to find a path to the goal it uses this plan skeleton to assign preferred headings to the edges and nodes in the map based on the expected total travel distance to the goal and estimates about how long it takes to turn directives are then associated with the markov stales a go forward directive is assigned to each state whose orientation is the same as the preferred heading of its associated topological entity the remaining states are assigned actions that will turn the robot towards the desired heading finally a slop directive is assigned to the goal state and to nearby states  which helps to increase the total probability mass of the slop directive when the robot reaches the goal  
　our planner and the voting heuristics used in action selec lion arc clearly inferior compared lo optimal pomdp solu tions  in which directives are assigned to probability distributions rather than individual states  for example  unlike pomdp algorithms  our planner cannot decide to take actions whose only purpose is lo gather information sometimes however it can be advantageous to gamer additional informa lion thai helps the robot to reduce positional uncertainty  even if that requires it to move away from the goal temporarily 
　at present however it is infeasible lo determine even approximate pomdp solutions given the size of our stale spaces and our real-time constraints  lovejoy 1   cassandra el at 1  for instance report that their pomdp method can solve a problem with 1 stales in under half an hour while the model for just half of one floor of our building has over 1 slates we still intend to explore pomdp algorithms however given recent advances in approximate algorithms  part and russell 1 and the hope that the restricted topology of our markov models might make them more amenable to efficient solutions 

figure 1 an office comdor environment 

1 	experiments 
while markov models are expressive and relatively efficient thev make strong independence assumptions empirical evidence is needed to determine whether mthiscase themarkov assumption is satisfied well enough to yield good  reliable navigation performance in this section we report on experiments in two environments for which the markov assumption is only an approximation a realistic simulation of a prototypical office comdor environment and an actual mobile robot navigating in our building the same navigation code is used for both sels of experiments since the simulator and the robot have the exact same interfaces 
1 	experiments with the simulator 
two navigation experiments were performed wilh the robot simulator in the comdor environment shown in figure 1 the topological map has 1 nodes and 1 directed edges we modeled the uncertainty of the length of a topological edge as a uniform distribution over the interval ranging from 1 to iso percent of the real length of the edge the resulting markov model has 1 markov slates the initial positional uncertainty for both experiments is minimal the initial prob-
ability for the robot s aciual location is about 1 percent the remaining probability mass is distributed in the vicinity of ihe actual location 
　in the first experiment the task was to navigate from start j lo goal  the preferred headings assigned by our planner are shown with solid arrows note that the preferred heading between b and c is towards c because even though the goal distance is a bil longer  this way ihe robot does not have to turn around if il overshoots b we ran a lolal of 1 trials for both the best action and the best-above-threshold strategies all of which were completed successfullv  table 1  
　the robot has to travel a rather long distance from start  before its first turn since this distance is uncertain and comdor openings are occasionally missed the robol occasionally overshoots b and then becomes uncertain whether it is re ally at c or b however  since the same directive is assigned to both nodes this ambiguity does not need to be resolved the robot turns left in both cases and then goes straight the 



same thing happens when it gets to d since it thinks it may be at either d or e the robot eventually corrects its beliefs when after turning left and traveling forward  and it detects an opening lo its left at this point the robot becomes fairly certain that it is at e a purely landmark based navigation lechnique can easily get confused in this situation since it has no expectations about seeing this opening  and can only attribute it to sensor error  which in this case  is incorrect  
   in the second experiment the robot had to navigate from start-i to goal1 the preferred headings for this task arc shown with dashed arrows again we ran 1 trials lor both action selection strategies  table 1  
   for reasons that are similar to those in the first experiment the robot can confuse g with f if at is at g but thinks it is probably at f it turns right and goes forward however when it detects the end of the corndor but does noi detect a right comdor opening it realizes that it must be at h rather man i since the probability mass has now shifted  it turns around and goes over g f and i to the goal this shows that our nav igation lechnique can gracefully recover from misjudgements based on wrong sensor reports - even if it takes some lime lo correct its beliefs it is important to realize that this behavior is not triggered by any explicit exception mechanism but results automatically from the way the position estimation and action selection interact 
1  	experiments with xavier 
xavier our indoor mobile robot is buill on an rwi b1 base and includes bump sensors sonars a laser range sensor and a color camera on a pan-tilt head control perception and planning are all earned out on two on-board mulli-processing 
1-based machines 
   as mentioned the probabilistic navigation system uses a modified version of the planner and essentially the same robot controller and sensor interpretation components as our landmark-based navigation system thus  differences in performance can be directly attributed to the different navigation approaches in addition to facilitate comparisons we ran xavier along the same routes as reported in  simmons 1  
1 c  	learning 
in particular the robot traversed from point s to g and back again  figure 1  in some trials  1 meters each way  and in some circumnavigated around the building  1 meters  
　the topological map used lo represent the corridors in figure 1 has 1 nodes and 1 directed edges as with the simulator trials the edge lengths ranged uniformly from 1 to 1 percent of the real comdor length the resulting markov model has 1 states 
　in 1 trials  mostly back and forth between points s and g  the robot successfully reached its goal in 1 cases averaging 1 cm/s while traversing a total of over a kilometer in two of those cases the robot missed seeing a junction  but turned back when it realized it had probably gone too far and successfully continued this success rate of 1% compares favorably with ihe 1% rate reported in  simmons 1  
　the main difference is thai ihe probabilistic navigation scheme uses all available sensor information to help locali e itself for example while the probabilistic navigation uses the robot s dead reckoning to directly constrain its po sition estimates the land mark-based navigation uses metric information in only two ways it ignores landmarks that are reported before a minimum distance has been traveled and turns around after a maximum distance similarly the prob abilistic navigation scheme utilizes all sensor reports  while the land mark-based scheme pays attention only to those features that might correspond to the expected landmark one effect of this is that the probabilistic navigation scheme tends lo turn the robot earlier when entering a junction it often gets enough confidence from a single sensor report while the land mark-based scheme needs several  eg seeing both an opening lo the side and the end of the corridor ahead  before it decides to turn 
　the few remaining failures are attributable to two sources occasionally the action selection heuristics enter a limit cycle and continually lurn the robot  we suspect this is due to a software bug  more fundamental is that the local obstacle avoidance will especially in foyers move the robot a signih cant distance orthogonally lo its commanded heading since this is not currently reported the robot s position estimation becomes very inaccurate we can remedy this by reporting side motions and adding a slide action lo the markov model that will cause the appropriate state transitions 
1 future work and conclusions 
this paper has presented our first efforts al using partially observable markov models  pomdps  for autonomous office navigation the approach enables a robot to utilize all its sensor information both positional and feature based in order to robustly track its location a simple path planner and action selection heuristics are used lo direct the robot s goal heading advantages of this approach include the ability to account for uncertainty in the robol s initial position actuator uncertainly sensor noise  and uncertainly in the interpretation of thesensordata also by integrating topological and metric information the approach easily deals with uncertainty arising from incomplete descriptions of the environment 
　we are extending this work in several directions we have implemented methods  based on em learning techniques that passively refine metnc map information as well as the sensor and action models and will be testing it with xavier in addition we are developing improved learning techniques that 

are more resistant to violations of the markov assumption we intend to pursue planning and action selection algorithms that approximate optimal pomdp policies and to compare meir performance to the greedy heunstics descnbed here finally  we inlend to add new sources of sensor information pnmanly vision-based feature detectors 
　the implemented probabilistic navigation system has demonstrated its reliability  both in simulation and on xavier even in the face of significant uncertainty we believe that such probabilistic navigation techniques hold gteat promise for getting robots reliable enough to operate unattended for long penods of time in complex uncertain environments 
acknowledgements 
thanks to lonnie chnsman richard goodwin and joseph o sullivan for helping to implement parts of the navigation system and for many valuable discussions swanijc willms helped perform some of the experiments with the simulator 
