
while even strips planners must search for plans of unbounded length  temporal planners must also cope with the fact that actions may start at any point in time. most temporal planners cope with this challenge by restricting action start times to a small set of decision epochs  because this enables search to be carried out in state-space and leverages powerful state-based reachability heuristics  originally developed for classical planning. indeed  decision-epoch planners won the international planning competition's temporal planning track in 1  1 and 1.
however  decision-epoch planners have a largely unrecognized weakness: they are incomplete. in order to characterize the cause of incompleteness  we identify the notion of required concurrency  which separates expressive temporal action languages from simple ones. we show that decisionepoch planners are only complete for languages in the simpler class  and we prove that the simple class is 'equivalent' to strips! surprisingly  no problems with required concurrency have been included in the planning competitions. we conclude by designing a complete state-space temporal planning algorithm  which we hope will be able to achieve high performance by leveraging the heuristics that power decision epoch planners.
1 introduction
although researchers have investigated a variety of architectures for temporal planning  e.g.  plan-space: zeno  penberthy and weld  1   vhpop  younes and simmons  1 ; extended planning graph: tgp  smith and weld  1   lpg  gerevini and serina  1 ; reduction to linear programming: lpgp  long and fox  1 ; and others   the most popular current approach is progression  or regression  search through an extended state space  e.g.  sapa  do and kambhampati  1   tp1  haslum and geffner  1   talplan  kvarnstr m et al.  1   tlplan  bacchus and ady  1   and sgplan  chen et al.  1   in which a search node is represented by a world-state augmented with the set of currently executing actions and their starting times.
this architecture is appealing  because it is both conceptually simple and facilitates usage of powerful reachability heuristics  first developed for classical planning  bonet et al.  1; hoffmann and nebel  1; nguyen et al.  1; helmert  1 . indeed  sgplan  which won the international planning competition's temporal planning track in both 1 and 1  is such a progression planner.
　there is an important technical hurdle that these temporal state-space planners need to overcome: each action could start at any of an infinite number of time points. most of these planners avoid this infinite branching factor by a  seemingly  clever idea: restricting the possible start-time of actions to a small set of special time points  called decision epochs. unfortunately  the popularity of this approach belies an important weakness - decision epoch planners are incomplete for many planning problems requiring concurrency  mausam and weld  1 .
　seen in juxtaposition with their phenomenal success in the planning competitions  this incompleteness of decision epoch planners raises two troubling issues:
1. are the benchmarks in the planning competition capturing the essential aspects of temporal planning 
1. is it possible to make decision epoch planners completewhile retaining their efficiency advantages 
　in pursuit of the first question  we focused on characterizing what makes temporal planning really temporal - i.e. different from classical planning in a fundamental way. this leads us to the notion of required concurrency: the ability of a language to encode problems for which all solutions are concurrent. this notion naturally divides the space of temporal languages into those that can require concurrency  temporally expressive  and those that cannot  temporally simple . what is more  we show that the temporally simple languages are only barely different from classical  non-temporal  languages. this simple class  unfortunately  is the only class for which decision epoch planners are complete.
　in pursuit of the second question  we show that the incompleteness of decision epoch planners is fundamental: anchoring actions to absolute times appears doomed. this leaves the temporal planning enterprise in the unenviable position of having one class of planners  decision epoch  that are fast but incomplete in fundamental ways  and another class of planners  e.g.  partial order ones such as zeno and vhpop  that are complete but often unacceptably slow. fortunately  we find a way to leverage the advantages of both approaches: a temporally lifted state-space planning algorithm called tempo. tempo uses the advantage of lifting  representing action start times with real-valued variables and reasoning about constraints  from partial order planners  while still maintaining the advantage of logical state information  which allows the exploitation of powerful reachability heuristics . the rest of the paper elaborates our findings.
1 temporal action languages
many different modeling languages have been proposed for planning with durative actions  and we are interested in their relative expressiveness. the tgp language  smith and weld  1   for example  requires that an action's preconditions hold all during its execution  while pddl 1.1 allows more modeling flexibility.1 we study various restrictions of pddl 1.1  characterized by the times at which preconditions and effects may be 'placed' within an action. our notation uses superscripts to describe constraints on preconditions  and subscripts to denote constraints on effects:
lpreconditionseffects	is the template. the annotations are:
s	 at-start  e	 at-end 
o:	 over-all   over the entire duration 
　for example  los e is a language where every action precondition must hold over all of its execution and effects may occur at start or at end. pddl 1.1 does not define  or allow  effects over an interval of time: o is only used as an annotation on preconditions.
　many other language features could be included as possible restrictions to analyze; however  most end up being less interesting than one might expect. for example  deadlines  exogenous events  timed literals   conditional effects  parameters  non-ground structures   preconditions required at intermediate points/intervals inside an action  or effects occurring at arbitrary metric points  as in zeno  can all be compiled into ls o es e  smith  1; fox et al.  1 . in particular  an analysis of just ls o es e is simultaneously an indirect analysis of these syntactically richer languages. naturally these compilations can have dramatic performance penalties if carried out in practice; the purpose of such compilations is to ease the burden of analysis and proof. of course  we also exclude some interesting language features  for the sake of simplicity   for example  metric resources and continuous change.
1 basic definitions
space precludes a detailed specification of action semantics; thus  we merely paraphrase some of the relevant aspects of the pddl 1.1 semantics for durative actions  fox and long  1 .
definition 1  actions  a model is a total function mapping fluents to values and a condition is a partial function mapping fluents to values. a transition is given by two conditions: its preconditions  and its effects.
　an action  a  is given by a beginning transition begin a   an ending transition end a   an over-all condition o a   and a positive  rational  duration δ a .
definition 1  plans  a plan  p = {s1 s1 s1 ... sn}  is a set of steps  where each step  s  is given by an action  action s   and a positive  rational  starting time t s . the makespan of p equals δ p  = max t s  + δ action s      min t s   s（p	s（p
　a rational model of time provides arbitrary precision without real complications.
definition 1  problems  a problem  p =  a i g   consists of a set of actions  a   an initial model  i   and a goal condition  g .
definition 1  states  a  temporal  state  n  is given by a model  state n   a time  t n   and a plan  agenda n   recording the actions which have not yet finished  and when they started .
　a precise formulation of plan simulation is long and unnecessary for this paper; see the definition of pddl 1.1  fox and long  1 . roughly  the steps of a plan  p =
{s1 ... sn}  are converted into a transition sequence  i.e.  a classical plan. simulating p is then given by applying the transitions  in sequence  starting from the initial model  a classical state . simulation fails when the transition sequence is not executable  simulation also fails if any of the over-all conditions are violated. in either case  p is not executable. p is a solution when the goal condition is true in the model that results after simulation.
　plans can be rescheduled; one plan is a rescheduling of another when the only differences are the dispatch times of steps. let  delay s d  be the result of delaying a step s by d units of time:  and action
action s  . similarly  p d is the result of delaying an entire plan:  {delay s d  : s （ p}. hastening steps or plans is the result of applying negative delay. a step s has slack d in an executable plan p when p  {s}“{delay s  t } is also an executable plan for every value of t between 1 and d. a step without slack is slackless  likewise  a plan is slackless when every step is slackless  that is  the plan is  left-shifted .
definition 1  completeness  a planner is complete with respect to an action language l  if for all problems expressible in l  the planner is guaranteed to find a solution if one exists. a planner is optimal  with respect to language l and cost function c  if for all solvable problems expressible in l  the planner is guaranteed to find a solution minimizing c. a planner is makespan optimal if it is optimal with makespan as the cost function.
1 required concurrency
we now come to one of the key insights of this paper. in some cases it is handy to execute actions concurrently; for example  it may lead to shorter makespan. but in other cases  concurrency is essential at a very deep level.

figure 1: preconditions are shown above actions at the time point enforced; effects are depicted below. action durations are shown in square brackets.  a    b   and  c : the first three problems demonstrate that lse  les  and ls e are temporally expressive  respectively. in the first two problems  every solution must have both a and b begin before either can end. in  c   every solution must have b contain the end of a.  d : modeling resources can easily lead to required concurrency. in this example  a provides temporary access to a resource r  which b utilizes to achieve the goal.  e : b must start in the middle of a  when nothing else is happening  to achieve makespan optimality.definition 1  required concurrency  let
p={s1 ... sn} be a plan. a step  s （ p  is concurrent1 when there is some other step    so that either  action s   or
 action. a plan is concurrent
when any step is concurrent  otherwise the plan is sequential. a solvable planning problem has required concurrency when all solutions are concurrent.
　to make this concrete  consider the plan in figure 1 d . the literals above the action denote its preconditions and below denote effects. starting with g and r false  assuming a and b are the only actions  the problem of achieving g has required concurrency. that is  both of the sequential plans  a before b or vice versa  fail to be executable  let alone achieve g.
definition 1  temporally simple / expressive  an action language  l  is temporally expressive if l can encode a problem with required concurrency; otherwise l is temporally simple.
1 temporally simple languages
theorem 1 loe is temporally simple  and so is the tgp representation1 .
proof: we will prove that loe is temporally simple by showing that every concurrent solution of every problem in the language can be rescheduled into a sequential solution.
　fix a concurrent solution  p  of a problem p =  a i g . without loss of generality  assume the step which ends last  say s （ p  is a concurrent step.1 since actions have effects only at end  the model that holds after simulating all of p {s} is identical to the model that holds immediately before applying the effects of action s  when simulating p. since every precondition of an action holds over its entire duration  the preconditions of action s  hold immediately prior to applying its effects  i.e.  in the final model of p   {s}. therefore delay s δ action s   } is an executable rescheduling of p. the final models in simulations of p and p are identical  since both result from applying action s  to the same model. by induction on the number of concurrent steps  note that p has fewer concurrent steps   there is a rescheduling of p into a sequential solution. 
　theorem 1 is interesting  because a large number of temporal planners  tgp  tp1  haslum and geffner  1   hsp   haslum  1   tlplan  bacchus and ady  1   and cpt  vidal and geffner  1   have restricted themselves to the tgp representation  which is now shown to be so simple that essential temporal phenomena cannot be modeled! note  for example  that the common motif of temporary resource utilization  figure 1 d   cannot be encoded in these representations. yet some of these planners did extremely well in the last three international planning competitions. the reality: the majority of the problems in the temporal track do not require concurrency!
　note that the proof of theorem 1 demonstrates a significantly stronger result than the theorem itself; not only does every problem in loe have sequential solutions  but there is in fact a sequential rescheduling of every concurrent solution. this idea can be applied in reverse: problems in temporally simple languages can be optimally solved using classical techniques.
theorem 1 let p be a planning problem in a temporally simple subset of pddl 1.1  and let p be a corresponding strips problem where durations are ignored and every action is collapsed into a single transition.1there is a linear-time computable bijection between the slackless solutions of p and the solutions of p.
　in particular  with the appropriate heuristics  optimal solutions to p can be found by solving p instead. that is  strips and temporally simple languages are essentially equivalent; though we do not delve into the details  one can show this correspondence in a formal manner using nebel's framework of expressive power  nebel  1 .1
proof: we give a linear-time procedure for mapping solutions of the strips problem to slackless solutions  which is the bijection of the theorem. however  we omit showing that the inverse is a linear-time computable total function on slackless solutions. we also omit proof for any case besides loe; the same basic technique  pert scheduling  can be applied  with minor modifications  to every other case.
　consider some solution of. associate with every literal  f=v  the time at which it was achieved  τ f=v   initially 1 if v is the initial value of f  and -1 otherwise. find the earliest dispatch time of each ai  τ ai   by the following procedure1; initializing and i to 1:
1. for all  f=v  （ effects argmax set τ f=v  = τ ai  + δ ai 
1. set precond ai+1 } “ {τ ai  + δ ai    δ ai+1 } 
1. increment i  loop until i   n
　then p = {si : action si  = ai and t si  = τ ai } is a slackless rescheduling of p  preserving the order of the ends of actions  starting each action only after all of its preconditions have been achieved. in particular  p is a slackless solution. 
1 temporally expressive languages
we have already seen one language  lss e  which can express problems with required concurrency  figure 1 d  . of course  the full language  pddl 1.1  is also a temporally expressive language. it is no surprise that by adding at-start effects to loe one can represent required concurrency  but it is interesting to note that merely shrinking the time that preconditions must hold to at-start  i.e. the language lse  also increases expressiveness. in fact  lse is a particularly special temporally expressive language in that it exemplifies one of three fundamental kinds of dependencies that allow modeling required concurrency.
theorem 1 lse is temporally expressive.
　the dual of l  is an odd language - all preconditions must follow effects. nonetheless  the language is interesting because it is also one of the three minimal temporally expressive languages.
theorem 1 les is temporally expressive.
　it is not surprising that adding at-start effects  to a language allowing at-end effects  allows modeling required concurrency  because there is an obvious technique to exploit the facility: make a precondition of some action available only during the execution of another action. figure 1 d  is a good example.

figure 1: the taxonomy of temporal languages and their expressiveness; those outlined by dotted lines are discussed in the text.
　what is surprising is that there is a different technique to exploit allowing effects at multiple times  one that does not even require any preconditions at all.
theorem 1 ls e is temporally expressive.
proof  of theorems 1  1  and 1 : we prove that lse  les  and ls e are temporally expressive by demonstrating problems in each language that require concurrency. see figure 1 a    b   and  c   respectively. 
1 temporal gap
figure 1 places the languages under discussion in the context of a lattice of the pddl sub-languages  and shows the divide between temporally expressive and simple. we have already shown that loe  our approximation to tgp  is temporally simple. surprisingly  the simple syntactic criteria of temporal gap is a powerful tool for classifying languages as temporally expressive or temporally simple.
　roughly  an action has temporal gap when there is no single time point in the action's duration when all preconditions and effects hold together  which is easy to check via a simple scan of the action's definition . a language permits temporal gap if actions in the language could potentially have temporal gap  otherwise a language forbids temporal gap. we show that a language is temporally simple if and only if it forbids temporal gap. this makes intuitive sense since without a temporal gap  the duration of an action becomes a secondary attribute such as cost of the action.1
definition 1 a before-condition is a precondition which is required to hold at or before at least one of the action's effects. likewise  an after-condition is a precondition which is required to hold at or after at least one of the action's effects.
　a gap between two temporal intervals  non-intersecting and not meeting each other  is the interval between them  so that the union of all three is a single interval . an action has temporal gap if there is a gap between its preconditions/effects  i.e.  if there is
a gap between a before-condition and an effect  or a gap between an after-condition and an effect  or a gap between two effects.
　actions without temporal gap have a critical point: the  unique  time at which all the effects occur.
theorem 1 a sub-language of pddl 1.1 is temporally simple if and only if it forbids temporal gap.
proof: we begin by showing that forbidding temporal gap is necessary for a language to be temporally simple.
　languages permitting a gap between a before-condition and an effect  a gap between an after-condition and an effect  or a gap between effects are super-languages of lse  les  or ls e  respectively. by theorems 1  1  and 1  such languages are temporally expressive. therefore temporally simple languages require that  for every action  all before-conditions hold just before any effect is asserted  all after-conditions hold just after any effect is asserted  and that all effects are asserted at the same time. that is  a temporally simple language must forbid temporal gap.
　for the reverse direction  i.e.  the interesting direction  we show that any language forbidding temporal gap is temporally simple  by demonstrating that slackless solutions to any problem can be rescheduled into sequential solutions  a generalization of the proof of theorem 1. fix some slackless solution to some problem in a language forbidding temporal gap.
　consider the sequence of critical points in the slackless solution  along with the models that hold between them  i.e.  m1 c1 m1 c1 ... mn 1 cn mn  where the ci are critical points and the mi are models. it is trivial to insert an arbitrary amount of delay between each critical point  lengthening the period of time over which each model holds  without altering them  by rescheduling steps. for example  multiplying each dispatch time by the maximum duration of an action achieves a sequential rescheduling preserving the sequence. for each critical point ci  all of that action's before-conditions hold in mi 1 and all of its after-conditions hold in mi  because the original plan is executable. since those models are unaltered in the sequential rescheduling  the rescheduling is also executable  and thus a solution. 
　coming back to the space of languages  we have already noted that several popular temporal planners  e.g. tgp  tp1  hsp   tlplan  cpt  restrict their attention to temporally simple languages  which are essentially equivalent to strips. the next section shows that most of the planners which claim to address temporally expressive languages  are actually incomplete in the face of required concurrency.
1 decision epoch planning
the introduction showed that most temporal planners  notably those dominating the recent ipc temporal tracks  use the decision epoch  de  architecture. in this section  we look in detail at this method  exposing a disconcerting weakness:
incompleteness for temporally expressive action languages.
　sapa  do and kambhampati  1   tlplan  bacchus and ady  1   tp1  and hsp a  haslum and geffner  1   among others  are all decision-epoch based planners. rather than consider each in isolation  we abstract the essential elements of their search space by defining dep. the defining attribute of dep is search in the space of temporal states. the central attribute of a temporal state  n  is the world state  state n . indeed  the world state information is responsible for the success and popularity of dep  because it enables the computation of state-based reachability heuristics developed for classical  non-temporal  planning.
　we define dep's search space by showing how temporal states are refined; there are two ways of generating children:
　fattening: given a temporal state  n  we generate a child  na  for every action  a （ a. intuitively  na represents an attempt to start executing a; thus  na differs from n only by adding a new step  s  to agenda na  with action s  = a and t s  = t n .
　advancing time: we generate a single child  nepoch  by simulating forward in time just past the next transition in the agenda: nepoch=simulate  where d=min{t : s （ agenda n  and  t=t s  or t=t s  + δ action s    and t − t n }.
　our definition emphasizes simplicity over efficiency. we rely on simulate to check action executability; inconsistent temporal states are pruned. obviously  a practical implementation would check these as soon as possible.
　the key property of dep is the selection of decision epochs  that is  the rule for advancing time. in order for dep to branch over action selection at a given time point  time must have advanced to that point. since time always advances just past the earliest transition in the agenda  dep can only choose to start an action when some other action has just ended  or just begun. conversely  dep is unable to generate solutions where the beginning of an action does not coincide with some transition. forcing this kind of behavior is surprisingly easy.
theorem 1 dep is incomplete for temporally expressive languages.
proof: it suffices to show that dep is incomplete for lse  les  and ls e to show that dep is incomplete for all temporally expressive languages  by theorem 1  see figure 1 .
　figure 1 c  gives a ls e example which stumps dep- achieving the goal requires starting b in the middle of a  but there are no decision epochs available in that interval. dep can solve the problems in figure 1 a  and  b   but not minor modifications of these problems. for example  altering a to delete g1  in  a   forces b to start where there are no decision epochs. 
theorem 1 dep is complete for temporally simple sublanguages of pddl 1.1  but not makespan optimal.
proof: figure 1 e  presents an example of makespan suboptimality; dep would find the serial solution  but not the optimal  concurrent  plan shown. completeness follows trivially from theorem 1: temporally simple languages have sequential solutions  and dep includes every sequential plan in its search space  consider advancing time whenever possible .
1 generalized decision epoch planning
as the example of figure 1 c  shows  dep does not consider enough decision epochs. specifically  it makes the mistaken assumption that every action will begin immediately after some other action has begun or ended. in figure 1 c   however  action b has to end  not begin  after a ends. thus  it is natural to wonder if one could develop a complete de planner by exploiting this intuition. in short  the answer is  no.  but the reason why the effort fails is instructive  so we present the dep+ algorithm below.
　we generalize dep to dep+ by considering both beginning and ending an action at the current decision epoch. this would involve altering the past in the case of ending an action if the decision epoch were not sufficiently far in the future; to address this  we take our decision epochs as the current time plus the maximum duration of any action in the problem. let Δ be the maximum duration  i.e.  Δ = maxa（a δ a .
　this raises a second issue: normally one would start the search at time 1  however  this would leave out the possibility of starting actions between 1 and Δ. we take the expedient of starting the search at time  Δ  and continue to rely on simulate to prune inconsistent temporal states  e.g.  trying to start an action before time 1. in particular  the first decision epoch is at time 1  and attempting to end an action at the current decision epoch is not successful until the action would begin at or after time 1
　fattening: for every action a  we create two children of n. nas is analogous to na in dep- we commit to starting action a by adding a step s to agenda nas  with action s =a and t s =t nas  + Δ.
　the latter  nae  the essential difference from dep  differs from n only in that agenda nae  contains a new step  s  with action s =a and t s =t nae  + Δ   δ a .
　advancing time: nepoch is obtained from n by simulating to just after the first time where t nepoch  + Δ is the start or end of a step in agenda nepoch . specifically 
where d=min{t|s（agenda n  and  t=t s  or t=t s  + δ action s    and t − t n  + Δ}.
theorem 1 dep+ is incomplete for temporally expressive sub-languages of pddl 1.1.
proof: dep+ cannot generate the plan in figure 1  because there are no decision epochs in the interval where c must execute; the beginning of b is not a decision epoch  because b is only included after the current decision epoch moves to just after the end of a  that is  past the interval that c must

figure 1: dep+ can not find a plan to achieve ga … gb … gc.
execute within. similar examples demonstrate that dep+ is incomplete for all other expressive languages. 
　furthermore  arbitrarily complex examples of chaining may be constructed; for example  split each action in figure 1 into a million pieces. that is  trying to fix dep+ by considering a denser set of decision epochs  or using some kind of lookahead  is a losing proposition.
dep+ does improve on dep  but  in just one way:
theorem 1 dep+ is makespan optimal for temporally simple sub-languages of pddl 1.1.
proof  sketch : in a temporally simple language  by theorem 1  every action has a critical point where all effects occur. restrict child-generation so that the critical point of the action being added is always further in the future than the current decision epoch. then every critical point eventually becomes a decision epoch. one can show that taking every critical point as a decision epoch is sufficient to allow the generation of every slackless solution. 
1 temporally lifted progression planning
the key observation about decision-epoch planning is that decisions about when to execute actions are made very eagerly - before all the decisions about what to execute are made. dep attempts to create tight plans by starting actions only at those times where events are already happening. unfortunately  for temporally expressive languages  this translates into the following two erroneous assumptions:
*1 every action will start immediately after some other action has started or ended.
*1 the only conflicts preventing an earlier dispatch of an action  however indirect  involve actions which start earlier.
　in developing dep+  we noted the first flaw  and attempted to address it by allowing synchronization on the beginnings of actions as well as their ends. however  there does not appear to be any  practical  way of addressing the second flaw within the decision-epoch approach. one must either define every time point to be a decision epoch  branching over dense time!  or pick decision-epochs forwards and backwards  arbitrarily far  through time  as in lpgp  long and fox  1  .
　instead  we develop a complete state-space approach  by exploiting the idea of lifting over time: delaying the decisions about when to execute until all of the decisions about what to execute have been made. note that vhpop  younes and simmons  1  also lifts over time - we take a different approach that allows us to preserve state information at each search node.
definition 1 a lifted temporal state  n  is given by the current temporal variable  τ n   a model  state n   a lifted plan  agenda n   and a set of temporal constraints  constraints n .
　we retain the terminology used in dep  and dep+  to highlight the similarity of the approaches  despite the differences in details which arise from lifting time. for example  the agenda in a lifted temporal state is different from that in a  ground  temporal state - we replace exact dispatch times  t    with temporal variables  τbegin     and impose constraints through constraints n . in fact  we associate every step  s  with two temporal variables: τbegin s  and τend s . all the duration constraints τend s    τbegin s  = δ action s   and mutual exclusion constraints
  for mutually exclusive transitions x action s   and y action t    x and y are each one of begin or end   are always  implicitly  part of constraints  .
　the aspect of lifted and ground temporal states that remains identical is the current world state  state n . in both cases this maps every fluent to the value it has at the current time. in particular  this is exactly the information needed to leverage the state-based reachability heuristics developed for classical planning. with respect to lifted temporal states  tempo is a complete and optimal state-space temporal planning algorithm  given by the following child-generator function:
　fattening: given a lifted state  n  we generate a child  na  for every action  a （ a. as before na represents starting a; we add a step s to agenda action s  = a. in addition  we add  τbegin s  − τ n   to constraints. unlike before  we immediately simulate: na=simulate. in particular  everything in agenda na  has already started.
　advancing time: for every s（agenda n   we generate a child  nepocha   where a=action s . note that a has already started; this is a decision to end a. specifically  we add  τend s  − τ n   to constraints and then simulate:
nepocha	=simulate
　in essence  tempo is searching the entire space of sequences of transitions  beginnings and endings of actions   in prefix order. that is  every search state corresponds to the unique sequence of transitions that  if  assigned dispatch times and  executed  result in the given  lifted  temporal state. of course  just before terminating  tempo must actually pick some particular assignment of times satisfying constraints n   for a state  n  satisfying the goal  in order to return a ground plan. since constraints n  will  among other things  induce a total ordering  this will not be very difficult. so it should not be very surprising that tempo is guaranteed to find solutions - if there is a solution  it has a sequence of transitions  and tempo will eventually visit that sequence  and find an assignment of times.
theorem 1 tempo is complete for any temporally expressive  or simple  sub-language of pddl 1.1  moreover  makespan optimal.
proof: every potential permutation of beginnings and endings of actions can be generated by appropriate decisions at fattening and advance-time choice-points  if not pruned by simulate   . the transition sequence of any concurrent plan is one such permutation  in particular a makespan optimal solution defines one such permutation. pruning occurs if simulate   fails at a search node  i.e.  a precondition is violated. no descendant of this search node can ever change the state where the precondition is evaluated: every descendant would likewise fail to be executable. solutions are  of course  executable  so tempo does not prune any solutions. it follows that tempo is complete; makespan optimality follows from the fact that the appropriate transition sequence is in the search space  and the optimal dispatch is easy to find. 
1 discussion and related work
it should be noted that our analysis of temporal expressiveness was done at the language level  and most of our conditions for expressiveness were necessary rather than sufficient. in particular  it is obviously possible to write a domain in a temporally expressive language that does not require concurrency  or write a problem for a temporally expressive domain that does not require concurrency . for example  the  temporal  rovers domain  contains actions with temporal gap. nonetheless  rovers is a temporally simple domain. this is not a contradiction of theorem 1 - any language permitting the rovers encoding also contains other domains and problems that require concurrency. it would be interesting to catalog domain/problem level necessary/sufficient conditions for required concurrency.
　several planners have considered using classical techniques augmented with simple scheduling to do temporal planning  for example  sgplan  mips  lpg-td  and crikey  chen et al.  1; edelkamp  1; gerevini and serina  1; halsey et al.  1 . that is  the planners only consider sequential solutions  but reschedule these using the temporal information. actually  crikey does not quite fit this classification; crikey attempts to do classical planning as much as possible  and switches to a tempo like search to handle actions that could easily lead to required concurrency  envelope actions . modulo unimportant details  an equivalent perspective on crikey is as an implementation of tempo that strives to cut down the number of transition sequences actually considered by identifying actions where it is safe to immediately apply the ending transition after the beginning transition  non-envelope actions . unfortunately  our preliminary investigation reveals that the pruning that results is not completeness-preserving; the conditions used to classify actions as safe are too generous.
1 conclusion
motivated by the observation that the most successful temporal planners are incomplete  mausam and weld  1   this paper presents a detailed examination of temporal planning algorithms and action languages. we make the following contributions:
  we introduce the notion of required concurrency which divides temporal languages into temporally simple  where concurrency is never required in order to solve a problem  and temporally expressive  where it may be  classes. using the notion of temporal gap  we then decompose subsets of pddl 1.1 into a lattice which distinguishes the expressive and simple sub-languages.   we show that temporally simple languages are essentially equivalent to strips in expressiveness. specifically  we show a linear-time computable mapping into strips  with no increase in the number of actions. thus  any classical planner may be used to generate solutions to temporally simple planning problems!   we prove that a large class of popular temporal planners  those that branch on a restricted set of decision epochs  e.g.  all state-space planners like sapa  sgplan   are complete only for the temporally simple languages. in fact  there exist problems even in simple languages for which these planners are not optimal. since these decision-epoch planners won the temporal track of the last three planning competitions  we question the choice of problems used in the competitions.1  on a constructive note  we sketch the design of a complete state-space temporal planning algorithm  tempo  which we hope will be able to achieve high performance by leveraging the heuristics that power decision epoch planners.
acknowledgments
we thank j. benton  minh b. do  maria fox  david smith  sumit sanghai  and menkes van den briel for helpful discussions and feedback. we also appreciate the useful comments of the anonymous reviewers on the prior draft. this work was supported by nsf grants iis-1 and iis-1  onr grants n1-
1  n1-1  and n1-1  the lockheed martin subcontract tt1 to asu as part of the darpa integrated learning program  and the wrf/tj cable professorship.
