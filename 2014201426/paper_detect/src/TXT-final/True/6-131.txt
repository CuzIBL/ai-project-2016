 
whenever people move through their environments they do not move randomly. instead  they usually follow specific trajectories or motion patterns corresponding to their intentions. knowledge about such patterns may enable a mobile robot to robustly keep track of persons in its environment or to improve its obstacle avoidance behavior. this paper proposes a technique for learning collections of tra-
jectories that characterize typical motion patterns of persons. data recorded with laser-range finders is clustered using the expectation maximization algorithm. based on the result of the clustering process we derive a hidden markov model  hmm . this hmm is able to estimate the current and future positions of multiple persons given knowledge about their intentions. experimental results obtained with a mobile robot using laser and vision data collected in a typical office building with several persons illustrate the reliability and robustness of the approach. we also demonstrate that our model provides better estimates than an hmm directly learned from the data. 
1 introduction 
whenever mobile robots are designed to operate in populated environments  they need to be able to perceive the people in their neighborhood and to adapt their behavior according to the activities of the people. knowledge about typical motion behaviors of persons can be used in several ways to improve the behavior of a robot since it may provide better estimates about current positions of persons as well as allow better prediction of future locations. 
　in this paper we present an approach for learning probabilistic motion patterns of persons. we use the emalgorithm 1  to simultaneously cluster trajectories belonging to the same motion behavior and to learn the characteristic motions of this behavior. we apply our technique to data 
   *this work has partly been supported by the german science foundation  dfg  under contract number sfb/tr1 and by the 
ec under contract numbers 1st-1 and hpmt-ct-1. recorded with laser-range finders. furthermore  we demonstrate how the learned models can be used to predict positions of persons. 
　recently  a variety of service robots has been developed that have been designed to operate in populated environments. these robots for example  have been deployed in hospitals   museums   office buildings   and department stores  1 where they perform various services e.g.  deliver  educate  entertain  1 or assist people  1  1  1 . a variety of techniques has been developed that allows a robot to track people in its vicinity  1  1 . additionally  several authors have used models of peopic's motions to adapt the behavior of a mobile platform according to predicted movements  1  1  1 . these approaches  however  assume that a motion model is given. they provide no means to learn the parameters of the motion behavior of persons. bui et al. proposed an abstract hidden markov model  ahmm  to predict people's motion  1j. they assume that the goals and subgoals a person might have  i.e. locations the person aims to approach  are given. our approach  in contrast  is able to learn the intentions and to automatically derive the parameters of the underlying hmm. the technique described in this paper is an extension of the approach recently proposed by bennewitz et al. . we describe how to learn the intentions of persons and how to derive an hmm from the corresponding motion patterns. this hidden markov model allows the robot to maintain a belief about the current location of a person. 
　the paper is organized as follows. the next section introduces our approach to learn motion patterns from observed trajectories and describes how we generate hidden markov models to predict motions of persons. in section 1 we present several experiments illustrating the robustness of our approach for estimating the positions of single and multiple persons using laser and vision data with a mobile robot. we also give results indicating that our models provide better estimates than hidden markov models directly learned from the observations. 
1 learning motion patterns 
when people perform their everyday activities in their environment they do not move permanently. they usually stop at several locations and stay there for a certain period of time  depending on what activity they are currently carrying out. accordingly  we assume that the input to our algorithm is a 

perception 	1 

collection of trajectories between resting places. the output is a number of different types of motion 
patterns 	a person might exhibit in its nat-
ural environment. each trajectory 	consists of a sequence of positions 	accordingly  
is the first position of the person when it starts leaving a 
resting area and is the destination. the task of the algorithm described in this section is to cluster these trajectories into different motion behaviors and finally to derive an hmm from the resulting clusters. 
　throughout this paper we assume that all trajectories have the same length where is chosen as the maximum length of all trajectories. a trajectory of length is extended by linear interpolation. the learning algorithm described below operates solely on this information and therefore does not take into account the velocities of the persons during the learning phase. in our experiments  we never found evidence that the walking speed of a person depends on its intention. however  one way to incorporate velocities is to introduce further dimensions to the state variables. the necessary changes to our clustering algorithm are then straightforward. 
1 motion patterns 
we begin with the description of our model of motion patterns  which is subsequently estimated from data using em. within this paper we assume that a person engages in m different types of motion patterns. a motion pattern denoted as where m is represented by k probability distributions for each the probability distribution is computed based on subse-
quent positions on the trajectories. accordingly  specifies the probability that the person is at location alter steps given that it is engaged in motion 
pattern 	thus  we calculate the likelihood of a trajectory 
under 	the 	motion patternas 
 1  
1 expectation maximization 
in essence  our approach seeks to identify a model that maximizes the likelihood of the data. to define the likelihood of the data under the model it will be useful to introduce a set of correspondence variables denoted as here i is the index of the trajectory and is the index of the motion pattern each correspondence is a binary variable. it is 1 if and only if the th trajectory corresponds to the th motion pattern. if we think of a motion pattern as a specific motion activity a person might be engaged in  then is 1 if person was engaged in motion activity in trajectory 
　in the sequel  we will denote the set of all correspondence variables for the data item by that is  
 for any data item the fact that exactly one of its correspondence variable is 1 leads to 
　throughout this paper we assume that each motion pattern is represented by k gaussian distributions with a fixed standard deviation  the goal is to find the set of motion patterns which has the highest data likelihood. em is an algorithm that iteratively maximizes expected data likelihood by optimizing a sequence of lower bounds. in particular it generates a sequence of models denoted as ... of increasing data likelihood. the standard method is to use a function which depends on two models  and in accordance with  this 
starting with some initial model 
function is continuous as in our case  the em algorithm converges at least to a local maximum. 
　in particular  the optimization involves two steps: calculating the expectations given the current model 
  and finding the new model that has the maximum expected data log likelihood under these expectations. the first of these two steps is typically referred to as the e-step  short for: expectation step   and the latter as the m-step  short for: maximization step . 
	to calculate the expectations 	we apply 
bayes' rule  obeying independence assumptions between different data trajectories: 
where the normalization constants and ensure that the expectations sum up to 1 over all if we combine  1  and  1  utilizing the fact that the distributions are represented by gaussians we obtain: 
 1  
　finally  the m-step calculates a new model by maximizing the expected likelihood. technically  this is done by computing for every motion pattern m and for each probability distribution a new mean we thereby consider the expectations computed in the estep: 
 1  
perception 

1 	estimating the number of model components 
since in general the correct number of motion patterns is not known in advance  we need to determine this quantity during the learning phase. if the number of motion patterns is wrong  we can distinguish two different situations. first  if there are too few motion patterns there must be trajectories  that are not explained well by any of the current motion patterns. on the other hand  if there are too many motion patterns then there must be trajectories that are explained well by different model components. thus  whenever the em algorithm has converged  we check whether the overall data likelihood can be improved by increasing or decreasing the number of model components. to limit the model complexity  during the evaluation we use a penalty term that depends on the number of model components  see  l1  . this avoids that our algorithm learns a model that overfits the data  which in the worst case is a model with one motion pattern for every single trajectory. if the maximum number of iterations is reached or if the overall evaluation cannot be improved after increasing and decreasing the model complexity our algorithms stops and returns the model with the best value found so far. in most of the experiments carried out with different data sets our approach correctly clustered the trajectories into the corresponding categories. 
1 	laser-based data acquisition 
the em-based learning procedure has been implemented for data acquired with laser-range finders. to acquire the data we used several laser-range scanners which were installed in the environment so that the relevant parts of the environment were covered. first  to identify persons in the laser data our system extracts features which are local minima in the range scans that come from the legs of persons. additionally  it considers changes in consecutive scans to more reliably identify the moving people. to keep track of a person  we use a kalman filter. the state of a person at time step is represented by a vector . whereas x and represent the position of the person  the terms and represent the velocity of the person in and -direction. accordingly  the prediction is carried out by the equation: 
where 	is the time elapsed between the measurement and 	usually  sensors only give the position of an object. 
since the laser range sensor does not provide the velocities and which are also part of our state space  the mea-
surement matrix projects onto the first two components of the state space. accordingly  the predicted measurement at step is: 
in a second step we identify the resting places and perform a segmentation of the data into different slices in which the person moves. finally  we compute the trajectories  i.e. the 
perception 
sequence of positions covered by the person during that motion. when computing these trajectories  we ignore positions which lie closer than 1cm to each other. 
1 deriving hidden markov models from learned intentions 
once the intentions of the persons have been learned  we can easily derive hidden markov models to estimate their positions. to achieve this  we distinguish two types of nodes. the first class are the initial and final nodes that correspond to the resting places. to connect these nodes we introduce so-called intermediate nodes which lie on the learned motion patterns. in our current system we use a sequence of intermediate nodes for each intention . the intermediate nodes are distributed over such that the distance between two consecutive nodes is 1cm . given this equidistant distribution of the sub-nodes and assuming a constant speed with standard deviation  of the person  the transition probabilities of this hmm depend on the length  of the time interval between consecutive updates of the hmm as well as on and in our current system  this value is set to 1secs. accordingly  we compute the probability that the person will be in node given it is currently in and given that the time has elapsed as: 
here is the value of the gaussian with mean and standard deviation at position the transition probabilities for the resting places are computed based on a statistics about the average time period which elapses before the person starts this particular motion behavior after staying in the corresponding resting area. 
　please note that the resulting model can be regarded as a two-level abstract hidden markov model . whereas the higher-level goals of this ahmm correspond to the resting places of the person  the lower-level goals are the nodes along the paths to the high-level goals. 
1 	an application example 
to see how our em-based learning procedure works in practice please consider figure 1. in this example  a model for nine trajectories with three different intentions has to be learned. the leftmost image shows the initial model  the means of the three model components are indicated by circles . in the next two images one can see the evolution of the model components. the fourth image shows the model components after convergence of the em algorithm. as can be seen  the trajectories are approximated quite well by the corresponding motion patterns. finally  the rightmost picture shows the hmm derived from these motion patterns. the different resting places are indicated by rectangles and numbers. 
1 experimental results 
the technique described above has been implemented and evaluated using data acquired in an unmodified office environment. the experiments described in this section are de1 

figure 1: hidden markov model derived from learned intentions. 
signed to illustrate that the approach can learn complex motion behaviors in a typical office environment. we furthermore demonstrate that the resulting models can be used to robustly estimate the positions of persons. additionally  we compare the performance of the models learned by our algorithm to that of a standard hmm. finally  we present an extension which allows the system to deal with multiple persons. 
1 	learning intentions in an office environment 
to evaluate our approach  we applied it to data recorded over two hours in our office environment. during the acquisition phase the average speed of the person was cm/sec with a standard deviation cm/sec. from the resulting data our system extracted 1 trajectories which were successfully clustered into 1 different intentions. the resulting hidden markov model is shown in figure 1. 
1 	tracking a single person 
to analyze the applicability of the learned hmm for the prediction of the locations of a person  we used our mobile robot albert  which is a b1r platform equipped with a laser range scanner. while the robot was moving along the corridor of our department with speed up to 1cm/sec  its task was to maintain a belief about the position of the person. 
to incorporate observations into the hmm we apply the 
1 
figure 1: evolution of the probability for a person of being in different resting areas over the time. recursive bayesian update scheme: 
thereby the likelihood of an observation given the state is computed using a gaussian distribution which depends on both  the variance in the current estimate of the tracking system and the variance used during the learning of the intentions. 
　figure 1 plots for different resting areas the probability that the person stays in this particular place. whereas the x-axis represents the individual time steps  the y-axis indicates the probability. the graph also includes the ground truth  which is indicated by the corresponding horizontal line-pattern at the .1 level. as can be seen from the figure  the system can reliably determine the current position of the person. during this experiment it predicted the correct place of the person in 1% of the time. 
1 	a comparison to standard hmms 
the second experiment is designed to demonstrate that an 
hmm that takes into account the people's intentions allows a better prediction than a standard hmm that is directly generated from the observed trajectories of the persons and that does not take into a account the clustered trajectories. to evaluate the performance of the two different approaches we chose two motion patterns from those depicted in figure 1. the first pattern is the one leading from resting place 1 via 
perception 

the office containing resting place 1 to the staying area 1. the second one is the motion pattern between the places 1 and 1. we defined a standard hmm over the possible states of the person in the space where and were 
discretized in 1cm patches; and encode 1 possible incremental moves per cell. the transition probabilities were learned from the trajectories corresponding to both motion patterns by counting. we randomly chose a position along the trajectories of both patterns as the observed position of the person. the states of the hmm were initialized according to the observation model  see section 1 . after convergence of the hmm we measured the likelihood of the final destination. we compared this value to those obtained by the hmm generated by our algorithm for the trajectories corresponding to these two intentions. we repeated this experiment for different locations along the trajectories of both patterns and determined the average probability of the true goal location. whereas we obtained an average of .1 with our model  the corresponding value of the standard hmm is .1. this illustrates that our model leads to better results and that the standard independence assumption of hmms is generally not justified in this application domain. please note that similar observations have been reported by murphy 1 . in contrast to a standard hmm our model automatically chooses the transitions that correspond to the actual intention of the person. 
1 estimating the locations of multiple persons the final experiment described in this section is designed to illustrate that our models can also be used to maintain beliefs about multiple persons. the major difference to the situation with a single person is that we have to be able to represent the beliefs for the individual persons and to detect multiple persons in the observations. in our current system we learn an individual hmm for every person. 
　to track multiple persons in the range scans  we apply independent kalman filters  one for each feature. to solve the data association problem  we apply a nearest neighbor approach  i.e. we update a filter using the observation  that is closest to new filters are introduced for observations from which all predictions arc too far away. furthermore  filters are removed if no corresponding feature can be found for one second. 
　we also need to be able to identify a person in order to appropriately update the belief about the location of that person. to achieve this we additionally employ the vision system of our robot. to identify a person  we proceed as follows: every time the laser-based people tracker detects a person in the field of view of the camera  an image is collected and following three steps are applied: 
1. segmentation: the size of a rectangular area of the image containing the person is determined. 
1. feature extraction: we compute a color histogram for the area selected in the previous step. 
1. database matching: to determine the likelihood of a particular person  we compare the histogram computed in step 1 to all prototypes existing in the database. 
to determine the area in the image corresponding to a feature detected by the laser tracking system  we rely on an accu-
perception 

figure 1: typical scene with two persons walking along the corridor  left image  and corresponding estimate of the laserbased people tracking system  right image . 
rate calibration between the camera and the laser and we use a perspective projection to map the 1d position of the person in world coordinates to 1d image coordinates. whereas color histograms arc robust with respect to translation  rotation  scale and to any kind of geometric distortions they are sensitive to varying lighting conditions. to handle this problem we consider the hsv  hue-saturation-value  color space. in this color model the intensity factor can be separated so that its influence is reduced. in our current system we simply ignore this factor. throughout all our experiments we could not find any evidence that this factor negatively affected the performance of the system. the image database is created beforehand. for each person it contains one histogram which is built from 1 images. 
　to compare a given query histogram 1 with a prototype m in the database we use normalized intersection norm h i  m   1. this quantity can be computed as: 
		 1  
where / and m are color histograms both having n. bins. one advantage of this norm is that it also allows to compare partial views  i.e. when the person is close to the camera and only a part of it is visible. 

figure 1: segmentation of the two persons from the image grabbed with the camera of the robot  left image  and similarity of these segments to the data base prototypes  right image . 
　to incorporate the similarity measure provided by the vision system into the hmm of the person  we simply multiply the likelihoods provided by the laser tracking system with the similarity measure h of the query histogram is for the segment s and the data base prototype for person 


figure 1: resulting posterior after incorporating the two segments shown in figure 1 into the belief over wolfram's position. 
1r. if the current estimate of the laser tracker is not in the field of view of the camera we simply update the hmm for all persons as we do in the case in which we track a single person only. 
　as an application example consider the situation depicted in the left image of figure 1. in this particular situation two persons  wolfram and greg  are walking along the corridor within the perceptual field of the robot. the right image of figure 1 shows the estimate of the laser-based people tracking system at the same point in time. the corresponding image obtained with the robot's camera is shown in the left image of figure 1. also shown there are the two segments of the image that correspond to the two persons detected with the laser. the right image of this figure plots the similarities of the two segments to the individual prototypes stored in the data base. finally  figure 1 depicts the hmm for wolfram  who is the left person in figure 1 . as can be seen  the probabilities indicated by the size of the rectangles are slightly higher for the states that correspond to wolfram's true location. throughout this experiment the robot was able to predict the correct location of the persons in 1% of all cases. 
1 conclusions 
in this paper we have presented a method for learning and utilizing motion behaviors of persons. our approach applies the em-algorithm to cluster trajectories recorded with laser range sensors into a collection of motion patterns  each corresponding to a possible intention of a person. from these motion patterns we automatically derive an hmm that can be used to predict the positions of persons in their environment. 
　our approach has been implemented and applied successfully to trajectories recorded in a typical office environment. practical experiments demonstrate that our method is able to learn typical motion behaviors of persons and to reliably use them for state estimation. the experiments have been carried out using a mobile robot equipped with a laser-range sensor and a vision system. we have furthermore presented experiments indicating that standard hmms directly learned from the same input data are less predictive than our models. 
1 
