 
in this paper  we concentrate on the expressive power of hierarchical structures in neural networks. recently  the so-called splitnet model was introduced. it develops a dynamic network structure based on growing and splitting kohonen chains and it belongs to the class of topology preserving networks. we briefly introduce the basics of this model and explain the different sources of information built up during the training phase  namely the neuron distribution  the final topology of the network  and the emerging hierarchical structure. in contrast to most other neural models in which the structure is only a means to get desired results  in splitnet the structure itself is part of the aim. our focus then lies on the interpretation of the hierarchy produced by the training algorithm and we relate our findings to a common data analysis method  the hierarchical cluster analysis. we illustrate the results of network application to a real medical diagnosis and monitoring task in the domain of nerve lesions of the human hand. 
1 introduction 
existing approaches to hierarchical clustering and classification neglect the spatial relations of clusters or partial solution spaces. a particular class of neural network models has the potential to overcome this problem. regarding the mapping from the input space onto the space spanned by the neighborhood relations of the neurons in the network  the property of certain neural network models to keep track of neighborhood relationships of clusters of data even in cases of reduction of dimensionality is called topology preservation. the degree of topology preservation can be determined by the observation  how well neighborhood relationships in one space are preserved by the mapping onto the other space. thus  one question is: for two input vectors that are close in input space  are their best matching units close1 in the network 
1
　　 as different input vectors may be mapped onto the same neuron  in this informal explanation  the closeness of neurons 
1 
topology  the other question is: for two neurons that are neighbors in the network topology  are their associated weight vectors close in the input space  these questions led to the development of the topographic function  villmann et al.  1   that effectively quantifies the topology preservation in topographic maps. we call locations  where those maps are not continuous topological defects. topology preserving models are  among others  the self-organizing map  som   kohonen  1   the growing cell structures  gcs   fritzke  1  and the topology representing network  trn   martinetz and 
schulten  1  as well as several descandants of these examples. but all those models lack the ability of hierarchically structuring the training set. depending on the reduction of dimensionality performed by the models  there is a principal difference in degree of topology preservation each model can achieve. if the dimension of the network structure is limited  as it is the case for the som and the gcs  the real dimensionality of the data space may necessarily invoke topological defects. 
   the splitnet model for the first time succeeded in developing a hierarchical structure over the training set. it is an unsupervised learning method and in some sense comparable to the hierarchical cluster analysis  see e.g.  duda and hart  1  . for static models  like e.g. the self-organizing map  the task of the network application determines the desired interpretability of the network and thus controls such parameters of network design as number and connectivity of neurons. in dynamically growing networks  the approach is necessarily different. the incremental construction of the network up to its final size and topology is in general controlled by specific performance criteria. the training result is a network  where not only the weights contain relevant information. additionally  the size of the network  the distribution of neurons and the emerged connectivity inside the network implicitly encode information on the trained sample set. compared to the above-mentioned topology preserving models  the tree-structured organization of topologically connected parts of the splitnet network adds a completely new dimension to the interpretability of the network model. the hierarchy offers 
includes also the identity of those neurons. 

structured knowledge on various levels of abstraction and generalization as well as optimized access to samples of the training population. 
　the rest of the paper is organized as follows. in the next section  we will outline the basic methods related to the neural model used in our approach. section 1 will present the principle of the splitnet model and in sec. 1 the role of the emerging hierarchical structure is explained. we then present results of the application of the splitnet model in the medical domain of finger movement pattern analysis. a summary and final remarks will conclude the paper. 
1 related work 
the hierarchical cluster analysis  either the divisive or the agglomerative approaches  are methods that progressively split or link clusters of data. the result of the analysis can be visualized as a dendrogram  see fig. 1   which is a two-dimensional tree structure that shows the order of linkage  for the agglomerative case  and the distance or similarity at which this linkage of clusters was performed. thus  this method is able to display the clustering of data  whereby the result depends on the distance measure that determines the closeness of clusters and/or samples. specific variants of agglomerative versions of the hierarchical cluster analysis are e.g. the single linkage and complete linkage methods  which minimize the minimum or maximum distance of cluster elements  respectively  during each merger of two clusters. for the comparison intended in this paper  cf. sec. 1   we will use the centroid method  which selects those clusters with the minimum distance between their means. 

	a 	b 	c 	d 	e 	f 
figure 1: example of a dendrogram and the distance information available for each linkage level 
　because of the explicit distance information contained in the dendrogram for each linkage of clusters  hierarchical clustering is a flexible way of detecting the resulting number of clusters given a certain threshold value. however  it is not possible to reason from the real spatial relationship of the observed pattern. there is no similarity information other than the one for linked clusters. similar statements are true of course for divisive methods. so the hierarchical clustering methods are useful tools for a preliminary analysis of the data  but they do not provide additional ways for explanation of the clustering results and do not enable reasoning on alternative solutions based on neighborhood observations. 
　such inspection of neighboring clusters and samples can be performed by topology preserving networks. as indicated above  several models like the gcs or the trn already exist for topology preserving representation of a training set. the growing cell structures  gcs  are a dynamic vector quantization model. different criteria  e.g. the quantization error  determine the insertion position of a new neuron. removal strategies yield an adaptive quantizer that is superior to the original som  but the gcs model also uses an a priori specified dimensionality  through the choice of simplices  and thus is prone to the appearance of topological defects for high dimensional data spaces. the trn algorithm also approximates the distribution of input data and constructs topology preserving connections between its neurons. in the limit  it is able to find the delaunay triangulation of a data set  thus it generates  by virtue of not being fixed to a given dimensionality  a nearly perfectly topology preserving map. but both neural models only provide data analysis on a flat level. they cannot provide views on the data at different granularities  and thus lack the advantages of methods like the hierarchical cluster analysis. 
1 the splitnet model 
splitnet is a topology preserving  dynamically growing model for unsupervised learning and hierarchical structuring of data  rahmel  1b . starting with a single  small kohonen chain  kohonen  1   localized insertion and deletion criteria enable an efficient quantization of the data space. the hierarchy in the architecture grows  if one of the following splitting criteria is satisfied: 
  detection of topological defects 
  deletion of neurons by an aging mechanism 
  significant local variances in quantization errors or 
  significant local variances in edge lengths. 
those criteria are checked several times during progress of training. if a criterion is satisfied  the affected chain is split into two or more subchains which are added to the network at one level lower in the hierarchy. the node in the hierarchy that formerly represented the unsplit chain now serves as a generalized description and access structure for the new son nodes. figure 1 illustrates this basic mechanism. if a topological defect is found  e.g. between neurons 1 and 1  which are close in input space but distant in the chain of neurons   the chain is split and 
	rahmel  blum  & hahn 	1 


figure 1: example of splitting a chain because of a topological defectnodes representing the fragments are added as descendants to the tree. path decisions in the so constructed hierarchy will be made according to the mean of the weight vectors of the neurons in the chain  therefore the mean is also indicated in the figure. the topology preserving construction of the network structure provides local neighborhood information that is necessary for incremental retrieval of nearest neighbor to a given input vector. the dashed lines in fig. 1 indicate this type of knowledge. the neighborhood relations are kept as lateral connections defining the topology of the network space. they are responsible for the high degree of topology preservation in splitnet and enable a fast and incremental search for a set of nearest neighbors. a more rigorous and exhaustive treatment of these aspects and retrieval results can be found in  rahmel and villmann  1 . the purpose of such a set of nearest neighbors is e.g. to serve as the basis for the k-nearest-neighbor rule in decision making processes  cf. sec. 1 . 
　since unsupervised learning methods provide no direct classification  the training result has to be interpreted in the context given by the training data. for the splitnet model  we observe three containers of knowledge that can be used for the tasks in applications like the one described in this paper: 
neuron distribution: the insertion criterion determines the error function to be minimized. quantization of the data set allows local estimation of sample density. 
topology: the connections between neighboring neurons provide information on where to find similar cases. measuring topological defects yields the search depth for incremental retrieval of nearest neighbors to a given query. 
1 
hierarchy: the hierarchical structure of the network contains different levels of generalization and abstraction. it allows a fast tree search for best matches and insightful visualization of the data structure for the domain expert. 
　the utility of the neuron distribution is comparable to reference vector placement in quantization algorithms  gray  1 . the neuron positions thus minimize the average reconstruction error for all elements of the data set. interpretation of the network topology is described e.g. in  rahmel  1a . it can be shown that splitnet produces networks with only small topological defects  indicated by low values of the topographic function  villmann et ai  1 . this specific property limits the search effort for procedures like the probing algorithm  lampinnen and oja  1   which conquers local neighborhoods of neurons in order to find a better match to a given input. in the following  we illustrate the semantics of the hierarchical structure developed by methods like splitnet. 
1 interpretation of hierarchy 
hierarchical organizations offer additional properties to make use of in data analysis and structure utilization. one rather general aspect is the fact that a hierarchical structure - like any search tree - provides fast access to the terminal nodes. for neural networks like splitnet  this results in accelerated training runs since the search for the best matching unit is supported by the hierarchical network structure. this determination of the best match can be summarized as follows: 
  tree search for a candidate unit using the means of chain vectors for descending the hierarchy  and then 
  local search through topological connections for a possibly better match. 
　the local search costs additional time  but since it is strictly local and depending on the degree of topology preservation in the network  it could demonstrated that the improved topology preservation of the splitnet model considerably increased the speed of best matching unit access  rahmel  1 . in addition  the larger the network  the less the influence of the additional local search procedure in comparison to the savings due to the hierarchical arrangement. 
　the hierarchies produced by classification or decision trees  breiman et a/.  1   quinlan  1  yield simple  crisp  and explicit tests as path decisions in nodes at the expense of flexibility of the decision regions. the orientation of hyperplanes generated by those tests is limited to the dimensionality of the respective test. unfortunately  higher dimensionality of the test yields both higher flexibility and massively growing computational effort for determination of optimal tests. therefore  in practical applications  tests are often one- or two- dimensional and the corresponding hyperplanes separating subspaces of the sample space are orthogonal to the coordinate axes or depending on only two of the possible vector components. in contrast to this  the splitnet structure offers implicit tests that cover the whole information contained in the description of a sample. the decision regions of splitnet approximate the voronoi regions given by the sample population and thus minimize quantization errors imposed by generalization inside the regions. 
　classification or decision trees select the tests for path decisions according to the gain criterion for classification of samples. in an unsupervised setting where class information is not available  efficient sample localization plays the most important role. in order to minimize the search effort  we need a test that maximizes the information about the location of the nearest sample. the kohonen model provides a solution for this task. as demonstrated in  ritter et a/.  1   the weight adaptation of the algorithm leads to a discrete approximation of principal curves by kohonen chains. if we divide the sample population according to the placement of neurons and recursively repeat this subset construction  we get a hierarchic structure that on every level optimizes the information on sample locations. thus  for an average test sample  we have an efficient access to the best match of the training population. in this respect  the tree is interpretable as a decision tree  regarding the optimization of spatial information  but still trainable and adpatable to slight changes in the training data set. it thus combines interpretability and flexibility of symbolic and connectionist machine learning methods  respectively. 
　the interpretation of a hierarchical structure like the one generated by splitnet combines the knowledge on the above-mentioned property of the kohonen algorithm with the splitting reasons of the splitnet model  which deviate from this principle. path decisions in the splitnet tree have definite semantics to be used when descending the tree and relating accessed clusters with others that are reachable through the topology of the network. 
1 diagnosis and monitoring of ulnaris lesions 
we now briefly present an application of the splitnet model in the domain of nerve lesions of the human hand. we will outline the general problem and describe the results obtained by using the hierarchical neural model. 
　the human hand is provided with the radial  median and ulnar nerve. the ulnar nerve provides sensory function for the small and ring finger and innervates the intrinsic muscles of the hand. these muscles are crucial in balancing and coordinating the flexor and extensor muscles  rendering possible fine movement such as grip and pinch. while assessing sensory function is feasible  objective analysis of motor function is quite difficult. clinical investigation includes grip force measurement and recording of active and passive range of motion. besides these factors  ulnar nerve dysfunction causes changes in coordination of the movement which cannot be measured by instruments. 
　in contrast to a normal  physiological movement pattern  fig. 1 a    the dynamic disorder 'rolling' describes the pathological flexion of the finger. this movement resembles the rolling of a carpet  fig. 1 b  . as an effect  patients are not able to grasp an object because their fingers push it out of the palm. the dynamic disorder 'clawing' describes the hyperextension of the mp joint with flexion of the pip and dip joint1 while the finger is in resting position  fig. 1 c  . these descriptions are based on the experience of the examiner. changes in quality and especially improvement of fine motor activities after nerve repair are difficult to detect and to quantify. if nerve repair fails  there are different operations to rebuild the movement pattern. in these cases  the outcome of surgery also cannot be quantified. until now  there was no convenient measurement system to distinguish finger movement patterns. 

figure 1: different forms of finger movement pattern:  a  normal  physiological movement   b  rolling  and  c  clawing  see text . each picture shows nine steps of finger movement during one cycle of closing  black lines  and opening  gray lines  the fist. 
　based on kinematic research we established a measurement system to get real-time data of human finger movement. attempts to analyze these data with classical mathematical methods like discriminant analysis failed to distinguish between normal and pathological movement. statistical clustering provides a good first insight into the structuring of the data but is not able to support the specific needs in this application like  for example  retrieval of samples and their comparison to a group of similar data  as it is required for diagnostic applications. for demonstration purposes  figure 1 shows an example of a tree structure generated with a small fraction of the available data. despite the fact that our preprocessing generates high-dimensional training vectors  we used no further dimension reduction method. the reason is the necessity to display the hierarchy with the neuron weights retranslated into finger positions. by this  physicians can evaluate the position of a newly encountered data vector in the tree. in fig. 1  the upper part of the tree contains roughly the patterns for 'clawing'  while the bottom part corresponds to physiological 
1
　　the mp  pip and dip joints are the three finger joints ordered from the base joint between hand and finger to the tip. 
	rahmel  blum  & hahn 	1 


figure 1: hierarchical representations generated by splitnet. the retranslation of neuron weights allows the display of interpretable finger movements in the learned hierarchical arrangement. 

movement and 'rolling'. 
　since we use unsupervised learning and therefore provide no class information for the training pattern  the resulting tree is obviously not a classification tree. the full information is here contained in the hierarchical structure and the topological connections of the nodes  which are not shown in the figure . pattern # 1  the only 'clawing'-data in the lower subtree  is an example of the case that the division of the data space by the path decisions of the tree is suboptimal with respect to path decisions alone. presentation of an input vector that closely matches the vector corresponding to pattern # 1 would cause the tree search  based on the vector means  to descend into the upper half of the tree in fig. 1. further path decisions would then yield pattern #1 as best match candidate. but the topological information that is accessible for the interpretation component of the network will show that this pattern is connected to pattern #1 in the lower subtree and local  topological search will identify the correct best match. 
　similarly  further analysis of branches and subtrees reveals the full organization of the hierarchy. the sequence of generalizing non-terminal nodes supports the physician in understanding relative positions of different patient vectors. at each non-terminal node  the reason for branching - outlier splitting  topological defect  etc. - is accessible  so a reasonable interpretation of the emerging hierarchy  supported by the local topological connections  not shown in the figure   is rendered feasible. 
　we currently have more than 1 pattern of 1 patients with different forms of lesions and at various stages of motion recovery. healing progress as well as success of 
1 
surgery can be monitored in our network that is trained with all available data. a sequence of pattern representing the recovery process of a patient can be mapped onto the fully trained network. the interpretation component provides the physician with comparable cases for each pattern and so  by relating current data to previous cases  an evaluation of the actual healing process is possible. 
　a comparison of the results obtained by splitnet with those of a hierarchical cluster analysis clarifies the strength of the neural model. we performed a run of the clustering process and examined a subgraph of the dendrogram with about as many terminal nodes as the splitnet tree described above. the result was not surprising. 
the clustering produced nearly the same groups of data represented by leaf nodes  thus supporting the clustering abilities of the splitnet model. however  despite the fact that distance information is available for the merging level of two clusters  interpretation of the dendrogram from a medical point of view was possible only in a very limited way. whereas the neuron chains representing the terminal nodes in splitnet arrange themselves in a direction that best reflects the largest variation in the associated movement pattern  the intrinsic property of the underlying kohonen model   such information is not available in the cluster analysis. moreover  the dendrogram provides information on the order of the cluster linkages  yet it does not contain explicit or implicit information on the spatial relationships of clusters. this is a crucial property for a reliable diagnosis of new cases which are not contained in the center of existing clusters. in order to compare those with nearest neighbors  reliable information on cluster connectivity is necessary. 
the lateral connections between neurons in the splitnet model facilitate reasoning for class assignment based on neighborhood considerations. we can use the retrieval properties of the topology preserving network structure for the enumeration of the nearest neighbors and application of the k-nearest-neighbor rule  duda and hart  1  yields a majority vote  if training samples can be associated with classification information. 
1 summary and outlook 
we briefly presented a recent neural network model which differs from existing models in the hierarchical structure that it creates by the training algorithm. the resulting network provides different sources of knowledge for network interpretation and we focused our discussion on the use of the hierarchy. we illustrated properties and advantages of the flexible tree structure. the applicability of the network model to real world tasks is shown with the example of a diagnosis system for ulnar nerve lesions. our approach for the first time applies pattern recognition by a neural net approach to human finger movement. besides simple clustering abilities  the applied splitnet model provides support for the interpretation of both the learning processes which have occurred and the emerged hierarchical structure. thus  in our case  interpretation of the images  which are retranslations of neuron weights into the semantics of training vectors  enhances our knowledge of the finger movement pattern. 
　so far  from the medical point of view  we do not know if we portray the whole spectrum of ulnar nerve dysfunction. more data have to be recorded and our aim is to build up a neural net containing all types of normal and pathological movement. then we are able to represent all ulnar nerve lesions by recording finger movement and classify the new movement pattern by observing the mapping performed by the neural net onto a certain location in the tree  for which clinical diagnosis is already accessible. 
 martinetz and schulten  1  th. martinetz and k. schulten. topology representing networks. neural networks  1   1. 
 quinlan  1  j.r. quinlan. c1: programs for machine learning. morgan kaufman  1. 
 rahmel and villmann  1  j. rahmel and t. villmann. interpreting topology preserving networks. technical report lsa-1e  university of kaiserslautern  1. 
 rahmel  1a  j. rahmel. on the role of topology for neural network interpretation. in w. wahlster  editor  proc. of the ecai  1. 
 rahmel  1b  j. rahmel. splitnet: learning of hierarchical kohonen chains. in proc. of the icnn '1  washington  1. 
 rahmel  1  j. rahmel. topology preserving neural networks - connectionist learning of structured knowledge. phd thesis  university of kaiserslautern  april 1. 
 ritter et al.  1  h. ritter  th. martinetz  and k. schulten. neural computation and self-organizing maps. addison wesley  1nd edition  1. 
 villmann et a/.  1  th. villmann  r. der  m. herrmann  and th. martinetz. topology preservation in selforganizing feature maps: exact definition and measurement. ieee transactions on neural networks  1. to appear. 

