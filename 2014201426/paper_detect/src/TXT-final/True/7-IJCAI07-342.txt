
we investigate a solution to the problem of multisensor perception and tracking by formulating it in the framework of bayesian model selection. humans robustly associate multi-sensory data as appropriate  but previous theoretical work has focused largely on purely integrative cases  leaving segregation unaccounted for and unexploited by machine perception systems. we illustrate a unifying  bayesian solution to multi-sensor perception and tracking which accounts for both integration and segregation by explicit probabilistic reasoning about data association in a temporal context. unsupervised learning of such a model with em is illustrated for a real world audio-visual application.
1 introduction
there has been much recent interest in optimal multi-sensor fusion both for understanding human multi-modal perception  ernst and banks  1; alais and burr  1  and for machine perception applications  beal et al.  1; perez et al.  1 . most of these have considered the simple cases in which the observations are known to be generated from the same latent source  and the task is to make the best estimate of the latent source state by fusing the observations.  we call models assuming such a fused structure pure fusion models.  however  in most real world situations any given pair of observations are unlikely to have originatedfromthe same latent source. a more general problem in multi-sensor perception is therefore to infer the association between observations and any latent states of interest as well as any fusion  integration  or fission  segregation  that may be necessary. this data association problem has been of more long standing interest in the radar community  bar-shalom et al.  1 . the data association may not merely be a nuisance variable required for correct sensor combination. it can be of intrinsic interest for understanding the data. for example  a key task in interpreting a meeting for a human or machine is not just to infer who was there and what was said  but to correctly associate visual and acoustic observations to understand who said what.
　in this paper  we illustrate the commonality of these multisensor perception problems and provide a unifying  principled bayesian account of their solution  reasoning explicitly about the association of observationswith latent states. moreover  we illustrate that using the em algorithm  inference can be performed simultaneously with parameter estimation for unsupervised learning of perceptual models.
1 theory
humans and machines equipped with multiple sensor modalities need to combine information from various senses to obtain an accurate unified perception of the world. perception requires computingtangible quantities of interest in the world  e.g. people's locations  as well as the association between sensor observations  e.g. who said what . to formalize the perceptual problems faced by a human or machine equipped with multiple sensor modalities  we use a probabilistic generative modelling framework. the task of perception then becomes that of performing inference in the generative model  where object states and data association are both inferred.
　we can frame the inferenceof data association equivalently as a model selection or a structure inference problem. a graphical model for the process of generating observations in two different modalities d = {x1 x1} from a single source with latent state l is illustrated in fig.1 a . the source state is drawn independently along with binary visibility/occlusion variables  m1 m1  specifying its visibility in each modality. the observations are then generated with xi being dependent on l if mi = 1 or on a background distribution if mi = 1.
alternately  all the structure options could be explicitly enumerated into four separate models  and the generation process then first selects one of the four generative models before selecting l and generating the observations according to the dependencies encoded in that model. inference then consists of computing the posterior over the latent state and the generating model  either as specified by the two binary structure variables mi or a single model index variable  given the observations. an observation in modality i is perceived as being associated with  having originated from  the latent source of interest with probability p mi = 1|d   which will be large if the observation is likely under the foregrounddistribution and small if it is better explained by the background distribution.
an illustrative example
to illustrate with a toy but concrete example  consider the problem of inferring a single dimensional latent state l representing a location on the basis of two point observations

figure 1:  a  graphical model to describe un-reliable generation of multi-modal observations xi  occlusion semantic  b c  generation with one or two source objects  multi-object semantic  c-g  inference in occlusion semantic model. observations  d  x1 x1 strongly correlated   e  x1 strongly discrepant   f  x1 x1 both strongly discrepant   g  x1 x1 both moderately discrepant. likelihoods of the observations in each of two modalities in black  prior in grey.
in separate modalities. for the purpose this illustration  let l be governed by an informative gaussian prior centered at zero  i.e.  p l  = n l|1 pl  and the binomial visibility variables have prior probability p mi  = πi.  note that we use precisions rather than covariances throughout . if the state is observed by sensor i  mi = 1  then the observation in that modality is generated with precision pi  such that xi ゛ n xi|l pi . alternately  if the state is not observed by the sensor  its observation is generated by the background distribution n xi|1 pb   which tends toward un-informativeness with precision pb ★ 1. the joint probability can then be written as in eq.1. if we are purely interested in computing the posterior over latent state  we integrate over models or structure variables. for the higher level task of inferring the cause or association of observations  we integrate over the state to compute the posterior model probability  benefiting from the automatic complexity control induced by bayesian occam's razor  mackay  1 . defining for brevity mi 《  mi = 1  and mi 《  mi = 1   we can write down the posteriors as in
eq.1.
p d l m  = n x1|l p1 m1n x1 pb  1 m1 n x1|l p1 m1
           ，n x1 pb  1 m1 n l|1 pl p m1 p m1 	 1  p m1 m1|d  『 n x1 pb n x1 pb 
p m1 m1|d  『 exp  1p1pl/ p1 + pl  n x1 pb   1  1 p m1 m1|d  『
　1 x1 p1 + pl    1x1p1 + x1 p1 + pl  exp  -
　1 p1 + p1 + pl
　intuitively  the structure posterior  eq.1  is dependent on the relative data likelihood under the background and marginal foreground distributions. the posterior of the fully segregative model depends on the background distributions and hence tends toward being independent of the data except via the normalization constant. in contrast  the posterior of the fully integrative model depends on the three way agreement between the observations and the prior. the assumption of a one dimensional gaussian prior and likelihoods is to facilitate illustrative analytical solutions; this is not in general a restriction of our framework as can be seen in sec.1.
　fig.1 illustrates a schematic of some informative types of behavior produced by this model. if the data and the prior are all strongly correlated  fig.1 d   such that both observations are inferred with near certainty to be associated with the latent source of interest  the fused posterior over the location is approximately gaussian with p l|x1 x1  「 n l| l pl|x  where
. if x1 is strongly dis-
crepant with x1 and the prior  fig.1 e    it would be inferred that sensor 1 was occluded and its observation irrelevant. in this case  the posterior over the location is again near gaussian but fusing only x1 and the prior;.
if both x1 and x1 are strongly discrepant with each other and the prior  fig.1 f    both observations are likely to be background originated  in which case the posterior over the latent state reverts to the prior pl|x = pl   l = 1. finally  if the correlation between the observationsand the prior is only moderate  fig.1 g   such that the posterior over the structural visibility variables is not near certain  then the posterior over the latent state is a  potentially quad-modal  mixture of gaussians corresponding to the 1 possible models. for real world data  occlusion  or other cause for meaningless observation is almost always possible  in which case assuming a typical pure fusion model  equivalent to constraining m1 = m1 = 1  can result in dramatically inappropriate inference  fig.1 box  .
incorporating temporal dependencies
now we consider the case where the latent state of interest and data association are correlated in time. a graphical model to describe the generation of such data is illustrated in fig.1 a . the state l and model variables mi are each connected through time  producing a factorial hidden markov model  ghahramani and jordan  1 . to generate from this model  at each time t the location and model variables are selected on the basis of their states at the previous time and the transition probabilities p lt+1|lt  and p mti+1|mti . conditional on these variables  each observation is then generated in the same way as for the previous independently and identically distributed  iid  case. inference may then consist of computing the posterior over the latent variables at each time given all t available observations   i.e.  smoothing  if processing is off-line. if the processing must be on-line  the posterior over the latent variables given all
the data up to the current time p lt mt|x1 t x1 t   i.e.  filtering  may be employed. multi-modal source tracking is performed by computing the posterior of l  marginalizing over possible associations. we have seen previously that the posterior distribution over location at a given time is potentially non-gaussian  fig.1 e  . to represent such general distributions  we can discretize the state space of l. in this simple case  exact numerical inference on the discretized distribution is tractable. given state transition matrices p lt+1|lt  and p mt+1|mt   we can write down recursions for inference in this factorial hidden markov model in terms of the posteriors  as
	αt 『	 1 
                                         1 x1t 1 p dt|lt m1t 1 p lt|lt 1 yp mit|mit 1 αt 1
	lt 1 m  	i=1
	γt 『	 1 
t+1t +1 p t p 1tl t1|lt qi1 p1 mit|mitt |m1 αit t 1 αt γt+1
                 p lt+1|lt  p m l  m l  m qi=1 i
　filtering makes use of the forward α recursion in eq.1 and smoothing the backward γ recursion in eq.1  which are analogues of the α and γ recursions in standard hmm inference. the benefits of temporal context for inference of source state and data association are illustrated in fig.1 bg . fig.1 b  illustrates data from a series of t observations 
  in two independent modal-
ities  of a continuously varying latent source l. these data include some occlusions/sensor failures  where the observation s  are generated from a background distribution  and an unexpected discontinuous jump of the source. the temporal state evolution models for l and m are simple diffusion models. the robustness of source location inference by a pure fusion model without temporal context  fig.1 e   is very limited  as it must always averages over observations  which is inappropriate when they are actually disassociated. a data association model  fig.1 f   is slightly more robust  inferring that the generation structure was likely to have been different when the observations are discrepant. however  without temporal context  it cannot identify which observation was discrepant  and hence produces a non-gaussian  multi-modal posterior for l. including some temporal history  an on-line filtering data association model can infer which observations are discrepant  and discount them  producing much smoother inference  fig.1 g  . in this case  after the discontinuity in state  the fully disassociated observation structure is inferred and based on the temporal diffusion model  approximately constant location is inferred until enough evidenceis accumulated to support the new location. finally  an off-line smoothing data association model  fig.1 c   infers a robust  accurate trajectory. for this case  the marginal posterior of the association variables is shown in fig.1 d . the illustrative scenarios discussed here generalize in the obvious way to more observations. with many sensors  the dis-association of a smaller number of discrepant sensors can be inferred even without prior information. in a pure fusion scheme  a single highly discrepant sensor can throw off the others during averaging.
an illustrative example with multiple objects
there is another simple way in which two multi-modal point observations can be generated  i.e.  each could be generated by a separate source instead of a single source. the choice of the multi-source versus the fused generating model

figure 1:  a  graphical model to describe generation of observations xi with temporal dependency.  b  synthetic input dataset in modality x1 and x1.  c  posterior probability of l and  d  posterior probability of model structure for the temporal data association model. posterior probability of l in  e  pure fusion model  f  iid data association model  g  filtered data association model.
 fig.1 b   can also be expressed compactly as structure inference as before by also using two latent state variables as in the single source case  but requiring equality between them if m = 1 and independence if m = 1  fig.1 c  . it is possible to enumerate all five possible model structures and perform the bayesian model selection given the data. however  frequently the semantics of a given perceptual problem correspond to a prior over models which either allows the four discussed earlier   occlusion semantic   or a choice between one or two sources   multi-object semantic  . the occlusion semantic arises for example  in audio-visual processing where a source may independently be either visible or audible. the multi-object semantic arises  for example in some psychophysics experiments shams et al.  1  where both sensors have definitely observed an interesting event  and the task is to decide what they observed  which is conditionally dependent on whether they observed the same source or not.
　we will now illustrate the latter case with a toy but concrete example of generating observations in two different modalities x1 x1 which may both be due to a single latent source  m = 1   or two separate sources  m = 1 . using vector notation  the likelihood of the observation x =  x1 x1 t given the latent state l =  l1 l1 t is n x|l px  where px = diag  p1 p1  . let us assume the prior distributions over the latent locations are gaussian but tend to uninformativeness. in the multi-object model the prior over lis p l|m = 1  = n l|1 p1  is uncorrelated  so p1 = p1i and p1 ★ 1. in the single object model  the prior over lis p l|m = 1  = n l|1 p1  requires the lis to be equal so p1 is chosen to be strongly correlated. the joint probability of the whole model and the structure posterior are given in eq.1.
p x l m  = n x|l px n l|1 p1  1 m n l|1 p1 mp m  p m|x  『 z n x|l px n l|1 p1  1 m n l|1 p1 mp m 
l
p m = 1|x  『 n x|1  p x1 + p 1  1 p m = 1  p m = 1|x  『 n x|1  p x1 + p 1  1 p m = 1 	 1 
　a schematic of interesting behavior observed is illustrated in fig.1. if x1 and x1 are only slightly discrepant  fig.1 a    then the single object model is inferred with high probability. the posterior over l is also strongly correlated and gaussian about the point of the fused interpretation; p l|x  「
n l| l pl|x  where l . the location marginals for each li are therefore the same and aligned at  l. if x1 and x1 are highly discrepant  fig.1 b    then the two object model is inferred with high probability. in this case the posterior p l|x  is spherical and aligned with the observations themselves rather than a single fused estimate; i.e.
 l x  pl|x = px + p1.
　the inferences discussed so far have been exact. there are various potential approximations such as computing the location posterior given the map model  which may be acceptable  but which crucially misrepresents the state posterior for regions of input space with intermediate discrepancy  c.f. fig.1 d  . alternately  the model probability could be approximated using a map or ml estimate of the state. the agreement between the bayesian and map solution depends on how sharp the state posterior is  which depends on both the agreement between the observations and the precision of their likelihoods. using the ml estimate of the state will not work at all as the most complex model is always selected.
　previous probabilistic accounts of human multi-sensory combination  e.g.  ernst and banks  1; alais and burr  1   are special cases of our theory  having explicitly or implicitly assumed a pure fusion structure.  triesch and von der malsburg  1  describe a heuristic democratic adaptive cue integration perceptual model  but again assume a pure fusion structure. hence these do not  for example  exhibit the robust discounting  sensory fission or segregation  of strongly discrepant cues observed in humans  ernst and banks  1 . as we have seen  such fission is necessary for perception in the real world as outliers can break pure fusion schemes. we provide a principled probabilistic  adaptive theory of temporal sensor combination which can account for fusion  fission and the spectrum in-between. the combination strategy is handled by a bayesian model selection without recourse to heuristics  and the remaining parameters can be learned directly from the data with em. a more challenging question is that of realistic multi-dimensionalobservationswhich depend

figure 1: inference in multi-object semantic toy model.  a  for correlated inputs  x1 「 x1  the presence of one objects is inferred and its location posterior is the probabilistic fusion of the observations.  b  for very discrepant inputs   the presence of two objects is inferred and the location posterior for each is at the associated observation.
in complex ways on the latent state  a topic we will address in the real world application discussed next.
1 bayesian multi-sensory perception for audio-visual scene understanding
to illustrate the application of these ideas to a real  large scale machine perception problem  we consider a task inspired by  beal et al.  1 ; that of unsupervised learning and inference with audio-visual  av  input.  beal et al.  1  demonstrated inference of an av source location and learning of its auditory and visual templates based on correlations between the input from a camera and two microphones - useful for example  in teleconferencing applications . the av localization part of this task is similar to the task required in psychophysics experiments such as  alais and burr  1  where humans are also reported to exhibit near bayes optimal sensor fusion. we now tackle the bigger scene understanding problem of inferring how the av data should be associated through time  pure fusion was previously assumed   i.e  whether the source should be associated with both modalities 

figure 1: graphical model for av data generation.
or only one  or if there is no source present at all.
1 introduction
a graphical model to describe the generation of a single frame of av data d = {x1 x1 y} is illustrated in fig.1. a discrete translation l representing the source state is selected from its prior distribution πl and its observability in each modality  w z  are selected from their binomial priors. for simplicity  we only consider source translation along the azimuth. consider first the all visible case  w z = 1 . the video appearance v is sampled from a diagonal gaussian distribution n v|μ φ  with parameters defining its soft template. the observed video pixels are generated by sampling from another gaussian n y|tlv Ψi  the mean of which is the sampled appearance  translated by l using the transformation matrix tl. the latent audio signal a is sampled from a zero mean  uniform covariance gaussian i.e.  n a|1 ηi . the time delay between the signals at each microphone is drawn as a linear function of the translation of the source n t|αl + β ω . given the latent signal and the delay  the observation xi at each microphone is generated by sampling from a uniform diagonal gaussian with the mean a  with x1 shifted t samples relative to x1; n x1|a v1i   n x1|tta v1i . if the video modality is occluded  z = 1   the observed video pixels are drawn from a gaussian background distribution independently of l and audio data. if the audio modality is silent  w = 1   the samples at each speaker are drawn from backgrounddistributions n xi|1 σii  independently of each other  l and the video.
　to describe the generation of a series of correlated frames  the iid observation model in fig.1 is replicated and a factored markov model is defined over the location and association variables  l w z  exactly as the toy model was developed previously  refer fig.1 a  . using j to index time  the state evolution distribution over the location shift is defined in the standard way p lj+1|lj  = Γlj lj+1  where the subscripts pick out the appropriate element of the matrix Γ. the observability transitions are defined similarly as p wj+1|wj  = Θwj wj+1 and p zj+1|zj  = Ωzj zj+1. suppressing indexing by j for clarity  the joint probability of the model including visible d = {x1 x1 y}jj=1 and hidden variables  factorizes as

1 inference
consider first the inference for a single frame of data. the posterior marginal of interest for this task is that of the discrete location and visibility structure variables p l w z|d . because of the linear-gaussian structure of the model  the latent appearance variables a and v can be analytically integrated out  leaving only the inter-microphone delay t to be summed out numerically when computing p l w z|d . conditioned on the fused model  and other discrete variables  z = 1 w = 1 t l  the posteriors over the latent signals are gaussian  n a|μa|x t νa  and n v|μv|y l νv   with precision and mean given by 
 
νv = φ + Ψ. the marginal video likelihood is also gaussian with μy|l = tlμ  νy|l =  Ψ 1 +tlφ 1tlt   1. expressions for the likelihood of the fully fused model and the source location  eq.1  and the likelihood of the fully fissioned model  eq.1  can be derived in terms of these statistics. defining again zi 《  zi = 1  and zi 《  zi = 1  etc  we can write p d|w z l  『 z p y v|l z xz p x1 x1 a t|l w 
	v	t	a
　for a single observed modality  the likelihood is a mixture of terms from eqs.1 and 1  along the lines of eq.1. to infer the posterior over location and observability for iid frames  these likelihoods can be combined with the discrete prior distributions over the location and observabilities. to infer the probability of location and observability over time given the data  the likelihoods are used in recursions exactly like those in eqs.1 and 1.
1 learning
all	the	parameters	in	this	model	θ	=

are jointly optimized by a standard em procedure of alternately inferring the posterior distribution q h|d  over hidden variables h given the observed data d  and optimizing the expected complete log likelihood or free energy
.	as this is a complex model of
many parameters  in the interest of space  we present just two informative updates1. eq.1 gives the update for the mean μ of the source visual appearance distribution. this is defined in terms of the posterior mean of the video appearance given the data d for each frame j and translation l  as inferred during the e step:
		 1 
intuitively  the result is a weighted sum of the appearance inferences over all frames and transformations  where the weighting is the posterior probability of transformation and visibility in each frame. the scalar precision parameter of background noise is given by eq.1  where nf specifies the number of samples per audio frame.
	σi 1	○ xq wj|d  xji txji/nf xq wj|d 	 1 
	j	j
again  it is intuitive that the estimate of the background variance should be a weighted sum of square signals at each frame where the weighting is the posterior that the source was silent in that frame. in an iid context  the posterior marginals to weight with  e.g. p lj zj|d   are given visible variable  dj. in the markov model context  the posterior marginal given the whole available data set d is used.
1 demonstration
results for an av sequence after 1 cycles of em are illustrated in fig.1. in this sequence  the user is initially walking and talking  is then occluded behind another person while continuing to speak  and then continues to walk while remaining silent. fig.1 a  illustrates three representative video frames from each of these segments with the inferred data association and location superimposed on each.
tracking with the iid  pure fusion model
to illustrate tracking behavior  the map rather than full location posterior is shown for clarity. in an iid pure fusion model  constrained such that w z = 1 and with prior πl instead of transition matrix Γ  the location inference is correct where the multi-modal observations are indeed associated  fig.1 c  . the video modality dominates the fusion as it is much higher precision  i.e.  the likelihood function is much sharper   and the posterior is still therefore correct during the visible but silent period where peaks in the audio likelihood are spurious. however  while the person in the video foreground is occluded but speaking  the next best match to the learned dark foreground template usually happens to be the filing cabinet in the corner. with pure fusion  the incorrect but still fairly sharp video likelihood still dominates the audio likelihood  resulting in an incorrect posterior.

figure 1: av data association & inference results.  a  video samples and  b  audio data from a sequence where the user is first visibly walking and speaking  then occluded but still speaking  and finally visible and walking but silent.  c  inferred map location with iid pure fusion model   d  iid data association model and  e  full temporal data association model. inference based on audio observation alone is shown in circles  video observation alone in triangles  and combined inference by the dark line.  f  posterior probability of visibility  dark  and audibility  light  during the sequence.  g  initial and  h i  final video appearance after learning.  j  final location state transition matrix after learning.
tracking with iid data association model
in an iid data association model  fig.1 d   the video modality is correctly inferred with high confidence to be disassociated during the occluded period. the final posterior is therefore based mostly on the audio likelihood  and is generally peaked around the correct central region of the azimuth. the outlier points here have two causes. as speech data is intrinsically intermittent  both modalities occasionallyhave low probability of association  during which times the final estimate is still inappropriately attracted to that of the video modality as in the pure fusion case. others are simply due to the lower inherent precision of the audio modality.
tracking with smoothed data association model
the data association posterior  w z   fig.1 f   correctly represents the visibility and audibility of the target at the appropriate times  as with the iid case. this enables information from the appropriate sensor s  to be used at each time. with the addition of temporal context  tracking based on the noisy and intermittent audio modality is much more reliable in the difficult period of visual occlusion. the user is now reliably and seamlessly tracked during all three domains of the input sequence  fig.1 g  . the inferred data association is used to label the frames in  fig.1 a   with the user's speaking/visibility status. to cope with intermittent cues  previous multi-modal machine perception systems in this context have relied on observations of discrepant modalities providing uninformative likelihoods  perez et al.  1; beal et al.  1 . this may not always be the case  and was not  for example in our video sequence where only the data association models succeeded during the video occlusion. this model retains properties of the inspiring formulation  beal et al.  1  which allow most of the expensive e and m step computations in the observation model to be expressed in terms of ffts. using 1 pixel images and 1 sample audio frames  our matlab implementation can perform on-line real time  filtered  tracking at 1fps after  smoothed  learning  which proceeds at 1fps.
1 discussion
in this paper  we introduceda principled formulationof multisensor perception and tracking in the framework of bayesian inference and model selection in probabilistic graphical models. pure fusion multi-sensor models have previously been applied in machine perception applications and understanding human perception. however  for sensor combination with real world data  extra inference in the form of data association is necessary as most pairs of signals should not actually be fused. in many cases  inferring observation association is in itself an important goal for understanding structure in the data. for example  a speech transcription model should not associate nearby background speech of poorly matching template and uncorrelated spatial location with the visible user when he is silent. in our application the model  knows  if observations arise from the source of interest by explicitly inferring association  so it can for example  start recording when the user enters the scene or begins speaking.
　in radar tracking and association  some work stone et al.  1  uses similar techniques to ours  however popular methods  bar-shalom et al.  1  tend to be more heuristic  use stronger assumptions and approximations e.g. gaussian posteriors  and use highly pre-processed point-input data. one interesting contrast between these candidate detection based approaches and our generative model approach is that we avoid the expensivewithin-modalitydata association problem typical of radar. this also enables use of signature or template information in a unified way along with cross-modality correlation during inference  which is exploited to good effect in our av application.
　investigations of human multi-sensory perception have reported robustness to discrepant cues  ernst and banks  1  but principled theory to explain this has been lacking. we envisage that our theory can be used to understand a much greater range of integrative and segregative perceptual phenomena in a unified way. performing psychophysical experiments to investigate whether human perceptual association is consistent with the optimal theory described here is a major research theme which we are currently investigating.
　in the context of machine perception  the type of model described generalizes existing integrative models and provides a principled solution to questions of sensor combination including signature  fusion  fission and association. as our av application illustrates  computing the exact posterior over source state and data association for real problems  even before applying approximations  is potentially even real-time. the major complicating extension not considered in detail here  is that of multiple sources. in this case  the computation required for exhaustive reasoning grows exponentially in the maximum number of objects; so for more than a few objects the simple strategy employed here is not viable. for these problems  we are investigating using approximate greedy inference to identify the objects one at a time in order of best correlation along the lines of  williams and titsias  1 .
