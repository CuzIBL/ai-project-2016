 
influence diagrams  ids  are a graphic formalism able to provide a compact representation of decision problems. ids are based on the axioms of probability and decision theory  and they define a normative framework to model decision making. unfortunately  ids require a large amount of information that is not always available to the decision maker. this paper introduces a new class of ids  called ignorant influence diagrams  iids   able to reason on the basis of incomplete information and to improve the accuracy of their decisions as a monotonically increasing function of the available information  iids represent a net gain with respect to the traditional ids  since they are able to explicitly represent lack of information  without loosing any capability of traditional ids when the required information is available. furthermore  i ids provide a new method to assess the reliability of the decisions by replacing the traditional sensitivity analysis with a single analytical measure. 
1 	i n t r o d u c t i o n 
bayesian belief networks  bbns   pearl  1  are a wellknown formalism to reason under uncertainty and they have been successfully applied to a variety of problems in different domains. a bbn is a direct acyclic graph in which nodes represent stochastic variables and arcs represent conditional dependencies among variables. from a probabilistic point of view  they provide a straightforward way to represent independence assumptions among variables  thus making easy the representation and the acquisition of knowledge. bbns are particularly appealing since they are based on a sound probabilistic semantics and they easily extend into a complete decision theoretic formalism  called influence diagrams  ids . ids  horviti et a/.  1  provide a compact representation for decision problems and their sound probabilistic semantics guarantees the normative character of their decisions  ids are an appealing complement to more traditional methods for representing decision problems  such as tables of joint probability distributions or decision trees  because they exploit the ability of bbns to express conditional independence assumptions in graphical terms  thus dramatically reducing the amount of information needed to specify a decision problem. 
　nonetheless  a bbn still requires a fixed and potentially very large amount of probabilistic information  that is not always available to the decision maker: the number of conditional probabilities needed to specify a conditional dependency grows exponentially with the number of its parent variables. current propagation algorithms require that all the conditionals probabilities defining a conditional dependency among variables have to be known  as well as all prior probabilities for the states of the root variables  before any reasoning process can start. furthermore  these probability measures have to be assessed as point-valued probabilities  even when the decision maker is not completely sure about them. this requirement  called credal uniqueness  stiling and morrel  1l   is one of the most controversial points of bayesian probability and decision theory  levi  1; kyburg  1   and it is the reason why bbns require such a large amount of probabilistic information: in order to specify a unique probability distribution over the stochastic variables of a bbn  we need to know the conditional probabilities relating it with all its parents in the network. 
　this limitation becomes even more apparent in the development of an id: when the decision maker is not able to specify a single probability  he is nonetheless forced to provide point-valued probability measures  and then to perform a costly and tiring analysis to assess the sensitivity of the resulting decisions to all the possible combinations of his imprecise assessment. 
　to overcome this limitation  and maintain the appealing features of probabilistic soundness and graphical nature of bbns  we have developed a class of bbns  called ignorant belief networks  ibns   ramoni and riva  1   able to relax the credal uniqueness assumption and to reason on the basis of incomplete probabilistic information. ibns implement an inference policy  largely wished in the literature about probabilistic reasoning systems  called incremental refinement policy  horviti  1   able to improve the accuracy of the solutions as a monotonically increasing function of the allocated resources and the available information. 
the aim of this paper is to extend ibns into a com-
	ramoni 	1 

plete decision theoretic formalism called ignorant influence diagrams  iids   and to show how i ids can be useful to model decision making when the information required by traditional ids is not available. the reminder of this paper will briefly outline the theory and the properties of the ibns. then  it will describe the way in which an i b n can be extended into an i i d and which decision procedures are needed when the available information is not sufficient to specify point-valued probability measures. it will also outline a new method  provided by iids  to assess the reliability of decisions without the costly sensitivity analysis required by traditional ids. a simple example will illustrate the properties of iids and a brief comparison with some related works will be provided. 
1 	ignorant belief networks 
the representation and use of incomplete information is a long standing challenge for ai researchers. during the past decade  they have developed a class of reasoning systems  called truth maintenance systems  tmss   mcallester  1   which incrementally record justifications for beliefs and propagate boolean truth values along chains of justifications. tmss are independent reasoning modules which incrementally maintain the beliefs for a general problem solver and enable it to reason on the basis of temporary assumptions and incomplete information. tmss able to propagate probabilistic rather than binaries truth-values are called belief maintenance systems  bmss   falkenhainer  1; laskey and leaner  1 . ibns are belief-maintained bbns: they exploit a bms based on probabilistic logic  and therefore called logic-based bms   l b m s    ramoni and riva  1 . 

 Π  Π'  is satisfied for any subinterval of  π  π* . 
　the l b m s uses a forward chained unit-resolution style algorithm called epistemic constraint propagation  bcp  to propagate labels over a network of propositions! formulas  bcp can be regarded as an extension to intervals of the boolean constraint propagation  bcp  algorithm  mcallester  1  used by the tmss based on the propositions! calculus. the intuition behind the bcp is simple and elegant. the algorithm starts converting any formula in cnf  that is  a set of clauses. bach clause acts as a constraint on the truth-values of the literals occurring in it. to be satisfied  a clause must contain at least one literal labeled as true. a clause is violated when all the literals occurring in it are labeled as false  thus producing a contradiction. when all literals but one in a clause are labeled as false bcp forces the unlabeled literal to be true. 
　in order to extend the bcp from boolean to probabilistic truth-values  we derived  from the theory of proba~ bilistic entailment  nilsson  1   a probabilistic inter-
pretation of disjunction able to define which constraints are imposed by a clause over the  probabilistic  truthvalues of the literals occurring in it  ramoni and riva  1 . 
　the first constraint  imposed by a clause over the literals occurring in it states that the label of a literal /  in clause  is bounded by: 
* 
		 1  
where 

1 	reasoning under uncertainty 

and the function 
the second constraint states that the label of the literal l1 is bounded by: 
　　　　　 1    
where { l 1   . . .   !   } is a set of literals  and { c 1   ... c1- } are the clauses built from { / 1   . . .   1 } with all the possible combinations of the negated and unnegated literals in the set { / a   . . .   l   } . 
   the propagation of these constraints is performed by a version of welti's propagation algorithm  walts  1  extended to intervals  davis  1 : each proposition is labeled with a set of possible values  and the constraints are used to restrict this set. this property  which is implicit in the form of the inequalities 1 and 1  implies 

a monotonic narrowing of the labels  thus ensuring the incrementality of bcp. 
　the most important feature of bcp is the ability to reason from any subset of the set of clauses representing a 
joint probability distribution  by bounding the probability of the propositions within probability intervals  and incrementally narrowing these intervals as more information becomes available. furthermore  bcp is sound: it never excludes from its intervals any probability value that could be derived by standard probability theory from the available information. even if incomplete in general  bcp is complete with respect to the clauses representing a joint probability distribution. this means that  with respect to this subclass of the language  bcp returns the tightest entailed interval. the incompleteness with respect to other clauses of the language is the result of a compromise between expressivity and efficiency  since theoretical analysis and empirical results show that the bcp propagation runs to completion in linear time with respect to the number of clauses  ramoni and riva  1   thus making easy the estimation and the trading off of the computational effort. 
1 	r e p r e s e n t a t i o n 
ibns are belief-maintained bbns based on the lbms. the ibn acts as a knowledge representation formalism expressing the assumptions of conditional independence in the domain of application and communicates the available conditional probabilities to the lbms. these conditional probabilities are transformed into clauses relating the propositions of the lbms which represent states of the stochastic variables of the ibn. in this way  any computation is left to the lbms and the ibn can exploit the incremental character of bcp. the elements of a bbn can be easily translated into a lbms network. 
 nodes in a bbn  a node represents a stochastic variable. a stochastic variable is a set of mutually exclusive and exhaustive states. therefore  the probability values assigned to the states in a variable have to sum to unit. in an ibn  when a variable is denned  each state is communicated to the l b m s as an atomic proposition. moreover  a set of clauses is installed to ensure that the states of the variable are mutually exclusive and exhaustive. for all propositions a 1   . . .   a n in the l b m s representing the states of the variable  the disjunction  and all the conjunctions i  with  are asserted as true in the lbms. when a proba-
bility value is assigned to a proposition a1 representing a state of the variable  the lbms receives the conjunction 

arcs in a bbns  arcs represent conditional dependencies among nodes. a conditional dependency defines a dependency relation between a set of parent nodes and a child node. a conditional dependency is denned by the conditional probabilities i 
where a h   . . .   a  is a combination of states of the stochastic variables represented by the parent nodes of the dependency and at is a state of stochastic variable represented by the child node. conditional dependencies can be propagated both ways over an ibn  thus emulating the two main operations involved in the evaluation of a bbn: node removal and arc reversal. 
1 	i n f e r e n c e 
there are two main operations involved in the evaluation of an id: node removal and arc reversal. node removal corresponds to propagating probability values along the direction of the arcs in the graph  while arc reversal corresponds to flowing backward the direction of the arcs and assessing the posterior probability of parent nodes in a dependency. 
n o d e removal in a bbn  node removal corresponds to marginalization. when the probability values of all states represented by the propositions  is assigned  the two different clauses resulting from the application of the de morgan's laws to i 
and 	are communicated to the lbms algorithm. 	are calculated according to a version of the chain rule extended to intervals: 

the resulting conjunctions are converted into clauses by the lbms before propagating them through bcp. 
a r c reversal from a probabilistic point of view  the capability of performing arc reversal in ibns is provided by the well-known bayes' theorem: 
 1  
1
the conjunction: 

since   we can also derive: 

when converted into clausal form  these conjunctions turn out to be the same clauses that were generated during marginaliiation. therefore  arc reversal results in an 
	ramoni 	1 
sound and compact formalism of bbns. in this section  we will illustrate how ibns can be easily extended to a 1 	properties 
from the theory of tmss  the lb ms inherits the concept of consumer  de kleer  1 . a consumer is a forwardchained procedure attached to a proposition  that is fired when the truth-value of the proposition is changed  that is  the probability interval associated with a state is narrowed. using consumers  ibns do not perform any computation themselves  but rather act as a high-level knowledge representation language  while the propagation of probabilities is performed by the lbms. 
　there are some properties of the ibns that will be crucial in the development of the iids. first of all ibns converge toward point valued probabilities  and when all the conditionals defining a joint probability distribution  they behave as standard bbns  returning point-valued probabilities. furthermore  an ibn will infer the tightest intervals from any subset of conditional probability in a conditional dependency  since the lbms is compete for clauses representing joint probability distributions and the ibn simply minimises and maximise the standard rules of node removal and arc reversal. 
　finally  it is worth noting that the lbms both performs and drives the propagation  since consumers are attached to the propositions of the lbms and are fired according to the changes occurring in their labels. therefore  the computational cost of a propagation grows linearly in space and time with respect to the number of conditional probabilities  even if the number of conditional probabilities needed to specify a conditional dependency grows exponentially with the number of parent nodes in the dependency. however  the incremental character of inference policy implemented by the ibns will allow the decision maker to trade execution time with precision of solutions  since an ibn will propagate only those conditional probabilities explicitly assessed by the decision maker. 
1 	influence d i a g r a m s 
ids  horvits et a/.  1  are a natural extension of bbns. 
they allow the formulation of a decision problem into the 
1 	reasoning under uncertainty 
complete decision formalism  thus creating a new class of ids called ignorant influence diagrams  iids . iids inherit from the ibns the ability to reason on the basis of incomplete information and to incrementally refine the accuracy of their decisions as more information becomes available. 
1 	representation 
ids are bbns containing three different kinds of nodes: chance nodes  also called state nodes   decision nodes  and value nodes  also called preference nodes . these nodes are related by standard conditional dependencies. the resulting id can be transformed into a bbn following the method proposed by cooper . on this view  the decision problem can be solved by determining the instantiations of the decisions which maximise the expectations of the decision maker. 
chance nodes a chance node represents a state of the world. it is basically a standard stochastic variable. bbns are usually defined as  influence diagrams containing just chance nodes   horvits et a/.  1 . in figure 
1  chance nodes are depicted as oval nodes in the graph. 
decision nodes a decision node identifies a set of possible alternative actions available to the decision maker. in the iid of figure 1  the decision node is depicted as a square node. a set of actions representing a possible solution for a decision problem is called strategy or policy. 
value nodes different strategies lead to different outcomes. value nodes represent preferences or utilities of the decision maker for alternative outcomes. a decision problem may be represented as the problem of finding the strategy which maximises the preferences expressed by the decision maker over the possible outcomes of the problem. in figure 1  the value node is depicted as a diamond. 


ramon i 1 

needed before any reasoning process can start. we will now show with an example how an i i d is instead able to reason from incomplete conditional probability distributions. figure 1 shows the iid used as an example. it represents the decision problem of taking a certain a c t i o n in order to prevent a certain e f f e c t of a particular cause. the a c t i o n has a foreseeable cost  and the problem consists in trading-off the value gained by prevention of the effect with the cost of the action. 
   the example is composed of two steps. in the first step  the system receives only the probability measures listed in the first column of table 1  with the preference function over the outcomes defined as: v  cost=yes   effect=yes   = 1  v  cost=yes  
 effect=no   = 1  v  cost=no   effect=yes   = 1  and v  cost=no   effect=no   = 1. figure 1 shows the graphical representation of the network generated in the first step of the example. the pop-up windows over the nodes graphically report the probability interval associated to each one of their states. in each bar  the area between 1 and p  a1  is black  the area between p* ai  and 1 is white  and the area between p  ai  and p* a1  is gray. thus  the width of the gray area is proportional to the ignorance about the probability. 
　the decision node reports its value in a strategy. the chances nodes report the probability values of each of their states for the same strategy. it is worth noting that the conditional p     e f f e c t = y e s   |  cause=no   action=no    not reported in the first column of table 1  is actually not included in the definition of the first iid  and therefore its probability value is not even propagated. the value node value reports the expected utility intervals for the possible strategies  action=y s  and  action=no   namely: u  action=yes   = 
 1 1  and u  action=no   =  1 1 . 
　it is apparent that the stochastic dominance criterion is unable to select only one strategy  and remains undecided. the weaker hurwici criterion is able to pick up a unique decision. however  the solution can change according to the hurwici value. using formula 1  we can estimate the robustness of the decision by calculating the decision threshold for the hurwici value. in our case  the decision threshold is r - 1. 
1 	reasoning under uncertainty 
　when all the probability measures required by a standard id are specified  as in the second column of table 1  the iid behaves as a standard id in returning pointvalued probabilities  as shown in figure 1. since all the criteria adopted collapse on the maximum expected utility criterion when they have to rank point-valued expected utilities  also the solution provided by the i i d is identical to the one suggested by a standard id. 
1 	related work 
there are at least two line of research trying to relax the credal uniqueness assumption within a coherent bayesian framework and to develop automated decision making systems able to reason on the basis of interval rather than point-valued probability functions. 
   the first line of research is based on the concept of probabilistic database  which generalises the standard relational model by replacing the characteristic function of a relation with a finite probability distribution function. using this concept  pittarelli  proposed a model able to represent probability intervals and provided methods for decision making based on it. the analogy between a probabilistic database and a table of 
joint probability distributions is apparent. therefore  iid s improve the probabilistic database model as ids improve the traditional decision theoretic methods based on tables of joint probability distributions: iids explicitly represent conditional independence assumptions in the domain of application  thus reducing the amount of probabilistic information needed to specify a decision problem. 
　closer to the aim of iids are the efforts addressed by breeze and pertig  to develop interval influence diagrams. they describe procedures for node removal and arc reversal in ids where lower bounds of probability intervals are stored at each node in the id. the appealing feature of this method is its effort to preserve both the probabilistic soundness and the graphical nature of standard ids. unfortunately  the probability bounds calculated by this method quickly degradatc during the propagation  thus resulting in the assignment of too wide probability intervals and jeopardising the normative character of their decisions: an analog of the classical dutch 

book can be made against an agent making decisions on the basis of the probability distributions erroneously allowed by too wide probability intervals. 
1 	conclusions 
ids are a powerful formalism to mechanise decision making  and they have been successfully applied to a wide range of problems. however  they require a large amount of information that is not always available to the decision maker. the acquisition of this large amount of information  either from human experts or from statistical analyses of databases  usually represents one of the major challenges in the process of developing decision support systems based on ids. this paper introduced a new class of ids  called iids  able to reason on the basis of incomplete information  and to incrementally refine the accuracy of their decisions as more information becomes available. however  when they are provided with complete probabilistic information  iids behave as standard 
ids. 
　therefore  iids represent a net gain with respect to the traditional ids  since they are able to explicitly represent the actual lack of information  without loosing any capability of the traditional ids when the required information is available. furthermore  by relaxing the credal uniqueness assumption  i ids provide a new method to assess the reliability of the decisions by replacing the costly and tiring sensitivity analysis with a single analytical measure. finally  the monotonic  incremental character of the refinement process in the iids provides a way to trade-off the amount of computational time and available information with the accuracy of the decisions. this feature makes iids a suitable formalism for real-time  resource-bounded decision tasks. 
acknowledgments 
this research was supported in part by the a i m programme of the commission of the european communities  a1 . i would like to thank alberto riva  greg cooper  carlo beriuini and riccardo bellassi for their helpful suggestions  and mario stefanelli for his continuous support. 
