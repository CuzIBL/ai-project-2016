 
in the computational theory of human vision  developed by d. marr and his school  zero-crossings detection is proposed as one of the first stages of human visual information processing. the justification of this theory reguires that the zero crossings are rich in information about the original image. in a paper  t. poggio  h.k. nishihara and k.r.k. nielsen stated that a successful extension of b. 
logan's analysis to two-dimensional images represents one of the critical unsolved steps of this computational theory. moreover  sucn an extension is crucial to the question of spatiotemporal interpolation in vision. in this paper  we shall provide a solution to this problem using a theory of spherical perspective and spherical harmonics. 
1. introduction 
the goal of low level vision is to detect changes in the reflectance of object surfaces and in surface orientation  geometry and depth value. in computer vision or the computational human vision  changes in image intensity of different scales of resolution is the optimal indicator of such changes. it has been proposed that different scales are set by filtering the image with 1-dimensional gaussian filters of different sizes . intensity changes of object surfaces are spatially localized at different scales. 
in the spherical model  we could extend the 
gaussian filter on the plane to a filter  probability distribution  of gaussian type  such as fisher and von mises filters on the sphere. it is quite natural to consider the exponential family of distributions on the sphere  because of its relation to spherical harmonics. we may consider some characterizations of the gaussian to set up analogous filters in the spherical model. alternatively  we may use the correspondence between the image plane and 
1 	perception 
the image sphere  see next section  to transform filtered planar images to scaled images on the sphere. that is  we may do the filtering in the plane first and then transform the filtered image to an scaled image g*i on the sphere. 
in both cases  zero-crossings are computed by finding the zero set of the spherical laplace operator a on g*i. detection of edges in an image is reduced to solving for zero-crossings. a key question is whether detected edges contain full information about the image. if we can reconstruct the image from detected edges  then the question is affirmatively answered. from the view point of visual information processing  we do not need to reconstruct the original image  but only to show that sufficiently enough information is provided. 
an extension of b. logan's theorem to the image sphere will be presented. 	thus  the theory of marr and hildreth  will be supported by this paper. 	the 	sphere 	is 	parametrized 	by 	the elevation 	and 	azimuth angles 	any square 	integrable 	function 	f 1  |1  	may be decomposed into a sum of spherical harmonics  which are products of exponentials 
and legendre functions  special functions   functions of two variables and as we have stated earlier  this framework will provide the appropriate extension of logan's theorem to two variables. it will be shown that such a function f can be reconstructed from the zero-crossings data  provided that enough of them are available. 
this extension of logan's theorem is the theoretical basis of zero-crossings and spatiotcmporal interpolation. spatiotemporal interpolation is proposed in  and other references quoted there. the positional accuracy in human vision  corresponding to a fraction of the spacing between adjacent photoreceptors in the fovea   implies the spatial interpolation. the perception of continuous motion requires spatiotemporal interpolation   our extension of logan's theorem addresses both the problem of spatial interpolation and an extension to for spatiotemporal interpolation. 
1. the spherical model 
the two imaging models are not very different. 
the image sphere  or hemisphere  is replacing the image plane tangent to it at the north pole. the perspective projection is extended beyond the image plane to the spherical perspective projection onto the image sphere. in   a nonlinear transformation sets up the correspondence between points on the image plane and points on the image sphere. image intensity is defined by this correspondence  under the lambertian model. if we move the origin  viewer  of the spherical model to infinity  the limit is the orthographic model. there are other nice features of the spherical model. for instance  the vanishing points are finite points on the image sphere. 
like the fourier descriptor method of expanding functions on expand an image intensity function spherical harmonics  which form a basis of all square 
integrable functions on the unit sphere. there are other orthonormal expansions of image intensity functions  such as svd and karhunen-loeve expansions; however  all the nice properties of fourier descriptors are lost. this spherical harmonics expansion carries the group invariance over and forms a natural setting in the group representation theory of modern physics . 
each spherical harmonic 	is the product for each k. in fact  
there is a vector space spanned by 	for each  the legendre function is presented in 	. for any 	square integrable  we have 


these coefficients can be calculated numerically and lookup tables are constructed to speed up numerical work involving with legendre functions. in a distance is defined for equivalent shape classes and   thus  object recognition is performed in a standard fashion. if coefficients 
over all rotations r  symmetries s and scalings 
s  	is the distance between 
1. zero-crossings 
the first order differential operators on the sphere are given by three basis operators 

the effect of these three differential operators 

feature of the spherical model. 
the correspondence between  on the image plane and  on the image sphere is given by the nonlinear transformation between the image plane at the north pole and the sphere. the image intensity function  is conveniently defined as the image intensity function  under this correspondence. this is a reasonable assumption near the fovea in human vision or near the optical axis in 
	chen 	1 

computer vision because the plane is tangent to the sphere. for peripheral views or wide viewing angles  problems arise and we need to rotate our eyeballs or cameras. this amounts to a rotation of the sphere and its tangent plane at the north pole. 
since the gaussian filter  distribution function  in  is to set up different scales of resolution  it is quite reasonable to project the 
1-dimensional 	gaussian 	filter 	on 	the 	plane 
to a 
filter on the sphere 

zero-crossings of i in the spherical model. the blurred image  may be expanded in terms of spherical harmonics: 

thus  zero-crossings are given by solutions of the following nonlinear equation 


form 	determinants 	of 	maximum 	rank. 
 consequently  	the 	image 	intensity 	function  is recovered from the spherical harmonics expansion 	whose 	are 
determined by the above 

1 	perception 

equations. 
theorem. under suitable conditions  image intensity functions in the spherical model may be recovered up to multiplicative constants from their zero-crossings data. 