 
we present an algorithm pref-ac that limits arc consistency  ac  to the preferred choices of a tree search procedure and that makes constraint solving more efficient without changing the pruning and shape of the search tree. arc consistency thus becomes more scalable and usable for many realworld constraint satisfaction problems such as configuration and scheduling. moreover  pref-ac directly computes a preferred solution for tree-like constraint satisfaction problems. 
1 introduction 
in the last two decades  considerable research effort in al has been spent on studying the complexity of reasoning and problem solving  and the identification of tractable cases has become an important goal of this research. however  even if a problem can be solved by a polynomial algorithm  or if search effort can be reduced by polynomial algorithms  this might not be sufficient for real-world ai systems that face challenges such as interactivity and real-time. we give some examples from constraint satisfaction  where achieving arc consistency might be too costly  although it is tractable: 
1. web-based configuration systems must provide a response in a few seconds while serving multiple users. although arc consistency  ac  is an appropriate technique to handle compatibility constraints  it will be too expensive in presence of large product catalogs. 
1. constraint-based approaches to problems such as scheduling  vehicle routing  and personnel planning often only maintain bound consistency in constraints involving time or other variables with large domains. as a consequence  complex rules on breaks  rest-times  and days-off provide only a poor propagation  which could be improved by arc consistency. 
these examples illustrate that domain reduction does not develop its full power in many real-world applications of constraint programming. pruning power and  indirectly  solution quality are traded against short response times. in certain circumstances  such a trade-off can be avoided if the system focuses on the right deductions and computations. in this paper  * a. fabre's work has been carried out during a stay at ilog. 
we argue that preferences are one possible way for achieving this. as stated by jon doyle  doyle  1   preferences can play different roles and need not only represent desiderata or user preferences. preferences can also control reasoning meaning that only preferred inferences and domain reductions are made. non-interesting deductions are left apart  but may become preferred if additional information is added. 
　we can easily apply this idea to typical backtrack tree search algorithms that maintain arc consistency when solving a constraint satisfaction problem. the crucial question is whether such an algorithm needs to achieve full arc consistency and to remove all values that are not in the maximal arc-consistent domains. in  schiex el al  1   it has been shown that the fails of the algorithm can be preserved if it simply constructs some arc-consistent domains  thus reducing the computation effort in average. in this paper  we show that the search algorithm can preserve its search strategy and the overall pruning if 1. the search algorithm uses a variable and value ordering heuristics that can be described by  static  preference ordering between variables and values and 1. we construct some arc-consistent domains that contain the preferred values. the first condition is  for example  met by configuration problems  junker and mailharro  1 . the second condition needs some careful adaption of the definition of arc consistency  which will be elaborated in this paper. 
　we can thus cut down the propagation effort in each search node without changing the search tree  which leads to an overall gain if the search tree will not be explored completely. this happens if we are interested in one solution  the best solution in a given time frame  or preferred solutions as defined in  junker  1 . arc consistency thus becomes more scalable and less dependent on the size of domains  which opens exciting perspectives for large-scale constraint programming. 
　we first introduce preferences  section 1   use them to define a directed constraint graph  section 1   and discuss arc consistency for preferred values  sections 1 and 1 . after introducing preferred supports  section 1   we present the algorithm pref-ac  section 1 . 
1 preferred solutions 
in this paper  we consider constraint satisfaction problems of the following form. let x be a set of variables and v be a set of values. a constraint c of arity kc has a sequence of variables x c  = {x1  r  ...  xkt  c } from x and a relation rc 

constraints 	1 

that is a set of tuples from . let c be a set of constraints. the triple  x' d  c  is then called a constraint network. 
　a solution of a constraint network is a mapping v of the variables x to the values in v such that each constraint is satisfied  i.e.   for all constraints c. the constraint satisfaction problem  csp  involves finding a solution of a constraint network. 
　alternatively  we can represent the tuples by sets of assignments of the form x = v between a variable :/: and a value v: if t is a tuple of the form then let f be the set of assignments . furthermore  let rc be the set of all /. such that t is in rc. this representation will facilitate definitions and permits a straightforward logical characterization of a constraint c: 
		 1  
   we further suppose that the following kinds of preferences are given. for each variable x  we introduce a strict partial order among the possible values for x. this order can represent user preferences as occurring in configuration problems  cf.  junker and mailharro  1  . for example  the user might prefer a red car to a white car. projecting preferences on criteria to decision variables  junker  1  also produces such an order  e.g. if price is minimized then try cheaper choices first . furthermore  we consider a strict partial order  between variables. for example  we may state that choosing a color is more important than choosing a seat material and should therefore be done first. in the sequel  we suppose that the search procedure follows these preferences as described in  junker and mailharro  1  and always chooses a variable and  value for x. these preferences are given statically and thus correspond to a static variable and value ordering heuristics  which are usually sufficient for configuration problems. 
   we now use the preferences to define a preferred solution. first of all we choose a linearization of the orders 
and in form of total orders that are supersets of the strict partial orders. then we consider a ranking of the variables in that corresponds to the 
we then consider two 
solutions v1 and v1 and compare them lexicographically 
  
 1  
definition 1 a solution v of a constraint network p :=  x d c  is a preferred solution ofv iff there exist linearizations  is the 
best solution of p w.r.t. 	the lexicographical order defined by 

　these preferred solutions correspond to the extreme solutions in  junker  1 that are obtained if all variables are criteria. if the search procedure follows the preferences then its first solution is a preferred solution. hence  the notion of a preferred solution helps us to forecast the first solution in certain cases. 

figure 1: directed constraint graphs. 
1 	preference-based constraint graph 
in order to find a preferred solution  the search procedure chooses values for more important variables first. we will see later that  in some cases  we can anticipate a preferred solution and construct it by a constraint propagation procedure if this procedure does not only follow the constraints  but also the order among the variables used by the search procedure. 
　in order to illustrate this  consider the bipartite constraint graph that connects the constraints with their variables. suppose that a variable x is connected via a constraint c to a less important variable y. search will then assign a value to x and cause a domain reduction of y. we can thus say that the preferences ＊ # among variables impose an order on the constraint graph. for example  we will say that the arc between x and c leads from x to c and the arc between y and c leads from c to y. 
　we generalize this idea for arbitrary constraints and partial orders. for each constraint r  we consider the - .v-best variables in x c  and call them input variables. the other variables are called output variables. arcs lead from input variables to a constraint and from there to the output variables. 
definition 1 let  x d c  be a constraint network and be a strict partial order between the variables x. a variable x of a constraint c is called input variable of c iff there is no other variable y of c s.t.  x. a variable x of c is called output variable of c iff it is not an input variable of c. the directed constraint graph of the csp is a bipartite graph having the nodes and the set of arcs  x  c  s.t. x is an input variable of c and  c  y  s.t. y is an output variable of c. 
　each constraint can have several input and several output variables  cf. figure 1 . if its variables are not comparable at all  then the constraint has no output variable  and it is a sink of the directed graph. however  each constraint has at least one input variable. as a consequence  no constraint can be a source of the directed graph. in general  the graph is not guaranteed to be acyclic  but it satisfies the following properties which are needed for our proofs: 1. all  variables of the set x are sources of the constraint graph since they cannot be an output variable of any constraint. however there can be sources that are not  variables. 1. if x is a ranking of the variables x that is a linearization of  then each output variable of each constraint is preceded by at least one input variable of the same constraint in the ranking. 

1 	constraints 

1 	arc consistency 
a typical systematic search procedure for solving csps proceeds as follows. in each search node  it picks an assignment x - v for such a variable and creates two successor nodes  one for x = v and one for  throughout the paper  we assume that a variable x is eliminated from the csp of a successor node by a preprocessing step iff it has only a single possible value. usually  the search procedure will not select an arbitrary assignment from the set a of all assignments  but tries to anticipate certain cases where the sub-tree of an assignment does not contain a solution. if such an assignment is detected it is eliminated from a. hence  the search procedure maintains a set of possible assignments and considers only elements of a. each solution can be characterized by a subset of a that assigns exactly one value to each variable and that satisfies all constraints. as a consequence  if a variable x has no assignment in a then no solution exists and the search will backtrack. in the sequel  we write ax for the set  of possible values for x in a. 
　assignments can be eliminated from a if they lack a support on a constraint: 
definition 1 a set of assignments s is a support for x - v in 
c iff 1. 	is an element of 
let be the set of supports for x = v in c. in this paper  we are interested in search procedures that maintain arc consistency  i.e. that work with a set a where all assignments have supports s that are subsets of a and this on all relevant constraints: 
definition 1 let a be a set of assignments. a subset a of a is an arc-consistent set of a iff i. ad is non empty for any  and all constraints c of 
x  there exists a support s for  x = v  in c such that s is a subset of a. 
if an arc-consistent set a contains a single assignment for each variable then a corresponds to a single solution. if no arc-consistent set exists then the csp has no solution. otherwise  there is a unique maximal arc-consistent set  which is a 
superset of all arc-consistent sets  including the solutions. 
　alternatively  we can consider a set  of some assignments for which we know that they do not belong to any solution: 
		 1  
this can easily be translated to a reflexive and monotonic operator that eliminates additional assignments: 

fixed-point theory then tells us that the transitive closure of this operator is the unique minimal set  satisfying equation 1. as a consequence  the set a* of all assignments that are not eliminated  i.e.  is the unique maximal set satisfying item 1 of def. 1. if each variable has an assignment in a* then a* is the maximal arc-consistent assignment. if some variable has no assignment in a* no arc-consistent assignment exists. in this case  no solution exists. 

figure 1: activating best values and their supports. 
1 	arc consistency for preferred values 
maintaining arc consistency prunes the search tree as follows: pi if the current csp is not arc-consistent then a fail occurs. 
p1 if a value v is not arc-consistent for a variable x then the search procedure will not assign v to x inside the current subtree. 
in general  it is desirable to eliminate as many values as possible and to determine a* by applying an algorithm of the 
ac-family. the worst-case complexity is  for binary constraints  if domains contain thousands or more elements as is the case for typical scheduling problems and for configuration problems with large catalogs  then maintaining arc consistency is no longer feasible in practice. 
　interestingly  it is not necessary to eliminate all assignments of a - a*.  schiex et al.  1  try to construct a small arc-consistent set a. if this succeeds then prunning rule pi cannot be triggered. this can lead to saving time in search nodes that are arc-consistent. we now want to extend this policy to pruning rule p1 in the case that the original search procedure uses the given preferences between variables and values in order to select an assignment. in each search state  the search procedure will pick variable and try out its possible values starting with the best value is not in the maximal arc-consistent set a* then we must ensure that it will be eliminated when constructing the subset a. 
however  if  then we must ensure that it will be in the subset a. 
   instead of doing a pure elimination process  we interleave construction and elimination steps and determine a set f of activated assignments  called focus  and a set of eliminated assignments. both sets will grow during the process and our purpose is to obtain  as arc-consistent set. this set is sufficient for our search procedure if some properties are satisfied: 1. if x is a  variable and among the non-eliminated values of x then the search procedure might pick x - v as next assignment. hence  we have to activate it. 1. if an activated assignment does not have a support on a constraint c then it has to be eliminated. 1. the supports for the activated  but non-eliminated assignments must only contain activated and non-eliminated elements. 1. we need to guarantee that  contains at least one value per variable if an arc-consistent set exists. since all variables can be reached from the sources via constraints  we activate best values for all sources of the directed constraint graph. 

constraints 	1 


1 	constraints 


figure 1: a preferred solution as stable activation. 
　given a preferred solution  we cannot guarantee that each assignment has a preferred support in all constraints. however  if certain assignments in a solution s have preferred supports then s is preferred solution: 
proposition 1 let s be a solution of v. suppose that and all  are strict total orders. if each assignment x - v to a source x of the direct constraint graph is a best assignment for x in the unique maximal arc-consistent set a* and all activated assignments to input variables of a constraint c have a preferred support on c in s then s is a preferred solution of p. 
　when constructing a stable activation  we choose preferred supports since this may result in a preferred solution: 
proposition 1 suppose that  and all  are strict total orders. let s1 ...  sm be an activation sequence and let  be defined as in def 1. if j. each s1  is a preferred support for some x = v on some constraint c s.t. x is an input variable of c or x = v is unsupported on c in and 1. preferred solution of p. 
　the first condition in proposition 1 can be satisfied by always activating preferred supports. the second condition can be met by csps of a special structure. for example  consider a binary constraint network such that its directed constraint graph forms a tree  cf. figure 1 . in this case  we only activate supports for assignments to input variables  but not for assignments to output variables  since each variable can only be an output variable of a single constraint. this result is  for example  interesting for certain car configuration problems and permits us to efficiently take into account certain user preferences. 
preferred solutions are also obtained in trivial cases: 
proposition 1 suppose that  and all  are strict total orders. if there is a preferred solution containing all best values of all variables in a then it is equal to all activations 
produced by preferred supports. 
1 	algorithm pref-ac 
in this section  we present pref-ac  an algorithm for computing an arc-consistent set a from a binary constraint network  x d c . this algorithm activates supports for unsupported elements and meets the requirements of definitions 1 and 1  and proposition 1. an algorithm for non-binary constraints can be derived from this one. pref-ac follows the principles of lazy arc consistency  schiex et al  1  in order to build an arc-consistent set of assignments that is not necessarily maximal. we base pref-ac on ac-1  bessiere  1  for keeping the discussion simple  although we could exploit the bi-directionality of supports  bessiere et al.  1 . 
　ac-1 assigns an ordering of the values in the domain of every variable x1  checks one support  the first one or smallest one with respect to the ordering  for each assignment  xi = a  on each constraint  to prove that  x1 = a  is currently viable. when  xj = b  is found as the smallest support of  xi - a  on c{xixj    xi = a  is added to  the list of assignments currently having  xj = b  
as smallest support. if b is removed from the domain of xj then ac-1 looks for the next support in the domain of xj for each assignment 
  a chosen linearization 
　　　when looking for supports in the domain of a variable x. furthermore  pref-ac seeks supports only for elements of a  the current set of activated and non-eliminated values 
 i.e.  uses following data structure: 
  each variable x  has a fixed initial domain dx  ordered by  containing all values from v except those 
that violate unary constraints on xi. the set  contains the values of that have not yet 
been removed by arc consistency. 
  a is the arc-consistent set built by the algorithm. 
  for each  contains the assignments that are currently supported by  xi = a . 
  the set pending contains all the 1-tuples  xia xj b  such that a support for  xt = a  has to be sought on r x i  x j  .  this means that all values of xj better than b have already been removed. 
pref-ac uses two subprocedures  algorithm 1 . procedure 
a c t i v a t e   x i a   adds an assignment  xi = a  to a  the set of current activated values. it initializes its data structure cs  and puts in pending all the information needed to look for supports for  x  = a  on the constraints involving xt. function bestsup x   a  xj   b  b  looks for the best support for  xi = a  in d which is less preferred than b  we know there is no support in b better than or equal to b . b is or axj depending on the status of xi  input variable or not . 
pref-ac works as follows. we start by initializing  to 
constraints 	1 dx  for each x1  line 1 of algorithm 1 . we activate the best value of the best variable  line 1 . then  1-tuples  x1  a  xj  b  are taken from the pending set  line 1   and if  x1 = a  is still active  line 1   we must seek a  new  support c for it. if x1 is an input variable of  we seek the support in  because we have to ensure that it will be a preferred support  lines 1 to 1 . otherwise  we first seek a support c among the activated  but non-eliminated elements  line 1 . if none exists  we seek a new best support c  line 1  following def. 1. if c exists  we activate it if not yet done  and store the fact that it supports  x1 = a   lines 1 to 1 . if no support exists for  xt - a   we remove it from and a  line 1 . if  is empty  a wipe out stops the procedure  line 1 . if xi is a source of the directed constraint graph and the best value of is not in was the best of ax  and   the best value 

　if pref-ac terminates with an empty set of pending propagations  line 1   a only contains assignments for which a 
　support has been activated on each constraint  because of line 1   and not deleted  because of line 1 . in addition  this support is the preferred support for this assignment on this constraint if the variable was an input variable for the constraint  because of line 1 and the way bestsup works . we know a contains at least an assignment per variable because of the activation of supports. therefore  a is an arc-consistent set. and because of lines 1  we know that for each xi which is a source of 
　the space complexity of pref-ac is the same as ac-1  namely  since in the worst case  all the values are activated and have a support stored on each constraint. the time complexity is also bounded above by that of ac-1  n a m e l y s i n c e for each value in each domain  we perform at most constraint checks on each constraint. 
1 	conclusion 
we have shown that it is sufficient to maintain an arcconsistent set for the preferred choices of a search procedure. this can significantly speed up constraint solving if the variable and value ordering heuristics of the search procedure can be described by preferences as is the case for typical configuration problems. we developed an algorithm called pref-ac for achieving this reduction and are currently testing it for configuration problems with large domains. 
　many real-world applications of constraint programming suffer from insufficient propagation  since most approaches support only bound consistency for crucial constraints such as precedences of activities  resources  and rest-time rules. adapting algorithm pref-ac to those constraints provides an interesting future perspective for improving constraint solving in areas such as scheduling  personnel planning  and other logistics applications. future work will be devoted to improve pref-ac such that it directly finds a preferred solution if the problem structure permits this  e.g. by activating preferred supports that are common to several variables . 
acknowledgements 
we would like to thank jean-charles regin and olivier lhomme for very helpful discussions. 
references 
 bessiere et al.  1  c. bessiere  e.c. freuder  and j.c. regin. using constraint metaknowledge to reduce arc consistency computation. artificial intelligence  1  1. 
 bessiere  1  c. bessiere. arc-consistency and arcconsistency again. artificial intelligence  1-1  
 doyle  1  jon doyle. preferences: some problems and prospects. in aaai-1 workshop on p