 
 in this paper  we consider the projection task  determining what does or does not hold after performing a sequence of actions  in a general setting where a solution to the frame problem may or may not be available  and where online information from sensors may or may not be applicable. we formally characterize the projection task for actions theories of this sort  and show how a generalized form of regression produces correct answers whenever it can be used. we characterize conditions on action theories  sequences of actions  and sensing information that are sufficient to guarantee that regression can be used  and present a provably correct regressionbased procedure in prolog for performing the task under these conditions. 
1 	introduction 
one of the most fundamental tasks concerned with reasoning about action and change is the projection task: determining whether a fluent1 does or does not hold after performing a sequence of actions. in the usual formulation  we are given a characterization of the initial state of the world and a specification of some sort of what each action does. the projection task requires us to determine the cumulative effects  and noneffects  of sequences of actions. 
　projection is clearly a prerequisite to planning: we cannot figure out if a given goal is achieved by a sequence of actions if we cannot determine what holds after doing the sequence. similarly  the high-level program execution task   which is that of finding a sequence of actions constituting a legal execution of a high-level program  also requires projection: to execute a program like  while there is a block on the table  pick up a block and put it away   one needs to be able to determine after various sequences of actions if there is still a block on the table. 
　a perennial stumbling block in the specification of the projection task is the frame problem : for each action  we need to specify somehow not only what changes as the result of performing the action  but the much larger number of fluents unaffected by the action. one solution to this difficulty is make a strips assumption : what will be known about a 
　state of the world will be representable as a database of simple atomic facts  and we specify actions as operators on such a database  adding or removing just what changes. 
　a much more expressive and declarative solution to the frame problem is presented in . there  the situation calculus is used to specify the effects of actions  and then a simple syntactic procedure is provided for combining the effects for each fluent into a so-called successor state axiom that logically entails not only the effect axioms  but all the frame axioms for that fluent as well. 
　however  this solution to the frame problem makes a strong completeness assumption: after specifying the  perhaps conditional  effects of the given actions on fluents  and then allowing for possible ramifications of these actions  e.g.     it is then assumed that a fluent changes only //it has been affected in one of these ways. thus  it is assumed that each fluent can be regressed in the sense that whether or not it holds after performing an action can be determined by considering the action in question and what was true just before. 
　what is not allowed  in other words  are cases where the value of a fluent does not depend in this way on the previous state. this can arise in at least two ways. first  a fluent might change as the result of an action that is exogenous to the system  i.e.  not represented in the action theory. if a robot opens a door in a building  then when nobody else is around  it is justified in concluding that the door remains open until the robot closes it. but in a building with other occupants  doors will be opened and closed unpredictably. similarly  the robot may be able to determine that a warning light is on simply because it was on in the previous state and the robot is the only one who can turn it off; but it may not be able to predict when the warning light goes on. secondly  the robot might have incomplete knowledge of the fluent in question. for example  a robot normally would not be able to infer the current temperature outdoors  since this is the result of a large number of unknown events and properties. even when a fluent is expected to stay relatively constant  like the depth of water in a swimming pool  the robot may not know what that value is. 
　in cases such as these  the only way we can expect a robot to be able to perform the projection task is if it has some other way of determining the current value of certain fluents in the world. to this effect  we assume that not only can the robot use regression  it can use a collection of onboard sensors. in   sensing is modeled as an action performed by a robot that returns a binary measurement. the robot then uses so-called 

sensed fluent axioms to correlate the value returned with the state of various fluents. however  in this account  no attempt is made to be precise about the exact relation between sensing and regression. moreover  there is no possibility of saying that only under certain conditions can regression be used  and in others  sensing. on the other hand  the knowledge or belief of an agent is modeled explicitly in  as a fluent that can be changed by sensing actions  while for our purposes  knowledge will be left implicit. 
　what we propose in this paper is this: a formal specification of a changing world that generalizes reiter's solution to the frame problem  and hence strips also  to allow conditional successor state axioms  and generalizes levesque and others' treatment of sensors  e.g.  1; 1; 1; 
1   to allow conditional sensing axioms. our specification will be sufficiently general that in some cases  there will simply not be enough information to perform the projection task even with sensing. however  in many cases  we will be able to do projection using a combination of sensing and regression. in addition to this specification  we propose a reasoning method for performing projection under these general circumstances which is guaranteed to be sound  and in many cases of interest  complete. we provide a prolog evaluation procedure for the projection task and prove its soundness and under suitable circumstances its completeness. 
1 	basic action theories 
our account of action  sensing  and change is formulated in the language of the situation calculus  1; 1 . we will not go over the language here except to note the following components: there is a special constant so used to denote the initial situation  namely the one in which no actions have yet occurred; there is a distinguished binary function symbol do where do  denotes the successor situation to s resulting from performing action a; relations whose truth values vary from situation to situation  are called  relational  fluents  and are denoted by predicate symbols taking a situation term as their last argument; and there is a special predicate poss a  s  used to state that action a is executable in situation s. 
　within this language  we can formulate action theories that describe how the world changes as the result of the available actions. one such is a theory of the following form  1; 1 j: 
  axioms describing the initial situation so  and axioms not mentioning situations at all  which form together the initial database. 
  action precondition axioms  one for each primitive ac-tion a  characterizing poss a  s . 
  successor state axioms  one for each fluent i  stating under what conditions  holds as function of what holds in situation s. these take the place of the so-called effect axioms  but also provide a solution to the frame problem . 
  unique names axioms for the primitive actions. 
  some foundational  domain independent axioms. 
for example  the successor state axiom1 
is 
it was already broken  and a is not the action of repairing it. 
　in   to characterize the result of sensing  it is assumed that each primitive action can return a binary sensing result  and that there is a special predicate sf  used to state that action a returns value 1 in situation s. to relate this sensing result to fluents  the following are added to basic action theories: 
  sensed fluent axioms  one for each primitive action characterizing sf. for example  the sensed fluent axiom 

states that reading the heat gauge returns 1 iff the temperature around the robot exceeds 1 degrees. 
1 	guarded action theories 
in what follows we will be replacing successor state and sensed fluent axioms by more general versions. to this effect  instead of assuming that actions return a binary sensing value  we assume that a robot has a number of onboard sensors that provide sensing readings at any time. thus  we drop sf from the language of the situation calculus  and introduce instead a finite number of sensing functions: unary functions whose only argument is a situation. for example  thermometers   sonar s   depthgauge s   might all be real-valued sensing 
functions.1 
　　we then define a sensor-fluent formula to be a formula of the language  without poss  for simplicity  that uses at most a single situation term  which is a variable  and that this term only appears as the final argument of a fluent or sensor function. we write is a sensor-fluent formula with free variables among the and s  and for the formula that results after the substitution of by the vector of terms and s by the situation term  a sensor formula is a sensorfluent formula that mentions no fluents  and a fluent formula is one that mentions no sensor functions. 
　we then define our generalized version of successor state and sensed fluent axioms as follows: 
a guarded successor state axiom  gssa  is a formula of the form 

and a guarded sensed fluent axiom  gsfa  is a formula of the form 

   1 here and below  formulas should be read as universally quantified from the outside. 
   1 syntactically  these look like functional fluents  so to avoid confusion  we only deal with relational fluents in this paper. 
	de giacomo and levesque 	1 

where a is a sensor-fluent formula called the guard of the axiom  f is a relational fluent  is a fluent formula  and  is a sensor formula. 
an action theory can contain any number of gss as and gsfas for each fluent. we can handle a universally applicable successor state axiom like the one for broken above by using the guard true. we no longer have sensing actions  but we can achieve much the same effect using a gsfa with guard true. for example  
true   robottemp  thermometers  
says that the on board thermometer always measures the temperature around the robot. 
1 	some examples 
we now proceed to consider examples that cannot be represented in the basic action theories from section 1. 
1. the outdoor temperature is unpredictable from state to state. however  when the robot is outdoors  its onboard thermometer measures that temperature. 
outdoors s  
	outdoortemp 	thermometer s  
note that when the guard is false  i.e.  when the robot is indoors  nothing can be concluded regarding the outdoor temperature. 
1. the indoor temperature is constant when the climate control is active  and otherwise unpredictable. however  when the robot is indoors  its onboard thermometer measures that temperature: 
climatecontrol s  lndoortemp n  do a s    indoortemp 
indoors s  
	indoortemp 	thermometer -  
note that in this case  if the climate control remains active  then a robot that goes first indoors and then outdoors will still be able to infer the current indoor temperature using both sensing and regressing. to our knowledge  no other representation for reasoning about action and change can accommodate this combination. 
1. the distance between a  1-dimensional  robot and the wall is affected only by the moving actions. also  the onboard sonar correctly measures the distance to the wall  but only when the reading is within a certain interval. true 
in this case  the successor state axiom is universally applicable  meaning we can always regress all the way to 1o to determine the distance to the wall. however  if the distance to the wall in so is unknown  we would still not know the current value  and so it much more useful to be able to regress to a situation where the sonar reading was within its operating range. 
1 	automated reasoning 
1. if the robot is alone in the building  the state of the door is completely determined by the robot's open and close actions. either way  any time the robot is in front of the door  its onboard door sensor correctly determines the state of the door. 

one intriguing possibility offered by this example is that on closing a door  and later coming back in front of the door to find it open  a security guard robot would be able to infer that - alone. 
1. a warning light for an alarm can go on unpredictably. once it is on  however  it will stay on until the robot turns it off. also  the robot can determine the state of the warning using its onboard light sensor  provided it is looking at the light. 

in this case  we need a complex guard for the successor state axiom  since we can only regress when the light was on previously or when the action is to turn it off. 
1 histories and the projection task 
we are now ready to define the projection task formally. obviously  to be able to determine if a fluent holds at some point  it is no longer sufficient to know just the actions that have occurred; we also need to know the readings of the sensors along the way. consequently  we define a history as a 
sequence of the form 	where ai 
is a ground action term and 
 is a vector of values  with understood as the reading of the j-th sensor after the th action. if is such 
a history  we then recursively define a ground situation term end 	by end 	and end 
where 	we also define a ground sensor formula 
sensed 	j end 	where 	is the subhistory up to action 	i  and 	is the j-th sensor function. so end 	| is the situation that results from doing the actions in 	and sensed 	is the formula that states that the sensors had the values specified by the projection task  then  is this: 
given an action theory as above  a history  and 
a formula  s  with a single free variable s  determine whether or not sensed 
     1 obviously interesting histories have to satisfy certain legality criteria such as consistency of sensed and conformance to 
pass. 

1 generalized regression 
in principle  the projection task as formulated can be solved using a general first-order theorem proven but the ineffectiveness of this approach in an even simpler setting is arguably what led many to abandon the situation calculus and take up strips. our goal here is to keep the logical framework  but show that in common cases  projection can be reduced using a form of regression to reasoning about the initial situation  as done in . the reduction is tricky  however  because of the interaction between the various gsfas and gssas  requiring us to solve  auxiliary  projection tasks at each step. 
　what we propose is a generalized form of regression that is a sensible compromise between syntactic transformations and logical reasoning. specifically we require the latter only in evaluating the guards to decide which gsfas and gssas to apply  sec section 1 where regression is again used . 
     in the following we assume that is an action theory as above  is a history  and a n d a r e sensor-fluent formulas  is a sensor formula  and is a fluent formula. we use the notation to mean the formula that results from replacing every sensor function by the th component of the final sensor reading in we denote by 
  the part of formed by the initial database and the unique 
name axioms for actions as above. 
lemma 1 let sensor formula. 	then for every 
history the following statement is valid:1 

proof: by induction on the structure of 
　to begin  we consider simplifications to formulas resulting from sensing  using the guarded sensed fluent axioms. 

　next  we consider simplifications involving reasoning backwards using the guarded successor state axioms. 
1  we assume a logic with equality. 
proof: by logical manipulation and lemma 1. 
putting both forms of simplification together we get: 

lemma 1 and lemma 1. 
　　observe that a formula can regress to zero  one  or more formulas from . .  depending on how many entailed guards we can find for the fluents at each stage. 
　when a formula with a single free variable docs regress  then  as a consequence of theorem 1  we get the following: 
corollary 1 	under plausible consistency conditions for 
sensed 	regresses to 	from 	then 

this provides a soundness result for regression: to perform the projection task  it is sufficient to regress the formula  and check the result against the initial database. 
   unfortunately  regression in general cannot be complete. to see why  suppose nothing is known about fluent f; then a formula like  will not regress even though it will be entailed at any history. in section 1  we show that for certain histories  namely those where enough useful sensing information is available   regression will be complete. 
　the other drawback of regression as defined is that we need to evaluate guards. however  evaluating a guard is just a subprojection task  and so for certain  well structured  action theories  we can again apply regression  as we now show. 
1 	acyclic action theories and g-regression 
we now restrict our interest to action theories that are acyclic  in the following sense. let called the dependency relation  be a binary relations over fluents s.t. f' f iff there is a gsfa 	in where 
f' occurs in .an action theory ♀ is acyclic iff the dependency relation is well-founded. when it is  we call the level of a fluent f the maximal distance in terms of -chains from a bottom element of 
definition 1 let be acyclic. the sensor fluent formula g-regresses to f r o m r e g r e s s e s to 
1 we will elaborate on this in a longer version of the paper. 
	de giacomo and levesque 	1 

suhhistory 
the trickiest aspect of this definition is to show that the recursion is indeed well-founded. this is done by simultaneous induction on the length of and the level of the fluents. clearly  if a formula g-regresses to another  then it regresses also  although not vice-versa . the main point however is that we only ever need to evaluate formulas at so'-
theorem 1 for an acyclic under plausible consistency conditions for sensed if g-regresses to some 
formula from then the only theorem-proving needed to perform projection is to evaluate formulas in 
proof: by induction on the total number of simplification and roll back steps used to g-regress using corollary 1. 
1 	jit-histories 
as noted above  we cannot expect to use regression to evaluate sensor-fluent formulas in general: a tautology might be entailed even though nothing is entailed about the component fluents. however  in a practical setting  we can imagine never asking the robot to evaluate a formula unless the history is such that it knows enough about the component fluents  using the given gssas and gsfas  and their component fluents. 
　for example  assume we have the indoor temperature axioms from section 1. we might only ask the robot to evaluate a formula that mentions the indoor temperature for those histories where the climate control is known to have remained on from some earlier point in the history where the robot was known to be indoors. we do not require the robot to know whether the climate control was on before then  since this may have required going to a control panel   or even whether it is indoors now. in general  we call a history just-in-time for a formula  if the actions and sensii ; readings it contains are enough to guarantee that suitable formulas  including guards  can be evaluated at appropriate points to determine the truth value of all the fluents in the formula. more precisely: 


for jit-histories we have the following theorem: 
theorem 1 let be an action theory as above  and sensor-fluent formula. if is a jit history for then 
there exists 	formula 	such that: 
proof:  1  is proven by induction on the length of and induction on the structure of  1  is proven by simultaneous induction on the length of and the  max  level of the fluents in the  and induction on the structure of 

this theorem shows that for jit-histories  regression is both a sound and complete way of performing projection. 
1 	an evaluation procedure for projection 
although our action theories are assumed to be open-world  a jit-history provides a sort of dynamic closed world assumption in that it ensures that the truth value of any fluent will be known whenever it is part of a formula whose truth value we need to determine. this allows us to evaluate complex formulas as we would if we had a normal closed world assumption. we now consider a prolog procedure that does this. we assume the user provides the following clauses:1 
is a prolog constant. we drop the 
situation arguments from fluents and sensor functions in for-

1 	automated reasoning 

mulas  and keep track of the situation in the history . 
　　histories are represented as lists. for brevity  we assume a predicate last which extracts the last value  for sensor function in history we assume also a predicate sub with the meaning t h a t i s the formula obtained by substituting fori; in the formula  see  . now we define eval with the intended meaning that the formula evaluates to the truth-value b   t t / f f  for the history as follows: 
　　1 for simplicity in what follows  we do not distinguish between situation calculus formulas and their representations as prolog terms. 

eval h and pl p1  tt  :e v a l   h   p l   t t     eval h p1 tt . 
eval h / and pl / p1   ff  :e v a l   h   p l   f f   ; eval h p1 ff . eval h neg p  tt  :- eval h p ff . eval h neg p  ff  :- eval h p tt . 
eval h some v pv  tt  :sub v    pv  px    eval  h  px  t t   . 
eval  h  some v  pv    f f  : -
not sub v   pv px   not eval h px ff   . 
	/* double negation for ' ' f o r a l l ' ' 	*/ 
　　/* so not eval  h  px  f f  flounders! */ eval h equ e  v    t t   :-
sensor e   last h / e r  / r=v. 
eval h equ e v  ff  :- /* neg as failure */ sensor e   last h e r   not r=v. 
eval   mu   f tt  	:- fluent f   	i n i   f   . 
eval   mu    f ff  	:- /* neg as failure */ 
fluent f   closed f   not i n i   f   . 
eval h f b  :~ fluent f   gsfa alpha f rho   eval h alpha tt   eval h rho b . 
eval   a mu |h  f b  :fluent f   gssa a alpha f gamma   eval h alpha tt   eval h gamma b . 
observe that a formula eval a   fi  b  can either succeed returning t t   succeed returning f f  fail  or not terminate. under the assumption that all the auxiliary predicates are correct and terminating  we get the following soundness and a weak form of completeness for eval: 

note that we cannot guarantee termination since we can get into a loop evaluating guards of gsfas or gssas  or by floundering in trying to evaluate to f f an existential. we can eliminate the first problem by using acyclic action theories. for the second  we can close the domain. let domain o  be a user-defined predicate over a finite domain. we can then change the definition of eval for existentials as follows: 
eval  h  some v  pv    t t   : domain o   sub v 1 pv po   eval h po tt . 
eval h some v pv  ff  :not domain o   sub v 1 pv po   not eval h po ff  . 
for this new version of eval we get a completeness result: 
theorem 1 let be acyclic  let be sensor-fluent formula with no free variables except the situation argument s  and let  be a j it-history for  then  e v a l b   always succeeds  returning either tt or ft. 
so under these circumstances  eval is a sound and complete implementation of projection. 
1 	conclusions 
we have given a formal definition of projection for a generalized action theory where successor state axioms and sensing information are only conditionally applicable. we also showed that in certain circumstances  a regression-based evaluation procedure could correctly perform the task. 
　many open problems remain  however. how can we decide in an automated but practical way when regression can be used  it may be expecting too much of a conditional planner to determine what actions it should perform now to permit it to later use sensing information in this way. an interesting alternative is offered by the high-level program execution model. given a program like  if then do  else do   the user can take the responsibility of inserting a prior program ensuring that the resulting history is just in time for 
　another related problem is the projection of initial databases. once a robot actually performs a sequence of actions in the world  we would prefer to no longer regress all the way back to the initial situation  but instead to project the database forward to the current state . how this can be done for the action theories we are proposing remains to be seen. 
