
desktop users commonly work on multiple tasks. the tasktracer system provides a convenient  lowcost way for such users to define a hierarchy of tasks and to associate resources with those tasks. with this information tasktracer then supports the multi-tasking user by configuring the computer for the current task. to do this  it must detect when the user switches the task and identify the user's current task at all times. this problem of  task switch detection  is a special case of the general problem of change-point detection. it involves monitoring the behavior of the user and predicting in real time when the user moves from one task to another. we present a framework that analyzes a sequence of observations to detect task switches. first  a classifier is trained discriminatively to predict the current task based only on features extracted from the window in focus. second  multiple single-window predictions  specifically  the class probability estimates  are combined to obtain more reliable predictions. this paper studies three such combination methods:  a  simple voting   b  a likelihood ratio test that assesses the variability of the task probabilities over the sequence of windows  and  c  application of the viterbi algorithm under an assumed task transition cost model. experimental results show that all three methods improve over the single-window predictions and that the viterbi approach gives the best results.
1 introduction
today's desktop information workers continually shift between different tasks  i.e.  projects  working spheres . for example  gonzalez and mark   in their study of information workers at an investment firm  found that the average duration of an episode devoted to a task was slightly more than 1 minutes  and that workers typically worked on 1 different tasks in a day. furthermore  the informationneeded for each task tends to be fragmented across multiple application programs  email  calendar  file system  file server  web pages  etc. . the tasktracer system  dragunov et al.  1  is one of several efforts that seek to address this problem by creating  task-aware  user interfaces for the information worker.
　tasktracer provides a convenient way for the user to define a hierarchy of tasks and associate information resources  email messages  files  folders  web pages  with those tasks. the user can declare a  current task   via a task selector component in the window title bar   and tasktracer then configures the desktop in several ways to support the selected task. for example  it supplies an application called the task explorer  which presents a unified view of all of the resources associated with the current task and makes it easy to open those resources in the appropriate application. it also predicts which folder the user is most likely to access and modifies the open/save dialog box to use that folder as the default folder. if desired  it can restore the desktop to the state it was in when the user last worked on the task  and so on.
　this approach of requiring the user to declare the current task makes sense when the user is returning from an interruption and wants to bring up the list of relevant resources. however  this approach fails when the user is interrupted  e.g.  by a phone call  instant message . the user typically changes documents  web pages  etc. without remembering to first inform tasktracer. in such cases  we would like tasktracer to automatically detect the activity switch.
　to address this problem  we wish to apply machine learning methods to automatically detect task switches. when a task switch is detected  we would like tasktracer to pop up a  balloon alert  asking the user for permission to change the current declared task. to be usable  this task switch detector must be highly precise  i.e.  have very low false alarm rate   and it must be timely  i.e.  it must detect the task switch as soon as possible after it occurs so as to avoid interrupting the user once he or she is fully engaged in the new task . finally  it must consume minimal cpu resources so that it does not interfere with the work the user is trying to accomplish. we call this task switch detector the taskpredictor.
　the first taskpredictor for tasktracer was developed by shen et al. and deployed in tasktracer in 1. this taskpredictor is a classifier trained to predict the user's current task based only on features describing the window currently in focus. in the remainder of this paper  we will refer to this as the single window classifier  swc . although the swc achieves fairly high accuracy  it is unusable in practice because it produces far too many task-switch false alarms.
　this paper describes a set of experiments to develop an improved taskpredictor. our basic idea is to develop algorithms that analyze the sequence of predictions from the swc to make more reliable task switch predictions.
　the remainder of this paper is structured as follows. first  we describe the single window classifier in detail. then we present a framework that we have applied to the task switch detection problem. this framework makes the task switch decision based on a metric that combines multiple task predictions over time. three different metric functions are proposed in this paper. third  we show experimental results on both synthetic and real user data. we conclude the paper with a review of related work and a discussion of future work.
1 tasktracer and the single window classifier  swc 
tasktracer operates in the microsoft windows environment and collects a wide range of events describing the user's computer-visible behavior. tasktracer collects events from ms office 1  ms visual .net  internet explorer and the windows xp operating system. then various tasktracer components provide services to the user based on this information. from the raw event stream  the swc extracts a sequence of window-document segments  wdss . a wds consists of a maximal contiguous segment of time in which a window is in focus and the name of the document in that window does not change. the swc extracts information about the window title and the file pathname from each wds. then it heuristically segments these into a bag of  words  and creates a binary variable xj in the feature set for each unique word. to put more weight on long-duration wdss  taskpredictor creates multiple training instances for each wds. for a wds that lasts t seconds  taskpredictor generates identical training instances.
　for the sake of both accuracy and speed  the information gain  yang and pedersen  1  of each feature is computed and then the 1 features with the highest  individual  predictive power are retained and the rest are discarded. we will refer to these 1 features as the  informative  features .
　it is reasonable to ask whether feature selection causes a large number of wdss to have empty bags of words  i.e.  to be uninformative . we checked this on one user's 1-month tasktracer dataset. this dataset contains 1 distinct words. we discretized time into 1-second periods and applied feature selection to the entire dataset. figure 1 shows the fraction of episodes that have at least one informative feature as a function of the number of features selected. with 1 features  more than 1% episodes still have informative features.
　the first version of our taskpredictor worked by applying the swc to predict the task of every informative wds. if the predicted task was different than the user's declared task and if the prediction was sufficiently confident  then taskpredictor issued a task switch alarm. initial experience with this taskpredictor revealed that it was very sensitive to noise and that it issued many false alarms. clearly  we need a more sophisticated technique to solve this problem.

figure 1: impact of feature selection. fraction of one-minute intervals that have informative observations as a function of the number of selected features.
1 switch detection with informative observations
detecting switches from individual task predictions fails mainly because decisions based on just one observation are not reliable: given the observations {x1 x1 ... xt}  the swc only uses xt to predict the task at time t. instead  we should detect switches based on the previous  observations
. the larger value of  can bring more information to make the task switch predictions. however  this comes at the cost of reducing the timeliness of the predictions  because roughly we have to wait for /1 observations before the system has enough information to reliably detect the task switch.
1 a framework to detect task switches
figure 1 presents our framework for detecting task switches. we execute the detector every f seconds or when an event is received. if the bag of features for a wds contains no informative features  i.e.  it is the null bag   then it is ignored. this usually happens for short-duration pop-up windows  empty internet explorer windows  new office documents   document1    and so on.
　the informative wds observations are pushed into a firstin-first-out queue x of maximum length . once x contains  elements  each new element added to x causes the oldest element to be removed. the function switchmetric computes the switch metric value Λ from x and also returns the predicted new task as discussed below. if Λ exceeds a threshold  a task-switch alert is shown to the user  and the user is asked to confirm it. if the user agrees  then the current task is changed to the new task  otherwise it is left unchanged.
　the variable silentnumber stores the number of informative observations since the last switch alarm was made. to avoid annoying the user  the method does not raise any new alarms for at least the next r informative observations after a switch alarm.
　if no event occurs for a long time  more than d seconds   then there is no point in predicting a switch  so we can avoid

procedure switchdetectorthreshold 

input:  - we will store  observations in queue x d - efficiency delay; skip switch computation if wds has lasted longer than d seconds
r - recovery time; keep silent for the next r informative
observations after a switch alarm
noeventtime ○ 1
silentnumber ○ ±
do  every f seconds or if an event happens  if  no event happened 
   noeventtime ○ noeventtime + f else noeventtime ○ 1
//skip inference if nothing has happened for d seconds if  noeventtime   d  continue
//update the observation queue x xnow ○ getobservation   if  xnow is not null 
updatequeue
silentnumber ○ silentnumber + 1
　else continue if  silentnumber ＋ r  continue  Λ  predictedtask  ○ switchmetric x  if  Λ   threshold  silentnumber ○ 1 if  popupalert predictedtask  == ok  setcurrenttask predictedtask  until the system is shutdown

figure 1: generic framework for detecting task switches.
the cost of computing the switch metric. we do not want x to be full of identical observations from the same long-duration wds. hence  there is no need to update x either.
　with some user studies  we set the default parameters for this framework as follows: f = 1  d = 1  and r = 1.
1 metric functions
we now describe three methods for computing metric functions based on the fifo queue of informative observations x. first we describe the baseline method  which is similar to what has been deployed in the latest tasktracer release.
baseline method
the baseline method applies the swc to each observation individually. given an observation x  the swc returns three things: a predicted class label y   a probability distribution Θ = p y|x  over the possible class labels  and a confidence measure that estimates p x . the baseline method considers a prediction to be confident if p x  exceeds a given threshold  shen et al.  1 . it compares the class labels of the two most recent confident predictions and declares a task switch alarm if they are different.
class probability voting
a simple solution to combine multiple predictions is voting. let x be the queue of informative observations. the basic idea is to vote for the task of 
and the task of  and see whether they are
the same.	first  compute ya = argmax
and yb = argmax. then calculate the switch metric as

where i p  = 1 if p is true and  1 otherwise. throughout this paper  we train support vector machines to do class probability estimation  platt  1; wu et al.  1 . this voting method votes the class probability distributions to calculate the metric. it is straightforward and cheap  but it doesn't take into account the variability of the task probabilities.
likelihood ratio scores
instead of just looking at the sum of the predicted class probability distributions  we can also consider the variability of those distributions. although voting may suggest a task switch  if the class probability distributions within each half of x are highly variable  this suggests low confidence in the prediction.
　let Θi be the posterior probability distribution over the tasks given observation xi  and μa  μb be the true means of respectively. we seek to test the hypothesis h1 : μa = μb against the alternative. developed by neyman and pearson  the likelihood ratio test provides a general methodology to test a two-sided alternative against a null hypothesis  mukhopadhyay  1 . the central limit theorem states that the sample mean is approximately a gaussian distribution given a sufficiently large sample. thus  we can compute the switch metric Λ as the gaussian likelihood ratio score

 where  and  are the sample means and Σa and Σb are the sample covariance matrices of  and  respectively. we should reject h1 for large values of Λ. if we assume are independent  and treat Σa and Σb as diagonal matrices  then the computation time is excluding the expense for the swc to compute p yj|xi .
　the central limit theorem suggests that  should be quite large  e.g.    1 . however  very large  values will substantially delay the task switch alarms. fortunately  our experimental results are good even when.
minimal transition costs
our third metric is based on hypothesizing a task switch cost and applying an additive conditional cost formula similar to that of hidden markov models  hmms . we define the cost of labeling x by y as

where ca is the atemporal cost of labeling observation i with yi and ct is the transition cost of moving from task yi 1 to task yi. we define ca as the negative log likelihood ca =  logp yi|xi . as in fern et al.   we define the transition cost function as  where c is a real and δ p  = 1 if p is true and 1 otherwise. this model simply charges an equal cost for all task switches  even though it's possible that some switches are more likely than others.
　we assume that the sequence x is short enough that it only contains 1 or 1 switches. we are concerned with whether there is one switch for sequence x. so we compare the minimal cost under the assumption of 1 switches to the minimal cost under the assumption of one switch:

.
 1 
we apply the viterbi algorithm to find these minimal costs. given  x1 ... xi   let αij be the minimal cost if we predict the task at time i as yj and predict no switch until time i. let βij be the minimal cost if we predict the task at time i as yj and that one switch has occurred prior to time i. for each yj  we initialize α1j = ca yj|x1  and β1j = +±. for task yj  if we assume that no switch has occurred until time i  then αij is simply the sum of the atemporal costs plus α i 1 j. if we assume that one switch has occurred prior to time i  there are two possibilities: this switch occurred at time i or before time i. we then pick the choice with the smaller cost and add the atemporal cost to give βij. thus   we can
recursively calculate the cost for each yj at time i as
	αij = α i 1 j + ca yj|xi  	 1 

the minimal costs over the entire sequence x will be α =  and. we set the value of the metric as their difference:
	Λ = α   β.	 1 
this viterbi search will take time excluding the expense for ca yj|xi . in step i we only need to calculate ca yj|xi  for each yj  and these values can be cached for future reuse.
1 experimental results
we tested the framework and the three task switch metrics on synthetic data and on data from four real users.1
　we generated 1 synthetic datasets using the following process. each dataset contained 1 tasks and 1 distinct words. for each task  its multinomial distribution over words was randomly generated so that 1 of the words were approximately 1 times more likely to appear than the remaining 1 words. then  we sequentially generated 1 episodes: first we chose a task y uniformly at random and generated the length of the episode m uniformly in the range  1 ＋ m ＋ table 1: datasets for evaluating switch detection  # of words is computed after stoplist and stemming 
data setfafbfcsasize in months 11.1# of switches11# of tasks11# of words111 . then we generated m observations for task y according to its multinomial distribution such that each observation lasts 1 second and contains less than 1 words.
　the real user data was obtained by deploying tasktracer on windows machines in our research group and collecting data from four users  whom we referred to as fa  fb  fc  and sa. the collected data is summarized in table 1. each episode in these data sets was hand-labeled with the associated task  although these labels probably exhibit considerable levels of noise.
　we now present the results for two performance metrics: coap and precision.
　coap given the size of the queue. we measure the probability that segment boundaries are correctly identified by the co-occurrence agreement probability  coap   beeferman et al.  1; mccallum et al.  1 . the sequence of observations can be divided into segments using either the observed or the predicted task switch points. consider two arbitrary time points t1 and t1 in the segmented sequence. either t1 and t1 belong to the same segment  or they belong to different segments. the coap is computed by choosing a probability distribution d over  t1 t1  and measuring the probability that the observed and the predicted segmentations agree on whether these two points belong to the same or different segments. in our case  d is the uniform distribution over all pairs  t1 t1  such that |t1   t1| ＋ 1 time units. for the synthetic data set  the time unit was 1 second; for the real user data  the time unit was 1 seconds.
　for each dataset  the data is ordered according to time and divided into three equal time intervals: a  b  and c. we first

figure 1: the average coap values of the synthetic data as a function of   the length of the observation queue x

figure 1: the average coap values of the real user data as a function of 
train the single window classifier using a. then for a given switch detection algorithm  we vary the threshold and evaluate on b to choose the best threshold. recall that we issue a switch alarm when the metric value is larger than the threshold. finally  we retrain the swc using a+b and apply the learned swc and threshold value to evaluate on c. the results on c are plotted in figure 1 and 1.
　from the plots    the size of informative observation queue  is crucial to the accuracy of methods. when creased  the coaps first increase and then decrease for all three metric functions. the initial increase is presumably due to the increase in the amount of information available. the subsequent decrease is presumably due to the fact that when the queuex is too long  it contains more than one task switch  but our framework assumes only 1 or 1 task switches occur. there might be 1 or even more switches when  is large. the maximal coaps are reached when  is around 1 for the synthetic data and around 1 for the real user data. the highest coap value of any metric function is larger than that of the baseline method.
　the minimal transition cost metric gives the best performance  particularly on the synthetic data. one reason may be that unlike the other metrics  it is not constrained to predict the switch point in the center of the observation queue x. the likelihood ratio metric is more conservative in predicting switches  since it will not issue any alarm if the predicted p y|xi  is not stable. thus it misses some real switches  but it makes fewer false alarms. this sometimes leads to a low coap value. the voting method is the least effective.
　precision given coverage. we measured precision and coverage as follows. if a correct  user-labeled  switch occurs at time t and a switch is predicted to occur between t 1 and t + 1  then the first such switch prediction is considered to be correct. however  subsequent predictions in the same time interval are counted as errors. precision is the probability that a switch prediction is correct. coverage is the probability that a user-labeled switch is predicted correctly.
　we adopted an on-line learning methodology to evaluate the algorithms on the real user data. we divided the data into days and assign d1 to be the day that is 1% of the way

figure 1: the average precision values as a function of the coverage for real users given 1 observations  created by varying the prediction threshold.
through the data set. this defines an initialization period. for each day d fromd1 to the end of the data set  we trained the system on the data from days 1 through d 1 and then evaluated its performance on day d. the precision given coverage for informative observations is plotted in figure 1.
　our framework with any of the metric functions outperforms the baseline method. these results show that using more observations does reduce the false alarms. the minimal transition cost metric gives the best results for coveragebelow 1%. compared to the baseline method  the minimal transition cost metric can improve precision by more than 1%. the likelihood ratio metric gives the best results for coverage from 1% to 1%. voting is the worst of the three metrics.
1 related work
our method of task switch detection is based on task recognition and prediction  for which many methods have been developed  see shen et al.   for a review . there are also some attempts in understandingthe user's interest in information retrieval area  ohsawa and yachida  1 .
　task switch detection is also related to change-point detection  chen and gopalakrishnan  1; guralnik and srivastava  1 . the standard approach of change-point detection has been to  a  apriori determine the number of changepoints that are to be discovered  and  b  decide the function that will be used for curve fitting in the interval between successive change-points guralnik and srivastava  1 . these approaches usually do not employ supervised learning techniques. our switch detection method sheds some light on such problems: we can hand-label observations and train a switch detector to predict change points.
　task switch detection is different from novelty detection  scho：lkopf et al.  1; campbell and bennett  1; ma and perkins  1  and first story detection  allan et al.  1 . novelty detection  or anomaly detection  tries to automatically identify novel or abnormal events embedded in a large body of normal data. one application is to liberate scientists from exhaustive examination of data by drawing their attention only to unusual and  interesting  phenomena  ma and perkins  1 . the problem is typically solved by learning a pattern to cover most normal data points. any point outside of this pattern will be considered as a novelty. however  in switch detection  when the user is changing tasks  the current observation may be neither novel nor abnormal. first story detection  fsd  is the task of online identification of the earliest report for each news story as early as possible. existing fsd systems usually compare a new document to all the documents in the past  and they predict a first story if the similarity score is smaller than some threshold. this method does not work for switch detection  because task switches often involve repeating activities that the user did in the past.
　text segmentation tries to predict where boundaries occur in text  beeferman et al.  1 . maximum entropy markov models  mccallum et al.  1  and conditional random fields  lafferty et al.  1  have been successful in natural language tasks. with some additional requirements  it is possible to apply these state-of-the-art models to detect task switches. first  since task switch detection is done in real time  we should do efficient filtering  instead of smoothing . second  the cost for wrong predictions is unbalanced: a false alarm costs a lot; it is more acceptable to miss some switches.
1 conclusions and further work
in this paper  we introduceda special case of the generalproblem of change-point detection  which we term task switch detection. this involves monitoringthe user's behavior and predicting when the user switches to a different task. to reduce false alarms  we made our decision based on multiple informative observations-observations exhibiting one or more of the 1 most informative features. we tested this framework in the tasktracer system and compared three switch metrics  each computed from information produced by a learned single window classifier  swc . we found that the metric based on an assumed task switch transition cost and the viterbi algorithm gave the best results.
　we are exploring four directions for future improvement. first  we are testing methods for overcoming noise in the user's task switch labels by treating those labels as noisy measurements of the true labels and training the swc using em. second  we are studying methods of active learning to reduce the number of labels that the user needs to provide. third  we want to learn episode-duration models and apply them  e.g.  in place of the fixed recovery time parameter r . finally  we would like to replace our simple decision threshold with a decision-theoreticprocedurebased on the estimated costs and benefits of interrupting the user with a task switch alarm.
acknowledgments
supported by the nsf under grant iis-1 and by the darpa under grant no. hr1-1and contract no. nbchd1. the authors thank the tasktracer team.
