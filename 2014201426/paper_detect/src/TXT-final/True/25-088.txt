 
uncertainty processing methods are analysed from the viewpoint of their sensitivity to small variations of certainty factors. the analysis makes use of the algebraic theory which defines the function for combining partial certainty factors by means of a group operation of the ordered abelian group over the interval of uncertainty. two approaches are introduced:  a  sensitivity analysis of the inference network and  b  calculation of second order probabilities. sensitivity functions are defined as partial derivatives of the combining function with respect to their arguments. based on the sensitivity functions  we define the path sensitivity which measures the sensitivity of a larger part of the inference network. if a set of samples of certainty factors is available instead of a single value  the second order probability distribution can be approximated by the distribution of an average value. it is shown that the parametric form of the distribution is completely determined by the combining function. 
1 introduction 
numerical values describing the uncertainty of knowledge and data in knowledge-based  kb  systems are usually imprecise due to the fact that they are almost always provided as the subjective assessments of experts or users. nonetheless  these imprecise numbers are processed by some algorithm and the results are used to draw conclusions. without a thorough kb verification which includes an analysis of the robustness of the uncertainty processing technique used  we must always be aware of die limited credibility of results. this paper aims to provide techniques for such an analysis. the methods described are based on compositional  extensional  calculation of uncertainty processing  duda et id.  1; gashnig  1; heckerman  
1; reiter  1; wise  1   see  hajek et al.  1; pearl  1  for more detailed discussion . although the current attention of the al community is focused rather on intensional  model-based  probabilistic  approaches 
1 	knowledge representation  spiegelhalter  1; lauritzen and spiegelhalter  1; pearl  1   the compositional methods are still popular due to their computational simplicity. the main objection to the compositional methods is that the results are not sound. in  hajek et al.  1  an attempt is made to revive these methods by replacing the original simple-minded interpretation of their results by a comparative one  thus improving their robustness as well as their soundness. 
　we will present two methods for assessing the imprecision of uncertainty measures in rule-based kb systems. the first approach is based on sensitivity evaluation. the idea of a sensitivity analysis of inference nets was explored in prospector  gashnig  1   where a uranium model was compiled and run for a large number of combinations of data and the sensitivity was calculated. our approach is more analytical. we define sensitivity functions for particular methods of combining certainty factors and then in terms of these functions and rule sensitivities  we analyse the sensitivity of a path in the inference network. the second method proposed in this paper is based on the idea of second order uncertainties  i.e. the uncertainties of certainty factors. the concept of second order probabilities has already been suggested by  cheeseman  1 . we will show that for certain statistics the parametric form of the second order probability density is completely determined by the method used for combining certainty factors. this property makes it possible to calculate the actual second order density functions. moreover  the parametric form of this density function is invariant with respect to the combining function used. 
1 preliminaries 
regardless of their origin  the uncertainty measures will be called certainty factors throughout this paper. our approach is based on the algebraic theory of uncertainty processing developed by  hajek et al.  1 . we will briefly summarise the relevant parts of hajek's theory needed for the presentation our work  for the complete theory see  hajek et al.  1  . it is assumed that knowledge is expressed in terms of rules. a numerical certainty factor  weight  w from 
  -1  is associated with each rule   the extreme certainty factors correspond to  hypothesis h is false   value -1  and  hypothesis h is true   value 1  respectively. certainty factor 1  zero  stands for  there is no evidence concerning hypothesis h' if two or more rules bear on the same hypothesis  the overall certainty factor of the hypothesis is calculated by applying some combining function to individual contributions. we will call the result produced by the combining function  the global certainty factor   and the contributions  i.e. the arguments of the combining function   partial  certainty factors. the combining function is defined by means of a binary operation  r  for which the following axioms hold: 


fig. 1  c  combining functions - counter-example 

1 sensitivity functions 
　for applications  the exact values of certainty factors must not be crucial. uncertainty processing methods must provide correct results regardless of small variations in numerical values. from this point of view we expect the processing methods to be insensitive to small changes. on the other hand the method must  weigh  the contributions; the global certainty factor must depend on the values of partial ones which means that it must not be too insensitive. given a standard rule-based architecture it is reasonable to assume that no knowledge is represented in terms of the combining method  i.e. we will consider the same  a priori determined  combining function throughout the inference network. the sensitivity of the final hypothesis depends on the sensitivities of rules and the sensitivities of combining algorithms. the behaviour of the combining function for small variations of one variable is described by the first partial derivative with respect to this variable. 
definition 	1 
the sensitivity function sx x y  of a combining function g x y  widi respect to x is 
1 	knowledge representation 



1 	knowledge representation 

　proposition 1 states that the combining function preserves sample averages. in accordance with the proposition 1 the combining function preserves the parametric form of the second order density of group averages. however the calculation of the second order density for group averages across all inference network cannot be carried out automatically by recursively repeating results of proposition 1 since there is still the non-linear edge propagation described by  1 . it is necessary to split the inference network into simple parts and cases and analyse them individually. 
　having obtained the second order density we can calculate average values of various characteristics which depend on values of certainty factors. as an example we can combine both measures introduced in this paper and calculate an average sensitivity function. it will be defined as 

　the averaging is a kind of smoothing procedure. if the dispersion a is very small  i.e. our knowledge of certainly factors is very certain  the second order density is a very high and narrow peak which takes a very local sample of the averaged function  of the sensitivity function in the case above . for a large c the average sensitivity function is very smooth. the doubts concerning the correct value of the certainty factor helps to solve the sensitivity problem. similarly  the second order density can be used to average other useful characteristics. 
1 conclusions 
　we have presented two different tools for the analysis of uncertainty processing methods in rule-based systems and shown some of their properties. the first method sensitivity analysis - is focussed on properties of the knowledge base with uncertainty. sensitivity functions evaluate the sensitivity of the combining formula while the path sensitivity makes it possible to assess the sensitivity of the inference network as a whole. the second method second order probability - is concerned with the impact of uncertainty values from outside the knowledge base  i.e. from the user. both techniques  which are intended mainly as an off-line analysis  can be used independently or in combination. they allow a deeper insight into properties of inference networks which is important from an application point of view. 
acknowledgements 
thanks to renato barrera  marc eisenstadt  radim jirousek  john reiter  arthur stutt  stuart watt and two of the three anonymous referees for useful comments on earlier versions of the paper. 
