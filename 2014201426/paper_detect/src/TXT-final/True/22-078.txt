 
　　many artificial intelligence systems implicitly use notions of granularity in reasoning  but there is very little research into granularity itself. an exception is the work of hobbs   which outlines several characteristics of granularity. in this paper we describe an approach to representing granularity which formalizes in computational terms most of hobbs' notions  often refining and extending them. in particular two types of granularity have been delineated: aggregation and abstraction. objects can be described at various grain sizes and connected together into a granularity hierarchy which allows focus shifts along either aggregation or abstraction dimensions. we briefly discuss how we have used granularity hierarchies in the recognition of novice lisp programming strategies and show how this enhances the recognition process and can lead toward planning appropriate feedback for the student. 
1 	introduction 
our long term goal in this research is to show how the use of granularity can enhance the capabilities of intelligent tutoring systems. granularity is an important part of instruction for two reasons. the first reason involves pedagogy. the level of generality or specificity at which a tutor chooses to present a topic  combined with the level of generality or specificity at which the student interprets the presentation  will affect the student's success at understanding instruction. both tutor and student must be  on the same instructional wavelength . shifting grain size in instruction must proceed smoothly  guided either by tutor or student. 
     the second reason is diagnosis. it is often difficult to precisely diagnose a student's problems. students frequently exhibit bizarre or original behaviour which may be quite incomprehensible in detail. however  it is often possible to understand generally what a student is attempting to do. this knowledge can be used in designing appropriate feedback to the student and in focussing on points of ambiguity and misunderstanding. thus in educational diagnosis  unlike other domains  being able to recognize student behaviour at coarse grain sizes is often useful. 
     in this paper we propose a model for granularity  and show how it can be used in the recognition of strategies that novice students use in solving recursive lisp programming problems. this recognition can occur at coarser or finer levels of granularity  corresponding to shallower or deeper understanding of student behaviour. 
1 background 
shifts in perspective from high level to low level and vice versa have been implicit in many ai systems  ranging from the level shifts in heuristic classification schemes  e.g. as discussed in  clancey  1    through the hierarchical reasoning used by various planning systems  e.g. isaccrdoti  1    the use of knowledge hierarchies to guide computer vision systems  e.g.  mackworth and havens  1    and the representation of knowledge in semantic network schemes  e.g.  levesque and mylopoulos  1  . such shifts can be interpreted as granularity shifts  but have seldom been viewed from this perspective. 
     an exception is the work of hobbs  which attempts to explicitly delineate the nature of granularity and to show how granularity can be used in representation and reasoning. hobbs describes the following characteristics and properties of granularity: 
  relevant predicate set  r  - given a view of the world  ie. a particular situation of interest  only certain selected predicates from the global theory of the world are of interest. these are called  relevant predicates . these must be determined locally since they constitute the perspective from which the world is viewed in a particular situation. 
  indistinguishability relation  -*  - pairs of objects  interpreted broadly as objects  events  actions  agents  etc.  in the domain of interpretation are considered to be indistinguishable if and only if no relevant predicate can distinguish between them. thus  . 
  simplification mapping  k  - a detailed view of the world may be collapsed to a simpler view by means of a function k which maps the objects at one grain size to a simpler set of equivalence classes of objects at a coarser grain size  k also maps relevant predicates at the finer grain size onto new relevant predicates which make objects within the coarser-grained equivalence classes indistinguishable. thus for some equivalence class c in the simpler theory  if 
k : v -   c and k:w- c then for all predicates k p  in the simpler theory  v is indistinguishable from w. 
  articulation - articulation is the translation from a coarse-grained to a finer-grained theory. relevant predicates 
at the coarse-grained level arc decomposed into finer-grained predicates. although hobbs only talks in general terms about articulation  such decomposition would presumably be carried out using a mapping like k~1  which defines the classes of indistinguishable objects at finer grain sizes. 
  idealization - often the need to differentiate between objects at a coarse grain size forces the imposition of an arbitrary boundary between these objects  a process of idealization that is necessary to preserve the integrity of the coarse-grained classification. for example  if temperatures in the 1's form one such object and temperatures in the 1's form another  a predicate that could distinguish these two objects would need to be capable of distinguishing 1 from 1. this seems counterintuitive  given the grain size of the two classes being distinguished  but is seen by hobbs as being preferred to fuzzy or probabilistic approaches. 
　　the theoretical framework for granularity described by hobbs has been the starting point for our investigations. 
we have been able to reinterpret hobbs' notions in a computational formalism which both elaborates and refines the concept of granularity  as will be discussed below. 
1 a representation for granularity 
　　on closer analysis of granularity  it becomes apparent that there are at least two dimensions along which which granularity must be interpreted: abstraction  corresponding to shifts in focus from general to specific or vice versa; and aggregation  corresponding to shifts in focus through partwhole relationships. we propose a hierarchical representation for granularity in objects  roughly equating granularity with level shifts in a directed graph. nodes in the graph are thought of as objects  broadly interpreted as in hobbs   with links representing two distinct granularity relations  abstraction and aggregation. 
　　formally  a granularity hierarchy  y  consists of a finite set of objects  n  linked by granularity relations  i.e. 
the asymmetric binary relations 	  
 corresponding to abstraction and aggregation respectively . 
for 	  
which may be read is an abstraction of    or alternatively  is a specialization of n-  and 
v 
for 
which may be read is an aggregation containing ni or alternatively  ni is a part of these two relations provide the links for a granularity hierarchy representing objects related by abstraction and/or aggregation. objects may be maximal aggregations  which by definition are those objects which are not parts of any other objects  i.e. n is a maximal aggregation iff 
　　a principal abstraction hierarchy  consisting of only these maximal aggregations  is a uniquely-rooted  directed acyclic graph with links corresponding to abstraction relations   connecting the maximal aggregation objects. 
the principal hierarchy represents the simplest  most aggregate  objects we wish to consider  arranged in terms of rela-
1 	intelligent tutoring systems 
tive abstraction. this hierarchy is rooted at the most abstract object  and bottoms out at the most specialized ob-
jects. figure 1 shows a fragment of a principal abstraction hierarchy for a set of lisp strategies at various grain sizes. 
　　each maximal aggregation object is the root of another directed acyclic graph  this time linked by aggregation relations p. each object in this dimension is a component part of the maximal aggregation object  or a part of one of its parts  etc. figure 1 shows the aggregation hierarchy rooted at the maximal aggregation  cdr recursion  object shown in the previous figure. 
　　abstraction and aggregation can be thought of as orthogonal dimensions of granularity  relating objects in the granularity hierarchy with one another. the entire granularity hierarchy is connected to the most general object   root   in the principal abstraction hierarchy according to the connectivity axiom  

respectively. this implies that from any object the root can be accessed by shifting focus to more aggregate grain sizes until reaching a maximal aggregation  followed by shifting to more abstract grain sizes along the abstraction dimension. the root in the above figures is the object  lisp program . 

in addition to these linkages  we permit  but do not require  the existence of abstraction relations between finer-grained objects in the aggregation dimension. this provides for abstraction relationships among parts of finer aggregations. the resulting granularity hierarchy is a partial lattice of objects characterized by its two orthogonal relations. a more complete description of this formalization of granularity is given in another paper  greer and mccalla  1 . 

a fragment of the aggregation 
hierarchy for cdr recursion figure 1 
     our approach to granularity can be interpreted in terms of hobbs' characteristics  and in fact often refines and extends his notions. each characteristic will be considered in turn: 
  indistinguishability and distinguishability: indistinguishability can be defined using the explicit structure of the hierarchy  y  rather than some set of relevant predicates. the indistinguishability relation is meaningful relative to a particular level of granularity  in abstraction and in aggregation . objects are considered indistinguishable if they are finer grained than the object under consideration. hence  there is a notion of indistinguishability with respect to each and every object in the hierarchy  denoted as ~n  . we define indistinguishability between objects n  and nj with respect to an object n as 

     a related characteristic  not directly discussed by hobbs  is distinguishability. intuitively  one may think that this is simply the dual of indistinguishability  but it is not. objects which can be distinguished with respect to a given object are precisely the other siblings of the object in both the aggregation and abstraction dimension. this relation gives an object knowledge of the perspective it embodies relative to local alternative perspectives. clearly some objects may be neither indistinguishable nor distinguishable relative to some given object. such objects are simply irrelevant to the given object  at least with respect to granularity considerations. 
     looking at figure 1  from the point of view of  cdr recursion    car/cdr recursion    car recursion    tailend recursion   and  embedded recursion  can all be distinguished from one another  being siblings . further   cdr tail-end recursion    cdr tail-end predicate   etc. down to  findb preferred solution  are all indistinguishable; and  predicate function    recursion    function 
definition   and  lisp program  are undefined. 
  relevant predicates: we refine hobbs' notion of relevance to incorporate two kinds of predicates: observations and k-clustcrs. these not only define the aggregation level of granularity of an object  but arc utilized in object recognition at a particular level of abstraction granularity  as will be discussed in section 1. 
     an observation is a predicate completely determined by evidence obtained directly from the environment through the evaluation of some observer function  ofunction . an observation may be associated with an object for the purposes of distinguishing it from other objects  or to contribute to the recognition of the object on the basis of outside evidence. in fact  at some grain size s  objects must be recognizable from direct observations alone. thus aggregation  bottoms out   and every finest grained object along the aggregation dimension ultimately must be recognized by a direct observation. 
     frequently an object can be characterised in a number of ways  even at a specific grain size. it may be characterized in terms of its parts and predicates that describe how those parts fit together; it may be characterised by some subset or other set of parts under certain conditions; or it may be characterized by predicates that are quite independent of its parts. for example  a recursive lisp function may be characterized by 1  a combination of recursive function parts  base cases and recursive cases  properly assembled  1  an infinite tail-end recursion  as in an interpeter   or 1  particular behaviour in traces of function calls and returns. we name each different way of characterizing an object a  kcluster   nilsson  1 . a k-cluster is a combination of observations and component parts that characterize an object under certain conditions. thus  k-clusters occur along the aggregation dimension of the granularity hierarchy. the kcluster provides a mechanism for effectively grouping relevant predicates into relevance groups. 
     in figure 1 there are a number of k-clusters  indicated by the arc connecting sub-aggregate descendants beneath a node. observers in the figure are denoted as circles rather than boxes. for example  the object  recursive cdr reduction case  has two k-clusters  one consisting of the two sub-aggregate objects  some test  default   and  recursive cdr-reduction action  as well as the observation  test-action pair   and the other consisting of the two subaggregate objects  recursive cdr-reduction test  and  some action  as well as the observation  test-action pair . each of these k-clusters represents a different way in which a recursive cdr reduction case could be framed in lisp  and hence define alternative groups of relevant  predicates  which must be  true  for the object  recursive cdr reduction case  to be distinguished. the truth or falsity of such predicate groups is determined by a gestalt function described below.   simplification and articulation: simplification in granularity hierarchies is accomplished by a focus shift from a particular level of granularity to a coarser grain size. a simplification operator  similar to hobbs' k mapping  is required to guide these focus shifts. in the abstraction dimension  simplification amounts to traversing an abstraction relation  which implicitly alters the sets of distinguishable and indistinguishable objects. 
     in the aggregation dimension  the presence of kclusters impacts the simplification process. each object that could be a candidate for aggregation simplification  objects that are not maximal aggregations  is by definition a member of one or more k-clustcrs. associated with each kcluster is a function  called a gestalt function  which arbitrates the simplification and articulation of k-clusters. the gestalt function is essentially a local interpreter for the 
k-cluster which determines whether the objects  parts and observations  in the k-cluster are put together correctly. for example  in figure 1  the gestalt function associated with the k-cluster of parts of the  cdr recursion  object will make sure that the null base case and recursive cdr reduction case are in fact embedded in the observed cond function in an appropriate manner  i.e. the null case must precede the reduction case in the cond  before it will allow the  cdr recursion  object to be distinguished. the gestalt function has proven to be particularly useful for guiding aggregation focus shifts when granularity hierarchies are employed for recognition  as described in section 1 . 
     articulation is accomplished by a focus shift from one level of abstraction granularity to a finer grain size. this type of focus shift is the inverse of simplification  but has quite different semantics when applied to recognition tasks. again the gestalt function is employed to arbitrate articulation between an object and one of its parts in a k-cluster. 
  idealization: the need to impose fine-grained distinctions or boundaries between coarser-grained objects poses a difficult problem  only partially resolved in our framework. in contrast to hobbs' framework where predicates relevant to coarser-grained objects are themselves necessarily coarser-grained  we permit but do not impose such restrictions. for example  in figure 1   null base case  
 one of the relevant objects necessary to distinguish  cdr recursion   could have specializations or generalizations at finer or coarser levels of abstraction. these specializations or generalizations could  in turn  be objects relevant to distinguishing descendants or ancestors of  cdr recursion  in the principal hierarchy. however  such correspondences do not need to exist. this allows us to incorporate specialized relevant predicates at any level of abstraction and solves the fine-grained boundary problem in a manner similar to hobbs' idealization approach. 1 intelligent tutoring systems 
     on the other hand  this solution prevents the delineation of planes across the hierarchy at a particular level of abstraction  except in the special case where a complete lattice is defined by abstraction relations on aggregate parts . such planes would roughly form a complete theory of the world at some abstraction grain size. in the recognition system that we have built using this theoretical framework  there has been no need for such a complete theory of the world at a level of abstraction  and in fact there are advantages to being able to connect objects to each other without regard for maintaining such planes  for example we have been able to avoid the need for plane-preserving intermediate dummy nodes required in mulder's scene recognition vision system  mulder  1  . 
1 using granularity in lisp program strategy recognition 
     our main interest in using granularity has been to recognize the strategics novice students employ when they solve simple recursive lisp programming problems. this work has been carried on in the context of the scent project  mccalla and greer  1   which is investigating issues in the construction of an intelligent tutoring system that dispenses advice to students as they learn to program in lisp. using granularity  we are able to recognize student programming strategies at various levels of detail  which can be useful pedagogically and can enhance the robustness of the diagnostic system by allowing at least coarse grained recognition of bizarre student solutions. in fact  in the granularity hierarchy that we have implemented for lisp programming  strategy recognition at some grain size is guaranteed  albeit sometimes at only a coarse grain size. 
     to give a flavour for how the granularity-based recognition system works  consider the following simple lisp program  which a student might submit as his or her solution to the findb problem  the findb problem is to return t if the atom b exists at the top-level of a list  and to return nil otherwise : 
 defun findb  lst  
 cond   null lst  nil  
  atom 'b  t  
 t  cons nil  findb  cdr lst       
this is a flawed solution  in that the task-specific test 
  atom 'b   does not check for a b in the list  and there is no need for the  cons  composition after the recursive call. most program recognition systems would find such a perturbed solution hard to deal with unless these particular perturbations had been explicitly anticipated. in our granularity-based approach  this program could at least be recognized as  cdr recursion   see figure 1 . 
     in order to be a cdr recursion  a program must have a null base case  a recursive cdr reduction case  and these must be put together in a well-formed conditional. a null base case  in turn  must have a null base test and some base action  both put together as a test-action pair. observers looking at the findb solution above would find that   null lst   is a satisfactory null base test  that  nil  is a suitable base action  and that the two are formed as a test-action pair. thus  this program has a null base case. does it have a 

recursive cdr reduction case  there are two ways of having a recursive cdr reduction case  as shown by the two k-clusters in figure 1. the relevant k-cluster here is the one requiring some test  possibly a default  and a recursive cdr reduction action combined as a test-action pair. the student's use of  t  in the third clause of the cond can be recognized as a default test  but recognizing a recursive cdr reduction action involves a further aggregation articulation requiring a cdr reduction and a recursive call  properly composed. observers can recognize   cdr lst   as a cdr reduction  the call to  findb  as a recursive call  and that these are composed properly  i.e. that the reduction is in the argument to the recursive call . thus  a recursive cdr reduction action can be recognized. it remains only to observe that the default test  t  and this recursive cdr reduction action form a test-action pair  which means that a recursive cdr reduction case is recognized. the recognition of both the null base case and the recursive cdr reduction case  combined with the observation that the cond is well-formed  means that a cdr reduction has occurred. since  cdr reduction  is an object in the principal hierarchy  further aggregation simplification cannot occur. despite its perturbations  the student's program has been definitely recognized as a cdr recursion. 
     the recognition process proceeds as recognition of  cdr recursion  automatically propagates upwards through levels of abstraction simplification  allowing  recursion    function definition   and  lisp program  all to be recognized as well  see figure 1 . in fact  once an object has been recognized at any level of aggregation  recognition propagates upwards through its abstraction ancestors  a fact which often allows rapid recognition of coarser grained sub-aggregate objects without needing to articulate all of their component parts. using this information  the scent system knows what the student is doing at any of 1 levels of abstraction granularity  as well as being able to understand more precisely the various parts of the student's program that have been recognized in the aggregation dimension. this can be useful for updating the student model  and for framing the discussion with the student by focussing on the parts of the program that are correct and well understood. 
this degree of recognition is insufficient  however. 
pedagogically  it is the unrecognized parts of the student's program which usually form the basis for tutoring. the granularity-based recognition system is also quite useful in this regard. in the attempt to recognize the student's program  various objects elsewhere in the granularity hierarchy may have been recognized. these can include subaggregate objects of finer grained objects in the principal abstraction hierarchy. in particular  objects like  cdr tailend recursion    cdr tail-end predicate   and  findb preferred solution  may all have some of their subaggregates recognized  while obviously not being able to recognize a complete k-clustcr of objects. for example   findb preferred solution   which is the finest grained object along the abstraction dimension  would be satisfied with the null base test  but would not accept the task-specific test  should be   eq car lst 'b     nor would it be satisfied with the existence of a composition step. these unfelicitous parts could form the basis for tutoring  or at least for inquiries of the student or the student model as to problemsolving intentions. thus  the two kinds of recognition  complete coarse grained recognition and finer grained partial recognition  provide the rest of the tutoring system with different sorts of relevant information for student modelling and pedagogical decision making. 
     the approach to granularity-based recognition discussed here has points of similarity to several other major research projects. in the domain of intelligent tutoring  the proust system  johnson and soloway  1  recognizes student programs at three levels: problem  goal  and plan. our strategies are most like proust's plans  but unlike proust  we do not attempt to induce a student's goals in choosing a particular strategy  this is a role envisaged in scent for the student modelling component   nor do we formalize the problem description  although our work is currently progressing in this area . instead  our approach has concentrated on strategy  plan  diagnosis  and in that regard goes considerably beyond proust in the formalization and use of granularity  in the delineation of both an aggregation and abstraction dimension to strategy recognition  in robustness  and in breadth and depth of strategies dealt with. 
knowledge-based vision systems  such as the various 
mapsee systems  mackworth and havens  1  mulder  
1  and alven and caa  tsostsos and shibahara  
1   have strong points of similarity with our approach to recognition as well. these systems  which use hierarchies of visual knowledge to guide recognition of scenes  bear similarity in organization of knowledge into aggregation and abstraction hierarchies to guide recognition. there are  of course  obvious differences in domain: the mapsee systems recognize an idealized sketch map  alven looks at medical images  and caa analyzes electrocardiograms. none of these systems explicitly formulate recognition in terms of granularity  nor are they satisfied  in general  with only achieving coarse-grained recognition. the usefulness in an education domain of coarse grained recognition and partial fine grained recognition does not carry over very well to scene analysis. there arc also many technical differences between our approach and the knowledge-based vision approaches. nevertheless  the important point is that the knowledge-based vision systems provide further evidence that the approach taken here may be widely applicable beyond program strategy recognition. 
1 	conclusion 
     much work has gone into the creation of a granularitybased recognition system for lisp strategies  and this work continues. one line of development has been to investigate various kinds of control paradigms. we have experimented with top-down  bottom-up  and task-dependent control schemes  and work by barrie  has investigated how to use so-called  strong  and  weak  recognizers to help direct the search through the granularity hierarchy. in fact  barrie's initial work some years ago on strategy recognition launched our investigations into the use of granularity in recognition. another line of development  explored by pospisil   has been to incorporate buggy strategies into the hierarchy  which if recognized allow a definitive diagnosis of the student's misconceptions  and provide even more concrete information for the student modelling and pedagogic components of scent. a third direction of current 

investigations has been the knowledge engineering of a large system in order to rigorously test this approach to recognition  to prove out its usefulness in a real domain  and to find limitations and/or to explore possible enhancements to the approach. the design of the strategy objects in this large system is based on a repository of actual solutions to several lisp problems collected from some 1 novice lisp programmers  sec  escott and mccalla  1  for an analysis of this data . we currently have implemented some 1 objects connected together at ten levels of abstraction granularity and averaging approximately four levels of aggregation granularity. these objects allow the recognition of a wide variety of the basic recursive strategies used by lisp programmers. we are enhancing the coverage of the hierarchy by adding more strategy objects and by integrating into the system knowledge-based program transformations in order to reduce the observers' dependency on exact code matches  huang and mccalla  1 . we are currently attempting to reduce the need to store explicit task-dependent strategies at the finer levels of abstraction granularity and instead to generate these task-dependent strategies from the problem description as new tasks arc created for students to solve. finally  we would like to find other domains where granularity-based recognition would be useful; some possibilities which we have considered include recognizing strategies used in software testing and debugging  and recognizing strategics employed by chess players. 
     much work has gone into the formalization of granularity as well. we have been able to describe granularity in precise computational terms  have characterized two kinds of granularity  and have shown how this approach to granularity relates to hobbs' properties of granularity  and in some ways refines and extends his ideas. we would like to explore our approach to granularity further  especially to define a notion of relative granularity between coarser and finer grained objects  to investigate how groups of objects at a similar relative grain size can be put together into a coherent  theory  of the world at a particular grain size  and to look at the implications of these variously grain-sized theories for representation and reasoning. another interesting avenue to explore is the delineation of other kinds of granularity besides aggregation and abstraction. in particular  the human ability to carry out goals and sub-goals may suggest the existence of a dimension of granularity involving focus shifts between levels of goals. perhaps other such dimensions exist as well. we believe that explicitly investigating granularity will prove to be useful for artificial intelligence  both theoretically and practically  and we are optimistic about our ongoing research into the formalization and use of granularity. 
acknowledgements 
we would like to thank bryce barrie and paul pospisil for helping recognize the need for granularity-based representations. we would also like to thank dan baril  shawkat bhuiyan  xueming huang  and mary mark for their help in current investigations into granularity. the financial support of the natural sciences and engineering research council of canada is gratefully acknowledged. 
1 	intelligent tutoring systems 
