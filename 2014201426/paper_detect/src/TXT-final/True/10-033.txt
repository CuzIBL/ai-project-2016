 predicate calculus necessarily leads to inefficient reasoning and information retrieval programs. i believe that this is an overthis paper discusses the problems of representing and reaction to earlier attempts to build domain-independent theorem reasoning with information about knowledge and action. the provers based on resolution. more recent research  including my first section discusses the importance of having systems that own m.s. thesis  moore  1   suggests that predicate calculus can understand the concept of knowledge  and how knowledge is be treated in a more natural manner than resolution and related to action. section 1 points out some of the special problems combined with domain-dependent control information for greater that are involved in reasoning about knowledge  and section s efficiency. furthermore  the problems of reasoning about presents a logic of knowledge based on the idea of possible worlds. knowledge seem to require the full ability to handle quantifiers section 1 integrates this with a logic of actions and gives an and logical connectives which only predicate calculus posseses. 
example of reasoning in the combined system. section 1 makes 
some concluding comments. section 1 of this paper attempts to bring out some of the special problems involved in reasoning about knowledge. section 
                                       1 presents a formalism which i believe solves these problems  and 1. introduction section 1 integrates this with a formalism for actions. section 1 makes some concluding comments. 
   one of the most important concepts an intelligent system needs to understand is the concept of knowledge. ai systems need to 
understand what knowledge they and the systems or people they 1. problems in reasoning about knowledge interact with have  what knowledge is needed to achieve particular goals  and how that knowledge can be obtained. this reasoning about knowledge presents special difficulties. it paper develops a formalism that provides a framework for stating turns out that we cannot treat know  as just another relation. if and solving problems like these. for example  suppose that there we can represent  block 1 is on block1  by 1n blockl block1   we is a safe that john wants to open. the common sense inferences might be tempted to represent  john knows that p  simply by that we would like to make might include: know john p . this approach glosses over a number of problems. 
we might be suspicious from the first  since p is not the name of 
if john knows the combination  he can immediately open an object but is rather a sentence  or proposition . the semantics the safe. of predicate calculus forbid the arbitrary intermingling of 
                                                           sentences and terms for good reason. for one thing  the second if john does not know the combination  he cannot argument position of know is a referentially opaque context. 
	immediately open the safe. 	ordinarily in logic we can freely substitute an expression for one 
that is extensionally equivalent  i.e.  one that has the same referent 
if john knows where the combination is written  he can or truth value   without affecting the truth of the formula that read the combination and then open the safe. contains the expression. this is called referential transparency. for example  if x   y = 1 and x = 1  then 1   y = 1. this pattern 
　　in thinking about this example  consider how intimately the of reasoning is not valid with know. we cannot infer from concept of knowledge is tied up with action. reasoning about know john  x   y ＊ 1   and x   1 that know john  1   y ＊ 1   is true  knowledge alone is of limited value. we may want to conclude since john might not know the value of x. 
from the fact that john knows a and b that he must also know c 
and d  but the real importance of such information is usually that one possible solution to this problem is to make the second it tells us something about what john can do or is likely to do. a argument of know the name of a formula rather than the formula major goal of my research has been to work out some of the itself. this is essentially the same idea as goedel numbering  interactions of knowing and doing. although it is not necessary to use such an obscure encoding as the natural numbers. we won't specify exactly how the encoding 
   that this area has received little attention in ai is somewhat is done  but simply use  p  to represent a term denoting the surprising. it is frequently stated that good interactive ai formula p. the representation of  john knows that p  now programs will require good models of the people they are becomes know john. p＜ . we are no longer in any danger of m
communicating with. surely  one of the most important aspects of infering know john  p a    from know john  p bd and a - b   m a model of another person is a model of what he knows. the because a is not contained in p a   only the name of a  i.e. only serious work on these problems in ai which i am aware of is  a   is contained  and since  a  does not equal  b   there is no a brief disscussion in mccarthy and hayes  1   and some more problem. 
recent unpublished writings of mccarthy. in philosophy there is a substantial literature on the logic of knowledge and belief. a there is  however  a more serious problem  the fact that 
good introduction to this is hintikka  1  and papers by quine  people can reason with their knowledge. we would expect a kaplan  and hintikka in linsky  1 . many of the ideas i will reasoning system to have built into it the ability to conclude b 
use come from these papers. from a and a =  b but if we treat know as just an ordinary predicate  we will have no reason to suppose that know john  a   
　　in representing facts about knowledge and actions  i will use and know john  a b   might suggest knowuohn.-b  . this first-order predicate calculus  a practice which is currently problem is emphasised by the fact that there is no formal unfashionable. it seems to be widely believed that use of connection between a formula and its name. the fact that we 
knowledge repr.-1: moore 
1 

regard  p  as the name of p is entirely outside the system. to get around this  it is necessary to re-axiomatize the rules of logic within the system  e.g. va p q know a/'p * q   a know a  p   d know a v  . but if we hope to do automated reasoning  this amounts to re-programming the deductive system in first-order logic  and using the top-level inference routines as the interpreter. when we consider the complexities of quantification and matching  it seems likely that this would be an inefficient process. 
　　a different idea which initially seems very appealing is to use the multiple data-base capabilities of advanced ai languages to set up a separate data base for each person whose knowledge we have some information about. we then can record what we know about his knowledge in that data base  and simulate his reasoning by running our standard inference routines in that data base. this idea seems to have wide currency in ai circles  and i advocated it myself in an earlier paper  moore  1 . 
　　unfortunately  it doesn't work very well. it can handle simple statements of the form  john knows that p   but more complicated expressions cause trouble. consider  john knows that p or john knows that q.  we can't represent this by simply adding 'p or q   to the data base representing john's knowledge  because this would mean  john knows that p or q     something quite different. we could try setting up two data bases  db1 and db1  add  p  to one and  q  to the other  and then assert in the main data base  db1 represents john's knowledge  or db1 represents john's knowledge.  however  if we also wanted to assert  john knows that c  or john knows that d  or john knows that e   we would need six data bases to represent all the possibilites for john's knowledge - one for each of the combinations  a  and  c   
 b  and   c   a  and  d   etc. as we add more disjunctive assertions  we get a combinatorial explosion in the number of data bases. 
　　we also have a problem in representing  john doesn't know that p.  we can't add  not p  to john's data base  because this would be asserting  john knows that not p   and simply omitting  p  from john's data base means that we don't know whether john knows that p. so it seems that what john doesn't know has to be kept separate from what he does know. but there are inferences that require looking at both. for example  if we have  john doesn't know that p   and  john knows that q  implies p   we might want to conclude that  john doesn't know that q   is probably true. this is representative of a class of inferences that the data base approach doesn't capture. there seems to be a fundamental problem in saying things about a person's knowledge that go beyond simply enumerating what he knows. 
1. reasoning about knowledge via possible worlds 
　　while there may be ways to directly attack the difficulties we have been discussing  there is a way to avoid them entirety by reformulating the problem in terms of possible worlds. when we want to reason about someone's knowledge  rather than talking about what facts he knows  we will talk about which of the various possible worlds might be  so far as he knows  the real world. a person is never completely sure which possible world  or possible state of the world  he is in  because his knowledge is incomplete. we will be willing to conclude that a person knows a particular fact  if the fact is true in all the worlds that are possible according to what he knows. this idea is due to hintikka  1   and is an adaptation of the semantics for modal logic developed chiefly by kripke  1 . 
　　hintikka uses these ideas about possible worlds to provide a model theory for a modal logic of knowledge. in order to use this theory directly for reasoning  we will axiomatize it in first-order logic. to do this  we must encode a language that talks about knowing facts  which we will call the object language  into term expressions of a first-order language that talks about possible worlds  which we will call the meta-language . then we will have a relation t  such that t w p  means the object-language formula denoted by p is true in the possible world denoted by w. so that we can talk more easily about truth in the actual world  we will have a predicate true  such that trut p  ＊ t w1 p   where wo is a constant which refers to the actual world. we will also have a 
　　relation k a w1 w1   which means that w1 is a world which is possible according to what a knows in wi. the fundamental axiom of knowledge is then vwl a p t wl know a p  ＊ 
vw1 k a wl w1  =  t w1 p  . this simply says that a person knows the facts that are true in every world that is possible according to what he knows. 
one problem with this axiom is that it is not universally true. 
for a perton to know everything that is true in all worlds which are possible as far as he knows  he would have to know all the logical consequences of his knowledge. of course  he can know only some of them. but in any particular case  if we can see that a certain conclusion follows from someone's knowledge  we are probably justified in assuming that he can see this also. so we can regard this axiom as a rule of plausible inference  using it when needed  but being prepared to retract our conclusions if they generate contradictions. i will not attempt here to devlop a general theory of plausible reasoning  but i believe that a theory can be worked out that will allow us to use this axiom in essentially its current form. 
　　i should clarify what type of possible worlds i have in mind. rather than all logically possible worlds  we will consider only those worlds which are possible according to  common knowledge . so  i will feel free to say that facts like  fish live in water   are true in all possible worlds. this gives us an easy way of saying that not only does everyone know something  but everyone knows that everyone knows it  and everyone knows that everyone knows that everyone knows  etc. 
　　we can now give the full axiomatization of knowledge in terms of possible worlds: 
ll.tru  pl  t wo pl  
l1. t wlf pl and p1   ＊  t wl pl  a t wl p1   
l1. t wl  pl or p1   ＊  t wl pl  v t wl p1   
l1. t wl  pl -  p1   ＊  t wl pl  = t wl p1   
l1. t wl  pl     p1   ＊  t wl pl  ＊ t wl p1   l1. t wl not pl   -t wl pl  
kl. t wltknow alfpl     vw1 k al wl w1  * t w1 pl   
k1. k il wl wi  
k1.  al wl w1  =   k al w1 w1  =  k al wl w1   
k1. k il wl w1  =   k al wl w1  =  k al w1 w1   
　　axioms li - l1 just translate the logical connectives from the object language to the meta-language  using the ordinary tarski definition of truth. for instance  according to l1   a and b  is true in a world if and only if a is true in the world and b is true in the world. kl is the fundamental axiom of knowledge which we already looked at. k1 says that each world is possible as far as anyone in that world can tell  which is another way of saying that if something is known then it is true. although it may not be obvious  k1 and k1 imply that everyone knows whether he knows a certain fact. k1 - k1 imply that for fixed a  k a wl w1  is an equivalence relation. this makes our logic of knowledge isomorphic to the modal logic s1. the correspondence between various modal logics and and possible-worlds models for them is discussed in kripke 1 . 
	this representation gives us what we need. 	the meta-

knowlf h*:e r e n r . - 1 : moore 1u 

language translations of the object-language statements have a structure that reflects their logical properties. to illustrate the use of these axioms  we can prove that people can do simple inferences: 
given true know a p  and know a  p ＊  q    

　　proofs in this paper use natural deduction. the right hand column gives the axioms and preceding lines which justify each step. indented sections are subordinate proofs  and ass marks the assumptions on which these subordinate proofs are based. dis indicates the discharge of an assumption. 
　　this proof is completely straight-forward. lines 1 - 1 simply expand the given facts into possible-worlds notation. then we pick wl as a typical world which is possible according to what a knows. in lines 1 - 1  we do the inference that we want to attribute to a. since this inference can be done in an abitrarily chosen member of the set of worlds which are possible for a  it must be valid in all of them  line 1 . from this we conclude that a can probably do the inference also  lines 1 - 1 . 
so far 1 have avoided dealing with the problem of quantifiers. 
exactly what do expressions like 1x know a p x   . mean  this is not a simple assertion that someone knows a certain fact  so its intuitive meaning may not be clear. the best paraphrase seems to be  there is something that a knows has property p.  it is a matter of great dispute in philosophy exactly how to handle this. i will take a pragmatic approach. to say that a person knows of something that it has property p means that he can name something that has property p. furthermore  just any sort of name won't do.  the thing that has property p is no good  for instance. we will say that a must know the standard name of the thing that has p. this is  of course  a simplification. not all things have standard names  and some things have different standard names in different contexts  but we will ignore these difficulties to preserve the simplicity of the ordinary case. 
abstract entities usually have unproblematical standard names  1  is the standard name of 1   1   1  is not. 
   turning to the model theory  the interpretation of the formula we are considering would be that there is something that is p in all worlds compatible with what a knows. that means that standard names must refer to the same thing in all possible worlds. there is a term for this in philosophy  rigid designator. we can greatly simplify our formalism if we require that all ordinary terms in the object language be rigid designators. we would then have to have a special notation for non-rigid designators  but this will not come up in our examples  so i will not develop that idea here. we can now give the axioms for quantifiers and equality: 

l1 and l1 are axiom schemas relative to p and x  and vl is a met a-language variable that ranges over object-language variables. means the result of substituting x for vl in p. 
　　these three axioms may seem somewhat peculiar in that they appear to say that individuals in the world can be part of objectlanguage expressions. in l1 and l1  we took x  a variable ranging over real objects  and inserted it into p  the name of a sentence  implying that objects can be contained in sentences. to preserve the simplicity of the notation  without this apparent absurdity  we will make the interpretation that all functions which represent atomic predicates in the object language  e.g. eq  take individuals as arguments and return expressions containing the standard names of those individuals. 
1. integrating knowledge and action 
　　in order to integrate knowledge with actions  we need to formalize a logic of actions in terms comparable to our logic of knowledge. happily  the standard al way of looking at actions does just that. most ai programs that reason about actions view the world as a set of possible situations  and each action determines a binary relation on situations  one situation being the outcome of performing the action in the other situation. we will integrate knowledge and action by identifying the possible worlds in our logic of knowledge with the possible situations in our logic of actions. 
　　first  we need to define our formalism for actions exactly parallel to our formalism for knowledge. we will have an objectlanguage relation res e p  which says that it is possible for event e to occur  and p would be true in the resulting situation. in the meta-language  we will have the corresponding relation r e w1 w1  which says that w1 is a possible situation/world which could result from event e happening in wl. these two concepts are related in the following way: 

　　the existential clause on the right side of rl says that it is possible for the event to occur  and the universal clause says that in every possible outcome the condition of interest is true. there is a direct parallel here with concepts of program correctness  the first clause expressing termination  and the second  partial correctness. 
　　we can extend the parallel with programming-language semantics to the structure of actions. we will have a type of event which is an actor performing an action  do a c .  c stands for  command .  actions can be built up from simpler actions using loops  conditionals  and sequences: 


　　r1 defines the step-by step expansion of while-loops: if the test is true  execute the body and repeat the loop  else do nothing. to prove general results we would need some sort of induction axiom. r1 defines the execution of a conditional action. notice that being able to execute a conditional requires knowing whether the test condition is true. this differs from ordinary program conditionals  where the test condition is either assumed to be a decidable primitive  or is itself a piece of code to be executed. r1 says that the result of carrying out a sequence of actions is the result of executing the first action  and then executing the rest. ni simply defines the no-op action we need for the definition of loop. 
　　one of the most important problems we want to look at is how knowledge affects the ability to achieve a goal. part of the answer is given in the definition of the notion can. we will say that a person can bring about a condition if and only if there is an action which he knows will achieve the condition: 
　　dl says that an actor can perform a dialing action if the thing he is dialing is a combination  the thing he is dialing it on is a safe  and he is at the same place as the safe. d1 tells how dialing a combination affects whether the safe is open: if the combination is the combination of the safe  then the safe will be open; if it is not the combination of the safe and the safe was locked  the safe stays locked; if the safe was already open  it stays open. 
　　d1 describes how dialing affects the knowledge of the dialer. roughly it says that the actor knows he has done the dialing  and he now knows whether the safe is open. more precisely  it says that the worlds that are now possible as far as he knows are exactly those which are the result of doing the action in some previously possible world and in which the information acquired matches the actual world. notice that by making the consequent of d1 a biconditional  we have said that the actor has not acquired any other information by doing the action. also notice that d1 is more subtle than just saying that whatever he knew before he knows now. this is not strictly true. he might have known before that the safe was locked  and now know that the safe is open. according to d1  if the actor knew before the action  p is true   after the action he knows  p was true before i did this action.  
　　having presented the basic formalism  i would now like to work out a simple example to illustrate its use. simply stated  what i will show is that if a person knows the combination of a safe  and he is where the safe is  he can open the safe. besides the axioms for dili  we will need two more domain-specific axioms: 

a 1 says that if one thing is the combination of another  the first thing is a combination and the second thing is a safe. a1 says that a person knows what is around him. the proof is as follows: 
giv*n: true at john sf   
　　the proof is actually simpler than it may look the real work is done in the ten steps between 1 and 1; the other steps are the overhead involved in translating between the object language and the meta language. notice that we did not have to say explictly that someone needs to know the combination in order to open a safe. instead we said something more general  that it is necessary to know a procedure in order to do anything. in this case  the combination is part of that procedure. it may also be interesting to point out what would have happened if we had said only that john knew the safe had a combination  but not that he knew what it was. if we had done that  the existential quantifier in the second assertion would have been inside the scope of know. then the skolem constant c would have depended on the variable wl  and the step from 1 to 1 would have failed. 
1- conclusions 
　　in summary  the possible-worlds approach seems to have two major advantages as a tool for reasoning about knowledge. first  

knowlphjre 	repr  ＊1: 	moore 1 

it allows  lifting  reasoning in knowledge contexts into the basic deductive system  eliminating the need for separate axioms or rules of inference for these contexts. second  it permits a very elegant integration of the logic of knowledge with the logic of actions. 
　　this approach seems to work very well as far as we have taken it  but there are some major issues we have not discussed. i have said nothing so far about procedures for reasoning automatically about knowledge. i have some results in this area which appear very promising  but they are too fragmentary for inclusion here. i have also avoided bringing up the frame problem  by not looking at any sequences of action. i am also working in this area  and i consider it one of the largest iou's generated by this paper. however  the possible-worlds approach has an important advantage here. whatever method is used to handle the frame problem  whether procedural or axiomatic  knowledge contexts will be handled automatically  simply by applying the method uniformly to all possible worlds. this should eliminate any difficulties of representing what someone knows about the frame problem. 
1. references 
hintikka  j.  1  knowledge and belief. ithica  new york: cornell university press. 
hintikka  j.  1  semantics for propositional attitudes  in linsky  1   1. 
rripke  s.  1  semantical considerations on modal logic  in linsky  1   1. 
linsky  l.  ed.   1  reference and modality. london: oxford university press. 
mccarthy  j. and hayes  p. j.  1  some philosophical problems from the standpoint of artificial intelligence  in b. meltzer and d. michie  eds.  machine intelligence 1  1. edinburgh: edinburgh university press. 
moore  r. c 	 1  d-script: a computational theory of 
descriptions. advance papers of the third international joint conference on artificial intelligence  1. 
moore  r. c.  1  reasoning from incomplete knowledge in a procedural deduction system. mit artificial intelligence laboratory  al-tr-1. 
knowlphp;e r e p r . - 1 : moorp 
1 

a state logic for  the peppesentation op 
natural language 1ased intelligent systems 
c a m i l i a p . s c  i w i n d 
t c c h n i s c h c u n i v o r s i t*~it m 'inchen l u n i c h   fpg 
summary 
tho work described h e r e i n i n t r o d u c e s a general l o g i c based formalism f o r the a c t i ons of an i n t e l l i g e n t system understandinn n a t u r a l language sentences  executing comnands and answering q u e s t i o n s . 
     n a t u r a l language t r a n s l a t i o n 
	s t a t e 	l o g i c 	d e r i v a t i o n s 	l o g i c a l 
	formulae 	 =-====- 	axioms 
i n t e r p r e t a t i o n 
of 	the 	l o g i c 
c h a r n c t c r i -
	k r i p k e - t y p e 	z a t i o n 	n n n - l o g i c a l 
	mod 	e 	1 	:  	: 	ax i om s 
the h e a r t of t h i s formal system is a s t a te  or tense  i o n i c c o n t a i n i n g s p e c i a l 
o p e r a t o r s f o r immediately next and p r e c e ding s t a t e s  + --  as w e l l as f o r a l l f u t u r e s t a t e s  f  and a l l past s t a t e s  p  . 
natural language t e x t s are analysed synt a c t i c a l l y and transduced i n t o s t a t e l o g i c formulae by an a t t r i b u t e d grammar   i n the same way as described by sehwind . 
the s t a t e l o g i c is f o r m a l i z e d by a set of l o g i c a l axioms and d e r i v a t i o n r u l e s f o r 
which completeness has been proven. s i m i l a r systems have a l s o been mentioned by rescher. but in usual tense l o g i c systems  the s t r u c t u r e of tense has been studied o n l y a s t o i t s  pure l o g i c a l   p r o p e r t i e s . in i n t e l l i g e n t systems however  wo nood theorems about the n o n - l o g i c a l p r o p e r t i e s of s t a t e changes. the tense s t r u c t u r e of a world is determined by changes w i t h i n the world which a f f e c t the n o n - l o g i c a l symbols o f the w o r l d   i . e . the f u n c t i o n s o r p r e d i c a t e s : if a robot takes a block   a   l y i n g on a block   b     then t h i s causes a 
change of the world   i . e . a s t a t e t r a n s i t i o n   w i t h the meaning of the p r e d i c a t e symbol on changing. such n o n - l o g i c a l change d e s c r i p t i o n s are i n c o r p o r a t e d i n t o our formal system. a model f o r the s t a t e l o g i c is given by a set of c l a s s i c a l s t r u c t u r e s m and a b i n a r y r e l a t i o n p on m where s p s' means t h a t the s t a t e of the w o r l d s immediately precedes the s t a t e s 1 . t r u t h values are assigned to formulae depending on the s t a t e of the v/orld in which the formula is e v a l u a t e d . and the s t a t e o p e r a t o r s take i n t o account the t r u t h v a lue of a formula in some o t h e r s t a t e s 
which can be  reached  from the a c t u a l s t a t e . to r e p r e s e n t the knowledge i n c o r porated in an i n t e l l i g e n t system by such k r i p k c - t y p e models we assign a n o n - l o g i c a l 
i n t e r p r e t a t i o n t o s t a t e t r a n s i t i o n s . the 
very general model of k r i p k e - s t r u c t u r e s is used in such a way t h a t the r e l a t i o n p bears a n o n - l o g i c a l meaning. for two s t r u c t u r e s ao and a   s p s' holds i f f the ''v/orld  ＜ a   is obtained from the w o r l d a  as t h e ' r e s u l t of an a c t i o n which can be executed w i t h i n a . v1hat a c t i o n s can be executed w i t h i n a v/orld depend on the extensions of the n o n - l o g i c a l symbols. on n a t u r a l language l e v e l a c t i o n s are v e r b s . the e x e c u t i o n of an a c t i o n has consequences on the extensions of the nonl o g i c a l symbols of the v/orld  i . e . a s t r u c t u r e is s u b j e c t to some change whenever the a c t i o n described by the verb is executed in i t . if somebody takes a t h i n g the p o s i t i o n o f t h a t t h i n   changes  i . e . the e x t e n s i o n of the p r e d i c a t e symbols on  behind e t c . and the e x t e n s i o n of the verb p r e d i c a t e symbol hold changes  because the person holds the t h i n g now. there are a l so p r e c o n d i t i o n s f o r the e x e c u t i o n of an a c t i o n ;  a takes bl: is only p o s s i b l e if  a  does not yet hold anything and if   b   has a p o s i t i o n such t h at it can be ta :on  
i . e . 	t h e r e 	is n o t h i n g on   b   . 	we describe 
both 	the p r e c o n d i t i o n s 	and 	the consequences of an a c t i o n by n o n - l o g i c a l 	axioms. and 	the a p p r o p r i a t e 	s t r u c t u r e must have the 	p r o p e r t y 	t h a t 	i n whatever 	s t a t e 	a l l the c o n d i t i o n s of an 	a c t i o n hold 	t h e r e must be 	some 	f o l l o w i n g 	s t a t e 	in which i t s consequences 	are 	r e a l i z e d . 
example: 	a c t i o n verb 	  t a k e   p r e c o n d i t i o n 	axiom 	 pa  
take x y hano x  -mhing y-  1lu x z -   1 on z y t h i s means: x can t a k e y i f f x is a hand and y is a t h i n g and x does n o t h o l d any o t h e r o b j e c t and t h e r e i s n o t h i n g on y. 
e x e c u t i o n axiom 	 fa  
take x y-*g+l hot d x y a ~lon y z  t h i s means: if x t a k e s y then t h e r e is an i m m e d i a t e l y f o l l o w i n g s t a t e such t h a t x h o l d s y and y i s n o t l y i n g o n a n y t h i n g . we c o u l d o n l y d e s c r i b e a s m a l l p a r t of t h e p o s s i b i l i t i e s o f our f o r m a l i s m h e r e . wo a c t u a l l y d e v e l o p a p p l i c a t i o n examples o f v e r y d i f f e r e n t t y p e s : one f o r t h e anal y s i s o f t a l e s and one f o r t r a f f i c . 
p.hayes  a l o g i c of a c t i o n s . machine i n t e l l . 1. p p . 1 1 - 1 o . ed. b . m e l t z c r + d . m i c h i e . e d i n b . u n i v e r s . press  1  
m.minsky  a framework f o r p e p r e s e n t i n g knowledge. m . i . t . a . i . memo 1  1  n.peschcr + a . u r q u h a r t   temporal l o g i c . s p r i n g e r - v e r l a g   wien 1 
c.sehwind  g e n e r a t i n g h i e r a r c h i c a l semant i c networks from n a t u r a l language d i s c o u r s e . p r o c e e d   o f t h e i j c a i 1    1  t . w i n o g r a d   u n d e r s t a n d i n g n a t u r a l languag e . academic press  1  

knowlf h re 	r e p r . - 1 : 	sehwind 
1 

vocabularies for problem solver state descriptions 
drew mcdermott 
computer science department yale 	u n i v e r s i t y 
new haven  connecticut 1 
abstract : a model of knowledge representation is presented and applied to representing problem s o l v e r s ' s t a t e s . the focus is on the nasl problem s o l v e r   which has been used to study elementary c i r c u i t design. the model d i s t i n g u i s h e s 
between the form and the content   vocabulary   of a r e p r e s e n t a t i o n . the vocabularies used by the modules of nasl are d i s p l a y e d . it is concluded that the model allows f l e x i b l e implement a t i o n and clear d e s c r i p t i o n of problem s o l v e r s . in p a r t i c u l a r   it demonstrates the importance of shallow reasoning in the control of problem s o l v e r s . 
d e s c r i p t i v e terms: problem s o l v e r s   knowledge r e p r e s e n t a t i o n   computer-aided design  production systems  rule-based systems. 
acknowledgements: 1 thank gerald sussman for the word   v o c a b u l a r y     and many of the concepts behind i t . much of the work reported herein was conducted at the a r t i f i c i a l i n t e l l i g e n c e laborat o r y   a massachusetts i n s t i t u t e of technology research program supported in part by the advanced research projects agency of the department of defense  and monitored by the o f f i c e of naval research under contract number n1-c-1. 
	1 	i n t r o d u c t i o n 
       this paper is about the   r e p r e s e n t a t i o n of knowledge  in problem-solving systems. 1 focus on the r e p r e s e n t a t i o n of f a c t s about the state of the problem solver i t s e l f   rather than on i t s representations of the current problem s t a t e . the discussion uses as an example the nasl problem-solving system.  mcdermott  1  it is argued that the range of   r e p r e s e n t a t i o n a l voc a b u l a r i e s   determines the power of a problem s o l v e r . 
       every representational system has two aspects: form and content. i t s form determines what can be i n f e r r e d from what; i t s content determines how what is i n f e r r e d is used by the user of the r e p r e s e n t a t i o n a l system. in abstract form  such a system can be represented by f i g . 
1. 

figure 1 general representation system 
the data base is managed by a  gatekeeper.  add i t i o n s to the data base and requests to the gatekeeper from the user's programs are in terms of the u s e r ' s concerns. inside the data base  they are t r a n s l a t e d into p r o p e r t y - l i s t operat i o n s   p a t t e r n matching  network marking  or some other i n t e r n a l representation f o r i n f e r e n t i a l processing. 
       i d e a l l y   the formal conventions used inside the data base should be hidden from the user. there is a c e r t a i n l e v e l of r e p r e s e n t a t i o n a l 
       power and r e t r i e v a l e f f i c i e n c y that he can take f o r granted  moore  1   so that he w i l l be f r e e to think in problem-oriented terms. another way to put t h i s is that content must be allowed to be more important than form. 
       in t h i s model  content appears as the vocabulary the user's programs use in t a l k i n g to the gatekeeper. since ray focus in t h i s paper is on the vocabulary  l e t me expand f i g . 1 to i l l u s t r a t e some p o i n t s . 

figure 1 structure of user's programs 
the user's programs often come in  modules   each of which is the primary holder of a specialized vocabulary. for example  in the mycin system   s h o r t l i f f e   1; davis  1   there are two vocabularies: a system of medical terms and a  meta-vocabulary  used in c o n t r o l l i n g r u l e app l i c a t i o n . inside the data base  most of the r u l e s are in medical terms; the r u l e - a p p l i c a t i o n vocabulary is used by   m e t a - r u l c s .   
       an a l t e r n a t i v e way of approaching these issues would be to l e t each module have i t s own data base  gatekeeper  and formal conventions  not j u s t i t s own vocabulary. for example  in noah  sacerdoti  1   the procedural net is stored separately  as special-purpose l i s t s t r u c t u r e s   from the ql1sp data base used to represent the current problem model. the problem w i t h t h i s approach is that it makes the communic a t i o n channel between any two modules ad hoc and clumsy. in my model  the data base is the chann e l ; any two rules in the data base can i n t e r a c t   regardless of t h e i r o r i g i n or  p r i n c i p a l vocabulary. 
knowledge 	r e p r . - 1 : mcdermott 
1        a consequence of my model is that symbols used by user programs have two kinds of  meani n g   : t h e i r   i n f e r e n t i a l   meaning  determined s o l e l y by the behavior of the data-base expressions in which they appear  and t h e i r  pragmatic  meaning  which depends on the way in which they a l t e r the behavior of the user programs which employ them. further  a user module can use a symbol in two d i f f e r e n t ways: in expressions added to the data base to t r i g g e r inferences  thus  a s i t were  t e l l i n g i t s e l f what i t ' s doing   and in requests to the gatekeeper  which are often asking what to do next . clearly  the same symbol may be used in both these ways. 
ii the nasl problem solver 
       nasl is a problem-reduction problem solver which has been applied mainly to the problem of designing simple e l e c t r o n i c c i r c u i t s . 
 mcdermott  1  as w i l l be seen s h o r t l y   it is implemented as i n t e r l e a v e d planning and execution modules. the data base is managed by a planner-like   h e w i t t   1  p r e d i c a t e - c a l c u l u s theorem prover  about which i w i l l say no more here.  see mcdermott  1.  i t s  problem vocabulary  includes terms p e r t a i n i n g to devices  c i r c u i t s   s i g n a l s   and component values. what i w i l l describe are i t s   c o n t r o l v o c a b u l a r i e s .   
       a problem solver is a system which solves problems by reducing them to simpler subproblems  and u l t i m a t e l y to   p r i m i t i v e s   which can be solved by b u i l t - i n programs. a problem solver 
must maintain somewhere a data s t r u c t u r e r e p r e senting important features of i t s current s t a t e . usually t h i s data s t r u c t u r e is d i f f e r e n t from the data s t r u c t u r e representing the current problem s t a t e   or  world model.  nasl  however  f o l l o w s the s t r u c t u r e of figure 1  and maintains a l l i t s data s t r u c t u r e s in the same p r e d i c a t e - c a l c u l u s data base. 
	this means that the formal 	system 	used 	by 
nasl r e s t r i c t s as l i t t l e as possible the content and i n t e r a c t i o n of the problem-state and problem s o l v e r - s t a t e d e s c r i p t i o n s . in what f o l l o w s   i w i l l f i r s t describe the vocabularies used by nasl modules  then show rules which i l l u s t r a t e the i n t e r a c t i o n s of the concepts they d e f i n e . 
	nasl looks l i k e 	t h i s : 

these modules do not correspond one-to-one w i t h programs  but are only conceptual. in figure 1  an arrow from module a to module b means t h a t a  depends o n      precedes   or   c a l l s   b. the c e n t r a l cycle in the graph is intended to suggest that a problem  or   t a s k     is c r e a t e d   then scheduled  then executed  e i t h e r as a p r i m i t i v e a c t i o n or by being reduced to subtasks. 
       as w i l l be seen s h o r t l y   the n o t a t i o n s used by these modules r e s u l t in a task network being represented in the data base. 
       two of the modules in figure 1 are worthy of f u r t h e r d e s c r i p t i o n now. the task reducer t r i e s to r e t r i e v e exactly one   p l a n    set of subtasks  to carry out i t s task. this attempt can f a i l in two ways: e i t h e r too many plans  more than one  are r e t r i e v e d   or too few  none at a l l   . in the f i r s t case  the cholce module t r i e s to choose among them. in the second  the rephrasing module creates a new task which t r e a t s the r e c a l c i t r a n t task as an object to be transformed i n t o subtasks; t h a t i s   i t brings a l l the problem s o l v e r ' s resources to bear on i t . 
i i . a 	nasl's 	vocabularies 	and  	their 	pragmatic meanings 
task creation and classification- 
the basic predicate for describing tasks is 
 task name 
           -input-data-   action   -output-data-    which defines a task with a certain name  which carries out a certain action. tasks in nasl can deduce or create information  so there must be some mechanism for passing data from task to task. 

describes a task  coupler plan1  which couples two c i r c u i t s and calls the result  ckt1 . the action slot must be a function which gives an action given the input data.  angle brackets surround tuples;     indicates a variable.  
knowledge 	r e p r . - 1 : 	mcdermott 
1        i use the neutral word  task  to describe a problem to be worked on  because the concept is intended to be broad. most problem solvers res t r i c t themselves to actions which cause a  real or simulated  change in the state of the problem model. for example  in the blocks world  actions cause the positions of blocks to change. there are many actions which do not satisfy this d e f i n i t i o n   for example   think of someone who would be w i l l i n g to lend you $1 ; and  while moving block a  avoid disturbing the blocks on top of i t .   the f i r s t example differs from the paradigm in that it causes no change in the world  but only the retrieval of some information. the second is an example of an action   avoid...   which is executed solely as an influence on the execution of another action   move...  . another such  parasitic  action is  wait here five minutes.  
　　　these c l a s s i f i c a t i o n s are indicated by using the predicates 
              inferential task-name action  to i n d i c a t e an i n f o r m a t i o n - r e t r i e v a l task  and 
　　　　　　　　 policy task-name action  to i n d i c a t e a task which is p a r a s i t i c . 
task scheduling- 
       tasks are not executed as soon as they are created   u n l i k e the right-hand sides of productions  newell  1  . they may be postponed by r u l e s using the  scheduling vocabulary.  the basic predicate here is 
 successor task-1 task-1  
which means  roughly   task-1 must be executed or reduced before t a s k - 1 .   the scheduler examines successor formulas  then sets the. state of a task using the p r e d i c a t e - c a l c u l u s term 
	 task-status 	task  
which is successively asserted equal 	  i n the data base  	to pending  enabled  active  and finished. 
 the 	actual 	scheme 	is 	more 	complex. 	see 
mcdermott 	 1  	f o r d e t a i l s .   
task reduction- 
       even when a task is enabled  it cannot usua l l y be executed immediately. if i t s a c t i o n is not a p r i m i t i v e   i . e .   does not have a lisp f u n c t i o n to carry it o u t     it must be reduced to subtasks by the task reducer. such tasks arec a l l e d   p r o b l e m a t i c .   the reducer f i r s t c a l l s the theorem prover with a request of the form 
 to-do task a c t i o n output-data  plan  
to r e t r i e v e a p l a n . 	a plan is 	e i t h e r 	a 	s i n g l e a c t i o n   	or 	a plan schema   macro a c t i o n     which expands i n t o a set of 	subtasks. 	 for 	the 	det a i l s   	see. 	mcdermott  	1.  	either 	way  new tasks are created by the task reducer  	and  	f o r each one  a p r o p o s i t i o n of the form 
          subtask new-task problematic-task  i s recorded. 
　　　at any instant  the set of created tasks form a network defined by successor and subtask formulas. 
knowl e frp re 

figure k - task network midway through designing a h i - f i 
here the arrows i n d i c a t e successor formulas. a t r i a n g l e p o i n t i n g from low nodes to high i n d i cates subtask formulas; i . e .   the low nodes are the sub tasks of the high one. 
p r i m i t i v e 	actions- 
       there are only a few p r i m i t i v e actions in the system. when the user is specifying a new domain  he uses the predicate 
 mod-manip task-name action d e l e t e - l i s t a d d - l i s t   
to define new   p r i m i t i v e   a c t i o n s .  cf. fikes and n i l s s o n   1  for example  to define the e f f e c t of puton in the blocks w o r l d   one would 
w r i t e 

the b u i l t - i n p r i m i t i v e s include 
  infer - f o r i n f e r r i n g a new f a c t 
  find - p r i m i t i v e information r e t r i e v e r 
  no-op - used for r e l a b e l i n g calculated data 
  monitor - a p r i m i t i v e p o l i c y  used for implementing things l i k e p r e r e q u i s i t e p r o t e c t i o n  sussman  1   to create an   i n t e r r u p t   task when i t s monitored datum is erased. 
choice and rephrasing- 
       f i n a l l y   there are the vocabularies belonging to the choice and rephrasing modules. the rephraser does not have a very r i c h vocabul a r y   a lack which r e f l e c t s the shallowness of my t h e o r i e s regarding i t . rephrasing c u r r e n t l y consists of c r e a t i n g a task with a c t i o n 
 rephrase r e c a l c i t r a n t - t a s k a c t i o n   . 
this f a l l s in the category of   t e l l i n g yourself what you are d o i n g .   if the u s e r ' s domains p e c i f i c information does not include a plan f o r 
1: 	mchprmott 

rephrasing tasks of t h i s s o r t   the system w i l l produce a task w i t h a c t i o n  rephrase . . .  rephrase . . .       f o r which there is a b u i l t - i n plan to stop and ask f o r h e l p . 
	the choice vocabulary 	is 	s l i g h t l y 	r i c h e r . 
rather 	than merely set up a  choice maker  task  
nasl enters a special choice p r o t o c o l . in t h i s s p e c i a l module  the options  the set of competing plans  are set up by being mentioned in formulas of the form 
 option choice-name option-name o p t i o n - d e s c r i p t i o n   
then a series of requests is made to the i n f o r mation r e t r i e v e r . each is of one of these forms: 
 rule-out option-name  
 rule-in option-name  
 rule-together   - o p t i o n s -   new-option  
retrieved formulas i n s t r u c t the choice protocol to eliminate o p t i o n s   favor o p t i o n s   or compose options   i n domain-specific ways . the cycle continues u n t i l only one o p t i o n remains  or a l l options have been ruled out  or no progress has been made on the l a s t loop. for example  the c i r c u i t - d e s i g n knowledge has r u l e s which suggest how to decide between a l t e r n a t i v e a m p l i f i e r c i r c u i t s   and when to t r y cascading them. 
i i * b i n f e r e n t i a l meanings of  vocabularies 
       the preceding survey of module vocabularies may be thought of as an informal d e s c r i p t i o n of the pragmatic component of t h e i r meanings - how they are used by the modules. the richness of the system derives from the   i n f e r e n t i a l   meanings of the same symbols  determined by t h e i r i n t e r a c t i o n s on the other side of the gatekeeper  t h a t i s   by the i n t e r a c t i o n s of the r u l e s cont a i n i n g them. these i n t e r a c t i o n s are the medium of communication between modules. 
       an act of communication occurs when one module adds an expression to the data base from which an expression of i n t e r e s t to another module may be i n f e r r e d . for example  one r u l e used by the designer is 

which defines the e f f e c t of the p a r a s i t i c 	a c t i o n constrain 	as 	i n f l u e n c i n g the execution of make. 
it suggests 	make'ing 	an 	op-amp 	as 	a 	way 	of 
  s o l v i n g    make amplifier  in the case where the a m p l i f i e r ' s v o l t a g e gain is constrained to be h i g h . 
        before going on  i should p o i n t out that not a l l rules r e l a t e two or more module vocabul a r i e s . most to-do r u l e s are   p l a n c o n t e x t   i n dependent. since in t h i s paper i am emphasizing problem-solver state d e s c r i p t i o n   i w i l l ignore the problem of domain-dependent vocabularies and t h e i r i n t e r a c t i o n s .   
       the most common classes of i n t e r a c t i o n s which 1 have observed are these: 
        1  task  successor: tasks which can i n t e r f e r e with each other must t r i g g e r r u l e s to schedule them p r o p e r l y . for example  in e l e c t r o n i c s   there are rules to the e f f e c t that 
        any component-value s e l e c t i o n subtask of a design task must f o l l o w every t o p o l o g y - a l t e r i n g subtask.  
 the f u l l r u l e   c a l l e d select-postpone  may be found in mcdermott  1 . many of the   c r i t i c s   of s a c e r d o t i ' s  1  noah may be thought of as b u i l t - i n r u l e s o f t h i s k i n d . 
        1  policy to-do: p o l i c i e s are defined as   p a r a s i t i c   actions which i n f l u e n c e other act i o n s . one way t h i s happens is by deduction of to-do formulas. 1 gave an example of t h i s above. 
        1  policy  choice r u l e : another common way to define p o l i c i e s ' e f f e c t s is in terms of t h e i r influence on the operation of the choice p r o t o c o l used to pick among plans. for example  one a m p l i f i e r - d e s i g n r u l e says: 
         i n choosing between a one-stage commone m i t t e r and a m u l t i - s t a g e   if the bandwidth is constrained to be high  rule-out the one-stage.  
 cf. 	diff-ce-n-stage  	in mcdermott  	1  
        a  task -  subtask: sometimes task r e d u c t i o n occurs e n t i r e l y v i a i n f e r e n t i a l r u l e s ; the task reducer j u s t ignores an already-reduced task. for example  bias and coupling plans f o r m u l t i - s t a g e c i r c u i t s overlap in t h e i r d u t i e s . a t y p i c a l r u l e from a coupling plan says  
        the tasks f o r coupling to the second stage also do the work of biasing the base of the second-stage t r a n s i s t o r .   
 by the way  to make these rules e f f e c t i v e   there is another r u l e   	of   i n t e r a c t i o n type 	  1       which says   do coupling before b i a s i n g .    cf. 	figure 
1.  see the r u l e s couple-before-bias and cedir-vol-couple-plan in mcdermott  1.  
       there is nothing special about t h i s l i s t of common i n t e r a c t i o n s ; any r u l e may be used that can be handled by the i n f e r e n t i a l system.  of course  we c a n ' t expect g e n i u s - l e v e l i n s i g h t from the data-base machinery. for instance  we must help it out by t e l l i n g it whether to use a statement of the form  implies p q  in a forward or backward d i r e c t i o n . cf. h e w i t t   1.  

knowledge repr.-1: mcdermott 
1 

i l l results 
　　　the nasl system has been applied to two rather different tasks: electronic-circuit design and the blocks world. both applications are s t i l l being debugged. the f i r s t domain requires many rules implementing theories of design and electronics; the system currently possesses about 1 rules defining design  elementary electronics  typical circuits  standard biasing plans  and much more; even so  i t s knowledge is p i t i f u l l y sketchy compared to what a technician knows. the blocks world was studied for a different reason: as a way of comparing nasl with sacerdoti's  1  noah; in this domain  the knowledge requires about six pages of rules  on the order of 1 rules . 
　　　nasl plus electronics and design rules is called des1. desi has never designed a circuit a l l the way through. it has  however  given ample opportunity for testing the power of nasl's vocabularies. the system at this writing is capable of doing most of the steps in some simple design tasks. for example  i t s theory of design specifies a standard  design rephrasing plan  which transforms design problems in ways varying from splitting conjunctive problems into their conjuncts  to translating signal-conversion problems from the time to the frequency domain.  mcdermott  1  1  
　　　the theory of design is fairly domainspecific. that i s   there is no general theory of putting to use a new kind of element; instead  there are many prepackaged partial plans for various tasks  and the main job of the designer is to coordinate them. it would be nice if some 
of the inferential interaction rules of the last section were deducible from knowledge about new devices  but accomplishing this seems very hard. 
　　　after nasl was devised for this task  1 tried applying it to the rather different blocks world  to see how general it was. my model was the noah program  which has several b u i l t - i n constructs i thought could be expressed as rules. some could; some couldn't. 
	for example  the 	notion 	of 	 prerequisite  
 sacerdoti  1; sussman  1  is not built into nasl. it can be defined by rules which say 
　　　 if tl's effect p is a prereq of t1  then t1 is a successor of t l   and there is a policy tp to protect p u n t i l t1 is begun.  
the problem state after the predecessors are finished. noah can assume such a model is well defined  because noah assumes actions are defined as state changes. nasl is pessimistic about the existence of such a model; it never reduces a task until it is time to start executing i t . 
　　　it is instructive to think of this as a deficiency in vocabulary. that i s   there is no action of the form  reduce a task  which nasl can carry out. there is also no b u i l t - i n term  before task  which would designate the problem model in which to carry out the reduction  but i believe this could be defined now in terms of things like mod-manip without extensions to nasl . noah  on the other hand  has a more limited notion of  task   in which a l l tasks are non-inferential and non-parasitic  have foreseeable effects  and do not compute results. this enabled its author to separate planning from execution cleanly. 
iv conclusions 
　　　1 have presented a model of using a representational system  especially its use by a problem solver to represent its state. the model assigns to each module of a problem solver a vocabulary consisting of symbols with special meanings not derived from inferential interactions. i applied the model to the description of the nasl system  mcdermott  1   and sketched a comparison with noah.  sacerdoti  1  
this model has the following advantages: 
　　　 1  expository clarity - in describing a problem solver  one can factor the description into a formal  representational component  and a  pragmatic  representation user. 
　　　 1  modular implementation - the two pieces can be implemented and optimized separately.  mcdermott  1  
　　　 1  ease of comparison - many differences between programs can be expressed as a difference in vocabulary. 
　　　 1  ease of experimentation - to add a 	new module 	is to add a new vocabulary  as far as the representation system is concerned. 	there are no unnecessary restrictions on form  and no need for a set of special communication channels between a new module and the old ones. 

 protection must be further defined in terms of monitor.  the notion of prerequisite can then be used in two ways: passively  to catch  protection violations   sussman  1 ; and actively  as a trigger of c r i t i c s like  resolve conflicts.   sacerdoti  1  
	one irreducible difference between nasl 	and 
noah is nasl's inability to reduce a task before i t s predecessors are reduced. to be able to do this  one must have at least a partial model of the model brings out these points about nasl 
　　　 1  it has an unconstrained notion of problem  the  task.  tasks may be  inferential  or  parasitic   and may compute and receive data from other tasks. 
　　　　mcdernott 1 
　　　 1  nasl interleaves planning and execution tightly. planning amounts to the execution of a problematic task. 
　　　 1  nasl is incapable of  lookahead  task reduction. there is no b u i l t - i n term for the state of affairs after an action. 
　　　 1  more generally  nasl relies on  shallow reasoning  for thinking about plans. it does not contain a complete axiomatization of any programming language  and cannot prove the correctness of any of i t s plans. the reason it is successful in spite of these limitations is that it represents i t s current plan in a very redundant way; almost a l l features of interest can be retrieved quickly. this means that interesting advice about the domain is likely to be e f f i ciently representable. in a complex and uncertain world  this is probably the best we can do. 
　　　the model is s t i l l under development. one area in which it needs work is in a general characterization of modules which would allow us to be as unrestrictive yet precise in describing the  pragmatic  component of symbol meaning as predicate calculus allows us to be in describing the  inferential  component. so far  we must make do with english descriptions like those of section i i . 
　　　one possibility is to use a production system for this. that is  a problem solver would be described by a set of  state transition  rules whose left-hand sides described problem-solver states and whose right-hand sides specified changes in terms neutral enough to cover all problem solvers. modules would correspond to groups of productions sharing a vocabulary. a problem solver would then consist of two complementary pattern-directed systems  one to do inference  the other to do action. this has a certain pleasing symmetry. 
