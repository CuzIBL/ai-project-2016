 
　　to solve d i f f i c u l t problems h e u r i s t i c a l l y   requires detailed attention to computational efficiency. this paper describes how a heuri s t i c problem solving system  hpa  attempts to find a near optimal solution to the traveling salesman problem. a c r i t i c a l innovation over previous search algorithms is an e x p l i c i t dynamic weighting of the heuristic information. the heuristic information is weighted inversely proportional to i t s depth in the search t r e e - - i n consequence it produces a narrower depth f i r s t search than trad i t i o n a l weightings. at the same time  dynamic weighting retains the catastrophe protection of ordinary branch and bound algori thms. 
　　key words. heuristic search  branch and bound  hpa  traveling salesman problem  b i nary tree sort  dynamic weighting  precond i t i o n i n g   heuristic combinatorics  a r t i f i c i a l intelligence  pruning. 
   a r t i f i c i a l intelligence can be defined as the a r t of computational compromise. pro-
blem spaces in a r t i f i c i a l intelligence are sizeable and are non-analytic in the sense that smooth convergence to a solution is un-
available. hence computational methods must attempt to use their resources--space and time--cleverly. this paper discusses a heur i s t i c search procedure for the travel salesman problem--n! in size  emphasizing computa-
tional efficiency and search organization. 
the problem  symmetric costs  
　　there is a complete graph of n nodes. each edge of the graph has a non-negative length. a tour is a path in the graph v i s i t i n g every node once and only once and returning to the i n i t i a l node. the length of a tour is the sum of the lengths of the edges of the tour. a tour is called optimal  if among a l l possible tours  it is the shortest. since tours are cyclic  the i n i t i a l node can be fixed as node 1. the space of a l l tours are the  n-1 ! permutations of the nodes 1 through n. 
　　it is well known  lawler and wood  1  that ordinary operations research algorithms require exponential time to solve the problem. thus large  n 1  problems are either solved by branch-and-bound methods or by local-refinement methods  shen lin 1  . branch-and-bound methods guarantee an optimal solution  if they terminate within their allotted time  of course the method is guaranteed to terminate in exponential time . local-refinement methods generate solutions in polynomial time which are not guaranteed to be optimal. 
heuristic path algorithm  hpa  
hpa is a general graph search algorithm 
that searches or-graphs using a merit ordering. it was developed by this author  pohl 
1  1  to generalize the methods of 
doran and michie  1  and hart  nilsson and raphael  1 . the c r i t i c a l difference from the l a t t e r ' s algorithm a* is the use of a 
weighted merit function f x  =  l-w g x  + wh   x     1   w   1  see table 1 . suitable generalizations of hpa have been used by kowalski  1  and michie  1  for resolution theorem proving. in this domain  kowalski's criticisms  kowalski 1  are especially astute. he notes that  diagonal search 
strategies   his term for w ~ 1  have a c r i t i c a l defect. they investigate a l l equally meritorious alternative paths. in d i f f i c u l t problem spaces where any solution path is desired  this procedure is inappropriately 
breadth f i r s t . 
computational catastrophes 
   when a computational procedure is forced to terminate having used up i t s time and space 
resources without finding a solution--this 
w i l l be called a type 1 catastrophe.* 
　　when a computationat procedure terminates with an i n s u f f i c i e n t l y good solution-this w i l l be called a type 1 catastrophe. this type 1 catastrophe can only occur in problems that have an ordered set of feasible solutions . 
　　examples: type 1 catastrophe occurs a l l the time in a r t i f i c i a l intelligence research. an early example was saint's failure on 1 integration problems  slagle 1 . a typical type 1 catastrophe is the failure of a resolution search procedure to find a proof within 
a preset level bound. 
　　type 1 catastrophe can only occur in problems that require  best  solutions. the simplest local refinement strategy for the traveling-salesman problem is the nearestneighbor rule  1-opt in shen lin's terminology  . the rule is to select the nearest node not yet included in the sub-tour. using this rule on the graph in figure 1 leads to a very 
bad tour  a type 1 catastrophe. 
　　other examples of type 1 catastrophe are not generating the only winning or drawing move in a game playing program  or remaining on a  heuristic plateau   minsky 1   which is d i s t i n c t l y sub-optimal  in a problem space. 
over-relaxation  admissibility and dynamic weighting 
　　when using hpa to solve various 1-puzzle  see figure 1  problems  it was found that values of w   1 were most e f f i c i e n t . this weighting of the heuristic function no longer guaranteed   a d m i s s i b i l i t y     i . e . a minimum length solution. the overreliance on the heur i s t i c term is called overrelaxation because of the analogous technique in the 
1 *space and time catastrophe w i l l be distinguished as separate types in a later paper. computational solution of p a r t i a l different i a l equation problems. the weight w was set to a constant using previous experience to obtain an e f f i c i e n t setting. the 1 puzzle experiments demonstrated the computational u t i l i t y of overrelaxation. however  these solutions were rarely near the minimum length solution. in the traveling salesman problem this type of search would result in type 1 catastrophe. 
　　　to avoid a type 1 catastrophe  hpa would l i k e to retain admissibility or at least be within a known percentage of error  pohl 1 . this can be accomplished by using a technique to be called  dynamic weighting . dynamic weighting makes w a 
is particularly simple to calculate. it is a lower bound on the assignment problem  but 
where an assignment problem is calculated in 
1 
1 n   steps  this bound ia c a l c u l a b l e in 1  n   steps given that the edges are 
function of the state. 	hpa now uses f x  = 
g x  + w x h x  where 1   w x  * 
　　let x be a state in the search for a tour. let the depth  x  = the number of edges i n cluded in the subtour represented by x and 
define 
   the effect of having w decrease with depth is to insure a depth f i r s t search  if and 
only if the added cost decreases within ever tighter bounds. if at some point in the 
depth f i r s t search a type 1 catastrophe were 
to occur  the search would revert to ordinary 
branch-and-bound behavior. the dynamic weighting provides incentive to proceed in a depth f i r s t manner provided no unforseen i n crease in cost occurs. the resulting solution is within  1 + e  of the optimal solution  see appendix for proof  . 
heuristic estimators for the traveling salesman problem 
　　there are several known bounds on the traveling salesman tour. one is the assignment problem  lawler and wood 1    and another is the minimum spanning one-tree 
 held and karp 1  . 	a t h i r d estimator used  	the one-tree 	estimator. 	the experiments on a in sorted order. the in-out estimator is c a l culated by summing the 1 shortest edges out of each node not already included in the subtour and such that these edges are not connected to i n t e r i o r nodes of the subtour. this sum is added to the shortest edge out of each end node of the subtour  and the total divided by 1. the in-out estimator is easily seen to be a lower bound on the remaining length of a tour from the given subtour. 


in my experiments on symmetric distance pro-
blems   i . e . undirected graphs  is a variant of the l i t t l e estimator   l i t t l e   et al 1   to be called the in-out estimator. 
　　the traveling salesman tour is the minimum weight connected graph  whose nodes are a l l of degree 1. the assignment problem is the 
minimum weight graph whose nodes are a l l of degree 1. the minimum spanning tree is the 
minimum weight connected graph. a 1-tree is a minimum spanning tree over nodes   1   . . .   n   
with the addition of the two shortest edges 
out of node 1  	in the case of the assignment 
problem a solution graph may be a set of 
cycles. in the case of the 1-tree a solution may contain many nodes of degree not equal to 1. each relaxes a constraint of the traveling salesman problem  hence each contains 
many nodes of degree not equal to 1. 	each 
relaxes a constraint of the traveling sales-
man problem  hence each contains the solution 
of the traveling salesman problem as a feas-
ible solution. 	 see figure 1  
1 node graph of known d i f f i c u l t y  croes 1  showed clearly that dynamic weighting found 
near optimal solutions relatively cheaply when compared to ordinary branch-and-bound using the same heuristic estimator  see table 1 . 
additional computational techniques for i n creasing search efficiency   
     the candidate set is kept as a sorted b i nary tree  where merit   l e f t son    merit  parent    merit   r i g h t son . the next node to be expanded is always the left-most node of 
this sorted candidate set. 	new nodes are en-
tered into the tree in approximately log 1  m  time  where m is the size of the candidate set. 
     the bound on the tour is i n i t i a l l y the best nearest-neighbor tour. such a nearest-
neighbor tour is generated using each node as a starting subtour. 	during the execution of 
the in-out estimator  due to the author  
1 hpa this may be updated by a tour found in the course of expanding depth - n- 1 search nodes the most important savings are obtained from preconditioning the edge lengths. the edges are sorted by length which requires 1  n1 log 1 n  steps. furthermore  the edges are stored in completely sorted order and in sorted order for each node. 
1 r s o r t j points at a t r i p l e   j   k  m  and means the edge   j   k  of length m is the i t h smallest edge in the graph 
1 order   j   i  is an integer k where edge   j   k  is the i t h smallest edge originating a t node j . 
the one-tree and in-out computations only require linear time when the edges are already sorted by length. 	this reduces these computations from quadratic time; at the expense of a single  n 	log 1 n  computation and extra storage for the sorted l i s t s . 	in a l l cases an overall saving w i l l occur because at least 
1 
1  n   heuristic functions need to be calculated. 
summary 
     an important guiding principle in heurist i c programming is the avoidance of catastrophe. this principle overshadows i t s competitor--the pursuit of the optimal solution- as a pragmatic guideline in large search spaces. the whole notion of min-max ration-
a l i t y in game theory is an e x p l i c i t axiomatization of this conservative r u l e . 
     a dynamic weighting approach is proving computationally e f f i c i e n t in obtaining near optimal solutions to the traveling salesman problem. it offers a highly depth f i r s t search along with guarantees of avoiding type 1 catastrophes. 
