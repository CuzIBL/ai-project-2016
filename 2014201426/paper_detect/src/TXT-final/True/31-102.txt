 
this paper introduces a novel planning method for reactive agents. our planning method handles  in a single framework  issues from ai  control theory  and concurrency that have so far been considered apart. these issues are mostly controllability  safety  bounded liveness  and real time. our approach is founded on the supervisory control theory and on metric temporal logic  mtl . the highlights of our method consist of a new technique for incrementally checking mtl goal formulas over sequences of states generated by actions and a new method for backtracking during search by taking into account uncontrollable actions. 
1 	introduction 
a reactive plan is a program that specifies the actions to be executed by an agent that continuously reacts to the occurrence of discrete events from its environment. the automatic synthesis of reactive plans is a key component in the design of autonomous systems. it is of interest in ai planning  georgeff and lansky  1; drummond and bresina  1; dean et al  1   control theory  ramadge and wonham  1; makungu et al  1   and concurrency theory  emerson  1 . in these areas  the terms control rules  supervisor  and reactive programs are respectively used to denote reactive plans. however  the paradigms used to generate such plans vary widely. in ai planning  the focus is on representing and reasoning about actions in an efficient and natural way. this has led researchers in this field to concentrate on heuristic search techniques. unfortunately  little research in ai planning has taken into account the concepts of controllable actions and liveness goals. 
　in the area of control theory  the emphasis has been on reasoning about the issues of controllability and observability of actions  ramadge and wonham  1 . a 
　　this work was supported by the canadian government through its nserc programs. 
key characteristic of models of actions in this field is that they distinguish between controllable and uncontrollable actions. this facilitates reasoning about controllability issues. 
　in concurrency  modal temporal logic has been recognized as a useful tool for dealing with liveness properties. for instance  real-time modal temporal logic can express bounded-time response properties of the form  each occurrence of event e leads to satisfaction of condition c within 1 time units   alur and henzinger  1 . one interesting development in this area is model checking  emerson  1 . in this approach  verifying a program is viewed as evaluating the truth of a temporal formula on a temporal structure representing the program. 
　in this paper  we describe a method for generating reactive plans. our method borrows concepts and concerns from all the three areas outlined above. from ai planning  we take the concern of reasoning about actions and using heuristic search to generate plans. from control theory  we borrow the concept of controllable action. as in concurrency theory  we are also concerned with the representation and reasoning about real time  safety  and liveness goals. 
　to be more specific  our planner takes as input a goal  a description of the primitive actions of a reactive agent  which are controllable  and those of its environment  which are uncontrollable. the planner returns a reactive plan for achieving the goal. note that both the agent and its environment are referred to as the process or plant in control theory. we generate plans essentially by searching among sequences of states that represent executions of primitive actions  checking whether they satisfy the goal or not. reactive plans are more or less immediately extracted from satisfactory sequences. we describe goals using metric temporal logic  mtl  formulas  alur and henzinger  1 . 
　recent research has investigated connections between ai planning  control  and concurrency. this includes work on representation of ai control programs  nilsson  1   a recent book by dean and wellman on planning and control  dean and wellman  1   work on the integration of planning and concurrency ideas  godefroid and kabanza  1; kabanza  1   and work on the synthesis of controllers in temporal logic frameworks  thistle and wonham  1; fusaoka et ai  1 . we view our contribution to this research in three respects. first  our planner integrates concepts and concerns from the above three fields deeper than any existing comparable framework. hence  besides its more general capabilities  our planner contributes to a better understanding of issues in the boundaries of these fields. 
　second  we introduce a method for checking mtl goals over state sequences on the fly  i.e.  incrementally . in contrast to other techniques for checking similar real-time formulas  e.g.   alur and henzinger  1; alur et al  1    our technique does not require an explicit storage of the state-transition graph over which formulas are checked. rather  our planner generates and checks state sequences on the fly. this allows us to generate plans using a standard forward-chaining search. it also lets our planner generate plan control rules incrementally. in this way  our planner can be considered as having anytime capability. according to dean and boddy  dean and body  1   an anytime algorithm is one that can be stopped at different stages of its processing and yield an approximate  but useful  result. 
　third  we introduce a search technique  called controldirected backtracking. this technique uses selective backtracking to states from which the planner can expand controllable paths. we use an example to demonstrate that this approach can allow the planner to prune the search space significantly. this search technique is reminiscent of  but quite different from  the mechanisms used in dependency-directed backtracking  stallman and sussman  1  and partial-order search using mazurkiewicz's traces  godefroid and kabanza  1 . 
　although our planning approach applies to standard mtl and more general logics  due to space limitations  we will describe it only for a restricted class of mtl formulas called bounded-time mtl formulas  bmtl . even with this restriction  our planner handles problems that are beyond the scope of comparable al planning or control-theoretic frameworks. for example  as was mentioned above  our planner treats various types of bounded-time goals. 
　the remainder of this paper is organized in three parts  beginning with the description of our model of actions and plans. this is followed by a brief overview of mtl and a description of our planning method. 
1 	actions and plans 
we adopt the following model of plans from ramadge and wonham1  ramadge and wonham  1 . a process is modeled as a spontaneous generator of sequences of actions. the set of actions a of the process are partitioned into two disjoint subsets au and ac . the ac-
1
　　 as was mentioned in the introduction  we use the term  plan  as a synonym for supervisor. 
tions in au are uncontrollable  while those in ac are controllable. hence  the evolution of the process can be controlled by prohibiting the occurrence of some controllable actions at certain points. a control input is a subset y of a satisfying the condition au 1. if a 1  then a is permitted to occur. let l denote the set of sequences of actions that can be generated by the process and r c 1a represent the set of all control inputs. a plan is a map / : l t yielding  for each sequence w g l of generated actions  the control input f w  to be applied to the process at that point. language lj denotes the sequences of actions generated by the process under the supervision of /. let c be the empty string  a g a  and w ♀ a*. the language lj is formally defined as follows: 
 1  c g lj and 	* 
 1  wa g lj iff w g lj a g }{w   and wa g l. 
in our framework  the process consists of a reactive agent and its environment  both performing primitive actions  see figure 1 . the actions performed by the agent are controllable  whereas those performed by the environment are uncontrollable. we model the interaction between the agent and its environment by interleaving their actions. 
	i-a 	supervisor 	1 
figure 1: a model of control 
actions there are various models of actions in the fields of ai  concurrency  and control theory. representations of actions in planning are mostly based on strips-like models  fikes and nilsson  1 . models of actions in concurrency and control theory are often based on state-transition machines such as automata or petri nets. nevertheless  all these models are more or less theoretically equivalent. for example  a state-transition model can be derived from a strips-like formalism by generating the states reachable from one or several initial states. hence  without loss of generality  we assume a strips-like formalism in this paper. 
　the strips model of actions includes two basic concepts  namely  world state and primitive action. a world state is defined as a set of propositions. propositions model facts about states of the agent and its environment. every primitive action is described by a precondition  a conjunction of propositions enabling the action   a delete-list  a list of propositions retracted by the execution of the action   and an add-list  a list of propositions asserted by the execution of the action . note that  in general  variables are used to describe schemata of instances of actions. 
   for the sake of clarity  we use the following functions to manipulate actions. let s denote a world state and a an action. the transition function  a  s  returns the successor world state of s after execution of action a. the function controllable a  returns true if a is controllable  otherwise it returns false. the function  a  s  is defined only when a is enabled in 1. when it is defined  the result of  is obtained by removing from s the propositions in the delete-list of a and then adding the propositions in the add-list of a. 
operational representation of a plan for convenience  we adopt the following automaton representation of a plan /. a plan is represented by a pair  r     where r = is a finite-state automaton1 and 
   : y t is an output map yielding  for each state of r  the control input to be applied to the process at that point. a pair  r   p  represents a plan / if for every 
 intuitively  the value of / 
on the sequence of actions w is obtained by the application of w to r  causing r to move from its initial state to the state and then calculating the 
1 	metric temporal logic 
in this section  we summarize the mtl formulas that we use to describe goals  alur and henzinger  1 . 
syntax mtl formulas are constructed from an enumerable collection of propositional symbols  the boolean connectives  and  and  not   and the temporal modalities   u n t i l       a l w a y s     where denotes =   or and x is an integer. the formula formation rules are  1  every propositional symbol p is a formula  and  1  if f1 and f1 are formulas  then so are 
the following abbrevi-
 eventually /  
semantics mtl formulas are interpreted over models of the form m -  where s is an infinite sequence of states so   i      ＊;   is a function that takes a proposition and a state as input and returns true if the proposition holds in the state; and t is a function that associates a time stamp with each state. as usual  we write  m  s  |= / if state s in model m satisfies formula /. in addition to the standard rules for the boolean connectives  we have that  for a state s  in a model m  a propositional symbol p  and formulas f  and f1: 
1 in this paper  all the states of automata are accepting. 
1
　　note that the standard mtl also has a congruence modulo constraint and a next modality  alur and henzinger  1 . 

finally  we say that the model m  or seauence of states s m  satisfies a formula / if  af  so  /  
bounded-time m t l formulas as was mentioned in the introduction  we describe our planning algorithm only for bounded-time mtl formulas. these formulas are defined in terms of normalized mtl formulas. a normalized mtl formula is one in which only propositional symbols are negated.1 a bounded-time mtl for-
mula is a normalized mtl formula in which every until modality is of the form 
example 1 the formula 	 i.e.  p holds 
within 1 time units and remains true afterwards  expresses a classical goal requirement in ai planning and stability in control theory  fusaoka et a/.  1 . in figure 1  the formula g1 expresses the safety  mutual exclusion  requirement that c i  and m i   1 i 1  are never true simultaneously. the formula g1 expresses the liveness requirement that c 1  and c 1  become simultaneously true infinitely often  at intervals shorter than 1 time units. ＊ 
1 	planning method 
1 	global view 
given a set of primitive actions  an initial state  and a goal  our planner searchs for sequences of world states  starting from the initial state  and checking on the fly whether or not sequences of states expanded so far satisfy the goal. reactive plans are extracted from satisfactory sequences. our search process differs from a classical forward-chaining exploration in three respects. first  the check of mtl goals requires that we actually search in a space of pairs where each pair consists of a world state and an mtl formula  rather than simply a space of world states. second  transitions corresponding to uncontrollable actions are subject to special treatment. third  when we reach a sink  we backtrack taking into account the fact that some transitions are uncontrollable. as will be illustrated  our backtracking mechanism can lead to considerable savings compared to blind backtracking. 
　to check formulas over state sequences on the fly  we associate an mtl formula to each world state. the formula attached to a state must be satisfied by each sequence starting from this state. the planner uses a mechanism of progressing mtl subformulas through 
1
　　 for any mtl formula  we can obtain an equivalent normalized formula by using logical equivalences to propagate the negation symbol inwards. 

1 function 1. 1. 1. 1. 1. 1. 1. 1. 1. 
1. 1. 1. 1. 1. 1. 1. 1. 1. end 
1 
 ft  

　　　　　　the epilogue derives a plan {r   p  from the intermediate automaton m as follows. first  the planner removes the states that are not satisfactory from m to obtain the automaton r  lines 1 . then  p is obtained by including in  p s  an action a for each transition  s  a  sf  of r  lines 1 . hence  a crucial step in our planning process is to determine satisfactory states. 
example 1 let us consider the maze example pictured in figure 1  taken from  ramadge and wonham  1  . the maze has five rooms. there are a cat and a mouse moving from one room to another through doorways. every doorway is either for the exclusive passage of the cat   c i   . . .   c1  or the mouse  m 1  ...  me . doorway c1 is bidirectional and uncontrollable  while others are unidirectional and controllable  i.e.  they can be closed . the goal of this process consists of two requirements. first  the cat and the mouse must never occupy the same room simultaneously. second  after leaving their initial rooms  room 1 for the cat and room 1 for the mouse   they must return within 1 time units. these requirements are specified by formula fo in figure 1  this formula is also commented on in example 1 . 

figure 1: maze for cat and mouse 
figure 1 details the expansion of the search graph 
 i.e.  automaton m  for this example. every state of the graph is composed of a world state  which is a pair consisting of the cat and mouse positions  and an mtl formula. for clarity in the figure  we only indicate formulas for some states of the graph. the initial state is   1  / 1  . the formulas fi 1  are defined in figure 1. a proposition c i   m i   means that the cat 
 mouse  is in room i. the initial formula /1 is the result of progressing the goal g1 g1 through the world state  1  with a time difference of 1. states are expanded by applying actions as explained above. for instance    1   /1  is produced by applying action c1 to obtain the world state  1  and by progressing f1 through  1   using a time difference of 1  to get f1. note that the eventually modality in f1 is bounded by 1  which conveys the fact that one unit of time has elapsed. the expansion of   1  f1  into   l 1  f 1   by applying the action c1 is similar. 
　the expansion of   1   f1  into   1  f1  by applying c1 deserves more comment. following lines 1 of the formula progression algorithm  the progression of which is a conjunct of f1  through 
 1  yields true 	which is simplified 
as true. in this way  the progression of f1 through  1  yields /o  hence closing a cycle. note that the infinite execution represented by this cycle satisfies fo- in general  as explained below  each cycle generated by cur search process is necessarily satisfactory. 
　in figure 1  solid lines represent transitions of the plan. dashed lines represent paths that have been explored then rejected when the planner has determined that they lead to sinks. for instance  state   1  f1  is a sink because it violates the subgoal g1 of fo. this violation causes the progression of f1 through  1  to return false  i.e.  f1. from such trivial sinks  the planner derives less trivial ones. for example  state   l 1  f 1   also becomes a sink because action c1 is uncontrollable. 
　dotted lines represent parts of the search space that are not explored by our search process due to the use of the dependency-directed backtracking technique explained below. ＊ 
determining satisfactory states and sinks we extend the notion of controllable action to a notion of controllable state. a state is controllable if it is expanded  i.e.  it is in closed  and all its outgoing transitions are due to controllable actions. each state is attached with a slot  controllable  indicating whether it is controllable or not. this slot is set to false for each newly created state. to each state is also attached a status that indicates whether the state is sink  satisfactory  or still undefined. the status of each newly created state is set to undefined. then  the search process updates the status of expanded states based on the following definitions. 
definition 1 a sink is  1  a state of the form  x  false  or  1  a state from which there is an outgoing uncontrollable transition to a sink or  1  a state involving an eventually modality and from which there is no enabled action or all enabled actions lead to sinks. 
condition 1 constitutes a basic case for determining sinks. it is implemented by the lines 1 of the plan-

alities  since the progression of an unbounded-time even-

ner's algorithm. condition 1 constitutes one of two recursive cases for determining sinks and is implemented in part by the function sink. this function is described in figure 1 and is discussed below. condition 1 is also handled in part concurrently with condition 1 by the procedure check non trivial satisfactory states. this is further explained below. 
definition 1 a state is satisfactory if  1  it is controllable and does not involve an eventuality modality or  1  it is in a cycle not containing a sink or  1  there exists at least one transition to a satisfactory state and every outgoing uncontrollable transition leads to a satisfactory state. 
condition 1 specifies the most trivial of two basic cases for determining satisfactory states. it is implemented by the lines 1. condition 1 constitutes the other less trivial basic case that needs further explanation. each formula progression decreases the timing constraints of bounded-time eventualities by the duration of the applied action. that is  each progression yields a formula different from the current one. hence  the search process cannot reach an ancestor state on the current path  i.e.  it cannot close a cycle  unless all the eventualities have been achieved. theorem 1 implies that each path terminated by such a cycle satisfies the goal formula. note that if we had unbounded-time eventualities  it would be possible to reach a cycle without achieving all the eventutuality does not necessarily change it. also note that a bounded-time eventuality cannot be progressed indefinitely without being achieved  since sooner or later its timing constraint will reach 1  resulting in a sink. 
	condition 	1 	is 	implemented 	in 	the 	function 
check non trivial satisfactory states. the recursive case is handled by the procedure satisfactory  figure 1   which is called each time a basic satisfactory state has been identified. because of space constraints  we describe check non trivial satisfactory states informally. essentially  condition 1 must label all satisfactory states of the automaton m. when all the satisfactory states have been identified  the remaining states still labeled undefined become sinks. in this way  the planner also takes into account condition 1 for sinks. 
control directed backtracking search the idea of this search technique is to avoid expanding descendants of nontrivial sinks. indeed  such expansions are useless. for example  in figure 1  when the expansion has reached the sink   1  f 1    through the uncontrollable transition c1  state   l 1  f 1   also becomes a sink. it then becomes useless to expand descendants of   1   f1  that cannot be reached through at least one path from the initial state. 
　to implement this idea  we need to attach backpointers to states to indicate their immediate parents: s.pre c 1 xxf  contains the set of immediate parents of s for which the transition to s is caused by an uncontrollable 

action; s.pct contains the set of controllable transitions incoming to s. hence  if  a s'  e s.pct  then state s can be avoided by disabling a at s'  since a is controllable. 
　the control-directed backtracking mechanism is then implemented by the function sink  see figure 1 . given a sink s  this function explores  backwards  all ancestors of s reachable through a path formed only of uncontrollable transitions. each state met in this traversal is marked  sink  and all its descendants are marked  useless  provided that their predecessors are sink or marked  useless   the function mark-useless runs over descendants of s  marking them  useless  until we meet a state already marked  useless  or for which at least one predecessor is not marked  useless  . a state marked  useless  is removed from open. 
　note  however  that this process might mark states for which all the incoming transitions have not yet been generated. hence  when these currently missing transitions are generated  the  useless  mark are removed. the overhead incurred by these removals can be avoided by deleting states rather than marking them. deleted states would then be re-expanded when reached again by further expansions. in this way  we replace the overhead due to updating the  useless  marks by the overhead incurred by re-expanding states. the problem here is comparable to the management of backpointers in the search algorithm a*  rich and knight  1   pp. 1 : one can either keep and update backpointers on expanded nodes  or re-expand them. both strategies are incomparable in terms of performance. 
1 	conclusion 
in this paper  we have described a new planning method based on an original control-directed backtracking technique and a procedure for checking mtl goal formulas incrementally. our framework generates plans of reactive systems that take into consideration safety  liveness  and real-time constraints as well as controllable actions in a uniform way. note that the computation of the feedback function  p does not need to be done after the construction of the entire automaton r. instead  we could detect satisfactory states at different stages of expansion and immediately update the function  p accordingly. this means that the processing done in the function check non trvial satisfactory states has to be interleaved with the expansion process. in this way   p is produced incrementally. this gives anytime capability to our planner  dean and body  1j. 
　as a matter of facts  the search process explained in the previous section can be seen as generating the product of two timed automata  or timed transition graphs : one automaton accepting all the world-state sequences  and the other accepting the legal sequences  satisfying the mtl formula . the product automaton is simply a search graph in which world-states correspond to states in the world-state automaton and mtl formulas corresponds to states in the mtl automaton. our search process computes this product on the fly. thus  rather than specifying the transitions of the world-state automaton explicitly  we use a strips-iike action language to specify them succintly and then recursively apply actions to generate them only when they become relevant in the search process. similarly  rather than specifying the transitions of the mtl automaton explicitly  we progress formulas to generate them only when they become relevant in the search process. recently  brandin and wonham have proposed an approach in which the transitions of the two automata are specified explicitly  brandin and wonham  1 . our approach has at least two advantages with respect to their work. first  in our planner only world-states and mtl formulas that are relevant in the product are generated. in the brandin and wonham's approach  sink states and all potential time transitions must be specified explicitly in the input automata since their relevance can only be determined when constructing the product. second  mtl specifications are declarative and are maintained as such during our search process. we think that this will facilitate debugging of controller specifications. for example  sink states rise when an mtl always modality is made false or the deadline of an eventually modality expires. these modalities provide information in a declarative form about undesired states in the process being controlled. 
　we are investigating different complementary strategies for coping with state explosion. recent work in ai planning shows that forward-chaining search can be made effective using such strategies  bacchus and kabanza  1 . at the same time  work in control theory has demonstrated that a forward-chaining exploration can become effective with real-world problems using efficient implementation or modular techniques  balemi et a/.  1; brandin  1 . in the same trend  we intend to investigate the application of ai planning goal-regression techniques   rich and knight  1   to generate search control knowledge that specifies the relevance of actions to a given goal. with this knowledge  forward-chaining will explore the more relevant parts of the search space before the less relevant ones. the usual goal-regression techniques in ai planning deal only with goals of achieving state conditions. our approach to handle general mtl goals is being influenced by two observations. on the one hand  an mtl eventually modality expresses a condition to be achieved. thus  we could parse an mtl formula to extract the sub-formulas expressing conditions to be achieved and then apply goal-regression techniques to determine the relevance of actions to these conditions. on the other hand  an mtl always modality expresses a condition to be maintained. each uncontrollable action that could falsify such a condition is relevant since it might lead to sinks. such relevant actions could also be determined using goal-regression. it thus 

seems possible to interleave the goal-regression processes of computing relevant actions and the forward-chaining one of generating accessible states. the challenge will be to study the tradeoffs between these processes and the effectiveness of their combination on real-world problems. in the same line of inquiry  we are also interested in abstraction over large numbers of states during search. 
