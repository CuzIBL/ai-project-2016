learning university mathematics 
edmund furse 
department of computer studies 
university of glamorgan 
pontypridd  mid glamorgan 
cf1dl u k efurse uk.ac.glamorgan 

a b s t r a c t 
this 	video 	demonstrates 	the 	program 	m u   	the 
mathematics understander  which learns university level pure mathematics. the video is both concerned with mu's performance in learning and performing mathematics  and its underlying cognitive architecture  the contextual memory system   cms . the changes in knowledge representation during proof checking and problem solving are demonstrated graphically. 
1. i n t r o d u c t i o n 
learning university level mathematics is a complex task for both people and machines and difficult to model for three main reasons: 
1. students can learn any branch of mathematics  and mathematics is continually developing. any learning model therefore has to be open in its representation. 
1. pure mathematics is a very large domain over 1 years old  and this means that a large amount of knowledge has to be acquired. 
1. understanding mathematics proofs and solving problems requires the ability to be able to retrieve the appropriate result at each step  and this 
   expertise only comes with experience. the mathematics understander  mu    furse  1  is a computational model of how students learn pure mathematics from texts written in a notation known as the formal expression language  fel    furse  1 . fel is a very expressive language and capable of representing almost all branches of pure mathematics. mu has read texts in both classical analysis and group 
theory. an extract from an fel text is shown in figure 1  where a definition  theorem and proof are shown in classical analysis. 
　　　mu has no built in knowledge of mathematical results  and acquires all its knowledge from the reading of texts. this knowledge is of two sorts: 
1. the mathematics results: definitions of concepts  theorems and lemmas. 
1. features which index the mathematical results  and enable easy retrieval of the appropriate result. the features provide an open form of representation thus enabling mu to learn in an open domain  see furse  1 . 

1. t h e m a t h e m a t i c s t a s k 
the mathematics task consists of checking proofs and solving problems using the knowledge of mathematical results that has been already been acquired. clearly there is more to understanding a mathematics text than this but this is the scope of mu's understanding  
　　　a knowledge of the mathematical results is not sufficient either to check proofs or solve problems since there are many results that could be applied at any one step. it is also necessary to have some control knowledge with to choose the appropriate result. in theorem proving systems  such as ammon   this is often done by heuristics  but in mu the choice of result is largely driven by perceptual features. 
   mu performs proof checking just by use of its features to retrieve the appropriate result. as explained in the next section through the experience of checking proofs and solving problems the features change in their representation  so that gradually more specific features emerge which enable important results to be easily retrieved  thus overcoming the combinatorial choice. this also ensures that mu goes faster rather than slower with more knowledge  as the specialised features ensure that retrieval is faster. 
	furse 	1 

　　in problem solving  mu uses four general purpose heuristics to give overall control: 1. break a problem up into parts; 1. suppose the left hand side; 1. expand definitions; 1. simplify expressions. a verbatim solution of mu using these heuristics to solve a problem in group theory is shown in figure 1. the simplification process uses the cms to control which results are applied. the above heuristics are not sufficient to solve all problems in mathematics  and research has shown that there is a need for specialised heuristics as well as the features used by mu. morgan et al  show how the heuristics can be learned from the analysis of worked examples. 
1. learning and the c m s 
mu's learning is all performed by the contextual memory system  cms  which controls all the storage and retrieval of the mathematical results in terms of dynamic features. because of the open learning requirement  there are no built in features. rather the cms uses built in feature creation mechanisms to generate a large number of features from the input. the cms performs its learning in two stages: 
1. initial encoding of the mathematical results when mu reads the fel statement in terms of features. 
1. continual updating of the features through the experience of proof checking and problem solving. feature creation works on a parsed form of the input. for example  the definition of abelian in fig. 1 is parsed as 
  =   abelian  cap g    and  group  cap g   
 forall  variables a b  
 propn  =   and  member a  cap g    member b  cap g    
 = *ab  *ba        
if this is treated as a tree  features can be constructed as subtrees. formally  features are defined by: 
 feature  ::=  position  specifierxtypexterm  
 position  ::= lhs- i rhs- i null 
 position  ::= lhs- position  i rhs- position  
 specifier  ::= is- i has type  ::= form- i term-
since the  term  is as open as the input  this results in an infinite feature space. in this example there are 
many features including general features such as: has-form- = a bj  is-form-  =* a b   has-form member a b  and more specialised features such as: lhs-has-form- abelian  cap a    rhs-has-form and  group a  b  is-form-    abelian al and b c   and only about 1 features are used for the first encoding. 
　　the initial encoding into features of a result may not be very efficient as at the time it is impossible to know which features will turn out to be salient. with subsequent experience  proof checking and problem solving will provide probes with which to do retrieval from the cms. often such retrievals will recall a result which cannot be applied to the current step  as well as the correct result  and these are termed failures. the cms learns from this experience in three ways: 
1. features which were used in the searching using the probe but are not currently linked to the found item are termed 'uncomputed features'. these features are now linked to the item. 
1 	videos 

1. conclusion 
mu shows that it is possible to model the learning of a very large and open domain. the solution is to use an arbitrary set of features built from the environment for initial encoding  and let experience dictate how the features should be revised to improve performance. 
