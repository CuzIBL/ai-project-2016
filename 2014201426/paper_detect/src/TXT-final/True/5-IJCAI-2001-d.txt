
this paper describes a new method for visualizing complex information spaces as painted images. scientific visualization converts data into pictures that allow viewers to  see  trends  relationships  and patterns. we introduce a formal definition of the correspondence between traditional visualization techniques and painterly styles from the impressionist art movement. this correspondence allows us to apply perceptual guidelines from visualization to control the presentation of information in a computer-generated painting. the result is an image that is visually engaging  but that also allows viewers to rapidly and accurately explore and analyze the underlying data values. we conclude by applying our technique to a collection of environmental and weather readings  to demonstrate its viability in a practical  real-world visualization environment.
1	introduction
this paper describes a formal method for constructing visual representations of complex information spaces that support rapid and accurate exploration and analysis. our technique falls within the domain of scientific visualization  the conversion of collections of strings and numbers  or datasets  as they are often called  into images that allow viewers to explore  analyze  validate  and discover within their data. we focused on two important issues  smith and van rosendale  1  during our investigations:
1. multidimensional displays: our technique must support the visualization of multiple overlapping data fields together in the same display. this is much more difficult than representing a single data field in isolation. designing techniques to effectively represent multidimensional datasets is an open area of research in visualization.
1. aesthetic displays: we also seek to create images that are visually engaging. we believe this will motivate viewers to study a visualization in more detail. it will draw viewers into an image  and can be used to emphasize areas of importance in a dataset.
we address these goals by:  1  applying results from human perception to create images that harness the strengths of our low-levelvisual system  and  1  using artistic techniquesfrom the impressionist movement to produce painterly renditions that are both beautiful and engaging. from an ai perspective  the contribution of this work is the identification of a close relationship between specific painterly techniques and the performance properties of human perception; our formalization lays the groundwork for the generation of scientific visualizations that are effective and aesthetically pleasing.
　our technique converts a collection of data values into a painterly image as follows. first  one or more computer generated  brush strokes  are attached to each data element in the collection. a brush stroke has style properties  e.g.  color  length  or direction  that we can vary to modify its visual appearance. data values in the data element are used to select specific states for the different properties. the result is a stroke that represents its corresponding data element. rendering all of the strokes for every data element produces a painterly image whose stroke properties visualize the underlying dataset.
　the remainder of this paper describes in detail how each step in this process is managed and controlled. we begin by defining formalisms for:  1  a multidimensional dataset and its visualization  and  1  the brush strokes that make up a painterly image. we next present a set of perceptual rules on the use of color and texture in visualization that we extend via our formalisms to the painterly domain. these rules ensure the images we produce represent a dataset in a perceptually salient manner. finally  we discuss how our techniques were used to visualize a real-world collection of environmentaland weather readings for the continental united states. we conclude with a summary and a short description of future work.
1	formalisms
we began our investigation by identifying methods for building painterly images that we can use to represent multidimensional datasets. a key insight is that many painterly styles correspond closely to perceptual features that are detected by the human visual system. in some sense this is not surprising. artistic masters understood intuitively which properties of a painting would capture a viewer's gaze  and their styles naturally focused on harnessing these features. moreover  certain movements used scientific studies of the visual system
　
to help them understand how viewers would perceive their work. the overlap of artistic styles and perception offers a important starting point: the body of knowledge on the use of perception during visualization will help us to predict how corresponding painterly styles might perform in the same environment.
　in orderto make use of this advantage  we define a relationship between traditional visualization techniques and painted images. this is done by constructing a correspondence between formal specifications of the two environments. the correspondence can then be used to extend our perceptual guidelines to a painterly domain.
1	multidimensional visualization
a simple formalization of a multidimensional visualization consists of two parts: a description of the dataset  and a definition of the mapping function used to convert it into an image. a multidimensional dataset contains samples points or data elements . represents two or more data attributes   ;
data elements encode values for each attribute  that is 
.
　visualization begins with the construction of a data-feature mapping that converts the raw data into images that are presented to the viewer. identifies a visual feature to use to display data attribute . maps the domain of to the range of displayable values in . based on these definitions  visualization is the selection of and a viewer's interpretation of the images produced by . an effective visualization chooses to support the exploration and analysis tasks the viewer wants to perform.
1	painterly styles
our investigation of painterly styles is directed by two separate criteria. first  we restrict our search to a particular movement in art known as impressionism. second  we attempt to pair each style with a corresponding visual feature that has proven to be effective in a perceptual visualization environment. there are no technical reasons for why impressionism was chosen over any other movement. in fact  we expect the basic theories behind our technique will extend to other types of artistic presentation. for our initial work  however  we felt it was important to narrow our focus to a set of fundamental goals in the context of a single type of painting style.
　the term  impressionism  was attached to a small group of french artists  initially including monet  degas  manet  renoir  and pissarro  and later ce＞zanne  sisley  and van gogh  among others  who broke from the traditional schools of the time to approach painting from a new perspective. the impressionist technique was based on a numberof underlying principles  see also  schapiro  1  :
1. object and environment interpenetrate. outlines of objects are softened or obscured  e.g.  monet's water lilies ; objects are bathed and interact with light; shadows are colored and movement is represented as unfinished outlines.
1. color acquires independence. there is no constant hue for an object  atmospheric conditions and light moderate color across its surface; objects may be reduced to swatches of color.
1. show a small section of nature. the artist is not placed in a privileged position relative to nature; the world is shown as a series of close-up details.
1. minimize perspective. perspective is shortened and distance reduced to turn 1d space into a 1d image.
1. solicit a viewer's optics. study the retinal system; divide tones as separate brush strokes to vitalize color rather than graying with overlapping strokes; harness simultaneous contrast; use models from color scientists like chevreul  chevreul  1  or rood  rood  1 .
although these general characteristics are perhaps less precise than we might prefer  we can still draw a number of important conclusions. properties of hue  luminance  and lighting were explicitly controlled and even studied in a scientific fashion by some of the impressionists. rather than using an  object-based  representation  the artists appear to be more concerned with subdividing a painting based on the interactions of light with color and other surface properties. additional painterly styles can be identified by studying the paintings themselves. these styles often varied dramatically between individual artists  acting to define their unique painting techniques. examples include:
path: the path or direction a brush stroke follows; van gogh made extensive use of curved paths to define boundaries and shape in his paintings; other artists favored simpler  straighter strokes  length: the length of individual strokes on the canvas  often used to differentiatebetween contextuallydifferent parts of a painting  density: the number of strokes laid down in a fixed area of canvas  coarseness: the coarseness of the brush used to apply a stroke; a coarser brush causes visible bristle lines and surface roughness  and weight: the amount of paint applied during each stroke; heavy strokes highlight brush coarseness and produce ridges of paint that cause underhanging shadows when lit from the proper direction.
in this context  a painting	can be seen as a collection of
brush strokes   with each stroke made up of style properties   that is    .
　although it would be tedious  and perhaps uninformative  to characterize a real painting in this manner  these definitions provide an effective way to relate the visualization process to a painted image. first  we can match many of the painterly styles to visual features used during visualization. for example  color and lighting in impressionism has a direct correspondence to the use of hue and luminance in perceptual visualization. other styles  e.g.  path  density  and length  have similar partners in perception  e.g.  orientation  contrast  and size . second  data elements in a dataset are analogous to brush strokes in a painting. attribute values in element could therefore be used to select specific for each style in .
　consider a data-feature mapping in this context. the visual features can be converted to their corresponding painterly styles . now describes how to convert a data element into painted brush stroke whose visual appearance represents the attribute values embedded in . the close correspondence between perceptual features and many of the painterly styles we hope to apply is particularly advantageous. since numerous controlled experiments on the use of perceptual features have already been conducted  we have a large body of evidence to use to predict how we expect painterly styles to react in a multidimensional visualization environment.
1	perceptual characteristics
past research has studied methods for applying rules of perception during visualization  bergman et al.  1; healey and enns  1; rheingans and tebbs  1 . the cognitive abilities of the low-level human visual system have been studied extensively in the area of human psychophysics. one interesting result is the identification of a limited set of visual features that are detected rapidly  accurately  and relatively effortlessly by a human viewer  triesman  1; wolfe  1 . these features are similar to the ones we display during multidimensional visualization  e.g.  hue  luminance  orientation  size  and motion . when combined properly  they can be used to perform exploratory analysis tasks like searching for data elements with a particular attribute value  identifying boundaries between groups of elements with similar values  tracking elements as they move in time and space  and estimating the number of elements with common values. the ability to harness the low-level visual system during visualization through the use of these features is especially attractive  since:
analysis is rapid and accurate  often requiring no more than 1 milliseconds 
task completion time is constant and independent of the number of elements in a display  and different visual features can interact with one another to mask information; psychophysical experiments allow us to identify and avoid these interference patterns.
a data-feature mapping that builds on a perceptual foundation can support high-level exploration and analysis of large amounts of data in a relatively short period of time. our recent work focuses on the combined use of fundamental properties of color and texture to encode multiple attributes in a single display. we draw on three specific areas of research in perception and visualization to guide the construction of our brush strokes: color selection  texture selection  and feature hierarchies that can cause visual interference and masking.
1	color selection
color is a common feature used in many visualization designs. some techniques attempt to measure and control the color difference viewers perceive between pairs of colors. this allows:
perceptual balance: a unit step anywhere along the color scale produces a perceptually uniform difference in color  distinguishability: within a discrete collection of colors  every color is equally distinguishable from all the others  i.e.  no color is  easier  or  harder  to identify   and flexibility: colors can be selected from any part of color space.
standard color models like cieluv or cielab use euclidean distance to approximate perceived color difference. more complex techniques extend this basic idea. for example  rheingans and tebbs  rheingans and tebbs  1  plotted a path through a color model  a allowed a viewer to vary how colors are selected along the path. ware constructed color scales that spiral up around the luminance axis  ware  1 ; such a scale maintains a uniform simultaneous contrast error along its length. healey and enns  healey and enns  1 showed that color distance  linear separation  and color category must all be controlled to select discrete collections of equally distinguishable colors.
　our color selection techniquecombines differentaspects of each of these methods. a single loop spiraling up around the luminance axis is plotted in the region of cieluv space that contains our monitor's color gamut. the path is subdivided into named color regions  e.g.  a blue region  a green region  and so on . colors are then selected by choosing  colors uniformlyspaced along each of the color regions. the result is a set of colors selected from a perceptually balanced color model  each with a roughly constant simultaneous contrast error  and chosen such that color distance and linear separation are constant within each named color region.
1	texture selection
although texture is often viewed as a single visual feature  it can be decomposed into fundamental perceptual dimensions. research in computer vision has used properties like regularity  directionality  and contrast to perform automatic texture segmentation and classification. results from psychophysics have shown that many of these properties can also be detected by the low-level visual system.
　one promising approach in visualization has been to use the perceptual dimensions of a texture pattern to represent multiple data attributes. individual values in a data element control a corresponding texture dimension  producing a texture pattern that changes its visual appearance based on the underlying dataset. grinstein et al.  grinstein et al.  1  built  stick-man  icons to represent high dimensional data elements; the orientation of each limb encodes a value for one particular attribute. ware and and knight  ware and knight  1  displayed gabor filters that modified their orientation  size  and contrast based on the values of three independent data attributes. healey and enns  healey and enns  1  constructed perceptual texture elements  or pexels  that varied in height  density  and regularity; their results showed that both height and density were perceptually salient  but regularity was not. more recent work  weigle et al.  1  found that an orientation difference of is sufficient to rapidly distinguish visual elements.
1	feature hierarchy
a third factor that must be considered is visual interference  that is  a situation where one visual feature masks another. although the need to rank each brush stroke style's perceptual strength is not necessary in a painting  this information is critical for effective visualization design. the most important data attributes  as defined by the viewer  should be displayed using the most salient features. secondary data should never be visualized in a way that masks the information a viewer is most interested in seeing.
　perceptual features are ordered in a hierarchy by the lowlevel visual system. results reported in both the psychophysical and visualization literature have confirmed a luminance- hue-texture interference pattern. variations in luminance can slow a viewer's ability to identify the presence of individual hues or the spatial patterns they form  callaghan  1 . the interference is asymmetric: random variations in hue have no effect on a viewer's ability to see luminance patterns. a similar asymmetric hue on texture interference has also been shown to exist  healey and enns  1; triesman  1 ; random variations in hue interfere with the identification of texture patterns  but not vice-versa. these results suggest that luminance  then hue  then various texture properties should be used to display attributes in order of importance.
1	painterly visualization
based on the perception guidelines discussed above  and on our formal correspondence between visualization techniques and painterly images  we decided to build a system that varied brush stroke color  size  spatial density  and orientation to encode up to four independent data attributes  in addition to the two spatial values used to position each stroke . the presence of feature hierarchies suggest color should be used to represent the most important attribute  followed by the texture properties. the results of  healey and enns  1  further refine this to applying color  size  density  and orientation in order of attribute importance.
　the brush strokes in our current prototype are constructed using a simple texture mapping scheme. a real painted stroke was digitized and converted into a texture map. this texture map is attached to a polygon to produce a reasonable approximation of a generic brush stroke. the stroke's position  color  size  and orientation are controlled by modifying the texture map and transforming the polygon. density is varied by changing the number of strokes rendered in a unit area of screen space. fig. 1 shows an example of brush strokes with four different greyscales  sizes  densities  and orientations  greyscale is used only for the printed figures; on-screen images are displayed in full color .
1	practical applications
one of the application testbeds for our visualization techniques is a dataset of monthly environmental and weather conditions collected and recorded by the intergovernmental panel on climate change. this dataset contains mean

figure 1: examples of texture mapped brush strokes with different orientations  top row   densities  second row   sizes  third row   and greyscales  fourth row 
monthly surface climate readings in  latitude and longitude steps for the years 1 to 1  e.g.  readings for january averaged over the years 1  readings for february averaged over the years 1  and so on . we chose to visualize temperature  precipitation  pressure  and windspeed. based on this order of importance  we built a data-feature mapping that assigns brush stroke greyscale  or color for on-screen images   size  or coverage   density  and orientation  respectively  to our four attributes. temperature is represented by greyscalesselected uniformlyfrom a perceptually balanced luminance path. this path runs from dark  for cold temperatures  to bright  for hot temperatures . precipitation is represented size  i.e.  the amount of an element's spatial region its brush stroke covers . sizes range exponentially from very small coverage  for little or no precipitation  to full coverage  for heavy precipitation . windspeed is represented by orientations ranging from 1 or upright  for weak winds  to 1 or flat  for strong winds . finally  pressure is represented by four increasingly dense arrays of brush strokes: a single stroke  a array of strokes  a array  and a array; continuous pressure values are discritized into four uniform ranges  then mapped to the appropriate density  sparse for low pressure  dense for high pressure .
　fig. 1 shows a visualization of data for februaryin the eastern half of the continental united states. although unlikely to be mistaken for a real impressionist painting  we feel the image contains important aesthetic qualities that make it stand out from a traditional visualization. the top four images  the top row of fig. 1  use a perceptual greyscale ramp to show the individual variation in temperature  precipitation  pressure  and windspeed. was used to construct the painterly visualization of all four attributes shown in the bottom image of fig. 1. various luminanceand texture patterns representing different weather phenomena are noted in this image.
　we have applied our painterly visualizations to a numberof additional real-world environments including scientific simulations  e-commerce activity logs  and medical scans. anecdotal feedback from domain experts collaborating on our ef-
　

	temperature	precipitation	pressure	windspeed

figure 1: a painterly visualization of environment conditions for february over the eastern united states:  top row  greyscale ramps  dark for small values to light for large values  of temperature in isolation  precipitation in isolation  pressure in isolation  and windspeed in isolation;  bottom image  a painterly visualization of all four attributes represented with the brush stroke properties greyscale  size  or coverage   density  and orientation
　
forts suggests that our technique achieves its goal of producing images that:  1  represent multidimensional datasets in a clear and effective manner  and  1  contain many of the aesthetic and visually engaging properties of a real painting.
1	conclusions and future work
this paper describes a new method of visualization that uses painted brush strokes to represent multidimensional data elements. our strokes support the variation of visual properties based in large part on styles from the impressionist school of painting. each attribute in a dataset is mapped to a specific painterly style; a data element's attribute values can then be used to vary the visual appearance of its brush stroke. the styles we chose are closely related to perceptual features detected by the low-level human visual system. research studying the use of these features during visualization allows us to optimize the selection and application of the corresponding painterly styles. the result is a  painted image  whose color and texture patterns are used to explore  analyze  verify  and discover information stored in a multidimensional dataset.
　one important area of future work is the construction of new brush stroke models. texture maps are common in most graphics apis  and are often rendered using hardware acceleration. unfortunately  certain styles  e.g.  stroke coarseness or weight  are not easy to manipulate using texture maps. it may also be difficult to animate textured brush strokes during real-time visualization. we are currently investigating three potential solutions to this problem:  1  building a library of texture maps that explicitly differ across certain styles;  1  using mathematical spline surfaces to model more sophisticated brush stroke properties  and  1  using a physical simulation system to construct realistic strokes. early results suggest a combination of models  e.g.  a texture map library whose entries are precomputed or dynamically updated  may be most appropriate.
　we are also working to identify new painterly styles  and to integrate them into our stroke models. two promising candidates we have already discussed are coarseness and weight. we are reviewingliterature on technicaland artistic properties in impressionism  while at the same time searching for perceptual features that may correspond to new painterly styles. increasing the number of styles we can encode in each brush stroke will allow us to represent larger datasets with higher dimensionality.
　we note one final advantage we can derive from the correspondence between perceptual features and painterly styles. we measure the perceptual salience of a visual feature using controlled psychophysical experiments. exactly the same technique can be used to investigate the strengths and limitations of new painterly styles. just as research in perception helps us to identify and control brush stroke properties during painterly visualization  work on new styles may offer insight into how the low-level visual system  sees  certain combinations of visual properties.
acknowledgments
this work is supported by the national science foundation research grant nsf-aci-1.
references
 bergman et al.  1  lawrence d. bergman  bernice e. rogowitz  and lloyd a. treinish. a rule-based tool for assisting colormap selection. in proceedings visualization '1  pages 1  atlanta  georgia  1.
 callaghan  1  t. c. callaghan. interference and dominance in texture segregation. in d. brogan  editor  visual search  pages 1. taylor & francis  new york  new york  1.
 chevreul  1  michel euge`ne chevreul. the principles of harmony and contrast of colors and their applications to the arts. reinhold publishing corporation  new york  new york  1.
 grinstein et al.  1  g. grinstein  r. pickett  and m. williams. exvis: an exploratory data visualization environment. in proceedings graphics interface '1  pages 1  london  canada  1.
 healey and enns  1  christopher g. healey and james t. enns. large datasets at a glance: combining textures and colors in scientific visualization. ieee transactions on visualization and computer graphics  1 :1  1.
 rheingans and tebbs  1  penny rheingans and brice tebbs. a tool for dynamic explorationsof color mappings. computer graphics  1 :1  1.
 rood  1  ogden nicholas rood. modern chromatics  with applications to art and industry. appleton  new york  new york  1.
 schapiro  1  meyer schapiro. impressionism: reflections and perceptions. george brazillier  inc.  new york  new york  1.
 smith and van rosendale  1  p. h. smith and j. van rosendale. data and visualization corridors report on the 1 cvd workshop series  sponsored by doe and nsf . technical report cacr-1  center for advanced computing research  california institute of technology  1.
 triesman  1  a. triesman. preattentive processing in vision. computer vision  graphics and image processing  1-1  1.
 ware and knight  1  colin ware and william knight. using visual texture for information display. acm transactions on graphics  1 :1  1.
 ware  1  c. ware. color sequences for univariate maps: theory  experiments  and principles. ieee computer graphics & applications  1 :1  1.
 weigle et al.  1  christopher weigle  william g. emigh  geniva liu  russell m. taylor  james t. enns  and christopher g. healey. oriented texture slivers: a technique for local value estimation of multiple scalar fields. in proceedings graphics interface 1  pages 1  montre＞al  canada  1.
 wolfe  1  jeremy m. wolfe. guided search 1: a revised model of visual search. psychonomic bulletin & review  1 :1  1.
visual analogy in problem solving
jim davies and ashok k. goel
college of computing
 georgia institute of technology  atlanta jimmydavies usa.net  goel cc.gatech.eduabstract
computational models of analogical problem solving have traditionally described source and target domains in terms of their causal structure. but psychological research shows that visual reasoning plays a part for many kinds of analogies. this paper describes a model that transfers a solution from a source analog to a new target problem using only visual knowledge represented symbolically. the knowledge representation is based on a language of primitive visual elements and transformations. we found that visual knowledge is sufficient for transfer  but that causal knowledge is needed to determine if the transferred solution is appropriate.
1	introduction
the goal of this work is to examine the nature and role of visual representations and inferences in analogical reasoning  and especially in analogical transfer. analogy involves learning about some target analog by transferring knowledge from a source analog. the process consists of several steps: retrieval is identifying a candidate source analog in memory; mapping is finding the best set of correspondences between components of the analogs; transfer is the application of knowledge from the source analog to the target analog; evaluation is determining if the target problem has been solved appropriately; storage is storing the target analog in memory for potential reuse.
　traditional conceptual and computational theories of analogy have focused primarily on causal knowledge and inferences  see  holyoak and thagard  1   bhatta and goel  1   falkenhainer et al.  1  for examples . psychological research  however  shows that visual reasoning often occurs in analogy  holyoak and thagard  1    pedone et al.  1  some recent theories  bhatta and goel  1   griffith et al.  1  represent structural knowledge in addition to causal knowledge. structural knowledge describes a system's physical composition but typically includes only the information directly relevant for analyzing the causal behaviors of the system. structural knowledge might be thought of as a schematic that shows the components of the system and the connections among them but leaves out other visual information such as what a wire looks like  which side of a pump is up  etc.
　we define visual representations as those that consist only of information relevant to how an image appears. note that this definition of  visual  includes both high-level symbolic representations and low-level bitmap representations  which only represent the locations of points of light . we view visual and causal knowledge as lying on a spectrum  where one extreme has raw sensory data   such as a bitmap image   and the other has highly interpreted and abstracted knowledge  e.g.  teleological knowledge . visual knowledge is closer to the perceptual  or modal  end of the spectrum  and causal knowledge is nearer to the amodal end. causality can only be represented implicitly in a visual representation. in contrast to a bitmap image  the visual knowledge we use contains abstractions of objects and relations  and is thus represented symbolically.
　our hypothesis is that symbolically represented visual knowledge provides a level of abstraction at which two otherwise dissimilar domains may look more alike. for example  the concepts of an army on the march and a ray of radiation are quite different  but if both are represented as lines  it may facilitate analogical retrieval  mapping and transfer. we hypothesize that evaluation  on the other hand  requires explicit causal knowledge: simply because the path of the army and the ray look alike does not imply that the two behave similarly. since other's work has begun to explore the use of visual knowledge for mapping  our work focuses on analogical transfer.
　in this paper  we sketch an outline of our computational theory of visual analogical transfer for a class of problems in which the source analog contains a sequence of images  or can be analyzed in terms of an image sequence . this theory has been implemented in an operational computer program called galatea. we illustrate the theory using the classical fortress/tumor problem  duncker  1  as an example. this example was chosen because psychological data indicates that experimental participants used visual inferences in solving it  holyoak and thagard  1 . in this task  experimental participants first read a story about a problem-solving situation: a general with a large army wants to overthrow a dictator who lives in a fortress. all roads to the fortress are armed with mines that will go off if many people are on them at the same time. to solve this problem he breaks up his army into small groups and has them take different roads. the groups arrive at the same time and take the fortress. then  the subjects are given a new problem: a patient needs radiation treatment on a tumor inside the body  but the radiation will harm the healthy tissue it reaches on the way in. finally  the participants are asked to solve the tumor problem. the analogous solution is to target the tumor with low-level rays coming from different directions  and have them converge on the tumor.
1	language and processing
our first task was to design a language to express visual analogs and the maps between them. since the theory pertains to sequences of images  we needed both a vocabulary of primitive visual transformations that express changes between two consecutive images  and a vocabulary of primitive visual elements that enable the transformations. we designed a primitive visualization language  called privlan  which consists of such primitive visual elements and primitive visual transformations. it can represent diagram-like images and changes to them. like other computational visual analogy theories  ours represents images as networks of symbols. in privlan symbolic images are called simages  to differentiate them from bitmap images.
privels: primitive visual elements
each simage is composed of a collection of primitive visual elements  or privels. table 1 shows a list of some privels.
table 1privel nameattributesgeneric-visual-elementlocation  sizelinestart-point  end-point
thickness  locationcirclelocation  sizeboxlocation  height  width  orientation　objects in the domain  like the fortress  are associated with a privel type. each privel type has attributes associated with it. as shown in table 1  lines have a start-point  an end-point  a location and a thickness. these attributes are not stronglytyped. for example  the end-point of a line could be a location such as the  center  of the image or some component of the image  like the fortress.
privits: primitive visual transformations
privlan represents changes to images over time with an ordered series of simages in different states. each simage in the sequence is connected to any simages before and after it with primitive visual transformations  or privits. table 1 shows some examples of privits.
table 1privit nameargumentsmoveobject  new-locationdecomposeobject  number-of-resultantsput-betweenobject  first-object  second-objectadd-componentobject　each privit can take arguments. move  for example  takes some object that it is moving  and a new-location. it changes the object's value for the location attribute to the new-location.
　for example  imagine a circle moving from the top of the image to the bottom. privlan would represent this as a series of two simages. the first simage would contain a circle with location set to top. the second would be to have another circle  called  say  circle-1  represented whose location would be set to bottom. privlan knows these two simages are in a series because they are connected with a transform-connection  which in turn is associated with a series of correspondences between objects in the simages: there would be a map between the circle in the first simage and circle-1 in the second. this map between the circles would be associated with the move privit.
1	algorithm
the bottom series of simages in figure 1 shows a representation of the solved fortress problem analog. the bottom left simage is the initial state of the problem. the top series of simages shows the target analog  the tumor problem. the darkly shaded box shows the output of the system. the first simage is all that is input of the tumor problem.
　to make an analogical transfer  the source and target analogs must have an analogy between them. the analogy between the first tumor problem simage and the first fortress problem simage specifies maps between the components. to avoid over-complication of the figure  only one of these maps is shown  that between the left-road1 and left-body1.
　privits are transferred from the bottom series to the top: decompose and move.
　following is the control structure for our visual analogical transfer theory. we will describe the transfer of the first privit as a running example. the process in the abstract can be seen in figure 1.
1. identify the first simages of the target and analog problems.
1. identify the privits and associated arguments in the current simage of the source analog. this step finds out how the source problem gets from the current simage to the next simage. in our example  the privit is decompose  with  four  as the number-of-resultants argument  not shown .
1. identify the objects of the privits. the object of the privit is what object the privit acts on. for the decompose privit is the soldier-path1  the thick arrow in the bottom left simage. 
1. identify the corresponding objects in the target analog. the ray1  the thick arrow in the top left simage  is the corresponding component of the source analog's soldier-path1  as specified by the analogical map between the simages  not shown . a single object can be mapped to any number of other objects. if the object in question is mapped to more than one other object in the target  then the privit is applied to all of them in the next step. if the privit arguments are components of the
　
source analog problem

figure 1: the things outside the shaded box are given to galatea: a complete source problem an incomplete target problem  and the analogy between them. galatea completes the analogical transfer and stores the new simage sequence for the target problem.

figure 1: the fortress/tumor problem representation
　
source simage  then their analogs are found as well. else the arguments are transferred literally.
1. applythe privitwith the argumentstothe targetanalog component. a new simage is generated for the target problem  top middle  to record the effects of the privit. the decompose privit is applied to the ray1  with the argument  four.  the result can be seen in the top middle simage in figure 1. the new rays are created for this simage.
1. map the original objects to the new objects in the target problem. a transform-connection and mapping are created between the target problem simage and the new simage  not shown . maps are created between the corresponding objects. in this example it would mean a map between ray1 in the first top simage and the four rays in the second top simage. the privit is associated with the map  as shown in the figure  so the target problem itself can be used as a possible source analog in the future.
1. map the new objects of the target problem to the corresponding objects in the source problem. in this case the rays of the second target simage are mapped to soldier paths in the second source simage. this step is necessary for the later iterations  i.e. going on to another transformation and simage . otherwise the system would have no way of knowing which parts of the target simage the later privits would operate on.
1. check to see if goal conditions are satisfied. if they are  exit  and the problem is solved. if not  and there are further simages in the source series  set the current simage equal to the next simage and go to step 1. if there are no further simages  then exit and fail.
1	system: galatea
our hypothesis was that a visual representation language would be sufficient to describe domains such that analogical problem solving could take place. to test this hypothesis  we implemented the above ideas in a program called galatea  and applied it to duncker's fortress/tumor analogy.
　galatea's knowledge representation architecture consists of two kinds of propositions: 1. a statement of existence of a concept or relation and 1. the connection of two concepts or propositions with a relation.
　galatea takes as input a solved source problem  an unsolved target problem  both represented visually   an analogical mappings between the simages  and criteria for an adequate problem solution. when instructed to solve the target using the source  it analogically transfers the solution procedure. as can be seen in figure 1  it outputs a series of simages for the target problem  and checks to see if the solution transferred indeed solves the problem constraints. the following section describes our results.
duncker's fortress/tumor problem
table 1 shows some of the privels and their attribute values for the first fortress problem simage.
table 1: privels from fortress problem simage 1visual objectattributesvaluefortresslooks-like:generic-visual-elementlocation:centerbottom-roadlooks-like:linestart-point:bottomend-point:fortressright-roadlooks-like:linestart-point:rightend-point:fortressleft-roadlooks-like:linestart-point:leftend-point:fortresstop-roadlooks-like:linestart-point:topend-point:fortresssoldier-pathlooks-like:linelocation:bottom-roadthickness:thick　we represented the fortress story with three simages  see figure 1.  the first was a representation of the original fortress problem. it had four roads  represented as thick lines  radiating out from the fortress  which was a generic-visualelement in the center. we represented the original soldier path as a thick line on the bottom road. this simage was connected to the second with a decompose privit  where the arguments were soldier-path1 for the object and  four  for the number-of-resultants. the second simage shows the soldierpath1 decomposed into four thin lines  all still on the bottom road. the lines are thinner to represent smaller groups. this is connected to the final simage with the move privit  which is applied to three of the new soldier paths. they are sent to the different roads. the final simage in the fortress problem shows all four soldier paths  each on a different road.
　we represented the start state of the tumor problem as a single simage. the tumor itself is represented as a genericvisual-element. the ray of radiation is a thick line that passes through the bottom body part.
　galatea transfers the first transformation  decompose  from the source analog  the solved fortress problem  to the target  the tumor problem . it knows which part of the tumor problem to apply this privit to from the given analogical mapping between the first simages of the fortress and tumor problems. galatea generates a second simage with the line representing the ray decomposed into four thinner lines. in the next iteration galatea successfully transfers the second transformation  moving each of the rays to the different roads.
　galatea can solve analogical transfer problems using only visual knowledge  as we have shown with the fortress/radiation example. though this work is still in progress  we conjecture that this theory  when privlan is more fleshed out  will apply to all problems whose solution constraints involve visually perceivable states of the world. another sense of this is: if you can make a diagram of it  our theory applies to it.
1	causal knowledge
though the solution procedure was transferred in both of these cases  the system still had no way of knowing if the transferred solution was adequate for the new problem. in the tumor problem  in order for the agent to determine if the tumor was destroyed and the patient was still alive  it needed some causal knowledge. by causal we mean knowledge of how things in a system change as they interact. pre- and postconditions are a straightforward way to represent this  but it is difficult to imagine what  visual  pre- and post-conditions might look like. visual representations alone cannot enable evaluation of the solution.
　galatea represents causal knowledge with production rules  implemented in act-r  anderson and libiere  1 . we have no theoretical commitment to production rules or act-r. one production rule identifies a body part as dead if there is a thick line representing a ray going through it. another rule identifies the tumor being killed if enough radiation is hitting it. if the tumor is dead and the body is alive  a final production fires that identifies the problem as being solved.
　when the tumor problem is first encountered  when it only consists of a single simage   galatea is unable to infer through the productions that the problem is solved in the initial state. when the solution is transferred from the fortress  the rules confirm that the problem has been solved.
1	discussion
in our earlier work  we have developed a theory of modelbased analogy based on structure-behavior-function models of causal mechanisms and physical systems. the ideal system  bhatta and goel  1   for example  transfers generic teleological mechanisms from a source analog to a target problem to address novel design problems. the torque system  griffith et al.  1  uses generic structural transformations to mutate a target problem or a source analog to construct analogies. galatea builds on the above theory of model-based analogy in that in it too relies on the core idea of generic transformations. thus  while the analogical process in galatea is similar to that in ideal  the content of its generic transformations is visual as opposed to teleological or structural. torque's structural knowledge captures only a small subset of visual knowledge. in contrast galatea has information about the location and appearance of objects in a particular simage: the fortress is not just connected to the road  it is in the center of the simage; the path is not just on the road  it is a thick line. these additional features enable the initial analogical mapping between simages without causal knowledge because the simages representing the two analogs are similar when described visually.
　like galatea  letterspirit is a model of analogical transfer  mcgraw and hofstadter  1 . it takes a stylized seed letter as input and outputs an entire font that has the same style. it does this by determining what letter is presented  determining how the components are drawn  and then drawing the same components of other letters the same way. like galatea  the analogies between letters are already in the system: the vertical bar part of the letter  d  maps to the vertical bar in the letter  b   for example. a mapping is created for the input character. for example  the seed letter may be interpreted as an  f  with the cross-bar suppressed. when the system makes a lower-case  t   by analogy  it suppresses the crossbar.
　it is not at all clear that letterspirit is applicable to other domains  such as the fortress/tumor problem  in part because there is little distinction between its theory and the implementation that works for letters. in contrast  one can see how galatea might be applied to the font domain: the stylistic guidelines in letterspirit  such as  crossbar suppressed  are like the visual transformations in galatea: it would be a transformation of removing an element from the image  where that element was the crossbar and the image was a prototype letter  f.  then the transformation could be applied to the other letters one by one. we conjecture that our theory has more generality than letterspirit.
　galatea does not generate the analogical mapping  but other systems  that create mappings with visual information  have shown that it can be done. the vamp systems are analogical mappers as well  thagard et al.  1 . vamp.1 uses a hierarchically organized symbol/pixel representation. it superimposes two images  and reports which components have overlapping pixels. vamp.1 represented images as agents with local knowledge. mapping is done using acme/arcs  holyoak and thagard  1   a constraint satisfaction connectionist network. the radiation problem mapping was one of the examples to which vamp.1 was applied.
　the structure mapping engine  or sme  falkenhainer et al.  1  finds the best mapping of elements between two domains. but sme typically is applied to instances where the situations are represented as having causal and structural knowledge. sme has been applied to visual knowledge in a system called magi  ferguson  1   which takes visual representations and uses sme to find examples of symmetry and repetition in a single image.
　like galatea  magi and the vamps use visual knowledge. but unlike galatea their focus is on the creation of the mapping rather than on transfer of a solution procedure. magi's and galatea's theories are compatible: a magi-like system might be used to create the mappings that galatea uses to transfer knowledge. the theory behind the vamps is incompatible because they use a different level of representation for the images.
　galatea has also been applied to the case study of james clerk maxwell's creation of his electro magnetic theory. according to nersessian's cognitive-historical analysis  nersessian  1   maxwell used analogical transfer to resolve a problem with his mental model of electro-magnetism. the transfer was mediated by a generic abstraction  and the abstraction was created  retrieved  and instantiated using visual representations and reasoning.
　galatea so far has been substantiated for only two examples: duncker's fortress/tumor problem and maxwell's case study. in the future  we will extend galatea to cover many more problems  and expand it to use  in addition to simages  bitmap images  which we believe will be important for changing representations when symbol mismatches make analogical mapping difficult.
1	conclusion
the first finding of our experiments with galatea is that visual knowledge alone  with no explicit representation of causal knowledge  is sufficient for enabling analogical transfer. this validates the central hypothesis of our work. galatea suggests a computational model of analogy based on dynamic visual knowledge that complements traditional models based on causal knowledge. although galatea does not address the issues of retrieval and mapping  put together with other work described in the previous section  we can now more confidently conjecture that visual knowledge alone can enable retrieval  mapping and transfer in analogy.
　a second finding of our work on galatea is that evaluation  in general  cannot be done using visual knowledge alone; it requires causal knowledge too. thus visual knowledge enables only the steps that depend directly on the visual similarity between the target problem and the source analog  e.g.  retrieval  mapping and transfer. it does not  however  fully support the evaluation step because it depends not on similarity but on the intrinsic causal and teleological structure of the target problem.
　galatea represents visual knowledge symbolically  in the form of symbolic images made of primitive visual elements and primitive visual transformations. the symbolic representation provides the standard benefits of discreteness  abstraction  ordering  and composition. although sequences of lower-level bitmap representations also capture the notion of ordering  they  by themselves  neither capture abstractions that enable noticing visual similarity nor enable transformations on the images. this leads us to a third finding: galatea provides additional evidence that symbolic representations of visual images are necessary for analogy.
1	acknowledgements
this work has benefitted from many discussions with nancy j. nersessian at the georgia institute of technology. this research has been inspired in part by the work of b. chandrasekaran at the ohio state university and lawrence barsalou at emory university in addition to that of nersessian. goel also benefited from discussions with david waltz at neci during his 1 sabbatical.
references
 anderson and libiere  1  john r. anderson and christian libiere. the atomic components of thought. lawrence erlbaum associates  1.
 bhatta and goel  1  sambasiva r. bhatta and ashok k. goel. a functional theory of design patterns. in proceedings of fifteenth international joint conference on artificial intelligence  pages 1  nagoya  japan  august 1.
 duncker  1  k. duncker  1 . a qualitative  experimental and theoretical  study of productive thinking  solving of comprehensible problems . journal of genetic psychology  1-1  1.
 falkenhainer et al.  1  brian falkenhainer  kenneth d. forbus  and dedre gentner. the structure mapping engine: algorithm and examples. artificial intelligence  1  1.
 ferguson  1  ronald w. ferguson. magi: analogybased encoding using regularity and symmetry. in proceedings of the sixteenth annual conference of the cognitive science society pages 1. atlanta  georgia: lawrence erlbaum associates  1.
 griffith et al.  1  todd w. griffith  nancy j. nersessian and ashok k. goel. function-follows-form transformations in scientific problem solving. in proceedings of the twenty-second annual conference of the cognitive science society. lawrence erlbaum associates  mahwah  new jersey  1.
 holyoak and thagard  1  keith j. holyoak and paul thagard. the analogical mind. american psychologist  1 :1  1.
 kosslyn  1  kosslyn  s. m. image and brain: the resolution of the imagery debate. mit press  cambridge  ma  1.
 mcgraw and hofstadter  1  g. mcgraw and douglas r. hofstadter. perception and creation of alphabetic style. in artificial intelligence and creativity: papers from the 1 spring symposium  aaai technical report ss-1  aaai press  1.
 nersessian  1  nersessian  n. j. opening the black box: cognitive science and the history of science. in thackray  a.  ed.  constructing knowledge in the history of science. osiris 1  1.
 pedone et al.  1  r. pedone  john e. hummel  and keith j. holyoak. the use of diagrams in analogical problem solving. manuscript draft  1.
 thagard et al.  1  paul thagard  d. gochfeld  and s. hardy. visual analogical mapping. in proceedings of the 1th annual conference of the cognitive science society  pages 1  hillsdale  erlbaum  1.
　
cognitive modeling
cognitive modeling - categorization

reasoning about categories in conceptual spaces
　
peter gardenfors：
lund university cognitive science
lund university
s-1 lund  sweden
peter.gardenfors lucs.lu.se mary-anne williams
business and technology research lab
university of newcastle
nsw 1  australia maryanne cafe.newcastle.edu.au
　
abstract
understanding the process of categorization is a primary research goal in artificial intelligence. the conceptual space framework provides a flexible approach to modeling context-sensitive categorization via a geometrical representation designed for modeling and managing concepts.
in this paper we show how algorithms developed in computational geometry  and the region connection calculus can be used to model important aspects of categorization in conceptual spaces. in particular  we demonstrate the feasibility of using existing geometric algorithms to build and manage categories in conceptual spaces  and we show how the region connection calculus can be used to reason about categories and other conceptual regions.
1	introduction
categorization is a fundamental cognitive activity. the ability to classify and identify objects with a high degree of exception tolerance is a hallmark of intelligence  and an essential skill for learning and communication. understanding the processes involved in constructing categories is a primary research goal in artificial intelligence.
　the conceptual space framework as developed by gardenfors  provides a flexible approach to model-： ing context-sensitive categorization. conceptual spaces are based on a simple  yet powerful  geometrical representation designed for modeling and managing concepts.
　in this paper we show how algorithms developed in computational geometry  and the region connection calculus  rcc   cohn et al.  1   a well known region-based spatial reasoning framework  can be used to model important aspects of categorization in conceptual spaces. in particular  we demonstrate the feasibility of using existing geometric algorithms to build and manage categories in conceptual spaces  and we show how the rcc can be used to reason about categories and other conceptual regions.
1	conceptual spaces
conceptual spaces provide a framework for modeling the formation and the evolution of concepts. they can be used to explain psychological phenomena  and to design intelligent agents  chella et al.  1; gardenfors  1 . for the pur-： poses of this paper conceptual spaces provide the necessary infrastructure for modeling the process of categorization.
　conceptual spaces are geometrical structures based on quality dimensions. quality dimensions correspond to the ways in which stimuli are judged to be similar or different. judgments of similarity and difference typically generate an ordering relation of stimuli  e.g. judgments of pitch generate a natural ordering from  low  to  high   gardenfors ： 1 . there have been extensive studies conducted over the years that have explored psychological similarity judgments by exposing human subjects to various physical stimuli. multi-dimensional scaling is a standard technique that can be used to transform similarity judgments into a conceptual space  krusal and wish  1 . an interesting line of inquiry is pursued by balkenius  who attempts to explain how quality dimensions in conceptual spaces could accrue from psychobiological activity in the brain.
　in conceptual spaces objects are characterized by a set of attributes or qualities {q1 q1 ... qn}. each quality qi takes values in a domain qi. for example  the quality of pitch  or frequency  for musical tones could take values in the domain of positive real numbers. objects are identified with points in the conceptual space c = q1 x q1 x ...qn  and concepts are regions in conceptual space.
　in the definition above we use the standard mathematical interpretation of  domain . in  gardenfors  1  however ： a domain is defined to be a set of integral dimensions  this interpretation is consistent with its use in the psychology literature. for example  pitch and volume constitute the integral dimensions of sounds discernible by the human auditory perception system. integral dimensions are such that they cannot be separated in the perceptual sense. the ability to bundle up integral dimensions as a domain is an important part of the conceptual spaces framework. domains facilitate the sharing and inheritance of integral dimensions across conceptual spaces.
　for the purpose of this paper  and without loss of generality  we often identify a conceptual space c with rn  but hasten to note that conceptual spaces do not require the full richness of rn. domains can be continuous or discrete1. they can also be based on a wide range of geometrical structures  for example  according to psychological evidence the human colour perception system is best represented using polar coordinates1  gardenfors  1 .：
　for the purpose of problem solving  learning and communication  agents adopt a range of conceptualizations using different conceptual spaces depending on the cognitive task at hand.
　similarity relations are fundamental to conceptual spaces. they capture information about the similarity judgments. in order to model some similarity relations we can endow a conceptual space with a distance measure.
definition 1 a distance measure d is a function from c x c into t where c is a conceptual space and t is a totally ordered set.
　distance measures lead to a natural model of similarity; the smaller the distance between two objects in conceptual space  the more similar they are. the relationship between distance and similarity need not be linear  e.g. similarity may decay exponentially with distance.
　the properties of connectedness  star-shapedness and convexity of regions in conceptual spaces will prove useful throughout.
definition 1 a subset c of a conceptual space is:
 i  connected if for every decomposition into the sum of two nonempty sets c = c1 “ c1  we have c．1 ” c1 “ c1 ”
c．1=   where c． is the closure of c. in other words  c is connected if it is not the disjoint union of two non-empty closed sets.
 ii  star-shaped with respect to a point p  referred to as a kernel point  if  for all points x in c  all points between x and p are also in c.
 iii  convex if  for all points x and y in c  all points between x and y are also in c.
definition 1 the kernel of a star-shaped region c is the set of all possible kernel points  and will be denoted kernel c .
　connectedness is a topological notion  whilst starshapedness and convexity rely only on a betweenness relation. a qualitative betweenness relation can be specified in terms of a similarity relation  s a b c   which says that a is more similar b than it is to c. alternatively  a betweenness relation can be used as primitive  and axioms introduced to govern its behaviour  borsuk and szmielew  1 . in the special case where the distance measure is a metric  the betweenness relation can be defined as:  b is between a and c  if and only if d a b + d b c  = d a c .
　convex regions are star-shaped  and in many topological settings star-shaped regions are connected. the kernel of a convex region is the region itself  and under the euclidean metric kernels are convex.
　constraints like connectedness  star-shapedness and convexity can be used to impose ontological structure on the categorization of the conceptual space  i.e. not any old region can serve as a category. in fact  there is compelling evidence that natural properties correspond to convex regions in conceptual space  and using the idea of a natural property in this way gardenfors  is able to sidestep the enigmatic prob-： lems associated with induction.
　in section 1 we show how categorization  the central theme of this paper  occurs in conceptual spaces  but first we briefly describe the rcc.
1	region connection calculus
the rcc is a qualitative approach to spatial reasoning. it was developed in an attempt to build a commonsense reasoning model for space  and its remarkable utility has been illustrated in numerous innovative applications  cohn et al.  1 .
　the rcc approach is region-based where spatial regions are identified with their closures. the rcc is based on a connection relation  c x y    which stands for  region x connects with region y  . the connection relation  c  is reflexive and symmetric. despite the fact that the basic building blocks in the rcc are regions  c can be given a topological interpretation  namely c x y   holds when the topological closures of regions x and y share at least one point.
　the rcc framework comprises several families of binary topological relations. one family  the rcc1 fragment uses the following jointly exhaustive and pairwise disjoint base relations to describe the relationship between two regions  see figure 1 ; dr  discrete   eq  identical   pp  proper part   pp 1 inverse pp   and po  partial overlap .

figure 1: the base relations in rcc1.
　boundaries of regions are not distinguished in rcc1; there is no difference between two regions being totally disconnected and externally connected  and no difference between a proper part tangentially connected to the boundary and a proper part disconnected from the boundary. another fragment  rcc1  possesses base relations that can make these distinctions.
　in this paper our interests lie in similarity based categorization  and we use rcc1 to illustrate how the rcc can be used to represent conceptual regions. extending to a more expressive mereotopological language to reason about the adjacency of categories  for example  is straightforward  and it can be done at no extra computational cost.
transition tables can be used to perform reasoning about
relationships between regions in rcc1 and rcc1. it is known that there is no complete first order finite axiomatization of topology. nebel  showed that propositional reasoning in rcc1 and rcc1 is np-hard  and renz and nebel  identified a maximal tractable subset of relations that contain all the base relations. efficient implementations in prolog have been constructed using a zero-order intuitionistic logic  bennett  1 .
　the rcc can be used to represent spatial regions and to reason about them in any dimension  provided that all spatial entities possess precisely the same number of dimensions. it can also represent regions composed of multiple  spatially distinct  parts  but it cannot represent null regions.
　in this paper we use the rcc to reason about spatial relationships between conceptual regions  and to model the indeterminacy of conceptual regions. the original formulation of the rcc concerned regions with crisp well-defined boundaries  but later cohn and gotts  extended the rcc to handle indeterminate vague regions that could be  crisped  into less vague regions. we describe this crisping relation in more detail in section 1.
1	categorization in conceptual spaces
1	prototypes and categorical perception
a categorization results in a partitioning of a conceptual space into  meaningful  subregions. the geometrical nature of conceptual spaces coupled with representations for prototypes and the ability to manipulate dimensions independently of one another ensures that they provide a highly flexible and practical representation of context-sensitive categorization.
　within each category certain members are judged to be more representative than others  rosch  1 . the most representative members of a category are prototypes. there is a wealth of psychological data supporting the existence of prototypes and their key role in categorization. typically human performance experiments are used to determine how well  and how quickly humans can classify  label  rank or compare objects. experimental results consistently show that the ease of classification varies with how similar an object is to a prototype. furthermore  the more similar a nonmember is to the prototype  the more difficult it is to exclude. it has been shown  for example  that the reaction time recognizing that a robin is a bird is shorter than identifying a penguin as a bird regardless of whether the stimulus is the name or an image.
　it is evident from experiments that humans make judgments about the degree of resemblance to a prototype during classification and identification; a robin is judged as a more prototypical bird than a penguin  harnad  1 . a prototype consists of features of either a typical  or ideal category member  rather than invariant features common to every member. for example  a prototype of a category can be thought of as an amalgam of the characteristic attributes of its category's exemplars1.
　classifying an object using prototypes is accomplished by determining its similarity to a prototype. instances above some threshold of similarity to the prototype are taken as category members  all other instances are nonmembers.
　prototypes are central to the representation and processing of categories. people classify  generate  acquire  and reason about typical exemplars faster and more accurately than atypical exemplars. they also produce stronger inductive inferences with typical exemplars than with atypical exemplars  hampton  1 .
　it is widely accepted on the basis of empirical psychological experiments that people sometimes judge membership of categories as graded. the existence of graded concepts supports the notion of continuous perception. the gradedness of category membership can be used to determine how closely an object resembles a prototype and can naturally be determined from the underlying similarity judgments.
　psychological evidence also suggests that people distinguish stimuli along a physical continuum much better when the stimuli are from different categories than when they are from the same category. this phenomenon is called categorical perception  harnad  1   and is manifested in the ability to discriminate stimuli with more ease and accuracy between categories than within them. when categorical perception is at work  stimuli related to a specific category are perceived as indistinguishable  whereas stimuli from a  nearby category are perceived to be entirely different. this phenomenon has been found in the way humans process sounds in speech. in color perception  for example  different shades of green are perceived to be more similar than green and yellow even though the wavelength differences are no larger. in other words  the psychophysical relationship between the physical intensity of a stimulus and the psychological intensity of the ensuing sensation is related to the categorization. categorical perception has also be found in primates  other than humans  may et al.  1 .
　it is also well known that similarity judgments crucially depend on the context in which they occur for both continuous and categorical perception. it turns that certain features of objects and concepts are more salient for a particular categorization  for both classification and identification  depending on the context. the classic example is that a robin is a prototypical bird  but a canary is a prototypical pet bird.
　in summary the key findings from psychological studies of categorization are  i  similarity judgments play a fundamental role in categorization and they are context sensitive   ii  the degree of similarity is judged with respect to a reference object/region such as a prototype   iii  category membership can be graded  discrete membership  if and when it exists  is considered to be a special case   and  iv  the psychophysical relationship between the stimulus and the response depends on the underlying categorization.
1	a mechanism for building categories
in this section results in computational geometry are applied to categorization in conceptual spaces. we provide computational evidence for categorization based on prototypes  rather than appealing to the usual intuitive arguments found in the psychology literature derived from facts like the presentation of prototypes enhances learning. it can be shown  for example  that the conceptual space model predicts that it is easier to learn categories in which the natural prototype is central to a set of variations than it is to learn categories in which the prototype occurs as a peripheral member  as observed by rosch .
　the main idea is that voronoi tessellations around prototypes can be used to determine the threshold of similarity that forms category boundaries. in other words  the prototypes and the underlying similarity relation can be used to tessellate a conceptual space into categories.
definition 1 a voronoi tessellation in conceptual space is given by the triple   p d c  where p is a set of distinct generator points {p1 p1 ... pm}  d is a distance measure on c a conceptual space. we define the tessellated regions c pi  to be {x|d pi x  ＋ d pj x  for j = 1 ... m}  and we call c pi  the category generated by pi.
　a voronoi tessellation divides a conceptual space according to the nearest-neighbor rule which says each point/object in the space is associated with the prototype closest to it. this results in prototypes being centrally located in their category. the euclidean metric is a basic distance measure: the euclidean distance d x p  between two points x =  x1 x1 ... xn  and p =  p1 p1 ... pn  in rn is calculated as. if the underlying distance measure is the euclidean metric  then the resultant categories c pi   are convex  and hence star-shaped with respect to pi. if the distance measure is the manhattan or the supremum metric  then the generated categories are not necessarily convex  but are star-shaped with respect to pi. in fact  it can be shown that if x is between y and pi is defined as d pi x +d x y  = d pi y  and the distance measure satisfies the triangle inequality  then the generated categories are star-shaped with respect to pi.
　star-shapedness with respect to a prototype p is a desirable property for categories: if a category c p  is not star-shaped with respect to p  then there is an object x that is between p and some y （ c p  but x 1（ c p .
definition 1 a well behaved categorization in conceptual space produces regions which are star-shaped with respect to their prototype region and contain their central prototype.
　a voronoi tessellation encapsulates the entire proximity information about the set of prototypes in a computationally compact fashion. voronoi diagrams in the plane can be computed in o n log n  worst-case optimal time using o n  space  okabe et al  1   and in d-dimensions for d   1 in o ndd/1e  worst-case optimal time  klee  1 .
　once constructed voronoi tessellations can be used to:  i  identify the category of arbitrary objects in logarithmic query time without increasing the storage space - this is asymptotically optimal since it matches the information theoretical lower bound  auberhammer  1   and  ii  compute the smallest enclosing sphere containing n prototype points in o n log n  worst-case optimal time  auberhammer  1 . furthermore  a prototype can be added or deleted to a voronoi tessellation in o n  time  and two voronoi tessellations can be merged in o n  time.
　it is interesting to note that classical techniques and algorithms for information retrieval and cluster analysis are related to voronoi tessellations. in fact  voronoi tessellations have been used to construct robust approximate solutions to well known np-complete information retrieval problems  i.e. acceptable approximate solutions can be found in o n log n  time  okabe et al  1 .
　much experimental psychological data concords with the idea of tessellating conceptual spaces into star-shaped  and sometimes convex  regions around prototypes or exemplars  e.g. stop consonants in phoneme classification  petitot 
1   other examples can be found in  gardenfors  1 .：
　not only do voronoi tessellations generated by prototypes support the prototype model of categorization  but the generated boundaries provide a threshold of similarity and support a mechanism which can explain categorical perception. the precise mechanism involves crisping the distance measure and is described in section 1.
1	generalized voronoi tessellations
in this section we discuss some useful extensions of the basic voronoi tessellation model. ordinary voronoi tessellations give rise to ideal categorizations  in the sense that crisp boundaries are generated from a single prototype. we generalize the definition so as to generate categories from conceptual regions rather than specific prototype points.
definition 1 a generalized voronoi tessellation is given by the triple   p d c  where p is a set of generator regions {p1 p1 ... pm}  d is a distance measure on c a conceptual space. we define the tessellated regions c pi  to be {x|d pi x  ＋ d pj x  for j = 1 ... m}  and we call c pi  the category generated by the region pi.
　we contrast two distance measures for generalized voronoi categorizations; the additively weighted distance and the power distance1. the additively weighted voronoi diagram is typically used to model the growth of biological cells  and can be used to model the growth of concepts also. the power distance  on the other hand  is best suited to handle indeterminacy and exemplar variability.
　an additively weighted distance between a point x and a sphere p （ p in rn with weight w p   denoted d x p   is defined as d x p    w p   where d x p  is the euclidean distance between x and p the center of p. a common way to define the additively weighted distance between a point x and a sphere p is to take w p  as the radius rp of p  i.e. d x p  = d x p    rp  which can naturally be interpreted as the shortest distance between the point x and the surface of the sphere p  see figure 1 a . the resulting tessellation is called the euclidean weighted voronoi diagram. a point x lies on or inside the sphere p if and only if d x p  ＋ 1. okabe et al.  proved that the bisector of a euclidean weighted voronoi diagram is either a hyperbolic surface or a hyperplane  and that the generated regions are connected and star-shaped with respect to its generator sphere in rn. this result also holds for the manhattan and the supremum metrics.
　one way to obtain convex regions  with straight line bisectors  is to use the power distance  also known as the laguerreq
distance : d x p  = d x p 1   rp1. when x is outside the sphere p centered on p the distance from p to x is given by the length of the tangent from p to x. the power distance and power bisector are illustrated in figure 1 b  and  c   respectively.
　the size of a particular prototype's radius relative to the surrounding prototype regions reflects its ability to influence its neighborhood. the magnitude of the radius can be related to the actual size of the category  the variability among the exemplars1  or the correlation of qualities.
definition 1 we define a power categorization to be a generalized voronoi tessellation   p d c  generated by a set of prototype regions p using the power distance.
　if the radii of the generator spheres are zero or equal in size  then the power categorization will be equivalent to the categorization based in the ordinary  point-based  euclidean voronoi tessellation.

figure 1: the euclidean and the power distance measures.
　the worst-case time complexity for the construction of the power categorization is no worse than that for the ordinary voronoi diagram. sometimes the structure of the space can be exploited  which means that the actual computational time can be dramatically lowered. voronoi tessellations are used in a wide range of applications and domain constraints can be used to improve algorithms  typically linear time can be expected  e.g. linear time can be expected if the generating spheres/points are uniformly distributed  dwyer  1 . parallel algorithms have also been developed  auberhammer 1  which construct voronoi diagrams in o log n  time using o n  processors.
　it turns out that for power categorizations  if a generator sphere p1 is a proper part of another generator sphere p1 then the generated category c p1  will not contain the center of the generator region p1  and a well-behaved categorization will not be produced. for example  using the generic bird and the robin prototype regions in figure 1 to generate a power categorization would not result in a well behaved categorization; since pp robin bird   it turns out that robin 1（ c robin  in the power categorization.
　rcc1 can be used to ensure that generating spheres are not proper parts of other generating spheres  and hence can play a role in the categorization process itself  by determining the legitimate spheres to use as generators.
　finally  we define the notion of a bounded tessellation which provides a useful mechanism for selecting conceptual regions to focus on for conceptual spatial reasoning and categorization.
definition 1 given a generalized voronoi tessellation   p d c  where the categories are generated by p = {p1 p1 ... pn} define the voronoi tessellation bounded by a region s  denoted by c”s  to be {c p1 ”s c p1 ”s ... c pn ”s}. we denote the bounded categories c pi  ” s by c”s pi .
　a bounded voronoi diagram may be disconnected if every boundary region is not star-shaped with respect to its generator point  okabe et al.  1 .
1	reasoning about categories
concept management involves categorization  concept acquisition  concept formation and conceptual change. cognitive processes such as learning and communication impel and guide concept management. in the previous section we showed how conceptual spaces provide a rich and computationally effective representation for categorization based on prototype regions  and in this section we show that the rcc machinery can be used to reason about categories and to describe other aspects of concept management.
1	determining spatial relationships
the rcc can be used to determine the relative configuration of conceptual regions such as categories  concepts  prototypes  and exemplars. for example we can determine:  i  if the smallest region containing all the prototypes is a proper part of a given category   ii  if some category overlaps another category e.g. pp c robin  c bird     iii  if the region containing all the prototypes contains all the exemplars  and  iv  if a category's kernel contains a specific region.
　as an example let us consider the conceptual spaces described in figure 1  below.

figure 1: prototype regions in animal space  reptile crispings  & the power categorization of bird  mammal &reptile.
using rcc1 we can describe the following spatial relationships:
dr bird penguin   pp robin bird  
po c robin  bird   po c robin  kernel c bird    
po archaeopteryx c reptile   
po archaeopteryx c bird   
dr c archaeopteryx  c mammal   
dr emu penguin  
dr c archaeopteryx  c mammal   
dr c robin  c bat    and dr c robin  c platypus  
　the rcc  including the egg-yolk theory  allows disconnected regions  i.e. multi-pieced regions  so it supports the construction of arbitrarily complex concepts. for conceptual spaces that means one can juxtapose disconnected concepts to form eclectic ones  e.g. penguins and emus  nonflying birds   and build new concepts from existing ones. within a single category the set of prototypes would in some applications be better modeled by a multi-pieced region rather than as a connected region such as the smallest surrounding sphere  or convex hull. in section 1 we show that being able to model multi-pieced regions is important to support nonmonotonic reasoning.
　for some applications it will be necessary to impose various ontological constraints on interrelated categories. in particular  it may be important to enforce consistency across the different levels of granularity so that the tessellated regions at one level are identical to the union of tessellated regionss at lower levels: c p  = s c p  c s  where s are subcategories of c p . this constraint is present in many software engineering applications  and made explicit in data modeling techiques. one way to model this constraint in a computationally efficient manner  without distorting the underlying similarity relation  is to bound tessellations within categories. it is important to note here that   p d c”s  is not identical to   p d s  in general  so bounding a conceptual space before or after the tessellation can  and typically will  result in a different categorization. for example  if the conceptual space parameters remain fixed then it would seem reasonable that the bird category region be the same regardless of whether the generator is the prototypical bird or the set of all prototypical birds at a lower level of granularity. in figure 1 c bird  can be tessellated independently of c reptile  and c mammal   so that c bird  = c robin  “ c penguin  “ c emu  “  c”c bird  archaeopteryx  . in other words  the generated subcategories of c bird  are bounded by c bird .
　other applications may possess weaker ontological requirements such as: if the prototype region p1 is a subregion of the prototype region p1 then c p1    c p1 . this condition also places constraints on the way that a voronoi tessellation can be generated across the levels of granularity  and is satisfied by robins and birds in figure 1.
1	crisping conceptual spaces
as noted in section 1 the rcc was extended by introducing an irreflexive  asymmetric and transitive binary relation x   y read as  x is crisper than y    or  y is a blurring of x . cohn and gotts also developed what has become known as the  egg-yolk theory for modeling indeterminate spatial regions. an egg is composed of two regions with definite boundaries; the yolk being a proper part of the egg. the egg and its yolk define the upper and lower bounds  respectively  on the range of indeterminacy of the region.
　in this section we show how the crisper relation   can be defined and the egg-yolk representation can be used to reason about categories and other conceptual regions.
　a crisper relation in conceptual space can be constructed in a multitude of ways. one straightforward method is to use the proper part relation  pp  i.e. x   y if and only if pp x y  . figure 1 also illustrates some potential crispings of the reptile category; a set of concentric spheres bounded by c bird  and c mammal . these crispings could be generated in numerous ways  e.g. using prespecified degradations in the distance measure  or by using the exemplars where each successive blurring captures another exemplar.
　given a conceptual space and a crisper relation we can build a vast range of useful queries using the rcc such as  does a conceptual region constitute a crisping/blurring of another region    does crisping a particular domain change the classification of a specific object     does every category contain its prototype crisping   and so forth.
　as an example let us consider the conceptual space in figure 1 where the crisper relation is based on pp. we have the following:
penguin   c penguin    kernel c bird   = c bird  robin   bird and robin   c robin    c bird  emu   c emu    c bird  bat   c bat    c mammal  platypus   c platypus    c mammal 
　other relations describing the relationships between indeterminate regions can be constructed from the crisper relation   such as crisp x  which is defined as  there does not exist a y such that y   x   and ma x y   which holds when x and y are mutually approximate  i.e. they possess a common crisping  cohn et al.  1 . from the conceptual space in figure 1 we can say:
crisp robin   crisp mammal  
crisp archaeopteryx ” c bird    crisp penguin  
 crisp bird   crisp kernel bird    crisp c reptile   
ma c penguin  c bird    ma robin bird   ma archaeopteryx c bird   
ma archaeopteryx c reptile   
　the rcc framework provides a number of axioms that govern the crisping relation in different kinds of applications. for example  there are axioms that ensure the existence of a complete crisping of any region  and the existence of alternative crispings and blurrings.
　crispings can play a role in the process of categorization itself; they can define regions to be used to generate tessellations. for example  in figure 1  below  the bisector shifts towards the sphere p1 with center p1 and radius r if p1 is crisped to a smaller sphere with radius r1. this crisping can be modeled precisely; the bisector between p1 and pi moves by distance  r   r1 /1d p1 pi  towards p1 in parallel to its previous location. so it is easy to show that p1   p1 if and only if  i.e. a local crisping  blurring  of a prototype region crisps  blurs  its category  and conversely.
　in well behaved categorizations one can construct an egg yolk system using the kernel of each category. the yolk of the prototype region p1 can be given by the largest sphere enclosed by kernel c p1    say protoyolk  and the egg can be given by the smallest sphere circumscribing kernel c p1    say protoegg. this egg-yolk prototype system can then be used to generate the corresponding egg-yolk category system: c protoyolk  and c protoegg .
　finally we extend the notion of crisping to distance measures to capture categorical perception; the observed phenom-

figure 1: crisping a prototype crisps the category.
ena where category members are judged to be more similar than members and nonmembers immediately across category boundaries. for example  the distance measure d1 is a crisping of distance measure d where
1
	d1 a b  =	dk  ad  ba  botherwise   if a b （ c p  for some p
for some 1 ＋ k   1.
　in the limit we have d1 a b  is 1 if a and b are in the same category and d a b  otherwise. categorical perception  and hence crisping a distance measure  represents a form of learning. our definition can be extended in numerous ways and the similarity relation derived from a crisped distance measure can easily be given a wide variety of threshold behaviours.
1	nonmonotonicity and concept management
in this section we highlight the nonmonotonic effects of changing context  and show how conceptual spaces can be used as an underlying model from which more traditional nonmonotonic reasoning formalisms can be derived.
　nonmonotonic changes to the categorization can arise in several ways:  i  by focusing on a region   ii  by modifying the underlying conceptual space  or  iii  by changing the mapping of objects to conceptual regions.
focusing on a region
focusing can be accomplished by changing the dimension weights  by crisping a region  bounding a region  or combining regions.
　as noted earlier categorization is context-sensitive. in conceptual spaces context-dependence is modeled using weighted dimensions. for example  weighting the distance measure along the x-axis results in a different categorization via the voronoi tessellation such that objects change categories. technically this is achieved by multiplying the specific dimensions by a given weight where the weight reflects its salience. for instance  under the euclidean metric a weightpp
can be placed on dimension i as follows:	i wi xi   pi 1.
weighting specific dimensions gives rise to a nonmonotonic crisping relation where x   y does not imply pp x y  ; some regions will contract in size others will dilate. in figure 1  below  the quality dimension represented by the x-axis in  a  becomes more salient and is elongated causing the object  q  to be reclassified in  b .

figure 1: changed categorization due to a change in context.
modifying the underlying conceptual space
the underlying conceptual space can be modified by adding and deleting exemplars or prototypes  changing the distance measure  changing the function relating the distance measure to similarity  or changing the generator prototype regions.
　the introduction of exemplars and/or prototypes will shift the boundaries and create new categorical regions  gardenfors  1 . as noted earlier the addition and removal： of prototypes is a fundamental concept management operation  and can be achieved in linear time in the worst case.
　changing the underlying distance measure or generating regions will shift boundaries. merely crisping the distance measure or modifying the function relating the distance measure to similarity will not change the underlying categorization  but will affect the magnitude of the similarity judgments.
changing the mapping of objects to regions
nonmonotonic reasoning formalisms are typically logic based  and hence symbolic systems. the conceptual space framework can be used to model nonmonotonic information  and used to construct nonmonotonic inference rules via the rcc. since the conceptual space model is based on the measure of similarity to prototypes the rcc's crisper relation can be used to build representations of minimal models or usual states of affairs.
　just as specific individual objects are points in conceptual space  generic  or under specified  objects are  possibly disconnected  regions. one might expect that the more generic or the more unspecified an object  the larger the region used to represent it.
　the generic bird  tweety  would be represented as a central region in bird space  e.g. the prototype bird region. in which case we would expect tweety to possess all the features common to birds in that region; we expect tweety to possess feathers  two legs  wings for flight  a four chambered heart  and so forth. as we learn more about tweety we adjust the target region used to represent him. if we learn he is a robin  then he could be remapped to the robin prototype. on the other hand  if we learn that he is a nonflying bird  then we may remap him to the prototype penguin region and the prototype emu region which in the example in figure 1 is a disconnected region  and we still expect tweety to have feathers  two legs  and a four chambered heart.
the rcc can represent conceptual regions which are required to support all concept management for nonmonotonic reasoning as described above  and as such it forms a natural bridge from the geometrical conceptual space representation to the symbolic representation in standard nonmonotonic formalisms.
1	conclusion
we showed how algorithms in computational geometry and the rcc can be applied to the conceptual space framework. categorization in conceptual spaces is achieved via  generalized  voronoi tessellations based on a similarity relation which results in a prototype being centrally located in its category. an analysis of existing algorithms in computational geometry established that categorization based on an underlying similarity relation which is used to generate voronoi diagrams is feasible. furthermore  once a categorization is completed concept management tasks like determining the category of an arbitrary object  adding and deleting prototypes  and merging categories are computationally fast. for example  once a classification has taken place the time taken to identify the category of an arbitrary object is logarithmic  and the time required to add or delete a prototype is linear.
　we demonstrated that the ability to reason about categories and other conceptual regions using the rcc enhances the conceptual space model. we showed that the rcc can be used to construct both monotonic and nonmonotonic reasoning systems from the information embedded in the categories of conceptual spaces  hence the rcc forms a natural bridge from the geometrical representation of information in conceptual spaces to its symbolic counterpart.
　in addition  the rcc provides facilities to determine the prototype regions from which to generate categories so that well behaved categorizations are produced.
　the crisper relation   and egg-yolk systems can be generated in conceptual spaces using prototypes and exemplars  and hence can be used to model the indeterminacy of conceptual regions. interesting properties followed from our constructions  for example  we were able to show that crisping a prototype region locally  leads to the crisping of its category under the power categorization  and that categorical perception can be explained by crisping the distance measure on the conceptual space.
references
 aurenhammer  1  aurenhammer  f.  power diagrams: properties  algorithms and applications  siam journal of computing surveys  1 :1  1.
 aurenhammer  1  aurenhammer  f.  voronoi diagrams: a survey of a fundamental data structure  acm computing surveys  1   1 - 1  1.
 balkenius  1  balkenius  c.  are there dimensions in the brain  in spinning ideas  electronic essays dedicated to peter gardenfors on his fiftieth birthday：	online at http://www.lucs.lu.se/spinning.
 borsuk and szmielew  1  borsuk  k.  and szmielew  w  foundations of geometry. amsterdam: north holland  1.
 bennett  1  bennett  b.  logical representations for automated reasoning about spatial relationships  phd thesis  university of leeds  1.
 chella et al.  1  chella  a.  frixione  m.  and gaglio  s. an architecture for autonomous agents exploiting conceptual representations  robotics and autonomous systems  1-1 :1  1.
 cohn et al.  1  cohn  a. g.  bennett  b.  gooday  j. and gotts. n.m.  qualitative spatial representation and reasoning with the region connection calculus  geoinformatica  1   1  1.
 cohn and gotts  1  cohn  a. g. and gotts. n.m.  representing spatial vagueness: a mereological approach  in principles of knowledge representation and reasoning: proceedings of the 1th international conference  morgan kaufmann  san francisco  1  1.
 dwyer  1  dwyer  r.a.  higher-dimensional voronoi diagrams in linear expected time  in proceedings of the 1th annual acm symposium on computational geometry  1 - 1  1.
 gardenfors  1：   gardenfors  p. ： conceptual spaces: the geometry of thought  a bradford book  mit press  cambridge massachusetts  1.
 harnad  1  harnad  s.  categorical perception: the groundwork of cognition  cambridge university press.
 hampton  1  hampton  j.  prototype models of concept representation  categories and concepts: theoretical views and inductive data analysis  academic press  london  1 - 1  1.
 krusal  1  krusal  j.b.  and wish  m  multi-dimensional scaling. beverley hills  ca: sage publications  1.
 klee  1  klee  v.  on the complexity of d-dimensional voronoi diagrams  archiv de mathematik  1: 1 - 1  1.
 may et al.  1  may  b. moody  d.b.  stebbins  w.c.  categorical perception of conspecific communication sounds by japanese macaques  macaca fuscata   j. acoust. soc. am.  vol. 1  no. 1  pages 1 - 1  1.
 nebel  1  nebel  b.  computational properties of qualitative spatial reasoning  in wachsmuth  rollinger and brauer  eds   proceedings of the 1th german ai conference  vol 1 lncs  1 - 1  springer-verlag  1.
 okabe et al.  1  okabe  a.  boots  b.  sugihara  k.  and chiu  s.n.  spatial tessellations  1nd ed  wiley  1.
 petitot  1  petitot  j.  morphodynamics and the categorical perception of phonological units  theoretical linguistics  1: 1 -1  1.
 renz and nebel  1  renz  j. and nebel  b.  on the complexity of qualitative spatial reasoning: a maximal tractable fragment of the region connection calculus  artificial intelligence  1  1 : 1 -1  1.
 rosch  1  rosch  e.  cognitive representations of semantic categories  journal of experimental psychology: general  1: 1 - 1  1.
simulating the formation of color categories
tony belpaeme vrije universiteit brussel
artificial intelligence lab
pleinlaan 1  1 brussels  belgium tony arti.vub.ac.beabstract
this paper investigates the formation of color categories and color naming in a population of agents. the agents perceive and categorize color stimuli  and try to communicate about these perceived stimuli. while doing so they adapt their internal representations to be more successful at conveying color meaning in future interactions. the agents have no access to global information or to the representations of other agents; they only exchange word forms. the factors driving the population coherence are the shared environment and the interactions. the experiments show how agents can form a coherent lexicon of color terms and - particularly- how a coherent color categorization emerges through these linguistic interactions. the results are interpreted in the light of theories describing and explaining universal tendencies in human color categorization and color naming. at the same time the experiments confirm the view that certain aspects of language act as a complex dynamic system  arising from self-organization and cultural interactions.
1	introduction
color has enthralled scientists for centuries. many disciplines in science  among which physics  neurology  cognitive science  philosophy  psychology  linguistics and anthropology  have all contributed to a vast body of work on the aspects of human color vision  including color perception  color categorization and color naming. cognitive processes concerned with color have often been considered as being ideal test ground for verifying theories proposed in the abovementioned disciplines. moreover  empirical studies on color perception have always offered ample food for thought for quite a few different opinions in cognitive science; often the interpretation being changed to better fit this or that perspective.
　the experiments described here study color categorization and color naming in artificial  well-controlled simulations; trying to provide justification or even new insights in theories on color categorization and color naming.
1	from color perception to color categories
human color perception can be studied at several levels. at the neurological level  electro-magnetic energy is transformed in the photoreceptors of the retina into a neural signal  which is then conveyed to the brain. humans have three different types of color sensitive photoreceptors: one sensitive for reddish light  one for greenish and one for bluish light. the cells are cone shaped and they are respectively called the l  m and s-cones; designating their sensitivity to long  middle or short wavelengths. humans are thus trichromatic species. however  at the psychological level humans seem to react rather different than one would expect for a species having three types of photoreceptors. hering's opponent color theory  later defined quantitatively by  jameson and hurvich  1  and observed experimentally during in vivo experiments on macaque monkeys by  devalois et al.  1   argued for an antagonistic nature of color perception: color seems to occur in pairs  with black opposed to white  green opposed to red and blue opposed to yellow. this gave rise to the two stage color theory; in a first stage light is received by three types of photoreceptors  and in the second stage the outputs are interconnected to form red-green  yellow-blue and white-black channels. however  we are still left with a continuous color experience  handling color information would require cutting up that color continuum. this brings us to color categorization.
1	color categories and color terms
color appearance has a categorical nature; this is immediately suggested by the fact that every language has different color words to indicate different color sensations. the belief was long held that cultures divided the color spectrum into arbitrary categories. however  in 1 berlin and kay published their influential monograph   in which they provide empirical evidence for universal tendencies in color categorization. they conclude that humans have eleven basic perceptual color categories; basic meaning that the corresponding color term is a monolexemic  unique color term  salient and unambiguous to all language speakers. human languages have at least two and at most eleven basic color terms referring to these perceptual color categories  english has all eleven of them: black  white  red  green  yellow  blue  brown  purple  pink  orange and gray . a second conclusion is that basic color terms appear in languages in a specific order. when a language has only two color terms it will be a term for black and white  when a third color term is added  it will be red  next either green or yellow is lexicalized and so on. at about the same time  new quantitative information on the opponent character of color vision seemed to support berlin and kay's theories very well  kay and mcdaniel  1 . thus  the universalist stance quickly became widely accepted. however  recently critical views have been offered on universalist extremism  pleading for a more subtle attitude and for more carefully collected and interpreted quantitative data  saunders and van brakel  1; lucy  1 .
1	the relation to language
language is unique to humans; although many animals are capable of communicating messages  they are not able of employing the full range of linguistic capabilities as we humans can. concrete and abstract concept formation  extensive lexicalizations and syntax all seem to be exclusive to humans. the way humans handle abstract reasoning  hierarchical structures and arbitrary mapping is unsurpassed  and there is good reason to believe that language is crucial to all this. the nature of language and the origin of language might indeed help us understand human intelligence.
　on the origin of language  two extreme stances exist. some assume that human language capacity is innate and at large genetically defined  chomsky  1; pinker and bloom  1; bickerton  1   while others believe that the origins of language are to be found in the combined play of human general cognitive capacities and cultural interactions  deacon  1; steels  1 .
　steels  1; 1  considers language to be the product of cultural evolution. according to steels language can be seen as a distributed  dynamical and adaptive system. language is not controlled by one central intelligence; instead  the knowledge of the language is distributed over its users. none of the users has perfect knowledge or control of the language. language is also robust to changes in the population; users may leave or join the community without significantly affecting the language spoken in the community. in addition language can be seen as a complex dynamic system: categories  concepts  word forms and grammar emerge and adapt according to population dynamics which can be described using ideas from the field of dynamical systems. these theories have been successfully used  for example to explain the self-organization of universal tendencies in vowel systems  de boer  1 .
　investigating the formation of color categories and color terms in the same way can help elucidate some aspects of human language  such as concept formation  lexicon grounding and the propagation of lexicalizations and meaning through a population.
　the paper is structured as follows. section 1 describes the internal organization of the individual agents  the representation of color perception  the categorization and the connection between color word and color categories . section 1 provides details on the dynamics on the individual level and on the population level. section 1 provides results illustrating some typical outcomes of simulations  while section 1 and 1 conclude.
1	the agents
the simulation uses a population of agents. on an individual level  the agents all have the ability to perceive color  to categorize their perception  to lexicalize their color categories and to adapt to other agents in order to be more successful at communicating color meaning. on the population level  the agents communicate with each other using a simple protocol called the guessing game. in a guessing game  two agents communicate about a visual context. through playing several thousands of these games a common lexicon is built up.
1	color perception and representation
when perceiving the physical world  a mapping is made from the physical space to a representation in the psychophysical space. upon this representation  further cognitive actions such as categorization or recognition are taken.
　the color stimuli are presented to the agents as spectral power distributions  expressed as energy at wavelengths in the visible spectrum  ranging from nm to nm . no information on spatial or temporal properties are given: the colors are presented in  aperture  mode  void of any contextual information. the sensation is a physical stimulus and has to be mapped to a psychophysical representation
　　　. for this a mapping is needed. the representation should fulfill three requirements. first and for all it should be a good model for how humans perceive color. second  it should make discrimination possible: two stimuli are discriminable if and only if they map onto different points in the representation space. third  one should be able to define a similarity measure over the representation space.
　the cie color space satisfies these requirements and has proven its merit at categorizing real-world color images  see  lammens  1  . it is a three-dimensional color space designed to be perceptually equidistant and can be represented in cartesian space. represents lightness  corresponds approximately to redness-greenness and to yellowness-blueness. for a definition and for a conversion from spectral power distribution to cie see for example  wyszecki and stiles  1  
1	color categorization
when an agent is to communicate about the world  a symbolic representation of the perception is needed. this categorical representation arises by cutting up and structuring the representation space.
　the color space  which is the psychophysical representation space in these experiments  is used to define categories. a category has a number of features  in our case   and
　  and for each feature a fuzzy membership function is defined. if an unknown stimulus is perceived  a measure is needed of how well a category matches the unknown representation. several solutions are possible to represent a category  one could take a radially symmetric function such as a gaussian; or a multilayer perceptron could be used. here an adaptive network is chosen  an adaptive network resembles a radial basis function -see eg.  broomhead and lowe  1 ; except that there is only one output unit  which is divided by the number of hidden units . adaptive networks are our preferred choice for representing categories since they can divide the input space into regions while not being restricted in any way: the regions can be convex or not  symmetrical or not  connected or disparate  even overlap is possible. a second advantage is that adaptive networks are easily analyzed. this is valuable for monitoring the performance of the simulations.

figure 1: adaptive network for representing a color category  it consists of one hidden layer of locally tuned receptors fully connected to a linear output unit.
　figure 1 shows the adaptive network. it consists of a layer of an unspecified number of hidden units acting as tuned receptors and one output unit. the input is a threedimensional vector containing a   and -value. the hidden units are gaussian functions   with center and width . the output of the network is the weighted sum of the gaussians  weighted by the number of hidden units.


　for adapting the network  a combination of instance-based and reinforcement learning is used. there are four possible actions: adding or removing a hidden unit  and increasing or decreasing the weight of a unit. the width of a unit -initialized to a default value- is never changed.
1	lexicalizing categories
finally  the agents need word forms in order to communicate about color categories: word forms are the only information exchanged by the agents. a category can be associated with one or more word forms  allowing for synonymy. it is also allowed for the same word form to be associated with more than one category  allowing for polysemy. note that categories are only lexicalized when they need to be communicated; often agents have categories with no word form associated.
　an agent has a set of associations   each association is a pair containing a category and a set of word forms   can be empty .
　word forms are randomly selected from a finite alphabet   . no other restrictions are applied to the creation of word forms  for example  it is not the case that more often used words tend to be shorter  as observed in human languages .
1	the simulation
during a simulation step two kinds of games are played. the discrimination game is played at the individual level. the guessing game is played at the population level. more on the mechanism of both games can be found in  steels  1 .
1	the discrimination game
the goal of the discrimination game is to construct categories in order to successfully distinguish color stimuli. it follows a simple scenario  and is completed by one agent without the need for interactions with other agents.
　an agent has a  possible empty  set of categories . a random context is created and presented to the agent. it contains objects  in this case color stimuli  of which one object is the topic. the topic has to be discriminated from the rest of the context. the game proceeds as follows.
1. context and the topic are presented to the agent.
1. the agent perceives each object and produces a sensory representation for each object:
.
1. for all	sensory representations  the best matching category	is found.
   is the output of the adaptive network belonging to category   and is the output of the adaptive network reacting best to .
1. the topic can be discriminated from the context when there exists a category matching the topic but not matching any other objects in the context.
　this scenario can fail in two ways. first  the agent has no categories yet    ; in this case a category is created with its center on the topic. second  no discriminating category can be found: the category found for the topic is also found for other objects. when this category is far from the topic  according to some distance measure   a new category is created. when it is closer than a certain threshold distance  the category is adapted by adding a new hidden unit with its center on the topic.
　when playing these discrimination games an agent is able to create categories that discriminate one object  i.e. color stimuli  from others. next to basic mechanism  the weight of the hidden units are decreased with every game. over time  this results in the  forgetting  of hidden units. only when a category has proven to be useful in an interaction  the weights are increased again.
1	the guessing game
for the guessing game  two agents are randomly chosen. one acts as the speaker  the other as the hearer. a context is presented to both agents  but only the speaker knows the topic. the game goes along the following scenario.
1. the speaker tries to discriminate the topic by playing a discrimination game  if it finds a discriminating category the game continues  otherwise the game fails.
1. the speaker looks if any word forms are yet associated with . if not  a new word form is randomly created and associated. if however one or more word forms are already associated with   then one word form is selected according to its success in previous guessing games. the word form is then conveyed to the hearer.
1. the hearer looks if it has in its associative memory  if not the game fails: the hearer is shown the topic and it learns the proper word form for it by adding a category for the topic.
1. if the hearer does have the word form in its lexicon it finds the associated category and tries to point out the topic. this will only work when the hearer can discriminate the topic from the context  otherwise the game fails.
1. if the hearer succeeds in pointing out the correct object as the topic  the game is successful. if the hearer points out the wrong object  the speaker identifies the topic and the hearer adapts its category by adding a hidden unit  so the category resembles the topic better in future games.
　when a guessing game is successful the weights of the hidden units of the category are increased  this strengthens a category making the probability of it being used in future games higher. categories which do not contribute to the game are through this less likely to be used in future interactions.
　the interactions are responsible for achieving agent lexicons which are coherent over the population. and because the agents adapt their categories according to the outcome of the guessing game  the categories of the agents show coherence as well. this is an illustration of the sapir-whorf thesis  which claims that language influences the way its users experience the world  whorf  1 .
1	results
for the simulations two data sets are used as input: one containing spectral measurements taken from over 1 color chips of the munsell color notation system and one with 1

figure 1: the average success rate plotted for 1 agents over 1 games. the upper curve shows the discriminative success  the lower curve the communicative success.

figure 1: coherence of the color categories in a population. the bottom data series shows the coherence without interactions  the top series shows how interactions increase the coherence.
measurements of colors of plants and flowers. a contextis selected out of these databases  containing minimum 1 and up to 1 different color samples. as a reference  artificial created color samples are use to test the robustness of the system.
　the results show that the agents create a set of categories with which they can discriminate any color context offered  provided that the color stimuli in the context are dissimilar enough; for example  the colors can not be metameric . figure 1 shows the success rate of a population of agents during a typical run1. the discriminative success -telling how good the agents are at discriminating the context- quickly rises to 1%. the communicative success -measuring how good the agents are at conveying meaning- rises quickly  then drops off as the games reach their full complexity and then gradually rises again as they agree on a common lexicon.
　another result demonstrates the benefit of communication. when no guessing games are played  so that there is no interaction between the agents  the agents do not manage to

figure 1: number of categories for 1 agents during 1 games. the gray curves show the number of categories for each agent  the black curve shows the population average.
form coherent category sets. clearly the environmental binding is not strong enough to obtain shared categorizations. when the interactive component is introduced  by letting the agents play guessing games  the coherence of the color categories rapidly increases. the coherence is computed by cross-summing the similarity for all categories of the entire population. let contain all the categories of all the agents  the coherence is then computed as 
　the higher the coherence  the better the categories of the agents agree. categories are matched according to a similarity function. the similarity between two categories and
is computed as in eq. 1  with and being the number of hidden units for both categories. it is proportional to the inverse of the euclidean distances between the centers of the hidden units of both categories.
		 1 
　figure 1 shows a typical run  with a population of 1 agents playing 1 games  the context contains 1 color stimuli selected from the munsell database. the coherence of a population only playing discrimination games is low compared to a population benefiting from interactions through guessing games; it demonstrates how linguistic interactions are responsible for coherence of categories. this might seem surprising because the agents neverhave access to the categories of other agents. however  through the linguistic interactions their internal representations adapt to allow for improved transfer of meaning. a side effect of this is that the categories become coherent over the population.
　the number of color categories  and proportionally the number of associated word forms  created by the agents rises quickly and stabilizes after a while. figure 1 shows a typical run: the number of categories stabilizes on an average of 1 color categories per agent. the number of color categories depends on several parameter settings. parameters having a large influence on the number of color categories are  1  the number of color samples in the context  more color samples force the agents to create more color categories to be able to discriminate the colors and  1  the similarity of the color samples; if the samples are rather similar  fine grained categories are needed to discriminate them. in a nutshell  the context exerts pressure on the agents to create more or less categories1.
　the environment does not only influence the quantity of categories  it also affects their quality. when the context contains only highly saturated colors  the agents will only create categories presenting high saturated colors. likewise  when the context contains a significantly higher amount of red samples  the agents are likely to all have a category and word form for red.
1	discussion
the evolutionary order of the emergence of named color categories  as observed by berlin and kay  does not show up in the experiments where there is no bias imposed on the color perception or on the environment. when in simulation the agents have only two color terms  they will have a term for warm-bright colors and one for dark-cool colors  which is in accordance with observations of human languages. however  when the agents have three or more color terms  there is no preference for creating a category for reddish colors: the creation of categories is entirely opportunistic. for humans the story is different  when human languages have three or more color terms  there will always be a term for reddish colors. several explanations have been offered for this  see  hardin  1  for an overview  that can be summarized in two ideas: the preference could be built into human biology or it could be rooted in near-universal environmental constraints. for years the focus has been on the former: by interpreting the neurophysiological structure of human color perception one is able to explain many observed phenomena of color lexicalizations. however  some discrepancies remain which can not be explained by the neurological makeup of color perception.
for instance  why do some languages not follow the evolutionary order proposed by berlin and kay  why do some languages have more than one word for blue  and why do languages spoken around the equator have less color terms  see  saunders and van brakel  1 .
　although a strong caveat should be issued when generalizing from artificial simulations to real-world phenomena  simulations can sometimes offer new insights and might help us find new ways to tackle problems. the simulations show how in simple artificial linguistic setting  a coherent color lexical and color categorizations can emerge in population of agents. this does not mean that shared human color categories emerge through cultural interactions; there is evidence that already infants have a categorical preference for certain strong hues  long before they engage in linguistic interactions  bornstein  1 . however  it might very likely that it is the interplay between cultural dynamics and biological dispositions that is responsible for how we categorize color  and not color alone.
1	conclusion
the experiments show how out of self-organization and linguistic interactions a coherent color lexicon can emerge. in addition  it shows how color categories can become shared among a group of language users solely by linguistic interactions. the color lexicons and category sets stabilize under a large range of parameter settings  showing the robustness of the system. the agents and their interaction dynamics form a dynamic system  with attractors in the form of stable lexical and category sets.
　many things still need to be investigated. most important  the influence of bias on the perception and on the environment needs to be studied. the conditions under which more realistic color categories arise  including the evolutionary order  need to be studied. already it is clear that the environment and contextual information will play an important role in this. as a bonus  it might be interesting to see if the system could learn color categories and names from a human instructor.
acknowledgments
i would like to thank erik myin and jelle zuidema for their useful comments. the author is a research assistant of the fund for scientific research - flanders  belgium   fwo .
references
 berlin and kay  1  brent berlin and paul kay. basic color terms. their universality and evolution. university of california press  berkeley  ca  1. reprinted in 1.
 bickerton  1  derek bickerton. catastrophic evolution: the case for a single step from protolanguage to full human language. in james r. hurford  michael studdertkennedy  and chris knight  editors  approaches to the evolution of language  pages 1. cambridge university press  1.
 bornstein  1  marc h. bornstein. color vision and color naming: a psychophysiological hypothesis of cultural difference. psychological bulletin  1 :1  1.
 broomhead and lowe  1  d.s. broomhead and d. lowe. multivariable functional interpolation and adaptive networks. complex systems  1-1  1.
 chomsky  1  noam chomsky. rules and representations. behavioral and brain sciences  1-1  1.
 de boer  1  bart de boer. the origins of vowel systems. oxford university press  1. to appear.
 deacon  1  terrence w. deacon. the symbolic species: the co-evolution of language and the brain. norton  1.
 devalois et al.  1  russell l. devalois  i. abramov  and g.h. jacobs. analysis of response patterns of lgn cells. journal of the optical society of america  1 :1  1.
 hardin  1  c.l. hardin. color for philosophers. hacket publishing company  indianapolis  1.
 jameson and hurvich  1  dorothea jameson and leo m. hurvich. some quantitative aspects of an opponent-colors theory. i. chromatic responses and spectral saturation. journal of the optical society of america  1 :1  1.
 kay and mcdaniel  1  paul kay and chad k. mcdaniel. the linguistic significance of the meaning of basic color terms. language  1-1  1.
 lammens  1  johan m. lammens. a computational model of color perception and color naming. phd thesis  state university of new york  buffalo  1.
 lucy  1  john a. lucy. the linguistics of  color . in clyde l. hardin and luisa maffi  editors  color categories in thought and language  pages 1. cambridge university press  1.
 pinker and bloom  1  steven pinker and paul bloom. natural languages and natural selection. behavioral and brain sciences  1-1  1.
 saunders and van brakel  1  barbara saunders and jaap van brakel. are there nontrivial constraints on colour categorization  behavioral and brain sciences  1-1  1.
 steels  1  luc steels. the synthetic modeling of language origins. evolution of communication  1 :1  1.
 steels  1  luc steels. synthesising the origins of language and meaning using co-evolution  self-organisation and level formation. in james r. hurford  michael studdert-kennedy  and chris knight  editors  approaches to the evolution of language  pages 1. cambridge university press  1.
 steels  1  luc steels. the puzzle of language evolution. kognitionswissenschaft  1   1.
 whorf  1  b.l. whorf. four articles on metalinguistics. foreign service institute  washington  1.
 wyszecki and stiles  1  gunther wyszecki and w.s. stiles. color science : concepts and methods  quantitative data and formulae. john wiley and sons  1nd edition  1.
　
cognitive modeling
cognitive modeling - perceptual grounding

grounded models as a basis for intuitive reasoning
josefina sierra-santiba＞nez 
escuela te＞cnica superior de inform＞atica
universidad auto＞noma de madrid josefina.sierra ii.uam.es
　
abstract
this paper introduces grounded models and compares them to axiomatic models of mathematics. grounded models differ from axiomatic theories in establishing explicit connections between language and reality that are learnt through language games. they are constructed and updated by autonomous agents connected to their environment through sensors and actuators using some conceptualization mechanisms and language games described in  steels  1 . they are based on conceptualization and support a form of intuitive reasoning  which can be done sometimes by constraint satisfaction and it is argued to be the basis of some axiomatizations. this is illustrated with a simple example of spatial reasoning.
1	introduction
the concept of grounded model introduced in this paper is based on some ideas and mechanisms described in the talking heads experiment  steels  1 . the experiment involves a set of robotic  talking heads  playing language games with each other about scenes perceived through their cameras on a white board in front of them. in particular  we focus on the conceptualization part of a language game  called the discrimination game  which generates the meaning of the verbal hint transmitted by the speaker to the hearer in a language game.
　the discrimination game  steels  1  is played by a single agent  and consists of the following steps. first  the agent perceives an image on a white board throughhis camera  segments the image into coherent units  and computes various sensory characteristics about each image segment  such as its color  horizontal or vertical position. then  the agent chooses an image segment as topic  and tries to find a combination of categories that distinguishes the topic from the other objects in the image. the game succeeds if the agent finds a combination of categories that is true for the topic  but it isn't true for the other objects in the image. if the game fails  the agent adapts its internal structures to become more successful in future games.
　the rest of this section describes  in some detail  the different processes and cognitive structures involved in the dis-

111figure 1: each object in the scene is characterized by values on three primitive sensory channels: hpos  vpos and grey.
crimination game.
1	perception
the agent captures an image on a white board in front of him. geometric figures of various sizes  shapes and colors can be pasted on the white board. then  the agent segments the image into coherent units. next low level visual processes gather information about each segment  such as its color  horizontal or vertical position. each process outputs its information on a sensory channel. we assume that there are only three primitive sensory channels.
hpos obj  contains the x-midpositionof object obj.
vpos obj  contains the y-midpositionof object obj.
grey obj  contains the average gray-scale of obj.
　the values on the sensory channels hpos  vpos and grey are scaled so that its range is the interval  1 1 . consider the three objects numbered in figure 1  object 1 has the values hpos obj1 =1  vpos obj1 =1  grey obj1 =1  object 1 the values hpos obj1 =1  vpos obj1 =1  grey obj1 =1  and object 1 the values hpos obj1 =1  vpos obj1 =1  grey obj1 =1.
　in addition to three primitive sensory channels  there are some sensory channels constructed from them.
hpos-diff obj1 obj1  contains the difference of the x-midpositions of objects obj1 and obj1  i.e. hposdiff obj1 obj1 =hpos obj1 - hpos obj1 .
vpos-diff obj1 obj1 contains the difference of the ymidpositionsof segmented objects obj1 and obj1.
grey-diff obj1 obj1  contains the difference of the average gray-scale of objects obj1 and obj1.
equal obj1 obj1  is defined as a predicate  i.e. a functionwhich takes the value 1  i.e. true  if the values of the primitive sensory channels hpos and vpos are equal for obj1 and obj1  and 1  i.e. false  otherwise.
　for example  the sensory channel vpos-diff has the value 1 when it is applied to the pair of objects formed by object 1 and object 1  i.e. vpos-diff obj1 obj1 =1. the range of the sensory channels hpos-diff  vpos-diff and grey-diff is  -1 1 . the range of the sensory channel equal is the discrete set of boolean values .
1	perceptually grounded categories
the data on sensory channels are values from a continuous domain  except for sensory channel equal . to be the basis of natural language communication  these values must be transformed into a discrete domain. one means of categorization is to divide up each domain of values on a particular sensory channel into regions and assign a category to each region. for example  the range of the hpos channel can be cut in two halves leading to a distinction between  left   1
hpos 1  and  right   1 hpos 1 . object 1 in figure 1 has the value hpos=1 and would therefore be characterized as  right . similarly  the vpos-diff channel can be cut in two halves as well leading to a distinction between  above  1 vpos-diff 1  and  below   -1 vpos-diff 1 .
　it is always possible to refine a distinction by dividing its region. thus an agent could divide the bottom region of the hpos channel  categorized as  left   in two subregions  totally-left   1 hpos 1   and  mid-left   1 hpos 1 . the categorization networks resulting from these consecutive binary divisions form discrimination trees.
　we label categories using the sensory channel from which they operate  followed by the upper and lower bound of the region they carve out. thus  totally-left  is labeled as  hpos 1 1   because it is true for a region between 1 and 1 on the hpos channel. we assume that perceptually grounded categories correspond to n-ary predicates of first order logic. for example  the category  hpos 1 1  corresponds to the unary predicate  hpos 1 1  obj   and the categories  vpos-diff 1 1  and  equal  to the binary predicates  vpos-diff 1 1  obj1 obj1  and  equal  obj1 obj1 .
　there are other ways to move from the continuous domain of sensory channels to the discrete domain of categories. we could introduce focal values and associate a category with each of them. in this case  the categorization process consists in identifyingthe focal point that is closest to an object's value.
1	concepts
perceptually grounded categories can be combined to construct concepts. we use a set of concepts which can be defined by induction as follows.
1. if is an n-ary category and are variables  then is a concept.
1. if	is a concept  then the negation of	 written	  is a concept.
1. if and are two concepts  then the disjunction of and  written   is a concept.
	the symbols	 	and	are introduced as abbreviations:
 1 	is an abbreviation of	;  1 
is an abbreviation of ;  1  is an abbreviation of . notice that the set of possible concepts is the set of free-quantifier formulas that can be constructed from the predicates associated with perceptually grounded categories.
　we distinguish three types of concepts: intuitive truths  intuitive falsehoods  and regular concepts. some concepts have the property of being true for every possible tuple of segmented objects. we will call them intuitive truths or just truths. for example  the concept vpos-diff
	vpos-diff	is an intuitive truth.
　other concepts have the property of being false for every possible tuple of segmented objects. we will call them intuitive falsehoods. for example  the concept
vpos-diff	is an intuitive falsehood.
　the rest of the concepts  called regular concepts or simply concepts  can be used to discriminate those tuples of objects that satisfy them from those tuples of objects which do not make them true. for example  the concept vpos-diff
　vpos-diff   which is true for a pair of segmented objects obj1 and obj1 if neither obj1 is above obj1  nor obj1 is above obj1  is a regular concept.
1	grounded models
1	categorizers
a categorizer is a cognitive procedure capable of determining whether a category applies or not. for example  the behavior of the categorizer for category  vpos 1 1  obj  can be described by a function that takes the value 1 if 1 vpos obj  1  and 1 otherwise.
　the categorizers of nonatomic concepts are compositions of the categorizers of categories. for example  the behavior of the categorizer for concept vpos-diff
　vpos-diff	can be described by a function that takes the value 1 if
       vpos-diff	  and vpos-diff	.
　categorizers establish explicit connections between symbols  categories and concepts  and reality  perceptual input as processed by sensory channels . these connections are learnt through language games  wittgenstein  1   and allow agents to check whether a concept is true or not for a given tupleof segmented objects. most importantly they provide information on the perceptual and cognitive processes an agent must go through in order to understand or evaluate a given concept.
1	grounded models
a groundedmodel is the set of concepts and categorizers constructed byan agent at a given time inits development history. these concepts and categorizers are organized as follows.
1. a discriminationtree for every sensory channel containing categories and categorizers which use the values on that sensory channel.
1. a set of intuitive truths containing concepts which aretrue for every possible tuple of segmented objects.
1. a set of defined concepts containingnonatomicconceptswhich are neither intuitive truths nor intuitive falsehoods.
　a grounded model reflects the conceptualization of the world constructed by an agent at a given time in its development history. grounded models are not static  but evolve and adapt as the agent is confronted with new experiences.
　consider the grounded model of an agent that has constructed top-level categories and categorizers for each sensory channel  but does not have any defined concept or intuitive truth yet. the categorizers of this grounded model are cognitive procedures whose behavior can be described by linear constraints. we associate a linear constraint describing the behavior of each categorizer with a predicate symbol that corresponds to the category it is capable of recognizing.
vpos	vpos	vpos
vpos	vpos	vpos
...
grey-diff -
-	grey	-grey	grey	-grey
grey-diff
	grey	-grey	grey	-grey
　categorizers are probablyimplemented by neural networks in natural agents. we only use linear constraints to model their behavior. we are not assuming therefore that agents do learn such constraints  but that they build them in their perceptual systems.
1	grounded models and axiomatic theories
a grounded model looks like an axiomatization or a theory of first order logic  but differs from it in some aspects. like a logical theory  it has a set of basic concepts  which correspond to perceptually grounded categories   and a syntax that allows constructing defined concepts from basic concepts1.
　one of the most important differences between grounded models and logical theories is the form in which basic concepts are defined. in a grounded model  concepts are defined by cognitive procedures which given a tuple of objects return one of the boolean values . for basic concepts  these cognitive procedures are the categorizers associated with perceptually grounded categories. for nonatomic concepts  the cognitive procedures are logical compositions of the cognitive procedures associated with basic concepts. basic concepts have  therefore  precise and explicit meanings in grounded models  which determine the set of concepts that can constitute the intuitive truths of a grounded model. this can be contrasted with logical theories  in which concepts are defined by simple symbols whose meaning is only constrained by the relationships the axioms in the theory postulate about them.
　it should be observed as well  that the meanings of basic concepts in grounded models are not arbitrary functions from the set of possible tuples of segmented objects on the boolean values   as it happens with the meanings of predicate symbols in model theory semantics. they are cognitive procedures which should make intuitively plausible distinctions  in general  relations  using data extracted by realistic sensory channels operating on real world environments. this fact has important consequences on the shape and inferential power of grounded models. first  the meanings of basic concepts are highly constrained by physical aspects of the environment and the sensory-motor apparatus of the agent. because  in order to qualify as a possible meaning  a cognitive procedure has to be implementable as a relatively easy computation on the range of values produced by realistic sensory channels. second  the set of intuitive truths is constrained as well by mathematical relationships holding among the meanings of basic concepts. for example  the following relationship holds among the meanings of the concepts vpos   vpos and vpos-diff	.
	vpos	vpos
vpos-diff
　therefore  the following concept can never be an intuitive truth of a grounded model containing the basic concepts vpos-diff and
vpos	.
　vpos	vpos vpos-diff
　this contrasts with axiomatic theories in which any well formed formula can be stated as an axiom.
　the mathematical relationships holding among the meanings of basic concepts are one of the most important features of a grounded model. as we will see later on  they allow agents to reason about their environment without having an explicit axiomatization of it. this form of intuitive reasoning is commonly used by people to reason about everyday problems  and it is also the basis of formal reasoning in the sense of mathematics. this is so  because grounded models provide an explanation for the fact that we accept certain axioms as intuitively true when we build axiomatic theories in mathematics.
　we can observe a dual character between grounded models and logical theories. grounded models are constructed around the notion of concept  i.e. the meanings of concepts determine the set of intuitive truths of a grounded model. logical theories are instead constructed around the notion of axiom  i.e. the set of axioms determine the set of theorems of a theory  and to some extent the meanings of concepts. by looking at our example of grounded model g  one could say that grounded models are logical theories whose axiom set consists only of definitions of concepts. but this is not true  because the meanings of concepts in grounded models are cognitive procedures rather than logical formulas. sometimes  the behavior of these procedures can be described by mathematical functions  as in the case of grounded model g  but other times it cannot be easily described this way  as in the case of categorizers for approximate concepts. in the first case  intuitive reasoning can be done by exact mathematical methods  as we will see later on  but in the second case different techniques  e.g. simulation  must be applied.
1	constructing grounded models
grounded models are constructed as a side effect of agents' activity. in particular  the grounded models studied in the paper are constructed by agents as they play discrimination games. a discrimination game  steels  1  is played by a single agent. the agent perceives a scene and chooses a topic from the possible tuples of segmented objects in the scene. he then uses his current grounded model to come up with a category or nonatomic concept that is valid for the topic  but not for any other tuple of objects in the context. the game succeeds if the agent can find such a category or concept. if the game succeeds  the use and success counters of the categorizers involved goup1. if the game fails  the use counters of the categorizers involved go up  and a repair process in which a new category or concept is generated takes place.
　initially  the agent constructs top-level categorizers for each sensory channel that has contained distinctivedata in the recent past. if a channel has the same data for every segment it is not goingtobe possibleto find a distinctivecategory from it. afterwards  the agent extends his discrimination trees or constructs new concepts from existing categories or concepts.
　a categorizer for a new category is constructed by taking a categorizer node in a discrimination tree and dividing its range into two new subranges. for example  if we take the categorizer for  hpos 1 1  x   which is true when the object is in the left most half of a scene  two new categorizers are created by dividing  1 1  into two halves  one for the range  1 1    hpos 1 1  x  or totally left   and one for the range  1 1    hpos 1 1  x  or mid left . a new categorizer is added to the tree for each of these halves.
　a categorizer for a new concept is constructed by composition of the categorizers of existing categories or concepts. we use three composition operations: negation  conjunction and substitution. these operations allow constructing every free-quantifier formula of the first order language defined by the categories of the grounded model. in general  new concepts are constructed from categories or concepts that have been useful in previous games  i.e. which have a high rate.
two logical compositions are preferred to relate existing categories and concepts: conjunction and implication. conjunctions tend to be more discriminating than their components  increasing the chances of success in future games. implications  on the other hand  are commonly used to describe causality  and world facts are often expressed as causal laws.
　the final step of the discrimination game  called assimilation  is as follows. whenever the agent constructs a new concept  he checks whether it is an intuitive truth or a falsehood. if the new concept is an intuitive truth  the concept is added to the set of intuitive truths of his grounded model. if it is an intuitive truth and it is already in his grounded model  or if it is a falsehood  the concept is ignored and it is not included in the grounded model. finally  if the concept is a regular concept  and it is not already in his current grounded model  it is added to the set of defined concepts of the grounded model.
1	intuitive reasoning
the process by which an agent tries to determine whether a concept is an intuitive truth  a regular concept or a falsehood of a grounded model is called  in this paper  intuitive reasoning. an intuitive truth of a grounded model is a concept whose meaning is true for every possible tuple of segmented objects. a regular concept is a concept whose meaning is true for some tuples of objects  but false for others. and a falsehood is a concept whose meaning is false for every possible tuple of segmented objects.
　we hypothesize that intuitive reasoning happens by a process of simulation in natural agents. first  they construct the categorizer of the concept they want to check combining the categorizers of basic concepts of their grounded models. then  they try to find combinations of values of their sensory channels that can satisfy the categorizer of the concept. this process can be seen as a form of constraint satisfaction by search  in which the agents generate possible combinations of values for sensory channels  and test them using the concept's meaning. of course  the search cannot be exhaustive  because sensory channels take values on a continuous domain. the search is performed at the level of subregions in which the categorizers involved take different values. each subregion is represented by a single value of a sensory channel  and the combinations of subregions for sensory channels by tuples of values. as soon as a value is shown incompatible with the concept's meaning or sufficient for satisfying it  all the combinations containing that value can be eliminated from the search space. this allows reducing the complexity of the search process. sometimes  however  the agents cannot explore the entire space of possibilities  because it is too complex  and they make errors when they try to approximate the result of the search.
　if  after the search process  the agents cannot find any combinationof values which does not satisfy the concept's mean-
ing  the concept is seen as an intuitivetruth. if they find some combinationsthat satisfy it  and others which do not  the concept is seen as a regular concept; and  otherwise  as an intuitive falsehood.
1	spatial reasoning
to clarify the ideas discussed in previous sections  we compare a first order theory   which can be used for reasoning about spatial relations among objects on the plane  with the grounded model g described in section 1. the language of consists of two binary predicates and . its axiom set is as follows.
 1 
 1 
 1 
 1 
 1 
 1 
　in the classical approach to ai  if one wants to build an agent capable of reasoning about spatial relations  such as above or right-of  one must construct a first order theory like and apply automatic theorem proving methods. theories like this one are constructed by agent designers  not by the agents themselves  and they must be extended or updated by designers as well when the agents are faced with new challenges. these theories are normally used to determine whether a fact follows or not from the axioms of the theory  i.e. whether it is a theorem  or to extract answers in the form of sets of tuples of objects that satisfy a particular property expressed as a logic formula.
　we are going to see how a simple grounded model  such as the one shown in section 1  can be used for the same tasks as
　. the difference is that grounded models are constructed and updated by agents rather than agent designers  and that inference is done by intuitive reasoning.
　first  we see that every theorem of is an intuitive truth of the grounded model . in order to do that  we need to prove that every axiom of is an intuitive truth of   and that the intuitive truths of are closed under the inference rule of resolution.
　when the behavior of the categorizers for basic concepts can be described by linear constraints  intuitivereasoning can be seen as a process of linear constraint satisfaction. in particular  in the grounded model   the behavior of the categorizer of every concept can be described by a disjunction of linear constraints which can be computed by replacing every category by a linear constraint describing the behavior of its categorizer in the concept expression  and computing the disjunctive normal form of the result. proving that the meaning of a concept is true for every possible tuple of segmented objects requires proving that the constraint system associated withthe concept is true for every value of every sensory channel. this is equivalent to proving that the constraint system associated with the negation of the concept's meaning is unsatisfiable.
　for example  it can be shown that axiom 1  which states that the relation above - a x y  - is transitive  is an intuitive truth of the grounded model g by checking that the following disjunction of constraint systems is unsatisfiable for every value of   and in the interval  1 1 . this formula has been obtained by:  1  replacing every category by a linear constraint describing the behavior of its categorizer in the concept associated with the negation of axiom 1 in the grounded model g;  1  replacing every instance of vpos x   vpos y  and vpos z  by x  y and z in the expression resultingfrom step 1; and  1  computing the disjunctive normal form of the result of step 1.
- - - - - - - - -
　it is easy to check that this constraint system is unsatisfiable. a disjunction of constraint systems is unsatisfiable if each disjunct is unsatisfiable. each disjunct is a linear arithmetic constraint that can be checked by a linear constraint solver  such as the one implemented in sicstus prolog.
　the rest of the axioms of can be shown to be intuitive truthsof the groundedmodel byintuitivereasoning as well. grounded model g provides  therefore  an explanation for the fact that we accept the axioms of as intuitively true  and consequently use them to buildlogical theories for spatial reasoning.
　it can also be proved that intuitive reasoning in grounded models in which the behavior of the categorizers for basic concepts can be described by linear constraints is closed under resolution. that is  if two concepts are intuitive truths of a grounded model  its resolvent is an intuitive truth of the grounded model as well. therefore  every theorem of can be shown to be an intuitive truth of the grounded model by intuitive reasoning. intuitive reasoning is not only much simpler than theorem proving for this domain  but it can also be automated using constraint satisfaction techniques as we have explained above. in fact  the grounded model can be used to derive many more intuitive truths than the theorems of   because it contains categorizers for a broader set of basic concepts includingthe standard notionsof up x   down x   right x  left x   dark x   light x  darker x y  and lighter x y . grounded models can be used to extract answers as well. for example  we can obtain all the triples of objects in the scene of figure 1 such that by applying the categorizer of this concept to every triple of segmented objects in the scene  and picking up those triples that satisfy it.
　notice that  as soon as the agents have constructed categorizers for the basic concepts above and right-of  they are capable of deriving every theorem of by intuitive reasoning. this means that an agent capable of linguistic competence  steels  1  at the level of interpreting and generating first order logic formulas does not need an axiomatizationto reach sound conclusions about its environment by intuitive reasoning in this domain. it only needs to understand the basic concepts involved  and the grammar rules by which concept expressions are translated into concept meanings. we have made some recent progress in this aspect  which is illustrated by the following experiment. figure 1 shows the results of an experiment in which a couple of agents learn both logical categories  which correspond to the usual connectives of propositionallogic              and a shared vocabulary to refer to them. the particular language game used to learn logical connectives is a variation of the language games de-

1 1 1 1 1 1
figure 1: this graph shows the evolutionof lexical coherence in a series of 1 language games. first  the agents learn unary connectives     reaching total coherence very soon.
afterwards they start learning binary connectives           reaching 1 coherence after 1 games.
scribed in  steels  1 . the experiment shows that agents can indeed acquire linguisticcompetence at the level of interpreting and generating free-quantifier first order formulas.
　finally  grounded models can be used for a task that logical theories do not support  namely  concept generation. as a side effect of their activity playing discrimination games  the agents construct new concepts which they store and can use afterwards for different purposes  such as classification  discrimination or communication. some of these new concepts are intuitive truths. these are stored in the set of intuitive truths of a grounded model  and allow the agents to learn general facts about their environment1. others are regular concepts  and are stored in the set of defined concepts of a grounded model. axiomatizations and conceptualizations get constructed then as a side effect of agents' activity  and do not have to be built into them.
1	conclusions
we have introduced grounded models and compared them to axiomatic models of mathematics. grounded models differ from axiomatic theories in establishing explicit connections between language and reality that are learnt throughlanguage games. they are constructed and updated by autonomous agents connected to their environment through sensors and actuators using some conceptualization mechanisms and language games described in  steels  1 . they are based on conceptualization and support a form of intuitive reasoning  which can be done sometimes by constraint satisfaction and it is argued to be the basis of some axiomatizations. this has been illustrated with a simple example of spatial reasoning.
acknowledgments
the author would like to thank luc steels for many interesting conversations on the topics of the origins of language and grounded representations.
references
 lifschitz  1  vladimir lifschitz. circumscription. in handbook of logic in artificial intelligence and logic programming  d. gabbay and c.j. hogger  ed.  oxford university press  1.
 mccarthy  1  john mccarthy. programs with common sense. in mechanization of thought processes  proceedings of the symposium of the nationalphysics laboratory  pages 1  1.
 mccarthy  1  john mccarthy. circumscription -a form of non-monotonicreasoning. artificial intelligence 1- 1  1.
 mccarthy  1  john mccarthy. applications of circumscription to formalizing common sense knowledge. artificial intelligence  1-1  1.
 mccarthy  1  john mccarthy. formalizing common sense. papers by john mccarthy. edited by vladimir lifschitz. ablex publishing corporation  new jersey  1.
 piaget  1  j piaget. the equilibration of cognitive structures: the central problem of intellectual development. university of chicago press  chicago  1.
 shoenfield  1  john r. shoenfield. mathematical logic. addison-wesley publishing company  1.
 sierra  1  josefina sierra santiba＞nez. grounded models.  in working notes of the aaai-1 spring symposium on learning grounded representations  pages 1  stanford university  stanford  california  march 1  1.
 steels  1  luc steels. perceptually grounded meaning creation. in proceedings of the international conference on multi-agent systems. tokoro  m.  ed. . aaai press  menlo park ca. aaai press  1.
 steels  1  luc steels. the synthetic modeling of language origins. evolution of communication  1 :1  1.
 steels  1  luc steels. the origins of syntax in visually grounded agents. artificial intelligence  1-1  1.
 steels  1  luc steels. the talking heads experiment. volume 1. words and meanings. special pre-edition for laboratorium  antwerpen  1.
 steels  1  luc steels. the emergence of grammar in communicating autonomous robotic agents. in proceedings of the european conference on artificial intelligence 1. horn  w.  ed.   ios publishing  amsterdam  1.
 steels  1  luc steels. the role of language in learning grounded representations. in working notes of the aaai- 1 spring symposium on learning grounded representations  pages 1  stanford university  stanford  california  march 1  1.
 steels and vogt  1  luc steels and paul vogt. grounding adaptive language games in robotic agents. in proceedings of the european conference on artificial life 1. the mit press  cambridge ma  1.
 wittgenstein  1  ludwig wittgenstein philosophical investigations. macmillan  new york  1.
perceptual anchoring of symbols for action
silvia coradeschi and alessandro saffiotti
center for applied autonomous sensor systems
orebro university  s-1：	orebro  sweden： http://www.aass.oru.se
silvia.coradeschi aass.oru.se  alessandro.saffiotti aass.oru.seabstract
anchoring is the process of creating and maintaining the correspondence between symbols and percepts that refer to the same physical objects. although this process must necessarily be present in any symbolic reasoning system embedded in a physical environment  e.g.  an autonomous robot   the systematic study of anchoring as a clearly separated problem is just in its initial phase. in this paper we focus on the use of symbols in actions and plans and the consequences this has for anchoring. in particular we introduce action properties and partial matching of objects descriptions. we also consider the use of indefinite references in the context of action. the use of our formalism is exemplified in a mobile robotic domain.
1	introduction
the focus of this paper is the connection between abstractand physical-level representations of objects in artificial autonomous systems embedded in a physical environment. we call anchoring the process of creating  and maintaining over time  this connection.
　anchoring must necessarily occur in any physically embedded system that comprises a symbolic reasoning component. a typical example is the problem of connecting  inside an autonomous robot  a symbol used by a symbolic planner to refer to a physical object to the data in a perceptual system that pertains to the same object. this connection must be dynamic  since the same symbol must be connected to new percepts when the same object is re-acquired. for instance  a robot may be asked to identify and track a specific person in a crowd using visual data and given a linguistic description.
　anchoring is related to symbol grounding  defined as the problem of how to give an interpretation to a formal symbol system that is based on something that is not just another symbol system  harnard  1 . anchoring is an important special case of symbol grounding where the symbols denote individual physical objects.
　the recognition of the anchoring problem as a problem per se is a recent phenomenon. although all existing robotics systems that comprise a symbolic reasoning component implicitly incorporate a solution to the anchoring problem  this solution is typical hidden in the code  and it is developed on a system by system basis on a restricted domain. to the best of our knowledge  the first domain independent definition of the anchoring problem was given in  saffiotti  1   while the first attempt at a computational theory of anchoring was reported in  coradeschi and saffiotti  1 . the goal of this theory was to specify the functionalities and the representations needed to perform anchoring in a general way that is applicable to a large number of systems.
　in this paper  we focus on one specific aspect of anchoring: the use of symbols to denote objects in actions and plans  and the anchoring of these symbols to objects in the world. consider the action 'pickup a .' we are interested in the problem of how to anchor the symbol 'a' to the relevant physical object through perception. to do this  we start from the above theory of anchoring  and extend it in three ways. first  we make a distinction between the properties of 'a' which are needed to identify the physical object to be used for the action  and those which are needed to perform the action. second  we introduce the concept of partial matching  where 'a' can be  tentatively  anchored to an object whenever a required perceptual property cannot be extracted from the sensor data. third  we consider the use of indefinite references in the context of action. definite references  like  the black suitcase  are meant to refer to one specific object with given properties  while indefinite ones  like  a black suitcase  are meant to refer to an arbitrary object in a given class  russell  1 .
　in order to clarify the use of anchoring  we show two experiments performed on a real robot. they illustrate how anchoring can be integrated in a robot architecture  and how its functionalities can be used to connect the symbols used by a planner to the data acquired by a vision system. the examples also show the essential difference between two ways to treat actions that involve an indefinite reference. this reference can be resolved by the symbol system  planner   or by the anchoring process.
1	a basic model of anchoring
we summarize here the basic elements of the computational theory of anchoring defined in  coradeschi and saffiotti  1 . the theory considers an agent that includes a symbol system and a perceptual system  and it focuses on the problem of creating and maintaining a correspondence between

figure 1: two percepts extracted from a camera image.
symbols and percepts that refer to the same physical object. it consists of a static part and a dynamic part. the static part includes the following.
a symbol system including: a set of individual symbols  variables and constants ; a set of predicate symbols; and an inference mechanism whose details are not relevant here.
	a perceptual system	including:	a set
           of percepts; a set of attributes; and perceptual routines whose details are not relevant here. a percept is a structured collection of measurements assumed to originate from the same physical object; an attribute is a measurable property of
	percepts  with values in the domain	. we let
.
a predicate grounding relation   that embodies the correspondence between unary predicates and values of measurable attributes.
example. may be a planner that includes the individual symbol 'a' and the predicate symbols 'large' and 'small.' may be a vision system able to recognize suitcases: from the image shown in fig. 1  may extract two percepts and . attributes computed by may include 'color' and 'width.' the predicate grounding relation may include the triple small width : this says that the measure 1 for an object's observed width is consistent with the predication of its being small.1
　the relation concerns properties  but anchoring concerns objects. the following definitions allow us to characterize objects in terms of their  symbolic and perceptual  properties.
definition 1 a symbolic description	is a set of unary predicates.
definition 1 a perceptual signature is a partial function from attributes to attribute values. the set of attributes on which is defined is denoted by feat .
	is the set of all	.
　intuitively  a symbolic description lists the predicates that are considered relevant to the perceptual recognitionof an object; and a perceptual signature gives the values of the measured attributes of a percept  and it is undefined for the remaining ones . the relation can then be used to define a

figure 1: the elements of anchoring.
function match that says whether or not the values in the perceptual signature are consistent with a given symbolic description .
　the dynamic part of the model tells us  at any time   what properties are associated to symbols in   and what attribute values are associated to percepts in .
a description state ds that associates each individual with its symbolic description at time .
a perceptual state ps that associates each percept to its perceptual signature at time . if is not perceived at time   then ps is everywhere
undefined. the set of percepts which are perceived at is denoted by .
example. consider our previous example. at time   the symbol system may associate property 'small' to symbol 'a' by having small ds . the perceptual system may extract the width of the two percepts in the image  and associate them with the perceptual signatures ps and
ps	such that	width	and	width	.
　the role of anchoring is to establish a correspondence between a symbol used in the symbol system to denote an object in the world  and a percept generated in the perceptual system by the same object. this is done by comparing the symbolic descriptionds and the perceptual signature ps via the matchfunction  hence via the grounding relation. in the previous example  the relation includes the triple small width   therefore the description of 'a' and the perceptual signature of can be matched  thus suggesting that the symbol 'a' might be anchored to the percept .
　the above correspondence is reified in an internal data structure   called anchor. since new percepts are generated continuously within the perceptual system  this correspondence is indexed by time.
definition 1 an anchor is any partial function from time to triples in	.
　at every moment   contains: a symbol  meant to denote an object inside ; a percept  generated inside by observing that object; and a signature  meant to provide the  best  estimate of the values of the observable properties of the object. we denote these components by and
     respectively. if the object is not observed at time   then is the 'null' percept   and still contains the best available estimate. intuitively  an anchor can be seen as an internal  sensori-motor level representation of a physical object - see fig. 1.
　in order for an anchor to satisfy its intended meaning  the symbol and the percept in it should refer to the same physical object. this requirement cannot be formally stated inside the system. what can be stated is the following.
definition 1 an anchor	is grounded at time	iff	.
　we informally say that an anchor is referentially correct if  whenever is grounded at t  then the physical object denoted by is the same as the one that generates the perception . the anchoring problem  then  is the problem to find referentially correct anchors.
1	extending the model
the above model provides the basic ingredients of a general theory of anchoring  with no assumption as to the task for which anchoring is performed. in this paper  however  we focus on the use of anchoring to connect symbols for actions to physical objects through perception. from this perspective  the anchoring process should make sure that the anchor:  i  represents a physical object which has the intended properties for the intended action  and  ii  contains information about the perceptual properties which are needed in order to perform the action. for instance  if the action is meant to pick up a green suitcase  then the anchor should represent an object which is a green suitcase  and its signature should include an estimate of the position and orientation of this suitcase.
1	action properties
the match function makes sure that the anchor is adequate with respect to the properties stored in the description state  i.e.  ds	. in order to make sure that the anchor's signature also contains the properties that are relevant for action  we extend the dynamic part of our model by including the following.
an action parameter state that associates each individual with the set of properties that need to be known in order to act on the object denoted by .
in our example  a would specify the position and orientation of the suitcase. in the following we call matching properties the set of predicates in ds and action properties the set of predicates in
　note that the predicates in are not used in the matching process: these predicates only indicate that the corresponding attributes must be included in the anchor's perceptual signature . however  these predicates can be used as default assumptions about the expected properties of the object in order to start action before the object is actually perceived. for instance  we may have an expectation about the position of a suitcase: this expectation can be included in the signature of the anchor in order to start approaching that position until the actual suitcase is perceived. these expectations can also be used to focus the perceptual system.
　having a property in the action state or in the description state may affect the meaningof an action. in our  pickup a   example  if the position is not included in the description state  then 'a' will be anchored to any green suitcase  irrespective of its position. if the position of a given suitcase in included in the description state  then 'a' will only be anchored to the specific suitcase at that position. the first setup encodes the action  pick up a green suitcase   while the second one encodes the action  pick up the green suitcase at the given position   saffiotti  1 . note that the object of the action is denoted by an indefinite reference in the first case  and by a definite one in the second case.
1	partial matching
some actions may affect the perceptual information which is gathered by the agent: for instance  moving closer to an object may allow the perceptual system to observe more properties of the object. for example  suppose that we are interested in a suitcase with a white label on it: depending on the distance and angle of the suitcase  the label may not be visible.
　recognizing the fact that not all attributes of a percept may be extracted at all times brings about the need to redefine the meaning of the match function: match should check that the signature is consistent with the descriptor for those attributes which have actually been observed  but it should ignore the ones which have not been observed. the following is a possible way to define the matchfunction.
match whereif	obs	cons otherwiseobsfeatconsfeatintuitively  obssays that an attribute related to viathe relation  has been observed in   and cons says that the observations in are consistent with the predicate according to . match returns if there was a mismatch between some predicate in and the observed values; otherwise it returns the subset of the predicates in for which a  consistent  value has actually been observed.
　it is useful to keep track of which of the predicates in the symbolic description for a symbol have actually been observed  and which ones have not. to do this  we extend the definition of an anchor to include a list of the observed predicates as follows.
definition 1  bis  an anchor is any partial function from time to tuples in	.
we write	to denote the fourth element of an anchor	.
1	the functionalities of anchoring
in order to turn the above model into a useful computational framework  we need to define which functionalities are needed in order to solve the anchoring problem for a given symbol . in  coradeschi and saffiotti  1  three main functionalities have been identified:  i  to create a grounded anchor the first time that the object denoted by is perceived;  ii  to update the anchor when we need to reacquire the object after some time that it has not been observed; and  iii  to continuously update the anchor while observing the object. given the above extensions to the model  these functionalities can be defined as follows.   denotes the time at which the functionality is called. 
find take a symbol	and return a grounded anchor defined at   and undefinedelsewhere. in case of multiple matching percepts  return one anchor for each of them. this is summarized by the following pseudo-code.
	procedure find  	 
	matchds	ps
if
then fail
else for
	matchds	ps
	attributes	ps
return
the attributes function returns the part of the perceptual signature ps that only includes the  interesting  attributes  that is  those that correspond to either description properties or to action properties.  a specific implementation may also include attributes which are needed by the perceptual system to track the object  e.g.  its position and velocity. 
reacquire this function is used to find an object when there is a previous perceptual experience of it. take an anchor defined at time and extend 's definition to . first  predict a new signature ; then see if there is some new percept that is compatible with the prediction and the symbolic description; in case of multiple matching percepts  use a domain dependent selection function. if one percept is found  update . prediction  verification of compatibility  and updating are domain dependent; verification should typically use match. procedure reacquire    
predict
　　select verify ds ps if then verifyds ps
	update	ps	ds
return
if reacquire fails to find a matching percept  then contains the predicted signature and the 'null' percept . note that in this case is not grounded.
track take an anchor defined for and extend its definition to . it is used in the special case of reacquisition whenever the object is kept under constant observation. prediction is in general much simpler than in the reacquire case  and verification is only made with respect to the previously perceived attributes via a domain dependent function matchsignature. this functionality could for instance be implemented with a kalman filter. procedure track    
onesteppredict
　　select	matchsignature	ps if	then	update	ps

figure 1: the robot architecture used in our examples.
return
notice that the anchor s  computed always include the best current estimate of the observable properties needed to perform the actions      and an indication of which parts of the symbolic description have actually been observed    . the next section will show two examples of use of anchoring that further clarify the role of this information.
1	examples
in this section we present two examples of anchoring with indefinite references implemented in a robotic system. the robot  a nomad 1  uses sonars for navigation and vision data to identify objects in the environment. the two-layered decision making architecture of the robot is shown in fig. 1.
　the higher layer includes a plan generator  etlplan   a plan executor  and a world modeler. etlplan is a conditional planner capable of generating plans with perceptual actions and conditional branches  karlsson  1 . the plan executor checks the conditions and invokes the actions in the plans generated by the planner. the world modeler maintains information about objects and places relevant for the task. it can obtain additional information about objects from the anchoring module.
　the lower layer includes a navigation and a vision module. the navigation module is a simplified version of the fuzzy behavior-based controller defined in  saffiotti et al.  1   which executes the actions sent by the plan executor. an example of an action is  gonear a . the vision module contains vision routines for recognizing objects and for calculating properties such as color and size.
　the anchoring module provides the connection between the symbols used by the planner and the world modeler  and the perceptual data provided by the vision module and used by the navigation module. it receives requests to create and update anchors and it provides the relevant information about the anchored symbols to the world modeler. it is in this module that the function is encoded. in addition  the navigation module uses the symbols that constitute the arguments to its actions when requesting information from the anchoring module about the corresponding objects. for instance while executing the action  gonear a   it regularly requests the position of a. finally  the anchoring module controls the vision processing  activating routines for recognizing objects and providing parameters  e.g.  expected position  to focus perceptual attention.

figure 1: the initial setup in the first example.
1	anchoring with partial matching
this example has the aim to show how the anchoring module works in practice and in particular the use of partial matching. it also serves to illustrate one way to handle indefinite references. the robot has the task to  find a black suitcase with a white mark and to go near it . the initial scenario is shown in fig. 1. the largest suitcase is green  while the other three suitcases are black. the world model contains information about three objects: the two small black suitcases  identified in the world model by the symbols c  the one on the right  and b  the one on the left   and the green suitcase identified by the symbol a.
the goal given to the plan generator has the form
 exists  x  and suitcase x  black x 
 white-mark x  near x     that is  the goal is to be near to a black suitcase with a white mark. the world modeler contains the information that both b and c are black suitcases  but does not have information about the mark. therefore  the plan generator creates a plan that consists of first going near suitcase c and looking for the mark. if the mark is found  the execution stops with success. otherwise  the robot goes near to suitcase b to look for the mark. note that the original indefinite reference   a black suitcase with a white mark   has now been turned onto two alternative definite references b and c. the actual plan is as follows:
  gonear c   observe c 
 if   white-mark c . true    :success  
 if   white-mark c . false  
  gonear b   observe b 
 if   white-mark b . true    :success    if   white-mark b . false    :fail     
　fig. 1 left  schematically indicates the path followed by the robot during plan execution. the robot goes first to suitcase c  checks the mark   observe c    does not find it  and goes to suitcase b where it successfully identifies a mark.
　the navigation module  while executing  gonear c   is regularly requesting the anchoring module to keep c anchored. the latter uses the track functionality to keep track of c while the robot is moving.
　the matching properties provided to the anchoring module are the properties attached to the symbol c  such as color  position  and shape  and the fact that the suitcase should have a white mark. the vision routines  due to the distance between the camera and the suitcase  cannot discriminate if there is a mark on suitcase c. a naive matching function might reject

figure 1: an illustration of the path of the robot in the first  left  and second  right  example.
this suitcase  given that one property is not satisfied. partial matching allows us to consider the case that the property is actually not perceivable  and the suitcase is still anchored.
　a final observation is that while the robot is moving towards suitcase b  a third black suitcase  which was previously occluded  is also perceived. however  this suitcase is ignored because it does not match the perceptual signature  incl. position  of suitcase b.
1	anchoring with indefinite references
this example shows the handling of indefinite references at the level of the anchoring module  as opposed to at the higher symbolic level in the previous example.
　the task is to  go near a green suitcase and then go near a black suitcase . the world model contains initially two suitcases  one green denoted by the symbol a and one black denoted by b. in this case however the plan is to go near a generic object that has the properties of being a green suitcase and then to go near an object that has the properties of being a black suitcase    gonear x   gonear y  .1 the difference is that the symbols used for action now do not denote fixed specific objects  but any object in the class of objects satisfying the given matching properties. in case of x  these are black and suitcase. the positions of the two known objects are used as action properties  that is  they are used as an initial value for the gonear action. however they are not considered to be matching properties.
　the path of the robot is illustrated in fig. 1 right . the robot first moves successfully near the green suitcase. however  when it turns towards the black suitcase  this suitcase has been removed. the robot starts moving toward the recorded position of the black suitcase  as its position was given as action property. while the robot moves  a previously occluded black suitcase is perceived: the dotted suitcase in the figure. this suitcase matches the required properties as it is black. it is therefore anchored and the robot goes near it. the fact that the position and the perceptual signature of this second black suitcase is different from those of the first one does not constitute a problem; the anchoring module just matches the percepts with the properties present in the description state  even if it uses the expected position of the first black suitcase to direct the perception and to provide information to the navigation module.
1	discussion
the autonomous robotics and machine vision literature contains a few examples in which the need and the role of anchoring  under different names  has been explicitly identified  e.g.   hexmoor et al.  1    saffiotti et al.  1    jung and zelinsky  1    chella et al.  1    bajcsy and kos eck＞a  1    satoh et al.  1    horswill  1    wasson et al.  1 . however  all the works above describe specific implementations and do not attempt a study of the general concept of anchoring.
　to our knowledge  coradeschiand saffiotti  1 was the first attempt to state the general anchoring problem in formal terms. the main technical contribution of this paper is the extension of the above framework with the introduction of two elements needed to deal with the anchoring of symbols in actions and plans. first we have introduced action properties  that is properties that are used in the execution of an action  but are not relevant for finding the correct object. second  we have introduced partial matching to be able to distinguish between properties that are not satisfied and properties that are not presently available for perception  that is one cannot presently determine whether they are satisfied or not. as we consider anchoring from an action perspective we can deal with the latter case actively  for instance by observing the object from a better position. anchoring in the presence of partial matching is actually tentative: if a property previously not observed is observed at a later point and it is discovered not to match the description  the anchor can be removed.
　the problem of connecting linguistic descriptions of objects to their physical referents has been largely studied in the philosophical and linguistic tradition. these traditions provide a rich source of inspiration for the conceptualization of the anchoring problem. for instance  russell  1  made a distinction between definite and indefinite references. to this respect our examples show two different ways to resolve an indefinite reference in the context of an action. in the first example  the planner resolves the indefinite reference  a black suitcase with a mark  by instantiating a variable to known matching objects in the world model  and then it uses definite references  b and c  in its actions. note that in order to handle the appearance of a new suitcase  it would be necessary to re-plan. in the second example  the plan contains indefinite references  which are sent as such to the anchoring module. instantiation is delegated to the anchoring module  which is able to shift  on the fly  to the new suitcase. note that resolution of ambiguities might be more difficult in this case  without the support of the high level reasoning.
　the first approach seems to be suitable for relatively static domains where there is the time to re-plan  while the second approach seems to be more appropriate in highly dynamic domains. in fact  we have used a similar approach in the sony aibo robots in the robocup competition  saffiotti and leblanc  1 . this domain is highly dynamic  but there are few ambiguities with respect of anchoring of objects.
acknowledgements this work was funded by the swedish kk foundation. we thank lars karlsson and zbigniew wasik for providing substantial help in running the robot experiments.
