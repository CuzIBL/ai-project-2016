ing translation system 
jun-jie li and key-sun choi 
cslab  center for ai research  korea advanced institute of science and technology 
taeion  republic of korea 
e-mail: {jklee kscnoi}   world.kaist.ac.kr 

abstract 
 a corpus-based chinese-korean abstracting translation system is designed and implemented. firstly  a text indexing method called natural hierarchical network nhn  is introduced  and then a corpus-based word segmentation algorithm is developed with the segmentation correctness of 1% for open test. based on a words weighting function and a sentence importance weighting function which can dynamically calculate the importance of words and sentences by using the word frequency both in corpus and context  word length  sentence length and so on  an abstracting system is implemented to produce abstracts of texts in deferent languages and domains by any abstracting rate. experiments show that generally abstracts produced by 1% to 1% abstracting rates can cover 1% of the important sentences of the input texts. finally  combines with an example-based 
chinese-korean machine translation system  the generated abstracts are translated into target language with the correctness of translation of more than 1% by the important words oriented machine translation strategy. 
1 introduction 
automatic abstracting system is a very attractive  historical and difficult topic of natural language processing. its aim is to identify and select the central content or user inquired content from the given original texts to form the summarized output with the sentences identical to the original input text or new generated. there are three kinds of methods on developing abstracting system: the first one is based on the surfaceclues of the current context such as the word frequency  luhn  1   sentence position  word clue or indication   title sentence watanabe 1   word association or rhetorical relations ono et al.  1  and linear heuristic sentence weighting function  zechner  1 .its advantages are simple and domain unconstrained  its shortcoming is inaccuracy in sentence abstracting due to the uncertain valve of word frequency for key words  varied distribution of important sentences and heuristic function itself. the second one is based on the knowledge-based natural language processing techniques  such as script-based summarization system for given texts with multilingual output tait  1   cdbased domain constrained abstracting system with incomplete syntactic and semantic analysis  dejong  1   rule-based summarization system with forward and backward scanning schema  danilo 1 etc. its advantages are more accurate and in depth language analysis and generation. its shortcomings are domain constrained and difficulty in knowledge base maintenance. the third one is the corpus based methods  li and wang  1; li  1 . the corpus based sentence segmentation  non-linear sentence weighting function   collocation computation based word and sentence importance analysis and efficient raw corpus and text indexing method  give this method a prospective future. 
　example based machine translation system ebmt  is essentially translation-by-analogy: given a sourcelanguage passage s and a collection of aligned source/target text or sentence  pairs  find the  best  match for s in the source -language half of the text collection  and accept the target-language half of that match as the translation  brown  1 . 
   in this paper  we firstly introduce the methodology of automatic abstracting system and example-based mt system  and then in section 1  a corpus indexing method called natural hierarchical network nhn  is illustrated. in section 1  the corpus based word segmentation algorithm is introduced. in section 1  the word weighting function and sentence weighting function as well as abstract generation algorithms are introduced in detail. in section 1  an ebmt system called ebmt/ck is illustrated which is to translate chinese abstracts into korean. finally the experimental results and conclusion are given in the section 1 and 1. 
1 	natural hierarchical network 


1 	natural-language processing and graphical presentation 

li & choi 	1 there are also other interesting factors such as digital numbers  sentence locations and word clues  this kind of factors is often user- oriented and text style related  and if used properly  it will make good effect. 
1 abstract generation 
the abstracts or summaries  are generated by selecting the important sentences with higher sentence weight from the input text  and keeping their original sequential orders in the text. 
	1 	natural-language processing and graphical presentation 

	li & choi 	1 

to obtain a realistic and steady coverage rate of abstracting. 
　another experiment shows that the correctness of abstracting  which is calculated by l- the number of wrong abstracted words / the number of total abstracted words   is about 1% with the above coverage rate of abstracting and does not changed too much when the coverage rate of abstracting go beyond 1%. 
an comparison of 1 word dictionary based 
backwards maximum matching bmm  algorithm and the non-dictionary word segmentation nws  algorithm  shows that the number of wrong segmented words of bmm is four times of that of nws for open test. 
　the running speed is 1 characters/min for the corpus with 1 characters. the computational complexity of time for the algorithm is 1 m*n   m is the size of input text  n is the size of the corpus . 
1 	abstract generation 
in order to evaluate the machine-made abstracts  we selects tens of articles from different domains with different styles and lengths. 
　one experiment shows that 1% of the abstracts of these articles with 1%-1% abstracting or summarizing  rate can contain the title sentence and some subtitle sentences and topic sentences  although we do not give particular attentions and weights to those sentences in our word and sentence weighting function. 
　another experiment shows that 1% of the important sentences neither title sentences nor topic sentences can also be abstracted by the abstracting rates less than 1%. 
　we have test our system on chinese and korean language texts  although most of the above experiments are conducted to chinese texts  the korean texts processing have the similar results on a small scale of test  since the methods we used are not language oriented. 
1 example-based abstracting translation 
we use a bilingual example corpus with 1 chinesekorean sentence pairs  a chinese-korean dictionary of 
1 most frequently used words and a chinese korean character transformation table with each entry corresponding to a chinese character. 
　an experiment shows that based on a small scale of text data  the correctness of word alignment is 1% and more than 1% of the important words can be correctly translated. 
1 conclusion 
we have illustrated the detailed algorithms of abstracting translation system ats  and shown some of the experimental data. the key techniques include the nhn natural hierarchical network  raw corpus and text  indexing method  the corpus- based word segmentation and word weighting function  dynamic sentence weighting function  and abstract generation algorithm  an example-based chinese-korean mt system with algorithms in pattern sentence finding  important word oriented word alignment and target sentence generation  etc.. the algorithms and ideas of our system are also quite meaningful for multilingual information retrieval and corpus-based natural language processing. 
acknowledgment 
this project has been supported by china national 
high -tech development plan  1  on automatic abstracting system and center of ai research of korea advanced institute of science and technology on chinese-korean mt system. 
