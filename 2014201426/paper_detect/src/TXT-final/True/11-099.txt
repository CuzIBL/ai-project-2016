 	1. introduction 

as scientists interested in studying the phenomenon of  intelligence   we first choose a view of man  develop a theory of how intelligent behavior is managed  and construct some models which can test out and refine that  theory the view we choose is that man is a symbolic information processor the theory is that sophisticated cognitive tasks can be cast as searches or explorations  and that each human possesses  and efficiently accesses  a large body of infoimal uiles of thumb {heinistics  which constrain his search the source of what we colloquially call  intelligence  is seen to be very efficient searching of an a priori immense space some computational models which incorporate this theory arc described. among them is am  a computer program which develops new mathematical concepts and conjectures' involving them  a m is guided in this exploration by a collection of 1 more or less general heuristic rules. the operational nature of such models allows experiments to be performed upon them  experiments which help us test and develop hypotheses about intelligence. one interesting result has been the ubiquity of this kind of heuristic guidance: intelligence permeates everyday problem solving and invention  as well as the kind of problem solving and invention that scientists and artists perform. 
1
 this work was supported in part by the defense 
advanced research projects agency  r1-o1  and monitored by the air force office of scientific research. 
much of the behavior which we regard as  intelligent  involves some sort of discovery process.1 this is obvious for some of the the most creative and intellectually difficult human activities  identifying an unknown chemical compound  composing a new sonnet  deriving a new c.osmological model  conjecturing a new theorem  solving the ny times crossword puzzle ... . we'll see that it's no less true for our everyday activities  cutting cheese  finding our way about boston  solving the pittsburgh press crossword puzzle ... . 
1   1   	model-building in scienee 
we in the field of artificial intelligence  ai  want to understand how its's possible to do such things  to understand the mechanisms of intelligence. to go about it scientifically  we must first propose some hypotheses  use the results of experiments to modify and develop them into a theory  and then embody that theory in several concrete  testable models. this is the paradigm of science; it has great power  as we all know. 
in very  hard  sciences  objective data are available about isolated and relatively simple phenomena. this enables the construction of small yet quite rigorous  predictive models  using the language of mathematics  e.g.  maxwell's equations for electromagrietisrn . but in the so-called  soft  fields  the phenomena cannot be measured precisely  or are not so reproducible  or  as in 
1
  much of the rest of  intelligence  involves algorithmic solving of well-structured problems. that topic will not be emphasized in this paper. we take the position that  algorithms known and used by experts  is just a proper subset of  knowledge experts use to reduce search . 

computers & thought: lenat 1 

the case of human intelligence  cannot be easily isolated for study. the resulting models are usually only descriptive  and may often be presented in everyday prose  e.g.  psychological theories of personality . 
scientific models serve two functions:  i  to unify large masses of empirical data; and  ii  to predict new effects  which subsequently can be tested for by conducting experiments. the physicist's model  his set of equations  is better than the psychologist's model  his prose description  because he is able to draw on the power of established mathematics1 to make his model quantitatively predictive. 
what kind of model can we build for the phenomena of discovery and creativity  the more formal  mathematical models have the greatest potential predictive power  but humans seem just too complicated  sophisticated  and unpredictable for their behavior to be captured by a few equations. planets and atoms behave in much more regular a fashion than do people. 
is that the end  then  are we forced to build purely descriptive models of creativity  are we limited to sterile prose discussions about the mysteries of incubation and illumination  e.g.  as in  poincare' 1  and  polya 1    can we draw only metaphorical pictures  e.g.  as in the 'hooked atoms' image that einstein reports by introspection  hadamard 1    
the answer  until quite recently  was unfortunately  yes . 
1. 	choosing an approach in science 
f.ach science is differentiated from the others not merely by the set of phenomena it claims as its object of study  but also by the approach it takes  the science's view of those phenomena; its paradigm  kuhn 1   if you will . 
so even though we've decided to study the phenomena of human intelligence  creativity  problem solving  etc.   we must still choose a view of man. 
1
  the power to solve analysis problems in closed form  e.g.  to solve a differential equation simply by repeatedly manipulating it according to known transformations   or the power to make approximations when necessary  or the power to somehow  run  the model  to  grind out  solutions to his equations . 
1
  attempts to formalize  soft  phenomena do go on continually  but the interpretation of the resultant rigorous mathematics is often a topic of heated debate  a current example is catastrophe theory  kolata 1  . 
if we view man as a gestalt actor whose internal thought processes can't be investigated  then we are called  classical psychologists  and we study his external behavior. if we view man as a brain  as a piece of hardware built out of neuions  then we're called 
 biologists  and we study rieuruphysiological responses  eg.  by implanting electrodes  if we view man as a machine  then we're called  cyberneticists   and we investigate mathematical piopertics of feedback networks of simple components. if we view man as a collection of atomic particles  then were called foolish : this is too fine a  granularity  with which to investigate intelligence. 
another view arose about twenty years ago  from three separate sources: engineering  broadbent   psycholinguistics  chomsky   and computer science  newell and simon . man can be viewed as a symbolic information processor. if we adopt that view of man  and are interested in the mechanisms of human memory  then we're called  cognitive psychologists . if we adopt that view and are interested in the mechanisms of human thinking  then we're  information processing psychologists . finally  if we view man as information processor only to learn more about problem solving and creativity  then we're working in the field of  artificial 
intelligence  
1. 	the foundation for artificial intelligence 
suppose we view man as information processor  newell and simon 1   how can we construct some models of intelligence which are predictive rather than just descriptive  we might build operational models  which can exhibit whatever behavior our theory called for. to do this  we need to use a general purpose symbol manipulator  an automatic way to carry out each bit of information processing. 
1 unlike the brownian motion of atoms in a perfect gas  the fundamental information processes of intelligence are not random. 
　　no one view is  righl  or  wrong ; each is adopted because from it we can build a model  which in turn has some practical consequences and uses. when i'm ill  i want to go to a doctor who practices medicine based on man as an animal  not man as an economic agent. it is not productive to argue whether or not any specific view of man is  correct   is  immoral   etc. at the present limited state of our understanding  any one view is bound to be simplistic and incomplete. on the other hand  we never capriciously adopt a view with impunity. it is the whole man who lives and reacts  even though we can only view him  first this way  then that. 

computers & thought: lenat 
1 

a general purpose information processing system must provide  i  a way to specify what processing' gets clone when   ii  a memory in which to store symbol structures  and  iii  an  engine  which can actually cause such processing to occur the science of artificial intelligence   ai   sprang into being soon after the invention of one such computational engine  the general purpose electronic digital computer. in fact  ai is sometimes called  machine intelligence . 
computational models of some task can be used directly to carry out  a simulation of  the modelled activity  composing- sonnets  doing astrophysics research  devising new ways to cut cheese  defining and investigating new concepts in mathematics  navigating this city  etc. . if our computer program does perform the desired task adequately  then we accept it as verification that our theory adecjuately explains one way in which intelligent performance at that task might be achieved. 
1. 	the paradigm of ai research 
we in a i have evolved the following paradigm: 
1  choose some human cognitive activity  like playing chess  proving theorems  understanding spoken 
     english   ii  develop hypotheses and eventually a theory about what kinds of information processing could be taking place to produce such ability  
iii  incorporate that theory into a computer program  which serves as the model.1 that computer program is made to carry out the original activity  and the researcher can observe how well it does  
iv  by experimenting with his program  he attempts to find out where the apparent  intelligence  is really coming from 
over the last twenty years  we've hypothesized and tested scores of models  for several different sophisticated 
　　symbol processing is not the same as mere data processing. a  universal turing machine   e.g.  is just a data processor  because the marks on its tape aren't symbols  they don't represent anything but themselves. it was some years after its discovery that the digital computer was perceived as a general symbol manipulator. 
1
  ai deviates from cognitive psychology at this stage. psychologists would run experiments on people  to see if they really do fit the theory. we in ai are more concerned with whether the programs containing the hypothesized mechanisms are capable of any sort of  intelligent  behavior - even if differs somewhat from human performance at that task. 
tasks. there have been many successes  and many failures - and we've learned much from thern. some of these experiments will be described later  section 1 ; for now  i just want to present a single  very central result. 
it turns out that we can model a surprising variety of cognitive activities  problem solving  invention  recognition  as a search or exploration  in which the performer is guided by a large collection of informal rules of thumb  which we shall call  heuristics . but what's really exciting is that not only can this single theory  intelligence as heuistic rule guided search  explain the behavior of the brainstorming math researcher and the wandering boston visitor  but when we go off and build up such models in detail  we find that they can all contain more or less the same informal rules. 
before trying to justify this result  let's notice two rather surprising consequences of it: 
 i  every day  each of us is forced to - and does successfully - carry out a great deal of  creative research  just to deal effectively with our complicated world; 
 ii  there's a large component of non-formal   plain common sense  knowledge that is necessary to do creative new work in lhe sciences or the arts. 
now that you see where i want to take you  let's see how to get there. i'll have to spell out this  heuristic rule based search  theory of intelligence  convince you that it makes sense and that it can account for the way in which people perform such disparate tasks as solving the 1 puzzle and performing scientific research. also  i must demonstrate that there is a large core of heuristics which is common to all such activities. 
1. heuristic rule guided search 
1. the theory 
there is a theory of intelligence lurking here  upon which some models - some computer programs - have been constructed. the theory goes something like this: 
1. human cognitive tasks can be cast as searches  as explorations wandering toward some goal which is well- or ill defined. 
1. we are guided in these searches by a large collection of informal rules of thumb: heuristics. 
1. we access potentially relevant heuristics in each situation  and either  a  select and then follow a single relevant heuristic  or  b  quickly  stitch together  some of the relevant ones  and then follow the  combined  advice. 

computers & thought: lenat 

that's it.1 it sounds plausible; in fact  it sounds trivial. 
yet the models which incorporate this theory are capable of simulating sophisticated behaviors at many tasks which one would suppose require intelligence: organic chemistry problem solving  organic chemistry research  chess playing  discovery of new math concepts and conjectures 
1.1 	intelligence and information 
the theory contains two important implicit assumptions  which might be worth stating explicitly: 
  man is viewed as a processor of symbolic information. 
  man 	exhibits 	 intelligence  	by 	his performance at various cognitive tasks. 
let's take a moment to try to justify these -remarks  that intelligence has something to do with information processing. 
twenty-seven years ago  alan turing  rejected as meaningless the question  can machines' think  . he replaced it with a game  called the imitation game  now commonly referred to as the turing test . one version of that game would go as follows: a human interrogator is placed in an isolated room a teletype exists in the room  and by using it he can communicate with a computer and with another human  both located in the next room. the interrogator asks them each some questions  and then must guess which is the human and which is the machine. if we can program the machine in such a way that it fools the interrogator into making the wrong identification at least 1. of the time  then we shall say that the machine  as programmed  is  intelligent . many of you are familiar with this game. now let me introduce you to a slightly different one: 
thirteen years ago  keith gunderson  rejected as meaningless the question  can rocks thfnk  . he replaced it with a game  an imitation game. a human interrogator is placed in an isolated room a small hole exists near the bottom of the door  through which the interrogator can shove most of his foot. on the other 
1
	 notice 	the 	conspicuous 	absence 	of 	the 	word 
 representation  anywhere in the theory. to.design and construct a model for this theory would entail grappling with representational issues  much as any running instance of an abstract algorithm must exist on some particular machine. but the validity and power of the theory are independent of representation  just as the validity and complexity of an algorithm are independent of which machine it's implemented on. 
side of the door are located a human and a rock. sometimes the human will stomp on the interrogator's foot  and sometimes the rock will be dropped on it. the interrogator must guess which one is the human. if we can shape a rock in such a way that it fools the interrogator at least 1. of the time  then we shall say that the rock is  intelligent . 
why does the dialogue test sound so much less silly  so much more indicative of intelligence  than the stompingtest  because unrestricted dialogue is open-ended; to do well at it requires a massive wealth of knowledge  experiences  cognitive abilities  emotions  and common sense. unrestricted foot stomping requires none of these. in short  the first test permits genuine interrogation of information and information processing capabilities  while the second test doesn't. if you agree that the first test is genuine and the second one bogus  it must be because intelligence has something to do with sophisticated processing of massive quantities of infot mation. 
thus it seems that the informal ion processing view of man is an especially good one from which to study intelligence. let's elaborate on it a bit more  and then go on and see what happens when one tries to build models based on it 
1  	some 	examples 
let's take a look at some heuristic searches that people perform  and in the process hopefully convey their universality  their ubiquity  and their power. we'll then be in a position to examine some specific al models  computer programs  that they have built; this will be done in section 1. 
1.1 everyday problem solving 
suppose we decide to plan a nip from cmu to mit. 
how can we find a good route to take  we will probably find a detailed road map and begin searching. we have some powerful rules of thumb which make our search very short  usually. we look for some main highways that will take us most of the way  and then do some  fixing up  around the termini  from cmu to the first highway  from the end of that stretch to the beginning of the next one ..  to mit . 
computers & thought: lenat 1 this is the heuristic of planning in an abstraction space: we take the original detailed map  our  search space   and simply ignore all but the biggest roads marked on it. needless to say  this makes the map much simpler. we also assume that whenever two big roads go nearby each other  they do in fact connect  and that big roads 
which go near to cities do in fart pass through them. next  we solve the problem in this very small space  called the  abstraction space    fimally  we use that solution as the skeleton of a real solution we may have a few more searches to perfonu  e.g.  how do we realty get. from the boston exit to the m i t campus itself  but notice that all these additional searches will be small  localized fixups to the skeleton solution using the heuristic method of planning has reduced our search dramatically. 
t h i s brief example has hopefully demonstrated how we can explain eveiyday problem solving behavior in terms ot the  heuristic rule seairh  theory of intelligence. we've seen a typical problem  and explained how to model it  how one could imagine even a computer being able to solve it: cast it as a quest for a solution m some huge  search space   with the searcher being heavily constrained by knowledge embedded in general common sense rules of thumb  hem islics . in the next subsection  we'll show that the same kind of analysis can explain episodes of brainstoiming  in particular  the inventing some new kitchen gadget . 
1.1. everyday invention 
suppose we're confronted with the following problem: we're fond of eating cheese  but every time we cut it with a knife  it crumbles il we try to cut it very thin. we could continue just cutting cheese the old way  but let's assume we try to design an improved tool we are now facing a search in an enormous space of possibilities. p ut we have many informal rules of t h u m b which may help us 
1. sometimes  there will be a good way  perhaps a recent invention  to do somothing  more general than what is strictly asked for. 
1. consider what variables affect the success/failure of the current  inadequate  technique. look for motivation at the extreme cases of the various known relationships involving those variables. 
1. look carefully at what is truly wanted; maybe the problem can be completely bypassed; at least  perhaps it's over-specified. 
o n e of them  *1  says to look for motivation at the extreme cases of various known relationships. there seems to be some relationship between the thickness of the knife and the thinness of the slices we can cut. so we might consider as an extreme the thinnest knife possible  just a knife edge  and voila'. we've invented the wire cheese cutter. or we might look at the extreme case of the relation that says that most cheese can be cut thinner if it's softer. we may ask ourselves if we can get the cheese very soft; an extreme case of that would be to get the cheese directly under the knife-edge completely molten; and voila'  we've invented the  hotknife ; probably general electric will come out with one soon. 
notice that the same heuristic leads to several solutions. 
t h i s was but a tiny example of heuristic guidance in action. in reality  we possess many hundreds of heuristics. incorporating them into a computer model which could then tirelessly apply them seems like a very promising direction to follow we'll follow it in section 1. bear in mind  however  that inventions are rarely made with little search. in the cheese cutting case  there might be many ways of applying each heuristic  only a few of which are even remotely viable. 
it's worth noting that both of the other heuristics might be used  too  for this situation. the first one could have us look at recent inventions which  cut : a laser for cheese slicing  t h e third heuristic might have us build a better mousetrap: go into business selling already sliced cheese; or try to devise a  cheese press  that takes the crumbs and squeezes them together into slices. 
1.1 	jndging 	'intnrcstinfliioss* 
let's put our theory to a most severe test  by asking whether it can account for our everyday judgments about what is and isn't  interesting . this would seem to be the realm of intuition  emotion  taste  and aesthetics - the antithesis of logical empiricism 
if in fact there is a large  hormonal component  to such judgments  then it is not surprising if they lie outside the power of any theory founded on a view of man which ignores that aspect of him. so even a partial success at explaining  taste  in terms of heuristic rules would be a major triumph for the theory  showing it had some relevance to these phenomena 
such a partial explanation is easy to find. texts on the arts abound with  rules  of composition. they analyze works in terms of symmetry  coincidence  recency  unconventionaliiy  harmony  balance  utility  associations  etc. a typical rule might say 
if two apparently disparate  par is of the work arc suddenly recognized as being very closely related  
then that increases the interetigncm; of both parts  and of the whole work as well. 
t h i s explains the eternal popularity of the  recurrent theme  in all genres of literature and cinema. it explains the impact of having a single melody recur frequently but with slight differences each time  the concept of  musical variations   dickens' success is due in no small measure to his mastery of this heuristic  i.e.  

computers a thought: lenat 

 coincidence  : the reader is always astonished and pleased when two separate diameters are discovered to be one and the same person. the above heuristic also explains why  aside from cost  the hot-kiufe might be better received than the laser-knife  the consumer alrearly possesses hot combs  electiic blankets  electric knives ... so the hot knife would be instantly accommodated  with even a modicom of pleasure at the new bit of  closure  that had occurred in his world . 
1.1 	scientific problem solving 
suppose we're designing a molecular genetics experiment  which will ultimately result in a certain biochemical end product. we must design a very long chain of steps  perhaps reaching into the thousands   each of the form  raise the temperature to x    add the following  nucleotide...   etc 
 the search for a successful solution  a path  a sequence of steps leading to the final product  is made much simpler when we're able to apply some heuristics. it's a common practice  for example  to ignore certain kinds of minor steps  and to concentrate on finding a relatively small sequence of important intermediate products. that is  we should first find a solution in a heavily restricted  hence small  space. afterwards  we can  fix up  the connections between these steps  e.g.  in case one of them must occur at 1＜ and the next must occur at 1＜  by adding many minor steps. we don't begin to execute the first step until this detailed sequence of steps is fully specified. we solved the problem by applying a general heuristic: planning. the basic technique of planning can be expiessed as follows. 
if you arc lated with a search through a iarge space of possible solutions;  and some aspects of each  intermediate stale  along the way to a solution are mote important than others. 
then try to ignore some of the delailed aspects of the problem  thereby simplifying il. solve the simpler problem  and try to extend that solution into a solution of the original hard problem. 
in the molecular genetics case  we chose to ignore such factors as the temperature at which a step must be carried out. the heuristic used is just the one we used in the previous subsection to find a route from cmu to mit. there  we chose to ignore all minor roads on the map. this repetition is not accidental; it illustrates the commonality between everyday problem solving and scientific problem solving. the next section will show the similarity between everyday invention and scientific invention. and that's what we set out to show! 
1.1 scientific invent inn 
suppose we're confronted with the following problem; we're fond of factoring numbers  e.g.  1x1   but often there are many little sets of factors that they crumble into  e.g.  1 crumbles into the following four sets: {1   {1.1   {1 1}. {1 1} . we may be content with this situation  or we may try to improve it in some way  or we may wish merely to find out more about factoring. 
the latter two options both involve searches in enormous spaces  looking for a new kind of factoring; looking for new facts about factoring . but we have many rules of thumb to help us  including the three rules which were displayed in section 1. 
one of them   1  says to look for motivation at the extreme cases of various known relationships. the relation in this case is  divisors of . it maps a number into a set of numbers  e.g.  divisors of i1  {1.1.1} . an extreme case would be when it mapped a number into an extreme kind of set - say a singleton  doubleton  or empty set. in other words  consider the-set of numbers with no divisors  with one divisor  and with two d.ivi.sois. voila  we've invented prime numbers. notice that we used the very same heuiistic  #1 in section 1  that jed earlier to the invention of the wire cheese cutter and the hotknife. 
1 1.i judging' initiestingness' 
even allowing that the  heuristic rule guided search  theory could account for the discovery of prime numbers  could it also explain how a researcher might have noticed that they were valuable  interesting  worth naming  and worth remembering  
let's look at how the following three heuristic rules could lead to the conclusion that  primes  is interesting  soon after it had first been defined. 
ik specializations of conccpl 1 have just been created  and the current task is to find examples of eaeh of them  
thkn one rnetliod is to look over i lie known examples of c; they may he examples of some of the new specialized eoneepls as well. 
ik all examples of a concept c  turn out to be examples of another concept d as well  and c was not previously known to he a specialization of d  
t h k n conjecture that c is a specialization of d  and raise the  interestiriftiicss  value o| hnl.lt concepts. 
ik all examples of a concept turn out to he in the domain of a rarely-applicable function k  

computers a thought: lenat 1 

th kn il's w o r t h compuing all their k-values  their images uinlrr llto  million i    ami minlying lltal roller! ion of v values as a kcparnlr concept. 
suppose we've just defined the set of numbers which have no divisors  the set of numbers which have only one divisor  only two divisors  only three-divisors. the lust of the three heuristics tolls us a quick way to find examples of those new special kinds of numbers: look at the known examples of numbeis  say the integers from i to 1  and dump each one into whichever new specialized set s  it belongs. if we do this  we get the following; empirical results: 
numbers with no divisors:  none found  numbers with i divisor: 1 
numbers with 1 divisors 	1  1  1  1  1  1  1  1  ... 
numbers with 1 divisors: 	1  1  1  -1  1  1  1  ... 
we can then apply the second heuristic: to each set of numbeis  to see if it's interesting. in this way  we'll notice that the last set  numbeis with three divisors  are all perfect squares. heuristic #1 directs us to take then square roots. lo and behold tliey'ie piecisely the thud set of numbers  i.e.  numbers with two divisors; i.e. primes  heuristic #1 notices this  and drastically increases the intereslin ness values .of both nos-with-1-
divisors and primes. 
so we were able to fit this kind of judgmental evaluation of  intercstingness  into the same theory. notice that the heuristics above are actually quite general: they  or at least analogues of them  can be used to evaluate works of art and new mechanical gadgets  as well as to evaluate new mathematical definitions. we saw the analogue of heuristic #1 used before  in section 1 1   to help judge the intetestingness of a tale of two cities and of a new kind of cheese cutter. other analogous heuristics  which favor various kinds of  closure  are used in all sciences  e.g.  consider the popularity of  charm   even before the confirming discovery of the dmeson  richter 1  . partial de-mystification of such phenomena as illumination  incubation  aesthetic taste  etc.  is one valuable result of this kind of ai research. 
1. models 
let me now describe a few landmark computer programs that have been written  models based on the theory of intelligence as heuristic rule guided search. 
1 in the terminology of that section  the two  disparate parts  were  numbers-with-1-divisors  and  numberswith-1-divisors . 
these programs form but a thin sliver of the work that has gone on under the label of  artificial intelligence . 1 don't want to distract from the themes of this talk by cataloging  lie various efforts; a glimpse at the table of contents of this conference's proceedings will give you a pictuie of then scope. 
1..l 	lt and g p s : g e n e r a l problem solving 
probably one of the earliest ai piograms written was the logic theorist   it   to its friends   newell  shaw  and simon 1  it was repeatedly given symbolic logic theorems from p i h u i p i a mathematica  and its task was to find a formal proof of each theorem lt had some given axioms and rules of infeienre. to search for a proof  in a completely exhaustive  systematic manner  would be quite an undertaking! but lt had a few heuristics which constrained its search: 
 ...selecth/e principles that enable solutions to be found after examining only a relatively tiny subset of the set of possibilities. one such principle - illustrated by the methods in the logic theorist - is to renerate only elements of the set that are already guaranteed to possess at least some of the properties that define a solution. another principle -- illustrated by the matching process in lt -- is to make use of information obtained sequentially in the course of generating possible solutions in order to guide the continuing search. a third principle -illustrated by the use of similarity tests in lt -is to abstract from the detail of the problem expressions and to work in terms of the simpler abstractions.  
-  newell and simon 1 . p. 1. 
after they learned the power of heuristics from lt  the same group of researchers then worked on a program called gps  for general problem solver. its aim was to embed the above heuristics in a domain independent form  one not tied to solving any particular problem  the way that lt was tied to propositional calculus it was hoped that any problem could be representee  in the gps formalism  and hence solved by gps. gps contained a few new heuristics: 
1. means ends analysis: taking differences  between the-current state and the desired goal   locating operators relevant to reducing those differences  
computers a thought: lenat        ai includes such disparate pursuits as machine perception  speech understanding  image parsing ...   natural language understanding  novel ways to represent knowledge  novel ways to control the attention of the computer  and ways to transfer some of what's been learned into improved teaching methods for people. 
and applying those operators. note that this heuristic guides forward search toward a goal. 
1. setting up subgonls  especially subgoals of the form 
 gps wants to apply operator x  so x's preconditions must becomr satisfied  true  . this heuristic is equivalent to the idea of problem ieduction  to divide and conquer strategies  etc. 
1. work on the most difficult of the subproblerns first. try to reduce the most important difference first. 
1. planning in an abstraction space. systematically ignore some kind of details in the original problem. this results in a much smaller search space  m which a solution can be more readily found. this solution is then used as a guide to finding a solution in the original  huge search space. 
i el's say a few more words about that last heuristic  planning  and how it was used when gps was set to the very same task which lt had al tempted: propositional calculus theorem proving. what gps did was to take all the axioms  rules of inl'eience  and the desired theorem  and then simply remove all the logical connectives from them. thus the modus ponens rule of inference would be transformed from  from 'p' and 'p 
implies 1'  conclude '  '  into this more abstract form:  from 'p' and 'poj  conclude 'q  this would sometimes produce fallacious proofs  or proofs with missing steps  etc.  but by and large it was quite cost effective  allowing the rapid solution of many otherwise intractable pioblerns. after the planning process was over  there would still have to be some  fixing up  of the details between steps; this was also what we observed for route planning and for molecular genetics experiment planning  
a decade or two of research has shown that  yes  a large array of problems can be cast in terms that gps can deal with  states  operators  difference tables   but no  gps' general heuristics just aren't powerful enough to solve problems as difficult as can be tackled by humans. 
1. dendral: scientific problem solving 
the next giant step along the line of development we're following was taken by ed feigenbaum and joshua lederberg  lederberg 1   soon to be joined by bruce tuichanan  buchanan et al 1 . they'* recognized what was lacking: expertise. humans had to train in 
l
* at about the same time  joel moses independently arrived at the same conclusions. he developed an expert program for the task of symbolic integration  moses 1 . 
specialized fields for quite a while before tbey were able to solve any hard problems in them. this phenomenon ought not just be a reflection of human brain frailties  it might indicate a necessary requirement for intelligent problem solving in a complex knowledge rich domain. 
in 1 they conceived a new computer program  and in the process a whole new appmach for al: they were willing to commit then program to working on a very specific kind of problem - in their case  the enumeration of atom bond graphs of organic molecules {based on analysis of mass spectrograph data and nuclear mass resonance data . they built their program  dendral  around a body of heuristics -- not just a few  but a few tens of heuristic rules. some of them were as general as the rules that lt had  but most of them were domainspecific informal rules of rhumb which they extracted from chemists  including some of the top experts in the field . these new heuristics were task-dependent: they won't work equally well for identifying images as for identifying unknown compounds; they were specific to the field of mass spectroscopy. even more important than their specificity is then power: they constrain the searching tremendously.' * 
the success of this research confirmed some of the conclusions of newell  shaw  and simon: the tradeoff between generality and powei  the importance of heuristics for guidance feigenbaum  lederberg  and piiichanan were willing to tap some of the  power  that humans need for.specific technical tasks. 
1. am: scientific .invention 
we now jump to quite recent research  by the author. 
the next step in the progression we're chronicling involved collecting hnuheds of heuristics  used in some very difficult task  on the frontiers of what humans can perform. in this case  the task chosen was that of discovering interesting new concepts in elementary mathematics  that of scientific theory formation  of openended research this is scientific invention  as compared to dendral  which performs scientific problem solving. 
     the size of the space to be searched is greatly reduced  hence searching will take much less time. thus  heuristics  which serve to constrain  are equivalent to power  more efficient searching . 
computers & thought: lenat 1      this is not the  inductive vs. deductive  issue: both dendral and author's program  called am  performed quite inductive tasks. the difference was that dendral was given specific problems to solve  specific mass spectra to identify   whereas am's activities were open-ended research  with no particular goal specified. 
am's heuristics guided it to make promising new definitions  explore those new concepts  and judge the interestingness of its discoveries am noticed connections between concepts  and was thus a theorem proposer  but it had no theorem proving abilities whatsoever. a different set of heuristics would be required if am were supposed to prove any of the conjectures it proposes making the necessary definitions to notice the fundamental theorem of arithmetic  numbers factor uniquely into primes  is quite a bit different  more ill-de.fmed  more sophisticated  than proving it once you've conjectmed it. 
1.1 math discovery as heuristic rulc-cuided search 
the task which am performs is the discovery of new mathematics concepts and relationships between them. the simple paradigm it follows for this task is the one specified by our theory  in section 1 : 
1. the activity of open-ended math research is viewed as a search  an exploration in a space of partially-developed concepts. the goal of this search is ill-defined; it is to maximize the interestingness value of what's being worked on at the moment. 
1. am is guided in this process by a collection of a few hundred heuristic rules. they are relatively general rules of thumb which guide it to define and study the most plausible thing next. 
1. in each situation  am accesses potentially relevant heuristic rules  finds which of them are truly relevant  and then follows them. 
for example  am possessed a rule of the form  if f is an interesting relation  then look at its inverse . this rule fired  was relevant and was actually followed  after am had studied  multiplication  for a while. the rhs  right hand side  then- part  of the rule directed am to define and study the relation  divisors-of  e.g.  divisors of  1  - {1 1 1} . another heuristic rule which later fired said  // / is a relation from a into bt then it's worth examining those members of a which map into extremal members of b'  this is a specialized version of our old friend  rule *1 from section 1.1. in this case  f was matched to  divisors-of   a was  numbers   b was  sets of numbers   and an extremal member of b might be  e.g.  a very small set of numbers. thus this heuristic rule caused am to define the set of numbers with no divisors  the set of numbers with only 1 divisor  with only 1 divisors  etc. one of these sets  the last one mentioned  turned out subsequently to be quite important; these numbers are of course the primes  as we saw in section 1 . the above heuristic also directed am to study numbers with very many divisors; such  highly composite  numbers were also found to be interesting  by am  by the author  and by professional mathematicians  heuristics like those in section 1.1 quickly led am to boost the  interestingness  rating of the primes concept. 
1.1 	representation of mathematical knowledge 
what exactly does it mean for am to  have the notion of  a concept  it means that am represents that concept somehow  that there is a data structure of some kind which is meant to correspond to  and contain information about  that concept. while the entire issue of representation of knowledge lias been de-emphasized in this paper  it is helpful to glance at how one typical 
concept looked after am had defined and explored it: 
namk: 	prime number*  primes  numl ers-u'itli-1- divisors dkfinitions: 
origin: niimil ei-of- liv.sor*~of x  -  . 
prki .-gai 1|ii 1is: primeu  *  v./.  /|x -  z=l xoh /  x  
itkrativk:  for x l : kor i from 1 to x-1  - .|x  
kx am pits: 1  1  .r   1  1  1  1 
boundary: 1  1 luhindaky-taiitkks: 1  1 
ka1uikks: 1 
cknkrauzations: niunhers  numbers with an even 
no. of divisors  niimlx is with a prime no. of divisors 
specializations: prime  pairs  prime uniqiielv-addablrs 
c.on.jkc'.s: unique faelorr/.at ion  coldbaeh's conjecture 
analogies: maximally-divisible number* are converse extremes of divisors-of 
interest: conjecv tying primes lo times  lo divisors-of  and to other closely related operations 
worth: 1 
 the representation of a concept is as a collection of facets  each of which can have some associated value. for example  the value of the worth facet of the primes concept is 1. another sample concept   sets   is presented earlier in these proceedings  in section 1 of 
 tcnat 1   
1.1 	flow of control 
am is initially given a collection of 1 core concepts  with only a few facets  i.e.  slots  filled in for each. am repeatedly chooses some facet of some concept  and tries to fill in some entries for that particular slot. thus a  job  for am is simply to engage in a mini-research project  to commit a simple act of discovery. its overall task - to discover interesting concepts and conjectures - is accomplished as a composition of hundreds of these repeated attempts at little discoveries. to decide which small job to work on next  am maintains an agenda of jobs  a global queue ordered by priority. a typical job 

computers a thought: lenat 

is  fill1n examples of primes . the agenda may contain hundreds of such entries. am repeatedly selects the top job from the agenda and tries to carry it out. this is the whole control structure! of course  we must still explain how am creates plausible new jobs to place on the agenda  how am decides which job will be the best one to execute next  and how it carries out a job. . 
a heuristic rule is relevant to a job if and only if executing that rule brings am closer to satisfying that job. potential relevance is determined a priori by where the rule is stored. a rule tacked onto the domain/range facet of the compose concept would be presumed potentially relevant to the job  fill in the domain of sort olnseit . the left hand side  if- part  of each potentially relevant rule is evaluated to determine whether the rule is truly relevant. 
once a job is chosen from the agenda  am gathers together all the potentially relevant heuristic  rules - the ones which might accomplish that job. the truly relevant ones are executed  followed   and then am picks a new job. while a rule is executing  three kinds 
of actions or effects can occur: 
 i  facets of some concepts can get filled in  e.g.  examples of primes may actually be found and tacked onto the  example*  facet of the  primes  concept . 
 ii  new concepts may be created  e.g.  the concept  primes which arc uniquely representable as the sum of two other primes  may be somehow be deemed worth studying . 
 iii  new jobs may be added to the agenda  e.g.  the current activity may suggest that the following-job is worth considering:  generalize the concept of prime numbers  . 
the concept of an agenda is certainly not new: schedulers have been around for a long time. but one important feature of am's agenda scheme is a new idea: attaching - and using -- a list of quasi-symbolic reasons to each job which explain why the job is worth considering  why it's plausible it is the responsibility of the heuristic rules to include reasons for any jobs they propose. 
am uses each job's list of reasons in three ways: 
i. when a job already on the agenda is re-suggested  the supporting reasons are examined: if the job is being proposed for a new reason  then its priority  and hence its position on the agenda  will be raised; but if the job is being proposed for an already-recorded reason  then it's priority rating won't change. 
1 once a job has been selected  the quality of the reasons is used to decide how much time and space the job will be permitted to absorb  before am quits and moves on to a new job. 
1. to explain to the human observer precisely why the chosen  current  job is a plausible thing for am to concentrate upon 
each of am's 1 heuristic rules is attached to the most  general  o  abstract  concept c for which it is deemed appropriate. the relevance of heuristic rules is assumed to be inherited by all c's specialisations. for example  a heuristic method which is capable of inverting any relation will be attached to the concept  relation ; but it is certainly also capable of inverting any permutation. if there are no known methods specific to the latter job  then am will follow the generalisation links upward from permutation to rejection to function to relation...  seeking methods for inversion. of course the more general concepts' methods tend to be weaker than those of the specific concepts 
in 	other 	words  	the 	aggregate 	of 	the 
generalization/specialisation relationships among the concepts induces a similar graph structure upon the set of heuristic rules. this  inheritability property  permits potentially relevant rules to be located efficiently. 
1.1 	behavior of this rule system 
am began its investigations with scanty knowledge of a hundred elementary concepts of finite set theory. most of the obvious set-theoretic concepts and relationships were quickly found  e.g.  de morgan's laws; singletons   but no sophisticated set theory was ever done  e.g.  cliagnnalizatinn . rather  am discovered natural numbers and went off exploring elementary number theory. arithmetic operations were soon found  as analogs to set-theoretic operations   and am defined such concepts as prime pairs  diophantine equations  the unique factorization of numbers into primes  and goldbach's conjecture. many concepts which we know to be crucial were never1 uncovered  however: remainder  gcd  greatcr-than  infinity  proof  etc. 
1
computers & thought: lenat 1 　 am did not run forever  despite what anybody at sumex tells you . all the discoveries mentioned were made in a run lasting one rpu hour  intorlisp+1k  sumex pdp-1 ki . two hundred jobs in toto were selected from the agenda and executed. on the average  a job was granted 1 cpu seconds  but actually used only 1 seconds. for a typical job  about 1 rules were located as potentially relevant  and about a dozen actually fired. am began with 1 concepts and ended up with three times that many. half of the synthesized concepts were technically termed  losers   both by the author and by am . 
although am fared well according to several different measures of performance  see section 1 in  lenat 1    it had some difficulties. as am ran longer and longer  the concepts it denned were furthei and further from the primitives it began with; while the general settheoretic heuristics were technically valid for dealing with primes and arithmetic  they weie simply too general  too weak to guide effectively. the key deficiency was the lack of adequate mcla rules  davis 1 : heuristics which cause the creation and modification of new heuristics. we are attempting to remedy this in eur is kg  see section 1 . 
am did demonstrate that scientific theory formation  the defining and exploring of new concepts and relationships  could be mechanized  could be modelled as heuristic rule guided search  using a few hundred heuristics for guidance. this is a significant verification 
of the theory of intelligence presented in section 1. 
1.-1. other heuristic rule guided...exportjprofirams 
there are several programs like am in existence  knowledge based expert programs which perform under the guidance of a large collection of heuristic rules. 
  the mycin program  aikms 1   shortliffe 1  contains a couple hundred judgmental rules which were extracted from physicians  and it uses them to make diagnoses of various blood and meningitis infections 
  tf.ires1as  davis 1  uses  meta-lcvcf knowledge rules to aid a human expert in transferring his knowledge to a program. its initial task has been to assist physicians in adding new rules to mycin. 
  molgen  martin et .al 1  attacks the molecular genetics experiment-planning problem discussed earlier  in section 1  
  meta-dendral  buchanan and mitchell 1  is a theory formation program which looks over mass spectra and then correct identifications  and then abstracts that data into new fragmentation rules  new pieces of mass spectroscopy theory. these rules are then usable by the dendral program  as if they had been extracted from a human expert. 
  the pecos program  barstow 1  contains rules about computer programming  and is a key component in an automatic programming system. 
  ut-itp  bledsoe and tyson 1  is a natural deduction system  guided by a collection of judgmental rules useful when constructing formal proofs. 
  the prospector program  duda et al 1  performs geological analysis of aerial photographs  aiding a human expert in the evaluation of the mineral potential of exploration sites. tts rules were gleaned from geologists  much as mycin's were from physicians. 
  the m-method program  zaripov 1  for improvising variations on a given melody is based around a body of musicology rules. 
  puff is a medical expert program  much like mycin in design  whose field of expertise is pulmonary disorders.  everything puff knows about pulmonary function diagnosis is contained in 
 currently  1 rules of the if..then... form.   feigenbaum 1  
  the eurisko program  lenat et al 1  is perhaps the most ambitious effort yet along this line  attempting to discover new heuristic rules in the domains it investigates. it is  ambitious  because even professional scientists are very poor at formulating - or even recognizing - new heuristics.1 eurisko's method for discovering and developing heuristics is simply to not distinguish between concepts and heuristics; i.e.  each heuristic is represented internally as a full-fledged concept. so  e.g.  any heuristic which can advise when it's time to generalize or forget any concept  can also automatically tell when it's time to generalize or forget any heuristic. any method for creating a new concept out of old ones can be used to create new heuristics out of old ones. evaluating the new heuristics is done just like evaluating any new concepts: by observing them in action  by gathering empirical data about them. 
     often  discovering a single powerful heuristic can trigger a scientific revolution  kuhn 1   e.g.  einstein's discovery of the heuristic  counterintuitive mathematical systems might have physical reality  led to a relatively important new paradigm in physics not too long ago.  counterintuitive mathematical systems may be consistent and interesting  led to a parallel revolution in geometry fifty years earlier. 

computers & thought: lenat 1 












1 

1 

1 



1 











1 

1 







