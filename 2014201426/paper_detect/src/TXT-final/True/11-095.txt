 data structures by giving the collections of procedures which define the primitive operations on them. they separate the part of the program which implements a structure from other parts which use it but have no concern with i t s representation. similarly in ai minsky's frame notion  minsky 1  offers a way of bundling together lisp functions into some meaningful entities. indeed one reason for the move away from a 'logical' representation of 
knowledge to a procedural one may be that we have some s k i l l at structuring programs but hardly any at structuring theories. 
　　　our work on theories derives from our attempts to clarify and generalise the above methods of building up programs in terms of abstract data structures. tackling problem specifications rather than programs turned out to use the same mathematical tools but to be rather less d i f f i c u l t . it is also an area overdue for illumination. the present paper sets forth in an informal way our f i r s t   tentative  proposal for a language in which one may describe theories. this language  called 'clear'  is intended prima r i l y as a tool for program specification  but it might also serve to represent knowledge in a machine manipulable form. we have largely worked out the mathematical semantics of clear  but we have not attempted to implement i t . 
　　　we w i l l f i r s t explain our notion of theory in general terms  then discuss possible areas of application. after this we w i l l describe our theory language and give some simple illustrations of i t s use. 
what we mean by a theory 
　　　the notion of theory is a loose intuitive one in mathematics. there should be axioms  rules of inference and theorems  but the language in which they are expressed is open to choice. a popular choice of a formal language would be f i r s t order predicate calculus  or more boldly a higher order calculus. some people  like the predicate calculus programmers  kowalski 1   would use a more restricted calculus  say horn clauses with free variables but no explicit quantifiers. we have chosen an algebraic notion of theory  due to lawvere  1   making it many-sorted  goguen  thatcher and wagner 1  and with provision for errors  goguen 1 . 
　　　a many-sorted algebraic theory is given by naming a set of sorts  a set of operators over those sorts and a set of laws which those operators must satisfy. the laws take the form of equations with free variables but no quantifiers. since we may introduce truth values as a sort and two no-argument operators  constants  true and false  we can introduce predicates as operators producing a truth value as result  just like lisp . 
here are two examples:-
vector spaces 	the sorts are scalar and vector. 
the operators are scalar addition and multiplication  scalar zero and one  vector addition  vector negation  vector zero  and vector-byscalar multiplication. 	the laws are associati v i t y and commutativity for scalar addition  identity for scalar zero with addition and so on. 
gps  general problem solver  the sorts are states  actions  action-sequences  state descriptions  attributes  values and differences.  in gps attributes of states have values  which give rise to differences between states.  the operators are   i   apply  taking an action and a state to a state    i i   descriptionof  
　　　
invited papers-1: burstall 
1 
　　　
taking a state to a description    i i i   valueof  taking a description and an attribute to a 
value   iv  undefined  a constant for a state  and so on. 
there are some laws  for example:apply a undefined  = undefined  concatenation of action sequences is associative. 
　　　lawvere showed how such a theory description can be taken to denote a more abstract algebraic structure  namely a collection of operators susceptible to 'composition'  substitution  and ' t u p l i n g ' . this is important because he was able to develop some theory about 'theories'   i f you can have a theory about 'groups' you can have a theory about 'theories'   and his work enables us to give a mathematical basis to our language for denoting theories. it is not appropriate to go into thi1 mathematics here  but it is a comfort to us that we have managed to outline a proper semantics for our language; we hope to develop this and write it up soon for publication* 
　　　not only is it relatively easy to reason about algebraic theories  but there is evidence that it is relatively easy to reason within an algebraic theory  indeed that is just the domain which was tackled very successfully by boyer and moore  1  with their lisp theorem prover  subsequently enhanced to deal with many sorts by aubin  1 . 
　　　we already have some encouraging experience of using algebraic theories  but not structured ones  as a specification tool  goguen 1  goguen  thatcher and wagner 1 . 
　　　the use of algebraic techniques for specifying abstract data types has been studied extensively by zilles  1  and by guttag  horowitz and musser  guttag 1  guttag et al 1  who give examples of program verification using such specifications. 
　　　we should remark that although we have chosen to use algebraic theories rather than predicate logic or lambda calculus theories  the methods we have used to combine them are rather general and may well apply to other kinds of theory. 
　　　we have not written out the above examples of theories' in f u l l because they would be long and hard to understand; even eight operators and a dozen laws is a l o t to swallow in one bite. a mathematics book would scarcely present the concept of vector space without some preparation on semigroups  groups and fields. indeed most of the structure can be explained by saying that the scalars form a f i e l d and the vectors a group. we then have to impose some extra conditions  e.g. commutativity of vector addition  and enrich the structure with an extra operator  multiplication of vectors by scalars  which is distributive  etc. 
　　　similarly gps becomes much easier to understand if we f i r s t describe a state-action system  then say that action-sequences are just strings of actions whose effect is the composition of the effect of the component actions. we can independently enrich the idea of state with attributes and values  saying that descriptions are justarrays   f i n i t e functions  from attributes to values. only then can we put it a l l together and introduce the notion of the differences reduced by an operator. 
　　　this then is i n t u i t i v e l y what we mean by building up a theory in a structured way: any good textbook does it a l l the time. luckily lawvere's notion of the category of theories supplies the mathematical correlate of this informal exposition and enables us to apply known mathematical methods  'colimits'  to the task of constructing theories by using other theories as ingredients. 
　　　one may view a theory as a natural generalisation of the notion of abstract data type. such a type is characterised by the operations which create i t s elements or apply to them. a theory may consist of several such types with the operations between them  thus avoiding the d i f f i culty of a r b i t r a r i l y assigning an operation from a's to b's to type a or to type b. analogous to a group of procedures which realise a data-type  as in simula  clu or alphard  would be a group of procedures which realise a theory. we learned recently that nakajima  honda and nakahara  1  
had also been working on this idea and had 
designed a programming language to incorporate i t . their use of theories in a programming language is close to what we had in mind. we hope that the mathematical methods we have for structuring specifications can be adapted to give semantics for such a programming language  see our tentative remarks about programs as theory morphisms later on . 
specifications required for -program verification  transformation and synthesis 
　　　program verification has been a continuing concern since mccarthy's classic paper  1   recently there has been considerable interest in synthesising programs from their specifications  manna and waldinger 1  1   dijkstra  1   darlington  1  1   one promising method being to take a very naive program as the specification and transform it into an acceptably efficient one  darlington and burstall 1  burstall and darlington 1  arsac 1 . all of these techniques for obtaining correct programs must start from a specification. verification  whether by hand or by machine  makes heavy weather even of non-trivial 'text-book' programs and s t i l l seems impractical for the much longer programs met with in practice. this comparative lack of success of verification techniques has obscured the fact that for large programs not only are we 
unable to carry through a correctness proof  but usually we cannot even specify the problem which the program is supposed to solve.* similar remarks apply to program synthesis. 
* for an overview of specification techniques  with many references  see liskov and berzins  1 . 
　　　
invited papers-1: burstall 
1 
　　　
　　　there are exceptions. to specify a compiler  and hence verify i t   you need to define the source language and the target machine. scott and strachey  1 and subsequent papers  battled valiantly to give us precise semantic definitions of programming languages. unfortunately  for large languages the specifications are very hard to understand  robert milne had one for algol-1 which he declined to publish on the grounds that no-one would read i t   . we surmise that a good part of the trouble may be the lack of structure in such a formal definition  the structure that the writer of an informal manual for a language 
must be very careful to make clear.* 
　　　thus we feel that a better grip on the way to structure the theory in terms of which specifications are made is a prerequisite for raising 
verification and synthesis techniques above the toy problem level. 
specifying ai problems 
　　in ai research  as in other disciplines dealing with complex programs  there is a tendency to write the program but never get around to specifying the problem. further any large program must be composed of subprograms  and these cannot be understood without a clear specification of the subproblems they are supposed to solve. thus better tools for problem specification are a pressing need in ai. 
　　　not only slould the theories used in specifying these problems and subproblems be well structured  they should also be sufficiently abstract. they should be concerned with the abstract nature of the data and the operations to be performed rather than the particular problem domain or the specific machine representation of the data. for example walts's  1  work is 
about the abstract notion of networks of relations  rather than just about blocks and shadows or about lisp s-expressions; i t s f u l l u t i l i t y can only be exploited if this is kept in mind  see mackworth 1 . our theory language must be able to handle such abstraction and enable us to hide unnecessary detail. 
representing knowledge within an ai program 
　　　ai programs are commonly conceived to embody knowledge  whether as program or as data. procedural embedding of knowledge may promote efficiency  and it may enable one to use existing program structuring techniques to impose some order on the embedded knowledge. however procedural embedding has disadvantages of i n f l e x i b i l i t y   and it makes it d i f f i c u l t to incorporate new knowledge  whether input or from inductive learning. much of the disquiet with knowledge held as data seems to us to stem from i t s lack of structure  a large collection of axioms or facts unorganised  slowing processing down with irrelevant information. 
　　　again we are exhorted to consider our commonsense knowledge of the world as composed of a large number of micro-theories about particular * mosses  1  makes a start in this direction. aspects. but we are l e f t largely in the dark as to how to put these micro-theories together. this 
question of 'putting theories together' is close 
to the heart of our concern. 
　　　thus although we cannot yet speak from experience  we very much hope that our theorybuilding techniques may eventually give some fresh insight into the appropriate organisation of knowledge in ai programs. a way of presenting theories so that people can understand them might help us to see how machines can 
make use of them. 
theories 
　　　we start our exposition of the language clear by looking more closely at the notion of many-sorted algebraic theory. 	our theories w i l l also make provision for errors  like division by zero  but we w i l l defer consideration of this u n t i l we have the basic ideas straight. 
　　　first we need the notion of a signature  that is a vocabulary of operators with given sorts. 
　　　a signature is a set of sort names and a set of operator symbols  each with a given sequence of 1orts for i t s arguments and a sequence of sorts for i t s results  possibly more than one result . 
we write w : 	s 1   . . .   s 	-  sj ....... sn' to show that 
w is an operator with input 1rts 	s1. .. sm 	and 
output sorts s1' ... s'n.* 
example 1 	natural numbers 
	sorts 	nat  bool 
operations zero 	: -  nat succ 	: nat -  nat iszero: nat -  bool true 	: -  bool false : -  bool not 	: bool -  bool or 	: bool  bool -  bool 
example 1 geometry  a fragment  sorts line  point  bool operati ons .join : point  point -  line intersection: line  line -  point 
colinear : point point point- bool true : -  bool false : -  bool not : bool -  bool 　　　a theory presentation is a signature together with a set of equations using the operators of the signature and respecting their input and output sorts. the equations have variables which are i m p l i c i t l y universally quantified. 
example 1  continued  variables m n: nat equations iszero zero  = true iszero succ n   = false not true  = false not false  = true 
* for multi-result operators we could use a syntax like  ...a...r... where  q r  = quotient and -remainder m n    but we will not need them. 
　　　
invited papers-1: burstall 1 
　　　
example 1  continued  	the theory boolo 
　　　
variables p q r: point; l m: line equations intersection join p.q .join q r   = q join p q  = join q p  not true  = false etc. 
　　　a theory is a signature together with a set of equations closed under inference by reflexivity  t r a n s i t i v i t y and symmetry of equality and by subs t i t u t i o n . for example 'false = iszero succ succ  zero   ' is an equation in the theory defined by the presentation above. 
　　　thus each theory presentation gives rise to a theory but the same theory can be presented in 
more than one way by choosing different sets of 
'axiom' equations to generate i t    the notion of theory is more basic than theory presentation in the sense that one would like to talk about the theory of groups for example irrespective of any particular axiomatisation of i t     * 
　　　the interpretations of a theory are algebras  where an algebra is a collection of sets  one for each sort  with a function over these sets assigned to each operator of the theory. these functions must obey the equations of the theory. in practice for theories containing bool we w i l l only be interested in 'consistent' interpretations in which true   false. 
theory-building operations 
　　　in the last section we were just writing down theories e x p l i c i t l y one at a time. as soon as they get to be interesting they become incomprehensible. we wind up with a large set of equations that no-one can understand and which are almost certainly wrong. so we must build our theories up from small i n t e l l i g i b l e pieces. for this we need 
  i   the a b i l i t y to write  small!  explicit theories  as above  thus 
theory sorts . . . opns . . . 
eqns . . . endth 
  i i   four operations on theories  combine.enrich. induce and derive  which enable us to build 
up theory expressions denoting complex theories. 
we w i l l explain these operations informally  using examples. 
first we define two explicit theories which w i l l be useful 

　　technically we should call this a 'theory with signature' rather than just a 'theory' because the choice of a particular set of operators is irrelevant to the abstract notion  just as is the choice of particular axioms  see lawvere 1 or manes 1 . 

 strictly we ought to insert 'variable p: bool' before 'eqns'. but we w i l l assume that undeclared single l e t t e r identifiers are variables; their type w i l l be obvious. we w i l l also allow ourselves to use traditional infixed symbols like a.  
combine 
　　　this operation is dull but plays i t s part in the larger scheme of things. we simply take two theories and add them together. the sorts of the resulting theories are the union of the sorts of the given theories  the operators are the union of their operators  and the equations are the union of their equations. we use the + sign for the combine operation. 
for example boolo + nato could be written 
e x p l i c i t l y as 	-- 

　　　we w i l l see later that combine does not necessarily produce the disjoint union of two theories; it allows for sharing of common subtheories. 
enrich 
　　　suppose that we want to build up a useful theory of the natural numbers including operators for ordering and for equality. 	the operators   and eq belong neither to boolo nor nato  but they can be added to their combination to obtain a new theory 

　　　in general one may add new sorts as well  thus 
　　　
invited papers-1: burstall 1 
　　　
	enrich . . . . by 	and operations which we require. for example  if 
	aorta . . . 	we only need eq from nat  and not   or zero or 
succ  we may write the theory natequal 
derive 
sorts element  bool 
opns equal  true  false 
from nat by element is nat bool 	is 	bool 
equal is eq 
	true 	is; true 
	false 	is  false endde 
       this denotes a new theory with two sorts and three operators. the equations governing the new operator  equal  are not specified. indeed we have only given the signature of the new thonry. but. the properties of equel are given implicitly by the correspondence equal is eq. notiee- thet the equations for eq use the auxiliary operator  . in general an operator of the derived theory may correspond to a λ defined operator of the original theory  thus  plus1 is λ n.succ succ n   . 
for brevity we will omit pairs of the form 
'x is x'  such as 'true is true'. also if we already have a theory t we may write'signature t' to denote its signature. 
       we use derive when we want to define a theory in terms of some other theories with which we are already familiar but which  taken together  are too rich for our purpose. we are making a construction from familiar mathematical objects  but the details of the construction are discarded in the more abstract result. an analogy would be the construction of the natural numbers in terms of the sets         {      } ... . the operations 
we need on the natural numbers are  say  zero  
successor and    other possible operations on these sets  such as cartesian product of two sets  are not meaningful for numbers. 	in programming 
work it is well-known that the operations on an abstract data type are defined in terms of those on a more concrete type which represents it; but 
at the abstract program level the more concrete 
operationsshould not be available. 
procedures for theory-building 
　　　we have some primitive operations on theories. the next step is to enable the user to define his own operations using these. for this we introduce procedures - no self-respecting language could be without them. 
       we shall introduce the simplest mechanisms which provide tolerably convenient facilities  namely 
 i  theory constants  enabling us to give a name to a theory 
 ii  theory procedures  taking theories as their parameters and producing a theory as a result. their bodies use the primitive operations already defined and may call other theory procedures  but we eschew * technically  induce t  is the theory of the recursion   initial algebra of t1 
invited papers-1: burstall 
1 
　　　
  i i i   local theory definitions  permitted in the bodies of theory procedures  thus:l e t t = . . . in . . . . 
　　　these f a c i l i t i e s would be very similar whatever domain we were working i n . let us introduce them in the familiar domain of numbers and truth-
values as a warming up exercise. we w i l l assume the primitives *  multiply   / divide  and i f . . . then...else... 
　　　a constant declaration  .just assigning a fixed value to an identifier p i   would be constant pi - 1 
　　　a procedure declaration for a procedure producing a number as result would be procedure f   x : number  b: boolean  = 
if b then pi * x else 1 
　　　a procedure declaration with an auxiliary local variable z would be procedure g y: number  = 
let z = f  y * y  true  in s * z * z 
　　　now if we evaluate g 1   1  takes the value f 1*   true   i.e.  1 *1  and g 1  is the cube of this value. 
　　　now the same definitional methods and syntax w i l l apply to theories  using the theory-building operations instead of *  if-then-else etc.  we do not need conditional expressions for theories . we w i l l need the type specification for parameters  as in x: number  since it turns out that there is notion of type for theory parameters. 
　　　there is one major difference however between numbers and theories as a domain. two theories may share some common subtheory. for example the theory of natural numbers has bool as a subtheory since it has predicates like    so does the theory of character strings which has predicates like isempty. we may want to enrich the combination of these two theories to allow operators like length: string -  nat 
　　　in this new theory we want the truthvalues produced by   to be the same as those produced by isempty. we want one copy of bool not two. thus bool is a shared subtheory. 
　　　where have we met this situation before  in lisp or any other language with pointers we have shared substructures. let us see how the definitional mechanisms we have introduced would behave with shared l i s t s . we w i l l then be ready to tackle theories. we need atoms  a   b etc.  the l i s t constructor cons  the selectors car and cdr and  crucially  the predicate eq which tests whether two l i s t s are equal in the sense of starting with the same l i s t c e l l   not just having the same shape. we w i l l not use lisp syntax  but 
we intend lisp semantics  passing parameters by pointer than than copying the l i s t structure. let us look at examples  the intended values of the expression are given on the right  
	 i  	eq cons  a  b  cons  a  b   	. . . . 	false 
	  i i   	constant ab = cons  a  b  
	eq ab ab  	... 	true 
  i i i   constant ab = cons  a   lb  eq cons ab   c    cons ab   c   . . . . f alse eq car cons ab  c    car cons ab   c    . . . . 
true 
 iv  procedure p   l ; l i s t   = eq l l  
	p cons  a  b   	. . . . 	true 
 v  procedure p   l : l i s t   let m - cons l  c  in e1 m m  
	p cons a  b   	..... 	true 
　　　thus every use of a constant  parameter or local variable refers to the same l i s t   to within eq  but writing down an explicit expression twice using cons refers to a different l i s t   i   . two different l i s t s can share a common sublist   i i i   . 
　　　now our theory-making operations  explicitly writing a theory and enriching one  behave ju1t like cons. but by using theory constants or 
variables we can arrange for the theories we create to contain shared sub-theories- one of our main technical problems was to make this remark precise  since for theories we do not have the addre1s/value storage model as we do for data structures. in fact the category theory ideas of  diagram  and i t s  colimit  give a rather general notion of shared substructure. we hope that the reader's intuition using the lisp analogy w i l l give him a reasonably good grip on the intended semantics. those who wish to know the precise 
method for determining the denotation of our specifications must await the mathematical semantics in the paper which we are preparing. 
the specification language clear 
　　　we w i l l call our proposed specification language  clear . a specification in clear consists of a sequence of constant and procedure declarations followed by an expression. the expression denotes a theory  not explicitly but using the theory-building operations and the declared constants and procedures. 
　　　clear can be viewed as a language for communicating a precise specification of a problem to people  such as programmers- it could also be implemented on a machine so that 'evaluation' of a clear specification yielded an explicit representation of the theory it denotes- a more useful implementation however would be to link clear to an equatinnal theorem prover which would try to prove that a given equation held in this theory without producing the theory e x p l i c i t l y . or it could be incorporated in a system which tried to show that a given program implemented some operations of this theory. this raises interesting  but s t i l l unanswered questions  about the relation between specification structure and program structure . 
　　　we w i l l explain clear by example. let us start by building up the theory nat of natural numbers using the constant f a c i l i t y and the let f a c i l i t y   thus repeating in succinct form the more fragmentary development of nat above. we start with bool  the theory of truth values. 
　　　
inviedt 	paners-1: rurstall 1 
　　　
　　the constant nat now denotes the theory of natural numbers. it is built up by f i r s t making a local definition of the simple theory nato with just zero and suec. we then combine this with boo   enriching the combination with extra predicates   and eq. f i n a l l y induce applied to the whole expression ensures that the theory contains general equations like eq m m  - true-
procedures in clear 
　　　we often build one theory on top of another. suppose for example that we have some partially ordered set  then we can form strings from i t s elements and define the predicate 'ordered' for strings- this is just what we would have to do if we wanted to specify some sorting task. a theory of ordered strings can be developed for any partially ordered set  poset  of elements and the latter can be regarded as a theory parameter  compare form parameters in alphari  . we can write a procedure using the theory-building operations to construct the theory of ordered strings from this parameter. now we can apply this procedure to any theory which has a 'less than or equal' operator satisfying the reflexivity  t r a n s i t i v i t y and antisymmetry laws  for example the theory nat- thus the procedure can only accept as parameter a certain sort of theory; we had better call it a 'meta-sort' to avoid confusion with the sorts within theories. this meta-
sort is i t s e l f a theory  in this case the theory of 
partial orderings-
　　　a degenerate example would be a theory procedure which can take any set as parameter and does not need any operators  for example the procedure which  given a set of elements  produces the theory of 1tring1 of those elements. the const poset = 

　　　use of a theory as a meta-sort is rather distinct from i t s use in defining some data structure such as natural numbers- it enables 
us to state the presuppositions for some task which we wish to specify  and we are interested in any interpretation of the theory rather than some particular canonical one. 
shared subtheories 
invited papers-1: burstall 1 　　　we observed already that just as two l i s t s may share substructure so may two theories; this in accomplished by having the same variable appear in both the expressions denoting these theories. the details  which follow  are a l i t t l e technical and may be skipped if desired. 
　　　suppose that we have a theory variable t ei ther a formal parameter or bound by a l e t     then the theory  enrich t by...enden  contains this theory t as a subthe~ory  and so do   t + . . .   
and  induce t . the theory ''derive aigrigture t1 from t  by  .tendde  contains t as a subtheory if tlnjontains i t . should t1. also contain t  as a subtheory then the   . . .   had better map its operators identically   i f they both contain bool   true is false  would not be welcome . now it we combine two theories t1  and t1 which both have t as a subtheory then tt+ t1  only contains t once . the same rules hold it t ts not a variable but is introduced by  const t = ... . all this enables us to have bool  say  as a subtheory of several theories without proliferating many copies of i t . sometimes we do need a fresh copy of a theory t   so we let ''copy t  denote one  to save writing it out again explicitly. 
　　　when we apply a procedure p to an argument  t the result always includes t just as if we had written p   t   + t instead of p t . for example string  nat  is a theory whic has not only string operators but also the operators like succ defined in nat  of course when we are writing the definition of the procedure string these latter operators are not available; the importance of such 'insulation' mechanisms has been pointed out by wulf and others. 
errors and condi tionals 
　　　before going on to look at examples of specifications written in clear we w i l l incorporate two usefu features: errors and conditionals. 
　　　some applications of ar operator to i t s arguments will  not give a meaningful result  for example dividing by zero or popping an empty stack. thus we need to consider errors  a topic which is often glo1ed over in algebraically oriented work  but whose proper treatment is essentialfor a realistic specification language. it is important too that the different levels of abstraction provided by our language should not become confused as soon as an error is encountered; we do' not want a stack underflow to produce an error message 'array subscript out of bounds'. gtoguen  1  studies this topic in depth  defining error algebras and error theories. we w i l l confine ourselves to an informal  glance at error theories. 
　　　the idea is to extend each sort by a set of error elements of that sort  and to have error operators which produce these elements. thus the theory of stacks might have an error operator underflow: -  stack 
and the theory of arrays might have an error operator notdefinedfor: index -  value meaning that there is no value for this index in the array. the term 'notdefinedfor 1 ' would serve as an informative error result. 
　　　to say when an error occurs or to equate two different error expressions we need to use error equations  thus pop empty  = underflow pop underflow  = underflow 
　　　we call the non-error elements of a 1ort  ok elements   the non-error operators  ok operators  and the non-error equations  ok equations . now we can write a presentation of a theory with a set of erroropns in addition to the previous  ok opns  and a set of erroreqns in addition to the previous  ok eqns. an interpretation of such a theory is an 'error algebra'  that is an algebra some of whose elements are designated error elements. this designation must obey the following rules:-
 1 error operators always produce an error element. 
    ok operators produce an error element if any of their arguments is an error element. 
　　　now for an error algebra to satisfy the theory an ok equation or an error equation does not have to hold for all values of the variables. only the following must be the case 
 1  an ok equation must hold if both sides evaluate to an ok element. 
 1  an error equation must hold if either side evaluates to an error element. 
for example theory sorts nat opns zero: -  nat succ: nat -  nat pred: nat -  nat 
erroropns neg: -  nat eqns pred 1ucc n   = n erroreqns pred zero  = neg succ neg  = neg pred neg  = neg endth 
　　　further examples  stack  array and symbol table  are given later. 
　　　it often happens that two expressions are equal only under a certain condition  thus f x  - g x  if p x  
　　　now we can permit such a conditional equation by regarding it as an abbreviation for if  p x  f x  g x   = g x  
where ' i f ' is the usual conditional operator defined for each type by the equations if  true y z  = y if  false y z  = z 
　　　conditional axioms have been studied using a different approach by thatcher  wagner and wright  1 . 
　　　notice that the fact that our ok equations automatically do not apply to error values often saves us from adding a condition such as   . . . if s # underflow . 
notation 
we should mention some small further points 
　　　
invited paners-1: burstall 1 
　　　
about notation. if we are naming sorts in a context where several theories are present  the same sort name  s  may appear in two different theories  t1 and t1  making a reference to s ambiguous. we then simply refer to  s of tv  or  s of t1. . a similar notation  f of tt   w i l l di sambiguate operators. 
　　　often a theory has a particular sort which is so to speak i t s raison d'etre  for example sort nat in theory nat  even though nat also has sort bool . to enable us to distinguish such a sort we define the principal sort of a theory to be the f i r s t sort mentioned in i t s definition  thus in 'theory sorts s t . . . endth' s is the principal sort and similarly in 'enrich t by sorts s t . . . enden'. now a helpful convention is to allow the theory name  in lower case  to denote its principal sort. also when we specify the correspondence between sorts in a derive operation we may omit a pair ' s is t' if s and t are the principal 1orts of their respective theories; similarly for the  ... notation used for actual 
parameters of procedures  thus 'strings  nat ' is acceptable for 'strings  nat  element is nat  '. 
examples of specification 
　　　we w i l l give two illustrations to show how clear can be used to build up theories from pieces in a systematic way:-
　　 i  a theory to specify a symbol table such as one might need in an algol compiler  an example given by guttag et al  1  
　  i i   a theory to specify a problem solving system for a two dimensional blocks world. 
these are  of course  rather small  simple examples  but we hope that they are .just complex enough to give the reader some idea of the modular structure that we wish to see in specifications. we hope the reader can grasp this structure without poring over every equation. the whole clear description denotes a theory which does not i t s e l f have this structure  sc that the implementer would be at liberty to organise his program in some other way.. 1  just as we might describe the number 1 as 1  but you are free to store it in the machine in any way you like  1uch as binary.  indeed by using derive we 'throw away' many of the operators introduced in our clear description of the theory  so that they do not appear in the final theory and need have no corresponding procedures in the program which implements i t . for example we describe a symbol table in terms of a stack of arrays  because stack and array are familiar concepts  but our specification does not demand that it be implemented in this way. 
　　　here is our plan of campaign showing the main procedures or constants we w i l l define and which other ones will use them. 

stack 
　　　since we can put any kind of element on a stack we take as a parameter theory a t r i v i a l 
　　　theory  one with a single sort and no operators. 
this describes the 'values' which go on the stack. the operators  such as push and pop  are wellknown. notice that no 'side-effects' are allowed. we explicitly produce a new stack from push and pop. 

　　　we define arrays with any kind of element as indices  not just integers. however the indices must have an equality relation defined over them in order for us to 'look up' indices in the array  so we have a parameter theory of meta-sort id.  a theory of identifiers with one sort besides bool and an equivalence operator == over that sort. we write the array access function as a i  instead of  say  get a i . 

　　　
invited 	papers-1i burstall 1 
　　　

　　　a compiler needs to maintain a symbol table relating each identifier to a value such as a machine address or an address plus a type. in an algol-like language with blocks each block introduces new identifiers which may or may not have occurred before. it associates new values with them  and these override any previous values u n t i l the end of the block is encountered and the table reverts to i t s prior state. thus we need a theory with sorts: symbol  value  table; it has operators: n i l s t - an empty table  extend used to mark entry to a new block  put - to add a symbol value pair  get written- .   . . .     - to retrieve a value  contract - used when the end of the block is reached. guttag e t al   1  have already given an equational specification of a symbol table as an abstract data structure. in contrast to their direct specification we w i l l 
　　　build up ours from the familiar concepts of stack and array  then use derive to extract just those operations which are required for a symbol table. 

　　　now let us specify a very crude model of a set of blocks on a tabletop together with some commands for moving them. we w i l l stick to two dimensions and assume square blocks a l l of the same size. we can do this in terms of a onedimensional array indexed by places on the table  each element of the array is a stack of blocks. we enrich this array of stacks theory with some extra operations: create an empty array of stacks  put a block on the stack at a given place  move a block from the stack at a place onto the stack at another place. we now use derive to get rid of the unwanted operations on stacks and arrays  just retaining these operations on an array of stacks  which we rename a tabletop. we do however need an equality for tabletops  because later we want to do problem solving and see whether we have the required goal tabletop. for this we use a theory procedure stackeq  value: id  of stacks with equality  ==: stack stacic -  bool . its defini t i o n from stack  value: triv  by enrichment is l e f t as an easy exercise. similarly for arrayeg  index: id  value: id . 
proc tabletop  block: i d   place: id.  = 
let stackofblocka - stackeq  block  in let arravofstactcs  = arraveq  place stackofblocksx  let t = enrich array of stacks by opns empty: -  arrayofst put: place block arrayofst- arrayofst move: place place arrayofst- arrayofst 
erroropns error: -  arrayofst eqns empty p  = nilstack put p b a  = put p push b afp   a  move p p' put p b a   - p u t   p ' b . a   erroregns move  p p a =serror if isemptv a p   enden in 
derive signature enrich block + place by 
sorts tabletop 
opns empty: -  tabletop put : place block tabletop -  tabletop move : place place tabletop -  tabletop 
　　　=- : tabletop  tabletop --  bool erroropas euror: -  tabletop 
	from t by. tabletop is  arrayofst 	endde 
　　　the problem solver w i l l seek a string of actions to transform one tabletop to another.. to provide these actions we define some commands  just expressions of the form  makemove place1  place1   using an operator  makemove  with no equations  like succ for numbers . now we can define a dynamic blocks world  in which you can execute commands to change the tabletop  proc commands  place: triv  = 
theory sorts command opns makemove: place place -  command 
endth 
proc blocksworld  block: i d   place: id  = enrich combine  tabletop  block   place  
　　　　　　　　　　commmands place by opns execute: commands  tabletop -  tabletop eqns execute makemove p p1  t  = move p p1 t  
enden 
state-action system and problem solver 
　　　quite separately from the blocks world  but later to be combined with i t   we define a problem solver theory for some arbitrary system with states and actions. first we define the state-
　　　
invlted papers-1: burstall 1 
　　　
action system alone with just these two sorts  then we have a procedure iterate to enrich any state-action system to give the  effect of a whole string of actions. a problem solver is then defined for such a system  with an operation solve which must attain any reachable set of goal states- note that we do not say how solve is to be programmed  just specify its desired result. 


blocks world problem solver 
　　　we now put this all together by deriving the required operations for a state-action system from the blocks world  and applying the theory producing procedure problem-solver to i t . the resulting theory specifies the notion of solving a problem for our blocks world  that is finding a sequence of suitable moves to get from one state to a specified set of states.  in practice we 
would have to add extra operators to describe the 
start and goal states.  we choose to represent blocks and places by natural numbers  but we leave as a parameter the set of natural numbers determining just which places are involved. 

examples. 
  i   the language pays for the extra structure and localness by being rather cumbersome. is this inevitable  we tried to moderate the longwindedness by 1ome conventions  but feared to sprinkle too much 1ugar lest the reader lose sight of the basic mechanisms. 
  i i   should we distinguish two kinds of enrichment  a  adding new sorts and operators and equations about them  but without constraining existing operators further   b  imposing further equations on the existing operators  
 iii  could we improve on the rather clumsy way sharing is indicated in derive  
 iv  the induce operation is rather different from the others  a l i t t l e mysterious. we stuck it in whenever we were talking about a particular data structure. could it be inserted more systematically  perhaps we should distinguish between theories used as metasorts  which generally do not need induce  and other theories  which generally do. does induce allow us to make a l l the inductive inferences we need  
 v  is our transfer of the lisp sharing paradigm to theories the best approach  can we make good our claim to understand i t s semantics  
programs and theory morphisms 
　　　in this section we discuss in a tentative way how programs  as opposed to specifications  might f i t into our algebraic framework. for this we w i l l need to define a 'morphism' between theories  which represents one theory in another.  the theories and their morphisms form a category  lawvere 1 . the idea is that a program is essentially a means of representing one theory  the specification  in another theory  the machine   that is a morphism from one to the other. 
　　　we can often represent operators of one theory by operators of another  to be precise by derived operators of the other theory. 	by a derived operator of a theory we mean one which can be expressed in terms of the primitive operators. 	in a theory with primitives 'not' and 
'and' the operator 

is a derived operator  'or' . in general we may build any term in the primitive operators using suitable variables  using the familiar notation to bind these variables. these operators include miliary ones  that is constant terms. an operator may be represented by more than one derived operator of the other theory. since our theories may involve several sorts we must also represent each sort of the f i r s t theory by a sort of the second. 
　　　now the operators of the f i r s t theory obey certain equations  so naturally the same equations must be true of the corresponding derived operators of the second theory. 
we call such a connection between two 
　　　
invited papers-1: burstall 1 
　　　
theories a theory morphism. here is the defini t i o n . * 
　　　a theory morphism from a theory t to a theory t' is 
 i  	a function f from the sorts of t to the sorts of 	t. 	 we write s is s' to mean f s  = s1. 
  i i   a function g from the operators of t to nonempty sets of derived operators of t'  such that any equation of t gives rise to an equation of t' when each operator of t is replaced by any operator in g - the input and output sorts of an operator in g must be the f-images of those of - we write  to mean g -
       by the obvious extension the* theory morphiam maps each derived operator of t to a set of derived operators of t'; this holds in particular for nullary operators i.e. constant terms. 
       consider for example id.   the theory of identifiers with an equivalence operator  and nat the 

　　　representing sets by strings and stacks by array-index pairs are other well-known examples. 
　　　as a matter of fact such theory morphisms play an essential role in our mathematical semantics for clear. but here we are concerned with their connection with programs. it seems that if we restrict ourselves to an applicative language  without assignment  our theory morphisms are the mathematical correlate of a simula class  clu cluster or alphard form  with the theory t playing the  generalised  role of the newly defined data type and the theory t' being the existing data type used to represent i t . the derived operators in the morphism from t to t' are the procedures in the class  cluster or form declaration. 
　　　we do need one generalisation however since in the programming case the procedures may well be recursive. fortunately wright  thatcher  wagner and goguen  1  have defined a notion of rational theories and their morphisms** allowing recursively 
* our theory morphisms are different from lawvere's which represent an operator by a single derived operator. 
** we would also need rational theories to make clear deal properly with i n f i n i t e data  such as i n f i n i t e trees  defined inductively. 
derived operations  not just but recursion too ; this seems to model the real programming situation  always provided that we regard an imperative program as a notational variant of an applicative one! . 
　　　now we see that a specification is just a theory  a machine  or more abstractly the primi t i v e operators and sorts of a programming language  is another theory  and a program to realise the specification is just a  rational  morphism from the specification theory to the machine theory. 
　　　of course we should not describe this morphism in an unstructured way  indeed there should be a programming language analogous to the specification language clear  but describing morphisms not theories.** this would be the correlate of simula etc. or more closely of the iota language of naka.jima et al  and of parnas'  1   method of programming with modules. we have worked on such a language but decided to f i r s t get straight the rather easier case of a specification language . 
　　　how would the structure of such a program relate to the structure of the specification which it implements  the degree of closeness would be up to the implementer  but it would be natural to use the various theories defined for specification purposes to define the task of subparts of the program. in general one would expect the specification would be simpler than the program  and to specify parts of the program one would need to elaborate the theories used in the specification with new sorts and operators. for example one might decide to use the gps method to solve the blocks world problem  and one would have to enrich the state-action theory with new sorts like 'difference' and operators like 'reduces'. 
　　　a speculative conclusion: the main i n t e l lectual task of programming is elaborating the theories which describe a l l the concepts used in the actual program. writing the code  defining the morphisms  is a much more humdrum business. 
　　　ah well! this is all delightfully vague and a great deal of work needs to be done. but it does promise to be interesting. 
conclusions 
　　　the main point of this paper is that it is possible to specify complex tasks provided that we do not try to write the specifications in an unstructured way. our particular language proposal is only important in bringing into fbcus the problem of devising structured descriptions of specifications and suggesting the kind of operations which should be used to build them up. the basic ideas developed for data abstraction in programming languages should guide us in this task  and we firmly believe that the mathematical ideas about the category of theories can help us to grasp the rather deep concepts involved-
** we have a base for such development in the equational languages we have already implemented 
obj  goguen and tardo 1  and npl  burstall 1 . 
　　　
invited papers-1: burstall 1 
　　　
acknowledgements 
　　　we owe a deep debt to the pioneers mccarthy  landin  eilenberg  maclane and lawvere  also to 
james thatcher  eric wagner and jesse wright at 
ibm and to john darlington at edinburgh  now london  for long and educative collaboration. many other colleagues have been very helpful especially patrick cousot  grenoble   john 
reynolds  syracuse/edinburgh   gordon plotkin  david macqueen and jerald schwarz  edinburgh  and joseph tardo  los angeles . j.a.g. wishes to thank saunders maclane for i n i t i a t i n g him into category theory  and william lawvere for help on the way. r.m.b. wishes to thank members of iftp working group 1 for much education and encouragement  also professor veillon for a visit to usmg grenoble where he started on this work  and to 
professor avizienis for help in visiting los angeles. alan bundy and michael woodger kindly read and made helpful comments on a draft. 
　　　we are grateful to the national science foundation and the science research council for supporting this work  including an src visiting fellowship at edinburgh for j.a.g. 
　　　our very sincere thanks to eleanor kerse for her meticulous  speedy and cheerful typing. 
personal thanks go to sei.ja burstall  
charlotte linde and chogyam trungpa rinpocho. 