 
in order to understand cognitive aspects of autonomous robots  it is fruitful to develop a mechanism by which the robot autonomously analyzes physical sensor data and construct a 
state space. this paper proposes a coherent approach to constructing such a robot oriented state space by statistically analyzing sensor patterns and rewards given as the result of task executions. in the state space construction  the robot creates sensor pattern classifiers called empirically obtained perceivers  eop-
s  which  when combined  represent internal states of the robot. a novel feature of this method is that the eop directs attention to select necessary information  and the state space is obtained with the attention control mechanism using eops. we have confirmed that the robot can effectively construct state spaces through its vision sensor and execute a navigation task with the obtained state spaces in a complicated simulated world. 
1 	introduction 
acquisition and utilization of internal representation are key issues in realizing intelligent behaviors in computer systems. they are especially difficult for robots that process noisy sensory information and interact in the real world. there are two directions for the research. one requires the programmer to provide the internal representation  1; 1 . another direction is to develop robots with cognitive interests . the purpose is not to develop a robot that can execute complex tasks  but to stress the possibility that a robot may learn how to behave in the real world. researchers in cognitive robotics  focus on cognitive aspects of physical agents - agents that learn their internal representation autonomously in order to perform tasks. 
　our research direction basically takes the cognitive approach. in the cognitive approach  the key issue is how the robot efficiently obtains necessary information from complicated environments through sensors. this paper proposes an approach to construct a state space with an attention control mechanism that performs nonlinear classification of sensory data. the method proposed here is rather simple as a method of pattern recognition  but it works well in the state space construction by a robot in a complicated environment. the key points of this paper are as follows: 
1. the proposed method enables the construction of a state space from redundant and noisy physical sensory data  such as visual data. 
1. the proposed method efficiently and autonomously constructs the state space from physical sensory data by employing an attention control mechanism. 
we consider  it is interesting and important to illuminate and examine the close relationship between state space construction and attention control. this paper discusses such a key issue in cognitive robotics. 
　the task of the robot discussed in this paper is to avoid obstacles. while moving  the robot collects data sets consisting of an action  sensor information  and a reward. then  the robot develops empirically obtained perceivers eops statistically analyze the da-
ta sets to classify sensory patterns according to actions and rewards to obtain a proper state space for the task. in the state space construction  eops perform attention control. there are two types of attention control: feature selection from sensory data and continuous gaze control. each eop select features in the image consisting of a huge amount of pixel data. further  the application of a combination of eops constitutes a sequence of changes in attention for gaze control. the acquisition of the sequence is called visual sequentialization . we have confirmed that the robot can construct state spaces for avoiding obstacles in a complicated simulated world. 
　there are several research approaches that autonomously construct state spaces and reduce its size. nakamura's work  deals with physical sensory data but the feature extraction is based on human intuitions. mahadevan's work based on q-learning  basically has trouble dealing with physical sensory inputs that have huge dimensions. although the g algorithm  and   address certain problems  they do not use complex physical sensory data. while both methods use statistics  they assume that the sensors generate 
ishiguro  kamiharako  and ishida 	1 
information that can be directly used to represent the state space. in other words  they do not address the problem of how to construct the state space from raw sensory data. g algorithm's sensory data selection performs a kind of attention control. however  difficulties arise when the robot directly deals with physical sensory data since simple pattern matching methods cannot be applied to complicated sensory data. the purpose of this paper is to propose a coherent method for constructing a state space from physical sensory inputs and to propose a means of attention control for physical sensors in state space construction. 
1 	state space construction 
1 	process flow 
figure 1 shows the process flow for incrementally constructing a state space. in the beginning  the robot does not discriminate any sensory data and it has just one state. while moving the robot collects data sets  consisting of sensory data  an action  and a reward. these data sets are divided into two classes. 
　here  the robot can move along plans if it has a state space whose size is sufficiently large for planning the robot motion. while constructing the state space  state transition probabilities can be computed from the data sets  and the robot can make plans for going toward goal states with standard planning methods by referring to the state transition probabilities and rewards assigned to states 1. 
　for discriminating the two classes  an eop is obtained and the state is split in two. then  if there are any identical states  they are coalesced. by iterating the process  a state space is incrementally constructed. 
1 	data collection 
the data set consists of the following four components: 
 state  action  sensory vector  reward  
where state means a state of the robot when it executes an action  acquires sensory information and receives a reward. sensory vector is one dimensional array of sensory inputs. 
　the method proposed in this paper can deal with any kind of physical sensory data. however  it is instructive to consider a vision-based robot  since visual data contains a very large of information and it is difficult to extract what is necessary for the robot to perform its task. for the analysis discussed below  1-d vision data is simply converted into a one dimensional array  the sensory vector. 

1
    several papers  concerning state space construction propose to apply q-learning to assigning q-values  which provide an action policy  during or after constructing the state space. however  such relations between states can be directly obtained by computing state transition probabilities from the data used for constructing the state space. 
1 	robotics and perception 

figure 1: process flow 
　in our model  humans cannot directly specify the robot's internal states. however  they can express their intentions to the robot through rewards. these rewards provide the robot's solely motive for learning to classify its sensory data. thus  by referring to the rewards  the robot constructs its internal state space by itself. for reactive robotic: tasks such as obstacle avoidance  the robot receives immediate rewards. for deliberative tasks such as moving toward goals  delayed rewards are used in place of immediate rewards. 
1 	sensor pattern classification 
imagine that a robot with an incomplete state space moves about in a real environment in which rewards are embedded. if the robot receives different rewards when executing an action in a given state  the robot finds that the state should be appropriately divided into two states. 
let be the frequency of be the number of samples in and and  be constant values  where 
　　　　　are state  action  and sensory vector  and reward  respectively.  represent a set of data sets of which state and action are  and  respectively. the following equations give the conditions for dividing   see figure 1 . 
 1   1  
 1   1  
is 
selected. in the conditions   1  means that rare events 


figure 1: divide condition 
are neglected.  1  guarantees enough data to make an eop. the method for clustering seems ad hoc. of course  we can employ other standard clustering methods using variance. however  the clustering needed for this approach is simple and we consider the four parameters that we have employed characterize the robot behavior. 
　data sets  are divided by  through the following procedure for state division: 
1. take actions in the real world and collect quadruplet data  classify them into disparate sets 

1. for each check whether should be divided. terminate if no state can be divided. 
1. if  should be divided by the threshold as shown in figure 1  define two classes: 

1. look for an eop which can discriminate class 1 and class 1 in eops already acquired. if no proper eop is found  then make a new eop using class 1 and class 1  see 1 . if the eop cannot be constructed because of the classification error  then abort to divide and go to 1. 
1. let us refer to the eop selected at 1 as 
	is divided into new states 	by 	di-
1 	acquisition of eops 
assuming that sensor patterns classes 1 and 1 are given with respect to an action  a discriminant function can be obtained in the following manner  the discriminant function is a function which takes as input a sensory vector s  represented as a tv-vector  and outputs a scalar 
value. it is represented as a sum of weighted components of a vector x. 

where c is decided so that df outputs a positive value for a sensor pattern in class 1 and a negative value for a sensor pattern in class 1. a value for w is determined to minimize the error rate  l  as follows: 

where is a covariance matrix of class 1 and class 1. and are mean vectors of class 1 and class 1  respectively. 
　the error rates of df are given by the following formulae: 
where and n1 are the number of data sets in class 1 and 1  respectively. is the number of data sets such that in class 1  and ml is the number of data such that in class 1. 
　here  the discriminant analysis generally takes much computational time for a large number of dimensions of the sensory data. therefore  it is necessary to perform a kind of dimensionality reduction to reduce the size of the sensory data. however  our policy in this research approach is that the robot has no access to models based on human intuitions for segmenting features  such as lines  color regions  and so on. for this problem  our idea is to use principal component analysis  pca    which calculates orthogonal dimensions of maximal variation in the data. the hotelling  aka karhunen-loeve  transform is used to rotate the axes  and only those dimensions that account for most of the variation are retained. the principle components of the visual data serve as low-level quantitative features  and represent spatial relations among pixels. therefore  it is meaningful to refer to the principle components for analyzing vision data. although we do not consider principle component analysis is ideal for the data compression  this approach is general insofar as it can be applied to any kind of sensory data. as better methods  we can consider to apply independent component analysis and wavelet transform  which have interesting relations with human visual process. 
　the weight vector of a discriminant function represents the importance of each component of the sensory input for the classification. thus  the weight vector defines attention control for pixel  or feature  selection. several approaches can be considered for the pixel selection with referring to the weight vector. our method employed in this paper is as follows. 
　pick up the maximum and minimum values of absolute values of the weights. then  we divide the range between the maximum and minimum values into ten  this number has been empirically determined  and acquire ten threshold values  with 
the threshold  the weight values are modified; if the value is less than the threshold  the weight is set as 1 and 
	ishiguro  kamiharako  and ishida 	1 

the pixel is ignored. thus  we obtain ten modified discriminant functions 
　next  we check error rates of all modified discriminant functions. the modified discriminant function  that does not satisfy the following condition 
is discarded. 

where  are error rates of the modified discriminant function and they are computed in the same way as 
　for the remained discriminant functions  we evaluate performance of the threshold values by using the following evaluation function. 

where n is the total number of data sets. then  a threshold that gives the minimum value of the evaluation function is selected. 
　the original linear discriminant function divides the parameter space with a hyper plane based on distribution of data in the parameter space. in this case  outliers significantly influence the discrimination. on the other hand  performance of the modified discriminant function is evaluated based on only the number of misclassified data. that is  there is a possibility that the pixel selection using the modified discriminant function ignores the outliers. 
　by the pixel selection  the discriminant function can be represented with a small number of coefficients and focuses on important sensor components. further  a combination of modified discriminant functions realizes nonlinear discrimination as discussed later. the efficiency of this attention control method is experimentally verified in section 1. the idea of attention control proposed here is simple but general  and it can be applied to any kinds of sensory data. 
　　the modified discriminant function  cut minor components off with a threshold value i and outputs a positive or negative value for an input data s. with we define a logical function eop as follows: 
　by iterating to collect data sets and obtain eops  the robot may generate a large number of states. in this case  identical states may exist. the states can be identified by their distribution of rewards across the possible actions. suppose the robot has two actions and each state-action pair has a distribution of rewards that it has acquired so far. if  for two states  all corresponding actions have a similar reward value  the states can be treated as identical. the identified pair of states is coalesced into a single state. the new state is represented by combining the eops used to represent the previous two states. in other words  by iterating the processes of identifying and coalescing states  the robot is able to perform a complex  nonlinear discrimination of an n-dimensional parameter space. 
1 	robotics and perception 

c 
figure 1: robot in the simulator 
1 	experimental results 
1 	robot and environment 
we have developed a robot simulator and used it to verify the proposed method. the robot in the simulator has an omnidirectional vision sensor. the robot can rotate in any of 1 directions and go forward  in other words  it has 1 actions. the configuration of the sensor and the actions are shown in figure 1 a  and  b . an action  consists of a rotation of  degrees and a forward movement of 1 pixels in the simulated environment shown in figure 1 with some errors  the size of the simulated environment in figure 1 is 1 x 1 pixels . the actual direction and distance of follow the normal distribution whose means are degrees and 1 pixels  respectively. the sensor provides edge images of  pixels as shown in figure 1 c  at each time step; and the robot acquires edge images for the state space construction by applying sobel edge operators 
1
 . the acquired images are compressed by acquiring the principle components. in this experimentation  we have determined the number of the principle components with a accumulated proportion of 1. 
1 	v i s u a l sequentialization 
the robot task in this experiment is obstacle avoidance. the robot receives a  reward when it collides with a wall and 1 otherwise. at the beginning  the robot knows nothing about the external world  it has no eop  and its internal state space consists of only one state 
 figure 1 shows a state tree at a time when the robot created 1 eops. the combination of the eops represent the states. for example  state is representand is represented as those two states are discrim-
in the image of the eop  bright and 
1
　　we have tried both of intensity images and edge images. as the results  we have found that the edge images are superior in efficient acquisition of eops to the intensity images in this simulated worlds. 


figure 1: simulated worlds 
eofs 

figure 1: visual sequentialization 
dark gray areas indicate positive and negative components of the weight vector  respectively. 
　　the tree structure of the state space represents how the robot continuously pays its attention in order to identify the states. in figure 1  the robot coarsely observes with then changes its attention to more detailed regions with and  this behavior 
called visual sequentialization is how our method constructs the state space. 
1 	effectiveness of attention control 
to evaluate the effectiveness of our proposed method of attention control  we have experimented in the complex outdoor environment with the reactive robot behavior for avoiding obstacles. first  we have given a fixed number of data sets for verifying effectiveness of the attention control method. with 1 data sets collected while the robot randomly moves  the robot has constructed a state space. in figure 1  the vertical and horizontal axes indicate the error of pattern classification and the number of states  respectively. the error e is defined as: 


figure 1: error of pattern classification for 1 data sets 
where  are the ids of state and action  respectively  nv and n are the number of acquired states and the number of all acquired data sets  respectively. for the obstacle avoidance   is the numbers of data sets that have a reward of 1 for an action a in a state s; and  is the number of data sets that have a reward of - 1 . that is  the error represents the normalized number of misclassified data sets. in the beginning  the error is large since the number of states is small. as the number of states increases  the error is reduced. 
　figure 1 shows an interesting behavior of state space construction with the attention control. in the beginning  the error of the method using standard discriminant functions was smaller than the method using the attention control. then the method using the attention control method became better at 1 states. 
　we analyze these phenomena as follows: in the beginning  the method using attention control suffers classification error in the attention control for each eop. however  after acquiring some total amount of eops  the method performs effective nonlinear state division by combining the acquired eops. 
　another characteristic is shown in figure 1. the vertical axis indicates the number of nonzero components of weight vectors for eops. a small number of the nonzero components means that the robot refers a small amount of pixels in the image to distinguish the states. in other words  it saves computational time for sensory data processing. as shown in figure 1  the method using standard discriminant functions needs more than three times of sensory data than the method using the attention control. 
　we have performed another experimentation in a more realistic situation. in this experimentation  the robot incrementally constructs a state space while collecting data sets and makes an eop in a state when 
1. 1 data sets for both classes  class 1 and class 1  are acquired  
	ishigur1  kamiharak1  and ishida 	1 


figure 1: the number of nonzero components of the weight vectors 

figure 1: error of pattern classification in incremental state space construction 

1. or the number of data sets in the class that has a smaller number of data sets than the other becomes 1 % of the other. 
　the error of the attention control method was smaller than the method using standard discriminant functions as shown in figure 1. in figure 1  we could not find the similar phenomena to figure 1  in which performance of the two methods is reversed. in the incremental construction  nonlinearity of the sensory data space is stronger since the robot needs to move by referring to the incomplete state space. we  therefore  consider that the method not using attention control could not represent good performance in the beginning. figure 1 shows a more impressive result. the method using the attention control was better than seven times. we consider that  in the incremental state space construction  outliers are often acquired since the robot acquire data sets while randomly moving and the method of the pixel selection efficiently filters them out. 
　in this experimentation  we could verify the attention control method. performance of the attention control method is better for the incremental state space construction than for the state space construction with a fixed number of data sets. in the incremental state space construction  nonlinearity of the sensory data space is strong; and our method is suitable to deal with such a complex classification problem. further  our method significantly reduces pixel data needed for the state space construction. this means how the method works well as an attention control method. 
1 	discussion and conclusion 
in this paper  we have proposed a coherent method for constructing a state space using attention control from physical sensory data. in addition to the approach's coherency  the proposed method has the following interesting point: 
1 	robotics and perception 
  it constructs a state space from a huge amount of physical sensory data. 
  the eop realizes a simple and general method of attention control. 
  a combination of eops controls continuous changes in visual attention and represents a state. 
  attention control with the eops efficiently con-structs a state space. 
　finally  we discuss remaining problems and future directions for our research approach. one problem is how to determine the threshold for the attention control. in this paper  we have determined the threshold based on performance of each eop. however  an eop influences performance of other eops obtained after the eop. that is  the threshold should be adjusted by taking al1 related eops in account. this threshold control is expected to construct a state space that has a more reasonable abstraction hierarchy. 
　in this paper  the eops have been made under the assumption that actions are already defined  but some tasks may require more precise actions and others can be done with coarser actions. in order to change the granularity  it is necessary to detect coarse actions or to identify similar actions. it maybe possible to segment actions with a method similar to that used above for sensory data segmentation. 
　this paper has discussed with a single simple robot task. however  a robot needs several tasks  for example avoiding obstacles  moving toward goals  following other robots and so on. a problem is how to implement the tasks in our approach. as one of the promising solutions  we consider to employ subsumption architecture . the idea is to prepare an independent state space for each robot task and connect the modules with a hierarchical network. another solution is to develop an abstract state space where we consider a robot behavior as an action. in other words  this idea is to construct a state space for representing relations between robot behaviors. the 


figure 1: nonzero components in incremental state space construction 
later idea is more ideal  however it has a difficult problem of simultaneous construction of state spaces in different abstraction levels. 
　the method proposed in this paper obtains a state space for a given task and environment. to extend this method  we must consider how to obtain a general state space which can be used in other environments. imagine if we place our robot in a different room and reconstruct the state space. it is expected that newly created eops will indicate the difference between the current room and the previous room  and eops that are commonly used indicate more general information. the final goal of our research approach is to obtain a general internal representation of a robot behaving in a class of environments. 
