 
the difficulty of maintaining very large software systems is becoming more widely acknowledged. one of the primary problems is the need to access information about a complex and evolving system. we are exploring the contribution to be made by applying explicit knowledge representation and reasoning to the management of information about large systems. lassie is a prototype tool  based on the argon system  that uses a frame-based description language and classification inferences to facilitate a programmer's discovery of the structure of a complex system. it also supports the retrieval of software for possible reuse in a new development task. among lassie's features are an integrated natural language frontend  teli  that allows users to express requests in an informal and compact fashion. although not without some limitations  lassie represents significant progress over existing software retrieval methods and strictly bottom-up cross-referencing facilities. 
1 	introduction 
the problems that arise with large  complex software systems include those of producing the code  managing a multiperson enterprise  testing the system  and assuring its integrity with respect to various specifications and other design documents. in many ways the most difficult problem involves maintenance  which includes fixing explicit bugs and  more importantly  upgrading the system to add new features or adapting the system for slightly different purposes. some software systems  including those that control the space shuttle  nuclear power plants  and communication networks  have become so large and complex that no one person  or even a small set of people  understand them. this lack of a reliable knowledge source is exacerbated by people moving within an organization or leaving it altogether. 
1 	tools 　one common aspect of maintenance and other problems with large software is the discovery problem  i.e.  the process of learning about an existing system in order to use or modify it. a developer must spend a great deal of time  discovering  features of an existing system  ranging from the overall software organization and the conceptual framework that drove that organization to the location and details of specific functions and data structures. all of this is prerequisite to implementing the actual modification for which the developer is responsible. discovery also has a lot in common with the problem of retrieving code for re-use. one could imagine  for example  a system that could retrieve an existing piece of code that implements a specified function. the discovery process then becomes a process of formulating a series of queries to retrieve information  including actual code  about the system. 
　we have undertaken the task of building an information system  is  to aid in the discovery process. this paper first examines the problem of developing such an is in more detail. an existing system of large software is used as a test case in this work; and four specific  discovery queries  arc examined to further motivate our approach. next  the core system we have developed  called lassie  is described in detail. then  two extensions to lassie are described: the addition of low-level code knowledge  and the integration of a natural language front end. finally  we put this effort into perspective by examining the queries that can be currently handled  comparing our effort to previous work on software retrieval and related systems  and outlining directions for future work. 
1 the problem in more detail 
the at&t system 1 tm   at&t technical journal  1  is a private branch exchange  pbx  that can handle up to 1 telephone lines. as a modern digital switch  it is controlled by a large and complicated software system that enables it to perform the basic switching functions as well as implement a sizeable collection of somewhat customizable features. this software is complex along several dimensions. it contains about a million of lines of c code; it comprises multiple versions  the latest of which is always in a state of flux; and  most importantly  it is a manifestation of a complex conceptual model of the architecture of the switch and its functionality. for this reason  the code can be understood only with reference to a framework that exists apart from it-a framework that reflects the hardware and software architecture  as well as the various resource and real-time-response constraints that the system is designed to satisfy. 
　the kinds of questions asked by system1 developers give us some insight into the conceptual model s  of a large switch. consider these queries  typical of the ones elicited in extensive discussions with developers: 

  ql. how do i allocate an international toll trunk  
  q1. what messages are sent by a process in the net-work layer when an attendant pushes a button to activate the  hold  feature  
  q1. what c functions enable the call forwarding fea-ture at a phone   
  q1. what functions in the line manager process access global variables defined in  /usr/pgs/ gp/tgpall/profum.h   
these queries require different kinds of answers  which depend on knowledge associated with at least four different views of the system: 
  a functional view-what is the code doing relative to the switching function  our is should know how internal operations  or actions  relate to external events such as a user picking up a phone. for ql  some code might be described as  allocating a trunk   which is an operation internal to the switch. 
  an architectural view-what is the hardware and soft-ware configuration  system 1 has a number of layers in its software architecture  each of which presents a  conceptual base  for the layers above it. for q1  one needs to know what processes are in the network layer.   a feature view-how are basic system functions associated with features such as  call forwarding   for q1  we must capture the way in which a feature cuts across a number of basic functions and has ramifications on all layers. 
  a code view-how do the code-level components 
 source files  header files  functions  declarations  etc.  relate to each other  functions call functions  source files include header files  functions and declarations are defined in source files  etc. for q1  these relationships need to be represented. 
in addition to these somewhat independent views  some additional issues must be addressed in a software information system capable of handling queries like those above. the views must be integrated in order to answer queries like q1 that combine them. the system must also allow queries about the structure of the knowledge base itself  in addition to individual facts in the domain. how the queries are asked is very important if the system is going to be useful; the use of a formal query language will be much less effective than being able to query in a subset of english. finally  the role of classification  discussed in detail later  will be important if the system is to out-perform a static keyword approach. 
1 the lassie system 
lassie is an experimental knowledge-based is running on a symbolics 1  under zetalisp/flavours. it consists of a knowledge base  kb   a window interface  based on argon  patel-schneider et al.  1    a graphical browsing tool  based on the isi-grapher  robins  1    and a customized version of the teli natural language interface  ballard and stumberger  1 . the system is designed to be used in a formulate-retrieve-reformulate cycle. if the answer to an initial query is unsatisfactory  the user can reformulate the query in a variety of ways  and try again. the reformulation step can be carried out using descriptions of retrieved individuals  or by exploring the knowledge base for related concepts. natural language can be used to formulate a query or to reformulate part of a previous query. 
　in all modes of querying  the kb plays a key role in processing queries and in assisting the user in reformulating a query when necessary. the design of this kb is therefore crucial. we now describe the perspective from which the kb was constructed. the lassie kb primarily captures the functioning of the system  from a conceptual viewpoint  with some information about its architectural aspects. 
1 functional knowledge 
most of the functions of system 1 can be described in terms of operations  or actions that it performs. some examples are 
  connect a user to a call. 
  initialize a call control process. 
  audit the digit translation database. 
  release buffer space to free some memory. 
  light up an led when a call is terminated at a station. 
  allocate a touch tone recognizer because of a pickup by a user. 
　corresponding to each of these actions are segments of code and the files that contain them. notice also that these actions can be cast into the general form actor does action on object to recipient using agent because-of action. this general form was used to formulate descriptions of a wide range of actions in the call processing area of system 1. it also motivated the design of lassle's natural language interface. we then coded these descriptions in the kandor knowledge representation system  patel-schneider    which classifies them into a conceptual hierarchy using a formally defined subsumption inference operation. this hierarchical kb is the core of lassie  consisting of about 1 frames and 1 individuals  which describe system 1 using functional  architectural  and code-level concepts  and their inter-relationships. 
1 the knowledge base 
as shown in figure 1  the four principal object types of concern in our domain are object  action  doer  and state. the edges of the taxonomy have their common  1sa  meaning1. doer represents those things in the system that are capable of performing actions. nodes below doer and object represent the architectural component of the system  i.e.  its hardware and software components. nodes below action represent the system's functional component  i.e.  the operations that are performed to or by the system. the relationship between the two system components is captured by various slot-filler relationships between actions  objects and doers. each action description 
   'in particular a trunk is-a resource-object  a communications-device  and a doer. 
	devanbu  selfridge  ballard and brachman 	1 

the talking state ; and it is implemented by the source file / u s r / p g s / g p / t g p a l l / p r o f u m . c  1 . it should be noted here that the kandor classification algorithm will ensure that this individual gets classified under the frame user-connect-action mentioned above. it is this kind of classification that organizes the large number of frames and individuals in lassie into a usable form. 
	1 	why classification is essential 
in a large software system  it is very difficult to know how one part of the system relates to another. our approach is to build explicit descriptions of the actions performed by different parts of the system  then use formal inference to build a taxonomic hierarchy  where all is-a links are derived from the descriptions themselves. the formal  logical nature of the inference  which is based on an intuitive set-theoretic semantics  ensures that action descriptions are classified where one would expect to find them.  the inference procedure that accomplishes this is described in  patelschneider  .  thus  programmers working on distinct components of the system can describe the operations performed by their specific components and be sure that their work is properly organized and categorized with other components for retrieval and re-use by later programmers. 
　the taxonomy can also be useful in query formulation and reformulation. when querying the database  if there are no answers  or if there are too many answers  a tool like argon  patel-schneider et a/.  1 can be used to specialize  generalize  or look for alternatives for an ap-
propriate portion of the query  modify that portion  and retry the query. for example  a programmer may query the system for an action that reinitializes a trunk. this query may be stated as  a process-operation whose operand is a trunk and whose result is the initialized-state . if no such action exists  the the user can use the taxonomy to generalize either trunk  initialized-state or process-operation  to see whether any matching instances are retrieved. 
　large at&t switches like system 1 and 1ess tm  are actually structured to support re-use. the layered architecture is intended to promote the re-use of primitives from lower levels to construct higher-level operations. although this is intended to simplify construction and maintenance  identifying the appropriate primitives when they are needed 
can be difficult. when primitives arc not used as they were intended  the original simplicity of the system is lost; in addition to needless re-coding  the system becomes harder 
to maintain and understand. the lassie kb will help prevent this loss of architecture by explicitly codifying the primitives supported by the architecture into a formal  taxonomic knowledge base and making it available for browsing and querying with a powerful user interface. 
	1 	incorporating the code view 
representing the  code view  of system 1 means developing a general representation of code objects and their inter-
       1it is dangerous for the same operation to be reimplemented several times by different programmers in different subsystems; besides the wasted work  when a bug develops in this operation  every single implementation thereof must be found and fixed. 
1 	tools 

relationships  then populating this generic taxonomy with instances from the system. the goal is to facilitate answering queries that contain requests for general information about file structure   what extensions do source files have     general information about system 1 software   where are system 1 header files located     and information about specific code objects   what functions call 'apost' and include 'errproc.h' '' . 
　we have designed a taxonomic and relational model of the c language and c programming conventions and implemented most of this model in a kandor knowledge base. this knowledge base  which is integrated with the functional and architectural knowledge described in the previous section  represents the unix file structure  including directories  c source files  header files  object files  makefiles  and their inter-relationships; and cross-reference information  including source files and functions  header files  macro definitions  and type  struct  declarations. the relationship knowledge includes both  defined-in   as in what function is defined in what source file  or what macro is defined in what header file   and  referenced-in   as in what functions reference  call  what other functions  relationships. 
　we have added to this generic knowledge base information specific to system 1 and its own software methodology. this information includes directory and file naming conventions as well as conventions about the file structure itself. 
　this conceptual framework of about 1 frames has been populated with individuals generated automatically from 1 system 1 source and header files. this generation was done in a three-stage process starting with the data file created by cscope  steffen  1   which is then further analyzed to generate two-place relations between code objects  which are then grouped together and used to generate legal kandor definitions. the resulting knowledge base includes  besides the 1 files  1 directories  1 functions  1 structure definitions  and 1 #def ines  macros . these objects are very richly interconnected; a fairly typical function will call a dozen others and use several dozen # defines. 
1 adding a natural language interface 
to provide a natural language interface for lassie  we customized the teli system  which maintains data structures for each of several types of knowledge  ballard and stumberger  1  ballard  1 . this information includes  1  a taxonomy of the domain  which enables the parser to perform several types of disambiguation;  1  a lexicon  which lists each word known to the system  along with information about it; and  1  a list of compatibility tuples  which indicate plausible associations among objects and thus reflect the semantics of the domain at hand. for example  an agent can perform an action on a resource  but actions cannot be performed on agents  resources cannot perform actions  etc. 
　in lassie  kandor individuals generally correspond to proper nouns  i.e.  names   while a frame may correspond to either a verb or a common noun. generally  frames under action correspond to verbs describing actions  while nodes under object or doer correspond to nouns. for example  the frame allocate-action maps to  allocate    reserve   and  grab   and process maps to the noun  process . individuals are usually associated with one or more proper nouns in an obvious way. for example  the individual process bus-controller is named  bus controller . 
　as explained above  action frames include slot restrictions corresponding to case roles including the actor  the operand  the recipient  the cause of the action  etc. to each of these  there naturally correspond one or more english prepositions. thus  each slot associated with an action frame gives rise to compatability tuples as described above. as an example  consider the frame definition1 shown below  with its associated verb connect: 
1  verbframe 	call-connect-trunk-action 
1  connect  	 action  
1  exists has-operand 	 generic trunk   
1  exists has-recipient  generic call   1  exists has-actor 
1 	 value 	call-control-process    
　for this frame and its slots  the following compatibility tuples are generated: 
call-control-process connect trunk 
call-control-process connect to call 
　the  annotation  of the knowledge base was done manually  after which the conversion to the teli data structures is automatic. the resulting compatability tuples for lassie include 1 verb case frames  corresponding to a total of 1 verbs. the lexicon contains 1 entries  including 1 common nouns and 1 proper nouns. 
　to process a query such as what actions by the line controller are caused by an action by an attendant   teli parses the input  making intimate use of the compatibility tuples and the taxonomy to insure globally consistent case bindings. the final parse tree is then converted into a semantic structure resembling a first-order logical form  which is sent to a lassie-specific filter to strip out quantifiers associated with words such as  a  and  the . the resulting structure is then passed back to lassie for translation into a query that is executed  thus performing a retrieval  but which also provides an editable argon expression. for example  tells output for the above query is: 
 set al 	 action al  
  action by agent  al line-controller  
  action cause action  a1 al  
  action by agent  a1 p1  
 attendant p1   
this is then translated into the following editable argon query: 
action 
	has-actor 	line-controller 
has-cause action has-actor attendant 
note that the user of lassie need not know the details of the underlying kb in order to pose questions in english but  by seeing the associated argon query  may well learn something about the kb when the input is processed. for 

example  a query what actions by a process reserve a touch tone recognizer because a pickup by a user    would be translated to 
allocate-a ction 
has-actor process 
	has-cause 	off-hook-action 
has-actor user 
in this case  the user would learn that the action verb 
 reserve  corresponds to allocate-action   pickup  to off-hook-action  and also that actors of and causes of actions respectively are specified by using the has-actor and has-cause slots. 
1 discussion 
1 results 
the overall goal of this project was to build an information system that represents a significant amount of knowledge of a large software system. our motivating problem was that of discovery: the need of developers to be able to access existing knowledge of the system prior to extending it. as we built lassie  we were forced to elucidate the kinds of knowledge that we needed to represent  as well as how it was to be represented. lassie represents hundreds of interrelated facts about the call-processing part of system 1  including a taxonomic breakdown of high-level actions that drive the system  and low-level knowledge about the code structure. the knowledge of code structure was generated automatically from source files. we added a natural language interface that allows many queries to be formulated in english  and uses the underlying knowledge base to help resolve lexical and syntactic ambiguities. the use of the existing argon system allows a very powerful form of exploration. 
lassie can answer hundreds of different queries about 
system 1  including queries about actions  architecture  code  and combinations of the three. argon or teli is used to formulate these queries  which are answered by showing a list of matching instances. these instances can be used to generalize or specialize the query  and the process continues. with regard to the discovery queries presented in section 1  which are illustrative of some important classes of queries  the current version of lassie successfully answers ql  q1  and q1 exactly as stated. q1 is an interesting case: while it cannot be handled exacdy as stated  lassie can be used to home in on the answer. q1 is:  what messages are sent by a process in the network layer when an attendant pushes a button to achieve the 'hold' feature  . the problem is that the sending of a message is not represented at a fine enough grain  so that  message sent when an attendant pushes a button  cannot be directly retrieved1. however  lassie can be used to answer the related query   what functions are called when an attendant pushes a button to activate the 'hold* feature . at this point  the user can inspect the functions' source code manually to determine which messages could be sent under actual running 
   to answer this question precisely  the code has to be actually run or simulated; this means that computing a correct answer would be undecidable. 
1 	tools 
conditions. even for queries that cannot be handled exactly  lassie's mode of interaction is rich enough to provide at least a partial answer. 
1 related work 
traditional approaches to software retrieval fall into two complementary categories: high-level classification techniques  which emphasize retrieval by software category; and low-level cross-reference tools  which facilitate various kinds of browsing at the code level. 
　the goal of high-level classification techniques is usually to create a database of programs and program parts that can be retrieved for re-use. two methods of indexing are normally used. in the first  keywords arc used to describe and classify software components and keywords are used for retrieval in the traditional fashion: a user will list a set of uninterpreted terms that  describe  the desired component and the system will retrieve all components that are close in some multi-dimensional space defined by the keywords. the catalog system  frakes and nejmeh  1  is of this type. clearly  the utility of a keyword system will depend on how well the keywords describe the components and how well they match those keywords normally thought of by a user. the further issue of generating the database arises here  as it does with any such database. 
　prieto-diaz expanded the notion of strict keyword retrieval by forming a static taxonomy of concepts or  facets  that impose an organization on the set of keywords.  prietodiaz  1  for example  the facet  function  includes the terms add  append  create  evaluate  and the facet  objects  includes the terms arrays  expressions  files  and functions. the system is queried much like a keyword system  but may be more amenable to a  query-modify  retrieval cycle than pure keyword description. once designed  however  his classification scheme is static and fixed. 
　at the low level  there are a number of tools derived from the notion of a cross-reference listing  which indexes two code components with each other  for example  files and function calls. masterscope  teitelman  1 was one of the earliest such tools; it was integrated with the interlisp environment. cscope  steffen  1  and cia  chen and ramamoorthy  1  are tools that run in the c environment; they both automatically generate a database of two-place relations  essentially  the  defined-in  and the  referenced-in  relations  and allow a user to query or browse the relationships of a large software system. cia  the more comprehensive of the two  is based on the relationships between five code objects: files  functions  global variables  type definitions  and macro definitions   #define  statements   and it allows limited two-place queries. for example  one can ask for all functions that call a given function  or all macros used in a given file. the current implementation is unable to handle queries with conjunctions  negation  or quantification. 
　neither of these two approaches-software classification techniques and cross-reference tools-comes close to achieving the power of lassie  due in part to the fact that they do not provide inference capabilities. they could not handle the classes of queries illustrated by q1-q1 in section 1. they do not address the issue of integrating high-level functional knowledge and code knowledge  attempt to model the underlying domain  or capture more than a single view of software. 
1 directions for future research 
lassie has reached a plateau of accomplishment  but there is a long way to go before it is the ideal software information system. for example  we need to incorporate more of the architectural view of system 1. this involves a more detailed examination of the process-level functioning of the system  including details on the purpose of specific processes  the messages they send  and the meanings of those messages. 
　on a more practical level  we are re-designing lassie to use the classic knowledge representation language  borgida et a/.  1 . present plans also include porting the system from the symbolics machine to run on sun workstations and other common lisp environments. this involves a re-design of the argon interface. 
　we must also continue to address the problem of knowledge acquisition. constructing a knowledge base is labor intensive  and we need to examine the possibility of doing some of it automatically. the acquisition of the code knowledge in the current version of lassie was done automatically; acquiring other kinds of knowledge in a similar manner is a research project in itself. there is reason to believe that some large software systems include enough highly standardized comments that this can be done. there has recently been some promising research in the area. biggerstaff  biggerstaff  1  has proposed an approach to reconstructing the lost design of software from a variety of sources  including source code  design documents  using a domain model  mimicking the process by which an expert who is well acquainted with  for example  windowing systems in general  might reconstruct the design of a new windowing system using his/her knowledge of the general structure of such systems. on a more formal  and somewhat closer the code  level  letovsky  letovsky  1  and wills  wills  1   have used formal methods to discover algorithmic patterns  loops  tests  accumulations  etc  in programs. 
1 summary 
our approach to the problem of maintaining and extending large software systems is to employ explicit knowledge representation and reasoning technology. this has led us to formulate complementary models of a software system in terms of its function  architecture  features  and code. to this end  we constructed a knowledge base that captures critical aspects of three of these four views of the system 1 switching system. we also customized and incorporated a natural language component to be used either alone or in conjunction with the argon interface. 
　as a result of these efforts  lassie is the first information system to incorporate multiple views of a large software system embedded in an environment that lets a user query the system and explore the knowledge base. although much remains to be done  lassie can handle successfully many classes of queries about a large software system. 
