 
this paper describes a real-time decisionmaking model that combines the expressiveness and flexibility of knowledge-based systems with the real-time advantages of anytime algorithms. anytime algorithms offer a simple means by which an intelligent system can trade off computation time for quality of results. previous attempts to develop knowledge-based anytime algorithms failed to produce consistent  predictable improvement of quality over time. without performance profiles  that describe the output quality as a function of time  it is hard to exploit the flexibility of anytime algorithms. the model of progressive reasoning that is presented here is based on a hierarchy of reasoning units that allow for gradual improvement of decision quality in a predictable manner. the result is an important step towards the application of knowledge-based systems in timecritical domains. 
1 	introduction 
this paper describes a real-time decision-making model that combines the expressiveness and flexibility of knowledge-based systems with the real-time advantages of anytime algorithms. the application of knowledgebased systems to real-time domains such as process control  automated navigation systems  medical monitoring  and robotics is an important problem in artificial intelligence. a major difficulty in solving this problem arises since real-time domains require continuous operation and predictable performance while knowledge-based systems rely on time-consuming algorithms with highly variable performance. performance variability has limited the application of knowledge-based systems to realtime domains. 
　'this author continues to collaborate with crin-1nria until september 1 at the address: batiment loria bp 1  
1 vandoeuvre  france  e-mail: amouaddi loria.fr 
　support for this author was provided in part by the national science foundation under grant iri-1. 
shlomo zilberstein* 
computer science department 
university of massachusetts 
amherst  ma 1 	u.s.a. shlomo cs.umass.edu 
　to avoid these problems  the ai community has constructed several general paradigms such as anytime algorithms  dean and boddy  1; horvitz  1   design-totime  garvey and lesser  1  and various types of progressive reasoning techniques  winston  1; mouaddib et a/.  1 . another approach has been to construct special architectures for particular problem domains such as the guardian system for monitoring the patient's condition in an intensive care unit  hayes-roth et a/.  1 . among the general paradigms  anytime algorithms in particular are increasingly used in ai applications since they are easy to construct and monitor and since they can be efficiently combined to produce larger real-time systems  zilberstein  1 . but successful control of anytime algorithms require the use of performance profiles that describe the dependency of output quality on computation time. knowledge-based anytime algorithms that have been proposed in the past do not exhibit high correlation between computation time and output quality. therefore  their performance profiles can not be constructed and their use as anytime algorithms is very limited. 
　in this paper  we describe a model of knowledge-based progressive reasoning that meets the requirements of a  well-behaved  anytime algorithm. the model consists of a rule-based language and an associated inference mechanism. problem solving is performed by an iterative process that produces quickly a first solution and refines it step-by-step until interrupted by the control mechanism. in section 1  we describe the problem of constructing knowledge-based anytime algorithms and the difficulties with current solutions to the problem. section 1 describes the model of progressive reasoning in detail. in section 1  we describe an application of the model to a collision avoidance system. we conclude with a summary of the contribution of this work and future research directions. 
1 anytime computation and knowledge-based systems 
this section presents the advantages of anytime algorithms for real-time decision making. the section describes several efforts to develop knowledge-based systems as anytime algorithms and explains the difficulty of combining the two paradigms. 
1 anytime algorithms 
anytime algorithms are algorithms whose quality of results improve gradually as computation time increases  hence they offer a tradeoff between resource consumption and output quality. the quality of the results produced by anytime algorithms can be measured by their level of certainty  accuracy  or specificity. a performance profile  dean and boddy  1  is a probabilistic description of the dependency of output quality on computation time. zilberstein and russell generalized this notion capturing also the dependency on input quality using conditional performance profiles. the latter can be used to optimally compose real-time systems using a library of anytime algorithms  zilberstein  1 . to solve the composition problem  an important distinction is made between two types of anytime algorithms  namely interruption and contract algorithms. an interruptible algorithm can be interrupted at any time to produce results whose quality is described by its performance profile. a contract algorithm offers a similar trade-off between computation time and quality of results  but it must know the total allocation of time in advance. interruptible algorithms are more flexible  but they are also more complicated to construct. zilberstein  solved that problem by a general construction that produces an interruptible version for any given contract algorithm and requires only a small  constant penalty. subsequently  a set of programming tools for composition and monitoring of anytime algorithms have been developed by grass and zilberstein . 
　since their introduction in the late 1's  anytime algorithms have been applied to such real-time problems as mobile robot navigation  medical diagnosis and monitoring  information gathering  and model-based diagnosis. in addition  several anytime algorithms have been developed for evaluation of probabilistic networks and for dynamic programming. but the technique has been less successful in the area of knowledge-based systems. 
1 real-time knowledge-based systems 
in a 1 comprehensive survey of real-time knowledgebased systems  laffey et a/.  1   the authors concluded that  currently  ad hoc techniques are used for making a system produce a response within a specified time interval.  unfortunately  not much has been changed since that survey was conducted. the primary method for achieving real-time performance is based in many cases on speeding up individual algorithms in a generate-andtest manner. this method slows down the development of real-time systems and makes them inefficient when operating in dynamic environments. 
　one approach to deal with the problem has been to develop specialized architectures for particular domains. one successful example is the guardian system for monitoring the patient's condition in an intensive care unit  hayes-roth et a/.  1 . the system integrates perceptual capabilities with real-time reasoning and action. closer to our approach is the patient monitoring system developed by ash et al. . the system exhibits an anytime behavior accomplished by organizing actions in a hierarchical structure. the result has been integrated into the guardian system to provide a response when the slower  deliberative methods cannot complete their tasks. the work described in this paper extends the hierarchical decomposition approach to general knowledge-based systems. our motivation is best summarized by the conclusion of the above survey: 
 we concluded that one of the main reasons for this situation is that expert systems developers * have often tried to apply traditional tools to applications for which they are not well suited. tools specifically built for real-time monitoring and control applications need to be built. an immediate goal should be the development of high-performance inference engines that can guarantee response times.  
1 knowledge-based anytime computation 
knowledge-based systems rely on an inference engine combined with a body of declarative knowledge. since the amount of relevant knowledge varies from situation to situation  it is hard to predict how problem solving will progress as a function of time. hence  a naive implementation of progressive reasoning techniques does not lead to  well-behaved  anytime algorithms. in this section we describe two attempts to construct anytime knowledge-based systems and their limitations. 
　elkan  presents an abductive strategy for discovering and revising plausible plans. in his approach  candidate plans are found quickly by allowing them to depend on assumptions. his formalism makes explicit which antecedents of rules have the status of default conditions. candidate plans are refined incrementally by trying to justify the assumptions on which they depend. the implementation of the model replaces the standard depth-first exploration strategy of prolog with an iterative-deepening version. the result is an anytime algorithm for incremental approximate planning. 
　as we pointed out earlier  it is hard to find the performance profile of such a planner. even in the context of particular domain knowledge  the performance of the inference engine  a theorem prover  is going to be highly dependent on the particular query and is hard to predict in advance. another difficulty is to measure the quality of results in a meaningful way. our model of progressive reasoning addresses successfully these two issues. 
　smith and liu  propose a monotone query processing algorithm which derives approximate answers directly from relational algebra query expressions. an approximate relation r of a standard relation 1 is a subset of the cartesian product of all the domains of s that can be partitioned into two blocks  the certain set c and the possible set p such that: c c 1 and r = cup   s. the algorithm assumes that the information stored in the database is complete and that the input data is precise. an incomplete answer to a query is generated when there is not enough time to complete processing the query  or because some relation that must be read is not accessible. 
　vrbsky and liu have implemented the approximate query processing algorithm in a system called approximate  vrbsky and liu  1 . the operation associated with each leaf node of the tree is an approximateread that returns one segment of the requested relation at a time. approximate relational algebra is used in order to evaluate the tree. initially  the certain set is empty for every approximate object and the possible set is the complete range of values for the particular object. after each approximate-read  a better approximate answer to the query is produced. the exact answer is returned if the system is allowed to run to completion. 
　approximate suffers from the same problem as elkan's approximate planning technique  namely the difficulty to derive the performance profile of the system due to its dependence on the contents of the database and the complexity of the query. it is also hard to evaluate the quality of an approximate relation and represent it quantitatively. to summarize  existing knowledgebased techniques are hard to convert to anytime algorithms due to wide variability in performance improvement over time. 
1 progressive reasoning 
progressive reasoning is an important technique to design knowledge-based systems that exhibit a highly predictable time-quality tradeoff. the technique uses multilevel deliberation in order to gradually transform an approximate solution into a precise one. the mapping from the set of inputs  problem instance  to the set of outputs  solution  is based on progressive exploration of data and knowledge  hence the name progressive reasoning. progressive exploration is facilitated by using a hierarchical structure of input elements defined by weights that the system's designer attaches to each input according to its importance. correspondingly  knowledge is also organized in a hierarchical way. this mapping is especially suitable in domains where the reasoner uses abstraction to structure the search space  as in hierarchical planning    and in problems that require the result to be expressed at varying levels of detail  as in model-based diagnosis . 
　furthermore  this organization is an important factor in reducing the unpredictability of knowledge-based systems by limiting the amount of knowledge and data that is the focus of the system at each level of the hierarchy. as a result  we can characterize precisely the tradeoff between computation time and quality of results offered by progressive reasoning systems. 
　this section explains how progressive reasoning works. the two major issues in progressive reasoning are the hierarchical organization of knowledge and the control of the evolution of solution quality. we cover these issues by first describing the conceptual model and then its implementation and properties. the implementation is based on the great  guaranteed reasoning time  model  mouaddib et a/.  1 . 
1 	conceptual model 
the distinctive features of our progressive reasoning approach result from the combination of:  1  a generic knowledge representation language that facilitates progressive problem solving; and  1  a control mechanism that progressively feeds data and knowledge into the inference engine using a preference criterion. 
　knowledge is represented using a rule-based language that refers to data by a set of attributes. the progressive problem solving process assumes that there are several solutions with different qualities each of which represents an intermediate  approximate  view of the final solution. the transition from one solution to a more precise one is done by using additional attributes and rules that are more precise than those previously used. each rule can change the current solution by adding  deleting or modifying the attributes contained in the current solution. this process is shown schematically in figure 1. 

figure 1: the schematic structure of progressive reasoning. 
　this organization is defined by a preference criterion representing the accuracy of the attributes specified by the system's designer. the attributes preference criterion allows the solution to be represented at different levels of detail. this preference criterion  named criticality by knoblock et al.   is generalized by the notion of granularity in the great model. we also use the certainty of attributes to control progressive manipulation of data of the same granularity. based on the attributes preference criterion  the preference criterion of rules is computed automatically as will be shown in the next section. the preference criterion defines aggregations of attributes and aggregations of rules that are 


completeness and its certainty. if the evaluation fails  processing resumes at level li until the evaluation succeeds or the deadline is reached. when the evaluation succeeds  the evaluator invokes the next level in order to improve the precision of the solution. 
　the construction of the reasoning levels  li  guarantees the improvement of the solution quality as the system moves from one level to another. this is true since the attributes computed by a new level li are always more precise than those contained in the current result. the level li deletes  from the current solution  attributes judged incorrect at the current level of granularity  for example  the attribute time that contains the value 1h can be replaced at another level of granularity which takes minutes into account by the value 1hl1min . that is why the quality of the solution slrea is preferred to that of*- 1 . 
1 application: a collision avoidance system 
consider the problem of collision avoidance in a railway network. assume that a railway network consists of n horizontal railway tracks and n vertical tracks each of which is used by one train. each horizontal track intersects all the vertical ones. the main objective is to prevent two trains from colliding with each other at one of the n1 crossings. the system needs to detect potential collisions and to optimally modify the speeds of the train to avoid any chance of collision. the rest of this section describes how the great model was used to construct this collision avoidance system  mouaddib  1 . 
1 	collision avoidance with progressive reasoning 
in our implementation  the collision avoidance task is achieved using different levels of approximation depending on how much time is available. the deadline is defined as the time remaining before a collision may occur. in this domain  there are several different policies to avoid collision. the system can either control the train in a qualitative manner  stop  slow  speed  or it can compute the actual speed at various levels of precision. different constraints can be taken into account  such as passenger comfort  this means that acceleration or slowing down have to be limited   the time-table of each train  and the priorities or time-dependent utilities of the different trains. 
to capture these types of knowledge  we used the components of great as follows: 
  the set of data attributes is defined as: d - {speed  tendency  nextcross  distance  railpriority  maxspeed  minspeed  timetable} 
  the context of a situation is defined as: 
c - controlcollision. in this context the set d is 

1 	experimental results 
the performance of great is summarized by the graphs shown in figure 1. we examine the performance as a function of two parameters:  1  the deadline  that causes gradual improvement of solution quality as it increases  and  1  the size of the network  that causes gradual degradation of solution quality as it increases. this is because control time increases as a function of the size while the deadline decreases. measuring the precise  objective  quality of the solution is hard in knowledgebased systems  but the level of reasoning is a good indication of solution quality in our system. hence we use the ratio between the number of activated levels and the total number of levels as our overall quality measure. we are currently investigating possible improvements in measuring overall quality  but the above measure is sufficient to show that the system exhibits gradual improvement/degradation of quality as computational time increases/decreases. 
to summarize  our experimental results show that 
great establishes a correlation between solution qual-

ity and computation time which can be quantitatively described by a performance profile. 
1 	conclusion 
we have presented a model of progressive reasoning - a knowledge-based approach to real-time decision making - and its implementation. our preliminary results show that by structuring the available knowledge in a hierarchical way and by limiting the amount of data and knowledge used at each level  we can construct knowledgebased systems that have all the characteristics of a  wellbehaved  anytime algorithm. in particular  our system exhibits gradual improvement/degradation of quality as computation time increases/decreases  or problem size decreases/increases . moreover  the behavior of the system is consistent and can be characterized by a performance profile  typically used in control of anytime computation. this result is an important step toward the adaptation of knowledge-based systems  that normally 

exhibit high variability in performance  to real-time domains where predictability of performance is essential. 
　further work is needed on several aspects of the implementation including the designer's task of mapping domain knowledge into a hierarchical structure  the development of more precise quality measures  and the use of a utility-based approach to control the operation of the system. other research directions include the application of the model to construct a multi-agent system and implementation of a larger application. 
