
in this paper we extend active monte carlo recognition  amcr   a recently proposed framework for object recognition. the approach is based on the analogy between mobile robot localization and object recognition. up to now amcr was only shown to work for shape recognition on binary images. in this paper  we significantly extend the approach to work on realistic images of real world objects. we accomplish recognition under similarity transforms and even severe non-rigid and non-affine deformations. we show that our approach works on databases with thousands of objects  that it can better discriminate between objects than state-of-the art approaches and that it has significant conceptual advantages over existing approaches: it allows iterative recognition with simultaneous tracking  iteratively guiding attention to discriminative parts  the inclusion of feedback loops  the simultaneous propagation of multiple hypotheses  multiple object recognition and simultaneous segmentation and recognition. while recognition takes place triangular meshes are constructed that precisely define the correspondence between input and prototype object  even in the case of strong non-rigid deformations.
1 introduction
recently  active monte carlo recognition  amcr   a new object-recognition approach exploiting the analogy between robot localization and object recognition was proposed by  von hundelshausen and veloso  1 . although the approach is conceptually interesting  it was only shown to work for shape recognition on binary images  so far. furthermore the proposed approach is not scalable to large object databases.
　in this paper we massively extend the approach in various ways  such that it works on realistic images of real-world objects  that it is scalable to large object databases  and such that a correspondence mesh is constructed between input and prototype object recovering correspondence even in the case of large deformations. we show that our new approach meshamcr can better discriminate between objects than state-ofthe art methods and that it performs better geometric verification than current approaches for both rigid and deformable objects.
　the field of object recognition can be divided in object class recognition  the problem of recognizing categories of objects  such as cars  bikes or faces  see  fei-fei et al.  1    serre et al.  1     mutch and lowe  1   and object identification  the problem of recognizing specific  identical objects  such a identifying a specific face or a specific building. our approach mesh-amcr addresses this latter problem.

figure 1: palm sunday  an ambiguous painting by the mexican artist octavio ocampo
　state-of-the-art approaches in object identification typically divide the task in two stages  feature matching and geometric verification. prominent feature detection methods are  lowe  1    ke and sukthankar  1    mikolajczyk and schmid  1  and  matas et al.  1 . for finding prototype images with matching features different schemes have been tried  reaching from nearest neighbor search and hough-based grouping  lowe  1  to the use of vocabulary trees  nister and stewenius  1 . in this first stage  the goal is to retrieve a bunch of candidate images  without worrying about the geometric validity of feature correspondences. in geometric verification the geometric layout of feature correspondences is verified. typically  ransac  fischler and bolles  1  is used to find valid groups of feature correspondences  typically verifying their positions subject to the class of affine transformations or rigid epipolar geometry  kushal and ponce  1 . an exemption is  alexander c. berg  1  where low distortion correspondences are found through solving an integer quadratic programming problem  similar to how correspondences where established in the work of  belongie et al.  1 .
　although  the referenced approaches let us reach a state of maturity in object identification  they still have some significant drawbacks and conceptual problems. with the exemption of  belongie et al.  1  their drawback is that they use only the feature descriptors to distinguish between objects. while the features are well-suited to establish hypothetical scale invariant frames of reference  their descriptors only describe a small amount of information that could be used for discrimination. sift features  for example  are willingly not detected at edges  but edges at locations where no sift-features are detected could help identification. the other drawbacks can best be described by three criterions that should be met by an object recognition framework that is suited to be integrated in a real-time robotic system.
1. iterative recognition the process of recognition should be distributable over several frames  only performing a small amount of processing in each frame  but this amount being rapidly computable  such that other approaches like tracking can take place simultaneously in real-time. using the information of several frames over time provides richer information for discrimination. none of the above approaches fulfills this criterion  because they are based on single images and perform all the processing in each image. only by using an iterative object recognition approach and combining it with tracking the continuity constraints that underly successive images of real-world video can be exploited.
1. allowing feedback figure 1 shows  that the mind sees what it wants. the nose can either be a nose or an elbow depending on what the mind wants to see. since recognition is also a question of will  a recognition approach should offer an interface for this will . for example  it should offer an interface of where attention is put on and on being able to specify a bias for favored interpretations. feedback not only means the control of attention but also on the type of features that are use for discrimination. also  real motoric actions  like gaze control  or even movements of a robot might be necessary to distinguish two objects. although these ideas are not new  none of the current best object-identification programs really implements these concepts.
1. propagating multiple hypotheses meanwhile the computer vision community has well understood  that segmentation cannot be accomplished independently from recognition. thus  no unique ad hoc frame of reference can be established for comparison  but rather different hypothetical matches have to be propagated simultaneously. rather than performing a depth first examination and iterative breath-first examination has to take place. while different interpretations iteratively compete  this competition can be examined to determine where to guide attention an which features to use in order to discriminate between the competing hypotheses. none of the before-mentioned approaches offers an interface for such a process.
we will show that mesh-amcr allows to integrate all these concepts. the remainder of the paper is organized as follows. in section 1 we shortly review active monte carlo recognition  amcr . in section 1 we describe our new approach mesh-amcr. in section 1 we show experimental results. section 1 finally concludes our paper.
1 active monte carlo recognition  amcr 
amcr was developed as the consequence of recognizing that mobile robot localization and object identification are essentially the same problem and transferring the best known localization method  monte carlo localization  mcl   s. thrun and dellaert  1  to the problem of object recognition von hundelshausen and veloso  1 . similarly to how a robot explores its environment and localizes itself in a set of maps  the focus of attention explores an image and recognition is put as the problem of localizing the focus of attention in one of a set of prototype images. in the same way as mcl uses a set of particles to approximate a probability distribution for the robot's position  amcr uses a set of m-particles to localize the position of the attentive v-particle. furthermore  not only one point of attention might be used but amcr employs a set of v-particles to explore the input image  similarly to how an unknown area might be explored by a swarm of robots. to apply mcl only two models have to be provided  a measurement model and a motion model. in amcr  the measurement model specifies what kind of measurements are taken at the point in the image where a v-particle is located. the motion model specifies the distribution of how the m-particles move when the corresponding v-particle moves. additionally amcr requires the specification of a motion policy  that is a mechanism of how the v-particles should explore the input image.
　in the original work  von hundelshausen and veloso  1  only binary images of various shapes where used. each v- and m-particle was just described by a  x y  location together with an orientation. the motion policy was defined by letting the v-particles move in the direction of their orientation and letting them being reflected at edges. the measurement model was implemented by letting the particles performing a range scan  measuring the distance to the first edge for each scan line  similarly to how laser range scanners are used in mobile robot localization.
　this instance of amcr  radial-amcr is hardly applicable on real word images  since the measurement model is too simplistic. but it has further drawbacks: one is  that the method does not scale well with the number of prototype objects  since for each v-particle a whole bunch of m-particles has to be instantiated in each prototype image. another drawback is that in radial-amcr there was no mechanism to prevent a v-particle returning to a location it already had explored.
　in our new approach mesh-amcr we will get rid of all these drawbacks by specifying a new measurement model  a new motion model and adding the idea of iteratively constructing hypothetical correspondence-meshes.
1 our new approach: mesh-amcr
in radial-amcr a swarm of m-particles starts forming a cluster in a prototype shape that corresponds to the input image  at a position that corresponds to the respective v-particle. while the v-particle is moving in the input image  the mparticles move accordingly. thus  a sequence of hypothetically corresponding points in the input image and the prototype images is retrieved. one basic idea of mesh-amcr is to use these points to construct corresponding meshes. here  each v-particle has a triangular mesh  and each of its mparticles has a corresponding triangular mesh with the same topology  but allowing a deformed geometric layout. each cell of the meshes is a triangle and each triangle in the vparticle's mesh has one unique corresponding triangle in each mesh of its connected m-particles. when mesh-amcr iteratively converges to a stable interpretation  the mesh of the best m-particle shows how the input image has to be deformed in order to match the retrieved prototype-image. here  each triangle in the v-particles mesh is linearly mapped to the corresponding m-particle's triangle. indeed the meshes define an affine transformation that can change from cell to cell such that the recovering of non-affine transformations is possible. before we describe these mechanisms in detail we first solve the problem of the bad scalability to large object databases.
1 candidate object retrieval
when using a large database of prototype images  we limit the number of images to be considered by applying the recently proposed vocaulary tree method of  nister and stewenius  1   but using pca-sift features  ke and sukthankar  1  instead of maximally stable regions  matas et al.  1 . here  we have to extract all pca-sift features prior to starting mesh-amcr  and by applying the tree bases scoring scheme we retrieve the k best candidate images. we then apply mesh-amcr solely on these candidate images. at this point we are violating our own iterative recognition philosophy  but we belief that the pca-sift feature extraction approach can be changed in future  such that the process of extraction can itself be reorganized into an iterative process and distributed over several frames. this would be an interesting topic for future research. currently  we just extract the features in the first frame  get the candidate prototype images and then start our iterative method with the successive frames. in our experiments we take the best 1candidate images out of a database of 1 objects.
1 v- and m-particles
both v- and m-particles will iteratively construct triangular meshes. the trick in mesh-amcr is that in each iteration a v-particle corresponds to exactly one cell in the v-mesh  and each m-particle corresponds to exactly one cell in the mmesh. but the cells that correspond to the particles change in each iteration. in fact  the meshes expand in each iteration by one additional cell  respectively  and always these last cells correspond to the particles. thus both  v- and m-particles are basically triangles  defined by three points. this is quite different to  von hundelshausen and veloso  1  where the particles were just points plus an orientation. in this way each related pair of v- and m-particles naturally defines an affine transformation that represents the hypotheses that the v-triangle has to be linearly mapped to the m-triangle in order to make input and prototype image match to each other. however  the validity of the affine transformation is restricted to the particular cells. pixels outside the triangles have to be mapped by the affine transformations that are given by the neighboring mesh-cells  if available. of course  the choice to use triangles as mesh-cells is not arbitrarily: two corresponding sets of three points constitute the smallest entity that uniquely define an affine transformation.
summarizing  a v-particle v is represented as
　　　　　　vi :=  pi1 pi1 pi1 v-meshi    1  with p  being the corner points of the triangle and v-meshi being a triangular mesh that initially only contains a copy of the v-particle's triangle. similarly  an m-particle is represented as a triangle  a mesh  and two additional indices:
　　　　m m-meshj ij kj  	 1  where ij is the index of the v-particle to which the m-particle is connected and kj is the prototype image in which the mparticle is located.
1 scale invariant features as igniting sparks
the m-particles approximate a probability distribution for the v-particle's corresponding position and mesh configuration in the prototype maps. since the meshes are iteratively expanded  the dimensonality of the the space of m-particles varies. initially  the meshes start with a single triangle and thus the dimensionality is 1 + 1 = 1  1 for the three points and one for the prototype index kj  for the first iteration. even this initial dimensionality is very large and a huge number of m-particles was needed to let recognition converge to the correct solution starting for example from a uniform distribution of m-particles. to overcome this problem  the trick is to place v- and m-particles at initial starting position that have a high probability of being correct. we use the pca-sift matches found in the candidate retrieval phase to define good starting points. here  we place a v-particle at each keypoint in the input image and connect it to m-particles placed at possible matches in the prototype images. more precisely  given a keypoint in the input image  we can efficiently navigate down the vocabulary tree reaching a leaf-node that contains a bucket with all keypoints in the protype images that define the same visual word  see  nister and stewenius  1  . these hypothetical relations between keypoints are the igniting sparks for mesh-amcr.
　a typical initial situtation is illustrated in figure 1. the main notion behind the v- and m-particles is that a pictorial element in the input image can be interpreted in different ways: for instance  the nose in image 1 can either be interpreted as a nose  prototype image face  or as an ellbow  prototype image of an arm . we now define the motion policy  the

figure 1: after keypoint matching  v- and m-particles are setup according to probable keypoint matches returned as a byproduct of the candidate object retrieval phase.
measurment model and the motion model for mesh-amcr.
1 motion policy and mesh expansion
consider the case of having only one v-particle v :=  p1 p1 p1 v-mesh . in each iteration  the v-particle performs a movement  i.e. the coordinates of its three points  p1 p1 p1  change. this movement is performed in a way  that the new triangle aligns with an edge of the old triangle  thereby expanding one of its edges and successively constructing a triangular mesh. while the v-particle moves in each iteration  the data structure v   mesh holds the corresponding mesh that is constructed. there are many different possibilities regarding the order of edges that are expanded. in our experiments we simply expand the boundary mesh cells in a clockwise order.
　with the v-particle moving and expanding its mesh by one cell each m-particle performs a corresponding movement and mesh expansion. while the topology of the m-mesh corresponds exactly to its v-mesh  the exact position of the points can vary  thereby allowing deformed meshes as is illustrated in figure 1. the distribution of variation is defined in terms of the motion model. thus while the motion policy defines how a v-particle moves  the motion model describes the variations of movements the m-particles can perform. note  that the expansion and position of the triangular cells is independent of the initial keypoints. only the first cell positions during initialization are placed at the location of keypoint matches.
1 motion model and mesh variations
because of the resampling process  good m-particles will produce multipe exact copies. when a v-particle performs a movement and mesh expansion step  all the m-particles will also perform a corresponding movement and mesh-expansion step. however  each m-particle will do so in a slightly different way such that variations arise in the newly added triangles of the m-meshes. indeed  it is only the free point of the new triangle that varies among the m-meshes. however  after

figure 1: during expansion the meshes behold the same topological structure. however  the positions of the nodes of the m-meshes can vary  thereby allowing to match deformed objects.
several iterations of measurement  resampling and expansion steps  the resulting meshes can be quite different  even when they all started to be the same.
1 measurement model
in each iteration  each m-particle gets a weight that represents the quality of the hypothetical relation to its connected v-particle. this weight is calculated by investigating the appropriate pixels in the input and prototype image. the triangle of the v-particle and the triangle of the m-particle define an affine transformation and we define a dissimilarity function that compares these triangles subject to the given affine transformation. instead of comparing the pixels  we build histograms with 1 bins of edge orientations and compare these histograms. this idea is inspired by  edelman et al.  1   based upon a biological model of complex cells in primary visual cortex.
1 resampling of the m-particles
in each iteration  the m-particles obtain a weight according to the measurement model and the m-particles are resampled. in this process a complete set of new m-particles is generated from the old one. some of the old m-particles are discarded  and some are copied multiple times to the new set  with the total number of m-particles remaining constant. the expected number of copies of an m-particle is proportional to its weight. resampling takes place in the set of all mparticles that are connected to the same v-particle  no matter in which prototype they lie. consequently  it can happen that a prototype looses all its m-particles after some iterations  meaning that the respective prototype does not represent the given input image. vice versa  m-particles will cluster in prototypes matching the input image. in this way the computational power is concentrated on similar prototypes.
1 experimental results
in this section we compare our method with state-of-the-art object recognition systems and show its advantages. since our goal is object identification we do not compare to object class recognition approaches. we show that mesh-amcr is better for both geometric verification and distinction between similar objects than existing approaches. to proof this  we show that mesh-amcr can deal with all cases in which traditional methods work  and that it can additionally solve cases in which state-of-the-art methods fail.
example
before describing our results on large object databases we illustrate mesh-amcr with an example. in this example we assume that an image of a deformed banknote has to be recognized within 1 candidate objects retrieved by the vocabulary tree scheme. one of the prototype images contains the same but non-deformed banknote. while we assume that the prototype images are segmented  the input image is not segmented and contains background clutter. figure 1 shows how recognition is performed and how deformations can be recovered by deforming the meshes of the m-particles.
efficient implementation
although several hypotheses are propagated  our method is still efficient. the number of v-particles in quite low  1 . in each iteration only one triangular cell of each m-mesh has to be compared to its corresponding cell of its v-mesh. since several m-particles are linked to the same v-particle  the pixels of each v-particle's cell have to be sampled only once. comparing the triangular cells subject to their affine transformation can be efficiently done using standard graphics accelerator hardware  e.g. using directx .
experiments on rigid object databases
to evaluate our method we use the wide-baseline stereo dataset of the amsterdam library of object images  aloi   geusebroek et al.  1  containing realistic images of 1 objects  each captured from three different viewpoints  left  center  right  rotated by 1 degrees each. we used all 1 right images to learn the vocabulary tree. as test images we used the left images  differing by 1 degrees  but additionally we scaled them down to 1 percent of the original size  plus rotating each about 1 degrees. for the geometric verification phase  we implemented a method of reference according to current approaches like  lowe  1  and  ke et al.  1 . they use affine transformations to explain the geometric layout for keypoint matches. in our reference method  we use ransac  fischler and bolles  1  to verify the

figure 1: red  dark  triangles show the position of v- and mparticles. the yellow  light  triangles show the corresponding meshes. the pixels within the m-meshes are texture mapped from its corresponding v-meshes. in  a  v- and m-particles are initialized according to well matching pca-sift features.  b  shows the situation after 1 iterations. in  c  only the maximum a posteriori  map  estimate of the m-particle and its corresponding v-particle is shown. the meshes of the map v- and m-particles specify the correspondence between input and correctly identified prototype image.
geometric validity of keypoint matches based on affine transformations. using this approach we get a recognition rate of 1 percent on the 1 objects database. for comparison we applied mesh-amcr on the same dataset and test images. here we used only 1 iterations leading to hypothetical correspondence-meshes with 1 triangular cells  respectively. as recognized object we take the candidate-image that has the most m-particles at the end. in doing so  we get a recognition rate of 1 percent. thus  mesh-amcr is performing significantly better. mesh-amcr correctly recognized 1 of the cases that were falsely classified by the affine transformation based ransac method.
　these failures typically occur when the image of one of the objects - input object or prototype object - has only few keypoints. in the work of  ke et al.  1  1 keypoint matches are required as minimal configuration that satisfies geometric constraints. in the approach of  lowe  1  as few as 1 keypoint-matches constitute the minimal valid constellation. this design was made  to allow recognition of objects with few keypoints. unfortunately  the less keypoint-matches the more likely the chance of finding a matching group in a wrong prototype image.
　the advantage of our method is that geometric verification is not based on the keypoint descriptors but on the original image data referenced by the constructed correspondencemeshes. thus  our source of information is much richer for both discrimination and geometric verification. we only need one keypoint-match as igniting spark for mesh-construction at the beginning. thus  while requiring less keypoint-matches to initiate verification  we still have richer information to check for geometric constraints.
1 conclusions
in this paper  we have proposed mesh-amcr  a new algorithm for object identification that has its origins in methods for mobile robot localization. besides the advantages of better discrimination and recognition of deformable objects our approach has some conceptual advantages: first  recognition is performed in an iterative way such that other algorithms like tracking can run in parallel. second  it does not assume a prior segmentation of the input images. third  it is able to propagate several hypotheses simultaneously. hence  the simultaneous recognition of several objects is possible  too. additionally  the algorithm yields precise correspondence in form of corresponding mesh-cells. there are plenty of possibilities of extending the approach: one of the most interesting one is how to guide the v-particles to parts that let us best discriminate among competing hypotheses  and how to dynamically adjust the measurement models of the v-particles for best discrimination. another interesting question is of how the meshes could be used to recover shading models to allow larger variations in lighting conditions.
