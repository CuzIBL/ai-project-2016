 
　　the complexity of the domains in which expert systems are expected to operate requires that they be capable of  reasoning*1 about their actions it has been argued that expert systems must reason from evidential information i.e.  uncertain  incomplete  and occasionally inaccurate information  low1a|. as a consequence  a model for reasoning about control must deal with several problems being able to organize  control-related  evidential information that is generically distinct and from disparate sources  to overcome minor errors in the evidential information needed to reach a decision  and to explain the actions taken by the system these are a few of some formidable control issues and problems that remain largely unsolved  bar1  thus  we report on an investigation into how these issues and problems can be addressed when the problem of reasoning about system control is viewed as an evidential process. 
introduction 
　　expert systems that operate in complex domains are continually confronted  m h the problem of deciding what to do next. furthermore  such systems must  reason  about their alternatives and choose an action on the basis of uncertain  incomplete  and inaccurate information  called evidential information  low1a . for instance  the decision to take a particular action can be influenced by the expected outcome of taking that action. however  situations may arise in which uncertainty exists about the consequences of taking any action  particularly when uncontrollable or unpredictable events may intervene. resource limitations  for example  might not permit gathering all relevant facts  thus forcing decisions to be made with incomplete information. finally  it must be anticipated that the information supplied to the system may be inaccurate because  among other reasons  the sources of the information are imperfect we  as well as the systems we build  must be capable of choosing an action on the basis of evidential information. 
therefore  the on-going research reported here is concerned with some problems that must be dealt with before such capabilities can be realized. 
some control problems 
　　typically the information needed to choose between alternatives is obtained from multiple sources and varies in both the type and the unit of measurement for example  costs and goals/subgoals are two 
distinct types of information. one source might talk about costs in terms of cpu cycles  and another distinct source might talk about 
costs m terms of the degradation of the system's ability to complete its task a problem of interest is how can generically distinct types of information be combined to obtain a consensus of opinions  from disparate sources  about the appropriate action to take  
　　a second problem is that the information that is required to choose between alternatives may contain minor errors. no system can always measure accurately the costs of taking an action or determine precisely the goals/subgoals that should be satisfied. yet we require that expert systems be robust enough to make effective decisions despite such errors what mechanisms can be employed to correct for minor errors  
     it is import ant that expert systems be able to explain their actions. sometimes decisions are based on information that tends to support those propositions in favor of choosing a particular action  tends to refute those propositions in competition with the action taken  or both  i e   conflicting information . at other times an action is taken because the system is partially ignorant about some aspect of the information required to reach any decision. in short  to explain its decisions  a system must be able to distinguish among evidence that tends to support  tends to refute  and neither supports nor refutes the propositions of interest what is an adequate representation of the total evidential information  as it bears on the propositions of interest  that will allow systems to provide more meaningful and accurate explanations of their actions  
actions  control-feature spaces  and 

*this research was supported  in part  by the defense advanced 
research projects agency  dahpa  under contract number n1-c-1. the views and conclusions contained in this document are those of the author and should not be interpreted as representing the official policies  either expressed or implied  of sri international  darpa  or the u.s. government. 
**the author is currently enrolled in the department of computer and information science  coins   university of massachusetts  amherst  ma 1. 
a control environment 
　　we consider an action to be the invocation of a parameterized process  such as a knowledge source  ks   where a ks is a procedure or sensor that makes observations about the environment or the invocation of processes for obtaining additional information that is required to choose an action. 
　　selecting the appropriate action depends on the observation of features in an environment. just as spectral attributes can be considered features of objects  so can goals/subgoals be features of actions. if ob-
jects can be partially discerned from information about what spectral features are observed  then the appropriate actions can be partially 

1 l. wesley 

	l wesley 	1 


1 l. wesley 
the evidential interval that is associated with every dependent proposition. 
     after the extrapolation process terminates a partial ordering over the set of alternative actions is reflected in the evidential intervals as-
sociated with each a e 1a. selecting the appropriate action involves evaluating these evidential intervals. although a complete decision theory for performing such an evaluation is not yet available  it is possible to choose actions on the basis of several simple criterion. for example  determining the best action is obvious for those propositions that correspond to alternatives that have evidential intervals that do not overlap for those propositions with overlapping evidential intervals  further evaluation is called for there are many utility- vs. costbased theories that can be used to select an action on the basis of beliefs that are constrained by an evidential interval. however  a simple scheme might be to use the median of the evidential interval. 
summary 
     this paper has described some important problems confronting expert systems that operate in complex domains pooling generically distinct evidential information  correcting for minor errors in evidential information  and realizing an adequate representation of the total evidence that tends to support  tends to refute  and neither supports nor refutes the propositions of interest. we have also described how an evidential approach to reasoning about control can address some of these problems. r  dempsters rule is a mechanism for obtaining a consensus about the appropriate actions to take and correcting minor errors: a system can better explain its actions because a confidence interval allows it to distinguish between supporting  refuting  and neutral evidential information. 
a c k n o w l e d g m e n t s 
1 would like to thank drs. john d. lowrance and thomas d. 
garvey for their untiring guidance and extremely helpful suggestions 
