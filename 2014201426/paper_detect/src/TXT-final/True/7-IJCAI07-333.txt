
this paper describes aspogamo  a visual tracking system that determines the coordinates and trajectories of football players in camera view based on tv broadcasts. to do so  aspogamo solves a complex probabilistic estimation problem that consists of three subproblems that interact in subtle ways: the estimation of the camera direction and zoom factor  the tracking and smoothing of player routes  and the disambiguation of tracked players after occlusions. the paper concentrates on system aspects that make it suitable for operating under unconstrained conditions and in  almost  realtime. we report on results obtained in a public demonstration at robocup 1 where we conducted extensive experiments with real data from live coverage of world cup 1 games in germany.
1 introduction
as more and more computer systems are equipped with sensing devices and are installed in environments where people act  there is a steadily increasing interest in application systems that can automatically interpret and analyze intentional activities. examples of such application domains are human living environments where computer systems are supposed to support the people's everyday life  or factories where machines and human workers are supposed to perform the production processes in joint action. another class of example domains that starts to receive increasing attention is the automated analysis of sport games.
　in all these cases the perception of intentional activity has to be solved reliably  accurately  and under unmodified conditions. indeed scaling reliability and accuracy of such perception towards real life situations still poses challenging problems for most perception and ai systems.
　in this paper we consider a particular subclass of these problems  namely the accurate and reliable tracking of players based on broadcasts of football games. to address the problem  we have realized aspogamo  automated sport game analysis model   a computer system estimating motion trajectories in world coordinates for the players in the camera view.
　aspogamo can track the players based on views provided by the overview cameras used in game broadcasts. it has a high player detection rate of more than 1%  an average inaccuracy of less than 1 cm  handles many cases of occlusions  and works in almost realtime.1 aspogamo deals with substantial variations in lighting conditions and complicated team dresses. the system has been demonstrated at the robocup 1 in bremen  tracking players based on live broadcasts of fifa world cup 1.
　the purpose of this paper is to briefly describe the basic system and algorithms and then to discuss in detail the extensions that are made to scale towards a real-world application. the main contributions are threefold:
1. an accurate and reliable model-based estimation systemfor the camera parameters based on the video sequence 
1. a color-based segmentation system for robust and precise detection of players in camera view even underchallenging conditions  difficult lighting and colors  partial occlusions  camera motion blur   and
1. a probabilistic  multi-camera enabled  player trackingsystem that handles a wide range of game typical occlusion scenarios.
　the remainder of this paper is organized as follows. the next section introduces the software architecture and the basic solution idea to solve the tracking problem. then the underlying components provided for obtaining the necessary reliability and accuracy are detailed in the sections 1  estimating camera parameters   1  detecting players   and 1  tracking players . we will then describe experimental results  discuss related work and finish with our conclusions.
1 system overview
before we discuss the technical details of our approach we will first explain the computational problem that we are solving  the structuring of the problem into subproblems  and the basic mechanisms for solving the subproblems.
1	input and output
the broadcasted video stream mainly consists of stretches recorded by the main camera  which is placed 1m high in the stands near the center line of the field. the main camera records the game activities and provides a good overview of the game action. the stream  however  is interrupted through displays of close-ups and replays from other cameras  usually when the game is paused or the activity is not interesting.

figure 1: player detection  left  and created tracks  right 
　aspogamo is given image sequences of the game taken by the main camera. the camera's position in the stadium is fixed  but it is constantly pointing towards the main area of activity and changing its zoom factor. therefore  the pan and tilt angles as well as the focus of the camera are continually changing. aspogamo computes trajectories on the field plane  representing the positions over time of individual players captured on camera  see figure 1 .
1	software architecture
aspogamo consists of four components: vision  state estimation  track editor and motion model generator  figure 1 .
　the two main components that will be described in this paper are the vision  responsible for image processing tasks  and the state estimation  used to estimate camera parameters and player positions as well as forming player tracks . they interact strongly to simplify each subtask.

figure 1: software architecture of the aspogamo system.
　aspogamo processes a video-stream by performing the following steps for each image. first  the camera parameter estimation predicts camera parameters for the current frame using optical flow from the correspondence finder. based on these predictions  the system uses context information and model assumption in order to simplify the player detection and the search for line correspondences. the player detection determines player blobs taking into account the hypotheses generated by the tracker. then  the correspondence finder uses predicted parameters and the player blobs to find line correspondences considering occlusions. these are used in conjunction with the given prediction based on optical flow to determine the a posteriori camera parameters and their uncertainties in terms of covariances in the camera parameter estimation. knowingthe cameraparameters  playerpositions and their uncertainties are calculated in the player position estimation from the observations made by the player detection. they are forwarded to the tracker  where individual positions are combined and associated over time  and hypotheses for the next time step are generated. once the tracker completes the tracks  they are send to the track editor  where they are associated with other tracks and receive player ids in a semi-automatic process. afterwards  completed tracks are smoothed and stored as a compacted representation in the motion model generator.
1 camera parameter estimation
in order to transform image coordinates into real-world coordinates  we need the position and direction of the camera as well as its intrinsic parameters including zoom factor  pixel sizes  principal point and radial distortion coefficient. because the position of the main camera is fixed during the game  only the direction  pan and tilt  and the zoom factor have to be estimated continuously  as they constantly change while the camera tracks the game activity. all other parameters are determined beforehand in a semi-automatic process.
1	basic algorithm
aspogamo uses modelbased localization for estimating camera parameters: an image of the game  figure 1 upper left  and a model of the football field  upper right  are matched together  lower left   and the camera parameters are estimated from this match  lower right .

figure 1: modelbased localization
　the estimation is formulated as an iterative optimization problem. first  the model is projected onto the image using predicted parameter values. the optimizer then searches for image points that correspond to given model points  figure 1   e.g. on field lines. finally  the best match between model and image is found by minimizing the distance errors obtained from the correspondences. this is done using the iterative extended kalman filter  iekf . iekf also gives the uncertainty of the estimation as a covariance matrix  which is used amongst others to determine the search window for correspondences in the next iteration.

figure 1: projected fieldmodel using predicted parameters  left   finding correspondences along the searchlines  right .
1	improvements
figure 1 shows why the basic algorithmfor matching the field model to the image lines is unreliable. non homogeneous lighting conditions  cast shadows and high color variations cause the color classes to be diffuse and to overlap. segmentation becomes inaccurate or ambiguous  and eventually fails. low resolution and the inclined camera position causes distant lines to almost disappear in the images. field lines do not appear as white  but as a slightly lighter green  making them hard to be found by uninformed line detectors. furthermore  zoomed in camera views often lack visible lines that allow for unambiguous parameter estimation. motion blur caused by fast camera movements is another problem. also  the varying focal length of a camera when zooming changes the radial distortion coefficient. finally  tv broadcasting and video compression produces noisy images with pallid colors.

figure 1: some hard scenes: different colors in background  upper left   cast shadow  upper right   motion blur  lower left   not enough field features  lower right 
these difficult context conditions require that
  lines contained in the image must be found reliably  which implies that outliers and false correspondences must be suppressed 
  camera motion must be tracked without the help of model information if not enough field lines are visible 
  the system should be able to recover from failure. let us consider some extensions that address these requirements in more detail and result in reliable longterm tracking of the camera.
　reliable line detection: to deal with blurry lines and edges we apply probabilistic methods for line detection. rather than making a hard color classification we assess the probability that pixels contain field lines. as stated above  distant white lines often appear as lighter green. we model color classes as a mixture of gaussians in rgb colorspace  see 1 . aspogamo detects lines by searching points where color distributions on both sides apply to the color green with a higher intensity in between. matches are thresholded depending on the expected linewidth in pixels. the quality of a correspondence and its variance is estimated depending on the match and its uniqueness. a similar method is used for edge detection.
　to reduce the influence of outliers  from a quadratic to a linear one   we're using weights for each correspondence according to the weight function from huber  huber  1  from the m-estimators  zhang  1 . assuming distances  errors/costs  of outliers are large  the m-estimators suppress such correspondences.
　tracking without field lines: for prediction we use the optical flow fromtwo subsequentimages. only1 randomly spread pixels from around the image border are used. during fast camera movement the rate of outliers increases  and without the outlier suppression the camera would be lost in a few steps. as the outlier suppression proposed in the upper section has no context information and considers only the distance for each correspondence  it might suppress correct correspondences having large distances while keeping erroneous correspondences having small distances. to address this problem we estimate the most likely homography to transform points between the two image planes  which is used for estimating correspondence variances and filtering outliers. this homography can be calculated using only 1 point-correspondences in the image plane. the ransac algorithm  fischler und bolles  1  is a robust method to find out the most likely homography.
　failure recovery: when the inaccuracies in the parameter estimation increase  the quality of the correspondencesdecreases as the projected field model starts drifting away from its real position. we detect these cases where we lose the tracking of the camera. a semi-automatic process is used to reinitialize the camera parameters. we currently integrate a fully automated field matching process into aspogamo.
1 player detection
aspogamo detects players by segmenting blobs on the field that are not field green. candidate blobs are analyzed using size constraints and color models. players are localized using their estimated center of gravity.
1	used color model
since football is a spectator sport  the playing field  the lines and the dresses of the players are designed to be visually distinctive. the most informative visual feature herein is color: the field is green  the lines are white  and the teams should dress so that they can be distinguished easily. we exploit the situation by designing algorithms that use color as their primary visual feature.
　we model color classes as mixture of gaussians in rgb space. this gives us the option to use statistics and probabilities in both learning and using color models. having multimodal distributions is important e.g. when trying to segment a field with cast shadows from a stadium roof  figure 1 . it also helps coping with lighting changes and keeping resembling color classes disjunct. for efficiency reasons we scale the rgb space down to the 1bit r1b1 space and use precomputed lookup tables for distances and densities. color models are learned semi-automatically using k-means clustering on manually marked regions. the ability to refine the learned colors as time progresses is inherent. fully automated color learning will be available in the near future.

figure 1: color segmentation on field with cast shadow
1	recognizing and localizing players
as illustrated in figure 1  simple color-based segmentation of players is doomed to fail. depending on the camera's position and focus  typical player sizes in the image are around 1 pixels  but can easily be as small as 1 pixels. input images tend to be very noisy as they are taken directly from tv broadcast. player's are often occluded by other ones  especially in situations like corners or free kicks. furthermore  fast camera movement causes additional motion blur. as a result  shapes and colors mix with their neighborhood.
　to solve the player recognition task despite these complications  we combine simple but powerful perceptual cues in a probabilistic manner  in order to achieve robustness  speed

figure 1: enlarged players. pixels are washed-out due to the small resolution and motion blur. players in front of advertising-banners are even harder to detect  right image .

figure 1: player recognition.
as well as the required precision. in a first step  all potential player regions unlikely to belong to either the field or the surroundings are segmented  figure 1b . we then estimate the mass centers of the players  more precisely the center between shirt and shorts  as this point prove to be the most robust to detect. this is done by calculating a likelihood map for the player whereabouts using multiple evidences based on color template matching  size constraints and predictions  figure 1c . player positions are extracted from the map by finding strong modes  figure 1d  and projecting their coordinates to a point half a player's height over the field plane.
　let us now consider the computation of the likelihood map in more detail  see figure 1 . potential player regions are found by segmenting the field and intersecting the inverted field region with the field's convex hull. the field region itself is segmented using a hysteresis threshold based on the mahalanobis distances to the learned field and line colors. sparse morphology is used to remove noise and to combine field regions still separated by e.g. field lines. the resulting player blobs  figure 1a  may contain more than one person  none  or only part of a person  when e.g. a leg got cut off because of bad color contrast.
　to localize the exact number and positions of players inside the blobs  we use color template matching  figure 1b   where a template  figure 1a  for every player type is moved across every pixel in a blob to calculate a similarity measure. the template is scaled to the expected size of a player at the respective image position  which can be calculated from the estimated camera parameters  see section 1 . the player's appearance is approximated by subdividing the template into a shirt  a shorts and a socks region  and associating each of them with the respective color classes learned in chapter 1. we use only distinctive color classes  as hair or skin colors do not qualify for separating different player types. the template is centered between shirt and shorts  which coincides well with a human's mass center. to account for inclined players  the shirt region of the template is shifted to five different configurations  and the best one is selected. the similarity measure is calculated from all pixels inside the template mask taking into account their probabilities regarding the affiliation to the template's associated color classes.

figure 1: calculating the likelihood map from figure 1c. first  player blobs are segmented  a . then  three likelihood maps based on color template matching  b   compactness  c  and height constraints  d  are calculated. in the last fusion step these are multiplied  and likelihoods at predicted player positions  e  are increased to form the final map  f .
　additional constraints are applied to increase accuracy in situations where players are completely dressed in one color  or players from different teams share similar colors on different parts of their dresses. in such cases  high likelihoods can be observed at positions that do not match the player's locations well. the compactness constraint  figure 1c  produces low likelihoods wherever the overlap between the player blobs and the template mask is small  reducing high probabilities near the blob contours. the size constraint  figure 1d  produces high likelihoods at locations where either the distance to the upper blob contour or to the lower blob contour is near the optimum for the expected player size. this is justified by the fact that the heads of the players should be located below the upper contour  and the feet above the lower contour. in case of bad segmentation  e.g. with feet cut off  there is still a good chance that at least the opposing contour has been segmented properly.
　finally  the three likelihood maps are fused by multiplication  and probabilities near the regionswhere a hypothesishas been returned from our tracker  figure1e  are increased. this way  bad observations due to partial occlusion or fast motion can be enhanced. the resulting likelihood map  figure 1f  is then searched for modes  and if they exceed a predefined threshold  a player observation is forwarded to the tracker. if the regional overlap between two observations is too high  only the stronger observation is selected. the location of the player on the field plane is then calculated using the estimated camera parameters.
　there are several issues that deserve discussion: by using color template matching with the additional constraints  players are recognized quite reliably even in the case of slight occlusions. probabilities and covariances for the observations can be easily extracted from the likelihood map and forwarded to the tracker. false positives and missed detections are rare  and can be dealt with by the tracker. due to the simplicity of the detection without extensive exception handling  the system generalizes well to different situations  e.g. wide angle or zoomed in camera views. even cast shadows on the field  motion blur or noisy input data can be dealt with  provided that the colors have been learned accurately.
　although we use template matching on full resolution pal images  due to the small player sizes   the player detection runs at realtime. the template matching is speed up using integral images thanks to the square template masks. another contributing performance factor is the use of runlength encoded region masks.
1 player tracking
as seen in the previous section  player positions can have big measurement errors  player types can be interchanged  false positive measurements or undetected players can disturb the tracking as well as player clusters. so the tracking of the players is not a straightforward task.
　in our system we use a multiple hypothesis tracker  mht   reid  1  to account for missing measurements and improve the robustness of the tracking. the input for the mht are the positions and covariance matrices of the measurements. the output are tags that define the track affiliation for the individual measurements. the smoothing capability of the internal kalman/particle filter is not propagated because we always generate a motion model afterwards which can produce better approximations to the real path.
　the implementation we use is the one described in  cox und hingorani  1  with some improvements to account for the non-gaussian distribution in blobs and the ability to assign more than one track to a blob measurement.
1 empirical results
we have presented aspogamo at robocup 1  where we gatheredlarge amounts of input data from live coverageof world cup 1 games in germany and conducted extensive experiments under public display.
　camera parameter estimation: the system has been able to track the camera without getting lost in almost all tested scenes from world cup 1  about 1 scenes  each 1 to 1 sec long . using original tv broadcast camera streams without scene disruptions  the system is able to track the camera parameters up to 1 minutes without getting lost. the accuracy of back-projections on the model-field is about 1 cm to 1 m  depending on the camera movement  the visibility of field features and the distance to the camera.
　playerdetection: table 1 shows the playerdetection rates for some games from the world cup  that have been determined manually by examining 1 randomly selected frames. both the openinggame germany vs. costa rica and the game argentina vs. serbia montenegro had detection rates over 1%  despite very noisy input data. the game portugal vs. iran was challenging because of a strong cast shadow on the field  making white dressed players in the sunlight hard to detect even for the human observer. finally we examined a corner situation from the opening game. the missed detections are almost entirely associated to occlusions and clustering of players. our experiments with other games confirm that detection rates of over 1% are generally achievable.
gameplayermissedmis-falsecountplayersclassifiedpositivesger - crc1.1%1%1%arg - scg1.1%1%1%por - irn1.1%1%1%corner1.1%1%1%table 1: detection rates for players
　the presented detection rates are based on observations that do not exploit the temporal information given in our tracker. when incorporating the tracker  most of the errors resulting from temporarily missed detections  false positives or misclassifications are resolved. figure 1 shows both the detected players and the created tracks for a short scene. in our experiments most of the tracks are complete for as long as a player is in camera view  usually until the scene gets interrupted. exceptions are players in front of advertising banners or extremely clustered scenes like corners.
　the inaccuracy of the player detection is typically lower than 1 m. the precision has been estimated by projecting detected image positions and manually determined image positions on the virtual field plane. another conclusionobtained from the experiments is that if both shirt and short colors are similar  pose estimation in vertical image direction is harder  and the detected positions tend to oscillate more. but the effect is reduced by smoothing and averaging the final tracks in the motion model generator.
　aspogamo is capable of fusing observations from multiple cameras viewing the same scene from different positions. experimentshave shown that the accuracyof the player detection is further improved  as the uncertainties of the measurements become smaller. aspogamo has also been used to gather all player trajectories overa full game of 1 minutes.
1 related work
several approaches in tracking soccer players exist that are constrained to static cameras  figueroa et al.  1; xu  orwell  und jones  1; kang  cohen  und medioni  1 . unfortunately  such systems are complex and expensive in their hardware setup. farin et al.  farin  han  und with  1  propose a method for camera calibration in realtime  but without player detection. bebie and bieri  bebie und bieri  1  and yamada et al.  yamada  shirai  und miura  1  describe similar systems also tracking players from tv broadcast  but both lack experimental results. no other systems comparable to aspogamo in terms of reliability  robustness and performance are known to us as yet.
1 conclusions
in this paper we have described aspogamo  a probabilistic vision-based tracking system for estimating the positions of players based on broadcasted football games. the main contributions are a set of techniques that make the system so robust that it reliably functions for broadcasts. the empirical studies show that the system can cope with difficult and changing lighting conditions  fast camera motions  and distant players. aspogamo enables computer systems to semi-automatically infer abstract activity models of football games. these models can be used for supporting coaches  football reporters  and interactive television.
