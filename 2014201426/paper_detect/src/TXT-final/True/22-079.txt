 interpretations of student models. 
	rick 	evertsz* 
scientia ltd  
1 brompton road  london  sw1hx  united kingdom. 

abstract 
as the range of models which a tutoring system can capture is extended  efficient diagnosis becomes more difficult. we have implemented a partial solution to this problem  in the form of a 'critical problem' generator. we argue that great diagnostic power can be obtained by generating discriminating problem examples. in general  efficient diagnosis is just not possible without such a hypothesis-testing capability. we describe a program  pg  which given a pair of production rule models and a description of the class of problems which the student must solve  generates an abstract specification of the problems which discriminate between those two hypotheses. the key to this problem lies in the realisation that we are only interested in the abstract mapping between a models inputs and outputs; from the point of view of generating a critical problem  the intermediate processing of the model is irrelevant. 
1. introduction 
in the realm of 1cai  the 'student model' is generally recognised as an essential prerequisite for adaptive tutoring. it embodies the machines view of what the student 'knows' without it  the tutoring system cannot make pertinent tutorial decisions. the space of models which a tutoring system must consider is non-trivial. current student modelling research is concerned with extending this space through the use of machine learning techniques  cf. acm  ilanglcy and ohlsson  1  . whilst the machine learning approach does extend the potential coverage of the modelling system  the larger search space leads to poor runtime performance - as it stands this method could not form part of a tutoring system which runs in real-time. interestingly  research on electronic fault diagnosis has run into similar problems. extending the range of models to the multiplefault case  leads to a mushrooming of an already large search space |dc kleer  1 . thus for diagnostic domains  a 
* 
       this work was funded by serc  through the uk alvey programme. major research goal is to provide the machine with efficient methods of searching ever larger spaces. 
through the medium of a computer program called pg 
 problem generator   we have developed an approach to controlling the diagnostic search space  whose roots lie in the methodology of science - where the experimental method is employed to distinguish between competing hypotheses. the central tenet is that great diagnostic power can be obtained by generating discriminating problem examples. armed with the ability to test hypotheses about what the student is doing  the modeller acquires the same powerful leverage available to the scientist who can generate experiments to test his/her theories. 
　imagine a situation in which a tutoring system is trying to ascertain how a student deals with fraction subtraction problems of the form: w - xy/z. the student has just solved the problem 1 - 1  and come up with an answer of 1. the tutor searches for an account of the student's error  and produces two possibilities: 
model-1: if the first whole number has no associated fraction  then subtract the second whole number from the first  and write down the fractional part of the second term. 
model-1: if the first whole number has no associated fraction  then the answer is the whole of the second term  i.e. discard the first term . 
　the tutoring system tries to obtain more information by setting the student a problem of a similar type  i.e. of the form w - xy/z . instantiating this problem template with a random set of numbers  subject to the constraint that it form a legal fraction subtraction problem   the tutor sets the following problem next: 1 - 1. unfortunately  in the current situation this problem provides no diagnostic power whatsoever. in order to discriminate between the above two models  the machine must generate a problem which will produce a different answer for each. 
　we call a problem which discriminates between two hypotheses a 'critical problem'. idebuggy  burton  1  adopts an essentially heuristic method of generating 
critical problems. each primitive bug has an associated set 
	evertsz 	1 

of problem templates which  when instantiated  are likely to produce problems which reveal the presence of that bug. not all of the problems will have this feature  therefore the system needs to run the model on the problem to make sure that it does the required job. though quite effective  idebuggy's approach has one major drawback. the system implementor must specify the problem templates for each of the bugs in the database of models. this means that any changes to the models must be echoed in their associated problem templates. this reliance on an outside party to maintain the problem templates  means that the technique is only useful where there is a fixed  unchanging library of bugs. 
　slecman  1  describes a system which attempts to generate such problem templates automatically  by running the rules backwards. his work is the only previous attempt to generate problems on the basis of the form of the rules in the models  rather than on the basis of 'canned' procedures attached to each rule. however  it can only be applied to a very limited range of production rule models  and even then it only works when in partnership with the user  who must supply the all-important termination condition . it can only be applied to models where working memory only ever contains one element  and all of the rules have one condition element only. there is no provision for multiple lhs conditions  or negated condition elements. the algorithm also ignores the relationships between variables in the lhs. in the simple algebra examples  tackled by the program  inter-variable constraints can be ignored. under such conditions  the program can generate a discriminatory template  where the two models contain the same rules  but ordered differently. in the more general case  where the two models contain different rules  limited to one pair only   the algorithm is incapable of generating a discriminating template. evertsz  presents a critique of the algorithm  and shows why any algorithm  which analyses the rules in the reverse direction  is doomed to failure because it cannot capture crucial aspects of the model's computational behaviour  in particular  conflict resolution . 
　our approach to the problem is to have pg reason about the abstract input/output behaviour of the candidate models. 
this approach borrows from the methodology of experimental science. scientists formulate experimental hypotheses in terms of variables which are either manipulate or measurable. these variables summarise the internal  unobservable workings of the system being tested. it is the descriptive economy of a theory  expressed solely in terms of observables  which simplifies the problem of proposing an informative experiment  for example  compare the simplicity of the general gas law with the more complicated kinetic theory of gases . from the hypothesis-testing perspective  the intermediate processing performed by a model is only relevant in so far as it defines the mapping between inputs and outputs. the hypothesistester can only manipulate inputs and observe the students outputs. 
　pg takes a pair of student models  expressed in an opslike production system  and through a process termed 'abstract interpretation' derives an abstract specification of the problems which discriminate between the two models. 
1 	intelligent tutoring systems 
this abstract specification can be instantiated  by a process of constraint satisfaction  to yield a critical problem. 
1. abstract interpretation 
student models arc designed to take concrete values as inputs  and produce other concrete values as outputs. for example  a model which computes the factorial of a number  would be given a concrete number  n  as input  and would output another number  n!. now  imagine that our goal is to characterise the general behaviour of that model. we do not want to know what its output would be for some specific  concrete input; rather  we want some general description of the model's output for some abstract  nonspecific n. this abstract description can then be compared with that for the competing model to see whether they are non-equivalent  if the two models are equivalent  in terms of their input/output behaviour  then no critical problem exists . 
　abstract interpretation is a commonly employed solution to the problems of automatic program analysis. the general idea is to glean information about a program by running it on abstract specifications of data objects  rather than the data objects themselves. cousot and cousot  first introduced the notion of the abstract interpretation of imperative languages. we have developed an algorithm for the abstract interpretation of production systems  which lakes as input a pair of production rule models and an abstract description of the class of legal inputs to those models  and produces a description of the set of critical problems. the key difference between an abstract 
interpreter and a normal production rule interpreter  is the former's ability to run in an abstract rather than a concrete domain. 
　note that it is not necessary that pg find all i/o mappings for the two models. it is sufficient to find just one from which a critical problem can be generated. although we do not require that pg find all i/o mappings  we do desire that its search strategy be 'complete'. that is  in the limit  it should be able to find all i/o mappings  stopping when either a discriminating output description is found  or there are no more i/o mappings for the two rulesets. furthermore  we require that the i/o mappings be sound'. in other words  pg should never derive abstract i/o mappings encompassing concrete i/o mappings which the models would never actually compute. for example  if a model only computes the i/o mapping:  x + y  for the two input variables x  and y  then we would not expect pg to derive the i/o mapping:  x - y . the mapping   x - y   is unsound because it embraces concrete i/o mappings which are never computed by the rulesel  e.g if x is 1 and y is 1  then the abstract mapping would erroneously predict an output of 1 . in other words  for any ruleset  if a is the set of possible i/o mappings in the concrete domain  and b is the set of possible instantiations  in the same concrete domain  of pg's derived abstract i/o mappings  then it should never be the case that: 1 xe b xg a. 

1. production system execution in the abstract domain 
each operation of a production system has its abstract equivalent in pg. for example  pattern matching is replaced by unification so that rules can match abstract working memory elements  i.e. ones containing uninstantiatcd variables . in general  a model  running in the concrete domain  can follow a number of different paths to a halt state  depending on what the initial input looks like. the input  together with the rules in the model  define the particular path taken through the space of possible routes from start state to halt state. pg characterises this set of potential paths by running on abstract data. for example  consider a model which takes a number  n  and outputs whether it is even or odd. the set of all possible paths through the production system is indexed by the members of the union of the set of all even numbers and the set of all odd numbers  i.e. the infinite set of integers . however  when run in the abstract  this infinite set is summarised by the two abstract paths: 

　during a run  pg collects the outputs along each of these paths  and terminates with a description of the abstract mapping between inputs and outputs. in principle  pg can search all paths  however in practice it searches the paths one at a time until a critical problem is found. 
1 	input specifications 
pg is provided with a description of the class of inputs which the model can consider  termed a set of 'input specifications . it is possible to abstractly interpret a ruleset without an input specification  however  the search space becomes unmanageable. in principle  any ordered subset of the lhs patterns could form a 'meaningful' abstract input to a model  by meaningful input' we mean one which is capable of matching a non-empty subset of the lhs patterns . for example  according to this criterion  a rulcset with five distinct lhs patterns is capable of spawning 1! input specifications  i.e. 1. in fact  there is nothing to stop us including duplicate abstract input elements  in which case the space of input specifications is infinite. 
　in the context of a tutoring system  the set of input specifications is precisely the collection of problem templates from which the tutoring system generates problems to pose to the student. these problem templates describe the set of legal problems for the domain being tutored. for example  a problem template in the subtraction domain might be: 'one number minus another  where the first number is greater than or equal to the second'. however  we should not expect our tutoring system to have the following template: 'one number  m  minus another  s  where the units digit of m is less than that of s  and m s'. this is because the reference to the relationship 
between the units digits of m and s has nothing to do with the legality of the problem; it is there to test for a particular subskill  i.e. borrowing. the units test is an implicit embodiment of the expectation that the borrowing subskill can be faulty  and implies that it is worth setting problems which require a borrow  as these will reveal any flaws in the student's algorithm. pg is only given input specifications which encode information about problem legality. to do 
otherwise  would be to bias its search for critical problems. 
1 	abstract rule instantiation 
pg keeps a record of the current state of working memory down each path being explored  and a record of the instantiations fired. it also maintains a note of the current tree-depth of the problem-solving process. every time a rule fires  it moves one level deeper into the tree. the level marker is used to rename variables in a production rule  so that they do not clash with variables of the same name  in other parts of the tree. pg also maintains a record of the variable bindings  from cycle to cycle  termed an 'environment' . working memory will contain terms with uninstantiatcd variables  however  pg can partially instantiate them by retrieving their values from the environment. in addition to an environment of variable bindings  pg maintains the set of 'constraints' on the variables in the environment. for example  if a firing rule requires that  x be less than  y  then this constraint must be carried forward to subsequent cycles. pg also records any outputs  as these will be used to build the i/o mappings of the ruleset. the role played by these various data structures will become clearer as the algorithm is developed in subsequent sections. 
　when pg is run on an input specification  the level marker is initialised to zero  and the patterns in the input specification arc added to working memory  after renaming the variables therein. any constraints in the input specification are also renamed  and are then added to pc's constraint set. for example  if the input specification were:   x -  y       x  y   then working memory would contain the single element:   x.o -  y.1   and the constraint set would consist of:     x.o  y.1 . pg is now ready to commence the first recognise-act cycle. the recognise-act cycle begins with the incrementing of the level marker to i. 
　the leflhand sides of the rules are unified with the contents of working memory. our unification algorithm is augmented to allow function expressions to be unified with constants or other function expressions. for example  when asked to unify the function expression:  *times  x.l 1  with: 1  it generates the equality constraint:  =  *times  x.l 1  1 . 
　the abstract rule instantiations are passed to a resolution theorem prover which assesses their consistency. for example  if the input specification defines  x to be odd  then the theorem prover will reject any instantiation of a rule whose leflhand side contains the constraint: e v e n     x     because even  x  a odd  x  is unsatisfiable for all values of  x. resolution theorem provcrs seem ideally suited to the job of spotting 
	evertsz 	1 
unsatisfiable sets of constraints  as they are geared to finding contradictions. 
　our production rule language includes 'negated patterns'; these are pauerns which require that no matching element be present in working memory. if a negated pattern unifies with some working memory element  then pg tries to build the minimal set of constraints  termed a 'negation nullifier'  which would prevent the negated pattern from matching that item. the instantiation is said to be valid if the negation nullifier is consistent with the constraints collected so far. this is illustrated in the following scenario. 
1. a simple scenario 
the following tiny ruleset has been created to illustrate how a negation nullifier is built  and to show the unification of a function expression with a constant. in the concrete domain  it starts with an input of the form:  add  x  y   where the variables are both natural numbers  and deposits the sum of  x and  y in working memory. the rule finish fires if that sum is zero  not equal to  x  and the original  x and  y are equal; it outputs  x and halts. clearly  there is no way that this rulcset can ever output anything  because the formula:  x+ y=1 a  x= y a 
 x*1 a n a t n u m     x   a n a t n u m     y   is unsatisfiable. in the following scenario  we shall see how the attempt to create a negation nullifier leads to the predicted contradiction. constraints and function expressions begin with an asterisk  and negated patterns are prefixed with a tilde. 

　at the start of the run  working memory is initialised with the single element:  add  x.o  y.o   and the constraint set is initialised to:  *natnum  x.o  a  *natnum  y.o . the recognise-act cycle begins  and the instantiation of start is added to the conflict set. the instantiation of start contains the following environment:   y.l/ y.o  x.l/ x.o   where  zi y denotes the binding of  z to  y. the instantiation fires and deposits  sum-x-y  *plus  x.l  y.l   in working memory. 
1 	intelligent tutoring systems 
	working 	memory: 
　  sum-x-y  *plus  x.l  y.l    add  x.o  y.o   constraint set:   *natnum  x.o  a  *natnum  y.o   environment: 
  y.l/ y.o x.l/ x.o  
　on the next cycle  start is instantiated  but is rejected because it has already fired. the two positive patterns in finish are satisfied by the contents of working memory as follows: the first pattern   add  x.1  x.1   unifies with  add  x.o  y.o  and adds the bindings    x.o/ y.o  x.1/ x.o   to the current environment. the second pattern   sum-x-y 1   unifies with  sum-x-y  *plus  x.l  y.l   generating the equality constraint:  =  *plus  y.o  y.1  1 . the two abstract pattern instantiations arc now paired by merging their environments and constraints. 

the negated pattern    sum-x-y  x.1   unifies with the 
working 	memory 	element  	 sum-x-y 	 *plus 	 x.l 
 y.l    and produces the abstract negated pattern instantiation shown below. 

the single binding is turned into an equality constraint  
 =  x.1  *plus  x.o  y.o    and then negated  -.  =  x.1  *plus  x.o  y.1  ; this is the negation nullifier. the negation nullifier is then instantiated in terms of the current environment  and passed to the theorem prover  along with the current set of constraints  instantiated . note that the combined set of constraints is instantiated in terms of the current environment  before passing it to the theorem prover. this explains why the constraint   *natnum  x.1   disappears when the current constraint set is conjoined with the negation nullifier. when it is instantiated it becomes:  *natnum  y.1   which then gets deleted because it is a duplicate constraint. 

　the theorem provcr rejects the combined constraint set  because it is unsatisfiable. informally  if  y.o is a natural number  which results in zero when added to itself  then  y.o can only be zero; however  this contradicts the first constraint  which states that  y.o is not equal to  y.o +  y.o. so  the interpreter halts because there are no other rules to fire. 
1. abstract conflict resolution and rule firing 
once the conflict set is computed  pg applies abstract versions of the conflict resolution principles recency and specificity. applying recency to abstract instantiations is not problematic  because pg maintains an abstract version of working memory for each path. specificity pertains to the lefthand sides of rules  thus its definition is the same as that for an interpreter operating in the concrete domain. 
　in the concrete domain  conflict resolution chooses a unique instantiation to fire  and only that path is followed subsequently. however  in the abstract domain the conflict resolution principles can only be used to order the instantiations in the conflict set. this is a subtle  but crucial point. imagine a situation in which the conflict set contains two instantiations  i1 and i1. after applying conflict resolution  i1 is found to be the winner. however  in the concrete domain  there may be cases where  because of the particular values in working memory     cannot be instantiated. in such instances  i1 will win  because it is the only member of the conflict set. the abstract interpreter must take this into account  otherwise it will unintentionally exclude valid paths. the instantiation  i1  wins precisely when its constraints arc satisfied and those of i  are not. for example  if    includes the constraint  
 *even  x   but i1 does not  then i1 will be chosen whenever  x is not even. if the input specification does not specify whether  x is even or odd  then both instantiations are valid  because pg has no evidence to the contrary. were it to simply choose i  on the basis of specificity  then it would loose the information pertaining to the path followed when  x is odd. 
pg solves this dilemma by explicitly attaching an 
'exclusion clause' to i 1 . the exclusion clause consists of the negation of the set of constraints in   . thus  i1 inherits the constraint  -   even  x   which in effect says that i1 can only fire if  x is not even. note that pg passes the constraints of i 1   together with the exclusion clause  to the theorem prover  which may find them to be unsatisfiable. in this case  pg rejects the instantiation altogether. 
　abstract rule firing is quite simple  and merely involves depositing any righlhand side elements in working memory  without instantiating any of the variables therein . any output' elements in the righlhand side are recorded  so that the path always has a list of the abstract outputs produced so far. 
1. generating critical problems 
as described so far  abstract interpretation is carried out on a single model. in fact  pg interprets the pair of candidate models in tandem. recall that its overall goal is to find a 
single input for which each model produces a different output. a naive way to achieve this goal is to find all of the i/o mappings for each model  and to then sift through these until a pair of mappings  with an overlapping input but non-overlapping output  is found. however  it is more economical to only associate the paths in one model with those paths in the other which have overlapping abstract inputs. this strategy enables pg to discard unpromising paths early on. returning to our even/odd example  if some path in model-1 specifics that the input is even  whilst another path in modei-1 specifies that it is odd  then there is no point developing these paths further. they will never yield a critical problem  because there is no concrete input which is both even and odd. 
　pg employs a heuristic which guides it down the most promising paths. before running the pair of models  it performs a dependency analysis on the lefthand side and righthand side patterns of the rules in each model. this analysis produces a graph which encodes how the lefthand side patterns arc triggered by the righthand side actions. this enables it to make informed guesses about what rules lie on a path between the start state and some intermediate state. because different rules tend to produce different behaviour  it is often the case that a path in one model  which passes through a rule which is not in the other model  will yield a different output. pg uses the dependency analysis to suggest a path in one model which goes through some rule which is not in the other model. 
　once pg has found a non-equivalent pair of abstract i/o mappings  it has only to instantiate the i/o mappings. this entails finding a concrete input  which satisfies the combined constraints of both i/o mappings  but produces a different output in each case. let the set of constraints for model i be denoted by  and let of be the output for that model. for the two candidate models  i and j  pg's goal is to find some instantiation of the following expression: 
  i*oj. we have implemented a simple constraintsatisfaction procedure which finds solutions to such expressions; however  this aspect of pg has received comparatively little attention  and we would not want to make any great claims in this direction. there are a number 
	evertsz 	1 
of constraint-satisfaction procedures which could more efficiently perform the function of instantiating such expressions  cf. davis   . 
1. evaluation in the domain of fraction subtraction 
we have evaluated pg on a set of empirically-derived production rule models from the domain of fraction subtraction. these are based on data collected from 1 children  everts/  1 . in all runs so far  pg is able to find a critical problem if one exists. this success is dependent on its axiomatisation of the constraints and function expressions used in the production rule models. pc's reasoning about the abstract computational behaviour of the models is sound  provided that it is supplied with an adequate semantics for the predicates and functions in the models. 
1. discussion 
despite pg's success in the domain of fraction subtraction  the current implementation embodies a fundamental limitation. it is our feeling that this limitation is unimportant for most domains  but we highlight it here nevertheless. 
　currently  there is one aspect of the computational behaviour of production systems which pg is unable to capture: i/o mappings defined in terms of loops. for example  consider a pair of student models which both compute the function factorial'. both models loop until the original number reaches zero  and then multiply the intermediate numbers together  e.g. 1! -  1  1  1  1  1  1 -  1*1*1 -  1 . however  one model 
performs the multiplication by successive addition  whilst the other simply calls the function * m u l t . such a situation throws pg into an infinite loop. the first time round the loop  both models output 1. on subsequent cycles  the base value of 1 gets wrapped in ever deeper nestings of * m u l t in one case  and an equivalent composition of * plus's in the successive addition case. to overcome this limitation in a general way  one could make use of mathematical induction  as in the boyer/moore theorem prover  boyer and moore  1 . 
　a general-purpose abstract interpreter of production systems should be capable of handling such loops. however  many procedural skills do not incorporate such looping behaviour. therefore  there seems little point in adding this functionality until we encounter a domain which requires the extra inductive machinery. 
acknowledgements 
　many thanks to marc eisenstadt  mark elsom-cook and tim o'shea for providing great support during the development of this work. 
　i am grateful to richard joiner for commenting on earlier drafts of this paper. 
1 	intelligent tutoring systems 
