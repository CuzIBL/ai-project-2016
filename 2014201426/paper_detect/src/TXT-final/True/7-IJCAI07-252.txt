
we consider an automated agent that needs to coordinate with a human partner when communication between them is not possible or is undesirable  tactic coordination games . specifically  we examine situations where an agent and human attempt to coordinate their choices among several alternatives with equivalent utilities. we use machine learning algorithms to help the agent predict human choices in these tactic coordination domains.
learning to classify general human choices  however  is very difficult. nevertheless  humans are often able to coordinate with one another in communication-free games  by using focal points   prominent  solutions to coordination problems.
we integrate focal points into the machine learning process  by transforming raw domain data into a new hypothesis space. this results in classifiers with an improved classification rate and shorter training time. integration of focal points into learning algorithms also results in agents that are more robust to changes in the environment.
1 introduction
agents often need to coordinate their actions in a coherent manner. sometimes  achieving coherent behavior is the result of explicit communication and negotiation. however  communication is not always possible  for reasons as varied as high communication costs  the need to avoid detection  damaged communication devices  or language incompatibility.
　schelling  called coordination-without-communication scenarios tactic coordination games  and named these games'  prominent solutions  focal points. a classic example is the solution most people choose when asked to divide $1 into two piles  of any sizes; they should attempt only to match the expected choice of some other  unseen player. usually  people create two piles of $1 each  and that is what schelling dubbed a focal point.
　the use of focal points to solve coordination games has previously been studied  both theoretically and experimentally  from two different perspectives. in the first  there were assumed to be two human coordinators  and research explored a formal theoretical framework for focal points  janssen  1 . in the second approach  there were assumed to be two automated agents  and both agents ran the same focal point finder algorithm  kraus et al.  1 . however  the use of focal points when an automated agent needs to coordinate with an arbitrary human partner has yet to be explored  and it raises new challenges.
　the main motivation for such research comes from the increasing interest in task teams that contain both humans and automated agents. human-agent collaboration can take the form of robots working with human partners. another scenario is the development of user interfaces that diverge from a master-slave relationship with the user  adopting a collaborative  task-sharing approach in which the computer explicitly considers its user's plans and goals  and is thus able to coordinate various tasks  grosz  1 .
　one important type of natural human-machine interaction is the anticipation of movement  without the need for prior explicit coordination. this movement can be physical  such as the movement of a robotic arm that is assisting a human in a construction task  e.g.  a machine helping a human weld pipes . as humans naturally anticipate their partners' choices in certain situations  we would like automated agents to also act naturally in their interactions with humans. coordinated anticipation can also take place in virtual environments  including online games  where humans and automated agents can inhabit shared worlds and carry out shared activities.
　there are several constraints implicit in the above scenarios. first  the human partner with whom our automated agent is trying to coordinate may not always be known ahead of time  and we want coordination strategies suitable for novel partners. second  the environment itself is not fully specified ahead of time  and may be configured somewhat randomly  although the overall domain is known  i.e.  the domain elements are a given  but not their specific arrangement . third  there is no option to  hard-wire  arbitrary coordination rules into all participants  since we are not dealing with coordination between two centrally-designed agents.
　we specifically consider environments in which a human and automated agent aspire to communication-free coordination  and the utilities associated with coordinated choices are equal. clearly  if utilities for various choices differed  the agent and human could employ game theoretic forms of analysis  which might specify certain strategies.
our integration of machine learning algorithms and focal point techniques  which we call focal point learning  fpl   is done via a semi-automatic data preprocessing technique. this preprocessing transforms the raw domain data into a new data set that creates a new hypothesis space  consisting solely of general focal point attributes. we demonstrate that using fpl results in classifiers  a mapping from a coordination problem to the choice selected by an arbitrary human coordination partner  with a 1% to 1% higher correct classification rate  and a shorter training time  than when using regular classifiers  and a 1% higher rate than when using only classical focal point techniques without applying any learning algorithm. in another series of experiments  we show that applying these techniques can also result in agents that are more robust to changes in the environment.
　in section 1  we describe the motivation and approach of focal point learning. we then describe the experimental setting  section 1   its definitions  section 1   and the domains that were used in the experiments  section 1 . in section 1 we discuss our results. related work is considered in section 1  and we conclude in section 1.
1 focal point learning
coordination in agent-human teams can be strengthened by having agents learn how a general human partner will make choices in a given domain. learning to classify human choices in tactic coordination games  however  is difficult: 1  no specific function to generalize - there is no known mathematical function nor behavioral theory that predicts human choices in these games; 1  noisy data - data collected from humans in tactic coordination games tends to be very noisy due to various social  cultural  and psychological factors  that bias their answers; 1  domain complexity - training requires a large set of examples  which in turn increases required training time. on the other hand  human-human teams are relatively skilled at tactic coordination games. experiments that examined human tactic coordination strategies  schelling  1; mehta et al.  1  showed that people are often able to coordinatetheir choices on focal points  even when faced with a large set of options.
　several attempts have been made to formalize focal points from a game theoretic  human interaction point of view   janssen  1  provides a good overview . however  that work does not provide the practical tools necessary for use in automated agents. however  kraus et al.  identified some domain-independent rules that could be used by automated agents to identify focal points  and discussed two approaches for doing so . the following rules are derived from that work  but are adjusted in our presentation  by adding firstness  and making minor changes in others .
  centrality - give prominence to choices directly in the center of the set of choices  either in the physical environment  or in the values of the choices.
  extremeness - give prominence to choices that are extreme relative to other choices  either in the physical environment  or in the values of the choices.
  firstness - give prominence to choices that physically appear first in the set of choices. it can be either the option closest to the agent  or the first option in a list.
  singularity - give prominence to choices that are unique or distinguishable relative to other choices in the same set. this uniqueness can be  for example  with respect to some physical characteristics of the options  a special arrangement  or a cultural convention.
　we employ learning algorithms to help our agent discover coordination strategies. training samples  gathered from humans playing a tactic coordination game  are used to create an automated agent that performs well when faced with a new human partner in a newly generated environment. however  because of the aforementioned problems  applying machine learning on raw domain data results in classifiers having poor performance. instead  we use a focal point learning approach: we preprocess raw domain data  and place it into a new representation space  based on focal point properties. given our domain's raw data oi  we apply a transformation t  such that nj = t oi   where i j are the number of attributes before and after the transformation  respectively.
　the new feature space nj is created as follows: each v （ oi is a vector of size i representing a game instance in the domain  world description alongside its possible choices . the transformation t takes each vector v and creates a new vector u （ nj  such that j = 1〜 number of choices . t iterates over the possible choices encoded in v  and for each such choice computes four numerical values signifying the four focal pointpropertiespresented above. for example given a coordination game encoded as a vector v of size 1 that contains 1 choices  c1 c1 c1   the transformation t creates a new vector
 1 possible choices 〜 1 focal point rules   where cc/e/f/sl denotes the centrality/extremeness/firstness/singularity values for choice l. note that j might be smaller than  equal to  or greater than i  depending on the domain.
　the transformation from raw domain data to the new representation in focal point space is done semi-automatically. to transform raw data from some new domain  one needs to provide a domain-specific implementation of the four general focal point rules. however  due to the generic nature of the rules  this task is relatively simple  intuitive  and suggested by the domain itself  we will see such rules in section 1 . when those rules are implemented  the agent can itself easily carry out the transformation on all instances in the data set.
1 the experimental setting
we designed three domains for experiments in tactic coordination. for each domain  a large set of coordination problems was randomly generated  and the solutions to those problems were collected from human subjects.
　we used the resulting data set to train three agents: 1  an agent trained on the original domain data set  a domain data agent ; 1  an agent using focal point rules without any learning procedure  an fp agent ; and 1  an agent using focal point learning  an fpl agent . we then compared coordination performance  versus humans  of the three types of agent.
　in the second phase of our experiments  which tested robustness to environmental changes   we took the first domain described in section 1  and designed two variations of it; one variant  vsd  a very similar domain  had greater similarity to the original environment than the other variant  sd  had. data from human subjects operating in the two variant settings was collected. we then carried out an analysis of automated coordination performance in the new settings  using the agents that had been trained in the original domain.
1 definitions
definition 1  pure tactic coordination games . pure tactic coordination games  also called matching games  are games in which two non-communicating players get a positive payoff only if both choose the same option. both players have an identical set of options and the identical incentive to succeed at coordination.
our experiments involve pure tactic coordination games.
definition 1  focality value . let r be the set of selection rules used in the coordination domain  c （ c be a possible choice in the domain  r （ r be a specific selection rule  and v r c  be its value. then the focality value is defined as:
.
　a focality value is a quantity calculated for each possible choice in a given game  and signifies the level of prominence of that choice relative to the domain. the focality value takes into account all of the focal point selection rules used in the coordinationdomain; their specific implementationis domain dependent  e.g.  what constitutes centrality in a given domain . since the exact set of selection rules used by human players is unknown  this value represents an approximation based on our characterization of the focal point rule set. in the experiments  our fp agent will use this value to determine its classification answer to a given game.
definition 1  focality ratio . let c be the set of all possible choices in the coordination domain and fv  c  be the focality value of c （ c  max be the maximum function and 1nd max be the second maximum function. then the focality ratio is defined as:
f ratio c  = max fv  c     1ndmax fv  c  . c（c	c（c
　a focality ratio is a function that gets a set of possible choices and determines the difficulty level of the tactic coordination game. naturally  a game with few choices that have similar focality values is harder to solve than a game that might have more choices  but with one of the choices much more prominent than the others.
　for each of the experimental domains  we built classifiers that predict the choice selected by most human partners. we worked with two widely used machine learning algorithms: a c1 decision learning tree  quinlan  1   and a feed forward back-propagation  ffbp  neural network  werbos  1 . each of these was first trained on the raw domain data set  and then on the new preprocessed focal point data.
　the raw data was represented as a multi-valued feature bit vector. each domain feature was represented by the minimal number of bits needed to represent all its possible values. this simple  low level representation helped standardize the experimentalsetup with both types of classifiers using exactly the same domain encoding.
　the transformation to focal point encoding provides focality values in terms of our low-level focal point rules  firstness  singularity  extremeness  and centrality  for each of the possible choices. their values were calculated in a preprocessing stage  prior to the training stage  and by an agent when it needs to output a prediction . it is important to note that following the transformation to the focal point encoding  we deprive the classifier of any explicit domain information during training; it trains only on the focal point information.
changes in the environment
to check agent robustness in the face of environment changes  we took the  pick the pile  domain  described below   and designed two variations of it  in which one variant is more similar to the original environment than the other is:
definition 1  environment similarity . similarity between environments is calculated as the euclidean distance:
 
where the environment vector x is constructed from the number of goals  number of attributes per goal  number of values per attribute  and the attribute values themselves.
　in our experiments  we put original agents  i.e.  agents that had been trained in the original pick the pile game  in the new environments and comparedtheir classification performance.
1 the experimental domains
we now present three experimental domains that were designed to check fpl's performances. the design principles for constructing them were as follows: 1  create tactic coordination games  equal utility values for all possible choices ; 1  minimize implicit biases that might occur due to psychological  cultural  and social factors; 1  consider a range of tactic coordination problems  to check the performance of fpl learning in different domains.
pick the pile game
we designed a simple and intuitive tactic coordination game that represents a simplified version of a domain where an agent and a human partner need to agree on a possible meeting place. the game is played on a 1 by 1 square grid board. each square of the grid can be empty  or can contain either a pile of money or the game agents  all agents are situated in the same starting grid; see figure 1 . each square in the game board is colored white  yellow  or red. the players were instructed to pick the one pile of money from the three identical piles  that most other players  playing exactly the same game  would pick. the players were told that the agents can make horizontal and vertical moves.
　in a simple binary encoding of this domain  for encoding 1 squares with 1 possible values  1 bits  per square  we used 1 neurons for the input layer. training such a massive network required a large training set  and we built the game as a web application to be played online. the web site was publicized in various mailing lists. to maintain the generality

figure 1: pick the pile game board sample
of the data  each game sequence was limited to 1 game instances; thus  the data set of approximately 1 games was generated by 1 different human players from around the world. each instance of the game was randomly generated.
　the transformation to the focal point space was done in the following way: the only distinguishable choice attribute is the color  thus the singularity of each pile was calculated according to the number of squares having the same color. naturally  a pile of money sitting on a red square in a board having only 1 red squares  would have a higher degree of singularity than a pile of money sitting on a white square  if there were 1 white squares on that board. the firstness property was calculated as the manhattan distance between the agent's square and each pile of money. centrality was calculated as an exact bisection symmetry  thus giving a positive value to a pile that lies directly between two other piles either horizontally  vertically  or diagonally. the extremeness property was intuitively irrelevant in this domain  so we gave it a uniform constant value.
candidate selection game
players were given a list of five candidates in an election for some unknown position. the candidates were described using the following properties and their possible values:
1. sex（{male  female}
1. age（{1  1  1  1  1}
1. height  in meters （{1  1  1  1  1}
1. profession（{doctor  lawyer  businessman  engineer  professor}
　each list was composed of five randomly generated candidates. the  pen and paper  experiments were carried out when subjects  1 first-year university students  were seated in a classroom  and were told that their coordination partners were randomly selected from experiments that took place in other classes  i.e.  their partner's identity is completely unknown. for a candidate to be elected  it needs to get these two votes  the player's and its partner's ; thus  both sides need to choose the same candidate. to create the necessary motivation for successful coordination 1 we announced a monetary reward for success. figure 1 shows a sample question.
　the binary encoding for this domain is a set of 1 input neurons in the input layer that encodes 1 candidates  each with 1 possible property values. the focal point transformation had the following intuitive implementation: the singularity of a candidate was calculated according to the relative

figure 1: candidate selection game sample
uniqueness of each of its values  i.e.  a sole female candidate in a set of males will have a high singularity value . the extremeness property gave high values to properties that exhibit extreme values in some characteristics of the candidate  for example  a candidate who is the oldest or youngest among the set of candidates would get a higher extremeness value than a candidate who is not . the firstness and centrality properties simply gave a constant positive value to the first and third candidates on the list.
shape matching game
players were given a random set of geometric shapes  and had to mark their selected shape in order to achieve successful coordination with an unknown partner  presented with the same set . the shapes were presented in a single row. the game was randomly generated in terms of the number of shapes  that ranged from 1 to 1  and the shapes themselves  which could be a circle  rectangle  or triangle . questionnaires containing ten game instances were distributed to students  1 students overall . as before  monetary prizes were guaranteed to students with the highest coordinationscores. figure 1 shows a sample question in the domain.

figure 1: shape matching game sample
　this domain is the easiest among our games to represent as a simple binary encoding  because each goal has only a single property  its type. in any game instance  each shape can be a circle  rectangle  triangle  or  non-existing   in the case where the randomized number of shapes is lower than 1. the focal point transformation was implemented as follows: the singularity of a choice was determined by the number of choices with the same shape  for example  in a game where all shapes are circles and only a single shape is a triangle  the triangular shape will have a high singularity value . the extremeness property gave higher focality values to the first and last choices in the set. those values became higher as the number of shapes increased  the extremeness in a game with 1 shapes was lower than the extremeness in a game with 1 shapes . centrality gave additional focality value to the middle choice  when the number of shapes was odd. in an even number of shapes  no centrality value was given. firstness gave a small bias to the first shape on the list.
　this domain is an example of a transformation in which j   i; the transformation actually increases the search space.
1 results and discussion
1 prediction performance
for each of the above domains  we compared the correct classification performance of both c1 learning trees and ffbp neural network classifiers. as stated above  the comparison was between a domain data agent  trained on the raw domain encoding   a focal point  fp  agent  an untrained agent that used only focal point rules for prediction   and a focal point learning  fpl  agent.  correct classification  means that the agent made the same choice as that of the human who played the same game.1
　we optimized our classifiers' performance by varying the network architecture and learning parameters  until attaining best results. we used a learning rate of 1  momentum rate of 1  1 hidden layer  random initial weights  and no biases of any sort. before each training procedure  the data set was randomly divided into a test and a training set  a standard 1%-1% division . each instance of those sets contained the game description  either the binary or focal point encoding  and the human answer to it. all algorithms were run in the weka data mining software  which is a collection of machine learning algorithms for data mining tasks. the classification results using the neural network and the decision tree algorithms were very close  maximum difference of 1% . figure 1 compares the correct classification percentage for the agents' classification techniques  in each of the three experimental domains. each entry in the graph is a result averaged over five runs of each learning algorithm  neural network and c1 tree   and the average of those two algorithms.

figure 1: average correct classification percentage
　examining the results  we see a significant improvement when using the focal point learning approach to train classifiers. in all three domains  the domain data agent is not able to generalize sufficiently  thus achieving classification rates that are only about 1%-1% higher than a random guess. using fpl  the classification rate improved by 1%-1% above the classification performance of the domain data agent.1 the results also show that even the classical fp agent performs better than the domain data agent. however  when the fp agent faces coordination problems with low focality ratios  its performance deteriorates to that of random guesses.
　note also that in the first domain  when using fpl instead of regular raw data learning  the marginal increase in performance is higher than the improvement that was achieved in the second domain  an increase of 1% vs. 1%   which is in turn higher than the marginal increase in performance of the third domain  an increase of 1% vs. 1% . from those results  we hypothesize that the difference in the marginal performance increase is because the first domain was the most complex one in terms of the number of objects and their properties. as the domain becomes more complex  there are more possibilities for human subjects to use their own subjective rules  for example  in the pick the pile domain  we noticed that few people looked at the different color patterns that were randomly created  as a decision rule for their selected goal . as more rules are used  the data becomes harder to generalize. when an agent is situated in a real  highly complex environment  we can expect that the marginal increase in performance  when using fpl  will be correspondingly large.
　an additional advantage of using fpl is the reduction in training time  e.g.  in the pick the pile domain we saw a reduction from 1 hours on the original data to 1 minutes   due to the reduction of input size. moreover  the learning tree that was created using fpl was smaller  and can be easily converted to a rule-based system as part of the agent's design.
1 robustness to environmental changes
follow-on experimentswere designed to check the robustness of agent-human tactic interaction in a changing environment.
　we created two differentversions of the pick the pile game  which had different similarity values relative to the original version. in the first variant  vsd   we added a fourth possible value to the set of values of the color attribute  four colors instead of three . in the second variant  sd   in addition to the first change  we also changed the grid structure to a 1 by 1 grid  instead of the original 1 by 1 . moreover  in both variants  we changed all four color values from actual colors to various black and white texture mappings.
　additional experiments were conducted in order to collect human answers to the two new variants of the game. the agents that had been trained on the original environment  using the neural network algorithm   were now asked to coordinate with an arbitraryhuman partnerin the new environments. figure 1 summarizes performance comparison of the agents in each of the new environment variants.

figure 1: classification percent in changing environments
the prediction results on the first variant  vsd  show that
all three agents managed to somehow cope with the new  very similar domain  and suffered only a small decrease in performance. however  when looking at the results of the similar domain  sd   we see that the domain data agent's performance decreased all the way to its classification performance's lower bound  that of random guessing. at the same time  our fpl agent did suffer a mild decrease in performance  around 1%   but still managed to keep a considerably high performance level of around 1%. we can also notice that the classical fp agent copes with the environmental changes better than the domain data agent  with performance level of around 1%; however  it is still low when compared to the fpl agent's performance level.
1 related work
the first use of focal points in artificial intelligence  kraus et al.  1  employed focal point techniques to coordinate between two computerized agents in communicationimpoverished situations. the authors modeled the process of finding focal points from domain-independent criteria using two approaches: decision theory  and step-logic. they also defined a robot rendezvous domain  and used simulations to show that their focal point-based algorithm  tailored specifically for that domain  effectively solved the problem. focal points have also been widely studied from the point of view of a human who is coordinating with another human partner.  janssen  1  provides a good overview of the formal models that attempt to describe the focal point phenomenon.
　for teams of automated agents  a variety of methods have been developed to achieve coordination  and cooperation without communication  for specific  well-defined tasks.  gervasi and prencipe  1  provides an example solution to the flocking problem  involving simple robot teams that cannot communicate with one another. a comparison of experiments with and without communication was done in  arkin  1   to check robot performance in the retrieval task. in a recent paper   schermerhorn and scheutz  1  used predefined social laws for achieving coordination without communication in the multiagent territory exploration task.
1 conclusions
we have presented the focal point learning  fpl  approach to building automated agents that play tactic coordination games with general human partners in changeable environments. the technique makes use of learning algorithms to train agents to coordinate with general human partners in specific domains; focal points are integrated into the learning process through the use of focal point selection rules. training data is preprocessed and transferred into a new representation space  where each vector contains quantified focal point values  and these are used to train the agent.
　we created three experimental domains  and collected data to be used for training agents to predict human coordination choices in those domains. results showed that when trained solely on the domain-encoded data  the classifiers resulted in a close-to-random correct classification percentage  while the fpl agents managed to achieve a significantly higher correct classification rate.
　in the next step we created two variants of one of the domains  collected human data for them  and then checked the coordination performance  in these variants  of each of the agents that had been trained in the original domain. here again  the fpl agents outperformed the others  and demonstrated robustness in a changing environment.
　when building agents to coordinate with unfamiliar human partners  without communication  machine learning classifiers have a difficult task generalizing data to predict human choices. focal point learning can improve performance and robustness to environmental changes. in future work we will explore fpl's performance on more complex problems. the first stage will likely be problems in which the agent has some uncertainty regarding the environment that the human sees.
1 acknowledgment
this work was partially supported by grants #1 and #1 from the israel science foundation.
