: artificial intelligence needs a formal theory of the process of non-monotonic reasoning. ideally  such a theory would decide  for every proposition and state of the process  whether the program should believe the proposition in that state  or remain agnostic. without non-monotonic inference rules  non-monotonic inferences cannot be explained in the same relational  rule-based fashion as other inferences. but with such rules  theoremhood is often formally undecidable and thus a useless criterion for our purpose. so how could any system be a  non-monotonic logic programming language   
our method uses the language  inference rules and proofs of non-monotonic logics  but ignores theoremhood. instead  it defines states of the reasoning process  and focuses on current proof as the criterion for belief. it defines  admissible beliefs  and  valid proof  for given states  and we prove in  that a belief is currently admissible iff it is currently proven. the primitive non-monotonic condition is  currently unproven . 
the theory  logical process theory  can accept a range of non-monotonic logics. it was inspired by doyle's rms  and is similar to his more recent theory in  1|. a model implementation  watson  exists and has been used to write a small diagnostic reasoner  which reasons non-monotonic ally using violation of expectations and an abstraction hierarchy. 
1. definition of logical processes 
briefly  logical process theory  lpt  accepts a triple where l and i are the object language and inference rule of some suitable logic  and ¡ê  the enumeration  is a control parameter. the theory then specifies the admissible statet of an inference process which obeys that logic and makes inferences in the order indicated by ¡ê a state consists simply of the set of inferences made so far  and the set of formulas taken to be believed by the machine 
this research wot sponsored by the swedish board of technical 
development. 
executing the process. at no point is theoremhood in the given logic defined or used by lpt itself; lpt deals always with finite  computable states. 
lpt requires of l only that it be a denumerable set of formulas; their grammatical structure and semantics is opaque to lpt and hence unrestricted. 
the inference rule i may be any set of inference ttept. an inference step is a triple  m n c   where the monotonic antecedents m are a set of formulas of l; the non-monotonic antecedents n are a set of formulas of l; and the consequent c is a formula of l. we also require some finite bound on the site of m and n for all inferences in j. 
informally  an inference  may be read: if all the formula in m are currently believed  and none of the formulat in n are currently believed  then c mutt be currently believed. note that this is stated as a constraint  not as an imperative  not as  if ... then infer c  . the constraint is understood to apply any state of the process after the inference was made. because it is a conditional constraint  it does not necessarily force belief in c; for the same reason  it can be safely made at any time  whether its antecedent conditions are satisfied at that time or not. 
no further restrictions are placed on l or j by lpt. normally l would be defined by a grammar  and j by a set of schemas or rules. the rules of default logic |1   for example  have the form: 

where a  b and c are single formulas; this may be expressed in lpt by the schema 
1 j. goodwin 
we prefer the alternative of introducing non-mono tonicity directly into the language l by a modal operator  as in  1|. watson uses an operator unproven. in this case it is convenient to represent the standard first-order inference rules as inferences in which n is always empty  and to obtain all non-monotonicity via one inference schema for introducing the modal operator    
 this may be read  if a is not currently believed  then 
  unproven a   must be currently believed . 
since l is denumerable and the sizes of m and n have a constant bound  i is also denumerable. we denote enumerations of j by the control parameter ¡ê. intuitively  ¡ê represents the order in which individual inference steps are taken by a logical process. to take an inference step simply means to add it to the database; the current database in the j:th state is therefore just the set of the first j inferences of ¡ê. 
to represent sets of beliefs  we define an in/out libelling as a total function from l to the set of labels {in out}. a state of the 
machine is then a pair  of a database and an in/out 
labelling g. 
an individual inference  is valid under an in/out 
labelling g if every formula in m is labelled in by g  and every formula in n is labelled out by g; 1 is invalid under g otherwise. where it is clear which labelling or state is intended  we say simply that 1 is valid. 
a state  d g  is relaxed if for each  either the consequent of d is labelled in by g  or 1 is invalid under g. 
a relaxed state satisfies all the constraints in the database locally  but to eliminate circular proofs  a non-local ordering must also be imposed. therefore: a state  d g  is well-founded iff there exists a partial order over lu j such that 
1. for every formula s labelled in by g  there b a 
which is valid under g  has s as its consequent  and and 
1. for every valid  for every formula s in the monotonic antecedents m of 
finally  an admissible state is one which is both relaxed and well-founded  and its labelling b said to be an admissible labelling for its database. 
having defined the admissible states  the main task at hand b to relate them to proofs. a proof of a formula c b a tree of inferences with c at the root  in which each node has for each of its monotonic antecedents a daughter node proving that antecedent  and has no other daughter nodes. a proof b valid in a hate  p g  if every inference in the proof tree b contained in v and b valid under g. 
 premises are introduced by inferences with empty m and n. such inferences are always valid  and may appear at any point in the enumeration. this allows inference and input of new external information to be arbitrarily interleaved.  
1. properties of logical processes 
the main theorem about logical processes correlates belief with current proof: for any admittible ttate t and any formula c of l  there it a valid proof of c in $ iff e it labelled in in t.  proof to appear in  . 
some additional properties are as follows  proofs again in  : 
admissible states are physically representable: any database b finite  and in any admissible state  the number of formulas labelled in is finite. 
non-monotonic belief behavior b actually obtained: a formula may be in in one state and out in a later state. this may result either  1  because of new premises being given  or  1  merely due to further inference based on information already available  or any combination of the two. 
we call both cases  non-monotonic inference   because the set of currently admbsible beliefs may vary non-monotonically as the process continues. from the perspective of a process theory of inference  there b no very natural distinction between them  nor much reason to try to find one. 
 we have several times met the objection that  non-monotonicity  has a standard definition  according to which the case 1 above b 
 non-monotonicity  and case 1 b something else. now   non-monotonic logic  has indeed a precise and well-establbhed meaning: any logic in which adding premises may delete theorems. but neither case 1 nor case 1 mentioned theorems; they described non-monotonic inference  as a process in which current proof of a formula may come and go. thb b a reasonable use of the term  non-monotonic inference   consistent with its common informal use in ai. certainly  non-monotonicity of belied during the inference process is a different matter than non-monotonicity of theorems under addition of premises. the former is computable where the latter is not  and the former explains case 1 where the latter does not allow the question to be put. for artificial intelligence  those are advantages. note also that the set of inference rules which are  non-monotonic  is the same in either sense.  
in a non-monotonic lp  a given database may have zero  one or many admissible labelling. moreover  its predecessor or successor may independently have zero  one or many admissible labelling*. it is therefore possible that an admissible state s may be  inaccessible  under a given ¡ê  in the sense that the process cannot reach s while passing only through admissible states. however  there is always a permutation of the initial subsequence of ¡ê up to and including s  such that every state up to s is admissible. 
by a proof adapted from  l   for a database to have rero admissible labelling  it must contain a configuration called an  odd loop   which is usually a kind of  liar's paradox  argument. by ruling this case out  we guarantee continuity of the sequence of admissible states  and also make possible an efficient reason maintenance algorithm for finding them. 
since the formulas of l are opaque to lpt  lpt cannot say anything about their consistency  in either a model theoretic sense  or in terms of provability of a contradiction. this is only to be expected  however  of a process theory of non-monotonic reasoning  since the purpose of non-monotonicity is to allow a reasoning agent to make unsound but reasonable inferences and then back out of them if they turn out to be inconsistent due to new information or - again  we stress the focus on process - simply due to further reasoning. the only guarantee given by lpt  that of admissibility  is that the system knows exactly what it does and does not have current proof of. 
1. watson: a model implementation 
watson is a model implementation in lisp of a non-monotonic logical process. it is a pure forward chaining system. the inference rules are  wired in  to the interpreter  which does nothing but add dependencies  inferences permitted by the rules  to the database. all valid inferences are drawn. unlike previous systems  1  there is no way to  escape to lisp  and manipulate dependencies. 
	j.goodwin 	1 
how much can be done with pure non-monotonic inference alone  
diagnose is a small diagnostic reasoner written in watson  which uses non-monotonicity both to reason by violation of expectations  and to work downwards in an abstraction hierarchy. so the system is not trivial. 
some inference rules which we cannot state in the format allowed by lpt include a forward chaining analog of negation by failure; conditional proof as in |1  and thus dependency directed backtracking as well; and inferring the set of all currently proven instances of a formula  contrast circumscription  . we have already extended watson to use these rules  as well as to allow expression of control in the language:  reasoned control of reasoning . revision of lpt to account for these extensions is in progress. 
