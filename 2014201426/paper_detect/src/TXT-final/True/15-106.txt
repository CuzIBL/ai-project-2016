 
　　　this paper discusses strategies for moving through sequences of hypotheses  each one of which is produced in response to an experimental test of the previous member. 	previous discussions of this issue have a l l agreed that hypotheses deductively incompatible with the evidence at stage ri cannot appear in the sequence beyond 	n 	this paper contends that this conclusion is untenable. 	the use of oversimplified models has led investigators into overlooking epistemological properties of 
more complex hypotheses which allow more sophisticated methodologies in testing and hypothesis generation. in particular  it is shown that testing already falsified hypotheses may give more experimental information than other  more traditional strategies. this is shown by considering a popular board game  but a realistic example is introduced to demonstrate the general importance and usefulness of the strategy. 
　　　in this short paper i discuss strategies in the testing of a sequence of hypotheses. each of the hypotheses  except perhaps the f i r s t   is proposed after an experimental test of the preceding hypothesis. the aim of the strategy is to maximise the rate of convergence of members of the sequence of hypotheses to the correct 
hypothesis. 
　　　this problem has been discussed in the literature quite extensively under the general 
heading of methodology of science and to a lesser extent in the field of heuristics. two fundamentally different views have been taken about the 
manner of proceeding in such a sequence. the f i r s t   associated with carnap  carnap  1   reichenbach  reichenbach  1  and many others following them is to put an evaluation on each 
possible n t n hypothesis and choose that hypothesis which has a maximum value for this evaluation. most often  but by no means always  the evaluations were simply the probabilities or confirmation of the alternative hypothesis  although this is by no 
means universal  e.g. reichenbach  op c i t   . such proposals are often termed inductivist. 
　　　a quite different view is taken by popper  popper  1  and followers who eschew a probabilistic or confirmatory evaluation function. instead they propose that the function rises with the risk of falsification of a hypothesis. by adopting as the n t n member of a sequence the hypothesis with the minumum risk of refutation  usually identified by maximising content of the hypothesis  we maximise the chance of refutation. this  in turn  maximises the expected rate of progress along the sequence of hypotheses and their convergence to the truth. the general stance of this latter group is that since there exist no objective measures of the confirmation of hypothesis by evidence  the appropriate evaluation is given by a methodologically derived function 
which reflects the a priori likelihood of refuta-
tion and hence progress along the sequence of hypotheses. such a thesis concerning the appropriateness of the evaluation is called f a l s i f i c a t i o n i s t . 
　　　both approaches to the evaluation function share one important common feature. the evaluation takes a minimum value for any hypothesis which is deductively incompatible with the evidence to date. this assignment is j u s t i f i e d in both approaches by the view that each proposed hypothesis must be a possible candidate for  the true hypothesis . the inductivist would restate this 
with term  probable  rather than possible but since  probable  entails  possible  the two views coincide. 
　　　the discussion of these topics has been rendered less helpful to investigators by the perhaps oversimple characterisation of hypothesis. they are  for much of the discussion  simply structured sets of sentences whose only relevant characteristic here is that they entail simple observation sentences which either do or do not accord with actual observations. the assessment of any hypothesis given a single piece of evidence is thus a two valued function - either inconsistent or consistent. while such a model of experimental testing has the virtue of simplicity it i s   i contend  so unrealistic as to obscure the real and interesting problem of strategies for 
experimental testing even in simple contexts. 
　　　i w i l l argue that when the two major schools of thought agree - that refuted hypotheses should be discarded - they are both wrong. in doing so i shall use hypotheses whose observational consequences are minimally more structured. these hypotheses w i l l assign occupation states to a f i n i t e ordered set of cells. accordingly the possibility arises of the hypotheses f i t t i n g the experimental data to a lesser or greater degree rather than a simple yes/no. 
　　　i have chosen such a form for the hypotheses because f i r s t l y they appear to represent the next simplest structure beyond unstructured hypothesis and secondly it is possible to find realistic and interesting examples of the use in scientific practice. 
　　　the most perspicuous way of proceeding is to produce a model with the characteristics of which i wish to discuss  then go on to outline a realistic example. 
　　　the example i w i l l use is the game mastermind. this game is for two players  a code maker and a code breaker. 	the code maker chooses four coloured counters from a. supply of six different colours  colour repetitions are allowed. 	the code of four colours is thought of as being ordered. 
　　　the code breaker conjectures a hypothesis as to the code and displays it on the board. 	the code maker then scores the hypothesis by displaying a black marker for each counter the code breaker 
has of the correct colour in the correct position  and a white marker for each counter  not yet scored  which is of a correct colour but in an incorrect position  by comparison with those code counters from which a black marker has not been awarded. the score is some measure of the nearness of the hypothesis to the truth. 
　　　for example  if the hidden code is red  red  green  green  a hypothesis red  blue  green  red would attract a black marker for the f i r s t red counter  no marker for the blue  a black marker for the green and a white marker for the last red. the scoring markers are not ordered  that i s   one cannot deduce which of the counters earns which marks. 
　　　in the light of that score the code breaker conjectures a new code which is then scored  the process continuing until the code breaker scores four black markers - he has the correct hypothesis. 
　　　if we are to show that the code breaker may do better to hypothesise falsely it is necessary to show  1  after the f i r s t hypothesis some hypotheses can be known  deductively  to be false and  1  that a measure of better and worse guesses is available. in what follows  i shall assume  for simplicity  that the code maker is equally likely to choose any coloured marker in any position. the general situation is not changed by such a restriction  unless the code breaker has knowledge about the 
probability distribution. 
　　　to show  1  we need f i r s t to observe that there are 1 - 1 possible codes  generated by an independent choice of one of six colours in each of the four positions. 	after choosing the f i r s t hypothesis the code breaker either gets no scoring markers or a combination of black and 
white markers. unless the code breaker obtains four black markers  he knows that  at least  that 
g. hunt 1 
hypothesis is false. if the code breaker does  improbably  get four black markers then he knows that a l l other possible codes are false  and the game is ended . either way he knows that at least one hypothesis is false and thus  1  is satisfied. in fact an average of 1 hypotheses are eliminated as the f i r s t hypothesis is scored. 
　　　we now turn to the second lemma: to show that some guesses as to the code are better than others and hence to show that some falsified hypotheses are better eliminators than some unfalsified hypotheses. 
　　　we f i r s t observe that in guessing a code and having it scored  the code breaker eliminates not only that guess  unless four black markers are scored  but  in general  many others as well. for example  if four red counters was guessed and no black markers obtained then it is certain that the hidden code does not contain any red counters in any position. a similar conclusion would follow if the guess contained only one red counter and no 
black or white counters were obtained. there are 1 codes containing at least one red counter  so if this is the code breaker's f i r s t guess a l l of these w i l l have been eliminated. if this guess 
was not the f i r s t then some of the 1 w i l l have already been eliminated. 	as most games last only five or so moves  in the course of which 1 codes are eliminated there w i l l be very few  if any  guesses which eliminate no other code but themselves. 
　　　i wish to suggest that the number of possibilities eliminated by a guess is a good measure of how valuable that guess has been in 
forwarding the aim of the code breaker. since in this paper i w i l l be concerned with the eliminative power of second guesses - there are no impossible codes for a f i r s t guess - i w i l l use as a measure of eliminative power the proportion of remaining possible codes eliminated by that second guess. because comparisons w i l l only be made between second guesses which share a common f i r s t guess no 
metrical assumptions are made which v i t i a t e the conclusions. the exception to this is where comparisons are made between the average eliminative powers of different ranges of guesses. these latter results are less important and w i l l be 
discussed separately. 
　　　when playing a f u l l game consisting of a sequence of guesses  it might well be that two successive guesses of lower eliminative power succeed j o i n t l y in eliminating more possible codes than an alternative pair of guesses each of higher eliminative power. this possibility cannot be ruled out a p r i o r i . this paper w i l l restrict i t s e l f to the stepwise maximisation of eliminative power. 
　　　it now remains to demonstrate that a best guess  as measured by eliminative power  may be and often is - a known false guess. of course this can only happen on a second or subsequent guess as nothing is known as possible or impossible u n t i l the f i r s t guess is scored. 

1 g. hunt 
　　　the method is to nominate a f i r s t guess and a score  e.g. red  red  blue  blue  score one black 
marker and one white. it is now possible to deduce which codes the code maker may have chosen. they are simply these codes which would give that score against that guess. in this example there are 1 possibilities. normally the next guess the code breaker w i l l try w i l l be one of these 1 codes. 
　　　for each of these 1 possible guesses and for each of the 1 possible codes  1 pairs  it is possible to calculate the number of codes 
eliminated by the second guess. if it is assumed that a l l 1 codes are equally likely to have been chosen by the code maker  then it is possible to calculate the average eliminative power of each of the code breaker's possible second guesses. a code breaker might use such a 
measure of rejection power in choosing a second guess so as to maximise the expected rejection of 
wrong codes. it is possible to further calculate the average eliminative power of the 1 possible guesses the code breaker might have chosen. see table 1 for results of mastermind using only black markers. these results are more concisely displayed than the f u l l game  but exhibit results typical of the f u l l game. 
　　　the fact that the scoring procedure is not a simple refutation is essential for the arguments in this paper. for the black markers show that some counters are of the correct colour and in the correct position  while the white markers show that some remaining counters are of the correct colour but in incorrect positions. in a roundabout way the markers give a measure of distance from the truth. indeed  two black and two white markers show that a simple interchange of two counters w i l l give the correct code. alternative  non-mastermind  systems of scoring  e.g. use black marker only  give different measures and w i l l be discussed later. they do  however  generally exhibit the interesting property which is the subject of this paper. this is because these scoring systems begin to take account in the experimental situation  of the structure of the hypothesis. my feeling is that after the simple yes/no given by an experiment to an unstructured deduction from a hypothesis  the next more complex observation statment would be a simple ordering of elements like the mastermind code. 
　　　in table 1 is listed the mean and maximum eliminative powers of both possible and impossible   i . e . already refuted  second guesses. further work has shown that the striking results here appear if the scoring system of mastermind is 
varied by using only black scoring markers or only white scoring markers  in the manner outlined in the game description  above. 
　　　in particular  modelling of an experiment designed to elucidate particular dna sequences by the absorption  in solution  of matching test and subject dna strings yields this same property: that use of already refuted hypotheses for further test results in more rapid convergence of 
hypotheses  by increasing the informational 
transfer at each experiment. 
　　　of course ultimately  both in mastermind and in molecular biology  one must eventually refer to unfalsified hypotheses for final confirmation. 
