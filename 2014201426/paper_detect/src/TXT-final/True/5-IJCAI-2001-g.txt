
the automatic generation of diagnostic decision trees from qualitative models is a reasonable compromise between the advantages of using a modelbased approach in technical domains and the constraints imposed by on-board applications. in this paper we extend the approach to deal with temporal information. we introduce a notion of temporal diagnostic decision tree  in which nodes have a temporal label providing temporal constraints on the observations  and we present an algorithm for compiling such trees from a model-based diagnostic system.
1	introduction
the adoption of on-board diagnostic software in modern vehicles and similar industrial products is becoming more and more important. this is due to the increasing complexity of systems and subsystems  esp. mechatronic ones like the abs and fuel injection  and to the increasing demand for availability  safety and easy maintenance. however  in order to keep costs acceptable  esp. for large scale products like cars  limited hardware resources are available in electronic controlunits  ecus . thus  althoughthe model-based approach is very interesting and promising for the automotive domain and similar ones  console and dressler  1; sachenbacher et al.  1   it is still questionable if diagnostic systems can be designed to reason on first-principle models on board. for this reason the following compilation-based scheme to the design of on-boarddiagnostic systems for vehicles was experimented in the vehicle model based diagnosis  vmbd  brite-euram project  1   and applied to a common-rail fuel injection system  cascio et al.  1 :
a model-based diagnostic system  which can be used to solve problemsoff-line  and then for off-boarddiagnosis

　　this work was partially supported by the eu under the grant grd-1  idd  integrated diagnosis and design   whose partners are: centro ricerche fiat  daimler-chrysler  magneti marelli  occ'm  psa  renault  technische universita：t m：unchen  univerisite＞ paris xiii  universit`a di torino.
in the garage   is used to solve a set of significant cases  that is  at least a good sample of the cases that have to be faced on-board . the solution includes the set of candidate diagnoses and  more important  the recovery action s  that should be performed on-board in that case.
cases and the correspondingrecoveryactions are used to generate a compact on-board diagnostic system. specifically  in  cascio et al.  1  decision trees are generated  using an algorithm based on id1  quinlan  1 .
　however  the system has a major limitation: even if some form of reasoning on the dynamics is used to achieve proper diagnostic results  all abnormal data are considered relative to a single snapshot  and therefore no temporal information is associated with the data in the table used by the compiler and then in the decision tree.
　in this paper the decision tree generation approach is extended to take into account temporal information associated with the model  with the manifestations of faults and with the decisions to be made. using the additional power providedby temporal information requires however new solutions for organizingandcompilingthe decisiontrees to be used on board.
　the essential idea for generating small decision trees in the temporal case is that in some cases there is nothing better than waiting  in order to get a good discrimination  provided that safety and integrity of the physical system is kept into account.
1	temporal diagnostic decision trees
defining and compiling decision trees is conceptually simple in the atemporal case. each node of the tree corresponds to an observable  e.g.  a sensor reading  and has several descendants depending on the qualitative values associated with the sensor. the leaves of the tree correspond to actions that can be performed on board.
　new opportunities and problems have to be faced in the temporal case. each fault leads to a different evolution across time  and  for some fault  the appropriate recovery action must be performed within a given time to avoid unacceptable consequences as regards the car integrity and  most importantly  safety.
　in the definition of the decision tree  temporal information can be exploited for discriminating faults based on temporal


figure 1: a simple example of temporal decision tree
information  e.g. faults that lead to the same manifestations
with different timing. suppose  for example  that faults and both produce an abnormal value for sensor   but produces an abnormal value for sensor after time while produces the same abnormal value for after time
　. the two faults cannot be distinguished in an atemporal decision tree and  in general  without temporal information on the contrary  in the temporal case we can build a tree like the one in figure 1. after observing an abnormal value for   the system waits for units of time  and then makes a decision  depending on whether at that time an abnormal value for is read. however  this behavioris only reasonable in case the recovery actions associated with faults and allow the system to wait for more units of time after fault detection  i.e. in this example  observing an abnormal value for  .
　timing information then leads to the definition of temporal diagnostic decision tree  i.e. a decision tree such that:
each node is labelled with a pair   where is the name of an observable and is a time delay.
the root corresponds to the sensor used for fault detection; in case more than one sensor may be used for such a purpose  there are multiple decision trees  one for each sensor.
each edge is labelled with one of the qualitative values of the sensor associated with its starting node.
leaves correspond to recovery actions.
the tree is used as follows:
1. start from the root when a fault is first detected.
1. when moving to a node   wait for units of time  then read sensor and move to the descendant of corresponding to the observed value for the sensor.
1. when moving to a leaf  perform immediately the corresponding recovery action.
　in the following sections we present how a temporal diagnostic decision tree can be generated automatically. before describing that  however  we must discuss the assumptions we make as regards the underlying model-based diagnostic approach.
1	the underlying model-based approach
as regards the temporal dimension  the architecture in  cascio et al.  1  relies on either static diagnosis  i.e. diagnosis based on a static model  or based on reasoning in a single state of the system  or a limited form of temporal diagnosis  see  brusoni et al.  1  for a general discussion on temporal diagnosis  where the model of time is purely qualitative  a sequence of qualitative states   abnormal manifestations are assumed to be acquired in a single snapshot and therefore matched with a single qualitative state  and normality of observations in times earlier than is used to rule out diagnoses which predict abnormal manifestation that were not detected  see  panati and theseider dupre＞  1  .
　what is not exploitedis the ability of discriminatingamong explanations for the observations at snapshot using information acquired at subsequent snapshots  which is what we intend to exploit in the present paper  to extend the approach to other forms of temporal models and other notions of temporal diagnosis.
　in particular  we consider models of temporal behavior in which temporal information is associated with the relations describing the behavior of a device. we do not make specific assumptions on the model of time  even though  as we shall see in the following  this has an impact on the cases which can be considered for the tree generation. similarly  we do not make assumptions on the notion of diagnosis being adopted  in the sense of  brusoni et al.  1  . this means that the starting point of our approach is a table containing the results of running the model-based diagnostic system on a set of cases   almost  independently of the model-based diagnostic system used for generating the table.
　however  some discussion is necessary on the type of information in the table. in the static case  with finite qualitative domains  the number of possible combinations of observations is finite  and usually small  therefore there are two equivalent ways of building the table:
1. simulation approach: for each fault   we run the model-based system to predict the observations corresponding to .
1. diagnostic approach: we run a diagnosis engine on combinations  all relevant combinations  of observations  to compute  the candidate diagnoses for each one of these cases.
in either case  the resulting decision tree contains the same information as the table; if  once sensors are placed in the system  observations have no further cost  the decision tree is just a way to save space and speed up table lookup.
　in the temporal case  if the model of time is purely qualitative  a table with temporal information cannot be built by prediction  while it can be built running the diagnosis engine on a set of cases with quantitative information: diagnoses which make qualitative predictions that are inconsistent with the quantitative information can be ruled out. of course  this cannot in general be done exhaustively  even if observations are assumed to be acquired at discrete times; if it is not  the decision tree generation will be really learning from examples.
　thus a prediction approach can only be used in case the temporal constraints in the model are precise enough to generate predictions on the temporal location of the observations  e.g.  in case the model included quantitative temporal constraints   while a diagnostic approach can be generate also in case of weaker  qualitative  temporal constraints in the model.
　as regards the observations  we consider the general case where a set of snapshots is available; each snapshot is labelled with the time of observation and reports the value of the sensors  observables  at that time. this makes the approach suitable for different notions of time in the underlying model and on the observations  see again the discussion in  brusoni et al.  1  .
　we require that some knowledge is available on the recovery actions that can be performed on-board:
	a recovery action	is associated with each fault	.
a cost ir is associated with each recovery action   due to e.g. the reduction of functionality of the system as a consequence of the action.
a partial order is defined on recoveryactions: in case is stronger than   in the sense that all recovery effects produced by are produced also by . this means that also recovers from although it is stronger than needed. for example  for two recovery actions in the automotive domain  cascio et al.  1 : reduce performance limp home as the latter corresponds to a very strong reduction of car performances which simply allows the driver to reach the first workshop. actions define a lattice  whose bottom corresponds to performing no action and whose top corresponds to the strongest action  e.g.  stop engine in the automotive domain.
	costs are increasing wrt	  that is  if	then
.
actions and can be combined into merge defined as follows:
if if
otherwise
the merge can be extended to compound actions:
merge
	s.t.	.
a simple action can be seen as a special case of compound action  identifying	with	.	in general merge	.
	for a compound action	the cost is such that
.
a merge of actions must be performed in case of a multiple fault or when alternative preferred  e.g. minimal  or minimum cardinality  diagnoses cannot be discriminated  either because no further sensors are available or there is no time to get further sensor readings.
　this actions model is valid only if actions are not faultdependent  e.g. their cost does not depend on the actual fault s  in the system. we will discuss this points in section 1.
　we now have all the elements to describe the structure of the table in which we collect the results of applying the model-based system on the set of simulated cases:
the table has one row for each case.
each row contains:
-the set of observations corresponding to the case. in particular  for each observable we have the value in each snapshot  this will be denoted as where identifies the snapshot and the row
of the table ;
-the recovery action to be performed and its cost. this is determined by considering the set of candidate diagnoses for the case under examination and  in case of multiple faults or multiple candidate diagnoses  merging the recovery actions associated with the individual faults occurring in the diagnoses;
-a probability which corresponds to the prior probability of the candidate diagnoses associated with the row;
-the maximum number of snapshots that can be used for completing the diagnosis.
this table is the input to the algorithm for generating the temporal diagnostic decision tree.
1	generating the tree
an important issue to be considered for the generation of decision trees is optimality. a standard decision tree is said to be optimal  with respect to the set of decision trees solving a particular decision problem  if its average depth is minimal. the id1 algorithm exploits the quantity of information  or its opposite  entropy  carried by an observation as a heuristic to build a decision tree that is  if not optimal  at least good enough.
　for temporal diagnostic decision trees depth is only a secondary issue  since the ability to select a suitable recovery action in the available time becomes more important. a suitable action is one that has the proper recoveryeffects  but that is not more expensive than necessary. each time two actions are merged  because of lack of discrimination   we end up with performing an action that could have a higher cost than needed. an expected cost can be associated with a tree.
definition. let denote the set of leaves of a tree   the set of candidate rows the tree discriminates 
the set of candidate rows associated with a leaf   the recovery action for   and the probability of . in particular we have

then the expected cost	of	can be defined as:
since we are interested in building a tree that minimizes expected cost  some more considerations on costs are worth being made. for any tree   the set is a partition of . it is easy to see that if two trees and	are such that	is a subpartition of	then
             . intuitively  has a higher discriminating power than   and therefore it cannot have a higher expected cost. it follows that if we build the tree with highest discriminating power we automatically build a tree with minimum expected cost. however  maximum discriminating power is a relative  concept: it ultimately depends on the data available in the table from which the tree is built. let us denote with the set of all pairs observable time in the initial table. to fully exploit the discriminating power in   a tree could be based on all the pairs in it. the partition induced on the set of candidates by such a tree is a subpartition of that induced by any other tree that makes use of pairs in . therefore the cost of this tree is the minimum achievable expected cost.
　unfortunately this is not the tree we want to build  since as well as minimum expected cost it has maximum depth. the algorithm we propose builds a tree with minimum expected cost while trying to minimize its depth  using the criterion of minimum entropy. the algorithm is essentially recursive. each recursive call is composed of the following steps:  i  it takes as input a set of candidates  represented by table rows;  ii  it selects a pair observable time for the current tree node;  iii  it partitions the set of rows accordingly to the possible values of the selected attribute;  iv  it generates a child of the current node for each block of the partition;  v  it performs a recursive call on each child.
　the difficult step is  ii . first of all  let us noticethat  differently from what happens in id1  the set of pairs from which we can choose is not the initial set   nor it is the same in all recursive calls. the set of available pairs depends on the current snapshot - a tree node cannot consider a snapshot previous to that of its parent - and on the deadline  which in turns depends on the set of candidates. choosing a pair with a time delay greater than for the current node means making all snapshots between the current one and the selected one unavailable for all the descendants of this node. a pair may be discarded that was necessary in order to attain the minimum expected cost. of course  the higher the time delay  the higher the risk.
　step  ii  can then be divided in two substeps: first  determine the maximum time delay that does not compromise the minimum expected cost; second  select the pair with lowest entropy between those with a safe delay. in order to determine if a particular delay is safe  we must associate with each possible delay the minimumexpectedcost that it is possible to obtain after selecting it. then  since a -delay is safe by definition  the delays with can be declared safe.
　the easiest way to compute is to build the tree that considers all the pairs still available after   as in the definition of minimum achievable expected cost. since we only need the leaves  and not the whole tree  we can simply consider the partition induced on the set of candidates by the combination of all available pairs. we will refer to this partition as the global partition for .
　doing this for all delays can be computationallyexpensive; luckily there is a more efficient way to obtain the same result.
if we consider two possible delays with we have that the set of available pairs for is a subset of that for .
this means that  if we computefirst the global partition for   we can build the global partition for starting from that of and considering only the extra pairs available for . if we apply this backward strategy to the set of all possible delays  we immediately see that we can compute for all while computing . in this way we will be able to determine which delays are safe and which are not looking only once at the set of pairs that are initially available. if we denote by the number of rows in the table  by the number of sensors  by the number of snapshots  and by the number of values that each sensor can assume  we have that in the worst case this algorithm behaves as  . the algorithm as presented in this paper is an improvement  in terms of efficiency  of the original version we described in  console et al.  1 .
1	the algorithm
the algorithm for compiling the tree is reported in figure 1. to start the algorithm up  the sensors used for fault detection must be determined  since a separate tree will be built for each of them. notice that each tree covers a subset of cases  depending on which abnormal measurement activates diagnosis.
　given the sensor used as the root of the tree  the values the sensor can assume induce a partition on the set of cases  and a subtree must be generatedfor each blockof the partition. this is done in the temporalid1 function  that takes in input a set of cases and returns a temporal decision tree along with its expected cost.
in order to express delays instead of absolute times  tem-
poralid1 needs a notion of current snapshot that varies from one call to another  and that correspondsto the last snapshot considered. more precisely  since each call to temporalid1 builds a subtree  the current snapshot is the one in which the parent nodes observation takes place. however ` since the delay between fault occurrence and fault detection depends on which fault is supposed to occur  each candidate has to maintain a pointer to its own current snapshot; we denote this pointer by . at the beginning  for each   is set to the snapshot at which the fault  or combination
of them  described by	is detected.
　moreover  we denote by the prior probability of   by its deadline for a recovery action  and by its recovery action  either simple or compound .
　let us briefly describe temporalid1. first  it considers all those situations in which it should simply return a tree leaf. this happens when:  i  the input set does not need furtherdiscrimination  that is  all the cases in have the same recovery action; or  ii  in the time left for selecting an action there are no more discriminating pairs  a particular case is when there is no time left at all . this means that it is not possible to distinguish between the candidates in and therefore the selected recovery action is the merge of .
　if none of the previous cases holds  temporalid1 uses the backward strategy described earlier in order to compute  for each delay   the expected cost   thus finding out which delays are safe. it exploits three subfunctions: pairs  split and expectedcost  which  for the sake of conciseness  we describe without providing their pseudocode.
function temporalid1 returns a pair tree cost
begin
	if	then
all candidates in	have the same recovery action return tree	cost	;
min	; current deadline merge	;
	if	then no time left
	return tree	cost	;
backward strategy:
undefined;
undefined;
;
	for each	in	do begin
　　　pairs	; if	then begin do begin
	split	;
	for each	do begin
	min	;
	pairs	;
end
	while	;
	new	expectedcost	;
if	is undefined or	new	then begin
new;
;
end
end
	if	is undefined then
no more discriminating pairs
	return tree	cost	;
	ok ok	the pair with minimum entropy
	between those with	;
	for each	do	update the value
of the current snapshot for each candidate
ok;
	split	ok ok	;
	for each	do
build the subtrees
　　subtree	temporalid1	; return tree	ok ok	subtree
　　　cost		; end.figure 1: the function temporalid1
pairs returns all the pairs with a delay betweenthe specified values.
split splits an existing partition using the set of pairs in input. a partition block can be split by a pair only if the pair can provide a value for all the candidates in the block. this is important since some pairs are beyond the deadline and thus do not provide a value for all the candidates.
rowactcost111111111nnnnvnlvvvnnnnn11nnnnvvnlllvvnnnnnv11nnnnhhnllllvnnnnnh11nnnnvnlvzznnnnn11table 1: a sample table of data
expectedcost computes the expected cost associated with a partition. the partition can be regarded as a set of tree leaves  and therefore it is possible to apply the definition of expected cost.
　when we compute   as a result of the backward strategy we can exploit the partition we created for a delay of
　　. first of all we consider the  new  pairs that are available at snapshot   that is  those pairs returned by pairs . however it may be that for some blocks of the newly created partition there are some more pairs available  because these smaller blocks have a looser deadline than the older ones. therefore we keep on  i  creating the new partition;  ii  computing the new deadline for each block;  iii  adding the new pairs due to the new deadline  if any. this is repeated until there are no more pairs to add.
　after determining the maximum safe delay  denoted by   the algorithm selects the pair with minimum entropy among those with a delay such that . the selected pair is denoted by ok ok .
　finally  temporalid1 updates the current snapshot pointers  partitions according to the selected pair  and calls recursively temporalid1 on each block of the partition.
1	an example
let us consider a simple example. there are three sensors 
　  and ; each one of them can have five possible values: normal  n   high  h   low  l   very low  v  and zero  z . possible recovery actions are denoted by         with the following partial order:   . the only compound action that can arise from a merge operation is and we assume its cost is . we assume that the faults associated with the four rows have the same prior probability. initial data are shown in table 1.
　we will build the tree whose root is sensor ; this is the only tree to be built since each fault in the table is first detected on . if  for example  cases and were first detected on while and on   we would have had to build two separate trees  the first with root dealing with and the second with root dealing with .
　the root of the tree is thus but it does not partition the set of candidates  so we still have   and for . in this example all faults show themselves with the same delay wrt fault occurrence; this is the reason why all s have the same value. in a different situation each would point to the first snapshot for which sensor has a non-normal reading. diagnosis must be completed by snapshots   corresponding to a delay of snapshots. using the backward strategy we first find out that with a delay of we would not be able to discriminate and   and therefore . on the other hand  if we consider a delay of we are able to discriminate all faults  thus	. the minimum entropy criterion prompts us to choose the pair   and we obtain the partition	.
for and the diagnosis is completed and the algorithm returns respectively and . for we have that the deadline is moved  and we can choose between delays and . however it is immediately clear that ; moreover all available pairs have the same entropy  quite obvious since there are only two candidates left . we can choose for example and the recursive calls return and .
the resulting decision tree is shown in figure 1.

figure 1: resulting decision tree
1	conclusions
in this paper we introduced a new notion of diagnostic decision tree that takes into account temporal information on the observations and temporal constraints on the recovery actions to be performed. in this way we can take advantageof the discriminatory power that is available in the model of a dynamic system. we presented an algorithm that generates temporal diagnostic decision trees from a set of examples  discussing also how an optimal tree can be generated.
　the automatic compilation of decision trees seems to be a promising approach for reconciling the advantages of modelbased reasoning and the constraints imposed by the on-board hardware and software environment. it is worth noting that this is not only true in the automotive domain and indeed the idea of compiling diagnostic rules from a model has been investigated also in other approaches  see e.g.   darwiche  1; dvorak and kuipers  1  .  darwiche  1   in particular  discusses how rules can be generated for those platforms where constrained resources do not allow a direct use of a model-based diagnostic system.
　future work on this topic is mainly related to recovery actions. while developing the algorithm  we assumed to have a model of actions and costs where actions are not faultdependent  see section 1 . modeling such a situation would mean to introduce  a  a more sophisticated cost model where the cost of an action can depend on the behavioral mode of some system components  and  b  a more detailed deadlines model  that expresses the cost of not meeting a deadline. notice that this does not affect the core part of the algorithm  i.e. the one that computes the expected costs related to different choices. however having fault-dependent costs requires a different criterion for stopping the discrimination process and building a tree leaf  since meeting the deadline becomes a matter of costs and benefits rather than a strict requirement.
　some other generalizations are more challenging  since they affect also the core part of the algorithm. as an example  we are currently investigating how to integrate actions and candidate discrimination  e.g. including probing actions  which modify the system state  and sequences of actions interleaved with measurements.
references
 brusoni et al.  1  v. brusoni  l. console  p. terenziani  and d. theseider dupre＞. a spectrum of definitions for temporal model-based diagnosis. artificial intelligence  1 :1  1.
 cascio et al.  1  f. cascio  l. console  m. guagliumi  m. osella  a. panati  s. sottano  and d. theseider dupre＞. generating on-board diagnostics of dynamic automotive systems based on qualitative deviations. ai communications  1 :1 1. also in proc. 1th int. workshop on principles of diagnosis  loch awe  scotland.
 console and dressler  1  l. console and o. dressler. model-based diagnosis in the real world: lessons learned and challenges remaining. in proc. 1th ijcai  pages 1  stockholm  1.
 console et al.  1  l. console  c. picardi  and d. theseider dupre＞. generatingtemporaldecision trees for diagnosing dynamic systems. in proc. dx 1  1th int. workshop on principles of diagnosis  morelia  1.
 darwiche  1  a. darwiche. on compiling system descriptions into diagnostic rules. in proc. 1th int. work.
on principles of diagnosis  pages 1  1.
 dvorak and kuipers  1  d. dvorak and b. kuipers. model-based monitoring of dynamic systems. in proc. 1th ijcai  pages 1  detroit  1.
 panati and theseider dupre＞  1  a. panati and d. theseider dupre＞. state-based vs simulation-based diagnosis of dynamic systems. in proc. ecai 1  1.
 quinlan  1  j. r. quinlan. induction of decision trees. machine learning  1-1  1.
 sachenbacher et al.  1  m. sachenbacher  a. malik  and p. struss. from electrics to emissions: experiences in applying model-baseddiagnosis to real problems in real cars. in proc. 1th int. work. on principles of diagnosis  pages 1  1.
model-based diagnosability and sensor placement 
application to a frame 1 gas turbine subsystem 
 
louise trav└-massuy┬s 
laas-cnrs and lea-sica  1 avenue du colonel-roche  1 toulouse  france louise laas.fr 
 
teresa escobet 
upc and lea-sica  automatic control department  universitat polit┬cnica de catalunya   terrassa  barcelona  spain teresa eupm.upc.es 
 
robert milne 
intelligent applications ltd  1 michaelson square  livingston  west lothian. scotland. eh1dp rmilne bcs.org.uk  
 
abstract 
this paper presents a methodology for: assessing the degree of diagnosability of a system  i.e. given a set of sensors  which faults can be discriminated  	and; 	characterising 	and determining the minimal additional sensors which 	guarantee 	a 	specified 	degree 	of 
diagnosability. this method has been applied to several subsystems of a general electric frame 1 gas turbine owned by a major uk utility. 
1 	introduction 
it is commonly accepted that diagnosis and maintenance requirements should be accounted for at the very early design stages of a system.  for this purpose  methods for analysing 	properties 	such 	as 	diagnosability 	and characterising the instrumentation system in terms of the number of sensors and their placement are highly valuable. there is hence a significant amount of work dealing with this issue  both in the dx community  console et al.  1  and in the fdi community  gissinger et al.  1 . 
this paper proposes a methodology for: 
  assessing the diagnosability degree of  a system  i.e. given a set of sensors  which are the faults that can be discriminated  
  characterising and determining the minimal additional sensor sets  mass  that guarantee a specified diagnosability degree. 
 the analysis for a given system can be performed at the design phase  allowing one to determine which sensors are needed  or during the operational life of the system  the trade off if not installing more sensors.  
 the main ideas behind the methodology are to analyse the physical model of a system from a structural point of view. this structural analysis is performed following the approach by  cassar and staroswiecky  1 . it allows one to derive the redundant relations  i.e. those relations which produce the analytical redundant relation  arr   cordier et al.  1 .  
 our contribution builds on these results and proposes to derive the potential additional redundant relations resulting from the addition of one sensor. all the possible additional sensors are examined in turn and a hypothetical fault signature matrix is built. this matrix makes the correspondence between the additional sensor  the resulting redundant relation and the components that may be involved. the second step consists of extending the hypothetical fault signature matrix in an extended hypothetical fault signature matrix that takes into account the addition of several sensors at a time. this later matrix summarises all the required information to perform a complete diagnosability assessment  i.e. to provide all the masss which guarantee the desired discrimination level.  
 this work is related to  maquin et al.  1; carpentier et al.  1 . similarly  it adopts the single fault and exoneration-working hypothesis in the sense that it is assumed that a faulty component always manifests as the violation of the redundant relations in which it is involved. however  unlike  maquin et al.  1  that only deals with sensor faults  our approach allows us to handle faults affecting any kind of component. 
this method has been applied to several subsystems of a 
general electric  ge  frame 1 gas turbine owned by 
national power in the framework of the european trial applications tiger sheba project. this paper focuses on the gas fuel subsystem  gfs  for illustrating the method. 
1 	the ge frame 1 gas turbine 
national power is one of the major electricity generating companies in the uk and its cogen wholly owned subsidiary specialises in gas turbine driven power stations providing electricity and steam. their aylesford newsprint site  located just southeast of london generates 1 mw of electricity for the national grid as well as providing steam to an adjacent paper re-cycling plant. the gas turbine is a general electric frame 1 and has been monitored by the tiger tm  software for over three years  milne and nicol  1 . 
 the original tiger esprit project  milne et al.  1  has been developed into the tiger gas turbine condition monitoring software product. currently over 1 systems are installed on 1 continents  include 1 systems on offshore oil platforms.  
 the first prototype tiger installation included the ca~en qualitative model based diagnosis system  trav└-massuy┬s and milne  1   but this was not deployed in the first commercial installations of tiger. the sheba project brought ca~en back into tiger with a full-scale demonstration of its capabilities and benefits on a frame 1 gas turbine. this improved tiger's capabilities by a more precise prediction of expected behaviour  from qualitative prediction  and the addition of model based fault isolation to complement the existing rule based diagnosis techniques. shortly after the project started  it became clear that the sensors which were installed would limit the diagnosis. hence work was begun to understand the gains that could be made from additional sensors. although this problem is discussed in the context of a specific site  it is a widespread important issue in many industries. 
1 	gas fuel subsystem  gfs  

figure 1 - flow diagram of the ge frame 1 turbine gfs 
 
 the main components of the gfs are two actuators: the stop ratio valve  srv  and the gas control valve  gcv . 
these valves are connected in series and control the flow of gas fuel that enters in the combustion chambers of the turbine. the first of these valves  the srv  is controlled by a feedback loop that maintains constant gas pressure at its output  pressure between the two valves  fpg1. this pressure being constant  the gas fuel flow is just determined by the position of the gcv. hence  the gcv is a positioncontrolled valve. the gfs diagram in figure 1 shows the variables  low case letter symbols  and the components  capital letter symbols . for the two valves gcv and srv  hydraulic and mechanical aspects have been distinguished  marked  h  and  m  . 
 for the gfs  the user's specifications state to consider faults on components: gcvm  gcvh  srvm  srvh  injectors and some transducers. the set of faults is hence given by fgfs={gcvm  gcvh  srvm  srvh  injt  tfsg  tfsgr  
tfqg  tcpd}. 
1 	a structural approach for analytical redundancy 
the model of a system can be defined as a set of equations  relations  e  which relate a set of variables x： xe  where xe is the set of exogenous variables. in a component-oriented model  these relations  called primary relations  are matched to the system's physical components. the structure of a model can be stated in a so-called structural matrix. 
 definition 1  structural matrix  let's define a matrix sm whose rows correspond to model relations and columns correspond to model variables. the entries of sm are either 1 or x: sij is x if and only if the variable in column j is involved in the relation in row i  it is 1 otherwise. then  s is defined as the model structural matrix. 
 from the model structure  it is possible to derive the causal links between the variables  iwasaki and simon  1; trav└-massuy┬s and pons  1 . these links account for the dependencies existing among the variables. given a self-contained system s =  e  x  formed by a set of n equations  relations  e in n variables x and the context of the system given by the set of exogenous variables  the problem of causal ordering is the one determining the dependency paths among variables which would indicate in which order every equation should be used to solve successively for the n unknown variables. 
 the problem of computing the causal structure can be formulated in a graph theoretic framework; it is then brought back to the one of finding a perfect matching in a bipartite graph g= e ： x  a  where a is the set of edges between variables and equations  port└ et al.  1 . the system being self-contained  the perfect matching associates one variable to one equation. a similar method is used in the fdi community to obtain a so-called resolution process graph  rpg .  cassar and staroswiecki  1  have shown that this graph can be used to derive the redundant relations within a structural analysis approach.  
 given a system s= e x： xe   the set of variables x can be partitioned as x=u： o  where o is the set of observed  measured  variables and u is the set of unknown variables. then  the structural approach of  cassar and staroswiecki  1  is based on determining a perfect matching in the bipartite graph g= e： u  a   i.e. between e and u. given the perfect matching c  the rpg is the oriented graph obtained from g= e： u  a  by orienting the edges of a from xi towards ej if a i j  ・ c and from ej towards xi if a i j    c. 
 obviously  the number of relations in e is greater or equal to the number of unknown variables. if it is greater  then some relations are not involved in the perfect matching. these relations appear as sink nodes  i.e. without successors  in the rpg. 
 definition 1  redundant relation  a redundant relation 
 rr  is a relation which is not involved in the perfect matching in the bipartite graph g= e： u  a . 
 rrs are not needed to determine any of the unknown variables. every rr produces an analytical redundant relation  arr  when the unknown variables involved in the rr are replaced by their formal expression by following the analytical paths defined by the perfect matching. these paths trace back variable-relations dependencies up to the observed variables. an arr hence only contains observed variables and can be evaluated from the observations  cordier et al.  1 . 
1 	redundant relations for the gfs 
a component-oriented model for the gfs was completed. for every component  the behavioural relations refer to generic component models  trav└-massuy┬s and escobet  1 . the structural matrix of the gfs model  including 1 primary relations  is given in table 1  transducers are not included . 
 

table 1 - gfs structural matrix 
 
 in table 1  a shaded column indicates that the variable is exogenous. although some internal variables have sensoare measured  let us perform the analysis as if we were at the design stage  i.e. as if the set of sensors s=  . the gfs is hence characterised by e={ri / i=1 ... 1}  xe={p1  cpd  1hq1  fsrout  fpgrout}  x=u： o where u={fpg1  p1  fqg  q1  q1  q1  fag  fagr} and o=  .  
 a perfect matching has been determined between e and u. the entries involved in the perfect matching are indicated by circles. this indicates that there is a redundant relation: r1.
1 a structural approach for diagnosability and partial diagnosability 
in this section  a method for determining the diagnosability degree of a system and the potential mass is presented. the structural analysis results from  cassar and staroswiecki  1  presented in the last section constitute the starting point of our method. the analysis can be performed at the design stage  starting from no sensors at all  s=     to design the instrumentation system  or during the operational life of the system  allowing us to determine the alternative mass to be added to the set of  existing sensors.  let's first introduce a set of definitions which are used in the following.  
 definition 1  diagnosability   console et al.  1  a system is diagnosable with a given set of sensors s if and only if  i  for any relevant combination of sensor readings there is only one minimal diagnosis candidate and  ii  all faults of the system belong to a candidate diagnosis for some sensor readings.   
 the definition above from  console et al.  1   characterises full diagnosability. however  a system may be partially diagnosable.    
 definition 1 a fault f1 is said to be discriminable from a fault f1 if and only if there exists some sensor readings for which f1 appears in some minimal diagnosis candidate but not f1  and conversely.  
 given a system s and a set of faults f  the discriminability relation is an order relation which allows us to order the faults: two faults are in the same d-class if and only if they are not discriminable. let's note d the number of such classes. 
 partial diagnosability can now be characterised by a diagnosability degree. 
 definition 1  partial diagnosability - diagnosability degree  given a system s   a set of sensors s  and a set of faults f  the diagnosability degree d is defined for the triple  s  s  f  as the quotient of the number of d-classes by the number of faults in f  i.e. d=d/card f . 
 proposition 1 the number of d-classes d of a  fully  diagnosable system is equal to the number of faults  card f . 
 a fully diagnosable system is characterised by a diagnosability degree of 1. a non-sensored system is characterised by a diagnosability degree of 1. 
 definition 1  minimal additional sensor sets  given a partially diagnosable triple  s  s  f   an additional sensor set is defined as a set of sensors s such that   s  s： s  f  is fully diagnosable. a minimal additional sensor set is an additional sensor set s such that   s '  s  s ' is not an additional sensor set.  
 our method is based on deriving the potential additional redundant relations resulting from the addition of one sensor. all the possible additional sensors are examined one by one and a hypothetical fault signature matrix is built. this matrix makes the correspondence between the additional sensor  the resulting redundant relations and the components that may be involved. this is obtained from an and-or graph which is an extension of the rpg. the second step consists in extending the hypothetical fault signature matrix in an extended hypothetical fault signature matrix that takes into account the addition of several sensors at a time. this later matrix summarises all the required information to perform a complete diagnosability assessment  i.e. to provide all the masss that guaranty full diagnosability. 
1 	and-or graph 
our method stands on building an and-or graph by extending the rpg with the hypothetical sensors. the andor graph states the flow of alternative computations for variables  starting from exogenous variables. to solve a relation ri for its matched variable  all the ri's input variables have to be solved  and . an input variable may have several alternative computation pathes  or .   the and-or graph is made of alternated levels of variables and relations. a variable node is associated an or  for the alternative ways to obtain its value  whereas a relation node is associated an and  meaning that several variables are necessary to instantiate the relation. every relation is labelled with its corresponding component. 
1 	 hypothesising sensors: one at a time 
in the fdi terminology  the fault signature matrix crosses 
rrs  or arrs  in rows and  sets of  faults in columns  cordier et al.  1 . the interpretation of some entry sij being 1 is that the occurrence of the fault fj does not affect arri  meaning that arri is satisfied in the presence of that fault. sij = 1 means that arri is expected to be affected by fault fj  but it is not guaranteed that it will really be  the fault might be non detectable by this arr .  
 the arr-based exoneration assumption is generally adopted in the fdi approach  meaning that a fault is assumed to affect the arrs in which it is involved. hence  sij = 1 is interpreted as arri is violated in the presence of fault fj.  our approach adopts this assumption as well. 
 definition 1  hypothetical fault signature  hfs  matrix   the hypothetical fault signature matrix is defined as the set of fault signatures that would result from the addition of one sensor  this sensor being taken in turn from the set of all possible sensors. 
 the hfs matrix is determined by assuming that one more sensor is added to the existing ones. every line of the matrix corresponds to the hypothesised additional sensor  hsensor   reported in the first column. the result of adding one sensor is to provide one more redundant relation  h-rr for hypothetical rr   which corresponds to the relation matched  by the perfect matching  to the variable sensored by the h-sensor. the resulting h-rr is given in the second column.  
 zero entries are interpreted as for the fault signature. now  two types of non zero entries exist in the hfs matrix:  1  means that the component  fault  is necessarily involved in the corresponding h-rr and  x  means that the component may or may not be involved  depending on whether other sensors are added. 
 for a given unknown variable  the hfs matrix indicates that there are two ways to determine this variable: its hsensor or the computation tree for solving the corresponding h-rr. the computation tree is a sub graph of the and-or graph. its root is the unknown variable and its branches trace back the variable-relation dependencies down to the exogenous variables  and eventually the h-sensored variable . the hfs matrix entry values are obtained from the set of components whose corresponding relations take part in the computation tree. at this stage  the other h-sensors are used to decide whether the entry is  1  or  x . the hfs matrix for the gfs application is given in table 
1.  
 
h-sensors h-rr gcvm gcvh srvm srvh none r1 
table 1 - hfs matrix of the gfs 
 	 
 let us explain the row corresponding to h-sensored fag. the computation tree is given in figure 1. the components involved are gcvm  which receives a  1  because it is matched to the h-rr  r1  itself  and tfsg which receives an  x . indeed  the value of fsg may be obtained from the h-
sensor  involving tfsg  or from r1 which is also associated gcvm. 

figure 1 - computation tree for fag 
1 	hypothesising sensors: several at a time   
given that some non-zero entries of the hfs matrix may be  x   this means that every h-rr in the hfs matrix can have several instances depending on the whole set of additional sensors  every instance being conditioned by a given set of sensors. the isolability properties conditioned by the set of sensors for the whole system can be derived from the extended hfs matrix  ehfs matrix  which states all the possible instances of the h-rrs in the hfs matrix. 
 the ehfs can be generated from the or-and graph  by analysing all the alternative computation trees.  
 the different instances of a h-rr  irr as instantiated rr  are obtained from the and-or graph by following the alternative paths for obtaining its associated variable. when a relation is in the path  its corresponding component receives a  1  instead of the  x . when a sensor is in the path  it is recorded in the sensor conditions column. this is summarised in the ehfs matrix.  
the following table provides the partial ehfs matrix for the irr corresponding to the h-rr r1. 
 

table 1 -  partial  ehfs matrix for the gfs 
 
 the full ehfs matrix for the gfs contains 1 irrs and summarises all the required information to perform a complete diagnosability assessment.  
1 	diagnosability assessment 
the ehfs matrix allows us to exhaustively answer the question:  which additional sensors are necessary and sufficient  minimal additional sensor sets  to guarantee maximal diagnosability  maximal discrimination between the faults   . 
1 	component involvement 
 definition 1  component involvement  the rows of the fault signature matrix of a system  s  s  f  and similarly  the rows of the ehfs matrix are defined as component involvement vectors. in the ehfs matrix  row i is the component involvement vector of irri. 
 corollary 1 under the arr-based exoneration assumption  two irrs that have the same component involvement vector have the same fault sensitivity.  
the proof is trivial and is omitted. 
 the irrs can be grouped in equivalence classes corresponding to the same component involvement vector  i.e. the same rows in the ehfs matrix. 
1 	alternative fault signature matrices 
we have the following result: 
 proposition 1 under the arr-based assumption and given a partially diagnosable triple  s  s  f   the number of d-classes of  s  s  f  is given by the structural rank  trav└ et al.  1  of its fault signature matrix.  
 from the above result and definition 1  one can derive the diagnosability degree of  s  s  f . 
 definition 1  alternative fault signature matrices  given a set of faults f of cardinal n  the alternative fault signature  afs  matrices are given by all the possible xxn matrices composed by the component involvement vectors corresponding to rrs  i.e. from the actual fault signature matrix  and the addition of a selection of component involvement vectors from ehfs  where x is = to the number of actual rrs.  
we can now state the following result: 
 proposition 1 under the arr-based exoneration assumption and given a system s  s  f  with card f =n  the maximal diagnosability degree is obtained for the maximal structural rank among the afs matrices. 
 proposition 1 under the same assumptions as proposition 1 and given a maximal rank fault signature matrix  the corresponding mass is obtained as the conjunction of the sensor conditions associated to the irrs belonging to this fs matrix.  
due to space constraints  the proofs are not included. 
1 	sensors 	for 	achieving 	maximal 	diagnosability in the gfs 
for the gfs application  the questions that have been answered are: 
  which are the components that can be discriminated using the currently available sensors  i.e. which is the diagnosability degree of the actual system    which are the necessary and sufficient additional sensors that guarantee maximal diagnosability  i.e. maximal discrimination between the 1 faults  
 referring to the first question  given the set of actual sensors on the gfs sgfs={fpg1  fqg  fsg  fsgr}  the method allowed us to assess that the fault signature matrix structural rank is 1  implying that only 1 components can be discriminated. a closer look made clear that gcvh  injectors and tcpd were the components that could not be discriminated. 
the actual diagnosability degree of  gfs  sgfs  fgfs  is hence 1.  
 let us now consider the second question. obtaining maximal discrimination between the 1 faults comes back to obtaining maximal discrimination between {gcvh  injectors  tcpd}. the different component involvement vectors with respect to gcvh  injt and tcpd and their corresponding irrs can be determined. this allowed us to assess that the maximal structural rank that can be achieved by the fs matrix when selecting a relevant set of component involvement vectors is 1. it can be noticed that the involvement of 
injt and tcpd in the irrs is always identical  implying that these can never be discriminated  given the considered set of sensors. however  discrimination can be obtained between gcvh and {injt  tcpd}. since the structural rank of the actual fault signature matrix is 1  it is hence enough to select one appropriate component involvement vector from the ehfs matrix to be added to those arising from the available sensors. two solutions exist. the first provides one possible mass: {s p1   s q1 }. the second provides two possible masss: {s q1   s q1 } and {s p1 }. 
 hence  the  minimal  solution guaranteeing maximal diagnosability in the gas fuel system is to add one pressure sensor on p1.  
 for more details about the application of the method to the gfs  the reader can refer to  trav└-massuy┬s et al.  1 . 
1 	conclusions 
a key issue for practical diagnosis in industry is the trade off of installing the minimal sensors  but getting a high degree of fault isolation and diagnosis. in order to keep costs down  industrial systems are typically configured with the minimum set of sensors needed for control and protection. long experience has shown that this standard set of sensors creates many limitations on how well faults can be diagnosed. what industry needs is better information to base the trade-off decision on. what do i gain for each possible additional sensor  
  in this paper  we have presented a methodology for showing what gains in diagnosis can be made with which additional sensors. this is accomplished by analysing the system from the model based diagnosis viewpoint  given a set of faults which it is desirable to diagnose. the approach has been illustrated through the gas fuel system of a general electric frame 1 gas turbine  based on an actual turbine being monitored by the tiger tm  software in the uk. 
 this approach can be very beneficial to industry. by being able to understand the gains to be made at the cost of a few more sensors  there is a real chance to instrument complex systems for not only control  but also diagnosis. the possible cost savings are substantial  not just from the direct gains in diagnosis  but in the better design of systems and the ability to design systems which will be more robust.  
acknowledgements 
this work was performed in the european community trial 
application project no: 1  tiger sheba. we thank national power cogen and their aylesford site and the other partners: intelligent applications  kvaerner energy  laas-cnrs and upc. tiger is a registered trademark of intelligent applications. 
references 
 carpentier et al.  1  t. carpentier  r. litwak and j.p. cassar.  criteria for the evaluation of f.d.i. systems application to sensors location. in proc. of safeprocess'1 workshop  hull  uk  1. 
 cassar and staroswiecki  1  j.p. cassar and m. stroswiecki. a structural approach for the design of 
failure detection and identification systems . in proc. 
ifac  ifip  imacs conference on 'control of industrial ifip  imacs conference on 'control of industrial systems'  belfort  france  pages 1  1. 
 console et al.  1  l. console  c. picardi and m. ribando. diagnosis and diagnosability analysis using 
process algebra. in proc. of dx'1  morelia  mexico  june 1. 
 cordier et al.  1  m.o. cordier  p. dague  f. l└vy  m.  
dumas  j. montmain  m. staroswiecki and l. trav└massuy┬s. a comparative analysis of ai and control theory approaches to model-based diagnosis. in proc. 
of ecai'1  berlin  germany  1. 
  gissinger et al.  1  g.l. gissinger  m. loung and h.f. reynaund. failure detection and isolation - optimal design of instrumentation system. in proc. of safeprocess 1  budapest  hungry  1. 
  iwasaki and h. simon  1  y. iwasaki and h. simon  causality and model abstraction. artificial intelligence  1  n＜1  1  1. 
  maquin et al.  1  d. maquin  m. luong and j. ragot. some ideas about the design of measurement systems. in proc. of ecc'1  rome  italy  1. 
  milne et al.  1  r. milne  c. nicol  l. trav└-massuy┬s  j. quevedo. tiger tm : knowledge based gas turbine condition monitoring. ai communications journal  vol 1  no 1  1.  publishers ios press  1.  
 milne and nicol  1  r. milne and c. nicol.  tiger tm : 
continuous diagnosis of gas turbines. in proc. of ecai/pais'1  edited by werner horn  berlin  1. 
 port└ et al.  1  n. port└  s. boucheron  s. sallantin  f. 
arlabosse. an algorithmic view at causal ordering. in 
proc. of int. workshop on qualitative physics qr'1  paris  france  1. 
 trav└-massuy┬s and escobet  1  l. trav└-massuy┬s and t. escobet. tiger deliverable 1 'ca~en models testing - fep'  laas-cnrs report  toulouse  france  1. 
 trav└-massuy┬s and milne  1  l. trav└-massuy┬s and r. milne. gas turbine condition monitoring using qualitative model based diagnosis. ieee expert magazine  'intelligent systems & their applications'  vol 1  no 1  1.  publishers: ieee computer society  1.   
 trav└-massuy┬s and pons  1  l. trav└-massuy┬s and 
r. pons. causal ordering for multiple mode systems .  in proc. of qr'1 workshop on 'qualitative reasoning about physical systems'   cortona  italy  1. 
 trav└ et al.  1  l. trav└-massuy┬s  a. titli  and a.m. tarras.  large scale systems: decentralisation  structure constraints  and fixed modes. lecture notes in control and information sciences  vol. 1  1  springer-verlag  1. 
 trav└-massuy┬s et al.  1  l. trav└-massuy┬s  t. escobet and r. milne. model based diagnosability and sensor placement - application to a frame 1 gas turbine subsystem. in proc. of dx'1  sansicario  italy  march 1.  
distributed monitoring of hybrid systems: a model-directed approach
feng zhao and xenofon koutsoukos and horst haussecker
james reich and patrick cheung
xerox palo alto research center
coyote hill road
palo alto  california 1  u.s.a.
claudia picardi
dipartimento di informatica
universita di torino
corso svizzera 1  1 torino  italyabstract
thispaper presentsan efficientonlinemodeestimation algorithm for a class of sensor-rich  distributed embedded systems  the so-called hybrid systems. a central problem in distributed diagnosis of hybrid systems is efficiently monitoring and tracking mode transitions. brute-force tracking algorithms incur cost exponential in the numbers of sensors and measurements over time and are impractical for sensor-rich systems. our algorithm uses a model of system's temporal discrete-event behavior such as a timed petri net to generate a prior so as to focus distributed signal analysis on when and where to look for mode transition signatures of interest  drastically constraining the search for event combinations. the algorithm has been demonstrated for the online diagnosis of a hybrid system  the xerox dc1 printer.
1	introduction
manyman-made electro-mechanical systems suchas automobiles or high-speed printers are best described as hybrid systems. the dynamics of a hybrid system comprises continuous state evolution within a mode and discrete transitions from one mode to another  either controlled or autonomous. a mode of an automobile could be an acceleration phase or a cruising phase. a printermay have a paper feeding phase followed by a registrationphase. withineach mode  the dynamics of a system is governed by a continuousbehavioralmodel. undera controlsignal suchas gear shift thesystemmay transitiontoadifferentoperatingmode. certaintransitionsareautonomous due to system state reaching a threshold value. for example  when a paper feed roll contacts a sheet of paper  the paper starts to move.
　diagnosis of a hybrid system requires the ability to monitor and predict system behaviors and detect and isolate faults.
the monitoring task involves estimating and tracking system state and is at the heart of hybrid system diagnosis. in a sensor-rich environment  the monitoring task is significantly complicated by the need to associate data from multiple sensors withmultiplehypotheses of states  modes  or faults. this is particularly true for distributed detection and diagnosis in large complex systems such as highway traffic monitoring or large print shop fault diagnosis where the numbers of sensors and system components can potentially be very large  1 - 1 or more . recent advances in micro-electromechanical systems  mems  and wireless networking have enableda newgenerationof tiny inexpensive  wirelesslyconnectedmemssensors. asshowninsection1 thecomplexity of brute-force monitoringschemes is exponential in the numbers of sensors and measurements over time and is clearly not scalable. our algorithm addresses this computational problem.
　monitoring of hybrid systems has two components  mode estimation and  continuous  state tracking. once a system is estimated to be in a particular mode  a continuous state estimatorsuch as kalman filtercouldbeused totrackthe continuous state. this paper focuses on the more difficult problem of mode estimation and its applicationto sensor-rich  distributed hybrid system monitoring and diagnosis.
　example. consider the problem of workflow identification and fault diagnosis in a document processing factory  or print shop   where multiple printing  collating  and binding machines may be placed in proximity of each other. the objective is to identify critical printing job and machine operating parameters for online workflow scheduling and fault diagnosis. an example of the printing equipment is the xerox document center dc1 printer  a multifunction system that prints at 1 pages per minute  fig. 1 . the system is made of a large number of moving components such as motors  solenoids  clutches  rolls  gears  belts and so on. a fault of  no paper at output  may be caused by abrupt failures such as a broken transfer belt. paper jams are often caused by subtler component degradation such as roll slippage or timing variations of clutch  motor or solenoid due to wear  some of whichisnotdirectlyobservablewiththesystem'sbuilt-insensors and must be estimated using system behavioral model and additional sensor information. the printer is an example of a hybrid system as is illustrated here using its paper feed subsystem. a component such as the feed motor may be in any one of the ramp-up  rotating with constant speed  rampdown  stationarystates  each of whichisgovernedbycontinuous dynamics. mode transitions are induced by either control events or evolution of the continuous dynamics. for example  the transition from stationary to ramp-up for the motor is caused by  turn motor on controleventandcan beestimated using the control event and sensor signal. however  a transition such as acquisitionroll contacting a paper is autonomous and must be estimated using model and sensor data.

figure 1: print shop with multiple machines such as a xerox dc1 printer.

figure 1: acoustic signal for a one-page printingoperation of dc1 printer.
　in this example  estimating the timing of the roll contactingpaper requirestosingleoutthe solenoidpull-inevent from incoming sensor data streams. the paper path system of the printer has 1 motors  1 solenoids  1 clutches  and a large number of gears connecting the motors to different rolls and belts. the testbed to be detailed in section 1 uses 1 sensors  each sampled at 1 times per second. many of the system components may be active around the time of solenoid pullin - the so-called cocktail party phenomenon in speech processing  fig. 1 . moreover  other machines may be active in an environment such as a print shop. as the number of event hypotheses scales exponentiallywith the numbers of sensors  system components  and measurements  section 1   pulling the relevant events out of a large number of high-bandwidth data streams from a multitude of simultaneous sources is a tremendous computational challenge - the main computationalproblem this paper addresses. signature analysis techniques such as  hung and zhao  1  could not immediately be applied to mode estimation withoutusing a model to focus on when to acquire data and where to look for events.
　thispaperdescribes anefficientmode estimationalgorithm for hybrid systems. the algorithm integrates model-based prediction with distributed signature analysis techniques. a timed petri net model represents the temporal discrete-event behavior of a hybrid system. the model generates event predictions that focus distributed signal processing on when and where to look for signatures of interest  and estimation of signatureinturnrefinesandupdatesmodelparameters andstates. the algorithmis novel in its use of model knowledge to drastically shrink the range of a time-domain search for events of interest  and has been experimentally validated on a multisensor diagnostic testbed.
　monitoring and diagnosis of hybrid systems are an active research area. existing approaches to hybrid system monitoring and diagnosis do not address the computational data association problem associated with distributed multi-sensor systems  bar-shalom and fortmann  1  and assume sensor outputhasalreadybeenproperlyassembled toformlikelihood functions of system output. moreover  they assume either no autonomous mode transition or autonomous transition without signal mixing.  lerner et al.  1  described a bayesian network approach to tracking trajectories of hybrid systems. they introduced a method of smoothing that backward propagates evidence tore-weighearlier beliefs soas toretainweak but otherwise important belief states withoutexplicitly tracking all the branches over time.  kurien and nayak  1  addressed the temporal branching problem in tracking using a consistency-based generation and revision of belief states in a partially observable markov decision process formulation.  mcilraith  1  described a particle filter approach to tracking multiple models of behaviors. qualitative diagnosis techniques such as  mcilraith et al.  1  are used to provide a temporalpriortofocusthe samplingofparticlefilteronpartof the distributionconsistent with the model prediction. in contrast  our approach exploits model knowledge of control and discrete-event behaviors of hybrid systems to address the exponentialblow-upindataassociationofmulti-sensorobservation  as well as the complexity due to multiple measurements over time.
　the rest of the paper describes three main contributions of this work: section 1 presents a formulation of the mode estimation problem for distributed monitoring of hybrid systems and its computational challenges. section 1 describes the mode estimation algorithm for both controlled and autonomous mode transitions. the algorithm has been demonstrated as part of a diagnosis system for the xerox dc1 multifunction printer and experimental results are presented in section 1.
1	hybrid system mode estimation problem
in the mode estimation problem we consider  a hybridsystem is described by a 1-tuple:   where is the continuousstate space of the system  is the mode space  set of discrete states   is the space of sensor signals  isthe set of possible control inputs to the system 
　　　is the transitionfunction  and	is the observation function.
　the mode space can be understood as the product of individual component modes of an -component system  with each mode vector denoted as .
for an -sensor system  the sensor output vector is
               where is the output of sensor . each could be a measure of a signal from component mode
alone or a composite signal of multiple components.
　the problem of mode estimation in a multi-sensorenvironment can be stated as follows. at each time step   given the previousmode estimate at and currentobservation mode estimation is a mapping:
 1 
equivalently  the mode estimation problem is to estimate
such that	  and	  i.e.  the time instance when one or more component modes have changed.
　mode transitionsinduced by external control events can be estimated using the control events and sensor signals. autonomous transitions must be estimated using a combination of system model  control event sequence  and sensor signals.
　to estimate   components of contributed by mode components 's must be associated with the 's in order to determine if there is a transition for   and if so  what the parameters  such as transition time  are. we illustrate the computational difficulties of data association for the hybrid system mode estimation problem for two cases.
　case i. assume there is no signal mixing and each measures a signal from system component only. the number of possible associations of 's with the corresponding 's is   that is  it is exponentialinthe number of sensors at each time step.
　case ii. more generally  each sensor signal measures a composite of 's through a mixing function: . without prior knowledge about   any combination of 's could be present in 's. pairing each with 's creates associations. the total number of associations of with is
　　　　　  i.e.  exponential in the numbers of sensors and signal sources.
　for applications such as diagnosis  it is often necessary to reason across multiple time steps and examine the history of mode transitions in order to identify a component fault oc-
curred in an earlier mode. each pairing of observation with mode vector in the above single-step mode estimation creates a hypothesisofthesystem mode transitionsequence. asmore observations are made over time  the total number of possible mode transition sequences is exponential in the numbers of sensors and measurements over time.
1	an online mode estimation algorithm
the objectiveof mode estimationistoestimate the mode transition sequence of a hybrid system:
where . each transitionis caused by one or more mode transitions of components of .
　assuming each sensor output is a linear superposition of possibly time-shifted 's
 1 
or more compactly 
 1 
where is an mixing matrix with elements and is the sampling function. the operator denotes element-wise convolutionin the same way matrix-vector multiplication is performed.
　in particular  when represents the signalevent characteristic of the mode transition   the mode estimation problem is then to determine   the onset of the signal event   and   the contributionof tothe compositesensor output . a common physical interpretation for the mixing parameters and is that characterizes signal arrival time at each sensor  and sensor gain for each sensor.
	the	following mode	estimation algorithm computes
　　　　　　  the posterior probability distribution of and given observation   iterating through the following three steps:  1  use a model of system behaviors to generate a temporal prior of transition events within the time window associated with the current time step;  1  decompose sensor observation as a sum of component signal events   and computethe likelihoodfunction
　　　　　　;  1  compute the posterior probability distribution of the mode transition using bayesian estimation and update the mode vector. the algorithm is suited for a distributed implementation. assume each node stores a copy of signal component templates . at each step  a few global nodes broadcast the model prediction  and each node locally performs signal decomposition  likelihood function generation  and bayesian estimation.
mode estimation algorithm
initialize	; for
 1  prediction:
 1  signal decomposition and likelihood generation:
	where	;


	where	is the covariance matrix for	;
 1  update:

　　when the signals are nonlinearly superposed  then a nonlinear source separation method must be used.
end
　to address the problem of exponential blowup in data association described earlier  modelprediction uses a model to predict signal events that are present within a time window  thus focusing the signal event localization and association on just the predicted subset of events. a variety of models such as timed finite automata or petri nets  section 1  could be used to generate a prior. other possible candidates include partially observable markov decision processes and dynamic bayesian nets suitably modified to encode both discrete and continuousvariables. signal decomposition and bayesian estimationidentifythe signalevents thatare most likelypresent  thus eliminating the exponential factor in associating events withcomponentmodes. thetrackingcostislinearinthenumber of measurements over time. nextmode updates the mode vector with the identified mode parameters and . alternatively  instead of keeping only the most likely events accordingto posterior  thealgorithmcould be extended to maintain less likely events by propagating the full posterior distributionand usingtechniques such as backtracking  kurien and nayak  1  or smoothing  lerner et al.  1  to manage the branching complexity.
　the notation in the algorithm represents the observation within a time window of interest. in the signal decomposition	    are the so-called signal event templates that characterize 's and are constructed from training data.
　the model predicts what combinations of signal components are present  the 's  and how they are appropriately shifted the 's withinthe time windowofinterest. given the parameters and   the likelihood functions for sensors are assumed to be independent of each other. since each signal templatehas a non-zerofinitelength itisnecessary toaccount for adjacent signal events spillingfrom the previous time step into the current time window. given an observation  the parameters and are determined by maximizing the posterior in bayesian estimation.
　for simplicity  the likelihood functions are assumed to be gaussian. for non-gaussian  multi-modal priors and likelihood functions  techniques such as mixture models or particle filter  also known as sequential monte carlo or condensation  could be used to represent and propagate probabilistic evidence.
　the algorithmexploitsa temporal priortomanage thecomputationalcomplexityin mode estimation. likewise  a spatial prior could also be exploited to associate each with one or a small number of identifiable signal sources 's  using techniques such as beamforming in a multi-sensor system.
1	experiment: an application to diagnosis of dc1 printer
wehave prototypedadiagnosissystem comprisingthreemain components: timed petri net model  mode estimation  and decision-tree diagnoser  fig. 1 .
　discrete-event data from built-in sensors and control commands of the printerare used to drive the petri net model. the

figure 1: architecture of the prototype diagnosis system.
model compares observed sensor events with their expected values. when a fault occurs  the deviation from the petri net simulationtriggersthe decision-treediagnoser. the diagnoser either waits for the next sensor event from the petri net or queries the mode estimator for a particular event  depending onthe next test. the mode estimator requests a temporalprior from the petri net  uses the prior to retrieve the segment of the signal from appropriate sensors  and computes the posterior of the event. the petri net uses the event posterior to update model parameters  generate a deviation of the event parameter for the diagnoser  and the process iterates until there are no more sensor tests to perform and the diagnoser reports the current fault candidates.
1	experimental testbed
we have instrumented an experimental testbed  the xerox document center 1st printer  fig. 1   with a multi-sensor data acquisition system and a controller interface card for sending and retrieving control and sensor signals. the monitoringand diagnosisexperimenttobe discussed inthissection will focus on the paper feed subsystem  fig. 1 .
　the function of the paper feed system is to move sheets of paper from the tray to the xerographic module of the printer  orchestrating a number of electro-mechanical components such as feed and acquisition rolls  feed motor  acquisition solenoid  elevator motor  wait station sensor  and stack height sensor. the feed motor is a 1v dc motor that drives thefeed andacquisitionrolls. the acquisitionsolenoidisused to initiatethe feeding of the paper by lowering the acquisition rollontothe topof the paper stack. the elevator motoris used to regulate the stack height at an appropriate level. the wait station sensor detects arrival of the leading or trailingedge of the paper at a fixed point of the paper path. the stack height sensorisused todetectthe positionofthepaper stack andcontrols the operation of elevator motor.
　in the experimental setup  in additionto the system built-in sensors  audio and current sensors are deployed for estimating quantities not directly accessible  so-called virtual sensors sampath et al.  1  . a 1-microphonearray is placed next to the printer. ground return currents of various subsystems of the printerare acquired using three 1 inlineresis-

figure 1: paper feed system of xerox dc1 printer
tors. sensor signals are acquired at 1k samples/sec/channel and 1 bit/sample by a 1-channel data acquisition system.
　the printer is designed such that control and sensor signals are passed between thecontrollerandprintercomponents through a common bus. by using an interface card these controland sensor signals can be accurately detected and mapped to the analog data acquired by the data acquisition system. another controllerinterface card is used to systematically exercise components of the printerone at a time in order tobuild individual signal templates required by the mode estimation algorithm.
1	prediction using a timed petri net model
we use a timed petri net to model temporal discrete-event behaviorof hybridsystems instead of finiteautomata for the following reasons. first  petri nets offer significant computational advantages over concurrent finite automata when the physical system to be modeled contains multiple moving objects. for example  it is desirable for a model of printer to compactly describe multiple sheets of paper and a variable number of sheets in a printing operation. second  petri nets can be used to model concurrency and synchronizationin distributedsystems very efficiently withoutincurringstate-space explosion. hybrid system models based on petri nets have been developed  for example  in  koutsoukos et al.  1 .
　the dynamics of a petri net is characterized by the evolutionof a marking vector referred to as the state of the net. the marking vector represents the mode of the underlying hybrid system and is updated upon firing of transitionssynchronized with system events. in a timed petri net  transitionfirings can be expressed as functions of time. a timed petri net can be used to monitor a physical system by firing some of the transitionsin synchronizationwith external events. in this case  a transitionisassociated withan externaleventthatcorresponds to a change in state of the physical system. the firing of the transitionwilloccur when the associated event occurs and the transition has been enabled.
　here  we associate with each transition a firing time domain . the transitionis enabled when all its input places are marked  but the firing of the transition occurs at a specific time instant within the time domain. the advantage of this formalism is that it takes into consideration stochastic fluctuations in the time duration of physical activities in the system. if statistical information for the firings of the transitionisprovided thenthefiringtimedomaincanbe augmented with a probability distribution characterizing the time instant the transition fires after it has been enabled. the model can be used to generate temporal priorprobabilitydistributionfor the occurrence of autonomous events.
　the petri net model of the normal operation of the paper feed system is derived from the control specification of the system  shown in fig. 1 . control commands issued by the controller and outputs of built-in sensors are external events for the appropriate transitions of the petri net. for example  the transition labeled by  acsl on  corresponds to the event  acquisition solenoid on  and will fire when the controller issues a command to energize the solenoid if it is enabled. the transitionlabeled by  dr ac rl  corresponds to the autonomous event  drop acquisition roll  that for the normal operation of the system should occur within a specified time interval from the time it was enabled. the transition labeled by  le s1  corresponds to the event the wait stationsensor detects the leadingedge of the paper and should alsooccur ina specified timeinterval. this timeintervalisderivedusing the motiondynamics of the paper according to the specifications. this transition is synchronized with the corresponding sensor signal from the physical system and is used to detect if the paper arrives late at the wait station sensor or does not arrive at all. this is accomplished by implementing a watchdog timer for the event based on the specifications of the paper feed system. it should be noted that the petri net of fig. 1 models the control logic of the paper feed system and can capture concurrent behavior for multiple sheets and multiple components in an efficient manner.
1	diagnoser
the diagnostic process consists of the following two steps. first  a fault symptom table is generated by a simulation of the hybrid system model of the paper feed system that parameterizes both abrupt and gradual failures. due to space limitations  interested readers should refer to  koutsoukos et al.  1  for details of the fault parameterization and the fault symptom table generation. alternatively  the fault symptom table could be derived from experimental methods such as fmea when feasible. second  a decision tree is compiled from the fault symptom table and it is then used as the diagnoser. the fault symptom table contains qualitative deviations of the sensor variables for different failure modes. individual measurements are labeled as normal   above normal   belownormal   maximumvalue   andminimum value . the minimum and maximum values are figure 1: petri net model of the paper feed system.
used to distinguish  for example  between a slow motor and a stalled motor. for real-time  embedded applications  the fault symptomtablecan becompactlyrepresented byacorrespondingdecisiontree using  forexample  theid1 algorithm quinlan  1 .
　inourdiagnosissystemwe have twotypesofsensors  builtin sensors that are always accessible with a low cost and virtual sensors that cannot be used directly in the diagnoser but require the invocation of the mode estimation algorithm. thus  the built-in sensors can be used for fault detection and trigger the diagnosis algorithm. the diagnoser will try to isolate the fault using only the built-insensors. if this is not possible  then it will use virtual sensors. in order to take into considerationthe sensor characteristics  we associate with the built-in sensors a cost equal to and with the virtual sensors a cost equal to . the objective of the decision tree generation algorithm is to minimize the weighted cost of the tree   where is the proba-
leaves
bility of a fault or faults corresponding to leaf of the tree and is the cost of sensor test at node of the path to . a decision tree minimizing the weighted cost is generated by applying the id1 algorithm in two phases. first  id1 builds a tree using only the built-in sensors. next  id1 is applied to leaf nodes of the tree with more than one faults  and generates subtrees for those leaves using the virtualsensors  see fig. 1 .
1	experimental results
the diagnosis system of fig. 1 has been demonstrated on four test fault scenarios  using the petri net model of the paper feed system  the automatically generated decision tree  and the mode estimation algorithm. the system  implemented in matlab running on a win1 pc  sequentially scans prerecorded data streams to emulate online monitoring. the four test cases involve a feed roll worn fault  labeled as  1  in the decision tree of fig. 1     a feeder motor belt broken fault   1    an acquisition roll worn fault   1    and a motor slow ramp-upfault  1    andcoveran interestingsubset ofsystemsystem.
level faults of the printer. these faults may cause a delayed paper or no paper at subsequent sensors. note the two  worn  cases are not directly observable. our algorithm isolates the faultsbyreasoning across several sensor teststo rule outcompeting hypotheses using the decision tree. the motor slow ramp-up fault could be directly observed by the corresponding virtual sensor test only at the cost of substantial signature analysis. instead  our algorithm uses less expensive system built-insensors to monitor and detect faults and only invokes virtual sensor tests on a when-needed basis.
　let's examine the trace of the diagnosis output for one of the fault scenarios. the paper arrives late at wait station sensor le s1. the arrival time is compared with the expected time to generate a qualitative deviation  +   which triggers the diagnosis. the value of le s1 rules out faults such as drive train broken. reading off of the decision tree  the next testte s1  trailingedge arrival time  isthen invokedand returns normal   1  . this rules out feed roll worn and motor slow ramp-up faults since both would cause the tailing edge late. nextonthedecisiontree  themore expensive acquisition solenoid pull-in time test  as.pt  is invoked. this calls the mode estimation algorithm to determine the transition time at which the acquisition roll contacts the paper  or equivalently  solenoid pull-in   an autonomous transition event. the compositesignalof one-page printingis shownin fig. 1. the estimation uses acoustic and current signal templates of solenoid  fig. 1  and motor  fig. 1  to compute a posterior probability distributionof the pull-inevent. using the petri net model prediction 1ms 1ms  to localize the event search  the estimation algorithm determines that the event is 1 ms later thanthe nominal value  well withinthe permissible range  see the peak location of posterior in fig. 1 . therefore  as.pt returns  1   and the only candidate remaining is the acquisition roll worn fault  which is the correct diagnosis. physically  the reduced friction between the worn acquisition roll and paper causes the leading edge of the paper late at le s1. but this does not affect the trailing edge arrival time since the paper stops momentarily when the sensor detects the leading edge  and moves again without using the acquisition roll. in contrast  a worn feed roll would cause the trailingedge to be late.
　the cost of the mode estimation algorithm scales linearly with the numbers of sensors and measurements when the mostly likely hypothesis is kept after each mode estimation. the cost of estimating is exponential in the number of active component sources predicted by the model  since it has to check combinations of active sources present in the signal. estimating employs a search for the maximum peak in the posterior in the mode parameter space. a brute-force search ofthespace iscomplete butatthecost exponentialinthenumber of predicted active component sources. a gradient-decent search significantly speeds up the search and usually terminates withina smallnumberofsteps  butatthe riskofpossibly convergingto local maxima. experimentally  the diagnosisof thefaultscenario describedabove was completedin1seconds for a sensor data sequence of 1 seconds in length.

figure1: acousticand  high-passfiltered currentsignaltemplates for aspull in event.
1	conclusions
this paper has presented a novel model-based mode estimation algorithm for monitoring and diagnosing multi-sensor distributed embedded systems. this work has demonstrated that monitoring of multi-sensor distributed hybrid systems can effectively exploit the knowledge of control and discreteevent behaviors of the system to drasticallymitigatethe exponential blowup due to the sensor data association problem.
　there are a number of ways this work can be extended. the simple sensor cost function could be generalized to model more realistic distributed processing and communication characteristics in a distributedmulti-sensorenvironment.

figure 1: acoustic signal template for fm ramp up event.

figure 1: posterior distribution of as pull in time.
currently  while mode estimation can be distributed  model simulation and diagnosis are performed centrally. distributing the model and diagnostic reasoning would require maintaining and updating hypotheses on multiple nodes and remains as one of the topics for future research.
acknowledgment
this work is supported in part by the defense advanced
research projects agency  darpa  under contract numbers f1-c-1 and f1-c-1. the views and conclusions contained herein are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the defense advanced research projects agency or the us government.
　we thank sriram narasimhan for his assistance in implementing a petri net simulator during an internship at xerox parc  bob siegel for helping acquiring the test fixture  meera sampath  ron root  and lloyd durfey for their help in instrumenting the testbed  johan de kleer  gautam biswas and bob siegel for insightful discussions on diagnostics  and jim kurien for comments on drafts of the paper.
references
 bar-shalom and fortmann  1  y. bar-shalom and t.e. fortmann. tracking and data association. academic press  1.
 hung and zhao  1  e.s. hung and f. zhao. diagnostic informationprocessing forsensor-richdistributedsystems. in proc. 1nd internationalconference on information fusion  fusion'1   sunnyvale  ca  1.
 koutsoukos et al.  1  x.d. koutsoukos  k.x. he  m.d. lemmon  and p.j. antsaklis. timed petri nets in hybrid systems: stabilityand supervisorycontrol. journalof discrete event dynamic systems: theory and applications  1 :1  1.
 koutsoukos et al.  1  x. koutsoukos  f. zhao  h. haussecker  j. reich  and p. cheung. fault modeling for monitoring and diagnosis of sensor-rich hybrid systems. technical report p1  xerox palo alto research center  march 1.
 kurien and nayak  1  j. kurien and p. nayak. back to the future for consistency-based trajectory tracking. in proceedings of the 1th national conference on artificial intelligence  aaai'1   1.
 lerner et al.  1  u. lerner  r. parr  d. koller  and g. biswas. bayesian fault detection and diagnosis in dynamic systems. in proceedings of the 1th national conference on artificial intelligence  aaai'1   1.
 mcilraith et al.  1  s. mcilraith  g. biswas  d. clancy  and v. gupta. hybrid systems diagnosis. in n. lynch and b. krogh  editors  hybrid systems: computationandcontrol  volume 1 of lecture notes in computer science  pages 1. springer  1.
 mcilraith  1  s. mcilraith. diagnosing hybrid systems: a bayesian model selection problem. in proceedings of the 1th international workshop on principles of diagnosis  dx'1   1.
 quinlan  1  j.r. quinlan. combining instance-based and model-based learning. in proceedings of the 1th international conference on machine learning  1.
 sampath et al.  1  m. sampath  a. godambe  e. jackson  and e. mallow. combiningqualitative & quantitative reasoning - a hybridapproach tofailure diagnosisof industrial systems. in 1th ifac symp. safeprocess  pages 1  1.

causal interaction: from a high-level representation to an operational event-based representation
ir┬ne grosclaude  marie-odile cordier and ren└ quiniou
irisa  campus de beaulieu  1 rennes cedex france
igroscla cordier quiniou irisa.fr

abstract
we propose to extend the temporal causal graph formalisms used in model-based diagnosis in order to deal with non trivial interactions like  partial  cancellation of fault effects. a high-level causal language is defined in which properties such as the persistence of effects and the triggering or sustaining properties of causes can be expressed. various interaction phenomena are associated with these features. instead of proposing an ad hoc reasoning mechanism to process this extended formalism  the specifications in this language are automatically translated into an event calculus based language having well-established semantics. our approach improves the way fault interaction and intermittent faults are coped with in temporal abductive diagnosis.
1	introduction
in the field of model-based diagnosis  which aims at explaining abnormal observations  causal graphs  console et al.  1  have been widely used to formulate the  deep knowledge  specifying how a faulty system may evolve. such a graph models the causal chains leading from initial faults to observable symptoms. the causal graph is used abductively in order to compute the set of initial faults explaining the observations  for example  brusoni et al.  1  .
　in most diagnostic applications  the temporal aspect appears to be crucial  either because some effects depend on the duration of fault occurrences or on their order  or because different faults leading to similar effects can be discriminated by the order in which symptoms appear or by the delays separating symptom occurrences. causal graphs have been extended to take time into account  brusoni et al.  1 : the nodes represent time dependent propositions  fluents  sandewall  1  ; the edges correspond to formulas:
　　　　　　　　　　　　　　　　　　　　　　　 1  such a causal relation can be informally interpreted as: the conjunction of facts leads to the occurrence of the effect . usually  the temporal constraints indicate the delay before the effect occurs. but they can also impose a minimal duration for the cause to produce the effect  or state that the effect has a maximal duration.
　though one of the claimed advantages of this kind of deep knowledge is the ability to represent fault interaction  paradoxically  existing diagnosis abductivealgorithms  brusoni et al.  1; gamper and nejdl  1  deal with limited forms of interaction. the language is restricted to positive effects and the interaction of faults reduced to additional effects. moreover  unique fault and absence of uncertainty are currently hypothesized  which limits the interaction problem.
　in real cases however  interaction can be much more complex: the effects of a fault can prevent  delay or accelerate the appearance of the effects due to other faults. in the medical domain for instance  the patient is often under treatment when the diagnosisis performed: the beneficial effects of drugs - interacting with the disease effects - must be taken into account as well as their secondary effects  long  1 . another kind of interaction is illustrated by the conjunction of two diseases leading to the absence of symptoms that are characteristic of one of the diseases. existing approaches dealing with interaction in causal models  gazza and torasso  1; long  1  propose to extend the causal language. first of all  negative effects     are allowed in causal relations in order to express preventing effects. secondly  the causal ontology is enriched by introducing knowledge on the causes and the effects. thirdly  priorities between causal relations can be asserted. the advantage of this method is a relatively easy incremental knowledge acquisition. the weakness of existing approaches is the use of ad hoc reasoning mechanisms  able to manage the different interaction schemes based on the particular features of the causal relations  but dependent on the chosen causal ontology.
　the problem of interacting faults is strongly related to the problem of concurrent actions representation encountered in the domain of action modeling. deducing indirect effects of actions  the so-called ramification problem  requires to take the way they interact into account. in the theories of action and change  the problem has first been viewed as how to integrate the treatment of interaction in existing formalisms  and has been partially solved by introducing state constraints and conditional effects into action rules  boutilier and brafman  1; miller and shanahan  1 . a now quite common way to tackle the ramification problem is to associate to the set of rules describing the direct effects of actions a set of causal rules modeling their indirect effects  giunchiglia and lifschitz  1;

	figure 1: example 1	figure 1: example 1
denecker et al.  1 . an interesting method consists in using the notion of influence  karlsson et al.  1 : actions have no direct effects but influences. separate rules describe the effects resulting from differentconjunctions of influences. the main drawback of these approaches is the difficulty of knowledge representation.
　this paperproposes to combine the advantagesof bothpreceding approaches by using a high-level causal language dedicated to the interaction problem. this language is powerful enough to express various forms of interaction. an automatic translation into an event calculus variant  kowalski and sergot  1  makes explicit the implicit knowledge embedded in causal relations and provides clear semantics to the language. moreover  this translation step makes the reasoning mechanisms no longer dependent on the ontology of causality as it produces an intermediate representation which can be exploited by dedicated algorithms. this work was motivated by an industrial application in the field of diagnosis. an efficient abductive diagnosis algorithm  making use of heuristics and specialized temporal constraint managers  has been developed  grosclaude and quiniou  1 .
　section 1 introduces interaction leading to masked or delayed effects on several motivating examples. in section 1  we describe the formalism of the extended causal graph and explain in section 1 how it can be translated into the event calculus. in section 1  we evoke the application of the method to diagnosis. our proposition is compared to related work in section 1 and we conclude in section 1.
1	motivating examples
example 1 a fire alarm starts ringing immediately after smoke has been detected and keeps ringing as long as smoke remains. the alarm is electrical  so may be subject to power cut. in a causal graph the situation could be described by:
         where	 	 	and	are the temporal extents associated to the basic propositions	 	and	 	. begun by and equals correspond to allen temporal relations.
let us suppose that smoke is observed and that a power cut occurs  as illustrated by fig. 1. to derive the common sense consequences of these interacting events  some extra knowledge is necessary: the power cut takes precedence over the smoke  the effect of the power cut is not persistent after power is back; the smoke sustains the alarm and triggers it again after cancellation.
　here follows a way to represent the situation by expliciting the relations between the start/end instants of the phenomena:
a  - the start of smoke causes the alarm to ring if power is on;

figure 1: example 1
b  - the start of the power cut provokes the end of the alarmif the alarm is ringing;
c  - at the end of the power cut the alarm starts again if somesmoke is still present.
example 1 figure 1 differs from the previous one by the fact that the fire alarm is only triggered when a particular smoke concentration is reached. the difference is that the  smoke  cause is instantaneous and triggers the alarm at inception instead of sustaining it from beginning to end. in this case  the alarm will not reappear at the end of the power cut  the smoke concentration is already above the triggering threshold . the a  and b  relations are valid but the c  relation is not.
example 1 the example represented in fig. 1  taken from  gazza and torasso  1   involves on the one hand  an oil loss from a motor leading to a lubrication problem if it lasts more than 1 hours and  on the other hand  an addition of oil. the effects of the two interacting phenomena correspond to the following relations:
d  - the oil loss provokes a lack of lubrication 1 hours after itsstart if no oil is added during this time;
e  - the oil addition stops a lubrication problem;
f  - if oil is added during oil loss the lubrication problem isdelayed to 1 hours later  if no oil is added meanwhile . in the following  we propose a high-level language in which properties of the causal relations influencing interaction phenomena can be expressed. we show how these relations inducing constraints on the starts/ends of causes and effects can be translated into axioms in an event calculus formalism.
1	the high-level language ecg
the previous examples show that the interaction outcomes can be derived from extra knowledge on the causal relations. in this section we propose a high-level representation language which corresponds to an extended causal graph  ecg .
　the entities we consider are propositional descriptions of situations  events or properties and are referred to as fluents   sandewall  1  . since we are dealing with time  the truth value of an entity is associated to time intervals. the ecg is composed of a set of causal relations having the following form:
typ	typ	 
example 1:	 1.a 
 1.b   example 1: 1.c     1.d   example 1: 1.e   figure 1: examples of causal rules in the ecg formalismwhere the causes and the effect are in a positive or negative form. the set of causes is referred as the cause. the time interval associated to the cause is the maximal time interval where all the causes are simultaneously true1. under the condition that this interval is non empty  the effect occurs and its validity interval satisfies the temporal conditions1. the temporal features of a causal relation are given by the delay and the minimal duration of the cause md. the delay       represents the time units between the start of the cause and the start of the effect. the minimal duration of the cause md indicates how long the cause must last to produce the effect.
this language is particularly suited to the expression of interaction patterns from which the precise effects of interacting causes will be deduce. the causal ontology has been extended in order to express priorities between causal relations  to specify two forms of effect persistence and different kind of causal relations  as trigger or sustain .
　- the causal-link can be one of {cause  impose  may cause  may impose}. and express the strength of the causal relation  cause being weaker than impose. when two causes have opposite effects  the causal link with the lowest priority produces its effect only if no causal link with a higher priority is enabled1. in example 1  represented in the ecg in fig. 1  smoke causes alarm and power-cutimposes not alarm .
　　 	and	 	express the uncertainty of the causal relation as in  console et al.  1 .
　- the type of effect persistence indicates whether an effect lasts even when its inducing cause has disappeared or if it does not survive it. if qualified by non pers effects are non persistent  non pers d  means that the effect disappears after a delay    otherwise they are persistent by default.
　- the type of causality typ is one of {os  c  cn} and indicates for each cause whether it triggers or sustains the effect. when a   -   cause comes true it triggers the effect. in fig. 1  reaching a given level of smokiness triggers the alarm; the alarm keeps on ringing until some other fact stops it. a     cause sustains the effect: the effect is  continuously  triggered by the cause. the effect can be temporarily masked but reappears later on if the cause is still present. in example 1  the smoke sustains the alarm which  even interrupted by a power-cut  can reappear. a cn  for continuously-necessary  cause is needed for a nonpersistent effect to persist. in example 1  fig. 1   gasoline is a cn cause: flames disappear when there is no more gasoline.
integrity constraints complete the description of the causal graph and allow to specify the maximal duration of a state.
　note that  contrary to  gazza and torasso  1   the type of causality is assigned to each individual cause  as each one

ing the formalism to set other constraints between the causes	.
1
　　the unique effect is not restrictive as multiple effects can be expressed by several causal relations with the same cause.
1
　　the two degrees of priority can clearly be extended to an ordered set of priorities  as in  gazza and torasso  1 .
can play a different role. see example 1  fig. 1  where the sparks are only necessary to trigger flames  whereas gasoline loss must be continuously present.
1	from the high-level causal language to event calculus
the high-level language presented above makes easier the representation of temporal causal relations. sentences in this language are then translated into formulas of an intermediate language  a variant of the event calculus  kowalski and sergot  1 . these formulas express the temporal relations existing between the starts or ends of causes and the starts or ends of the producedeffects. reasoning tasks  such as abductive explanation for diagnosis  rely upon this language. this approachhas several benefits: on the one hand  a clear semantics is provided to our causal formalism; on the other hand  the causal ontology for interaction can be easily completed or changedby updatingthe set of translation rules without modifying the reasoning tasks. first  we present the event calculus formulation that we have used and then the rules translating  extended  causal relations into event calculus sentences.
1	event calculus
the event calculus is a logic-based formalism for representing actions or events and their effects. we use a classical version of the event calculus based on i  a set of time points isomorphic to the non-negative integers  ii  a set of time-varying properties  fluents  and iii  a set of events related to the start and end of fluents and named and . the classical event calculus axioms are adapted:
　we need to express the maximal validity interval of propositions. for this purpose  we introduce the predicate which means that the interval
bounded by and is a maximal validity interval for the fluent : is true throughout this interval and is false just before and just after. the constant is introduced to represent the latest instant in time.
 1.a 
 
 1.b 	 
 1.c 
 
figure 1: event calculus domain axioms related to example 1  fig. 1 the basic event calculus version is extended to take into account indirect effects of events  the ramification problem and uncertain delays. the domain axioms are computed from causal relations expressed in the ecg. the translation rules are described in section 1.
　in our representation  positive information has been emphasized as this is common practice when representing expert causal knowledge. negative information  such as or   can be deduced by non-monotonic reasoning  negation as failure as in logic programming  or transformation  completion or circumscription as in  miller and shanahan  1  . the negation symbol in event calculus sentences must be interpreted as non-
monotonic negation.
1	translation rules
the principle underlying the translation of the causal graph is to make explicit the links between the starts or ends of causes and the starts or ends of effects. the causal relations leading to contradictory effects must be treated globally. they are gathered and translated into several domain axioms of the form  examples are given in fig. 1 : temporal constraints
the temporal constraints relate the occurrences of and . represents the preconditions necessary to the realization of the relation whereas are the preconditions preventing the relation. if the causal relation is uncertain     or     an abstract precondition is added in the body of the axiom  console et al.  1 . the translation rules are given below. in a first step  we assume that the causal relation antecedentsonly contain a single cause. later on  we explain how a conjunction of causes can be treated as a single cause. the typefaces of cause symbols  boldface or underline  will be used to explain the treatment of conjunctive causes.
rule 1: strong positive causation - causal link ; positive effect.

rule 1: weak positive causation - causal link ; positive effect.

the rules leading to are taken into account by inserting the precondition prev. this ensures that does not happen during an interval where is imposed by a relation	.	is the expression:

with regard to the delays  two cases are considered:
a  the delays are precise:	and	. the temporal constraints	are:	.
when the effect is not persistent and disappears at the end of  after a delay d = d  d   the constraint is added.
as an illustration  rule 1 is used to translate the causal rule 1.a  fig. 1  into the axiom 1.a  fig. 1 .
b  the delays are imprecise. then  constraints on the relativetemporal position of the interacting causes are not sufficient to ensure that does not happen during an interval where is imposed. we solve the problem by introducing intermediate effects representing the positive or negative influences of interacting causes. a causal relation  typ   c causal relation e {d} is replaced by the two relations  1   typ   c cause infle {d} and  1   cn  infle causal relation e {1}. this way  the interaction involves relations of type  1  with precise  null  delays. the final effects are produced by the starts and ends of influences  following the relative position of the opposite influences.
rule 1: strong negative causation - causal link ; negative effect.

　rule 1 is used to translate the causal rule 1.b  fig. 1  into the axiom 1.b  fig. 1 .
rule 1: weak negative causation - causal link ; negative effect.

	where	is the same as in rule 1.
rule 1: influence of causation on end instants.




　　　　is used to verify that no other cause produces the effect . is the same as in rule 1 and 1.
 
 
 
 
figure 1: event calculus domain axioms related to example 1  fig. 1 rule 1: end of a cause masking an effect	.




if the delays are precise:	and	  then indicates that a cause sustaining	must be present:
the constraints	are:
is the same as in rule 1  1 and 1.
rule 1 is used to translate the causal rule 1.b  fig. 1  into the axiom 1.c  fig. 1 .
if the delays are imprecise  we use the same transformation of causal relations as in rule 1  which adds intermediate influences.
　due to lack of space  we do not give the precise translation rules used when a minimal duration md of the cause is necessary for the effect to occur. this constraint is expressed using the predicate	:
　the precondition	md is used to constrain the duration of the cause .
conjunctive causes.
we have presented translation rules operating on causal relations with single antecedent. to deal with causal relations having multiple antecedents  the fluent corresponding to the conjunction of the causes  true when all the causes are true  is introduced. if the effect of the causal relation is not persistent  a second intermediate fluent is added  representing the part of the conjunction necessary for the persistence of the effect  the  sustaining  part . the start of corresponds to the start of   but ends only when one cause of type cn ends. the axioms corresponding to example 1  fig. 1  are represented on fig. 1. during the translation process or is considered as the unique cause of the causal rule. the translation rules coveringthe multiple causes are those given before  where is replaced by and c by
   . if all the causes are of type   the unique cause is of type . in the remaining cases  if one of the cause is os  the unique cause is os  else the unique cause is cn.
1	application to diagnosis
our work originates from an application in diagnosis requiring to deal with interacting faults. the problem is to explain a set of imprecisely dated observations by a set of possibly interacting faults. the observations are expressed by statements	  where and define the temporal interval on which the observation has been observed and specifies the constraints on this possibly imprecise interval. a candidate diagnosis is expressed by using predefined  abducible  predicates:	 
associated with temporal constraints on the instants and and where the are initial faults. we are then faced to a
temporal abductive task as usual in a diagnostic context.
　the domain knowledge is described by a set of causal relations using the formalism defined in 1 and automatically translated into the event calculus formalism as explained in 1. a first solution would have been to make use of existing abductive tools. for instance  the aclp framework  kakas et al.  1  integrates abductive and constraint logic programming. as such  it is well adapted for encoding variants of event calculus implementing abductive planning or scheduling tasks. but  for efficiency reasons - aclp suffers from a lack of efficiency mainly due to its standard resolution strategy causing many backtracks - we decided to implement our own algorithm which takes advantage of domain-dependent heuristics to cope with the inherent complexity of the abductive task. this algorithm is described in  grosclaude and quiniou  1 .
　the method has been implemented in java and experimented on a real causal graph provided by edf  └lectricit└ de france  which contains about 1 nodes and 1 arcs. following the approach in  brusoni et al.  1   the consistency of temporal constraints is efficiently checked by testing the consistency of a temporal constraints network every time constraints are added  in order to reject an hypothesis as soon as possible. the tests confirm that the approachis feasible despite its inherent computational complexity. the system has been able to detect potential interaction cases. the graphical interface displays the original causal graph as well as a graphical representation of the axioms in the event calculus to the user  so as to let him notice the consequences of the interaction and correct his model if he wants to. we are currently investigating additional heuristics in order to reduce the computation time.
1	discussion
deduction on a causal graph including negative effects have been studied by  gazza and torasso  1 . causal relations are categorizedaccording to the relative position of the occurrences of the cause and the effect. the considered properties associated to causal relations  as one-shot or continuous are closed to ours. nevertheless  since the property is associated globally to the causal relation  it is not clear how conjunctive causes of different kinds can be dealt with. with regard to reasoning with opposite effects  a priority is associated to each relation. for every pair of relations  a specific interaction scheme is determined. the approach is used in order to maintain temporal databases and makes the assumption that all the temporal constraints are precise. as far as we can see  our method has two advantages: first  patterns of interaction are clearly related to particular features of causal relations; second  interaction is represented explicitly in the domain axioms of our event based language. we propose a graphical representation of the domain axioms that can be displayed to the expert  who can detect more easily erroneous modeling leading to bad prediction of interaction.
　beyond the diagnosis area  some recent works on the deduction of indirect effects of actions have introduced causality. few of them are explicitly dealing with temporal aspects.  karlsson et al.  1  have proposed a logical formalism to deal with delayed and concurrent effects of actions with explicit time. the causal theory is described by a narrative in the tal-c language  allowing to express features such as the persistence of effects and imprecise delays. in order to avoid inconsistency  the notion of influence is introduced: actions have no direct effects but influences  and rules for combining influences are given. the narrative is translated into a firstorder language in order to test the consistency of a scenario containing actions and observations. as far as we can see  time is managed by logical inference and the treatment of imprecision should not be as efficient as ours which is based on temporal constraint propagation. with respect to this work  our main contribution is the high-level language which allows us to express the causal relations at an ontological level instead of at an operational one. it would be interesting to test how ecg could be used as a high-level language for tal-c.
1	conclusion
we have presented a formalism dedicated to reasoning on interacting causes. it takes advantage  on the one hand  of the knowledge acquisition benefits offered by causal languages developedin the abductivediagnosis context and  on the other hand  of the well-defined formalisms developed to reason about change. the idea is to express the knowledge about potentially interacting causes into a high-level language  the extended causal graph language  and to provide an automatic translation into an event calculus based formalism. the method have been experimented in an abductive diagnosis context and the complexity of the domain axioms show the relevance of their automatic computation from a high-level causal language. moreover  updating the causal knowledge is made easier and can be performed without bothering of the whole set of relations.
　in the domain of diagnostic  future work concerns the application of the method for maintenance purposes. the ability to deal with contradictory knowledge makes it possible to represent the effects of repairs in the causal graph. it is thus interesting  especially when the system is evolvingslowly and when maintenance is expensive  to rely on the causal graph in order to detect the dates at which some repair is mandatory. another perspective is related to the interest of the ecg language and its event-calculus translation for reasoning tasks involving actions and changes as in planning for instance.
references
 boutilier and brafman  1  c. boutilier and r.i. brafman. planning with concurrent interacting actions. proc. of the 1th national conference on artificial intelligence  aaai-1   1.
 brusoni et al.  1  v. brusoni  l. console  p. terenziani  and d. theseider-dupr└. characterizing temporal abductive diagnosis. proc. of 1th int. workshop on principles of diagnosis  dx1   p. 1  1.
 brusoni et al.  1  v. brusoni  l. console  l. terenziani  and d. theseider-dupr└. an efficient algorithm for temporal abduction. lecture notes in artificial intelligence 1  p. 1  1.
 console et al.  1  l. console  d. theseider-dupr└  and p. torasso. a theory of diagnosis for incomplete causal models. proc. of the int. joint conference on artificial intelligence  ijcai-1   p. 1  1.
 denecker et al.  1  m. denecker  d. theseider dupr└  and k. van belleghem. an inductive definition approach to ramifications. link ping electronic articles in computer and information science  http://www.ep.liu.se/ea/cis/1/  vol. 1 :1  1.
 gamper and nejdl  1  j. gamper and w. nejdl. abstract temporal diagnosis in medical domains. artificial intelligence in medicine 1  p. 1  1.
 gazza and torasso  1  m. gazza and p. torasso. temporal prediction: dealing with change and interaction within a causal framework. topics in artificial intelligence  p. 1  1.
 giunchiglia and lifschitz  1  e. giunchiglia and v. lifschitz. an action language based on causal explanation: preliminary report. proc. of the 1th national conference on artificial intelligence  aaai-1   p. 1  1.
 grosclaude and quiniou  1  i. grosclaude and r. quiniou. dealing with interacting faults in temporal abductive diagnosis. proc. of the 1th int. workshop on principles of diagnosis  dx1   1.
 kakas et al.  1  a.c. kakas  a. michael  and c. mourlas. aclp: abductive constraint logic programming. journal of logic programming  1-1 :1  1.
 karlsson et al.  1  l. karlsson  j. gustafsson  and p. doherty. delayed effects of actions. proc. of the 1th european conference on artificial intelligence ecai-1  p. 1  1.
 kowalski and sergot  1  r. kowalski and m. sergot. a logicbased calculus of events. new generation computing  vol.1  p. 1  1.
 long  1  w. long. temporal reasoning for diagnosis in a causal probabilistic knowledge base. artificial intelligence in medicine 1  p. 1  1.
 miller and shanahan  1  r. miller and m. shanahan. the event calculus in classical logic - alternative axiomatisations. link ping electronic articles in computer and information science  1   1.
 sandewall  1  e. sandewall. features and fluents  a systematic approach to the representation of knowledge about dynamical systems. oxford university press  1.

diagnosis
hierachical diagnosis and monitoring

hierarchical diagnosis guided by observations
luca chittaro and roberto ranon
department of mathematics and computer science
university of udine - 1 udine  italy email: chittaro ranon  dimi.uniud.it

abstract
we propose a technique to improve the performance of hierarchical model-based diagnosis  based on structural abstraction. given a hierarchical representation and the set of currently available observations  the technique is able to dynamically derive a tailored hierarchical representation to diagnose the current situation. we implement our strategy as an extension to the well-known mozetic's approach  mozetic  1   and illustrate the obtained performance improvements. our approach is more efficient than mozetic's one when  due to abstraction  fewer observations are available at the coarsest hierarchical levels.
1	introduction
abstraction has been advocated as one of the main remedies for the computational complexity of model-based diagnosis  mbd . mbd approaches that exploit abstraction  e.g.   mozetic  1   represent the system at multiple levels of detail  and typically isolate faults one level at a time  starting at the most abstract possible level  and using the results at one level to reduce the cost of diagnosis by removing impossible diagnoses from consideration at more detailed levels.
　one limit to the effectiveness of hierarchical diagnosis is the fact that often a single  fixed hierarchical representations is employed  regardless of the currently available observations. in many cases  effectiveness depends on the situation at hand. as we show in the paper  the same hierarchical representation can improve the performance of diagnosis in some cases  but also lead to a performance which is identical to non-hierarchical diagnosis in other cases. on the other hand  building a new hierarchical representation by hand for each diagnostic scenario cannot in general be a viable alternative.
　in this paper  we propose a technique that  given a hierarchical representation and a set of currently available observations  is able to derive a hierarchical representation which is particularly suited to diagnose the current situation. our technique does not build the tailored representation from scratch  but instead rearranges the original hierarchical representation  i.e. it exploits only the original abstractions. the rearrangement process is guided by the currently available observations. the technique we present focuses on structural abstraction  hamscher  1; genesereth  1 . to show the usefulness of our technique  we formalize it as an extension to mozetic's approach  mozetic  1   and experimentally evaluate its performance vs. that approach  showing that it improves efficiency when fewer observations are available at the coarsest hierarchical levels due to abstraction.
　the paper is structured as follows: section 1 contains some prerequisites on diagnosis and structural abstraction; section 1 analyzes mozetic's approach  while section 1 presents our hierarchical diagnostic strategy. section 1 illustrates the experimental evaluation. finally  section 1 mentions future work.
1	diagnosis with structural abstraction
following  de kleer et al.  1   a diagnosis problem	in
a language	is a triple	 	 	  where
and are first-order theories in language   representing the system description and observations  respectively  and is a subset of the object constants of   identifying the set of system components. each component is assigned a set of behavioral modes  each one represented by a distinct predicate of  and also specified by a formula over the component's ports   that represent either multiple normal operating modes  e.g. a valve can be open or closed  or faulty behavioral modes  e.g. a pipe can be leaking  or be obstructed . each formula   where
represents a behavioral mode for component   is a candidate of . a candidate is a diagnosis of if and only if is consistent. the diagnosis task consists in finding all possible diagnoses  or to find a set of diagnoses  such as the kernel diagnoses  de kleer et al.  1   that are a compact representation for all the possible diagnoses.
　for clarity purposes  the hydraulic system depicted in figure 1  called system a  will be used as an example throughout the paper. it is composed by a volumetric pump   pipes             and valves  in closed state  and
 in open state . in table 1  we define the component modes in system a  the formulae that specify the types of components and the connections among them can be easily derived from the schema in figure 1 . in the volumetric pump's behavioral description    which depends on the pump's settings  is the amount of flow the normal pump is able to impose. to avoid unnecessary complex examples  we consider only flow observations.
typebehavioral modestable 1: behavioral modes for the components of system a.
　structural abstraction decomposes a system into a hierarchy of subcomponents  or  vice versa  aggregatescomponents into a hierarchy of supercomponents . we adopt the following terminology and assumptions. the structural abstraction of a diagnosis problem	1is a  more abstract  problem    
　　　　　　  obtained by aggregating a subsystem  denoted by the set of components	  into a single supercomponent	.
　the more abstract diagnosis problem represents the same system as   but:  i  from a structural point of view  the components belonging to have to be replaced by a single component   and   ii  from a behavioral point of view  a representation of the behavior of has to be introduced. the behavior of is reasonably a simplified representation of the possible combinations of behavioral modes of its subcomponents  e.g.  by forgetting and/or collapsing some of the variables of components in  . finally  also the set of observation could differ from   because observations that are internal to subsystem cannot be represented in . for example  suppose to aggregate pipe and open valve of system a into a component of type   in open state. the choice is reasonable since when both and are normal  they act as an open valve  allowing fluid to flow. we can thus remove all the formulae which mention and   and introduce the theory	 
	 	.
in this case  the abstraction removes the flow measurement at the connection between and   and keeps the other measurements.
　we define a hierarchical representation of a given diagnostic problem	 	 	as a list of	diagnostic problems	 	 	with where for every	 	is a structural abstraction of	. a possible 1-levels hierarchical representation of system a is sketched in table 1. each row of the table shows a level of the hierarchical representation. for each level  we indicate the level number  the components  together with their type   and the aggregations performed to obtain that level  in the third column of the table 	+
	means that	and	have been aggregated into	 .
　in order to ensure correctness and completeness when reasoning with abstract system representations  structural abstractions must satisfy some constraints. more specifically  the following property must be satisfied.
property 1  relation between diagnoses . let be diagnosis problems  such that is a structural abstraction of . let and be candidates of and   respectively  and suppose that is a more abstract representation of  according to the aggregation that has been performed in order to obtain  . if is not a diagnosis of   then must not be a diagnosis of .
　if this property is satisfied  one can rule out candidates at the more detailed level by reasoning only at the abstract level  because structural abstraction never mistakenly rules out a diagnosis. on the negative side  diagnosis must consider also the more detailed level in order to ensure correctness and completeness of results. we now show that similar requirements are imposed by other formalizations of structural abstraction proposed in the literature. thus  the techniques we present are not constrained to a specific formalization. in the following  let be a set of components which is aggregated into the supercomponent   and a formula saying that component is behaving normally.
　in  struss  1   structural abstraction is defined as follows.	supercomponent	is a structural abstraction of if	. in this way  whenever	is inconsistent with the observations  then also	is inconsistent  i.e. by excluding at the abstract level that	is normal  we can exclude also that all its subcomponents are normal. this is a special case of property 1 when we represent only the normal behavior of components in	.
　 mozetic  1   using a different formalization of diagnosis  lists a set of consistency conditions that must hold between a system representation and its more abstract version. these conditions ensure that property 1 holds.
　 autio and reiter  1  formalizes structural abstraction for diagnosis problems where only the correct behavior of components is represented. their approach requires both that
　　　　　　　　　　　　　 as in struss' formalization  and that	 i.e.  if is behaving normally  we can conclude that all its subcomponents are behaving normally . the second assumption can cause incorrect diagnoses when structural abstraction hides some measurements  e.g. there is a sensor which is  hidden  inside  . indeed  because of the lacking measurement  one could conclude that the normal behavior of is consistent with the observations  and thus infer that all 's subcomponents are also behaving normally  which in general is not true.
1	analysis of mozetic's approach
we illustrate mozetic's diagnostic algorithm in a format that will allow us to easily compare it with our proposal and highlight the refinements we made. the inputs of the algorithm are the hierarchical representation  and a set of observations at the finest level of detail  i.e.  level  . for each level of the hierarchical representation  is the set of candidates which have no abstraction at upper levels. hierarchical diagnosis is formalized as follows:
procedure hierarchical-diagnosis abstract-observations; top-down-diagnosis.
procedure abstract-observations
;
number of levels of the hierarchical representation;
while	do
	abstract 	 ;
;
endwhile;
if	then
procedure top-down-diagnosis
;
all possible candidates at level ;
while	do
	verify 	 ;
	if	then
	verify	 ;
;
endif;
	if	then	detailed 	 ;
;
endwhile.
we divided mozetic's algorithm into two separate pro-
levelcomponentsaggregationstable 1: components in the hierarchical representation for system a.
cedures. the first one  abstract-observations  associates the available observations to the abstract levels of the hierarchical representation. then  the second one  topdown-diagnosis  performs the diagnosis.
　in particular  abstract-observations takes as input the initially available observations   and  by repeatedly applying the abstract function  corresponding to the abstract predicate in mozetic's original formulation   determines the available observations  if any  for the more abstract levels. the number associated to the coarsest level with observations available is then stored into variable . the levels from to are then considered by the procedure topdown-diagnosis: for each level   first diagnosis is performed using the verify function  corresponding to mozetic's verify predicate ; then  the diagnoses that are found are translated into their representations at the next more detailed level by the function detailed  corresponding to mozetic's detailed predicate . those diagnoses will be the possible candidates for level . moreover  also those candidates  if they exist  which have no abstraction at upper levels  and are thus considered for the first time at the current level  are verified. when level 1 is reached  the final diagnoses are returned. it must be noted that no assumptions are made on the implementation of the verify function  e.g. it can be a generate-andtest method  a gde-like reasoner  or other mbd technique .
　by performing diagnosis at more abstract levels  mozetic aims at finding those diagnoses that are impossible  thus reducing the number of possible diagnoses  i.e. the size of the search space  at more detailed levels. this makes it possible  in many cases  to perform significantly better than directly solving the most detailed diagnosis problem. experiments done by mozetic report  in a medical example using a fourlevel qualitative model of the heart  a speed up by a factor of 1 over a one-level diagnosis. however  given a hierarchical representation  there are situations where the performance is not as good as one would expect because only part of the hierarchical representation is exploited  as we show in the following.
example 1. consider the 1-levels hierarchical representation of system a sketched in table 1  and suppose that the following observations are available: flow at the input of pipe
is   while flow at the output of valve is   i.e.	. executing abstract-observations  the observation at the input of can be abstracted to level 1 as the input of   but cannot be abstracted to level 1  where the input of is not visible anymore. by applying the same line of reasoning  the observation on is abstracted up to level 1. the topdown-diagnosis procedure can thus start only at level
1.
　in this example  diagnostic reasoning considers only the three more detailed levels of the hierarchical representation  no observations can be abstracted higher than level 1   and thus cannot take any advantage from the remaining coarser levels  where reductions of the search space could be in principle obtained with less effort. the result is that the computational savings gained over a plain  one-level diagnosis are not as good as one would expect  because diagnosis is started at an intermediate level of the hierarchy.
　in general  when we structurally abstract a diagnosis problem  all the observations that refer only to components that are aggregated become unavailable. thus  as we climb the hierarchical representation  less observations are available. in the systems where the position of measurement sensors is known and cannot be changed  one can limit this problem by choosing the aggregations in such a way that the most abstract levels have always  or at least often  some observation available. however  in general  whatever hierarchical representation we exploit  as the total number of given observations decreases  the top level from which diagnosis is started tends to become lower  i.e. the number of abstract levels not considered for diagnosis increases. the worst consequence of this problem is that the performance of mozetic's algorithm can become identical to a plain diagnostic approach. this happens whenever the observations given as input cannot be abstracted to level 1  i.e. when all observations refer only to components that are aggregatedin order to obtain level 1. the following example shows one possible scenario in which this situation occurs in system a.
example 1. suppose that the following observations are available: flow at the output of pipe is   i.e.
. the observation on the output of
cannot be abstracted to level 1  because it is not present at that level. hence  at the end of the execution of the abstractobservations procedure  the most abstract level with observations is level 1. thus  diagnosis is started at that level.
1	our proposed approach
we propose a technique that aims at improving mozetic's strategy when structural abstractions are used. our approach exploits also an additional data structure  called structural tree  presented in section 1   that highlights the aggregations performed to build the hierarchical representation.
1	the structural tree
we associate any hierarchical representation  built with structural abstractions  to a structural tree for called st h . in the tree  each node represents a component of   and its sons are its subcomponents.
given a hierarchical representation of a diagnostic problem
　　　　　 	 	  st h  is built as follows:
	first  for each component	  a new leaf
is created; then  for each aggregation of
into such that   a new node is created such that .
the root of is associated with the component that represents the whole system  i.e.
　　　　　　. figure 1 shows the structural tree for system a which has been obtained from the 1-level hierarchical representation sketched in table 1.
	since each node	of st h  is a component
for some   we associate to it the theory and the observations  when they are available . thus  each node is associated with a subset of one of the diagnostic problems of .

figure 1: structural tree for system a derived from the hierarchical representation of table 1.
1	the rearrange algorithm
we propose a technique that dynamically determines a new hierarchical representation suited to diagnose the specific situation described by the current observations. the new hierarchical representation will be built by rearranging the levels of a given hierarchical representation using the corresponding st h  on the basis of the available observations.
　the idea is to improve mozetic's algorithm when it is not able to fully exploit the hierarchical representation  by providing a new  tailored hierarchical representation consisting of:  i  all levels of the original hierarchical representation which have observations  i.e. the levels considered by mozetic's algorithm   and  ii  additional  more abstract levels which are not present in the original hierarchy  and have the same observations of the coarsest level considered by mozetic's algorithm.
　we will now show  using an example  how these additional levels can be built with little effort. in some cases  indeed  the abstract level at which diagnosis is started by mozetic's algorithm is too detailed than necessary. consider the scenario presented in example 1  where diagnosis is started at level 1  which contains 1 components   without exploiting the possibility of starting from a more abstract diagnosis problem. for example  the diagnosis problem  let us call it best  with components           and is more abstract than level 1 but has the same observations  i.e.  . the search space of best is much smaller: the diagnosis problem at level 1 has 1 possible candidates  while has 1 possible candidates.
　mozetic's algorithm cannot start from because this diagnosis problem is not available in the given hierarchical representation: the only level with observations is level 1. the problem is that the algorithm exploits the representation in a  fixed  way: levels are identical for any set of observations  and only the choice of starting level changes.
　we can derive by selecting nodes in the structural tree of figure 1. the structural tree highlights indeed the aggregations used in a hierarchical representation  regardless of the order in which they were performed. one can derive by selecting a set of nodes in the structural tree which:  i  represent the full system   ii  have the same observations that are present at level where mozetic's algorithm starts   iii  are as abstract as possible. then  one can compose the theories associated to the selected nodes to derive a new  more abstract starting level.
　we implemented this strategy as an extension to mozetic's algorithm  which we call the rearrange extension. more specifically  the building of the new levels is performed as an additional activity after the abstract-observation procedure  as shown in the following:
procedure hierarchical-diagnosis
abstract-observations; rearrange; top-down-diagnosis.
procedure rearrange
if	then
for each node	of	referred in
	is a port of	;
;
while	do
;
;
	if	then
;
;
;
add a new level numbered	with components to the hierarchical representation	;
;
else
;
endif;
　endwhile; endif.
the new activities performed by the procedure are:
each observation available at mozetic's coarsest level with observations is associated to the corresponding nodes in st h   obtaining the sets ; if possible  new diagnosis problems  which are more abstract than the one at which mozetic starts  are added to . these new levels are built by:
1. considering the components of the current  most abstract level  which initially is the original coarsest level with observations ;
1. finding a subset of components that are all the sons of a node in such that the union of the observations associated to them are exactly the observations associated to  i.e. by substituting them with their father we do not hide any observation ;
1. if such set of components does exist  adding to a new level whose components are the components of the current level which are not sons of   and itself. in this way  we build a more abstract diagnosis problem without losing any observation;
1. if such set of components does not exist  the algorithm stops; otherwise  the search for components which meet the above described requirements is repeated considering the components of the newly derived level.
　after the execution of rearrange  is the number of the new top level from which diagnosis is started. note that 

figure 1: most abstract levels derived by mozetic's algorithm and by the rearrange extension  examples 1 and 1 .

figure 1: most abstract levels derived by mozetic's algorithm and by the rearrange extension  examples 1 and 1 .
given the currently available observations  if abstractobservations is able to reach the most abstract level  then rearrange does nothing  and the whole reasoning proceeds exactly as in mozetic's algorithm. in order to show the advantages of this strategy with respect to mozetic's algorithm  we will now reconsider the previously illustrated examples.
example 1. given the observations in example 1  mozetic's hierarchical diagnosis would start at level 1  which contains components         and  see figure 1  left .
rearrange derives an additional  more abstract level 1. it contains components       and  see figure 1  right : components and of mozetic's most abstract level with observations are aggregated into pump . this is possible because and are the sons of in the corresponding structural tree  that is  an aggregation for them is available   and the observations associated to them are the same associated to their father  in this case      and have no observations . no coarser level can be derived  because there is no node in the structural tree whose sons belong to the newly derived level 1 and that can be aggregated without losing observations. thus  rearrange stops. topdown-diagnosis starts from the newly derived level 1. example 1. the observations given in example 1 cannot be abstracted to level 1. hence  the most abstract level with observations is level 1. by applying our technique  first a new level is derived with components               and   and can be aggregated without eliminating observations ; then  an additional level is derived with components             and   and can be aggregated without losing observations ; finally  a most abstract level  from which diagnosis will start  is derived with components         and   and can be aggregated without losing observations . the most abstract level used by mozetic and by our algorithm are graphically illustrated in figure 1.
1	experimental evaluation
we experimentally evaluated our extension with respect to the original mozetic's algorithm. both algorithms were implemented in swi prolog  iso-compliant free source prolog  developed by the university of amsterdam and run on a powerpc g1 mhz  apple imac dv  under the linuxppc 1 operating system. the verify procedure used by both algorithms was implemented as a generate-and-test algorithm  i.e. a procedure that considers each possible candidate and then verifies its consistency with the system description and observations. obviously  this is the worst choice for implementing the verify procedure  but it gives us a worst case scenario  corresponding to the exact size of the considered portion of the search space .
　the experimental comparison was performed with diagnosis problems of different size in the hydraulic domain. the considered systems differed in the layout and in the number of components and ports. more precisely  the simplest considered system was system a  1 components   and the most complex was an heavy fuel oil transfer system  1 components  of a container ship. for each hydraulic system  we considered several possible sets of observations. each set contained a number of observations randomly selected between one and   with where is the number of possible measurements points for the considered system  e.g. in systems with 1 possible measurement points  each set contained between one and four observations . the justification for this choice is twofold: first  with a few observations  the problem is more difficult  and this is the typical case in which one wants to use abstraction ; second  in the majority of real cases  observations are very scarce because of cost and reliability of sensors  so considering more observations is not a realistic scenario. each set with observations was generated by assigning a random value to measurements points  randomly selected between the available ones . figure 1 illustrates the average cpu times we obtained with the considered hydraulic systems considering 1 different sets of observations for each system. as one can see  for both algorithms the average cpu time becomes very high for small increases of the number of components of the considered systems  this is due to the generate-and-test procedure . however  our extension performs significantly better  and is more effective as the size of the considered system increases. this is due to the fact that  in a hierarchical representation with many components and levels  rearrange has more opportunities for deriving additional levels  and thus obtaining greater improvements. finally  the experimental evalua-

figure 1: comparison using 1 hydraulic systems with different number of components.
tion shows that the advantages rearrange brings to hierarchical diagnosis outperform the cost of its additional activities.
1	conclusions
we presented an extension to mozetic's algorithm that improves its performance when structural abstractions are employed. although improvements were demonstrated experimentally  we definitively need to test our approach with other real-world systems in different domains to evaluate its effectiveness. moreover  we are also working on alternative rearrangements of hierarchical representations which can be more effective in some situations. finally  we are considering to include the cost and discrimination power of measurements in the rearrangement process.
references
 autio and reiter  1  k. autio and r. reiter. structural abstraction in model-based diagnosis. in proceedings of the thirteenth european conference on artificial intelligence  pages 1. john wiley and sons.  1.
 de kleer et al.  1  johan de kleer  alan k. mackworth  and raymond reiter. characterizing diagnoses and systems. artificial intelligence  1-1  1.
 genesereth  1  m.r. genesereth. the use of design descriptions in automated diagnosis. artificial intelligence  1-1  1.
 hamscher  1  w. c. hamscher. modeling digital circuits for troubleshooting. artificial intelligence  1-1  1.
 mozetic  1  igor mozetic. hierarchical diagnosis. in w. hamscher l. console  j. de kleer  editor  readings in model-based diagnosis  pages 1. morgan kaufmann  san mateo  ca  1.
 struss  1  peter struss. what's in sd  towards a theory of diagnosis. in w. hamscher l. console  j. de kleer  editor  readings in model-based diagnosis  pages 1- 1. morgan kaufmann  san mateo  ca  1.
mode estimation of model-based programs:
monitoring systems with complex behaviorbrian c. williams and seung chung massachusetts institute of technology 1 massachusetts ave. rm. 1
　cambridge  ma 1 usa williams chung  mit.edu vineet gupta
purpleyogi  inc.
1 ravendale drive
mountain view ca 1 vineet purpleyogi.com

abstract
deductive mode-estimation has become an essential component of robotic space systems  like nasa's deep space probes. future robots will serve as components of large robotic networks. monitoring these networks will require modeling languages and estimators that handle the sophisticated behaviors of robotic components. this paper introduces rmpl  a rich modeling language that combines reactive programming constructs with probabilistic  constraint-based modeling  and that offers a simple semantics in terms of hidden markov models  hmms . to support efficient realtime deduction  we translate rmpl models into a compact encoding of hmms called probabilistic hierarchical constraint automata  phca . finally  we use these models to track a system's most likely states by extending traditional hmm belief update.
1	introduction
highly autonomous systems are being developed  such as nasa's deep space one probe  ds-1  and the x-1
reusable launch vehicle  that involve sophisticated modelbased planning and mode-estimation capabilities to support autonomous commanding  monitoring and diagnosis. given an observation sequence  a mode estimator  such as livingstone  williams and nayak  1   incrementally tracks the most likely state trajectories of a system  in terms of the correct or faulty modes of every component.
　a recent trend is to aggregate autonomous systems into robotic networks  for example  that create multi-spacecraft telescopes  performcoordinatedmars exploration or perform multi vehicle search and rescue. novel model-based methods need to be developed to monitor and coordinate these complex systems.
　an example of a complex device is ds-1  which flies by an asteroid and comet using ion propulsion. ds-1's basic functions include weekly course correction called optical navigation   thrusting along a desired trajectory  taking science readings and transferring data to earth. each function involves a complex coordination between software and hardware. for example  optical navigation  opnav  works by taking pictures of three asteroids  and by using the difference between actual and projected locations to determine the course error. opnav first shuts down the ion engine and prepares its camera concurrently. it then uses the thrusters to turn to each of three asteroids  uses the camera to take a picture of each  and stores each picture on disk. the three images are then read  processed and a course correction is computed. one of the more subtle failures that opnav may experience is a corrupted camera image. the camera generates a faulty image  which is stored on disk. at some later time the image is read  processed  and only then is the failure detected. a monitoring system must be able to estimate this event sequence based on the delayed symptom.
　diagnosing the opnav failure requires tracking a trajectory that reflects the above description. identifying this trajectory goes well beyondlivingstone'sabilities. livingstone  like most diagnostic systems  focuses on monitoring and diagnosing networks whose components  such as valves and bus controllers  have simple behaviors. however  the above trajectory spends most of its time wending its way through software functions. ds-1 is an instance of modern embedded systems whose components involve a mix of hardware  computation and software. robotic networks extend this trend to component behaviors that are particularly sophisticated.
　this paper addresses the challenge of modeling and monitoring systems composed of these complex components. we introduce a unified language that can express a rich set of mixed hardware and software behaviors  the reactive modelbased programminglanguage rmpl  . rmpl merges constructs from synchronous programming languages  qualitative modeling  markov models and constraint programming. synchronous  embedded programming offers a class of languages developed for writing control programs for reactive systems  benveniste and berry  1; saraswat et al.  1  - logical concurrency  preemption and executable specifications. markov models and constraint-based modeling williams and nayak  1 offerrich languagesfor describing uncertainty and continuous processes at the qualitative level.
　given an rmpl model  we frame the problem of monitoring robotic components as a variant of belief update on a hidden markov model  hmm   where the hmm of the system is described in rmpl. a key issue is the potentially enormous state space of rmpl models. we address this by introducing a hierachical  constraint-based encoding of an hmm  called a probabilistic  hierarchical  constraint automata  phca . next we show how rmpl models can be compiled to equivalent phcas. finally  we demonstrate one approach in which rmpl belief update can be performed by operating directly on the compact phca encoding.
1	hmms and belief update
the theory of hmms offers a versatile tool for framing hidden state interpretation problems  including data transmission  speech and handwriting recognition  and genome sequencing. this section reviews hmms and state estimation through belief update.
	an hmm is described by a tuple	.
and denote finite sets of feasible states and observations . the initial state function    denotes the probability that is the initial state. the state transition function 
                   denotes the conditional probability that is the next state  given current state at time . the observation function  denotes the conditional probability that is observed  given state .
　belief update incrementally computes the current belief state  that is  the likelihood that the system is in any state   conditioned on each control action performed and observation received  respectively:
p
p
exploiting the markov property  the belief state at time is computed from the belief state and control actions at time and observations at using the standard equations. for
simplicity  control actions are made implicit within	:

　the space of possible trajectories of an hmm can be visualized using a trellis diagram  which enumerates all possible states at each time step and all transitions between states at adjacent times. belief update associates a probability to each state in the graph.

1	design desiderata for rmpl
returning to our example  opnav is best expressed at toplevel as a program:
opnav   :: turncameraon  if engineon thennext switchenginestandby  do
	when enginestandby	cameraon donext
takepicture 1 ;
takepicture 1 ;
takepicture 1 ;
turncameraoff 
computecorrection  
	watching pictureerror	opticalnaverror 
when opticalnaverror donext opnav    when pictureerror donext opnavfailed
in this program comma delimits parallel processes and semicolon delimits sequential processes.
　opnav highlights four key design features for rmpl. first  the program exploits full concurrency  by intermingling sequential and parallel threads of execution. for example  the camera is turned on and the engine is turned off in parallel  while pictures are taken serially. second  it involves conditional execution  such as switching to standby if the engine is on. third  it involves iteration; for example   when engine standby donext   says to iteratively test to see if the engine is in standby and if so proceed. fourth  the program involves preemption; for example   do watching   says to perfom a task  but to interrupt it as soon as the watch condition is satisfied. subroutines used by opnav  such as takepicture  exploit similar features.
opnav also relies on hardware behaviors  such as:
camera :: always choose
if cameraon then if turncameraoff thennext micasoff elsenext cameraon 
if cameratakepicture thennext cameradone
 
if cameraoff then if turncameraon thennext cameraon elsenext cameraoff 
if camerafail then if micasreset thennext cameraoff elsenext camerafail
with1 
next camerafail with 1
opnav's tight interaction with hardware makes the overall process stochastic. we add probabilistic execution to our design features to model failures and uncertain outcomes. we add constraints to represent co-temporal interactions between state variables. summarizing  the key design features of rmpl are full concurrency  conditional execution  iteration  preemption  probabilistic choice  and co-temporal constraint.
1	rmpl: primitive combinators
our preferred approach to developing rmpl is to introduce a minimum set of primitives for constructing programs  where each primitive is driven by one of the six design features of the preceding section. to make the language usable we define on top of these primitives a variety of program combinators  such as those used in the optical navigation example. in the following we use lower case letters  like   to denote constraints  and upper case letters  like and   to denote well-formed rmpl expressions. the term  theory  refers to the set of all constraints that hold at some time point.
   . this program asserts that constraint is true at the initial instant of time.
　if thennext . this program starts behaving like in the next instant if the current theory entails . this is the basic conditional branch construct.
　unless thennext . this program executes in the next instant if the current theory does not entail c. this is the basic construct for building preemption constructs. it allows a to proceed as long as some condition is unknown  but stops when the condition is determined.
　　　. this program concurrently executes a and b  and is the basic construct for forking processes.
　always . this program starts a new copy of at each instant of time  for all time. this is the onlyiteration construct needed  since finite iterations can be achieved by using if or unless to terminate an always .
　choose with with . this is the basic combinator for expressing probabilistic knowledge. it reduces to program with probability   to program with probability   and so on. for simplicity we would like to ensure that constraints in the current theory do not depend upon probabilistic choices made in the current state. we achieve this by restricting all constraints asserted within and to be within the scope of an if next or unless next.
　these six primitive combinators cover the six design features. they have been used to implement a rich set of derived combinators  anonymous  including those in the opnav example  and most from the esterel language  berry and gonthier  1 . the derived operators for opnav  built from these primitives  is given in appendix a.
1	hierarchical  constraint automata
to estimate rmpl state trajectories we would like to map the six rmpl combinators to hmms and then perform belief update. however  while hmms offer a natural way of thinking about reactive systems  as a direct encoding they are notoriously intractable. one of our key contributions is a representation  called probabilistic  hierarchical  constraint automata  phca  that compactly encodes hmms describing rmpl models.
　phca extend hmms by introducing four essential attributes. first  the hmm is factored into a set of concurrently operating automata. second  each state is labeled with a constraint that holds whenever the automaton marks that state. this allows an efficient encoding of co-temporal processes  such as fluid flows. third  automata are arranged in a hierarchy - the state of an automaton may itself be an automaton  which is invoked when marked by its parent. this enables the initiationand terminationof more complexconcurrentand sequential behaviors. finally  each transition may have multiple targets  allowing an automaton to be in several states simultaneously. this enables a compact representation for recursive behaviors like  always  and  do until .
　the first two attributes are prevalent in areas like digital systems and qualitative modeling. the third and fourth form the basis for embedded reactive languages like esterel berry and gonthier  1   lustre halbwachs et al.  1   signal guernic et al.  1  and state charts harel  1 . together they allow complex systems to be modeled that involve software  digital hardware and continuous processes.
　we develop phcas by first introducing a deterministic equivalent  and then extending to markov models. we describe a deterministic  hierarchical  constraint automaton
 hca  as a tuple	  where:
is a set of states  partitioned into primitive states
and composite states . each composite state denotes a hierarchical  constraint automaton.
is the set of start states  also called the initial
marking .
　is a set of variables with each ranging over a finite domain . denotes the set of all finite domain constraints over .
is the set of observable variables.
               associates with each primitive state a finite domain constraint that holds whenever is marked.
　　　　　　　　　　associates with each primitive state a transition function . each
　　　　　  specifies a set of states to be marked at time   given assignments to at time .
at any instant the  state  of an hca is the set of marked states   called a marking. denotes the set of possible markings  where .
	consider the combinator always	  which maps to:

this automaton starts a new copy of at each time instant. the states of the automaton consist of primitive state   drawn to the left as a circle  and composite state   drawn to the right as a rectangle. the start states are and   as is indicated by two short arrows.
　a phca models physical processes with changing interactions by enabling and disabling constraints within a constraint store  e.g.  opening a valve causes fuel to flow to an engine . rmpl currently supports propositional state logic as its constraint system. in state logic each proposition is an assignment   where variable ranges over a finite domain . constraints are indicated by lower case letters  such as   written in the middle of a primitive state. if no constraint is indicated  the state's constraint is implicitly true. in the above example implicitly has constraint true; other constraints may be hidden within .
　transitions between successive states are conditioned on constraints entailed by the store  e.g.  the presence or absence of acceleration . this allows us to model indirect control and indirect effects. for each primitive state we represent the transition function as a set of  transition  pairs   where   and is a set of labels of the form or
     for some . this corresponds to the traditional representation of transitions  as labeled arcs in a graph  where and are the source and destination of an arc with label .
for convenience  in our diagrams we use	to denote the label
     and  to denote the label . if no label is indicated  it is implicitly true. the above example has two transitions  both with labels that are implicitly true.
　our hca encoding has three key properties that distinguish it from the hierarchical automata employed by reactive embedded languages benveniste and berry  1; harel  1 . first  multiple transitions may be simultaneously traversed. this allows an extremely compact encoding of the state of the automaton as a set of markings. second  transitions are conditioned on what can be deduced  not just what is explicitly assigned. this provides a simple but general mechanism for incorporating constraint systems that reason about indirect effects. third  transitions are enabled based on lack of information. this allows default executions to be pursued in the absence of better information  enabling advanced preemption constructs.
1	executing hca
to execute an automata a  we first initialize it using
           which marks the start states of all its subautomata  and then step it using   which maps its current marking to a next marking. 1
a trajectory of automaton is a sequence of markings such that is the initial marking   and for each  
.
　given a set of automata to be initialized  creates a full marking  by recursively marking the start states of and all their descendants:
is composite
for example  applying to automata always   returns the set consisting of always     and any start states contained within . transitions an automaton a from one full marking to the next:
::
is primitive

return
     involves identifying the marked primitive states  step 1   collecting the constraints of these marked states into a constraint store  step 1   identifying the transitions of marked states that are enabled by the store and the resulting states reached  step 1   and  initializing any automata reached by this transition  step 1 . the result is a full marking for the next time step.
　to transition in step 1  let be any transition pair of a currently marked primitive state . then is marked in the next instant if is entailed by the current constraint store   computed in step 1 . a label is said to be entailed by   written   if   and for each	.1
	applying	to the initial marking of always	causes
     to transition to and back to   and for to transition internally. the new mark on invokes a second copy of   by marking start states. more generally  is responsible for initiating a during every time step after the first. a transition back to itself ensures that is always marked. the transition to puts a new mark on at every next step  each time invoking a virtual copy of . the ability of an automaton to have multiple states marked simultaneously is key to the compactness of this novel encoding  by avoiding the need for explicit copies of a.
1	a simple example
as an example consider the rmpl expression:
do
always when	donext always if	thennext
watching
this expression roughly maps to:

　the automaton has two start states  both of which are composite. every transition is labeled   hence all transitions are disabled and the automaton is preempted whenever d becomes true. the first state has one primitive state  which asserts the constraint . if does not hold  then it goes back to itself - thus it repeatedly asserts until becomes true. the second automaton has a primitive start state. once again  at anytime if becomes true  the entire automaton will immediately terminate. otherwise it waits until becomes true  and then goes to its second state  which is composite. this automaton has one start state  which it repeats at every time instant until holds. in addition  it starts another automaton  which checks if holds  and if true generates in the next

1
	formally 	.
state. thus  the behavior of the overall automaton is as follows: it starts asserting at every time instant. if becomes true  then at every instant thereafter it checks if is true  and asserts in the succeeding instant. throughout it watches for
to become true  and if so halts.
1	probabilistic hca
we extend hca to markov processes by replacing the single initial marking and transition function of hca with a probability distribution over possible initial markings and transition functions. we describe a probabilistic  hierarchical  constraint automata by a tuple   where:
	 	 	and	are the same as for hca.
　　　　denotes the probability that is the initial marking.
　　　　  for each   denotes a distribution over possible transition functions .
the transition function is encoded as an and/or tree. we present an example at the end of the next section  when describing the choose combinator.
phca execution is similar to hca execution  except that probabilistically selects an initial marking  and
probabilistically selects one of the transition functions in for each marked primitive state. the probability of a marking is computed by the standard belief update
equations given in section 1. this involves computing and	.
　to calculate transition function for marking recall that a transition is composed of a set of primitive transitions  one for each marked primitive state   and that the phca specifies the transition probability for each primitive state through . we make the key assumption that primitive transition probabilities are conditionally independent  given the current marking. this is analogous to the failure independence assumptions made by gde de kleer and williams  1  and livingstone williams and nayak  1   and is a reasonable assumption for most engineered systems. hence  the composite transition probability between two markings is computed as the product of the transition probabilities from each primitive state in the first marking to a state in the second marking.
we calculate the observation function for marking from the model  similar to gde de kleer and williams 
1 . given the constraint store	for	from step 1 of
　　  we test if each observation in is entailed or refuted  giving it probability 1 or 1  respectively. if no prediction is made  then an a priori distribution on observables is assumed  e.g.  a uniform distribution of for possible values .
　this completes phca belief update. our remaining tasks are to compile rmpl to phca  and to implement belief update efficiently.
1	mapping rmpl to phca
each rmpl primitive maps to a phca as defined below. rmpl sub-expressions  denoted by upper case letters  are recursively mapped to equivalent phca.
	. asserts constraint	at the initial instant of time:

the start state has no exit transitions  so after this automaton asserts in the first time instant it terminates.
　if thennext . behaves like in the next instant if the current theory entails . given the automaton for   we add a new start state  and a transition from this state to when is entailed:

　unless thennext . executes in the next instant if the current theory does not entail c. this mapping is analogous to if thennext . it is the only construct that introduces condition . this introduces non-monotonicity; however  since these non-monotonic conditions hold only in the next instant  the logic is stratified and monotonic in each state. this avoids the kinds of causal paradoxes possible in languages like esterel berry and gonthier  1 .
unless
　　　. this is the parallel composition of two automata. the composite automaton has two start states  given by the two automata for	and	.

	always	. starts a new copy of	at each time instant  as
described in section 1.
　choose with with . reduces to with probability   to with probability   and so on. recall that we required that all constraints asserted within and must be within the scope of a next. this ensures that probabilities are associated only with transitions. the corresponding automaton is encoded with a single probabilistic start transition  which allows us to choose between and . this is the only combinator that introduces probabilistic transitions.

　encoding probabilistic choice requires special attention due to the use of nested choose expressions. we encode the transition function as a probabilistic and-or tree  below  left   enabling a simple transformation from nested choose expressions to a phca.

	a	b c	d	a	c b	c	a	d	b	d
　in this tree each leaf is labeled with a set of one or more target states in   which the automaton transitions to in the next time step. the branches of a probabilistic or node represent a distribution over a disjoint set of alternatives  and are labeled with conditional probabilities
p . these are in the left tree. the probabilities of branches emanating from each or node sum to unity.
　the branches of a deterministic and node represent an inclusive set of choices. the node is indicated by a horizontal bar through its branches. each branch is labeled by a set of conditions   as defined for hca. these are and in the left tree. during a transition  every branch in an and node is taken that has its label satisfied by the current state  i.e. 
p	 .
　to map this tree to   each and-or tree is compiled to a two level tree  shown above  right   with the root node being a probabilistic or  and its children being deterministic ands. compilation is performed using distributivity  shown by the figure  and commutativity. commutativity allows adjacent and nodes to be merged  by taking conjunctions of labels  and adjacent or nodes to be merged  by taking products of probabilities. this two level tree is a direct encoding of . each and node represents one of the transition functions   while the probability on the or branch  terminating on this and node  denotes .
1	phca estimation as beam search
we demonstrate phca belief update with a simple implementation of mode estimation  called rmpl-me  that follows livingstone williams and nayak  1 . livingstone tracks the most likely trajectories through the trellis diagram by using beam search  which expands only the highest probability transitions at each step. to implement this we first modify   defined for hca  to computethe likely states of
　　　　　. this new version  step   returns a set of markings  each with its own probability.
::
is primitive

return
step 1a builds the sets of possible primitive transitions. step 1b computes for each set the combined next state marking and transition probability. step 1c sums the probabilities of all composite transitions with the same target. step 1 returns this approximate belief state. in steps 1a and b  we enumerate transition sets in decreasing order of likelihood until most of the probability density space is covered  e.g.   . best first enumeration is performed using our opsat system  generalized from  williams and nayak  1 . opsat finds the leading solutions to the problem
  subject to    where is a state vector  is a set of propositional state constraints  and is an additive  multi-attribute utility function. opsat tests a leading candidate for consistency against . if it proves inconsistent  opsat summarizes the inconsistency  called a conflict  and uses the summary to jump over leading candidates that are similarly inconsistent.
　after computing the leading states of   rmplme computes using the constraint store extracted in step 1  and uses these results to compute the final result   from the standard equation.
1	implementation and discussion
implementationsof the rmpl compiler  rmpl-me and opsat are written in common lisp. the full rmpl language is an object-oriented language  in the style of java  that supports all primitive combinators  section 1  and a variety of defined combinators. the rmpl compiler outputs phca as its object code. rmpl-me uses the compiled phcas to perform online incremental belief update  as outlined above. to support real-time embedded applications  rmpl-me and opsat are being rewritten in c and c++.
　the ds1 opnav example provides a simple demonstration of rmp-me. in addition rmpl-me is being developed in two mission contexts. first  the c prototype is being demonstrated on the mit spheres formation flying testbed  a  robotic network  of three  soccer ball sized spacecraft that have flown on the kc-1. rmpl models are also being developed for the john hopkins apl near  near earth asteroid rendezous  mission.
　beam search is among the simplest of estimation approaches. it avoids an exponentialblow up in the space of trajectories explored and avoids explicitly generating the trellis diagram  but sacrifices completeness. consequently it will miss a diagnosis if the beginning of its trajectory is sufficiently unlikely that it is clipped by beam search. a range of solutions to this problem exist  including an approach  due to  hamscher and davis  1   that uses a temporal constraint graph analogous to planning graphs. this encoding coupled with state abstraction methods has recently been incorporated into livingstone  kurien and nayak  1   with attractive performance results. another area of research is the incorporation of metric time.  largouet and cordier  1  introduces an intriguing approach based on model-checking algorithms for timed automata. finally   malik and struss  1  explores the discriminatory power of transitions vs state constraints in a consistency-based framework.
acknowledgments
we would like to thank michael hofbaur  howard shrobe  randall davis and the anonymous reviewers for their invaluable comments. this research is supported in part by the darpa mobies program under contract f1-c1 and by nasa csoc contract g1.
a	rmpl defined operators
to express complex behaviors in rmpl  we use the six rmpl primitives to define a rich set of constructs common to embedded languages  such as recursion  conditional execution  next  sequence  iteration and preemption. this section includes a representative sample of rmpl's derived constructs  used to support the ds1 opnav example.
recursion and procedure definitions. a recursive declaration is of the form   where may contain occurrences of procedure name . we implement this declaration with always if then . at each time tick the expression looks to see if p is asserted  corresponding to p being invoked   and if so starts a. this method allows us to do parameterless recursion. recursion with parameters is only guaranteed to be compilable into finite state automata if the recursion parameters have finite domains.
next . this is simply if thennext . we can also define if thennext as if thennext unless thennext .
a; b. this is the sequential composition of and . it performs until is finished. then it starts b. it can be written in terms of the preceding constructs by detecting the termination of by a proposition  and using that to trigger . rmpl detects the termination of by a case analysis of the structure of .  fromherz et al.  1  for details . for efficiency  the rmpl compiler implements a; b directly  rather than translating to basic combinators.
do while . executes   but if is not true in a state  then is terminated immediately. this combinator can be derived
from the preceding combinators as follows:
do	while do if	thennext	while
	if	thennext do	while
do while do while do while do always while always if then
	do	while	next
do unless thennext while if then unless thennext do while
	do choose	with	with	while
	choose do	while	with	do	while	with
　for efficiency  rmpl derives the automaton for do while from the automaton for a by adding the label to all transitions in   and in addition  replacing all the propositional formulas in the states by . thus if is not entailed by constraints outside of a  no transition or constraint in this automaton will be enabled.
do watching . this is a weak preemption operator. it executes   but if becomes true in any time instant  it terminates execution of in the next instant. the automaton for this is derived from the automaton for by adding the label on all transitions in .
when donext . this starts at the instant after the first one in which becomes true. it is a temporally extended version of if thennext . and is defined as:
when donext always if thennext do always watching
