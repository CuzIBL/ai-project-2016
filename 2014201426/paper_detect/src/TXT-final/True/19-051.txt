 
one of the major 'weaknesses of current automated reasoning systems is that they lack the ability to control inference in a sophisticated  context-directed fashion. general strategies such as the set-of-support strategy are useful  but have proven inadequate for many individual problems. a strategy component is needed that possesses knowledge about many particular domains and problems. such a body of knowledge would require a prohibitive amount of time to construct by hand. this leads us to consider means of automatically acquiring control knowledge from example proofs. one particular means of learning is explanation-based learning. this paper analyzes the basis of explanations - finding weakest preconditions that enable a particular rule to fire - to derive a representation within which explanations can be extracted from examples  generalized and used to guide the actions of a problem-solving system. 
1. introduction 
　　the current generation of automated reasoning systems is characterized by very sophisticated inference mechanisms but relatively simple mechanisms for guiding inference. typical strategies consider the set of existing clauses  the  clause space   and the recency of derivation of each clause. useful general strategies can be formulated with this information. unfortunately  these weak strategies have proven inadequate in many instances. 
　　in order for a strategy to be able to respond to features of individual problems and domains it must have access to a large body of knowledge. in addition  it must take into account more types of information than just the clause space and the recency of the clauses. this paper describes how strategy information can be automatically learned from examples by explanation-based learning  and presents a metalanguage that permits the use of more sophisticated strategies and facilitates the analysis of explanations. 
　　explanation-based learning is a widely-used technique in ai      it has been used to generalize methods within a top-down problem-solver  to generalize control information  to facilitate interaction with users  and to refine knowledge bases. logically formulating explanation-based learning provides us with two strengths that logic typically contributes to the problem-solving process: 
a precise notation for describing explanationbased learning; 
the precise semantics of logic  which provides a semantics for precondition-based reasoning . 
1 knowledge aq 
also  formulating explanation-based reasoning within a 
logical framework permits its application to areas of mathematics for which standard axiomatizations exist  such as group theory. this opens the possibility of using explanation-based learning to acquire general strategies to guide theorem-proving systems in such domains. this paper presents one facet of our research on metatheoretical formulation of strategies  l   . 
1. formalizing explanations 
　　in order to be able to use explanation-based learning in a wide variety of domains and to more fully understand its strengths and weaknesses  it is desirable to formalize the use of explanations. we present a system which formalizes the organization  acquisition and generalization of control rules. 
　　many production system  1  architectures distinguish between two types of information. the first type consists of the rules for manipulating the objects in the task environment  often called the object-level  rules. we will consider the system to be initially provided with a fixed set of object-level rules. we can think of these rules as corresponding to the statements in a programming language. the second type of information contains the knowledge about how to fire the objectlevel rules in order to successfully achieve a goal. this information is sometimes referred to as  meta-level  information  1l. we can think of this information as descriptions or programs written in the language of object-level rules. we use a production system as the object-level language in order to illustrate the usefulness of this approach to an existing ai programming system  and to take advantage of the conflict set  a data structure that contains the set of fully instantiated rules. production systems compute the conflict set  but theorem-proving programs typically do not. 
     the object-level rules contain all the initial domain-specific procedural knowledge in the system  and therefore constitute a model of problem-solving in the domain. an object-level rule can be viewed as a 
     transformation  and an example execution trace is then a sequence of transformations leading from the initial state to the goal state. thus  an example execution trace is a proof that the goal state is reachable from the initial state via the object-level rule set  or alternatively  that the initial state is a sufficient precondition to guarantee the truth of the goal condition after executing a specific sequence of instructions. this observation permits us to construct a system that examines object-level proofs. 
　　such proofs are valid only to the extent that the object-level rule set is correct. if the object-level rules contain errors or omissions  then a proposed proof may be incorrect  or the system may not be able to find a 

proof that exists. for example  if the domain is manipulations of a robot arm  then the object-level rules are all possible movements of the arm. in this case  it is possible to formulate a complete and correct set of object-level rules. on the other hand  if the domain is medical diagnosis  then this is not possible. in the following sections  we describe a language for describing the state of the object-level production system that facilitates reasoning about problem-solving methods. 
	1. 	the space of rule instantiations 
     a ground instance of a rule is called a rule instantiation. when a system draws inferences from its 
knowledge of its possible actions  we say that it is reasoning in instantiation space. in order to reason in this space  it is necessary for a system to have a language that provides access to its rule instantiations. 
     at each point in the execution of a task  the state of a system can be represented in terms of its full and partial instantiations. this representation captures existing and possible relationships among working memory elements. in addition  given a sequence of such state descriptions  i.e. a trajectory in instantiation space  we can derive relationships among instantiations. in particular  explanation-based reasoning is based upon the precondition relationship  in which an instantiation helps another instantiation to become 
matched by either placing an element needed by that instantiation in working memory or removing an element that matches a negated condition in that instantiation. precondition analysis has been used in the derivation of programs  and in the formulation and modification of plans . the representation described in the next section combines waldinger's approach to planning with davis' approach to reasoning about rules and controlling rules   1j. 
1. the representation 
　　this section provides a very brief description of the representation. detail is omitted for brevity and clarity. the production system used is ops1 . the ops1 system does not have the capability of accessing its matching network as data for the productions. this precludes writing ops1 meta-rules. thus  we have designed the meta system to sit above the ops1 system  and access its internals. each object-level rule is represented at the meta-level as a term of the  form: rule variables  -  action 1 & action1 ... where  rule  denotes the the left-hand side of a rule  and each actioni denotes an action that can be executed. for example  the following ops1 rule is from the monkeyand-bananas problem  a well-known ai task in which a monkey must retrieve a bunch of bananas from the ceiling using a ladder.  
which moves the monkey to an object's location  is represented as: walk 1 p c  - + modify monkey at p . the parameters of the  walk  function are the variables in the rule definition. instantiations of the  walk  object-level rule are represented as meta-level terms  which permits the meta-system to reason about the rules that are fire able. 
     representing rules in this way permits rules to be characterised both according to their variable bindings  and according to the actions that they perform. this 
	benjamin 	1 

1 	knowledge acquisition 

