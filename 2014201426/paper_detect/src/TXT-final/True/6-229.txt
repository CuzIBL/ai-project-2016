 
in many real-world tasks of image classification  limited amounts of labeled data are available to train automatic classifiers. consequently  extensive human expert involvement is required for verification. a novel solution is presented that makes use of active learning combined with an ensemble of classifiers for each class. the result is a significant reduction in required expert involvement for uncertain image region classification. 
1 	introduction 
multimedia contents arc rapidly becoming a major target for data mining research. this work is concerned with image mining  discovering patterns and knowledge from images for the purpose of classifying images. the specific problem we address is image region classification. egeria densa is an exotic submerged aquatic weed causing navigation and reservoir-pumping problems in the sacramento-san joaquin delta of northern california. as a part of a control program to manage egeria  classification of regions in aerial images is required. this problem can be abstracted to one of classifying massive data without class labels. relying on human experts for class labeling is not only time-consuming and costly  but also unreliable if the experts are overburdened with numerous minute and routine tasks. massive manual classification becomes impractical when images are complex with many different objects  e.g.  water  land  egeria  under varying picture-taking conditions  e.g.  deep water  sun glint . the main objective of the project is to relieve experts from going through all the images and pointing out locations where egeria exists in the image. we aim to automate the process via active learning to limit expert involvement to decisions about which the automatic classifier is uncertain. 
　the contributions of this work are a novel concept of classspecific ensembles  and learning class-specific ensembles. we notice that different types of classifiers are better suited to detecting different objects such as egeria  land  water. since it is impractical to train one classifier for each object  as experts need to provide training instances for all objects   we propose a novel approach to class-specific ensembles. we also discuss how to combine individual classifiers to learn class-specific ensembles. we show that this approach significantly reduces the number of uncertain image regions and is better than a single ensemble for the task of object detection. 
1 	class-specific ensembles 
we may tend to use as many classifiers in an ensemble as possible because  1  each classification algorithm may have a different view of the training image and capture varied aspects of the image  as different classification algorithms have different biases and assumptions; and  1  no single classifier can cover all aspects. in other words  some algorithms may succeed in capturing some latent information about the domain  while others may fail. however  problems can result from using too many classification algorithms: e.g.   1  using more classification algorithms can result in longer overall training time  especially so if some of the algorithms are timeconsuming to train; and  1  some algorithms may be prone to overfitting. if these algorithms are included in the ensemble  there may be a high risk of allowing the ensemble to overfit some training image s . the above analysis suggests the necessity of searching for a relevant set of classifiers to form ensembles. exhaustive search for the best combination is impractical because the search space is exponential in the total number of classification algorithms for consideration. thus we need an efficient methodology to find the optimal combination of classifiers for the class-specific ensembles. 
　we adopt three performance criteria for this work: precision  recall  and number of uncertain regions  uc . the first two standard measures are defined in terms of the instances that are relevant and the instances that are classified  or retrieved . the third one is the number of instances  regions in an image  the class-specific ensembles cannot be certain about their class predictions. high precision or high recall alone is not a good performance measure as each describes only one aspect of classification. together they provide a good measure: for example  the product of precision and recall  pr . if both values are 1  their product is 1  which means all and only positive instances are classified as positive. hence  pr is a measure for both generality and accuracy. f measure can be used for the same purpose. 
1 	learning class-specific ensembles 
in order to learn class-specific ensembles  we need a data set that links classifiers to the label of each image region. this 

poster papers 	1 

new data set can be obtained by applying all the classification algorithms to the training image so that each classifier is a feature  i.e.  a column  and its value is the prediction of the classifier. for each image region  one instance in the new data set   there are predictions of all the classfiers and also the class label 'egeria' or 'non-egeria' given by experts. we are concerned only with those rules that have the class label egeria or not as the consequent. we will restrict our search to such rules and obtain rules with the maximum number of features  classifiers  in the precedent without a significant loss in support or confidence. the best rule for each class label indicates the best combination of classifiers for the ensemble. 
　among many learning algorithms for classification  clustering  and association rules  we observe that association rule algorithms lagrawal and srikant  1 can search the attribute space to find the best combination of attributes associated with a class. our algorithm is presented in figure 1. it takes as input the entire set of classification algorithms e and training data tr with class labels /tr  and produces as output two ensembles for class label yes and class label no. 
the next task is to use the dual ensembles  ei=yes and 
el-no  to determine certain and uncertain instances. we need to decide the maximum number of classifiers in an ensemble that should agree on a prediction to reach a decision of  certain  or  uncertain  for each ensemble. an ensemble with all classifiers being required to agree on a prediction would lead to high precision  but low recall; an ensemble with few classifiers being required to agree would lead to high recall and low precision. we need to find a balanced number of classifiers with which the ensemble gives the best estimated precision and recall. the training image is used again for this task. 
　the dual ensembles el-yes and el=no work together to decide if an instance's prediction is certain or not following the rule of majority. in predicting an instance  if both el=yes and el=no are certain with their predictions  follow the one with more agreeing classifiers; if one is certain and the other is uncertain  follow the certain one; if both are uncertain  the 
experiments and evaluations 
with the principal goal of reducing the burden on experts  we use only one image for training and apply the learned results to another 1 testing images of different areas for detection. among the classification algorithms available in the machinelearning package weka  witten and frank  1   we select all that can be applied to the image domain to ensure a variety of classification algorithms. we apply the algorithm in figure 1 with the complete set of classification algorithms as input. the class-specific ensembles found by association rules are: class = yes decision trees c1  alternating decision trees  decision trees  part   prism  hyper pipes  
kernel density  logistic  decision tables; and class = no 
   id1  alternating decision trees  decision trees  part   prism  kernel density  instance based 1  decision tables. 
　we design 1 experiments and provide the summarized results here  the details will be provided upon request . 
experiment 1. we compare the use of dual ensembles with that of single ensembles  either 
the average ucincrease  increase in un-
certain regions  is almost 1% and the average prgain is 1%. it is observed that in general  dual ensembles are not only more accurate  but also separate certain and uncertain instances better than single ensembles. 
　experiment 1. we compare the learned dual ensembles to 1 randomly selected dual ensembles. each classifier is randomly chosen and learns from the training image. although the average prgain is only decreased by 1%  the ucincrease increases significantly by 1%'. hence  it is necessary to search for relevant dual ensembles  as random dual ensembles work poorly in reducing uc. 
　experiment 1. we compare the learned dual ensembles to results obtained by the classification rules of domain experts. the experts' rules outperform the learned dual ensembles in terms of prgain by 1%  but the number of uncertain instances  uc  increases by 1% the high prgain and high uc for the expert classification rules is due to the fact that an expert can only directly work on the former  designing highly general and accurate rules   but not on the latter  finding low uc rules . our system is particularly designed to compensate in this shortcoming. 
1 	conclusion 
we present a novel approach to active learning with ensembles of classifiers. one ensemble is trained for each class. extensive experiments were conducted in the real-world domain of detecting seaweed in aerial images. 
