 
are we justified in inferring a general rule from observations that frequently confirm it  this is the usual statement of the problem of induction. the present paper argues that this question is relevant for the understanding of machine learning  but insufficient. research in machine learning has prompted another  more fundamental question: the number of possible rules grows exponentially with the size of the examples  and many of them are somehow confirmed by the data - how are we to choose effectively some rules that have good chances of being predictive  we analyze if and how this problem is approached in standard accounts of induction and show the difficulties that are present. finally  we suggest that the explanation-based learning approach and related methods of knowledge intensive induction could be a partial solution to some of these problems  and help understanding the question of valid induction from a new perspective. 
1 	the traditional problem of induction 
induction seems to escape all deductive explanations  because its conclusions cannot be proved to be correct. worse than this  it is not even possible to prove that they are correct most of the time  unless we are ready to accept very elaborate and questionable premises. many conclusions obtained by an inductive process are totally wrong  although infinitely many examples confirm them. some actually get worse as more confirming evidence is found. the philosophical literature is full of such examples; for instance  let me paraphrase a bit the well known argument of goodman  goodman  1 . sup-
pose we define a learning system of  unexpected value'1 as a system that performs quite badly until august 1  1  and then starts to produce incredibly good results. if one was to believe blindly in the power of induction  then an l1ca1 paper describing all kinds of very poor results and emphasizing how badly their system works would thus confirm in many ways that the system is of 
   *i am grateful to paola dessi'  stuart russell and lorenza saitta for helpful comments on a draft version 
 unexpected value . the more and the more varied the confirming examples that are possible before the ijca1 conference  the worse the conclusion seems to follow. 
　in this paper  we analyze the problem of induction in a computational framework  where it is possible to make clear the assumptions that we could rely upon when we  or computers  infer general rules that are justified only by a finite number of confirming examples. 
　when the scope of the enquiry is so restricted  one of the most authoritative approaches to the problem is statistical estimation  as developed  for example  by neyman. this theory is very well known  but the following will make our later discussion clearer. suppose  for example  that we are to estimate the mean  of a given population  that we know to be normal and with standard deviation . let us observe a sample having mean 
　then  because of the properties of the normal distribution  we may say that  with probability 1 
		 i  
that is to say  we have estimated the value of the real mean with some precision  and we know we are right with high probability. this is a form of inductive reasoning  since we have inferred a general statement about  a large population from the observation of a limited number of facts. but the puzzles seem to have vanished because we now know that we are right most of the time. this  as neyman also believes  follows deductively from the premises. alas  the premises are quite hard to demonstrate and cannot be taken as intuitively plausible  as they involve knowledge of the form of the distribution and of some of their parameters. it seems that what we are required to know before we perforin any experiment is much more than what we are actually able to infer. moreover  this technique deals with the estimation of parameters in a continuous domain  so that approximation with an interval makes sense; it is not clear how this can be adapted to inductive arguments in general. 
　these problems have led many researchers and practitioners to adopt the alternative approach of subjective bayesian inference. in this framework  probabilities of inductive hypotheses are defined as subjective degrees of belief and objective data are used to update their values. all that is needed for the updating is the application of bayes' theorem. the bayesians defend themselves from the difficulties of subjectivism by arguing that the precise value of prior probabilities is not important: in many 

cases even large differences in the prior probabilities lead to the same conclusions if sufficient data are provided  e.g.  edwards et a/.  1  . we will argue later that in many other cases relevant to induction and ai this is not true. subjective bayesian induction  as well as traditional statistical reasoning  is often concerned with the inference of numerical parameters when various kinds of continuity assumptions are acceptable. such assumptions are quite far from the mark when dealing with logical hypotheses such as the ones we work with in many fields of science and particularly in ai. 
　an approach that emphasizes the logical and symbolic aspects of inductive reasoning is the framework of inductive logic  as developed  for example  by carnap and hintikka. in their views  the probability of some statement is defined on the basis of the ground conjunctive expressions that it implies. in carnap's theory  for instance  the function indicates the degree  or the strength of the implication and is defined as follows: 

where in indicates some measure of the extension of a formula  that is of how many and how important are the basic statements covered by the formula. some such measures allow one to justify inductive inference  in the sense that a positive example e of a general rule  f  will be such that where k is our previous knowledge. unfortunately there are  as carnap finally came to admit  infinitely many such functions  and there is no objective criterion for preferring one over the other. moreover  the choice of the confirmation function will have profound effects on what one actually deems to be credible on the basis of the very same evidence. 
　but before we move on to further analysis and criticism  we must discuss the new challenges and the new aspects of induction that have been brought to our attention by the recent research on machine learning. 
1 	n e w issues r a i s e d b y m a c h i n e l e a r n i n g 
let us start with a terminological question. induction  in machine learning  is not only taken as the inference from observations to given general rules. it includes the search for these rules in a large set of possibilities. this is not always so in the philosophical literature; for example peirce seems-to be calling  abduction  the choice of the hypotheses  and  induction  the leap from observing the chosen hypotheses work on the available data to accepting them in general. also when dealing with scientific reasoning  the works on induction are mainly concerned with the testing of some theory which is already given  and strive to justify the conclusions that are derived from the test. we argue  on the contrary  that it is the search and the choice of a plausible inductive hypothesis that is problematic  more than the inductive leap per se. 
　this issue is emphasized in machine learning and ai also because of the great importance given to inductive hypotheses of a logical form. the move from numerical to symbolic al-oriented learning methods has prompted 
1 	philosophical foundations 
the problem of the very great number of possible rules moreover the rules are quite unrelated and distinct: it is hard to see how one rule can be accepted as an approximation of another. the problem at hand is very different from the one of numerical estimation  where the hypotheses are embedded in a continuous space of ordered values. for example  if the standard deviation is 1 and we estimate the mean from a sample of size 1  we will regard as practically equivalent the hypotheses and on the contrary  even if we were to translate a logical space of hypotheses into a numerical representation  e.g. by means of a godel numbering  we could by no means consider hypotheses n and n + 1 to be  close  in any other sense. 
　nevertheless  both because of cognitive and knowledge engineering motivations  we cannot set aside our goal of learning symbolic information. the problem of induction is in this case related to the problem of chosing an inductive hypothesis in a large space of distinct possibilities and this choice leads us to a twofold discussion. on the one hand we are to analyze the predictivity of induction from a new perspective  that turns out to be rather pessimistic with respect to the standard account of statistical estimation. on the other  we are concerned with the computational complexity of inductive inference. 
1 	a new understanding of predictivity 
this analysis will be limited to the problem of concept acquisition. in this framework we are given concept examples and counterexamples in the form of ground con-
junctive expressions  and we search for propositional or first order descriptions of the concepts. for instance  we may be given an example of a  block's world car  as follows: 

and we might learn from the above and other examples the following description of the concept  block's world car : 
　　　　　  1  although this description may seem insufficient  it could result from the learning process if it distinguishes well enough the examples from the counterexamples of the concept. 
　if we were given a concept description such a.s the above and were asked how predictive it is  i.e.  how well it could distinguish independent examples and counterexamples of block's world cars  we could use bernoulli's limitation1: 
  1  
were m is the number of examples and counterexamples that we have seen  the ones the observed-error is computed from. true error is the recognition error that would be observed on all the possible examples1. if 
　　1 this limitation is found in the original proof of his theorem. the constants have been improved upon in an inequality of hoeffding  hoeffding  1 . 
1
　　there is a finite number of possible examples representable with conjunctive ground expressions without functions  if the number of available predicates and constants is finite  as it usually is. 

the number of examples is sufficiently large  the above limitation states that  with high probability  the performance of the given concept description as measured on the available examples is quite close to the performance that we may expect on new examples. 
　unfortunately  this is not what we call induction in machine learning. this would just be the testing of a hypothesis supplied by an oracle. normally  this hypothesis is not given and we must search for the best one in a very large number of possibilities. if we are asked how predictive we expect this best hypothesis to be  we cannot use bernoulli's limitation  which is valid when the recognition rule is fixed  but we must modify it into the following  vapnik  1; devroye  1  : 

where  is the set of hypotheses that are possible. better limitations may be found  but this is the basic idea. 1 torn this we see that a large number of possible rules has very bad effects on predictivity. in other words  the larger the language that we use for learning the concept descriptions  the worse the correspondence between the observed and the unknown. obviously  there is an advantage in having a larger set of hypotheses: the observed error rate is likely to be reduced  because by trying more rules we have more chances of finding one that performs well on the training data. nevertheless  this advantage may vanish when we move to classify new examples. 
　when performing induction with a machine  one cannot ignore this fact  which is constantly observed in machine learning experiments. as a consequence  much emphasis has been given to  bias  or preference criteria 
 mitchell  1; bergadano el a/.  1; bergadano el a/.  1   for choosing only the hypothesis that are deemed plausible a - priori. 
1 	the problem of computational complexity 
it is not sufficient that learning be predictive  it must also be performed efficiently. if the time needed for obtaming predictive concept descriptions grows exponentially with the size of the examples  e.g. the number of propositional variables   then induction may turn out to be practically unfeasible. following the work of valiant  valiant  1a; valiant  1b  there has been a growing interest on these aspects of induction  giving rise to the new field of computational learning theory. 
　in that approach  the dimension of the problem depends both on the size of the examples and on the accuracy that is required  i.e. the value off in the above limitations . it can be shown that if the language used for formulating the inductive hypotheses is not adequately restricted  learning accurate hypotheses is np-hard. for example  under some general assumptions  disjunctive normal form propositional formulas with at most k terms are  not learnable   kearns et a/.  1   in the sense that the computation time grows exponentially with the size of the examples and the required accuracy. in other words  it turns out that even relatively simple description languages cause the search for accurate inductive hypotheses to be practically impossible when the size of the examples is large. 
　it is indeed very interesting that predictiveness and complexity are so closely interrelated. here is the tradeoff: if the language for expressing inductive hypotheses is simple and contains few alternatives  then we may not be able to find a description that discriminates the available examples  i.e. we cannot adequately describe the observations; if the language is too complex then it may take too long to find acceptable hypotheses and what we find may turn out to perform badly on new data  i.e. we cannot produce effectively reliable predictions of the unobserved. 
1 the above problems as addressed by standard accounts of induction 
when learning classification rules  we want to estimate the performance  of the hypothesis that we have found to be the best for the given examples. for this purpose it is sufficient to evaluate the probable difference e between the error observed on the data and the error that we want to estimate: 

where  is what we deem to be a high probability  e.g. 1 ; e will then be the probable performance loss when moving from past to future examples. limitation  1  allows us to compute f given n  m  the number of learning 
examples  and  
　this analysis does not take into account the nature of the hypothesis space    it only counts the number of its elements. it may be the case that the possible hypotheses  while being many  are very similar  in the sense that they classify the possible examples  about  in the same way. in particular  there may be an infinite number of possible hypotheses  but there are at most 1m ways of classifying a set of m examples. the work of vapnik and chervonenkis  vapnik  1  has extended traditional estimation methods to deal with these problems  and provided limitations such as  1   where the cardinality of the hypothesis space is replaced by a measure of its expressiveness. even if there is an infinite number of possible hypotheses  e.g. the set of linear discriminants   their expressiveness when classifying m examples may be limited  and often much lower that 1 m . nevertheless  the bounds that may be found following this approach are quite inadequate for the symbolic languages used in machine learning  pearl  1; bun tine  1; bergadano and saitta  1 . suppose that we fix n and e in the above limitation  and we want to known the minimum number m of examples needed for this level of probable performance. it turns out that this number is much larger than the number of examples that ml programs seem to need. 
　the subjectivist bayesians have often criticized the traditional approach to statistical inference and proposed an alternative approach that could alleviate some of the above problems  lindley  1; howson and urbach  1 . to the concept of a sample space they have substituted subjective prior probabilities  and have defended themselves from the problems of subjectivism in science by noting that  when sufficient data are available  the posterior probabilities will converge to the same values  even for very different initial priors. from the above discussion  it seems that there is a more fundamental problem in inductive inference  when explained in terms of objective probabilities: the arbitrariness of the hypothesis space. the choice of which hypotheses are possible is as crucial as the definition of the sample space  i.e.. which examples are possible . if the hypotheses are unrestricted  or even just too many   what we learn will not be probably predictive  if they are few and badly chosen  we will not even describe effectively the available data  and may expect bad performance on new examples as well. the subjectivist approach would subsi it ute prior probabilities of hypotheses to the concept of a hypothesis space. we would not define a minimum number of examples needed to make learning predictive  but will just update the probabilities as we see new examples  making more probable the hypotheses that are confirmed by the data. it would seem that the problem of the prohibitive number of examples is avoided  enabling a learning system to learn even from limited information. 
　unfortunately  in symbolic machine learning it is no longer true that the choice of the priors is not critical  and is corrected by sufficient data. this is easily seen in the following example. suppose we give equal prior probabilities to any hypothesis of a propositional language with n variables; then the best classifier on the available examples will always be just the disjunction of the example descriptions. needless to say  its predictiveness will be null  unless future examples are perfectly equal to the ones that were seen . by contrast  if we give non-zero prior probabilities only to a small  fixed set of hypotheses  the learned description will not be equivalent to the disjunction of the examples and might be predictive according to whether the priors are well chosen and to how many examples we see. in general  if we have not seen most of the 1n examples  the two above choices of priors will not converge to the same result. 
　we then need to face the problem of subjectivism  because the irrelevance of the prior is no longer an excuse. of course  the choice of a sample space is as arbitrary as the choice of a prior probability  lindley  1 . but there is certainly a difference between  subjective  and  arbitrary . the premises of any inference are  in a way  arbitrary  in the sense that one has to chose them on the basis of no other reason at all. the chain of  why  and  because  has to stop at some point and there are assumptions which either correspond to self-evident facts or which we accept without further enquiry. a subjective probability is not an  arbitrary  assumption in this sense. it is not clear when the assumption is true or false  even if we were to obtain the whole factual information that is needed  i. e. the meaning of a subjective probability is not clear. but this is only my  subjective  opinion. 
　the fact that the choice of the priors is in fact very important is connected to another traditional criticism to 
1 	philosophical foundations 
subjectivist bayesian induction  which is usually stated as an unrelated question: hypotheses that are constructed explicitly to fit the data should not be confirmed by the very same data. by contrast  bayesian updating does not distinguish among hypotheses that were generated at different times  or with different intentions. for example  if one sunday we perform an experiment and we see that our scientific theory is wrong  we should not just correct it by adding that our laws only work during weekdays. nevertheless  bayesian updating will increase the probability of the corrected theory. on the other hand  it is hard to explain why one should prefer theories that where generated before seeing any datum. this is the same as saying that the credibility of scientific hypotheses depends on the order some particular scientist performs his actions. the puzzle can be explained  1 think  if we understand that the choice of the priors is actually important. if we give non-zero probability to many hypotheses of high complexify  it may happen that inductive inference comes out with rules such as the sunday-excluding theory. if  on the contrary  we chose only some hypotheses as possible  and we give them nonzero prior probabilities  then we may not be able to obtain high posterior probabilities for any of them. the problem of defining a suitable hypothesis space is essential when learning symbolic concept descriptions  both in the traditional and in the subjectivist accounts of induction. 
1 is explanation-based learning a possible answer  
there is an understanding of the word  learning  that is apparently unrelated to induction  for instance  after our first few tic-tac-toe games  we might have  learned that the second move in fig. 1 should never be made because it leads to certain loss. 

　this is in fact a simple form of explanation-based learning  ebl . here is another example: suppose we are given peano's arithmetic and the fact then we could  learn  the commutative property of addition. this is in fact a deductive consequence of the theory but  learning  has somehow been guided by the example. as a more general case  suppose we have the following first order theory  defining the predicate p: 
		 1  
and the ground formula  which will serve as an example of the concept p. we may now learn  through ebl  a specialized description of p  by substituting the theory of  1  with 
		 1  
this example may look trivial  and in fact it is  but i i hink it shows precisely the basic idea behind ebl. here the theory  1  plays the role of the rules of tic-tac-toe in the first example and the ground formula corresponds to the board situation of fig. 1  a similar correspondence holds with respect to peano's arithmetic 
 iii.| the fact  in the second example. 	a 
miven theory has a number of deductive consequences 
 in the extreme case of  1  these consequences are just the two disjunctive components of the theory itself  or their instantiations   we are given some examples or ob .nations about the predicates involved in the theory and we  learn  a subset of the deductive closure of the theory which allows us to explain the observations. 
　there has been quite a number of interpretations of this form of reasoning from examples to rules with logical constraints that justify the conclusions. some have argued that ebl is not truly learning  because it is just a form of deduct ion. others have stressed  that  although this form of inference is in fact truth-preserving  there is nevertheless some degree of generalization from the available data. for example  in the above tic-tac-toe name  we might have learned not only that this particular move is wrong  but that  in general  any move on a middle-side position is wrong. similarly  formula  1  is more general than . others have compared 
ebl to lemma generation and to partial evaluation. 
　these perspectives  though all correct  fail to show that. ebl is actually related to induction  and in an important way. let me put forward an alternative definition: fauj is inductive inference with a logical definition of the hypothesis space. 
   the fact that ebl was not unrelated to induction was noticed early on  when systems started to include statistics of how often a given ebl-generated rule was used; the most frequently used rules were kept in the knowl --dgc base  and the others were discarded. in other words  it was soon understood that  although the learned rule is certainly correct   it follows deductively from the theory   the fact that it will be of some utility on future examples is not guaranteed  and the assumption implies an inductive leaf . for instance  it is certain that  but it is not certain that by adding this rule to peano's axinns we will prove more efficiently a given theorem. for this reason ebl is often performed with more than one example - for instance the commutative property of addition may be established as another axiom only after seeing more cases were it is useful i and 

　in the usual approach to inductive learning  any hypothesis may be generated  if it explains the data and 
satisfies general constraints  e.g. being a dnf formula with less than n terms . in ebl  only the hypotheses that may be obtained deductively from the theory are possible. the examples are used to select  among the hypotheses that are possible  the ones that seem to perform well. 
   if the theory is complete and correct1  the only risk is that the ebl-generated rules do not represent the most useful part of the theory: these rules are a subset of the deductive closure of the theory  and as such they must continue to be correct  but when they are used alone  without the rest of the theory  they may be incomplete and fail to classify new examples - this will occur more often if the training examples were biased or insufficient. 
   if the theory is incorrect and/or incomplete1  then this only means that a 1% correct rule for our learning examples may be excluded from the hypothesis space. this corresponds to the general stochastic classification problem in pattern recognition  and is not necessarily a harmful situation if the hypothesis space is well chosen and of a limited size. restriction to correct hypotheses  the deterministic problem  often leads to larger search spaces and degrading performance  bergadano and saitta  1. this is apparently contradicted by the fact that in the deterministic case we can obtain formulas such as  1   where e'1 is substituted by e  yapnik  1; blumer et al.  1   leading to better limitations of the number of examples needed for a specified performance. nevertheless  in order to be sure that a 1% correct rule is possible  the hypothesis space lias to be larger  and  as a consequence  the difference between the observed error  which is 1  and the true error grows. this is also observed experimentally when pruning decision trees  quinlan  1  or simplifying logical descriptions  bergadano et al.  1 . 
   the possibility of describing a hypothesis space in a knowledge-based style is an important advantage of ebl and other forms of declarative bias  e.g. determinations  russell  1  1. it allows us to inform our inductive procedures of the basic constraints that are present in a given domain  e.g. the meaning of high level features usually employed by experts  or maybe the results of automated learning on another  similar  domain'. we have argued that the definition of a good hypothesis space is responsible for the difficulty of induction and some-
1
     in ebl  a domain theory is said to he complete when it is able to classify any example. the theory is correct if all the classifications that are produced correspond to the a priori classification of the examples. 
1
     there has been substantial work on ebl with incorrect and incomplete theories  for example many papers in the 1 machine learning workshop on  combining empirical and explanation-based learning  are devoted to this problem  proceedings published by morgan kaufmann  
     induction in the deterministic and in the stochastic case have also been distinguished in the philosophical literature  for instance mill calls the latter  approximate generalization  and keynes speaks of  universal induction  and  inductive correlation   respectively. keynes discusses inductive correlation separately  in the context of statistical inference in the last part of his treatise on probability. here we basically view the two cases as instances of the same problem 
1
     an alternative perspective that distinguishes ebl from declarative bias is found in  russell  to appear  
1
     this feature is related to what is called  local induction  in the philosophical literature  kyburg  1   i.e. induction that is based on knowledge that was itself obtained with some form of inductive reasoning. 
times the reason of the paradoxes of inductive inference. therefore  we must devote our efforts to this goal  acquire knowledge about the domain of a given inductive problem  understand the basic constraints  and transform all this into a domain theory  the logical definition of the hypothesis space. 
1 	conclusion 
of rourse  this is a good start  but it is not a solution of the problem. with ebl we have  in some sense  a good programming language for describing the hypothesis space. but how to write a good program  how to know which hypotheses we should regard as possible  the statistical analysis which we have discussed above might give us some advice about how many these hypotheses should be  if we want to avoid total degradation of performance when moving to test examples. but this advice  which has been compared to occam's razor  blimier et al  1   is so pessimistic  that it is more adequately associated to an axe. according to theoretical analysis  even when quite many examples are available  we should restrict our search to very few hypothesis; as a consequence  we will easily obtain bad performances even on the training data. maybe  better advice could be obtained by experimental analysis  with cross-validation techniques  such as leave-one-out   in order to evaluate the probable performance loss. 
　in any case  all these analyses might well tell us how many hypotheses we should have  they will never tell us which. better understanding of the inductive problem and more research in machine learning might allow us to transfer knowledge of relevant features from one domain to the other  to explore the hypothesis space more efficiently  to collect more data in order to save predictiveness even if our previous knowledge is poor. bui it will always be important  and sometimes necessary  to describe a hypothesis space which is both expressive and reasonably constrained. it is not surprising  i think  that knowledge of nothing at all does not lead to anything useful  in induction as well as in any other kind of inference. all forms of reasoning need premises that do not follow from anything else.  the starting point  of scientific knowledge is not itself scientific knowledge. therefore  since we possess no other infallible faculty besides scientific knowledge  the source from which such knowledge starts must be intuition   or  1 would rephrase  some form of a lucky guess. good luck! 
