 
utility elicitation is a critical function of any automated decision aid  allowing decisions to be tailored to the preferences of a specific user. however  the size and complexity of utility functions often precludes full elicitation  requiring that decisions be made without full utility information. adopting the minimax regret criterion for decision making with incomplete utility information  we describe and empirically compare several new procedures for incremental elicitation of utility functions that attempt to reduce minimax regret with as few questions as possible. specifically  using the  continuous  space of standard gamble queries  we show that myopically optimal queries can be computed effectively  in polynomial time  for several different improvement criteria. one such criterion  in particular  empirically outperforms the others we examine considerably  and has provable improvement guarantees. 
1 introduction 
as software for decision making under uncertainty becomes increasingly common  the process of utility elicitation takes on added importance. tailoring decisions to a specific user requires knowledge of the user's utility function  information that generally cannot be built into software in advance. in domains as varied as travel planning  product configuration  and resource allocation  to name but a few  assessing a user's utility function is an integral part of interactive decision making. unfortunately  as is well-known among decision analysts  utility functions are unwieldy  complex  and difficult for users to articulate . to mitigate these difficulties  analysts have developed many techniques for easing the burden of elicitation. for example  structuring of multiattribute utility functions reduces the number of parameters that need to be assessed ; and the use of standard gamble queries and sensitivity analysis allows users to calibrate utilities more easily . 
　more recently  emphasis has been placed on decision making with incomplete utility information. the principle of maximum expected utility  meu  cannot be used directly in such cases  since the utility function is unknown; thus 
decision theory 
minimax regret decision criterion 
craig boutilier 
department of computer science 
university of toronto 
toronto  on  m1s 1  canada cebly cs.toronto.edu 
new decision criteria are needed. in addition  methods for the automatic generation of queries have been developed that reduce uncertainty or incompleteness in the utility function with minimal effort. within al  probabilistic models of utility function uncertainty have been used  1; 1 . by assuming a density over possible utility functions  expectations over this density can be taken to determine the value of a decision; and standard bayesian updating techniques can be used to account for the responses to queries. a different perspective is taken in work on imprecisely specified multiattribute utility theory  ismaut   1; 1  in which linear constraints on multiattribute utility functions are refined  allowing the set of pareto optimal decisions to be identified; these constraints arc often refined until one action can be proven optimal. boutilier  bacchus and brafman  and blythe  adopt a somewhat related perspective  also reasoning with linear constraints on utility functions. 
　in this work  we adopt a distribution-free model  working with linear constraints on utility functions  much like ismaut. unlike ismaut  we allow for decisions to be made  or recommended  even when the incompleteness in utility knowledge prevents us from proving a decision is optimal. in such circumstances  we adopt the minimax regret decision criterion. we also propose and examine several methods for generating queries that reduce regret quickly  in contrast to work on ismaut  where query generation strategies have not been studied in depth . in this sense  our model more closely resembles probabilistic models  1; 1   which rely on the fact that decisions of good expected quality can be made with uncertain utility information. using the minimax regret criterion  we generate decisions whose quality  difference from optimal  can be bounded in the face of incomplete utility information. these bounds can be traded off against query cost or minimum error requirements to guide the query process. 
　the paper is organized as follows. we outline relevant background in section 1 and define the minimax regret criterion for decision making with incomplete utility information. we show how decisions of minimax regret can be computed using simple linear programs  lps  if utility constraints are linear. we also discuss incremental elicitation  focusing on standard gamble queries  sgqs    the responses to which impose one-dimensional  linear utility constraints that can be easily handled using lps. our key contribution is described 

in section 1  where we develop several myopic elicitation strategies. assuming linear constraints in each utility dimension  an assumption consistent with the use of sgqs   we show that the minimax regret improvement offered by any response to a sgq  as a function of the  continuous  query parameter  is piecewise linear  pwl  and weakly monotonic  decreasing or increasing  depending on the response . this fact allows optimal queries under each query strategy to be computed efficiently  in time linear in the number of utility attributes  despite the fact that query space is continuous. we present empirical results comparing the different strategies in section 1  demonstrating the effectiveness  in particular  of the maximum expected improvement strategy. 
1 	minimax regret with incomplete utility information 
we assume a system charged with making a decision on behalf of a user in a specific decision scenario. by a decision scenario  we refer to a setting in which a fixed set of choices  e.g.  actions  policies  recommendations  are available to the system  and the  possibly stochastic  effects of these choices are known. for example  the decisions could be courses of medical treatment with known probabilities for specific outcomes . the system's task is to take the optimal decision with respect to the user's utility function over outcomes  or some approximation thereof. the system may have little information about the user's utility function  so to achieve this  it must find out enough information about this utility function to enable a good decision to be made. we assume that the system has available to it a set of queries it can ask of the user that provide such information. we make these concepts more precise below. 
1 	the minimax criterion 
formally  a decision scenario consists of a finite set of possible decisions d  a finite set of n possible outcomes  or states  
1  and a distribution function prd e a s   for each d 1 d1 the term prd s  denotes the probability of outcome s being realized if the system takes decision d. a utility function u : s -   1  associates utility u s  with each outcome s. we often view u as a n-dimensional vector u whose ith component ui is simply u s{ . we assume that utilities are normalized in the range  1  for convenience. the expected utility of decision d with respect to utility function u is: 

note that eu d u  is linear in u. the optimal decision d* w.r.t. u is that with maximum expected utility  meu . 
　in general the utility function u will not be known with certainty at the start of the elicitation process  nor at its end. as in ismaut  1; 1   we model this uncertainty by assuming a set of linear constraints c over the set of possibly utility functions u =  1  l  n . more precisely  we assume that constraints 
   'the extension of our elicitation methods to a set of possible decision scenarios is straightforward. 
over unknown utility values ui are linear. we use c u to denote the subspace of u satisfying c. 
　if a system makes a decision d under such conditions of incomplete utility information  some new decision criterion must be adopted to rank decisions. following   we adopt the minimax regret decision criterion.1 define the optimal decision d*u with respect to utility vector u to be 

if the utility function were known  du would be the correct decision. the regret of decision di with respect to u is 

i.e.  the loss associated with executing di instead of acting optimally. let c c u be the feasible utility set. define the maximum regret of decision di with respect to c to be 

and the decision d*c with minimax regret with respect to c: 

the  minimax  regret level of feasible utility set c is 

if the only information we have about a user's utility function is that it lies in the set c  then d*c is a reasonable decision. specifically  without distributional information over the set of possible utility functions  choosing  or recommending  d*r minimizes the worst case loss with respect to possible realizations of the utility function  e.g.  if the true u were chosen by an adversary . 
　if c is defined by a set c of linear constraints  then d*c as well as mmr c  can be computed using a set of linear programs . we can compute the pairwise max regret  for any pair of decisions di and dj  

using an lp  i.e.  maximizing a linear function of the unknown outcome utilities subject to c . solving 1  d 1  such lps  one for each ordered pair of actions  allows us to identify the decision d*c that achieves minimax regret and to determine the minimax regret level mmr c . 
1 	incremental elicitation 
given partial knowledge of a utility function in the form of constraint set c  the optimal decision d*c may have an unacceptable level in regret. in such a case  a user could be queried in order to reduce this level of uncertainty  thus generally improving decision quality.1 


　a common type of query is a standard gamble w.r.t. outcome .si  where the user is asked if she prefers si to a gamble in which the best outcome st occurs with probability / and the worst s＼ occurs with probability 1 - / . we will designate this query qi l  and focus our attention on such standard gamble queries or sgqs.1 given a response yes to query qi /   the constraint ut   i can be imposed on the user's utility function  thus  in general  refining our knowledge; similarly  a no response corresponds to the constraint ui   i. a response to any standard gamble query imposes a one-dimensional  i.e.  axis parallel  linear constraint on the utility set. thus if our initial constraint set c is linear  computing the minimax optimal decision after a sequence of sgqs can be accomplished using the lp method above. furthermore  if c consists of a set of bounds on utility values in each dimension-i.e.  c forms a hyper-rectangle within  1  l   n - then after any sequence of sgqs  the feasible utility set retains this form. 
　the interactive decision making context we consider is one in which queries are asked repeatedly until the minimax regret level falls to some acceptable value. at that point the  optimal  decision  that with minimax regret given the current constraints  is recommended. termination can be based on simple thresholding  or can take into account the cost of a query  which can be weighed against the predicted improvement in decision quality .1 generally  queries will be asked that offer the greatest predicted improvement in decision quality. 
　both query selection and termination rely critically on the way in which  predicted improvement in decision quality  is defined for a query. for example  when asking a query qi{l  with respect to current constraint set c  we obtain two constraint sets cno and cyes. respectively  given responses  no and yes. we might then define the improvement in de-
cision quality associated with the query as some function of mmr cno  and mmr cyes . such a method of evaluating queries is myopic: the query is evaluated in isolation  without consideration of its impact on the value or choice of future queries. 
　it is important to note that optimal query choice is inherently nonmyopic-in general  a sequence of several queries may offer much more value than the aggregate myopic values of the component queries. unfortunately  nonmyopic methods require some form of lookahead  and thus often impose severe computational costs on the process of query selection. for this reason  we focus on the development of several myopic query selection strategies in the next section. this is analogous to the use of myopic methods for the approximation of value of information in cases where uncertainty is quantified probabilistically; while the computation of true value of information requires some form of sequential rea-
   1 other types of queries could be considered  though we rely on the special nature of sgqs in some of our results. sgqs are used widely in decision analysis   and have been the main query type studied in recent bayesian elicitation schemes  1; 1 . 
   1 of course  elicitation can continue until a zero-regret  i.e.  optimal  decision is identified: this occurs whenever c c rd for some decision d  the region of utility space for which d is optimal. the regions rd are convex polytopes within u. 
decision theory 
soning  myopic approximations tend to be used frequently in practice  1; 1 . 
1 	myopic elicitation strategies 
in this section we describe three myopic strategies for query selection under the minimax regret criterion. throughout this section we make the following assumptions: 
 a  the initial constraints have the form of upper and lower bounds in each utility dimension  these may be trivial bounds  1  1 . 
 b  sgqs are asked  assuming some known best and worst outcome. these ensure that each constraint set  after any query  has the same form as the initial set  i.e.  a hyperrectangle . we denote by uhl and lbi the current bounds on the utility ui of outcome it. 
 c  for simplicity  we assume a threshold r is used to implement termination; that is  when the predicted improvement of a query falls below t  we terminate the process. 
we discuss the impact of relaxing these assumptions later. 



figure 1: structure of various functions in dimension i  as a function of/:  a  the pmr for d   w.r.t. d1  d1  d1  are shown; as is mr d c  i l  the max  thin solid line1of pairwise max regret functions. mrno  thick solid upper line  is obtained by replacing the pmr line d1 - d   with negative slope  by the constant line  and again taking the max.  b  mmrn   dashed line  is the min of the mrno functions for each decision;  c  intersection of mmrno and mmryes gives maximin improvement in mmr. 

to max regret in dimensions other than i is constant  while the contribution to regret in dimension i given ui - i is linear in /  with coefficient it follows that is a pwl convex 
function of/  since it is the max of these pairwise regret functions  see figure 1 a  . 
　now define 	the max regret of d after obtaining a negative response to query 
  note that this differs from which is defined by assuming .     is 
also a pwl convex function  obtained from the set of linear pmr-functions that make up as follows: we replace any linear components with negative slope by the constant line intuitively  if the regret of d w.r.t. d' after learning ui = i decreases with /  then simply learning that cannot reduce pairwise max regret  since this weaker constraint does not rule out the maximum regret at  see figure 1 a  for this intuitive flattening of the regret line for d1 - d1 . this ensures that  is also nondecreasing in /  as illustrated in figure 1 a . 
finally  note that  by definition of minimax regret  
 the minimum of 
a collection of pwl  convex  nondecreasing functions is also pwl and nondecreasing  though not necessarily convex   see figure 1 b  . 
note that this proof sketch shows how to construct a finite representation of the function  as a finite collection of linear functions and inflection points. by entirely analogous reasoning  we also have: 

1 	maximin improvement 
one goal of any query strategy is to determine utility information that reduces regret as quickly as possible. unfortunately  for any given  the exact reduction in regret cannot typically be predicted in advance  since it differs depending on whether a yes or no response is obtained. the maximin improvement  mml  query strategy myopically selects queries with the best worst-case response. more precisely  let c be our current constraint set. we define the minimum 

at each stage  the query qi l  is asked whose minimum improvement with respect to the current constraint set is maximum. the process stops when no query has minimum improvement greater than threshold r. 
　to compute the optimal mmi query point  we find the optimal query point in each dimension i  and ask the sgq corresponding to the dimension with greatest mmi. the pwl representation of the functions mmryesi c i l  and 
mmrno c i  i  described above allows the optimal point in each dimension to be computed readily. the point / that offers mmi in dimension i can be determined by computing the intersection of the two functions: since one is nondecreasing and the other nonincreasing  the maximum point of the 
function  must lie at the intersection. note that the intersection must exist since each has the same maximum value mmr c   see figure 1 c  .1 finally  the value of the improvement in regret is the difference between the original minimax regret level and this value. 
　computation of the intersection of these functions is straightforward  requiring only the computation of the intersection of the linear segments whose bounds overlap. as such  this can be accomplished in linear time in the maximum number of segments in either function. the number of segments in these functions is  very loosely  bounded by   since we must compute the optimizing point for each utility dimension  the complexity of this algorithm is the algorithm thus scales linearly in the number of outcomes and quadratically with the number of decisions. 
1 	average and expected improvement 
one difficulty with the mmi criterion for query selection is that  due to its worst-case nature  we can often find situations in which no query offers positive  minimum  improvement  we will see evidence of this in the next section   despite the 
   1 if the intersection occurs where both functions are  flat   any query point in the intersection can be used. 
   1 in practice  the number of segments appears to grow sublinearly in the number of decisions  d . 

fact that the current regret level is positive. this occurs when 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　predicted mmr by mei at least one of the responses for every query offers no im- actual mmr by mei provement  thus stalling the query process. intuitively  just true regret by mei because one response to a query ql l  offers no improvement is no reason not to ask the query: the opposite response may still offer immediate improvement.1 this suggests an alternative criterion called maximum average improvement  mai : sgqs are ranked according to the average improvement offered by both positive and negative responses. 
　computing the optimal query point according to mai can also exploit the pwl nature of the functions and mmrno c  i  / . as with mmi  we compute the optimal query point i in each dimension i independently. it is not hard to see that the point of maximum average improvement must occur at an inflection point of one of the two functions. thus  each dimension can be optimized in time linear in the number of segments in the two functions. 
the mai criterion is not subject to stalling in the sense that 

mmi is: if mmr c  is positive  then there exists some query with positive mai  this will follow from a result discussed below . however  it is subject to a different form of stalling: it may well be the case that the query qi l  with mai occurs at one of the boundary points . in such a case  only one  consistent  response is possible  imposing no additional constraints on the utility function. as such  the constraint set c will remain unchanged  meaning that the same query remains mal-optimal at the next stage. 
　this second type of stalling can be prevented. suppose that a query qi l  is optimal  where we know that 
 i.e.  a yes offers 
greater improvement at the point ubl   but since cannot exceed ubi  the probability of receiving a yes response is zero  so the yes-improvement cannot be realized. we can thus make the query qi l  appear to be less desirable by accounting for the odds of receiving a specific response. the maximum expected improvement  mei  criterion does just this. we define the expected improvement of a query: 

at each stage  we ask the query with maximum el. 
　computation of expected improvement requires some distribution over responses. for simplicity  we assume a uniform distribution over utility functions and noise-free responses: thus   with the negative probability defined similarly . this assumption also allows for the ready computation of the mel-optimal query. again  we optimize each dimension separately. the optimization in dimension i can be effected by doing separate optimizations in the regions defined by the union of the inflection points in the functions  and 
 we defer the details  but note that the func-
tion being optimized within each region is a simple quadratic function of/ that can be solved analytically. thus the computational complexity of this criterion is similar to that of mmi and mai. fortunately  mei is not subject to stalling: 
　　1 note that  since mmi is myopic  even a nonimproving response may offer information that can be exploited in the future. 
decision theory 
figure 1: performance of mei on three-good problems  1 runs . 
proposition 1 if mmr{c    1  then there exists some query1 qt l  with positive expected improvement; and at least one response to the mel-optimal query reduces minimax regret. 
　the mei criterion could be adopted using other distributional assumptions  though the optimization required by query selection could become more complicated. it is worth noting that the manner in which we use distributional information is consistent with the worst-case perspective imposed by the minimax criterion. with some distribution over utility functions  we could adopt the perspective of  1; 1   and make decisions by taking expectations with respect to this distribution. however  even in this case  minimax regret allows one to offer guarantees on decision quality that a bayesian approach does not address. the mei criterion exploits distributional information only to guide the querying process  hoping to reach a point more quickly where acceptable guarantees can be provided; the distribution is not used to evaluate decisions per se. 
　while other prior distributions will generally require a different approach to the optimization problem for query selection  it is interesting to observe that queries associated with a mixture of uniform distributions can be determined in exactly the same manner. the derivation of the optimal query given such a mixture is straightforward  and these models have the desirable property  like uniform priors  that they are closed under update by query responses. thus  if our prior beliefs can be approximated well using a mixture of uniforms with a small number of components  mei-querying can be used directly as described here  without distribution-specific optimization. it is important to note  however  that  even if the approximate priors are used  the decision quality of the mei strategy is unaffected-only the number of queries required may be adversely impacted. 

we evaluated the mm1  mai  and me1 query criteria on a number of elicitation problems in two different domains. with the mei criterion  we have also tested its robustness to different assumptions about the prior over utility functions. 
   we first tested our methods in two bidding scenarios involving simultaneous auctions and combinatorial preferences . in the first scenario  a bidding agent must offer bids for four different goods auctioned simultaneously in four different markets. to discretize the decision space  we assume that the agent can offer three distinct bids-low  medium  and high-for each good. each of these bid levels corresponds to a precise cost: should the bid win  the user pays the price associated with each bid  with  of course  higher prices associated with higher bid levels . to suppress the need for strategic reasoning  the agent has a fixed  known probability of winning a good associated with each of the three bid levels. the probabilities of winning each good are independent  and increasing in the bid level. with four goods and three bid levels  there are 1 possible decisions  mappings from markets to bids  and 1 outcomes  subsets of goods the user might obtain . the user's utility function need not be additive with respect to the goods obtained. for instance  the user might value goods g  and g1 in conjunction  but may value neither individually. thus utility is associated with each of the 1 outcomes. we assume that the overall utility function  accounting for price paid  is quasi-linear; so the price paid is subtracted from the utility of the subset of goods obtained. a smaller scenario with three goods was also run: this has 1 decisions and 1 outcomes. 
　we first discuss the smaller  1-good  scenario. for each query criterion  we run elicitation using that criterion for 1 steps  or until no query has positive value . for each criterion  1 trials using random utility functions drawn from  1  l   n were run  with elicitation simulated using responses based on that function. for each query in a run  we record:  a  predicted mmr-the mmr level that is predicted to hold after asking the optimal query;1  b  actual mmr-the mmr level realized once the actual query response is obtained; and  c  the true regret-the difference in utility between the minimax decision and the true optimal decision for the underlying utility function. while our algorithms don't have access to true regret  this measure gives an indication of true decision quality  not just the quality guarantees the algorithms provide. 
　figure 1 shows the performance of the mei criterion  std. error bars are shown on actual mmr and true regret  but are excluded from predicted mmr for legibility . we see that the algorithm quickly converges to a point where the minimax regret guarantees are quite tight: within 1 queries  the average regret guarantee falls below 1  less than 1% ; and within forty queries  decision quality is guaranteed to be with 1% of optimal. more interesting  we see that true regret falls to under 1% with 1 queries  and to near zero within 1 queries. thus the actual decision quality associated with acting according the decision with mmr is generally far better than the mmr guarantee. the mei criterion seems to select 
　　1 for example  mmi predicts the maximum regret over all responses  while mei predicts the expected regret. 
figure 1: performance of mai on three-good problems  1 runs . 
suitable queries  allowing optimal decisions and tight regret guarantees to be identified with few interactions. for reference  we also include the performance of randomly selected queries  where both dimension i and query point / are chosen uniformly at random from the feasible region . because the problem is of relatively low dimension  random queries perform reasonably well  though they have difficulty reducing regret to zero  and do not compete with mei queries. 
　figure 1 shows the same measurements for the mai criterion. we note that this query strategy does not reduce regret bounds nearly as quickly as the mei strategy  reaching only an average regret guarantee of 1 after 1 queries. true regret is generally much better  but still does not approach the performance of mei  or even random queries . we note that the mai criterion often stalls: in such a case  we complete the data with the last minimax regret value. finally  it is worth noting that the mmi criterion performs extremely badly. we don't plot its performance  but note that in all runs  it stalls after a maximum of five queries; its average minimax regret bound is 1  and average true regret level is 1 when it stalls. 
　the mei criterion appears to offer much better performance than mai  mmi  or random querying. figure 1 shows the performance of mei  mai and random querying strategies on the larger four-good  1-outcome  1-decision  scenario. again we see that mei converges quickly and outperforms the other strategies. with the increase in dimensionality  random queries fare worse than mai-optimal queries. we note that in all experiments  the optimal query  regardless of criterion  can be computed very quickly. 
　we have also tested the mei criterion on a travel planning domain  as in the previous tests  mei seems to dominate the other criteria  so we focus on it . in this domain  an agent must choose a collection of flight segments from a flight database to take a user from a source to a destination city . to make the elicitation problem interesting  we added the following information to the db: the probability of any flight arrival being delayed by specific amount of time; 


figure 1: performance on four-good problems  1 runs . 	figure 1: performance on yyz-sfo  with utility functions drawn 

the probability of missing a connecting flight as a function of connection time and airport; a distribution over ground travel times to a hotel in the destination city as a function of arrival time  reflecting  e.g.  arrival in rush hour or off-peak ; and the probability of losing a hotel room as a function of arrival time at the hotel. as a result  for any specific flight combination  decision   a joint distribution over these variables  outcome  is obtained. a user's utility function is quasi-linear  given by her utility for a specific outcome over these four attributes less the flight price. the specific formulation discretizes these attributes  so the outcome space is of size 1. in our experiments  the flight db was designed to allow 1 flights  both direct and indirect  between pairs of cities. 
　we tested the me1 strategy using a uniform prior over utility space to select queries  with user utility functions drawn from the same uniform distribution. the results for a specific source-destination pair  toronto-san francisco  are shown in figure 1. as before  we see that the me1 strategy easily outperforms random querying  both in terms of the regret guarantees  and the true regret of the decisions it would recommend at each stage. these results are representative of those obtained in other decision scenarios. 
　we also explored the use of strong prior knowledge to guide the querying process. we repeated the test above  drawing user utility functions from a strongly peaked  truncated  gaussian distribution over utility space  with diagonal covariance matrix  and variance 1 in each dimension . we tested the mei-criterion using a  hand-chosen  mixture of three uniform distributions over subregions of utility space that very roughly approximated the gaussian.1 to test the robustness of mei to inaccurate priors  we also used mei using a single uniform prior over all of utility space  despite the fact that the true utility function is drawn from the gaussian . the results illustrated in figure 1 demonstrate that mei can benefit 
   1 in principle  this mixture could have been fit to the actual pnor using  say  em; but our goal is not accurate modeling of the prior. 
decision theory 
from uniform  1 runs . 
considerably from strong prior information. indeed  minimax regret is reduced very quickly when a reasonable prior is used to select queries; and true regret is reduced to zero in every instance of this scenario within four queries. random querying does very poorly  indicating that this problem is not easy to solve without sufficient utility information. the robustness of mei to inaccurate priors is also in evidence. we see that minimax regret and true regret are also reduced very quickly when an uniformative uniform prior is used to guide the meiquerying process. 
1 	concluding remarks 
we have presented a new procedure for decision making with incomplete utility information which recommends decisions that minimize maximum regret. we defined several different myopic query selection criteria  and showed that myopically optimal queries under each criterion can be computed effectively  in polynomial time. the empirical performance of one such criterion  maximum expected improvement  proved to be rather attractive: not only did it provide strong guarantees after few queries  but true decision quality tended to exceed these guarantees significantly. 
　our work differs from existing approaches to preference elicitation in several important ways. like recent bayesian approaches  1; 1   our approach identifies a concrete decision in the face of utility function uncertainty. unlike these methods  for the purposes of decision making  we assume only constraints on possible utility functions  not distributions. as a result  the minimax regret criterion is used to identify decisions with guaranteed error bounds on quality. our use of constraints on utility functions is more closely related to work on ismaut  1; 1 . however  the focus in ismaut is the identification of pareto optimal decisions in the face of utility function uncertainty  as opposed to the choice of a specific decision that maximizes some decision criterion. furthermore  


figure 1: performance on yyz-sfo  with utility functions drawn from a strongly peaked gaussian. mei querying using both a uniform prior and a 1-component mixture are shown  1 runs . 
little attention has been paid to query strategies in ismaut  which  in contrast  is our main focus. 
　there are a number of directions in which this work can be extended. obviously  scaling issues are of paramount importance. we are currently exploring pruning techniques for removing decisions from consideration that can never be minimax optimal  thus reducing the quadratic dependence on the number of decisions. we are also exploring methods for dealing with more general linear constraints  apart from one-dimensional bounds   as well as more expressive query types. also of interest are methods for dealing with noisy/inconsistent query responses  and visualization techniques. finally  we are developing heuristics that simulate some of the effects of nonmyopic elicitation without explicit lookahead. one such technique involves enumerating the vertices of the regions rd of utility space in which each decision d is optimal  the regions are convex polytopes . queries at those points can quickly help rule out suboptimal actions. we hope to combine the computationally attractive methods devised in this paper with more intensive techniques like this to help reduce the number of required queries even further. 
acknowledgements 
this research was supported by the natural sciences and engineering research council  nserc  and the institute for robotics and intelligent systems  iris . 
references 
 jim blythe. visual exploration and incremental utility elicitation. in proceedings of the eighteenth national conference on artificial intelligence  pages 1  edmonton  1. 
 craig boutilier. a pomdp formulation of preference elicitation problems. in proceedings of the eighteenth national conference on artificial intelligence  pages 1  edmonton  1. 
 craig boutilier  fahiem bacchus  and ronen i. brafman. ucp-networks: a directed graphical representation of conditional utilities. in proceedings of the seventeenth conference on uncertainty in artificial intelli-
gence  pages 1  seattle  1. 
 urszula chajewska  daphne koller  and ronald parr. making rational decisions using adaptive utility elicitation. in proceedings of the seventeenth national con-
ference on artificial intelligence  pages 1  austin  tx  1. 
 simon french. decision theory. halsted press  new york  1. 
 ralph l. keeney and howard raiffa. decisions with multiple objectives: p