 
stereo-vision-based mobile robots observe their environments and acquire 1 data with considerable errors 1n range. rather than to use the conventional 1 maps  described with these inaccurate data 1n the absolute coordinate system  a flexible relational model of the global world can be built with local maps suited for each function of robots such as path planning or manipulation. for the path planning  a perspective representation of the local world  the image on which the scene interpretation is mapped  1s proposed. using world constraints and sensory information of camera orientation  a stereo-image analyzer determines vertical projections of edge points on the floor in the image. a method for planning of promising paths to the specified goal using this representation is presented. 
1. introduction 
sensor-based navigation of mobile robots 1n unstructured environments has been extensively studied as one of key problems of artificial intelligence research. host robots plan paths to the destinations using 1 maps  given a priori or built by themselves  represented 1n the absolute coordinate system  horavec 1  glralt et al. 1  tsujl 1  elfes 1 . drawbacks of such maps were pointed out by brooks  brooks 1   who presented an interesting idea to use a rubbery and stretchy relational map  making the spatial reasoning robust to errors 1n estimating positions of objects and robots 1n the absolute coordinate system. realization of the idea  however  has not been reported yet. 
the authors' group has been also studying a vision-based robot wandering about and accomplishing the specified task in an indoor environment. we follow the above-mentioned idea 1n the sense that use the local coordinate systems with relative transforms and error estimates. rather than to use the conventional 1 maps for spatial reasoning  a flexible relational model of the global world can be built with local maps suited for each function of robots  such as path planning or manipulation. for the path planning  this paper presents a new scheme  based on the properties of 
this work is supported 1n part by grant-in-a1d for 
scientific research from ministry of education  science and culture  japanese government. 
vision  for representing the local world and using 1t for planning. investigating the merits and demerits of transforming the visual data into the conventional 1 map* we use a perspective representation of world  the image on which the scene interpretation is mapped  for planning promising paths to the goal  or sub-goals . using world constraints and sensory information of camera orientation  a stereo-image analyzer determines vertical projections of edge points onto the floor in the image. a method for planning of promising paths to the specified goal using this representation is presented. 

vision of intelligent robots play the most important role among their sensors in building and maintaining models of their environments. for the effective usage of the models  their structures should be carefully designed so as to be suited for the functions of the robots. a mobile robot wandering around in an unstructured environment needs functions as follows:  1  it plans a route to the specified destination   1  navigates safely along the planned route and  1  performs the given job such as manipulation or monitoring at the destination. we do not need a world model of a unified structure and thus same performance through the entire task  but models with different structures and different grain sizes  which represent facts about the world needed for each function  are more reasonable. 
for example  the planning needs coarse representation of free spaces relative to some landmarks and the robot* but the detailed structures and shapes of objects in scene  1n most cases  do not provide important information. navigation uses the local world model describing the approximate direction and distance it will move  obstacles along the route and the landmarks by which the sub-goal 1s specified. manipulation needs  on the contrary  precise 1 models of objects located 1n a limited area such as a workbench. we can  therefore  build a global world model covering a wide environment by combining the different representations of the local worlds with coarse geometrical relations between them. 

let us consider how the local world is represented for planning paths to the destination. precise estimate of the free space geometry is  in 
tsuji and zheng 1 
general  d i f f i c u l t because of the limited resolution of visual sensors and  if possible  they are often not so meaningful at the planning stage. robots can not always find the route to the destinations from single view. in many cases  when they have not enough experiences of wandering about the routes  these robots plan promising routes and next observation points where the poss i b i l i t i e s of further navigation are examined. representation of the local worlds should be selected so as to be convenient for such planning. 
vision-based robots analyze input images taken by tv cameras and yield 1-d maps in the absolute coordinated system by transforming positions of obstacles found in the images into an euclidean representation. the maps  on which the robots are located  are then labelled with free  occupied  or unknown regions  and the routes to the destination are planned on i t . the 1-d maps have been used because  1  we can easily understand them and  therefore   1  integration of 1-d data acquired from images taken at d i f f e r e n t positions seems straight forward  but not so easy because of uncertainties in camera locations and orientations  and much research has been done  faugeras et al. 1  lin et a l . 1  . 
d i f f i c u l t i e s arise in such representation from inherent error due to measuring in image. measurements of ranges to objects suffer from the minimal spatial resolution of vision sensors used. thus  the error in depth measurement increases with proportional to the squared distance of the object from the camera. as a result  estimates of far object points  back projected from the images to the 1-d map  are very uncertain. such uncertainty must be added as a feature of each point in the maps. another d i f f i c u l t y is that the observed points are sparse in far areas in the 1-d maps; the density is inversely proportional to the squared distance from the camera. if a c e l l u l a r representation of the 1-d map  elfes 1  is used  we need to interpolate features between the observed points to f i l l in blank cells. 
we propose to map the scene interpretation onto a perspective world  the image itself  rather than transform the image data into the 1-d maps. we assume our robot moves on an almost f l a t floor  and the projection of the i n f i n i t e plane containing the floor onto the image is used as a 
representation of the local world. this representation is natural in the sense that  1  i t s spat i a l resolution is same as that available from the sensors and  1  any interpolation and transformation is not needed while we deal with single image. we argue human beings without maps also plan the route in the field of vision rather than make reasoning in a top-view of the world. 
integration of information available from the local perspective worlds at d i f f e r e n t points is possible by estimating transformation matrices between them. a different approach  however  is proposed. we use a simple principle that an observation from a closer point yields more reliable results. promising paths to the next observation point  where more reliable estimates w i l l be obtained  are generated in each perspective world. 
1 image analysis and path planning 
hardware system 
we have been doing experiments with a hero robot  on which two small ccd cameras  nec ti-1ai  separated from each other by 1m are mounted at a height of 1m. pitch and roll angles of a camera are measured by orientation sensors  watson fluxgate magnetometer . images are converted into 1 by 1 b i t d i g i t a l pictures  the appoximate equivalent focal length is 1 pixel  and their edge points are found by a t1spix-1 image processor connected to a sun1 workstation  which analyzes the stereo imagery and plans the promising routes. the results are fed back to the robot through a control computer mc1. the number of rotations and steering angle of the front wheel are sent to the control computer  from which a coarse e s t i m a t e of i t s motion is available. 
stereo matching and scene interpretation 
an image analyzer in the sun1  	which receives 


1 	robotics 

stereo images and their edge pictures obtained by a 1 sobel operator  finds 1-d structure of the viewed world and  then  determines the floor boundaries. most indoor scenes are rich in straight edges which give important cues for scene interpretation. for segment-based stereo matching  the analyzer f i t s lines to edge segments of considerable lengths found by tracking edge points. we use a competitive matrix between line segments of the stereo pair  and find correspondence of lines in the images  by examining the similarity of edge strengths  locations and directions of segments and the consistency in matching. fig.l shows an example of input l e f t images and figs.1 display the results of matching of the stereo pair  bold and thin lines represent matched and non-matched segments  respectively . thus we can determine the 1-d structure of most portions of the scene. 
in order to find free spaces for the navigation  we need information of height of edge points. we assume the optical axes of two cameras are parallel and horizontal. let the coordinate system x y 1 be fixed at the center of the two lens centers of cameras with z axis parallel to the optical axes. suppose a point p at  x y z  in space is projected on an image plane of camera at  x y   assuming the central projection. using the camera geometry  we have the following simple equations for y#o  tsuji et al. 1 . 

where d is the disparity between corresponding image points  f is the focal length of the camera  l is the distance between two camera centers  and 
h and ho are heights of p and the lens center from the floor  respectively. thus  the disparity of a point in space is determined from the camera parameters  l and ho  and i t s heights in image and in space. 
boundaries of shadows casted on the f l o o r are labelled as the floor edge points  while the bottom edge of an object appearing in the right lower part in fig.l is interpreted as floating above the floor  the object is supported by wheels . thus a l l edge points in the image are labelled as the floor or non-floor. 
most path planning of mobile robot uses 1-d maps without height information. as a result  the planned routes may be very dangerous for collision with objects overhanged to the path. therefore  we need 1-d information to find free paths in the world. since the shape of our robot is simple  approximated by a cylinder  and it cannot change its shape to avoid collision  we use rather simple 1-d information that each point on the floor has an overhanged object or not. we  therefore  project dangerous non-floor edge points onto the floor in the image. we have the following simple relation between the image point  x y  and i t s vertical projection  x y'  onto the floor. 
		 1  
thus  we can easily project these edge points onto the floor in the image  and label the projection as obstacle edge points. thus  the edge points have three labels; floor  obstacle and non-floor. 
the above discussion assumes the invariance in height and t i l t of the cameras through execution of the task. the floor on which our robot moves is almost f l a t and  as a result  we can consider the height is invariant. small uneveness of the floor  however  causes the cameras to shake  and results in a considerable amount of movements of images. in order to solve the problem  we use the information from the orientation sensors of the camera  and can compensate for the movements less than one pixel. 
planning paths 
as mentioned before  the system searches the local map for promising paths to the goal or the next 
	tsuji and zheng 	1 

observation point. at first  we label the perspective world as free  dangerous  uncertain  and invisible. we move the projection of robot onto the floor in the perspective world  therefore the shape and size of the projected area change  and examine the possibility of collision. for simplicity of computation  we approximate the robot's projection by a square. 
we start with the bottom row of the image assuming that it belongs to the free area  and move the robot's projection until its any part collides with edge points  see fig.1 . then  we change the direction of movement  and continue to move it until it cannot move further. by iterating the procedure  we can find all possible movement of the projection  and areas covered by the center of the projection are labelled as free. fig.1 shows the free area found in fig.l. the proposed procedure is robust to the errors in finding edge segments  because missing of small portions of edge segments results in very l i t t l e effects to the labelling. 
we also label the narrow regions between the free areas and the obstacle edges as dangerous regions  and those between the free areas and non-floor edge as uncertain regions. the rest parts in the perspective world are considered as invisible regions. 
now let us consider how we can find possible routes to the goal if its approximate location is given in the perspective world. route finding seems easy if routes to the goal exist in the free region. objects in scene  however  often occlude parts of the routes or the goal  and we need to search the perspective world for promising routes to the goal. if the labels are correct  the routes from the free region must exist across the uncertain regions toward the goal as pointed in fig.1  and we can determine the most promising route by using a heuristic function to estimate the possibility and cost of attaining to the goal  and set observation points along the route where the uncertain regions are easily observable. 
we should note that the labels are not reliable if areas are far from the cameras  because of the limitation of sensor resolution. for example  free paths sometimes exist in far areas labelled as dangerous because of the uncertainty in estimate of 1-d distance between edge points. the uncertainty in hight estimate results in 

fig.1 free regions in fig.l. 
1 	robotics 
labelling of edges of low obstacles as floor edges. therefore  a good policy for path planning is to plan promising or possible paths to the destination  and moves along a route to obtain a closer view of the path. we propose that promising paths are generated in each perspective world and portions with more reliable estimates are merged together with a graph structure of which arcs give the approximate geometrical relations between them. 
1. conclusion 
in this paper  we examine problems of world modelling and path planning which must be solved by a mobile robot exploring an unknown environment. in particular  we introduce the perspective model of the local world for planning promising paths to the destination. image analysis and spatial reasoning based on this representation are also described. the major parts of the system have been already implemented and tested  and the whole system will be built in near future. 
acknowledgment 
the authors wish to express their hearty thanks to 
minoru asada  osaka university for his kind discussions on this work. 
