
this paper presents a novel approach for extracting high-quality  thread-title  reply  pairs as chat knowledge from online discussion forums so as to efficiently support the construction of a chatbot for a certain domain. given a forum  the high-quality  thread-title  reply  pairs are extracted using a cascaded framework. first  the replies logically relevant to the thread title of the root message are extracted with an svm classifier from all the replies  based on correlations such as structure and content. then  the extracted  thread-title  reply  pairs are ranked with a ranking svm based on their content qualities. finally  the top-n  thread-title  reply  pairs are selected as chatbot knowledge. results from experiments conducted within a movie forum show the proposed approach is effective.
1 introduction
a chatbot is a conversational agent that interacts with users in a certain domain or on a certain topic with natural language sentences. normally  a chatbot works by a user asking a question or making a comment  with the chatbot answering the question  or making a comment  or initiating a new topic. many chatbots have been deployed on the internet for the purpose of seeking information  site guidance  faq answering  and so on  in a strictly limited domain. existing famous chatbot systems include eliza  weizenbaum  1   parry  colby  1  and alice.1 most existing chatbots consist of dialog management modules to control the conversation process and chatbot knowledge bases to response to user input. typical implementation of chatbot knowledge bases contains a set of templates that match user inputs and generate responses. templates currently used in chatbots  however  are hand coded. therefore  the construction of chatbot knowledge bases is time consuming  and difficult to adapt to new domains.

*
　　 this work was finished while the first author was visiting microsoft research asia during feb.1-mar.1 as a component of the project of askbill chatbot led by dr. ming zhou.
1  http://www.alicebot.org/　an online discussion forum is a web community that allows people to discuss common topics  exchange ideas  and share information in a certain domain  such as sports  movies  and so on. creating threads and posting replies are major user behaviors in forum discussions. large repositories of archived threads and reply records in online discussion forums contain a great deal of human knowledge on many topics. in addition to rich information  the reply styles from authors are diverse. we believe that high-quality replies of a thread  if mined  could be of great value to the construction of a chatbot for certain domains.
　in this paper  we propose a novel approach for extracting high-quality  thread-title  reply  pairs from online discussion forums to supplement chatbot knowledge base. given a forum  the high-quality  thread-title  reply  pairs are extracted using a cascaded framework. first  the replies logically relevant to the thread title of the root message are extracted with an svm classifier from all the replies  based on correlations such as structure and content. then  the extracted  thread-title  reply  pairs are ranked with a ranking svm based on their content qualities. finally  the top-n  thread-title  reply  pairs are selected as chatbot knowledge.
　the rest of this paper is organized as follows. important related work is introduced in section 1. section 1 outlines the characteristics of online discussion forums with the explanations of the challenges of extracting stable  threadtitle  reply  pairs. section 1 presents our proposed cascaded framework. experimental results are reported in section 1. section 1 presents comparison of our approach with other related work. the conclusion and the future work are provided in section 1.
1 related work
by  chatbot knowledge extraction  throughout this paper  we mean extracting the pairs of  input  response  from online resources.
　based on our study of the literature  there is no published work describing the use of online communities like forums for automatic chatbot knowledge acquisition. existing work on automatic chatbot knowledge acquisition is mainly based on human annotated datasets  such as the work by shawar and atwell  and tarau and figa . their approaches are helpful to construct commonsense knowledge for chatbots  but are not capable of extracting knowledge for specific domains.
　notably  there is some work on knowledge extraction from web online communities to support qa and summarization. nishimura et al.  develop a knowledge base for a qa system that answers type  how  questions. shrestha and mckeown  present a method to detect  question  answer  pairs in an email conversation for the task of email summarization. zhou and hovy  describe a summarization system for technical chats and emails about linux kernel. these researchers' approaches utilize the characteristics of their corpora and are best fit for their specific tasks  but they limit each of their corpora and tasks  so they cannot directly transform their methods to our chatbot knowledge extraction approach.
1 our approach
an online discussion forum is a type of online asynchronous communication system. a forum normally consists of several discussion sections. each discussion section focuses on a specific discussion theme and includes many threads. people can initiate new discussions by creating threads  or ask  answer  questions by posting questions  replies  to an existing section. in a section  threads are listed in chronological order. within a thread  information such as thread title  thread starter  and number of replies are presented. the thread title is the title of the root message posted by the thread starter to initiate discussion. one can access a thread from the thread list and see the replies listed in chronological order  with the information of the authors and posting times.
　compared with other types of web communities such as newsgroups  online discussion forums are better suited for chatbot knowledge extraction for the following reasons:
1. in a thread within a forum  the root message and its following up replies can be viewed as  input  response  pairs  with same structure of chat template of a chatbot.
1. there is popular  rich  and live information in an online discussion forum.
1. diverse opinions and various expressions on a topic in an online discussion forum are useful to extract diverse  input  response  pairs for chatbots.
　due to technical limitations of current chatbots in handling dialogue management  we think that pairs of  input  response  for a chatbot should be context independent  which means that the understanding inputs and responses will not rely on the previous  input  response .
　however  because of the nature of a forum  it is difficult to extract high-quality  input  response  pairs that meet chatbot requirements:
1. replies are often short  elliptical  and irregular  and full of spelling  usage  and grammar mistakes which results in noisy text.
1. not all of replies are related to root messages.
1. a reply may be separated in time or place from the reply to which it responds  leading to a fragmented conversational structure. thus  adjacent replies might be semantically unrelated.
1. there is no evidence to reveal who has replied to which reply unless the participants have quoted the entire entries or parts of a previously posted reply to preserve context  eklundh  1 .
　to overcome these sorts of difficulties  lexical and structural information from different replies within threads are analyzed in our experiments  as well as user behaviors in discussions.
　therefore  to extract valid pairs of  input  response  from a forum  we first need to extract relevant replies to initial root messages. in this process  replies that are relevant to the previous replies rather than to the initial root message are ignored and the replies logically directly relevant to the thread title are extracted. the replies to the initial root message  in spite of being relevant  may have different qualities. to select high-quality replies  a ranking svm is employed to rank the replies. finally  the pairs of the title of the root message and the extracted top-n replies are used as the chatbot knowledge.
1 cascaded hybrid model
an input online discussion forum f contains discussion sections s1 s1 ... sk. a section consists of t threads t1 t1 ... tu. each thread t is a sequence of replies t={r1 r1 r1 ... rn}  where r1 is the root message posted by the thread starter and ri is the ith  i 1  reply. a reply r is posted by a participant p at a specific moment m with content c. a thread t can be modeled as a sequence of triplets:
t ={r1 r1 r1 ... rn}
={ p1 m1 c1   p1 m1 c1   p1 m1 c1  ...  pn mn cn }
　we define an rr as a direct reply rj   j 1  to the root message r1 where rj is not correlated with the other reply rj'   j'1  j' j  in the thread.
　therefore  chatbot knowledge  ck  can be viewed as the pairs of  input  response  that fulfill the following constraints:
ck ={ input response }
={ thread-title high-quality rr }
　a thread title is used to model the user input of a chatbot and rrs of this thread are used to model the chatbot responses. the high-quality pairs of  thread-title  rr  will be selected as chatbot knowledge.
　a high-quality pair of  thread-title  rr  for the chatbot should meet the following requirements:
1. the thread-title is meaningful and popular.
1. the rr provides descriptive  informative and trustworthy content to the root message.
1. the rr has high readability  neatly short and concise expressive style  clear structure.
1. the rr is attractive and can capture chatter's interest.
1. both thread-title and rr should have no intemperate sentiment  no obscene words and exclusive personal information.
1. both thread-title and rr should have proper length.
　in this paper  identifying the qualified thread-title is not our focus. instead  we focus on selecting qualified rr. figure 1 illustrates the structure of the cascaded model. the first pass  on the left-hand side  applies an svm classifier to the candidate rr to identify the rr of a thread. then the second pass  in the middle  filters out the rr that contains intemperate sentiment  obscene words and personal information with a predefined keyword list. the rr which is longer than a predefined length is also filtered out. finally the rr ranking module  on the right-hand side  is used to extract the descriptive  informative and trustworthy replies to the root message.

figure 1. structure of cascaded model.
1 rr identification
the task of rr identification can be viewed as a binary classification problem of distinguishing rr from non-rr. our approach is to assign a candidate reply ri  i 1  an appropriate class y  +1 if it is an rr  -1 or not . here support vector machines  svms  is selected as the classification model because of its robustness to over-fitting and high performance  sebastiani  1 .
　svmlight  joachims  1  is used as the svm toolkit for training and testing. table 1 lists the feature set to identify rr for a pair of  thread-title  reply .
1structural features
1	does this reply quote root message 
1	does this reply quote other replies 
1	is this reply posted by the thread starter 
1	# of replies between same author's previous and current reply1content features
1	# of words
1	# of content words of this reply
1	# of overlapping words between thread-title and reply
1	# of overlapping content words between thread-title and reply
1	ratio of overlapping words
1	ratio of overlapping content words between threadtitle and reply
1	# of domain words of this reply
1	does this reply contain other participants' registered nicknames in forum table 1. features for rr classifier.
　in our research  both structural and content features are selected. in structural features  quotation maintains context coherence and indicates the relevance between the current reply and the quoted root message or reply  as discussed in  eklundh and macdonald  1; eklundh  1 . two quotation features  feature 1 and feature 1  are employed in our classifier. feature 1 indicates that the current reply quoting the root message is relevant to the root message. on the contrary  feature 1 indicates the current reply might be irrelevant to the root message because it quotes other replies. we use features 1 and 1 based on the observation of behaviors of posting replies in forums. the thread starter  when participants reply to the starter's thread  usually adds new comments to the replies. therefore  the added replies gradually diverge from the original root message. if a participant wants to supplement or clarify his previous reply  he can add a new reply. therefore  the participant's new reply is often the supporting reason or argument to his previous reply if they are close to each other.
　content features include the features about the number of words and the number of content words in the current reply  the overlapping words and content words between the root message and the current reply. in our work  words that do not appear in the stop word list1 are considered as content words. feature 1 estimates the specialization of the current reply by the number of domain specific terms. to simplify the identification of domain specific terms  we simply extract words as domain specific words if they do not appear in a commonly used lexicon  consists of 1 english words . feature 1 estimates a reply's pertinence to other replies  because some participants might insert the registered nicknames of other participants and sometimes add clue words such as  p.s.  to explicitly correlate their replies with certain participants.
1 rr ranking
further  after the rrs have been identified  non-eligible rrs are filtered out with a keyword list with 1 obscenities  1 personal information terms  terms beginning with  my   such as my wife  my child  and 1 forum specific terms  such as tomatometer  rotten tomato  etc. . replies with more than n words are eliminated because people may become bored in chatbot scenarios if the response is too long. in our experiments  n is set as 1 based on our observation.1
　we analyzed the resulting rrs set of 1. for some rrs  there is certain noise left from the previous pass  while for other rrs  there are too many rrs with varied qualities. therefore  the task of rr ranking is to select the highquality rrs. the ranking svm  joachims  1  is employed to train the ranking function using the feature set in table 1.
　the number of being quoted of a reply is selected as a feature  feature 1  because a reply is likely to be widely quoted within a thread as it is popular or the subject of debate. in other words  the more times a reply is quoted  the higher quality it may have. this motivates us to extract the quoted number of all the other replies posted by an author within a thread  feature 1  and throughout the forum
 feature 1 .
　we also take  author reputation  into account when assessing the quality of a reply. the motivation is that if an author has a good reputation  his reply is more likely to be reliable. we use the author behavior related features to assess his  reputation.  an earlier work investigates the relationship between a reader's selection of a reply and the author of this reply  and found that some of the features raised from authors' behavior over time  correlate to how likely a reader is to choose to read a reply from an author  fiore et al.  1 . features 1 to 1 are author behavior related features in the forum. feature 1 models how many people have chosen to read the threads or replies of an author in the forum by using the measurement of the influence of participants. this is described in detail in  matsumura et al.  1 .
1feature of the number of being quoted
1	# of quotations of this reply within the current thread1features from the author of a reply
1	# of threads the author starts in the forum
1	# of replies the author posts to others' threads in the forum
1	the average length of the author's replies in the forum
1	the longevity of participation
1	# of the author's threads that get no replies in the forum
1	# of replies the author's threads get in the forum
1	# of threads the author is involved in the forum
1	the author's total influence in the forum
1 # of quotations of the replies that are posted by the author in current thread
1 # of quotations of all the replies that are posted by the author in the forumtable 1. features for rr ranking.
1 experimental results
1 data for experiments
in our experiments  the rotten tomatoes forum1 is used as test data. it is one of the most popular online discussion forums for movies and video games. the rotten tomatoes forum discussion archive is selected because each thread and its replies are posted by movie fans  amateur and professional filmmakers  film critics  moviegoers  or movie producers. this makes the threads and replies more heterogeneous  diverse  and informative.
　for research purposes  the discussion records are collected by crawling the rotten tomatoes forum over the time period from november 1  1 to june 1  1. the downloaded collection contains 1 1 replies from 1 threads posted by 1 distinctive participants  so there are  on average  1 replies per thread  1 replies per participant  and 1 threads per participant. the number of thread titles in question form is 1  1%  and in statement form is 1  1% . we use part of these discussion records in our experiments.
1 rr identification
to build the training and testing dataset  we randomly selected and manually tagged 1 threads from the rotten tomatoes movie forum  in which the number of replies was between 1  min  and 1  max . there were 1 replies in 1 threads  i.e.  1 replies per thread on average. three human experts were hired to manually identify the relevance of the replies to the thread-title in each thread. experts annotated each reply with one of the three labels: a  rr  b  non-rr and c  unsure. replies that received two or three rr labels were regarded as rr  replies with two or three non-rr labels were regarded as non-rr. all the others were regarded as unsure.
　after the labeling process  we found out that 1 replies  1%  were rr  1 replies  1%  were non-rr  1  1%  were unsure. we then removed 1 unsure replies and 1 replies with no words. we randomly selected 1 threads for training  including 1 replies  and 1 threads for testing  including 1 replies . our baseline system used the number of replies between the root message and the responding reply  zhou and hovy  1  as the feature to classify rrs.
　table 1 provides the performance using svm with the feature set described in table 1.
feature setprecisionrecallf-scorebaseline1%1%1%structural1%1%1%content1%1%1%all1%1%1%table 1. rr identification result.
　with only the structural features  the precision  recall and f-score reached 1%  1%  and 1%. content features  when used alone  the precision  recall and f-score are low. but after adding content features to structural features  the precision improved by 1% while recall stayed the same. this indicates that content features help to improve precision.
root message
title: recommend some westerns for me 
description: and none of that john wayne sh*t.1. the wild bunch it's kickass is what it is.
1. once upon a time in the west
1. does dances with wolves count as a western  doesn't matter  i'd still recommend it.
1. white comanche this masterpiece stars ...... 1.	here's some i'm sure nobody else ......
1. for dances with wolves.
1. : understands he's a minority here: ...... 1.	open range is really good.  regardless ......
1. one of the best films i've ever seen.
1. the good the bad and the ugly ......figure 1. a sample of rrs.
　figure 1 presents some identified rrs listed in chronological order for the root message with the title   recommend some westerns for me   and description for the title   and none of that john wayne sh*t. .
1 extract high-quality rr
to train the ranking svm model  an annotated dataset was
required. after the non-eligible rrs were filtered out from the identified rrs  three annotators labeled all of the remaining rrs with three different quality ratings. the ratings and their descriptions are listed in table 1.
ratingdescriptionfascinatingthis reply is informative and interesting  and
it is suitable for a chatbotacceptablethe reply is just so-so but tolerableunsuitablethis reply is bad and not suitable for a chatbottable 1. rr rating labels.
　after the labeling process  there were 1  1%  fascinating rrs  1  1%  acceptable rrs  and 1  1%  unsuitable rrs in the 1 rrs of the 1 training threads. and in the 1 rrs of the 1 test threads  there were 1  1%  fascinating rrs  1  1%  acceptable rrs  and 1  1%  unsuitable rrs.
　we used mean average precision  map  as the metric to evaluate rr ranking. map is defined as the mean of average precision over a set of queries and average precision
 avgpi  for a query qi is defined as:
	m	p  j * pos  j 
avgpi =
j=1 number of positive instances
where j is the rank  m is the number of instances retrieved  pos j  is a binary function to indicate whether the instance in the rank j is positive  relevant   and p j  is the precision at the given cut-off rank j.
　the baseline ranked the rrs of each thread by their chronological order. our ranking function with the feature set in table 1 achieved high performance  map score is
1%  compared with the baseline  map score is 1% . we also tried content features such as the cosine similarity between an rr and the root message  and found that they could not help to improve the ranking performance. the map score was reduced to 1% when we added the cosine similarity feature to our feature set.
1 chat knowledge extraction with proper n setting
the chat knowledge extraction task requires that the extracted rrs should have high quality and high precision. after we got the ranked rrs of each thread  the top-n rrs were selected as chatbot responses. the baseline system just selected top-n rrs ranked in chronological order. figure 1 shows the comparison of the performances of our approach and the baseline system at different settings of n.
　figure 1 shows the top-n  n=1  n can be adjusted to get proper equilibrium between quantity and quality of rrs when extracting chatbot knowledge  rrs after ranking the rrs in figure 1. as an instance  we uniformly extracted top-1 high-quality rrs from each thread. altogether 1  thread-title  reply  pairs were generated from 1 threads. among these extracted pairs  there were 1 fascinating pairs and 1 wrong pairs  which showed that 1% of the extracted chatbot knowledge was correct.

1 1 1 1 1 1 1 1 1 1 1 precision	 precision  baseline figure 1. precision at different n.
input: recommend some westerns for me 
chatbot responses:
1.    for dances with wolves.
1.  young guns! & young guns 1!
1.    once upon a time in the west 1.    one of the best films i've ever seen.
1.  i second the dollars trilogy and also big hand ......
1. classic anthony mann westerns: the man from laramie
 1  ......
figure 1. top-1 rrs.
1 comparison with related work
previous works have utilized different datasets for knowledge acquisition for different applications. shrestha and mckeown  use an email corpus. zhou and hovy  use internet relay chat and use clustering to model multiple sub-topics within a chat log. our work is the first to explore using the online discussion forums to extract chatbot knowledge. since the discussions in a forum are presented in an organized fashion within each thread in which users tend to respond to and comment on specific topics  we only need to identify the rrs for each thread. hence  the clustering becomes unnecessary. furthermore  a thread can be viewed as  input  response  pairs  with the same structure of chat template of a chatbot  making a forum better suited for the chatbot knowledge extraction task.
　the use of thread title as input means that we must identify relevant replies to the root message  rrs   much like finding adjacent pairs  aps  in  zhou and hovy  1  but for the root message. they utilize ap to identify initiating and responding correspondence in a chat log since there are multiple sub-topics within a chat log  while we use rr to identify relevant response to the thread-title. similarly  we apply an svm classifier to identify rrs but use more effective structural features. furthermore  we select high-quality rrs with a ranking function.
　xi et al.  use a ranking function to select the most relevant messages to user queries in newsgroup searches  and in which the author feature is proved not effective. in our work  the author feature also proves not effective in identifying relevant replies but it is proved effective in selecting high-quality rrs in rr ranking. this is because irrelevant replies are removed in the first pass  making author features more salient in the remaining rrs. this also indicates that the cascaded framework outperforms the flat model by optimally employing different features at different passes.
1 conclusions and future work
we have presented an effective approach to extract  threadtitle  reply  pairs as knowledge of a chatbot for a new domain. our contribution can be summarized as follows:
1. perhaps for the first time  our work proposes using online discussion forums to extract chatbot knowledge.
1. a cascaded framework is designed to extract the high-quality  thread-title  reply  pairs as chabot knowledge from forums. it can optimally use different features in different passes  making the extracted chatbot knowledge of higher quality.
1. we show through experiments that structural features are the most effective features in identifying rr and author features are the most effective features in identifying high-quality rr.
　compared with manual knowledge construction methods  our approach is more efficient in building a specific domain chatbot. in our experiment with a movie forum domain  1  thread-title  reply  pairs were extracted from 1 threads within two minutes. it is simply not feasible to have human experts encode a knowledge base of such size.
　as future work  we plan to improve the qualities of the extracted rrs. the method of selecting valid thread titles and extracting completed sentences from the extracted rrs is an area for exploration. in addition  we are also interested in extracting questions from threads so that  question  reply  pairs can be used to support qa style chat.
　we currently feed the extracted  thread-title  reply  directly into the chatbot knowledge base. but there is much room to improve quality in the future. for example  we can generalize the chat templates by clustering similar topics and grouping similar replies  and improve coherence among the consecutive chat replies by understanding the styles of replies.
acknowledgements
the authors are grateful to dr. cheng niu  zhihao li for their valuable suggestions on the draft of this paper. we also thank dwight for his assistance to polish the english. we wish to thank litian tao  hao su and shiqi zhao for their assistance to annotate the experimental data.
