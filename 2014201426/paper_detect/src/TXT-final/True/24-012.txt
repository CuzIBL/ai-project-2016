* 
this paper presents an extension of the inverse resolution framework  which is a logical model of theory induction in first order logic. we first propose a definition of completeness for inductive procedures and exhibit some limitations of inverse resolution with respect to this definition. we then propose our model of inversion of logical entailment that extends inverse resolution with regard to these limitations. two operators are formalized that implement this formal framework and we prove that they arc complete. in the last part of the paper  we propose two possible controls for these operators  to restrict the search for an acceptable theory. these two controls express some semantic properties of the theory that the system is searching for. 
1 introduction 
there have been considerable research efforts concerning automated induction in the field of machine learning  under different subfields such as generalization  michalsksi  1; kodratoff & ganascia  1; buntine  1   theory refinement  shapiro  1; duval & kodratoff  1  and concept formation  sammut & banerji  1; de raedt & bruynooghe  1 . recently   muggleton & buntine  
1  have proposed a logical framework for induction of logic programs in first order logic  inversion of resolution  ir . 
1r was the first inductive framework to provide a strong logical basis that allows the study of the formal properties of inductive behaviors. having some elementary processes that can be controlled and combined to perform complex inductions is one step towards a more well founded comparison of learning programs. moreover  making the link between machine learning and logic programming allows us to study formal properties of learning systems  such as completeness  soundness  and a concept more particular to ml: what kind of programs can be induced from data and some background knowledge. 
ir  however  was subject to many limitations  rouveirol & puget  1; rouveirol 1b . we propose in this paper a framework that addresses some of those limitations  inversion of logical entailment  ile   which is defined as follows. given: 
     a domain theory t 
     an example e such that e does not belong to the set of logical consequences of t  denoted t e  
we look in ile for a domain theory t  such that t logically entails both e and t. in this paper  we will restrict ourselves to the case where t' is identical to t plus a single new clause. 
ile  as opposed to ir which is based on the notion of proof procedure  is a semantic model for induction  i.e.  ii is based on the notion of logical models of the manipulated theories: the model of t is considered as a partial model of t  the theory sought. 
the paper is organized as follows: we first recall limitations of ir that lead us to introduce ile. in this framework  we introduce a definition of completeness for inductive procedures and two new elementary operators truncation and saturation and we then prove they are complete. finally  we will consider the control aspects of the method. in particular  we will introduce two controls for truncation  one bias imposes some limits on the language in which the resulting theory is expressed  and another takes into account semantic properties of concepts the system learns about. we adopt here the logical notations  as described in  lloyd  
1 . we are dealing with definite clauses  i.e.  clauses with exactly one head literal a clause can be interpreted as a partial definition for a concept  where the head literal identifies the defined concept and the literals in the body of the clause represent the preconditions for an object to belong to this concept. a clause c  is an instance of a concept represented by the clause c iff the body of c 1-subsumes  plotkin  1  the body of ci   that is  the body of cj unifies with a subpart of the body of c. 
1. completeness of inductive procedures 
1  incompleteness of ir 
we are interested in characterizing formal properties of inductive procedures such as ile. among the properties that arc usually studied in the logical framework  let us first concentrate on completeness. a very natural semantic definition for completeness of inductive procedures in ile is the following: 
given a logic program t  a clause e such that t 	e  	and 
ip  an inductive inference procedure  then ip is complete iff 
	rouveirol 	1 
ip generates all the logic programs t'= ip t e  such that t 1= t and t 1= e. 
ir is not complete with respect to this definition of completeness. it is a well known result in logic programming that resolution is refutation complete  that is  given an unsatisfiablc set of clauses  resolution always derives the empty clause. but resolution for first order logic clauses is not complete in the sense of consequent finding when dealing with definite clauses. the following subsumption lemma gives a more precise formulation of this statement: 

 in other words  given a clause c belonging to a domain theory t  all the clauses cs  such that c g-subsumcs cs are logical consequences of t  although it is not possible to derive those clauses by using resolution. it is therefore not sufficient to invert resolution to have a complete inference procedure. we have shown in  rouveirol & puget  1  the practical consequences of incompleteness of ir  truncation in cigol is limited to inversion of substitutions and therefore cannot handle the dropping conditions rules . now that we have a semantic model for induction  we arc no longer restricted to inversion of a proof procedure  we have extended cigol's original operators to overcome the above limitations. 
1. saturation 

in other words  the generalization amounts to replacing by the head of c r   substituted by 1  the literals 1-subsumed by the body of cr in the body of c e . therefore  a problem arises when there exists in a domain theory partially overlapping concepts. in this case  there are several competing generalizations for the literals in the body of the initial clause. 
just to take a very simple proposilional example  let us suppose our domain theory is formed of the two following clauses: 

and that our example is: 

there are two possible generalizations following the above algorithm  either 

or 

but it is not possible  by using the above algorithm to get the most specific generalization of this clause and to perform both generalizations at the same time. we have presented in 1 learning and knowledge acquisition  rouveirol & puget  1  a solution to this generalization problem in the form of a new operator called saturation that performs all the possible and concurrent absorptions in parallel. we will now develop a formalization of this saturation operator  relating it to our ile framework and then to resolution itself. 
1. elementary 	saturation 
let us first introduce an intermediate step called elementary 
saturation. basically  elementary saturation docs not replace the description of an instance of a concept by the concept identifier in the body of the generalized clause  but rather adds to the body of the clause the information that an object is an instance of a concept. 
definition: let there be a clause ce : te l c e that we will call the initial or example clause  and a clause  
            saturant clause such that l c s 1-subsumes such that we call elementary saturation of ce by c s   the clause: 

given the same domain theory and example as defined in section 1  one possible elementary saturation is 

and this elementary saturation does not prevent us from performing the other elementary saturation that would lead us to the most specific clause: 

theorem n¡ãl: elementary saturation is a sound process. 
it is indeed interesting to notice that elementary saturation which has been recognized as an inverse resolution step  muggleton  1  can be expressed in terms of sound processes  skolcmization and resolution. skolcmizing a clause means that all the universally quantified variables are replaced by constants that do not appear elsewhere  in the domain theory . skolemization of the example is logically sound due to the following theorem  proved in  rouveirol  1a . 
theorem n¡ã1  soundness of skolemization : let t be a definite logic program and l the language of t . let f  x 1   . . . x n   be a n-ary formula of l  where x1 ...xn are the variables of f. 

where c 1  ...cn  are constants that do not appear in t. 
1. 	saturation 
when there is no information about how control the use of elementary saturation  we have chosen to be exhaustive. elementary saturation with this exhaustive control is refcred to as saturation. 
definition: saturation operator. 
given a definite program t and a definite clause c e   the saturation of ce given t is the transitive closure of the elementary saturation operator. more precisely: 



definition  inversion completeness : an inference procedure ip is inversion complete  given a definite logic program p and a definite clause c e : te  - l c e   such that p |=/=ce  iff ip produces all the clauses cs : ts  - l c s such that: 

theorem n¡ã1 : saturation is inversion complete. 
we will not produce here the proof of inversion completeness of saturation that can be found in  rouveirol  1a  but we rather give the saturation algorithm which follows the structure of the proof. this algorithm exploits the relationship between elementary saturation and resolution: inverting logical entailment amounts to performing exhaustive deduction on the skolemized negation of the body of the example clause. 
given the clause  and a domain theory t  roceed to steps 1  1 and 1: 
. skolemization of ce i n t o   o n e keeps track of 1s for deskolemization . for eacn literal l c e i in the body of c e   a clause c s k i is created  with c s k i : 
 . deductive phase: we apply all possible resolutions oetween the set of clauses {cski} and the clauses of t. 
n. if atoms have been deduced after step 1  they are transformed into unit clauses and added to {csk i }. the process then iterates on step 1. if no literals have been deduced after step 1  the  cski  are deskolemizcd and added to l c e to form the body of the saturated clause  
c s   
figl: algorithm of saturation 
the result of saturation is a clause that subsumes all the possible generalizations of the initial clause. the set of all the possible generalizations of the initial clause contains all the clauses that are obtainable from the initial clause by any sequence of inversion of resolution steps. 
saturation can be seen as a formalization of the use of deduction while generalizing  which is an idea that was presented in  kodratoff & ganascia  1  although not in such a systematic way. similar steps to saturation arc used in various systems such as msg  buntine  1   kbg  bisson  1   clint  de raedt & bruynooghc  1 . 
1. truncation 
1. 	definition 
truncation is a purely inductive operator  that is  it generalizes clauses without using background knowledge. according to  michalski  1   there are two main purely inductive generalization rules  the dropping conditions rule and the turning term into variable rule. truncation can produce  given an input clause c the set of all the clauses that are 1-subsumed by c. it is an extension of the 
1
  we notice that saturation looks very much like the operator used to build the least herbrand model  muggleton  1 . 
truncation operator of cigol  because it can model both the turning term into variable and the dropping conditions rules  whereas truncation in cigol only takes into account the former. given an initial clause e  we consider that one truncation step cither drops one literal in the body of e  or replaces all occurrences of a given term by the same new variable in e or else splits different occurrences of the same term into different variables. 
1. coupling saturation and truncation 
coupling saturation and truncation amounts to performing generalization in the presence of background knowledge. it can  depending on the chosen control for truncation  reproduce the behavior of generalization algorithms such as structural matching  kodratoff & ganascia  1   and golem  muggleton & feng  1 . 
coupling saturation and truncation allows us to achieve inversion of logical entailment  but with a restriction to the completeness defined in section 1. given a clause e and a domain theory t  saturation provides the clause es. then  truncation can build from es all the clauses estj such that e s l i 1-subsumes es  that means  all the possible generalizations of e which have the same head as e. therefore  by adding to the initial theory t any of the esli  we get all the logic programs which differ from the initial clause by a clause which has the same head as the unrecognized example. to remove this restriction  that is  to induce esti clauses that do not necessarily have the same head as the example clause  we would have to apply some backward chaining mechanism on the head of the clause. in this way  we would achieve real completeness  but controlling the combination of an descending method such as  wirth  1  and our ascending method is still a research problem. 
1. implementation: the itou system 
itou takes as input a domain theory and the example  it starts by performing a subsumption test: docs the theory logically entail the example  the subsumption test is based on the theorem n¡ãl. this subsumption test is very similar to saturation: the body of the example is skolemized  resolution is then performed  if the skolemized head of the example is derived  the example is subsumed by the theory  otherwise not. this subsumption test and saturation suffer from the same limitations: if the theory contains loops  the deduction graph grows exponentially. in this case  the depth of the deduction graph is bounded  and once this bound is reached  the example is by default considered unexplained. 
if the example is not subsumed by the theory  itou first saturated the example  indeed  it uses the deduction graph of the subsumption test . the system then tries to generate a new theory t' such that t subsumes both the initial theory and the unrecognized example. there are of course plenty of theories that satisfy these two conditions. the simplest one is the initial theory plus the unrecognized example only. however  it is clear that we are looking for greater predictiveness for the new theory than this allows. therefore  itou integrates the example into the domain theory  by expressing it in terms of concepts already defined in the domain theory  it is the role of saturation  and then it will generalize it  dropping unnecessary information  by applying truncation. the coupling saturation-truncation  as explained in section 1  allows to perform generalization in the presence of the domain theory. 
	rouveirol 	1 

saturation is deterministic  it produces only one clause whose body contains the bodies of all possible generalizations of an initial clause  given a domain theory   the only control point is within truncation. strictly  truncation generalizes one single clause  the saturated failure example   but to restrict the possible choices for applying truncation  it has been implemented as a n clauses generalization algorithm: the saturated failure example is generalized against some similar clauses already existing in the incomplete domain theory. truncation up to now is based on a constrained least general generalization algorithm described in the next section. each computed generalization is proposed to the user for validation. each validated 
generalization is added to the domain theory. 
1. control for induction in itou 
the truncation has to be carefully controlled for two reasons. first of all  it is the only inductive step of the method  so information loss has to be under control. the second reason is more practical: the space of reachable clauses from one given clause is very large  if we consider only the general formulation for truncation. 
to reduce the search space of truncation  the operator takes as input a set of definite clauses: only the literals that are not common to the n clauses after saturation are dropped. so the first control point in itou is in the choice of clauses  that may already belong to the domain theory or that may be other unrecognized examples  that will be generalized with the saturated example. in our current implementation  examples are represented as definite clauses  so by default  clauses that have the same head predicate will be generalized together. extensions to more sophisticated clustering techniques that allows for learning of disjunctive concepts have to be studied. 
as truncation is a generalization algorithm that does not use background knowledge  the basis of the algorithm is the least general generalization algorithm  denoted lgg   plotkm  1 . basically  the lgg algorithm uses the notion of selection. a selection is a n-uple of literals having the same predicate symbol  each member of the n-uple belonging to one of the n clauses to generalize . the arguments of each member of the selection of each selection are recursively scanned in parallel  each occurrence of different terms occurring at the same place in members of the selections is replaced by a variable in the generalization of the selection. all the possible selections are considered and same terms or subterms within the same clauses are replaced by the same variables to ensure that the obtained generalization is the least general one. 
we have modified the basic lgg algorithm because  sometimes  it may well be the case that the least general generalization is not the most suited to the learning situation. we have therefore introduced some constraints at different points in the algorithm. the constrained lgg algorithm first orders all the possible selections to consider. moreover  each time the generalization of a selection is added to the current generalization  the system tests whether the new current generalization satisfies a set of constraints defined on the result of the generalization. if it is the case  the algorithm succeeds and return the new current generalization. if it is not the case  the algorithm considers further selections. if no constraints are given to the 
1 	i earning and knowledge acquisition algorithm  it returns at the end the lgg of the n input clauses. 
there have been a lot of biases for generalization  mostly syntactic  such as constraints on the form of generalization. just to mention some of them  there are simplicity criteria evaluated with regard to the number of variables or to the number of literals  connectivity or utility criteria  that maximize the number of times where the same object  variable or term  appears in the generalization  the generalizations can be evaluated in terms of their position in the generalization lattice  least or most general generalization  or any domain dependent characteristic. we refer to  kodratoff  1  for a survey of generalization techniques and biases. sometimes  counter examples can also be used to restrict the space of possible generalizations. 
we present here two biases  one called connexion  that restricts the language in which the generalizations are expressed. this bias has an interesting semantic property  and moreover it addresses some well known concerns in knowledge representation. the second one  that we call functional relation bias exploits some semantic properties of concepts we want to learn about. 
1. 	connexion 
the connexion principle states that variables in the body of a clause must either appear in the head of the clause  or be linked to a variable of the head of the clause through a path of predicates. this ensures that all literals in the body of a clause are related to its head  or that all the conditions for an instance to belong to a concept are related to the concept itself.  morik  1  lists some common errors in knowledge modeling that justify the use of connexion. 
the input of the generalization algorithm is restricted to connex clauses  and the generalization of two connex clause has to be connex. the corresponding constraint in our generalization algorithm is that there must be at least one variable in the generalization of a new selection that appears in the current generalization. this allows us to limit the number of variables in the generalization. similar constraints have been used in clint  de raedt & bruynooghe  1 . moreover  we have proved that a non connex formula has the same least herbrand model as the corresponding connex clause  where all the unconnected literals have been dropped . 
1. functional 	relation 
the functional relation principle is a semantic bias. for some predicates  we know that instantiation of some of its arguments uniquely sets instantiations for its other arguments. for example  an object has only one position  people have only one social security number  one father and one mother  etc... we propose here a definition of functional relation close to the one proposed in  puget  1 . 
definition: let p be a logic program  let p r e d  x  y  be a predicate where x and y are two vectors of variables defined in p. p r e d  x  y  is afunctional relation of x if p r e d  x  y  verifies : 

the notion of functional relation is very close of that of the functional determination  russel  1 . functional relations are indeed frequent: for example  in object oriented languages  a mono-valued slot defines a functional relation. 
 puget  1  showed how such an information can be used to remove negated literals in the body of a clause describing the negation of p r e d . let us see here how it can be used in drive the generalization process. let us suppose we are generalizing two clauses: 

and that we know that p r e d is a functional relation of x. the generalization of c  and c1 is the clause cg 
and  
q1  a b c  must be such that p r e d  a  b  is a functional relation of a. this means that given any instantiation of a  there must be only one possible instantiation for b whatever the relationships between variables of c and a and variables of c and b. to be able to compute such a q1  a  b  c   we need of course to know about predicates in q1  x  y  z  and q1   x '   y '  z '  that are themselves functional relations. the most general q1s contain only predicates which arc functional relations. 
 let us see on a small example how knowledge about functional relationship can guide the generalization process  p l u s  x  y  z  is a functional relation of any two of its arguments. for example  once x and y are instantiated  there is only one possible instantiation for z. we want to generalize two clauses that describe saturated addition examples  see rouveirol  1  for details ': 

which is the flattened saturated representation of 1 plus 1 equals 1. the literal in bold has been added by saturating the clause representing 1 plus 1 equals 1 with the clause representing 1 plus 1 equals 1. 

which is the saturated flattened representation of 1 plus 1 
equals 1  obtained by saturation of the initial clause representing 1 plus 1 equals 1 with the clause representing 1 plus 1 equals 1 and i 1 f s. 
a candidate generalization is p l u s   x   u   v    p l u s   x   y   z   a s u c c   y   u   . let us check whether this generalization verifies the functional relation of addition. let us take any of the three functional relation constraints given for addition  for example 
   g i v e n p l u s   x   y   z     if y and z a r e i n s t a n t i a t e d   t h e r e i s o n l y one p o s s i b l e i n s t a n t i a t i o n f o r x . we also need the knowledge that s u c c   x   y   is a functional relation for any one of its arguments. 
 plus x y z  means that the result of x plus y equals z  and succ x y  means that y is the arithmetic successor of x. 
checking this functional relationship on the candidate generalization amounts to instantiating u and v. we then have to check how these instantiations propagates through the body of the clause. there is no instantiated variable in p l u s  x  y  z     so no other variables become instantiated. for succ  y  u   u is instantiated; as succ is a functional relation of any of its arguments  y becomes instantiated. but this is not sufficient for x and z to become instantiated  as only on variable in p l u s  x  y  z  is instantiated. x is not instantiated after propagations of all the instantiations  and therefore the functional relation is not fulfilled by our candidate generalization. 
another candidate generalization is: 

checking the same functional relation constraint  we start as in the previous example  but for s u c c   z   v    v is instantiated and thus so becomes z. therefore  y and z are instantiated arguments in p l u s   x   y   z     and then x becomes instantiated. the functional relation is verified  this generalization is thus proposed to the user. this is one of the recursive definitions for addition. 
just to give an idea about the power of these two biases  on this example for synthesizing addition from examples  rouveirol  1   our basic generalization algorithm computed all the subparts of the least general generalization 
 plotkin  1  of two clauses. there were approximately 1 candidate generalizations without using any bias  1 candidate generalizations after using the connexion bias  and only six of them were left after also applying the functional relation bias. the most general of these six was the recursive definition of addition. 
1. related works 
we do not present here cigol  but a detailed comparison of our work and that of  muggleton & buntine  1  can be found in  rouveirol  1a . golem  its successor has some strong similarities with our. our saturation operator is similar to the vn operator introduced in  muggleton  1  but it is not restricted to handle strongly generative clauses  that means clauses where any variable appears at least twice  although wc can introduce afterwards this constraint to restrict our search for a good generalization in truncation. to restrict the complexity of the task  golem is restricted beforehand to theories formed of strongly generative clauses. under this assumption  the background knowledge can be replaced by a finite set of ground atoms  i.e.  a propositional case. 
the vn operator maintains a set of clauses that are obtainable by applying at most n most specific inverse resolution steps  a most specific inverse resolution step is similar to our elementary saturation . the difference is that our saturation operator applies elementary saturation exhaustively: therefore it provides only one clause as a result that implicitly contains all the clauses maintained by the vn operator. it is by applying truncation that itou could build all the clauses built by v n   but it will never  in practice  build them all. a completeness result for the vn operator was reported for golem  restricted to strongly generative clauses. independently from  rouveirol & puget  1    muggleton  1  made a theoretical link between relative least general generalization  rlgg  that is  least general generalization in the presence of background 
	rouveirol 	1 
knowledge  and inverse resolution with the vn operator. there is a strong similarity in both approaches: vn is similar to saturation  whereas golem is similar to our generalization algorithm fro truncation. but in itou  saturation is used to complete the example description before performing truncation  whereas it does not seem that vn is used as part of golem. 
another difference is that our approach relies on a small number of well chosen examples  whereas golem builds efficient relative least general generalizations of a mass of examples. at last  to simplify the obtained rlgg  golem uses biases to guide a dropping rule mechanism in a similar way. the msg algorithm  buntine  1  is also similar but addressed a different generality relation  generalized subsumption  whereas we deal with logical entailment with definite clauses. 
1. conclusion 
we have proposed a new semantic model for induction of first order logic logic programs. in this framework  we have defined a notion of completeness and defined two operators that achieve a restricted completeness. these two operators are left deliberately general  so that they can be guided through an external declarative control that allow the system to converge faster towards the desired theory ies . 
there are many further directions for future research. the main one is the development of other operators within our framework. a specialization operator  up to now  we have just proposed operators that allow us to increase the number of logical consequents of logic programs   and therefore  we still cannot handle incorrect logic programs. works of  shapiro  1   wrobel  1  and  bain  1  should be investigated. introduction of new terms needs to be developed   in particular the notion of completeness has to be adapted to include the introduction of recursive predicates to allow to keep the size of the resulting theory finite. in parallel to introduction of new operators  declarative means of control should be developed. an interesting work in this respect is  kirshenbaum & sterling  1 . 
acknowledgements: i would like to thank yves kodratoff  who was my thesis supervisor for the support and suggestions he has provided to this work  m. bruynooghe and j.g. ganascia  and the anonymous referees for their comments. i thank also j.f. puget who has started with me this work on inverse of resolution  for his support. 
