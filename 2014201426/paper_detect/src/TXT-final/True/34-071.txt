microphonhhes as fundamental segments of speech wave 
	primary segmentation - automatic 	searching for 	microphonemes 
	mgr i n z . 	a n d r z e j d z i u r n i k o w s k i 
i n s t i t u t e of o r g a n i z a t i o n   	management and c o n t r o l sciences  	 /arsaw  	poland 

a b s t r a c t 
t h i s paper concerns the stage of a c o u s t i c a n a l y s i s i n speech r e c o g n i t i o n o f speech u n d e r s t a n d i n g system susy; subsystem akord  a c o u s t i c a n a l y s i s i n t h i s system i s based on dynamic s p e c t r a l a n a l y s i s of the speech wave. i t corresponds w i t h the f u n c t i o n o f 
the h e a r i n g organ expressed by an analog nodel of human e a r . a c o u s t i c a n a l y s i s in 
the akord system uses an fft a l g o r i t h m b u t i s not s t r i c t l y based o n a c c e p t i n g c o n s t a nt i n t e r v a l s of 1 ms; a n a l y s i s does n o t cause i n a c c u r a c y a t the l e v e l o f p a r a met r i z a t i o n because of a c o n s i d e r a b l e d i s p e r s i o n o f parameters o f p a r t i c u l a r s e g ments. a c o n c l u s i o n was made in the akord system t h a t a p r o p e r l y conducted process o f segmentation w i l l h e l p i n s o l v i n g some problems of speech wave a n a l y s i s   p a r t i c u l a r l y r e c o g n i t i o n and time c o m p r e s s i o n . t h i s paper a t t e m p t s to choose the p r i m a r y segment  microphonem  in the most optimum way and to i n d i c a t e the a l g o r i t h m of a u t o matic segmentation based on microphonemes as t h e dynamic segments. 
i n t r o d u c t i o n 
　　system akord was designed f o r r e s e a r c h work c o n c e r n i n g the a n a l y s i s and s y n t h e s i s of speech waves by means of a zam-1 comp u t e r   1   1   1   - d u r i n g the i n i t i a l phase o f r e s e a r c h t h a t system was h e l p f u l i n d e f i n i n g t h e most e s s e n t i a l problems o f speech wave a n a l y s i s - i t a l s o made i t poss i b l e to i n c u l c a t e and t e s t some a l g o r i t h m models of speech a n a l y s i s . however  b e f o r e a c c e p t i n g a c o n c r e t e a l g o r i t h m model of speech a n a l y s i s i t was necessary t o r e a l i z e d i f f e r e n t f u n c t i o n s o f the h e a r i n g 
　　o r g a n . those f u n c t i o n s are expressed by an analog model of the human ear   1   . g e n e r a l l y   the t r a c k of a g i v e n sound in the ear may be p r e s e n t e d as f o l l o w s : t h e e x t e r n a l e a r   the e a r - d r u m   the i n t e r n a l ear and i t s bones   m a l l e u s   i n c u s   s t i r r u p   . the movements of the s t i r r u p bone cause t r a n s l o c a t i o n of cochlea septum : - i t s r e s i i e n c e i s n o t c o n s t a n t t h r o u g h i t s whole l e n g h t   1   1   . that v i b r a t i o n i s s u b s e q u e n t l y t r a n s n i t t e d through the nerve c e l l s on the septum to ~1 a u d i t o r y nerve f i b r i l s . f i g u r e 1 shows analog model of human ear p r e s e n t e d by p.kolers   1   . a l t h o u g h t h i s mod l is o n l y approximate  a comparison o f the c h a r a c t e r i s t i c s o b t a i n e d 
　　e x p e r i m e n t a l l y showed a c o n s i d e r a b l e c o n vergence   1   . ne accept the c o n c l u s i o n   w i t h no deeper c o n s i d e r a t i o n of the ear model presented h e r e   t h a t the i n t e r n a l car i s the c e n t r e o f sound s p e c t r a l a n a l y s i s s t  . tts r e s u l t s are made average 

p t  -external auditory duct pressure  
g f  - l i n e a r block transforming pressure p t into voluminal translocation sct of the s t i r r u p   h f x  - t h i s function connects translocation s t with translocation of septum d   t   x   a t the point x  cm  from the s t i r r u p   rfis - realises the mean-square function of input signal d   t   x   f o r short duration  ~1 ras . 
figure 1 
in time for the period ts  ~ 1ms .the model of the auditory organ presented here is a basis in this paper  although i t s imperfection is realised. but it is not a novelty. the majority of studies concerning the analysis of speech waves have been based on the spectral analysis of the examined signals   1   . some of them used the dynamic spectral analysis  yet they were s t r i c t l y based on accepting constant i n tervals of 1 ms. although .the acceptance of that constant interval made it possible to realise some functions of analysis more simply  it caused some inaccuracy at the level of parametrization due to a considerable dispersion of parameters of particular segments 1 . this fact r e sulted in substantial d i f f i c u l t i e s connected with the segment extraction for r e cognition. it seems r e l a t i v e l y easy to find a relevant set of d i s t i n c t i v e phoneme features and so the segment corresponding with phonemes would be the most suitable for the recognition   1   . the number of segments determining particular classes also points to the same conclusion; in the case of phonemes there would be no more than 1. yet  d i f f i c u l t i e s connected with phoneme segmentation as well as those resulting from the lack of univocal dependence between the parameters of some concrete realization of the stochastic process and the process i t s e l f   make it too d i f f i c u l t to work out a highly e f f i c i e n t automatic system of speech recognition. oome authors consider it simply impossible to develop studies bas d on phoneme analysis and recognition  1  pointing to the practical d i f f i c u l t i e s of segment extract i o n . it is possible to conclude that a solution of this problem w i l l becone a basis for the development of some methods of speech analysis by means of particular speech sounds of a given natural language. 

1 

the process of segmentation when properly conducted w i l l help in solving some other problems of speech wave analysis e.g. time compression  coding  code ciphering and recognition. many scientists have noted the role of segmentation in the process of speech wave analysis  1 1  . yet  they were too strict in their choice of segments derived from the analog model. naturally  therefore  they did not obtain the type of results which could be acquired through a segmentation based on the segments chosen in the most optimum manner. this paper attempts to indicate the algorithm of automatic segmentation based on microphonemes as the dynamic segments. 
flicrophoneme as the fundamental segment of voiced speech~waves 
we are concerned with voiced speech since only for that class of speech is possible to extract fundamental segments in a simple way  keeping in mind the purpose this extraction could serve. it is also possible to resolve the stochastic signal into the class of stationary signals  as considered in frequency domain  by means of some simple methods  for examples  fourier's transformation. it corresponds with the model of the ear presented above. if we consider the objective function in speech wave analysis the following requirements arise: 
   - for the purposes of information recognition cits content  it is necessary to accept segment making it possible to realize the set of relations m; for the correct classification  while considering the subset of parameters defined for a given segment. it may be presented as the following condition: 


condition no 1 determines the time for the segment sk ; it is tk . considering the function of compression and coding  ik should be the maximum length of time of the segment  satisfying . condition no 1. fundamental segments forming quasi-periodicity of the segment sk w i l l be called primary segments. each of them is of different duration t j  and they form quasi-periodicity within the segment sk : - see formula no 1. with regard to the function of speech wave time compression  primary segments should satisfy the following condition : 

this condition states that a number of primary segments n should be maximum. 
　- for the purposes of speaker i d e n t i f i -cation it is necessarv to indicate such 
segment for the subset 
of parameters afterwards defined cidentifying the speaker  to satisfy condition no 1 in consideration of a given class of speakers kp and also : 

this condition indicates that the subset of parameters identifying the speaker 
specified in consideration of a freely accepted segment si  free in the sense of time   is the equivalent of the subset of parameters    these parameters are defined by means of one of the possible 
methods and the subset is calculated with some optional duration of speech for a given speaker  belonging to tho class kp   
   - in the process of reducing the noise the most essential parameters are : the speech spectrum and particular! the average spectrum of a speech wave. let us denote the subset of those parameters : . with this approach it is necessary to define the segment so such as : 

this condition means that it is necessary to indicate such a segment so for the calculated parameters of the average speech spectrum  to f i x univocally the average spectrum parameters calculated for 

1 

a speech wave of any duration and at any moment. in this case it is necessary to indicate a segment which would satisfy condition no 1 and which would at the same time be the most favourable considering the minimal time interval. this approach shortens the process of indicating the parameters ts considerably. with regard to these considerations  it is necessary to state that in the process of speaker identification and noise reduction  the choise of the best segment should be carried out considering i t s length of time. the shorter the segment si or so   the larger the possibilities of realizing both processes. therefore  it w i l l be possible to.indicate the minimal segment of a speech wave and through that to identify the speaker. the segment chosen in this way must satisfy condition no 1 and 1  corresponding with condition no 1 in that the set of parameters is indicated for a ftiven speaker p . but for the purposes of compression and codification it is necessary for the segment sk to be maximum and also to satisfy condition no 1 as in the case of recognition. in this case the aim is also to find the segment sk j  which 
would satisfy conditions no 1 and 1. we must search for a primary segment satisfying the following condition : 
within a given class 
because it is well known that the acceptance of the segment s  fixes the number of classes k*t tct fcs*    the minimation of the number of classes ki is the additional condition that should be taken into consideration while choosing the segment sr . if we accept syllables and words as the segment s  f the number of classes in which it would be necessary to include the analysed segments would be tens and hundreds of thousands. therefore it seems that it is necessary to accept a phoneme as the segment sn or a primary segment which is the equivalent of phoneme considering the condition no 1. the number of classes with a segment so defined is m ＊ 1 for the polish language. with this number of classes a 
given phoneme as a segment s* is the longest segment and it would f i x the segment 1k within the class ki . yet in spite of its usefulness for the purposes of recognition and compression  it would not be the most favourable segment because the condition 1 would not be satisfied. and only finding the primary segment that would meet a l l the requirements would make it possible to state the existence of the most favourable choice of the speech wave segment  in terms of recognition of the content and time compression of a speech wave   
　the number of classes according to condition no 1 would be retained. the additional effect of such an approach on speech wave analysis would be the obtaining of a dynamic analysis of parameters defined within the primary segment  1k . concerning the two remaining goals  speaker i d e n t i f i cation and reduction of noise  we may accept the primary segments  sk as fundamental 
only if it is possible to determine the parameters ♀r/and ♀a * on the basis of any parameter combination estimated within a given segment * k . in the case of speaker identification is advisable to estimate parameters for the dynamically analysed speech wave. spoed and changes in the larynx vibrations are some of the dynamic parameters characterizing the speaker and his articulation : let us denote the length of time of the larynx tone : tk   it is a function of time for a given voiced speech wave. therefore it is advisable to accept the primary segment  1k; its duration is t j  - tk . tt is different from the majority of algorithms assuming t j}= const . this approach would also give 
the phase accordance of the analysed segments  1     the primary segment is based on pitch period equal to tk corresponding to the analog ear model  tk 1 ms  and is called a microphonerae in this paper. our studies have entirely confirmed the pertinence of the accepted reasoning and also the fact that a microphoneme satisfies all the above conditions  1    
primary segmentation automatic searching for microphonemes 
     since a voiced speech wave results from the vibration of the vocal cords and is therefore only approximately periodic and since it depends on the individual characteristics of the speaker  it is not possible to assign definitely the frequency which could be considered fundamental for all segments 1 of a speech wave. in other words  the length of time of microphonemes is : t   i w const. the purpose of primary segmentation is the extraction of microphoneme sequence from the continuous speech wave of a given speaker by means of an algorithm realized as a computer programme. the solution of the problem concerning the extraction of quasi-periodic segments of a speech wave is complicated by the fact that not only quasi-periodicity is troublesome but also because the speech waves vary in amplitude and shape. in assigning microphonemes the algorithm uses some of the methods and remarks included in reddy* s algorithm : pitch period determination  1    it also completes reddy's algorithm with the elements connected with the acceptance of the microphonemes as a primary segment and with other parameters appropriate for polish speech as well as the accepted method of their representation  1     the algorithm ppd was used as an element to indicate the location neighbourhood of the expected end of a given microphoneme. the algorithm extracts microphonemes and indicates the places of expected microphoneme ends of the analysed speech wave and also gives a proportional indication of the voiced signal content in the analysed speech wave* 
1 　as we have already assumed  we shall be searching for the microphonemes only in that part of the speech wave which is voiced according to condition no 1  therefore the f i r s t step of the present segmentation 
is to find and indicate voiced segments of the analysed speech wave. because the whole procedure of primary segmentation operates on the time signal of the speech wave  the f i r s t step makes use of amplitude and frequency criteria   at this stage these c r i teria make it possible  as well as in the ppd algorithm  to distinguish three fundamental kinds of signals : silence  noise and a quasi-periodic signal. the algorithm has been adapted to the processing of the input signal which is f i r s t quantized. it assumes the frequency of sampling : -fp =1 khz  which makes it possible to represent the primary speech wave quite well. the analog-digital converter working in the akord system performs signal quantization on 1 levels  enabling the notation in the form of numerical data ranging from ♀-1  +1  . this fact has i t s reflection in the values of coefficients indicating the amplitude thresholds. i n i t i a l l y the following assumptions have been acceoted as in reddv pro : 
quency noise segments  .faereas the seg-
ments for which the number of zero-crossings exceeds c 1khz   and their maximum amplitude is max are accepted as  conditional noise .  conditional noise  may be accepted as a voiced segment or as high frequency noise. if there is a group of  conditional noise  segments in the close neighbourhood of the segment accepted as high frequency noise  the whole group is accepted as high frequency noise. otherwise the  conditional noise  segments are considered and included among the class of voiced segments. if we denote the segment s  accepted as s i lence - o  voiced segment - 1   conditional noise  - 1  and high frequency noise - 1  the signal represented by the following sequence of the approprite classes of 

during the next stage of the algorithm we make use of the results of the previous stage. only those segments which have been accepted as voiced are exposed to processing. it is necessary to search for indexes t for which the momentary values correspond with the significant amplitude of a given microphonemes. as well as pr  a l gorithm the following terms are introduced - local maximum and local minimum  absolute maximum  significant maximum and minimum and also significant extreme. some modifications concerning the semantic content of the above terms have been introduced and also the algorithm of their indication has changed. 
if we denote the vector representing the 
v/e shall denote them maxtx  mintx respectively* on the basis of local maxima the absolute maximum  the significant maxima and significant minima are indicated  v/e denote them max x  min x  a. the absolute maximum a is calculated for the succeeding segments of the length d1 = 1d c it makes about 1 ms  . here  it is necessary to point out that a division of a signal into segments of the length dt as dictated by the limitations posed by the zah-1 is different from the principles given in the algorithm ppd and aims at using as few memory cells as possible and achieving compatibility with the system akord  1   . accepting the segments of the length d i greatly inffluences the process of dynamic analysis of the microphoneme periods. it is also extremely significant in the process of correction  during the final stage of algorithm. the indication of the period of the larynx tone for such segments a l lows independence from f a i r l y essential changes of the length of the larynx tone owing to some changes in articulation  contrary to the indication of the expected period of the larynx tone estimated continually through the whole signal x. 

1 

presented by roddy  and thus the s i g n i f i cant extremes w i l l have different meanings than in the algorithm ppd. yet owing to this difference it is possible to eliminate errors of the type of amplitude f l u c t u ation caused by low frequency the algorithm of searching for the s i g n i ficant minimum is analogous to the search for the significant maximum  speech wave analysis has shown that because the envelope of the larynx tone is of a rather differentiated character  not a l l s i g n i f i cant maxima univocally assign the places of extremes of the microphoneraic envelope. it can be observed that whenever there exists a significant maximum that we accept as the extreme of the microphoneme envelope  there also exists a corresponding significant minimum within a small neighbourhood. this can be explained by the occurence of the greatest turbulence in the speech wave at the moment when the vocal tract is excited by the release of the pressure resulting from the vibration of the vocal cords  the moment in time when the microphoneme begins   therefore  as the  significant extremes  only those 

　　the process described above concerning the logical processing is iterated for the same segments according to need. the r e trieved markers indicate the significant places within the microphoneme and those regions make a basis for finding the ends of microphonemes. the author w i l l consider the zero-crossing point or the point where the signal assumes a value which is the closest to zero  the end or begining of the microphoneme. the end or begining of microphoneme is indicated in the region where the envelope of the signal assumes a minimum. such a choice for the place of the microphoneme end reflects the physical aspect connected with the excitement of the vocal cords and also it corresponds with the results of the spectral analysis. the spectral analysis concerning microphonemes showed great parameter s t a b i l i t y . the agreement of phase as well as the great relevance of microphoneme and phoneme char a c t e r i s t i c s   belonging to the same speaker and to the same class of speech sounds  proves the correct segmentation. in accordance with the phenomenon of vocal cords vibration we shall search for the place of the microphoneme end  or the begining  before the maximum of turbulence assigned by the significant extremes  /e .search for the ends of the microphoneme before the significant extremes or before the proceeding local maxima. we accept a p r i n c i ple that the end of the microphoneme is calculated d i r e c t l y before the local maximum which is the furthest on the l e f t and i t s value is not less than 1 of the 
1 

	in 	the 	o t h e r cases  	a process ox c o r -
r e c t i o n i s undertaken which may l e a d t o i n d i c a t i n g a new and b e t t e r end of the m i crophoneme. the a l g o r i t h m of c o r r e c t i o n aims at f i n d i n g a new end of the m i c r o p h o neme  s a t i s f y i n g c o n d i t i o n w1 . t h i s phase ends the stage of c o r r e c t i o n f o r a g i ven microphoneme or t h e stage of i n d i c a t i o n o f the microphoneme end  which i s t h e l e a s t d i s t a n t from t h e expected end  marked by esr . the ends of microphonemes are c a l c u l a t e d d u r i n g the stage o f c o r r e c t i o n a c c o r d i n g to the analogous p r i n c i p l e as b e f o r e but the v a l u e s o f succeeding l o c a l maxima need n o t exceed h a l f of the v a l u e of t h e r e s p e c t i v e e x t r e m e . because the process of c o r r e c t i o n may be r e p e a t e d   t h e r e i s a c o n d i t i o n i n d i c a t e d   c o n c e r n i n g 
the c h a r a c t e r of t h i s p r o c e s s . the process o r c o r r e c t i o n should b e   u n i l a t e r a l l y c o n v e r g e n t     by which we mean t h a t a new end of the microphoneme w i l l be c o n s i d e r e d c o r r e c t   and the stage o f c o r r e c t i o n i n w h i c h i t was c a l c u l a t e d w i l l b e c o n s i d e r e d e s s e n t i a l   i f i t i s p l a c e d c l o s e r t o the expected end t h a n the p r e v i o u s i n c o r r e c t one and a l s o   i f i t i s o n the same s i d e   i n r e l a t i o n t o the expected end  a s t h e end c o n s i d e r e d i n c o r r e c t . in the case of   o s c i l l a t i o n   o f the c o r r e c t i o n proccess towards the expected end  we accept the end of the microphoneme i n d i c a t e d d u r i n g 
the p r e v i o u s stage of c o r r e c t i o n as c o r r e c t . as a consequence of a p o s s i b l e c o r r e c t i o n we o b t a i n the markers of m i c r o p h o -
1 

1. s. zwicker  r.feldkeller : das ohr als 
nachrichtenempfanger 
stuttgart  1 
1. pierre vicens : aspects of speech recognition by computer 
 a dissertation  com. scien. dep. stanford university  1 
1. e.a. sapozkow : 1ygnal mowy w telekomunikacji i cybernetyce 
./arszawa  vnt  1 
1. r. tadeusiewicz : sioniczna koncepcja mowy 
papers of symposium: zietody bezposredniego wprowadzania informacji tekstowej i obrazowej w systemach i n f o r r.iatycznych  jablonna  1. 
j.l. flanagan : speech analysis  syn-
1. thesis and perception berlin  springer-verio   1. 
1. d.r. reddy : pitch period determination of speech sound communication of the acm  1  vol.1 g.modena  c. scagliola  e. vivalda : 
1. influence of phase handling on short time speech spectra 
the 1 international congres on acous t i c   london  july 1  vol. 1. p. 
1. contributed papers 
a.dziurnikowski : segmentacja pierwo-
1. tna sygnaiu mowy i ekstrakcja mikrofonemow 
papers of symposium : komputerowe systemy przetwarzania danych doswiadczalnych  kazimierz  1 
	a.dziurnikowski : 	system rozumienia 
1. rnowy susy 
papers of symposium : metody rozpoznawania  k l a s y f i k a c j i i wyszukiwania infornacji  jadwisin 1. 
