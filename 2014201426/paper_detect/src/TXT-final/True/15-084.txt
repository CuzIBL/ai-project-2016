 
　　　　this paper describes a theory of reasoning about uncertainly  based on a representation of state'i of certainly called endorsements  see cohen and grinberg  1  for a more detailed discussion of the theory.  the theory of endorsements is an alternative to numerical methods for reasoning about uncertainty  such as subjective bayesian methods  shortliffe and buchanan  1; duda  hart  and nilsson  1  and the shaferdempster theory  shafer  1 . the fundamental concern with numerical representations of certainty is that they hide the reasoning that produces them and thus limit one's reasoning about uncertainty. while numbers are easy to propagate over inferences  what the numbers mean is unclear. the theory of endorsements represents the factors that affect certainty and supports multiple strategies for dealing with uncertainty. 
introduction 
　　　　nothing is certain. people's certainty of the past is limited by the fidelity of the devices that record it  their knowledge of the present is always incomplete  and their knowledge of the future is but speculation. even though nothing is certain  people behave as if almost nothing is uncertain. they are adept at discounting uncerta.nty -making it go away. this paper discusses how al programs-specifically  rule based systems-might be made similarly adept. 
　　　　there are serious limitations to current al approaches to reasoning under uncertainty. many authors have discussed the mathematical  psychological  and practical problems associated with numerical approaches  ouinlan  1; shafer  1; shortliffe and buchanan  1; duda  hart  and nilsson  1; 
kahneman  slovic  and tversky  1   and their arguments are not repeated. this section proposes that numerical approaches to reasoning under uncertainty are restricted because the set of numbers is not a sufficiently rich representation to support the considerable heuristic knowledge about uncertainty and evidence. 
　　　　a common al method for reasoning under uncertainty is to augment domain inferences with parallel certainty inferences. systems such as emycin  van melle  1  associate certainty factors with the conclusions of inference rules. a rule of the form ''if a and b and c  then d  asserts d when a  b  and c are certain; additionally  a number is associated with d to indicate one's belief that d follows from a  b  and c. if a   b  and c  though certain  suggest but do not confirm d  then the number associated with d will be less than the 1 that usually represents certainty in such systems. if a  b  or c are themselves uncertain  then the number associated with d is modified to account for the uncertainty of its premises. these numbers are given different names by different authors; we refer to them as degrees of belief  shafer  1 . the functions that propagate degrees of belief over inferences are called combining functions. domain rules are assigned a priori degrees of belief and the purpose of the combining functions is to faithfully represent the intent of each in the context in which it is eventually used. some systems propagate not one degree of belief  but two  indicating a range of certainty. in all cases  one's certainty in a hypothesis is represented only by a numerical degree of belief. 
　　　　all al systems that reason this way adhere to the scheme with little or no variation. all evidence is processed in exactly the same way: it propagates through a combining function to the conclusion it supports. current systems are unable to treat different kinds of evidence differently. they do not take some evidence  with a grain of salt  and other evidence with judicial solemnity  and the reason is obvious: since evidence is nothing more than a proposition with an associated number  there is no way to tell whether it warrants scrutiny other than by examining the number. this permits only a limited ability to discriminate kinds of evidence. if there are several kinds of evidence  then the numerical representation is inadequate; for example  one cannot expect to discriminate eyewitness evidence from circumstantial  hearsay  or photographic evidence on the basis of their numerical degrees of belief. 
　　　　numerical degrees of belief are adequate if one intends only to propagate them over inferences without reflection. but if one desires to treat different kinds of evidence differently  and if the weight of evidence can change in different contexts  then it is necessary to reason about one's evidence. two problems must be solved to achieve this. the first is to represent explicitly many aspects of evidence besides  how much  it is believed. the other problem is to develop additional methods for reasoning with this richer information. the remainder of this paper outlines four components of a model of heuristic reasoning about uncertainty. 
a 	theory 	of 	heuristic 	reasoning 	about uncertainty. 
　　　　the theory of endorsements has four components. endorsements are records of reasons for believing or disbelieving a hypothesis. in addition  the theory proposes heuristics for ranking endorsements  heuristics for propagating endorsements over inferences  and heuristics for discounting uncertainty. 
　　　　
1 p. cohen and m. grlnberg 
endorsement 
　　　　the explicit marking of factors relating to one's certainty is called an endorsement. the process is best introduced by an analogy. a piece of work in a bureaucracy proceeds from one stage to the next contingent on the endorsement of a bureaucrat. the job must satisfy certain  typically formal  requirements before it is endorsed at any given level. imagine  in place of bureaucrats watching over a job  a collection of rules watching over the development of a line of reasoning. each endorses a step in the argument if it satisfies certain requirements. whenever a domain rule is used  its conclusion accrues one or more endorsements. thus  endorsements are just records that a particular kind of inference has taken place  and endorsers are just the computations that assert the records. bureaucrats can require a job to be cleared by lesser bureaucrats before they even consider it; for example  a city council won't consider a proposal unless it is cleared by the planning department. similarly  an endorser may require the conditions of a rule to have a certain level of endorsement before it will endorse the conclusion of the rule. most conclusions accrue several  more or less stringent endorsements. the certainty of a hypothesis can be represented by its pedigree-it s endorsements and those of its logical predecessors. in terms of the bureaucracy analogy  one's confidence in a job is proportional to the degree of scrutiny and level through which it has passed.1 
ranking endorsements 
　　　　implicit in this is the idea that endorsements can be ranked  and that a system needs heuristics to do the ranking. preference of the endorsement of one hypothesis over the endorsement of another is equivalent to having more confidence in the one hypothesis over the other. for example  in most contexts  eyewitness testimony is preferable to circumstantial evidence  corroboration to contradiction  and inference to assumption. what is meant by one kind of evidence being preferable to another is that a conclusion endorsed as having the one kind of evidence for its support is more certain than a conclusion endorsed as supported by less preferred evidence. much knowledge is needed to rank endorsements. for example  it is difficult to know whether the eyewitness account of a drunk is more certain than a dozen  respectable  but circumstantial anecdotes  but the ability even to pose the question  if not answer it  is evidence for the role of world knowledge in weighing evidence. if the drunkard's testimony is not comparable to that of the character witnesses  i.e.  if neither is preferred to the other  then there would be no rules in the system to rank these kinds of evidence. this is in contrast to numerical approaches to reasoning about uncertainty  which give the erroneous impression that all evidence is comparable. 
　　endorsement is similar to recording justifications in 1 truth maintenance system  doylo  1   but with a crucial difference. in doyle's system  a justification is used to decide whether a conclusion has support  but the kind of support is irrelevant. there are  however  many different kinds of endorsements  corresponding to different kinds of evidence for and against a proposition. 
propagating endorsements over inferences 
　　　　just as degrees of belief are propagated over inferences by combining functions  so must endorsements be propagated over inferences by heuristics. given that one proposition implies another  and the premise has a set of endorsements  what endorsements should the conclusion accrue  a set of rules is needed to propagate endorsements over inferences. these serve the same purpose as combining functions  to make a rule sensitive to the context in which it is used  but the context is now a set of endorsements instead of a single degree of belief. a default rule is that the endorsements of the premise should all propagate to the conclusion. in fact  interactions between endorsements may complicate this picture. for example  if a parameter is derived by taking a central value of several others  e.g.  an arithmel.c mean  and if one of the component values is thought to be an extreme value  the endorsement extreme usually would not apply to the central value. each domain of expertise is expected to have numerous idiosyncratic rules for propagating endorsements over inferences. 
discounting uncertainty 
　　　　endorsements can also be used to resolve uncertain values and discount uncertainty  although this  too  requires masses of general and special knowledge. a general method for resolving uncertain values is to choose a central or representative value in their stead. this is related to the hedging strategy discussed earlier. alternatively  a highly endorsed hypothesis may be chosen over less well endorsed conflicting hypotheses; for example  the  credentials  of disputants can help decide between their claims-until recently  the word of a congressman outweighed that of a convicted swindler. other methods are specific to the kinds of uncertainty they resolve. for example  if ycu can't resolve whether to withdraw $1 or $1 for an evening's entertainment  it's best to get $1. 
　　　　discounting uncertainty is not equivalent to certainty: one may be certain enough for one purpose but not for another. for example  one might be certain enough of one's prospective 
income to decide to buy a car  but not certain enough to decide to buy a house. the idea of complete certainty is an artifact of numerical representations of degree of belief. it is more productive to think in terms of certainty with respect to a task; in fact  it makes little sense to speak of certainty except with respect to a task. 
　　　　
conclusion 
　　　　we expect that each domain of expertise has a characteristic set of endorsements and a set of methods that define what they mean. these methods include ranking rules  rules for propagating endorsements over inferences  and rules for discounting uncertainty. the methods interact in characteristic ways. uncertainty about alternative conclusions can be discounted either by choosing the one with the highest endorsement  or by replacing the uncertain conclusions by another  more certain one. this is not equivalent to saying that the chosen conclusion is certain  only that in the circumstances it is not uncertain enough to warrant other action. but in another context  such a resolution may not be certain enough  and the system will need to backtrack to its original uncertainty and reconsider it. finally  a system that cannot resolve between uncertain conclusions may propagate both. this makes sense only if information will become available later to resolve the uncertainty. otherwise  it is most expedient to hedge. 
summary 
　　　　a heuristic approach to reasoning about uncertainty and a representation that supports it has been presented. the theory includes records of information that affect one's certainty  called endorsements; and rules for propagating endorsements over inferences  for ranking endorsements  and for discounting uncertainty. the rules interact in a classic planning pattern: balancing commitment to resolutions of uncertainty  and the penalty of backtracking  against least-commitment propagation of multiple uncertain hypotheses. for a detailed description of the theory see cohen and grinberg  1 . 
	p. cohen and m. grinberg 	1 
