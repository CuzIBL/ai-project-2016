 
     this paper presents an overview of a game p l a y i n g model which is based on human perceptual and problem solving a b i l i t i e s . the representation of games  acq u i s i t i o n of r u l e s   learning of s t r a t e g i e s   and select i o n of moves are o u t l i n e d . details of move s e l e c t i o n   including scanning of the board  use of f a m i l i a r patterns to suggest move candidates  evaluation of moves  and lookahead are described. f i n a l l y   there is a d i s cussion of the means by which the model learns to play a b e t t e r game. 
i n t r o d u c t i o n 
     people can be taught a board game by means of natural language i n s t r u c t i o n   which may or may not be accompanied by a demonstration. moves made by beginners are almost always l e g a l   often bad  and probably never random. people can improve the q u a l i t y of t h e i r play with experience  and can also be taught  by a book or a t u t o r   p a r t i c u l a r moves  patterns of pieces  or s t r a tegic concepts. a model of human game p l a y i n g should e x h i b i t a l l of these c h a r a c t e r i s t i c s . one possible model is developed in t h i s paper. the major assumptions of the model are being tested through experiments w i t h human game players. in t h i s paper  we c i t e our experimental studies in the footnotes. 
     our model is embedded in the framework of a larger model of human information processing which has been described in rumelhart  lindsay & norman1 and rumelhart & norman1. the database s t r u c t u r e is that of a semantic network consisting of nodes connected by bid i r e c t i o n a l   labelled r e l a t i o n s . a parser translates english i n t o the database. a programming language  sol  wnich is a subset of english  allows the user to i n t e r a c t w i t h the database. there is no inherent d i s t i n c t i o n made between data and procedures. although t h i s paper i l l u s t r a t e s many of the mechanisms necessary f o r the implementation of the game p l a y i n g model  the complete implementation has not yet been accomplished. 
acquiring the rules of a new game 
     in learning to play a game there are two d i s t i n c t stages: d e f i n i n g the task  learning the rules of the game   and searching for a s o l u t i o n  playing the game to w i n   . in order to s t a r t p l a y i n g a game  knowledge of three things is necessary: the goal of the game; the universe w i t h i n which the game takes place; and the rules governing actions w i t h i n that universe. two quest i o n s arise w i t h i n t h i s context:  a  what does it take to understand the rules of a game   b  how are these rules represented once they are acquired  
understanding the rules of a game 
     it is always possible to state the rules of a game in english. most people can understand such rules and can s t a r t playing a legal game once they have heard them. c l e a r l y   these rules would be meaningless if the 
words comprising them were not understood. the study of how t h i s understanding is acquired c o n s t i t u t e s a maj o r i n v e s t i g a t i o n in i t s own r i g h t that w i l l not be performed here. for our model  we assume that t h i s level of understanding has already been achieved. this 
assumption has two important i m p l i c a t i o n s ; f i r s t   a l l the concepts considered to be important f o r understanding the rules of games are incorporated i n t o the model   i . e .   entered by hand  in advance. second  the model only applies to the behavior of adults who can be assumed to possess t h i s knowledge. 
the i n t e r n a l representation of a game 
     although there is a large v a r i e t y of board games  a l l games have much in common. the existence of a general s t r u c t u r e which represents the common features is i m p l i c i t l y assumed whenever the rules of a game are described. building an i n i t i a l i n t e r n a l representation of a game consists of f i l l i n g in s p e c i f i c arguments in the v a r i a b l e s l o t s of that general frame. those v a r i a bles can be anything from single values to complex s t r u c t u r e s . appendix a gives our representation of the frame f o r games. 
generating p r i m i t i v e strategies 
     mere knowledge of the rules of the game would r e s u l t in the generation of random  though legal  moves. but even beginners of a game do not play randomly.1 
the nonrandom nature of p l a y i n g is inherent in game p l a y i n g   since games are by d e f i n i t i o n a goal directed a c t i v i t y . as the game s t a r t s   the player must already 
have a set of p r i m i t i v e s t r a t e g i e s for playing that p a r t i c u l a r game. 
     for example   capture more pieces  is a p r i m i t i v e strategy f o r checkers  while  get more in a row  is a 
p r i m i t i v e strategy for gomoku.1 these p r i m i t i v e s t r a tegies have in common the notion of making progress on some dimension such as  capture  or  number of pieces in a row.  the dimensions f o r which p r i m i t i v e s t r a t e gies are generated are those e x p l i c i t l y mentioned in the rules of the game. a meta-strategy is needed to determine how  progress  is to be characterized f o r each dimension. one way to do t h i s is to apply meansends analysis in order to see whether a goal state f o r a p a r t i c u l a r dimension may be attained by successive app l i c a t i o n s of a single operation. if so  that operat i o n is singled out as a p r i m i t i v e strategy. the sym-
metric nature of most games allows the creation of complementary p r i m i t i v e strategies f o r impeding the opponent's progress on a given dimension. 
move selection 
     here is a quick overview of the flow of processing performed by our model following the opponent's move. first  it tries to find a reason for the opponent's move: the representation of the current situation is updated in light of that reason. the model may then either respond to the opponent's move  continue with the execution of a previously created plan  or generate a new plan. 
     the evaluation of newly created patterns identified by a scan of the board singles out the reason for the opponent's move. plans are sequences of moves leading to a situation which is more favorable than the current one. the moves within the plan sequences are originally suggested either by familiar patterns or by strate-
gies. the suggested moves undergo evaluation during a lookahead process whose depth is limited by the constraints of a working memory. 
　　of necessity  a l l of these processes interact heavily. 	it w i l l be convenient  however  to discuss individually the following segments of the model: scanning the board  familiar patterns  move evaluation  
lookahead  and finding a reason for the opponent's move. 
scanning the board 
     the game board serves as an external memory for human players. this external memory is simulated by a 
     1-dimensional array which remains conceptually distinct from the model. the problem of scanning the board may 
be thought of as a problem of parsing a 1-dimensional string. top-down parsing algorathms which have been used as a mechanism for the analysis of line drawings1  
1   1    capture the predictive power and analysis-by-
synthesis nature of human visual processing. bottomup parsers  e.g.  ledley   capture the essence of organization of visual scenes for which there are no ex-
pectations. they may also miss important configurations  which is a disadvantage for an optimal game 
playing machine  but a necessity for a realistic model of human game playing. 
　　the scanning routine used by our model begins with a bottom-up parse of the board  but becomes a top-down parse as soon as enough information is gathered to generate some expectations. the scan iterates through all board locations whose contents have changed as a result of the last move  treating each such location as the origin of a bottom-up parse. when scanning from a given origin the model peripherally notices all the im-
mediate neighbors of that origin  i.e.  a l l pieces within the 1 area containing the origin and its neighbors. it identifies those combinations which either constitute complete patterns or are possible members of some larger patterns. 
     if a larger pattern is marked as potentially present  the scan then switches to its top-down phase and actively tries to find that larger pattern. the identification of patterns is made by network matching routines which compare the current view with a network containing descriptions of familiar patterns. 
　　the top-down parse starts with an attempt to identify familiar patterns derived from gestalt principles of human perception. the three gestalt principles included in the model are those of proximity  similarity  and continuity.1 proximity is incorporated by having the scan move outwards from the origin in expanding concentric circles. the principle of similarity is embodied 
by marking  piece next to a similar piece  as a familiar pattern for a l l games. the principle of continuity is incorporated by regarding lines of pieces as inherently familiar patterns. consequently  a potential line of 
pieces seen in the i n i t i a l 1 area w i l l result in the initiation of a top-down search for that line. 
     note that although patterns are  familiar   they are not necessarily meaningful within the context of a particular game. thus  a row of four bishops side by side on a chess board w i l l be called  familiar  by the gestalt principles  although the intrinsic importance of such a configuration is not at all clear. once simple gestalt groupings are recognized  the top-down scan continues looking for other potential patterns   i f other potential ones are indicated . the remaining ones are those which are important within the context of the specific game currently being played.1 
familiar patterns 
the ability to recognize familiar configurations 
of pieces on the board is crucial for the playing of any game. a person who recognizes a familiar pattern can refer to its representation in his long-term memory by using a single label  thus freeing valuable space. additional savings are obtained if the pattern is associated with a well known sequence of suggested moves  since these suggestions need not be generated in the 
normal lookahead manner. a large repertoire of familiar patterns is one of the characteristics of s k i l l f u l players. 1 
   patterns are represented in the model by means of active semantic networks of the type described in rumelhart g norman.1 such networks may be treated either as data to be consulted during the recognition of patterns   i . e .   as a table of rewrite rules during a visual parse  or as procedures which themselves direct the recognition process. in fact  the current scanning algorithm invokes the procedural definitions during its top-down phase  and treats the same definitions as data during its bottom-up phase. 
   this format of representation appears to be both powerful and general. if we represent specific locations and pieces  the representation becomes equivalent to that of simon and gilmartin's mapp program.1 nonspecific locations and orientations allow us to have internal representations which are homomorphic to the real world configurations. this was the type of representation used by murray and elcock for gomoku.1 recursive definitions of groups of stones in go  found useful by ryder -* are also easy to handle in this format. a sequence of suggested moves for a familiar pattern is represented as a procedure which  when executed  returns with advice relevant within the context of a particular game. for example  if the pattern  four in a row  is discovered in the game of gomoku  a procedure is activated which looks for a vacant square next to and in a line with the pattern  and recommends moving to that square. note how this contrasts with the  meaningless  chess pattern of four bishops in a row described earlier. 
evaluation 
   the evaluation of moves is based on the dimensions stored under a  strategy  node. for example  on the dimension of  length   a string of five in a row has a 
   greater value than a string of four in a row. if we are comparing two moves along the dimension of  capture value   we might compare the number of pieces captured  e.g.  in checkers   or the numerical value which some book or tutor has told us to assign to the captured pieces  e.g.  in chess . relevant dimensions are stored explicitly under the strategy node  but are different for different games. 
   actual numerical values are not computed in the current model  and at present there is no ordering of the sequence in which different dimensions are encountered  but we allow an ordering of the nodes within a given dimension. 
   when a pattern has been found by the scan  candidate moves w i l l be suggested if there are explicit recommendations associated with the pattern. if such recommendations are not found  the strategy node provides suggestions by pointing out a dimension and a way of increasing values on that dimension {e.g.  adding a 
piece next to its neighbors to increase length . 
   a pairwise comparison of successively generated candidates is made along relevant dimensions  as suggested by strategies  in order to choose the best move. if  during the course of these comparisons  a candidate is found which has a value above  satisficing  1 on any dimension  the evaluation terminates and that-candidate becomes the model's choice for the next move. 
1    when trying to find the best of two candidate moves  it is possible that they w i l l have the same values on the dimension on which they are compared  or that these values can only be determined if they lead to a familiar configuration of pieces within several moves. if this is the case  we call a lookahead procedure which looks for recommended moves for the opponent and com-
pares the outcomes of these recommended moves  which i t s e l f may require another call to the lookahead procedure  . since there are normally several alternative moves  the only recommended moves which are considered for evaluation  and possible further lookahead  are 
those which have the highest probability of being realized. if we could objectively decide on a move for the opponent using an unbiased evaluation scheme  then our move selection technique would be formally equivalent to minimaxing. people typically do not perform 
this type of analysis  since they are subject to a bias when trying to carry out a plan; they may assume that pieces only have a particular role  e.g.  offensive or defensive  or only move with a specific intent  e.g.   he is trying to capture my bishop  . 	in the model  bias operates by instructing the scanning routine to look only for pieces which 	f u l f i l l 	certain roles. 	in this way  we s t i l l choose  best  moves for the opponent  but bias yields what we call  subjective minimaxing.  
lookahead 
     the model's actual lookahead may be regarded as a product of many interacting processes. these processes  which we w i l l discuss in detail below  include: an active working memory which effectively limits the depth of lookahead; heuristics for narrowing the selection of move candidates; a mechanism for making hypothetical moves; a limited backup capability which restricts the model to a  progressive deepening  search. the actual lookahead typically proceeds by means of a forward search  but capability for means-ends analysis is also provided. plans are treated as an outcome of the lookahead process. 
     working memory. all active processing takes place within the confines of a limited size working memory. the size restriction is regarded as an asset to the model  as it necessitates garbage-collection and chunking of information. the contents of working memory is a homogeneous mixture of data  procedures  and pointers to items in long-term memory. achieving a given performance level  e.g.  remembering 1＼1 random digits 1   depends upon a model's specific implementation. we are currently considering different size limitations  and the final choice is likely to be in the order of hundreds of nodes. this conceptualization is an adaptation of the one proposed by newell and simon.1 
     heuristic candidate selection. the selection of only a few move candidates for further lookahead is an automatic result of the way in which these candidates are suggested. the scan of the board concentrates on those areas which have changed as the result of a move. some candidate moves are suggested by familiar patterns which result from this localized scan. other candidate moves are suggested by advice from different dimensions known to the strategy node  e.g.   increase length  . finally  if good move candidates which were previously considered are s t i l l in working memory  a re-analysis of these candidates may be performed. the number of candidates is often small in highly constrained situations  such as dynamic piece exchange. since working 
memory size is constant  a small number of candidates enhances the depth of lookahead. 
     hypothetical moves. since the array representing the board is regarded as an external memory  imaginary moves do not affect this array. a hypothetical move is made by asserting a proposition which includes  among other things  a  beginning-state   an  end-state   and the move which causes the transition between the two states. the end-state for a given move is the result of augmenting the beginning-state for that move with the changes caused by that move- the beginning-state for a move is simply the end-state of the preceding 
move  if such a preceding move existed. the beginningstate for the f i r s t imaginary move is empty  since no changes have yet been imagined. during lookahead  the board scanning routine scans the real world array as described earlier  but it also consults the latest asserted end-state in order to correctly locate imaginary pieces. if many changes are imagined  there is the danger that old ones w i l l be lost as working memory f i l l s 
up  in which case board scanning errors w i l l occur. 
     progressive deepening. the search path followed by humans during lookahead is best characterized by the 
term  progressive deepening. 1 	this term refers to the tendency of people to revisit a given lookahead path in order to explore a single new side path or to extend the depth of the original path. 	the search path of a subject solving a chess problem thus looks like a succession of many straight paths  with only a few cases of true backup to positions one or two moves back in the 
path. 1 	if the model has to back up  it may do so 
either by going back to the real board and beginning another lookahead  or by undoing the latest hypothetical move  only the most recently asserted proposition is accessible  and the sequence of moves cannot be deduced from the end-states . 
     old propositions are recognized by a pattern matching primitive if they are s t i l l within working memory when re-asserted by the model. a simple  termination  flag on old propositions allows the model to investigate other move candidates and thus avoid following the exact same path each time. propositions become flagged as soon as their end-state imaginary board positions evaluate to some criterion level. upon re-initiating lookahead  the model re-explores part of the most recent 
path  branching off when it tries to re-assert a proposition which has been flagged as terminal. 
     plans. beginning with the current real board position  each asserted proposition is connected by a  forward  link to the asserted proposition which follows i t . one-move backup results in multiple links extending forward from the target of the backup  but a return to the starting position causes a brand new sequence to become linked. thus  if the sequence of imaginary moves a b c d is followed bv a return to the original position and then by the sequence a b c e  the two structures symbolized by 
athenb1thwizcthen 1 
a n d	  t h e n	t h e n	t h e n
	 	a	-*e'	 c'	 e 
w i l l be constructed. a' and a w i l l be complex structures representing two instances of the verb  move  with identical arguments. the other letters have a similar connotation. these linked sequences are the model's representation of plans. the restriction to forward links may be regarded as a result of the way events are perceived in the real world  e.g.  it is virtually impossible to whistle a tune backwards . 
     means-ends analysis. the lookahead mechanisms described above were presented mainly in the context of a forward-search analysis of a board position. not all move selections are arrived at in this way. one or more of the dimensions under the strategy node may suggest a goal state rather than an actual move  e.g.   try to capture a piece  . since the definition of moves such as  capture  includes the notion of a transition from a peginning-state to an end-state  the model regards the beginning-state in such definitions as a 
1 precondition which must be attained before the recommendation may be carried out. for example  in the game of chess the prior state for  x captures y  is  x bears on y.  if the prior state exists on the board  then the specific recommendation leads to the assertion of a new move candidate. if the state does not exist  then that state is treated as a new subgoal  and its preconditions are searched for in a similar manner. 
the actual search is constrained in the same way as forward search  and therefore we refer to it as  regressive deepening  search. 
     since the concept of  forward  linking refers to the order in which the imaginary propositions are asserted  an actual sequence of moves leading to a goal state arrived at through means-ends analysis w i l l be stored in reverse order   i . e .   starting move last . the correct sequence may be rederived at each stage. this rederivation may occur a move at a time during the course of the game  or may occur in lookahead by initiating a forward search from the i n i t i a l move after it has been discovered by means-ends analysis. in practice we expect the model to be able to begin a 
forward search  and then initiate a means-ends analysis from some hypothetical position which is embedded within the forward s.earch. 
finding a reason for the opponent's move 
     the opponent's latest move is examined to see whether it is part of a current plan sequence. if so  then it is classified as an  expected  move. we then assign to that move a  reason  taken from the reason for which the model generated this expected move during its earliet planning sequence. this reason may 
not be why the opponent actually made that move. this egocentric oversight may cause the model to miss some important configurations  but we believe that humans suffer from exactly this failing. 
     if the opponent's move is unexpected  the model checks to see whether the change between the previous board and the current board has been favorable for the opponent. if either a material change or a pattern identified by this check has a value which surpasses the satisficing criterion  then the model assumes it has found the proper reason for the opponent's move. as before  this may be wrong if there were multiple outcomes of the move. if no satisfactory reason has yet been found  the model tries to see what the opponent can do on his following move  by looking at the current board and pretending to be its own opponent. 
the most favorable outcome for the opponent after a  lookahead  evaluation is regarded as being the reason for the questionable move. 
     note that while a l l of these processes lead to a seemingly shortsighted and subjective determination of the reason  the model may become more sophisticated by not stopping these procedures upon the discovery of some single high-valued reason  but rather doing all of them  thus finding multiple reasons. 
learning to play a better game 
     playing a game may be viewed as an attempt to modify a current state into some goal state by means of 
some operator  or a plan . improving one's s k i l l in playing a game involves the emergence of the ability to identify states for which operators exist  and to find operators which are applicable to already known states. states and operations which transform states can be acquired by means of both experience and instructions 
from an external source  books  a tutor  etc. . 
the lookback mechanism 
     the main mechanism for learning through experience proposed here is that of  lookback.  whenever the model encounters a situation which looks definitely better  or worse  than the situation existing before  it reconstructs the former situation and tries to identify what operations were performed which transformed it into the present state. the model may notice a change in states but be unable to reproduce the way in which the change has occurred  especially when it has taken many moves to produce a change. as with lookahead  the deptn of lookback is limited by working memory and aided by the ability to encode whole segments of moves into one 
meaningful chunk. 
     since winning and losing constitute definite changes in states  at these points the model looks back and tries to identify what has made the situation just preceding the completion of the game so powerful. this situation now becomes a subgoal state. the model also attempts to characterize the last move along the dimensions employed during move evaluation. this characterization serves as a plan for transforming the newly found subgoal into a win. moves that would prevent the win from occurring can also be considered. winning  or losing  is not the only case where a definite change in states occurs  but it is the most striking one. whenever the model notices that an already known state has been achieved  the same evaluation process may take place. the result of a successful lookback is the creation of a new node representing the newly identified subgoal. in addition to a description of the subgoal  this node includes a pointer to the goal  and to the sequence of moves leading from the subgoal to the goal. whenever an existing operation is about to be executed  the player has definite expectations about the outcome. if that outcome fails to materialize  then the operation can be te-evaluated and modified  or even discarded. 
     lookback can occur whenever one encounters a familiar pattern. this is true regardless of whether that familiar pattern is actually there on the board   i . e .   consists of real pieces   or whether it partially or wholly consists of imaginary pieces   i . e .   pieces  added  to the board by the lookahead process . the working memory constraints acting upon lookahead will make 
the detection of an imaginary familiar pattern somewhat less likely than the detection of a real familiar pattern  but once such a pattern is detected the learning process may proceed in the regular way. 
the identification of patterns and operations 
     so far the discussion has implicitly assumed that plavers engaged in lookback know what they are looking for  and that the identification of new patterns and plans occurs after the f i r s t occurrence of an opportunity to learn which the player is aware of. that assumption is far from being true. progress in game playing s k i l l is very slow and often frustrating. working memory constraints arc one reason for the slow progress. often players just cannot recall the i n i t i a l state or the sequence of moves which led to the final state. 
　　an even more important obstacle to fast progress  and one which may also greatly increase working memory load  is the player's inability to distinguish between 
relevant and irrelevant information which exists on the board. the i n i t i a l state  which eventually becomes a familiar pattern and a possible final state  is not on the board by itself. the board often contains many irrelevant pieces. even the relevant pieces may have properties which are irrelevant for the identification of a particular subgoal. 
　　this situation is analogous to the one existing in psychological experiments on concept learning  and our model goes about learning patterns in a way similar to that in which human subjects learn concepts. studies of concept learning1 indicate that people usually generate a hypothesis about the concept they have to learn on the basis of available instances. they regard this hypothesis as the correct concept until they encounter a disconfirmation of the hypothesis  in which case they try another one. 
1 　　whenever a subgoal is achieved  the lookback mechanism reconstructs the preceding situation  the   i n i t i a l state   unless the subgoal has been the result of the application of a plan  in which case no lookback and re-evaluation w i l l occur . those features which have 
changed serve as a clue as to which features may be relevant to the d e s c r i p t i o n of the i n i t i a l s t a t e . this description is the model's current concept f o r the state preceding that subgoal. when the same subgoal occurs again a new d e s c r i p t i o n of i t s i n i t i a l state is generated. a generalization routine compares t h i s new d e s c r i p t i o n w i t h the current concept f o r the i n i t i a l state which precedes t h i s subgoal. the common features found by t h i s comparison form a new generalized concept f o r that i n i t i a l s t a t e . a s i m i l a r process is applied to the sequences of moves which have led to the f i n a l goal. the states and plans i d e n t i f i e d at the early stages of the game are greatly modified over short 
periods of time  but they r a p i d l y s t a b i l i z e . 
tutoring 
     the preceding section has described the way in which the model learns to play a b e t t e r game on the basis of experience only. people can become b e t t e r players by using external sources of knowledge. zob r i s t and carlson 1 emphasize the importance of advicetaking f o r a model of game p l a y i n g . our model has t h i s c a p a b i l i t y and can be given advice in a f a i r l y natural way. for example  the pattern ''openfour '1 which is c r u c i a l in gomoku  can be taught to the model by entering the statement: 
 openfour  looks like a sequence of a blank square  a row of four pieces  and a blank square. 
 looks like  is a predicate which adds a p o i n t e r from the name of the p a t t e r n to i t s d e f i n i t i o n .  sequence  builds a structure with its members ordered along one a x i s   and is also a procedure f o r i d e n t i f y i n g the existence of a s i m i l a r s t r u c t u r e on the board.  row  is s i m i l a r to  sequence   except that it allows permutations of i t s members along a given a x i s . 
     the  meaning  of openfour f o r the game of gomoku may be added by saying: 
 openfour  suggests for gomoku that you 
place a piece on any unoccupied member 
of the  openfour.  
     we are c u r r e n t l y implementing procedures f o r giving advice i n v o l v i n g f u n c t i o n a l d e f i n i t i o n s and lookahead. for example  we would l i k e to be able to define a pin in chess as follows: 
x pins y to z 
iswhen: 	x sears on y. 
if y moves  x  which does not bear on z  will bear on z  
the value of x capturing z for x's owner 
is greater than the value of any move 
of y for y's owner. 
the operator  value  takes i n t o account the value of an exchange plus the value of patterns r e s u l t i n g from a given move   i t may have to c a l l lookahead to do t h i s   . 
notes and 