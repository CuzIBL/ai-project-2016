 
     this paper describes a practical solution to online dictionary update in xtra  a machine translation system developed by xiuming huang at the computing research laboratory of new mexico 
state university. the focus of the discussion in on ives - an interactive vocabulary enrichment system built by this writer for xtra  it reflects an ongoing effort at the laboratory to build embedded learning mechanisms in machine translation systems. two types of learning are discussed  word learning and word sense learning. each type of learning undergoes three routine processes: detection  acquisition  and evaluation. the emphasis of this paper is on the use of semantic preference violations in the detection of the need to learn new word senses. 
	i 	introduction 
     machine translation systems  built using an ai approach  could be equipped with embedded learning mechanisms so that the systems would constantly update themselves and modify their behavior. building such embedded systems should speed up the early realization of machine translation on microcomputers. this is because  except for the closed system of function words  an mt procram cannot be expected to have a 'complete' vocabulary at the time of installation. and it is almost impossible for the customer to purchase such systems that are adequate to start with. learning mechanisms could be a remedy in this regard. it is usually easier to find a bilingual person than a software engineer to upgrade a system. 
the focus of the discussion is on ives - an 
interactive vocabulary enrichment system built by this writer for xtra. two types of learning are discussed  word learning and word sense learning. each type of learning undergoes three routine processes: detection  acquisition  and evaluation. the emphasis of this paper is on the use of semantic preference violations in the detection of the need to learn new word senses. 
ii word learning 
     according to a model of machine learning advocated by cohen and feigenbaum  1   machine learning has four important elements:  a  the environment   b  the learning element   c  the knowledge base  and  d  the performance element. the environment supplies information to the learning element; the learning element uses this information to make improvements in the knowledge base; the performance element uses the acquired informauon to carry out its task; finally  feedback information gained during attempts to perform the task goes back to the learning element. in the context of word and word sense leaming in xtra  the environment is the system's interaction with the user; the learning element is ives; the knowledge base is the system dictionaries; and the performance element is the english sentence parser. depending on the kind of information supplied by the environment to the learning element  there exist five different learning strategies. these are rote learning  learning by instruction  learning by deduction  learning by analogy  and learning by induction.  michalski  carbonell  and mitchell  1  p. 1 . 
     word learning in xtra belongs to rote learning. in rote learning the information supplied by the environment is directly accepted by the learning system. the strategy is elementary  not powerful enough to accomplish intelligent learning on its own  but it is an 'inherent and important part of any learning system'  cohen and feigenbaum  1  p. 1 . 
     the detection of the need to learn new words in xtra is facilitated by xtra's preprocessing routine. whenever a certain word in the input sentence is found to be missing from xtra's dictionaries  the preprocessing routine issues a warning and prints out the missing word. whenever a word is detected as missing  ives is called  and an interactive session with the system user begins. 
     during the acquisition phase  information is elicited from the user to expand xtra's dictionaries. ives  as it stands now  handles four major categories of open system words  i.e.  nouns  verbs  adjectives  and adverbs. all input into the system dictionaries is checked for its validity. invalid entries are automatically rejected  and a second request for the same piece of information follows the rejection. although the default value of the target language is chinese  ives could handle any target language. 
     when the acquisition phase is over  parsing continues from where it left off. often  it succeeds as a result of dictionary expansion. however  it may also fail for reasons that will be discussed in the next section. 
ill word sense learning 
     word sense learning can be categorized as a special type of learning by instruction. it undergoes the same three processes as word learning does  i.e.  detection  acquisition  and evaluation. the difference between word learning and word sense learning is that the detection process for the latter is much more complicated than that for the former. also  in the course of the detection process  
	quo 	1 
     
responses from the user are not learned by rote and used by the system. instead  they are taken as pragmatic instructions and carried out accordingly. word sense learning uses the same learning module as word learning to acquire new word senses. the acquired word senses are always evaluated by xtra. 
     the need to learn new word senses in xtra is detected when a semantic preference violation occurs. in semantic primitive based systems  semantic primitives and semantic preference rules embody world knowledge  and they play an extensive role in word sense disambiguations  wilks  1; huang  1 . in fact  the same mechanism can be employed in detecting the need to learn new word senses. suppose xtra has the word 'bridge' in the svstem which means 'a physical structure built on the river'  and it also knows the word 'play' as in 'play basketball'. when processing the input sentence 'john plays bridge'  the system would fail as a result of semantic preference violations. in this case  the semantic specification of the expected object of the predicate verb  play  is 'game' whereas the semantic specification of the actual object head noun  bridge  is 'grain'  which means 'any kind of structure'. what nap pens is that 'grain' is not anywhere close to the semantic specifications of the expected object head noun of 'play'  hence a semantic preference violation. this particular type of semantic preference violation indicates the lack of a required word sense  and therefore the need to learn. 
     unfortunately  not all violations of semantic preference rules signal the need to learn. only some of the preference violations are learning signals. the non-learning signals are symptoms of some linguistic complications  such as ill-formedness. in word and word sense learning  ill-formedness often involves misspelling and the figurative use of language. it is not surprising that part of the game of word and word sense learning is the recognition and handling of metaphors and misspellings. ives will not request new vocabulary information until the last recorded semantic preference violation is found unaccounted for: i.e.  when no metaphors or misspellings are identified in any pair of recorded worcf senses involved in semantic preference violations. 
a. recognition and handling of metaphors 
     many solutions have been suggested to handle ill-formeaness incurred by metaphors. four strategies were proposed by fass and wilks  1  for semantic primitive based systems. they are the passive relaxation strategy  the change the data  ctd  strategy  the change the expectations  cte  strategy  and the active strategy that involves the use of pseudo-texts  wilks  1 . the strategy adopted by xtra is to relax the preference of the predicate and accept the semantic representation with the conflict unresolved. relaxation is a useful heuristic to handle metaphors  but not without flaws. to illustrate the unpredictable nature of the relaxation strategy  look at the following sentence: 
the chopper drank gasoline. 
     'chopper' can either be a 'helicopter' or an 'ax'. in this particular sentence  more than likely it means a 'helicopter'. what will happen if the system dictionary has  a  the 'helicopter' sense of chopper only   b  the 'ax' sense only  or  c  both the helicopter' and the 'ax' senses  since xtra relaxes 
1 	natural language 
the preference of 'drank' for an animate subject in all three cases  we obtain the desired sense of chopper under  a ; the less than desired sense ol chopper under  b ; and unpredictable results under  c . in other words  'relaxation' can help produce the correct parse sometimes  but may not do so at all times. 
     as carter  1  pointed out  to recognise metaphors 'recourse to a richer source of knowledge like wilks' pseudo-text is necessary.' a pseudo-text is a preference semantic representation of factual and functional information about a concept. the form of representation used in ives incorporates the pseudo-text idea in a form that integrates linguistic knowledge with general world knowledge in one unit of representation. it is called the integrated semantic unit  isu . each isu is an integrated representation of the meaning of a word sense. the building blocks of an isu are also word senses. the general form of an isu is as follows: 
is u  wordsense  
belong   class    i k  i ntegrated knowl edge  
where 	'isu' stands for 	integrated semantic unit; 
'wordsense' is a word sense of any entry word in longman dictionary of contemporary english  ldoce ; 'belong' introduces a hierarchical relationship between wordsense' and 'class'; 'class' represents a superordinate word sense in the hierarchy of word senses in ldoce; 'ik' introduces integrated linguistic and world knowledge associated with wordsense. although the general form of an isu is uniform across all four open-class categories of english words  i.e.  nouns  verbs  adjectives and adverbs  the actual specification of their respective superordinate word senses  and integrated knowledge varies from category to category. an example is given below: 

     ives uses isus to recognize metaphors. in fact the recognition process begins with the recording of all semantic preference violations detected during parsing. some of these violations represent a searching process and are eliminated. only interesting semantic clashes remain. ives looks into each one of these clashes for indications of metaphorical use and misspelling before it requests to acquire any new word senses. among the semantic clashes that ives can handle are subject/verb mismatches  verb/object mismatches  adjective/noun mismatches  and subject/predicative adjective mismatches. 
     
     to recognize metaphors. ives first tries to identify three important parts of a metaphor  the tenor  the vehicle   richards  1  and the salence  ortony  1 . ortony takes 'salence' to mean an estimation of 'prominence of a particular attribute with respect to a concept to which it does or could apply.'  p. 1.  in 'the chopper drank gasoline'  the tenor is man  a human-being who can drink liquid; the vehicle is 'chopper' the actual subject of the sentence; the salence is found in the resemblance between a man's act of drinking and whatever a chopper can do. computationally  the expected subject of 'drank' is taken as the tenor; the actual subject 'chopper' is taken as the vehicle; and 'drank'  the main verb of the sentence  is used to find the salence. ives examines the properties associated with both the tenor and the vehicle to see if their properties are both related to the act of drinking. once a metaphor is found  ives would check with the user for confirmation. to handle metaphors  the cte strategy as mentioned earlier is used. if no metaphors are spotted  ives would start looking for spelling errors. the recognition and handling of misspellings are discussed in the next section. 
b. recognition and handling of misspellings 
     ives recognizes two types of spelling errors in collaboration with the user. they are context-independent errors and contextrdependent errors. context-independent errors can be spotted without examining the context where the error occurs. these spelling errors typically involve missing  surplus  or wrong letters  or letters with their proper positions switched  'convenence'  'conveenience' conviniece'  and 'conveneince' for 'convenience 
would be examples in point. these errors would be picked up by xtra's preprocessing routine simply because the misspelled forms are not found in the system dictionaries. the system would treat them as missing words and call the learning module to input the required information. to recognize and handle contextrindependent errors  the learning module checks on the spelling of any word that calls for new vocabulary information. the user is requested to do the actual checking  and is given a chance to correct him/herself when a spelling error is spotted. however  it so happens tnat sometimes the misspelled word takes the form of the correct spelling of another word which is already available in xtra's dictionaries. we call this second type of misspellings contextrdependent errors. their recognition requires the examination of the context where the error occurs. more often than not  the spelling error would cause a semantic preference violation  and ives would undergo the same processes as described in subsection a above to process the semantic mismatch. when ives fails to identify any metaphors  it will start looking for spelling errors. again the user is requested to do the actual checking  and is given a chance to correct him/herself when a spelling error is spotted. two research questions remain open and unanswered at this stage: 
     1. what if the user is locked in an undesireable mind set and fails to see the spelling error when he or she is given a chance to  
     1. what if a context-dependent spelling error does not cause any semantic preference violations  
	iv 	conclusion 
     on-line vocabulary acquisition is not a recent phenomena either for machine translation in particular or for natural language processing in general. what is new in this paper is the use of semantic primitives and semantic preference violations in the detection of the need to learn new word senses. the mechanism originally designed to disambiguate multiple word senses in an mt system is taken advantage of and made into part of a complex of mechanisms intended to detect the lack of required word senses  and therefore  the need to learn. to cope with tne inescapable problem of metaphor recognition in the process of detecting the need to learn new word senses  a new form of representation  isu. that integrates linguistic knowledge with general world knowledge is introduced. the motivation behind such introduction stems from the following observation: 
     knowledge-based systems typically ignore the rich linguistic knowledge found in conventional dictionaries while conventional dictionaries never express the rich commonsense knowledge assumed of the reader explicitly. yet  linguistic knowledge and general world knowledge are not ultimately separable. what natural language processing really needs is an integrated form of representation that combines the two kinds of knowledge in one unit of representation  wilks  1 . the present research represents an effort in the application of the integrated approach to the area or dictionary update in machine translation. 
acknowledgements 
     my deep appreciation is due to all members of our natural language processing group  particularly to xiuming huang  dan fass  ana yorick wilks  for their encouragement  advice and help. 
