
 algorithms for pruning game trees generally rely on a game being zero-sum  in the case of alpha-beta pruning  or constant-sum  in the case of multi-player pruning algorithms such as speculative pruning. while existing algorithms can prune non-zero-sum games  pruning is much less effective than in constant-sum games. we introduce the idea of leaf-value tables  which store an enumeration of the possible leaf values in a game tree. using these tables we are can make perfect decisions about whether or not it is possible to prune a given node in a tree. leaf-value tables also make it easier to incorporate monotonic heuristics for increased pruning. in the 1-player perfect-information variant of spades we are able to reduce node expansions by two orders of magnitude over the previous best zero-sum and non-zero-sum pruning techniques.
1  introduction
in two-player games  a substantial amount of work has gone into algorithms and techniques for increasing search depths. in fact  all but a small fraction of computer programs written to play two-player games at an expert level do so using the minimax algorithm and alpha-beta pruning. but  the pruning gains provided by alpha-beta rely on the fact that the game is zero-sum. two-player games most commonly become nonzero-sum when opponent modeling is taken into consideration. carmel and markovitch  describe one method for pruning a two-player non-constant-sum game.
 a multi-player game is one with three or more players or teams of players. work on effective pruning techniques in multi-player games began with shallow pruning  korf  1   and continued most recently with speculative pruning   sturtevant  1 . while a game does not need to be constant-sum for pruning to be applied  the amount of pruning possible is greatly reduced if a game is not constant-sum.  both two-player and multi-player pruning algorithms consist of at least two stages. they first collect bounds on players  scores  and secondly test to see if  given those bounds  it is provably correct to prune some branch of the game tree. this work focuses on the second part of this process. alpha-beta and other pruning methods use very simple linear tests as a decision rule to determine whether or not they can prune. for zero-sum games these decisions are optimal. that is  they will make perfect decisions about whether pruning is possible. for non-zero-sum games  however  current techniques will not catch every possibility for pruning.  in order to prune optimally in a non-zero-sum game we must have some knowledge about the space of possible values that can occur within the game tree. carmel and markovitch assume a bound on the difference of player scores. we instead assume that we can enumerate the possible outcomes of the game. this is particularly easy in card games  where there are relatively few possible outcomes to each hand. given that we can enumerate possible game outcomes  we can then make optimal pruning decisions in non-zero-sum games. in addition  these techniques can be enhanced by incorporating information from monotonic heuristics to further increase pruning.
 in section 1 we illustrate the mechanics of a few pruning algorithms  before moving to a concrete example from the game of spades in section 1. in section 1 we examine the computational complexity and the leaf-value table method that is used to implement different decision rules for pruning  followed by experimental results and conclusions.
1 	pruning algorithms
to prune a node in a game tree  it must be proven that no value at that node can ever become the root value of the tree. we demonstrate how this decision is made in a few algorithms.
1 alpha-beta
we assume that readers are familiar with the alpha-beta prun-
 	maxvalue state  ¦Á  ¦Â   	 	if cutofftest state  return eval state   	 	for each s in successor state   	 	 	¦Á ¡û max ¦Á  minvalue s  ¦Á  ¦Â  
 	 	 	if  ¦Â - ¦Á ¡Ü 1   return ¦Â
 	 	return ¦Á
figure 1: alpha-beta pseudo-code.
¦Â   ¦Á
1
figure 1: alpha-beta pruning decision space.
ing algorithm. in figure 1 we show pseudo-code for the maximizing player  modified slightly from  russell and norvig  1 . the statement marked   is where alpha-beta determines whether a prune is possible. this is illustrated in figure 1. the x-axis is the value ¦Â   ¦Á  and we plot points as they are tested. if a point  such as the solid one  falls to the left of 1  we can prune  and if it falls to the right  like the hollow point  we can t. it is useful to think of this as a linear classifier  because it makes a single comparison with a linear function to determine if a prune is possible.
1 maxn
the maxn algorithm  luckhardt and irani  1  is a generalization of minimax for any number of players. in a maxn tree with n players  the leaves of the tree are n-tuples  where the ith element in the tuple is the ith player s score or utility for that position. at the interior nodes in the tree  the maxn value of a node where player i is to move is the maxn value of the child of that node for which the ith component is maximum. at the leaves of a game tree an exact or heuristic evaluation function can be applied to calculate the n-tuples that are backed up in the game tree.
 we demonstrate this in figure 1. in this tree there are three players. the player to move is labeled inside each node. at node  a   player 1 is to move. player 1 can get a score of 1 by moving to the left  and a score of 1 by moving to the right. so  player 1 will choose the left branch  and the maxn value of node  a  is  1  1  1 . player 1 acts similarly at node  b  selecting the right branch  and at node  c  breaks the tie to the left  selecting the left branch. at node  d   player 1 chooses the move at node  c   because 1 is greater than the 1 or 1 available at nodes  a  and  b .
1 maxn pruning algorithms
given no information regarding the bounds on players  scores  generalized pruning is not possible. but  if we assume that each player s score has a lower bound of 1  and that there is an upper bound on the sum of all players scores  maxsum  we can prune. these bounds do not guarantee that a game is constant-sum  and existing pruning algorithms may miss pruning opportunities if a game is not constant-sum.
 1  1  1 

 1  1  1  1  1  1   1  1  1   1  1  1   1  1  1  1  1  1 
figure 1: a 1-player maxn game tree
maxsum = 1	 a 

figure 1: shallow pruning in a 1-player maxn tree.
1.1 shallow pruning
shallow pruning  korf  1  is one of the simplest pruning algorithms for multi-player games. an example of shallow pruning is shown in figure 1. the sum of players  scores in each maxn value is always 1  so maxsum is 1. in this tree fragment player 1 is guaranteed at least a score of 1 at node  a  by moving towards  b . similarly  player 1 is guaranteed 1 points at  c  by moving towards  d . regardless what the unseen value is at  e   player 1 will not select that move unless it gives him more than 1 points. thus  before exploring  e   we can already guarantee that player 1 will never get more than maxsum - 1 = 1 points at  c . because player 1 is guaranteed at least 1 points at  a   the value of  e  is irrelevant and can be pruned.
 in this example we used consecutive bounds on player 1 and player 1 s scores to prune. as stated previously  the general idea is to prove that unseen leaf nodes cannot become the maxn value of the game tree. in figure 1  for instance  we can consider all possible values which might occur at node  e . if any of these can ever become the maxn value at the root of the tree  we cannot prune.
 to formalize this pruning process slightly  we construct a n-tuple similar to a maxn value called the bound vector. this is a vector containing the lower bounds on players  scores in a game tree given the current search. while the maxn value is constrained to sum to maxsum  the bound vector can sum to as much as n¡¤maxsum. in figure 1  after exploring every node except node  e  our bound vector is  1  1  1 . this is because player 1 is guaranteed 1 points at the root  and player 1 is guaranteed 1 points at node  c . existing pruning algorithms prune whenever the sum of the components in the bound vector is at least as large as maxsum.

               player 1 figure 1: shallow pruning decision space.

 we show a visualization of the shallow pruning space in figure 1. the x- and y-coordinates are scores or bounds for player 1 and player 1 respectively. the shaded area is the space where possible maxn values for player 1 and 1 will fall. all maxn values in the game must be in this space  because their sum is bounded by maxsum. because shallow pruning ignores player 1  player 1 and player 1 s combined scores are not constant-sum  so they can fall anywhere to the left of the diagonal line. bound vectors  however  can fall anywhere in the larger square. if a bound vector is on or above the diagonal line defined by x+y = maxsum  we can prune  because there cannot be a maxn value better than those bound vectors. like alpha-beta  shallow pruning is using a linear classifier to decide when to prune.
 ignoring player 1 s values  we plot the leaf values  1  1  -  and  1  1  -  from figure 1 as open points  and the bound vector  1  1  -  used to prune in figure 1 as a solid point. in this instance  there is no gap between the gray region and the diagonal line  so the line defined by x+y = maxsum is a perfect classifier to determine whether we can prune.
1.1 alpha-beta branch-and-bound pruning although shallow pruning was developed for multi-player games  the basic technique only compares the scores from two players at a time. alpha-beta branch-and-bound pruning  sturtevant and korf  1  is similar to shallow pruning  except that it uses a monotonic heuristic to provide bounds for all players in the game. the bound vector in figure 1 was  1  1  1 . player 1 s bound was 1  because we had no information about his scores. but  supposing we had a monotonic heuristic that guaranteed player 1 a score of at least 1 points. then the bound vector would be  1  1  1 . this additional bound makes it easier to prune  since we can still prune as soon as the values in the bound vector sum to maxsum.
1.1 speculative pruning
speculative pruning  sturtevant  1   like alpha-beta branch-and-bound pruning  takes into account all of the players in the game. it does this by considering multiple levels in the game tree at one time. we demonstrate this in figure 1. in this figure  the important bounds are player 1 s bound at  a   player 1 s bound at  b  and player 1 s bound at  c . these together form the bound vector  1  1  1 . if these values sum 

figure 1: speculative pruning decision space.
to at least maxsum we can guarantee that there will never be a value at the right child of  c  which can become the maxn value of the tree. when pruning over more than 1-ply in multi-player games there is the potential that while a value at  c  cannot become the maxn value of the tree  it can affect the maxn value of the tree. other details of the speculative pruning algorithm prevent that from happening  but we are only concerned with the initial pruning decision here.
 we illustrate the pruning decision rule for speculative pruning in figure 1. in this case  because we are comparing three player s scores  the decision for whether we can prune depends on a 1-d plane in 1-d space  where each axis corresponds to the score bound for each of the 1 players in the game. thus each maxn value and bound vector can be represented as a point in 1-d space. for a three-player constantsum game  all possible maxn values must fall exactly onto the plane defined by x+y+z = maxsum  which is also perfect classifier for determining when we can prune. as in shallow pruning  bound vectors can fall anywhere in the 1-d cube.
1 generalized pruning decisions
in all the pruning algorithms discussed so far  a linear classifier is used to make pruning decisions. this works well when a game is zero-sum or constant-sum  but in non-constant-sum games a linear classifier is inadequate1.
 when a game is non-constant-sum  the boundary of the space of maxn values is not defined by a straight line. we demonstrate this in the next section using examples from the game of spades. to be able to prune optimally  we need to know the exact boundary of feasible maxn values  so that we can always prune when given a bound vector outside this region. we explain methods to do this in section 1.
1 	sample domain: spades
spades is a card game for 1 or more players. in the 1-player version players play in teams  while in the 1-player version each player is on their own  which is what we focus on. there are many games similar to spades which have similar proper-
# tricks takenutility/evaluation  bid ranked maxn valsp1  1 p1  1 p1  1  1  1  1 11 1  1  1  1  1  1  1+1+1 1  1  1  1  1  1  1+1 1  1  1  1  1  1  1+1 1  1  1  1  1  1 11+1 1  1  1  1  1  1  111 1  1  1  1  1  1  111 1  1  1  1  1  1 11 1  1  1  1  1  1  111 1  1  1  1  1  1 11 1  1  1 table 1: outcomes for a 1-player  1-trick game of spades.
ties. we will only cover a subset of the rules here. a game of spades is split into many hands. within each hand the basic unit of play is a trick. at the beginning of a hand  players must bid how many tricks they think they can take. at the end of each hand they receive a score based on how many tricks they actually took. the goal of the game is to be the first player to reach a pre-determined score  usually 1 points.  if a player makes their bid exactly  they receive a score of 1¡Ábid. any tricks taken over your bid are called overtricks. if a player takes any overtricks they count for 1 point each  but each time you accumulate 1 overtricks  you lose 1 points. finally  if you miss your bid  you lose 1¡Ábid. so  if a player bids 1 and takes 1  they get 1 points. if they bid 1 and take 1  they get 1 points. if they bid 1 and take 1  they get -1 points. thus  the goal of the game is to make your bid without taking too many overtricks.
 if all players just try to maximize the number of tricks they take  the game is constant-sum  since every trick is taken by exactly one player  and the number of tricks available is constant. but  maximizing the tricks we take in each hand will not necessarily maximize our chances of winning the game  which is what we are interested in. instead  we should try to avoid overtricks  or employ other strategies depending on the current situation in the game.
 in a game with 1 players and t tricks  there are  t+1  t+1 /1 possible ways that the tricks can be taken. we demonstrate this in table 1  for 1 players and 1 tricks.
 table 1 is an example of a leaf-value table. it contains all possible leaf values and their associated utility in the game. in spades  we build such a table after each player had made their bid  but before game play begins. the first column enumerates all possible ways that the tricks can be taken by each player. the second through fourth columns evaluate the score for each player  that is their utility for each particular outcome. in this example  player 1 and player 1 have bid 1 trick each  and player 1 bid 1 tricks. if a player does not make their bid they have a score of 1  otherwise we use a heuristic estimate for their score  1¡Ábid - overtricks + 1¡Á how many opponents miss their bid . as has been shown for minimax  russell and norvig  1   we only care about the relative 

           player 1's score figure 1: pruning decision space for table 1.
value of each state  not the absolute value. so  in the last column we have replaced each player s utility with a rank  and combined all player s ranks into the final maxn value.  as an example  the first possible outcome is that players 1 and 1 take no tricks  while player 1 takes 1 tricks. since players 1 and 1 both missed their bids  they get 1 points. player 1 made his bid of 1 tricks  and took 1 overtrick. since we want to avoid too many overtricks  we evaluate this as 1 = 1 points. but  since both player 1 and 1 miss their bids in this scenario  player 1 has a bonus of 1 points. this is the best possible outcome for player 1  so it gets his highest ranking. for player 1 and 1 it is their worst possible outcome  so they rank it as 1.
 we graph the shallow pruning decision space for the first two players of this game in figure 1. in this game maxsum is 1. the 1 possible leaf values for the first two players are all plotted as hollow points in the graph. if we use maxsum as a discriminator to decide if we can prune  it will indicate that we can only prune if a bound vector falls on or above the bold diagonal line. but  we can actually prune as long a bound vector is on or above the border of the gray region. so  we can actually prune given any bound vector for player 1 and 1 except  1  1    1  1    1  1  and  1  1 .
 as a final point  we note that in card games like spades the number of tricks you have taken can only increase monotonically  which can be used as a heuristic to help pruning. this observation is the key behind the alpha-beta branchand-bound pruning technique. but  if we are using a utility function like in table 1  it is difficult to describe how the monotonic heuristic relates to the evaluation function. leafvalue tables  however  make the task easy.
 assume  for instance  that player 1 has already taken 1 trick. then  we can ignore all outcomes in which he does not take one trick. this gives us a reduced set of values  which are marked with a   in table 1. looking at the associated maxn values  we then see that player 1 will get no more than 1 and player 1 will get no more than 1. we show how this is used in the next section.
1 	leaf-value tables
the formal definition of a leaf-value table is a table which holds all possible outcomes that could occur at a leaf node in a game. looking back to the pruning algorithms in section 1  

 	global leaf-value table { outcome  rank }
1 	canleafvaluetableprune bounds  heuristicub  1 	 	if  inhashtable bounds  heuristicub  
1 return hashlookup bounds  heuristicub 
1 for each entry in leaf-value table
1 for i in players 1..n
1 if entry.outcome i    heuristicub i 
1 skip to next entry;
1 for i in players 1..n
1 if entry.rank i  ¡Ü bounds i 
1 skip to next entry;
1 addtohashtable false  bounds  heuristicub 
1 return false;
1 addtohashtable true  bounds  heuristicub 
1 return true;

figure 1: leaf-value table pruning pseudo-code.
we want to replace the linear classifiers with more accurate classifiers  given a leaf-value table. thus  we need an efficient way to both find and compute regions like in figure 1 to determine when we can prune.
theorem: the information stored in a leaf-value table is sufficient to make optimal pruning decisions.
proof: we first assume that we have a bound vector b =  b1  b1  ...  bn   where each bound in the vector originates on the path from the root of the tree to the current node. we are guaranteed that a player i with bound bi will not change his move unless he can get some value vi where vi   bi. thus  if there exists a value v =  v1  v1  ...  vn  where  i vi    bi then we cannot prune  because v is better than every bound in the search so far. given a leaf-value table  we know every possible value in the game  and so we can explicitly check whether some v exists that meets the above conditions  and thus we can use a leaf-value table to make optimal pruning decisions.  
 because a leaf-value table gives us an exact description of the boundary of the spaces where we can and cannot prune  the only question is how we can use this information efficiently. given a bound vector  we need to quickly determine whether or not we can prune  because we expect to ask this question once for every node in the game tree.
 for small games  we can build a lookup table enumerating all possible bound vectors and whether or not we can prune. this will provide constant time lookup  but for a table with t entries and n players  this table will be size o tn  and take time o tn+1  to compute. including heuristic information makes these tables even larger. but  most of these entries will never be accessed in any given game. instead  we can dynamically compute entries as we need them  and store the results in a hash table.
 pseudo-code for using a leaf-value table is in figure 1. this procedure is called by a pruning algorithm to decide whether or not to prune given current bounds. a leaf-value table is pre-computed with each possible outcome of the game and the associated rank of that outcome for each player. we pass in the current bound vector  as well as any heuristic upper bounds on players  scores. if an entry in the leaf-value table is inconsistent with the heuristic  line 1   we can ignore that entry  because that outcome cannot occur in the current sub-tree. if there is an entry in the table for which every player does better than their value in the bound vector  tested on lines 1  we reach lines 1  indicating we cannot prune.  every time we attempt to prune  we will pay at most 
o table size   but this cost is quickly amortized over the lookups  and doesn t add significant overhead. in a game with a large number of outcomes there are a variety of other methods that could be used to reduce the lookup cost. additionally  we can always use the standard linear maxsum check  as it will always be correct if it indicates we can prune. the heuristic does not speed up the check for whether we can prune  but it can reduce the effective size of the leaf-value table  making it more likely that we do prune.
1 	experimental results
1 nodes expanded in three-player spades
we use the game of spades as a test-bed for the techniques introduced in this paper. our first experiment will illustrate that leaf-value tables are quite effective for pruning  and will also help demonstrate when they will be most effective. to do this  we compare the number of nodes expanded using  1  previous pruning techniques and  1  a variety of evaluation functions in the 1-player version of spades. one of these evaluation functions is actually from a different bidding game  called  oh hell! 
 for each method  we counted the total number of node expansions needed to compute the first move from 1 hands of spades  where each player started with 1 cards and searched the entire game tree  1-ply . our search used a transposition table  but no other search enhancements besides the pruning methods explicitly discussed. bids for each player are pre-determined by a simple heuristic. for these trees  the leaf-value tables contain 1 entries. we present the results in table 1.  the first column in the table is the average size of the game trees without pruning  1 million nodes. this is determined by the cards players hold  not the evaluation function used  so we will compare the other tree sizes to this value.  the next two columns are the results using speculative pruning with a linear classifier  the previous best pruning technique. if we use a non-constant-sum  ncs  evaluation 

full treencsmtmombmotsmotwlohnodes expanded1m1m1m1k1k1k1.1kreduction factor-11111table 1: overall reduction and average tree sizes in spades.

full treebest nzszero-sumlvtnodes1k1k1k1kreduction-111
avg. points% winslvt1.1%prev. methods1.1%table 1: reduction and average tree sizes in 1-player spades.	table 1: average score over 1 games of spades.

function  speculative pruning is able to reduce the average tree size by a factor of 1 to 1 million nodes. maximizing tricks  mt  is the best-case evaluation function for speculative pruning  because it is constant-sum. in this case the average tree size is reduced to 1 million nodes.
 now  we replace speculative pruning s linear classifier with leaf-value tables and use a non-zero-sum evaluation. the first function we use is momb  maximizing the number of opponents that miss their bid. this is quite similar to the strategy of maximizing your tricks  but the average tree size can be reduced further to 1k nodes  a 1 fold reduction.  the next evaluation function we use tries to minimize overtricks  mot. this produces much smaller trees  1k nodes on average  a 1 fold reduction over the full tree. a similar evaluation function  smot  allows a slight margin for taking overtricks  because that is how we keep our opponent from making their bid  but tries to avoid too many overtricks. this evaluation function reduces the tree further to 1k nodes  over 1 times smaller than the original tree. the smot evaluation is what was used with speculative maxn for the ncs experiment. in the end  both algorithms calculate the exact same strategies  but with leaf-value tables we can do it hundreds of times faster.
 finally  we show a very simple evaluation function  wl. this function gives a score of 1  win  if we make our bid and 1  loss  if we miss it. in practice we wouldn t want to use this evaluation function because it is too simple  but it does give an estimate of the minimum tree size. with this evaluation function the average tree has 1 nodes.
  oh hell!   oh  is a similar game to spades  however the goal of this game is to get as close to your bid as possible. in the context of this paper  we can just view this a different evaluation function in the game of spades. using this evaluation  the average tree size was 1k nodes  1 times smaller than the full tree.
 besides showing the effectiveness of leaf-value tables  these experiments help illustrate two reasons why leaf-tables are effective for pruning in a non-constant-sum game. the first reason for large reductions is that the non-constant-sum evaluation may significantly reduce the number of unique outcomes in a game  which will be captured by a leaf-value table. the best example of this is the wl evaluation function. but  smot also reduces the possible outcomes over mot  and thus reduces the size of the game trees.
 the other factor that is important for pruning is having a monotonic heuristic along with an evaluation function that is not monotonic with respect to the heuristic. evaluation functions like mot are non-monotonic in the number of tricks taken  because we initially want to take more tricks  and then  after making our bid  we don t want to take any more tricks. this allows a monotonic heuristic to more tightly constrain the search space  and thus increases pruning.
 the momb evaluation function is both monotonic and only a slight simplification of the mt evaluation function  so we should and do see the least gains when using this evaluation function.
1 nodes expanded in two-player spades
we conducted similar experiments in the two-player game of spades.  korf  1  described how deep pruning fails in multi-player games. it is not difficult to show that the same problem exists in two-player non-zero-sum games as we have described them here. the bottom line is that we cannot prune as efficiently as alpha-beta once we use a non-zerosum evaluation function. in these experiments we did not apply every conceivable game-tree reduction technique  only transposition tables and basic alpha-beta pruning  so in practice we may be able to generate smaller two-player zero-sum game trees.
 in the two-player spades games  we searched 1 hands to depth 1  1 tricks  using a variety of techniques. the results are in table 1. the full tree averaged 1k nodes. using a non-zero-sum evaluation function and the best previous methods produced trees that averaged 1k nodes. using alpha-beta pruning and a zero-sum evaluation function reduced the trees further to 1k nodes on average. using leaf-value tables  lvt  for pruning produced trees were slightly larger  1k nodes. as referenced above  these trees are larger than those generated by alpha-beta because we cannot apply deep pruning  but they are still much smaller than previously possible given a non-zero-sum evaluation function.
1 quality of play from extended search
finally  to compare the effect of additional search on quality of play  we then played 1 games of 1-player spades  where multiple hands were played and the scores were accumulated until one player reached 1 points. also  each complete game was replayed six times  once for each possible arrangement of player types and orderings  excluding games with all of one type of player. each player was allowed to expand 1 million nodes per turn. one player used speculative pruning with leaf-value tables to prune  while the other used speculative pruning with a linear classifier. hands were played  open  so that players could see each others cards. the results are in table 1. the player using the leaf-value tables  lvt  was able to win 1% of the games and averaged 1 points per game  while the player using previous techniques averaged only 1 points per game.
1 summary
we have presented results showing that leaf-value tables  when combined with previous pruning techniques  can effectively prune non-constant-sum games such as spades or oh hell!
 although we do not present experimental results here  we can predict the general nature of results in other games such as hearts. in most situations in hearts  our evaluation function will be constant-sum. but  there will be some situations where a non-constant-sum evaluation function is needed. thus  if we use leaf-value tables for such a game  we will have the same gains as previous techniques in portions of the game that are constant-sum. but  when the game is non-constant sum  we will benefit from additional pruning  although the exact amount will depend on the particular situation.
1 	conclusions and future work
in this paper we have shown how an enumeration of possible leaf-values in a game tree  called a leaf-value table  can be used to change the linear classifier used in classical pruning algorithms to an arbitrary classifier needed for non-zero-sum games. this technique works particularly well in card games like spades  where we see up to a 1 fold reduction of nodes expanded over the previous best results using a constant-sum evaluation function  along with gains in quality of play.  this work expands the limits of how efficiently we can search two-player and multi-player games. to a certain extent there is still an open question of how to best use limited resources for play. recent results in applying opponent modeling to two-player games have not been wildly successful  donkers  1 . in multi-player games  we have shown that deep search isn t always useful  if there isn t a good opponent model available  sturtevant  1 . but  given a reasonable opponent model  this work allows us to use the best  evaluation function possible and still search to reasonable depths in the game tree.
 in the future we will continue address the broader question of what sort of opponent models are useful  and what assumptions we can make about our opponents without adversely affecting the performance of our play. the ultimate goal is to describe in exactly which situations we should use maxn  and in which situations we should be using other methods. these are broad questions which we cannot fully answer here  but we these additional techniques will provide the tools to better answer these questions.
acknowledgements
this research benefited from discussions with jonathan schaeffer  michael bowling  martin m¨¹ller  akihiro kishimoto and markus enzenberger. the support of alberta s informatics circle of research excellence  icore  is also appreciated.
a game transformations
in this paper we have often made distinctions between games or evaluation functions based on whether they are constantsum or not. these distinctions can be blurred through minor transformations  however such transformations do not change the underlying nature of the game. in this appendix we explain this in more detail  but the details are not necessary for understanding the technical contributions of this paper.  first  we can take a game or evaluation function that is naturally constant-sum and make it non-constant-sum by either adding a player which doesn t actually play in the game  but receives a random score  or by applying an affine transform to one or more players  scores. neither of these transformations  however  will change the strategies calculated by maxn  because maxn makes decisions based on the relative ordering of outcomes  which an affine transform preserves  and because any extra players added will not actually make decisions in the game tree.
 if we are unaware of either of these changes  previous pruning algorithms may treat the game as non-constant-sum and miss pruning opportunities. but  leaf-value tables are not affected by either of these changes. leaf-value tables compute the ranking of all outcomes  so any affine transform applied to an evaluation function will be removed by this process. because no bounds will ever be collected for any extra players in the game  as they are not actually a part of the game  pruning decisions are unchanged.
 secondly  we can take a game that is non-constant-sum and make it constant-sum by adding an extra player whose score is computed such that it makes the game constant-sum. again  because this extra player never actually plays in the game  no pruning algorithm will ever collect bounds for this player  and it is equivalent to playing the original game. no extra pruning can ever be derived from such a change.  adding an additional player may also make a non-linear classifier appear to be linear. but  because the extra player never plays  we will actually need to use the non-linear classifier to make pruning decisions.
 	thus  while the difference between constant-sum games and non-constant-sum games can be blurred by simple transforms  the underlying game properties remain unchanged.
