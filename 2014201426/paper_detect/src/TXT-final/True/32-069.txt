 
localization is one of the most important capabilities for autonomous mobile agents. markov localization  ml   applied to dense range images  has proven to be an effective technique. but its computational and storage requirements put a large burden on robot systems  and make it difficult to update the map dynamically. in this paper we introduce a new technique  based on correlation of a sensor scan with the map  that is several orders of magnitude more efficient than ml. cbml  correlation-based ml  permits video-rate localization using dense range scans  dynamic map updates  and a more precise error model than ml. in this paper we present the basic method of cbml  and validate its efficiency and correctness in a series of experiments on an implemented mobile robot base. 
1 introduction 
localization is the process by which a mobile robot or other physical agent keeps track of its position as it moves around an environment. it is an essential capability for autonomous mobile robots if they are to perform tasks in an efficient way: a robot that gets lost in performing a delivery is useless. 
　the problem of localization is made difficult because  in general  we are trying to construct robots that can act intelligently in environments that are imperfectly known  and for which their sensors give only uncertain information. this naturally leads to the consideration of probabilistic methods  in which the spatial state of the robot is represented as a probability distribution over the space of possible robot poses  location and direction . the problem of localization is then the problem of updating the distribution  based on robot motion and sensing  given a map of the environment that may be imperfect. 
　a recent approach to this problem called markov localization  ml  has proven to be both robust and accurate. ml makes the choice of an explicit  discreet representation for the prior probability  using a grid or topological graph to cover the space of robot poses  and keeping a probability for each element of this space. the 
1 	robotics and perception key idea of ml is to compute a discrete approximation of a probability distribution over all possible poses. 
　different variants of ml have been developed  burgard et ai 1  kaelbling et al. 1; they can be distinguished according to the type of sensor readings they work with. here we are concerned with dense methods  in which a all the information in a range scan is used to match against a model of the environment  burgard et al. 1 . 
　dense methods have proven particularly successful in robot localization tasks  including wseveral real-world robot installations as tour-guides in museums  burgard et al. 1  thrun et al. 1 . still  dense methods are subject to several daunting representational and computational challenges that make them difficult to use. the basic problem is that the probability update step of ml involves comparing actual sensor readings to readings that would have resulted from having the robot at every possible pose in a given map. this update can be enormously expensive  generating billions of sensor comparisons for even moderately sized maps  if done in a straightforward way. but through clever approximations  and especially by pre-computing expected sensor readings from all map poses  researchers have made it possible to apply dense ml in practical systems  burgard et al 1 . yet there remain significant problems  some brought on by the approximations. 
  dense ml remains computationally difficult. for example  globalization in moderately-sized environments can take many minutes for integration of a set of sensor readings. 
  environment maps are fixed and cannot be easily updated to account for dynamic objects or structural changes such as open doorways  because the expected sensor readings must be re-computed. 
  precise localization with fine spatial grids is difficult  because it presents increased computational and storage demands  especially for the pre-computed expected readings. 
  error models for objects in the map are poor approximations to actual errors  because they must be represented by a single number for each pose  the expected distance to the object. 
in this paper we present a new method for computing 
markov localization  which we call correlation-based 

markov localization  cbml   that addresses these problems. instead of pre-computing expected distances to map objects  we use techniques from image processing to correlate a sensor scan with an existing map. because these methods are regular  that is  they are applied uniformly over the map  we can take advantage of simd  single-instruction  multiple data  instructions in modern processors to yield extremely efficient implementations. in comparisons with the best existing ml methods on similar processors  cbml is two orders of magnitude faster. 
　besides being efficient  cbml does not have to precompute expected object distances in the map. thus  it tolerates changes to the map on-the-fly  allowing dynamic objects or structural information to be incorporated. an additional benefit is that the grid size of the map need not be fixed ahead of time  so that the grid resolution can be increased or decreased as necessary: a coarse grid for initial globalization  and a fine grid for precise maneuvering. a more realistic uncertainty model can be introduced into the map  increasing the fidelity of the probabilistic updating process. finally  correlation opens the door for some techniques that are not possible with standard ml  for example  the use of fused sensor readings for extended matching. 
　in the rest of this paper  we develop the mathematics of cbml  and show how it corresponds to the equations of ml. then  we explore some of the performance issues associated with cbml  and show how it can be implemented in an efficient way. we present experimental results of the method using a pioneer ii platform equipped with a laser range finder. finally  we discuss some implications of correlation on future capabilities of ml. 
1 	markov localization as a correlation operation 
1 markov localization 
　ml  like other filtering operations designed to estimate the state of a system  consists of two steps: predicting the next state of the system based on state-space motion  and updating the predicated state based on sensor readings. for mobile robots  the prediction step uses dead-reckoning from internal encoders  and we won't consider it further in this paper. the update step changes the predicted probabilities according to the formula: 
 la  
where is the robot pose  s is the sensor reading  m is a particular state of the map  that is  of each cell being occupied or not   and  is a normalization factor. given a new sensor reading s  the probability that the robot is at location  is a function of the sensor model the prior probability of the robot being at pose and the prior probability of the map state  the sensor model represents the probability of getting a reading 1  given the robot is at pose  and the map state is  note that  1  explicitly takes into account both sensor error and map error. the markov assumption is that the updated probability depends only on the robot's expected position and current sensor readings  and not their history. 
　　multiple sensor readings  taken at different angles from the same location are assumed to be independent  and the update function is: 
		 lb  
　　in practical systems  uncertainty in the map position is eliminated by adding more noise into the sensor model  so that the summation over m is eliminated  and 
 1  becomes 
		 1  
here it is assumed that the location of map objects are fixed and known. the evaluation of  1  involves computing the distance of the nearest object in the direction of the sensor in the  fixed  map  which is expensive. to compute  quickly  the distance is precomputed and stored for every possible sensor angle and position  leading to a very large data structure for the map. any changes to the map mean that the expensive pre-computation must be repeated. 
1 correlation and ml 
　to obviate the need for pre-computation of object distances  we introduce a new method for determining the probability  this method is based on the concept of correlation between the map and the sensor scan. in correlation  a sensor scan is converted to a small discretized area patch  and matched against the larger discretized map. a high value for correlation indicates a good match between sensor readings and the map. figure 1 shows the basic idea: a sensor indicates an uncertain range to an object  as shown by the discretized sensor patch on the left. a discretized map contains uncertain information about the location of objects. the correlation operation places the sensor patch on the map  multiplies the corresponding values  and sums them to give the response of the sensor at the origin of the sensor. moving the sensor patch over the whole map computes the complete sensor response. 
　given a sensor patch p and a map m  we must define a correlation operation that computes  1 . for each cell ci  in p  let 
 1  
where is the probability of getting a sensor reading given the robot is at location  and there is a 
map object at the cell location. then  the correlation is computed as 
		 1  
and the updated probability is 
	konolige and chou 	1 


map grid 
figure 1 a sensor patch correlated with a map grid. 
		 1  
　equation  1  is only an approximation to  1   since we are using an approximate sensor model  the difference is that  does not take into account visibility constraints  that is  objects closer than are not considered to interfere with the sensor. for example  in figure 1 correlation shows a strong response  but ml would not  because the closest object is not at the sensor range. correlation violates the visibility constraint of the range sensor. in the next section we present experimental evidence that correlation is still a good approximation to ml updating. 
　note that  1  deals with uncertainty in both the map and the sensor. in a manner similar to ml  we can fold the sensor error back into the map error  so that the sum in  1  reduces to a single value per sensor reading. this idea is the key to implementing an efficient version of correlation  since it allows many sensor readings to be processed using the same correlation patch. let be the cell where a sensor reading  falls. then the sensor patch is defined as being 1 at all such cells  and 1 elsewhere. now multiple-sensor correlation becomes: 
		 1  
　using mcorr in place of corr in equation  1  gives an approximation to equation  1 . it does not take into account visibility constraints  and assumes the sensor error 

map grid 
figure 1 correlation violating a visibility constraint for the sensor. 
1 	robotics and perception 
has been accounted for in the map error. 
　the advantage of correlation is that it uses the map as is  without any additional pre-computed information. storage requirements for the map are reduced by two orders of magnitude  and it is possible to dynamically update the map as new information is made available. correlation using  1  is also computationally efficient  as we show in section 1. 
1 sensor and map error models 
　in general  the sensor response to a map    is a complicated function of the sensor characteristics and the environment. this is especially true for wide-angle  active sensors such as sonars or radars  which are subject to specular reflection  corner reflection  and similar phenomenon  leonard et al. 1 . simplifying assumptions are needed to evaluate  la  efficiently. 
　ml implementations typically assume that the distance to the nearest object  given a particular sensor pose  is the only map information that is needed in  la . if the map is uncertain  then the sensor model is broadened by an appropriate amount  e.g.  if the sensor variance is and the map variance is then the sensor variance is reset to  this assumption fails badly  however  when there are depth discontinuities in the map. consider figure 1  in which two walls are offset in depth. wall variance is indicated by the dotted lines; sensor variance is along the sensor line of sight. i n this situation  we would expect a sensor reading at the depth of wall a or b. relying on sensor variance alone  the best we can do is to pick a point midway between the wails  and extend the sensor variance to include both walls. this is not a very accurate approximation of the actual situation. on the other hand  folding the sensor variance into the map  by extending the wall variance slightly  gives a much more realistic error model. 
1 experimental validation 
　in this section we report results of numerical experiments to compare the performance of the cbml and ml methods. the focus of these experiments is to evaluate the effects resulting from conceptual and implementation differences between the two methods. for cbml  we use the variance of the sensor probability  as the basis for an isotropic kernel to blur the map. this gives 

figure 1 sensor vs. map variance. 


figure 1 ml vs. cbml response  white  on a typical map  with different sensor variances. top figures are m l   bottom cbml. dark grey lines are map segments. the sensor patch was taken from the center of the map. 

roughly equal error models for the two methods. 
　the numerical experiments were performed using a 1 by 1 position grid. figure 1 displays the results of the ml  top  and cbml  bottom  methods applied to data corresponding to a 1 degree span  where range measurements are taken every 1 degree. the sensor patch was taken from the middle of the figure. the variance  as explained above  is set to 1 for the left figures  1 pixels for the middle  and 1 for the right. the color images represent the values of  in pseudo-color  with yellow and then red being the highest values. we use a log scale for the intensities in order to highlight the differences in the fine structure of the densities. note that the cbml result shows additional lines not found in the ml case. these lines result from the violation of visibility constraints. these spurious features  however  are extremely low in probability; if plotted on a linear rather than a log scale  the results of the two methods are virtually identical. 
　for the nonzero variance cases  the results show a much greater spread in probability values  as expected. the cbml results  however  differ from those of the ml method in at least two ways in the vicinity of the peak: 1  the spreading seems larger for cbml  given identical sigma and 1  the spreading is less symmetrical in the case of cbml vs. ml. the first point indicates that differences in the implementation of the uncertainty models results in greater spreading of the map uncertainty for cbml. the second point provides evidence of the fact that the uncertainty model for cbml more faithfully reflects map uncertainty than ml does. 
　in order to characterize these differences on average  an experiment was performed using 1 different robot positions. in order to compare the posterior density for the two different methods the following difference measures were used. 
  the divergence is an information-theoretic measure for the closeness of two distributions. it is defined as the difference in expected values of the log-likelihood ratio with respect to two densities: 
where 	and el is expectation with respect to using ml  while e1 is the expected value taken using cbml. 
   gives a measure of the peakedness of the density. this measure provides a way of comparing the performance of the two methods in that a  the location of the peak indicates the estimated position 
and b  the value of  at the peak is the probability that the position corresponds to the pose 
　the average statistics for the divergence measure and peak  values are shown in figure 1  the top graph shows the divergence of cbml and ml  divided by the divergence of ml and a uniform distribution. a value close to zero indicates that cbml tracks ml much better than chance. in fact  the divergence measure statistics show that  for the two methods is virtually identical for small variance. as variance increases  the cbml results spread more than ml  and cbml at smaller spreads tracks ml more closely. as before  this effect is probably due to the difference in error models between the map and the sensor. 
	konolige and chou 	1 

　the peak value graph  bottom  shows the ratio of peak values for cbml and ml. here  a result near 1 indicates they are similar; lower than this  cbml is less specific at localization than ml. again  cbml tracks ml well at lower sensor/map variance  then tends to spread more  and have a lower peak  at higher variance. in part  this difference may be accounted for by the fact that at higher variances  cbml has increased sensitivity to visibility constraint artifacts; in part  it arises because the map error model is different from sensor error model  and probably more appropriate  see below . 
1 other sensor grid matching schemes 
techniques for matching evidence grids  moravec and 
elfes 1  are similar to the sensor correlation method proposed here  schiele and crowley 1 . recent implementations of the method  schultz and adams 1  have shown impressive results  and do allow the simultaneous integration of new information with the map. our work is distinguished by being more efficient  by many order of magnitude; see below  and having a bayesian theoretical justification. 
1 	implementation and results 
　to test the efficiency and practicality of the method  we integrated it into a robot localization system on our pioneer ii robot  equipped with a laser range finder 
 lrf  for sensing  ref omitted . an lrf scan returns a hemicircle of 1 readings at 1 degree increments; the range error is 1 cm  and the maximum range is 1 m. several techniques were used to make cbml efficient; we describe these methods  some experiments in global localization  and extensions to the method. 
1 log grid update 
　to implement  1  and  1   we use a log representation of the probabilities. log probabilities have some advantages for computation: 
  multiplication of probabilities is addition of logarithms  so the correlation operation  1  uses addition. 
  normalization is accomplished by addition of a constant to all values; in practice we don't worry about normalization  just relative log probabilities. 
  small probabilities are represented more precisely. 
  small integers can be used for efficient storage. mcorr is implemented as a series of additions on small integers. if the robot poses are represented by a regular grid  we can take advantage of parallel instructions  simd  available on most processors to generate several results simultaneously. 
　to describe the computational properties of the cbml algorithm  or any other dense ml update process  we propose the following measure. in general  the amount of time taken by any method is proportional to the number of poses that must be updated  and the number of sensor readings that must be integrated. so the measure of power of an implementation is the amount of time 
1 	robotics and perception 
spent per pose-reading. for our cbml implementation  on a 1 mhz pii we achieve a power rating of less than 1 ns per pose-reading. this compares with 1 ns per pose-reading using an optimized ml algorithm  d. fox  personal communication . 
　the efficiency of cbml makes it possible to run local tracking  using a small grid  at video rates  even for the relatively large number of sensor readings in an lrf scan. typically it takes only a few milliseconds to integrate these readings and update the pose. 
　globalization is also efficient. figure 1 shows an example in our office environment. the map is 1 by 1 meters  and the grid resolution is 1 cm and 1 degrees  for a total of poses. each sensor scan has 1 readings  yielding a total of update operations per scan. the time for one scan update is less than a second on a 1 mhz pii  the lower than expected time is a result of the sensor patch discretization  which collapses several lrf readings into one grid space . 
　figure 1 shows a sample run of the robot. after several scans  its position is ambiguous  left . after 1 scans  the robot has seen enough of the environment to become uniquely localized  middle . finally  its position is tracked through subsequent motion  right . although we have anecdotal evidence like this to show that cbml performs as well as ml  we have not done a definitive set of experiments  as in  gutmann et al. 1 . 

figure 1 divergence  top  and peak value measures. 


figure 1 global localization of the robot using simulated scans. see text for details. 

　another application of cbml that we are actively pursuing involves the correlation of larger patches  rather than just a single sensor scan. for example  in trying to  close the loop  while creating a map  we will correlate a number of scans  1 to 1  to try to find a match in the already-constructed map. this type of operation is very expensive with ml  since each scan must be matched individually. 
1 structural uncertainty in maps 
because cbml does not adhere to the visibility constraint  it can represent map objects at different possible locations; we call this a disjunctive map. an example is the state of a door. figure 1 shows a disjunctive map used to anticipate three possible door positions: closed  open by 1 degrees  and open by 1 degrees. the actual door position is in black  and the robot position is the cross. the ml response  middle  uses the default closedoor position  while the cbml response  right  uses the disjunctive map. note how much better localized the cbml response is. 

figure 1 map of doorway in several positions  left   and corresponding ml  middle  and cbml  right  response. 
1 	conclusion 
localization based on correlation operations is an efficient alternative to standard ml updating. it is several orders of magnitude faster  and uses corresponding less storage in representing map objects. this efficiency opens cbml to applications that have been too expensive: realtime updates of robot position at video rates. it has other advantages over ml. because it doesn't require any special pre-computations in the map  changes can be incorporated dynamically. the error model for cbml violates visibility constraints  but does allow uncertainty in the map  which is a more realistic model than typically used for ml. finally  cbml can deal with structural uncertainty in the map  allowing disjunctive information about map objects. 
　cbml is a method for updating robot pose. although our experiments have used a pose grid for representing robot locations  other more compact representations are also possible  e.g.  a gaussian  gutmann 1  leonard et ai 1 . in this case  the probability is discretized for update  and then translated back to the gaussian form. 
