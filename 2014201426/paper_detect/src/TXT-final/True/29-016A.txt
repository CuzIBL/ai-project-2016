 
a learning framework that combines the two frameworks of explanatory and descriptive inductive logic programming  ilp  is presented. the induced hypotheses in this framework are pairs of the form  t  ic  where t is a definite clausal theory and ic is a set of integrity constraints. the two components allow us to combine complementary information from the same data by applying both explanatory and descriptive learning methods. this non-trivial integration is achieved using a nonmonotonic entailment relation for the basic notion of coverage in the combined language of rules and constraints where the constraints can restrict the conclusions derivable by the rules. we present a semantics for the new framework and then discuss different cases where combining information from explanatory and descriptive ilp could be useful. we present some basic algorithmic frameworks for learning in the new framework  and report on some preliminary experiments with encouraging results. 
1 	introduction 
inductive logic programming  ilp   muggleton and de raedt  1   is concerned with learning clausal theories in first-order logic. two main approaches exist to learning in first-order logic  known under the names of explanatory and descriptive learning. the first  muggleton  1  is also called learning from entailment or normal ilp  the second  de raedt and dzeroski  1  is also called learning from interpretations or nonmonotonic ilp. the first setting is concerned with the induction of rules that explain  correctly classify  the given observations  whereas the latter is concerned with the induction of constraints that describe the  dependencies in the  given observations. 
　while attempts have been made to relate the two settings  see e.g.  muggleton and de raedt  1    
1 	learning 
very few  if any  attempts have been made to combine the two frameworks. on the other hand  the combination of rules and integrity constraints is a very powerful modeling or representation framework found in several areas of computer science. it forms for example the basic conceptual model of databases where the data must always conform to the properties that the integrity constraints of the database specify. in artificial intelligence the combination of a theory with constraints has been extensively studied  e.g.  poole  1; kakas et a/.  1   and applied to problems of planning  diagnosis  legal reasoning and many others. 
in this paper we bring together work from the areas of 
machine learning  ilp  and knowledge representation to propose an integrated learning framework that synthesizes in a non-trivial way the two separate approaches of explanatory and descriptive learning. in this framework the induced hypothesis is a pair of a definite clausal theory  set of rules   t  and a set of integrity constraints  ic. this induced theory is used to reason in a nonmonotonic way  where the integrity constraints in ic specialize the rules in t by restricting their conclusions. the integration of the two forms of learned output in t and ic becomes non-trivial by this reasoning. in turn  when this is used as the basic notion of coverage for the learning problem the two processes of explanatory and descriptive learning interact in a strong way. 
　the integrated learning framework allows us to combine together  during the learning process  complementary information that can be learned from the same data using the two different approaches of explanatory and descriptive learning. in a typical situation  the rules generated by the explanatory learning process can be  informally  understood as sufficient information on the concepts to be learned whereas the output of descriptive learning as necessary information. this combination of information is particularly useful when the learning data or the learning method is incomplete. the integrated learning framework can thus enhance our learning capabilities by allowing us to learn inherently non-monotonic theories  which by definition can not be completely specified . more importantly though it can also be particularly useful  enhancing  for many other learning problems not necessarily non-monotonic in nature as learning by its very nature is often an incompletely specified problem. at the more practical level  the integration of a set of integrity constraints in the learned theory :  i  provides additional complementary information   ii  offers a new type of specialization operator on the rules of the theory   iii  offers a complementary notion of classification via the satisfaction of the constraints and  iv  allows us to learn from incomplete data  e.g.  from positive data only where the constraints provide implicitly negative data. 
	although 	there 	exist 	several 	learning 	systems 
 de raedt and bruynooghe  1; de raedt and van laer  1; muggleton  1  that learn  or can learn  integrity constraints none of these does so in a strongly integrated fashion as we are proposing here. in fact  most of the constraints learned in practical domains  see e.g.  de raedt and dehaspe  1   have the form of definite clauses  the same form as for explanatory ilp   and are even used in the same fashion i.e. for explanation rather than description as is their natural role. 
1 	an integrated learning framework 
in this section we present the basic learning framework that integrates the two different problems of explanatory and descriptive learning. we will assume that the reader is familiar with basic notions of first order logic and logic programming  see e.g.  lloyd  1  . 
　in the integrated framework the hypothesis space is extended to accommodate the learned output for either setting of explanatory or descriptive learning. 
definition 1  hypothesis language : a hypothesis h is a triple   t  c  ic    where c is a set of predicate symbols  the concepts to be learned   t is a definite horn theory  of rules defining concepts in c  and ic is a set of first order formulae  integrity constraints on the theory t . 
　the integrity constraints in ic can in general be any first order formula but in practice  see e.g.  de raedt and bruynooghe  1   it is useful to restrict these to be clauses which are also range-restricted. we have also restricted here the theory t to contain only definite horn clauses with no negation as failure  naf . the framework can easily be extended to allow naf. moreover  the language of definite rules with integrity constraints subsumes naf  eshghi and kowalski  1 . 
the integration of the two forms of learned output 
 explanatory rules in t and general regularities of the data in ic  becomes non-trivial by combining together the reasoning made with each part and then using this as the basic notion of coverage for the learning problem. this combined notion of entailment is inherited here from work in the area of knowledge representation  poole  1    kakas et a/.  1 . reasoning with the theory is done in the usual way using the minimal herbrand model semantics. for the integrity constraints there are several alternative semantics. in this paper we will use the epistemic or meta-level view  reiter  1  where the constraints are understood as statements at a different level from those in the theory and they specify what must be true of the theory. they are formalized as first order formulae that must be true in any given model of the theory for this model to be accepted. 

	dimopoulos  dzeroski  & kakas 	1 
learned theory h. there are also several ways in which this problem could be generalized or modified. for example  the background knowledge may already contain some integrity constraints. another alternative relates to how strong we want the exclusion of negative examples to be. we may for example want to replace the third condition by the stronger condition  there is no generalized model m of h such that 
the proper study of these extensions and alternatives is beyond the scope of this paper. 
　the above definition combines elements from the explanatory and descriptive learning problems via the coverage relation of definition 1. the rules in the theory t give sufficient conditions for the concept s  that we are learning whereas the integrity constraints in ic provide complementary necessary conditions on the concept. 
　let us illustrate the potential and possible use of the integrated framework with a few simple examples. as a first example we take a well known domain from knowledge representation which is not possible to express using only the language bias of definite horn logic. 
example: consider the background theory b bird x   - penguin x  
penguin x   --- superpenguin x  bird{a   bird b   penguin c   penguin d   superpenguin e   superpenguin f  with the set of concepts to be learned c = {flies - }. consider also the training data  consisting 
simply of a set of positive and negative examples as fol-

a solution to this problem is given by the hypothesis 

the integrity constraint expresses a general regularity that characterizes the available data is also used to compensate for the overgenerality of the learned rule in t. the conclusion flies c  is not possible as the constraint is violated: in we would have penguin c  and not superpenguin c . on the other hand  the conclusion flies e  is allowed by the learned theory since this does not violate the constraint. note that if the integrity constraint is considered simply as another clause in the theory t then the resulting hypothesis would be inconsistent covering negative examples. 
　this learning problem can also be captured using the non-monotonic construct of naf by extending the language bias of the theory t from definite horn clauses to normal logic program clauses. a possible solution is given by the rules: flies x  -- bird x  not abnormal x  and abnormal x   ---penguin x  not superpenguin x . 
negation as failure can easily be captured within the 
1 	learning 
framework of definite rules and integrity constraints  eshghi and kowalski  1 . hence the integrated framework subsumes the use of naf in learning systems. conversely  it is indeed possible to simulate the effect of most forms of integrity constraints using naf. this  however  would typically require the use of auxiliary new predicates  as in the above example  thus making the learning process unnecessarily more complicated with the need of predicate invention  bain and muggleton  1 . a more important difference is the fact that the use of naf alone still relies only on the explanatory  normal  ilp learning criteria. in the integrated framework in addition we can use the second independent learning criterion of describing the data available. this can be significant particularly in problems where the training data is incomplete. in the above example  if we are not given the negative examples the integrated framework can still find the same solution as before since the integrity constraint can be learned independently from the rest of the problem. 
　in the previous example due to the inherent nonmonotonicity of the problem it is not possible to learn the correct theory using each of the two ilp settings separately. we will now consider some examples where although there are solutions in these separate settings these may be difficult to find. lack of complete information in learning can effectively result in a situation similar to that of a non-monotonic problem. 
　let us first consider an example where we are trying to learn the concept daughter given complete background information on parent  father  mother  male and female but possibly incomplete information on daughter. suppose that we have learned the rule daughter x y   - parent y  x . 
we first note that the usual specialization of this rule by adding the extra condition of female x  can also be equivalently achieved by learning the integrity constraint female x   -- daughter{x y . 
in fact  any condition in a rule can be simulated by a new constraint of the general form condition  -- concept  subbody-of-rule. note though that this alternative way of specializing the rule is also possible even when there is insufficient negative information in the training data to drive the first alternative of explicit specialization of the rule. suppose now that the background knowledge does not contain the predicate female. an explicit specialization of the rule can now only be done using the naf condition not male x  . this can again be equivalently achieved via the integrity constraint - daughter x y  male x   but as before this constraint can exist independently of any negative examples. 
　the information provided by the integrity constraints may not be captured by the rules of the theory and is thus complementary to that of the rules. suppose for example that we do not have any direct information on the predicates male and female and we have learned the rule daughter x y   - parent y  x . it is still possible to specialize this rule with the use of integrity constraints. this can happen using other information available in the background knowledge and/or the training data that we learn  using the descriptive criteria  is necessarily related to the concept of daughter. consider for example that the background knowledge also contains information about the predicates child - -  and sister - - . then we could learn the integrity constraint: sister x z   - daughter{x y  child{z y  z 』 x. this will provide  some  specialization to the general rule excluding all persons which are not sisters to their sibling from being classified as daughters. similarly other integrity constraints such as mother x z ;aunt x z   daughter x y  grandparent y z  etc could provide additional specialization of the rule. 
　this type of specialization comes from learned dependencies in the data relating the concept we are trying to learn with other known relations in the background knowledge. this information encoded by the integrity constraint should not necessarily be seen as part of the rule definition of the concept. it is instructive to compare the behavior of the integrated framework with that of normal ilp in these situations. firstly  for the latter framework to capture this type of information it will need explicit negative information to drive this specialization  e.g.  a negative example of a sibling that is not a daughter. if this is given then normal ilp will try to specialize the general rule by adding extra conditions in its body. in the example above it will specialize the rule to daughter x y   -- parent y x  cmld z y  z 』 x sister x z  resulting in an arguably artificial definition. 
　apart from the non-naturality of the rules another important difference of encoding this type of information in rules instead of integrity constraints is the fact that the extra conditions added to the rules  e.g.  here child z  y  z 』 x  now become necessary for the conclusion to hold whereas this is not the case with the integrity constraints. but these conditions may not be relevant in all cases. they may not be known by the theory  e.g.  in the case where we have multiple predicate learning and child is another predicate that we are learning  or they simply do not hold  e.g.  cases where the daughter does not have a sibling . this then means that in addition  the normal ilp system must now generate another rule  or rules  to re-cover all the positive examples that are lost by these extra conditions. this is the phenomenon of rule splitting in normal ilp systems that can result in many overspecific rules containing conditions not directly relevant to the proper definition of the concept. 
　learning integrity constraints differs significantly from learning more clauses in the theory. the integrity constraints are not simply some extra clauses of the theory learned on some additional concepts that  possibly  appear in the heads of the integrity constraints. although the integrity constraints could be used to provide a partial definition for these predicates their main purpose is to specialize the concept rules in the theory t. to be more specific  if the above integrity constraint is considered simply as another clause in the theory for a new concept sister  this will not have any effect on the rule of the theory which will remain overgeneral. similarly  if we add the  corresponding clause  daughter x y   -- sister x  z  child{z y  to the theory  this will not have any specialization effect on the other rule for daughter. the choice of the integrity constraints is not independent from the rules of the theory and part of the difficulty is to find the  relevant  constraints that would compensate correctly for the rules of the theory. 
　summarizing  the integrity constraints can sometimes provide implicitly the required specialization of the defining rules without the need of explicit negative training data. they effectively form additional implicit training data for the explanatory part of the problem allowing us to learn from positive data only. in addition  the integrity constraints offer new possibilities of specialization of the rules when these express regularities of the concept with other predicates not directly involved in the definition of the concept. 
1 	learning algorithms and experiments 
several approaches to developing learning algorithms in the integrated framework are possible. one is to separate the generation of the two components  rules or constraints . a top-level description of an algorithm that generates the rules first  which then drive the rest of the learning process  is: 
algorithm 1 
find a set of rules r that cover all + ve examples; decide-bias-of-ics r  e; bias ; 
generate-ics  bias  e; ic ; choose-ics  ic  r e;c ; 
return 	 r c ; 
　after the first step that generates the rules of the theory  the algorithm goes into a constraint generation and selection phase. we first select the general ic schema ta   or bias  that will be given as input to the descriptive inductive procedure. we have identified two types of analysis that help decide on the bias  a  analysis of the form of the rules  b  analysis on the examples misclassified. other information that helps in finding an appropriate schema for the constraints is their complexity  roughly the number of literals they involve  and 
	d1mopoulos  dzeroski  & kakas 	1 

more importantly their independence from the existing rules  i.e. they should not be subsumed by the rules . in the experiments we report below we have restricted this kind of analysis to constraints of the form literati  - concept literal1 or literall  - concept  subbody-of-rule  literal1 where literall is a literal which can be the  false  literal and literal1 is a conjunction of up to 1 literals. 
then we call a descriptive system that generates constraints with the decided bias. in our experiments we have used the claudien system which offers a strong declarative language for expressing the bias. the last step in the constraint computation phase is to choose among the constraints produced by the descriptive system  those that will be actually added to the theory. here we use a combination of the usefulness of the constraints in specializing the theory  the number of negative example misclassifications they correct  together with descriptive criteria  e.g.  the degree of applicability in the data. 
　in algorithm 1 above  the generation of rules is done outside the process of generating the ics of the theory. in an  interleaved  approach the generation of rules and ics are combined together and one dynamically influences the other. constraints again offer an extra possibility of specialization. 

　the procedure extended-specialization  r; r'  nic  can use either the normal specialization step of adding a new literal in the body of r or call on a descriptive ilp algorithm to generate more constraints nic. as above this will involve deciding on the bias of constraints to look for and choosing amongst the generated ones. the form of the integrity constraints can now be more specific relating strongly to the rules they are trying to specialize. the general bias of the constraints again follows the schema literall  - concept  literal1 where literall can be the  false  literal. 
　another possibility is to generate  and select  in a first phase the integrity constraints and then use these in a second phase of rule generation. the integrity constraints are used primarily as additional  negative  training data and thus this strategy is particularly appropri-
1 	learning 
ate for problems where there is no or limited explicitly given negative training data. a top level shell for such an algorithm is the following: 
a l g o r i t h m 1 
generate a set of ics c; 
 use descriptive criteria e.g. degree of applicability  repeat 
generate rule r; 
while  and not satis f r  c  
specialize-rule r ; 

until all positive examples are covered; 
c' := set of ics violated by the generated rules; return  r' c' ＊ 
　note that here specialization of the rules does not come form the negative examples only  but also from the ics that are violated. these constraints force the specialization of a rule until either some minimum threshold on the number of positive examples that it covers is reached or the integrity constraints are indeed satisfied by all the consequences of the generated rule. if the constraints can not be fully satisfied within the threshold  they are returned in the output. the generate-rule and specialize-rule are the usual procedures from top-down normal ilp algorithms. 
1 	i n i t i a l e x p e r i m e n t s 
we report here on some initial experiments with integrated learning  the main purpose of which was to provide an initial confirmation of the theoretical ideas and a basis for the future development of a system for integrated learning. 
　several experiments were carried out on the real-life problem of characterizing river water quality. the task is to interpret a biological sample taken from a river in terms of five quality classes  see  dzeroski et al  1  . a fact of the form family x   resp. family x  a   indicates that the bioindicator family is present in sample x  resp. at abundance level a . the five classes are denoted class1 x  to class1 x . several machine learning systems have been applied on this problem  including cn1  clark and boswell  1   claudien  de raedt and bruynooghe  1  and golem  muggleton and feng  1 . making use of abundance level data cn1 achieves accuracy of 1 on unseen cases  while without abundance levels it achieves 1 accuracy. claudien and golem were only used to generate rules from the entire dataset. in the following  a theory correctly classifies a sample if it predicts the correct class  and no other class is predicted by it. this is different from the classification procedure in cn1  which adds the numbers of examples of each class covered by each rule applicable to 

an example. the majority class is predicted by cn1 if no rule applies. 
　starting from a set of rules that golem induced from data with abundances  we have tried  following algorithm 1  to specialize and complement these rules with integrity constraints. in fact  in this process a different analysis for the different classes is appropriate. we concentrated only on the first three classes  since golem rules for the last two classes are not available. the bias for constraints for classl was generated by analyzing the actual golem rules of classo and classl. four constraints  e.g.  ancylidae x   clas1l x  perlodidae x   were selected which can correct the misclassification of classo examples as classl examples while at the same time not affecting significantly the correct classification of classl examples. in contrast  for class1 constraints  the bias was found by analyzing the actual misclassifications of other examples as class1. the results were similar to that for classl. overall  a small number of constraints were generated and the performance of the integrated theory was comparable to that of the rules alone with just a marginal improvement. this was expected due to the very specific nature of the golem rules. the point to note though is that the constraints learned form complementary information to the rules as they do not affect the coverage of the correct class examples. in fact  some of these constraints were useful in the other two experiments. 
experim. 1 accur. experim. 1 accur. original cn1 rules 1 original 
golem rules 1 cn1 rules without naf 1 golem rules without abund. 1 cn1 rules without naf + ics 1 golem rules without abund. + ics 1 j 	table 	1 
　the next two experiments  see table 1   that also concern the first three classes  involve learning a theory from training data with information only on the presence or absence of each family  no abundance levels . in the first experiment we started with the cn1 rules whose accuracy was found to be 1 on unseen cases  compare this to the 1 accuracy of the same rule set under the cn1 classification procedure  and removed all naf literals form these to produce an overgeneral theory. the task was then to specialize these rules with appropriate constraints by following algorithm 1 and applying the same types of analysis as above for generating constraint bias. it was again possible to learn an integrated theory whose accuracy  1 on testing examples  is comparable to that of the full cn1 rules with naf although this time more constraints were necessary. 
　in the second experiment  we removed the abundance information from the golem rules discussed above to produce an overgeneral set of rules. examples of these rules are: class1 x   chironomidae x   heptageniidae x  perlodidae x  for classo  classl a  - ancylidae a   erpoddellidae a   hydropsychidae a  for classl and class1 a   asellidae a   erpoddellidae a   physidae a . to specialize these rules  we used some of the constraints from the first experiment  together with some new constraints that were added because negative examples were still covered by the theory. examples of these constraints are: false  - classl x   leuctridae{x   physidae{x  and lymnaeidae x   - classl x   asellidae x   gammaridae x   corixidae x  restricting classl and false  -- class1 x   heptageniidae x   perlodidae x  and baetidae x   -- class1 x   hydrobiidae x   leptoceridae x . most of the new constraints were selected based on the number of misclassifications they correct. the resulting theory has accuracy 1 on unseen cases. this compares well with the accurary of 1 of the original golem rules as these rules were generated from the whole data including the testing data. 
　the overall conclusions drawn from these experiments is that it is indeed possible to generate complementary information in the form of constraints with comparable accuracy as that of a given explanatory theory. furthermore  it is possible to learn simpler overgeneral explanatory rules  which when augmented with constraints in an integrated theory have comparable and sometimes better accuracy. 
1 	conclusions and related work 
we have presented a new framework for learning that integrates explanatory and descriptive learning. this framework allows us to synthesize complementary information from the same learning data by applying interactively both explanatory and descriptive learning methods and is particularly useful when the given learning problem is incompletely specified. 
　the need to strongly integrate learning of rules and integrity constraints  ics  was proposed recently in  dimopoulos and kakas  1  in their study of the relationship of abductive and inductive reasoning. as mentioned though in the introduction  ics have been often used in explanatory ilp. the interactive theory revision system clint  de raedt  1  introduced the use of ics in explanatory ilp. intermediate revisions of the theory are tested for consistency with the ics  and further revised if found inconsistent. 
　most explanatory ilp systems that learn starting from an empty theory on the target predicate s  do not make use of ics. the monic-skilit system  jorge and 
	dimopoulos. dzeroski  & kakas 	1 

brazdil  1  is a notable exception. clauses proposed for addition to the theory are checked for consistency with the ics. this is done in a stochastic fashion: a number of consequences of the theory are randomly generated; if none of these violate the ics the theory is considered consistent. 
progol  muggleton  1  learns from entailment. 
while it has been mostly used to learn definite clauses  it can also learn integrity constraints in the form of denials. claudien    de raedt and bruynooghe  1    de raedt and dehaspe  1   learns from interpretations: it takes as input a set of interpretations p and learns a set of constraints c that hold in each of the given interpretations. icl  de raedt and van laer  1  takes an additional set of interpretations n requiring that at least one constraint in ic is violated by each interpretation in n. 
　to sum up  some explanatory ilp systems can take into account ics given by the user. these are used in the learning phase  but seldom  if ever  together with the learned rules of the theory. on the other hand  ilp systems that can learn constraints do not use them  if at all  as constraints in their coverage  classification  relation as we are proposing in this paper. 
　several issues remain for future work. on the theoretical level the relationship with nonmonotonic reasoning needs to be explored further to study problems of learnability and compactness of the learned theory in this new framework. on the practical level  the development of an integrated learning system is needed for the application of the framework to other real life problems. 
acknowledgments 
part of this work was supported by the european project 
esprit iv no 1 ilp1 and the graduiertenkolleg  menschliche und maschinelle intelligenz   university of freiburg. 
