 
the quantity of resources that an agent expends in solving problems in a given domain is determined by the representations and search control strategies that it employs. the value of individual representations or strategies to the agent is determined by their contribution to the resource expenditure. we argue here that in order to choose the component representations and strategies appropriate for a particular problem domain it is necessary to measure their contribution to the resource expenditure on the actual problems the agent faces. this is as true for a 
system designer making such choices as it is for an autonomous mechanical agent. we present one way to measure this contribution and give an example in which the measure is used to improve problem solving performance. 
1 	introduction 
a primary goal of artificial intelligence research is to enable automated agents to have general reasoning abilities over a wide range of domains. due to the inherent computational complexity of this task  system designers make performance choices that trade generality for improved resource use. such 
p
erformance choices are necessary for any agent with 
 limited amounts of space and time to be effective within a dynamic world. most running ai systems have embedded within them the choices that their designers felt would maximize their usefulness. unfortunately  such choices rely on hidden assumptions  such as what variety and frequency of problems will be encountered  or now correct or close to optimal the eventual solution should be. often  the designers themselves may not know what these assumptions are  since they are further obscured  for example  by choices implicit in the implementation of the representation language  or by insufficient prior information on the range of problems that the system may encounter. unfortunately  this makes it difficult 
this work was supported in part by the nih public health 
service under grant 1 r1 ns 1  by the national science foundation under grant dcr-1  and by the air force 
systems command  rome air development center  griffiss air force base  new york 1  and the air force office of 
scientific research  boiling afb  dc 1 under contract number f1-c 1 which supports the northeast artificial intelligence consortium  n aic . 
the authors would like to thank the xerox corporation university grants program for providing equipment used in the preparation of this paper. for other researchers to determine if the tradeoffs are appropriate for their problem domain. 
in this paper  we argue that performance choices should be made explicit in order to establish measures with which different choices can be compared. further  we provide an example of how this might be done by developing a cost metric defined over search control strategies. 	the short- term benefit of this approach is that system designers will have a formalism which can be applied in determining preferred performance choices for the problems they are solving. the longterm benefit is that an automated agent will have the ability to evaluate its success in satisfying its goals in comparison with other candidate control strategies. 
1 	intractability 
intelligent agents perform computations upon an internally stored representation of the world. 
examples in  levesque and brachman  1  show how the choice of representation language bears on the computational complexity of solving problems using that language. as they point out  reasoning systems  will either be limited in what knowledge tney can represent  or unlimited in the reasoning effort they might require.  for example  if we use a first-order predicate representation language  then there exists no algorithm that will decide for any theory t and sentence s encoded in this language whether s is a theorem of t. however  it might be the case that a 
particular theory t in which we are interested can be encoded within a weaker representation  such as finite automata. then there exist algorithms of bounded computational complexity that will answer most questions with regard to this theory  such as if a string is accepted by the automaton. unfortunately  no algorithm exists that decides whether some first-order theory can also be expressed in a weaker representation language. 
we will say that a problem p is intractable if there is no expression language l in which to state problem instances of p sucn that there is a deterministic turing machine that can compute solutions to such instances within polynomial time and space. the following  a version of the travelling salesman problem  is an example of a problem believed to be intractable. imagine that an agent finds itself in a city and is given a set of n buildings to visit  along with information as to the distance between each pair of buidings. the question to determine is whether the agent can visit each building exactly once on a path no more than k units long. it is possible that the agent can answer this question quickly for some given set of parameters  but 
	hartman and tenenberg 	1 
it is believed that there is no deterministic algorithm  serial or parallel  that will solve every possible instance of this problem within an amount of time polynomial in the number of buildings in the problem. note that this is not a function of the representation  but of the problem  since it is believed that there exists no representation for which this problem is tractable. many problems that agents are called upon to solve are intractable. 
the fact that an agent will encounter difficult problems does not mean that the agent should make no attempt to solve them. but in order to perform effectively  an agent must reason not about whether it can solve all possible problems optimally but  rather  how it can maximize resource use over the entire sample of 
problems that it will encounter. in order to do this  we believe that defining notions of problem class and 
resource cost is essential. 
1 	problem classes 
standard complexity theory typically defines a problem class in terms of the worst-case time or space behavior of a particular computational model  as a function of the size of the input problem. for example  the travelling salesman problem mentioned above falls in the class np-time  which means that there is a 
non-deterministic turing machine that solves every instance of a travelling salesman problem within time polynomial in the size of the input. the fastest known deterministic turing machines for these problems take at least time exponential in the size of the input. unfortunately  it is not known whether there are faster deterministic algorithms. it is in fact quite difficult to determine what is the fastest algorithm one can construct for a given problem. 
there are several aspects of this definition of class which are inadequate for the task of optimizing an agent's use of its resources. first  each input problem instance to an algorithm is assumed to be in the correct form so that all operations of the algorithm are defined. for example  a typical sorting algorithm requires a list of elements from a set as input. the interpretation of this data structure is implicitly defined by the algorithm. intelligent agents  however  are required to determine from general representations of its input which specific type of problem its input is an instance of. for example  if an agent has the goal of ordering a set of objects  it must recognize that this is a sorting problem and that there are algorithms for solving such problems. the difficulty of this recognition task will be a property of the language in which sorting problems are expressed. 
second  worst-case behavior is often too pessimistic. in practice the worst case may occur infrequently. third  there might be restrictions one can place on the input that allow a subset of the problems to be solved quickly. for example  in the travelling salesman problem  if the cities are known to be collinear  then the solution can be trivially generated. typically  general algorithms do not attempt to determine if the given input falls within one or the easier restricted subsets. 
class if the algorithm solves that instance.we can assume that any complex agent will be called upon to solve a variety of tasks  some as easy as finding the largest element from a set  and some at least as difficult as the travelling salesman problem. if a domain is encoded using a general representation for which there exists an algorithm capable of solving each problem expressible in this representation  then we can consider an agent using this algorithm as solving problems from a single class. that is  every problem that the agent encounters falls within the large problem class defined by the algorithm. 
many algorithms fail to distinguish between tasks of various difficulties  as was noted earlier with the travelling salesman problem. due to the general nature ofthe algorithms  a high computational cost is incurred when solving both the easy and the hard tasks. taking a more general example  suppose an agent's domain is represented in the first order predicate calculus  and the agent is able to solve each problem it is presented  i.e.  each theorem to be proven  using a complete proof procedure. unfortunately  these proof procedures take greater than exponential time in the length ofthe input to generate a proof in the generalcase  if a proof exists. assuming that some of the input problems involve finding the largest element from a set  the agent is expending considerably more resource than necessary to solve these problems using the general proof procedure. that is  it the agent were able to distinguish these problems at low cost  then the agent could use one of the known polynomial time algorithms for their solution. this fact motivates the use of  for example  procedural attachment in theorem proving  nilsson  1 . 
an agent  then  can be provided with a repertoire of algorithms  each one optimized to a particular set of problems. the agent can be considered to encounter problems from a variety of classes - one problem class for each algorithm. unlike the standard complexitytheoretic model where the algorithms are never required to distinguish between the various restricted subcases  we assume that complex agents will be obliged to do so. there will therefore be a cost associated with determining into which class a given input problem falls  i.e  which algorithm should be used to solve the problem. there might thus be no computational advantage to an agent in having a large repertoire of algorithms. the usefulness of a member algorithm will be a function both of the frequency with which problems falling within this algorithm's class are encountered by the agent  and of the comparative costs of solving problems using this algorithm versus other candidate algorithms. by considering the entire set of encountered problems as falling into a variety of problem classes  the statistical properties of the various classes can be exploited to improve performance. a faster running time of an algorithm whose class occurs with high relative frequency will improve the overall performance of the agent. the longer a period of time over which an agent solves problems  the greater will be the gains from the algorithm optimization  assuming the relative frequencies remain invariant. hence such sustained problem solving activity justifies the expenditure of 

we will consider a much weaker notion of problem class. in general  an algorithm will define a problem class  in tnat a problem instance is a member of the 
1 	knowledge representation 

resource to perform the optimization. 

1 	costs 
there are few precedents in ai that involve measuring costs. one example is the a* algorithm  nilsson  1 . a* is an algorithm for searching a state space  described by an initial state  a goal state  and the legal transitions between states  which computes a path between the initial and goal states. this algorithm has the characteristic that it is admissable  meaning that the first path it finds that solves the problem will be of minimum length  if any solution patn exists. the algorithm works by searching through the current least-cost transition  where cost is a function of the number of transitions already taken on that path  and an estimate of the number of transitions required to reach the goal along that path. this cost  therefore  only measures the length of the solution. a* makes no attempt to model the resources required to arrive at a state  which includes the resources expended on the other incomplete or failed attempts up to that point in the computation. it is just such a measure of total computational costs that we are attempting to model. this replaces search for minimal length solutions with search for minimal resource use solutions. 
a* places a premium on the optimality and correctness of every solution it reaches  which makes it generally un suited for the task of searching through complex domains. it will typically be cost-effective for an agent to trade some degree of minimality  completeness and correctness of the solution for a speed-up in the time required to compute it. for example  several polynomial time algorithms have been constructed that find sub-optimal solutions to np-complete problems  garey and johnson  1 . many of these algorithms are such that the larger the upper bound on the acceptable distance between an approximate solution and the optimal solution  the taster the algorithm returns one of these approximate solutions. 
augmenting the symbolic approach of ai by decision theoretic techniques is suggested in  feldman and sproull  1 . it is argued there that for many problems in ai there are natural numeric measures of cost and that it is only on the basis of such measures that good decisions can be made. that is  a decision theoretic form is an appropriate representation for certain problems. in the search for a solution to a problem instance  the paper discusses how to select between alternate plans  how to deal with the uncertainty of the outcome of plan steps and how to introduce knowledge producing actions into plans. the basic mechanism is to compute the expected utility of a problem instance's candidate solutions. our goal here is to investigate the expected utility  or more specifically  the expected computational expenditure  of a problem solving strategy over an agent s entire sample of problem instances. similar to choosing  from a set of candiates  a solution that maximizes expected utility  we intend to choose from a set of candidate problem solving strategies one that maximizes expected computational cost. 
also discussed in  feldman and sproull 1  is the utility of additional planning. if an agent possesses a solution to a problem then in order for further planning effort to be profitable  the improvements in the solution must offset the additional cost. in a similar way the measurements and computation required to determine the expected computational cost of a strategy must be offset by the performance improvement that results from this improvement. 
as mentioned earlier  finding lower bounds proofs is difficult for people  and will certainly be so for automated agents. this means that most agents will rarely be able to prove that they are doing the best possible. therefore  it will usually be in the interests of an agent  and its designer  to express its performance choices in such a way that measuring the efficacy of these choices is possible. this requires considering all resource expenditure as cost  and expected improvements of one strategy over another as benefits. we claim that for agents who are called upon to make decisions in domains containing intractable problems  performance choices can only be made with respect to the sample of problem instances that an agent encounters. whereas a particular performance choice may work quite well for a given problem sample  it may give equally poor performance for another sample. that is  agents cannot solve all problem instances optimally within such domains. by making the performance choices explicit  it is possible to evaluate whether a given choice is a good one for a particular sample. thus  one is able to exploit any information about the sample of problems that is believed will be encountered in the future. although the properties of future problems are unknown  predictions can be based upon the sample of problems that have already been seen. one of the long-term objectives of the approach advocated here is to state in a domain independent fashion those invariant properties of a particular domain or sample of problems that justify the belief that one has a good algorithm for the domain. such domain independent properties also provide 
justification for applying the algorithm to other domains that are similar to the original domain with respect to these properties. additionally  future performance improvements may also transfer across these similar domains. 
1 	definitions 
this section defines a cost metric for problem solving that illustrates some of the points raised above. this metric corresponds to the expected cost per problem that an agent expends. the metric is based on problem classes and the relative frequency that a given problem is a member of a particular class. the solution strategy used by an agent partitions problems into equivalence classes. one of these equivalence classes is intended to correspond to a set of problems of comparable difficulty or computational complexity. the cost metric makes clear how classes of difficult problems increase the expected cost and how an agent can exploit the presence of a class of easy problems. 
we take the agent to consist of a search strategy. the agent exists in an environment in which problems are presented to it one at a time. the agent's response to the current problem is a solution to that problem obtained by the search strategy. we assume that the statistical properties of this seauence of problems presented to the agent are fixed. specifically  we assume that the probability of members of a problem class being presented to the agent are constant and 
	hartman and tenenbarg 	1 
that this probability is asymptotically approximated by the relative frequency of the problem class. 
let x be a countable set of problems. the problem instances that are presented to an agent are members of x  let p be the set of solutions that correspond to the problems in x. we intend that p have a flexible interpretation. the members of p may be  for example  
literal solutions as a sorted list is the solution to a sort problem. alternatively the members of p may be algorithms that generate such literal solutions. however pis interpreted  the agent's problem-solving strategy selects members from p. without loss of generality  every problem in x is assumed to have a solution in p. for the present purposes we also assume that whether a member of p solves a member of x is decidable. 
1 	knowledge representation 

approximations to a complete algorithm to find motion 

1 	example: a hybrid algorithm 
having defined a measure of computational cost  the question arises as to how it may be used. the following example illustrates the use of this measure to improve performance. a problem solution strategy is defined such that  given a problem  it selects an algorithm whose output is the solution to the problem. from a family of such strategies we show how to choose the optimal one according to the performance measure. 
consider a sequence of algorithms a1 a1 ... an  each member of which terminates on all input  takes as input an encoding of a problem and yields as ouput a 
solution to the problem or an indication of failure. let the sequence have the additional property that any member of the sequence solves at least all of the problems of its predecessor. we refer to this property of a sequence of algorithms as the subsumption property. a specific instance of such a sequence of algorithms can be constructed to address the motion planning problem in robotics. the motion planning problem  e.g.   lozano-peres  wesley  1   is to find a collision free path for an object from an initial position to a desired final position. for an object b  if we have a sequence of object approximations b1 b1 .. bn -b and a motion planning algorithm m  we can specialize m by each of the bi's to yield m1 m1... mn so that mi computes paths only for bj. that is  mi computes paths for the ith approximation of object b. if b; strictly contains its successor in the sequence and if m is suitably wellbehaved then the mi's have the subsumption property. that is  since mi uses an approximation to the object that is bigger than that used by mi + /  mi; can only find a path if mi +1 does  figure 1 . 
we are appealing to the intuition that giving up detail and completeness  i.e.  the property that a solution is found if one exists  enables us to obtain more quickly the solutions we do find. in ascending order the bi's are increasingly better approximations to the original object. similarly  the mi's are increasingly better 
plans for the original object. in this instance we may profit from giving up the precision of a complete algorithm by being able to use representations of lower combinatorial complexity. 
now let the search strategy s be such that  given a problem  s applies the a;'s in turn until one of the aj's returns a literal solution to the problem. such a search strategy  which we will refer to as a hybrid algorithm  is unambiguously specified by its component algorithms. intuitively s has generality and also exploits the presence of simple problems. the strategy s can be as general as we want by appending to the sequence the most general known algorithm. in particular  s can be made complete if a complete algorithm is known. because the simpler and  presumably  faster approximation algorithms are applied first  s solves easy problems quickly. to some degree a hybrid algorithm invests an appropriate amount of effort in solving a problem instance. 

	hartman and tenenberg 	1 


in addition to obtaining a globally optimal set of component algorithms for a particular problem sample  we can also determine under what conditions an incremental change to s  e.g.  the insertion of a new component algorithm into the sequence  yields an improvement on the expected cost per problem. that is  we know where candidates for future improvements may be found. 
we do not claim that this is the best way to solve any particular kind of problem. the optimization is only within the narrowly defined class of hybrid algorithms. however  the example does show how the cost measure defined in the previous section can be used to optimize performance  in particular  the derformance improvement is independent of the actual representations and component algorithms used. it does not depend on increasing knowledge about how to solve the particular problem such as  in this case  motion planning. the improvement is based solely on the invariant statistical properties of the problem sample and measurement or performance. 
1 	conclusion 
agents in real world domains will be called upon to solve difficult problems. although an agent might choose to expend arbitrarily large amounts of a resource in solving a particular problem  the opportunity costs of doing so typically make such a choice prohibitively expensive. this resource would be better spent in either solving approximations of this problem  ignoring this problem completely and solving other  easier problems  or improving the agent's general ability to solve these difficult problems. this is as true for agents who introspect upon their own problem solving ability as it is for designers who attempt to ascertain the utility of ai systems that they develop. we argue that these performance choices should be made explicit  and that they should be based upon the resource cost incurred in solving actual problem samples. 
1 	knowledge representation 
we have provided one example of a resource cost measure. although by no means definitive  it measures the search costs associated with finding the solution to a given sample of problems using a given search strategy. as opposed to previous formal analyses of search strategies within artificial intelligence  the emphasis here is not upon the efficiency of the solution  as it is in a*  but upon the amount of resources expended in finding solutions. central to this endeavor is the concept of dividing a problem space into a set of problem classes. we can measure both the frequency with which a search strategy places problems from the sample within a class  ana the average cost of solving each problem placed into a class. this allows one to demonstrate improved performance by changing the search strategy to place more of the problems into tnose classes for which solutions can quickly be generated  or to ascertain more quickly into which class a problem belongs. cost measures such as the one described here  will be necessary  we believe  in order to maximize the resource use of an agent which must solve many problems drawn from an intractable class. 
acknowledgements 
we would like to thank our advisor  dana ballard  for his patience and insight  and for the opportunity to do this research. 
