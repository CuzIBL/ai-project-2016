 
problem solving programs that generalize and save plans in order to improve their subsequent performance inevitably face the danger of being overwhelmed by an ever-increasing number of stored plans. to cope with this problem  methods must be developed for selectively learning only the most valuable aspects of a new plan. this paper describes morris  a heuristic problem solver that measures the utility of plan fragments to determine whether they are worth learning. morris generalizes and saves plan fragments if they are frequently used  or if they are helpful in solving difficult subproblems. experiments are described comparing the performance of morris to a less selective learning system. 
1 introduction 
　building problem-solving programs that improve their performance by generalizing and re-using past solutions is one of the goals of machine-learning research. it has been demonstrated that generalized solution sequences  or plans  can be produced by analyzing the constraints inherent in solution instances  1 . this method of learning has been successfully employed in domains as diverse as game-playing  and mathematical problem-solving . 
　one drawback to learning plans is that the number of stored plans may increase quickly as the problem-solver gains experience. furthermore  the applicability conditions of long plans tend to be highly specific. searching through the space of stored plans to find one that is best-suited to the current problem may be as expensive as searching through the original search space. this leads to the following paradox: as the system gains experience it gradually becomes swamped by the knowledge it has acquired. in some cases performance can eventually degrade so dramatically that the system operates even more poorly than a non-learning system. 
　one of the earliest and best-known plan learning systems was the strips problem solver  1 . having solved a problem  strips produced a parameterized version of the solution  called a macrop  by generalizing constants while maintaining the dependencies among the steps in the solution. the macrop might subsequently be used-either in whole or in part-to aid in rapidly solving similar problems. this paper explores how the degradation problem manifests itself in strips-like learning systems. moreover  two methods are considered whereby a 
　heuristic problem-solver may selectively save fragments of generalized solutions in order to stave off degradation. 
1 strips and macrops 
　the generic* term  macro-operator  will be used hereafter to refer to a parameterized sequence of operator applications  eg.: 
constants are denoted by capitalized strings  and variables by lower case strings. the macro-operator shown above describes a series of actions for getting the keys and unlocking  opening  and going through a door.1 
　a strips problem-space consists of a world model  represented by a set of well-formed formulas  wffs  in the predicate calculus  and a set of operators. each operator includes an add-list  a delete-list and a precondition wff. an operator is applicable if its precondition wff is satisfied. applying an operator simply involves making the changes indicated in the add and delete lists. 
　strips  like many other problem-solvers  searched through the space of operator sequences in order to solve a problem. means-ends analysis  was used to guide the search. once a sequence of operators that solved the problem was found  strips produced a macrop by replacing the problem-specific constants in the operator sequence with problem-independent parameters. any subsequence of the macrop could then be used as a composite operator during future planning. 
　fikes et al.  described a series of 1 problems that strips solved more rapidly when macrops were learned after each trial. they claimed that  the search tree sizes 
 were  all smaller when macrops were used and the macrops allow longer plans to be formed without necessarily incurring an exponential increase in planning time . 

the author is supported by an at&t belt laboratories scholarship 

   1 strips's macrops also included information helpful for monitoring execution of the operator sequence in the real world. 

　there appear to be two distinct factors that can contribute to the effectiveness of macro-operators in problem-solving. first  since macro-operators represent sequences of operators  the preconditions and postconditions of the individual operators can be compiled into aggregate preconditions and postconditions for the macro-operator as a whole. therefore it can be quicker to test whether a macro-operator is applicable than to test whether the corresponding sequence of operators is applicable.1 . even more importantly  the use of macrooperators can bias the order in which the search space  of operator sequences  is explored. if relevant macrooperators tend to be considered before relevant operators  then previously successful paths will generally be explored before other paths. this experiential bias can be a significant source of heuristic power. 
　unfortunately  a problem solver that uses macro-  operators in this manner may find that as the number of macro-operators increases  the experiential bias gradually disappears. in the extreme case  if eventually every operator sequence that the problem-solver might conceivably consider in solving a problem becomes a 
　macro-operator  then the ordering advantage will have been effectively negated. 
　in practice  however  only a subset of these sequences become macro-operators. for any given domain  the crucial issue is whether or not the use of macro-operators will effectively compress the search space associated with that domain. if a small set of macro-operators can be generated that  cover  the relevant problems in the domain  then search will be confined within this smaller space. for example  korf's macro problem solver  is powerful enough to generate a set of macros that completely eliminates search  unfortunately  his technique only works for domains that exhibit operator decomposability. with strips  every unique subsequence of all previously acquired solutions is a potential macro-operator; the strips technique for generating macro-operators does not have strong domain requirements  but neither does it guarantee that the search space will be adequately compressed. indeed  it has been our experience that even in small domains  the strips approach can quickly lead to an explosion of macrooperators. for example  in strips even  useless  operator sequences  such as stack x  y  followed by unstack x  y   can become macro-operators due to 
strips's methods of generating and editing solution sequences. 
1 morris: a selective learner 
　to avoid being swamped by too many macro-operators  a problem-solver can endeavor to retain only those macrooperators that are most useful. morris   the finicky learner   is a heuristic problem-solver in the strips 
　1 clever methods for storing macro-operators and ordenng f preconditions may also effect the efficiency of the search  although attention has been given to these issues 
s. minton 1 
tradition1 that demonstrates the importance of selective learning. currently morris saves two types of macrooperators  s-macros and t-macros. s-macros  or  scripts   are frequently used operator sequences. t-macros  or  tricks   are operator sequences for solving difficult problems. 
1 s-macros 
　the strategy of retaining only the most frequently used macro-operators was suggested by fikes et. al.   but never implemented in strips. morris accomplishes this by maintaining a record of the problems solved and their generalized solutions. each time a new solution is acquired  it is compared to the previously acquired solutions in order to locate common subsequences. when two unifiable subsequences are found  the more general of the two subsequences is added to the list of s-macros. 
　a limit is maintained on the number of s-macros kept active by the system. once this limit is exceeded  the smacros that were least-used during their lifetimes are deleted from the active set. the net result of this process is a set of relatively short macro-operators  which is desirable  since the time cost of evaluating whether a macro-operator is applicable can grow exponentially with 
the number of preconditions it has1. 
1 t-macros 
　t-macros are macro-operators that represent  nonobvious  solutions to difficult problems. the notion of non-obviousness is defined by morris's heuristic evaluation function  called hdiff. hdiff is used to estimate the progress that an operator  or macro-operator  makes with respect to the current set of goals. at each node in the search tree  morris collects the relevant set of operators  and macro-operators  for extending the current path and evaluates them with respect to hdjff. since morris employs a best-first search through the tree  operators that appear to make the most progress are considered before less promising operators. 
　in evaluating the progress made by an operator  hdiff takes into the account the number of goals that remain to be solved as well as the criticality of each of these goals. a criticality value is a difficulty estimate assigned to each literal  i.e. potential goal  in the domain . higher criticality goals are attacked before goals of lesser criticality.  generally one literal is given a higher criticality value than another literal if achieving the first literal typically undoes the second literal.  
   although patterned after strips  morris operates within a closed world  and therefore uses matching rather than theorem proving to test whether the preconditions of an operator are satisfied. 
   1 there is generally a linear relationship between the average number of preconditions and the length of a macro. 
1 	s. minton 
　occasionally the values given by hdiff will be misleading; if the real solution path is estimated to be less promising than alternative paths  morris may be led far astray in its search. for example  consider the situation depicted in figure 1. paths a and b appear to be productive  but eventually lead to dead ends. path c  despite its unpromising rating at node no  actually leads to a solution.  the heuristic is of the hill-climbing variety; up indicates apparent progress towards the solution.  in such cases  the mistaken estimate may be uncovered only after many alternatives have been explored  since morris uses a best-first search to traverse the search space. 

figure 1: misleading path ratings 
　the operator subsequence from node no to node n1 is locally anomalous. its initial segment appears to make no progress  but the subsequence as a whole is rated as advantageous. parameterizing and saving this 1-step operator sequence as a t-macro will enable morris to avoid similar pitfalls in the future. if the goal at node no is encountered again  morris will evaluate its relevant operators as usual  but now the saved t-macro will be among them. consequently  a more accurate heuristic estimate of this path will be generated. this strategy helps morris avoid states which  in hill-climbing terms  are local maxima. 
　t-macros are also relevant to problems involving interacting goals. many well-known problems fall into this class; for example  a robot planning problem might require the robot to move a box from a room and turn off the light to the room. if the robot first tries to turn off the light  it will not be able to move into the room to get the box. because the two goals interact  ordering considerations are important. 
　if morris finds that re-ordering goals succeeds in solving a problem that could not be solved otherwise  it must be the case that that some interaction between these goals occurred. the eventual solution to such a problem will always include a locally anomalous subsequence. this happens because re-ordering goats corresponds to attacking a lower criticality problem before a higher crtticality problem  usually an unproductive undertaking   and consequently a low hdiff rating is generated at that point. 
　once the solution is found  morris identifies the goals involved in the re-ordering and constructs a t-macro in the normal fashion. t-macros of this type are particularly effective  since their use can be restricted to situations where the combination of these goals reoccurs.1 
1 experimental results 
　in order to compare the effectiveness of morris against a less-selective learner  a problem-solver called max was constructed that closely follows the strips philosophy of saving all usable macro-operators. as does strips  max generalizes the entire solution sequence whenever a problem is solved  and considers all composable subsequences to be potential macro-operators. max's procedures for saving  editing  and eliminating subsumed macro-operators are all modeled after those used by strips with macrops. 
　once an operator  or macro-operator  is determined to be relevant to the current goal  both max and morris use the same method to instantiate the operators. the bindings necessary to produce the relevant additions are first substituted into the operator's precondition list and then a partial-matching process is instituted to find potential instantiations. since the time cost of the matching process is sensitive to the ordering of the preconditions  the matcher re-orders the preconditions to decrease the cost. furthermore  during the matching operation  partial instantiations with many unsatisfied conditions may filtered out if the number of potential instantiations grows exceptionally high. each instantiation produced by the matcher is then evaluated by hdjff. 
　max and morris are identical programs with respect to their method of exploring the problem space. since both programs employ a best-first search  misleading heuristic estimates can be costly. the only difference between them is in the types and numbers of macro-operators saved. 
　max and morris were compared in a robot world consisting of 1 operators. this world is similar to the strips experimental domain  but is richer in that many interacting problems can occur. there are 1 rooms  and operators for going to objects  going through doors  standing on  picking up  stacking  unstacking and putting down objects. boxes can be pushed to various locations. objects can be fixed and broken with various tools. lights can be turned on and off  doors can be opened  closed  locked and unlocked. food can be eaten. sample problems include the following:  go into room1 and lock the door to room1 ;  push boxa and boxb together and stand on boxa ;  take the keys from rooml to the room1 . 
　the experimental results for a sampling of problems from a series of 1 are shown in table 1. the table includes results for morris  max  and a non-learning problemsolver that uses hdjff but does not save any macrooperators.  the non-learning program is a stripped down version of morris . the timing data does not include the time taken to generalize macro-operators  only the time necessary to find a solution. typically  the learning time is considerably less than the search time. 
   1 presently  morris does not attempt to fully analyse why the interaction occurred. in order insure that application of the t-macro is restricted to circumstances under which the interaction occurs  a slightly weaker form of generalization is used whereby identical constants in the goals are replaced by single variables. 

* no solution generated within 1 cpu seconds 
table 1: experimental results 
since small variations in the problems can cause large differences in performance for each of these systems  table 1 is only partially indicative of their relative abilities. however  some points do stand out. 
　the benefits attributable to morris's strategy of selectively saving macrops are revealed by the smaller number of branches   relevant operators and macrooperators   that were evaluated by morris during each search as compared to max. saving fewer macrooperators did not hurt morris's overall performance. consider  for example  that in solving problem 1 max and 
morris followed the same path to the solution  but max evaluated more alternatives along the way. the problem with max is that it gradually loses the efficiency advantage provided by hdiff. whenever hdiff indicates the correct branch  max will waste considerable time instantiating many macro-operators  in effect  performing look ahead. whenever hdiff is wrong  morris will be as well prepared as max assuming the appropriate t-macro has been saved. 
　compared to the non-learning problem-solver  morris generally performed better. admittedly  the sequence of problems was arranged so that the smaller problems were presented first. in many cases  the t-macros learned while solving these earlier problems were necessary for solving later  more difficult problems. once a wrong path was taken by the non-learning program  recovery was impossible to achieve if the number of alternatives was very high  as was typically the case in complex problems. 
　in the later stages of the experiment  the contrast between max and the non-learning program became evident: if the non-learning program could find a solution to a problem  it generally did so more quickly than max. because max was busy performing look-ahead at each node  by evaluating all the relevant macro-operators   it it could not take full advantage of hdiff in pruning the search. 
　overall  the results confirm our expectations. morris's t-macros appeared to extend the heuristic advantage 
	s. minton 	1 
provided by hdiff  resulting in a significant improvement in problem-solving ability. s-macros were more frequently useful  but resulted in less significant gains. occasionally the extra time necessary to test for the applicability of smacros slowed morris down enough so that the non-
learning system performed more efficiently  in either case  the extra computational expense incurred by saving these macros was more than offset by their benefits. we have yet to perform extensive experiments comparing t-macros and s-macros. 
1 conclusions 
　the approach to learning embodied in morris is rather unusual  since we have focused on the issue of  what to learn   rather than  how to learn  . this issue can be crucial for a macro-operator learning system; if the acquisition of macro-operators is unbridled  the size of the search space defined by the set of macro-operators may grow rapidly  approaching the size of the original search space. 
　the two strategies morris employs for evaluating the worth of a macro-operator have been found to be effective in controlling the learning process. using these strategies  morris maintains a balance between its reliance on knowledge  and its reliance on search. 
　in the future we hope to improve morris by having it explicitly reason about the utility of control knowledge in order to direct its learning. we suspect that as machinelearning becomes better understood  the problem of deciding what is worth learning will assume greater importance. 
1 acknowledgements 
　the author thanks jaime carbonell for his many contributions to this research. 
