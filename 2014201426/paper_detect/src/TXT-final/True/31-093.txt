 
computational ecosystems are large distributed systems in which autonomous agents make choices asynchronously based on locally available information which can be uncertain and delayed. they share these characteristics with biological ecosystems  human societies and market economies. we show that  even when designed with a single overall goal in mind as in the case of distributed problem solving  computational ecosystems can face well-known social dilemmas of sustaining cooperative behavior among selfish agents. specifically  public-goods problems  where a common good is available to all regardless of individual contribution  can arise due to information limitations as well as the commonly recognized incentive conflicts. some techniques for mitigating the impact of these problems are also presented. 
1. introduction 
effective use of distributed computation is challenging since the individual processes or agents must obtain resources in a dynamically changing environment and collaborate despite a variety of asynchronous and unpredictable changes. because centralized control is often unable to respond rapidly to local changes in these systems  the agents are often designed to act autonomously using locally available information. such decentralized systems are often more robust and simpler to design and incrementally modify than those using a central controller. on the other hand  these agents face the difficult task of performing well in spite of incomplete  imperfect and changing information. because these characteristics are shared with biological ecosystems and human societies  we refer to these systems as com-
putational ecosystems  hogg  1; huberman and hogg  
1; gasser and huhns  1; miller and drexler  1; waldspurger et al.  1; wellman  1; white  1 . 
　this analogy between computational and human societies offers suggestions for the appropriate design of agents as well as new potential problems not seen with centralized control or with a small number of agents. in this paper we show that one such problem  namely the social dilemma involved in maintaining cooperation among a large group of self-interested agents  can readily arise even when the agents are designed with a single overall goal. this situation is unlike most studies of distributed artificial intelligence  dai  that consider agents with possibly conflicting goals and focus on designing incentives to encourage cooperation  gasser and huhns  1 . in the situation reported here  social dilemmas can still arise even with full control of the agents' overall incentives. thus issues raised by dai have a broader range of applicability than might initially appear to be the case. while social dilemmas can adversely affect a group's performance  we also show how they can be addressed to some extent with methods used in human societies. 
　this paper is organized as follows. the next two sections summarize the social dilemmas for cooperation and a model for the dynamical behavior of computational ecologies. section 1 gives the main new result  showing how the dilemmas can readily arise in computational ecosystems  even those with a single overall goal  and how this lowers performance. in some cases  this can lead to the paradoxical situation in which giving more resources to the system results in lowered overall performance  as shown in section 1. some possible ways to address this problem  and concluding remarks are given in the remaining two sections. 
1. social dilemmas 
one of the most challenging problems for societies of autonomous agents is providing for public goods  hardin  1   i.e.  benefits produced by the society and available to all of its members regardless of individual contribution. examples of public goods in human societies include provision of parks  roads  a clean environment and national defense. when there is a cost involved in contributing  there is the temptation for agents to free ride on the efforts of others; but if everyone reasons this way  no public good is produced  lb the extent that the individual costs are less than the public good's benefit to the whole group  individually rational behavior leads to an overall suboptimal result this is the social dilemma involved in maintaining cooperation for the production of such goods. 
　while it is easy to see how such problems arise computationally when agents have different goals  rosenschein and zlotkin  1   when there is a single overall goal for 
	hogg 	1 

the system  e.g.  in distributed problem solving  one might hope to avoid social dilemmas entirely by explicitly programming desired cooperative behaviors into the agents. recently  however  it has been recognized that such dilemmas can occur in contexts such as coevolutionary genetic algorithms with a single overall goal  glance and hogg  1 . this is an example of the general mathematical fact that locally optimal actions can result in suboptimal global performance. at the same time  determining the globally superior choice by central fiat may be computationally intractable. in some cases  the optimal state may actually be provably impossible to find within a distributed setting since individual choices will take the system away from the optimum instead of towards it this is the computational analogue of a social dilemma. in this case the dilemma is due to information limits rather than incentive problems  but has the same detrimental effect social dilemmas stand in contrast to other causes of difficulty in computational problems. for instance  hilly landscapes cause methods such as neural nets  rumelhart et al.  1   simulated annealing  kirkpatrick et al.  1  and greedy heuristics for np-hard search problems  garey and johnson  1  to become trapped in local minima  making the overall minimum hard  but not impossible  to find. despite these observations  one might hope computational social dilemmas are exceptional and so rarely seen in practice. the major new finding of this paper  given in section 1  is that these dilemmas are indeed readily found in computational ecosystems. 
1. dynamics of computational ecosystems 
computational ecosystems consist of agents  with computational tasks to perform  and various resources with which to accomplish their tasks. these resources can include both hardware and software  e.g.  information from sensors  databases and the use of specialized algorithms . a simple model of these societies supposes each agent uses one resource at a time  evaluates its choice at a rate a and selects that resource it perceives to be best based on locally available information. the suitability of a resource can depend on how many other agents are using it  leading to a range of dynamical behaviors including simple equilibria  continual oscillations and chaos  kephart et al.  1 . 
　specifically  the state of a system with r resources at a 
　given time can be characterized by the fraction of agents fi using resource i with 
		 1  
1 
let c  be an agent's cost of using the resource  which can depend on the state of the system. the overall average cost per agent is then given by   this provides one simple measure of global performance for the system and is appropriate for situations in which the agents are each contributing to the result more complex global measures can arise in other situations such as cooperative problem solving in which a single solution is required and so the global performance is determined by the time for the first agent to finish  clearwater et al.  1 . 
　the dynamical behavior  on average  is given by  huberman and hogg  1  
		 1  
where pi  is the probability that resource i will be perceived to be the best one  i.e.  have lowest cost  when an agent makes a choice. note that pi = 1 and that the p - depend on the /  because the resource costs do. the two terms on the right side of eq. 1 are readily understood as 1  a decrease in use of resource i due to agents already using it making choices at a rate a  and 1  an increase in the use of resource i due to agents perceiving it to be the best one when they make their choices. 
　the simplest case is when the agents have full information on their individual costs and there are no delays in the information. in that case they will always select that resource with the lowest actual cost giving pi = 1 when ci is the lowest cost  and zero otherwise. uncertainty and delays in the information give well-studied mechanisms that degrade performance  kephart et al.  1 . here we focus instead on the perfect information case to highlight the suboptimal behavior due explicitly to the social dilemmas. 
1. how dilemmas arise 
having introduced the possibility of social dilemmas and the dynamical model for computational ecosystems  we now turn to the question of how often these dilemmas can be expected to occur. although ideally approached empirically once many such systems become available for study  we can gain considerable insight from examining the kinds of resource costs that will give rise to a social dilemma. specifically  this will happen when the local dynamics does not lead to the globally optimal state even when the agents have perfect local information. in such cases  the performance of the group as a whole would benefit if some agents  cooperated  by making different resource choices even though they would incur higher costs. 
1 theory for linear costs 
consider the situation with r resources and with costs depending linearly on their utilization: 
		 1  
with the vectors c and f having components ci and fi  giving the cost and utilization of the resources. the matrix m specifies how the costs depend on the utilization  and the vector v is a usage-independent contribution to the costs. note that because of eq. 1  the choices for a/ and v are not unique  e.g.  this relation can be used to eliminate fr from the costs so the last column of m will be zero. furthermore  

because agents make choices based on the minimum cost option  when they have perfect information   the results presented here will not be affected by rescaling the unit of cost  i.e.  multiplying each component of m and v by a constant  or by shifting the origin of the costs  i.e.  adding a constant to each component of v. 
the global average cost is given by 
		 1  
from this we see that the linear cost example considered here is particularly useful for investigating social dilemmas: except in degenerate special cases   has only one minimum and so avoids the complication of local minima. the resource usage that minimizes this cost is found by minimizing   where the lagrange multiplier is used to enforce eq. 1. setting all partial derivatives to zero gives the extremum as the solution to 
 1  
with 
 1  
where 1 represents the vector all of whose components equal 1. there are two degenerate cases in which this extremum will not in fact be the global minimum cost. first  while this is the only point where the partial derivatives vanish  it could be a maximum or saddle point instead of a minimum. second  the extremum may not have each fi   1. in either case  the true minimum cost will be found at the boundary of the allowed set of values  i.e.  at least one resource is not used at all. in effect  such systems can be viewed as having fewer resources. 
　by contrast  the equilibrium found by local choices will be where all resources have the same cost so agents will remain where they are  on average. that is c = u1 where u is a constant  which gives cglobal - u. this can be combined with eq. 1 to obtain 
 1  
with 
 1  
whose solution gives the equilibrium state found by local choices  again provided  otherwise  some resources  with relatively high costs  will not be used in equilibrium . 
1 the existence of social dilemmas 
lb see that social dilemmas can be expected quite frequently in computational ecosystems  consider a typical situation in which the cost to use a resource increases with its use  with some fixed overhead  but is not directly dependent on the 

by contrast  the local equilibrium from eq. 1 is fi /ai  =: s + v - vi.-  with cost ci; = s + v  which is also the value of cglobal at this equilibrium in both cases  a negative resulting value for fi  indicates resource i isn't used and the calculation should be repeated without it to find the correct resource use. 
　we thus see that the local equilibrium is globally optimal only if all v - are the same  as was the case in a limited i previous study of the 1-resource case  kephart et al.  1 . otherwise  the local equilibrium point will have wider range of resource use than is optimal. thus we see that generally  even with resources whose costs depend only on their own load  the public goods social dilemma arises. 
a simple example  with two resources  is shown in fig. 1 
with the dynamics given by  and 
	hogg 	1 

. the global minimum cost is at f1 = | but the local equilibrium is at the suboptimal value fi = 1. even though  in this case  the system passes through the optimal state during its evolution  more agents continue selecting to use resource 1. this results in the final state having a higher cost  as shown in the figure. 
　the basic cause of the problem is agents choose based only on their own costs  not on how their actions affect others. for example  if there are 1 agents at the global minimum  i.e.  1 agents using resource 1   then the costs are  and agents using resource 1 are tempted to switch. suppose one agent moves from resource 1 to 1  reducing its own cost by about 1. this move also affects the remaining agents: the cost of resource 1 drops slightly  thereby benefiting the 1 agents that remain there  but the cost of resource 1 increases slightly  harming the 1 already there. the net result in this case is that the increased cost to the agents already using resource 1 outweighs the benefit both to the agent that moved and those remaining on resource 1: the global cost increases slightly. 
1 generalizations 
in the general case with nondiagonal matrix m  we can see that dilemmas will also often arise as follows. in order that eqs. 1 and 1 give the same value for f  we must have 
		 1  
which is a linear equation for v. in general  most vectors v will not satisfy this equation  and hence the global minimum and the local equilibrium will be at different points. thus on very general grounds we can expect the results seen explicitly above for simple diagonal matrices to apply to a wide range of linear cost functions. 
　an example is where resource 1 uses a communication channel controlled by resource 1  so agents using resource 1 incur higher cost when resource 1 is busy with its own tasks and unable to service the requests. such an instance is 
		 1  
which has global minimum at / =  1 1  with cost 1  but local equilibrium at f =  1  with cost 1. to avoid the dilemma  eq. 1 requires that v1 = v 1 - 1 . 
　finally  for the more realistic case of nonlinear cost functions  the analysis cannot give a complete characterization of the dynamics  e.g.  there may be local minima   but can provide some insight. the dilemma will exist  in addition to any problems due to local minima  when the local dynamics drives the system away from the global minimum  even if it is initially quite close. whether this is the case can be determined by expanding eq. 1 around the global minimum  giving a linearized system to which the above analysis applies. because we saw that dilemmas exist quite commonly with linearized costs  this argument shows they will correspondingly exist for many nonlinear problems. how important the dilemmas will be in such cases will depend on how easily the system is stuck in local minima. that is  if there are many local minima  they can be expected to prevent the system from getting near the global minimum at all and hence the existence of a dilemma that prevents convergence to the global minimum will rarely affect the dynamics. on the other hand  systems with fewer local minima  or that have techniques to avoid or overcome them  would be limited instead by a social dilemma. this suggests that an interesting question for future work is to determine the interplay between these effects  and whether strategies that alleviate one problem increase the other. 
1. braess' paradox 
a particularly subtle version of the dilemma is given by 
braess' paradox  cohen and horowitz  1; irvine  1  in which adding resources to a system can actually lower performance. while usually presented in the context of traffic or electric current flow  it has a natural interpretation as selection among resources. a specific example  which corresponds to that considered for traffic and genetic algorithms  glance and hogg  1  is given by the three resource case with the costs 
		 1  
　when only the first two resources are available  p1 = 1 when c1   c1  corresponding to f1   f1  and similarly p1 - 1 when f1   f1. thus  starting from an initial condition of all agents using resource 1  i.e.  f1  = 1  eq. 1 gives and f1 t  = 1 - f1 t  until these values reach 1  at which point they remain at that value. 
　when the third resource is added  each agent finds the new resource has a lower cost and selects it  i.e.  p1 = 1. thus f1 and f1 decay exponentially toward zero increasing the overall cost  as illustrated in fig. 1. 
in our previous notation  this case corresponds to 
		 1  
eq. 1 gives the global minimum at f1 = f1 = 1  f1 = 1 with a cost of  while eq. 1 gives the local equilibrium at f1 = f1 = 1  f1 = 1 with cost cglobal = 1. 
　more generally  when a social dilemma exists  the local equilibrium has a higher cost than the global minimum. hence some additional constraints on the resource use  e.g.  eliminating any use of the third resource in the example of eq. 1  can in fact change the local equilibrium to be closer to  or even reach  the global minimum. thus social dilemmas will always be associated with a seemingly paradoxical 


fig. 1. behavior as a function of time for a computational ecosystem facing resource costs that include braess' paradox. we use f1  = 1 and a = 1. initially there are two resources  but at t = 1 the third resource is added the top figure shows the fraction of agents using resources 1  1 and 1  solid  dashed and gray  respectively . on the bottom is the global average cost cglobal for the system. note that the addition of the third resource causes the cost to rise from its minimum value of 1 up to 1. 
situation in which additional restrictions can result in lower costs. this contrasts with the usual intuition that eliminating some available choices in a minimization problem gives a cost at least as large as that for the unrestricted problem. braess' paradox is particularly surprising in the form given here where an additional constraint of simply eliminating one of the resources is sufficient to lower the cost. 
1. addressing social dilemmas 
having seen that social dilemmas can arise for a variety of resource costs  a natural question is how their effect can be alleviated while still retaining the autonomous local decision-making of the computational ecosystem. 
　a dynamical approach relies on using uncertainty in the agents' evaluation of the costs  which tends to move the system toward equal use of the available resources  kephart et al.  1 . when the dilemma gives an equilibrium with more variation in resource use than is optimal the addition of some uncertainty  either deliberately added to the agents or from external causes  can help to improve the performance. this benefit of uncertainty is in addition to its previously recognized use to improve the stability of computational ecosystems. specifically  uncertainty is 

modeled by adding a normally distributed random variable with zero mean and standard deviation  to the costs as evaluated by each agent. for the case of two resources  this changes the probability that an agent will choose resource 1  
used in eq. 1  to be   where erf x  denotes the error function. when is small agents usually choose the resource with the lower cost  but for large each is chosen with nearly equal probability. an example of the improvement this can give is shown in fig. 1. 
　a second approach to public goods dilemmas  commonly used in human societies  is to introduce mechanisms that enforce contribution  such as taxation. this can be used to artificially change the relative costs perceived by the agents when making choices. an example  shown in fig. 1  is to add an extra cost x to the overused resource. 
　while they can be effective  these methods require finding the correct value for the adjustment which can be hard to determine  especially in a complex  changing situation. hence one would like to rely on the agents themselves to make the necessary adjustments. one such method is suggested by a different approach to the dilemma in human societies: create new markets that  at least partially  restrict benefits to those that contribute. this amounts to privatizing the public good using computational pricing and accounting mechanisms  miller and drexler  1  within computational economies  waldspurger et al.  1 . the resulting prices also provide information on competing uses for resources in a manner similar to that in market economies  hayek  1 . for example  in fig. 1 agents could be required to pay for the use of resource 1 thus encouraging more of them to use resource 1 instead. 
　finally  cooperation can be maintained if the benefits are concentrated in small groups with long-range plans  glance and huberman  1  or if interactions 
	hogg 	1 

are repeated  axelrod and hamilton  1; bendor and mookherjee  1 . there are also a variety of mechanisms to evolve cooperation in such cases  simon  1 . these observations can suggest additional mechanisms for computational ecosystems as well. 
1. conclusion 
we have seen that social dilemmas readily arise in computational ecosystems even when all the agents are designed with a single overall goal. this is a new mechanism that lowers performance  in addition to the previously recognized oscillations and chaotic behavior caused by dynamical instabilities  kephart et al.  1 . since the existence of a dilemma will not always be readily apparent from the cost functions  especially in cases that include nonlinearities  it may be easy to confuse the lowered performance due to a social dilemma with that due to uncertainty or delays in the available information. such confusion could lead to inappropriate attempts to address the problem. 
　in dynamic environments with changing resource availability  e.g.  a new machine added to a network  or cost functions  e.g.  due to a better implementation of a database search  the system could have public goods problems at some times but not others. this is another reason to investigate analogies with human social institutions such as markets that allow local decisions by many agents to respond to these problems in a timely way. 
　finally  social dilemmas can also occur in  coevolutionary genetic algorithms and cooperative problem solving where the usefulness of particular methods depends on choices of other agents  glance and hogg  1 . the results presented here  showing that many cost functions can give rise to dilemmas  suggest they may be common in these situations as well despite their very different dynamical behaviors. thus methods for recognizing and alleviating social dilemmas are likely to prove useful in a variety of multiagent computational contexts. 
acknowledgments 
i have benefited from discussions with n. glance. 
