 
this paper explores a newly developing direction of machine learning called ''socially embedded learning . in this research we have been building an office-conversant mobile robot which autonomously moves around in an office environment  actively gathers information through close interaction with this environment including sensing multi-modal data and making dialog with people in the office  and acquires knowledge about the environment with which it ultimately becomes conversant. here our ma-
jor concerns are in how the close interaction between the learning system and its social environment can help or accelerate the systems learning process  and what kinds of prepared mechanisms are necessary for the emergence of such interactions. the office-conversant robot is a platform on which we implement our ideas and test their feasibility in a real-world setting. an overview of the system is given and two examples of implemented ideas  i.e. dialog-based map acquisition and route acquisition by following  are described in detail. 
1 introduction - socially embedded learning -
 why can children and young animals learn complicated things so efficiently     why can't machine learning systems take off and overcome hard coded systems    in the last thirty or forty years the field of machine learning has developed many effective representation schemes and learning algorithms. although these algorithms have achieved a wide variety of successes and brought about the systems which can recognize speech  human faces  medical diseases  etc.  the learning capability of artificial systems is still far from that of humans. in many explanations which have been proposed to answer the questions  one of most likely is that the machine learning systems lack social relationships with the environment including teachers or other learning systems. 
　in the design of traditional learning systems  learning algorithms are implemented only in the learning systems. no special consideration is given to the teacher or the environment surrounding the system. the learning systems are fed with training data which is prepared by users  and learn simple functional relationships hidden in the data. in other words  only very narrow information channel is maintained between the systems and the teachers. the learning systems are rather isolated from the information-rich environment surrounding them. 
　on the other hand  human children apparently have very dense interaction with their surroundings  especially with their parents. recent research in developmental psychology has been revealing that there is a huge number of innate mechanisms or tricks implemented not only by the learners  babies  children  but also by the teachers  parents  adults   which often function unconsciously and support the children's learning process by maintaining the close coupling between the learners and their environment. 
　for example  as for language development of newborn babies  masataka analyzed the interaction between 1-and 1-month-old babies and their mothers  and reported that mothers unconsciously respond to babies' cooing  the most early stage of speech  by imitating these sounds. babies associated this imitating response with a comfortable  safe feeling  which motivates them to imitate their mothers' sounds. this circle of imitating sound works as a very good training process for making vocal sound. here the most important stimulus is the mother's appropriate response at the appropriate time. 
　we often observe that one of the most important information sources for learning of not only new-born babies but also elder children is the information given from surrounding adults  on the job . giving appropriate instructions or advices at the appropriate time is the most powerful way to teach something. while teaching  adults estimate children's focus of attention and choose the most effective time for giving information. 
　this kind of closely coupled interaction with the environment significantly supports and accelerates children's learning. we call this aspect of the learning process  social embeddedness of learning. here the most impor-
tant point is that the mechanisms are implemented in both learners and teachers. not only learning systems but also the people in the system's environment actively 

participate in the learning processes and play important roles. 
　in the field of artificial intelligence  the importance of such close coupling with environment has been emphasized recently  agre and chapman  1; brooks  1 . terms such as  reactiveness    situatedness'  or  embeddedness in the environment  are used to express such understanding. many trials to build situated intelligent systems have been undertaken and reported  kaelbling  1 . although the importance of such features for learning  one of the most important capabilities of intelligent systems  has been advocated recently  kaelbling  1  it still has not investigated thoroughly. 
　based on these considerations  we have launched a research project for fostering a learning system called  office-conversant robot jijo-1  which has ample interaction with its environment and plenty of assistance from nearby humans  matsui et a/.  1 . the officeconversant robot is a mobile robot which autonomously walks around in an office environment  actively gathers information through close interaction with this environment including sensing multi-modal data and making dialog with people in the office  and acquires knowledge1 about the environment with which it ultimately becomes conversant. 
　our research interest is in investigating and clarifying how the close interaction between learning systems and teachers can help and accelerate the learning processes. what kind of mechanisms are necessary to make the effect emerge   in particular  our interest is not in the learning of lower level functions but in learning at higher levels  such as combinatorial symbolic structure in the environment  and how human teachers can assist the systems to learn. 
　in the following sections we give an overview of the office-conversant robot system  and present two examples of socially embedded learning  i.e. dialog-based map acquisition and route acquisition by following a person. 
1 office-conversant robot 
we chose indoor autonomous mobile robots as a platform of our research for the following reasons: 
  in order to communicate with humans naturally  it is desirable to have a physical body. 
  the ability to move around helps data to be col-lected actively in a real world environment 
  compared with manipulators  the mechanisms of mobile robots are rather simple and easy to control. 
  there are several commercial mobile robot bases available even to the novice of robotics. 
　the conventional application of machine learning in robotics is learning to control complex mechanisms. learning of dexterous manipulation and smooth navigation are typical research issues. however  in our study  learning of controlling is not significant part. in other words  the office-conversant robot is a robot which survives to learn many things  not learns many things to survive. there are many interesting targets to be learned by office-conversant robots  such as 
  the topological and geometric structure of environ-mental space  map   
  the relation between humans/objects/resources and locations  
  the relation between humans and objects or re-sources  
  the relation between humans  and 
  the ontological structure of the office environment. these targets are combinatorial symbolic structures in office environments. learning combinatorial structures is one of the most important challenges for machine learning research. 
　as the robot becomes conversant with its office environment  it can function as an information server in the office. the existence of such a walking dictionary will facilitates smooth communication between members of the office and supports efficient group projects. 
1 hardware architecture 
almost all hardware components are off-the-shelf  figure 1 . we use nomad 1  a three-wheel mobile robot base provided by nomadic inc.  stanford  u.s.a. . our nomad 1 is equipped with 1 ultra sonic sonar ring sensors  1 infrared ring proximity sensors  touch sensors in the robot's bumper  odometrie sensors for measuring running distance and steering angle  and a compass. the on-board computer is an ibm/at with intel pentium  1 mhz  controlled by linux os and connected to a lan through radio ethernet. 
　we added a small microphone  one ccd color camera  an image capture board  an analog radio transmitter for transmitting the speech signals to the host computer  and the japanese speech synthesizer  shaberimbo   commercial product by ntt data co  ltd. . the host computer is sparc station 1 with super sparc 1 mhz x1. 


1
　　the name jijo-1 means  conversance  when pronounced in japanese 

asoh etal. 	1 

1 software architecture 
the control software is organized in a multi-agent based reactor-integrator architecture  matsui et a/.  1 . ten agent modules are formed in a subsumptive architecture  and concurrently running modules communicate with each other in an event-driven manner using unix sockets  figure 1 . some of these modules consist of sub-modules. in each module  several behavior classes are implemented and they are instantiated and invoked by request messages from other modules. with this modular architecture  we can rather easily realize concurrent event processing  which can cope with interrupts caused by exceptional event notification. 
   as is shown in figure 1  all modules are divided into two groups. the lower group is devoted to reactive behaviors such as obstacle avoidance  and elemental motions  go straight along a corridor  turn right at a corner  etc. . image capturing and simple early vision processing  visual tracking with correlation matching   interface with a speech synthesizer  and navigation-related local event  such as detecting an open space etc.  monitor are also included in the group. these modules are implemented on the on-board pc in c. 
　the upper group provides more deliberative goaldirected behaviors such as scheduling multiple goals  goal-directed route planning  and making simple goaloriented dialog with humans. these modules are implemented with euslisp  matsui and hara  1   which is a dialect of object-oriented lisp on the host machine. the speech recognizing module is a hidden markov modelbased  speaker-independent continuous speech recognition system for japanese sentences  itou et a/.  1 . the recognition rate in a previous controlled experiment was approximately 1 % of the spontaneous speech of 1 subjects  1 utterances . because the conditions are not as favorable for our robot  we limited the variety of acceptable speech. currently the robot's vocabulary is approximately 1 words. the dialog control is very simple using templates of dialog patterns. for example  

figure 1: multi-agent software architecture 
a template for asking location is used to extract location names from the speech of humans. some templates for answering to simple questions from humans are also prepared. 
1 socially embedded map learning 
as mentioned above  there are many targets to be learned by the office-conversant robot. the most fundamental one is map learning for efficient navigation in the environment. although our chief aim is for a variety of knowledge about the office environment  we chose this as the first target and implemented two mechanisms for map learning using intensive human assistances. 
　as is well known  many representation schemes of maps have already been proposed. they can be roughly divided into two categories:  occupancy grids   buhmann  1; elfes  1   and finite automat a-based topological maps  kuipers and byun  1; mataric  1; tani  1   which represent the space as a state transition graph. each node of this graph usually corresponds to a specific location or landmark  and each edge corresponds to an elemental movement of the system. 
　we employed the latter one mainly because it does not require accurate global coordinates  and it is more natural for humans to designate the name of a specific place than to designate the x-y coordinate values of the place. to cope with the uncertainty of a real-world setting  we used a partially observable markov model like that of simmons and koenig  1  and cassandra et al  1 . the map is a collection of conditional prob-
abilities 
p stoplocation  	observations start location  	action . 
each probability corresponds to an edge of the state transition graph of the partially observable markov model. in our tentative system  action is one of six elemental actions  go straight  turn right/left following free space  turn right/left following wall  and turn around  observations are running distance and accumulated steering angle during execution of action. they are measuied by odometric sensors. the distribution of these values are approximated by gaussian. observation also includes information acquired from dialog  e.g. location name  when the robot asks a question. 
1 	dialog-based m a p a c q u i s i t i o n 
we implemented dialog-based map acquisition  where the system learns a map through making dialog with human trainers  asoh et al.  1a  1b . in the task of probabilistic map building  the robots' localization of itself was the most difficult part. among its sensors  jijo-1 can use ultrasonic sonars  odometric sensors  and vision sensor  ccd camera  for locating itself in its environmental space. although the vision sensor is the most powerful one  it requires a huge computational cost unless we prepare artificial visual landmarks. with sonars and odometric sensors  only very rough localization can be achieved. accumulating the uncertainty of location 

seriously prevents the system from efficiently learning the map  dean et a/.  1 . 
　here is the first point where we introduced the assistance of humans to facilitate the learning process. humans in the office can work as very high quality sensors which tell the identifiable name of the location to the robot. the robot always assesses its certainty about the location and if the certainty falls below some threshold  the robot asks a question to a nearby human. 
　the following is an example of a dialog between a human and jijo-1  actual dialog was in japanese : 
r: where am i   
h: you are in front of dr.nakashima's office. 
r: dr.nakashima's office   
 because the accuracy of speech recognition is not enough high  the robot always confirms human answer. we are planing to use certainty of the recognition to determine whether confirms or not.  
h: yes 
r: where shall i go   
h: please go to dr.hara's office. 
r: dr.hara's office   
h: yes 
r: sorry  i don't know how to go to dr.hara's office. 
h: ok. please go straight. 
r: go straight   h: yes 
r: i ' l l go straight. 
  the robot goes straight till an end-of-action condition is satisfied. normally the end-of-action condition is detecting a doorway or crossing.  r: where am i   
h: you are in front of dr.matsui's office. 
  the robot goes straight but suddenly stops because of detecting a false end-of-action condition  r: where am i   
h: you are on your way. 
r: on my way   
h: yes. 
r: where shall i go   
　at the beginning of learning  the system knew nothing about the topological structure of the environmental space. it can only detect close space  corridor between long walls  and open space  doorway and crossing  using sonar. repeating the execution of a command such as  go straight down the corridor  and asking the question  where am i     it gradually acquired its probabilistic map. even after the learning proceeded to some extent  while executing ordered navigation such as  go to dr. matsui's office   the system always assessed its position and asked question   where am i     at appropriate times. 
　in this setting of map learning  the function of the information coming from dialog is not only to reduce the location uncertainty  but also to help the system to decide the time to learn and the time to add a new location node to the map. in the above dialog  by the human's answer   you are on your way   the robot could understand that the end-of-action condition was satisfied incorrectly. in this situation the system did not use the data acquired in the previous movement . 
1 	r o u t e a c q u i s i t i o n by following 
the second point where we introduced human assistances was in teaching a long path to a goal. although the above dialog-based method worked well  a user  who was also a teacher  had to command each elemental motion  go straight  turn right etc.  at the early stage of learning because the robot did not know anything about its environment. this was rather tedious. a solution is to give the robot more powerful dialog capability which could accept compound commands like  first go straight  then turn right  then.... . 
　here we introduced another assistance of humans. instead of commanding a composed path through spoken dialog  a teacher simply commands the robot  follow me. . the robot follows the teacher with visual tracking capability and learns a path to a goal during the guided tour  see figure 1 . 
　to acquire the path  that is  a sequence of elemental actions  the robot should segment the entire path to the goal and recognize each segment as an elemental motion. 

figure 1: jijo-1 following a person 
	asoh.etal. 	1 

figure 1: geographic map of the etl e-building 
here the self-motion recognition capability plays an important role. we employed the dynamic programming matching method to recognize each motion trajectory element  asoh et a/.  1 . 
1 	experimental results 
we evaluated the effectiveness of the methods in the real environment. the site of the experiment was a part of a floor of our laboratory building  figure 1 . 
　in an experiment the system executed 1 trial runs. each run was a trip from their current place to an arbitrary selected place  denoted by the character a  b ... in figure 1 . the longest run was about 1 m. ultimately the system succeeded in acquiring a topological map with 1 state nodes  asoh et al.  1a; asoh et al.  1 . average moving speed was about 1 cm/sec. 
1 related work 
the book of leslie kaelbling  which popularized the concept of  learning in embedded systems   is mainly concerned with learning state-action pairs using reinforcement learning. the interaction channels between learning systems and environments are sensing to recognize the current state and reward for the action. 
　several researchers proposed a learning method in which a teacher observes learner's performance and provides appropriate advices  clouse and utgoff  1; gordon and subramanian  1; maclin and shavlik  1 . doringo and colombetti  considered the interdependence between the environment  the learning agent  and the trainer  and applied reinforcement learning not only to learning agent but also to trainer program. 
　recently in the field of robot learning   learning from observation  and  learning by imitation  are being considered as promising learning schemes  demiris 1; ikeuchi and suehiro  1; kawato et al.  1; kuniyoshi et ai  1 . these are also considered as an approach of utilizing wider communication channels between the learning systems and human teachers. here the assisting information is mainly visual. our second experiment of route acquisition by following can be viewed as a kind of learning by imitation. 
　one of the pioneering works of introducing dialog as a communication channel with learning systems was the well-known intelligent robot  shakey  developed by nilsson . a natural language understanding system  shrdlu  by winograd  also had some learning capability. recently  mark torrance  has developed a mobile robot which learns a map through natural language dialog typed in from a keyboard. 
　the office-conversant robot presented in this paper  which was deeply inspired by these earlier projects  tries to integrate these ideas into a platform to evaluate their effectiveness in acquiring a higher level structural knowledge about the environment. 
1 conclusion and future work 
we have described the architecture and functions of an office-conversant robot jijo-1  a platform for the research toward socially embedded learning. the results have convinced us that introducing close interaction with the environment  especially human assistance into learning processes  is very effective in enlarging the scope and applicability of machine learning. we would like to continue our explorations in this direction and achieve learning of more functionalities. 
　tentative status is far from satisfiable one. we should explore more variety of interaction between robot and its environment. the most urgent problems we currently face are in visual processing and making dialog. for visual processing  we plan to give the robot the capability of detecting humans in the environment and recognizing these humans using an active vision system. this capability is necessary to enlarge the communication channel between the robot and humans. in order to widen the content of dialog  we must implement semantic analysis of spoken sentences and reason with semantic representation. we also plan to utilize the framework of socially embedded learning for realizing these capabilities themselves. scaling up the experiment is also important in evaluating the system's performance. 
acknowledgement 
this work is supported by the real-world computing program organized by the ministry of international trade and industry of the japanese government. 
