 
web search engines struggle to satisfy the needs of web users. users are notoriously poor at representing their needs in the form of a query  and search engines are poor at responding to vague queries. however progress has been made by introducing context into the search process. in this paper we describe and evaluate a novel approach to using context in web search that adapts a generic search engine for the needs of a specialist community of users. this collaborative search method enjoys significant performance benefits and avoids the privacy and security concerns that are commonly associated with related personalization research. 
1 	introduction 
it is a tragic irony of the information age that users are finding it increasingly difficult to benefit from access to unprecedented amounts of information. even with the help of modern search engines we regularly fail to locate relevant information in a timely manner. many factors contribute to this information overload problem. certainly  the sheer quantity of information  and its growth rate  tax even the most advanced search engines. for example  various estimates indicate that even the largest search engines often cover only a fraction of the available information space  lawrence and giles  1 . 
　however  search engine coverage is just the tip of the iceberg  and can be greatly enhanced by using meta-search methods  dreilinger and howe  1; selberg and etzioni  1 . a more pressing problem is the limited degree to which those pages that are covered can be accurately ranked with respect to a given query. part of this problem lies with the users. search engines work very well for properly formulated queries  but they come up short when presented with an average web user's query  which typically contains about 
1 query terms  lawrence and giles  1 . the inevitable outcome is long lists of apparently relevant results  with genuinely useful results  for the target user  few and far between. moreover  these problems are exacerbated by the new generation of mobile computing devices  eg. wap phones and 
   the support of the informatics research initiative of enterprise ireland is gratefully acknowledged. 
pdas . their restricted input capabilities and limited screen real-estate mean that mobile users are even less likely to provide well formulated queries or tolerate long result lists. 
　for the most part  recent search engine advances have focused on better ways to handle vague queries by improving existing page analysis  indexing and ranking methods. however a critical shortcoming still remains: a query might include terms that identify the primary information target  but rarely includes terms that usefully describe the search context. for example  a simple query for  jaguar  docs not indicate whether the user is interested in cars or cats  and queries for  michael jordan  do not distinguish between the basketball star and the berkeley professor. consequently  researchers have recently focused on ways to exploit context during search  either by explicitly establishing context up-front or by implicitly inferring it. for example  the inquires 1 meta-search engine  glover et al.  1  supplements keyword-based queries with a context category; users explicitly select from a set of categories such as  research paper    homepage  etc. alternatively  implicit context can be automatically inferred. for example  systems such as watson  budzik and hammond  1  take advantage of user activity prior to search to judge context; watson monitors a user's word processing activity and uses document text as the basis for query terms. in contrast  relevance feedback techniques attempt to use actual search results to inform context. for example   mitra et al.  1  extract correlated terms from top-ranking search results to focus context on the most relevant search results as opposed to the entire set. 
　in this paper we describe a novel technique for exploiting context during search: collaborative search acts as a frontend for existing search engines and re-ranks results based on the learned preferences of a community of users. we describe and evaluate its implementation in the i-spy system and highlight how i-spy achieves personalization in an anonymous fashion  without storing individual user profiles. 
1 collaborative search 
collaborative search is motivated by two key ideas. first  specialised search engines attract communities of like-minded users and naturally limited context variations. for example  a motoring search engine is likely to attract queries with a motoring theme; here  jaguar  queries are more likely to relate to cars than cats. second  by capturing the selections of 

poster papers 	1 


figure 1: the i-spy meta-search engine. 
a community of users it is possible to estimate query-page relevance as the probability that a page pj will be selected for query qt. collaborative search combines both ideas in a 
meta-search engine called i-spy  figure 1 . 
　the unique feature of collaborative search is its ability to personalize search results for a community of users  but without relying on traditional context-analysis  eg.  lawrence and giles  1j  or personalization  eg.  bradley et al  1   techniques. i-spy achieves this by storing the usage patterns of users as a hit matrix  h. each element  hi j  equals the number of times that page pj was selected for query qt. this matrix is a powerful source of relevancy information; after all its data reflect query-page relevancy judgments by users. the relevancy of p1 to query qz is estimated by the probability that pj will be selected for query qi; sec equation 1. 
		 1  
this relevancy metric is tuned to the preferences of a community of users  and the queries and pages that they tend to prefer. deploy i-spy on a motoring web site and its hit matrix will become populated with queries and pages that are relevant to car fans. for example  over time queries for  jaguar'  will tend to result in the promotion of car sites because users submitting this query term will tend to select jaguar car sites  ignoring the wild cat pages. the wild cat pages may still be returned but will be relegated to the bottom of the result list. 
　in fact i-spy can deploy multiple i-spy search agents  each with its own separate hit table. thus the central i-spy engine can be used to service many different search services across a range of portals  for example  each one adapted for the needs of a particular user group through its associated hit matrix. alternatively  different hit matrices could be associated with different regions of the same site to bias search with respect to different topics. for instance  the work of  havel iwala  1  biases pagerank with respect to different topic groups in an internet directory by generating category-biased pagerank vectors from the urls contained in top-level directory categories. a similar strategy can be supported by 1spy. placing a search box on the programming languages directory page will naturally capture queries from this domain. and the behaviour of the users providing these queries  will gradually adjust i-spy's relevancy metric and ranking function in favour of programming languages pages. 
1 	evaluation 
for our evaluation we focus on a specific user community and search domain: computer science students and programming languages. a set of 1 queries is produced from the programming languages listed in yahoo. i-spy is configured to query two underlying search engines  yahoo  which uses google  and splat!  and each of the 1 queries is submitted to obtain up to 1 results based on a standard meta-search ranking function. a group of 1 computer science students are asked to identify relevant results  based on the summary result descriptions returned by 1-spy. 
　a leave-one-out evaluation methodology is employed so that each user is designated to be a test user with the remaining 1 serving as training users. the relevancy results of the training users are used to populate i-spy's hit matrix and the results for each query are re-ranked using i-spy's relevancy metric. next  we count the number of these results listed as relevant by the test user for various result-list sizes  k = 1..1 . finally  we make the equivalent relevancy measurements by analysing the results produced by the untrained version of i-spy  standard   which serves as a benchmark. 
　figure 1 presents the results for i-spy and the benchmark search engine as a graph of precision versus recall for each result-list size; these are really bounded versions of the standard precision and recall metrics and the measures for each engine converge once a complete result-list is returned. the results indicate a significant and consistent benefit for i-spy over the standard meta-search benchmark. for example  for result-lists of 1 items  i-spy achieves a precision of just over 1% compared to the standard meta-search precision of only 1%. similarly  at the same result-list size  we find an average recall for 1-spy of 1% compared to just under 1% for the standard method. indeed we see that i-spy achieves 1% recall at just over 1 items whilst it takes the benchmark 1 items to achieve the same level of recall. the fact that larger relative benefits are available at smaller result-list sizes is important. users rarely sift through large result-lists and so  the more relevant items that can be presented earlier on  the better. this means that i-spy is likely to be especially valuable in situations where large result lists must be truncated for other reasons  such as the small screen sizes o f mobile devices. 

1 	poster papers 


figure 1: precision vs. recall results. 
1 	discussion 
there are number of problems with collaborative search that need to be addressed to guarantee its applicability across a broad range of search tasks. perhaps the most important problem is the so-called cold-start problem. this refers to the fact that newly indexed web pages find it difficult to attract user attention since they will have a low relevancy score using 1spy's metric and thus appear far down in result-lists  limiting their ability to attract the hits they deserve for a given query. essentially there is an in-built bias towards older pages. 
　there are a number of ways that this problem might be dealt with. one is to look at ways to normalize the relevancy of pages with respect to their age. for example  we might measure the age of a page by the time  or number of queries  since its first hit and amplify the relevancy of young pages relative to older pages. 
　indeed there is another side to this problem. just as new pages find it difficult to attract hits  so too older pages may find it easy to attract hits. in the worst case scenario this could even bias i-spy's result-lists towards pages that are likely to be out of date and thus less relevant to current users than they were to past users. once again  biasing relevance towards new pages should help to cope with this problem. 
　of course in general there are many factors that can  and probably should  be taken into account when ranking search results. we have focused primarily on i-spy's relevancy factor  but other factors such as the age of a page and its metasearch ranking are also appropriate. as part of our future work we will explore how best to combine these factors to produce optimal result rankings. this may or may not involve a direct combination of the rankings. for example  one option is to present search results not as a single list of results  as is normally the case  but perhaps as two or more lists of results in order to emphasise the different qualities of the returned pages. for instance  in general only a subset of search results are likely to have non-zero i-spy relevance scores; that is  a subset of results will have been selected in the past for the current query. therefore  it is practical to present the i-spy results with relevancy scores as special recommendations  ranked by their relevancy . the remaining results can be presented separately  ranked by their meta-score. in turn a third list of new pages  ranked by meta-search score or relevancy  can also be separately presented. 
1 	conclusions 
improving the accuracy of web search engines by introducing context into the search process is an important and challenging research problem. we have described a generic search engine that can be adapted or personalized to fit the context and needs of a community of users by using the collaborative search technique. the benefits include superior precision and recall characteristics when compared to a benchmark search engine. in addition  this level of personalization is achieved without the need to store individual user profiles  leading to superior security and privacy benefits when compared to alternative approaches. 
　in closing it is worth highlighting that collaborative search makes no strong assumptions about the form of the underlying search engines and is generally applicable across a range of content types including web pages  graphics and photos  audio and video. finally  its proposed ranking metric is computationally efficient  o k  in the number of search results  and requires no additional parsing of result pages. 
