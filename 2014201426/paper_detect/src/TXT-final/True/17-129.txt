 
     a system has been designed in which explanation-based learning is applied to classical mechanics. an overview of the fully-implemented system and an example run by it are presented. from the example the system acquires a general formula describing how the momentum of a collection of objects changes over time. the derivation of this formula is prompted by the analysis of a human's solution to a simple two-body  onedimensional collision. the human's solution is based on the principle of momentum conservation. the acquired formula serves to solve a three-dimensional collision in the presence of external forces  a situation where momentum is not conserved. 
	i 	introduction 
     explanation-based learning  dejong1l  is a knowledge acquisition method that utilizes deep domain models. this type of learning involves generalizing a single problem solution into a form that can be later used to solve conceptually similar problems. the generalization process is driven by the explanation of why the solution worked. it is the deep knowledge about the domain that allows the explanation to be developed and then extended. this approach to learning has much in common with  mitchell1l  silver1l and  winston1 . see  dejong1  for a full discussion. 
     a system has been designed and implemented in which explanation-based learning is applied to classical mechanics. initially this system is capable of performing many of the mathematical manipulations expected of a college freshman and is provided a representation of newton's laws. physical concepts taught in a first semester physics course are to be acquired; hence the name of the system  physics 1. newton's laws - which constitute the initial domain model - suffice to solve all problems in classical mechanics  but the general principles that are consequences of newton's laws are interesting for their elegance as well as their ability to greatly simplify the solution process. since the system's physical knowledge rests on the strong foundation of newton's laws  only its mathematical sophistication will limit the physical concepts it can acquire. 
system overview 
     the operation of the system can be seen in figure 1. after a physical situation is described and a problem is posed  physics 1 attempts to solve the problem  reporting its solution if one can be found. when its knowledge is not adequate to solve a problem  the system requests a solution from the human user. it then verifies the correctness of the answer  relative to its current knowledge level . the human-provided solution need not fully specify the solution steps; some  reading between the lines  is possible. if the system cannot verify the human's solution  or if an erroneous step was detected  more details are requested. once a satisfactory answer to the posed problem is obtained  the system determines why the 
　　　this research was supported by the air force office of scientific research under grant f1-k-1. 
human's solution worked and attempts to extend the solution technique. any resulting generalizations are recorded and can be used to solve future problems. 

figure 1. the operation of physics 1 
     section ii contains an example of this process. conservation of momentum is used  by a human  to solve a one-dimensional  twobody collision problem that the system could not solve. the human's solution is verified and then generalized  during which the system discovers that momentum is only conserved in the absence of any net external force. a general equation describing how external forces affect momentum is derived by the system. a second problem  which involves three bodies under the influence of an external force  has been solved by physics 1 using this generalized result 
explaining human solutions 
     the system classifies human solution steps into one of four categories 
 1  a known formula could have been used; force = mass x acceleration is an example of this type. 
 1  new variables can be defined in order to shorten later expressions. a formula such as momentum = mass x velocity would fall into this class. 
 1  equations can be algebraic variants of previous steps. the replacement of variables by their values also falls into this category. 
 1  the user can specify an equation that states a relationship among known variables  yet the system knows of no algebraically equivalent formula. these steps require full justification  which the system does by using its abilities to symbolically reason with calculus. only the equations falling in this category are candidates for generalization. 
     
1 	j. shavlik 
representing physical situations 
　　　physical situations are represented as worlds  which comprise a number of objects. objects have four measurable attributes; mass  position  velocity  and acceleration. all but mass are timedependent  three-dimensional vectors. the relationships among these attributes  with respect to symbolic differentiation and integration  are known to the system. 
newton's second and third laws are also known to the system. 
 newton's first law is a special case of his second law.  his second law says that an object's acceleration is determined by the net force acting on the object  divided by its mass. the net force can be decomposed into two components; the external forces  due to sources outside the physical system   and the internal forces  due to each of the other objects within the system . these inter-object forces are constrained by newton's third law  which says that every action has an equal and opposite reaction. 
　　　when solving physics problems it often proves useful to represent the instantaneous state of a world at two separate times  eg.  the initial and final states . for this reason all variables in the world can have known values at two specific times  as well as a value  which may also be unknown  for all time. a constraint system  shavlik1  maintains the known algebraic relationships among these values. several of these values - for object attributes or any of the forces - are set by the user to characterize a physical situation. 
ii illustrative example 
　　　in the one-dimensional problem shown in figure 1  there are two objects moving in free space  without the influence of any external forces.  nothing is known about the forces between the two objects. besides their mutual gravitational attraction  there could be a long-range electrical interaction and a very complicated interaction during the collision.  in the initial state  state a  the first object is moving toward the second  which is stationary. some time later  state b  the first object is recoiling from the resulting collision. the task is to determine the velocity of the second object after the collision. 
　　　as there is insufficient information for the constraint subsystem to determine this velocity  physics 1 attempts to determine an expression for object two's velocity as an explicit function of time. the resulting expression could then be evaluated in state b. progress past the last line in figure 1 can not be made though  as the time-dependence of the inter-object force is not known.  all of the calculus in figures 1 and 1 is generated by physics 1. several minor intermediate expressions have been 
excised  for the sake of brevity.  


figure 1. the computer's failed solution attempt 
     at this point the system requests a solution from the user. the solution provided can be seen in figure 1. without explicitly stating it  the user took advantage of the principle of conservation of momentum  as the momentum of the world at two different times was equated. after that  various algebraic manipulations lead to the answer. in order to accept the answer  the system has to verify each of the steps in this solution. 
     the last three steps are easily verified  as they are simple algebraic manipulations. the hard part is determining a justification for the first equation in figure 1. physics 1 must ascertain that this equation is consistent with its physical knowledge. since the two sides of the equation only differ as to the state in which they are evaluated  an attempt is made to determine a time-dependent expression describing the general form of one side of the equation. figure 1 presents the calculus involved in determining how the general expression explicitly depends on time. this calculation can go to completion because the unknown force that was an obstacle in figure 1 is now cancelled by the other inter-object force. even though the values of these two forces are unknown  newton's third law constrains them so that they cancel. since the expression is constant  its value in any two states can be equated. the initial step has been validated. 
     next  the system attempts to generalize the initial equation in the human's solution. in the initial equation of figure 1  four variables are used to determine the value of object two's velocity. the system ascertains that the first object's velocity produces the inter-object force that cancels the force that had been an obstacle in figure 1. physics 1 also determines that the two mass terms are needed for this additive cancel to occur. now that the system has explained why the human's attempt worked  it can generalize the 
     
figure 1. a two-body collision problem 
     
technique to situations with more than two objects. any object in a world may exert a force on any other object so to cancel the total inter-object force in the general case  a mass x velocity contribution must come from every object in the world. physics 1 produces the left-hand side of equation 1  and then uses its knowledge of physics and calculus to arrive at the right* 

figure 1. the human's solution 
     
	j. shavlik 	1 

figure 1. verifying the first step in the human solution 
     
hand side. in the general case  all the internal forces cancel but the external ones remain. 
 1  
 dejong1l  g. dejong   generalizations based on explanations   
proceedings of the seventh international joint conference on artificial intelligence  vancouver  b.c  canada  1  1.  dejong1  g. dejong  r. mooney  p. o'rorke  s. rajamoney  a. segre and j. shavlik   a review of explanation 
based learning   technical report  coordinated science laboratory  university of illinois  urbana  il  forthcoming in 1.  forbus1  k. forbus and d. gentner   learning physical domains: towards a theoretical framework   proceedings of the 1 international machine 
learning workshop  urbana  il  june 1  1.  langley1l  p. langley   data-driven discovery of physical laws   cognitive science 1  1   1.  larkin1l  j. h. larkin   enriching formal knowledge: a 
model for learning to solve textbook physics 
problems   in cognitive skills and their acquisition  j. r. anderson  ed.   lawrence erlbaum  hillsdale  nj  1  1.  mitchell1  t. mitchell  s. mahadevan and l. steinberg  
 leap: a learning apprentice for vsli design   lcsr-tr-1  rutgers university  new brunswick  n j   january 1.  shavlik1  j. w. shavlik   building and processing constraint networks for vector algebra   working paper 1  
coordinated science laboratory  university of illinois  urbana  il  december 1.  silver1  b. silver   learning equation solving methods from worked examples   proceedings of the 1 international machine learning workshop  
urbana  il  june 1  1.  winston1  p. h. winston  t. 1. binford and m. lowry  
 learning physical descriptions from functional definitions  examples  and precedents   ai memo no. 1  mit  cambridge  ma  january 1. this formula says the total momentum of the objects in a world is determined by the integral of the sum of the external forces on those objects. 
iii conclusion 
　　　by analyzing a worked example  physics 1 is able to derive a formula describing the temporal evolution of the momentum of any arbitrary collection of objects. this formula can be used to solve a collection of complicated collision problems. 
　　　others  forbus1l  langley1ll  larkin1l  have investigated the learning of physical concepts. larkin's able system learns how to algebraically apply principles of physics. langley's work involves the analysis of multiple data measurements and does not utilize deep knowledge about the physical world. forbus and gentner consider learning qualitative physics by analogical reasoning. unlike any of these systems  physics 1 reasons with calculus to explore the implications of newton's laws. 
　　　there are several possible long-term applications of this research. from the viewpoint of the development of expert problem solvers  the techniques outlined here could be used to  train  programs in domains that are based on the selection and manipulation of formulae. their analogs of newton's laws could be encoded and then sample solutions to various problems could be presented  much in the way technical textbooks are organized. this system should also prove applicable to cognitive modelling and intelligent computer aided instruction  as it is able to recognize incorrect applications of physical principles  e.g.  assuming momentum is conserved in the presence of an external gravitational field . 
acknowledgements 
　　　this work greatly benefited from discussions with my advisor  professor gerald dejong. 
     
references 

training and tracking in robotics* 
oliver g. selfridge and richard s. sutton gte laba  waltham  ma 1 
andrew g. barto 
department of computer and information science 
university of massachusetts  amherst  ma 1 
     
a b s t r a c t 
     we explore the use of learning schemes in training and adapting performance on simple coordination tasks. the tasks are 1-d pole balancing. several programs incorporating learning have already achieved this  1  s  1 : the problem is to move a cart along a short piece of track to at to keep a pole balanced on its end; the pole is hinged to the cart at its bottom  and the cart is moved either to the left or to the right by a force of constant magnitude. the form of the task considered here  after  1   involves a genuinely difficult credit-assignment problem. we use a learning scheme previously developed and analysed  1  1  to achieve performance through reinforcement  and extend it to include changing and new requirements. for example  the length or mast of the pole can change  the bias of the force  its strength  and so on; and the system can be tasked to avoid certain regions altogether. in this way we explore the learning system's ability to adapt to changes and to profit from a selected training sequence  both of which are of obvious utility in practical robotics applications. 
     the results described here were obtained using a computer simulation of the pole-balancing problem. a movie will be shown of the performance of the system under the various requirements and tasks. 
i introduction 
     the importance of good training experience it well recognised in pattern classification and inductive inference  where careful choice of rule exemplars and counter-exemplars clearly affects learning progress  e.g.  ref.  . it is also important for learning in symbolic problem solving as illustrated by the problem generation component of lex . here we show that similar pedagogic care can be significant in nonsymbolk problem solving of the kind that is important in robotics; namely  problems of learning to control physical dynamical systems. 
     it is sometimes faster for a system to warn to solve a different problem from the one assigned and then to adapt that solution once it it learned. and it it usually far fatter for a system to adapt to new requirements by modifying old solutions than for it to start again from scratch. in the case of learning to control a physical system  it may be much easier  for example  to first learn to control a related system with simpler dynamics  and then to continue to learn at that system is deformed  continuously or by a sequence of steps  into the system required. this it noi an approach that lends itself to orthodox control theory due to the difficulty of adjusting to nnforeseen changes in dynamics and task requirements. 
     a related issue is that the ability of a system to adjust to unforeseen changes in circumstances and requirements it important even if it 
* this research was supported by the air force office of scientific research and the avionks laboratory  air force wright aeronautical laboratories  through contract f1-1. 
does not lead to increased learning speed through training. although an obvious role of learning is to construct a knowledge base through experience in domains where there is little a priori knowledge  another role that receives less attention is to track a moving optimum  either incrementally or non-incrementally  as unforeseen changes take place. 
     here we show how both training and tracking can be done with a learning system that was described by barto  sutton  and anderson . our domain is the classic problem of balancing a pole in one dimension. this problem has the advantage that it has been considered by several researchers  1  1   and it can be made quite difficult by adopting certain assumptions. specifically: 
a rigid pole is hinged to a cart  which is free to move within the limits of a 1-d track. the learning system attempts to keep the pole balanced and the cart within iti limits by applying a force of fixed magnitude to the cart  either to the left or to the right. 
this task is susceptible to a number of different learning schemes depending on the quality of the evaluative feedback provided to the learning system. here we consider a version of the task similar to the one studied by michie and chambers  in which the only evaluative feedback occurs on failure-hitting the stops with the cart  or having the pole fall over. this sparsity of evaluative feedback create! a genuinely difficult credit-assignment problem. since a failure usually occurs only after a long sequence of individual control decisions  it is difficult to determine which decisions were responsible for it. to solve this problem  the system identifies certain regions as being in some sense  close  to failure  and will try to avoid them as well. the back-propagation method for generating this internal evaluation is like samuel's method  1   but refined and improved by sutton . 
     the learning system usually starts with an empty experiential knowledge base  and it takes some time to fill it with enough data for the system to perform well. we first show that to learn a new task-for example  one with very different parameters  like a vastly heavier pole-can be easier when the system adjusts its knowledge base from a successful state than from scratch. while it is obvious that a suitably primed knowledge base ought to facilitate learning compared to  tabula rata  learning  our point is that the initial knowledge can be that acquired from learning to solve an easier task  which may itself have been learned at a result of facing an even easier task. other results show this explicitly. 
     we also consider tasks that add a constraint  such as avoiding particular pole positions. in these tasks  the learning system must adapt to the constraint without explicit instruction as to how to do it. systems capable of discovering  how  to accomplish a goal  specified only in terms of  what   are more powerful than those that require more explicit specifications. such  operationalization* capabilities are ihown by systems like ours that modify behavior without performing adaptive model reference system identification  as is usual in adaptive :ontrol theoretic techniques. that is  what is used here is a  learning by discovery  method that owes more to ai than to conventional adaptive control. 
ii technical approach and experimental results 
     although the state space of the cart-pole system is continuous- -hat is  the state variables are continuous-we divide the four of them discretely  as in : 

which yield together 1 regions corresponding to the combinations. the system is always in just one region. the job of the learning system  then  is to assign the proper action to each region  so that the system will act correctly. the learning algorithm is given in the appendix and is discussed in detail in refs.  and . 
     the cart-pole system was simulated on a vax-1  using the equations of motion given in  and the following initial parameter values: 

there are two small coefficients of friction  one for the cart and the other for the pole. in the initial state the pole is stationary and upright  and the cart is stationary in the middle of the track. since there is always a force  the pole will not long stay upright. the time from initial position to failure-the cart or pole hitting a stop-is considered one learning trial. time was discretised to a fiftieth of a second. the system was judged to have succeeded in balancing the pole when it achieved a trial that continued without failure for 1 time steps  corresponding to some 1 minutes real time. we used the number of failures before reaching this criteria of success as some measure of the power and efficiency of learning. a run using the standard parameters listed above typically might have 1 trials before a criterion trial is achieved. 
     in the first set of tasks the system was required to adapt to changes in the parameters of the cart-pole system. one task required adaptation to bias in the force  which changed from +1 and -1 newtons to +1 and - 1   and to +1 and -1. this can be considered an  inaccurate  approximation to tilting the track right and left. that problem was solvable: the control surface learned was specific to the direction of the tilt  and a system trained for one tilt did not work well for another. however  after several switches of the direction of tilt  with training to criterion for each  the system was eventually able to balance the pole each way without failure. that is  the system had generalised its solution to satisfy all the problems simultaneously. 
　　the second task required adaptation to an increase in the mass of the pole. the initial training used the standard .1kg pole to the criterion of 1 steps without failure. then the mass of the pole 
	1. selfridge et al. 	1 
was increased one order of magnitude  to 1kg . this made the problem much harder  and performance dropped accordingly. however  criterial performance was soon regained: initial training took an average of 1 failures; subsequent adaptation to the heavier pole took only 1. on the other hand  without pre-training  learning to balance the heavier pole took an average of 1 failures. it is clearly more efficient to use a previous solution as the starting place for this new task than to start from scratch. 
     the system finds it harder to learn to handle shorter poles. if we started training with a pole reduced in length and mass to two-thirds of the original lm/.lkg pole  it took 1 failures on average to reach criterion  compared to 1 with the full-sise pole. when the system was first trained to criterion on the full-sise pole and then switched to the short pole  however  only 1 additional failures were incurred on average after the switch  for a total of 1 failures overall. this result shows not only adaptability to changing requirements  but also improvement in learning rate with  directed* training. 
     directed training resulted in a larger advantage in switching to a shorter track. with the track length 1 meters  instead of 1m   learning took more than 1 failures on the average. but training first at 1m  then at 1m  1m  and finally at 1m  each to criterion  took merely 1 + 1 + 1 + 1- 1 failures. 
     the final task required learning to avoid some region of state space; namely  the region in which the pole is near vertical  ＼1＜ . we added a penalty  equal to 1 the penalty for failure  for being within this region. despite the fact that remaining in this state is the  natural  way to balance the pole  the learning system reduced the proportion of time spent there from 1% to 1%. increasing the penalty 
reduced the fraction still further  but then hitting the stops became more attractive relatively  and balancing failures occurred more often. 
	ill 	analysis and discussion 
     the training illustrated in these results consists of selecting a sequence of control tasks that ends with the required task and that presents a graded series of difficulties. since this kind of sequence consists of entire problem-solving tasks  rather than exemplars and counter-exemplars of a pattern class  it is quite different from the usual training sequence in'supervised learning pattern classification or concept formation. the potential utility of this type of training seems clear; these results show that the learning system considered here is in fact able to benefit from it. the learning system treated here is  moreover  a simple one; it does not deal with hierarchical control at all  nor does it take advantage of a specific accessible knowledge base. 
     part of the utility of the training in our examples is due to the fact the external evaluative feedback is in the form of a binary signal- failure or not. such systems are always subject to what has been termed the  mesa phenomenon  . what is needed is a more continuous feedback so that the system can become better and better  rather than merely satisfy some set of binary constraints. one observes this constantly in people performing physical tasks; it would obviously be desirable in robotics as well. one mechanism used by the learning system to provide a more continuous evaluation is the part of the algorithm that constructs an internal evaluation signal. training provides another way of reducing the effect of the mesa phenomenon by effectively leading the system to better regions of the solution space. significantly  this can be done by manipulating aspects of the task without using detailed knowledge of what the performance surface is 
     
1. selfrldge et al. 
like. 
     another way to ease the problems caused by the mesa phenomenon is to provide our robotics systems not with just one purpose  but with a structure of purposes: the first purpose to be satisfied is to fulfill the constraints and avoid outright failure-that is  to keep the pole upright and to avoid allowing the cart to crash into the ends of the track. next the system might try to keep the pole upright  by reducing the average magnitude of 1 ; after that  it might try to minimise the angular velocity  so as to keep the pole still. beyond that  we can imagine a universal purpose of wanting to do all the above with minimum work  just as people's physical efforts become more and more efficient with practice. 
     related to the issue of training  and equally important  is the ability of the learning system to track a changing optimum for the control parameters. in robotics  there are practical reasons for this: the dynamics change with time  sises and viscosities change with temperature  bearings and surfaces suffer wear  and so on. such problems are clearly not feasible to solve analytically  and in any case  the point is to provide systems whose behavior is robust enough to handle unexpected as well as expected situations. 
acknowledgements 
     the authors thank charles w. anderson for assistance with the pole-balancing experiments. 


