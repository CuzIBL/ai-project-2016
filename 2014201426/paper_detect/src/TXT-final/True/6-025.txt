 
this paper presents a method for analyzing human-robot interaetion by body movements. future intelligent robots will communicate with humans and perform physical and communicative tasks to participate in daily life. a human-like body will provide an abundance of non-verbal information and enable us to smoothly communicate with the robot. to achieve this  we have developed a humanoid robot that autonomously interacts with humans by speaking and making gestures. it is used as a testbed for studying embodied communication. our strategy is to analyze human-robot interaction in terms of body movements using a motion capturing system  which allows us to measure the body movements in detail. we have performed experiments to compare the body movements with subjective impressions of the robot. the results reveal the importance of well-coordinated behaviors and suggest a new analytical approach to human-robot interaction. 
1 introduction 
over the past several years  many humanoid robots such as 
honda's  hirai et al  1  have been developed. we believe that in the not-too-distant future humanoid robots will interact with humans in our daily life. their human-like bodies enable humans to intuitively understand their gestures and cause people to unconsciously behave as if they were communicating with humans  kanda et al  1a . that is  if a humanoid robot effectively uses its body  people will naturally communicate with it. this could allow robots to perform communicative tasks in human society such as route guides. 
　several researchers have investigated about social relationships between humans and robots. for example  kismet was developed for studying early caregiver-infant interaction  breazeal  1 . also  a robot that stands in a line  nakauchi et al.  1  and a robot that talks with multiple persons  nakadai et al.   1  have been devel-
* this research was supported in part by the telecommunications advancement organization of japan. 
oped. furthermore  various communicative behaviors using a robot's body have been discovered  such as a 
joint-attention mechanism  scassellati et al.  1 . 
　on the other hand  methods of analyzing social robots  especially with respect to human-robot interaction  are still lacking. to effectively develop any systems in general  it is essential to measure the systems' performance. for example  algorithms arc compared with respect to time and memory  and mechanical systems are evaluated by speed and accuracy. without analyzing current performance  we cannot argue advantages and problems. for social robots  no analysis method has yet been established  thus  it is vital to determine what types of measurements we can apply. although questionnaire-based methods have been often used  they are rather subjective  static and obtrusive  that is  we would interrupt the interaction when we apply a questionnaire . less commonly  human behaviors are employed for this purpose  such as distance 
 hall  1   attitude  reeves and nass  1   eye gaze 
 often used in psychology   and synchronized behaviors  ono et al  1 . although those methods are more difficult to apply  the results are more objective and dynamic. sometimes  interactive systems observe human behaviors for synthesizing behaviors  jebara and pentland  1 . however  they are still fragments rather than a systematic analysis method applicable for human-robot interaction. 
　in this paper  we present our exploratory analysis of human-robot interaction. our approach is to measure the body movement interaction between a humanoid robot and humans  and compare the results with traditional subjective evaluation. we have developed an interactive humanoid robot that has a human-like body as the testbed of this embodied communication. furthermore  many interactive behaviors have been implemented. it encourages people to treat the robot as a human child. we employ a motion capturing system for measuring time and space accurately. 
1 an interactive humanoid robot 
1 hardware 
figures 1 and 1 display an interactive humanoid robot 
 robovie   which is characterized by its human-like body expression and various sensors. the human-like body 

cognitive robotics 	1 

consists of eyes  a head and arms  which generate the complex body movements required for communication. the various sensors  such as auditory  tactile  ultrasonic  and visual  enable it to behave autonomously and to interact with humans. furthermore  the robot satisfies mechanical requirements of autonomy. it includes all computational resources needed for processing the sensory data and for generating behaviors. it can continually operate for four hours with its battery power supply. 
1 	s o f t w a r e 
using its body and sensors  the robot performs diverse interactive behaviors with humans. each behavior is gencrated by a situated module  each of which consists of communicative units. this implementation is based on a constructive approach  kanda et al  1b :  combining as many simple behavior modules  situated modules  as possible.  we believe that the complexity of the relations among appropriate behaviors enriches the interaction and creates perceived intelligence of the robot. 
communicative unit 
previous works in cognitive science and psychology have highlighted the importance of eye contact and arm movement in communication. communicative units are designed based on such knowledge to effectively use the robot's body  and each unit is a sensory-motor unit that realizes certain communicative behavior. for example  we have implemented  eye contact    nod    positional relationship    joint attention  gaze and point at object .  when developers create a situated module  they combine the communicative units at first. then  they supplement it with other sensory-motor units such as utterances and positional movements for particular interactive behaviors. 
situated modules 
in linguistics  an adjacency pair is a well-known term for a unit of conversation where the first expression of a pair requires the second expression to be of a certain type. for example   greeting and response  and  question and answer  arc considered pairs. we assume that embodied communication is materialized with a similar principle: the action-reaction pair. this involves certain pairs of actions and reactions that also include non-verbal expressions. the continuation of the pairs forms the communication between humans and a robot. 
   although the action and reaction happen equally  the recognition ability provided by current computer science is not as powerful as that of humans. thus  the robot takes the initiative and acts rather than reacting to humans actions. this allows the flow of communication to be maintained. each situated module is designed to realize a certain action-reaction pair in a particular situation  fig. 1   where a robot mainly takes an action and recognizes the humans' reaction. since it produces a particular situation by itself  it can recognize humans' complex reactions under limited conditions; that is  it expects the human's reaction. this policy enables developers to easily implement many situated modules. on the other hand  when a human takes an action 

toward the robot  it recognizes the human's action and reacts by using reactive transition and reactive modules; that is  some of the situated modules can catch the human's initiating behaviors and interrupt its operations to react to them  as shown in fig. 1: the second module turn . 
   a situated module consists of precondition  indication  and recognition parts  fig. 1 . by executing the precondition  the robot checks whether the situated module is in an executable situation. for example  the situated module that performs a handshake is executable when a human is in front of the robot. by executing the indication part  the robot interacts with humans. with the handshake module  the robot says  let's shake hands   and offers its hand. this behavior is implemented by combining communicative units of eye contact and positional relationships  it orients its body toward the human   and by supplementing a particular utterance   let's shake hands   and a particular body movement  offering its hand . the recognition part is designed to recognize several expected human reactions toward the robot's action. as for the handshake module  it can detect human handshake behavior if a human touches its offered hand. 
1 	cognitive robotics    the robot system sequentially executes situated modules  fig. 1 . at the end of the current situated module execution  it records the recognition result obtained by the recognition part  and progresses to the next executable situated module. the next module is determined by the results and the execution history of previous situated modules  which is similar to a state transition model. 

1 realized interactive behaviors 
we installed this mechanism on  robovic.  the robot's task is to perform daily communication as children do. the number of developed situated modules has reached a hundred: 1 of which arc interactive behaviors such as handshake  fig. 1  upper-left   hugging  fig. 1  upper-right   playing paper-scissors-rock  fig. 1  lower-left   exercising  fig. 1  lower-right   greeting  kissing  singing a song  short conversation  and pointing to an object in the surroundings; 1 are idling behaviors such as scratching its head  and folding its arms; and 1 are moving-around behaviors  such as pretending to patrol an area and going to watch an object in the surroundings. 
　basically  the transition among the situated modules is implemented as follows: it sometimes asks humans for interaction by saying  let's play  touch me   and exhibits idling and moving-around behaviors until a human acts in response; once a human reacts to the robot  touches or speaks   it starts and continues the friendly behaviors while the human reacts to these; when the human stops reacting  it stops the friendly behaviors  says  good bye  and re-starts its idling or moving-around behaviors. 
1 body movement analysis 
1 experiment settings 
we performed an experiment to investigate the interaction of body movements between the developed robot and a human. we used 1 university students  1 men and 1 women  as our subjects. their average age was 1. first  they were shown examples how to use the robot  then they freely observed the robot for ten minutes in a rectangular room 1 m by 1 m. as described in section 1  the robot autonomously tries to interact with subjects. at the beginning of the free observation  the robot asks subjects to talk and play together  and then subjects usually start touching and talking. 
　after the experiment  subjects answered a questionnaire about their subjective evaluations of the robot with five adjective pairs shown in table 1  which was compared with the body movements. we chose these adjective pairs because they had high loadings as evaluation factors for an interactive robot in a previous study  kanda et al.  1a . 
1 m e a s u r e m e n t o f b o d y 	m o v e m e n t s 
we employed an optical motion capturing system to measure the body movements. the motion capturing system consisted of 1 pairs of infrared cameras and infrared lights and markers that reflect infrared signals. these cameras were set around the room. the system calculates each marker's 1-d position from all camera images. the system has high resolution in both time  1 hz  and space  accuracy is 1 mm in the room  
as shown in fig. 1  we attached ten markers to the heads 
 subjects wore a cap attached with markers   shoulders  necks  elbows  and wrists of both the robot and the sub-
jects. by attaching markers to corresponding places on the robot and subjects  we could analyze the interaction of body movements. the three markers on the subjects' head detect the individual height  facing direction  and potential eye contact with the robot. the markers on the shoulders and neck are used to calculate the distance between the robot and subjects  and distance moved by them. the markers on the arms provide hand movement information  the relative positions of hands from the body  and the duration of synchronized movements  the period where the movements of hands of the subject and robot highly correlate . we also analyzed touching behaviors via an internal log of the robot's touch sensors. 
1 	r e s u l t s 
comparison between the body movements and the subjective evaluations indicates meaningful correlation. from the experimental results  well-coordinated behaviors such as eye contact and synchronized arm movements proved to be important. this suggests that humans make evaluations based on their body movements. 
subjective e v a l u a t i o n :   e v a l u a t i o n score  
the semantic differential method is applied to obtain subjective evaluations with a l-to-1 scale  where 1 denotes the most positive point on the scale. since we chose the adjective pairs that had high loadings as evaluation factors for an interactive robot  the results of all adjective pairs represent subjective evaluation of the robot. thus  we calculated the evaluation score as the average of all ad-
jective-pairs' scores. table 1 indicates the adjective pairs used  the averages  and standard deviations. 
correlation between body movements and subjective impressions 
cognitive robotics 	1 table 1 displays the measured body movements. regarding eye contact  the average time was 1 seconds  which is more than half of the experiment time. since the robot's eye height was 1 m and the average of subject 

figure 1: attached markers  left  and obtained 1-d numerical position data of body movement  right  
in the left figure  white circles indicate the attached markers  and the circles in the right figure indicate the observed position of the markers 
eye height was 1 m  which was less than their average standing eye height of 1 m  several subjects sat down or stooped to bring their eyes to the same height as the robot's. the distance moved was farther than what we expected  and it seemed that subjects were always moving littlc-by-little. for example  when the robot turned  the subjects would then correspondingly turn around the robot. some subjects performed arm movements synchronized with the robot's behaviors  such as exercising. 
　next  we calculated the correlation between the evaluation score and the body movements  table 1 . since the number of subjects is 1  each correlation value whose absolute value is larger than 1 is significant. we highlight these significant values with bold face in the table. from the calculated results  we found that eye contact and synchronized movements indicated higher significant correlations with the evaluation score. 
　according to the correlations among body movements  the following items showed significant correlations: eye contact - distance  eye contact - distance moved  synchronized behaviors - distance moved by hands  and synchronized behaviors - touch. however  these items  distance  distance moved  distance moved by hands  and touch  do not significantly correlate with the evaluation score. that is  only the well-coordinated behaviors correlate with the subjective evaluation. isolated active body movements of subjects  such as standing near the robot  moving their hands energetically  and touching the robot repetitively  do not correlate to the subjective evaluation. 
estimation of momentary evaluation: ''entrainment score  
the results indicate that there are correlations between subjective evaluation and body movements. we performed multiple linear regression analysis to estimate the evaluation score from the body movements  which confirms the above analysis and reveals how much each body movement affects the evaluation. we then applied the relations among body movements to estimate a momentary evaluation score called the entrainment score. 
　as a result of the multiple linear regression analysis  standardized partial regression coefficients were obtained  
adjective-pairs mean std. dev. good bad 1 1 kind cruel 1 1 pretty ugly 1 1 exciting dull 1 1 j likable unlikable 1 1 evaluation score 1 1 table 1: the adjective-pairs used for subjective evaluation  and the mean and resulting mean and standard deviation 
mean std. dev. distance  m  1 1 eye contact  s  1 1 eye height  m  1 1 distance moved  m  1 1 distance moved by hands  m  1 1 1synchronized movements  s  1 1 touch  num. of times  1 1          table 1: results for body movement as shown in table 1. the obtained multiple linear regression is as follows: 

where dist  ec  eh  dm  dmh  sm  and touch are the standardized values of the experimental results for the body movements. since the evaluation was scored on a l-to-1 scale  evaluation score e is between 1 and 1. the multiple correlation coefficient is 1  thus 1% of the evaluation score is explained by the regression. the validity of the regression is proved by analysis of variance  f 1  = 1  p 1 . 
　the coefficients  table 1  also indicate the importance of well-coordinated behaviors. eye contact and synchronized movements positively affected the evaluation score; on the contrary  distance  distance moved and touch seem to have negatively affected the evaluation score. in other words  the subjects who just actively did something  standing near the robot  moved around  and touched repeatedly   especially without cooperative behaviors  did not evaluate the robot highly. 
　because we can momentarily observe all terms involved in the body movements of the regression  l   we can estimate a momentary evaluation score by using the same relations among body movements as follows: 

where designations such as dist t  are the momentary values of the body movements at time /. we named this momentary evaluation score the  entrainment score   with the idea that the robot entrains humans into interaction through its body movements and humans move their body according to their current evaluation of the robot. the 

1 	cognitive robotics 

evaluation score and entrainment score satisfy the following equation  which represents our hypothesis that the evaluation forms during the interaction occurring through the exchange of body movements: 
		 1  
　let us show the validity of the estimation by examining the obtained entrainment score. figure 1 shows the entrainmcnt scores of two subjects. the horizontal axis indicates the time from start to end  1 seconds  of the experiments. the solid line indicates the entrainment score e t   while the colored region indicates the average of the entrainment score eft  from the start to time t  this integration value grows the estimation of e at the end time . 
　the upper graph shows the score of the subject who interacted with the robot very well. she reported after the experiment that   it seems that the robot really looked at me because of its eye motion. i nearly regard the robot as a human child that has an innocent personality.  this entrainment-score graph hovers around 1 and sometimes goes higher. this is because she talked to the robot while maintaining eye contact. she performed synchronized movements corresponding to the robot's exercising behaviors  which caused the high value around 1 sec. 
　at the other extreme  the lower graph is for the subject who became embarrassed and had difficulty in interacting with the robot. the graph sometimes falls below 1. in particular  at the end of the experiment  it became unstable and even lower. he covered the robot's eye camera  touched it like he was irritated  and went away from the robot. we consider that those two examples suggest the validity of the entrainment score estimation. 
evaluation of the implemented behaviors 
in the sections above  we explained the analysis of body movement interaction. here  we evaluate the implemented behaviors. although the application of this result is limited to our approach  our findings also prove the validity and applicability of the entrainment score. 
　we calculated the evaluation score of each situated module based on the average of the entrainment score while each module was being executed. tables 1 and 1 indicate the worst and best five modules  respectively  and their scores. the worst modules were not so interactive. sleep pose and fully fed do not respond to human figure 1: illustration of entrainment score 
 upper: subject who treated the robot as if it were a humans child  lower: 
　　　　　subject who was embarrassed by interacting with it  action and exhibit behavior similar to the sleeping pose. notturn is the behavior for brushing off a human's hand while saying  i'm busy  when someone touches on its shoulder. the best modules were rather interactive modules that entrain humans into the interaction. exercise and conductor produce the exercising and imitating of musical conductor behaviors  which induced human synchronized body movements. other highly rated modules also produce attractive behaviors  such asking and calling  which induce human reactions. we believe that the entrainment scores provide plenty of information for developing interactive behaviors of robots that communicate with humans. 
1 discussions 
cognitive robotics 	1 the experiment reveals the correlation between humans' subjective evaluations and body movements. if a human 
evaluates the robot highly  then the human behaves cooperatively with it  which will further improve its evaluation. that is  once they establish cooperative relationships with the robot  they interact well with the robot and evaluate the robot highly. regarding evaluation of the implemented behaviors  the modules that entrain humans into interaction were highly evaluated  such as asking something that induces human's answer and producing cheerful body movements like exercising to let humans 
join and mimic the movements. we believe that the entraiment can help us to establish cooperative relationships between humans and robots. 
   meanwhile  the multiple linear regression explains 1% of the subjective evaluation. this is remarkable because it is performed without regard to the contents or context of language communication. with speech recognition  the robot can talk with humans  although its ability is similar to that of a little child. some of the subjects spoke to the robot. often  there were requests for the robot to present particular behaviors  especially behaviors it had performed just previously   to which it sometimes responded correctly and sometimes incorrectly. to analyze this  we could use several analytical methods such as conversation analysis  however  these methods are rather subjective. on the other hand  our evaluation employed objective measures only: numerically obtained body movements without context  which means there could be a lot of potential usages. for example  an interactive robot could learn and adjust its behavior by using this method. it would be applicable to different subjects  age  culture  etc.   different agents  physical-virtual  body shape  behaviors  etc.   and inter-human communication. 
1 conclusions 
this paper reported a new approach to analyzing embodied communication between humans and a robot. our interactive humanoid robot is able to autonomously interact with humans. this complexity and autonomy is achieved by many simple behaviors. we measured humans' body movements while they observed and interacted with the robot  and the result of the analysis indicates positive correlations between cooperative body movements and subjective evaluations. furthermore  the multiple linear regression explains 1% of the subjective evaluation without regard to language communication. we consider our approach of body movement analysis to be widely applicable in embodied communication. 
