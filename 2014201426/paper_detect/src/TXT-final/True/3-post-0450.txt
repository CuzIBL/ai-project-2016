
we describe a system for generating extractive summaries of texts in the legal domain  focusing on the relevance classifier  which determines which sentences are abstract-worthy. we experiment with na： ve bayes and maximum entropy estimation toolkits and explore methods for selecting abstract-worthy sentences in rank order. evaluation using standard accuracy measures and using correlation confirm the utility of our approach  but suggest different optimal configurations.
1 introduction
in the sum project we are developing a system for summarising legal judgments that is generic and portable and which maintains a mechanism to account for the rhetorical structure of the argumentation of a case. following teufel and moens   we are developing a text extraction system that retains a flavour of the fact extraction approach. this is achieved by combining sentence selection with information about why a certain sentence is extracted-e.g. is it part of a judge's argumentation  or does it contain a decision regarding the disposal of the case  in this way we are able to produce flexible summaries of varying length and for various audiences. sentences can be reordered  since they have rhetorical roles associated with them  or they can be suppressed if a user is not interested in certain types of rhetorical roles.
　we have prepared a new corpus of uk house of lords judgments  holj  for this work which contains two layers of manual annotation: rhetorical role and relevance. the rhetorical roles represent the sentence's contribution to the overall communicative goal of the document. in the case of holj texts  the communicative goal for each lord is to convince their peers of the soundness of their argument. in the current version of the corpus there are 1 judgments which have been annotated for rhetorical role. the second manual layer is annotation of sentences for 'relevance' as measured by whether they match sentences in hand-written summaries. in the current version of the corpus  1 of the 1 judgments which have been annotated for rhetorical role have also been annotated for relevance. a third layer of annotation is automatic linguistic annotation  which provides the features which are used by the rhetorical role and relevance classifiers.
1 classification and relevance
following from  kupiec et al.  1   machine learning has been the standard approach to text extraction summarisation as it provides an empirical method for combining different information sources about the textual unit under consideration. for relevance prediction  we performed experiments with publicly available na： ve bayes  nb  and maximum entropy  me  estimation toolkits. the nb implementation  found in the weka toolkit  is based on john and langley's  algorithm incorporating statistical methods for nonparametric density estimation of continuous variables. the me estimation toolkit  written by zhang le  contains a c++ implementation of the lmvm  malouf  1  estimation algorithm. for me  we use the weka implementation of fayyad and irani's  mdl algorithm to discretise numeric features.
the features that we have been experimenting with for the
holj corpus are broadly similar to those used by teufel and moens . they consist of location features encoding the position of the sentence in document  speech and paragraph; a thematic words feature encoding the average tf*idf weight of the sentence terms; a sentence length feature encoding the number of tokens in the sentence; quotation features encoding percentage of sentence tokens inside and in-line quote and whether or not the sentence is inside a block quote; entity features encoding the presence or absence of named entities in the sentence; and cue phrase features.
　the term 'cue phrase' covers the kinds of stock phrases which are frequently good indicators of rhetorical status  e.g. phrases such as the aim of this study in the scientific article domain and it seems to me that in the holj domain . teufel and moens invested a considerable amount of effort in building hand-crafted lexicons where the cue phrases are assigned to one of a number of fixed categories. a primary aim of the current research is to investigate whether this information can be encoded using automatically computable linguistic features. if they can  then this helps to relieve the burden involved in porting systems such as these to new domains. our preliminary cue phrase feature set includes syntactic features of the main verb  voice  tense  aspect  modality  negation . we also use sentence initial part-of-speech and sentence initial word features to roughly approximate formulaic expressions which are sentence-level adverbial or prepositional phrases. subject features include the head lemma  entity type  and entity subtype. these features approximate table 1: accuracy measures for yes predictions.
the hand-coded agent features of teufel and moens. a main verb lemma feature simulates teufel and moens's type of action and a feature encoding the part-of-speech after the main verb is meant to capture basic subcategorisation information.
1 experimental results
table 1 contains cumulative precision  p   recall  r  and fscores  f  for the na： ve bayes  nb  and maximum entropy  me  classifiers on the relevance classification task.1 though only the cue phrase feature set performs well individually  all feature sets contribute positively to the cumulative scores with the exception of sentence length for me and quotation for nb. both classifiers perform significantly better than a baseline created by selecting sentences from the end of the document  which obtains p  r and f scores of 1  1 and 1. f-scores for the best feature combinations are similar to the partial results reported in teufel and moens . taking the f-score as the best metric to optimise would lead us to choose nb.
　however  a basic aspect of summarisation system design  especially a system that needs to be flexible enough to suit various user types  is that the size of the summary will be variable. for instance  students may need a 1 sentence summary containing  for example  quite detailed background information  to get the same information a judge would get from a 1 sentence summary. furthermore  any given user might want to request a longer summary for a certain document. so  what we actually want to do is rate how relevant/extract-worthy a sentence is in such a way that will allow us to select sentences in rank order. bearing this in mind  precision is probably the more important metric given that recall will be controlled by the size of the summary. so  me with all but sentence length features actually appears to be the better approach for sentence extraction.
nbmeprfprfcue111111entities111111them. words111111location111111quotations111111sent. length111111nbmeiciccue1111entities1111them. words1111location11-11quotations1111sent. length1111　since we need a ranking rather than a yes/no classification  this might actually be considered a regression task. however  due to the way the corpus was annotated  the target attribute is in fact binary. as both of our classifiers are probabilistic  we use p y = yes|~x  as a way to rank sentences. to evaluate the ranking methods with respect to our binary gold standard  we use the point-biserial correlation coefficient  rpb . table 1 contains correlation coefficients between the gold standard yes/no classification and p y = yes|~x  for na： ve bayes  nb  table 1: point-biserial correlation coefficients.
and maximum entropy  me .1 the i column has scores for the individual feature sets and the c column has cumulative scores. the correlation results are strikingly different for nb and me. while nb successfully incorporates all features  rpb= 1   me performs best using only cue phrase  entity and thematic word features  rpb = 1 . for me  the location feature set actually gives a negative correlation. judging by these results  we would again be likely to choose nb.
1 conclusions and future work
in this paper  we have presented work on the automatic summarisation of legal texts for which we have compiled a new corpus with annotation of rhetorical status  relevance and linguistic markup. we presented sentence extraction results in classification and ranking frameworks. na： ve bayes and maximum entropy classifiers achieve significant improvements over the baseline according to standard accuracy measures. we have also used the point-biserial correlation coefficient for quantitative evaluation of our extraction system  the results of which suggest diffierent optimal configurations. in current work  we are developing a user study that will help determine empirically whether correlation coefficients are a better evaluation metric than precision and recall accuracy measures.
