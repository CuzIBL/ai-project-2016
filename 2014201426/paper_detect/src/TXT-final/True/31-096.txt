 
susumu ohno's provocative book evolution by gene duplication proposed that the creation of new proteins in nature  and hence new structures and new behaviors in living things  begins with a gene duplication and that gene duplication is  the major force of evolution.  this paper describes six new architecture-altering operations for genetic programming that are patterned after the naturally-occurring chromosomal operations of gene duplication and gene deletion. when these new operations are included in a run of genetic programming  genetic programming can dynamically change  during the run  the architecture of a multi-part program consisting of a main program and a set of hierarchically-called subprograms. these on-the-fly architectural changes occur while genetic programming is concurrently evolving the work-performing steps of the main program and the hierarchically-called subprograms. the new operations can be interpreted as an automated way to change the representation of a problem while solving the problem. equivalently  these operations can be viewed as an automated way to decompose a problem into an non-pre-specified number of subproblems of non-pre-specified dimensionality; solve the subproblems; and assemble the solutions of the subproblems into a solution of the overall problem. these operations can also be interpreted as providing an automated way to specialize and generalize. 
1 	introduction 
the goal of automatic programming is to create  in an automated way  a computer program that enables a computer to solve a problem. this goal  attributed to arthur samuel in the 1s  can be stated as follows: how can computers learn to solve problems without being explicitly programmed  
　at ijcai-1  genetic programming was proposed as a domain-independent method for evolving computer programs that solve  or approximately solve  problems  koza 1 . genetic programming extends the biologically motivated genetic algorithm described in john holland's pioneering adaptation in natural and artificial systems  1 . 
　genetic programming starts with a primordial ooze of randomly generated computer programs composed of the available programmatic ingredients and then applies the 
1 	genetic algorithms 
principles of animal husbandry to breed a new  and often improved  population of programs. the breeding is done in a domain-independent way using the darwinian principle of survival of the fittest and an analog of the naturallyoccurring genetic operation of crossover  sexual recombination . the crossover operation is designed to create syntactically valid offspring programs  given closure amongst the set of ingredients . genetic programming combines the expressive high-level symbolic representations of computer programs with the near-optimal efficiency of learning of holland's genetic algorithm. 
　genetic programming: on the programming of computers by means of natural selection  koza 1  provides evidence that genetic programming can solve  or approximately solve  a variety of problems from a variety of fields  including many benchmark problems from machine learning  artificial intelligence  control  robotics  optimization  game playing  symbolic regression  system identification  and concept learning. a videotape  koza and rice 1  shows examples. recent additional work is described in kinnear 1. the sequence of the workperforming steps of the programs being evolved by genetic programming is not specified in advance by the user. instead  both the number and order of the work-performing steps are evolved as a result of selective pressure and the recombinative role of crossover. however  this first book genetic programming has the limitation that the vast majority of its evolved programs are single-part  i.e.  one result-producing main part  but no subroutines . 
1 background on automatically defined functions 
1 believe that no approach to automated programming is likely to be successful on non-trivial problems unless it provides some hierarchical mechanism to exploit  by reuse and parameterization  the regularities  symmetries  homogeneities  similarities  patterns  and modularities inherent in problem environments. subroutines do this in ordinary computer programs. 
accordingly  genetic programming ii: automatic 
discovery of reusable programs  koza 1a  1b  describes how to evolve multi-part programs consisting of a main program and one or more reusable  parameterized  hierarchically-called subprograms. 
an automatically defined function  adf  is a function 
 i.e.  subroutine  subprogram  defun  procedure  module  that is dynamically evolved during a run of genetic programming and which may be called by a calling program  or subprogram  that is concurrently being evolved. when automatically defined functions are being used  a program in the population consists of a hierarchy of one  or more  reusable function-defining branches  i.e.  automatically defined functions  along with a main result-producing branch. typically  the automatically defined functions possess one or more dummy arguments  formal parameters  and are reused with different instantiations of these dummy arguments. during a run  genetic programming evolves different subprograms in the function-defining branches of the overall program  different main programs in the resultproducing branch  different instantiations of the dummy arguments of the automatically defined functions in the function-defining branches  and different hierarchical references between the branches. 
　when automatically defined functions are being used in genetic programming  the initial random generation of the population is created so that every individual program has a constrained syntactic structure consisting of a particular architectural arrangement of branches. when crossover is to be performed  a type is assigned to each potential crossover point in the parental computer programs either on a branchwide basis  called branch typing  or on the basis of the actual content of the subtree below the potential crossover point  called point typing . crossover is then performed in a structure-preserving way  given closure  so as to ensure the syntactic validity of the offspring  koza 1a . 
　genetic programming with automatically defined functions has been shown to be capable of solving numerous problems. more importantly  the evidence so far indicates that  for many problems  genetic programming requires less computational effort  i.e.  fewer fitness evaluations to yield a solution with a satisfactorily high probability  with automatically defined functions than without them  provided the difficulty of the problem is above a certain relatively low break-even point . also  genetic programming is usually yield solutions with smaller average overall size with automatically defined functions than without them  provided  again  that the problem is not too simple . that is  both learning efficiency and parsimony appear to be properties of genetic programming with automatically defined functions. 
　moreover  there is also evidence that genetic programming with automatically defined functions is scalable. for several problems for which a progression of scaled-up versions was studied  the computational effort increases as a function of problem size at a slower rate with automatically defined functions than without them. in addition  the average size of solutions similarly increases as a function of problem size at a slower rate with automatically defined functions than without them. this observed scalability results from the profitable reuse of hierarchically-callable  parameterized subprograms within the overall program. 
　five major preparatory steps required before genetic programming can be applied to a problem  namely determining  1  the set of terminals  i.e.  the actual variables of the problem  zero-argument primitive functions  and constants  if any  for each branch   1  the set of functions  e.g.  primitive functions  for each branch   1  the fitness measure  or other arrangement for implicitly measuring fitness    1  the parameters to control the run  and  1  the termination criterion and result designation method. 
1 the problem of architecture discovery 
when automatically defined functions are added to genetic programming  it is also necessary to determine the architecture of the yet-to-be-evolved programs. the specification of the architecture consists of  a  the number of function-defining branches in the overall program   b  the number of arguments  if any  possessed by each functiondefining branch  and  c  if there is more than one functiondefining branch  the nature of the hierarchical references  if any  allowed between the function-defining branches. 
　sometimes these architectural choices flow directly from the nature of the problem. sometimes heuristic methods are helpful. however  in general  there is no way of knowing a priori the optimal  or sufficient  number of automatically defined functions that will prove to be useful for a given problem  or the optimal  or minimum  number of arguments for each automatically defined function  or the optimal  or sufficient  arrangement of hierarchical references. 
　if the goal is to develop a single  unified  domainindependent approach to automatic programming that requires that the user pre-specify as little direct information as possible about the problem  the question arises as to whether these architectural choices can be automated. indeed  the requirement that the user predetermine the size and shape of the solution to a problem has been a bane of automated machine learning from the earliest times  samuel 1 . 
　one way to automate these architectural choices for computer programs in general  called the technique of evolutionary selection of architecture  was described in chapters 1 of koza 1a. this technique starts with an architecturally diverse initial population  at generation 1  that has randomly-created representatives of a broad range of different architectures. as the evolutionary process proceeds  certain individuals with certain architectures will prove to be more fit than others at solving the problem. the more fit architectures will tend to prosper  while the less fit architectures will tend to wither away. eventually a program with an appropriate architecture may emerge from this competitive and selective process. however  in this technique  no new architectures are ever dynamically created during the run. and  no architectures are ever dynamically altered during the run. there is only selection from amongst the architectures created at the beginning of the run. 
　this paper asks  and affirmatively answers  whether it is possible to enable genetic programming to dynamically alter the architecture of a multi-part program during a run while it is concurrently solving the given problem. 
1 recourse to nature 
a change in the architecture of a multi-part computer program during a run of genetic programming corresponds to a change in genome structure in the natural world. therefore  it seems appropriate to consider the different ways that a genomic structure may change in nature. 
koza 
　in nature  sexual recombination ordinarily recombines a part of the chromosome of one parent with a homologous part of the second parent's chromosome. however  in certain rare and unpredictable occasions  recombination does not occur in this normal way. a gene duplication is an illegitimate recombination event that results in the duplication of a lengthy subsequence of a chromosome. 
susumu ohno's seminal book evolution by gene 
duplication  1  advanced the thesis that the creation of new proteins  and hence new structures and new behaviors in living things  begins with a gene duplication. 
　the six new architecture-altering operations for genetic programming described in this paper are motivated by the naturally occurring mechanisms of gene duplication and gene deletion in chromosome strings. 
　the six new architecture-altering operations can be viewed from five perspectives. first  the new architecture-altering operations provide a new way to solve the potentially vexatious problem of determining the architecture of the overall program in the context of genetic programming with automatically defined functions. second  the new architecture-altering operations provide an automatic implementation of the ability to specialize and generalize in the context of automated problem-solving. third  the new architecture-altering operations provide a way to automatically and dynamically change the representation of the problem while simultaneously solving the problem. fourth  the new architecture-altering operations provide a way to automatically and dynamically decompose problems into subproblems and then automatically solve the overall problem by assembling the solutions of the subproblems into a solution of the overall problem. fifth  the new architecture-altering operations provide a way to automatically and dynamically discover useful subspaccs  usually of lower dimensionality than that of the overall problem  and then automatically assemble a solution of the overall problem from solutions applicable to the subspaces. 
1 outline of this paper 
section 1 of this paper describes the naturally occurring processes of gene duplication and gene deletion. section 1 describes the six new architecture-altering operations. section 1 describes an actual run that solves that the problem of symbolic regression of the boolean even-1-parity function while the architecture is being simultaneously evolved. section 1 compares the computational effort required for five different ways of solving the problem. it concludes that the cost of automated architecture discovery is less than the cost of solving the problem without automatically defined functions  but more than that required with a fixed  user-supplied architecture that is known to be a good choice for this problem . 
1 gene duplication in nature 
gene duplications are rare and unpredictable events in the evolution of genomic sequences. in gene duplication  there is a duplication of a lengthy portion of the linear string of nucleiotide bases of the dna in the living cell. after a sequence of bases that code for a particular protein is duplicated in the dna  there are two identical ways of manufacturing the same protein. thus  there is no immediate change in the proteins that are manufactured as a result of a gene duplication. 
　over time  however  some other genetic operation  such as mutation or crossover  may change one or the other of the two identical genes. over short periods of time  the changes accumulating in a gene may be of no practical effect or value. as long as one of the two genes remains unchanged  the original protein manufactured from the unchanged gene continues to be manufactured and the structure and behavior of the organism involved may continue as before. the changed gene is simply carried along in the dna from generation to generation. 
　ohno's evolution by gene duplication corrects the mistaken notion that natural selection is a mechanism for promoting change. natural selection exerts a powerful force in favor of maintaining a gene that encodes for the manufacture of a protein that is important for the survival and successful performance of the organism. however  after a gene duplication has occurred  there is no disadvantage associated with the loss of the second way of manufacturing the original protein. consequently  natural selection usually exerts little or no pressure to maintain a second way of manufacturing a particular protein. over time  the second gene may accumulate additional changes and diverge more and more from the original gene. eventually the changed gene may lead to the manufacture of a distinctly new and different protein that actually does affect the structure and behavior of the living thing in some advantageous or disadvantageous way. when a changed gene leads to the manufacture of a viable and advantageous new protein  natural selection again works to preserve that new gene. 
　ohno also points out that ordinary point mutation and crossover are insufficient to explain major changes   ...while allelic changes at already existing gene loci suffice for racial differentiation within species as well as for adaptive radiation from an immediate ancestor  they cannot account for large changes in evolution  because large changes are made possible by the acquisition of new gene loci with previously nonexistent functions.  
ohno continues  
 only by the accumulation of forbidden mutations at the active sites can the gene locus change its basic character and become a new gene locus. an escape from the ruthless pressure of natural selection is provided by the mechanism of gene duplication. by duplication  a redundant copy of a locus is created. natural selection often ignores such a redundant copy  and  while being ignored  it accumulates formerly forbidden mutations and is reborn as a new gene locus with a hitherto non-existent function.   emphasis in original . 
ohno concludes  
 thus  gene duplication emerges as the major force of evolution.  
　ohno's provocative thesis is supported by the discovery of pairs of proteins with similar sequences of dna and similar sequences of amino acids  but distinctly different functions. examples include trypsin and chymotrypsin; the protein of microtubules and actin of the skeletal muscle; myoglobin and the monomeric hemoglobin of hagfish and lamprey; myoglobin used for storing oxygen in muscle cells and the subunits of hemoglobin in red blood cells of vertebrates; and the light and heavy immunoglobin chains. 
　in gene deletion  there is a deletion of a subsequence of nucleiotide bases that would otherwise be translated into work-performing proteins in the cell. 
　analogs of the naturally occurring operation of gene duplication have been previously used with genetic algorithms operating on character strings and with other evolutionary algorithms. holland  1  page 1  suggested that intrachromosomal gene duplication might provide a means of adaptively modifying the effective mutation rate by making two or more copies of a substring of adjacent alleles within an overall string. cavicchio  1  used intrachromosomal gene duplication in early work on pattern recognition using the genetic algorithm. gene duplication is implicitly used in the messy genetic algorithm  goldberg  korb  and deb 1 . lindgren  1  analyzed the prisoner's dilemma game using an evolutionary algorithm that employed an operation analogous to gene duplication applied to strings. gruau  1  used genetic programming to develop a clever and innovative technique to evolve the architecture of a neural network at the same time as the weights are being evolved. 
1 new architecture-altering operations 
the six new architecture-altering genetic operations provide a way of evolving the architecture of a multi-part program during a run of genetic programming. meanwhile  darwinian selection continues to favor the more fit individuals in the population to participate in the operations of crossover and mutation. 
1 branch duplication 
the operation of branch duplication duplicates one of the branches of a program in the following way: 
　 1  select a program from the population. 
　 1  pick one of the function-defining branches of the selected program as the branch-to-be-duplicated. 
　 1  add a uniquely-named new function-defining branch to the selected program  thus increasing  by one  the number of function-defining branches in the selected program. the new function-defining branch has the same argument list and the same body as the branch-to-be-duplicated. 
　 1  for each occurrence of an invocation of the branch-tobe-duplicated anywhere in the selected program  e.g.  the result-producing branch or any other branch that invokes the branch-to-be-duplicated   randomly choose either to leave that invocation unchanged or to replace that invocation with an invocation of the newly created function-defining branch. 
　the step of selecting a program for all the operations described herein is performed probabilistically on the basis of fitness  so that a program that is more fit has a greater probability of being selected to participate in the operation than a less fit program. 

figure j program consisting of one two-argument function-defining branch  adfo  and one result-producing branch. 
k1za 　figure 1 shows an overall program consisting of one twoargument automatically defined function and one resultproducing main branch. figure 1 shows the program resulting after applying the operation of branch duplication to figure 1. specifically  the function-defining branch 1 of figure 1 defining adfo  also shown as 1 of figure 1  is duplicated and a new function-defining branch  defining adf1  appears at 1 in figure 1. there arc two occurrences of invocations of the branch-to-be-duplicated  adfo  in the result-producing branch of the selected program  namely adfo at 1 and 1 of figure 1. for each occurrence  a random choice is made to either leave the occurrence of adfo unchanged or to replace it with a reference to the newly created adf1. for the first invocation of adfo at 1 of figure 1  the choice is randomly made to replace adfo 1 with adf1 in figure 1. the arguments for the invocation of adfl 1 are dl 1 and d1 in figure 1  i.e.  they are identical to the arguments dl 1 and d1 for the invocation of adfo at 1 in figure 1 . for the second invocation of adfo at 1 of figure 1  adfo is left unchanged. 
　the new branch is identical to the previously existing branch  except for the name adf1 at 1 in figure 1 . moreover  adf1 at 1 is invoked with the same arguments as adfo at 1. therefore  this operation does not affect the value returned by the overall program. 
　the operation of branch duplication can be interpreted as a case splitting. after the branch duplication  the resultproducing branch invokes adfo at 1 but adf1 at 1. adfo and adf1 can be viewed as separate procedures for handling the two subproblems  cases . subsequent genetic operations may alter one or both of these two presentlyidentical function-defining branches and these subsequent 
changes to lead to a divergence in structure and behavior. this subsequent divergence may be interpreted as a specialization or refinement. that is  once adfo and adf1 diverge  adfo can be viewed as a specialization for handling for subproblem associated with its invocation at 1 and adf1 at 1 can be viewed as a specialization for handling its subproblem. 
　the operation of branch duplication as defined above  and all the other new operations described herein  always produce a syntactically valid program  given closure . 
1 argument duplication 
the operation of argument duplication duplicates one of the dummy arguments in one of the automatically defined functions of a program in the following way: 
　 1  select a program from the population. 
　 1  pick one of its function-defining branches. 
　 1  choose one of the arguments of the picked functiondefining branch as the argument-to-be-duplicated. 
　 1  add a uniquely-named new argument to the argument list of the picked function-defining branch of the selected program  thus increasing  by one  the number of arguments in its argument list. 
　 1  for each occurrence of the argument-to-bc-duplicatcd in the body of picked function-defining branch of the selected program  randomly choose either to leave that occurrence unchanged or to replace it with the new argument. 
　 1  for each occurrence of an invocation of the picked function-defining branch anywhere in the selected program  identify the argument subtree corresponding to the argumentto-be-duplicated and duplicate that argument subtree in that invocation  thereby increasing  by one  the number of arguments in the invocation. 
　because the function-defining branch containing the duplicated argument is invoked with an identical copy of the previously existing argument  this operation leaves unchanged the value returned by the overall program. 
　the operation of argument duplication can also be interpreted as a case-splitting. the particular instantiations of the second and third arguments in the invocations of adfo provide potentially different ways of handling the two separate subproblems  cases . 
1 branch creation 
the branch creation operation creates a new automatically defined function within an overall program by picking a point in the body of one of the function-defining branches or result-producing branches of the selected program. this picked point becomes the top-most point of the body of the branch-to-be-created. the operation of branch creation is similar to  but different than  the compression  module acquisition  operation of angeline and pollack  1 . 
1 argument creation 
the argument creation operation creates a new dummy argument within a function-defining branch of a program. details of all the new operations are in koza 1c. 
1 branch deletion 
the operations of argument duplication  branch duplication  branch creation  and argument creation create larger programs. the operations of argument deletion and branch deletion can create smaller programs and thereby balance the persistent growth in biomass that would otherwise occur. 
　the operation of branch deletion deletes one of the automatically defined functions. 
　when a function-defining branch is deleted  the question arises as to how to modify invocations of the branch-to-bedeleted by the other branches of the overall program. the alternative used herein  called branch deletion with random regeneration  randomly generates new subtrees composed of the available functions and terminals in lieu of the invocation of the deleted branch. 
1 argument deletion 
the operation of argument deletion deletes one of the arguments to one of the automatically defined functions of a program. when an argument is deleted  references to the argumenl-to-be-deleted may be corrected by argument deletion with random regeneration. the operations of argument deletion and branch deletion affect the value returned by the overall program. they may be viewed as a generalization in that some information that was once considered in executing the procedure is now ignored. 
1 creation of the initial population 
when the architecture-altering operations are used  the initial population of programs may be created in any one of three ways. one possibility  called the minimalist approach  is that each multi-part program in the population at generation 1 has a uniform architecture with exactly one automatically defined function possessing a minimal number of arguments appropriate to the problem. a second possibility  called the big bang  is that each program in the population has a uniform architecture with no automatically defined functions  i.e.  only a result-producing branch . this approach relies on branch creation to create multi-part programs in such runs. a third possibility is that the population at generation 1 is architecturally diverse  as described in koza 1a . 
1 structure-preserving crossover 
when the architecture-altering operations arc used  the population quickly becomes architecturally diverse. structure-preserving crossover with point typing  koza 
1a  permits robust recombination while simultaneously guaranteeing that any pair of architecturally different parents will produce syntactically valid offspring. 
1 example of an actual run 
the architecture-altering operations described herein will now be illustrated by showing an actual run of the problem of symbolic regression of the cven-1-parity function. boolean parity functions are often used as benchmarks for experiments in machine learning because a change in any one input  environmental sensor  toggles the outcome. the problem is to discover a computer program that mimics the behavior of the boolean even-k-parity problem for every one of the 1k combinations of its k boolean inputs. the primitive functions are and  or  nand  and nor. 
　a population size  m  of 1 was used. all runs solved well before the targeted maximum number of generations  g  of 1. the run uses the minimalist approach in which each program in generation 1 consists of one result-producing branch and one two-argument functiondefining branch. on each generation  there were 1% crossovers; 1% reproductions; 1% mutations; 1% branch duplications  1% argument duplications; 1% branch deletions; 1% argument deletions; 1% branch creations; and 1% argument creations. other minor parameters were chosen as in koza 1a. 
　the problem was run on a home-built medium-grained parallel computer system. in the so-called distributed genetic algorithm or island model for parallelization  tanese 1   different semi-isolated subpopulations  called demes after wright 1  are situated at the different processing nodes. the system consisted of a host pc 1 type computer running windows and 1 transtech trams  containing one inmos t1 transputer and 1 megabytes of ram memory  arranged in a toroidal mesh. there were d 
- 1 demes  a population size of q = 1 per deme  and a migration rate of b = 1%  in each of four directions on each generation for each deme . generations are run asynchronously. details of the parallel implementation of genetic programming on a network of transputers can be found in koza and andre 1. 
　on generation 1 of one run  a 1%-correct solution to the even-1-parity problem emerged in the form of a computer program with one three-argument automatically defined function and one two-argument automatically defined function. three-argument adf1  which originally had only two arguments in generation 1  performs boolean rule 1  a non-parity rule. two-argument adf1  which did not exist at all in generation 1  is equivalent to the odd-1-parity function. the result-producing branch of this program invokes both adf1 and adfl. 
1 performance of the new operations 
we now use the boolean even-1-parity problem to compare  over a series of runs  the performance of the architecturealtering operations for the following five approaches: 
　 a  without automatically defined functions 
 corresponding to the style of runs discussed throughout most of genetic programming   
　 b  with automatically defined functions  evolutionary selection of the architecture  corresponding to the style of runs in chapters 1 of genetic programming ii   an architecturally diverse initial population  and structurepreserving crossover with point typing  
　 c  with automatically defined functions  the architecture-altering operations described herein  an architecturally diverse population  after generation 1   and structure-preserving crossover with point typing  
　 d  with automatically defined functions  a fixed usersupplied architecture that is known to be a good choice for this problem  i.e.  one three-argument and one two-argument automatically defined function   and structure-preserving crossover with point typing  and 
　 e  with automatically defined functions  a fixed  usersupplied  known-good architecture  and structure-preserving crossover with branch typing  corresponding to the style of runs throughout most of genetic programming ii . 
　the comparisons are made for the following three performance characteristics: computational effort  e  with 1% probability ; the wallclock time  w m t z  in seconds with 1% probability ; and the average structural 
koza 

complexity  s. these three measures are described in detail in koza 1a. 
　as table 1 shows  all four approaches employing automatically defined functions  b  c  d  or e  require less computational effort than not using them  approach a . approach e  which benefits from user-supplied architectural information  requires the least computational effort. 
　approach c  using the architecture-altering operations  requires less computational effort than solving the problem without automatically defined functions  approach a   but more than with the fixed  user-supplied  known-good architecture  approach e . 
　approach d isolates the additional computational effort required by point typing  relative to approach e . greater computational effort is required by approach d than approach e. since the computational effort for approach c is virtually tied with approach d  the cost of architecturealtering operations for this problem is not much greater than the cost of point typing. 
　approach e consumes less wallclock time than approach c  using the architecture-altering operations   which  in turn  consumes less wallclock time than approach a  without automatically defined functions . 
　the average structural complexity  s  for all four approaches  b  c  d  or e  employing automatically defined functions is less than that for approach a  without automatically defined functions . approach c  using the architecture-altering operations  has the lowest value of s  i.e.  produces the most parsimonious solutions . 
acknowledgements 
david andre and walter alden tackett wrote the computer program in c to implement the above. 
