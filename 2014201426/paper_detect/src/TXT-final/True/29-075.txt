 
current inductive logic programming systems are limited in their handling of noise  as they employ a greedy covering approach to constructing the hypothesis one clause at a time. this approach also causes difficulty in learning recursive predicates. additionally  many current systems have an implicit expectation that the cardinality of the positive and negative examples reflect the  proportion  of the concept to the instance space. 
a framework for learning from noisy data and fixed example size is presented. a bayesian heuristic for finding the most probable hypothesis in this general framework is derived. this approach evaluates a hypothesis as a whole rather than one clause at a time. the heuristic  which has nice theoretical properties  is incorporated in an ilp system  l i m e . experimental results show that l i m e handles noise better than foil and progol. it is able to learn recursive definitions from noisy data on which other systems do not perform well. l i m e is also capable of learning from only positive data and also from only negative data. 
1 	introduction 
most ilp systems like golem  muggleton and feng  1  and foil  quinlan  1  employ a greedy covering heuristic to build hypotheses. they try to find the clause that covers maximum number of positive examples without covering any or few negative examples. a new set of positive examples is created by removing the covered positive examples and the process is repeated with this new set of positive examples and the negative examples until there are no uncovered positive examples 
* supported by an australian postgraduate award. 
 
　　 supported by australian research council grant a1. 
1 	probabilistic reasoning 
left. while this approach has lead to efficient learning in many applications  there are situations in which it fails to perform well. 
	consider the problem of noise handling. 	golem 
 muggleton and feng  1  has a rudimentary noise handling facility as each clause is allowed to cover a fixed number of negative examples in addition to as many positive examples as possible. this approach is inflexible as it requires adjusting the noise parameter with changes in sample size and noise level. inflexibility aside  handling of noise at the clause level  in many cases  appears to result in a poor overall hypothesis  mainly because of overfitting. foil  quinlan  1  employs an m d l / m m l  rissanen  1; wallace and freeman  1  like approach to noise handling. while this is better than an ad hoc approach  its greedy covering strategy of building the hypothesis one clause at a time can lead to overfitting in the presence of noise  for example  see figure 1 that describes foil's performance on a simple predicate plus1 .1 a single clause only yields information about overgeneralization errors  information about data not covered by the hypothesis requires looking at the complete hypothesis. 
　another problem with current ilp systems arises while learning predicates that require recursive definitions. in these situations  for successful learning to take place  a system has to be provided with a complete initial sequence of the data  including the base case. however  if the data is sparse  it becomes very difficult for these systems to learn hypotheses with recursive clauses. again  an approach that evaluates complete hypotheses instead of individual clauses does a better job of overcoming such deficiencies in the data. 
　apart from the above mentioned difficulties  many applications of m d l / m m l like heuristic have an implicit expectation that the distribution of examples received by 
   1mfoil  lavrac et o/.  1  has an improved noise handling capability  but it still suffers from the greedy covering approach. noise handling in linus  lavrac and dzeroski  1  is more about taking advantage of noise handling techniques from attribute value learning. 

the learner matches the true  proportion  of the underlying concept to the instance space. however  in many learning situations this assumption is unjustified. usually the cardinality of positive and negative examples is fixed and independent of the concept being learned. as an example  consider a learner presented with a set of 1 positive and 1 negative examples of cancer patients. it is very unlikely that this set of examples is representative of the population from where the examples are drawn. moreover  many systems require a minimum number of positive and negative examples. 
　motivated by the above problems with existing ilp systems  the present paper introduces a general framework for noise handling in learning systems  and derives a bayesian heuristic for inducing a hypothesis with the maximum posterior probability. the framework assumes that the number of examples is fixed independent of the concept  and certainly not representative of the actual proportion of the concept to the instance space . hence  the heuristic can be employed to learn from only positive data and from only negative data in addition to the usual combination of positive and negative data. an interesting theoretical result about the framework is that it formalizes the intuitive importance of an extra positive example over an extra negative example for concepts that are  small  with respect to the instance space. a similar result for the importance of negative examples over positive examples holds for concepts that are  large  with respect to the instance space. empirical evidence in keeping with these theoretical results are presented. 
　the heuristic is adapted for ilp and implemented in the llme system that considers complete candidate hypotheses rather than single clauses. we would like to note that another system that looks at complete hypotheses instead of single clauses is tracy  bergadano and gunetti  1 . a theoretical bound is derived that yields a bound on the search space for the most probable hypothesis. it is shown that l i m e equipped with this heuristic handles noise better than foil and progol. empirical results also show the effectiveness of this heuristic in handling recursive definitions from sparse data. additional results are presented to show that this heuristic is capable of learning from only positive data and from only negative data. 
1 	noise model and the bayesian heuristic 
we describe a framework of learning for modeling noise and fixed example size. within this framework  we derive a bayesian heuristic for the optimal hypothesis. 
　let x denote a countable class of instances. let dx be a distribution on the instance space x. let 1x be a countable concept class. let dc represent the 

figure 1: model of positive example generation 
distribution on c. let h be a hypothesis space and p be the distribution  prior  over h. the concept represented by a hypothesis h is referred to as the extension of h  written: ext h  . further  let c and h be such that: 
  for each  such that c = ext h ; and 
  for each 
　we assume that a concept c is chosen with the distribution dc- let  be the level of noise. suppose we want to generate m positive examples and n negative examples  the reader should note that in the fixed noise model  m and n are independent of the concept c . 
　now  each of the m positive examples are generated as follows: with probability a instance is randomly choose from x and made a positive example  this could possibly introduce noise . with probability an instance is repeatedly selected randomly from x until the instance is an element of the concept. this instance is the positive example generated. figure 1 illustrates this process. the generation of negative examples is done similarly1. 
　the fixed example size aspect of the framework makes it more flexible than other frameworks that have an implicit expectation that the proportion of positive and negative examples reflects the concept. the reader should note that this allows learning to take place from only positive data and from only negative data in addition to the usual combination of positive and negative data. 
　we now derive a bayesian heuristic for finding the most probable hypothesis h given the example set e.1 
   1  the level of noise e can be made different for the positive and negative examples  but for simplicity we take it to be the same. 
   1  all references to example sets are actually references to example multisets. 
	mccreath & sharma 	1 

this induction can be formally expressed as follows.1 substituting 1 and 1 into 1 and using tp  tn  and fpn  we get the following. 

we will apply occam's razor in computation of p h   
now substituting 1 into 1 and 1 into 1 and perform-
the prior probability of the hypothesis h  thereby assigning additional arithmetic manipulation  we obtain the 
ing higher probabilities to simpler hypotheses  where q h  is defined 
the probability of the examples e given that hypoth-
                                                             as follows. esis h represents the target cpncept  can be calculated by taking the product of the conditional probabilities of the positive and negative example sets. as each positive example is generated independently   may be calculated by taking the product of the conditional probabilities of each positive example.  the con-
ditional probability of a positive example e given hypothesis h  is computed as follows. hence  in our inductive framework  a learning system attempts to maximize q h   referred to as the quality of the hypothesis h . a number of theoretical results can be shown about this heuristic. for example  the following theorem formalizes the intuitive expectation that if the proportion of a concept to the instance space is small  then positive examples are more useful than negative ones. 
1 	probabilistic reasoning 

to this setting  we need to interpret h in equations 1 as 
　lime's functioning may be described in three stages:  a  preprocessing of the background knowledge   b  generation of candidate clauses  and  c  search for the most probable hypothesis. 
　l i m e preprocesses the backgound knowledge to identify functional dependencies  type information  and redundancies  mccreath and sharma  1 . this step is very helpful in reducing the search space. most ilp systems require such information to be explicitly provided together with data. 
　the second phase then uses the above information together with the examples and the background knowledge to construct a large set of candidate clauses. these candidates are selected on the basis of their potential to form part of the most probable hypothesis. subsets of this set are searched for a set of clauses  h  such that the value of q h  is maximized. clearly  it is infeasible to examine all subsets  although  an exhaustive  but finite  search will find an optimal hypothesis. so  we digress a little to describe the following theorem that gives a bound on the search space for the most probable hypothesis. 

proof: we omit the proof. 
the above result is useful because once the value of 
q h  is known for any h h  the system has a bound on the prior probability of the most probable hypothesis  thereby restricting search to a finite well defined set of hypotheses. since there are at least three such readily available hypotheses-the hypothesis that entails the entire instance space  the hypothesis that entails no memebr of the instance space  and the hypothesis that exactly entails the positive examples-such a bound can be determined. 
　the above discussion notwithstanding  it is easy to see that the bound still leaves an infeasible amount of search to be done. however  these sets form a lattice under the subset operation in such a way that the more general elements of the lattice have both lower prior probablity and are more general in terms of the instances they cover. this property gives structure to the search space  and allows each element in the lattice to be assigned a value that estimates an upper bound on the heuristicvalue of more general elements in the lattice. an a*like search of this lattice produces the final hypothesis. 
entire branches of the lattice may be pruned if the estimated upper bound for a branch is less than the heuristics value of the best hypothesis so far. this pruning reduces expected execution time significantly. also  before a hypothesis replaces the best hypothesis so far  a prolog interperator is used to determine the hypothesis' exact coverage  thereby providing a more accurate estimate of the heuristic. this step also removes poorly constructed recursive hypotheses  thereby enhancing lime's ability to learn recursive logic programs. a detailed description of l i m e will be given in a more expanded paper. 
　we now briefly discuss the computation of q h  for a hypothesis h. prom equation 1  it is clear that computation of q h  requires  i  cardinality of tp  tn  and fpn;  ii  1 ext h  ; and  iii  p{h -the prior probability of the hypothesis h. each of the items in  i  can be estimated from the example sets  h  and a prolog interpreter. 1 ext h   is estimated by randomly generating a set of instances and finding the proportion in this set of the concept represented by h with the help of a prolog interpreter. the computation of the prior p h  is somewhat involved. each clause in a hypothesis is considered independent and as more clauses are added  the prior probability of a hypothesis decreases. the prior probability of a clause is computed from prior probability of literals  which in turn is computed from prior probability of variables. current implementation of l i m e uses the geometric distribution in the above computations. however  it turns out that as the number of examples increases  the prior probability of a hypothesis h becomes less and less important in the computation of q h . this result can be formally established using the borel-cantelli lemma. the details of the p h  and the associated theoretical result will be presented in an expanded version of the paper. 
1 	empirical results 
we present three sets of experiments to illustrate how 
l i m e achieves its design goals of better noise handling  learning from fixed set of examples  and of learning recursive logic programs. since these goals are our main focus here  we have omitted to include the time performance of l i m e . it should be noted that lime's time performance is of the same order as that of the other systems being compared in this study. 
noise 
we first demonstrate lime's superior noise handling capability for the simple concept plus1  which may be represented by the following logic program: 

in the above inc denotes the increment predicate available as background knowledge. a random selection of 1 positive and 1 negative examples are given to l i m e . 
	mccreath & sharma 	1 


figure 1: predictive error vs noise for plus1 


                     noise figure 1: predictive error vs noise for add 

these examples include noise. the predictive error of the induced hypothesis is measured against a noise-free test set that is generated by taking the  first  1 positive examples and a random selection of 1 negative examples. this process is repeated 1 times to calculate the average predictive error. this is repeated with different noise levels and the results are shown in figure 1. the error bars in the figure indicate the sample standard deviation. the results show that llme is able to correctly learn the concept with noise levels of up to approxamatly 1%. the same test is carried out with foil and 
progol.1 
　l i m e performs better than foil and progol for noise levels of up to approximately 1%. here  foil overgenerizes inducing a less predictive hypothesis. this is mainly due to the covering approach which introduces unnecessary clauses. however  for noise levels higher than 1%  l i m e   progol and foil perform poorly. 
we next show lime's noise handling ability with add 
 the addition relation -a more complex target predicate that requires a recursive definition. the target concept may be represented by the hypothesis: 

this time we take a random selection of 1 positive and 1 negative examples but perform only 1 repeations at each noise level. figure 1 shows the relationship between noise and predictive error measured against a noise-free test set of the  first  1 positive examples and a random set of 1 negative examples. the results show that gap between l i m e and other system widens further when the target concept requires a recursive definition. experiments with foil and progol were limited to 1% and 1% noise levels respectively because the quality of the programs output by these systems beyond these noise levels were difficlut to assess. 
learning from positive examples and from negative examples 
our second set of experiments shows empirical evidence for theorem 1 which implies that positive examples are more useful than negative examples for a target concept that is  small  with respect to the instance space distribution. the experiments also give evidence for the converse that negative examples are more useful than positive examples for a target concept that is  large  with respect to the instance space distribution. these experiments also establish that l i m e is capable of learning from only positive data and from only negative data. 
　we consider two concepts  the plus1 and notplus1  the complement of plus1-that is  notplus1 a  b  holds if  it is easy to see that under reasonable assumptions  plus1 is a  small  concept and notplus1 is a  large  concept. l i m e is run on examples of plus1 and notplus1 with identical background knowledge. the total number of examples is invariant over each test  however  the number of positive examples is increased as the number of negative examples is decreased. each test is repeated 1 times and the results for both plus1 and notplus1 are shown in figure 1. 
recursive logic programs 
table l1 summarizes experimental results on lime's ability to learn a number of predicates that require recursive definitions. it should be noted that the data sets used in these experiments are noisy and not contiguous. foil cannot learn these predicates from such data sets. 

     1  all our experiments are with foil  version 1 and with progol  version 1. 
1 	probabilistic reasoning 
     1  the column titled  incorrect  denotes the % of incorrect examples given to lime. 


figure 1: error vs i  i = number of positive examples & 1-i = number of negative examples  for the plus1 and notplus1 logic programs 

table 1: some recursive logic programs 
1 	discussion 
another approach to modeling noise in learning systems is due to  angluin and laird  1 . their noise level parameter measures the percentage of data with the incorrect sign  that is  elements of the concept being mislabeled as negative data and vice versa. in their model 1% noise level means the data is truly random  whereas in our model truly random data is at noise level of 1%. thus  in their model it is not useful to consider noise levels of greater than 1%. our current model requires that the noise level be provided to the system. although this may appear to be a weakness  in practice  a reasonable estimate suffices  and it can be shown that with increase in the example size  the impact of an inaccurate noise estimate diminishes. it should be noted that experiments reported in this paper always used a noise parameter of 1% in computing q h  even if the actual noise in the data was considerably higher. 
　recently  we have become aware of the work of  muggleton  1  in which he has used a bayesian heuristic for learning from only positive data. interestingly  if we take the noise level to be 1 in our model and only consider positive examples  then our heuristic becomes identical to muggleton's. 
　future work will attempt to derive stochastic convergence in the limit results for the noise model presented in this paper in the style of laird's  laird  1  result for the angluin-laird noise model. another direction would be to do adapt the predicative error analysis of  muggleton  1  for the bayesian heuristic with noise and fixed example size. on the empirical front  applicability of l i m e on additional real-world domains will be investigated. to this end we would like to note that initial experiments with l i m e on protein secondary structure data show comparable results to golem. 
acknowledgements we would like to thank m. bain for bringing  muggleton  1  to our attention. we would also like to thank the referees for several valuable comments that have improved the paper. 
