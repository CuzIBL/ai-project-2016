 
this paper describes an evolvable hardware  ehw  system for generalized neural network learning. we have developed an asic vlsi chip  which is a building block to configure a scalable neural network hardware system. in our system  both the topology and the hidden layer node functions of a neural network mapped on the chips are dynamically changed using a genetic algorithm. thus  the most desirable network topology and choice of node function  e.g. gaussian or sigmoid  for a given application can be determined adaptively. this approach is particularly suited to applications requiring ability to cope with time-varying problems and real-time timing constraints. the chip consists of 1 digital signal processors  dsps   whose functions and interconnections are reconfigured dynamically according to the chromosomes of the genetic algorithm. incorporation of local learning hardware increases the learning speed significantly. simulation results on adaptive equalization in digital mobile communication are also given. our system is two orders of magnitude faster than a sun ss1 on the corresponding problem. 
1 	introduction 
the traditional applications of neural networks focused on the off-line learning of a given function using a single network whose weights are gradually modified. in recent years  the alternative approach of on-line adapting by reshaping the network itself has been attracting renewed attention  fiesler  1 . the on-line approach has the advantages of efficiency and flexibility which are impossible with the off-line approach. we embody this on-line approach with evolvable hardware  ehw   higuchi et al.  1  higuchi et al.  1 . ability of this method to dynamically adapt to changing situations is particularly suited to practical industrial applications. 
　however  optimal performance for a given application is produced by an architecture with the most suitable topology and the most appropriate node functions  i.e. 
1 	neural networks 
sigmoid or gaussian . further  to meet the time constraints imposed by real-time applications  neural network hardware systems need to be 'tailored' to the size of the ideal network for the problem. in general  it is very difficult to design an optimal neural network and process it with scalable parallel hardware. 
　to solve these two problems  we have developed  1  a learning scheme which utilizes genetic algorithms  gas  to automatically select both the optimal network topology and the node functions  and  1  an evolvable hardware chip that functions as a building block for configuring a scalable neural network. 
　a concept of ehw is an innovative hardware design methodology for truly adaptive hardware systems  higuchi  1 . in systems designed by ehw concepts  both the choice of the hardware function on each processing element and the specification of these elements' interconnections are determined by a ga  goldberg  1  and reconfigured dynamically. the particular chip that we describe in this paper is an example of hardware designed by the ehw concept aimed at generalized neural network processing. 
　the paper is organized as follows. section 1 reviews related work on learning neural networks with gas  highlighting especially some of the shortcomings that our learning scheme will address. section 1 describes the concept of ehw. section 1 explains our new scheme and how ehw chips are dynamically configured to process neural networks. in section 1  we report simulation results on the problem of adaptive equalization in digital mobile communication. section 1 briefly describes the chip  and section 1 gives our conclusions. 
1 	evolutionary neural networks 
many researchers have worked on designing neural networks with gas. since there are many thorough reviews on this work  schaffer et a/.  1  yao  1   we do not attempt an exhaustive review here. such approaches typically utilize a ga to evolve the optimal topology of an appropriate network  and then use back-propagation to train the weights. however  using this approach online for industrial applications would be difficult because of the slow speed of both the back-propagation and ga components. 


figure 1: evolvable hardware at the gate-level 
to improve the learning speed  radial basis function 
 rbf  networks  powell  1  poggio and girosi  1  combined with genetic algorithms may be an appealing choice. indeed  the learning speed of rbf networks  rbfns  can outperform multi-layer perception  mlp  by up to three orders of magnitude  moody and darken  1j.billings  for example  has worked on the genetic synthesis of rbfns  billings and zheng  1 . 
　however  compared with the mlp  rbfn requires large numbers of hidden layer nodes  particularly for high-dimensional input /output spaces  the  curse of dimensionality  . it was therefore our idea to mix the use of rbfs and sigmoid functions within a single architecture. further  rather than specifying a priori how the two functions should be combined  we developed a method of using a ga to automatically tailor the node functions in a network to a given problem. to reduce the learning time  a local learning algorithm is first applied to bring the network weights to a reasonable level. this local learning is performed in parallel by hardware. 
　one significant benefit of our approach is that the network structure can vary in time. this is not possible with conventional neural network hardware  but our chip allows the optimal network structure and node functions to be dynamically reconfigured even while the network is being used on-line. in other words  our hardware system is a parallel processor where the number of processing elements is varied by a ga to continually produce the best performance. 
1 	evolvable hardware 
　the method of the evolvable hardware design is to change dynamically following two hardware configurations according to the ga chromosomes:  1  choices of a hardware function on each processing element of a soft ware-reconfigurable device and  1  specification of interconnections between these elements. these reconfigurations can continue on-line to improve performance adaptively. in the conventional hardware design  it is necessary to prepare all the specifications of the hardware functions in advance. on the other hand  ehw can be reconfigured without such specifications. from this  we can see that the ehw concept provides a contrasting bottom-up hardware design methodology to the conventional top-down methodology. thus  ehw is particularly suited to real-time applications where no hardware specification can be given in advance. 
　to realize the ehw concept  most existing research employs field programmable gate arrays  fpgas  and programmable logic devices  plds  as softwarereconfigurable devices. their internal circuit connections and node logic functions can be reconfigured by downloading binary strings  called architecture bits. the basic idea of these researches is to regard the architecture bits as chromosomes and to evolve good hardware structures by applying gas to these strings  as shown in figure 1. 
　attempts to apply most research on ehw to practical problems  however  would suffer from the common problem that only relatively small circuits can be evolved. this is because the hardware evolution is based on primitive gates such as and-gates and or-gates; we call the evolution at this level gate-level evolution. the hardware functions resulting from gate-level evolution are not typically powerful enough for use in industrial applications. 
　in order to solve this problem  we have proposed a new type of hardware evolution: function-level evolution  murakawa et a/.  1 . our proposal is that if hardware is genetically synthesized from high-level hardware functions  such as adders and multipliers  instead of primitive gates  like and and or gates   more useful hardware functions will be obtained. depending on the application  the high-level function and the topology of the interconnection need to be determined carefully. this suggests that  there will be a variety of ehw architectures at the function-level. the particular chip that we describe in this paper is an example of hardware designed for the function-level evolution. in the chip  the high-level functions can be directly implemented by a single dsp to perform the neural network processing 
 e.g. summation  calculation of the sigmoid functions or rbfs . the interconnections and the functions of each dsp are then determined by the ga chromosomes. 
1 	evolvable hardware for generalized neural networks 
we have developed a learning scheme for a generalized neural network  murakawa et a/.  1 . we describe the genetic: learning and then show how the network is mapped onto fpmd  field programmable multiple dsps  chips. fpmd is an evolvable hardware chip specially designed for implementing generalized neural networks. 
1 	genetic learning 
the generalized neural network considered here is defined as follows: 

	murakawa  et al. 	1 

figure 1: evolvable hardware for generalized neural networks 
basis function  rbf  or sigmoid function: 

the number of outputs in the network is assumed to be one  but the architecture can be readily extended to cope with multi-output problems. 
the genetic learning determines the network topology 
 e.g. the number of nodes:n  and the choice of node functions  e.g. gaussian or sigmoid function  adaptively for a given application. 
	the 	and the parameters of the node functions 
 e.g. are tuned by local learning with the steepest descent method. in table 1  descriptions of the genetic operators are given  for more details  see  murakawa et al.  1  . 
　figure 1 illustrates this genetic learning. a chromosome of the ga represents one network. the network is evolved by applying the genetic operators to the chromosome. for example  figure 1 shows how a network 
1 	neural networks 
table 1: genetic operators 
  coding | a chromosome consists of n genes gene a gene represents one hidden layer node 
 node function and the parameter  selection tournament selection 
 tournament size is 1  crossover modified two-point crossover mutation 	| three types of mutations: insertion of a node - insert a rbf node or a sigmoid node deletion of a node - delete a node 
selected randomly 	| replacement of a node change the node function random immigrant |　1% of the population are replaced  with new individuals created randomly 	| local 
learning 	|　tune the node parameters by  iterations of the steepest descent method with two hidden layer nodes  a  is evolved to have 1 nodes  b . 
1 	mapping on the f p m d chips 
in section 1  we have described how the most desirable network structure and the choice of the node functions are determined with genetic learning. here we show how the obtained network is mapped on the fpmd chips and how they are reconfigured dynamically. 
　the fmpd chip is a building block to configure a scalable neural network hardware. an arbitrary size of neural network hardware can be configured with multiple fpmds because the chip includes 1 dsps connected in a binary tree shape as shown in figure 1 c . 
　the obtained neural network by genetic learning is immediately mapped on fpmds. for example  the network in figure 1 a  can be mapped onto fpmd no.l in figure 1 c . in this case  as the network is still small  only one fpmd is used. 
　each dsp can perform any arithmetic function. so  for example  by using the seven dsps in fpmd no.l in figure 1 c   on the right side   a sigmoid function is effectively implemented with the binary tree connections utilizing the inherent parallelism. binary tree connections are also very useful when the summation of outputs is calculated. for example  the fpmd no. 1 in figure 1 d  is configured to conduct the summation in parallel. 
　the functions and interconnections of the fpmd chips are dynamically controlled by rewriting the chromosome. for example  the output of the fpmd no.1 in figure 1 c  is connected to the dsp no.l. after evolution the dsp no.1 is connected to the output in figure 1 d . 
also  the 1 dsps on the right side of the fpmd no.l in figure 1 c  calculate the sigmoid function. after reconfiguration they are changed to the gaussian function in figure 1 d . 


figure 1: adaptive equalizers 
1 	adaptive equalizer in digital mobile communication 
to examine the performance of our system  we conducted a simulation of adaptive equalization in digital mobile communication. in particular  the ability to adapt to a dynamically changing environment was of special concern to us. 
　high-speed communications channels arc often impaired by linear and non-linear channel distortion and additive noise. to obtain reliable data transmission in such communications systems  adaptive equalizers are required  proakis  1   in digital mobile communications  the channel can be influenced by environmental conditions such as landscape and the presence of buildings  figure 1 . the task of the equalizer is to recover the transmitted symbols based on the channel observation y t . 
　existing adaptive equalization techniques for timevarying channels employ a linear transversal filter  figure 1 . however  if the non-linear channel distortion is too severe  adaptive equalizers based on such linear transversal filters suffer from severe performance degra-

figure 1: 	learning performance of the ehw-based 
equalizer  snil: 1 db  

figure 1: bit error rate of the ehw-based equalizer versus snr 
dation. for such channels  non-linear adaptive equalizers based on neural networks were proposed  chen et al.  1  chen et al.  1 . but the algorithms are so 
complicated for hardware implementation. 
　to overcome these difficulties  we apply our system to the adaptive equalizer. a communications system that employs the ehw-based adaptation equalizer is shown in figure 1. the transmitter sends a known training sequence to the receiver  and the receiver adjusts the ehw-based equalizer so that it reproduces the correct transmitted symbols. 
1 learning performance of the ehw-based equalizer 
we simulated the learning performance of the proposed ehwt-based equalizer. the transfer function of the channel was given by  and zero-mean white gaussian noise was added to the output of the channel. the order of the equalizer was 1  m = 1 . 
　a training set of eight data points was generated at every generation. using a population size of 1  the fitness of each individual was determined by n/1  where n was the number of correct classifications by the ehw. the bit-error-rate  ber  was defined as the ratio of misclassified to correct symbols in the output of the best-ofgeneration individual. the ber was evaluated at every generation based on 1 random input symbols. simulations were carried out which restricted the maximum 
	murakawa  et al. 	1 


figure 1: non-linear transmission channel used in the simulations 
number of the hidden layer nodes to 1. 
　figure 1 shows the learning performance of this simulation for a signal-to-noise ratio  snr  of 1 db. the solid curve was obtained by averaging the results of 1 independent runs. the broken line shows the learning curve of a transversal-filter-based equalizer  whose total number of training sequences was the same as that of the ehw. as can been seen  the ber of the ehwbased equalizer is far lower. this is due to the ability of the generalized neural network to synthesize non-linear functions. 
　figure 1 shows the ber versus snr achieved by the ehw-based equalizer at generation 1. we found that a significant improvement in the ber could be achieved by the ehw-based equalizer  especially at a high snr. 
1 adaptive equalization of time-varying channels 
in real communications systems  the characteristics of the channel are usually time-varying. hence  adaptive equalizers are required to follow such changes and compensate for the channel distortion. 
　we therefore simulated the performance of the ehwbased adaptive equalizer for time-varying channels  using the non-linear channel shown in figure 1. the transmitted sequence is passed through a linear channel whose 
transfer function is  and the output of the channel is added to the nonlinear harmonics. the value of the gain coefficients d1 d1 and d1 determines how severe the nonlinear distortion will be. such non-linear channel models are frequently encountered in data transmission over digital satellite links. the linear transversal-filter-based adaptive equalizer can not compensate for such non-linear channel distortion. 
　as before  we simulated the bit-error-rate achieved by the ehw-based adaptive equalizer whose order m was 1. simulations were performed for the case in which d  changed drastically during evaluation  figure 1  and for the case in which d  changed gradually  figure 1 . in the simulations  the coefficients were set to d1 = 1  d1 = 1  and d1 = 1. the length of the training sequence was 1. for the genetic learning  the maximum number of the hidden layer nodes was restricted to 1 and the population size was 1. the results were averaged over 1 independent runs. 
1 	neural networks 

	figure 1. time-varying 	figure 1. time-varying 
channel  drastic change channel  gradual change in d   	in d   

figure 1. adaptive 
equalization of the 
ehw-based equalizer 
 snr: 1 db  figure 1. adaptive 
equalization of the 
ehw-based equalizer  snr: 1 db  　the bers achieved by the ehw-based equalizer for the channels of figure 1 and figure 1 are shown in the graphs of figure 1 and figure 1  respectively. these graphs demonstrate that ehw-based equalizers have the ability to follow both drastic and gradual environmental change. 
1 	hardware implementation 
we have developed a prototype board and an asic vlsi chip. the fpmd chip is designed to implement generalized neural networks. 
1 	f p m d chip 
the fpmd chip includes 1 dsps connected in a tree shape. the tree size is genetically controlled. within a chip  broadcast hardware is included to speed up local learning. local learning is conducted in parallel at each dsp. the chip has 1k gates and operates at a 1 mhz clock speed. it will be available in july  1. for the learning of the adaptive equalizer  we have a simulation result that the execution with 1 fpmd chips takes 1 seconds while the execution on sun ss1 takes 1 minutes. 
1 	the prototype board 
the prototype board is designed to enable on-line adaptation. as shown in figure 1  the prototype board includes two sets of fpmd chips. one of the two fpmd sets is an execution fpmd set  which actually processes the incoming data. the other set is a learning fpmd set  which is continually used to find a better hardware 


arm : architecture bit memory 
figure 1: prototype board 
structure by genetic learning while the execution fpmd set is processing the existing best work. the training data are updated at regular intervals  enabling the architecture to keep track of a changing environment. 
　if the performance of the learning fpmd set is improved  then the execution fpmd set is reconfigured using the chromosome obtained by the learning fpmd set. thus  the system realizes on-line adaptation. 
　the design of the prototype board allows it to be connected to the pci bus of a personal computer. the ga calculation is performed outside the board  by the personal computer. 
1 	conclusion 
we have described a learning scheme and an evolvable hardware chip for generalized neural network learning. this development is aimed at the use in practical industrial applications  especially those which require the ability to cope with time-varying problems and real-time timing constraints. the need for such applications has been increasing recently. so  in addition to the adaptive equalizer  we are now working on loss-less data compression and atm buffer control. 
