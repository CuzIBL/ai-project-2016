 
we discuss some important properties of various search techniques  and some properties that knowledge must have in order to support adequate game playing behavior. 
i. some points on the continuum 
it seems that everything in game-playing  and possibly in all of ai  ultimately comes down to knowledge and search. this is really another case of a space/time tradeoff. all state-space problems can be solved by searching  if there were enough time to do a complete search of the problem space. also all problems can be solved by enough knowledge  by merely having all pertinent information available for every node in the problem space; provided it is available and there is enough space to store it. tasks that can be solved by either of these methods are considered not to be interesting. 
to search without knowledge when a complete search is not possible does not make sense. to apply partial knowledge without search has not been very successful in games such as chess. turing achieved only mediocre play with his  hand-simulated  chess program turochamp  tur1   and other attempts since then have not realized much improvement. 
thus interesting problems appear to require a combination of search and knowledge. however  there are many possible methods  both for controlling the search and for organizing the knowledge. knowledge must be able to detect interim advantages. in non-terminal states such interim advantages can be considered indicators of how the game may go in the future. 
a search with such knowledge will be able to find leaf nodes at the limit of its searching capability which maximize its understanding of the universe. however  such a search only understands  ends ; it does not understand  means . thus if it reaches a leaf node in a search to an arbitrary depth  it does not understand how it achieved its present success  or lack of it . this creates additional problems when a greater success can be achieved in another branch by the same means  but at a slightly greater depth. this is the horizon effect  ber1 . 
ii. some tractable search techniques 
it is convenient here to distinguish goal-directed searches which develop and prune nodes based on properties of a node  rather than the terminal value of its branch   and  mindless  techniques which search all of a predefined search space to find the optimal path  basing decisions solely on the value of terminal nodes. to date the latter techniques have been eminently more successful in game-playing. this is no doubt due to the tremendous amount of knowledge that is required 
1
 	this work was supported by the advanced research 
projects agency of the office of the secretary of defense 
 contract f1-c-1  and is monitored by the air force office of scientific research. 

invited panel-1; berliner 

to adequately guide a goal-directed search in a large domain. we now discuss advantages and limitations of each approach. 
a. techniques that search a uniform space 
it is now rather clear that the old controversy of depth-first vs. breadth-first search  if it was ever really controversial  has been resolved in favor of a new technique called depth-first search with iterative deepening. this technique was discovered independently by slate & atkin  sla1  of the northwestern university chess group  and james gillogly  then at carnegie-mellon university. the technique searches depth-first fashion to depth n  and reports its results. the search is then itereated to depth n+l  using information gained in the earlier searches. this information allows the guiding of the search so as to produce a better ordering of alternatives  which makes the alpha-beta mechanism more effective. this makes an iterated depth-n search cheaper than a depth-n search without the signposts  so to speak . these results indicate that search to one additional ply maintains much of the relative value structure of the branches  at least in a domain such as chess and almost certainly for any domain having structure. this technique is also very effective in allocating time to a search as the time for one additinal iteration can be well estimated from the previously iterations. thus this technique which combines the best features of depth-first alpha-beta  efficiency  and breadth-first  uniform coverage  appears vastly superior to any other technique that searches a uniform space. 
b. techniques that search selectively 
selective search techniques are generally classified as best-first searches. it is very probably that the reason that these techniques have not been very successful is that at every node it is necessary to apply knowledge to ciecide how to continue the search. the decision can range from stopping  to jumping to another branch of the tree  to selectively expanding the current node. the knowledge that could be used for such purposes is extensive  and it appears quite likely that no one has thus far been able to ciccumulate a data base of sufficient size and detail in any complex domain. however  it appears likely that there is another reason too; one-pass evaluation which we take up in section v. of the present techniques  harris' bandwidth .search  an adaptation of the a* procedure  appears very effective  har1 . 
i have recently invented a new procedure called the b* tree search procedure which combines the best facets of best-first searching with branch and bound  ber1 . this procedure requires that an optimistic and pessimistic value be assigned to every node at the time it is generated. when the most optimistic  as seen from the 
opponent's side  successor of node n is better for the side on move at node n than the previously estimated pessimistic value  then this pessimistic value is adjusted to correspond with the most optimistic value of the opponent. in the same way the optimistic value at node n must be adjusted if the pessimistic value of the most pessimistic successor to node n  as seen by the opponent  is worse than the previously estimated optimistic value. in this way values are backed up from newly expanded nodes. to find the next node to expand  it is only necessary to trace the most optimistic  for both sides  path through the tree and expand that node  although other search strategies are possible. the search terminates when it can be shown that the pessimistic value of a successor node to the root is at least as good a:  the best optimistic value of the remaining successors to the root. 

in diagram 1  we illustrate a simple search with b*. the upper part shows an initial tree configuration  and the lower shows the tree upon completion of the search. nodes in boxes have max to play; nodes in circles have min to play. the numbers inside the node symbols indicate the order in which nodes were expanded. the pair in brackets are the optimistic and pessimistic values at a node  updated by being crossed out . the search terminates because the pessimistic value of the right-most descendant of the root is no worse than the optimistic value of any other descendant. 
this search is guaranteed to converge as long as the estimates are consistent  though not necessarily correct . we believe that this algorithm will never expand more nodes than any other procedure having access to the same information. thus it should be the best of the and/or tree searching procedures. it can be trivially demonstrated that in its or/or form  it can never do worse than the a*  nil1  procedure which is supposed to be optimal. however  in all these procedures there are serious difficulties in finding reasonable functions for computing the bounding values. 

invited pane1: berliner 1 

c. mechanism within the search 
we consider that the actual tree search procedure is strongly subordinate to the ability to reject searching of sub-trees based on the semantics of the search. this type of pruning is supported by mechanisms that collect information  other than terminal values  during the search and back this up as the search progresses. decisions are then made  based on the backed-up information  which allow pruning of large sub-trees. 
the 	first 	of 	these 	mechanisms 	to 	appear 	was 	the 
causality 	facility 	 ber1  	in 	my 	chess 	program 
caps-ii. this facility collected descriptions from nodes when backing up in a tree search. when it reached a node where the side on move was not satisfied with the backed up value of the search  measured against a global expectation level   that side set in motion the causality facility which examined the backed up description  called the refutation description . current versions of the causality facility are able to determine whether or not the problem described by the refutation description was caused by the current move at this node. if so  a lemma is posited which describes the partial position  out of the current position  which makes the refutation description possible. lemmas are also posited about winning moves. whenever a move is suggested at some future point in the search  the lemma file is first examined to determine if a lemma exists about this move and if the partial board description matches. if so  the result of the move is assumed known and the search can be foregone. a similar system has been described by adelson-velsky  et. al.  ade1 . 
if the move in question did not cause the current problem  then we know it to have existed when the current node was reached. thus the backed up refutation description  describes this problem. the causality facility has mechanisms for generating the set of all moves  counter-causal moves  that can do something about the refutation description. this can save a tremendous amount of effort in ad hoc searching to find a solution. sometimes the counter-causal set is empty so it is known that the problem cannot be solved at this node and the search must back up further. sometimes a proposed counter-causal move leads to another problem description which is also not caused by the move. then it is known that there is more than one problem to solve at the current node  and any suggested move must be on the list of counter-causal moves for each such problem  a fact which radically reduces further search. 
another technique was recently demonstrated by pitrat  pit1 . he used plans to guide the search. plans were formulated to satisfy goals of winning at least a certain amount of material. if such a plan failed  the reason for its failure was analyzed  and a plan for overcoming this difficulty was inserted into the appropriate place in the original plan. the description of the plan was pushed down the tree as the search progressed and only moves in accordance with the plan  as modified  were admitted to the search. this method was shown to develop small trees and solve many interesting chess problems. 
the essence of techniques of this type is that a potential move is analyzed with respect to a specific purpose. if the move fails  then information is returned which can be used to improve the selectivity of the remaining search. it appears to this writer that these techniques are ripe for application to other areas  e.g. theorem proving  planning techniques.. 
iii. problems with certain search techniques 
at times search is a very powerful technique  achieving things that humans may have difficulty in replicating  e.g. samuel's checker program  sam1 |  dendral  buc1   and 
ciess 1  sla1 . however  certain artifacts appear to be associated with some well known search techniques. 
any piocedure which changes the mode of search  including termination  at an arbitrary depth creates the conditions necessary for the horizon effect  ber1 . thus searches to fixed depths must reconcile themselves to the possibility that the program will try to push unavoidable consequences over its search horizon  by conceding lesser  but avoidable  ones. 
techniques that search a large uniform space usually try to get the maximum value for each cpu second of evaluation. this is because there are many nodes to be evaluated and a few extra microseconds per node may add an intolerable amount of time to the whole search. therefore evaluation must be lean. if a tree contains two or three reachable good nodes  the path to one of these will be selected depending upon very arbitrary factors. 
1 his is fine when all these nodes are very favorable. however  in delicate situations it would be highly desirable to isolate the competing nodes and apply additional knowledge to them in an effort to find which is really best. 
the minimax alpha-beta procedure is undoubtedly the most efficient of all known search procedures. however  a minimax procedure does very poorly at defending losing positions. in such cases  it will almost always choose the path which postpones the opponent's win the longest. however  this is seldom the best way. in bad to hopeless situations it appears necessary to have an opponent model  no matter how primitive  and select moves based on the hope that the opponent is fallible and will thus not always find the best way. thus  for instance  it would be emminently reasonable for a program to avoid losing a rook in an otherwise even position  at the cost of the opponent finding a difficult mate in five moves. however  any program using the minimax approach and discovering the opponent's mating possibility will defend against it and leave the rook to its fate. further  in near equal positions it is sometimes wise to take small risks in the hope of gaining an advantage. this  too  is impossible with the minimax model. 
iv. knowledge organization 
when the search does not go to terminal nodes as defined by the domain  knowledge is needed to evaluate leaf nodes. in goal directed searches knowledge is also needed to make guiding decisions  if any kind of means-ends methods are used. 

invited panet-1: berliner 

the results of samuel $am1  sam1  have always been interpreted to mean that a linear polynomial cannot adequately span a large domain such as checkers. however  recently slate & atkin  sla1  have had great success with their chess program chess 1. this program uses essentially one evaluation function for the whole domain. the coefficients of the terms are designed so that they change very slowly over the domain  and thus provide a sort of rolling landscape in the evaluation space. with this type of design  the program appears to always find something constructive to do. it seldom gets stuck on a hill  since there is always a somewhat higher hill within searching distance from the present one. 
howevei  it is not difficult to show that it is impossible to evaluate all states in a state-space correctly with a single  reasonable  function. in chess  for instance  there are positions where changing the location of one man by one square  or changing whose turn it is  can make the difference between a win  loss  or draw. for many of these positions  even expert players will require some time to fully comprehend the value of the situation. therefore  the single function approach appears to have definite limitations  and it may he necessary to partition the state-space and make evaluation functions which are expert in certain state classes only. 
such expert functions could show their worth when branches lead to leaf nodes representing very different kinds of positions. consider figure 1. 

white can win by playing qxp because the k&p ending is won. but if the black king were one square nearer to the center of the board  the k&p ending is a draw. therefore  qxp is only effective now  and it is inconceivable that 
white can win any other way. in the single function approach  it is almost inevitable that q vs. r+p will be considered better than the materially even k&p ending. it would be simple to design functions which would judge both positions as superior for white. however  for the state-class approach to succeed it is necessary for the k&p endgame function to recognize that endgame as a win. otherwise  this opportunity will be missed. this shows that at times it is necessary to have excellent goodness ordering across state-class boundaries. however  merely recognizing the goodness of a position may not be sufficient. consider figure 1. 

white has a winning position and can play k-b1  k-k1  or 
k-k1  all of which retain the win. however  if he chooses either of the first two alternatives  he will be back in the current position in another three ply. this is an instance of the  make-progress  problem which can frequently be resolved by the search  which notices that no progress has been made. howevei  in more complicated examples  this may not suffice. notice that if in figure 1 the white king were at qb1 then it would be sufficient to recognize the position resulting from k-b1 as a win because there are no real competitors to it. thus the make-progress issue can be separate from the goodness issue. the make progress issue was first treated by huberman  hub1  by having predicates which recognized nearness to a mate in simple winning chess endgames. however  the problem exists both in winning positions and also in positions that are not clearly won  but where a path toward progress exists. another issue is  how to put up resistance   which arises in bad or losing positions. this is not quite the inverse of make-progress  because while there may be a guarantee of progress in superior positions  it is up to the losing side to find the method of resistance which requires the most knowledge  or calculation  from the superior side. 
to investigate the above knowledge issues  we have for some time now been investigating backgammon  a game which due to its non-deterministic nature has a branching factor of about 1 at each node. thus full width searches in this environment  as in go  are not sensible. our program achieved the ability to discriminate generally favorable and unfavorable factors together with appropriate coefficients for a single evaluation polynomial. this design reached a high beginner level  but there were great problems in having it understand more by merely adding more terms and tuning coefficients. in searching programs  some of these problems are subordinated by the search  since the program does not have to know about  means  up to the search depth  and any position potential up to that depth also does not have 

invited panel-1: 	berliner 1 

to be inferred. 
we have now implemented several state-classes which allow a great deal of context to be brought to bear on any evaluation. in some cases evaluation is iterative  so that additional knowledge is only invoked when competitive moves exist. these steps have caused a great jump in performance of the program; however  it is still too early to evaluate the whole approach. 
v. a modest proposal 
all these problems appear to be due to the fact that game playing programs indulge in one-pass evaluation of all nodes  i.e. the amount of knowledge that can be applied to a node has been predetermined. it is thus an efficient amount of knowledge  since applying all that is known would not be cost-effective most of the time. while this is fine for picking out the correct branch when there are no real competitors  this does not work when several nodes are very close in value or when there are other factors such as creating opportunities for opponent error.  much of this was already pointed out in  new1  . here a multi-stage process which weighs the pros and cons of each competitor for best node is required. it would seem that an ideal framework in which to do this search is the 1* algorithm. what is known about a node will increase as nodes in its sub tree are expanded  further  the amount of knowledge being applied can be a function of the degree of competitiveness between nodes. a first attempt at this type of problem solving mechanism is reported in  per1 . 
references 
 ade1   adelson-velskiy  g. m.  alazarov  v. l  and donskoy  m. v.   some methods of controlling the 
tree search in chess programs   artificial intelligence   1  vol. 1  no. 1  pp. 1. 
 ber1   berliner  h. j.   some necessary conditions for a master chess program   proceedings 1rd international joint conference on artificial intelllicnce  august 1. 
 ber1   berliner  h. j.   chess as problem solving: the development of a tactics analyzer   ph. d. 
thesis  carnegie-mellon university  pittsburgh  pa.  march  1. 
 ber1   berliner  h. 1   the b* tree search procedure: best-first search combined with branch and bound   computer science dept.  carnegie-mellon university  july 1. 
 buc1   buchanan  b.  sutherland  g.  and feigenbaum  e. a.   heuristic dendral: a program for generating 
explanatory hypothese in organic chemistry   in 
machine intelligence 1   b. meltzer  et. al.  eds   pp. 1  amerkan elsevier  1. 
 har1   harris  l. r.   the heuristic search under conditions of error   artificial intelligence  1  vol. 1  no. 1  pp. 1. 
 hub1   hubermann  b. j.   a program to play chess lind games   stanford technical memo cs 
	1  	1  	computer 	science 	department  
stanford university. 
|new1   newell  a.   the chess machine: an example of dealing with a complex task by adaptation   proceedings of the 1 western joint computer conference  march 1  pp. 1. 
|nil/1   nilsson  n.  problem solving methods in artificial intelligence  mcgraw-hill  1. 
  p e r / /     perdue  c  and berliner  ii.   eg  a case study in problem solving with king and pawn endings   proceedings of the sirth ijcai  boston  1. 
 pil1  pitt at  j.  a chess progtam which uses plans   to appear in artificial intelligence. 
 sam1   samuel  a. l   some studies in machine learning using the game of checkers   in computers and thought   feigenbaum  i. a. and eldman  j.  eds.   pp. 1  mcgiaw hill  1. 
 sam1   samuel  a. i.   some studies in machine learning using the game of checkers  ii recent piogress   ibm journal of research and 
development  nov. 1  pp. 1. 
|sla1   slate  d. j.  and atkin  l.r   chi ss 1  -the northwestern university chess program   in 
chess skill in man and machine   p. frey  ed   springer ver lag  1. 
| l u r 1 |   luring  a. m.   digital computers applied to games   in faster than thought   b v bowden  ed.   pp. 1  pitman  london  1. 
using plans in a chess playing program 
jacques pitrat 
c.n.r.s. 
paris  france 
1 present a program which does not develop systematically a large tree; but it analyzes carefully the initial situation and generates plans which it then executes. the analyses deeper in the tree are made only when something goes wrong and are always directed towards a goal. with this method  it is possible to find combinations requiring many ply-
invited panel-1: berliner today the chess playing programs do not play as well as the grandmasters. one reason is that there are serious problems for developing the tree. this tree is necessary for finding possible combinations. programs develop very large trees  but it often occurs that important moves are not included in the tree; the minimax procedure backs up an incorrect value if somewhere in the tree the best move is omitted as it is difficult to generate large trees  the solution seems to be to improve the choice of the moves at all the levels in the tree. 
i have realized a program founded on this principle. this ptogtam cannot play a game  but only indicates if a combination exists in the given position. the program analyzes  this position very meticulously. it does not  as anany programs  generate all the legal moves and then eliminate some of them later. but it searches for the characteristics of the position and  using these c h a n a c t i c s   it generates plans  i.e.  a sequence of actions that may be tried. 
the program looks for various characteristics  one of the most important is finding men which could be attacked  cither because they are not protected or because their value is high. when these men have been found  the program checks if two of them can be attacked simultaneously  double attack or pinning one of them if they are on the same line . eventually  if there are some obstacles which are in the way  it indicates that they first have to be removed. if a man has a low mobility  as the king   it looks for an attack on him alone. in some cases  it first prompts an enemy man to move to some square before realizing the combination. 

fx. figure 1. this position was taken from a game lorrf fdward lasker. the combination was not seen by laskrr who played f1 - f1. 
i be knight on e1 is attacked once and protected once. the first plan is: play qd1xe1. it failed because white plays bb1xe1. so the program modifies its plan and first adds a subplan for correcting this. for instance: 
move one of my men to c1 such that this man creates a threat. 
then play qd1xe1. 
1
 k for king. q for queen. r for rook. b for bishop  n for knight. p for pawn. each square is name by the combination of the letter of the file and the number of the rank. 

fx. figure 1. the white king cannot move. so the program t r i e s to attack it. one possibility is to play a bishop on a1 after removing the pawn on b1. for playing a bishop on a1  it is necessary to first remove the pawn from d1. the following plan is generated: 
remove the pawn from d1 so that it creates a threat. remove the pawn from b1. play bf1~a1. 
play ba1xcj. 
in general  if the king and an unprotected knight are on the same file  the program tries to play a rook or the queen on this file. but it never considers a priori all the moves of the rooks  
this analysis is very slow  but it is done only once. the program usually produces several plans and then it tries to execute them. 
fx. figure 1. for realizing its plan  black can move a pawn to c1  threatening the bishop  therefore: 
play t1-e.1 then play c1xb1 or qd1xe1. 
fx. figure 1. black removes the pawn on d1  if it plays d1-d1 threatening d1xc1. if after d1-d1  white plays bc1xd1  the program tries the second element of the plan  i.e.  remove the pawn from b1. the principal methods for removing an enemy man and leaving the square empty are: threatening it or capturing a man which it protects. here the pawn protects the pawn on c1. the program looks for the moves capturing c1: qf1xc1. if white replies with b1xc1  black considers immediately the third element of the plan  i.e.  bf1-a1 mate. 
we see that it is not necessary to analyze fully the other positions  when the plan is in action. it is sufficient to generate the moves which can realize some goal  for instance removing some enemy man or verifying that some move is always legal. there are two advantages: the analysis is fast and the program generates few moves: usually only a few moves satisfy a goal. 
at each level of the tree  only  obvious  moves are considered. a move is added to the tree only if there is some reason to do so. if there is some problem  if the plan 

invitsct 	panel-1: berliner 1 

cannot bo executed as it was foreseen  the program looks for the enemy moves which hinder the success of the plan. then it modifies the original plan as follows: it adds a subplan which corrects the problem. 
this entire method is applied for generating the moves of both players. 
the program analyzes quickly the intermediate positions when all the plans fail. the main principle is to search for new possibilities to capture an opponent  moves which did not exist two ply before  such that this capture is advantageous  capture of an unprotected man or of a man whose value is greater than that of the capturing man . 
fx. figure 1. after c1-c1  white has two new possibilities to capture: the first is d1xc1  but the second element of the black's plan  i.e.  qdxe1  succeeds. the other is bb1xc1 which also destroys the threat c1xb1. if now black plays qd1xeb  there is the new opportunity to capture: bc1xe1 and black's plan fails. 
another way of using the initial analysis is to see if one of the initial plans cannot also be executed deeper. this can be done if the first condition of the plan is now fulfilled. in the case of figure 1  the program generated several initial plans  and among them was: 
remove bb1 
then play qd1xa1 
after c1-c1 bb1xc1  it sees that the first element of the preceding plan is satisfied. then it considers the second element  qd1xa1 and the combination succeeds. 

figure 1 
white to play 
 x. figure 1. the program finds only one useful characteristic: the queen on d1 is vulnerable. only one plan is created: 
play qd1xd1 
after this move  black plays rd1xd1 and white has no advantage. so it tries to destroy the possibility of playing rd1xd1. one way is to remove the rook. so a new plan is: 
remove the rook from d1 
play qd1xd1 
a method for removing a piece is to threaten it. it is possible with the rook f l : 

if there is a new opportunity to capture  the program adds it in all its plans which are possible in this position. for instance  for figure 1  if  after c1-c1  white plays qa1xd1  the plan: 
play c1xb1 	or 	qd1xe1 becomes: 
play c1xb1 or c1xd1 since qd1xe1 is no longer legal and c1xd1 becomes a new possibility to capture. after black plays c1xd1  black has a new chance to capture: d1xe1 and after c1xd1  it considers the plan: 
play c1xb1 	or 	d1xe1 
white cannot do anything against this plan  and the combination still succeeds. naturally there are other variations. 
the initial analysis of a position generates a set of plans. these plans generate a set of moves at the first level of the tree. if one of these moves leads to a failure  the program analyzes the reasons for this failure and eventually creates some new plans. with these plans  we may generate moves which were not considered before. 
play rf - 1 
then play rf1xd1 	or 	qd1xd1 
so the program considers rf 1 -f1 which was not first consiclered. it is not an obvious move  because the rook on f1 is not protected and is attacked twice. this is a check move  but the program does not consider it because the black king can move to h1 and because if the white rook is on f1  it may be captured. after rfl-f1  black may play rd1xf1  and then white executes the following move in the plan: qd1xd1. so black considers kh1-h1. if white plays the following move rf1xd1  black replies ra1xd1 and the combination fails. but the alternative move of the plan  qd1xd1 is good. black plays rd1xd1 and there is a new possibility to capture: rf1xa1. 
in the same way  see figure 1   we have seen that c1-c1 was considered only because black realized that it was interesting to obstruct the diagonal a1-d1. 
the program does not develop the tree in depth first. it develops the nodes before or after the enemy moves  such that  if they were not legal  the balance backed up with the minimax procedure would be advantageous. if it succeeds  it applies the same method for the other player. therefore it is necessary to represent the tree in the computer. but this is feasible  because the tree is not very large. it is 

invited panel-1: berliner 

not possible to use the alpha-beta procedure  because after each node the program may later add new nodes. but the method used takes into account the provisory balance found with the minimax. it is difficult to compare my method with the alpha-beta procedure  but my method is also very selective: the program considers only the advantageous moves. if  for instance  some enemy move evaders an attack  it does not develop the other enemy moves at the same level. 
the main difficulty in implementing this method is programming the analysis of the initial position. this is not a problem of computer time  because this analysis is made only once  but this program is large and difficult to define. for this reason  i do not program the detection of all the possible types of combinations. for this  it would be necessary to add some subroutines to the program. but i do not believe that it is possible to write a chess program which is simple and effective. playing chess is a difficult problem and it would be necessary for several scientists to work several years to create a chess program playing as well as a grandmaster. 
berliner has written independently a very interesting program which has several similar features. for instance  if a node has been developed  and if the opponent has a combination after this move  then it is possible  with the causality facility  to generate new moves which destroy the combination. but most of the chess playing programs do not use such methods and systematically develop large tiees. now they have better results because the authors use very clever methods to develop the tree. it is now necessary to work in another direction  using methods developed by berliner and myself  and certainly some other methods which have not yet been found . the results are not always successful at this time  because it is difficult to write and check large programs  but  in my opinion it is possible to considerably improve the performance. 
