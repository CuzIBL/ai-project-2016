 
real-valued heuristic functions have been extensively used as a means for constraining search in large problem spaces. in this paper we look at an alternative approach  called strategic search  in which heuristic information is expressed as strategies. strategic search generates a search graph by following some strategy or set of strategies  backtracking to previous choice points when the current strategy f a l l s . we f i r s t examine algorithms for performing strategic search using both determlnisltic and nondeterministic strategies. some examples are given which indicate that strategic search can out-perform standard heuristic search methods. the construction of strategies is also considered  and reans for acquiring strategic information both from analagous problems and from example execution traces are described. finally  we indicate how meta-level strategies can be used to guide the application of object level strategies  thus providing a hierarchy of strategic information. 
1. 	introduction 
search for solutions in combinatorially large problem spaces s t i l l remains one of the major problems in a r t i f i c i a l intelligence. for such problems exhaustive search methods are not feasible  and it is necessary to guide the search process in some way. most of the early techniques were based on heuristic functions whose value for a given state provided a numeric measure of the promise or otherwise of pursuing the search from this state . 
however  it soon became apparent that some form of planning had to be incorporated into such problem solvers if substantial reductions in search effort 
were to be achieved. this led to the development of a number of schemes for constructing and then executing plans  1  1  1 . the basis of these schemes is to construct a global plan to constrain the set of possible paths in the search space  and then to search for a solution in this constrained solution space. the entire plan is constructed from the i n i t i a l state to the goal state  making use of information associated with the operators to devise the plan. 
however  there are many problems where this approach either does not work or is inappropriate. for example  in chess it is not clear how to define the abstract spaces in which the planning can take place  and the variation in environmental influences   i . e . the responses of the other player  makes global plan formation and modification very d i f f i c u l t . in such situations we may wish to construct localized plans that involve conditional operations  1 . in other problem domains  plan knowledge may simply be part of the domain specific knowledge of the problem solver  e.g. tesuji in the game of go   strategies for rublk's cube  and program transformations   1     and methods of experimental design    these plans are often heuristic in nature that i s   they are intended to advance us towards a goal  but they may take us down a dead-end  or f a l l by suggesting an i l l e g a l or impossible transition. 
in this paper we examine some basic search algorithms which use such heuristic plans or strategies rather than numeric valued heuristic functions. that is  for any given state  the heuristics provide a set of promising strategies or plans for advancing towards the goal. the basis of these algorithms is quite straightforward -- we pursue promising strategies u n t i l either they are no longer applicable or they generate an i l l e g a l transition. then  exactly as in the standard heuristic search methods  we back-up and try some other promising strategy. in the more general case  we may alternatively apply corrective strategies  allow for the dynamic creation of strategies or use meta-level strategies to guide the use of object-level strategies. such search algorithms w i l l be called strategic search algorithms. 
1. 	definitions 
we define a problem 	p 	to be a quadruple 
¡¡¡¡¡¡p -  d  q  ss  dg  where d is a setof states called the problem space  q is a set of partial functions d -- * d called operators  ss in d is the start state  and dg is a subset of d called the set of goal states. 
we say that a state s in d directly generates a state s* in d  denoted s   s'  assumed to be indexed by p   if for some operator o in q we have o s    s v . we w i l l also say that  s s*  is a legal transition in p. we call 1* an  immediate  successor of s  and we call s an  immediate  predecessor of s ' . a state s in d generates a 
state s* in d if s     s '   where -* is the transitive closure of - * . we call s' a descendant of s  and s an ancestor of s*. 
1 	strategies 
1 a strategy is simply a program or machine that gener-

note that s is allowed to be partial that i s   it may be that a strategy is not defined for some states in d. furthermore  no restrictions are placed on the state transitions specified by the strategy. in particular  they need not be legal transitions of p. neither is there any requirement that the final state of the sequence be a goal state of p  although it would be expected that the strategy at least moved us closer to a goal. finally  note that it is possible for states in d to have more than one strategic successor that i s   the strategic successor of an inter-
mediate state may depend on the strategic path to that state. 
for example  consider the eight puzzle . a very simple strategy for this problem might be given by 

there are three points to note about this strategy. first  the strategy contains conditional and iterative constructs  and in general could have an arbitrarily complex control structure. second  it is clear that in many cases the strategy w i l l invoke an illegal transition for p. finally  the strategy is problem specific  as it depends on the goal state of p. in general  the strategy could also depend on other properties of the problem  such as the start state  the operators or some cost function. 
1 strategy-first search 
consider a problem p    d  q  1  dg   and the graph c defined by g -   d ' p *   . the search problem is to find a path  possibly of minimum cost  in this graph from the start state ss to some goal state. generation of a l l successors of a state is called expanding that state . i f   during a search  a l l successors of a state have been generated  we w i l l say that the state is closed . otherwise the state is said to be open. if a state s generates more than one successor in the search graph then we call state s  or the node corresponding to s  a choice point. 
given a strategy 	s 	for 	p  we w i l l attempt to find a path to a goal state by applying the strategy 
s 	to the start state 	ss. however  in most cases 
 p we w i l l reach a point in the search where the strategy cannot be followed  either because the strategy terminates without finding a goal or because some illegal transition is invoked . we might then want to apply the strategy afresh to some of the strategically generated states or to some of their non-strategic successors. we therefore need a selection scheme for determining which choice point to expand next. 
given that strategic moves can be expected to advance the search towards a goal  one possible scheme is to pursue paths containing the least number of non-strategic moves in preference to other possible paths. the search resulting from the use of such selection schemes w i l l be called strategyf i r s t search. 
1. 	the basic algorithm 
the procedure for performing strategy f i r s t search is essentially the same as standard search algorithms   except that the selection scheme is based on choosing strategic transitions in preference to non-strategic transitions. the simplicity of this selection scheme  however  has important consequences for the representation of open choice points. in particular  unlike best-first search  selection of the next choice point need not involve a search of the l i s t of open choice points. for example  a l l strategically generated states can be placed directly on the l i s t representing the open states  where as a l l those generated by non-strategic transitions can be held temporarily on some other l i s t . only when a l l strategic transitions have been exhausted need the held states be opened for selection. indeed  there is no need to expand held states until they are opened  resulting in further gains in efficiency. 
in the following algorithm  the operator . denotes the standard l i s t constructor  lisp cons   hd 
1 denotes the head of the l i s t and tl denotes the t a i l of the l i s t . the expression  x - y  denotes set  more accurately  l i s t   difference and  x + y  denotes set union. 

the function select pops the top element off open; strat returns the l i s t of states generated at st by the strategy s p ; - expand returns the l i s t of states directly generated from the state s: and path returns the  unique  path in the search tree from the start state to state st  in this case the path may simply be taken to be the f i r s t path found . 
the ordering placed on open states and held states w i l l determine the order in which strategic moves and non-strategic moves  respectively  are generated. one of the simplest schemes is to treat both the open and held l i s t s as stacks  giving depth f i r s t generation of both types of move. this scheme is used in the examples that follow. 
1 	examples 
the example to be considered is the 1 puzzle. we w i l l assume that the square is numbered clockwise starting at the top left hand corner  with square 1 in the centre. we w i l l further assume that the goal state is such that the number on each square corresponds with its position and that the blank   t i l e   is in the centre   i . e . at position 1 . 
we w i l l consider two strategies represented by the following rules: 
 i  if the blank is not in the centre  then swap the blank with the t i l e whose position the blank occupies; otherwise swap the blank with the f i r s t misplaced t i l e . 
  i i   if the blank is not in the centre  swap the blank with the t i l e whose position the blank occupies; otherwise rotate the 1 tiles in some quarter of the square so that the number of misplaced tiles is reduced  and the blank is returned to the centre. 
in order that strategy   i i   be deterministic  the f i r s t of the  possibly many  rotations that satisfy the condition is taken as the strategy. for example  in state  1 1 a 1 1 1  the strategy produces a clockwise rotation of the top left hand quarter of the square  giving state   1 1 1 1   . 
note that using strategy-first search with depthf i r s t expansion of open states  strategy  1  generates exactly the same search tree as does the strategy strati given in section 1. note also that strategy  1  is partial and does not generate a 
strategy when the blank is in the centre and the number of misplaced tiles cannot be reduced by a quarter square rotation. 

fig. 1. tree from strategy  i  
figure 1 shows the search tree generated by strategy-first search using strategy   i   . 	the states at which the strategy is evaluated are i n d i cated with *. 	strategy   i i   generates the solution path directly with two evaluations of the strategy. these search trees may be compared with the search tree generated using the standard heuristic search 
method with the heuristic function h n  ¡ö w n   where w n  is the number of misplaced t i l e s in the state n  see  . this search tree finds the same solution path and contains 1 nodes  states . moreover  the heuristic function is evaluated at every node in the tree. 
thus for both strategies  and particularly strategy   i i     the number of evaluations of the strategy during the search is considerably less than the number of evaluations of the heuristic function. moreover  evaluation of strategy  1  and evaluation of the above heuristic function are of comparable complexity  and evaluation of strategy  1  can be achieved in about twice the time. thus  in this case  strategic search is more efficient than heuristic search by a factor of almost two for strategy  i  and over three for strategy   i i   . furthermore  the heuristic search method requires that the entire l i s t of open states be searched 

1 

either on state insertion or selection - strategy-first search simply pops a stack. 
it is important to note that in the above cases it was possible to determine the appropriate strategic transitions without explicitly generating and evaluating different paths in the search space. thus  for example  under strategy  1  it was not necessary to try a l l possible  or in fact any  quarter souare rotations in order to determine which to use. if this criterion were not met  then strategic search would be grossly inefficient. interestingly  this is exactly the kind of criteria imposed on real world strategies a strategy is not much help if one needs to do a complete search to determine what to do next. 
1. 	non-deterministic strategies 
in many problems the strategy adopted may be nondeterministic in the sense that for a given state in the domain of the strategy a set of strategic paths  rather than a single strategic path  is generated. that i s   the strategy is generated by a non-deterministic program or machine. the situation is exactly the same if  instead of a single strategy  we specify s set of strategies that can be applied to each problem state the set of strategies can be considered to be a single non-deterministic strategy. 
the basic strategic search algorithm can be readily generalized to allow of non-deterministic strategies. we simply require that the function strat return the  possibly non-singleton  set of state paths generated by the non-deterministic strategy. given that we usually process l i s t s rather than sets  it is natural to also allow that the set of state paths generated by strat be ordered with preferred sequences occurring f i r s t . 
of course  while this approach w i l l work  considerable effort can be expended in generating states that are not subsequently used. this is not so 
much of a problem n the standard heuristic search methods as the expense of applying a single operator is usually quite small. however it can be very i n efficient in strategic search  where the generation of new states can involve the calculation of long sequences of state transitions. when possible  it is thus preferable to i n i t i a l l y generate only the 
most promising state path while allowing the possibility later in the sesrch of generating more state sequences. in the most general case it may then be best to represent open as s l i s t of coroutines or generators. each time a non-deterministic branch occurs in the strategy  additional coroutines are sprouted and added to open. 
1 	example 
let us say that a state s1 is better-ordered than a state s  i f   considering only those t i l e s around the perimeter of the square  more t i l e s in s1 are followed by their proper successor than in s1. now consider the following strategy. 
if the blank is in the centre  and a rotation of the t i l e s is some quarter of the square or in some half of the square produces a better-ordered state  then rotate the appropriate t i l e s . if 
more than one rotation is applicable  order the set so that the quarter square rotations occur f i r s t . 	if the tiles are perfectly ordered  but not in place  then rotate the t i l e s around the entire perimeter so that each moves closer to home. 
figure 1 shows the search tree generated by applying the above strategy to the configuration  1 1 1 1 1 . only those states at which the strategy is evaluated are shown. each arc is labelled with the operator sequence used the symbol :: represents the four quarters of the square  the arrow specifies the tiles rotated and the direction of rotation. 

fig. 1. tree from strategic search 
for comparison  consider the tree produced by the heuristic search algorithm based on the heuristic h n  - p nh1s n  
where p n  is the sum of the distances that each t i l e is from home  end s n  is a sequence score obtained by checking around the perimeter t i l e s in turn  alloting 1 for every t i l e not followed by i t s proper successor and 1 for every other t i l e   except that a  non-blank  t i l e in the centre scores 1  see  . 	this search tree contains 1 nodes and the length of the  optimal  solution path is 1 moves. 

1 

although the path found by the strategic search is considerably longer than that found by the standard heuristic search  it is interesting to note that the strategy is again evaluated for far fewer states than is the heuristic function. furthermore  the solution found by the strategic search is very similar to the type of solution generated by humans attempting the task that i s   the f i r s t priority is to achieve the proper ordering; the perimeter rotation is straightforward and can be done with l i t t l e processing effort at the last stage. 
in fact  the comparison above is a l i t t l e unfair to the strategic search method as it did not make use of any information on distance from home. 	if we use the same strategy as above  but order the strategic moves on the basis of the change in distance from home and weighting the half square rotations by +1  then in this case strategic search generates the minimum cost path to the goal state directly 	no other path is explored. 
strategies also have other advantages. they tend to be more transparent that parameterized heuristics  local information can be readily incorporated 
and subsequent modifications can be made easier. in development  it is not necessary to try adjusting the values of a numeric values expression  which  
while improving selection on one area may impair it in another. for example  consider that the goal state for the eight puzzle is changed so that the blank now occurs in the corner. then we only need modify the above strategy so that once it achieves the  intermediate  goal with the blank t i l e in the centre  it makes two further moves to get the blank to the appropriate corner. it is far less clear how one would go about modifying the heuristic function. 
it is also possible to modify the above algorithms so that they are admissable  when the strategy satisfies certain restrictions. the details can be found in . 
1. 	discovering strategies 
several approaches to constructing heuristic functions have been proposed. most have attempted to optimise the values of coefficients in an heuristic function so as to maximize overall performance  1  1 . a potentially more powerful approach has been suggested by gashnig . given some problem p  instead of seeking an heuristic directly for p  one seeks instead another problem  p' say  similar to the given problem but easier to solve. in particular  there must exist an algorithm a' for solving p'  and the transitions specified by a1 applied to p* must be capable of being represented by a graph which is an  edge subgraph  or  edge supergraph  of the given problem. gashnlg then proposes that the value of the heuristic function for some state s in p be simply the number of transitions from s to the goal state under the algorithm a'. 
for example  we can use the maxsort algorithm for sorting the numbers 1 to 1 to calculate heuristic values for the 1 puzzle. maxsort simply swaps the 1 with the element whose proper place in the permutation it occupies  except when the 1 is in the 1th position  in which case the f i r s t misplaced element is swapped. for a given state  the number of swaps to reach the goal is taken as the heuristic value of this state.  note that except for a small perturbation caused by swapping the 1 into the ninth position  the number of swaps under maxsort is the same as the number of misplaced t i l e s   . 
the major problem with this approach is that unless an analytic result is available  the problem p' has to be solved   i . e . the algorithm a* executed  separately for each state in the search graph of p. however  we can use the same approach much more advantageously if we use strategic search rather than heuristic search in solving p. in this case 
we simply transfer the strategy of p1  in essence  the control structure of a'  to the problem p. for example  the strategy s t r a t i given in section 1  equivalently  strategy  1  in section 1  is exactly the maxsort strategy. 
informally  consider that we are given two problems p -  d  q  ss  dg  and p' -  d'  q1  as'  dg*  and a partial map g from d' to d. now assume that we have a strategy  program  a' for solving p f   and that we can construct  appropriate  mappings h- and h from the functions f' and predicates p! occurring in a' to functions f. and predicates p. over the domain d of p. then we can obtain a strategy a for p by replacing each occurrence of f* in a' by h f   f !   and each occurrence of p' by h  p! . of course  there is nothing in this definition that guarantees that a w i l l be a useful strategy for solving p. 
for example  consider that we know how to f i x leaking taps: 
procedure leak 
determine whether you need a spanner if you do then go to position of spanner grasp spanner take spanner to tap use spanner to f i x tap release spanner 
else go to tap f i x tap 
end-1f end-procedure  
this strategy can be transferred to the monkey and bananas problem  by associating the functions and predlcatea in the tap world with corresponding one1 in the banana world  giving the following algorithm: 

1 

procedure bananas 
determine whether you need the box if you do then go to poaition of box hands on box push box to bananas climb on box; grasp bananas get off box 
else go to bananas grasp bananas 
end-if 
end-procedure. 
with this strategy the monkey can solve his problem determlnistlcally. in fact  it is not too d i f f i c u l t to generalize this strategy to one governing the use of most types of tool  viz. 
if you need to use a tool  go to the tool f i r s t   then take it to the job and use i t . 
as far as automating the problem solving process is concerned  the problem of constraining the expansion of the search graph for a given problem has been reduced to finding an analagous problem for which we already have a solution method. this is a more tractable task than that of generating an heuristic function  1 . 
another approach is to learn the strategy directly from traces of aample solutions generated during some sort of training session. this is a standard inductive inference problem: find a program that generates successful execution traces for the problem p. associating with each operator o. in q and  pre-specified  predicate p. over d a distinct symbol from some alphabet v  then successful execution traces form a language over v. the problem then reduces to a grammatical inference problem  that i s   to the construction of a grammar which generates this language. some interesting work has been done along these lines by stolfo . 
1. 	meta-level strategies 
strategy-first search is a simple but effective way for constraining search in many problems. however  in more complex problems we may need more sophisticated and possibly problem specific selection schemes. one way to achieve this is to use other strategies for defining the selection scheme. we w i l l call such strategies meta-level strategies  in contrast to the object level strategies such as those discussed above. thus strategy-first search corresponds to the very simple problem-independent meta-strategy 
choose the choice point generated by the fewest number of non-strategic transitions. 
the use of numeric valued heuristic functions is also a special case of meta-level strategic information  as is the use of mats -level production rules in teiresias   1   . 	however  none of these cases involve; sequences of selections. 	more general meta-level strategies could take account of information -derived during the aearch  and could 
allow for dynamically changing lines of reasoning. 
more abstractly  given a problem p we construct a meta -level problem m over states that represent the progress of the search. a meta-level strategy is a strategy for m; that i s   a program  possibly non-deterministic  that specifies how the search space should be expanded. 
as the meta-level problem m is no different from any other problem  the basic procedure outlined above  or some variation of i t   can be used to generate a solution to m  and hence to p. how-
ever  in almost a l l cases we can expect the metalevel problem to be commutative - that i s   if for a given state there exists a number of possible successors  and one of these leads to a solution  then so do a l l the others. in such a situation there is no need to back-up and consider previous states of the computation. in systems that are required to interact with experts  such uniformity of knowledge representation is an important consideration. furthermore  with such a scheme it is possible to provide a hierarchy of meta-level problems and strategies  each determining how to handle the non-determinism of the one below i t . 


1 
