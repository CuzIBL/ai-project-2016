 
user feedback is vital in many recommender systems to help guide the search for good recommendations. preference-based feedback  e.g.  show me more like item a    is an inherently ambiguous form of feedback with a limited ability to guide the recommendation process  and for this reason it is usually avoided. nevertheless we believe that certain domains demand the use of preference-based feedback. as such  we describe and evaluate a flexible recommendation strategy that has the potential to improve the performance of case-based recommenders that rely on preference-based feedback. 
1 introduction 
at last year's european case-based reasoning conference 
 eccbr 1  in scotland  delegates were treated to a whiskey tasting. a range of different whiskeys were sampled  each accompanied by a feature-based description  e.g. distillery  age  alcohol content  cask  peatiness  sweetness  
palette  etc. . however  the value of these descriptions was limited as most of us had little or no understanding of the features  nor could we reliably reconcile individual features with the taste of a particular whiskey. nevertheless virtually everyone could chose a favourite whiskey by the end of the session  after a lot of sampling it has to be said! . this example corresponds to a challenging problem for developers of recommender systems  for reasons that will become clear. 
　normally the success of case-based recommenders depends on two important domain properties:  1  the items need to be described using well-defined features; and  1  users must have some understanding of these features and how they relate to their requirements. for example  restaurants are readily described using features such as cuisine  location and price  and most people have a reasonable understanding of their needs in relation to these features. when the above characteristics are present content-based recommendation strategies can be combined with different forms of user feedback  such as value elicitation  e.g.  i want an expensive  
asian restaurant    bridge  1  or critiquing  e.g.  show 
    the support of the informatics research initiative of enterprise ireland is gratefully acknowledged me more like holly's bistro but less formal''   to good effect  burke  1. however  if these properties are not present then other strategies are needed. for example  if item descriptions are not available  collaborative filtering can be used to recommend items that have been rated positively by similar users  burke  1; shardanand and maes  1 . the whiskey recommendation scenario above is different. the availability of item descriptions suggests case-based recommendation  but the lack of user expertise limits the use of feedback strategies such as value elicitation or critiquing. 
　indeed the whiskey domain is not unique in this respect. in many domains users are able to express a preference without necessarily understanding individual item properties. this is especially true in domains where a specialised v :abulary already exists to describe items  e.g. fashion  jewellery  art  music  etc. . consider a recommender system designed to help a bride-to-be to choose her ideal dress  individual dresses are described using specific features  e.g. coul-back  scoop-cut  georgian-style  etc.  but most of these terms are meaningless to the average bride  and yet the typical bride-to-be is capable of recognising what she likes when she sees it. this problem is more than the user being unaware of the correct vocabulary to use during recommendation. the point is that even if they were presented with the appropriate vocabulary terms  they would not be in a position to use or appreciate these terms. 
　one form of feedback that could be used is preferencebased feedback; the user simply expresses a preference for an item  e.g.  show me more like dress 1  . this has been largely avoided by researchers - it is assumed to be too limited to efficiently guide the recommendation process. nevertheless in our research we arc interested in looking at how to make this a practical form of feedback in these challenging domains. incidentally  unlike other feedback types  preference-based feedback also benefits from minimal interface needs  and so is particularly relevant for recommenders designed for use with the current generation of mobile devices  such as wap phones and pdas. 
　in this work we describe a way to improve the performance of recommenders that use preference-based feedback. our novel adaptive selection method mirrors how real-life sales assistants adapt their recommendation strategies in response to user feedback by balancing the importance of similarity and diversity during each recommendation cycle. dramatic improvements in recommendation performance have 
been observed  e.g. reductions in dialog length of up to 1% . 
1 comparison-based recommendation 
comparison-based recommendation is a content-based 
 or case-based  recommendation strategy  burke  1; mcginty and smyth  1   as opposed to a collaborative recommendation strategy  burke  1; konstan etal.  1; shardanand and maes  1 . the notion of comparisonbased recommendation was introduced by  mcginty and smyth  1  to emphasise the role of feedback in contentbased recommenders  and to allow for an analysis of preference-based feedback in particular. the focus was on how query modification methods might be used with preference-based feedback to produce efficient recommendation dialogs without richer forms of feedback like value elicitation or critiquing. we briefly review this earlier work  describing the basic comparison-based recommendation framework and some successful query modification strategies. 
1 the basic algorithm 
comparison-based recommendation  figure 1  is an iterative recommendation algorithm that presents the user with a selection of k items as recommendations during each of a sequence of n recommendation cycles. during each cycle the user expresses a preference for one of the suggestions and this feedback is used to revise the query for the next cycle; in the vocabulary of shimazu  it is a type of navigation by proposing  shimazu  1 . the recommendation dialog terminates when the user is presented with an acceptable suggestion. 
1 simple selection: more like this 
the simplest approach to comparison-based recommendation is to recommend the k most similar items to the current query  and use the newly preferred item as the query for the recommendation next cycle. this more like this  mlt  method is a facility often provided by web search engines; although it should be noted that search engines rarely rely upon this method  primarily focusing instead on query elicitation and 
term-based search. the mlt method is flawed by a tendancy to follow so-called false-leads as it overfits to the current preference  and this results in protracted recommendation dialogs. using each preferred item as the next query is problematic if some of its features are not relevant to the user. for example  a user may indicate a preference for a whiskey that is oak-aged  sweet  and peaty. but if the preference was largely a result of the peatiness and independent of  or even at odds with  the sweetness or the aging  then blindly focusing the next selection on sweet and oak-aged whiskeys  as well as peaty ones  may result in poor recommendations. 
　figure 1 shows the scope of this problem by graphing the similarity of the preference to the target in a sample recommendation dialog. instead of an increasing similarity profile  we find sustained decreases in similarity as mlt follows false-leads. between cycle 1 and 1  target similarity falls from 1 to as low as 1 as the user is forced to accept poor recommendations  and again between cycle 1 and 1 there is a noticeable similarity trough. indeed it is only after cycle 1 that mlt finally begins to focus on the target region and similarity rises. 

figure 1: profiling the similarity of the preference case to the target case in a typical recommendation session 
1 	query modification strategies 
query modification techniques can relieve the false-lead problem  and have been shown to improve recommendation efficiency  reducing mlt dialogs by 1% on average  mcginty and smyth  1 . the central idea is to identify features in the preference case that are likely to be the reason for the user's choice  and those features that are likely to be irrelevant. only relevant features are transferred to the new query. returning to the whiskey example above  if the rejected cases are also very sweet then sweetness may irrelevant to the user. hence  one query modification strategy  partial mlt  pmlt  only includes preference features in the query that are not found in any of the rejected cases. 
　 mcginty and smyth  1  also propose more sophisticated query modification strategies that weight preference features in the query according to how likely they are to be reliable. one strategy computes a weight for a preference feature based on the proportion of rejected items that also contain that feature. if 1 cases are recommended to the user  and if the preference and just one of the rejected items are oak-aged and then this feature is transferred to the new query with a weight of 1  1% of the rejected items are oak-aged . 
1 	adaptive case selection 
so far we have assumed the use of similarity-based selection during each cycle. however  in the real-world two selection strategies can be observed in the dialogs that take place between customers and sales assistants. if a customer is unsure of their exact needs the sales assistant will tend to present a diverse range of alternatives  based on a preliminary set of requirements  to focus in on a promising region of a product space. a good sales assistant can recognise when the customer sees something that they genuinely like and uses this as a cue to switch their strategy to one that tries to refine subsequent recommendations in the region of the preference by selecting similar items. 
1 	case-based reasoning 　in this paper  instead of using query modification methods to improve recommendation efficiency  we propose an alternative called adaptive selection. it adapts the way that new items are selected for recommendation and is motivated by the above observation that different selection strategies are appropriate at different times in the recommendation process. 
1 similarity vs diversity 
our observation about real-life recommendation scenarios is partly echoed by recent research that has questioned the apparent over-emphasis on similarity in content-based recommenders  with diversity forwarded as an important additional selection constraint. a number of strategies for improving recommendation diversity have been suggested.  shimazu  1  proposes the recommendation of three items or cases  i1  in and 1  per recommendation cycle: i1 is the most similar case to the query; i1 is maximally dissimilar from i1; and i1 is maximally dissimilar from i1 and i1. by design these items are maximally diverse  but similarity to the query may be compromised as there are no guarantees that in and i1 will be very similar to the query. 
　other researchers have proposed alternative diversity enhancing mechanisms with a more manageable balance between item diversity and query similarity  bridge  1; mcsherry  1; smyth and mcclave  1. although all of these techniques introduce diversity into selection in a uniform way  they do not fully reflect the strategy switching seen in real-world scenarios. moreover  while increasing diversity may improve the efficiency of of a recommender by allowing it to cover more of the item-space per recommendation cycle  it may also lead to new types of inefficiencies. diversity enhancing methods pass over items that might otherwise be selected and the target item may be one of these. 
　a more flexible mechanism for introducing diversity must be adopted based on whether or not the recommender has focussed on the correct region of the item space. if there is evidence that it is correctly focused then a pure similarity-based selection method can be used to refine the recommendations and safe-guard against passing over the target item. if the recommender is not correctly focused  then diversity is introduced in order to maximise the coverage of the item space in the next cycle  and so help to refocus the recommender by offering the user contrasting recommendations. 
1 	preference carrying 
unfortunately it is not immediately obvious how to judge whether the recommender is correctly focused; the target item is unknown and user requirements are typically vague. adaptive selection solves this by evaluating whether the recommendations made in the iih cycle are an improvement on those in the i ~ ith cycle before choosing a selection strategy for the i +  th cycle. 
　this is achieved by carrying the preference item from the previous cycle to the current cycle. if the user selects the carried preference in the current cycle it must mean that they are unhappy with the k - i new alternatives in that cycle. these new items must have failed to improve upon the recommendations made during the previous cycle  and so the recommender must not be correctly focussed. if the user ignores the carried preference and selects one of the newly recommended items then the recommender must be correctly focused. thus  by carrying the preference item  and monitoring whether or not the user reselects it  we can implement a switching mechanism between two alternative selection strategies: a refine strategy that emphasises similarity; and a refocus strategy that balances similarity and diversity for improved recommendation coverage. 
　in theory carrying the preference may lead to new inefficiencies because the carried preference takes up a valuable slot in each cycle  thus limiting recommendation coverage. however  this is easily compensated for because carrying the preference helps protect against against false-leads. if none of the k: - 1 new cases are relevant then by reselecting the carried preference the user is at least maintaining the previous best recommendation rather than being forced to accept a lower quality false-lead. in practice  this on its own can offer a substantial improvement to recommendation efficiency. 
1 refine & refocus 
as mentioned above  the refine strategy makes use of a standard similarity-based selection method  picking k - 1 new items that are maximally similar to the current query. the refocus strategy uses the bounded-greedy diversity technique proposed by  smyth and mcclave  1 ; see figure 1. 
　very briefly  the bounded-greedy technique involves two basic phases. first  the bk most similar items to the query are selected  where b is typically an integer between 1 and 1 . during the second phase  the set  r  of selected items is built incrementally. during each step of this build the remainder of the bk items are ordered according to their quality and the highest quality item added to r. the quality of a item i is proportional to the similarity between i and the current query q  and to the diversity of i relative to those items so far selected  r = {r1  ... rm}; see equations 1 & 1. 
quali1y q i r  = a* sim q i  +  1 - a * div i  r   1  
	div i r  	= 	1 if r = {}; 
	- 	- otherwise  1  
m 
the first case to be selected is always the most similar to the query and in subsequent iterations  the chosen case has the highest quality relative to the query and diversity and cases selected so far. note  we set b = 1 and a = 1 to balance similarity and diversity during refocusing. 
1 evaluation 
in this section we evaluate the performance of adaptive selection focusing on the average number of cycles and unique items that must be presented to a user in a typical recommendation dialog. the shorter the dialog  the more successful the recommender is likely to be  and we demonstrate that adaptive selection delivers dramatic reductions in dialog length. 
1 setup 
a case-base of 1 unique scotish whiskey cases  figure 1  is used to compare two comparison-based recommenders using preference-based feedback: mlt uses the standard mlt strategy; mlt+as implements adaptive selection. we use a leave-one-out methodology for testing using 1 randomly selected cases as test cases. each test case  base  is removed from the case-base and used in two ways. 


1 	case-based reasoning 

　first it serves as the basis for a set of queries made by taking random subsets of features. second  it is used to identify a maximally similar  target  case. thus  the base is the ideal query for a user  the generated query is the initial test query given to the recommender  and the target is the best case for the user given their ideal. during each recommendation cycle 1 cases are recommended to the user  and the most similar to the target is chosen as a preference  thus simulating a user that is capable of correctly selecting the best preference item in each cycle; we relax this assumption in section 1. a query is satisfied when the target is returned in a cycle  thereby simulating the situation where the user is seeking a specific case; once again  we relax this condition in section 1. in total 1 queries are generated and divided into three groups based on their difficulty; where difficulty is based on the number of recommendation cycles required by mlt. 
1 	recommendation efficiency 
basic recommendation efficiency can be measured in terms of the average number of cycles  or unique cases or items  that a user must work through before being presented with their ideal target. the leave-one-out method outlined above is used by the two recommenders for each of the 1 queries and and the mean number of cycles and unique items presented to the user are measured. the results are shown in figure 1 a-b  as graphs of mean cycles and items for each algorithm and query group. the benefits of mlt+as should be clear for both measures. for example  we see that mlt requires 1 cycles  and 1 items  for simple queries  but mlt-as needs only 1 cycles  and 1 items   a relative reduction of 1% in terms of cycles  and 1% in terms of items. 
　we see similar results for the other query sets. in fact  the relative reductions enjoyed by mlt-as increase with query difficulty. the recommendation dialogs associated with more difficult queries include more false-leads than the dialogs for simpler queries  and so offer adaptive selection an even greater opportunity for dialog reduction. this trend is clearly seen in figure 1 c   which graphs the percentage reduction in cycles and items due to mlt-as  relative to mlt. for cycles  the relative reduction grows from 1%  simple  to 1%  difficult  and for unique items it grows from 1% to 1%. these results clearly show a dramatic benefit for adaptive selection. indeed this benefit is so great that mlt-as is capable of satisfying the most difficult queries far more efficiently than mlt takes to satisfy even the simplest queries. 
1 	preference noise 
in this experiment we re-evaluate our recommenders by relaxing the assumption that the user always prefers the most similar item to the target to test whether benefits are found with sub-optimal preferences. the above experiment is repeated except that noise is introduced into the preference selection by perturbing the similarities between each recommended item and the target by some random amount within a set noise limit. a 1% noise means that each similarity value can change by up to +/-1% of its actual value. this will potentially change the internal ordering of recommended items during each cycle resulting in the selection of a preference that may not be the most similar to the target. this approach mimics the situation where users are likely to make preference mistakes more frequently if there is little difference between the target similarities of the recommended items. 
　figure 1 d&e  graph the mean number of cycles and items presented to the user versus the noise limit for moderate queries. as expected  introducing preference noise has a negative impact on the ability of each recommender to locate the target item. mlt dialogs increase from 1 cycles at 1% noise to 1 cycles at 1% noise  and mlt-as dialogs increase from 1 cycles to 1 cycles. the number of items required is also seen to increase in a similar manner. however  the benefits of mlt-as remain across all levels of noise  see figure 1 f   although the magnitude of these benefits is seen to fall as noise increases. for example  the mlt-as benefit  in terms of unique items  falls from 1% at the 1% noise level to 1% at the 1% level. nevertheless  adaptive selection once again offers significant improvements in recommendation efficiency even when users make imperfect preference selections. while the results presented here focus only on moderate queries  for reasons of brevity  it is worth noting that qualitatively similar results are found for simple and difficult queries. once again the mlt-as benefits increase with query difficulty; for example  in terms of unique items  at the 1% noise level  a 1% mlt-as benefit is observed for simple queries  and a 1% mlt-as benefits for difficult queries. 
1 	target noise 
our second key assumption is that users are interested in a single target item during recommendation  and that the dialog only terminates when this item is returned. it is perhaps more realistic to assume that the user will be satisfied by any one of a group of items that are similar to the optimal target. we re-evaluate our recommenders under this more relaxed termination condition by repeating the basic efficiency experiment except that we terminate each dialog once an item has been recommended that is within some pre-defined similarity of the target. a similarity threshold of 1% means that the dialog terminates when an item that is at least 1% similar to the targer has been recommended. 
　figure 1 g-i  presents the results in a number of ways. first figures 1 g&h  graph the mean number of cycles and items presented to the user versus the similarity threshold for moderate queries. as expected  relaxing the termination condition results in shorter recommendation dialogs for mlt and mlt-as. for example  mlt dialogs reduce from just under 1 cycles at the 1% similarity threshold  where the optimal item must be recommended  to just over 1 cycles at 1% similarity. mlt-as dialogs reduce from 1 cycles to just under 1 cycles across the same similarity range. the number of items required is also seen to reduce in a similar manner. however  positive mlt-as benefits are maintained across all similarity thresholds  see figure 1 i  . in fact  as the threshold increases  and the termination condition becomes more rigid  we find increasing benefits for mlt-as in terms of cycles and items. for example  the mlt-as benefit  in terms of unique items  grows from 1%; at the 1% similarity threshold to just under 1% at the 1% threshold. once again  adaptive selection delivers significant improvements in recommendation efficiency across a variety of termination conditions. 

figure 1: preference-based feedback vs critiquing. 
1 	preference-based vs critiquing 
finally  it is worth briefly considering the impressive dialog reductions observed for adaptive selection with preferencebased feedback in the context of a much richer form of feedback  namely critiquing  burke  1; mcginty and smyth  1 . figure 1 presents an efficiency comparison 
 in terms of average recommendation cycles  between our two preference-based recommenders and an equivalent recommender that implements critiquing; briefly  during each cycle feedback corresponds to a preference case plus a critique that constrains a selected feature value. 
　on the face of it we expect critiquing to produce more efficient dialogs than preference-based feedback. and so it does for all query types when compared to standard preferencebased feedback. however  the surprise is that combining preference-based feedback and adaptive selection produces recommendation dialogs that are consistently and significantly shorter than even those produced by critiquing. for example  relative to mlt-as  critiquing requires 1% more cycles for simple queries and 1% more cycles for the difficult queries. 
1 conclusions 
to date preference-based feedback has been largely ignored by recommender systems. it is an inherently ambiguous form of feedback with a limited ability to efficiently guide the recommendation process. nevertheless  we believe that this form of feedback is useful  and perhaps even vital  in certain recommendation domains where other forms of feedback cannot be used  perhaps because of limited user expertise or even basic device restrictions. 
　we have described how preference-based feedback can be made more efficient using the adaptive selection technique  which modifies its recommendation strategy depending on whether or not the recommender is correctly focused on the right region of the recommendation space. using this method we have demonstrated dramatic performance improvements over standard preference-based feedback  across a variety of experimental conditions  with reductions in dialog length of up to nearly 1%. indeed  adaptive selection is so effective that it is capable of using simple and cheap preference-based feedback to produce recommendation dialogs that are even more efficient than those available with richer forms of feedback such as critiquing. 
　in this paper we have presented evaluation results from one recommendation domain  whiskey. this domain is especially interesting because of its dependency on preference-based feedback  as discussed in section 1 . we have also tested our technique on more traditional domain datasets  i.e. travel  pc  and have found similar results imcginty and smyth  
1 . we believe that these results have the potential to change the perception of simple preference-based feedback  facilitating its practical use in a variety of recommendation scenarios. indeed adaptive selection is in no way limited to preference-based feedback. in our future research we intend to investigate if similar performance benefits can be achieved by integrating this technique in recommenders that use other forms of feedback  e.g. critiquing and rating-based . 
