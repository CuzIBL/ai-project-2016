
in this paper  we perform an empirical study of the impact of noise on cost-sensitive  cs  learning  through observations on how a cs learner reacts to the mislabeled training examples in terms of misclassification cost and classification accuracy. our empirical results and theoretical analysis indicate that mislabeled training examples can raise serious concerns for cost-sensitive classification  especially when misclassifying some classes becomes extremely expensive. compared to general inductive learning  the problem of noise handling and data cleansing is more crucial  and should be carefully investigated to ensure the success of cs learning. 
1 introduction
recently  a body of work has been attempted to address cost-related inductive learning issues  with techniques known as cost-sensitive learning  tan 1  turney 1  pazzani et al. 1   where the  cost  could be interpreted as misclassification cost  training cost  and test cost  turney . among all different types of costs  the misclassification cost is the most popular one. in general  misclassification cost is described by a cost matrix c  with c i  j  indicating the cost of predicting that an example belongs to class i when in fact it belongs to class j. with this type of cost  the objective of a cs learner is to form a generalization such that the average cost on previously unobserved instances is minimized. obviously  this minimal cost is determined by two most important factors:  1  the inductive bias of the underlying cs learner; and  1  the quality of the training data. existing research has made significant progress in exploring efficient cs learning algorithms  bradford et al. 1  zuberk & dietterich 1  tan 1  geibel & wysotzki 1  brefeld et. al. 1  domingos 1  chan & stolfo 1  zadrozny 1  abe & zadrozny 1   with assumptions that the input data are noise-free or noise in the datasets is not significant. in datadriven application domains  many potential problems  such as unreliable data acquisition sources  faulty sensors  and data collection errors  will make data vulnerable to errors. it is therefore important to understand how a cs learning algo-
    the support of the national science foundation of china under grant no.1 is acknowledged.
rithm behaves in noisy environments and how to handle data errors in supporting effective cs learning. in this paper  we report our empirical study on the impact of noise on cs learning. it is hoped that our observations will be beneficial to any real-world applications with cost concerns.
1 	related work
the problem of learning from noisy data has been a focus of much attention in data mining  quinlan 1b   and most algorithms have a mechanism to handle noise in the training data. for example  pruning on a decision tree is designed to reduce the chance that the tree is overfitting to noise in the training data  quinlan 1 . in real-world applications  many learning algorithms rely on a data cleaning model for data enhancement  brodley & friedl 1 . although the problem of error handling in supervised learning has been well studied  research in the area has been mainly focused on general inductive learning for the minimization of zero-one loss or error rate. in reality  many applications are not only characterized by error rate  but also by various types of costs  turney   such as misclassification cost and test cost.
　among all different types of costs  the misclassification cost is the most popular one. assume that examples of a dataset are drawn independently from a distribution  d  with domain x y c  where x is the input space to a classifier  y is an output space  and c  1    is the importance  misclassification cost  associated with misclassifying that example. the goal of cost-sensitive  cs  learning  from the misclassification cost perspective  is to learn a classifier h: x  y which minimizes the expected cost  zadrozny 1 
	ed x y c  c  i h x   y  	 	 1 
　two important issues determine the minimization of the expected cost: the total number of misclassifications and the cost of each single misclassification. to minimize overall costs  a compromise is often made by sacrificing cheap examples and enhancing the accuracy on classes containing expensive instances. this is distinct from general inductive learning  because the latter is biased towards larger classes  likely the cheap examples in a cs scenario . to enhance a cs learner trained from noisy data environments  zhu and wu  1  have proposed a classification filter for data cleansing. but the study of cs learners in noisy environments still lacks in-depth empirical and theoretical analysis.
1 	experiment setting
an empirical study needs a full control over noise levels in the data  so that we can observe the behaviors of the underlying cs learners. for this purpose  we implement two manual corruption mechanisms  total random corruption  trc  and proportional random corruption  prc . with trc  when the users specify an intended corruption level x 1%  we will randomly introduce noise to all classes. i.e.  an instance with its label i has an x 1% chance to be mislabeled as another random class  excluding class i . trc  however  changes the class distribution in the dataset after noise corruption  which raises a big concern in cs learning  because modifying the class distribution may change the average cost considerably. we then propose prc  which keeps the class distribution constant during the noise corruption. given a dataset with y classes  assume the original class distribution is 1  1 ..  y  with iy i =1  where 1 and
y are the percentage of the most and least common classes respectively. for any user specified corruption level  say x 1%  we proportionally introduce random noise to different classes with instances in class i having a   y / i  x 1% chance of being corrupted as another random class. that is  we use the least common class as the baseline  and proportionally introduce noise to different classes. it is obvious that the actual noise level in prc is less  or even much less  than the intended corruption level.
　for each experiment  we perform 1 times 1-fold crossvalidation. in each run  the dataset is divided into a training set e and a test set t. we introduce a certain level of noise to e and generate a noisy dataset e . meanwhile  assuming a noise cleansing technique is able to remove all noisy instances from e   we can therefore build a cleansed dataset e . we observe cs learners trained from e  e   and e to study noise impact  assessed by using t as the test set . the empirical study is made by the observation on three benchmark two-class datasets  credit screen dataset  credit   wisconsin breast cancer dataset  wdbc   and thyroid disease dataset  sick   blake & merz 1   with their class distributions varying from almost even to extremely biased  as shown in table 1 . we use two-class datasets as our test bed  because a two-class problem can explicitly reveal the impacts of noise and cost-ratio on cs learning  whereas for multiple-class problems  issues such as costs among classes  class distributions  and errors in each class often make it difficult to draw comprehensive conclusions. we use the c1 cs classification tree  quinlan 1  in all experiments.
　to assign misclassification cost matrix values  c i  j   i j  we adopt a proportional cost  pc  mechanism: for any two classes i and j  i j   we first check their class distributioni and j. if i j  which means that class j is relatively rarer than i  then c j  i =1 and c i  j  equals to 1r; otherwise c i  j =1 and c j  i = 1 r  where r is the cost-ratio  as defined by eq.  1 .
	r  c  i  j 	c   j  i 	 	 1 
table 1. class distributions of the benchmark datasets 
datasetclass distributionseparability c1 credit screening  credit  1:11%wisconsin diagnostic breast cancer  wdbc 1:11%thyroid disease  sick 1:11%table 1. major symbols used in the paper
symboldescriptione  t  e   e e: training set  t: test set  e : noise corrupted training set  e : noise cleansed training setcs xthe average misclassification cost from dataset xac cs x ac nm xthe average classification accuracy of a cs and a normal classifier on dataset x respectivelyh t  vs h t a cs classifier vs a non-cs classifierx  y  cx: an input instance  y: class label of x  c: the cost associated to mislabeling xrthe cost ratio between the minor class and the major classthe number of instances in the test set tc  i  j the cost of predicting that an example belongs to class i when in fact it belongs to class j.	 	1the distribution of the major class vs the minor class	 	  1the classification error rate on the whole test set  the major class examples and the minor class examples
respectivelycsminthe cost of classifying a major class example into the minor classcsavgthe average misclassification cost on the test set tcsupper boundthe upper bound of a cs classifierd x y c the distribution of the noisy training set e d  x y c the distribution of a new set constructed by sampling e ed x y c   c i h x  y  the expected average misclassification cost of the instances drawn from the distribution d1	noise impact
1	misclassification costs
in figs. 1 to 1  we report the noise impact on the cost of cs learners trained from the benchmark datasets  where figs. 1 a  and 1 b   and figs. 1 a  and 1 b  represent the results from different noise corruption models of the wdbc and sick dataset respectively. fig. 1 c  reports the results from the credit dataset  because the class distributions of the credit dataset are almost even  we only report its results on the trc model . in all figures  the first and the second rows of the x-axis represent the intended and actual noise levels in the dataset. the y-axis indicates the average cost of cs classifiers. cs e and cs e represent the average cost of a cs classifier trained from e and e  before and after noise cleaning .
　as we can see from figs. 1 to 1  for both noise corruption models  the average cost of a cs classifier proportionally increases with the value of r  even if the dataset is noisefree. this does not surprise us  because we fix the cost of c i  j  to 1 and set the cost of c j  i  to 1r. so raising the value of r will surely increase the average cost. when noise is introduced to the dataset  the average cost will inevitably increase  regardless of the noise corruption model and the value of r. on the other hand  removing noisy in-

stances can keep average costs almost the same as that of r=1  1/1  is significantly larger than the increase from the noise-free dataset  e . this indicates that data cleansing r=1  1/1 . it is obvious that given the same amount of is an effective way to reduce the impact of noise on cs noise in the dataset  even if noise does not change the class learning. distribution  a dataset with a large cost-ratio tends to be 
　although noise increases the cost of a cs classifier re- more error prone and therefore may receive a large misclasgardless of the cost-ratio  r   when comparing the results sification cost. these observations indicate that when the from three r values  we can find that their patterns of in- dataset has a large cost-ratio value  the existence of noise crease are different. as shown in fig. 1 a   fig. 1 a   and becomes fatal  and a small portion of noise can corrupt the fig. 1 c   when r is small  increasing noise levels will results significantly. because of its sensitivity to minor data gradually raise the average cost  and the impacts of noise are errors  a dataset with a large cost-ratio will experience more less significant for low noise level data. on the other hand  difficulties in data cleansing  if the overall goal is to minifor large r values  introducing a small portion of noise will mize the misclassification cost. elevate the average cost greatly  and increasing the noise another interesting finding in figs. 1 to 1 is that when level further does not show significant extra impacts. how- applying cs learners to a noisy dataset  it seems that the ever  trc in fig. 1 a   fig. 1 a   and fig. 1 c  have already trained cs classifiers have a saturation point in reacting to changed the class distribution of the dataset  it is not clear the actual noise in the dataset  regardless of whether errors that given the same amount of noise in the dataset which change the class distribution or not. when the noise level is one is responsible for the increase of the cost: the change of below this point  it will continuously impact the cs classithe class distribution or the large cost-ratio r. we then turn fier. but once the noise level is beyond this point  the classito fig. 1 b  and fig. 1 b  for answers  where the class distri- fier becomes insensitive to noise. the following analysis bution is constant during noise corruption. will reveal that this saturation point is determined by two
　as shown in figs. 1 b  and 1 b   depending on the bias of most important factors: the class distribution and the costthe class distribution of the dataset  the actual noise level in ratio r. given a two-class dataset  assuming its class distrithe dataset is lower  or much lower  than the intended cor- bution is 1: 1  with 1 and 1 denoting the distribution of ruption level. for example  in fig. 1 b   when the intended the major class and the minor class respectively. the cost of noise level is 1  the actual noise level in the database is predicting a minor class instance as the major class is just about 1  please refer to section 1 and tab. 1 for the csminr  with csmin indicating the opposite cost  from the reason . at this noise level  the cost increase for r=1 is 1 major class to the minor class . assuming that we have built
 from 1 to 1   but for r=1 the increase is about 1 a cs classifier from the dataset and  for a test set t with  from 1 to 1 . one may argue that this increase may be examples  the classification error rates of this classifier on incurred by increasing the class-ratio r  because raising r the whole test set and the major class are and 1 will make the minority class more expensive. nevertheless  respectively. the error rate for the minor class 1 even if we assume that the classification accuracy remains is the number of incorrectly classified minor class examples the same  we can still see that the average increase from 
	 a  wdbc dataset  total random noise  trc 	  b  wdbc dataset  proportional random noise  prc 
fig. 1. impacts of class noise on the average cost of a cs classification algorithm

   a  sick dataset  total random noise  trc   b  sick dataset  proportional random noise  prc    c  credit dataset  total random noise  trc 
fig. 1. impacts of class noise on the average cost of a cs classification algorithm

divided by the total number of minor class instances  as shown in eq.  1 . then  the average misclassification cost in t  csavg  is denoted by eq.  1 .

the average misclassification cost csavg  with its value bounded by an upper bound given by eq.  1 .
	min	if	r 	 1 
1
cs upper   bound
	cs min	otherwise
　actually  the upper bound in eq.  1  is the average cost of predicting all instances belonging to the minor class when r
1  or predicting all instances belonging to the major class when r   1/ 1  which is the optimal solution for a cs classifier with low confidence  because any cost higher than this upper bound is not necessary . it is understandable that csavg csupper bound holds most of the time  which eventually produces the inequality denoted by eq.  1 . since
	 	  r	if r
	1	1	1	1 1
csavg csupper bound
	1  	1	1  r r	1 otherwis
	 1 	1	1 r
so	if	r	1	 1  r   1     1	1  r 1	otherwise r   1  
	for two class problems	1+ 1  so eq.  1  becomes
	*	1 { 1 	1} r	if	r 1  1 
	1	 1 r 	1	1	otherwise
　with the inequality in  1   we can finally analyze the relationship between the class distribution 1  1  the cost ratio r  and the error rate   and reveal the following facts: 
1. given a test set t  the average misclassification error rate of a cs classifier  which is trained from a training set equivalent to t  is bounded by a critical value* defined by eq.  1 . when r 1/ 1 the higher the value of the cost-ratio r  the lower the *  and the more likely the classifier tends to approach the saturation point.
1. in theory  when r   1/ 1  * becomes 1  1r  1  which can be approximated as 1. this means that the larger the number of minor class instances  a larger 1   the higher the*  and the less likely the classifier tends to approach the saturation point. however  this conclusion crucially relies on the fact that the underlying cs learner is  optimal  and indeed knows that sticking to the major class will lead to the lowest cost  which is not always the case in reality  as we will analyze next .
	from section 1 and tab. 1  we	know that	1:
1.1.1  r   	1/ 1 for any r=1  1  1  and
csmin=1 for the wdbc dataset. so according to eq.  1  
csupper bound is 1  which is consistent with the results in fig. 1 a . now the interesting results come from the results in fig. 1 a   which also clearly poses a saturation point of the misclassification cost. according to table 1 and eq.  1   we know that for the sick dataset 1: 1.1.1  so the ratio between 1/ 1 is far larger than the value of r. as a result  the csupper bound should be 1 r csmin   1  1 r  corresponding to the second item in eq.  1  . unfortunately  the results in fig. 1  a  indicate that the real csupper bound we got is about 1  which actually equals the value of having all instances classified into the minor class  the first item in eq.  1  . in reality  it is understandable that the underlying cs learners are reluctant to stick to the major class for minimal misclassification cost  especially when noise has changed the apriori class distributions significantly. instead  the cs learners will tend to stick to the minor classes in high uncertainty environments. as a result  the results from this seriously biased dataset are consistent with the conclusion drawn from the first item in eq.  1 . 
　based on the above observations  we know that given datasets with the same noise level but a different cost-ratio value r  the larger the cost ratio r  the smaller the value of
 *  then the dataset is more likely to approach to a saturation point  where the misclassification cost appears to reach the maximum. meanwhile  class noise does not continuously make an impact on the cs classifier all the time  and after noise reaches a certain level  the cs classifier may simply stick to the minor class. as a result  the impact of the noise in the system becomes constant. given a dataset with r 1/ 1  which is pretty common in reality   the higher the cost-ratio  the more likely the classifier tends to do so. for situations r   1/ 1  the conclusions will also likely hold.
1 classification accuracies
the above observations conclude that a dataset with a higher cost-ratio is sensitive to data errors  and learners built from such data are most likely cost intensive. this conclusion does not  however  solve the concerns like:  1  why is a learner built from noisy data with large cost-ratio cost intensive  and  1  given any noisy dataset d  if users were able to build both a normal classifier or a cs classifier  which one of them is more trustworthy in identifying noisy examples  now  let's refer to the theoretical proof and empirical comparisons of the classification accuracies between a normal classifier and a cs classifier for answers.
the following analyses are based on an existing folk theorem1  zadrozny et. al. 1   which states that if we have examples drawn from the distribution:
c
	d' x  y  c  d x  y  c 	 1 
ed x  y  c  c 
where d x y c  represents the distribution of the original dataset e  then the optimal error rate classifiers built for newly constructed distribution d are the optimal cost minimizers for data drawn from d. this theorem states that if we sample from the original distribution  d  of dataset e and constructing another distribution d   the efforts which try to learn an optimal error rate classifier on d actually leads to a classifier which optimizes the misclassification cost for d.
theorem 1: for a dataset e with a distribution d  assuming we are able to use an optimal learning theory to build a cs  h t    and a normal classifier  h t   respectively. then h t  is inferior to h t  in terms of the average classification accuracy. that is  errd h   errd h   where errx    represents the classification error rate of the classifier on x.
proof:
assume a cs classifier h t  was built from d. then with the cs learning formula in eq.  1   the expected cost of h t  on d can be denoted by eq.  1 .
	ed x y c  c i h x 	y   	d x  y c  c i h x 	y 	 1 
x y c
with the folk theorem in eq.  1   we know that
		c	  where d  is the sam-
d  x  y  c  d   x  y  c 
             e d   x   y   c    c  pled distribution from d. then eq.  1  becomes.
ed  x y c d  x y c  c 	d  x  y c i h x 	y  1 
ed  x y c 	d  x y c  i h x 	y   we can transform eq.  1  as follows.
1
	ed x y c  i h x 	ed x y c 	y  
 1 
ed x y c 
because ed x y c  c 	argmaxc{ x  y c  d}  eq.  1  becomes
because h t  was built on a biased distribution d sampled from d  therefore errd  h t   errd  h t  ; otherwise  there is no need for h t  to exist  we can directly use h t  on d for normal classification . therefore  we have eq.  1  and the statement of theorem 1 is true.
	errd h t   	errd h t  	 1 
　now let's turn to the experimental results in fig. 1 to evaluate whether the empirical results indeed support our theoretical analysis  the meaning of each curve in fig. 1 is denoted in fig. 1 . in fig. 1  ac cs e and ac nm e indicate the classification accuracies of a normal and a cs classifier trained from e respectively. as shown in fig. 1  when the cost-ratio is small  r=1   the differences between the accuracies of the normal and cs classifiers are trivial  with the accuracy of the cs classifier slightly worse. this is understandable  because a cs classifier likely sacrifices the accuracy for minimal costs. when the cost-ratio gets larger  r=1 or higher   the accuracy of the cs classifier becomes significantly worse than the normal classifier. if we compare fig. 1 a  with fig. 1 a  and fig. 1 c  with fig. 1 a   we can find that this is actually the reason a dataset with a large cost-ratio is more willing to approach to the saturation point. in this situation  a small portion of noise will make the cs classifier ignore the classification accuracy and stick to the  optimal  class.

	 a  wdbc dataset  trc 	   b  wdbc dataset  prc 	 	 c  sick dataset  trc 	  d  sick dataset  prc 
fig. 1. impacts of class noise on the classification accuracy of normal and cs classification algorithms　theorem 1 together with the results in fig. 1 clearly indicates that in general situations  a cs classifier is inferior to a normal classifier  in terms of classification accuracy. because removing mislabeled training examples was shown to lead to a better cs learner  as shown in figs. 1 to 1   class noise handing for effective cs learning will crucially depend on accurate noise identification mechanisms. as a result  in noisy environments  if we want to adopt a noise identification mechanism for data cleansing  we shall trust a normal classifier rather than a cs classifier  because the former always has a higher accuracy in determining the right class of an instance. 

1	misclassification costs and accuracies
for a given example ik  assume we know the probability of each class j  p j|ik   the bayes optimal prediction for ik is the class i that minimizes the conditional risk  domingos 1  duda & hart 1   as defined by eq.  1 . the conditional risk p i|ik  is the conditional probability of predicting instance ik belongs to class i. according to the bayesian formula  we can transform eq.  1  to eq.  1 . the bayes optimal prediction is guaranteed to achieve the lowest possible overall cost  i.e.  the lowest expected cost over all possible examples ik  weighted by their probabilities p ik  .
　with eq.  1   it is clear that c i  j   p ik | j   and j  together with the rule above imply a partition of the example space with j regions  such that class j is the optimal  leastcost  prediction in region j. the goal of cost-sensitive classification is to find the frontiers between these regions  explicitly or implicitly. however  this is complicated by two factors:  1  their dependence on the cost matrix c; and  1  the changes of both likelihood p ik | j  and prior probability j of different classes j  caused by the existence of noise. in 
general  as misclassifying examples of class j becomes more expensive relative to misclassifying others  the region where j should be predicted will expand at the expense of the regions of other classes  even if the class probabilities p j|ik  remain unchanged. in noisy environments  the probability of each class j  p j|ik   becomes less reliable  due to the reason that noise modifies the likelihood p ik|j  and the prior probability j. with eq.  1   it is understandable that any error introduced to the likelihood p ik|j  is going to be magnified by the cost matrix c i  j   the cs classifier tends to favor  expensive  classes   even if noise does not change the apriori class distribution j. as a result  the higher the costratio in the dataset  the more sensitive the cs classifier behaves to the data errors.
	arg mini p i | ik    arg mini  p  j | ik    c i  j 	 1 
j
according to bayesian formula  we have
	p  j | ik   	 1 
where p ik | j  is the likelihood of instance ik  given a particular class j  and p is the sum of all the likelihoods. assume j=p j  is the prior probability of class j. then  eq.  1  can be transformed as follows:
arg min i p i | i k    arg min i j  1  j	p
1 	conclusions 
this paper has empirically and theoretically studied the impacts of mislabeled training examples  commonly referred to as class noise  on cost-sensitive learning. we observed behaviors of cost-sensitive learners trained from different noisy environments and assessed their performances in terms of average misclassification cost and classification accuracy. our quantitative study concludes that the existence of class noise can bring serious troubles  higher misclassification costs and lower classification accuracy  for cost-sensitive learning  especially when misclassifying some classes becomes extremely expensive. removing noisy instances will significantly improve the performance of a costsensitive classifier learned from noisy environments. our observations suggest that cost-sensitive learning should be carefully conducted in noisy environments. comparing to general inductive learning  the success of the cost-sensitive learning crucially depends on the quality of the underlying data  where system performances can deteriorate dramatically in the presence of a small portion of data errors.
