 
we present a design for an automated theorem prover that controls its search based on ideas from several areas of artificial intelligence  ai . the combination of case-based reasoning  several similarity concepts  a cooperation concept of distributed ai and reactive planning enables a system to learn from previous successful proof attempts. in a kind of bootstrapping process easy problems are used to solve more and more complicated ones. we provide case studies from two domains in pure equational theorem proving. these case studies show that an instantiation of our architecture achieves a high grade of automation and outperforms state-of-the-art conventional theorem provers. 
1 	introduction 
research concerned with achieving more efficient  fully automated  theorem provers focuses on three directions: higher inference rates  eliminating unnecessary inferences  and better control of the search. although all these directions can indeed lead to more efficiency  better control of the search offers the highest gains  but also causes the most problems and has some risks. nearly all approaches to improving search control involve the use of techniques and methods from other areas of artificial intelligence  ai   as for example knowledge representation  case-based reasoning  cbr   learning  planning  or multi-agent systems. in most of the known works only ideas from one of these areas are exploited. 
　one area' that should-from the human point of view-be the most promising for high efficiency gains is learning. but the use of machine-learning techniques for improving automated theorem provers faces several severe problems. learned knowledge has to be stored  retrieved  and very often must be combined. so  the focus of attention should not be restricted to the area of machine learning. other areas of ai must also contribute in order to successfully apply the results the learning techniques produce. 
　in this paper we present an approach to controlling the search of an automated theorem prover that com-
1 	automated reasoning 
bines techniques from several areas of ai to overcome the problems that arise when trying to learn and to use control knowledge. the central idea is to utilize a known  i.e.  learned  proof of a so-called source problem solved previously in order to guide the search for a proof of the target problem at hand. to this end we employ a method 
called flexible re-enactment  cp.  . 
　source problems must of course satisfy certain similarity criteria with respect to the target problem. our techniques for maintaining a database of source problems and our mechanisms for selecting source problems that are the most similar to the target are inspired by cbr. unfortunately  one of the important premises of cbr  namely that  smail differences between problems result in small differences of their solutions   is not fulfilled in automated theorem proving. 
we cope with this uncertainty by applying the team-
work method     a multi-agent approach to distributed search. teamwork reduces the risk of deploying an inappropriate heuristic by having a team of heuristics  agents  guide the search concurrently and cooperatively. the reactive planning capabilities of a further agent  namely the supervisor  are made use of to compose a suitable team  cf.  . moreover  the selection of the most suitable source problem required by flexible re-enactment can also be integrated with teamwork in form of a specialized agent. 
　the combination of all these ai methods allowed us to build a theorem prover for pure equality reasoning that is fully automated  in both learning and proving  and is able to solve hard problems by using a kind of bootstrapping process that starts with easy problems and uses their proofs to gradually solve harder and harder problems. besides providing the problems  no interaction with the system is required. our experiments validate and substantiate the achievements of our system. we cannot provide as many details as some readers  and we  would like. these readers may refer to . 
1 	equational reasoning 
equational reasoning deals with the following problem: 
given a finite set e of equations  of terms over a fixed signature sig  and a goal u = v. the question is whether the goal equation is a logical consequence of e  i.e.  e  = u = v. unfailing completion  e.g.    has proven to be quite successful for solving such a proof problem a =  e  u = v . the method is also a good example for socalled generating calculi that are based on generating new facts until a fact describing the goal is reached. 
　the inference rules of a generating theorem prover can be divided into two classes: expansion and contraction rules  see  . completion uses the expansion criticalpair-generation and the contractions reduction and subsumption. basis for the completion procedure is a socalled reduction ordering y that is used to restrict the applicability of the inference rules and to avoid cycles. 
　an algorithmic realization of the inference rules of a generating theorem prover can be characterized as follows. there are two sets of facts  equations in our case : the set fa of active facts and the set fp of passive facts. the algorithm centers on a main loop with the following body: at first a fact a is selected and removed from fp   activate a  . after that a is normalized resulting in a fact a'.  normalization denotes the application of contraction rules to a fact until none of these rules is applicable anymore.  if a' is neither trivial nor subsumed by an active fact  all elements of fa are normalized  a' is added to fa  and all facts that can be generated with a' and other elements of fa are added to fp. a proof is found if the normalization of the two terms of the goal leads to the same term. 
　assuming that there is a given order in which contracting inference rules are applied  normalization of a fact is a deterministic process. hence  the remaining indeterminism is to determine which fact should be activated next. in order to eliminate this indeterminism  selection strategies and heuristics are used  see  e.g.   . in section 1 we present such a selection heuristic that is based on re-enacting a successful proof attempt for a problem that is somewhat similar to the problem at hand. 
　since we want to learn from  successful  proof attempts  we have to obtain  represent  and store an actual proof run produced by the algorithm and a selection heuristic. sa denotes the sequence of facts activated during a proof run for problem a using a fixed heuristic h. the actual proof to a is denoted by pa and it is obtained by eliminating from sa all facts that did not contribute to the proof. we refer to the facts occurring in pa also as the set pa of positive facts. the other facts in sa form the set na of negative facts that is needed for some learning approaches  see  1; 1  . a successful proof attempt is stored as the quadruple  a h sa va   or {a c sa va  with c denoting the teams used  that allows the use of various approaches for learning from previous proof experience. 
1 	teamwork 
the teamwork method is a knowledge-based distribution method for certain search processes   . equational deduction by completion  as well as for example first-order deduction by  hyper-  resolution  is a member of this class of search processes. in a teamworkbased system there are four different types of agents: experts  specialists  referees  and a supervisor. experts and specialists are the agents that work on really solving a given problem. experts form the core of a team. they are problem solvers  in our case theorem pro vers  that use the same inference mechanism  in our case unfailing completion   but different selection strategies for the next inference step to do. specialists can also search for a solution  using other inference mechanisms  or they can help the supervisor  for example by analyzing and classifying the given problem like pes  see section 1 . each expert/specialist needs its own computing node. therefore  the supervisor determines the subset of experts/specialists that are active during a working period. 
　after a working period a team meeting takes place. in the judgment phase  each active expert and specialist is evaluated by a referee. each referee has two tasks: judging the whole work of the expert/specialist of the last working period and selecting outstanding results. the first task results in a measure of success  an objective measure that allows the supervisor to compare the experts. the second task is responsible for the cooperation of the experts and specialists  since each selected result will be part of the common start search state of the next working period. the referees send the results of their work to the supervisor. 
　in the cooperation phase the supervisor has to construct a new starting state for the next working period  select the members of the team for this next period and determine the length of the period. the new start state for the whole team consists of the whole search state of the best expert enriched by the selected results of the other experts and the specialists. the supervisor determines the next team with a reactive planning process involving general information about components and problem domains  long-term memory  and actual information about the performance of the components  shortterm memory . the long-term memory suggests a plan skeleton that contains several small teams for different phases of a proof attempt. these suggested teams are reinforced with appropriate experts/specialists  if more computing nodes are available . during each team meeting the plan has to be updated. this means that adjustments are made according to the actual results  see  . 
　teamwork allows for synergetic effects that result in enormous speed-ups and in finding solutions to problems that are beyond the possibilities of the single experts and specialists. while the competition of the experts directs the whole team into interesting  and promising  parts of the search space  the cooperation provides the experts with excellent facts they are not able to come up with alone. thus gaps in their derivations towards the goal can be closed. this makes teamwork the ideal basis for a learning theorem prover. 
1 	flexible re-enactment 
similarity between two proof problems a and b can occur in many variations. one possible kind of similarity is 
	denzinger  fuchs  & fuchs 	1 
that a considerable number of the facts that contribute to a proof of a are also useful for proving b  or vice versa . this means in our terminology that the associated sets of positive facts pa and pb or the proofs pa and pb  have a lot in common  or  in other words  share many facts.   pa pb pb is almost equal to pa and pb   our goal is to think up a heuristic that is able to exploit such a similarity. 
　given 1 =  as /h sas 'pas  as past experience regarding a source problem as  and assuming that a target problem at is similar to as in the way just described  it is reasonable to concentrate on mainly deducing facts when attempting to prove at that also played a role in finding the source proof pas   namely the positive facts pas we therefore design a heuristic flexre which-when trying to prove at-makes use of j by giving preference to facts that were important for finding pas such facts will henceforth be referred to as focus facts. note that focus facts are facts inferred or. inferable in connection with at   they must be distinguished from the positive facts pas belonging to the source problem as  since it might be the case that some a 1 pas is not deducible at all in connection with at  due to a different axiomatization . pas is merely used to determine if some fact a inferable in connection with at is a focus fact. to put it another way  the use of pas is effected by flexre on a strictly heuristic basis  meaning that pas only influences the selection of facts from fp  not  for instance  fp itself. that is  pas is a guideline that flexre tries to follow if possible. 
　depending on how strongly focus facts are preferred  flexre will re-enact  parts of  pas more or less quickly. 
some of the focus facts  though useful for proving as  may be irrelevant regarding the proof vat of at eventually found. but these irrelevant focus facts are not a big problem. the crucial difficulty is to find those  nonfocus  facts that have to supplement the relevant focus facts in order to obtain a proof vat   it is very likely that these  few  missing facts are descendants of relevant focus facts. consequently  flexre should also favor descendants of focus facts. favoring descendants should weaken with their  distance  from focus facts  since it cannot be assumed that the few missing facts are located very deeply relative to focus facts.1 
　preferring descendants of focus facts in addition to giving preference to focus facts themselves justifies the attribute 'flexible' in the term 'flexible re-enactment' which summarizes the working method of flexre  see 
 or  . 
1 learning and cbr in the teamwork environment 
in sections 1 and 1 we concentrated on how to use knowledge learned from previous successful proofs  in form of 
　　1   distance  and  relative  depth basically refer to the number of inference steps separating two facts  one of these facts contributing to the deduction of the other. 
1 	automated reasoning 
flexible re-enactment  and on how to overcome the problems such a use might cause  in form of the teamwork method with cooperation with other experts  assessment of experts and results  and reactive planning to adapt to the problem at hand using long- and short-term memory . the problems that remain are how to find a proof that should be re-enacted in order to solve a given target problem and how to structure  build  and maintain the long-term memory from proof run to proof run. 
　the first problem will be tackled by a specialist pes that is providing the supervisor with information about known proof problems that are similar to the given target problem  see subsection 1 . the second problem naturally depends on how the proof problems are presented to the system. found proofs have simply to be extracted  analyzed and stored  the latter depending on how specialist pes will perform its retrieval . as we shall see in the next subsection  the necessary components are already provided in form of teamwork agents. 
1 	the basic learning cycle 
systems that use learning techniques for solving their tasks can be  very  roughly divided into two groups: systems that have a clearly defined learning phase after which  usually  no further learning takes place  and systems that always learn. in automated theorem proving  systems of the first type may be usable in clearly defined situations  see  for example     but in general learning should never stop. 
　nevertheless  one can observe times in the use of a  learning  theorem prover in which new domains are explored  and other times in which one is interested in proving one particular problem. when exploring a new domain  typically there is a set of problems to be solved  and when starting the exploration no knowledge in the prover will be triggered. in the following  we will first concentrate on the exploration of a new domain and then we will point out how the one-problem case is handled. 
　when exploring a new domain the ordering of the problems given to a prover may influence its success. in order to deal with this problem we decided to let the prover handle the ordering of the given set of problems and also allow the prover to make several attempts to solve a problem. the latter is necessary since each solved problem may result in new knowledge that allows for solving some other problems that could not be solved so far   bootstrapping''' . note that the set of problems given to the prover has to include easy and typical problems of a domain that the prover can use to get fundamental knowledge about this domain. 
　as already stated  in a teamwork-based system the long-term memory that represents knowledge about domains is the responsibility of the supervisor. when confronted with a set of example problems of a new domain  the supervisor controls not only the single proof attempts  but a whole series of proof attempts that are to result in solving as many of the problems as possible. 
　since the supervisor has no appropriate information when being confronted with a new domain  the first step 


	denzinger  fuchs  & fuchs 	1 

1 	automated reasoning 


problems when trying to solve the next one  the chain of the grp domain is the result of 1 rounds  while the chain of the lcl domain was produced in only 1 rounds of the bootstrapping process. note that any other ordering of the problems would produce the same table 1 and the same chains in table 1. only the number of rounds needed may be different. 
   among all the problems there is only one problem that o t t e r can solve and our learning team cannot  but 1 problems that our learning team can solve and otter cannot. 
   in general  our experiments show that our concept of a learning theorem prover clearly outperforms current conventional theorem provers if the learning prover is provided with enough ''exercise  in the domain it has to work in. in this case even the learning process is accomplished by the prover without help from the user. 
1 	conclusion and future work 
we presented a concept for a learning theorem prover that uses methods from several areas of a l . ai methods like planning and cbr are combined with the t e a m w o r k multi-agent architecture  resulting in a theorem prover that clearly outperforms renowned provers. a prerequisite for the success of our system- as for a human student-is the presentation of problem domains in a  learnable  way  meaning that the presented problems cover the whole spectrum of difficulty ranging from easy to challenging. in a kind of bootstrapping process the system is able to solve harder and harder problems without any interaction on the parts of a user   teacher  . 
　despite the success of our system  nevertheless most components are only first ideas that leave much room for improvements and extensions. also  there are other concepts that can be used  e.g.    or are at least worth investigating  e.g.  the division of problems into easier sub-problems on the basis of learning   that will provide a wider range in the use of learned knowledge. 
acknowledgments 
this work was supported by the schwerpunktprogramm deduktion of the deutsche forschungsgemeinschaft  dfg . 
