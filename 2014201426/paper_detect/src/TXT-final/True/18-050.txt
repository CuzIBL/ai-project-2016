 
landscan  language driven scene analysis  is presented as an integrated vision system which covers most levels of both vision and natural language processing. computations are both data-driven and query-driven. in the report we focus on the design of the vision and control modules. future work will investigate in more detail the design of the natural language interface. the data-driven system employs active control of stereo cameras for image acquisition  and dynamically constructs a surface model from multiple aerial views of an urban scene. the query-driven system allows the user's natural language queries to focus analysis to pertinent regions of the scene. this is different than many image understanding systems which present a symbolic description of the entire scene regardless of what portions of that picture are actually of interest. 
1. introduction 
     the aim of our research on landscan  language driven scene analysis  is to develop a system capable of dynamically updating and maintaining a model of an urban world over multiple aerial views. the system will have a natural language front end through which users can query the system about a scene  and interactively assist the vision processing by restricting the analysis to those areas of the scene which are of current interest. a unique contribution of the work is that processing is both data-driven  bottom up  determined by sensor data  and query-driven  top clown  determined by user queries . the integration of both methods into one system can help overcome the shortcomings of each method employed independently. for example  if data-driven processing were able to segment a graph of edges derived from the image into several different connected components  querydriven information about what the system should be looking for can help impose structure  and a unique segmentation  upon the otherwise ambiguous data. 
     the data-driven processing starts with stereo aerial images and reconstructs the surfaces in the scene. the query-driven processing constructs a logical representation of the scene using the queries to guide analysis. highlevel scene analysis is performed using an augmented transition network  atn . 
this research was supported by the following grants: aro 
daa1-1-k-1 afosr 1-nm-1w nsf mcs-1-cer nsf mcs 1 avro daab1-k-f1 nih 1-rol-
hl-1. 
     as an example  suppose the user asks   is there a car on the street * the output from this query would be: the objects to be recognized  car and street; the relation on which must hold between them; and an indication that this query is responded to by a yes/no answer with some explanation. the vision system would then be called to find a car and a street in the relation on. the car and street would then be added to the scene model  if not there already  and the system would reply with an affirmative response. 
     this paper will describe some related research  the implementation of the data-driven and query-driven portions of the landscan system  and our plans for future work. a later paper will detail how natural language queries will interface with landscan to guide the scene analysis. 
1. related research 
     a large corpus of research on aerial image understanding per se exists  and many general vision techniques are applicable to the aerial domain. large aerial projects have been undertaken at usc  nevatia 1   cmu  herman 1  and sri  fischlcr 1 . however  very few integrated systems have been successfully implemented  and the best system architecture is still an open question. in particular  the problem of providing high-level feedback to the vision system has not been adequately addressed. 
     atn's have been used primarily in the domain of natural language  bates 1    winograd 1 . a notable exception is the system designed by tropf and walter 
  tropf 1  which uses an atn model for the recognition of 1d objects with known geometries. 
the work of talmy  talmy 1  and herskovits 
  herskovits 1  influenced the design of both the topological relations in the models and the choice of linguistic attributes which must be associated with objects in order to ensure a robust and reliable natural language interface. 
1. data-driven system implementation and results 
     this section will describe the data-driven vision module ;  which must be effective in an urban world  seen from above. urban scenes are characterized by an abundance of straight lines and planar surfaces. under 

1 r. bajcsy et al 

1. surface model 
a graph is constructed to serve as the surface model 
  krotkov 1 . the construction algorithm converts a set of contours into a set of closed contours represented as a graph  a linked list of vertices  edges  and faces  by traversing edges and at trihedral junctions choosing the path making the most acute angle with respect to the present path. 
surface attributes and relations are computed in the 

	figure 1: 	depth map of partial view of 1-
surfsup  radack  et al 1  geometrical modelling system. 
attribute values for each face in the surface graph are computed: compactness  centroid  normal  area  type  building  sidewalk  field  street  and unknown   and number of sides. these values are computed once and stored on an attribute list. computed topological relations are above  adjacent  touching   contiguous  sharing an edge   contains  proper inclusion   looksadjaccnt  lookscontiguous  respectively adjacent and contiguous under perspective transformations . relations  and indirectly their complements  are computed once and stored as boolean arrays. 
1. query-driven system implementation and 
results 
     this section describes the design and implementation of the query-driven processes! these include object recognition and scene modelling  zwarico 1   high level reasoning processes  and query handling. 
1. object recognition 
     the atn formalism ha s been chosen as the paradigm for object recognition in landscan. it is composed of three parts: the grammar  a dictionary  and an interpreter. the grammar represents the a priori or world knowledge that the system must have in order to recognize objects. the dictionary represents the actual data: a list of all of the faces which have been segments ' by vision and the relations between them. the third component is a lisp program which provides the control sructure for the process. figure 1 shows the results of 
running the recognizer on the scene in figure 1. 
1. the scene model 
     the scene model is composed of two components: a list of objects currently known to be in the scene and a 
     set of matrices representing the primitive relations. the objects on the object list have already been recognized. each object has associated with it a list of surfaces  its location  and a subtype. the relations which are the same as in the surface model  are represented by their adjacency matrices because the adjacency matrix is easily updated and makes composition of relations a simple matter of boolean matrix multiplication. 


	figure 1: 	reconstructed planar surfaces. 
     the scene model is dynamic because information can be added to it as further image analysis occurs. a new object is added to the head of the list. the relations are updated by calculating the relations between the new entity and the current object list. 
1. linguistic analyzer 
     given a query  the linguistic analyzer will symbolically represent this utterance so that it can be used by the reasoning process to analyze the image. the linguistic analyzer will parse the query  determine the query type  and categorize all implicit subqueries in the actual utterance. its output will contain a list of the obects to be found  the relations which must hold between these objects  and the query type  so that an appropriate response can be generated . this is not yet implemented. 
1. reasoning 
     the reasoner analyzes the query  determines the strategy for obtaining an answer to the query  and provides feedback to the vision system. in order to obtain the information necessary for the generation of the response the reasoner must have both runtime data  the current scene model and the query  and global knowledge  the world model and the object model . 
     the world model describes the features and relations of the objects in the domain  buildings  streets  sidewalks  etc. the world is represented by a labelled directed multigraph in which the nodes are the objects in the domain and the arcs are labelled with the relation which can hold between them. the object model represents the expected physical features  subparts  and linguistic properties  features which affect the usage and interpretation of a spatial construct  of the objects in the domain. 
     if the reasoning processes fail to produce a positive response  the query fails to have an answer   the reasoner performs two types of query failure analysis. the first type of query failure involves a query violating the global knowledge. in this case  the system will respond with a message indicating why the query is conceptually illformed in this domain. the other type of failure involves not finding the information requested in the scene model. in this case  rather than simply responding  not present   
r. bajcsy et al. 1 
the system may ask the user whether a new view of the scene should be analyzed. 
1. discussion 
     this paper has presented landscan  a prototype integrated system under development that covers most of the different levels of vision and natural language processing. it may be used both to guide the low-level vision processing  and to provide communication of visual information to a user. while landscan is not complete in the sense that all of it is successfully implemented  it provides a computational model for a vision system guided by natural language. 
     in summary  the data-driven subsystem of landscan takes stereo images and builds a surface graph representing three-dimensional geometric and topological attributes. the query-driven modules recognize objects and build a scene model which represents the user's interest in  the image. 
     the natural language interface which uses the scene representation still has to be designed. it must be able to apply locative linguistic constructs to some representation of visual data and reason about this data. when this is operative  the scene analysis will be truly query-driven and the goals of the system will have been reached. references 
 bates s   bates  madekine. the theory and practice of augmented transition network grammars. 
in leonard bole  editor   natural language communication with computers. springer-verlag  1. 
 fischler 1  	martin fiscliler. image understanding 
research and its application to cartography and computer-based analysis of aerial imagery. technical report  sri international  september  1. 
 herman 1  herman  martin  takeo kanade  shigeru kuroe. the 1d mosaic scene understanding system. in proceeding of the 1th international joint conference on artificial intelligence. 1. 
 herskevsts 1  herskovits  annette. space and the prepositions in english: regularities and irregularities in a complex domain. phd thesis  department of linguistics  stanford university  1. 
 krotkov 	1  	krotkov  eric. construction of a three 
dimensions 	surface model. technical report mscis-1 -jo  cis department  university of pennsylvania  1. 
 talmy 1  talmy  leonard. how language structures space. technical report 1  berkeley cognitive science report  january  1. 
 tropf 1  tropf and walters. an atn for 1-d recognition of solids in single images. in proceedings of the sth international joint conference on artificial intelligence. 1. 
 winograd 1  winograd  terry. language as a cognitive process. addison-wesley publishing co.  1. 
 zwarico 1  	amy zwarieo. the recognition and 
representation of 1d images for a natural ianguage driven scene analyzer. technical report ms-c1s-1  university of pennsylvania  1. 
learning shape descriptions 
jonathan h. conn ell and michael brady 
massachusetts institute of technology  artificial intelligence laboratory 
technology square  cambridge ma 1 abstract 
   we report on initial experiments with an implemented learning system whose inputs are images of two-dimensional shapes. the system first builds semantic network shape descriptions based on brady's smoothed local symmetry representation. it learns shape models from them using a modified version of winston's analogy program. the learning program uses only positive examples  and is capable of learning disjunctive concepts. we discuss the lcarnability of shape descriptions. 
1. introduction 
   we report on initial experiments with an implemented system that learns two-dimensional shapes from images. the system first builds semantic network descriptions of the imaged shape based on brady's smoothed local symmetry representation  brady and asada 1  ileide 1 . it learns shape models from the descriptions using a modified version of winston's ana log y program  winston 1  1  j1; winston  binford  katz  and lowry 1 . the inputs to the program are grey-scale images of real objects  such as tools  model airplanes  and model animals. the outputs of the program are production rules that constitute a procedure for recognising subsequent instances of a taught concept. 
   figure la shows the gray-scale image of  a model of  a boeing 1  figure lb shows the results of brady's smoothed local symmetries program  and figure lc shows a portion of the semantic network that is computed from them by our program. the semantic network is transformed into a set of associative triples  doyle and katz 1  and input to our learning program. the 1 generates 1 associative triples. similarly  figure 1a shows the subshapes found from the smoothed local symmetries of a tack hammer and figure 1b shows the full semantic net for this image. the tack hammer generates 1 associative triples. 
   the learning program is a modification of winston's analogy  council 1 . it is capable of learning concepts containing disjunctions. the program learns shape models using positive examples only. figure 1b shows the concept hammer that is learned from the three positive instances shown in figure 1a. 

figure 1. a. the input image  b. the smoothed local symmetries of the plane c. a portion of the hierarchical semantic network that is computed from the information m b. the full network generates 1 associative triples. 
   the novelty of our work is the ability to learn visual shape representations from real visual data. previous work has not been based on real data because such data was unavailable or too complex and unstructured for existing learning algorithms. however  recent developments 
in edge-detection  canny 1  and middle-level vision  brady and asada 1  have provided a solid base on which to build a robust vision system. using this system we can generate shape descriptions in a form amenable to learning. furthermore  although the descriptions typically comprise between fifty and three hundred assertions  various forms of abstraction keep this volume of data manageable. 

j. connell and m. brady 1 


figure 1. a. the main nmoothed local symmetries computed from the results of brady's program  h. the semantic network that is computed from the information in a. 
1. representing shape 
to describe an object it is necessary to first segment it into separate subshapes. in terms of the mathematical analysis in brady and asada 1 i  a subshape is defined as maximal with respect to smooth variations in the defining parameters. for example  the portions of fuselage in front of and behind the wings of the b1 in figure 1 are joined  but the handle and blade of a screwdriver arc perceived as separate pieces. once a part has been found  its shape is specified by three numbers: the aspect ratio  the curvature of the axis  and the change in width along the axis. 
   joins between subshapes are determined by examining the spines of the regions and the adjacency of the contour segments. a join is specified by the relative angle and sizes of the pieces  and the location of join with respect to each piece. few previous representations of shape have described subshape joins. for example  acronym  brooks 1  brooks and binford 1  specified the coordinate transformation between two joined pieces  but did not explicitly describe the join. 
   once we break the image into pieces and find the joins we must somehow represent this information. images are noisy  so it is necessary to develop representations that are stable  in the sense of being invariant under localized changes such as image noise. however  tasks involving visual representations  for example inspection  often require that programs be sensitive to fine detail. a variety of techniques for simultaneously achieving stability and sensitivity have been proposed  each expressing some aspect of hierarchical description. the underlying idea is that gross levels of a hierarchy provide a stable base for the representation  while finer levels increase sensitivity. 
figure 1. the concept hammer that is learned from the three positive instances shown above. 
a vision program needs to maintain several different representational hierarchies  including the following:   numeric values and symbolic descriptors 
   specifying a shape parameter of interest  say a measure of the elongation of a shape  by a numerical value is sensitive  but highly unstable. symbolic names that correspond to an interval of numeric values are  usually  more stable but less sensitive. our representation employs symbolic descriptors that have overlapping ranges. for example  an end which is determined to be on the borderline between blunt and sharp is declared to be both blunt and sharp. overlaps like this help to combat the quantization error introduced by encoding a continuous range as a set of discrete symbolic values. a small change in value leads to a small change in the representation. 
  structural approximations to shapes 
   marr and nishihara  proposed summarizing the lesser subparts of an object  leaving them unspecified until they are needed. for example  all airplanes have a fuselage  writh pairs of symmetrically attached wings and elevators. upon closer examination  a wing of a b1 has two attached engine pods  a dc1 has one  and an l1 none. suppressing mention of the engine subshapes  as well as summarizing the parameters that describe the shapes of the wings and fuselage  enables the descriptions of the three airplanes to closely match each other. 
   in general  larger subshapes tend to determine gross categorization  and so they tend to appear higher in the structural hierarchy. conversely  smaller subshapes tend to allow finer discrimination and occur lower in the hierarchy. the smaller subparts of a tool typically determine the specific function of the tool. for example  deciding whether a tool is an awl  a gimlet  or a phillips screw 

1 j. conneil and m. brady 
driver involves looking closely at the end of the blade; the relatively localized context of the business end of the blade is established by the grosser levels of the hierarchy  where it is recognized  for example  that the tool is not a hammer or wrench. in this way  the marr-nishihara proposal tends  hcuristically  to relate large scale geometric structure to gross functional use. 
  a-kind-of hierarchies 
   family hierarchies are ubiquitous  and apply as much to visual shape representations as to the more cognitive situations in which they were developed in artificial intelligence. acronym represents the fact that the sets of b1-sps  b1s  wide-bodied jets  jets  and aircraft  are ordered by subset inclusion. similarly  a claw hammer is a-kind-of framing hammer  which is a-kind-of hammer. in general  a subset hierarchy is a partially-ordered set  but not a tree. from the domain of tools  for example  a shingle ax is both a-kind-of ax  and a-kind-of hammer. 
1. learning 
the commonest form of inductive generalization used to learn concepts from positive examples is the drop condition heuristic idietterich and michalski 1  winston 1  page 1 . this is the method used in our program. through careful design of the representation the method has been extended to allow generalizations of intervals and structural graphs. 
   the idea behind the heuristic is that if two things belong to the same class then the differences between them must be irrelevant. accordingly  when we have a partial model of a concept and receive a new example  we modify the model by deleting all the differences between it and the example. this can be seen by comparing figure 1b with figure 1b. notice that the network in figure 1 puts very little constraint on the size or shape of the head. this is because the shapes of the heads in the examples vary widely. for instance  the heads of the first and third hammer are straight while the head of the second hammer is curved. note also that the manner in which the handle joins the head.is only loosely specified. this is because the handle is joined to the side of the head in the first two examples but to the end of the head in the third example. 
   this is a simplified explanation of the learning algorithm. the matching involved is not graph isomorphism nor is it  merely counting the number of required features an object has. rather it is a complex local matching scheme. consider using the semantic net shown in figure 1 as the model for the airplane concept. for an object to match this model  at the top level it must have three pieces which look similar to the three in the model. a piece of the example is similar to the wing model if  first of all  it has the shape specified in the network and  second  it has two things which look like engines attached to it. suppose that a certain piece has the right shape for a wing but has only one engine attached to it. at the level of the wing model the program notices that there is a discrepancy yet judges that the piece is still close enough to the description to be called a wing. when the top level of the matcher asks if the piece in question looks like a wing the answer is  yes . no mention is made of the fact that the wing is missing an engine. the difference only matters locally and is isolated from the higher levels of matching. 
   another important concern is limiting the scope of generalizations made. imagine that the program is shown a positive example that is substantially different from its current model. altering the model by the usual induction heuristics typically leads to gross over-generalization. this  in turn  runs counter to what winston  1  page 
1  has dubbed martin's law  namely: learning should proceed in small steps. therefore our program creates a new  separate model based on the new example  splitting the concept being taught into a disjunction. 
   in some cases  the disjunction will be replaced by a single model as positive examples are taught that are intermediate to the disjuncts. for example  suppose that the first example of a hammer shown to the program is a claw hammer  and that the second is a sledge hammer. the program will create a disjunction as its concept of hammer  but it will be consolidated into a single model once it has seen such examples as a mallet and ballpein hammer. 
   even though the program only generalizes a concept using an example that is structurally similar  it is sometimes deceived and must recover from over-generalization. we follow winston  and provide censors that override the offending rule. censors can be generalized and there can be disjunctive censors; in fact this is the usual case. since censors can be generalized they also have the possibility of being over-generalized. this is countered by putting censors on the censors. in general  a concept is not represented by a single model but by a group of models. there can be several positive models corresponding to the disjuncts as well as several negative non-models summarizing the exceptions to the other models. 
1. current work 
the goals of our research are not limited to learning. the work reported here forms part of the mechanic's mate project  brady  agre  braunegg  and conneil 1   which is intended to assist a handyman in generic assembly and construction tasks. the primary goal of that project is to understand the interplay between reasoning that involves tools and fasteners and representations of their shape. 
   for example  instead of learning that a certain geometric structure is called a hammer  we learn that something which has a graspable portion and a striking surface can be used as a hammer. these two functional concepts are then defined geometrically in terms of the shape representation. reasoning from function as well as from form 

allows more flexibility. for instance  faced with a hammering task  but no hammer  one might try mapping the hammer structure onto that of any available tool. a screw driver provides a good match  identifying the blade of a screw driver with the handle of the hammer  and the  assumed flat  side of the screw driver handle with the striking surface of the head of the hammer. in this way  the mechanic's mate can suggest improvisations  like using a screw driver as a hammer. 
   our initial goal was to learn shape models cast in the representation described previously. eventually  the mechanic's mate will have to learn about the non-geometric 
properties of objects: weight  material type  and the processes that use them. currently we are using katz's english interface |katz and winston 1  to tell our program such things. this is not satisfactory. instead  we hope to teach dynamic information using a robot arm and hand. 
   another area of interest is inducing structural subclasses from examples. since the subclasses that form the a-kind-of hierarchy are an important part of the shape representation  they should be learnable. however  in learning subclasses there is a danger of combinatorial explosion. learning subclasses requires a suitable similarity metric. feature-based pattern recognition systems learn subclasses as clusters in feature space  and clusters are sets that are dense with respect to the euclidean metric. part of our research in learning shape descriptions has been to determine what makes objects look similar. this suggests using the metric employed in the learning procedure to form subclasses through a process analogous to feature space clustering. this is the focus of our current work. 
1. acknowledgements 
this report describes research done at the artificial intelligence laboratory of the massachusetts institute of technology. support for the laboratory's artificial intelligence research is provided in part by the the system development foundation  the advanced research projects agency of the department of defense under office of naval research contract n1-o-1  and the office of naval research under contract number n1-c1. we thank the people who have commented on the ideas presented in this paper  particularly phil agre  steve bagley  hob berwick  hen duboulay  alan bundy  
margaret fleck  scott heide  boris katz  tomas lozanoperez  john mallery  tom mitchell  sharon salveter  dan weld  and patrick winston. 
