 
   this paper describes a method to extract 1-d information from two cameras in the scene on which multiple stripes are projected. though a single camera cannot identify each stripe in a scene and its image when discontinuities of each stripe occur  with one more camera which our method employs the identification problem can be solved  because multiple stripes and two cameras give two constraints. one is the geometric constraint which gives the necessary condition for identification of each stripe. another is the local constraint that features between images lie in constant order. after applying the geometric constraint  utilization of the local constraint enables identification of each stripe in a scene and its image. as a result  range data are obtained along multiple stri pes. 
   we also give a new method for computing camera parameters of 1 degrees of freedom which influence accuracy of 1-d information. they are derived mathematically by seeing the known cube. 
1. introduction 
   the importance of 1-d information in robotics has been widely recognized. one approach is to measure the distance on the basis of the triangulation principle from the disparity of two images taken at two different position  which is well known as stereo vision. this method has long been studied; however  it has a few problems; one is detecting features which are easily recognized in both images   and the other is finding correspondence of those features between both images . 
   on the other hand  the structured light method which replaces one of the cameras in stereo vision by a spot or a sheet of light projector solves the above problems a   however  this technique needs much time to extract range data of the entire image  because a sheet of light must be scanned across the scene. 
   in this paper we project multiple stripes. in this method  however  one image cannot inform of identifying each stripe in a scene and its corresponding image when discontinuities of each stripe occur; for example  when the object is concave or occlusion occurs between objects. in order to identify each stripe in a scene and its image  our method employs one more camera in addition to a light projector and a camera. then epipolar lines which two cameras produce on both images and multiand masahiko yachida ++ 
¡¡++ osaka university toyonaka  osaka 1  japan. 
pie sheets of light yield the geometric constraint  which gives the necessary condition for identification of each stripe. in addition  under a certain condition which is described later  the local constraint is useful  which means that some features on epipolar lines lie in constant order between both images. using the local constraint after the geometric constraint  we can identify each stripe between a scene and its image. 
   it is important to determine the camera parameters precisely  because they influence the accuracy of the computed value of 1-d position. gennery determined the most suitable camera parameters which minimize the sum of the errors over the known matching points. however  applying gennery's method requires that the initial estimate is fairly accurate. provided an uncertain initial estimate  this method may obtain the incorrect camera parameters as the most suitable ones. on the other hand  our method calculates the camera parameters mathematically from the image of a known cube. therefore our method does not need the i n i t i a l estimate and can obtain the camera parameters automatically 1. 

1 t. echigo and m. yachida 


point pk must correspond to the intersection between the epipolar line and the stripe pattern in the left image as same as the intersection r in the right image. the others  pk-   pk+1    pk+x  distribute on the epipolar line and few of them j ike a pk+m in fig.1 may correspond to the intersection between the epipolar line and a stripe which should not match with the one of stripes investigated on the right image. these projections  pk pk+m ....  corresponding to the intersections in the left image  which contain a true and a false  are treated as matching candidates. 
   therefore the geometric constraint cannot match all of them  but rejects false matching candidates remarkably. 
1 the local constraint 
   on the ordinary scene  left and right images may exchange the order of some features on two epipolar lines only when some objects exist in front and in the rear in the scene. fig.1 shows the top view of this situation. assuming that the point pi on the surface of the object p will project onto both images  the sub-object q  which exchanges the order of lines containing pj and the other features on the epipolar lines in the left image and the right one  should lie in the laterally striped region r1 in fig.1. at the same time q occludes some features in the checked region r1 on either of images. in fig.1 the order of the point p  and its neighboring features is exchanged between the left image and the right one by q. however  the greater q is  the larger region is occluded by q. then a set of the point pi and its neighboring features whose order is exchanged becomes smaller and at last p  may be occluded too. on the other hand  under the condition that the angle made of optical axes of left and light cameras is very small  the laterally striped region r1 becomes narrow. 
   from the above considerations  it can be said that exchange of the order occurs only when a very small object exists in front of the larger object  and stripe pattern is projected on it. however  in real scenes actually stripe pattern w i l l seldom appear on it.  therefore we can use monotony of order for correspondence  that is the order of appearing features on the epipolar lines is not exchanged for the left image and the right one. similarly if a projector lie in the neighborhood of a camera  the locaj constraint should be effective between light planes and stripes in the image. 

fig.1 	a counter-example of the local constraint. 
1 finding correspondences 
   first of a i l   lines of sight through intersections between an epipolar line and stripes of a 
t. echigo and m. yachida 1 
right image are drawn. then crossing points between light planes and lines of sight are treated as candidates for identification. 
   secondly the geometric constraint reduces a lot of improper candidates  using the left image to project all crossing points. then the local constraint is applied to the rest of candidates  that is when one stripe in the right image has plural candidates as a corresponding light plane  a candidate which is out of line with candidates of neighboring stripes must be canceled. for example  let a stripe image rj and neighbors have the fol-
lowing candidates: 

then candidates sk for ri should be satisfied with 

   this procedure keeps running until each stripe in the right image corresponds to the only one light plane or a number of candidates does riotdecrease. 
1. experimental results 
1 camera parameters 
   a cube in fig.1 is used for determination of camera parameters. three edges of a cube denote x y z axes in the object coordinates system. 
   in order to verify a camera parameter obtained by our method  a calculated parameter is compared 

fig.1 the cube for determination of camera parameters. 

fig.1 the experiment to examine a camera parameter 1 derived by our method. 

1 t. echigo and m. yachida 

