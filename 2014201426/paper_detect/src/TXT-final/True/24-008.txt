 
uncertainty on data often makes the task of perfectly matching two descriptions quite ineffective. in this case  a flexible matching  measuring the similarity of two descriptions rather than their equality  is more useful. according to the convention of connecting similarity to the most common concept of distance  we present a definition of distance measure  based on a probabilistic interpretation of the matching predicate  which can cope with structural deformations. as the problem of matching two formulas of the fopl is np-complete  two methods arc presented in order to cope with complexity: firstly  a branch-and-bound algorithm  and secondly  a heuristic method. these ideas are applied to the problem of recognizing office documents in digital form according to their page layout. 
1 	introduction 
the nature of the problem solving task performed by most expert systems is classification  that is  mapping entities of the world into a set of predetermined solutions or recommendations  clancey  1; weiss and kulikowski  1 . typically  expert systems for diagnosis are concerned with selecting an answer from an existing set of diagnoses  solution elements  given the description of a situation. classification is equally fundamental in nearly all knowledge-based pattern recognition systems  which have to assign appropriate interpretations to objects within a scene  chandrasekaran and keuneke  1 . independently from the direction of reasoning  either forward or backward  such systems operate with a description of the current state in the working memory and a description of the conditions to be satisfied in order to select the rule. 
   unfortunately  in real applications the descriptions may be both incomplete and also affected by noise. the latter problem is especially felt in those applications in which data are directly detected through sensors or transducers. a scribble on a document or a voice in the background are two common forms of noise. in addition  humans can also introduce errors in the data due to misunderstanding or lack of attention. another form of noise in a measurement occurs when the measuring instrument shows a poor accuracy. finally  information may be incomplete due to either human inadequacy or malfunctioning equipment. 
   when acquiring knowledge from humans  the problem could be solved by multi-expert knowledge acquisition and by applying a cross-validation technique to the rules provided by 
learning and knowledge acquisition 
the experts. in automatic knowledge acquisition the problem is approached by making the machine learning techniques more robust as regards noisy and/or incomplete data  quinlan  1 . 
   bergadano et al.  proposed an approach to learning human concepts which are inherently imprecise and context dependent. the method uses a two-tiered representation of learned concepts and a flexible matching  based on a numerical estimation of the typicality or certainty that an instance is a member of a concept  so providing a form of probabilistic inferential extension of a concept in this case  both concept metaknowledge concerning the importance of concept attributes as well as the  joint  probability distributions of these attributes are essential. 
   to sum up  noisy  imprecise  context-dependent and incomplete descriptions demand a more flexible matching process  also called partial matching in  hayes-roth  1   where two descriptions are compared in order to identify their similarities rather than their equality. generally  the term best match is also used when the rule which maximizes the similarities and minimizes the differences against the current state is selected. the result of a flexible matching should produce a number indicating how well two descriptions match. the number can be a value in the unit interval  1  such that 1 indicates a perfect match  1 no match at all  and any real number r  re  1   denotes our confidence in matching. the definition of such a similarity measure is strictly connected to the most common concept of distance  as the more distant two objects are  the less similar they can be considered. 
   several distance measures  or conversely  several similarity measures  have been proposed in the fields of pattern recognition 
 sanfeliu and fu  1; wong and you  1; shapiro and haralick  1  and machine learning  michalskief a/.  1; 
kodratoff and tecuci  1 . they differ in a variety of respects: 
  representation language: propositional logic  first-order predicate logic  feature vectors  attributed relational graphs;   type of problem the distance measures are applied to: pattern matching in knowledge-based systems  concept acquisition  pattern classification  discriminant analysis  conceptual clustering  numerical taxonomy; 
  theoretical approach: geometrical  syntactical  probabilistic  entropical  fuzzy  hybrid; 
  type of corrected deformations: local or structural. 
   this last point requires further explanation. generally  an object  or situation  can be decomposed by successive 

refinements until atomic parts  called primitives  are defined. once these subparts and their mutual relationships are identified  the structure is obtained  stepp  1 . the complete description of the object is given by: 
  the attributes of the entire structure  global attributes ; 
  the attributes of some subpart  local attributes ;   the attributes of the interrelationships between parts 
 relations . 
   when the differences between the two matching descriptions concern the global/local attributes it is said that local deformationsoccur  while when the differences are at the level of relations then deformations are called structural. not all distance measures take into account structural deformations  particularly those adopting a representation language which does not allow us to represent structural descriptions. 
   this paper introduces a definition of distance measure suitable for dealing with structural deformations which is based on a probabilistic interpretation of the matching predicate. the three basic characteristics of our definition are: 1  the possibility of dealing with rules whose conditions are not stated as exact descriptions of a particular situation but descri be  complex  properties that the situations must have; 1  the necessity to define  objectively or subjectively  the probability density functions of the features  attributes or relations  used to describe a situation; 1 the possibility of dealing with rules whose conditions are incomplete structural descriptions. 
　　in the following  section 1 introduces the definition of a flexible matching function for evaluating the goodness of any match between noise-affected structural descriptions. the problem of matching  or unifying  two expressions with commutative and associative operators is np-complcte  garey and johnson  1; siekmann  1   moreover the computational cost of a flexible matching procedure increases with the need to calculate the similarity measure. consequently  we can either try to find algorithms that perform quickly on average or try to find approximate algorithms that produce acceptable answers in an acceptable amount of time. in section 1 we describe how a branch-and-bound algorithm can be used for reducing the average computational time of the actual similarity between two structural descriptions. furthermore  for those applications involving complex descriptions and requiring an answer in relatively short time  we discuss the possibility of introducing a heuristic rule which allows us to find an approximate value of similarity. finally  in section 1  an application of the proposed distance measure to the recognition of office documents in digital form according to their page layout is illustrated. 
1 a distance measure for flexible matching between wff's 
　　let denote the space of all the possible descriptions  or well formed formulas  wff's    complying with the syntax of the representation language and built according to a given vocabulary of attributes and relations. here we are interested in defining a flexible matching function: 
               flex match::  which could be considered as an extension of the canonical  strict  matching predicate: 
match: {false true . 
by extension we mean that: 
 flex match s t  = 1 	match s t =true flex match s t  	 1  otherwise. 
   the function flex match s t  represents a degree of similarity between two descriptions or even the degree of fitness of s on t. the definition of such a function should be based on a theory which is able to quantify the degree of similarity between two descriptions. as probability theory fulfils such requirements  we can assign to each pair of wff fs in the probability of precisely matching the two formulas provided that a change is made in the description t; formally: flex match s t  = p match s t   
   such a definition marks the transition from syntactic to probabilistic matching. consequently  it is possible to define a probabilistic distance measure  between s and t as follows: 
   a more detailed definition of distance measure requires a rather more specific description of the representation language than we have given up to now. in particular  the representation formalism we have chosen is inspired to vl1  michalski  1   the basic component of the vl1 is the selector or relational statement  written as: 
 l = r  
where: 
  l  called referee  is a function symbol with its arguments; 
  r  called reference  is a set of values of the referee's domain; function symbols  called descriptors  are n-adic functions   mapping onto one of three different kinds of domains: nominal  linear and tree-structured. 
selectors can be combined by applying different operators  
such as and i and decision operator  in order to define wff's like: 
　　　　　　　　 d-formula    c-formula  where d-formula is a disjunction of or-atoms  selector conjunctions   while c-formula is a conjunction of selectors. this formalism is adequate to express classification rules in many knowledge-based pattern recognition systems dealing with structural descriptions. 
　　since the main application of theproposed distance measure is noise-affected concept recognition  from now on s will denote the description of a concept and t the observation to be classified. moreover  the specializing isomorphism  sisomorphism   larson  1  rather than the simple isomorphism is used in concept recognition  therefore the match of s and t consists in searching for a substitution a such that: 

　flex match is computed according to the following topdown evaluation scheme: 
i  s is a disjunction of conjuncts:  
or atomn. then the formulation of the flexible matching is given as follows: 
	flex match s t  = max flex match or atomif t  	 1  

   this definition corresponds to the idea that when a concept is polymorphic  i l   we are usually interested in finding the  best  matching between one of its morphisms and the observation t. for instance  if s  length sl =1..1  
 width s1 =1..1  and t   length sl =1   width sl =1   we say that t  nearly  satisfies s simply because it is  near  to the first morphism of s. when correlations occur among the 
	esposito  malerba  and semeraro 	1 
different morphisms expressed by s  the definition above has to be extended so as to take them into account. 
ii  s is a conjunction of selectors: 
thus the computation of the flexible matching is affected by the consistent substitution or of the variables in s. as we are looking for the best matching between s and t  we define: 
	flex match m  = max 	flex 	matchj seit  	 1  
where flex match. denotes the flexible matching function 
with the tie of the substitutions fixed by  
iii  s is a selector: where/ is a 1-adic descriptor and {gl  g1  ...  gm} is a subset of the domain d of/. flex  matchisel. t  is determined by evaluating the degree of similarity between the selector r s  = sel. and the corresponding selector of t   
  which has the same referee as sel . consequently: 
   flex jvlatch  s t  = flex match seli selt   1  and flex matcn selfselt  computes the degree of similarity between the references of self and selt 
   since we are searching for an s-isomorphism  the similarity between the references of sel  and sel is equal to 1 if and only if the reference of selt is more specific than that of selz. the notion of specialization is intended as set inclusion  if the descriptor/ is a nominal or linear one. this interpretation can be easily extended to tree-structured descriptors: each single element in the reference of two selectors is replaced by all the values representing the leaves of the subtree having that particular element as its root. 
   the presence of multiple values in the reference of selt actually means that the value of an attribute is not known exactly  but it ranges over a subset of the attribute domain. this is a form of uncertainty in data  dubois and prade  1  and its management  together with the problem of incomplete descriptions  has been extensively described in lesposito et al.  1a . henceforth  we will assume that m=l  that is we are sure about the value e taken by / in selt. 
   let equal x y  denote the matching predicate defined on any two values x and y of the same domain. since we are looking for the best mapping from {e} into {g   g 1  ...  g m    then the definition of flexible matching depends on the maximum probability of two matching selectors computed over the set of all possible correspondences between the elements of {e} and  g1  g1 ...  gm   that is: 
	flex match self  selt  = max p equal g. e   	 1  

   suchadefinition takes into account the goal of classification by means of event covering  thus when ee {gt  g1 ...  gm  then mf self  selt  = 1 because there is a perfect matcn  otherwise mf self  sel   represents the maximum probability that the value in the reference of sel  equals one of the m values in the reference of sels. 
   the probability of the event equal g1 e  can be defined as the probability that an observation e could be a distortion of g.  that is: 
	 1  
where: 
  x is a random variable assuming values in the domain d of 
/; 
   is a distance defined on the domain itself. 
in other words  the probability that any two values of the 
learning and knowledge acquisition 
domain d match is defined as the probability that a randon variable x defined on d takes a value farther than e from g{ given that g{ is the centroid. in figure 1  a geometrica interpretation of this definition is provided. 
   the definition of 1 must take into account the type of vl 1 descriptor. in particular we propose the discrete metrics fo nominal 	descriptors: 
	1 	ifx-y 
	.	y	 	=	 	1	  
	1 	otherwise 
for linear not numerical descriptors: 
	 1  
where ord x  denotes the ordinal number given to and forlinear numeri
		 1  
   it should be observed that other reasonable choices of 1 an possible; nevertheless the value of p equal g. e   does no change since we compute the probability over distance and no merely geometrical distance. this key point also allows us tc ignore problems with scaling when the similarity is computec over the whole set of features. 
　　of course  the computation of p equal g  e   must tak  into account the probability density function or x. when nc information is available on the probability distribution of x wc assume x to have a uniform probability distribution  that is: 

for the descriptors with a finite domain  here c is the cardinality of d   while 

if the domain d is an interval  a b   here fd denotes the density 
function . 
   having made such assumptions it can be proved that foi nominal descriptors wc have: 
	1 	ifgr* 
	p	 	e	q	u	a 	g	i	 	e	 	 	=	 	1	  
 c-l /c otherwise 
 
p equal g  e  = 1 ifgt=e  1 p y  
	gi 	e 
figure 1. the shaded area represents p equal gi.e  . 
where: 
1 if x 1 
stcp x  = 
1 otherwise 
a proof of formulas  1  and  1  is given in appendix a. 
   for the descriptors with tree-structured domain the computation of p equal g. e   makes use of the previous formulas. each element in the references of sel and selt is replaced by the values representing the leaves of the subtree which has that element as its root. the formulas  1  and  1  are adopted  depending on whether the generalization hierarchy for the descriptor is unordered or ordered  respectively. the only changes to be made both in  1  and  1  consist in replacing c with the number of leaves of the tree-structured domain. 
1 	coping with complexity of matching 
   the computation of the flexible matching when s is a conjunction of selectors requires the evaluation of the maximum conditional probability as in formula  1  as a varies. unfortunately  if p and q  p q  are the number of variables in s and t respectively  the number of possible substitutions a is given by the permutation of p elements taken from a set of q elements  i.e. p q p . consequently  the computation of flex match s t  has a combinatorial cost which should be reduced in some way  particularly when p q p  is very large. 
   in order to prevent an exponential growth of the computational time  two alternative techniques are presented in the following. each of them requires that s and t were connected conjunctions of selectors  for a definition of connected formulas see  larson  1  . 
   firstly  we can make use of a branch-and-bound algorithm which performs quickly on average. the search space can be represented by a tree where: 
  the nodes are variable pairs   v. wk   representing the substitution v.  wk of a variable v. appearing in s with a variable w appearing in t; 
  a branch from a node nl to a node n1 represents the instantiation of a variable of s which has not yet been instantiated in any node along the path from the root to n1. 
   when all the variables in s have been instantiated  the node of the tree representing the last instantiation can by no means branch  i.e. it is a leaf   and the set of the substitutions along the path from the root represents one possible substitution a  see figure 1 . 
each node of the tree can be labeled with a pair of 
figure 1. an example of tree explored by the branch-and-bound algorithm. 
numbers. the first number represents the partial measure of fitness computed only on those selectors of s whose variables have already been instantiated along the path to the node. the second number represents the exact number of selectors in s which gave a contribution to the computation of the partial measure of fitness. if there is a branch from a node nl toa node n1 then the value of the partial measure of fitness in n1 must be less or equal to that associated with n1  due to the definition of flexible matching. in other words  walking along a path from the root towards a leaf of the tree  the partial distance measure associated with each node can only decrease or remain the same. a similar  but increasing  monotonic property is also true for the second value reported in node labels. these considerations suggest how a branch-and-bound algorithm can help in finding the best substitution more quickly. in fact  it is sufficient to consider a function cost composed by the partial distance measure and the opposite of the number of selectors in s which contributed to the computation of the partial distance. minimizing the function cost while the tree is extended allows us to find the best substitution without necessarily exploring all the possible alternatives. when s is a disjunction of or-atoms  the algorithm proceeds exploring alternative consistent instantiations of variables belonging to all the or-atoms  otherwise it could spend too much time trying to evaluate the distance measure concerning a single  bad** oratom. 
   as second al ternative  it is possible to decompose s into two parts: 

so that: 
  s* = sel1 sel1 selr  r k  is a conjunction of selectors such that the referee of sel  i = 1  1  ...  r  contains the maximum non-null number of variables not appearing in the referees of sel| sel1 ..   scii-1; 
  s  is a conjunction of the remaining selectors in s. 
   the constraint of connection upon s ensures that all the distinct variables in s were in s'. as a consequence  the search for a substitution a such that  can be weakened into: 
		 1  
   under such a hypothesis the events flex matchi sel t   i=r+1  r+1 ...  k  become independent since the substitution a that verifies  1  has already bounded the variables in s  as a result  we have: 
	esposito  malerba  and semeraro 	1 
between s' and t sometimes the choice of s' is not unique  in that case a simple preference criterion based on the sum of weights of the selectors in s' may help to select the best alternative. 
1 	application to document recognition 
   the flexible matching algorithm has been employed and tested as a part of plrs  a system for digitized office document recognition based upon the page layout  esposito et al  1 . within the scope of the oda/odif standards  horak  1   a document presents two hierarchical structures: both the layout  or geometric  and the logical structure. the former concerns the internal organization of the document  i.e. the areas containing text and images  and some components are: set of pages  pages  frames and basic blocks. the logical structure associates the content of a document with a hierarchy of logical components  such as articles  summaries  sections  paragraphs  page numbers  logotypes  and so on. furthermore  documents can be grouped into classes according to a specific criterion  such as the kind of processing or the common subject. 
   plrs classifies single page documents using only on the page layout structure  i.e. the invariant geometrical characteristics shared by documents belonging to the same class  due to underlying printing standards or writing style. an extension of plrs exploits the results of the document classification process in order to identify the logical components of a document again using the page layout structure. however  this problem  named document understanding  is still under study and it will not be dealt with in this paper. 
   the rules used for the page layout recognition are produced by means of a process of inductive learning  in which some meaningful examples of document classes  relevant for a specific office  are used to train the system. this allows the  in field  customization of the system  thus avoiding the definition of user-handwritten classification rules for a specific office. 
the form of a recognition rule is: 
　　　　　　　　 condition  ::   decision  where: 
   condition  is a vl1 wff in disjunctive normal form;    decision  refers to a document class. 
   the page layout of a document is automatically described in symbolic form  as a vl1 conjunctive formula  by a document processing system performing the following steps: 
  preprocessing of the digitized document; 
  segmentation into basic blocks through the run length smoothing algorithm  rls a ; 
  layout analysis  that groups together blocks satisfying some predefined requirements  such as closeness  alignment  and so on  into larger blocks  called frames  and produces numerical tables describing each frame; 
  translation of the numerical tables produced by the previous step into vl1 symbolic descriptions. 
the descriptors used in the document description are: 
contain in pos doc block  width block   
height block  to.right blockl  block1   
on top blockl  block1   align blockl  block1  
and a page layout description of a training document is reported in the following: 
 contain n pos x 1  x1 =north  
 contain in pos xl  x1 =northjwest  
 contain in pos x 1  x1 =centre   width x1 =large    learning and knowledge acquisition 

the classification of a new document consists of two steps. 
firstly the condition part of each recognition rule generated by the learning system is matched against the symbolic description of the new document. secondly  the document is assigned to the class specified in the decision part of the matching rule.due to the presence of noise affecting the vl1 descriptions of documents  such as a scribble on a document or sensing problems  it is not possible to use a canonical  strict  matching procedure forclassifying test documents  therefore the proposed flexible matching is adopted. 
   in order to test our approaches to coping with complexity in flexible matching  we organized an experiment in which a set of 1 single page documents  belonging to nine different classes  has been considered. four classes are letters  each class containing generic printed letters of the same company  while other four classes are magazine indexes; the ninth class is a reject class  representing the rest of the world. fifty instances were selected as training examples  leaving the 
remaining 1 documents for the testing process. 
   the results of the application of both branch-and-bound algorithm and the heuristic method in the flexible matching procedure applied to the test documents are reported in table 1 and 1  respectively. in table 1 entries containing a *  mean that the value of the flexible matching  fm  is not known since the search has been interrupted. this happens when the partial similarity measure becomes lower than a fixed threshold  1 in our experiment . in table 1 null  fm  values indicate that a strict matching on s' is not possible  see formula  1  . in both tables  an fm value 1 in the column denoted by rule indicates the presence of a perfect matching between the test document and the rule generated for the i-th class. the results concerning a full comparison between the canonical matching procedure and the flexible matching have been reported in  esposito et al  1b in press . 
   as we could theoretically expect  entries in table 1 are never less than the corresponding ones in table 1  since the branch-and-bound algorithm finds the highest similarity. it should be observed that the classification results do not change at all if the heuristic method is used and the class corresponding to the highest value of similarity is taken as the membership class. the correct class is reported in the first column of table 1. both the tables also present the throughput time  expressed in seconds  for each flexible matching and the total time per document  last column  or per class  last row . we can conclude from a comparison of these time entries that the branch-andbound method needs much more time than the heuristic method  and this is a great limitation for a real-time document handling system. 
1 	conclusions 
　in the paper a definition of a flexible matching is presented: it is based on a probabilistic interpretation of the matching predicate and proves useful to cope both with noisy data and with structural deformations. unfortunately  computing the 
	table 1 	table 1 
	classification results using the branch-and-bound algorithm 	classification results using the heuristic on matching 
similarity of two descriptions is computationally impractical  therefore two distinct methods are adopted to reduce the complexity: firstly  branch-and-bound algorithm  and secondly  a heuristic method. the flexible matching has been applied to the recognition of digitized office documents and the results of both the algorithms are presented. 
a 	proof of formulas  1  and  1  
let us recall the definition  1  given above: 
	 ib  
henceforth  in order to simplify our notation  we will use 
g instead of gi as already said  formula  ib  takes into account both the type of domain which g and e belong to and the probability distribution of the domain values. 
   by assuming that the probability distribution is uniform  and remembering the definition of 1 for nominal domains  we have: 

where c is the number of elements of the domain. for ordinal domains   ib  becomes: 
	esposlto  malerba  and semeraro 	1 

   finally  resubstistuting ord g  and ord e  to g and c  respectively  we have formula  1 . 
