 
this paper presents an improved backjumping algonthm for the constraint satisfaction problem  namely conflictdirected backjumping  cbj . cbj is then modified such that it can detect infeasible values and removes them from the domains of variables once and for all. a similar modification is then made to gaschnig's backjumping routine bj and to haralick and elliott's forward checking routine fc. empirical analysis shows that these modifications tend to result in an improvement in average performance. the existence of a peculiar phenomenon is then shown: the removal of infeasible values may result in a degradation in the performance of intelligent backjumping algorithms  and conversely the addition of infeasible values may lead to an improvement in performance. 
1. introduction 
in the binary constraint satisfaction problem  bcsp  we are given a set of variables and a set of constraints  where each vanable has a discrete and finite domain and each constraint acts between a pair of variables. the problem is to find an assignment of values to variables  from their respective domains  such that the constraints are satisfied  dechter 1  kumar 1  mack worth 1  meseguer 1 . this problem may be represented as a graph g  where v g  is the set of variables and a g  is the set of constraints. there are a number of tree search algonthms that address this problem  most notably chronological backtracking  bt   bitner and reingold 1  golomb and baumert 1   backmarking  bm   gaschnig 1 and 1   backjumping  bj   gaschnig 1   and forward checking  fc   haralick and elliott 1 . all these algorithms perform a  depth first  search  and the most primitive of these is bt. when bt instantiates a vanable with a value  the current vanable vt  it checks backwards against variables that have already been assigned values  the past vanables . if no value can be found for the current variable that is consistent with all of the past vanables  bt steps back to the previous vanable  and attempt a new instantiation for that vanable  and so on . it may be the case that the value assigned to  was not in conflict with vi  but some other variable higher up in the search tree  vh  precluded some value from the domain of 
constraint satisfaction problems 
v . if the search process could jump back directly to vh and find a new value for vh  the search process might then be able to move forward beyond vi. 
     gaschnig's backjumping routine  bj  attempts to do this. given the cunent vanable v   bj records the  deepest  variable with which vi checked against. if all values in the domain of vi failed consistency checks with past vanables  bj then jumps back to the deepest variable that vi checked against  namely vh   and if vh is relnstantiated with a new value we may then find a value for vi. alternatively  if bj successfully instantiates the cunent vanable vi  then the deepest past vanable that vi checked against will be therefore  if later on in the search process bj jumps back from  where 
i   and there are no more values remaining to be tried for vh   bj will then  step  back to  therefore  we get this mix of  jumping  and  stepping  back. this behaviour can be rectified such that we can continue to 
jump over constraint violations  and we do this by recording for each vanable vi the set of vanables that were in conflict with some instantiation of vi.. we call this modified routine conflict-directed backjumping  cbj . a further modification is then made such that cbj can detect infeasible values and remove them once and for all. this modified version is called cbj-dkc  conflict-directed backjumping with directed k-consistency . one would expect that in the worst case cbj-dkc would perform no worse than cbj. we show that this is not so. the removal of an infeasible value may result in a reduction in  thrashing   mackworth 1   but this may result in a reduced opportunity for jumping  and the reduction in jumping may outweigh the saving in reduced thrashing. 
¡¡¡¡¡¡the algonthms are described in a pseudocode modeled on pascal and common lisp. a fuller description of this language is given in nadel  and in prosser . the following variables are assumed to have been globally declared  n is the number of variables in the constraint satisfaction problem  v is an array of values  such that is the value assigned to the vanable vh domain is an array of sequences  such that domain i   is the domain of the variable v . 
note that domain = nil. current-domain is an anay of sequences  where cunent-domainfi   is the sequence of values in domain i  that have not yet been 

shown to be inconsistent with respect to the ongoing search process. current-domain i  is initialised to be equal to domain i . when v i  is to be instantiated a value is selected from current-domain i   and if that value is found to be inconsistent with respect to the current search state  then that value is removed from current-domainfi . when backtracking takes place from v i  to v h   where h   i  cument-domainlj  is reset to domain j  for all j  where h   j   i. note that current-domain = nil. c is an n x n 

and v j . therefore we have an extensional representation of constraints  rather than intensional  as a set of compatible pairs . the function check i  j  delivers a result of true if c i j  = nil  otherwise it delivers the result of applying the relation c i j  between the instantiations of v i  and v j   and is counted as a consistency check . 
¡¡¡¡¡¡generally v i  will be considered to be the current variable  v h  will be a past variable  and v j  a future variable  h   1   j . it is assumed that all arguments are passed by reference and that the first occurrence of a variable corresponds to an implicit declaration. the algorithms are described in terms of a pair of mutually recursive functions  similar to the style of dechter and pearl   and dechter  . that is  we have a forward move  such as bj-label  and a backward move  such as bjunlabel. in section 1  the number of  nodes visited  by the search process x is taken to be the number of calls to the forward move x-label. the algorithms address the binary constraint satisfaction search problem  nudel 1 . that is  they find the first solution. 
1. conflict-directed backjumping  cbj  
where bj steps back from v h  after jumping back from v i   the conflict-directed backjurnper  cbj  continues to jump across conflicts which involve both v h  and v i . cbj achieves this by recording the set of past variables that failed consistency checks with the current variable  and we refer to this as a  conflict set  as in  dechter 
1  . if no consistent instantiation can be found for v i   cbj then jumps back to the deepest vanable  v h   that conflicted with v i . if on jumping back to v h  cbj discovers that there are no more values to be tried in current-domain h  cbj then jumps back to v g   where v g  is the deepest vanable that was in conflict with either v i  or v h . 
¡¡¡¡¡¡cbj maintains a conflict set conf-set i  for each variable  where the array conf-set is declared globally. initially each element of conf-set i  is set to be 1 . when a consistency check fails between v i  and v h   h is added to the set conf-set i . therefore  conf-set i  is the subset of the past variables in conflict with v i . if there are no remaining values to be tned in current-domain i   cbj 
jumps back to the deepest vanable v h   where h € confset i   that is h  -- max-list conf-set i    where the function max-list delivers the largest integer in a set of integers . 
when jumping back from v i  to v h  the information in conf-set i  is earned upwards to v h . the array element conf-set h  becomes conf-set h  u conf-set i  - h  the set of variables in conflict with v h  or v i . therefore  when further backtracking takes place from v h   cbj jumps back to v g   where v g  is the deepest variable in conflict with either v h  or v i . 

in line 1 above  the call pushnew h conf-set i   adds h to the set conf-set i  if h is not already a member of confset i . it is assumed that the loop variable h is available to the statement in line 1  and that h is the value that caused the call to check i h  to deliver false. 

cbj is then realised as cbj-label l . if we move line 1 in cbj-label to line 1 the array element conf-set i  is updated unconditionally  and cbj behaves as bj. 
     the reasoning behind cbj might be better understood when viewed from the perspective of de kleer's atms . we can consider the past vanables as a set of assumptions that are in  currently believed   and the 
	prosser 	1 

array element conf-set i  as a conjunction of assumptions  and therefore an environment. let s be the set of indices of the past variables ie. s =  1 1  ... i-1    and disallowed i  = domain i  - cunent-domain i   the set of values in domainfi  that have been discovered to be inconsistent with the current search state. we then have the assumed node where disallowed i  is the datum  and conf-set i  is the justification for datum  and consequently the single environment within the label. if  we then believe that the current search state cannot be extended by any instantiation of v i  from the set disallowedfi . conversely  if conf-setfi  is not subsumed by s we can no longer believe disallowed i  and we must reset currentdomain i  to be domain i . when current-domainfi  is empty  ie. disallowed i  = domain i   we need to force out some assumption in conf-set i   and we choose the most recent assumption  namely max-list conf-set i  . this is done implicitly when cbj backtracks from v i  to v h . 
¡¡¡¡¡¡cbj is conservative when it jumps back from v i  to vfh . as noted above we can believe disallowed i  whenever conf-set i  is subsumed by s. however  when cbj jumps from v i   over vfj   to vfh  we automatically reset current-domain j . it may be the case that max-list confsetfj     h and we can continue to believe disallowed j   and thus prune the search space more efficiently. however  in order to do this we would have to examine all future conflict sets whenever backjumping takes place. cbj would then look even more like an atms. in fact  such an algorithm is described by rosiers and bruynooghe  and by prosser . 
¡¡¡¡¡¡cbj has many features in common with dechter's graph-based backjumping algorithm gbj  dechter 1 . when gbj reaches a dead end on v i  it jumps back to the deepest variable amongst those connected to v i  in the constraint graph  namely vfh   and if there are no values remaining to be tried for v h  gbj jumps back to v g  where v g  is the deepest variable connected to either vfi  or vfh . therefore we might say that when jumping back bj is directed by consistency checks that have been performed  cbj is directed by conflicts  and gbj is directed by the topology of the constraint graph. 
1. directed consistency 
cbj can be modified such that it removes values from the domains of variables once and for all  when it can be deduced that these values are infeasible. we may add the following conditional to procedure cbj-unlabel. 

the above modification gives us cbj-dkc  where dkc stands for  directed k-consistency   dechter and pearl 1   and is similar to nth order learning fdechter 1  . the effect of this modification can be described as follows. let us assume that cbj has successfully 
constraint satisfaction problems 
instantiated v i-l  and that cbj moves forwards to v i . at that point conf-set i  = {1}  and current-domainfi  = domainfi . further assume that the call to cbj-label i  fails to find any instantiation of vfi  that is consistent with the past variables. if |conf-set i | = 1 then vfi  is in conflict with the instantiation of vfh  and the pseudo variable v. we can then deduce that vfh  is  are-inconsistent  with respect to domainfi . that is  an arc consistency algorithm  mackworth 1  deville and van hentenryck 1  would have removed the value vfh  from domain h . 
¡¡¡¡¡¡assume that it is not the first time that we have visited vfi   that we successfully instantiate vfi   and that all values in domainfi  are consistent with respect to the past variables. therefore conf-setfi  = {1}. assume that we then attempt to instantiate some future variable v j  and all values in domainfj  conflict with either vfh  or vfi . we then have conf-setfj  = {1 i h}  ie. for all values xj in domainfj    is inconsistent with vfh  or vfi . cbj will then jump back to vfi  and instantiate vfi  with the next value in current-domainfi . assume that this process continues until we have exhausted currentdomainfi . we then have conf-setfi  = {o h}  ie. for all values xj in domainfj    is inconsistent with vfh  or   for all values xi  in domain i . therefore we can remove the value vfh  from domainfh . 
     we can adopt the same approach with respect to fc and to bj. in fc we instantiate vfi  with the value k and 
check forwards against the future variables. assume that vfi  checks against vfj  and this results in a  domain wipe out   nadel 1  for vfj . if no other variable checks against vfj  we can then remove k from domainfi  once and for all. this corresponds to  directed arc consistency   and corresponds to 1st order learning fdechter 1    and we can realise this by maintaining a count of the number of variables forward checking against vfj   as in  prosser 1  . we will call this algorithm fc-d1c. 
¡¡¡¡¡¡similarly in backjumping  if no instantiation for v i  can be found  and all consistency checks from vfi  failed against the single instantiation  we might then remove k from domainfh . we can do this by maintaining a flag for each variable  call it instantiated i   which is initialised to false  and is set to true when bj-label finds an instantiation for vfi  which is consistent with the past variables. if we jump from vfi  to vfh   when length confset h   = 1 and instantiatedfi  = false  we can remove the value vfh  from domainfh   and when we jump from vfi  to vfh  we reset instantiated j  to false for all 
this gives us the algorithm bj-d1c. if we perform the following edits to cbj-label and cbj-unlabel we get bjd1c: 
 a  in cbj-label move line 1 to line 1 
 b  in cbj-label replace line 1 with the following segment 

	1 	end 
 c  	in cbj-unlabel add the following lines 

more generally  since fc and bj only reason over failures that occur between pairs of variables we can only detect directed arc inconsistencies  1st order learning . on the other hand  since cbj reasons over failures within a set of variables  it can detect directed k-inconsistencies  nth order learning . 
1. experimental evaluation 
the following algorithms were compared against each other: bt  naive/chronological backtracking   bj  gaschnig's backjumping routine   gbj  dechter's graphbased backjumping routine   cbj  described here   bm  gaschnig's backmarking routine   fc  haralick and elliott's forward checking routine   bj-d1c  cbj-dkc  and fc-d1c  again  described here . 
¡¡¡¡¡¡the algorithms were applied to 1 instances of the zebra problem  described in  dechter 1 and smith 1 . that is  1 different instantiation orders of the zebra were created  and each algorithm was applied to those problems in turn. table 1 shows the average number of consistency checks performed by an algorithm  the standard deviation  the minimum number of consistency checks performed  and the maximum number performed over the 1 problems. table 1 shows the same information but with respect to nodes visited. 

table 1. consistency checks 

table 1. nodes visited 
if we take consistency checks performed as a measure of search effort we may rank the algorithms as follows: fcd1c  cbj-dkc  fc  cbj  bj-d1c  bm  bj  gbj  bt. with respect to nodes visited the algorithms are ranked: fc-d1c  fc  cbj-dkc  cbj  bj-d1c  bj  gbj   bm and bt . 
¡¡¡¡¡¡the algorithms were then applied again to 1 instances of the zebra problem  and the cpu time was measured. table 1 below shows the average cpu time used  on a sparcstation ipc  with 1 mega-bytes of memory  using sun common lisp 1  by the algorithms for solving an instance of the problem  and the average number of consistency checks performed in a second. 

table 1. cpu time 
although bt performed on average 1 times as many consistency checks as bm  table 1  bt took only 1% longer to run than bm  table 1 . this is due to the poor  checking rate  of bm  and this is explained more fully in  prosser 1 and 1   cbj has a higher checking rate than bj. therefore  not only does cbj perform less checks than bj  it performs these checks with less overheads  these tests used the more efficient version of bj described in  prosser 1   rather than the derived version here . this is because cbj updates conf-set i  conditionally  and bj updates max-check i  unconditionally. generally  there is an insignificant overhead associated with the modifications performed to bj  to give us bjd1c   cbj  giving cbj-dkc  and fc  to fc-d1c . 
these modifications resulted in a reduction in consistency checks performed  nodes visited  and a reduction in run time. therefore  with respect to run time the algorithms may be ranked: fc-d1c  cbj-dkc  fc  cbj  bj-d1c  bj  bm. with the exception of bm  this ranking agrees with those above  and in fact there is little to choose between cbj-dkc and fc-d1c. 
1. the bridge  and the long jump  
it was expected that cbj-dkc would always perform at least as well as cbj. however  on analysing the experimental results it was discovered that out of the 1 problem instances there were 1 cases where cbj performed better than cbj-dkc. this was a surprise. one of these problems was then examined in detail. this was the problem with the instantiation order:  water  tea  coffee  japanese  kools  blue  ukranian  chesterfield  old-gold  
zebra  horse  fox  orange-juice  yellow  snails  red  
	prosser 	1 
green  englishman  lucky  dog  spaniard  parliament  
ivory  norwegian  milk . during the search process cbjdkc discovers  amongst other infeasibilities  that there is no solution to the problem when spaniard is assigned the value 1  therefore  the value 1 is removed 
from domain. in some latter stage in the search process v again becomes the current variable and cbjdkc considers the instantiation  at the same point in the search space cbj considers the instantiation 
 the two search trees now differ significantly  and in cbj's search tree it is possible to jump back to a conflicting variable higher up in the search tree than cbj-dkc. 
¡¡¡¡¡¡more generally  cbj-dkc may remove an infeasible value k from the domain of a variable v i . at some later stage in the search process cbj may move forwards from v i-l  to v i   and be unable to re-instantiate v i  with the value k. cbj-dkc may then jump back to v h . at the same point in the search tree cbj is allowed to make the instantiation  and move forwards to v|j . cbj may then jump back from v j  to v g   where g   h. therefore  the value k has acted as a bridge that allows the search process to move from one area of the search space to another  where it can then make a  long jump  back to a conflicting variable. 
¡¡¡¡¡¡to confirm this analysis  the value 1 was removed from domain  the problem was reset  and cbj and cbj-dkc were re-run. it was expected that cbj would be unable to  cross the bridge  and unable to make  a long jump . with the bridge in place cbj performed 1 checks  and visited 1 nodes  and cbj-dkc performed 1 checks  and visited 1 nodes . with the bridge removed cbj performed 1 checks  and visited 1 nodes  cbj-dkc performed 1 checks and visited 1 nodes . this implies that the removal of an infeasible value from the domain of a variable may result in a degradation in the performance of an algorithm that jumps back to the cause of a conflict  such as bj  cbj  or any of the hybrid derived from these algorithms  prosser 1 and 1  . 
1. conclusion 
a new algorithm has been presented  cbj. it has been shown that bj can be derived from cbj  and that bj might be considered to be a degenerate form of cbj. cbj was then modified  the addition of a single conditional expression  such that infeasible values can be detected and removed once and for all. a similar technique was applied to backjumping and forward checking. empirical evidence suggests that these modifications result in an improvement in the performance of these algorithms on average 
¡¡¡¡¡¡the removal of infeasible values has revealed a disturbing phenomenon  namely that this can lead to a degradation in the performance of a  conflict directed  backjumping algorithm. it has  almost  become an article of faith that if we remove infeasible values  mackworth 1  deville and van hentenryck 1  freuder 1  or 
constraint satisfaction problems 
redundant values  benson and freuder 1  freuder 1  from the domains of variables  the subsequent search algonthm will be presented with an easier task. we have been lead to believe this because  the subsequent search algonthm  is generally assumed to be a chronological backtracker  bt  bm  fc   or the effect of removing a bndge has been masked by a reduction in thrashing. we should now assume that increased consistency  or the removal of redundancies  can only guarantee a reduction in search effort if that search is unintelligent  such as a chronological backtracker . conversely  we should expect that we can improve the performance of an intelligent backjumping algorithm by adding an infeasible value to the domain of a variable. 
