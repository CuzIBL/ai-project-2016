 
       in this short article  we report new results on our work on the problem of using passive vision and more precisely stereo vision to build up consistent 1d geometric descriptions of the environment of a mobile robot 
i-introduction 
       the robot that we have built consists of a four-wheeled platform with two driving wheels operated by electrical motors. a set of three ccd cameras provides black and white images of the environment the cameras are located at the vertexes of a vertical roughly equilateral triangle. images are transmitted via a vhf link to a workstation where they are stored and made available through ethernet to a number of processors. to the user  the vehicle appears as a standard peripheral and can be accessed as such from any terminal on the net it is therefore a very convenient testbed for studying a number of problems in vision. 
       one such problem is the following. suppose we let our vehicle wander around in a building using its ultrasound sensors to avoid obstacles  odometry to roughly estimate its motion and its three cameras to compute 1d descriptions of its environment one question then is  can we hope to combine coherently the various sources of information  and especially the visual information obtained at different times and from different places  and build up an accurate geometric 1d representation of the building even if each individual measurement is itself fairly inaccurate 1 we call this problem the visual fusion problem. 
       there are two deep issues which are associated with this question. first is the issue of the type of geometric representation that is used by the system. representations which are mathematically equivalent may behave quite differently on a real problem due to the unavoidable presence of noise and errors. this brings up the second issue which is the question of how do we represent and manipulate uncertainty. 
       in the next sections we propose a solution to these issues and present some results. 
ll - what is the problem that we are trying to sol ve   
       each triplet of images provided by the three cameras is analysed by a stereo program described in  1 . this program outputs 1d line segments described in a coordinate system attached to the three cameras. each line segment has a geometric description which we elaborate on in the next section and an uncertainty which we explain in section iv. this uncertainty is directly related to the limited resolution and the geometry of the three cameras. 
       to relate the various coordinate systems corresponding to the different viewpoints we estimate the rigid motions between them. this is done in two steps. first a rough estimate is obtained by combining the odometry with the rotation of the cameras. second  a better estimate is obtained by combining the two 1d representations provided by the stereo program in the two positions of the vehicle. this is done by matching 1d segments which are present in the two views and is described in details in  1 . the result is an estimate of the rotation matrix and translation vector between the coordinate systems attached to the cameras in their respective positions  together with some measure of their uncertainty  to be explained in section iv . 
       this having been completed  the current representation of the 1: this work is supported by the esprit project p1. 
1 	perception 
environment is a number of uncertain geometric primitives  here 1d line segments  attached to coordinate frames related by uncertain rigid motions. the more we move the robot and measure  the move we increase the number of line segments until we run out of memory. this is clearly unsatisfactory and we must provide the system means of  forgetting intelligently . by this we mean the following. let us consider a physical line segment s like a part of the frame of a window  or the edge of a desk. this line segment is very likely to have been detected in different positions 
1  1  ...   n of the mobile robot and is therefore present as segment sj in position 1  segment s1 in position 1  ...   segment sn in position n. since we can relate by rigid motions position 1  to positions 1  1 n  by applying the right transformation  the physical segment s is represented by n segments sj  s'1 ...   s'n in the coordinate system attached to position 
1. 
       we would like our system to have the capability of automatically deciding that s1  s1 ...   and s'n are the same segment s and fusing them into one segment s   a combination of sj  s1  ...   s'n. this has two advantages. first  s being a combination of n sources of information should be at least as accurate as each of its instanciations  therefore accuracy in the description is now able to increase  and second since the system has recognized that sj  s1 ...  and sn are the same segment s   it can forget diem and remember only s  it is now able to  forget intelligently . 
       in order to achieve this goal  two questions must be answered. how do we represent and manipulate geometry and uncertainty   
hi - representing lines and line segments 
       the obvious way to represent a line is by choosing two points on it  or one point and a direction. the first representation has dimension 1  the six coordinates of the two points   the second representation has dimension 1  the three coordinates of the point and the two coordinates defining die direction as  for example a unit vector on the gaussian sphere . in fact  the minimal dimension of the representation of a line is four. this can be seen by choosing  in the second representation  the point such mat the segment from the origin to the point is perpendicular to the line. the line is then located in the plane normal to that segment and can be determined by its orientation with respect to a known direction in that plane  i.e. by one parameter. 
       a line segment is six-dimensional  being represented either by its two endpoints or by one endpoint  1 parameters   the line direction  1 parameters   and its lengm  1 parameter . 
       for our problem  even though we actually manipulate line segments because this is what is provided by our stereo algorithms  what we in fact would like to fuse are lines. the reason for this is the fact mat segmentation errors  variations of illumination  inadequate edge detectors  and variations of viewpoints result in the same physical segments being instantiated as a variety of subsegments. since we do not know the real segment we must deal with its supporting line. 
       a convenient minimal  i.e. four-dimensional  representation of 1d lines is the  a  b  p  q  representation where the line is defined by the two planes: 
	x   az + p 	y - bz + q 	 1  
       this representation is easily computed using the coordinates of two points on the line. 
       the effect of a rigid motion defined by a rotation matrix r and a translation vector t can be readily assessed  i.e. if we route and translate a 
       

	ayache and faugeras 	1 
       
over the endpoint fusion. this last point is due the arbitrary segment breaking  which is not taken into account in the endpoint covariances  whereas it does not affect the line representations. 
       actually the same experiment conducted without line breaking yielded a similar error rate of about 1 % for the two kalman approaches  while the least-squares technique was still yielding a 1.s % mxerror. 
       the second experiment is conducted with real data. figures 1 to 1 shows a calibration grid observed by our mobile robot from 1 different positions. actually the robot has 1 eyes  cameras  and builds in each position a set of 1d segments. covariance matrices are computed on the segments endpoints assuming gaussian noise in the images  see  . using those segments which are common to a pair of successive views  the system computes the 1d motion between each such pair  and then places all the segments into a single reference frame. figure 1 shows a vertical view 
of the grid segments in such a frame. 
       fusing is then achieved between endpoints using the formalism described in iv. l. allowing a reduction of the spread of the vertical projection of the segments akmg 1 ideal lines  vertical segments lie slightly in front of horizontal ones . this spread agrees very well with the computed a priori and a posteriori computed covariance matrices  not shown in these figures . 
vi - discussion amd conclusions 
       we have expanded in this paper on some key and simple motions which we have presented elsewhere  1 . 
first we have obtained more evidence of the necessity to combine geometry and uncertainty in visual representations. second we have confirmed that the gaussian assumption which allows us to use the powerful tool of extended kalman filtering is quite adequate for both synthetic and real data obtained by a mobile robot operating in a human made environment third  we have shown that these simple ideas provide an efficient mechanism for building up incrementally a coherent 1d representation of this environment while allowing the system to forget intelligently redundant information and  at the same time  improving the accuracy of its current estimation. 
