 
the idea of ordering plays a basic role in commonsense reasoning for addressing three interrelated tasks: inconsistency handling  belief revision and plausible inference. we study the behavior of non-monotonic inferences induced by various methods for priority-based handling of inconsistent sets of classical formulas. one of them is based on a lexicographic ordering of maximal consistent subsets  and refines brewka's preferred sub-theories. this new approach leads to a non-monotonic inference which satisfies the  rationality  property while solving the problem of blocking of property inheritance. it differs from and improves previous equivalent approaches such as gardenfors and makinson's expectation-based inference  pearl's system z and possibilistic logic. 
1 	introduction 
it is noticeable  although very natural  that the notion of ordering  between logical formulas  between models  between subsets of formulas  has emerged from studies in nonmonotonic reasoning and belief revision as playing a crucial role. in both cases  the existence of such orderings is a direct consequence of a set of axioms which plausible inference  or revision processes  must obey. makinson and gardenfors  have pointed out that some nonmonotonic inference systems can be expressed in terms of the appropriate revision of a related set of propositional sentences  both inference and revision being guided by the ordering. namely  given a set of sentences s and a revision procedure  given a formula a to be added to s  inferring  from a in the context defined by s can be achieved by checking whether is a consequence of the result of revising s by a; the revision process takes care of the case when is inconsistent. the ordering underlying these operations helps altogether coping with inconsistency  solving a revision problem  and guiding a nonmonotonic inference. in this paper we shall assume that a set of formulas is equipped with a complete preordering structure  or priority ranking  which  contrarily to gardenfors'  view  is not related to the semantical entailment ordering between sentences. this kind of ordering has been considered by brewka   geffner 
  nebel   cayrol  in the recent past. especially nebel has used it to define syntax-based revision procedures  such that two semantically equivalent knowledge bases may  upon the arrival of some input inconsistent with them  result in non-semantically equivalent revisions. a first idea 
1 	knowledge representation 
to revise an inconsistent knowledge base 1 is to select one of its maximal consistent subbases; another natural idea is to keep as many sentences as possible  i.e. consider a consistent subbase of s of maximum cardinality. the latter option helps reducing the number of revision candidates. the presence of an ordering on s leads to refine both approaches. besides  one does not need to select a single preferred subbase when defining a non-trivial notion of inference from an inconsistent knowledge base. the task of this paper is precisely to study inferences of the form  s entails b if can be classically inferred in all the preferred consistent subbases of s . here we shall focus on two meanings of  preferred : one  already considered by brewka and geffner  that combines priorities and maximal consistent subbases; another  which has not been studied in the literature  combines priorities and consistent subbases of maximum cardinality. borrowing from gardenfors the image that nonmonotonic reasoning and belief revision are two sides of the same coin  we pursue nebel's work on syntax-based revision  by studying the other side of that particular coin; namely we study the properties of inference based on the two kinds of preferred subsets of formulas  and give algorithms for computing these inferences. inconsistency-tolerant inferences are interesting since they can overcome some limitations of the kind of nonmonotonic inference that is the exact counterpart of gardenfors' revision theory  see  . this kind of inference is also at work in possibilistic logic    and in system z . this approach suffers from what we call the  drowning effect : all formulas which are not sufficiently entrenched are inhibited; this is an attenuated form of the fact that in classical logic anything follows from an inconsistent set of sentences; a particular case of this effect is the property inheritance blocking   . 
1 	nonmonotonic inference relations generated by a flat belief base 


	benferhat et al. 	1 

1 	knowledge representation 

	benferhat et al. 	1 


1 	knowledge representation 


1 	applications and conclusion 
in this paper we started by noticing the limitations of several approaches to non-monotonic reasoning such as expectation-based inferences  possibilistic logic and system z  which cope with inconsistency at the expense of taking away too many pieces of knowledge  the drowning effect . we then proposed two ways of coping with this problem: the first one  inferring a conclusion iff it is deducible from all inclusion-based preferred subbases  avoids it but fails to satisfy weak rational monotony. the second one  less cautious  inferring a conclusion iff it is deducible from all lex-preferred subbases  still avoids the drowning effect and enables us to recover rational monotony. 
¡¡there are many situations where all this can be applied  of which we mention some examples. first in default reasoning  geffner and pearl  have already used inclusionbased prioritized inference to mend system z. here we have shown that the lexicographically-preferred subbases led to another solution recovering property inheritance. it would be interesting to compare this solution to the approach based on maximum entropy . a second potential application is model-based diagnosis  in this spirit  see   where s describes the functioning of the system to diagnose  the levels reflecting the certainty of the rules  and the reliability of the components ; a corresponds to the observed situation; then each of the maximal consistent subbases correspond to a consistency-based diagnosis  where the absent formulas correspond to faulty components . in the non-gradual case  subbases of maximum cardinality correspond to a minimum number of faulty components. lexinferences are a generalisation of this principle  and are thus very natural in this context. other potential applications are consistency maintenance in temporal data bases  where recent informations are preferred to older ones   prioritized constraint satisfaction problems  where overconstrained problems are solved by taking priorities into account   or to minimisation of surprizes in a logic of time and action. 
acknowledgements: this work has been partially supported by the european esprit basic research action n¡ã 1 entitled  defeasible reasoning and uncertainty management systems  drums-1  . thanks also to 
thomas schiex for checking the algorithm. 
references 
1 c.baral  s.kraus  j.minker  v.s.subrahmanian combining knowledge bases consisting in first-order theories. computational intelligence 1-1. 
1 s.benferhat  d.dubois  h.prade representing default rules in possibilistic logic. kr'1  1. 
1 c.boutilier what is a default priority  proc. 1th canadian conf. on ai  1  1. 
1 g.brewka preferred subtheories: an extended logical framework for default reasoning. ijcar1  1. 
1 c.cayrol un modele logique general pour le raisonnement rdvisable. revue d'intell. artif. 1-1. 
1 c.cayrol  v.royer  c.saurel management of p