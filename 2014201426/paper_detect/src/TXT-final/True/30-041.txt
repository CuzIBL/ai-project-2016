 
the robocup  robot world-cup soccer  effort  initiated to stimulate research in multi-agents and robotics  has blossomed into a significant effort of international proportions. robocup is simultaneously a fundamental research effort and a set of competitions for testing research ideas. at ijcai'1  a broad research challenge was issued for the robocup synthetic agents  covering areas of multi-agent learning  teamwork and agent modeling. this paper outlines our attack on the entire breadth of the robocup research challenge  on all of its categories  in the form of two fielded  contrasting robocup teams  and two off-line soccer analysis agents. we compare the teams and the agents to generalize the lessons learned in learning  teamwork and agent modeling. 
1 	introduction 
increasingly  multi-agent systems are being designed for a variety of complex  dynamic domains. to stimulate and pursue research towards such multi-agent systems  the robocup initiative has proposed simulation and robotic soccer as a common  unified domain for multi-agent research! kitano et at.  1 . robocup has now blossomed into a significant effort of international proportions. 
　at ijcai1  a broad research challenge was issued for the robocup synthetic agents!kitano al  1 . this paper responds to this challenge  in the form of research lessons drawn from several systems we have constructed for robocup. in particular  we fielded the isis1 and isis1 teams  which won third place and fourth place at robocup1 and robocup1 respectively  out of 1 to 1 participating teams . we have also constructed two experts  isaac and teamore  for off-line review of robocup. our response draws from these multiple systems for two reasons. first  the robocup challenge covers a broad spectrum of multi-agent research  and requires teams and off-line experts to be built. indeed  it proposes three separate challenge areas  learning  teamwork and agent modeling. second  these challenge areas often do not have just one right answer  rather  they point to tradeoffs  which we explore via multiple systems. 
1 	challenge papers 
　our challenge response also attempts to extract general lessons from robocup. indeed  despite the robocup aim to stimulate general multi-agent research  few robocup researchers have extracted domain-independent research lessons  there are a few notable exceptionststone and veloso  1b  . this paper attempts to remedy this situation. 
1 background: domain and agents 
the robocup simulation league uses a complex  dynamic  noisy soccer simulation  called the soccerserver  which simulates the players'  1  bodies  the ball and the soccer field with goals and flags. software agents  1 agents per team  provide the  brains  for the simulated bodies. visual and audio information as  sensed  by the player's body are sent to the player agent   brain    which can then send action commands to control the simulated body  e.g.  kick  dash  turn  say  etc. . the server constrains an agent's actions  one action per 1ms  and sensory updates  one perceptual update every 1ms . the players also have limited stamina. 
　the software agents we constructed to control the player bodies are based on a two-tier architecture. the lower-level  developed in c  processes input received from the simulator  and together with recommendations of an intercept microplan and possible kicking directions  sends the information up to the higher-level. the higher-level is implemented in the soar integrated architecture newell  1 . soar uses the information it receives to reach a decision about the next action and communicates its decision to the lower-level  which then forwards the relevant action to the simulator. soar's operation involves dynamically executing an operator  reactive plan  hierarchy. the operator hierarchy shown in figure 1 illustrates a portion of the operator hierarchy for isis player-agents. only one path through this hierarchy is typically active at a time in a player agent. the hierarchy has two types of operators. team operators constitute activities that the agent takes on as part of a team or subteam  shown in   e.g.   play  . in contrast  the  normal  individual operators are ones that players execute as individuals  e.g.  intercept . the implication of this distinction will be clarified later. 
1 	response to the learning challenge 
isis teams have addressed the problems of off-line skill learning and on-line adversarial learning  with results used in actual 


figure 1: operator hierarchy for player-agents. 
competitions. different learning algorithms are integrated in isis via a divide-and-conquer approach  i.e.  different modules  skills  within individual agents are learned separately. 
1 offline skill learning 
shooting a ball to score a goal is clearly one of the critical skills in soccer. yet  our initial  heuristic  hand-coded approaches  e.g.  shoot to a corner of the goal  failed  because  i  small variations in shooter-position sometimes had dramatic effects on the best shooting direction and  ii  large number of heuristic rules were needed. 
　we addressed these problems via automated  off-line learning of the shooting rules. a human specialist created a set of 1 shooting situations  each of them labeled with an optimal shooting direction: up  down  and center  that were used as training examples forc1 quinlan  1 . each such shooting scenario was used as a training case described by 1 attributes: the recommended kicking direction  the shooter's facing direction  and the shooter's angles to the visible play-
ers  flags  lines  ball  and goal. the system was trained on 1 randomly chosen examples  and the other 1 examples were used for testing. we repeated this procedure 1 times  and the average accuracy of the rules on the testing sets was 1%. even though the predictive power appears low  the kicking rules were quite efficient in practice. this is because learned-rules covered far more difficult shots than were actually used in practice. 
　while the c1 learned rules dramatically improved shooting skills  in the competitions  the rules sometimes appeared to take unnecessarily risky shots on the goal. this occurred because offline learning assumed the worst about the opponents' level of play  while in practice  weaker teams provided easier opportunities that did not justify such risks. thus  while one key lesson learned here is that a divide-and-conquer learning technique may be promising for agent design  another key lesson is that off-line learning in dynamic multi-agent contexts must be sensitive to the varying capabilities of other agents. 
1 	online adversarial learning 
a key skill in robocup where adaptation to the opponent is critical is that of intercepting the ball. in particular  an opponent may kick/pass/run harder than normal  thereby requiring a player to adapt by running harder  modifying their path or forgoing interception. to enable players to adapt their intercept online to adversaries  isis exploits reinforcement learning. 
　one key difficulty in applying reinforcement learning however is rapid adaptation - in the course of a game  there are not many opportunities to intercept the ball. to address this concern  our approach employs intermediate reinforcement  rather than waiting for the end of the intercept. a player intercepts the ball by stringing together a collection of micro-plans of a turn followed by one or two dashes. for every step in a micro-plan  isis1 has an expectation as to what any new information from the server should inform it as to the ball's location. failure to meet that expectation results in a learning opportunity. to allow transfer to similar states  the input conditions are clustered. repeated failures lead to changes in the plan assigned to an input condition. in particular  the turn increment specific to that input condition is adjusted either up or down upon repeated failure. typically  the actual turn is calculated from the turn increment in the following fashion: 

　experiments: in accordance with the ijcai challenge  experiments were performed against publicly available teams  specifically cmunited1  team of stone and veloso of carnegie mellon  1th at robocup'1  andhill1  team of t andou of ntt labs  1nd at robocup'1 . in each experiment  each player started with a default value of 1 for their turn increment across all input conditions. the online learning in these games results in turn increment values that range from +1 down to - 1   across input conditions. while these may appear small numbers  because of the multiplicative factors  and since the intercept plan is invoked repeatedly  even a small change is overall very significant. 
　the results show some surprising differences in what is learned. for instance  the same player may learn very different turn increments against different teams. figure 1 compares the mean results for player 1  a forward  in games against cmunited1 with games against andhill1. the mean for all players is also shown. the x-axis plots the clock ticks  continued until 1  and the y-axis plots the turn increment. this data is for the input condition of balls moving across the player's field of vision  a middling-to-close distance away. against andhill1  the player is learning a turn increment similar to the mean across all players for this input condition. however  against cmunited1  the player is learning a considerably larger increment  difference in means is significant using a welch two-sided t-test  p-value=.1 . figure 1 shows that different players against the same team do learn different increments. it plots mean turn-increments for player 1 and player 1 for the the same input condition as above  against cmunited1. the difference in the means is significant  using a welch two-sided t-test  p-value = 1e-
1  
　lessons learned: player 1 distinctly tailors its intercept to its role and particular opponents. this occurs because cmunited1's defenders often clear the ball with a strong sideways kick  which player 1 continuously faces. player 1 's adaptation not only illustrates the benefits of on-line learning  but also a general point: it shows a high specialization of  intercept  skills according to the role and situations faced. thus  sharing experiences of individuals in different roles or training individual across roles would appear to be detrimental  i.e.  there are key limits to social learning. of course  it does not rule 
	tambe et al. 	1 


figure 1: player 1 against cmunited1 & andhill1. 

figure 1: players 1 & 1 against cmunited1. 
out social learning. indeed  in the results above  the trends of the changes were shared across players  so that some social learning can be carried out. thus  our goalee agents  which tend not to get as many intercept opportunities during the game  rely on mean intercept values from the other players. 
1 	teamwork challenge response 
the teamwork challenge covers team planning  plan decomposition  execution  etc. there is not necessarily one best answer to this challenge  and our two robocup teams present at least some of the tradeoffs. 
1 team plan execution 
our response to the team plan execution challenge is a key distinction of our isis teams - the use of a general-purpose teamwork model called steamltambe  1. based on the notion of joint commitmentslcohen and levesque  1    steam enables team members to autonomously reason about coherence during team plan execution. it also enables team reorganization upon disablemen of a team member and selective communication. steam's reasoning is instigated by a  sub team's execution of a team operator. for an example of steam in operation  consider the simple-defense team operator executed by the goalee subteam to position themselves on the field and watch out for the ball  fig 1 . each player sees only within its limited cone of vision  and can be unaware at times of the approaching ball. if any one of these players sees the ball as being close  it declares the simple-defense team operator to be irrelevant. its teammates now focus on defending the goal in a coordinated manner via the careful-defense team operator. specifically this includes intercepting the ball and then clearing it. should any one player in the goalee subteam see the ball move sufficiently far away  it again alerts its team mates  that 
1 	challenge papers 
careful-defense is achieved . the subteam players once again revert to simple-defense. all the communication decisions for the subteam coordination here are handled automatically by steam. 
　for teamwork  one evaluation criteria in  kitano et a/.  1  is generality  i.e.  reuse of the teamwork capability across applications. steam was originally used in battlefield simulations tambe  1   and its generality is illustrated in its reuse in robocup. we may measure this reuse in terms of the number of steam rules reused. steam originally had 1 rules  of which 1%-1% are used in isis. without steam reuse  communication in isis would have required dozens of domain-specific coordination plans. 
　a second evaluation criteria is general performance. to this end  we measure impact of steam on isis1  by experimenting with different settings of communication cost in steam. in particular  at  low  communication cost  isis1 agents communicate a significant number of messages  while at  high  communication cost  isis agents communicate no messages. since the portion of steam in use in isis is effective only with communication  a  high  communication cost essentially nullifies the effect of steam. table 1 below shows the results of games for the two settings of communication cost  illustrating the usefulness of steam. it compares the performance of the two settings against andhill1 and cmunited1 in approximately 1 games. it shows that the mean goal difference between isis1 and andhill1 was -1 per game for  low  cost  and was -1 per game for  high  cost. this difference in the means is significant using a t-test  null hypothesis p=1 . it also shows a similar comparison for 1 games between isis1 and cmunited1. it shows that the mean goal difference between isis1 and cmunited1 for  low  was 1  and was 1 for  high   again  using a ttest  p=1 . thus in both cases  steam's communication  low cost  helped to significantly improve isis's performance. 

table 1: isis1: mean goal difference with/without steam. 
1 	team monitoring challenge 
in response to the team monitoring challenge  part of the team plan execution challenge   we contrast isis1 with isis1. our individual isis1 players very precisely monitored their own and the ball's x y positions on the robocup field. in contrast  isis1 players only approximately  and often inaccurately  estimated their own or the ball position  without x y . thus  isis1 players were individually more situationally aware  and were expected to outperform isis1 players. 
　the surprise: in actual games  e.g.  against cmunited1  however  isis1 players appeared to be as effective as isis1 players. our analysis revealed that isis1 players were com-

pensating for their lack of individual monitoring by relying on their teammates. consider for instance the carefuldefense team operator discussed earlier. this operator is terminated if the ball is sufficiently far away. in isis1  without x y locations  individually recognizing such termination was difficult. however  one of the players in the subteam would just happen to stay at a fixed known location  e.g.  the goal   acting as a reference. when it recognized that the ball was far away  it would inform the teammates  as per its joint commitments in the team operator. thus  other players  who were not situationally well-aware  would now know the ball is far away. in contrast  isis1 players  with x y computations  would individually quickly recognize the termination of this operator. 
　table 1 shows the means of goal differences for isis1 with differing communication costs and different opponents  over 1 games against cmunited1 against andhill1 . steam's communication   low  communication cost  does not provide a statistically significant improvement over nocommunication  using a two-tailed t-test . this indicates decreased reliance on communication among teammates  and contrasts with results for isis1 from table 1. 

table 1: impact of steam in isis1. 
　thus  the response to the team monitoring challenge is the discovery of a general tradeoff: one monitoring approach provides individual agents with complex monitoring capabilities  making them situationally well-aware and hence independent of others  for monitoring . another approach provides simpler monitoring capabilities to agents  but they must now rely on teammates to compensate for the lack of own capabilities. 
1 	plan decomposition challenge 
the robocup challenge of team plan decomposition focuses on designing roles for individual agents in a team. ideally  roles should divide the team responsibilities fairly  avoid conflicts  and conserve resources by avoiding redunducies. indeed  in isis1  these factors led to players' roles being defined in terms of non-overlapping regions of the soccer field  in which they were responsible for intercepting and kicking the ball. these regions were flexibly changed  if the team went from attack to defense mode. in contrast  in 1sis1  players* roles  also defined in terms of regions   had a significant overlap  possibly wasting stamina. thus  the role non-overlap plan decomposition of isis1 was expected to be significantly superior to the role overlap style of isis1. 
   the surprise: when we played isis1 and isis1 against cmunited1  however  isis1 was not outperformed as expected. in particular  isis1 managed to attain a reasonable division of responsibilities  via competition within collaboration. essentially  multiple players in 1sis1 would chase the ball  competing for opportunities to intercept the ball. players that were out of stamina  or those that lost sight of the ball etc.  would all fall behind  and the player best able to compete  i.e.  get close to the ball first  would get to kick the ball. 
　thus  a key lesson is tradeoff in role design: a flexible  role no-overlap design reduces conflicts  conserves resources  but requires careful off-line role planning. it can also fail in dynamic load balancing  e.g.  an isis1 player  even if very tired  is still solely responsible for its region. in contrast  isis1's role overlap can exploit competition within collaboration to more autonomously plan its role division  and attain more dynamic load balancing  e.g.  if a player is tired  a teammate with more stamina will get to the ball quicker. however  role overlap may waste resources  due to redundant actions. 
1 	agent modeling response 
the agent modeling area provides a key difficult robocup challenge: off-line review by an expert to analyze teams. we have constructed two contrasting agents in response to this challenge. both agents use a domain-independent approach that avoids the encoding of extensive domain knowledge and rely instead on extensive data-mining. these agents are thus collaborative assistants  relying on the  knowledge-rich  human observer to complete the analysis. since both agents rely on data-mining  they excel at uncovering unexpected phenomena. within the complexity of the robocup environment  these off-line review agents appear capable of capturing novel regularities that escape unaided human observers. 
1 	off-line expert agent 
isaac is a web-based off-line soccer expert  fig. 1  http://coach.isi.edu . it is focused on automated analysis to aid in improving a team's behavior. isaac approaches the problem by investigating actions that did not produce the desired result and then classifying the contexts in which failures occured. based on that classification  isaac recommends changes in behavior to avoid the failures: either the team should perform a different action in that context or should perform the action in a modified context. more specifically  isaac's analysis starts with logs of a particular team's games. 
from the logs  isaac extracts interesting behaviors and the outcomes of those behaviors. for instance  shots on own or opponent goals are interesting behaviors  so isaac gathers data on such shots  and whether they succeed. isaac then classifies these successes and failures into subclasses with similar contexts. for instance  a subclass might be all goal shots with a near-by opponent  that fail. currently  c1 is used to induce these subclasses by generating rules that classify the successes and failures of the shooting team. 
　isaac's next step is to formulate suggestions that may improve the team's performance  once again  using a knowledgelean approach. to that end  isaac formulates and analyzes perturbations of the rules. each rule consists of a number of conditions that must be satisfied for the rule to be valid. we define a perturbation to be the rule that results from reversing one condition. thus a rule with n conditions will have n perturbations. the successes and failures governed by the 
	tambe et al. 	1 


figure 1: isaac exists on the web. 
perturbations of a rule are examined to determine which conditions have the most effect in changing the outcome of the original rule  turning a failure into a success. 
   let us consider a simple example of isaac's analysis of andhill1 against other teams in the robocup '1 tournament. one of isaac's learned rules states that when taking shots on goal  the andhill1 team often fails to score when  i  ball velocity is less than 1 meters per time tick and  ii  the shot is aimed at greater than 1 meters from the center of goal  which is just inside the goalpost . isaac reveals that shots governed by this rule score once  and fail to score 1 times. that andhill1  the 1nd place winner of 1 had so many goal-shot failures  and that poor aim was at least a factor was a surprising revelation to the human observers. the user can review the  video  of these shots on goal in isaac's log monitor to better appreciate what is occurring in these cases. perturbations of this rule can also be considered. in cases where the rule is perturbed so that ball velocity is greater than 1m/t and the shot aim is still greater than 1m  andhill scores once and fails to score 1 times. in another perturbation  where ball velocity is again less than 1ma  but now shot aim is equal to or less than 1m  see figure 1   andhill is now scoring 1 times and failing to score 1 times. these perturbations suggest that improving andhill1's shot aiming capabilities can significantly improve performance. 
　more recently  isaac has been extended to analyze sequences of behaviors  again using c1   such as sequences of actions  e.g.  assists  that lead up to successes or failures. this analysis has revealed that out of the top four teams of robocup'1  isis is at one extreme with little or no emergent pattern of assists  while cmunited shows deeper patterns of assists and secondary assists. 
1 	teamwork review agent 
teamore  or teamwork monitoring review  is an agent that performs off-line review via a contrast of the behaviors of the agents in a team. teamore is based in socially-attentive monitoring  originally applied in battlefield simulations kaminka and tambe  1   underscoring its generality. in robocup  teamore complements the use of goals scored as a measure of teamwork. 
1 	challenge papers 

figure 1: isaacs rule perturbations for andhill'1. 
　teamore currently assumes that it has access to plans or behaviors executed by agents during a game  via agents' execution traces . teamore then compares the plans being executed by different team members  identifying discrepant situations  where team-members failed to agree on the joint team-plan that they should have been executing together. for instance  suppose the forwards are to execute a team tactic together  but one forward fails to execute it - this is a team discrepancy. teamore uses this discrepancy information over time as the basis for a quantitative measure of teamwork. 
　teamore uses several measures of discrepancy  but one particularly useful is the average time that it takes for a subteam  e.g.  forwards  to switch from one team plan to another. in perfect teamwork situations  all team-members switch team plans  tactics  together  moving in unison from one agreed upon team plan to another. thus  the perfect team-plan switch time is exactly one time unit. the worst possible switch is if one team member never makes the switch and the sub-team never establishes agreement. 
　earlier in this paper  isis1 was shown  table 1  to have significantly different score-differences with and without communications  while even a large number of games  over 1  of isis1 resulted in no statistically significant difference  table 1 . table 1 presents the results of teamore's analysis for the isis1-andhill1 and isis1-anghill1 games. the average time per switch for two sub-teams  defenders and goalees  is shown for the two settings of the communication cost  approximately half of the games were played in each setting . these results show that communications  when cost is low  do reduce the average time per switch for each of the sub-teams. this reduction is statistically significant  two tailed t-test values are shown in the table   hinting at an improvement in the quality of teamwork with communication. 
　the first two columns of table 1 show that while isis1 had no statistically significant difference in the goal-difference for these games  teamore is able to confirm that in fact steam is still making a statisically significant impact on the quality of teamwork  allowing validation of design objectives. moreover  as the last two columns  presenting teamore's 

analysis of the isis1-andhill1 games  show  the difference in quality of teamwork that steam makes for isis1 is much greater than it is for isis1  supporting our hypothesis that isis1's superior monitoring capabilities reduced its dependency on teamwork. in fact  the average-time-per-switch values for isis1 using communications lie in between the values for isis1 with and without communications. however  the values for isis1 without communications are much greater then those for isis1  explaining the much bigger impact communication had on isis1. 

table 1: ave time per switch in games against andhill1. 
1 	lessons learned 
our research in robocup has been fueled by the ijcai1 challenge. we have responded to the challenge in all three categories of learning  teamwork and agent modeling. few other robocup teams have attacked the ijcal'1 challenge in this much breadth. one possible exception is  stone and veloso  1b   who have focused on layered learning for agent design  and an approach to teamwork based on locker-room arrangements  stone and veloso  1a . in their teamwork approach  agents synchronize their individual beliefs periodically in a fixed manner  in contrast with isis's steam in which communications are issued dynamically. indeed  in comparison with  stone and veloso  1a  and other teams  isis stands alone in its use of a domain-independent teamwork model  with its demonstrated reuse. other robocup researchers have investigated individual research areas. for instance   luke et al  1  have investigated an innovative approach to learning in robocup  but they have yet to address the agent modeling and teamwork challenge of robocup. others have investigated teamwork via explicit team plans and rolestch'ng and padgham  1   but not learning or agent modeling  and they fail the basic performance requirement of the robocup challenge  i.e.  the team must be able to play reasonably well. isis passes this test  given its thirdand fourth-place in robocup'1 and robocup'1. 
　in conclusion  in responding to the ijcai challenge  we have been able to extract the following general lessons in multi-agent learning  teamwork  and agent modeling: 
  some multi-agent environments require a significant role specialization of individuals. thus  sharing experiences of individuals in different roles can sometimes be significantly detrimental to team performance  placing key limits on social learning. 
  divide-and-conquer learning can be used to enable dif-ferent learning techniques to co-exist  reducing the complexity of the learning problem. 
  reuse of general teamwork models can improve perfor-mance and reduce development time. 
  tradeoffs exist in individual and team monitoring  e.g.  responsible team behavior enables the design of simpler monitoring capabilities for individuals. 
  competition within collaboration can provide a simple but powerful technique for designing role responsibilities for individuals. 
  in analyzing agent behavior in complex multi-agent en-vironments  data-driven analysis combined with human oversight appears promising. 
  comparison of the behavior of team members can pro-vide a useful teamwork monitoring tool. 
acknowledgements 
this research is supported in part by nsf grant iri-1  and in part by a generous gift from the intel corporation. 
