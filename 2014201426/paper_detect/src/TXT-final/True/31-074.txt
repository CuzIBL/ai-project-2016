 
constraint satisfaction problems  where values are sought for problem variables subject to restrictions on which combinations of values are acceptable  have many applications in artificial intelligence. conventional learning methods acquire individual tuples of inconsistent values. these learning experiences can be generalized. we propose a model of generalized learning  based on inconsistency preserving mappings  which is sufficiently focused so as to be computationally cost effective. rather than recording an individual inconsistency that led to a failure  and looking for that specific inconsistency to recur  we observe the context of a failure  and then look for a related context in which to apply our experience opportunistically. as a result we leverage our learning power. this model is implemented  extended and evaluated using two simple but important classes of constraint problems. 
1 introduction 
1 	overview 
constraint satisfaction problems  csps  involve finding values for problem variables subject to constraints on which combinations of values are allowed. they have many applications in artificial intelligence  ranging from design to diagnosis  language understanding to machine vision. a solution is an assignment of a value to each variable such that all the constraints are simultaneously satisfied. a constraint on a subset of k variables can be regarded as a set of k-tuples of values  where each ktuple represents an inconsistent choice of values for those variables. 
　in addition to the inconsistencies in the constraints that are given to define the problem  there are implicit inconsistencies  that become apparent during the search for a solution. in general  a k-tuple of values is inconsistent  or a nogood1  if it does not appear in any solu-
*this material is based on work supported by the national 
science foundation under grant no. iri-1 
　　1 we only consider global nogoods  whose inconsistency does not depend on a context of other choices. 
tion. solution methods are commonly based on backtrack search. when a failure is encountered during search  there are  learning  methods that can identify and record an individual nogood  responsible  for the failure. while the inference methods employed to extract the nogoods may be relatively sophisticated  the actual learning tends to be rather primitive. there is little if any of the generalized learning from examples or background knowledge that has been employed so successfully in the machine learning community.  there are other interesting applications of learning methods to constraint satisfaction  to synthesize heuristics or algorithms  but we focus here on learning additional constraint information.  
　as a simple  motivating example of generalized learning consider five vertices  a  b  c  d and e in a coloring problem with a great many vertices and three colors: red  blue and green. suppose that there are no edges among these five  but that each of them is connected to vertex f. a person trying to color the vertices in lexical order would observe that while there are no edges between vertices a  b and c  nevertheless there is an implied constraint that if a is red and b is blue  then c cannot be green. a csp search algorithm could make the same observation. a standard csp learning algorithm could learn and remember that the triple of values  red  blue  green  for the triple of variables  a  b  c  is inconsistent. a person  however  would be likely to generalize that learning: 
  a person could recognize that d and e cannot be green either  when a is red and b blue. 
  when encountering a similar configuration among other variables elsewhere in the problem  the person could recognize that this situation had been encountered before. 
  a person would understand that the specific colors involved are not critical  they could be black  orange and brown. 
  a person might even observe that a similar situation exists when four colors are available  or n colors . 
　in this paper we introduce a basic form of generalized learning. the principle behind it is this: when a subproblem  learning environment  can be mapped onto another subproblem encountered later in the search with 
	freuder and wallace 	1 
an  inconsistency preserving mapping   then the original learned nogood generalizes to the new situation. 
　of course  finding such mappings could easily become more computationally expensive than solving the original problem. to apply the general insight we need to identify learning contexts that are general enough to be interesting  but restricted enough to make generalization cost effective. we identify a basic context that meets these criteria  which encompasses  in particular  the first two examples of generalization listed above   and then begin to relax the restrictions. 
　we validate the utility of generalization in two specific contexts. we start by considering  coloring  problems in which the single permitted constraint is inequality. these  constraints of difference   regin  1  are of considerable interest  and in fact model basic coloring  scheduling and resource allocation problems. next we add the ordering constraints:             =. 
1 	relation to previous work 
there is a stream of work on csp nogood learning  see 
 frost and dechter  1; schiex and verfaillie  1  for recent examples  with connections to truth maintenance  e.g.  smith and kelleher  1  . there is a stream of work on csp symmetry  see  ellman  1; puget  1  for recent examples   which extends at least as far back as   fillmore and williamson  1  . one of the current authors did some tentative work earlier on subgraph isomorphism in constraint graphs  freuder  1 . benhamou  benhamou  1  uses symmetrical values and search branches to improve csp algorithms. 
　the current work brings these two streams together  using isomorphic mappings to generalize learned nogoods. we find local mappings  dynamically during search  between subproblems  in which some of the variables have been instantiated to specific value choices. the pruning done by the basic form of generalization that we implement would be subsumed by some forms of look-ahead  though not by forward checking alone   haralick and elliott  1 . however  generalization accomplishes the pruning in a more targeted manner; our experimental results show that generalization can be more cost effective than the additional look-ahead. 
1 	principle 
generalization will be based on inconsistency preserving mappings. a mapping takes a value/variable pair  e.g. red/a  value red for variable a  into another value/variable pair. an inconsistency preserving mapptng  f  from a source subproblem  s  to a destination subproblem  d  is a function from the value/variable pairs of s into the value/variable pairs of d  such that if any v/v is inconsistent with any u/u in s  then f v/v  will be inconsistent with f u/u  in d. clearly  inconsistency preserving mappings can permit us to generalize the application of learned nogoods by mapping a nogood acquired in one subproblem into a situation encountered in another subproblem. 
　just as clearly  looking for these mappings could easily be computationally counterproductive. we can focus 
1 	constraint satisfaction 
our attention along a number of axes: semantic  syntactic and pragmatic. we choose a very restricted starting point on each of these axes  to establish a basic model of generalization learning  and then begin to move outward. we begin with with value-identity mappings such that a value/variable pair  v/v  can only map into a pair  v/u  involving the same value. we assume that in a given problem all variable domains are the same  and all the given constraints are the same  and binary  involves only two variables . we use the fundamental  deadend learning  context to establish the structure of the source subproblem  and the basic backtrack search structure to propose destination subproblems. 
　instances of the prototypical source and destination problems  with an inconsistency preserving mapping between them  are shown in figure 1. the source subproblem consists of a hub variable and k spoke variables. each spoke variable domain has been reduced to a single value; all these values are deemed mutually consistent by the given problem constraints. every value in the hub variable domain is inconsistent with at least one of the spoke variable values. this is the basic csp deadend learning situation  in which we record that the spoke variable values  or some subset of them  form a learned nogood.1 here  for simplicity  we assume that the hub variable in the destination problem corresponds to the current variable in the search  the one for which we are about to choose an instantiation. the values from k-1 of the spoke variables in the source map into k-1 previously chosen values in the destination. the kth source spoke variable corresponds to a  future  uninstantiated variable at the destination. applying the discovered generalization is done by pruning the value in the source subproblem corresponding to the value at the kth spoke variable.  note that there may be additional  past   instantiated variables  or future  uninstantiated ones that constrain the current variable. the other future variables offer additional opportunities for generalization pruning.  
　given the assumptions that we have made here  it is easy to see that this is an inconsistency preserving mapping  and that to discover it all we have to do is observe that k-1 of the source spoke values appear in instantiated variables that share a constraint with the current variable in the destination subproblem.  for example  there may be constraints between spoke variables in the source  but they are irrelvant now since the spoke variable values are all mutually consistent.  discovering source problems requires essentially the same effort as deadend learning; the effort expended in looking for an opportunity to generalize is strictly circumscribed. 
　in the next sections we will implement and evaluate this basic generalization mechanism. we start by considering  coloring  problems in which the single permitted constraint is inequality. these problems precisely fit the basic model we have just introduced. next we add the 
　1 in more advanced learning the deadend can consist of a subproblem rather than a single variable. this is beyond the scope of the present paper; however  we believe we can generalize such advanced learning  and avoid combinatorial explosion by limiting the size of the failed subproblem. 
figure 1: scheme for nogood learning. 　1 nogood learning and generalization 
generalization can  of course  be used with a variety of csp algorithms. in the present paper  a forward checking engine is used to evaluate the effect of adding generalization. as part of the overall comparison  nogood learning without generalization  dechter  1   schiex and verfaillie  1  is also considered. 
　we first describe our nogood learning procedure  and then discuss the ways in which learning based on generalized nogoods differs from it. when nogood learning is used with forward checking  preclusion based on k-ary nogoods is performed in tandem with ordinary preclusion  figure 1 .  in  ordinary preclusion   values in future  uninstantiated  domains that are inconsistent with the latest value chosen for instantiation are discarded  or precluded.  for fixed order search  k-ary nogoods are ordered by their variables in accordance with the search order. each nogood is associated with the penultimate variable in its ordered set. at this point in search  a match with previous assignments  plus the value currently being considered for the current variable  allows preclusion of the domain of the last variable in the nogood. 
two variants of nogood learning will be considered. 
one is based on the set of variables that are adjacent to one that has been wiped out. this is the procedure that  frost and dechter  1  call graph-based nogood learning. the other is based on the preclusion set  i.e.  the variables whose assignments led to deletions of values in the domain that has been wiped out. this is called the jump-back set by  frost and dechter  1  and the in the algorithms discussed here nogood building is based solely on ordinary preclusion. thus  results of preclusion due to k-ary nogoods are not used. this would have required further elaborations to search for the relevant variables and to combine them properly. since the nogoods will be larger than ones based on ordinary preclusion  they are probably not as useful. this is because the probability that a nogood matches a current partial assignment decreases as the size of the nogood increases. some overhead is incurred because the program has to check that domain wipeout did not involve k-ary nogoods. 
　the procedure for building generalized nogoods is similar to that used for ordinary nogood learning  figure 1 . nogoods are built following wipeout of a domain. but in this case the nogood consists of a set of disallowed values  one per domain  together with the conditions under which they are disallowed. in the general case these conditions are: the type of constraint and the original set of values in the domain that was wiped out. if a particular condition is consistent for the entire problem  then it does not need to be specified. for example  if the original domains of the problem are identical  then a nogood will hold for any subproblem having the necessary pattern of constraints. if both the domains and the constraints are constant for a problem  then only the values need to be specified. 
　for coloring problems  inconsistency mapping was done so that the hub variables were the uninstantiated  i.e.  future  variables adjacent to the variable currently considered for instantiation. in other words  generalization was based on a look-ahead by one procedure. in coloring problems  if the current variable itself is used as 
	freuder and wallace 	1 
the hub  then preclusion based on nogoods is completely redundant with ordinary preclusion. this is because nogood preclusion will apply only in those cases where the domain of the current variable has been reduced to the one value that can be precluded from the adjacent domains. but  then  the value in the current domain will also preclude the same values from the adjacent domains  with the same  total  number of constraint checks. since look-ahead by one proved to be a successful strategy  it was used with all sets of problems. 
it 
figure 1: scheme for generalized nogood learning  with look-ahead by one . 
　as with ordinary nogood learning  variants based on adjacency sets and on preclusion sets were included in the tests. in connection with adjacency sets  two further cases are considered. in the first  there is no attempt to minimalize the set of nogoods and all are used in attempting to preclude values. the second case involved minimalization. for nogood learning this is probably too expensive  dechter  1; frost and dechter  1 . but  if there is only one set of generalized nogoods  as in the cases considered here  minimalization may be costeffective. 
1 experimental tests 
1 	problems tested 
generalization in k-coloring problems is carried out as described in the previous section. if a nogood is discovered during search  it can be used with any variable having k or more adjacent variables  to delete values from some of the adjacent nodes. of course  some procedures  those based on adjacency sets  may discover nogoods 
1 	constraint satisfaction 
that are multisets of the k colors  and these can be generalized in the same fashion. 

figure 1: performance on 1-color problems  density = 
1. means for 1 problems. legend maps onto columns of graph when former is rotated counterclockwise. 
　for problems with ordering constraints based on relational operators   relop  problems   nogoods are discovered in the same fashion as with coloring problems. for ordinary nogood learning  use of nogoods during search is also identical. however  in order to generalize properly  information about constraints must be considered in addition to nogood values. in the general case these nogoods are applied according to the mapping principles described in section 1. this means that each constraint associated with a nogood value must match  by subsumption  a constraint in the subproblem being considered  and that the nogood value must not be more constraining than the current instantiation. 
　for example  suppose that the domains of a problem are all {1  1  1  1} and that the assignment for variable vi must be greater or equal to the value of variable vk*  and the assignment for variable vj must be equal to the value of vk. in this case  assigning values 1 and 1  respectively  to f  and vj results in a wipeout of the domain of vk- this nogood can be represented by the tuple      1   = 1    whose elements can be thought of as partial lisp expressions with the second argument unspecified. in addition to matching any subproblem with the same constraints and values  the first element of this nogood will match an assignment of 1 to a variable associated with a   constraint  an assignment of 1 to a variable with a   constraint  and so forth. 
　clearly  the effort to find a general match in this case may be too costly. in particular  finding an adequate mapping may require backtracking when a nogood element can be matched to more than one element in the subproblem. however  the comparison criteria can be tightened  and search effort may still be reduced with acceptable overhead. for example  the comparison can be discontinued if a nogood element does not match any of the remaining instantiations  to avoid backtracking. in addition  matches can be restricted to identity mapping of constraints  here  exact matches for the relational 

are currently implementing dynamic ordering by minimal domain size; this should still allow improvement due to nogood learning  as  frost and dechter  1  have shown.  forward checking with look-ahead  fc+la-1  was also tested to determine the effect of this procedure  which was used with generalized nogood testing. 

figure 1: performance on 1-color problems  density = 1. means for 1 problems. same relation between legend and figure as in figure 1. 
1 	experimental methods 
coloring problems had either three or four colors. threecolor problems had 1 variables and an expected graph density of 1  1 or 1; four-color problems had 1 variables and an expected density of 1.  here  density is measured in terms of edges added to a spanning tree.  the 1-color densities span the critical region for problem complexity. in accordance with this  problem difficulty increases from 1 to 1 density  and decreases again at 1 density. the percentage of problems with solutions at successively higher densities was 1  1 and 1. four-color problems were also in the critical region; 1 percent of these problems had solutions. 
　relop problems had 1 variables and expected densities of 1 and 1. the percentage of problems with solutions at successively higher densities was 1 and 1. 
　both types of problem were generated according to a random model for arc inclusion. construction began with a spanning tree in which successive nodes were chosen at random and connected at random to nodes already in the tree. then each remaining edge was chosen with a probability equal to the expected density. for relop problems  the type of each constraint was chosen at random from among the six possibilities. fifty problems were generated for each sample. 
　the basic experimental comparison was with forward checking. in these experiments  each algorithm was run with a fixed variable ordering based on  maximum  degree of a node in the constraint graph for the csp.  we look-ahead was done using distance bounded relaxation 
 freuder and wallace  1  with distance = 1  which was the same as the distance used with the nogood algorithms. results were also compared with two of the most powerful techniques for solving csps: forward checking with conflict-based backjumping  fc-cbj   prosser  1  and maintained arc consistency  mac1   sabin and freuder  1 . in the latter case  an ac-1-like procedure was used to maintain arc consistency  in order to have a measure  consistency checks  that allowed comparison with the other algorithms. 
　for coloring problems  both ordinary and generalized nogood learning  ng and genng or gen in the tables  were tested using either adjacency sets or preclusion sets   adj  and  precl  in tables ; adjacency sets were either full or minimalized when used with generalized nogoods. for relop problems  testing was done with preclusion sets only. the following types of generalization were also tested:  i  simple identity matching  genng-id    ii  identity matching of constraints  relational operators  and set/subset matching of values  genng-idop    iii  set/subset matching of both operators and values. for the last two categories  a kind of minimalization was also carried out  according to the following procedure. if k-1 elements in two nogoods were identical  the kth elements were matched for operators. if both operators were in the set {    } or in {    }  then the element whose value was more inclusive was retained. 
　three measures of performance were used: backtracks  constraint checks and total search time. the number of backtracks  i.e.  the number of times the values in a domain were exhausted causing search to back up  is an indication of the size of the search tree. number of consistency  or constraint  checks often gives a better overall view of performance. all algorithms did some consistency checking as part of the preclusion done by forward checking. algorithms that incorporated nogood learning 
	freuder and wallace 	1 

also checked k-ary nogoods. algorithms that employed look-ahead also did consistency testing between values in domains of future  uninstantiated variables. naturally  k-ary constraint checks differ from ordinary constraint checks in the time required  and the time required to test ordinary nogoods is different from the time to test generalized nogoods. for these problems simple nogood testing was faster than ordinary constraint checking  partly because the nogoods were small and look-up operations were simpler.  rapidity of failure when testing successive nogood variables may also have been a factor.  generalized nogood testing was more involved  since the set of variables and their order were not known in advance; hence  this operation was slower than ordinary constraint checking.  these differences are most 
evident in the data of table 1.  
　experiments were run on a dec alpha  dec 1 m1lx . algorithms were coded in common lisp  using lispworks by harlequin. all solutions were tested for validity; in addition  solutions produced by the new algorithms described in this paper were compared with those produced by a version of forward checking that has been thoroughly tested in previous work.  all of these algorithms should find the same first solution to a problem if the same variable and value orderings are used.  
for all problem sets  nogood learning improved on forward checking alone  figures 1  tables 1 . in most cases generalized nogood learning was better than ordinary nogood learning; the only exception was for 1color problems with expected density = 1  see table 1 . comparisons involving look-ahead show that this technique may have been partly responsible for the improvement found with generalized nogood learning  but the latter was superior to straight look-ahead in situations in which it was also better than ordinary nogood learning. generalized nogood learning also outperformed forward checking with conflict-directed back-
jumping or maintained arc consistency on most problem sets  including those in the critical complexity regions. 
　as would be expected  minimalizing nogoods reduced the number of constraint checks. timing data also in-
1 	constraint satisfaction 
dicate that overall performance was improved  so that minimalization used with generalized nogood learning was cost-effective in this case. using preclusion sets was more effective than using adjacency sets for both ordinary and generalized nogood learning  and this difference was greater for the harder 1-color problems. but for generalized nogood learning  minimalization made the two almost identical with respect to search time and measured operations. 
relop problems 
for these problems  nogood learning was again superior to forward checking alone  figure 1 . the effect of using generalized nogoods depended on the character of the match and the use of minimalization. with pure identity matching  performance was actually worse  showing that a simple matching strategy corresponding to the one used with coloring problems was not sufficient in this case. more sophisticated matching based on set/subset relations was much more successful  and performance was further improved by the minimalization procedure.  examination of data structures during runs confirmed that this procedure did reduce the proliferation of nogoods found during search.  although the results were not as good as those for ordinary nogood learning  they show that generalization can improve on the basic forward checking engine even for problems with a fairly complicated pattern of constraints. 
　the targeting strategies mentioned at the end of section 1 have not yet been implemented and these may improve performance further. in particular  a simple 'match and store' strategy  in which matching nogoods are stored in a manner similar to ordinary nogoods  may reduce the amount of redundant matching during search. 
1 	conclusion 
by using inference  background knowledge  and recognizing structural similarities within and among problems  we can potentially leverage our learning power. we have identified a basic principle that supports generalized learning  and begun to identify specific contexts in which the principle can be profitably applied. 
