 	skill organization and compilation 

　three aspects of learning to program are described-the organization and compilation of problem-solving operators  the impact of knowledge representation  and the impact of working memory limitations. the grapes system simulates the organization and compilation of these operators. the simulation of one problem solving episode is discussed. also discussed are the impact of different data notations and the impact of working memory load on successful application of lisp functions. 
introduction 
　this paper is concerned with the cognitive factors that are involved in acquiring a skill like programming in lisp. among the relevant factors are the following: 
1. understanding sufficient instruction about the system to enable effective problem-solving. 
1. organization and compilation of this knowledge into a procedural form. 
1 tuning of the operators that underlie the procedural 
form. 
1. representing the problem optimally for the operators possessed. 
1. expanding working memory capacity to keep relevant knowledge available. 
the first is the focus of most of the educational effort 
- whether in textbooks  user's manuals  or the classroom. the other four are largely ignored. they are things that are learned implicitly in the act of solving problems. in looking at novices learning how to program in lisp  they spend less than 1% of their time actually trying to absorb the relevant knowledge and more than 1% of their time learning how to use that knowledge. we have yet to see a novice understand any instruction of modest complexity such that he could do the task without error. there are always serious holes in the understanding which are only dealt with in the act of solving problems. 
　this paper will describe what we have learned about topics 1  and 1 above. i want to stress  however  that our findings are not unique to lisp or indeed to programming. similar things are being found in areas such as geometry and physics  e.g. 
anderson  1; larkin  1 . 
　we have developed a production system  called grapes  that simulates the problem solving involved in programming and the learning that occurs in the course of this problem solving. grapes uses a set of problem solving operators that decompose goals into subgoals. a programming problem is solved in grapes by decomposing an initial goal to program a function into subgoals and these into subgoals  etc.  until goals are reached which correspond to lisp code. given the right operators grapes can solve moderately difficult lisp problems  write  test  and debug the code  see anderson  farrell & sauers  1 . this is a critical sufficiency test because humans eventually are capable of this. however  more interesting is its simulation of the behavior of novices in their first hours of learning lisp. here i will consider one of the many simulations we have performed and what this simulation says about skill organization and knowledge compilation. 
simulation of onetwo 
　the case comes from a subject  ss  who had written just three functions--to take first  second  and third elements of a list. then she was given the onetwo problem. the onetwo problem required the subject to write a function which would take a list as an argument and return a now list consisting of the first two elements of the argument list. the lisp functions that the subject knew at this time included cons  but the subject had not yet learned about list. she knew about car and cdr and with these she had defined functions that would return the first  second  and third arguments of a list. these were the only functions that she had written up to this point in time. 
   initial attempt at onetwo. she flailed at writing the function onetwo and the experimenter suggested writing a simpler function  addtwo  which would take two arguments and make a list out of them. this problem she was able to make some headway on. it is interesting to speculate why addtwo was more tractable than onetwo. as we will see  the basic problem and its solution did not change in going from onetwo to addtwo. however  by reducing the complexity of the task by one level  the burden on working memory was reduced so that the subject was better able to match operators. a later section 
discusses 	in 	more detail the 	impact of 	working 	memory limitations. 
	figures 	1 	illustrate the 	simulation's attempts to 	solve 
1 j. anderson 
　the subject and grapes mentally simulated what the outcome would be of the code  cons ' a b  ' c d  . this involved retrieving the definition of cons again. as evidence 
that her definition of cons was not in error  she correctly determined that   a b  c d  would result as a answer. this onetwo. 	given the perfect correspondence between the figure 1 illustrates the processes by which she decided how to create this example at the top level. after deciding on the example  she went through an episode where she explicitly reviewed the definition of all the functions she knew  searching for an appropriate one. she selected cons. we represented the definition of cons to grapes as 
　the first argument of cons is any s-expression and the second argument is a list. its result is a list. the first element of the result is the first argument. the rest of the result consists of the second argument. 
she and grapes chose cons on the basis of the fact that a list was wanted and cons makes lists. having selected cons the subgoals were now to determine what arguments to pass to cons in order to get the intended result. 
　the critical piece of information in selecting the first argument is the definition statement the first element of the result is the first argument. grapes interfaces this with the desired result    a b   c d    to determine that the correct argument should be  a b . 
	next  ss and grapes turn to the second argument. 	the 
appropriate part of this definition is the rest of the result consists of the second argument. matching this would retiieve   c d   as the second argument. however  our subject retrieved  c d . we assume  see detailed discussions in anderson  farrell and sauers  that the semantic feature of consists were partially lost and this statement became the rest of the result contains the second argument. we manipulated grapes' working memory so corresponded to an error she had encountered frequently and we assume she had acquired an operator to repair this which embedded the second argument to cons in a extra list. in this way  she and grapes recover from their errbr and make up the corcrete example  cons ' a b  '  c d   . 

　the mapping. figure 1 illustrates the simulation of ss's initial attempt to map from the concrete code to an abstract lisp function. first she maps cons in the concrete code into cons in the lisp {unction. at this point the structure of the function is 
 clef addtwo  lambda  one two  
 cons            
the remaining task is to map the two concrete arguments into abstract arguments. she first focuses on mapping  a b . the following rule applies: 
if the goal is to map a concrete expression of lisp and the expression is a data structure involving 
a term 
　figure 1 illustrates some of the subsequent evolution of this definition. the coding of addtwo had the brother goal of checking that code. both ss and grapes called the lisp interpreter to try the code with the arguments  a b  and  c d . both received the same error message  two undefined function object.  this also corresponds to an error that ss had encountered a few times previously in her problem solving. in 
	j. anderson 	1 
previous occasions  the cause had been failure to quote an argument. therefore  we assumed that she had acquired an operator that used quote to stop evaluation. when this operator applied  her lisp code became 
 def addtwo 
 lambda  one two  
 cons one ' two     
again  the code was tried. this time it returned the result   a b  two . comparing this with her desired result the problem was localized to the second argument given to cons and grapes went back to retrying the goal of mapping   c d  . 
 def addtwo 
 lambda  one two  
 cons one  cons two nil     
　return to onetwo. figure 1 illustrates the behavior of the simulation and the subject when they returned to the original 

1 	j. anderson 
onetwo problem. the code they generated is given below: 
 def onetwo 
 lambda  list  
 cons  first list  
 cons  second list  nil     
whereas the subject had taken an hour to code addtwo  she only took ten minutes to solve onetwo and most of that time was spent confirming what the functions first and second did. onetwo is solved by the same method that addtwo is solved  but without any rehearsal of the onetwo method. our assumption is that operators were compiled from this problem that summarized the planning steps that went into the problem solution. 

	figure 	1 
　one of the operators that grapes compiled summarizes the problem solution illustrated in figure 1 that started with the goal of creating a list of a single element and resulted in the action of consing that element with nil. the compilation procedure recognizes that the various aspects of the concrete example and its code are intermediate results and are not essential to the final answer. it traces through these steps to determine if there are any connections from the top goal to the final consing action. 
the summary operator built is: 
if the goal is to code a list consisting of one argument 
         then cons that argument with nil and set as subgoals to code that argument similarly  an operator is compiled to correspond to the outer cons in the addtwo function. it has the form: 
if the goal is to code into a list consisting of argument! and argument1 
then cons argumentl into a list consisting of argument1 
and set as subgoals to code argumentl and to code a list consisting of argument1 conclusions from simulation. this example illustrates a number of conclusions that we have come to in simulating the problem-solving of our subjects. the first conclusion is that their behavior is hierarchically organized according to goal trees like the ones illustrated in figures 1. the second conclusion is that subjects prefer to solve problems by analogy to concrete cases. in this episode the subject created an example at the top level which she then tried to map over into the code for the function. 
   the third conclusion is the importance of knowledge compilation in extracting from an example problem operators that will streamline the solution of later problems. there are numerous technical issues in deciding how much to collapse into a single operation and we have hardly solved them all. however  for a discussion of what progress we have made consult anderson 1  and anderson  farrell  and sauers 1 . the hierarchical organization imposed by goal structures such as the one in figure 1 is important to the compilation process. it serves to indicate what aspects of the original problem solving episode should go together in the compiled operator. 
　the fourth conclusion concerns the impact of working memory failure on performance. we saw that cons was incorrectly applied because the subject momentarily misrepresented its definition. i will return later in this paper to the issue of how working memory failure impacts on incorrect application of a function. 
representation 
　how one represents a problem has a strong impact on one's problem solving. we have been trying to document the impact of 
data structure representations on subject's problem solving. typically  lisp is now taught with respect to parenthesized notation. subjects conceive of the effects of basic lisp operators like car  cdr  cons  and list in terms of changes made on marks on a page. we think this representation has strong implications for the relative difficulty of the various functions and the types of errors. 
	 car '     a   	 b    =  a  
very easy 
	 cdr '     a   	 b    =   b   
more difficult 
	typical error: 	= 	 b  
	 list ' a  	'   b     = 	  a  	 b   
fairly easy 
	 cons ' a  	'   b     =   a  b  
most difficult 
	typical error: 	=   a   b   
figure 1 
   figure 1 illustrates the four functions. car takes the first element of a list and subjects have little difficulty with it beyond overcoming the non-mnemonic character of the function name. cdr returns the remander of a list and subjects have more difficulty with it. a frequent error is illustrated in figure 1. when the tail of the list contains a single list  subjects will return that list with one set of parentheses missing. the function list subjects find both mnemonic and easy to understand. they have the greatest difficulty with cons. cons inserts its first argument into the list that is its second argument. a frequent error is leaving an extra set of parentheses around the second argument. 
exactly why these errors are made is a little uncertain. robin 
jeffries has developed a grapes model that will produce these errors. it and many similar explanations turn on the fact that cdr and cons are explained to subjects as moving parentheses. for instance  this instruction is quite explicit in siklossy 1 . subjects think thai cdr operates by deleting the first parenthesis and the first element and inserting the parenthesis in front of the rest of the list. if the last insert operation is omitted it is possible to have an error. subjects think of cons as deleting the left parenthesis of the second argument  inserting the first argument in front of that  and then inserting left parentheses. if they omitted the deletion operation they could produce the error in figure 1. subjects also think of car and list as moving parentheses  but omission of any step in car and list results in a nonsensical result as does omission of any of the other steps in cdr and cons. thus  the problem with cdr and cons is that there are critical steps which  if omitted  will lead to nondetectable errors consistent with this view is that the same subject will randomly make and not make the errors. this is what we would expect if it were produced by occasionally forgetting a step. 
 car   a.nil .  b.nil .nil    =  a.nil  very easy 
 cdr   a.nil .  b.nil .nil    =   b.nil .nil  very easy 
 list  a.nil   b.nil  =   a.ntl .  b.nil .nil   
difficult 
	typical error: 	=   a.nil . b.nil   
 cons  a.nil   b.nil   =   a.nil . b.nil   fairly easy 
figure 1 
　one might think that the problems with cdr and cons are unavoidable. however  this is certainly not the case. originally  lisp' was taught as operating on a box structure  which is much closer to the actual computer-implementation of lisp. figure 1 illustrates how the functions apply to the dotted pair equivalent of the box notation  weissman  1 . we performed an experiment in which we explained the operation of these lisp functions with respect to the dotted pair equivalent of the box notation and contrasted this with the list notation. as we have informally observed  cdr is harder than car with the list notation and this is largely due to forgetting parentheses in examples like figure 1. this difference went away with the dotted-pair notation. again we confirmed our informal observation that cons was more difficult than list and this was in part due to failing to put parenthesis around the second argument. we found that the difficulty reversed with the dotted-pair notation and the errors with list derived from failing to embed its second argument in a separate dotted-pair structure. this clearly indicates that the difference is not a matter of the greater mnemonic value of the word list rather than cons  as some have suggested. 
  now  i do not want to be read as advocating that lisp instruction go back to the box notation. there are good justifications for using the parenthesized list notation as basic and only later introducing the box representation. people find lists easier to reason about and the appropriate data structure usually turns out to be a list. however  there are applied consequences of understanding how representation impacts on difficulty of functions. the basic problem with cdr and cons in the representation is that they destroy and reconstruct the structure of their arguments. if the destroy and reconstruct are not carried out properly  non-detectable wrong answers can result. there are ways to characterize the operations of cdr and 
	j. anderson 	1 
cons to avoid this difficulty. rather than deleting the left parenthesis  the first element  and reinserting the left parenthesis  cdr could be characterized as erasing the first element. rather than characterizing cons as deleting the left parenthesis of the second argument  adding the first argument  and adding the left parenthesis  we could characterize cons as squeezing its first argument into the front of the second. 
problems of memory load 
　one of the surprises to me in studying lisp novices is how much of their programming time is spent recovering from errors of memory. we intend to quantify this for each of our protocol subjects  but informally i would guess it averages around 1%. this includes time spent trying to reconstruct what forgotten subgoals are. worse is when the subject misremembers a subgoal and solves a different one. also subjects will often retrieve the wrong function to perform a task subjects do not have the experience of so much wasted time because in retrospect they tend to forget their failures of memory and only remember their correct steps. so you might get remarks like   i don't know how i could have spent two hours on solving this. i must have been asleep.  
　experts do not have the same frequency of memory errors on problems. in part this is because their short term memories are better  perhaps due to something like chunking. but they are also more reliable at recalling things that occurred half an hour earlier in the problem solving protocol  jeffries  turner  atwood & poison  1 . this cannot be simply due to chunking. their long term memories are more reliable for the domain and become reliable extensions of short-term memory. this better working memory for the domain of expertise seems a fairly general phenomenon. chase and ericsson  1  have studied some subjects who reliably increased their digit span up to 1 digits from the usual 1 -+ 1. they also were able to show that this depended on reliable storage and retrieval from ltm. the interesting observation was that subjects with 1 digit spans were no different in other ways. in fact  their letter span was 1 -+1. i think the same thing happens in programming - we develop better working memories for partial information computed in the process of programming and this better working memory is specific to programming. 
   one of the classic memory retrieval errors in novice lisp programming is using list instead of cons. anderson  farrell and sauers have shown how this can be explained in terms of what the subject's representation of what cons and list do. the interesting observation is that these errors appear to be more frequent in the context of writing a complex function  thus  it seems when the working memory load increases  errors in function recall increase. 
　we did an experiment to see if embedding an extra level of processing would result in increased errors. figure 1 illustrates the materia! used in the experiment. there were three types of tasks. one involved recognizing the missing function that would transform the input into the output. the second involved evaluating the function as applied to a series of arguments. the third involved recognizing the argument which  if provided to the function  would produce the output. 

1 j. anderson 
 a  function recognition    ' a  '  b   c   d   = 
	1% 	  a   b   c   d   
	   	' a   reverse '  b   c   d     
	1% 	  a   d   c   b   
 b  evaluation 
1%  cons ' a  '   e c d     =   
1%  cons ' a   reverse ' b c d    =   
 c  argument provision 
1%  cons 'x    =  x  y z   
1%  cons 'x  reverse     =  x  y z   
figure 1 
　the two types of functions used were list and cons  although only cons examples are illustrated in figure 1. thus  for function recognition the subjects choice was implicitly between list and cons  although occasionally an append was given. in evaluation and argument provision  the typical errors were incorrect number of parentheses with error much more frequent for cons. subjects got 1% of the list problems correct  but only 1% of the cons problems. this is in line with earlier remarks about the relative difficulty of the two functions. 
   the principal manipulation of interest was whether the function had a reverse composed in. reverse simply changes the order of elements in a list; it does not change the appropriateness of a cons or a list in the function generation problems. in evaluation and argument provision  it does not change the correct parentheses  - and we only scored these problems for parentheses  not whether the subject had correctly done the reversing. however  as can be seen from the percentages correct in figure 1  errors did increase when a reverse was involved. thus  adding an extra piece of information to working memory increased the error rate. this is an example of working memory spill over -- extra memory load in one aspect of the problem impacts on performance in a logically independent aspect. the effect on function recognition is particularly relevant here. we see that whether we credit a student with knowing the difference between list and cons may depend on the working memory demands of the test context. 
　many situations contain working memory demands that pose needless difficulty for novices. novices become overburdened in extracting needless detail and fail to extract the critical information for learning. one of the most frustrating instances of this in lisp is parenthesis counting. novices will be on the verge of an insight  go off to check whether the parentheses are balanced for some expression  and lose any chance of getting the insight after they are finished with the balancing. the implication is that tutorial techniques that reduce working memory load should facilitate learning. 
