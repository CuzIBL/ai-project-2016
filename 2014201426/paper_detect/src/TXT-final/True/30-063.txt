 
most studies concerning constraint satisfaction problems  csps  involve variables that take values from small domains. this paper deals with an alternative form of temporal csps; the number of variables is relatively small and the domains are large collections of intervals. such situations may arise in temporal databases where several types of queries can be modeled and processed as csps. for these problems  systematic csp algorithms can take advantage of temporal indexing to accelerate search. directed search versions of chronological backtracking and forward checking are presented and tested. our results show that indexing can drastically improve search performance. 
1 	introduction 
many problems in a variety of application domains can be modeled and solved as constraint satisfaction problems  csps . a binary csp is defined by:   a set of variables  
  for each variable 	a domain 	of  values: 
  for each pair of variables a binary constraint which is a subset of  
an assignment 	is consistent if 
　　　　　　　　　　　　　　the goal is to find one or all solutions  i.e.  n-tuples 	such that for each {i j}  	is consistent. 
　several systematic search heuristics that aim to minimize the number of consistency checks have been proposed. based on the general idea of backtracking  these methods try to improve the backward step  e.g. back-
jumping  or the forward step. e.g. forward checking  haralick and elliot  1 . hybrid algorithms combine different types of backward and forward steps fprosser  1 . the aforementioned search methods apply exhaustive search in the variable domains while assigning or pruning values. when the number of potential values for a variable is small  i.e. less than 1  linear scan suf-
1 	constraint satisfaction fices; for large domains  however  the overhead can be significant due to repetition of scan. 
　in this paper we study how indexing may be utilized by csp algorithms to direct search and avoid linear scan of domains. as an application  we deal with csps  where the values are temporal intervals and the constraints are disjunctions of temporal relations as defined in  allen  1 . such problems may occur in planning or temporal databases. a previous work that uses indexing in temporal databases is  dean  1j. in contrast to our method  where intervals are indexed according to their position in space  that method directs search using a conceptual hierarchical structure  the discrimination tree. algorithms that combine csp search and indexing to facilitate retrieval of structural queries in large spatial databases were presented in  papadias et ai  1 . here  we extend this work by investigating the application of directed search in temporal databases and study the per formance gain of directed search under various problem conditions using different csp algorithms. 
　the rest of the paper is organized as follows. section 1 introduces data structures and search methods for temporal intervals. section 1 shows how conventional methods for solving csps can be modified to accelerate search using indexing. section 1 experimentally compares directed search algorithms with methods that do not use indexing. finally  section 1 concludes the paper with directions for future work. 
1 	temporal csps 
the class of problems that we deal with in this paper includes csps where domain values are well defined intervals in  time  and each binary constraint  is a disjunction of the permissible set of allen's  1  temporal relations between and  notice that the current issue is different from traditional temporal reasoning problems  e.g.  van beek  1j  where the aim is to identify a consistent scenario for a set of continuous variables  given information about their relationships. here  we search into domains of intervals for variable assignments that satisfy the given constraints. 
　this temporal csp can be solved by employing traditional search techniques. each time a variable is visited  


　figure 1: organizing a set of intervals into a 1-d r-tree its whole domain has to be scanned in order to identify consistent assignments. when the variable domains are small  classic csp algorithms behave well  but as the domain size increases  linear scan for consistent values is expensive. 
　csp algorithms can avoid linear scans by employing interval-based data structures that index the variable domains. the search for solutions can be directed upon satisfaction of the temporal constraints  using the data structure to minimize the number of consistency checks. since search through the domains is repeated a large number of times  directed search has a significant effect on performance. 
for the indexing of variable domains we use r-trees 
iguttman  1   a data structure aimed at indexing multidimensional rectangles in spatio-temporal databases. the data rectangles are stored into leaf nodes; each intermediate node contains a pointer to a lower level node and the minimum bounding rectangle of the rectangles in this node. we chose r-trccs because they are becoming a standard in both research and industry  e.g.  lllustra  informix  due to their efficiency  dynamic nature and relatively simple implementation. alternatively  any interval-based data structure  such as interval trees and segment trees  preparata and shamos  1  can be employed. 
　figure 1 illustrates how a 1-dimensional r-trce can be used for interval storage and retrieval  assuming maximum tree node capacity equal to 1. the data intervals  a to k  are stored in the leaf nodes. artificial intervals in the higher tree nodes are formulated by grouping intervals from the level below  e.g.  a b and/are grouped in a . the end points of an intermediate node interval are the leftmost and rightmost end points of the intervals it indexes. the r-tree for a static set of intervals can be built in a bottom-up fashion after sorting them with respect to one end-point  e.g. in this example the left one 

table 1: bounding conditions for intermediate node entries 
{r-tree packing . thus  the r-tree construction for n intervals costs  
　r-trees arc very efficient in answering range intersection queries  i.e.  find all intervals that intersect  share a common point with  a  in addition  the hierarchical nature of r-trec facilitates general selection queries  i.e.  retrieval of intervals that satisfy any temporal condition with respect to a query interval. as an example  consider the query:  find all intervals that start immediately after interval /t applied to the r-tree of figure 1. retrieval starts from the root of the tree; due to the relative positions of b and 1  there can be no interval indexed by the root entry 1 that starts immediately after b. thus the sub-tree under 1 is pruned. on the other hand  entry 1 can contain qualifying intervals and is recursively searched. both entries a and b may point to a query answer and they arc followed; the only solution is interval c. typically  the retrieval cost is proportional to the number of solutions; when this is small  worst case performance is logarithmic to the number of stored intervals.  be a query interval; table 1 
shows  for each temporal relation  the bounding conditions that an  intervalshould satisfy in order to potentially point to a query answer  this is the criterion of following an r-tree node during retrieval. 
in the previous example the intermediate nodes to be searched should satisfy and 
　　　　　　　　　　　　　　intermediate interval 1 is pruned because it violates when the query is a disjunction of temporal relations  the disjunction of the bounding conditions is applied during search. for instance  if the search predicate is starts  during  finishes  the bounding conditions for an intermediate level 
	mamoulis and papadias 	1 

entry / are  and  although for the examples throughout the paper we use the tree of figure 1  for our implementation we assume that each variable domain is different and indexed by a separate rtree. the next section describes algorithms that use these indexes to prune the search space  the methods can be easily applied when some domains/trees are common . 
1. directed search for temporal csps 
classic local consistency methods  like arc and path consistency  perform well for small domains  because in this case there is a high probability that a value will be pruned. however  for large variable domains and dense constraint graphs usually they do not pay-off. therefore  we do not consider conventional local consistency methods for pre-processing  but apply the temporal network maintenance algorithm from  allen  1 prior to search in order to infer undefined constraints and refine the existing ones. this is equivalent to a path consistency algorithm that does not check value consistency  but constraint graph consistency  and its complexity is  therefore  independent from the domain sizes. for instance  consider a constraint graph of three variables  where = meets  = during  and is undefined. the implied constraint is then overlapstarts  during. if  was defined  then the updated constraint is  
 notice that this reasoning 
method detects inconsistency prior to search  e.g. when 

　　efficiency of csp search depends on the order by which variables are instantiated  dechtcr and meiri  1 . the usual rule for static variable ordering  svo  schemes is to ''place the most constrained variable first . a simple way to apply this rule is to sort the variables in decreasing order of their degree in the constraint graph. since in our problem the constraint edges do not have the same tightness  we follow another method: instead of  adding 1  for each edge that goes out from a variable  we add a weight that represents the tightness of the constraint edge. for a temporal relation weight r  is the inverse of the probability1  that will be satisfied between two arbitrary intervals. in typical cases  the relation with the largest weight is equal  and the relations with the smallest  before and after. if a constraint is a disjunction of primitive relations  the weight is the inverse sum of the relation weights that participate in the disjunction  e.g.  

the weight of a variable is then the sum of the weights of all constraint edges adjacent to it. svo will instantiate the  heaviest  variable first and the one with the smallest weight last. whenever dynamic variable ordering  dvo  
1  the probabilities of temporal relations can be estimated cither by sampling the input data  or by using probabilistic estimation formulae given the distribution of interval positions and sizes. 
1 	constraint satisfaction 
is employed  the above method is used to find the variable with the largest weight and place it first. the order of subsequent variables is dynamically changed according to their domain sizes during search. 
1 	directed search backtracking 
integration of directed search into backtracking  is rather simple. whenever a variable  is visited  its consistent values are retrieved from the corresponding rtree by applying the instantiations of the previous variables as query intervals  and the constraints as retrieval conditions. during retrieval  the conjunc-
tion of bounding conditions  defined by each  direct the search at intermediate r-tree levels. at the leaf level  the entries that satisfy the constraint with each variable  are retrieved as consistent values for  
　　to clarify the retrieval procedure  consider the following example. let the query overlapped by and the instantiations in 
figure should overlap to the right and to the left . in order to retrieve all consistent values for first the bounding conditions  bc  according to and are calculated using table 1; and and  
       the conjunction of the above constraints results in the bounding conditions   used to guide r-tree search. retrieval starts from 
the root  where entry 1 is pruned as it docs not satisfy 
 similarly  entry a violates and the sub-tree below is pruned. only intervals under 
entry b can satisfy both and 	finally  	and 	 
constitute the consistent assignments for notice that the whole process costs 1 consistency checks at the intermediate levels and 1 at the leaf level  each interval under b is tested against both  and  whereas a linear scan would cost 1 consistency checks. 
　the above method can be applied with alternative forms of backtracking  e.g.  backjumping  dynamic backtracking  using information about nogoods. in the next subsection we illustrate how forward checking can employ the index to prune the domains of future variables. 
1 	directed search forward checking 
 after a variable instantiation  forward checking  fc  marks in the domains of all future variables the values that are consistent with the current variable  checkforward . when a subsequent variable is to be instantiated only the marked values will be considered. this marking mechanism can be thought of as a linear index in the variable domain that points to the consistent values. assume that an intermediate variable is being instantiated. the domain of each future variable has already been pruned by the instantiation of variables before v . as the linear indexes of some variables may still be large  check-forward during instantiation of  can be rather costly. for these variables we apply directed 

search using the r-tree and filter the results using the linear index. filtering with respect to the linear index is needed  because directed search is performed on the whole domain  i.e.  an interval which satisfies the current constraint with  may have been pruned out by a previous instantiation . the issue to be investigated is when to apply directed search instead of linear scan. 
　a good heuristic is to employ directed search at a future variable only when the number of remaining consistent values is large  and the search constraint is tight  so the search would benefit from the r-tree. for example  let  = before and  = equal. after  is instantiated  directed search is applied to prune the domains of and 
 when  is given a value it is worth applying directed search again while checking forward for consistent values of  because the domain of  is still large and is a tight constraint. the results of directed search that do not satisfy before with respect to the value of are filtered out. now let and after  is given a value  the domain of is expected to be-
come very small; thus  during instantiation of linear scan of  is cheaper than using the tree. 
　this mechanism is called a double index  in the sense that we keep both the whole domain r-tree and the linear index of consistent values and use either both  or only the linear index. directed search is applied when the expected number of values that satisfy the search conditions is smaller than the number of values in the linear index. the number of retrieved values is estimated using the temporal relation probabilities. for instance  if  = 
 = 1 and  then 1 inter-
vals in the domain of  are expected to be consistent with the value of a previous variable  if while instantiating  the remaining consistent values of  from former checks is smaller than 1  linear scan at  will be preferred to directed search. 
　alternatively  versions of the variable r-trces could be maintained at each instantiation level  where only consistent values would remain in the data structure  and search could be performed at each check-forward. we do not use this method because dynamic operations on data structures  i.e. insertion  deletion  construction  are usually expensive. 
1 	experiments 
in this section we compare the performance of directed 
bt  and  with plain versions of the algorithms based on linear scan. fc and dirfc use the   ff   heuristic  haralick and elliot  1j. bt and dirbt apply the  heuristic described in section 1  because  as suggested in  bacchus and van run  1   bt with  does at least as much work as 
fc with dvo  thus it is just a  algorithm with redundant checks. 
　the problems were randomly generated by modifying the parameters  see  dechter and meiri  
1    where is the number of variables   the cardinality of the domains  the probability that a random pair of variables is constrained  constraint network density   and  the probability that a random assignment for a constrained pair is inconsistent  constraint tightness . the centers of the intervals in the variable domains are uniformly distributed and their sizes take values with an average  of the workspace. the intervals in each domain are indexed by r-trees with node capacity equal to 1. 
　in order to identify the hard region of the problems we use the constrainedness measure  gent el al.  1 : 
		 1  
the hard region for an ensemble of problems is when whereas problems with and  are easy and soluble and easy and insoluble  respectively. the denominator of eq.  1  denotes the size of the problem and sol denotes the number of solutions in a random problem of the class. if the binary constraints are independent  sol can be estimated by: 
	 1  
where pic     as described in the previous section  is the probability that two intervals from and  satisfy the first product in  1  corresponds to the total number of  of intervals  while the second one to the probability that a tuple constitutes a solution. for acyclic networks the constraints are independent and  1  will give a good estimation of the problem solutions. when cycles exist the constraints are no longer independent  but applying  1  for the minimum spanning tree of the graph  w.r.t. the constraint tightness  will give an overestimation of the expected solutions. 
　we first tested the performance improvement achieved by the path consistency  pc  method of section 1 for 
acyclic networks  by running experiments for w=1 and m=1  and several values of p1 around the hard region. for each value of p1 we solved an ensemble of 1 problems and measured the average cost for finding one solution. usually  random csps are generated with every constraint having exactly the same tightness. because this cannot be done for the current problem  we chose disjunctions of temporal relations which may be different for each constraint  but have average tightness the target value  
the hard region is w h e n t h i s large value of  is due to the large domain size and the sparseness of the graph. in general  problems with sparse graphs are easy  dechter and pearl  1  and the few 
	mamoulis and papadias 	1 

figure 1: comparison of directed and plain search for cliques 
existing constraints must be very tight in order to generate a small number of solutions. 
　figure 1 shows the cost  in terms of consistency checks1  of directed search bt and fc  with and without pc. the dotted vertical lines include the phase transition  i.e. the first ensemble that included an insoluble problem  left line  and the last ensemble that included a soluble one  right line . as expected  the performance gain of pc is significant since the inferred constraints drastically prune the search space. in the sequel we use pc for both directed search and plain versions of the algorithms. the nearest point to 1% solubility  crossover point  was at p1 = 1  k= 1   where 1% of the problems were soluble. 
　the second set of experiments compares the cost of directed versus undirected search for tree  and clique  graphs. the experimental settings are the same as in the previous experiments  n=1 and m=1; each ensemble contains 1 problems for each value of  around the hard region . figure 1 illustrates the cost 
for tree graphs. the directed search versions outperform the original algorithms by more than one order of magnitude. tree constraint graphs can alternatively be solved by the application of arc consistency prior to search. 
  we consider as consistency checks the comparisons that take place at all levels of the r-trees. 
1 	constraint satisfaction 
figure 1: performance gain of dirfc for various domain sizes 
which would lead to backtrack-free search  dechter and pearl  1j. this method is also expected to profit from indexing. 
　for cliques  the hard region cannot be estimated using  1   due to the dependency of the constraints. in order to identify it  we experimented with various values of p1. the diagram of figure 1 illustrates the behavior of algorithms for a wide scope of tightness values. notice that the hard region corresponds to a larger range of  than in the case of tree graphs. while the cost difference between directed and regular versions of the algorithms is again about an order of magnitude for large  their performance converges as the constraints become loose. when  most of the constraints contain relations before or after. on the average  each such constraint prunes out around  of the values in a domain  and directed search is only about twice as fast as linear scan. 
　as a general conclusion  the performance gain of directed search in comparison to linear scan grows with the constraint tightness  dirfc is  as expected  more efficient than dirbt due to its relevance with fc which in most cases outperforms bt. in the sequel we focus on the performance gain of dirfc with respect to fc for various problem settings. 
　the next experiment compares fc and dirfc for n=1  clique topology  and various values of m and  figure 1 shows how many times dirfc is faster than fc  average 

of 1 instances per experimental setting . the gray horizontal lines present the phase transition for each  and the symbol on the line indicates the position of the crossover point. with the exception of and very small tightness values dirfc outperforms fc several times. for small domains the constraints should be very tight in order for the intermediate r-tree node comparisons to pay-off. however  directed search is intended for large domains  e.g.  in spatio-temporal databases the cardinality often exceeds 1    and in such cases the performance gain is significant. for this experiment  we limited m to 1  so that fc could terminate in reasonable time. 
#vars p%soluble fc dirfc gain 1 1 
1 1% 1 1 1 1 1 1% 1 1 1 1 1 1% 1 1 1 1 1 1% 1 1 1 1 1 1% 1 1 1 table 1: performance gain of dirfc compared to fc for various number of variables 
in order to test the implication of the number of variables  we fixed w=1   to be around the crossover point  the graph topology to clique  and generated 1 random problems for several values of table 1 presents  for each ensemble  the value of the percentage of soluble problems  and the mean consistency checks of fc and dirfc. the last row of the table shows how many times dirfc was faster than fc. as the number of variables increases  the value of  at the crossover point decreases. as a result  the costs of dirfc and fc converge due to the relaxation of constraints which deteriorates r-trce search  making it comparable to linear scan. 
1 	discussion 
this paper studies a specific csp problem  where variable domains are large collections of well defined intervals and constraints are temporal relations. we show how systematic csp algorithms can take advantage of indexing to accelerate search. although we experimented with two representative algorithms  chronological backtracking and forward checking  directed search can be applied with a variety of algorithms and heuristics  e.g. arc consistency . in typical database applications  where m is in the order of 1 or above and the performance gain of directed search is large. 
　　application of data structures is not limited to the temporal csp discussed here. any problem  where variables have large domains and the nature of constraints facilitates directed search  can benefit from it. this particularly applies for spatial and multimedia databases where several types of content-based queries can be modeled as csps  e.g.  find all triplets of ob-
jects such that is inside  and 	is northeast of 
an alternative approach that solves the above problem by hierarchically applying csp algorithms at each r-tree level is described in  papadias et al.  1 . 
acknowledgement 
this work was supported by grant hkust 1e from hong kong rgc and grant dag1.eg1. 
