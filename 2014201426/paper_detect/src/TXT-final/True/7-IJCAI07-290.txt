 
question paraphrasing is critical in many natural language processing  nlp  applications  especially for question reformulation in question answering  qa . however  choosing an appropriate data source and developing effective methods are challenging tasks. in this paper  we propose a method that exploits encarta logs to automatically identify question paraphrases and extract templates. questions from encarta logs are partitioned into small clusters  within which a perceptron classier is used for identifying question paraphrases. experiments are conducted and the results have shown:  1  encarta log data is an eligible data source for question paraphrasing and the user clicks in the data are indicative clues for recognizing paraphrases;  1  the supervised method we present is effective  which can evidently outperform the unsupervised method. besides  the features introduced to identify paraphrases are sound;  1  the obtained question paraphrase templates are quite effective in question reformulation  enhancing the mrr from 1 to 1 with the questions of trec qa 1. 
1 introduction 
paraphrases are alternative ways of conveying the same information. in recent years  there has been growing research interest on paraphrasing since it is important in many nlp applications  including multi-document summarization  qa  text generation  and machine translation. 
　question paraphrases  as a sub-class of paraphrases  are formally distinct questions that actually mean the same thing and have the same answer. question paraphrasing is crucial in the question reformulation phase of a qa system. if an input question can be expanded with its various paraphrases  the recall of answers can be improved. 
　compared with declarative sentences  questions contain some additional information  such as question words  ques-
                                                 

 this work was finished while the first author was visiting microsoft research asia as a member of the project of askbill chatbot led by dr. ming zhou. 
tion types and focuses. these are all indicative features when identifying question paraphrases. thus  a method specially designed for question paraphrasing is worthy of study. 
　question reformulation in qa has been widely researched. some researchers have written reformulation templates manually  brill et al.  1 . others have expanded questions using dictionaries such as wordnet  hovy et al.  1 . some researchers have used the web as a resource for question reformulation  yang et al.  1 . although employing various reformulation methods  all the above researches have verified the effectiveness of question reformulation. 
　this paper exploits a new resource  the encarta logs  for question paraphrasing. an automatic method is designed to process the logs and identify paraphrases  including question classification  question partition  and paraphrase identification using a classifier. in recognizing paraphrases  some novel features are presented. especially  user click information is used  which proves effective in experiments. 
　templates are extracted from the derived question paraphrases and applied in question reformulation. experiments show that the templates achieve wide coverage when tested on a trec-qa question corpus  demonstrating that the encarta log data is a good resource to learn question paraphrase templates. experiments also show that the extracted templates are quite effective in question reformulation. 
　the remainder of the paper is organized in this way: section 1 introduces related work. our method of question paraphrasing is presented in section 1. experiments and results are described in section 1. section 1 is the conclusion and discusses future work. 
1 related work 
various resources have been employed for paraphrase extraction. one resource is parallel monolingual corpus  such as multiple translations of literary works  barzilay and mckeown  1 . while the translation-based methods facilitate the identification of paraphrases  such corpora are of limited availability since multiple translations on a large scale are not readily available in non-literary domains. 
　other researchers exploit nonparallel monolingual corpora. lin and pantel  1  discovered paraphrases by parsing a large unlabeled monolingual corpus and extracting semantically similar paths from dependency trees. the disadvantage is that  only the templates with two arguments are considered. another kind of nonparallel monolingual resource is the comparable news articles that report the same events  shinyama et al.  1; barzilay and lee  1 . the assumption behind it is that articles derived from different newspapers can contain paraphrases if they report the same event on the same day  shinyama et al.  1 . however  these methods seem to be of limited generality and difficult to be extended to other domains. 
　bannard and callison-burch  1  have sought to derive paraphrases from parallel bilingual corpora. they equated different english phrases aligned with the same phrase in another language based on the assumption that phrases mapped onto a single foreign language phrase tend to mean the same thing. though this is a promising method  its performance depends greatly on word alignments. 
　none of the resources above are suitable in question paraphrasing because of domain limitation as well as the sparseness of question sentences. in contrast  encarta logs are not domain limited  the queries in which can be about any topic. in addition  a sizable corpus of questions can be easily constructed from encarta logs. 
　there is very limited work reported on question paraphrasing. tomuro  1  employed an faq corpus and defined patterns manually for question paraphrasing. compared with faq corpora  encarta logs supply additional information  i.e. the user click information  which proves a good indicator of paraphrases in our experiments  described in section 1.1 . another difference from tomuro's method is that our method identifies question paraphrases and extracts templates automatically. 
1 our approach 
the method comprises five steps:  1  extracts questions from encarta logs;  1  classifies the extracted questions according to question types;  1  partitions the classified questions into fine-grained clusters;  1  identifies paraphrases from all question pairs within each cluster;  1  extracts templates from the identified paraphrases. 
1 question extraction 
encarta is an online encyclopedia  http://encarta.msn.com . encarta logs are user logs containing queries and documents that users clicked on for review. a small segment of encarta logs is shown in figure 1. for each line  a query session   the first half is a query. the codes following the query  separated by  #   are ids of clicked documents. 
......
plant cells: #1 malaysia: #1 #1 rainforests: #1 #1 #1 what is the role of a midwife: #1 
......
figure 1. encarta logs 
　the encarta logs have been used for query clustering  wen et al.  1   in which the user click information proved a helpful feature. encarta log data used in our experiments contains 1 1 query sessions. though the number of logs is substantial  most of them are keywords or phrases rather than well-formed questions. therefore  we need to filter the query logs and only retain questions. here  simple heuristic rules are used: a query is recognized as a question if it contains three words or more  and a question word  i.e. who  what  when  where  why  and how .
　note that  in fact not all questions contain question words. for example   name a stimulant.  is a question from trec-qa which contains no question word. currently  we do not process this kind of questions since it is difficult to differentiate them from declarative sentences. future work may apply our method to these questions. 
　after extracting questions using the above method  a corpus containing 1 questions is constructed. in what follows  this corpus is called  question corpus . 
1 question type classification 
in principle  any pair of questions in the question corpus should be considered when identifying paraphrases. however  the corpus contains over 1 questions  it is infeasible to identify paraphrases for each pair of questions. therefore  a two-step process  involving question type classification  described in this section  and question partition  in section 1   is employed to divide the whole corpus into thousands of small clusters and the identification of paraphrases is performed within each cluster. 
　the question type is an important attribute of a question  which usually indicates the category of its answer. in qa  question type classification is a necessary preprocessing stage. table 1 shows a widely accepted question type taxonomy in qa  li and roth  1 . 
abbreviation  explanationanimal  body  color  creative  currency  disease  event  food  instrument  language  letter  other  plant  product  religion  sport  substance  symbol  technique  term  vehicle  worddefinition  description  manner  reasongroup  individual  title  human-descriptioncity  country  mountain  other  statecode  count  date  distance  money  order  other  period  percent  speed  temperature  size  weighttable 1. question type taxonomy 
　based on the observation that two questions with different question types can hardly be paraphrases  questions in the corpus are first classified into 1 different types  table 1 . our question classification method is similar to that introduced by metzler and croft  1 . we also build a two-level classifier. at the first level  questions are divided into six sets. each set corresponds to a type of question word  i.e. who  what  when  where  why  and how . at the second level  a support vector machine  svm  classifier based on the taxonomy in table 1 is trained for each set using the words as features. when classifying new questions  the process closely mimics the training steps. given a new question  its question word is first identified. a feature vector is then created using the same features as in the training. finally  the svm corresponding to the question word is used for classification  metzler and croft  1 . 
　the reason why a two-level classifier is employed is that the question words are prior knowledge and imply a great deal of information about the question types. a two-level classifier can make better use of this knowledge than a flat classifier that uses the question words simply as classification features. the training and testing data are the uiuc corpus  li and roth  1  and the trec-1 questions. the experimental result shows that the classifier can achieve a classification accuracy of 1%. 
1 question partition 
in this stage  questions in each of the 1 classes are further partitioned into more fine-grained clusters. in this work  the paraphrases that have no common words are not considered. 
　formally  given a content word  non-stopword  w  all questions within each question class that contain w are put into the same cluster  we may take it that this cluster is  indexed  by w . apparently  if a question contains n different content words  it will be put into n clusters. after this process  the 1 classes obtained in the last step are further partitioned into about 1 clusters. 
　the question partition approach will be improved in future  in which two questions will be put into a same cluster if at least one pair of their content words are identical or synonymous. 
1 question paraphrase identification 
1.1 feature selection 
at this step  a classifier is used to identify paraphrases within the clusters obtained at the last step. if a cluster has n questions  n* n-1 /1 question pairs are generated by pairing any two questions in the cluster. for each pair  the classifier learns whether they are paraphrases  classifier outputs 1  or not  classifier outputs -1 . 
　there are other researchers taking paraphrase identification as a problem of classification  brockett and dolan  1 . however  different features are used. the following are the features used in our work. 
cosine similarity feature  csf : the cosine similarity of two questions is calculated after stemming and removing stopwords. suppose q1 and q1 are two questions  vq1 and vq1 are the vectors of their content words. then the similarity of q1 and q1 is calculated as in equation  1 . 
       sim q1 q1   cos vq1 vq1          1 
where . . denotes the inner product of two vectors and . denotes the length of a vector. 
named entity overlapping feature  nef : since named entities  e.g. person names  locations  time...  should be preserved across paraphrases  shinyama et al.  1   the overlapping rate of named entities in two questions is selected as a feature. the overlapping rate of two sets can be computed as in equation  1 : 
            or s1  s1              1 
max | s1 | | s1 | 
where s1 and s1 are two sets. |.| is the cardinality of a set. user click feature  ucf : it is easy to understand that if two questions often lead to the same document clicks  then these two questions tend to be similar  wen et al.  1 . the feature of user click similarity of two questions is calculated using equation  1 : 
	rd q1 q1 	      1 
simuser   click  q1 q1  max rd q1  rd q1  
where rd .  is the number of clicked documents for a question and rd q1 q1  is the number of document clicks in common. 
wordnet synonyms feature  wsf : the pair of questions is expanded with the synonyms extracted from wordnet synset entries. specifically  a question q can be expanded to q'  which contains the content words in q along with their synonyms. then for the expanded questions  the overlapping rate is calculated and selected as a feature. unmatched word feature  uwf : the above features measure the similarity of two questions while the unmatched word feature is designed to measure the divergence of two questions. given questions q1  q1 and q1's content word w1  if neither w1 nor its synonyms can be found in q1  w1 is defined as an unmatched word of q1. we calculate the unmatched rate as in equation  1  and use it as a feature. 
         ur q1 q1   max ur q1  ur q1            1  where ur .  denotes the percentage of unmatched words in a question. 
syntactic similarity feature  ssf : in order to extract the syntactic similarity feature  the question pairs are parsed by a shallow parser whereby the key dependency relations can be extracted from a sentence. four types of key dependency relations are defined: sub  obj  attr  and adv. for example  for the question  what is the largest country   the shallow parser will generate  what  is  sub    is  country  obj    largest  country  attr  as the parsing result. as can be seen  the parsing result of each question is represented as a set of triples  where a triple comprises two words and their syntactic relation. the overlapping rate of two questions' syntactic relation triples is computed and used as their syntactic similarity. 
question focus feature  qff : the question focus can be viewed as the target of a question. for example  in the question  what is the capital of china   the question focus is  capital . obviously  two questions are more likely to be paraphrases if they have identical question focus. currently  the question focuses are extracted using predefined rules. the qff feature has a binary value  namely  1  two questions have identical question focus  or 1  otherwise . translation similarity feature  tsf : translation information proves useful in paraphrase identification  wu and zhou  1 . in our experiments  google online translation  http://translate.google.com/translate t  is called to translate each english question into chinese. then the cosine similarity of the translations of two questions is calculated. 
1.1 paum classifier 
it is found in the experiments that the input data for the paraphrase identifier is rather unbalanced  in which  only a very small proportion of the question pairs are paraphrases. the methods dealing with classification with unbalanced data include the positive example based learning  pebl   one-class svms and perceptron algorithm with uneven margins  paum . among these methods we use paum in our experiments  li et al.  1 . paum is an extension of the perceptron algorithm  which is specially designed to cope with two class problems where positive examples are very rare compared with negative ones  as is the case in the paraphrase identification task. paum considers the positive and negative margins separately. the positive  negative  margin 1 w b z is defined as: 
           	1 w b  z 	min	  w xi	b             1  
	 xi   1  z	w
where z   x1  y1  ...  xm  ym      { 1  1} m is a training sample. : rn is a feature mapping into an n-dimension vector space . xi  xi   . w  b r are parameters. . . denotes the inner product in  
1 template extraction 
templates are extracted from the derived question paraphrases. there is some research work on paraphrase template generation  barzilay and lee  1 . in our work  we use a simple method to extract templates. a better method will be presented in future. 
　as mentioned above  paraphrases are identified from each cluster in which a common content word w is shared by all questions. hence  the paraphrase templates are formalized by simply replacing the index word w with wildcard  * . for example  the questions  what is the length of nile   and  how long is nile   are recognized as paraphrases from the cluster indexed by  nile.  then the paraphrase template  what is the length of *  how long is *  is induced by replacing  nile  with  *.  
1 evaluation 
to evaluate the effectiveness of our method  three experiments are carried out. the first one is designed to evaluate the paraphrase identifier  especially feature selection. the second experiment evaluates the performance of the whole paraphrase acquisition process  which includes question type classification  question partition  and paraphrase identification. the third is designed to verify the usefulness of the generated templates in question reformulation. 
1 evaluation of paraphrase identifier 
1.1 data 
as mentioned in section 1.1  the paraphrase identifier is a paum classifier. in order to train and test the classifier  we extracted 1 question pairs from the question corpus and annotated them manually. the resulting data is extremely unbalanced  which contains 1 positive  paraphrases  and 1 negative  non-paraphrases  examples. in the experiment  1  1 positive and 1 negative  of the data is used in training while 1  1 positive and 1 negative  is left for testing. 
1.1 performance of the identifier 
in this experiment  the precision and recall of the identifier are computed. given that scp is the set of paraphrases automatically recognized by the identifier; smp is the set of paraphrases manually annotated. then precision and recall are defined as in equations  1  and  1 : 
         precision | | scp |            1            recallmp |             1 
　the classification margins in a paum classifier can be adjusted so as to get different trade-offs between precision and recall. in most applications of the paraphrase templates  precision is more important than recall. for instance  in question reformulation of qa  a false expansion might do more harm than good  since it may bring about noise and lead to incorrect answers. therefore  when setting the classification margin parameters  many different combinations have been tried on a small development set and ultimately we set positive margin parameter 1 and negative margin parameter 1  which are deliberately skewed towards precision. experimental results show that the precision and recall are 1% and 1%  respectively. 
1.1 feature contributions 
to investigate the contributions of different features  we omitted each feature from several runs. the results are shown in table 1. 
 
 precision %  recall %  all features 1 1 no csf 1 1 no nef 1 1 no ucf 1 1 no wsf 1 1 no uwf 1 1 no ssf 1 1 no qff 1 1 no tsf 1 1 table 1. effect of eliminating each feature 
 
table 1 shows that eliminating the features csf  ucf  ssf  qff  and tsf can all produce a notable degradation in precision while eliminating the uwf feature can have large impact on recall. of all the features  removal of the feature wsf appears to have the least impact. the reason may be that the wordnet synonyms used in wsf are also used in the feature uwf  which makes the wsf feature redundant. besides  the effect of nef feature is also small. in our future work  the ne information will be used in preprocessing. specifically  only the question pairs with identical nes are retained and identified by the paraphrase identifier. 
　in particular  we can see that feature ucf improves the precision evidently  which indicates that the user click information is an effective constraint in paraphrase identification. figure 1  a  shows an example of non-paraphrases that only can be identified correctly when the ucf feature is considered. as can be seen  the two questions are differentiated by their user clicks though they are highly similar at string level. figure 1  b  shows an example of paraphrases that only can be recognized when the ucf feature is used. evidently  it is the identical user click that makes it possible to identify these two formally distinct questions. however  it can be seen from table 1 that the ucf feature only makes a slight improvement in recall. we conclude that the calculation of the user click similarity should be improved so as to enhance the recall. since documents in encarta are organized into a hierarchy that contains four levels  the hierarchy of logs will be taken into account in our future work. 
 
 a  where can i find information on automobiles #1
where can i find information about 1's automobiles #1 
 b  when did florida become a state: #1 
when did florida join the united states: #1 figure 1. examples that benefit from ucf feature 
1.1 comparison of feature selection approaches 
 brockett and dolan  1  used different features in their svm classifier to identify paraphrases from related news sentences. four feature classes are involved in their work  including string similarity features  morphological features  wordnet lexical mappings  and word association pairs. to compare our feature selection strategy with theirs  we have tested their features on the question corpus in our experiments. the comparison result is in table 1: 
 
 precision recall ours 1% 1% b & d 1% 1% table 1. comparison of feature selection approaches 
 
　as can be seen  our feature selection dramatically outperforms that of  brockett and dolan  1  on the question corpus. this shows that the feature set we have designed is more effective in indicating question paraphrases. 
1 evaluation of the whole method 
in the last section  the paraphrase identifier is evaluated. in this section  the paraphrasing method  including question type classification  question partition  and paraphrase identification  is evaluated as a whole. question classification and partition divide the large question corpus into many small clusters  which makes it feasible for the identifier to detect paraphrases. however  they also bring about lost. thus our main purpose is to evaluate the effect of these two stages. 
　to evaluate the performance of paraphrase acquisition  we randomly selected 1 questions from the question corpus  from which 1 pairs have been manually annotated as paraphrases. the 1 questions are first classified by question types. after that  further partition is done within each class as described in section 1. finally the paraphrase identifier is employed in each cluster to detect paraphrases.  
　after the above process  1 pairs of questions are recognized as paraphrases  of which 1 pairs are true paraphrases  which overlap with the 1 hand-tagged ones . 
precision and recall are 1% and 1%.  
　compared with the result shown in table 1  precision decreases from 1% to 1% and recall decreases from 1% to 1%. there are two main reasons for the notable decreases. one is that the question classification and partition bring about mistakes. especially  some paraphrase pairs are divided into different classes or clusters; the other reason is the irregularity of the encarta logs. there are many spelling mistakes in the logs.  e.g.  egyptian  was written as  egyption   these mistakes influence the calculation of similarity and the performance of paraphrase recognition. additionally  the questions from the encarta logs are quite flexible in expression  some of which are even ungrammatical. e.g.  russia what do they wear     atomic bomb dropped on hiroshima why   and the like. for these questions  the extraction of question focuses and the recognition of syntactic relations are extremely difficult  which makes the ssf feature and the qff feature fail to work. 
　we also compared our method with the unsupervised method presented by wen et al. . in their method  they clustered query logs using a density-based clustering method. they combined similarity based on query contents and that based on user clicks in clustering. in our experiment  the minimal density parameter was set to 1  which means that only those clusters containing at least 1 queries were kept. then we varied the similarity threshold from 1 to 1. the performance is shown in table 1. 
 
threshold precision recall 1 1% 1% 1 1% 1% 1 1% 1% 1 1% 1% table 1. performance of the clustering method 
 
　as can be seen  both the precision  1%  and recall  1%  of our method are much higher than the clustering method  which indicates that the supervised method presented in this paper is more effective than the unsupervised method in recognizing question paraphrases. 
1 evaluation of templates in qa 
to evaluate the templates in question reformulation  1 factoid questions from trec-1 qa track are used. of the 1 questions  1  1%  are matched with the extracted templates and reformulated while the left 1 questions are not reformulated.  
　since we have not built a trec qa system at this point  we evaluate the reformulation templates using a web qa method. specifically  for each question  top 1 web snippets are retrieved by google and mean reciprocal rank  mrr  is used in the evaluation of question reformulation  wang et al.  1 . mrr is defined as follows: 
1 n
                   mrr                1 
n i 1 i
where n is the number of questions and ri is the rank of the first correct answer occurring in the top 1 retrieved snippets for the i-th question.  
　we compare the mrrs before and after question reformulation on the 1 template-matched questions as well as the total 1 questions. the comparison result is in table 1. 
mrr  before reformulation  mrr 	 after 
formulation  re-1 questions 111 questions 11table 1. mrrs before and after question reformulation 
　table 1 shows that question reformulation using the extracted paraphrase templates enhances mrr dramatically  which suggests that question reformulation based on paraphrase templates can make correct answers rank higher in the retrieved snippet lists. this result demonstrates that our question paraphrasing method is effective in qa. 
1 conclusion
this paper presents a novel method to automatically extract question paraphrases from encarta logs and generate templates for question reformulation. our contribution is that  a new data source  namely  the encarta log data is exploited to learn question paraphrases. the process for extracting paraphrases  including question type classification  question partition  and paraphrase identification  proves effective. different features from all possible constructs are tested and the most effective combination of features is identified. specifically  we introduce new features such as the user click feature in question paraphrase identification. 
　the generated templates also prove effective in question reformulation  leading mrr to grow from 1 to 1 with the questions of trec qa 1. 
　in the future work  we shall make better use of the user clicks from encarta logs for paraphrase identification. besides  we will evaluate our method on trec qa corpus. 
acknowledgments 
we are grateful to yi chen for his help in the experiments. we also thank changning huang  cheng niu  dwight daniels  and wanxiang che for their valuable comments on this paper. 
reference
 bannard and callison-burch  1  colin bannard and chris callison-burch. paraphrasing with bilingual parallel corpora. in proceedings of acl-1  1. 
 barzilay and lee  1  regina barzilay and lillian lee. learning to paraphrase: an unsupervised approach using multiple-sequence alignment. in proceedings of hlt/naacl  1. 
 barzilay and mckeown  1  regina barzilay and kathleen r. mckeown. extracting paraphrases from a parallel corpus. in proceedings of the acl/eacl  1. 
 brill et al.  1  eric brill  susan dumais  michele banko. an analysis of the askmsr question-answering system. in proceedings of emnlp  1. 
 brockett and dolan  1  chris brockett and william b. dolan. support vector machines for paraphrase identification and corpus construction. in proceedings of iwp1  1. 
 hovy et al.  1  eduard hovy  ulf hermjakob  chin-yew lin. the use of external knowledge in factoid qa. in proceedings of trec-1 conference  1. 
 li and roth  1  xin li and dan roth. learning question classifiers. in proceedings of the 1th international conference on computational linguistics  1. 
 li et al.  1  yaoyong li  hugo zaragoza  ralf herbrich  john shawe-taylor  jaz s. kandola. the perceptron algorithm with uneven margins. in proceedings of icml 1  1. 
 lin and pantel  1  dekang lin and patrick pantel. discovery of inference rules for question answering. in natural language engineering 1 :1  1. 
 metzler and croft  1  donald metzler  w. bruce croft. analysis of statistical question classification for fact-based questions. information retrieval 
1 :1  1. 
 shinyama et al.  1  yusuke shinyama  satoshi sekine  kiyoshi sudo and ralph grishman. automatic paraphrase acquisition from news articles. in proceedings of hlt  1. 
 tomuro  1  noriko tomuro. interrogative reformulation patterns and acquisition of question paraphrases. in proceedings of iwp 1  1. 
 wang et al.  1  yi-chia wang  jian-cheng wu  tyne liang  and jason s. chang. web-based unsupervised learning for query formulation in question answering. in proceedings of ijcnlp  1. 
 wen et al.  1  ji-rong wen  jian-yun nie  and hong-jiang zhang. query clustering using user logs. acm trans. information. systems. 1 : 1  1. 
 wu and zhou  1  hua wu and ming zhou. synonymous collocation extraction using translation information. in proc. of acl-1  1. 
 yang et al.  1  hui yang and tat-seng chua  shuguang wang  and chun-keat koh. structured use of external knowledge for event-based open domain question answering. in proceedings of the twenty sixth annual international acm sigir conference on research and development in information retrieval  1. 
ijcai-1

ijcai-1

ijcai-1

