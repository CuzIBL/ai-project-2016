
this paper develops a statistical inference approach  bayesian tensor inference  for style transformation between photo images and sketch images of human faces. motivated by the rationale that image appearance is determined by two cooperative factors: image content and image style  we first model the interaction between these factors through learning a patch-based tensor model. second  by introducing a common variation space  we capture the inherent connection between photo patch space and sketch patch space  thus building bidirectional mapping/inferring between the two spaces. subsequently  we formulate a bayesian approach accounting for the statistical inference from sketches to their corresponding photos in terms of the learned tensor model. comparative experiments are conducted to contrast the proposed method with state-of-the-art algorithms for facial sketch synthesis in a novel face hallucination scenario: sketch-based facial photo hallucination. the encouraging results obtained convincingly validate the effectiveness of our method.
1 introduction
recently  machine learning becomes more and more popular applied to the computer vision community. various applications and methods that learn low-level vision have been proposed in the classical literature  freeman et al.  1 . in this paper  we focus on a fascinating vision topic: automatic image sketching which automatically generates alike sketch images from photo images. sketches are the simplest form of drawings because they consist of only drawing lines. the artists can distill the identifying characteristics of a photo and highlight them with a small number of critical strokes.
¡¡implementing the great idea of learning vision  successful image sketching techniques try to observe and learn from the artist's works  and hence generate vivid and expressive sketches. as a result  example-based methods are widely studied in the latest years. given a set of training images and their associated sketches drawn by artists  it is of interest to generate a sketch image automatically from an input image with the help of machine learning techniques.
groundtruth 

figure 1: bidirectional transforms on photo-sketch pairs.  a  forward transform: synthesizing a sketch image from a photo image;  b  backward transform: hallucinating a photorealistic image from a sketch image.
¡¡for the particular image class of human faces  the transform between photo-realistic faces and their associative sketch drawings has shown promising applications in the future. in recent years  some works have been done to address the issues of synthesizing sketches from photos  chen et al.  1; tang and wang  1; liu et al.  1a  and sketch-based face recognition  tang and wang  1; liu et al.  1a . however  to the best of our knowledge  a more difficult issue - the backward transform from sketches to photos - has not been seriously addressed. in this paper  we develop a novel research topic: hallucinating photorealistic faces from sketches  which is termed as sketch-based facial photo hallucination. we design a new face hallucination technique to fulfill the intractable backward transform. we also consider the forward and backward transforms together in order to explore the inherent relation between the bidirectional transforms shown in fig. 1.
¡¡considering the complexity of image spaces and the conspicuous distinction between photos and sketches  global linear models such as  tang and wang  1; liu et al.  1a  tend to oversimplify this problem. therefore  we try to extract the local relations by explicitly establishing the connection between two feature spaces formed by a patch-based tensor model. to hold the statistical dependencies between pairwise patches with two styles more precisely and flexibly  we present a bayesian tensor inference approach that incorporates the advantages of multilinear analysis techniques based on tensor into bayesian statistics.
¡¡the rest of this paper is organized as follows. in section 1  we elicit a tensor model for a facial image ensemble. the detailed rationale and algorithm for bayesian tensor inference are presented in section 1. experimental results are shown in section 1 and conclusions are drawn in section 1.
1 tensor model
recently  multilinear algebra and tensor modeling have attracted considerable attention in both computer vision and computer graphics communities. research efforts applying tensor cover a broad range of topics including face modeling and synthesis  vasilescu and terzopoulos  1; wang and ahuja  1; vlasic et al.  1   super-resolution  liu et al.  1b   etc.
¡¡motivated by previous multilinear approaches  we make use of a novel tensor model to exclusively account for the representation of images with two styles: photo-style and sketch-style. as small image patches can account for highlevel statistics involved in images  we take patches as constitutive elements of the tensor model. based on a corpus containing image patches with photo- and sketch-styles  we arrange all these patches into a high-order tensor which will suffice to encodethe latent connectionbetween the two styles.
1 tensorpatches
based on the observation that both styles  i.e. photo- and sketch-styles  share some common characteristics and each style possesses its special traits  we assume the existence of decomposition of the patch feature space into the common variation space  which reflects the commonalitiesshared by both styles  and the special variation space. relying on this rationale  we employ multilinear algebra to perform tensor decomposition on one large patch ensemble carrying two modalities.
¡¡let us divide training pairwise images into overlapping small square patches which are assumed to be of the same size. m pairs of patches within a spatial neighborhoodlocated in images are collected to form a high-order tensor. following the non-parametric sampling scheme  chen et al.  1   we allow m to be smaller than the length of each patch feature vector d. resulting from the confluence of three modes related to patch examples  patch styles and patch features  a 1-order tensor is built by grouping pairwise patches pertaining to the same neighborhood.
¡¡this paper adopts the high-order svd  lathauwer et al.  1  or n-mode svd  vasilescu and terzopoulos  1   both of which are the generalizations of svd  to decompose the higher-order tensor d as follows1
	d	=	c ¡Á1 u1 ¡Á1 u1 ¡Á1 u1
¡¡¡¡¡¡¡¡= c ¡Á1 upatches ¡Á1 ustyles ¡Á1 ufeatures   1  where c  known as the core tensor  governs the interaction between the mode matricesu1 ¡¤¡¤¡¤ un. mode-nmatrix un contains the orthonormal vectors spanning the column space of matrix d n  resulting from mode-n flattening  unfolding  d. defining a tensor t = c ¡Á1 ufeatures as tensorpatches  then we have
	d = t ¡Á1 upatches ¡Á1 ustyles.	 1 
so far  we succeed in decomposing the two-modal patch feature space into the common variation space spanned by
uand the special variation space spanned by u.
¡¡for any patch whether it is photo- or sketch-style  its corresponding tensor representation is
		 1 
where w contains patch parameters encoding the common characteristics of pairwise patches  and sk  capturing style parameters reflecting the special properties of style k  1 denotes photo-style  1 denotes sketch-style   is the k-th row vector of ustyles. when wt is the i-th row vector of upatches  the tensor representation of the i-th training patch with k-th style is obtained. its vector representation can be derived via mode1 or 1  1  flattening the subtensor p  that is   f1 p  t.
¡¡for a new patch pair  x y   x represents the photo-style and y denotes the sketch-style. their tensor representations can be learned in line with eq.  1  by
p x  = t ¡Á1 wt ¡Á1 st1 = a1 ¡Á1 wt
¡¡¡¡¡¡¡¡¡¡p y  = t ¡Á1 wt ¡Á1 st1 = a1 ¡Á1 wt   1  where both are constant tensors. mode-1 flattening eq.  1  results in
x =  f1 a1  t w = axw y =  f1 a1  t w = ayw.	 1 
aand a are called inferring matrices.
the shared parameter vector w  expected to be solved  exists in the common variation space. we solve it through mapping pairwise patches into the common variation space as follows
w = bxx
	w = byy 	 1 
where bx =  atx ax  1atx and by =  aty ay  1aty are called mapping matrices. fig. 1 illustrates the relations among x y w.
¡¡when one of  x y  is unknown  inferring the counterpart style from the known style of a patch is the objective of image sketching or hallucination. combining eq.  1  and eq.  1   a coarse estimation for y can be derived as
	y ¡Ö aybxx 	 1 

figure 1: illustration of relations among common variation space  photo patch space and sketch patch space.
which coincides with the path shown in fig. 1: mapping the  photo patch space  to the  common variation space  from which inferring the  sketch patch space  .
¡¡importantly  the coarse estimation offered by eq.  1  is consistent with sketch synthesis methods  tang and wang  1  liu et al.  1a  under particular conditions. considering  x y  as the holistic photo-sketch image pair of faces  when ax and ay are sample matrices whose columns are vectors recording the training sketch and photo images  eq.  1  is equivalent to the eigentransform method  tang and wang  1  where w contains linear combination coefficients w.r.t. training faces. in the case that ax contains k nearest neighbors of input photo patch x in the training set and bx collects associative sketches of these neighbors  eq.  1  resembles the local geometry preserving method  liu et al.  1a . furthermore  eq.  1  can be thoughtas the unconstrainedsolution of lle  roweis and saul  1  where w is the weighting vector for locally linear reconstruction.
1 tensorpatches for facial image ensembles
due to the structural characteristics of face images  we adopt a higher-order tensor rather than the 1-order tensor modeled on generic images. for the facial image ensemble  it necessitates modeling both global structures and local details of face images together.
¡¡given the multi-factor people  spatial positions of patches  and multi-modal  styles  natures of these patches  we develop a 1-order tensor model to explicitly account for both styles and constituent factors of facial patches. suppose we have n pairs of face images available for training  of which each is divided into m overlappingsquare patches. with two styles  the length of each patch feature vector is d. therefore  patches are influenced by four modes: people  patches  styles and features. a 1-order tensor is naturally built by grouping all photo-sketch patches sampled from the training faces. perform tensor decomposition on d
¡¡¡¡= 1 upeople ¡Á1 upositions ¡Á1 ustyles  where the core tensor c governs the interaction between 1 modes encoded in 1 mode matrices: u 
u and ufeatures ¡Ê   and tensorpatches t is obtained by forming the product c ¡Á1 ufeatures.
¡¡significantly  the two factors  people  position  are crucial to determine a concrete patch and encoded in row vector spaces of mode matrices upeople and upositions. to remove factor  people  position  redundancies and suppress the effects of noise  a truncation of the two mode matrices is needed. in this paper  we adopt the n-mode orthogonal iteration algorithm in  vasilescu and terzopoulos  1  to perform factor-specific dimensionality reduction  outputting converged truncated mode matrices u 
  along with the rank-reduced
approximation of tensor d
	d  = t ¡Á 	1 u  people ¡Á1 u  positions ¡Á1 u  styles.	 1 
¡¡in analogy to the last subsection  for a new patch pair  xj yj  residing in the j-th spatial position of face images  their tensor representations can be derived with the similar form as eq.  1 
	p xj  = t ¡Á 	1 wt ¡Á1 vjt ¡Á1 s1t = a1j ¡Á1 wt
	p yj  = t ¡Á 	1 wt ¡Á1 vjt ¡Á1 s1t = a1j ¡Á1 wt 	 1 
 where vjt and stk is the j-th and k-th row vector of the mode matrix u  positions and u  styles  respectively.	both a1j =  and are constant tensors. the people parameter vector  maintains to be solved for new patch pairs.
mode-1 flattening eq.  1  results in
xj =  f1 a1j  t w = ajxw yj =  f1 a1j  t w = ajyw   1 
where a are position-dependent inferring matrices. note that the people parameter vector w is shared in all patch pairs  appearing in the same person. defining a concatenated photo feature vector ix =  whose sketch counterpart is iy =  and two enlarged md ¡Á r1 matrices
ax =  a1x;¡¤¡¤¡¤;amx   and   we have

ix = axw

	iy = ayw.	 1 
so we can solve the parameter vector w by the least square method
w
	w 	 1 
	t	t
where both ax ax and ay ay are invertible because md    which is always satisfied throughout this paper.
1 bayesian tensor inference
the learned tensor representations eq.  1  model the latent connection between ix and w  or iy and w. the concluded relations eq.  1    1    1   and  1  originate from factor decomposition which is implemented through tensor decomposition. although eq.  1  gives a direct inference from x to y  we lack analysis in statistical dependencies between x and y.
¡¡utilizing the merits of super-resolution techniques  freeman et al.  1; baker and kanade  1   we incorporate the learned relations eq.  1  and  1  in which the tensor model entails into a bayesian framework. the entire inference process is thus called the bayesian tensor inference.
1 formulation
we fulfill the backward transform iy ¡ú ix through the people parameter vector w by taking these quantities as a whole into a global optimization formulation. our inference approach is still deduced from canonical bayesian statistics  exploiting pca to represent the photo feature vector ix to be hallucinated. the advantage of our approach is to take into account the statistics between the latent variable a and ix. we write the eigenface-domain representation after performing pca on the training photo vectors
             ix = ua + ¦Ì + ¦Å ¡Ö ua + ¦Ì   1  where pca noise ¦Å may be ignored. the prior p a  is easier to acquire
¡¡¡¡¡¡¡¡¡¡¡¡¡¡p a  ¡Ø exp{ at¦« 1a}   1  where ¦« is a l ¡Á l diagonal matrix with eigenvalues at its diagonal.
¡¡due to the bayesian map  maximuma posterior criterion  we find the map solution a  for hallucinating the optimal ix  as follows
	a  =	argmaxp w a|iy 
w  a
=	argmaxp iy|w a p w a  w  a
=	argmaxp iy|w p w|a p a .	 1  w  a
we take the statistics between w and iy into considera-

tion. due to the learned relation  see eq. 1   iy = ayw  we assume the representation error of iy w.r.t w is i.i.d. and gaussian. the conditional pdf p iy|w  is thus obtained as follows
	 	 1 
where ¦Ë1 scales the variance in the photo space. in analogy to above  we obtain the condition pdf p w|a  in doing w =

bxix and using eq.  1 

where ¦Ë1 scales the variance in common variation space.
¡¡substituting pdfs given in eq.  1    1   and  1  into eq.  1   maximizing p w a|iy  is equivalent to minimizing the following object function
 1  significantly  function  1  is quadratic  and consequently minimizing it is a quadratic optimization problem  unconstrained  where a globally optimal solution exists.
¡¡taking the derivative of e with respect to w and a respectively  the partial gradients of e can be calculated as
 e
	 
 w
.
by  e/ w = 1 and  e/ a = 1  we obtain a pair of solutions that is unique  and so must be globally optimal. the optimal map solution a  is hereby given as
	 	 1 
where the r1 ¡Á r1 matrix c is predefined as
	c = i  .	 1 
¡¡so far  we accomplish the task of backward transform  i.e. hallucinating the photorealistic photo feature vector ix  = ua +¦Ì givena sketch feature vector iy based on an available set of myriad training photo-sketch image pairs.
1 algorithm
our algorithm tackles the intractable problem: sketch-based facial photo hallucination with a learning-based scheme. there have been several successful relevant efforts on facial sketch synthesis. example-based sketch generation  chen et al.  1  takes pixels as rendering elements  so the computational efficiency is somewhat low. linear methods  tang and
wang  1; liu et al.  1a  tend to trivialize the synthesized results without any statistical consideration. the fact that our work improves upon the existing techniques is that patch-based tensor learning and bayesian inference are coordinated in our algorithm  which is illustrated in fig. 1.
   collect a large corpus of n training facial image pairs  with two styles  and divide each image into m overlapping patches. because the sketch image space and photo image space are disparate in terms of gray-level intensities  to bring the two spaces into correspondence  we use the horizontal and vertical image derivatives as features of both photo- and sketch-style patches for learning the tensorpatches model. concretely  we envision bayesian tensor inference involving two phases: the training and testing phase.
training phase
¡¡1. based on the derivative feature representation  build a 1order tensor on n  m photo-sketch patch pairs sampled from n training image pairs and learn the matrices ay and .
¡¡1. construct concatenated photo feature vectors  and run pca on them to achieve the eigen-system  u ¦«  and the mean vector ¦Ì.

figure 1: architecture of our sketch-based facial photo hallucination approach.  1  learn the tensorpatches model taking image derivatives as features in the training phase;  1  obtain the initial result applying the local geometry preserving method;  1  infer image derivatives of the target photo using the bayesian tensor inference method  given input image derivatives extracted from the test sketch face;  1  conduct gradient correction to hallucinate the final result.
testing phase
¡¡1. for a new sketch image iy  divide it into m patches the same way as in the training phase. using grayscale intensities for image features  apply the local geometry method  liu et al.  1a  to estimate an initial hallucinated result ix1.
¡¡1. construct the concatenated sketch feature vector iy us-

ing m overlapping patches  and exploit it and ay bx u ¦« ¦Ì to inferthe target photo featurevector ix  accordingto eq. 1 .
¡¡1. break ix  into m patches and afterward integrate these patches into two holistic derivative maps ixh and ixv  with pixels in the overlapping area blended.
¡¡1. conduct gradient correction on ix1 using the derivative maps ixh  ixv  i.e. gradient field  to render the final result ixf.
1 experiments
sketches often have many styles  for example  a cartoon sketch often represents a person very exaggeratedly. in this paper  we only focus on sketches of plain styles without exaggeration  as for applications in law enforcement or photo search  no much exaggeration is allowed in sketch images so that the sketches can realistically describe the real subjects. some sketch examples are shown in fig. 1 and fig. 1.
¡¡we conduct experiments on a database over 1 persons of which 1 persons are for training and the rest is for testing. each person has a frontal face photo image and a sketch image with a plain style drawn by an artist. all the training and testing images are normalized by affine transform to fix the position of centers of eyes and mouths. each 1 ¡Á 1 face image is divided into 1 overlapping 1 ¡Á 1 patches in the same way  and the overlap between adjacent patches is three pixels.
¡¡to display the effectiveness of our bayesian tensor inference  we compare it with the representative methods  which have been applied in facial sketch synthesis  including the global method- eigentransform  tang and wang  1  and the local method- local geometry preserving  lgp   liu et al.  1a . fig. 1 and fig. 1 illustrates the results of sketchbased face hallucination for asians and europeans  respectively. in both the two groups of results  patch-based methods  c    d  consistently and notably outperform the global method  b  in high fidelity of local details  which indicates that a local model is more suitable for modeling complex distributions such as images. by comparing the results yielded by lgp  c  and those produced by our method  d   we can clearly see that our inference algorithm performs sharper and more realistic with higher image quality than lgp. one reason is that employing the patch-based tensor model can recover both the common face structure and local details.
¡¡we set the scale parameters ¦Ë1 and ¦Ë1 to be 1 and 1  respectively. we use standard svd to do pca on the training photo feature vectors  with 1% of the eigenvalue total retained. when applying the lgp method to obtain the initial hallucinated result in step 1 of the testing phase  we choose k = 1 to be the number of nearest neighbors.
¡¡from the quantitative perspective  table 1 lists the average root-mean-square pixel errors  rmse  for 1 different methods. the baseline is the nearest neighbor method. as might be expected  the performance of our method does improve as the number of training sample pairs increases from 1  training set i  to 1  training set ii . although the rmse of our method is larger than that of lgp  the hallucinated images look better  as detailed as that in the groundtruthface images. to sum up  our sketch-based face hallucination method acquires the best visually perceptual quality.
table 1: comparison of hallucination methods.
hallucination methodtraining set itraining set iirmsered.rmsered.nearest neighbor1-1-eigentransfrom11%11%local geometry preserving11%11%bayesian tensor inference11%11%1 conclusions
in this paper  we present a statistical inference approach called bayesian tensor inference between the photo patch space and the sketch patch space. based on the principle that only commonalitiescontributeto the inferenceprocess and by virtue of the patch-based tensor model  we capture and learn the inter-space dependencies. the bayesian map framework integrates tensor modeling and statistical optimization to ensure the inference performance of the difficult vision problem: sketch-based facial photo hallucination. the potency of our method is sufficiently shown in the comparative experiments  achieving surprising photo rendering quality.
	 a 	 b 	 c 	 d 	 e 
figure 1: photo hallucination results for asian faces.  a  input sketch images   b  eigentransform method   c  local geometry preserving method   d  our method   e  groundtruth face photos.
	 a 	 b 	 c 	 d 	 e 
figure 1: photo hallucination results for european faces.  a  input sketch images   b  eigentransform method   c  local geometry preserving method   d  our method   e  groundtruth face photos.

acknowledgement
the work described in this paper was fully supported by grants from the research grants council of the hong kong special administrative region and a joint grant  n cuhk1  from hksar rgc and china nsf. the work was done at the chinese university of hong kong.
