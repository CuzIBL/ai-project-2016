 
al research has developed an extensive collection of methods to solve state-space problems. using the challenging domain of sokoban  this paper studies the effect of search enhancements on program performance. we show that the current state of the art in at generally requires a large programming and research effort into domain-dependent: methods to solve even moderately complex problems in such difficult domains. the application of domain-specific knowledge to exploit properties of the search 
space can result in large reductions in the size of the search tree  often several orders of magnitude per search enhancement. understanding the effect of these enhancements on the search leads to a new taxonomy of search enhancements  and a new framework for developing single-agent search applications. this is used to illustrate the large gap between what is portrayed in the literature versus what is needed in practice. 
k e y w o r d s : single-agent search  ida*  sokoban 
1 	introduction 
the ai research community has developed an impressive suite of techniques for solving state-space problems. these techniques range from general-purpose domainindependent methods such as a*  to domain-specific enhancements. there is a strong movement toward developing domain independent methods to solve problems. while these approaches require minimal effort to specify a problem to be solved  the performance of these solvers is often limited  exceeding available resources on even simple problem instances. this requires the development of domain-dependent methods that exploit additional knowledge about the search space. these methods 
can greatly improve the efficiency of a search based program  as measured in the size of the search tree needed to solve a problem instance. 
   this paper presents a study on solving challenging single-agent search problems for the domain of sokoban. 
1 	computer game playing 
sokoban is a one-player game and is of general interest as an instance of a robot motion planning problem  dor and zwiek  1 . sokoban is analogous to the problem of having a robot in a warehouse move specified goods from their current location to their final destination  sul -
ject to the topology of the warehouse and any obstacles in the way. sokoban has been shown to be np-hard  culberson  1; dor and zwick  1 . 
   previously we reported on our attempts to solve sokoban problems using the standard single-agent search techniques available in the literature  junghanns and schaeffer  1c . when these proved inadequate  solving only 1 of a 1-problcm test suite  new algorithms had to be developed to improve search efficiency  junghanns and schaeffer  1b; 1a . this allowed 1 problems to be optimally solved  or nearly so. additional efforts have since increased this number to 1. the results here show the large gains achieved by adding application-dependent knowledge to our program rolling stone. with each enhancement  reductions of the search tree size by several orders of magnitude are possible. 
   analyzing all the additions made to the sokoban solver reveals that the most valuable search enhancements are based on search  both on-line and off-line  by improving the lower bound. we classify the search enhancements along several dimensions including their generality  computational model  completeness and admissibility. not surprisingly  the more specific an enhancement is  the greater its impact on search performance. 
   when presented in the literature  single-agent search  usually ida*  consists of a few lines of code. most textbooks do not discuss search enhancements  other than cycle detection. in reality  non-trivial single-agent search problems require more extensive programming  and possibly research  effort. for example  achieving high performance at solving sliding tile puzzles requires enhancements such as cycle detection  pattern databases  move ordering and enhanced lower bound calculations  culberson and schaeffer  1 . in this paper  we outline a new framework for developing high-performance single-agent search programs. 
this paper contains the following contributions: 
1. a case study showing the evolution of a sokoban 


figure 1: problem #1 of the test set 
solver's performance  beginning with a domainindependent solver and ending with a highly-tuned  application-dependent program. 
1. a taxonomy of single-agent search enhancements. 
1. a new framework for single-agent search  including search enhancements and their control functions. 
1 	sokoban 
figure 1 shows a sample problem of sokoban. the goal is simple: use the man to push all the stones in the maze to the shaded goal squares. only one stone can be pushed at a time. these rather simple rules bely the difficulty of sokoban problems  especially with respect to computer solutions. we identified several reasons why sokoban is so difficult  junghanns and schaeffer  1c : 
  the graph underlying sokoban problems is directed; some moves are not reversible. consequently  there are deadlock states from which no solution is reachable. deadlocks represent a challenge for anytime algorithms  when committing to a move  how can we make sure that no deadlock is introduced  
  the combination of long solution lengths  up to 1 stone pushes in the test set  and potentially large branching factors make sokoban difficult for conventional search algorithms to solve. 1 sokoban offers the challenge of a large search space  
  sokoban solutions are inherently sequential; only limited parts of a solution are interchangeable. subgoals are often interrelated and thus cannot be solved independently. 
  a  simple   effective lower bound on the solution length of a sokoban problem remains elusive. the best lower bound estimator is expensive to calculate  and is often ineffective. 
　none of the above obstacles are found in the  standard  single-agent test domains  such as puzzles and rubik's cube. 
1 	application-independent techniques 
ideally  applications should be specified with minimal effort and a  generic  solver would be used to compute the solutions. in small domains this is attainable  e.g.  if it is easily enumerable . for more challenging domains  there have recently been a number of interesting attempts at 

figure 1: two simple sokoban problems 
domain-independent solvers  e.g.  blackbox  kautz and selman  1  . before investing a lot of effort in developing a sokoban-specific program  it is important to understand the capabilities of current al tools. hence  we include this information to illustrate the disparity between what application- independent problem solvers can achieve  compared to application-dependent techniques. 
　the sokoban problems in figure 1  mcdermott  1  were given to the program blackbox to solve. blackbox was the winner of the aips'1 fastest planner competition. the first problem was solved within a few seconds and the second problem was solved in over an hour. 
　clearly  domain-independent planners  like blackbox  have a long way to go if they are to solve the even simplest problem in the test suite  figure 1 . hence  for this application domain we have no choice but to pursue an application-dependent implementation. 
1 	application-dependent techniques 
as reported in  junghanns and schaeffer  1c   we implemented ida* for sokoban. we gave the algorithm a fixed node limit of 1 billion nodes for all experiments  varying from 1 to 1 hours of cpu time on a single 1 mhz processor of an sgi origin 1 . after adding an enhancement  rolling stone was run on 1 test problems  http://xsokoban.lcs.mit.edu/xsokoban.html  to find out how many could be solved and how much search effort was required to do so. 
　figure 1 presents the experimental results for different versions of rolling stone. version ro is the program using only ida* with the lower bound; ra contains all the search enhancements. the logarithmic vertical axis shows the number of search nodes needed to solve a problem. the horizontal axis shows how many problems can be solved  out of 1   ordering the problems by search tree size. the performance lines in the figure are sorted from left to right with an increasing number of search enhancements. 
　lower b o u n d  1 solved : to obtain an admissible estimate of the distance of a position to a goal  a minimum-cost  perfect bipartite matching algorithm is used. the matching assigns each stone to a goal and returns the total  minimum  distance of all stones to their goals. the algorithm is 1 n1  in the number of stones n. ida* with this lower bound cannot solve any of the test problems within one billion search nodes. 
	junghanns and schaeffer 	1 


figure 1: program performance 
　transposition table  1 solved : the search space of sokoban is a graph  rather than a tree  so repeated positions and cycles are possible. a transposition table was implemented to avoid duplicate search effort. positions that have the same stone locations and equivalent man locations  taking man reachability into account  are treated as the same position. transposition tables reduces the search tree size by several orders of magnitude  allowing rolling stone to solve 1 problems. 
　move ordering  1 solved : children of a node are ordered based on their likelihood of leading to a solution. move ordering only helps in the last iteration. even though move ordering results in no additional problems being solved  less search effort is used to solve each problem. 
　deadlock table  1 solved : the pattern database is a recent idea that has been successfully used in the nx /v-puzzles  culberson and schaeffer  1  and rubik's cube  korf  1 . an off-line search enumerated all possible stone/wall placements in a 1 region and searched them to determine if deadlock was present. these results are stored in deadlock tables. during an ida* search  the table is queried to see if the current move leads to a local deadlock. thus  deadlock tables contain search results of partial problem configurations and are general with respect to all sokoban problems. 
　tunnel macros  1 solved : a sokoban maze often contains  tunnels   such as the squares kh  lh  mh and nh in figure 1 . once a stone is pushed into a tunnel  it must eventually be pushed all the way through. rather than do this through search  this sequence of moves can be collapsed into a single macro move. by collapsing several moves into one  the height of the search tree is reduced. tunnel macros are identified by pre-processing. 
　goal macros  1 solved : prior to starting the search  a preliminary search is used to find an appropriate order in which to fill in the goal squares. in many cases this is a non-trivial computation  especially when 
1 	computer game playing 
the goal area s  has several entrances. a specialized search is used to avoid fill sequences that lead to a deadlock. the knowledge about the goal area is then used to create goal macros  where stones are pushed directly from the goal area entrance s  to the final goal square avoiding deadlocks. for example  in figure 1  square gh is defined as the entrance to the goal area; once a stone reaches it  a single macro move is used to push it to the next pre-determined goal square. these macro moves significantly reduce the search depth required to solve problems and can dramatically reduce the search tree size. whenever a goal macro move is possible  it is the only move considered; all alternatives are forward pruned. 
　goal cuts  1 solved : goal cuts effectively push the goal macros further up the search tree. whenever a stone can be pushed to a goal entrance square  none of the alternative moves are considered. the idea behind these cuts is that if one is confident about using macro moves  one might as well prune alternatives to pushing that stone further up in the search tree. 
	pattern 	search 	 1 	solved : 	pattern searches 
 junghanns and schaeffer  1b  are an effective way to detect lower bound inefficiencies. small  localized conflict-driven searches uncover patterns of stones that interact in such a way that the lower bound estimator is off by an arbitrary amount  even infinite  in the case of a deadlock . these patterns are used throughout the search to improve the lower bound. patterns are specific to a particular problem instance and are discovered on the fly using specialized searches. patterns represent the knowledge about dynamic stone interactions that lead to poor static lower bounds  and the associated penalties are the corrective measures. 
　pattern searches lead to dramatic improvements of the search: many orders of magnitude vanish from the search tree size and 1 more problems can be solved. note that tree sizes reported include the pattern search nodes. 
　relevance cuts  1 solved : relevance cuts  junghanns and schaeffer  1a  are an attempt to cut down the branching factor using forward pruning. if moves are  inconsistent  to the previous move history  they are pruned. this heuristic is unsafe  since it has the potential to prune solution paths. however  it does decrease search tree sizes  and can be a beneficial trade-off. 
　overestimation  1 solved : given the difficulty of solving sokoban problems  any solution  even a nonoptimal one  is welcome. the patterns that rolling stone discovers indicate when potentially  difficult  situations arise. to ensure admissibility  some patterns that match are not always used to increase the lower bound. overestimation allows every pattern to add to the lower bound. in principle  this can be interpreted as the program  avoiding  difficult situations. we prefer to describe it as a knowledge-driven postponement of search: the additional penalty only postpones when the search will explore a certain part of the tree  it will not cut branches indefinitely. in this respect  this method preserves completeness  but not solution optimality. 


　the performance gap between the first and last versions of rolling stone in figure 1 is astounding. for example  consider extrapolating the performance of rolling stone with transposition tables so that it can solve the same number of problems as the complete program  1 . 1  not a typo!  seems to be a reasonable lower bound on the difference in search tree sizes. 
　the preceding discussion closely corresponds to the order in which enhancements were initially added to rolling stone  although most enhancements have been continually refined . figure 1 shows how these results were achieved over the 1-year development time. the development effort equates to a full-time phd  a part time professor  a full-time summer student  and feedback from many people. additionally  a large number of machine cycles were used for tuning and debugging. it is interesting to note the occasional decrease in the number of problems solved  the result of  favorable  bugs being fixed. the long  slow  steady increase is indicative of the reality of building a large system. progress is incremental and often painfully slow. 
　the results in figure 1 may misrepresent the importance of each feature. figure 1 shows the results of taking the full version of rolling stone and disabling single search enhancements. in the absence of a particular method  other search enhancements can compensate to allow a solution to be found. most notably  while the lower bound function alone cannot solve a single problem  neither can the complete system solve a single problem without the lower bound function. 
　figure 1 shows that turning off goal macros reduces the number of problems solved by 1  more than 1%! turning oft transposition tables loses 1 problems. turning off pattern searches reduces the number of solved problems by 1. other than the lower bound function  these three methods are the most important for rolling stone  losing any one of them dramatically reduces the performance. while other enhancements don't have as dramatic an effect  turning any one of them off loses at least one problem. 

figure 1: effort graphs for methods  fumed off 
1 	knowledge taxonomy 
in looking at the domain-specific knowledge used to solve 
sokoban problems  we can identify several different ways of classifying the knowledge: 
generality. classify based on how general the knowledge is: domain  e.g.  sokoban   instance  a particular sokoban problem   and subtree  within a sokoban search . 
computation. differentiate how the knowledge was obtained: static  such as advice from a human expert  and dynamic  gleaned from a search . 
admissibility /completeness. knowledge can be: admissible  preserve optimality in a solution  or non-admissible. non-admissible knowledge can either preserve completeness of the algorithm or render it incomplete. admissible knowledge is necessarily complete. 
figure 1 summarizes the search enhancements used in 
rolling stone. other enhancements from the literature could easily be added into spaces that are still blank  e.g. perimeter databases  manzini  1   dynamic  admissible  instance . note that some of the enhancement classifications are fixed by the type of the enhancement. for example  any type of forward pruning is incomplete by definition  and move ordering always preserves admissibility. for some enhancements  the properties depend on the implementation. for example  overestimation techniques can be static or dynamic; goal macros can be admissible or non-admissible; pattern databases can be domain-based or instance-based. 
　it is interesting to note that  apart from the lower bound function itself  the three most important program enhancements in terms of program performance  figure 1  are all dynamic  search-based  and instance/subtree specific. the static enhancements  while of value  turn out to be of less importance. static knowledge is usually rigid and does not include the myriad of exceptions that search-based methods can uncover and react to. 
	junghanns and schaeffer 	1 

classification domain instance subtree static admissible lower bound tunnel macros move ordering complete incomplete relevance cuts goal cuts dynamic admissible deadlock tables pattern searches transposition table complete overestimation incomplete goal macros figure 1: taxonomy of search enhancements in sokoban 
1 	control functions 
there is another type of application-dependent knowledge that is critical to performance  but receives scant attention in the literature. control functions are intrinsic parts of efficient search programs  controlling when to use or not use a search enhancement. in rolling stone numerous control functions are used to improve the search efficiency. some examples include: 
transposition table: control knowledge is needed to decide when new information is worth replacing older information in the table. also  when reading from the table  control information can decide whether the benefits of the lookup justify the cost. 
goal macros: if a goal area has too few goal squares  then goal macros are disabled. with a small number of goals or too many entrances  the search will likely not need macro moves  and the potential savings are not worth the risk of eliminating possible solutions. 
pattern searches: pattern searches are executed only when a non-trivial heuristic function indicates the likelihood of a penalty being present. executing a pattern search is expensive  so this overhead should be introduced only when it is likely to be cost effective. control functions are also used to stop a pattern search when success appears unlikely. 
　implementing a search enhancement is often only one part of the programming effort. implementing and tuning its control function s  can be significantly more time consuming and more critical to performance. we estimate that whereas the search enhancements take about 1% of the coding effort and the control functions only 1%  the reverse distribution applies to the amount of tuning effort needed and machine cycles consumed. 
   a clear separation between the search enhancements and their respective control functions can help the tuning effort. for example  while the goal macro creation only considers which order the stones should be placed into the goal area  the control function can determine if goal macros should be created at all. both tuning efforts have very different objectives  one is search efficiency  
1 	computer game playing 

figure 1: enhanced ida* 
the other risk minimization. separating the two seems natural and convenient. 
1 	single-agent search framework 
as presented in the literature  single-agent search consists of a few lines of code  usually ida* . most textbooks do not discuss search enhancements  other than cycle detection. in reality  non-trivial single-agent search problems require a more extensive programming  and possibly research  effort. 
　figure 1 illustrates the basic ida* routine  with our enhancements included  in italics . this routine is specific to rolling stone  but could be written in more general terms. it does not include a number of well-known single-agent search enhancements available in the literature. control functions are indicated by parameters to search enhancement routines. in practice  some of these functions are implemented as simple if statements controlling access to the enhancement code. 
　examining the code in figure 1  one realizes that there are really only three types of search enhancements: 
1. modifying the lower bound  as indicated by the updates to /1 . this can take two forms: optimally increasing the bound  e.g. using patterns  which reduces the distance to search  or non-optimally  using overestimation  which redistributes where the search effort is concentrated. 
1. removing branches unlikely to add additional infor-


mation to the search  the next and break statements in the for loop . this forward pruning can result in large reductions in the search tree  at the expense of possibly affecting the completeness. 
1. collapsing the tree height by replacing a sequence of moves with one move  for example  macros . 
　some of the search enhancements involve computations outside of the search. figure 1 shows where the pre-search processing occurs at the domain and instance levels. off-line computation of pattern databases or pre processing of problem instances are powerful techniques that receive scant attention in the literature  chess endgame databases are a notable exception . yet these techniques are an important step towards the automation of knowledge discovery and machine learning. preprocessing is involved in many of the most valuable enhancements that are used in rolling stone. 
   similar issues occur with other search algorithms. for example  although it takes only a few lines to specify the alpha-beta algorithm  the deep blue chess program's search procedure includes numerous enhancements  many similar in spirit to those used in rolling stone  that cumulatively reduce the search tree size by several orders of magnitude. if nothing else  the deep blue result demonstrated the degree of engineering required to build high-performance search-based systems. 
1 	conclusions 
this paper described our experiences working with a challenging single-agent search domain. in contrast to the simplicity of the basic ida* formulation  building a high-performance single-agent searcher can be a complex task that combines both research and engineering. application-dependent knowledge  specifically that obtained using search  can result in an orders-of-magnitude improvement in search efficiency. this can be achieved through a judicious combination of several search enhancements. control functions are overlooked in the literature  yet are critical to performance. they represent a significant portion of the program development time and most of the program experimentation resources. 
   domain-independent tools offer a quick programming solution when compared to the effort required to develop domain-dependent applications. flowever  with current ai tools  performance is commensurate with effort. domain-dependent solutions can be vastly superior in performance. the trade-off between programming effort and performance is the critical design decision that needs to be made. 
1 	acknowledgements 
this research was supported by a grant from the natural sciences and engineering research council of canada. 
computational resources were provided by m a c i . this paper benefited from interactions with yngvi bjornsson  afzal upal and rob holte. 
