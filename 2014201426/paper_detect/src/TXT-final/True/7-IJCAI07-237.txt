
decentralized reputation systems have recently emerged as a prominent method of establishing trust among self-interested agents in online environments. a key issue is the efficient aggregation of data in the system; several approaches have been proposed  but they are plagued by major shortcomings.
we put forward a novel  decentralized data management scheme grounded in gossip-based algorithms. rumor mongering is known to possess algorithmic advantages  and indeed  our framework inherits many of their salient features: scalability  robustness  globality  and simplicity. we also demonstrate that our scheme motivates agents to maintain a sparkling clean reputation  and is inherently impervious to certain kinds of attacks.
1 introduction
in open multiagent environments  self-interested agents are often tempted to employ deceit as they interact with others. fortunately  dishonest agents can expect their victims to retaliate in future encounters. this  shadow of the future  motivates cooperation and trustworthiness.
모however  as the size of the system grows  agents have an increasingly small chance of dealing with another agent they already know; as a consequence  building trust in domains teeming with numerous agents becomes much harder. reputation systems address this problem by collecting and spreading reports among agents  so that agents may learn from others' experience. to put it differently  agents are intimidated by the  shadow of the future  today  even though tomorrow they are most likely to meet total strangers.
모reputation systems can be decomposed into two major components: 1  the trust model  which describes whether an agent is trustworthy  and 1  the data management scheme. the latter component poses some interesting questions  since it is imperative to efficiently aggregate trust-related information in the system. a simple solution is maintaining a central database that contains the feedback gathered from past transactions. unfortunately  this solution is inappropriate in distributed environmentswhere scalability is a major concern  as the database soon becomes a bottleneck of the system. moreover  this approach is not robust to failures. previous work on decentralized reputation schemes suffered from their own major problems: agents have to maintain complex data structures  evaluation of trust is based only on local information  or there are restrictive assumptions on the trust model.1
모we approach this hornets' nest by designing a novel method of trust aggregation  i.e.  a reputation system's data management scheme . the method is demonstrated in this paper for a simple trust model  but it can be extended to more complex models.
모the roots of our gossip-based approach can be traced to a seminal paper by frieze and grimmett : a rumor starts with one agent; at each stage  each agent that knows the rumor spreads it to another agent chosen uniformly at random. the authors show that the rumor reaches all agents quickly  a result that coincides with real life . we directly rely on more recent results  surveyed in the next section. it has been shown that aggregate information  such as averages and sums of agents' inputs  can be calculated using similar methods of uniform gossip in a way that scales gracefully as the number of agents increases. furthermore  the approach is robust to failures  and the results hold even when one cannot assume a point-to-point connection between any two agents  as is the case in peer-to-peer  p1p  networks .
모in our setting  each agent merely keeps its private evaluation of the trustworthiness of other agents  based on its own interactions.1 when an agent wishes to perform a transaction with another  it obtains the average evaluation of the other's reputation from all agents in the system  using a gossip-based technique. although the presented algorithms estimate the average reputation  they can be easily adapted to estimating whether a certain agent has a high reputation in the eyes of the majority of the agents  or certain other similar metrics. thus  the framework we advocate for aggregating reputation information accommodates more sophisticated trust models.
모some advantages are immediately self-evident. each agent stores very little information  which can be simply and efficiently organized  and evaluation of trust is based on global information. additionally  this framework inherits the advantages of gossip-based algorithms: scalability  robustness to failure  decentralization  and as a consequence  applicability in peer-to-peer networks.
모we show that our scheme has two other major advantages. an important desideratum one would like a reputation system to satisfy is motivating agents to maintain an untarnished reputation  i.e.  to be absolutely trustworthy  as opposed to  say  being generally trustworthy but occasionally cheating . we show that our data management scheme  together with an extremely simple trust model  satisfies this property. we also demonstrate that our scheme is inherently resistant to some attacks  with no assumptions on the trust model . this is a positive side effect of the exponential convergence rates of the algorithms we use.
모in this paper we do not address the problem of designing a trust model. rather  we suggest an approach for agents to aggregate distributed trust information so as to decide with whom to carry out transactions.
1 gossip-based information aggregation
in this section  we survey the relevant results of kempe  dobra and gehrke  kempe et al.  1 . these algorithms allow us to estimate the average of values held at network nodes  in our case  these values will be the reputation values concerning a particular agent .  kempe et al.  1  also shows how to calculate other functions over these values  such as the majority function and sum. thus our algorithms can be adapted for other  more sophisticated models of trust.
모we begin by describing a simple algorithm  push-sum  to compute the average of values at nodes in a network. there are n nodes in the system  and each node i holds an input xi 뫟 1. at time t  each node i maintains a sum st i and a weight wt i. the values are initialized as follows: s1 i = xi  w1 i = 1. at time 1  each node i sends the pair s1 i w1 i to itself; at every time t   1  the nodes follow the protocol given as algorithm 1.

algorithm 1

1: procedure push-sum
be all the pairs sent to i at time t   1
1:
 ft i  uniformly at random
1:	send the pair and to ft i   is the estimate of the average at time t
1: end procedure

모let  the diffusion speed of uniform gossip  be an upper bound on the number of turns push-sum requires so that for all and all nodes i 
 the relative error is at most   with probability at least 1   붻.
theorem 1   kempe et al.  1  .
1. .
1. the size of all messages sent at time t by push-sum is o t + maxi bits xi    where bits xi  is the number of bits in the binary representation of xi.
모a major advantage of gossip-based algorithms is their robustness to failures: the aggregation persists in the face of failed nodes  permanent communication failures  and other unfortunate events. further  no recovery action is required. the assumption is that nodes can detect whether their message has reached its destination; push-sum is modified so that if a node detects its target failed  it sends its message to itself.
theorem 1   kempe et al.  1  . let 뷃   1 be an upper bound on the probability of message loss at each time step  and let u be the diffusion speed of uniform gossip with faults. then:
.
모in several types of decentralizednetworks  such as p1p networks  point-to-pointcommunication may not be possible. in these networks  it is assumed that at each stage nodes send messages to all their neighbors  flooding . when the underlying graph is an expander  or at least expected to have good expansion results similar to the abovecan be obtained. fortunately  it is known that several peer-to-peer topologies induce expander graphs  pandurangan et al.  1 .
in the rest of the paper  we have xi 뫞 1  and in particular
. therefore  it is possible to redefine u to be an upper bound on the number of turns required so that for all t 뫟 u and all nodes i  the absolute error  with confidence   and it still holds that
we refer to u we have this definition in mind.
remark 1. the protocol push-sum is presented in terms of a synchronized starting point  but this assumption is not necessary. a node that poses the query may use the underlying communication mechanism to inform all other nodes of the query; convergence times are asymptotically identical.
1 our framework
let the set of agents be n = {1 ... n}. each agent i 뫍 n holds a number rij 뫍  1  for each agent j 뫍 n  including itself . this number represents j's reputation with respect to i  or to put it differently  the degree to which i is willing to trust j. as agents interact  these assessments are repeatedly updated. we do not in general concern ourselves with how agents set these values.
모when an agent i is deliberating whether to deal with another agent j  i wishes to make an informed evaluation of the other's reputation. let be the average of j's reputation with respect to all agents. knowledge of r몬j would give i a good idea of how trustworthy j is  this is  of course  a simple model of trust .
모we show that in this scenario  agents can use gossip-based algorithms to decide with whom to carry out transactions. also  in such a setting  agents are encouraged to keep a completely untarnished reputation. similar results can be obtained for more complex trust models.
algorithm 1
1: procedure eval-trust    몬 with accuracy   confidence 1   붻
1:	for all k 뫍 n do
1: xk 뫹 rkj  inputs to push-sum are j's reputation w.r.t. agents
1:	end for
1:	run push-sum for stages
1:	return wsu iu i 1: end procedure

a simple way to compute the average trust is via
push-sum.
the protocol eval-trust is given as algorithm 1.
push-sum is executed for stages. at time
u  it holds for all k 뫍 n  and in particular for agent i  that
               with probability 1   붻. in other words  the algorithm returns a very good approximation of	j's average reputation.
모in practice  when two agents i and j interact  i may evaluate j's reputation  and vice versa  by calling eval-trust. the protocol quickly returns the approximation of r몬j  based on the values rkj at the time eval-trust was called. each agent i keeps different values st i and wt i for every different query that was issued by some other agent in the system  and updates these values repeatedly according to push-sum. thus  at any stage every agent participates in many parallel executions of push-sum.
모a possible cause for concern is the amount of communication each agent has to handle at every turn. however  the quick convergence of push-sum guarantees that the burden will not be too great. indeed  it is plausible to assume that the number of new interactions at each turn is bounded by a constant c  or at worst is very small compared to n . each such new interaction results in at most two new executions of eval-trust  but the execution lasts at most u turns. to conclude the point  each agent sends at most c몫u = o logn  messages per turn.
remark 1. the size of messages depends on how the rij are calculated  and as mentioned above  this issue is outside the scope of this paper. nevertheless  there would usually be a constant number of reputation levels  say  for instance  rji 뫍 {1.1.1 ... 1}   so the message size would normally be constant.
모as the above method of aggregating an agent's average reputation relies on the gossip-based algorithm push-sum  it inherits all the latter's benefits  in particular robustness to failure and applicability in peer-to-peer networks.
1 the benefit of an unstained reputation
it is very desirable  indeed  crucial  that a reputation system be able to induce truthfulness in agents. naturally  an agent with a stained reputationwould be shunnedby its peers  while an agent with a good reputation would easily solicit deals and transactions. a further step in this direction is motivating agents never to cheat. indeed  an agent with a generally good reputation  that only occasionally cheats  would probably be able to win the confidence of peers; there is seemingly no reason why an agent should not play false now and again. nevertheless  we consider in this section an extremely simple and general trust model  and show that with the data management scheme that we have presented  there is a social benefit to having a very high reputation: the higher the agent's reputation  the shorter the time required to close deals.
모we consider a model in which each agent i has a reputation threshold rithr  similar to  xiong and liu  1   and a confidence level 붻i: agent i is willing to deal with an agent j iff i knows that j's average reputation is at least rithr  with confidence 1   붻i. i evaluates j's reputation as above  using eval-trust. recall that when the algorithmterminates  agent i only has an -close approximationof is very close to rithr  i would have to increase the accuracy.
remark 1. we still do not commit to the way the values rji are determined and updated  so the above trust model is quite general.

algorithm 1
1: procedure decide-trust	decides if it wants to deal with
1:	뫹 1	 initialization
1:k1 뫹 1:loop1:	
1:	run eval-trust j  for another k1   k1 stages  a total of k1 stages
1:	ifthen
1:	return false
1:	else ifthen
1: return true 1: end if
1:
1:
1:	end loop
1: end procedure

모the procedure decide-trust  given as algorithm 1  is a straightforward method of determining whether r몬j 뫟 rithr. agent i increases the accuracy of the evaluation by repeatedly halving   until it is certain of the result. in this context  a stage of eval-trust corresponds to a stage of push-sum.
proposition 1. let i j 뫍 n  and 붟ij = |r몬j   rithr|. with probability at least 1 붻i  decide-trust correctly decides whether agentreputation is at least rithr after o logn +  stages of eval-trust.1
proof. assume w.l.o.g. that rithr   r몬j  and that the algorithm reached a stage t1 where. at this stage  it holds that  with probability 1   붻i   and therefore:

hence  the algorithm surely terminates when .
now the proposition follows directly from the fact that
.	
모to conclude proposition 1 implies that there is a benefit for agent j in maintaining a high reputation: for any agent i with a reasonable threshold  붟ij is significant  and this directly affects the running time of decide-trust.
remark 1. the result is limited  though  when the number of agents n is large  as the time to evaluate an agent's reputation is also proportional to logn.
1 resistance to attacks
we have seen that information about an agent's reputation can be efficiently propagated  as long as all agents consistently follow eval-trust. however  with reputation systems we are usually dealing with self-interested agents. in our context  a manipulative agent may artificially increase or decrease the overall evaluation of some agent's reputation by deviating from the protocol.
모in the framework we have presented  trust is evaluated on the basis of global knowledge  i.e.  the average of all reputation values in the system. therefore  any small coalition cannot significantly change the average reputation of some agent j by setting their own valuations rij to legal values in  1   and then following the protocol eval-trust.1
모this is  of course  not the case when a manipulator is allowed to set its reputation value arbitrarily. as a simple motivating example  consider a setting where agents propagate agent j's average reputation  m wants to ensure that for allxi = rij for alli  st i i converges to  and a manipulator i	
a high value as the time t increases. at some stage t1  the manipulator updates st1 im to be n  but except for this harsh deviation follows the protocol to the letter. in particular  the manipulator might initially set rijm = xim = sn. we refer to this strategy as strategy 1. clearly  for all eventually converges to a value that is at least 1.
모despite the apparent effectiveness of strategy 1  it is easily detected. indeed  unless for allit holds that st1 i = 1 at the time t1 when the manipulator deviated by assigning st1 im = n  the expressions wst it i would eventually converge to a value that is strictly greater than 1; this would clearly unmask the deceit. it is of course possible to update st1 im to be less than n  but it is difficult to determine a priori which value to set without pushing the average reputation above 1.
모we now consider a more subtle way to increase the values wst it i   a deceit that is indeed difficult to detect; we call this strategy strategy 1. for the first t stages of the algorithm  the manipulator im follows push-sum as usual  with the exception of the updates of st im: after updating
 as usual   im updates: st im = wt im. in other words  the
manipulator sets its personal evaluation of the average wst it imm to be 1 at every stage t = 1 ... t. for time t   t  the manipulator abides by the protocol. using this strategy  it always holds that  for all i. in addition  for all t  it still holds that. therefore  without augmenting the system with additional security measures  this manipulation is difficult to detect. we shall presently demonstrate formally that the manipulation is effective in the long run: wst it i converges to 1 for all i.
proposition1. under strategy1  for all in probability.
proof. we first notice thatis monotonic increasing in stage t. moreover  as noted above  it holds that at every stage 
  as for all  and thus:

let. we must show that it is possible to choose
t large enough such that for all t 뫟 1t and all i 뫍 n 
.
assume that at time t it holds that:
		 1 
let. it holds that:

모it follows that. the total weight of agents in n  it is at least n w it . there must be an agent it 뫍 n   it with at least a 1/n-fraction of this weight:
	.	 1 
in order for the choice of it to be well-defined  assume it is the minimal index that satisfies equation  1 .
모now  let be the manipulator's sum had it updated it according to the protocol  i.e.  for all messages l sent to im. with probability1/n  and independentlyof other stages   ft it  = im; if this happens  it holds that:

for all stages t it holds that 
  as the manipulator is the only agent that might change. therefore  in the conditions of equa-
tion  1  

모so far  we have shown that for each stage t where equation  1  holds and ft it  = im  it is the case that
. this can happen at most  times before equation  1  no longer holds  or to put it differently  before.
모let xt be i.i.d. binary random variables  that are 1 iff ft it  = im. it holds that for all t where equation  1  is true  e xt  = 1/n. by chernoff's inequality  it holds that:
t
pr .
=1
it is possible to choose t1 to be large enough such that this expression is at most 붻/1  and in addition .
therefore  at time t1  the average  with probability 1   붻/1.
모recall that after t stages  where im deviated from the protocol   it still holds that. assume that indeed
. by modifying the proof of theorem 1 from  kempe et al.  1   it is possible to show that after another stages where all agents observe the protocol  it holds with probability 1   붻/1 that for
   and thus for all i and with probability 1   붻.
모the proof is completed by simply choosing t = max{t1 t1}.	
모proposition 1 implies that strategy 1 poses a provablyacute problem  when push-sum is run a large number of turns. fortunately  push-sum converges exponentially fast  and thus it is usually the case that the manipulator is not able to significantly affect the average reputation  as the following proposition demonstrates.
. under strategy 1 it holds that
.
proof. let {s l w l} be the messages that the manipulator received at time t + 1. the manipulator sets st+1 im =
. essentially  this is equivalent to setting for all l s l = w l  or in other words  raising each s l by w l  s l. at turn t it was already true that st im = wt im  w.l.o.g. this is also true for t = 1   so it is enough to consider messages at time t from all.
therefore  for all stages t  it holds that:

the last equality follows from the fact that for all t 
.
as  and from the linearity of expectation  we
obtain that


in particular  since 
push-sum is executed o logn  stages  and thus the difference in the average is at most  which is quite insubstantial.
remark 1. it is not guaranteed at time t1 that each wst it i is close to r몬j  because the inputs were dynamically changed during the execution of push-sum.
remark 1. the above discussion focused on a setting where the manipulator attempts to increase the average reputation of an agent. it is likewise possible for a manipulator to decrease an agent's average reputation  or indeed set it eventually to any value it wants.
1 related work
p1prep  cornelli et al.  1  and xrep  damiani et al.  1  are p1p reputation systems that can be piggybacked onto existing p1p protocols  such as gnutella . p1prep allows peers to estimate trustworthiness of other peers by polling. no guarantees are given with respect to computational efficiency and scalability.
모aberer and despotovic  introduce a reputation system that consists of both a semantic modeland a data management scheme. the latter relies on p-grid  aberer  1   and uses distributed data structures for storing trust information; the associated algorithms scale gracefully as the number of agents increases. this approach  however  suffers from several shortcomings compared to ours. agents in this scheme assess others' reputation only on the basis of complaints filed in the past; the framework is generally limited to such binary trust information. in addition  trust is evaluated only according to referrals from neighbors  whereas in our approach the evaluation is based on all the information in the system.
모xiong and liu  presented a sophisticated framework specifically applicable in p1p networks  where the decision whether to trust a peer is based on five metrics: satisfaction  number of transactions  credibility of feedback  transaction context  and community context.  srivatsa et al.  1  extended this work. both papers focus on the trust model  and generally do not elaborate on the data management scheme. specifically  in  xiong and liu  1  a p-grid  aberer  1  is used. thus  this work is in a sense orthogonal but complementary to ours. dewan and dasgupta  propose self-certification and ip-based safeguards as ways of inducing trust; this work also complements ours.
모finally  gossip-based algorithms1 have many applications in other domains  for instance replicated database maintenance  demers et al.  1 .
1 conclusions
we have presented a data management scheme built on gossip-based algorithms  and have demonstrated that it possesses several interesting features. our method is decentralized  and uses no central database. it is also applicable in networks where point-to-point communication cannot be assumed. it is scalable: the time to evaluate an agent's average reputation with confidence 1   붻 and accuracy  is
. the evaluation of trust is global 
and based on all relevant information in the system  rather than only local information. we have used simple data structures: each agent merely keeps an assessment of the agents with which it personally interacted. our method motivates absolute truthfulness  as the time to close deals may decrease as reputation increases. it is also resistant to some attacks  such as carefully tampering with the updates performed by
push-sum.
모we have focused on the data management scheme  and have largely ignored the trust model. however  we believe that many existing trust models can be integrated with our framework. a simple example is the binary trust model of  aberer and despotovic  1   where agents can file complaints against other agents. in our framework  each agent i sets its value rij to be 1 if it wishes to file a complaint against j; otherwise  the value is 1. more sophisticated models may  however  require modifications to the framework. for example  an agent may give higher credibility to agents that have a high reputation  in its opinion   and weight their estimations accordingly. an interesting direction for further work would be to use gossip techniques to take even such considerations into account.
1 acknowledgment
this work was partially supported by grant #1 from the israel science foundation.
