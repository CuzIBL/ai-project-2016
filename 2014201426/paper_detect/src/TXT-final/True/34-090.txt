 

     we describe an interpreter for the programming language predicate logic. some topics are; syntax and proof procedure  procedure evocation  function transformation  goal variation and interactive computational control. 
introduction 

     the development of programming languages has more and more relieved a programmer from machine control and details  giving him the power of abstract reasoning and thus helped him to concentrate more on his problem. kowalski  1  has convincingly argued that predicate logic formalizes a man's thoughts and is a useful simple programming language for human problem solving. consequently it is desirable to have predicate logic implemented on machines for practical programming. there is one implementation at the university of aixmarseille  prologue . at the university of stockholm we have implemented an interpreter in lisp 1 . 
syntax and proof procedure 

     the syntax of the language consists of kowalski's procedural form  plus a control structure consisting of an ordered procedure  ordered procedures and computational consequences  tarnlund  . the proof procedure is based on kowalski's connection graph system  1 . 
kowalski's procedure form 

     a procedure is the only type of statement in the language. it contains two special cases  a goal and an assertion. two typical procedures are 
own x y   *  own  x  z  tpart  y  z    
which is read  x owns y if there is a z such that x owns z and y is a part of z   and 
　　d x y  d x z  * d xtw  p x  m y z w t which is read  x divides y or x divides z if there is a w such that x divides w and x is a prime and y - z * w . the part to the left of the arrow is called procedure name and the part to the right is called procedure body consisting of procedure calls. 
     a goal statement is a procedure without a name e.g.  
  - own  john  tyre  . 
an assertion is a procedure without a body 
e.g.   
part tyre car    . 
     a program is a set of procedures connected in a graph depending on how they match each other. 

flg.l. a connection graph. each atom is connected to all other atoms with the same name occurring on opposite sides of the arrows  provided that they can be matched i.e.  unified  1 . recursive procedures are linked with dotted lines. 
     the connection graph is indipendent of the order the programmer presents his statements. de-
pending on one's programming style  problem-solving  one can combine top-down  middle-out and bottom-up programming. the goal of the interpreter is to activate links  resolve corresponding atoms  in a way that eventually leads to the empty pro-
cedure d . 
control structure 

     the control structure transfers some decisionmaking responsibility from the search strategy to the programmer and makes the decisions explicit. this is illustrated by a program that probes for a node to be deleted in a binary tree such that its remaining nodes are sorted when traversed in symmetrical order. the program is based on a delete algorithm in knuth . we use knuth's zodiac example  sec. 1.1  to delete the node capricorn from a binary tree. the initial goal is 
	- delete* capricorn . 	 1  
suppose that we have the binary tree in a data base 
	a tree  -   	 1  
where a is an arbitrary predicate whose argument 
tree is equal to 

1 

	t t 1 aquarius t o.aries t 1 cancer 1     	 1  
capricorn t t 1 gemini t 1 leo t 1 libra 1     pisces t t 1 scorpio 1  taurus t o.virco.o      
this zodiac binary tree  tree  is an instantiation of the data structure 
t x y z  
denoting a binary tree with a root y and a left subtree x and a right subtree z. an empty tree is denoted 1. when we have picked up the binary tree from the data base and deleted the node capricorn  we want to put the new tree back into the data base i.e.  
 a z  * } delete* u  -  a x  delete x u z     1  where u is the node to be deleted in a binary tree x  and z is the resulting binary tree. note that delete and delete are two different predicates. the predicate within the braces is a computational consequence not to be resolved upon during the computation  but to be put into the data base when the remaining part of procedure  1  is resolved to the empty clause.  computational consequences may be viewed as a generalization of greenf s answer predicate  . the angled brackets ' ' and ' ' tell us that procedure  1  is an ordered procedure and is executed from left to right within the brackets. 
     in the delete algorithm we check each node in the binary tree to determine whether it is to be deleted or if we have to continue a binary tree search for the node to be deleted. the procedures for this algorithm are ordered among themselves and delimited by a pair of double angled brackets '    ' and '    ' . this ordering controls the execut i-
on of the procedures. 
there are two cases when a node is deleted. 
the simpler case occurs when the left subtree of the right subtree of a node u is empty viz.    delete t x u t 1 y    z      u t x y z      +    1  where the new binary tree 
t x y z'  
is  the old tree with the root u deleted . the control structure attempts to execute this procedure first. in case we have to search for the successor node y of the deleted node u in symmetrical order  the procedure is more complicated viz.  
delete  t   x   u   t   x   y  z       u   t  x y   t   x     y  z '    -
	s u c c e s s o r   x '   y   x       	 1  
where t   x   y   t   x     y   z '     
is the new binary tree in which the root y and the left subtree x  are still unknown. they are deduced by the successor procedures  1  and  1 . 
　　　in case we have not found the node to delete we have to search for it viz.  
delete t x y z  u t x' y z   * 
	 le u y  delete x u xf    	 1  
where the node u to be deleted is to be found in the left subtree x of y. the new binary tree becomes 
t x l  y z   
where xf is the same tree as x but with a node deleted. when the probed node i s in the right subtree of y we have 

where the node u to be deleted is found in the right subtree z. le and gr are  built-in  procedures that determine alphabetic orderings  see below . the procedures  1  -  1  are ordered among themselves  which means that a procedure call delete x y z  first will try procedure  1 ; if that procedure cannot be resolved to the empty procedure the call will try procedure  1  and so on. 
     to complete the program we write the recursive successor procedures that probe for a node y which is the successor in symmetric order of the deleted 
node u viz.  

where  1  is the recursion step and  1  the recursion base which terminates the search for the successor node on the first root with an empty left subtree. 
　　　procedures  1    1    1  and  1  with the goal 
+ delete tree capricorn z   
where tree is equal to the binary tree in  1   have been executed on the theorem prover of allen & luckham   at the artificial intelligence laboratory  stanford university  in 1 seconds  see appendix . 
procedure evocation 

     a computation is mainly goal oriented i.e.  the interpreter tries to find out a deduction topdown from the goal. there are  however  some important deviat ions. 


1 



f i g . 1 . a bottom-up pre-processed tower program. 
       the program in f i g . 1 with the data s t r u c t u r e pre-processed i n t o the procedures seems to use the   r i g h t   data s t r u c t u r e t   x   u   for t h i s problem where x is a top block and u is e i t h e r an empty tower or a tower t   v . y   where y is an empty tower  denoted 1  or a non-empty tower. notably  t h i s more d e t e r m i n i s t i c tower program is more than 1 
times f a s t e r than the program in f i g . 1 f o r the goal 
              t o w e r   t   a   t   b   t   c   t   d   1           . when run on the theorem-prover at the a r t i f i c i a l i n t e l l i g e n c e laboratory  stanford u n i v e r s i t y  see appendix . 
       in a top-down execution the v a r i a b l e v of atom on x v  w i l l always be bound to a block so the starred l i n k in f i g . 1 w i l l never be a c t i v a t e d . consequently we can erase i t   which then implies that 	the recursive  on  procedure contains a pure l i t e r a l and thus can be deleted from the graph. this reasoning about data types would be s i m p l i f i ed if the v a r i a b l e s and t h e i r types were declared. most of the pre-processing that we have seen f o l l o w a one l i n k r u l e 	 see below . 
one l i n k evocation 
　　　another important d e v i a t i o n from a top-down computation can occur from a one l i n k evocation. the one l i n k r u l e   however  is also useful during a top-down computation  because of the fact that 
a whole procedure can be deleted from a graph  if the procedure contains an atom connected w i t h only one l i n k   which is a c t i v a t e d 	 kowalski 	  1     . 
the f o l l o w i n g f i g u r e s show a one l i n k evocation. 


fig.1. two connection graphs g and g'. graph g'. follows from g by evoking statement 1 in a top-down computation. interesting substitutions are shown. the dotted links show recursion. 
     there are two atoms connected with only one link in graph g. selecting statement 1 gives a topdown computation and a new goal 

in c. this goal is non-deterministic in the sense that the interpreter is not told which subgoal to solve f i r s t . this problem is discussed tjelow in the sections b u i l t - i n procedures and instantiation evocation. the old goal 

in g  is deleted giving a cleaned up graph g'. 
　　　the one l i n k rule does not work in g'; however  the interpreter could have followed the one link rule in a bottom-up computation by evoking statement 1 giving g . 

fig.1. graph g  follows from g by evoking statement 1 in a bottom-up computation. 
　　　the one l i n k rule is applicable again in g   this time middle-out  giving the new fact 
　　　　　　　　　own  john.tyre  which is a recursion base. the problem is now s o l ved top-down using the recursion base giving a solution 	x  john 	in the goal  own x tyre . 
　　　the transformation from c to c  shows an efficient problem-solving sequence by the one l i n k rule combining bottom-up  middle-out and top-down computation. bottom-up and middle-out execution corresponds to planner's  hewitt  a   antecedent theorem and top-down to a consequent theorem. 
　　　a matcher containing a unification algorithm  robinson   plays a major r o l e   operating on the substitution sets corresponding to a link. the matcher computes the substitution set to a new link in a local area. 

1 

instantiation evocation 

     the graph g1 in fig.1 has no one link atom  however  in the goal 
own x.z  .part  tyre z  
the second subgoal is more instantiated than the 
other. tliis fact is a heuristic giving the interpreter a hint that a first attack on that goal could give a more deterministic computation  mlnker et al.  1  . the interpreter recognizes also that the subgoals have common variables i.e.  they are dependent. so when searching for soluti-
ons for z tn part  tyre z   the interpreter checks these for compatibility with the subgoal 
 -- own x.z  . 
built-in procedures 

     the interpreter also has built-in knowledge that makes it simpler to write programs. we are nlready familiar with the built-in predicates 
l.k u y  and gr u y   the delete program above  which arc true when the relations u   y and y   u are satisfied. 
     we can also use ordinary numbers like 1  1  1  ... instead of 1  s 1   s s 1    ...   where s is a successor function. 
     the interpreter has a knowledge base of useful lisp-functions  which can be used as procedures. the knowledge base can be increased by a programmer. some useful lisp-functions e.g.  add  difference and cons which can be represented as the following procedures: add x y z   dlff x y z  and c1ns x y z   where x and y are input variables and z is an output variable. if the input variab-
les are instantiated with numbers then the add and diff predicates are solved directly e.g.  
add 1 z  
is solved with z 1. the procedure cons x y z  is even solved when the output variable z is bound to a list e.g.  
cons x y  a b c   
gives x + a and y  ---  b c  
     the matcher can solve more complex problems like the three dependent subproblems 
+- add l y z  add x 1 z  add x y 1  
from its knowledge base in lisp-code. the solution is equivalent to the following sequence of substitutions  y  --- diff z l   and x  --- diff z 1  giving addfdifflz 1  diff z l   = 1  which gives z - --- 1  y  --- 1 and x  -- 1. 
     built-in procedures like le and gr are used frequently at decision points during a computation thus they are given high priority to be matched. function transformation 

     in the section on pre-processing predicates were instantiated with a data structure  function . 
sometimes  however  we want to do the opposite 
i.e.  move a function out of a predicate and transform it to a predicate. we explain this idea from kowalski  with an example. 
suppose that we have to sort a list of three elements  c b a  i.e.  the initial goal is 
  --- sort  cons  c  cons  b  cons  a  nil     z    1  where z is the output variable and x is the first element and y the rest of the list cons x.y . assume further that we have a procedure 
         sort list x  z  	 ---o list x   	 1  in the sort program. procedures  1  and  1  do not unify though their first arguments denote a list. but let us transform the term 'list' in  1  to a 
predicate and also use two auxiliary procedures 
i.e.  
sort u.z   --- 1 x  list u x   1  
and 
list cons x'  y     list x' u'    ---- list y' u'   1  
	list cons x' nil  list x'.nil   	 1  
then the situation is changed and yields after some computational steps the intended goal 
	+ 1  list c.list b t list a nil    . 	 1  
     the transformation of a term into a predicate extends the domain of the unification algorithm and gives the opportunity to use a uniform procedure for terms and predicates to determine which of them to evoke. 
goal variations 

     in problem-solving problem variation sometimes leads to a successful solution  polya  . we show two ways to vary a problem i.e.  problem generalization and problem specialization. in both cases logical consequence plays an important role. problem generalization 

     perhaps the simpliest example that shows both problem generalization and specialization is a family example from kowalski . 
suppose that we have the following goal 
　　　　*- male x    parent  x y   father  x  and the procedure 
father x  * male x  parent x y   
then by logical consequence we have the new goal 
 --- male  x  parent x y . 
the problem is generalized in the way that the connection graph for the new goal contains less details in form of predlcate s  and link s   yet still gives the same solution. 
problem specialization 

     a reasoning by logical consequence can also give a specialized problem in the way that we put in more details in form of link s  and predicate s  into the connection graph. 
suppose we have the goal 
 ---- male x  parent  x y  
and the procedure 
father x   -- - male x   parent  x y   
then by logical consequence we have the new goal 
 --- male x .parent x y .father x . 
     the idea of logical consequence can also be used in a heuristic reasoning. 

1 

suppose that we have a goal to show that x is a parallelogram 
	 parallelogram x  	 1  
and a procedure d e f i n i n g a parallelogram 
parallelogram x    1  
and two rectangle procedures 
rectangle x   parallelogram x  rightangled x    1  
rectangle a  	 1  
let us assume that the goal we obtain by resolving  1  and  1  is very n o n - d e t e r m i n i s t i c ; then we could use the idea of l o g i c a l consequence in a h e u r i s t i c reasoning and make the following assumpt i o n . 
suppose that rectangle x  is a l o g i c a l consequence of parallelogram x   then we have the new specialized g o a l   
　　　　 parallelogram x  rectangle   x      1  which by r e s o l u t i o n    a  and  1   gives the goal 
	 parallelogram a   	 1  
which is more d e t e r m i n i s t i c and could give a faster s o l u t i o n . this computation i s   however  based on a h e u r i s t i c assumption that could be f a l s e and thus could be a wasted computation. 
　　　whether or not it is favourable to generalize or specialize a problem depends b a s i c a l l y on how much each can decrease the non-determinism of a problem. 
i n t e r a c t i v e computation control 
       i n t e r a c t i v e control of a computation helps a programmer debug a program  as w e l l as improve a 
       program  and can give the programmer hints that he can use to t r i m the search strategy. 
program debugging 
　　　a computation is a deduction  a unique property of predicate logic among programming languages    which means that each step in the computat i o n is a l o g i c a l step. this gives us a powerful mean to discover bugs e . g .   m i s s p e l l i n g s   missed termination conditions  recursion bases  and badly expressed ideas. program improvements 
which a p r i o r i can be matched w i t h a l l elements in the data base  then t h i s program is reasonable f o r 
very few elements only. if a programmer is t o l d when the number of possible matches is more than a given threshold then he could s t a r t t h i n k i n g of some program improvements. 
　　　a simple refinement of the given program is to s u b s t i t u t e goal 	 1  by goal 
		 1  
and add the procedure 
		 a  
which gives a d e t e r m i n i s t i c sequential search program. 
conclusions 
　　　our experience in predicate logic programming has only been p o s i t i v e . a program becomes s t r u c t u red and transparent. a l l variables of a procedure are local variables of that procedure so we do not get side e f f e c t s from global v a r i a b l e s . each step in a computation is a l o g i c a l step  which supports 
debugging. a proof of an algorithm on a theoremprover has a d i f f e r e n t behaviour from  for example a proof in group theory where a proof of depth 1 is a s u r p r i s e   though a proof of depth 1 for an algorithm has been found in 1 seconds  ta'rnlund 
acknowledgements 
　　　the design of the i n t e r p r e t e r is very much inspired by robert kowalski of 	imperial college 
who v i s i t e d university of stockholm in december 1. james mcskimin of university of maryland and ake llansson of university of stockholm have given many valuable comments on d r a f t s of this paper. david luckham  jorge morales and joachim schreiber of stanford university made the appendix possible. nfr  naturvetenskapliga forskningsradet  and itm   i n s t i t u t e t for tillampad matematik  have p a r t ly supported t h i s work. 
