 
　　this paper describes a domain-independent implementation of explanation-based generalization  ebg  within a logic-programming environment. explanation is interleaved with generalization  so that as the training instance is proven to be a positive example of the goal concept  the generalization is simultaneously created. all aspects of the ebg task are viewed in logic  which provides a clear semantics for ebg  and allows its integration into the logic-programming system. in this light operationally becomes a property requiring explicit reasoning. additionally  viewing ebg in logic clarifies the relation of learning search-control to ebg  and suggests solutions for dealing with imperfect domain theories. 
	i 	introduction 
　　mitchell  keller  and kedar-cabelli  1  present a 
　　unifying framework for an explanation-based approach to generalization. its underlying idea is to form an explanation structure  such as a plan or a proof tree  for a specific situation  and generalize the explanation structure so that it applies to a wider range of situations. explanationbased generalization  ebg  uses a logical representation for knowledge  and an inferential view of problem solving. dejong and mooney  1  suggest a more general term  explanation-based learning  ebl   to also cover systems that may specialize knowledge using information from an explanation structure. they take a problem-space view of problem-solving  in which generalization is a method of acquiring schemata for problem solving. 
   * discussions with paul rosenbloom  devika subramanian  ray mooney  smadar kedar-cabelli  stuart russell  rich keller  allen 
van gelder  and michael genesereth had a significant impact on this work. comments by paul rosenbloom  marianne winslett  stuart russell  and jane hsu on earlier drafts of this paper were invaluable. 
mrs has been developed by the logic group at stanford university; the ebg program was written on top of the existing mrs architecture  and incorporates modified versions of jeff finger's residue method  finger and genesereth 1 . computing resources were funded in part under nih grant rr-1 from the division of research resources biomedical research technology program. the arrangement of facilities at isi by norm sondheimer and bob neches for work on this paper is greatly appreciated. 　　this paper describes the result of viewing all aspects of ebg in the logical formalism of the mrs logicprogramming system  russell 1 . mrs provides many forms of inference  including forward-chaining  backwardchaining  resolution  and residues  a form of abduction that has many similarities to ebg   and allows specification of proof strategies in meta-level theories. the underlying representation of mrs is logic. a user provides the system with a set of rules  and selects a form of inference with which facts are to be proved. the discipline of logic provides a clear semantics for ebg  and allows integration of ebg with other logic-inference methods. under such strict formal representation it becomes possible to reason about operationality  as well as provide a consistent framework for learning search control in ebg. it furthermore clarifies the difficulty of imperfect domain theories in ebg  and suggests some solutions to this problem. 
	ii 	framework 
　　the logical framework of mitchell  keller  and kedarcabelli was taken as the appropriate starting point for this work. ebg takes knowledge  rules and facts  about a goal concept  an instance of the concept  and operationality of predicates. given a specific instance of a concept  the training instance   and knowledge about that concept  the domain theory   the task for ebg is to find a definition of the concept expressible in terms of operational predicates. it does this by using the domain theory to prove that the instance is an example of the goal concept  generalizing the proof to find an operational description of a larger class of instances that are verifiable examples of the goal. 
	i l l 	example 
　　this framework for ebg is illustrated using the safeto-stack example from mitchell  keller  and kedar-cabelli  1 . given the following facts about two objects  objl and 1bj1  that satisfy safe-to-stack 1bjl  1bj1   
	hirsh 	1 

1n 1bj1bj1  isa obj1 box  
isa 1bj1 endtable  
color obj1 red  
color obj1 blue  
volume obj1  
　density 1bjl 1   and rules about the safety of stacking one object on another  with appropriate procedural attachment for  x  and      * 
hot fragile y  - safe-to-stack x y  
lighter x y  - safe-to-stack x y  
volume pl vl adensity pl dl ax vl dl wl  
- weight pi wl  
	isa pl endtable -+weight pl  1  	 default rule  
weight  p1 w1 aweight p1 w1 a  wl w1  
　　　- lighter p1 p1   and facts about the operationally of predicates 
operational volume p v   
operational density p d   
operational 1n x y   operational color p c   
operational isa x o   
operational   x  x  y  z    
　operational   x y    the ebg system should verify that the training instance is indeed a correct example of safe-to-stack  and generalize its verification to form a rule specifying a larger set of cases that are saf e-to-stack: 
volume v1 v1 adensity v1 v1  
　　ax v1 v1 v1  aisa v1 .endtable  a   v1  - safe-to-stack v1 v1 . 
ebg constructs a proof that the example satisfies the goal  as in figure 1. this proof is generalized  resulting in the generalized explanation structure for safe-tostack v1 v1  shown in figure 1. the conjunction of the operational predicates  volume  density  x  isa  and    in the generalized proof form a condition on the generalized goal predicate. mooney and bennett  1  provides more detail on three other versions of ebg. further detail on the implementation of ebg for this work follows. 

figure 1: 	explanation structure  proof tree  for 
safe-to-stack 1bj1bj1  
i v 	i n t e r l e a v e d e x p l a n a t i o n a n d 
g e n e r a l i z a t i o n 
　　as just described  the task of ebg is to prove that an instance is an example of a concept  and generalize the proof to form an operational description of the concept. these two stages  explanation and generalization  are typically done sequentially: after creating a proof  a generalization step forms the operational description from the proof. this work takes a different approach-the two stages are done simultaneously. the system attempts to prove that the instance is an example of the concept  such as safe-to-stack 1bjl 1bj1  above  by backward chaining on the goal through rules until training-instance facts are reached. however  each time a rule is used  it is simultaneously applied backward to the variablized goal concept  such as saf e-to-stack v1  v1    creating the generalized explanation structure in parallel with the instantiated explanation structure. 
　　ebg is started on a specific goal  such as safe-tostack 1bjl 1bj1 . the first step is to find all rules that could potentially conclude this fact  namely all those whose consequent unifies with the goal concept. they are 
　not fragile y  - safe-to-stack x y  and 

　 throughout this paper variables begin with lower-case letters and are assumed to be universally quantified. all relations  including    lighter x y - safe-to-stack x y . 
are written in prefix form  and n-ary functions are written as n+l-ary 
relations  with the result as the additional n+lst argument. 	the first is tried  since it occurs earlier in the data-

safe-to-stack v1 v1  
lighter v1 v1  
figure 1: generalized explanation structure  proof tree  for safe-to-stack 1bjl 1bj1  when weight p v  is operational 
figure 1: generalized explanation structure  proof tree  

for safe-to-stack 1bjl 1bj1  
base   and generates the subtask not  fragile  obj1   by unifying the consequent of the rule with safeto-stack 1bjl 1bj1  and applying the binding list thus formed to the antecedent of the rule. the antecedent becomes the new subtask. the generalized subtask 
not  fragile  v1    is generated in the same way  by unifying the consequent of the rule with the generalized form of the original task  sale-to-stack v1 v1 *  and applying the resulting bindings to the antecedent of the rule  resulting in a new generalized subtask. thus the generalized explanation structure is formed in parallel to the formation of the instantiated explanation structure. 
　　not  fragile   obj1   fails  for lack of applicable rules   so the system backtracks to the earlier goal safe-tostack 1bjl 1bj1   and its generalization  safe-tostack v1 v1 . the second rule is now tried  resulting in lighter  1bjl  1bj1  and lighter  v1 v1 . the backward-chaining process continues  at each step unifying both the current task and its generalization with the consequents of rules and applying the resulting bindings to the antecedents to obtain new subtasks. failure to prove a subtask causes backtracking to an earlier subtask for a different rule selection or variable binding. backtracking also occurs if a subtask is proved  but yet the subtask's generalization is not operational  since ebg must generate an operational definition of the concept. note that backtracking removes all record of failed attempts to prove the task  and thus erroneous proof paths will affect neither the explanation structures  nor ebg's final learned rule. 
　 the generalized form of the first goal  safe-to-stack v1 v1  here  is created by simply taking the non-unified consequent of the rule used to backward chain from the instantiated initial goal. 
　　the above description of backward-chaining on generalized goals while creating the proof has one exception. if a generalized subtask is ever operational  but the instantiated subtask requires further proof  the system merely continues normal proof of the subtask alone. this causes ebg to find more general operational definitions than it might otherwise form. the current generalized subtask becomes a terminal node in the developing generalized explanation structure  without inclusion of any of the subtasks that occur below it. for example  if weight is operational  i.e.  operational  weight  p1  w1   is in the database for safe-to-stack   the resulting generalized explanation structure will be that of figure 1. 
　　the final step of ebg is to form the conjunction of terminal nodes of the generalized explanation structure  and create a rule with this conjunction as the antecedent and the top goal of the generalized explanation structure as its consequent. all bindings formed during creation of the generalized explanation structure are applied to this rule  to handle interacting subgoals correctly. the resulting rule is the final result of ebg. thus 
　weight  v1 v1 aweight v1 v1 a  v1 v1  - safe-to-stack v1 v1  would be the rule learned for the preceding example in which weight is operational. 
　　dejong and mooney  1  point out that there is often more than one way to prove that an example is indeed an instance of a concept  and each such differing proof can result in a different rule from ebg. thus  for example  if the training-instance data for ob j 1 included knowledge for concluding not  fragile  obj1    there would be two ways to prove safe-to-stack objl  1bj1   and thus two rules could be created by ebg  depending on which proof was chosen. as discussed in section vii  such selection is deterministically specified by the order of rules in the 
	hirsh 	1 

domain theory-whichever knowledge came first  fragility or weight  would succeed in creating a proof. however  logic programming systems often provide a means for finding multiple results due to alternative inferential paths. in mrs  if the plural form of an inference method is selected  mrs finds all conclusions that can be found with the specified inference method. since ebg has been implemented as an additional form of inference for mrs  ebgs was also implemented  to allow creation of all rules that can be formed from all possible proofs of the training instance. furthermore  meta-level knowledge can be used to specify which rule to select at any point  thus determining which explanation ebg will form  and hence what the final learned rule will be. 
	v 	o p e r a t i o n a l i t y 
　　operationality criteria are one of the inputs that mitchell  keller  and kedar-cabelli specify for their ebg  but the only operational definition they give for it is  the concept definition must be expressed in terms of the predicates used to describe examples ... or other selected  easily evaluated  predicates from the domain theory.  it is only a small extension to allow specification of any set of predicates  such as including weight in the example above. 
however  dejong and mooney  1  and mooney and 
bennett  1  point out that such simple selection of operational predicates is insufficient  and provide examples in which operationality is a function of the proof structure. in one such example they define operationality to be predicates at terminal nodes of the generalized explanation structure after all predicates that only support isa facts are removed. this dynamic operationality cannot be supported in ebg as described by mitchell  keller  and kedar-cabelli. 
　　another example of dynamic operationality not included in mitchell  keller  and kedar-cabelli  1   nor in dejong and mooney  1  or mooney and bennett  1   is applying a theorem-prover to decide operationality dynamically. since explanation is interleaved with generalization  it becomes easy to prove operationality while the actual goal is being proved. for example  an axiomatization of keller's  1  definition of operationality could be used to determine operationality dynamically  with predicate definitions changing over time as problem solving occurs. the axiomatization could even perforin experimentation or look-ahead search to determine whether a specific predicate is operational. finally  since operationality is now a problem-solving task  ebg can be applied to it as well  resulting in better operationality criteria  suited to the particular task at hand. 
　　deliberate reasoning about operationality allows the user to specify rules about operationality rather than rigidly listing a set of operational predicates. such application of logic programming allows operationality to be defined in terms of proof progress  rather than of the final explanation structure. thus operationality can change while doing explanation. for example  if the logic-programming system provides caching of intermediate results  a rule such as  if a predicate succeeds n times  make it operational   for some n  could be used to specify operationality. 
　　the motivation for making operationality a provable property is the notion of meta-level reasoning in mrs. in mrs  proof strategies can be specified in a meta-level theory. thus  for example  a meta-level rule can specify to try one branch of a proof over another if it uses an arithmetic predicate. the vocabulary already exists within mrs to specify such properties  and hence it becomes easy to specify operationality rules such as 
arithmetic-predicate  pred argi  .. .  arg    
-  operat ional pred argi ... argn  .* 
as another example  the rule specifying  if only one potential path is possible at this point  make the current subtask operational  would use the same meta-level predicates used by meta-level proof strategies in mrs. this notion of operationality is more robust than operationality as specified by mitchell  keller  and kedar-cabelli. 
　　this also highlights the difference between the ebg described here and that of dejong and mooney  1  and mooney and bennett  1 . in their problem-space framework  they simultaneously generate both the instance's explanation structure and the generalized explanation structure. however  during creation of the generalized explanation structure they do not reason about operationality; only later  during the subsequent generalization stage  do they determine operationality and modify the explanation structure.** the generalization stage prunes the generalized explanation structure using operationality  and then uses the resulting abridged structure to form the rule. thus  although much of the work of generalization is accomplished during explanation  they still separate explanation and generalization. 
　　one difficulty with ignoring operationality during explanation generation is that situations can arise in which an explanation is generated from which no operational concept definition can be created  yet other explanations exist from which operational definitions can be formed. since in this work operationality is determined during the explanation process  such situations do not occur. as soon as a branch terminates without an operational definition  backtracking will occur to try to find an alternate proof for the branch from which an operational concept definition can 
*this uses the ability to quantify over predicates in mrs. 
　**the generalized explanation structure is actually represented as an overgeneral explanation structure  with a binding list to sufficiently specialize the structure. since operationality may change the binding list as well  it must also be modified during generalization. be generated. it is impossible to generate a complete explanation structure without simultaneously ending with a 
　generalized explanation structure that has an operational definition of the goal concept. 
	v i 	s e a r c h c o n t r o l 
　　mitchell  keller  and kedar-cabelli include an example of learning search control for integration operators. their domain theory includes the following rules:* 
useful op x  not solved x  asolvable op x   solvable  x  -  

where regress in the last rule propagates y through op. the goal concept is useful 1 x -to learn search control for 1. however  the actual definition for 1 is never given. the hidden definition of regress is the source of all resulting knowledge of op1. 
a footnote of mitchell  keller  and kedar-cabelli 
 1  remarks:  notice that the regression here involves propagating constraints on problem states through problem solving operators. this is a different regression step from the second step  generalization  of the ebg process  in which the goal concept is regressed through the domain theory rules used in the explanation structure.  they are saying that for this task the regress predicate is necessary in addition to ebg's own regression  since it is a different form of regression. the correct distinction  however  is not that they are different regressions  but rather that they are regressing through different knowledge representations. rosenbloom and laird  1  point out that  the ebg implementation of search-control acquisition requires the addition of general interpretive rules to enable search with the task operators and the regression of the solution property through them  while soar makes use of the same goal/problem-space/chunking approach as is used for the rest of the processing.  basically  they are saying that soar has only one way to represent knowledge  and thus only has one form of regression possible. likewise here  the strict enforcement of a logical representation forces representation of all knowledge  including operators  as rules in logic  with only a single form of regression. 
　　thus the distinction is not that soar uses problem spaces  but rather that soar consistently uses a single representation. mapping this back to ebg  using a single representation scheme to represent all information uniformly allows use of a single form of regression. here this means 
　* their domain theory has been modified a bit here for greater clarity. 
representing all information about operators  such ae op1  explicitly as rules in logic. a domain theory for integration satisfying this uniform representation constraint* is 
apply op problem newproblem  
asolvable newproblem  
- useful op problem  
integrat e problem answer  - solvable problem  
any-fn problem -*integrate problem problem  

this database does two things. in addition to making the definitions of operators  such as 1 and 1  explicit  it also makes the notion of state explicit. rather than having functional application of operators within predicates  such as solvable   apply is used as a separate conjunct to create explicitly the state to which predicates will be applied. 
given that op 1 is useful for   i.e.  
useful  as well as proper definitions for 
any-fn  operationally  etc.  the rule learned by ebg  simplified by removing duplicate conjuncts  is 

this is equivalent** to the simpler rule 

which is similar to the rule of mitchell  keller  and kedarcabelli  1 .*** note that the matching predicates of mitchell  keller  and kedar-cabelli  1   matches x.y   are done implicitly with unification  and that regression through operators is done by the same mechanism as regression through rules  since the operators arc rules . 
　*the domain theory has been simplified somewhat for presentation. 
　**a1 other conjuncts of the original antecedent will be true if the antecedent of this simpler rule is true. prieditis and mostow  1  discuss how to use partial evaluation to generate such simplifications automatically. 
 ***the difference  as in rosenbloom and laird  1   is in the representation of integration problems and the applicability of operators to them. the difference is not significant. 
	hirsh 	1 
v i i 	i m p e r f e c t d o m a i n t h e o r i e s 
　　mitchell  keller  and kedar-cabelli point out the reliance ebg has on the user-provided domain theory and identify the issue of imperfect domain theories as a topic for future work. they recognize three sources of imperfection in a domain theory: incompleteness  intractability  and inconsistency. rosenbloom and laird  1  discuss two further sources  incorrectness and defeasibility of domain theories. the precision of a logical view of ebg greatly clarifies these issues  and suggests solutions to some of these issues. 
　　as recognized by mitchell  keller  and kedar-cabelli  and rosenbloom and laird  the existence of a default rule to compute the weight of an endtable in the safe-to-stack example causes difficulties for application of ebg. use of this default rule makes ebg learn an overgeneral rule  since the learned rule has hidden the fact that it was only relevant when the second object's weight was otherwise unprovable. the learned rule will thus allow concluding safe-to-stack for endtables that are not safe-to-stack using the original domain theory. this form of inconsistency raised by mitchell  keller  and kedar-cabelli is the same as the defeasibility issue raised by rosenbloom and laird.* in logic they become the issue of nonmonotonicity. 
　　a theory is monotonic if adding new facts will never invalidate a previously proved fact. if new facts can invalidate previous results  the theory is nonmonotonic. until now domain theories have been viewed as theories in a formal sense. however  when given to a theorem prover  the needs of efficiency outweigh the needs of theory  and extralogical notions such as rule order and default rules must be added. these added computation devices cause monotonic theories to become nonmonotonic. 
　　the saf e-to-stack example has such nonmonotonicity. the order of rules in a database specifies what order the rules will be used in attempting a proof. by ordering the rules in the correct way  a rule can be made to serve as a default  to be used if other means of proof  tried earlier since they occurred earlier in the database  fail. thus  for example  the endtable weight rule was placed after the volume times density weight rule to cause the endtable rule to serve as a default rule. 
　　the cause of these difficulties is the fact that some rules conflict-that more than one rule can be used at the same time for some instances  and that different conclusions can be reached using these different rules. in such cases conflict resolution is necessary to decide which rule to select. the example of rule order above is one simple example of a conflict resolution strategy. the difficulty for 
ebg is that this extra information is not an explicit part 
　*a theory is defeasible if the addition of knowledge can change results. 
of the domain theory  and is thus hidden from the ebg process  which therefore cannot incorporate this information into the learned rule. ebg is only as correct as the information given to it. since knowledge of the default status of the endtable weight rule is kept hidden from ebg  it has no way to learn a correct rule.* 
　　this view of the problem suggests a solution. if the difficulty is that information is hidden  the solution is to make this information explicit. there are two ways to do this. the first is to incorporate conflict resolution decisions into the explanation structure  so that ebg can form rules from all information used in verifying the instance. the domain theory would in effect contains all rules and facts for conflict resolution  and conflict resolution decisions will be incorporated into the explanation structure. thus the explanation structure would include failing branches  which may be used in one of two ways. ebg could learn a rule with an added conjunct saying that weight v1 v1  is not provable using the volume-times-density weight rule. it might alternatively learn a rule with an added conjunct corresponding to the specific reason for the failing branch in the explanation  unprovable  volume  v1  . 
　　as discussed below  such addition of conflict resolution decisions into the explanation structure will often cause ebg to create over-specialized rules. furthermore  conflict-resolution strategies such as rule order are often difficult to encode explicitly for use in the explanation structure. in these cases a second choice  reformulating the domain theory  becomes appropriate. the goal of such reformulation should be to remove all need for conflict resolution  namely  to eliminate overlap in conflicting rules. this can be done using predicates about provability. for example  the following reformulated domain theory for the safe-to-stack example makes the nonmonotonicity of the default rule explicit: 

 note that the volume-times-density weight rule now concludes the new predicate weight 1 rather than weight.  given a database with these rules  ebg will learn the correct rule: 
　* lewis  1  has discussed a similar concept of the safety of production-system learning mechanisms. when priority schemes are used to order productions  the result of composing two productions may be inconsistent with respect to the original production system. 

failure to compute the endtable weight has become explicit in the unprovable weighti v1 v1   conjunct of the new rule. 
　　finally  note that conflict resolution schemes can be used to serve two different purposes. in the safe-to-stack example there are two cases of rule conflict. the first is the two different ways to conclude safe-to-stack x y : unprovable  fragile  y   and lighter x y . in this case rule order has no impact on the correctness of the results of ebg; rule order will only influence the speed with which the system reaches conclusions. on the other hand  the rule order of the two weight rules embodies domain knowledge: the second rule is a default rule  and it is only correct to try it if the first rule fails. it is only this second use of conflict resolution  when it embodies domain knowledge  that can cause ebg to overgeneralize. thus only some conflicting rules need be reformulated to remove the conflict. likewise  only some conflict resolution decisions need be included in the explanation structure. although in both cases ebg learns correct rules when all conflicting rules are addressed  the learned rules will often be over-specialized.* 
	v i i i 	c o n c l u s i o n 
　　this paper has described an implementation of explanation-based generalization  ebg  within a logicprogramming environment  in which generalization is done in parallel with explanation generation. all aspects of ebg are viewed in logic  which clarifies issues of ebg. operationality becomes a provable property requiring explicit reasoning. additionally  logical representation of domain operators unifies regression of constraints through operators with regression of goals through domain rules. finally  overgeneralization by ebg is better understood when viewed from a logic standpoint. making those inconsistencies in a domain theory that are due to nonmonotonicity explicit  either by incorporating conflict resolution decisions into the explanation structure  or by making rules mutually exclusive  removes the cause of overgeneralization for ebg. 
　*soar  laird  rosenhloom  and newell 1  has solved this by providing two forms of preferences  soar's version of conflict resolu tion . necessity preferences  laird  rosenhloom  and newell 1  are used to specify those preferences that embody knowledge of the goal test. the backtracing mechanism used in soar ignores all preferences except necessity p