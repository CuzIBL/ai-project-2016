 
　　we consider the problem of getting a computer to follow reasoning conducted in dynamic logic. this is a recently developed logic of programs that subsumes most existing firstorder logics of programs that manipulate their environment  including floyd's and hoare's logics of partial correctness and manna and waldinger's logic of total correctness. dynamic logic is more closely related to classical first-order logic than any other proposed logic of programs. this simplifies the design of a proof-checker for dynamic logic. work in progress on the implementation of such a program is reported on  and an example machine-checked proof is exhibited. 
introduction 
the logical language. 
　　our objective is to be able to discuss programs with a computer. the prerequisites are a language for holding the conversation in  and reliable criteria for following a line of reasoning expressed in this language. we adopt a simple language having just four basic constructs. three of these constructs come from ordinary logic; they are function symbols  predicate symbols  and logical connectives.  we lump constants and variables together with the zeroary function symbols.  the fourth construct  while not a familiar one in logic  is nevertheless one that occurs in everyday conversations about programs; it is the notion of  after executing program a.  for example we may say in ordinary conversation   after executing the program  is equal to 
1.  
　　while these four constructs may not seem very much to go on  they are in fact sufficient for almost any  first-order  conversation about the input-output behavior of programs. they may express such diverse concepts as partial correctness  termination  equivalence  determinism versus nondeterminism  totality  reversibility of a process  accessibility of states  weakest antecedents  strongest consequents  weakest and strongest invariants  and convergents. they also shed new 
light on the axioms relevant to quantifiers in first-order predicate calculus by treating them from the programmer's point of view rather than the logician's. 
   we abbreviate  after executing program a  	so that the observation of the first paragraph condenses to  we have found it convenient in conversation to pronounce  a  as  box a   	we shall later find useful the dual concept  a1  which we write  o   pronounced  diamond a.  	the notation 
this rtsearch was supported by the advanced research 
projects agency of the department of defense under office of naval rtsearch contract n1s-1. 
is borrowed from modal logic. dynamic logic is more intimately connected with modal logic than one might at first suppose; the connection is discussed in more detail in section 1 of . fischer and ladner  1 demonstrate the connection between various restrictions of dynamic logic and the classical systems k  t  s1 and ss of modal logic. we call  a  and  a  modalities  respectively box and diamond modalities   and formulae of the form  a p and  a p modal formulae. we shall call a quantifier-free logic augmented with such modalities a dynamic logic. syntactically  modalities behave exactly like logical negation; they are placed in front of a formula  and their precedence is such that   is 
 would have been parsed 
the programming language 
　　in order to understand the meaning of a formula such as  we first need a precise account of  we shall think of programs solely in terms of their effect on the state of the world. a state is defined by the values taken on by the function and predicate symbols of the language in some domain.  a logician would call a state an interpretation.  we call the set of all possible states  keeping the domain fixed  the universe. thus a universe is defined by the available function and predicate symbols and the choice of domain. 
　　we could restrict our attention to deterministic programs  permitting us to think of them as functions from states to states. as we shall see later however  reasoning nondeterministically about deterministic programs can simplify the argument. hence we shall allow for nondeterministic programs by capturing the effect of a program on a universe as a binary relation on that universe. this of course means that we will be able to discuss nondeterministic programs in general. however  the question of what first-order facts one wants to assert about nondeterministic programs is presently the subject of much discussion in the literature  see  s  in particular   and we shall avoid that issue in this paper beyond observing that dynamic logic as presented here can express many useful ideas about nondeterministic programs. 
programming constructs 
　　the programs we want to discuss have five constructs. these constructs  while not all entirely conventional  have been chosen primarily for the ease with which one can discuss programs written using them. 
 i  assignments. 	x:=l is an instance of an assignment  as is 
	in general an assignment is a pair 
of terms  respectively the left-hand and right-hand sides of the assignment  of our logical language. 	 a term is an expression 

theorem provlnj-1: 	litvintchouk 


theorem 	proving-1: 	litvintchouk 1 

the second inference rule  really the rule of necessitation 

　　the reader wishing to pursue these concepts further is referred to  1 some simple statements expressible in dynamic logic that do not fall into any of the above categories  and are not expressible in hoare's partial correctness formalism or the total correctness formalism of manna and waldinger   are: 
　　all of the above concepts can be stated in a second order logic that permits explicit manipulation of states and/or 
programs as individuals  as in c1  where states can be quantified over  or  where programs are terms. the interest in dynamic logic is that it achieves its expressive power using only first-order language. the advantage of keeping the language restricted in this way is that it is easier to completely axiomatize parts of the logic  though loops present an insurmountable obstacle to completeness as demonstrated in 
theorem 1 of  1 
an axiom system for dynamic logic 
　　let us now exhibit a sound complete effective axiom system for first-order logic.  by effective we mean one whose axioms form a recursive set and whose inference rules are recursive relations on formulae.  the theorems of the following system are exactly the valid formulae of first order logic. a novelty of this system is that it separates into logical and non-logical components what are usually taken to be entirely logical rules and axioms  on the principle that facts about x:=  are program-specific facts. 
of modal logic  can be considered as an upper bound on the power of programs  which cannot falsify theorems. if p is a theorem then p is true in every state  whence in particular it must be true after executing a. in our system it is straightforward to prove as theorems the axioms of  say  mendelson's system k c1  p. s1   and it should be clear that the second rule subsumes the rule of generalization; in fact  if 
the only modalities allowed are those with values of the form x:=  then the rule of necessitation is the rule of generalization  and the theorems of this system coincide with the theorems of k. it is interesting to note that mendelson manages to express as one axiom what we take two to express  namely our axiom m and the second quantification axiom. the advantage of our decomposition of this axiom is that we get two axioms about quantifiers that serve respectively as a lower and an upper bound on what the binary relation x:=  
may be. 
　　so far we have only given axioms for random assignments. now let us axiomatize the four loop-free programming constructs. 
interestingly  but fairly obviously  as demonstrated in 
 1   the axiom system with these four new axioms remains sound  complete and effective.  it is possible to give further axioms to handle the converse operation  still preserving soundness  completeness and effectiveness. however we shall not make use of this in the following.  
a derived rule 
　　we could at this point proceed with the discussion of our ultimate objective  the construction of a proof-checking program that would check proofs expressed in the above axiom system. unfortunately the above system is too weak to permit reasonably succinct proofs; for example  it appears that 1 lines are needed to prove  x:=1 x=1 from the assumption 1 using the above system. in this section we explore a derived rule with an eye on strengthening the axioms and rules. in this respect we are emulating j.a. robinson   who prescribed a new rule to facilitate the construction of automatic theoremprovers. the constraints on a proof-checker are somewhat different from those of a theorem-prover  and the arguments for robinson's resolution rule are not sufficiently compelling for us. in particular  the convenience of having a clause as the unit of information  which helps an automatic theorem prover organize the proof  may be more hindrance than help in a proof-checker because the user may not have conceived his proof in terms of clauses that are disjunctions of literals. this is not to say that we shall not make use of unification; indeed  unification is a most valuable tool in automated logic. 
theorem 	p r o v i n g - 1 : 	litvintchouk 
1 we now give the details of the rule  which we call the show rule for lack of a more descriptive term. a proof step using it looks like 
　　for the moment ignore the items inside braces { }. ideally  we would like this rule to apply whenever the formulae to  tl  t1 ... logically entail the formula s  a semantic characterization of the rule. unfortunately that would lead to a non-effective proof-checker  since logical entailment is not even partially decidable for our language  1 instead we resort to an effective syntactic characterization. this is where the items in braces enter the picture. the braces enclose  templates  which contain the propositional content of the proof step  in the sense that each template is a propositional  approximation  to the formula it follows. for example  we might say 

     the template paq refers to the result of expanding  and then to 1a1. it should be clear that the two uses of p in the templates refer to the same formula  1  and similarly for the two uses of q. more generally  we shall require only that multiple occurrences of the same letter refer to unifiable formulae. 
　　we check this proof step in two phases  which can be done independently and in either order  or in parallel by two processors . one phase  called identify  is to check that repetitions of the same letter can be justified. we do this by attempting to unify corresponding formulae. the other phase  called verify  is to see whether the templates alone constitute a sound argument in modal propositional logic. in this example all modalities were eliminated so that we were left with the argument 
show paq using p  q 
which is in fact a sound argument of non-modal propositional logic. a situation where modal logic would help is: 
shou 
here we are dealing with  uninterpreted  programs u and v  a situation that arises when we are given a program about which we have previously proved some useful properties and whose code we no longer wish to be bothered with.  this situation arises frequently in the extended example of the next section but one.  in this case  knowing nothing about the programs u and v beyond the facts given  we could not expand them in the way we did with cx:=1  so they carry over to the templates. here the argument of modal logic is: 

this argument can readily be seen to follow if we apply 
necessitation to 	and hence 
. the rest is propositional reasoning. 
the identify phase begins by determining what subformula each occurrence of a template letter refers to. this is done by systematically expanding the formula associated with the template containing the given letter until the formula can be matched to the template. thus will match directly with a matched to u;v  b to w and p however will not match  a  b p directly but must first be expanded as will not match paq directly but must first be expanded as i :1. once the formula matches the template  the subformula corresponding to each letter can immediately be determined. then all the subformulae corresponding to occurrences of the same letter are checked for whether they can be unified. this may require further expansion; for example  attempting to unify i and w 1 involves eliminating the assignment modality to give 1  and instantiating w as 1  this latter step being performed by a unification algorithm. all instantiations necessary must be compatible with each other. 
　　any formulae that fail to unify are put to one side while the remainder of the proof step is checked. when that is done  then the failed pairs are expressed as an equivalence and tested by a routine that checks for validity of quantifier-free presburger arithmetic  in the hope that the formulae turn out to be equivalent on arithmetic grounds.  this together with the rule of convergence described in the next section is the only concession to domain-dependencies in the system.  
　　the verify phase is a satisfiability tester for modal propositional logic. it begins by determining what applications of the rule of necessitation are sufficient to make the proof go through. boxes are then eliminated from the formula by the appropriate generalization of the transformation 
  which preserves satisfiability for tne intuitively obvious reason that  acts only as a constraint on those worlds one might construct  in attempting to satisfy  a    that are accessible via a and satisfy p  namely that in any such world q must be true. in our present implementation  we first eliminate all top-level propositional letters by expressing the formula in conjunctive normal form and applying the davisputnam algorithm for each of those letters. then we convert the resulting formula involving only modalities to disjunctive normal form and apply the above transformation. then the process is repeated on the arguments of the top-level diamond modalities. though this approach can be inefficient  in practice on the kinds of formulae we encounter it is the most efficient of the methods we have tried. with all boxes eliminated  the satisfiability of the result no longer depends on the names of the diamonds; that is   are equally satisfiable. indeed  satisfiability of the whole is preserved if  a p is replaced by true when p is satisfiable and false when not. thus we can proceed recursively  working up from the lowest diamonds to determine satisfiability of progessively larger portions of the formulae. 
axioms for programs with loops 
　　if straight-line programs were all that could be proved correct in our system  it would find relatively little application. for programs with loops we have the following axioms and rules. 
	axioms of intent  one for each n . 

theorem 	p r o v l n g - 1 : 	l i t v l n t c h o u k 
1 


arithmetic  using quasi-gaussian elimination.  
　　the above proof is not the largest proof we have successfully checked with our system. a substantial part of a total correctness proof of the knuth-morris-pratt patternmatching algorithm has been machine-checked  and we are in the process of completing this proof. this extends work on the partial correctness of this algorithm by wegbreit  1 
discussion of the proof-checker 
　　we have constructed a system for checking proofs of the kind exemplified above. in this we are following in the footsteps of milner  1 1   who is doing for scott's logic of computable functions what we are doing for the above modal extension to first-order logic. inasmuch as we are treating programs that manipulate their environments  we are also continuing a tradition of several years of implementing systems for proving and checking proofs of properties of programs  1 1 1. however the greater expressive power of dynamic logic compared to that of partial correctness assertions  the language used in almost all such systems  adds considerably to the interest of our system. this consideration actually makes milner's system a closer relative of ours than the partial correctness systems  due to the greater emphasis on  expressions as first class citizens  in milner's system and ours  resulting in a logic where programs and facts mingle more freely than say with hoare's notation. the major difference between milner's system and ours is the lcf treatment of 
programs  computable functions  as individuals in the underlying domain versus our treatment of programs as  adverbs   analogously to quantifiers. another system related to ours is richard weyhrauch's  1 fol  first-order logic  proofchecker. a detail in which our program differs from milner's and weyhrauch's  apart from the obvious one of choice of logical language  is that our program makes less of an effort to help the user interactively than is done by either lcf or fol  but rather is  at least thus far  a system in which the user prepares his proof exactly as though he were writing a program. this means that his proof exists on a file and is read by the proof-checker just as an interpreter reads a program from a file. this has permitted us to focus all of our effort on the proof-checker proper. 
　　the proof-checker is implemented on the pdp-1 computer at m.i.t.'s artificial intelligence laboratory. the program written to date has aproximately 1 lisp functions comprising a total of 1 lines of code averaging 1 lisp atoms per line. the bulk of this code is for formula manipulation. however  a small amount of it is for book-keeping tasks of a relatively minor nature associated with keeping track of the structure of a proof. 
directions for further research 
　　although our immediate goals may not appear to be particularly ambitious or difficult to achieve  as well as not being obviously  artificial intelligence  research  we admit to far more ambitious and less plausible objectives on a larger time scale. ultimately we see the proof-checker itself becoming a component of a variety of very intelligent programmanipulating programs. this depends on our belief that the ability to check proofs is a vital part of any program that pretends to  understand  some domain of discourse where the discussion is at all involved. two applications that we would like to explore when the proof-checker has reached a satisfactory level of performance are  i  the automatic production of reliable software and  ii  machine-mediated reasoning about programs. our plan of attack for each of these areas is not presently so crisp that we would feel confident embarking on either area forthwith  particularly the second  but we can nevertheless at this early stage present thoughts on these subjects. 
　　the notion of program reliability through correctness proofs has gained momentum in the past few years  spurred on most notably by the axiomatic methods of floyd  1 and hoare  1. as yet there is not a shred of hard evidence to suggest that this approach supplies the most economical approach to reliability  where the economics takes into account both the cost of having unreliable software and the total programming and maintenance cost . indeed  it may well turn out that the bulk of the problems encountered today with unreliable software may be disposed of by a happy combination of a good programming language and a clean programming style. nevertheless  if the proof-oriented approach can be made to work and does not put too great a burden on the programmer and/or the computer  it may provide reliable software at low cost. we feel it is well worth continuing the experiments that have been going on in this area in the past few years. although these experiments have not thus far demonstrated the value of correctness proofs  it is still too early to draw any negative conclusions about the method in general. 
　　from a longer-range viewpoint  the burden of programming should become progressively more the computer's responsibility  requiring the computer to  understand  better the programs it executes. this has been the trend since the first assembler was used  and though the trend is perhaps not as pronounced as some have hoped  there is no doubt that the trend continues. as it does  methods of reasoning about programs will concomitantly become a more essential part of the computer's repertoire. this raises the question of the choice of language most appropriate to such reasoning. in view of the expressive power of dynamic logic we feel that it is worth developing the methodology of reasoning in this language with an eye to automating the reasoning as far as possible. a program like our proof-checker is precisely what is needed in the way of a  black box  that  accepts  a reasonably sized step in a discussion about a program. the sort of machine-mediated discussions we envisage could quite well be cast as proofs  albeit in the form of a dialogue. if the notion of a dialogue as a proof seems strange  visualize a conversation - about a program - punctuated with  i don't see why you need that test there  and  how do you guarantee that x will never become negative   such conversations about programs arise all the time  and it is clear that the questions are referring to proofs  probably expressed informally but proofs nonetheless. one might argue that proof-checking is not understanding  but we would insist that it is at least a component of understanding. 
as humans are taken progressively further out of the loop 
 admittedly a very long-range view  the dialogue will become more of i monologue. however it may still be appropriate for 

theorem provln*-1: li tvfntchouk 1 

the computer to reason about the programs it is contemplating using a language like dynamic logic. thus even in this scenario the basic proof-checking methodology may continue to be used. we should add that we see nothing strange in the idea of a computer checking proofs that it generated itself; the best way to generate proofs may be to propose possibly faulty proofs and subject them to detailed criticism. this would require not only the error-detecting capability of our proposed proof-checker but error-correcting capabilities as well. 
acknowledgments 
　　david harel and albert meyer made substantial contributions to the theoretical underpinnings of dynamic logic. we thank richard weyhrauch and derek oppen for many helpful arpa-net-mediated conversations on proof-checking and theorem-proving. 
bibliography 
ci  aiello  m. and r. w. weyhrauch  checking proofs in the 
metamathematics of first order logic. computer science dept  stanford university  august  1.  so pages . 
c1  ashcroft  e. and z. manna. the translation of 'go to' programs to 'while' programs. stan-cs-1  stanford  ca. 
1. 
♀1  de bakker  j.w.  and d. scott. an outline of a theory of programs. unpublished manuscript  1. 
c1  deutsch  l.p. an interactive program verifier. ph. d. thesis  dept. of computer sci.  u.c. berkeley  1. 
 dijkstra  e. a discipline of programming. prentice-hall  englewood cliffs  nj. 1. 
 fischer  mj. and r.e. ladner. propositional modal logic of programs. proc. 1th ann. acm symp. on theory of 
computing  1  boulder  col.  may 1. 
c1  floyd  r.w. assigning meanings to programs. in mathematical aspects of computer science  ed. j.t. schwartz   1 1. 
 cood  d.l  r.l. london and w.w. bledsoe.  an interactive 
program verification system.  ieee trans. software eng.  se1  1. march 1s. 
 harel  d.  a.r. meyer and v.r. pratt. computability and 
completeness in logics of programs. proc. 1th ann. acm  sicact  symposium on theory of computing  boulder  co  
1. 
c1 hitchcock  p. and d. park. induction rules and termination proofs. in automata  languages and programming  ed. nivat  m.   ir1a. north-holland  1. 
cll  hoare  c.a.r. an axiomatic basis for computer programming. cacm 1  s1-s1. 
 1 hughes  c.e. and mj. cresswell. an introduction to modal logic. london: methuen and co ltd. 1. 
 joyner  w. h.  c. b. leeman  and w. c. carter   automated verification of microprograms   ibm rcs1  april  1.  1 pages  
 king  j.c. a program verifier. proc. ifip cong. 1  northholland  amsterdam  1  1s-1. 
 is  kripke  s. semantical considerations on modal logic. acta philosophica fennica  1 1. 
 manna  z. and a. pnueli. axiomatic approach to total correctness of programs. acta informatica  1  1-1. 
 1   and r. waldinger. is  sometime  sometimes better than  always   intermittent assertions in proving program correctness. proc. 1nd int. conf. on software engineering  oct. 1. 
 mendelson  e. introduction to mathematical logic. van nostrand  n.y. 1. 
 milner  r.c. implementation and applications of scott's 
logic for computable functions. proc. acm conf. on proving 
assertions about programs   sicplan notices  1  1; sicact news  1   1. las cruces  nm  jan. 1. 
 milner  r.  l. morris and m. newey  a logic for 
computable functions with reflexive and polymorphic types  university of edinburgh  lcf report no. 1  january  1s.  1 pages . 
 1 pratt  v.r. semantical considerations on floyd-hoare logic. proc. 1th ann. ieee symp. on foundations of comp. sci.  1.1. 
 robinson  j.a. a machine-oriented logic based on the resolution principle. j. acm 1  1. jan. 1s. 
 sutuki  n.   automatic verification of programs with 
complex data structures   stanford university  aim-1  february 1   1 pages  
 wegbreit  b.  constructive methods in program verification. ieee trans  on software engineering  se-1  1  1. may 1. 
 weyhrauch  r. w.  and a. j. thomas  fol: a proof 
checker for first-order logic. computer science dept  stanford university  aim-1s  september  1.  1 pages . 
 weyhrauch  r.t and r. milner  program semantics and correctness in a mechanized logic. first usa-japan computer conference  1.  1 pages . 

theorem 	proving-1: 	litvintchouk 
1 
