 
the information resources on the web are vast  but much of the web is based on a browsing paradigm that requires someone to actively seek information. instead  one would like to have information agents that continuously attend to one's personal information needs. such agents need to be able to extract the relevant information from web sources  integrate data across sites  and execute efficiently in a networked environment. in this paper i describe the technologies we have developed to rapidly construct and deploy information agents on the web. this includes wrapper learning to convert online sources into agent-friendly resources  query plan-
ning and record linkage to integrate data across 
different sites  and streaming dataflow execution to efficiently execute agent plans. i also describe how we applied this work within the electric elves project to deploy a set of agents for continuous monitoring of travel itineraries. 　we have developed a set of core technologies to simplify the task of building intelligent agents for gathering and monitoring information on the web  knoblock et al  1; 1; barish and knoblock  1  1al. the technologies include the ability to gather information from the web  to link that information with related information  to build plans to integrate 
the various sources of data  and to efficiently execute these plans in the web environment. we have applied these technologies to build agents for a variety of applications  barish et al  1; ambite et a/.  1  including an application for monitoring travel plans from online sources. 
　researchers have developed a variety of agents that have been deployed on the web over the years. some notable systems include the internet softbot  etzioni and weld  1   an agent that interacts with a range of internet resources  bargainfinder  krulwich  1  a comparison shopping agent for cds  shopbot  perkowitz et a/.  1  a system for automatically locating and incorporating new stores into a com-
parison shopping agent  and warren  decker et al  1   a system for gathering data on a financial portfolio. there has also been a significant amount of research on the underly-

1 introduction 
there is a tremendous amount of information available on the 
web  but the access to this information is largely dependent on the information providers. the individual web sites decide what information to provide to the visitors to their site and how a visitor will access that information. there is little in the way of capabilities to combine information across sites and only the most primitive capabilities to monitor information on individual sites. of course  sites may provide integrated access to specific data sources or sophisticated monitoring capabilities on their data  but users of the web are dependent on a site to make these capabilities available. 
　in contrast  imagine a world where access to information is driven by the consumers of the data. where it is not only possible  but simple to task your own personal information agents to gather specific information  monitor for changes in the gathered data  and to notify you of important information or changes. the challenges are that the required information is often embedded in html pages  the data is organized in different ways on different sites  there are a huge number of ways the information could be combined  and it can be slow and cumbersome to combine the information. 
1 
ing technologies required for developing agents on the internet  levy and weld  1 . as noted by etzioni   the web provides a tremendous opportunity for building intelligent software agents. yet  surprisingly few have seized this opportunity. this is almost certainly because there are many technical issues that must be addressed to build such agents. our work is designed to address these issues and simplify the task of building agents for the web. 
　in this paper i first describe an example set of agents for monitoring travel plans. then 1 will briefly describe the technologies that we have developed to gather data from web sources  link data across sources  generate plans to integrate the data  and efficiently execute these plans. finally  i present directions for future research and conclusions. 
1 information agents for monitoring travel 
as part of the electric elves project  chalupsky et a/.  1; 
ambite et al.  1 we have applied our agent technologies to build a set of agents for various tasks including tracking visitor schedules  monitoring meeting schedules  and monitoring a user's travel plans. in the case of monitoring travel plans  this task is particularly well-suited for applying agent technology for several reasons: a  this is a fairly compli-
invited speakers 

cated task with many possible forms of failure ranging from flight cancellations and schedule changes to hotel rooms being given away when a traveler arrives late at night  b  there are a large number of online resources that can be exploited to anticipate problems and keep a traveler informed  and c  these tasks would be tedious and impractical for a human to perform with the same level of attention that could be provided by a set of software agents. 
　to deploy a set of agents for monitoring a planned trip  the user first enters the travel itinerary and then specifies which aspects of the trip she would like to have the agents monitor. a set of information agents are then spawned to perform the requested monitoring activities. for the travel planning application  we developed the following set of agents to monitor a trip: 
price  address  phone number  latitude  longitude  and distance from the user's location. 
　these agents are scheduled to run at regular intervals  where the agents are woken up to perform their task. the agents can cancel their own task once it is complete and can change the interval in which they are run based on the information from other agents. the agents often invoke other agents to help them perform their tasks for example  the flight-status agent calls another agent that extracts the flight status information directly from a web site and it invokes the hotel notification agent  which in turn sends a message to the fax agent. 
　figure 1 shows the messages that various agents generated during actual use of the system. the original set of agents were in use for about a year and then based on feedback and 

  a airfare-monitoring agent that tracks the current price of a flight itinerary. the agent sends a notification on price increases and/or decreases. a traveler might consider retickcting if the price drops significantly below what they paid. 
  a schedule-change agent that keeps track of the pub-lished schedule for a given flight itinerary and notifies a traveler of any change to this itinerary. small schedule changes occur quite frequently  especially if one purchases tickets well in advance of a flight. travel agents are supposed to notify their customers of changes  but one usually arrives at the airport before discovering that the scheduled departure time has changed. 
  a flight-status agent that continually monitors the status of a flight. when a change of status or cancellation is detected  the traveler is immediately notified. this agent also sends a fax to the hotel if the flight arrival is delayed past 1pm in order to ensure that the hotel room is held for the traveler. this agent differs from what is available from commercial sites  such as ual.com  which simply check the status a fixed period of time prior to the flight. in contrast  our agents maintain state and can notify the user of multiple status changes without sending messages that provide no new information. 
an earlier-flight agent that checks for flights that leave before the scheduled flight. it also checks the status of these flights to avoid suggesting delayed or cancelled flights. this agent is particularly handy when one finishes a meeting early or one wants to skip out of a particularly boring meeting. 
a flight-connection agent that monitors a users scheduled flights and if there is a connecting flight it wakes up a few minutes before the projected landing time  checks the status and gate information of the connecting flight and also searches for any earlier flights to the same destination that the user might be able to take instead. this agent is particularly useful when there are only a few minutes to make an earlier connection that is about to depart. 
a restaurant-finding agent that locates the nearest restaurant based on the user's gps location. on request  it suggests the five closest restaurants providing cuisine type  
invited speakers 
requests from the users we recently developed a new set of agents that provide improved capabilities. 
 a  airfare-monitoring agent: airfare dropped message 
the airfare tor your american airlines itinerary  iad - lax  dropped to $1.  b  schedule-change agent: 
the schedule of your united airlines flight 1 has changed from 1 pm to 1 pm. 
 c  flight-status agent: flight delayed message 
your united airlines flight 1 has been delayed. it was originally scheduled to depart at 1 am and is now scheduled to depart at 1 pm. the new arrival time is 1 pm. 
 d  flight-status agent: flight cancelled message 
your delta air lines flight 1 has been cancelled 
 e  flight-status agent: fax to a hotel message 
attention : registration desk 
i am sending this message on behalf of david pynadath  who has a reservation at your hotel. david pynadath is on united airlines 1  which is now scheduled to arrive at iad at 1 pm. since the flight will be arriving late  i would like to request that you indicate this in the reservation so that the room is not given away 
 f  earlier-flight agent: 
the status of your currently scheduled flight is' 
# 1 lax  1 am  - iad  1 pm  1 minutes late 
the following united airlines flight arrives earlier than your flight' 
# 1 lax  1 am  - iad  1 pm  1 minutes late  g  flight-connection agent: 
your connecting united airlines flight 1 will depart at 1 pm  1 minutes late  at gate c1. 
 h  restaurant-finding agent: 
these are the five closest restaurants from your location. 
wingmaster's on i st. american  1 i st nw  1-1  $1  lar 
1  lon: -1  1 miles 
figure 1: actual messages sent by monitoring agents 
1 gathering data from web sources 
a key capability for information agents is the ability to reliably access information. as the web moves towards xml and web services  accessing data could become greatly simplified. however  movement in this direction has been quite 
1 

slow and for various reasons many sources will remain available only in html  so there is still a critical need to turn html sources into agent-enabled sources. 
　the challenge in building wrappers for online sources is how to achieve broad coverage and high accuracy with minimal user input. the two general approaches to this problem are supervised machine learning techniques  kushmerick  1; muslea et al  1; hsu and dung  1  and unsupervised grammar induction techniques  lerman et al.  1; crescenzi et al  1; hong and clark  1 . the unsupervised grammar induction techniques have the advantage of no user input  but they are not able to handle the full range of semistructured sources. in contrast  the supervised learning techniques apply to a wider set of sites  but can require a significant amount of labeled data to achieve high accuracy. 
we developed an machine learning algorithm called 
stalker  muslea et al.  1  that requires labeled data  but attempts to minimize the amount of information that must be provided by a user. given labeled data  the system employs a greedy set covering algorithm to learn extraction rules that define a wrapper for a source. we minimize the amount of labeled data required by decomposing the learning problem into a number of simpler subproblems  which require fewer examples to learn. the decomposition is based on the hierarchical structure of the information in a web source. this approach allows stalker to learn how to extract data from complicated sites that involve lists of information and even arbitrary nesting of embedded lists. 
　an issue for any learning system  even stalker  is that to achieve high accuracy the system must see the right set of examples. since the expectation in a wrapper is to extract the data with 1% accuracy  finding a representative set of examples is a critical part of the problem. rather than relying on the user to identify these examples  we developed an active learning technique called co-testing  muslea et al.  1; muslea  1; muslea et al.  1  that selects the most information examples to label. co-testing works by learning multiple classifiers using different views of the same problem. in the case of wrapper learning  the system exploits the fact that it can learn equally well a classifier by finding landmarks from the beginning of the page or by finding landmarks from the end of the page. the system can then exploit the fact that both classifiers should agree if they have learned the same concept and any disagreement provides a source of training examples. both classifiers are applied to the unlabeled examples and the user is asked to label the examples where there is disagreement. this allows the system to quickly identify the unusual cases in the data set to rapidly converge on an accurate set of extraction rules. 
　another important challenge building wrappers is to ensure that they continue to work properly over time. this problem has not received much attention. the exception is the work by kushmerick  who developed an approach that uses the global properties of a page  such as the density of html tokens on a page  to determine when the page or even the specific information being extracted has changed. the limitation of this approach is that it is too coarse to detect some sites that have changed  lerman et al.  1 . 
we developed a wrapper maintenance system that can re-

figure 1: wrapper induction  verification  and reinduction process 
pair wrappers by learning a description of the content extracted by a wrapper  lerman et al  1 . this approach learns a pattern by using a hierarchy of pattern types  such as number or capitalized word  and then learning a description of the beginning and ending of the information that is being extracted. the resulting description or learned patterns are then stored and compared to the information being extracted. the patterns are compared statistically to avoid false positives due to examples that have not been seen before. in a large test set  this approach was able to identify 1% of the web sites that had changed. 
　once the system has identified a source that has changed  the learned patterns can then be used to automatically relabel the site and run the labeled examples through stalker  the wrapper learning system. the wrapper learning  validation  and reinduction process are illustrated in figure 1. 
1 linking information 
once data has been extracted from a web site  then one frequently needs to combine it with other information in order to perform some task. for example  if one wants to build an agent for recommending nearby restaurants  then one might want to combine the data on a restaurant review site with the department of health site to ensure that the restaurant has an adequate health rating. the problem is that the information on these two distinct sites will often refer to the restaurants in different ways - the name  address  and phone number may all have slight variations that preclude simply joining the two sites across a single attribute. 
　to address this problem  we developed a machine learning approach to record linkage  tejada et ai  1; 1 . in this approach the system  called activeatlas  compares the attributes that are snared across the two data sets and learns two things. first  it uses a committee of decision tree learners to decide whether two records are matched based on the strength of the match of the various attributes  figure 1 . second  it improves the accuracy of these matches by learning an appropriate set of weights on a library of transformation rules  figure 1 . activeatlas takes an active learning approach to 
invited speakers 

figure 1: activeatlas also learns the weighting of the transformation rules for an application 
select examples for the user to label in order maximize the accuracy of the matches and minimize the amount of user input. compared to other approaches to this problem  cohen  1; sarawagi and bhamidipaty  1   the combination of the transformation weight learning and the active learning of the rules allows the system to achieve very high accuracy in matching entities. 
1 planning to integrate sources 
once an agent has access to the sources and can link the data across sources  the problem remains how to compose a set of information sources to perform some task. we developed an approach to automatically planning the integration of these sources to answer queries. in this approach  which is implemented in the ariadne information mediator  knoblock et al  1; 1   the contents of the sources available to the system are described using a common model  ambite et al  1 . the system uses this model to create a plan that specifies both the data sources and the specific operations to be performed to satisfy a request. 
　one of the interesting problems is that due to the large search space and the need to optimize the plans  traditional planning techniques do not scale. to overcome this problem we developed a general-purpose planning approach  called planning by rewriting  ambite and knoblock  1   and we use it as the planner for ariadne  ambite and knoblock  1 . in planning by rewriting  the system starts with an initial  but suboptimal plan  and then the planner performs a local search through the space of plan transformations to maximize the given evaluation criterion. in the query planning application  the planner searches through the space of sources and the operations on these sources to find an efficient way to process a query. figure 1 shows a simple example of how planning by rewriting searches through the space of plan transformations. researchers have explored a variety of approaches to this general problem of planning for information gathering  see  lambrecht and kambhampati  1  for a summary of this work . 
　we are currently exploring planning techniques for composing web services  thakkar et al  1 . the web serfigure 1: planning by rewriting searches through the space of possible transformations on a plan 
vice infrastructure provides access to online sources in a form with which agents can interact without having to construct a wrapper for a site. in addition  the semantic web provides semantic-level descriptions of the services that are available  ankolenkar et al  1 . our approach to integration planning builds on previous work on data integration  levy  1  and applies the inverse rules approach of duschka . 
　one challenge is that the sources available online often have restrictions on how they can be accessed in that certain inputs may be required to access a source. in the inverse rules framework this means that computing a complete set of answers to a query may require recursion. since it can be expensive to execute integration plans in a language such as datalog  we have developed an approach to automatically convert the recursive plans produced by the inverse rules algorithm into a streaming dataflow execution framework that can efficiently execute these plans  thakkar and knoblock  1 . this execution framework is described next. 
1 executing plans 
given a plan for performing some task on the web  an agent needs to be able to efficiently execute this plan. in the web environment  sources can be quite slow and the latencies of the sources are also unpredictable since they can be caused by heavy loads on both servers and networks. since the primary bottleneck of most agent plans on the web is retrieving data from online sources  we would like to execute information requests as early as possible. to address these issues  we have developed a streaming dataflow language and executor  called theseus  barish and knoblock  1a   which is optimized for the web environment in the following three ways. first  since the executor is based on a dataflow paradigm  actions are executed as soon as the data becomes available. second  theseus performs the actions in a plan in separate threads  so they can be run asynchronously and in parallel. third  the system streams the output from one action to the next so that sequential operations can be executed in parallel. 
　theseus is similar to network query engines  such as telegraph  hellerstein et al  1  or tukwila  ives et al  1   

invited speakers 	1 

figure 1: example plan for integrating data from three carrelated sites 
in that they are also streaming dataflow execution systems. however  the network query engines focus on the efficient execution of of xml queries  while thesues provides an expressive language for expressing information gathering and monitoring plans. the theseus language supports capabilities that go beyond network query engines in that it supports recursion  notification operations  and writing and reading from databases to support monitoring tasks. 
　recently we developed an approach to increase the potential parallelism in a streaming dataflow execution system. this optimization technique  called speculative execution  barish and knoblock  1b; 1j  attempts to predict the results of an operation based on data and patterns that it has seen in the past. the predicted results can then be used to speculate about the operations that will need to be performed later in the plan. the system decides where to speculate by analyzing a plan and determining the critical paths. on these paths it then inserts a  speculate  operation  which uses input to earlier operations to predict the input to later operations. the system also inserts a  confirm  operation  which ensures that the final result is correct regardless of whether the prediction is correct. this approach to optimizing streaming dataflow plans can achieve arbitrary speedups by speculating on the speculations. if the system is able to make accurate predictions  the executor could speculate on all of the input  execute the entire plan in parallel  and then confirm all of the results. 
　figure 1 shows an example agent plan for integrating carrelated data from three online sources. this plan first uses the edmunds.com site to find the midsize cars priced between 
$1 and $1. next it selects out those cars made by oldsmobile. then for each of those cars  in parallel it calls both the nhtsa site to get safety reports and the consumer guide site to retrieve car reviews. finally  all of this information is combined into a single report. figure 1 shows an abstract version of the same plan with the speculation operations inserted into the plan. the use of speculative execution in this plan makes it possible to invoke all three web sites in parallel. 
　the effectiveness of the speculation technique depends on making accurate predictions. we have developed a learning system that uses decision tree learning to make predictions on similar inputs and transducer learning to discover patterns in web navigation paths. the learning system is described in more detail in  barish and knoblock  1 . 
figure 1: augmented plan for speculative execution 
1 future directions 
given the growing interest in both web services and the semantic web  hendler  1    we believe it will become easier to rapidly create and deploy agents on the web. as more semantic information becomes available about online sources  we plan to exploit this information to automatically discover and integrate new sources of information. similarly  as web services become available that can support transactions  we plan to move beyond gathering and monitoring of online sources to build agents that perform more complex tasks  such as not just finding the lowest price ticket  but also purchasing it. 
　there are many possible uses of agents for retrieving and monitoring data from online sources. ideally  users could define their own tasks that they want an agent to perform. for example  i might want an agent that monitors airfares and notifies me the moment 1 can buy a ticket to hawaii for less then $1. someone else might want an agent to monitor for travel delays in their connecting airport and notify them when the average delay exceeds 1 minutes. the possibilities arc endless. we are currently working on what we call an agent wizard  which allows the user to define new agents for monitoring tasks simply by answering a set of questions about the task. the resulting system will work similar to the excel chart wizard  which converts numerical data into charts by asking the user a set of questions. the agent wizard will automatically build the corresponding theseus plan and schedule the monitoring task for the user. 
　another exciting direction is to deploy agents to collect and learn about online data and then use the results to make predictions about the world. for example  we recently developed a system called hamlet that advises a user about whether they should immediately buy a ticket on a particular flight or wait for a possible drop in the price  etzioni et al  1. hamlet makes these recommendations by collecting data on the current pricing of flights on a particular route and then learning a model of the pricing in order to make predictions about future price behavior. in a simulation using real data  hamlet was able to save 1 simulated passengers $1  which was 1% of the savings possible with complete knowledge of the future price changes. hamlet provides a compelling example of the potential of information agents. 
1 conclusion 
the world wide web provides a tremendous opportunity for al researchers to build  deploy and test software agents. the 
web provides a real world environment that sidesteps many 
invited speakers 

of the difficult issues of sensing and control and makes it possible to explore higher level capabilities. we have developed the tools and infrastructure for rapidly constructing agents on the web for performing various types of information gathering and integration tasks. 
　while the agents we have developed are extremely useful  there are many interesting and challenging problems that remain to be solved in order to widely deploy agents on the web. agents need to be able to robustly accomplish their tasks  responding appropriately to failures of various types. they must be able to communicate flexibly with people and other software agents  ideally in natural language. they need the ability to explain their behavior  especially as the tasks they perform become more complex. and  of course  we want agents that can learn from their past experience to both broaden their capabilities and improve their performance. 
acknowledgments 
i want to thank my collaborators for their many contributions to the projects described in this paper. steve minton has worked closely with me on defining  building  and executing many of the research projects described here. jose luis ambite  greg barish  maria muslea  jean oh  snehal thakkar  and rattapoon tuchinda all helped build the travel application of the electric elves. ion muslea developed the wrapper learning systems  kristina lerman developed the wrapper maintenance and repair techniques  sheila tejada developed the record linkage approach  snehal thakkar and jose luis ambite developed the various query planning algorithms  and greg barish built the theseus executor and speculative execution techniques. 1 also want to thank both doug dyer and robert herklotz for their support of my research over the years. 
　this research was supported in part by the air force office of scientific research under grant numbers f1-1 and f1-1  in part by the defense advanced research projects agency  darpa  and air force research laboratory under contract/agreement numbers f1-c-1 and f1-1 -1  in part by the united states air force under contract number f1-c-1  and in part by a gift from the microsoft corporation. 
　the u.s.government is authorized to reproduce and distribute reports for governmental purposes notwithstanding any copy right annotation thereon. the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements  cither expressed or implied  of any of the above organizations or any person connected with them. 
