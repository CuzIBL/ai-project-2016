 
this paper describes an efficient control mechanism for incorporating picture-specific context in the task of image interpretation. although other knowledge-based vision systems use general domain context in reducing the computational burden of image interpretation  to our knowledge  this is the first effort in exploring picture-specific collateral information. we assume that constraints on the picture are generated from a natural language understanding module which processes descriptive text accompanying the pictures. we have developed a unified framework for exploiting these constraints both in the object location and identification  labeling  stage. in particular  we describe a technique for incorporating constrained search in context-based vision. finally  we demonstrate the effectiveness of this approach in piction  a system that uses captions to label human faces in newspaper photographs. 
1 	introduction 
to solve the inherently under-constrained task of image interpretation  additional sources of knowledge have successively been added to provide the necessary constraints for the recognition of objects and understanding of scenes. 
　vision systems have attempted to exploit general knowledge assumed applicable to all scenes and specific knowledge of scene objects and their appearance/configuration  model based vision . as a result  complex control strategies to utilize knowledge in the image interpretation task have been suggested. devising control structures for knowledge based vision has been an active area of research since the mid 1's with several refinements of the cycle of perception and the development of hierarchical  heterarchical and blackboard models. see  firschein and fischler  1; chellapa and kashyap  1  for the historical development of control structures in image understanding. 
　*this work was supported in part by arpa contract 1-1. 
1 
there has also been recent work in domain-
independent control structures where interpretation can be formally stated based on the semantics of a standardized representation niemann et a/.  1 . 
1 	collateral based vision 
our research has focused on developing a computational model for  understanding  pictures based on accompanying  descriptive text. understanding a picture can be informally defined as the goal-driven process of locating and identifying objects whose presence in the image is suggested by the accompanying text. the ideas presented in this paper carry the notion of top-down control one step further  incorporating not only general context but a high-level description of the actual picture. 
　we have divided this problem into two major subtasks. the first task is the processing of language input. we are developing a theory called visual semantics which describes a systematic method for extracting and representing useful information from text pertaining to an accompanying picture. this information is represented as a set of constraints. the processing of captions for generating constraints is discussed in  srihari and burhans  1 . the second major task involves the design of an architecture wherein collateral information from text can be efficiently exploited in the process of image interpretation. this second subtask is the focus of this paper. 
　there are several applications which are enabled by collateral-based vision. these include diagram understanding  indexing and retrieval from text/image databases and aerial image analysis. 
　we first present an overview of piction  a caption based face identification system. section 1 discusses control in piction  constraint satisfaction as a model for control  spatial reasoning and a general algorithm which exploits constrained search. the next section highlights some limitations and discusses future work to overcome them. 
1 	piction 
the computational model for collateral-based vision we have developed can be applied to any situation where photos are accompanied by descriptive text. in describing the model however  it is useful to present working examples based on this model. for this reason  we refer to the system piction  srihari et a/.  1   that identifies human faces in newspaper photographs based on information contained in the associated caption. piction is noteworthy since it provides a computationally less expensive alternative to traditional methods of face recognition in situations where pictures are accompanied by descriptive text. traditional methods employ modelmatching techniques and thus require that face models be present for all people  for them to be identified by the system. 

　the four main components of the model are as follows:  i  a natural-language processing  nlp  module   ii  an image understanding  iu  module   iii  a high level control module  and  iv  an integrated language/vision knowledge base. 
the nlp module processes the caption text and expresses the result as a set of constraints. spatial constraints are geometric or topological constraints  such as left-of  above  between  inside  etc. they can be binary or n-ary  and describe inter-object relationships. they are typically used to identify/disambiguate among objects but can also be used to locate them. characteristic constraints are those which describe properties of objects. examples include gender and hair color. finally  contextual constraints are those which describe the setting of the picture  and the predicted ob-
jects in it. for example  the people present  explicitly mentioned in the caption   whether it is an outdoor scene  and general scene context  apartment  airport  etc . 
　the iu module performs two basic functions  the location and segmentation of objects  and the extraction of visual properties. the face-location module govindaraju et a/.  1  is an object locator which uses edge contours as basic features  and a  springs and templates  model in a multi-resolution framework. we are currently improving a simple neural network based gender discriminator. a line detector  bums et ai  1  is being used to construct simple detectors for 1d rectilinear objects. figure 1 is an example of a digitized newspaper photograph and the accompanying caption. the task is to correctly identify each of the seven people mentioned in the caption. information from the caption  in the form of a constraint graph  is used to locate and label faces. figure 1 illustrates some of the constraints which were derived from the caption. the number of faces and the fact that they are aligned in rows is used by a program which locates faces in the image. identification of the faces revolved around the correct interpretation of the word 'surround'. we have interpreted it as an nary constraint involving minimum distances from a given candidate to the rest. the simultaneous satisfaction of this and the remaining constraints resulted in the final  
1 
correct labeling. 
piction has been implemented in loom lsx  
1 . the visual routines have been implemented in c; the system runs on a sun sparestation. 
1 	control in p i c t i o n 
recent work by strat and fischler l1l  discusses the use of context in visual processing  but focuses on the exploitation of low-level collateral information  e.g.  lighting conditions . furthermore  they do not address the generation of these constraints. we present a control strategy which exploits  i  a confident hypothesis of the image contents and  ii  all levels of contextual information to aid the visual processing. 
　our approach is to select a set of object classes of interest which we would like to locate and identify in images. for piction this set has been restricted to one object class  the human face. however  recognizing additional classes of objects  like hats and boxes  may greatly assist us in identifying faces. 
　constraint satisfaction provides a single framework for incorporating spatial  characteristic  contextual and other general domain constraints without having to overspecify control information. however the location of ob-
jects is still performed at the iu level thereby allowing existing object detectors to be integrated into the overall model. 
1 the single object class problem: labeling faces 
for the single object class version of piction  the overall control can be summarized in a few steps : 
  constraint graph generation  hypothesis genera-tion: nlp module  
  face candidate generation  candidate generation : iu module  
  consistent labeling  verification and recognition  
　knowledge of the domain allows us to make simplifying assumptions for spatial reasoning. the assumptions concern spatial representations of objects  frames of reference  scale and rotation invariance. spatial reasoning in this domain involves verification of predicates corresponding to spatial relations.  burhans et a/.  1  

reduction strategies  and involves achieving local  i.e. node and arc  consistency mohr and henderson  1; mohr and masini  1 . this reduces the amount of backtracking required for global consistency. 
　in piction  each variable vi corresponds to an object or person hypothesis  i.e.  object or person predicted to be in the picture by the constraint generator. the domain di for each variable is initialized to the set of all candidates {cii   ...  cim } generated by a call to the face locator. 
　there are 1 types of constraints used in the labeling process. unary constraints typically correspond to characteristic constraints  e.g.  gender  color of hair  etc. . binary constraints typically correspond to spatial constraints  e.g. left-of  above  etc. . n-ary constraints correspond to rules obtained from the domain a priori but applied in a discretionary manner by the constraint satisfier  or n-ary spatial constraints like the 1-ary constraint between. an example of a domain dependent n-ary constraint is one which examines height relationships between people in the same row. it favors those solutions where the vertical positions of faces do not differ significantly and where there is a minimal amount of horizontal overlap. 
　constraint satisfaction in a schema-based methodology has been used in computational vision  eg. the mapsee system mulder et a/.  1 . their approach is that of data driven scene labeling where image features are nodes and possible interpretations form the sets of labels. our application of constraint satisfaction is in a goal-driven image interpretation system where a strong scene hypothesis forms the set of nodes  and located ob-
jects  features  form the sets of labels. the constraints in our system are picture specific as well as domain dependent. 
1 	hyperarc consistency and expensive constraints 
there are two key differences between the statement of piction's constraint satisfaction problem and a traditional csp. traditionally unary constraints are satisfied before higher order constraints. knowing that certain binary constraints are cheaper to evaluate than unary constraints motivated a new algorithm where constraints 

1 

are applied based on cost and reliability measures. additionally  the algorithm can handle n-ary constraints without explicitly computing the complete corresponding n-ary relation  chopra et a/.  1 . 
1 	multiple object classes: generalizing piction 
so far we have seen a control strategy that exploits collateral information to identify objects of a single class in an image. this needs to be extended to more general cases involving multiple object classes. apart from making it applicable to domains with more than one object class of interest  this capability may be required even if there is a single object class of interest. we borrow here the terminology of defining a target vocabulary and a recognition vocabulary  strat  1   even if the target 

vocabulary consists of a single object class  its recognition is greatly enhanced by the development of a large recognition vocabulary. for the example in figure 1  the recognition vocabulary would need to contain picture frames apart from faces. though picture frames may be specific to the newspaper photograph domain  the idea is applicable to other domains with a specific set of interesting objects and a larger set of recognizable objects. 
　we currently assume an unstructured collection of object locators associated with object classes is available. we are designing a hierarchy of object locators that is linked to our semantic lexicon. this lexicon is organized as a comprehensive ontology of object classes. this will enable us to recognize more object classes using the same primitive object locators. we also assume a corresponding set of image processing tools to verify and compare predetermined attributes of instances of these object classes. domain specific knowledge allows us to make assumptions regarding object representations and frame of reference for spatial reasoning. given these assumptions  a naive approach would be: 
  constraint graph generation  same as before  constraints are between objects of same/different classes  
  all object classes candidate generation  apply ob-ject locators for all object classes mentioned in the caption  
  consistent labeling  verification and recognition  
the above scheme is wasteful  since all object classes needn't be identified for the identification of the target vocabulary. it does not exploit locative constraints to reduce the search space and improve the performance of the object locators/candidate generators. 
　the caption of the image in figure 1 is  sharon bottoms and april wade hold a picture of tyler doustou 1. assuming picture frames/portraits in our recognition vocabulary  the relevant constraints generated are included-in tyler doustou  picframel ; left-of sharon bottoms  april wade  
using the naive approach  labeling is impeded by the failure of the face locator to find tyler's face. the picture frame also cannot be labeled as no candidate frame object satisfies the included-in relation with a face candidate. 
constrained search 
to overcome the above limitations  we choose a more complex approach with some semblance to planning. the idea of using partial interpretation results to localize the search for related objects has been used in several vision systems. for example  constrained search is used by selfridge  to guide the search for building shadows  but with minimal spatial reasoning. in section 1 we classified constraints as contextual  spatial and characteristic. when the control algorithm employs any of these constraints to disambiguate candidates  we call them verification constraints and when it employs them 
obtained with permission from the buffalo news 
to locate candidates for an object  we term them locative constraints. we assume cost and reliability measures for our object locators and attribute verifiers are available. the control algorithm loops over three stages: 
  decision stage a complex cost/utility function is employed to decide which object class to detect next  given the current state of the constraint graph and labelings. the factors taken into account for this function are the tool cost  reliability  number of ob-
jects to be found  size of search region  number of constraints between this class and the objects of interest and the level of interest in this particular class of objects. some measures are class specific  tool cost   others are instance specific  number of ob-
jects  and some are dynamic  size of search region . 
  labeling stage: candidates for objects of chosen group are located using the collateral information available. these objects  candidates and the constraint relations between the objects are inserted in a constraint graph representing the partial interpretation. constraint satisfaction techniques are applied to uniquely label the objects. constraints between objects in the new group and between ob-
jects in prior groups and the new ones are satisfied to increment the partial interpretation of the image. 
  propagation stage: any object which has been labeled uniquely in the previous module potentially constrains the search region for those objects involved in a spatial relation with it. the propagation module computes the search region using the labeled object and the type of spatial relation. so far  this spattal prediction has been implemented for binary spatial constraints. 
　the effect of locating objects of a particular class can then be summarized as  i  potential identification of objects already located   ii  labeling and partial identification of current class objects and  iii  constraining and prioritizing the search for some other objects. 
　as we have mentioned  an object locator is parameterized by the number of objects of that particular class. since the actual routines for object-location are not completely accurate  we might obtain too few or too many object candidates. information from the spatial prediction stage is used at this point to attempt a solution. the object locator routines are called again on the constrained search region with relaxed parameters if there were initially too few candidates. if there were extra candidates  the information is used to order the candidates and the top choices are picked. 
　traditionally  planning in vision has been deliberative  i.e. a plan for the entire task is constructed prior to object location based on probabilistic measures garvey  1; ballard et a/.  1 . we employ planning reactively to choose amongst locators using a-priori knowledge as well as the observable situation to minimize computation and maximize accuracy. 
　in addition to verifying spatial relations between object candidates  the spatial reasoning module performs the task of spatial prediction. in the process of interpretation  any object that becomes uniquely labeled can 
1 

serve as a potential reference object. spatial relations between this reference object and other objects not yet located are used to generate search areas for those objects. the simplifying assumption of a known fixed reference frame makes this task relatively simple. 
　as an example of how picture-specific constraints can enable a constrained search for objects  consider figure 1. the object schema for  picture frames  yields the information that it contains a frame/border and an interior and that the border is typically a rectangle or an oval. the other object schema is for faces. based on this  the control module invokes the following operations: 
  since rectangles and ovals are easier to find than faces  the decision stage chooses to look for pictureframe objects first. it finds one candidate  a working constraint graph containing a single node is created and labeling is successful. next  the search region for tyler's face is constrained because of the relation included-in. control loops back to the decision stage 
where the next best class  the only one left in this example  is chosen. 
  the object locator for faces is now called to find 1 faces. the schema contains information that one face must be in a specified constrained area. fig. 1  1nd image  shows the output of the face locator. since the number of candidates  two  is less than the known number of faces  the locator must be called again. since neither of the candidates found is in the constrained region  the missing face must be in it  and the locator is called on this sub-image. the last image on the top of the page shows the output. the rectangle in black is the candidate returned by the face-locator and the grey rectangle is a weaker choice not returned in the first pass. the third face candidate is thus located. 
  the constraint graph is now augmented with 1 more nodes  representing the 1 persons  and initialized with the new labels and 1 constraints  ref. sections   resulting in a successful labeling. 
1 	future work 
the cost function evaluated for different classes in the decision stage is currently based on weights computed by 
1 
trial and error. the encoding of relative tool costs and measures should be made more declarative or learned from a training set. we also need to relax our assumption of a known fixed frame of reference and incorporate progress made in the field of spatial representations. the constrained search paradigm is currently being applied only for spatial relations between objects. we need to explore its application to other visual relations  for example  if darker-than a b  and a is uniquely labeled  then that constrains the value of the characteristic constraint  brightness  of b  and could be used for a locative purpose. 
there are several sources of collateral information which can accompany an image. the task of co-referencing words/phrases in the text with their corresponding image areas is greatly facilitated if deictic input is a|so available. our system does not currently make use of deictic input. 
　we are experimenting with several techniques to find faces given poor edge data. these techniques include the use of color  a more sensitive edge detector  and finding facial features  e.g.  eyes  directly without locating the face contour. we have recently started experimenting with color images. color is useful in several ways; it can help the face locator detect boundaries of objects  and allows us to assert and process additional characteristic constraints of objects. an example of such a characteristic constraint for the face object class is hair color. 
1 	summary 
we have presented a computational model for incorporating picture-specific constraints in the task of image interpretation. we have applied the constraint satisfaction paradigm to this problem. in particular  we have illustrated the use of constrained search in improving the efficiency and accuracy of object locators. a face identification system  piction has been described  which uses collateral information derived from captions to identify human faces in newspaper photographs. we have identified several limitations of the system and have suggested approaches to overcome them. 

acknowledgments 
the authors would like to thank debra burhans  hans chalupsky  venu govindaraju and mahesh venkatraman for their input in writing this paper. 
