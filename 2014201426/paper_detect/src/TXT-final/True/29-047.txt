 
we study the problem of statistically correct inference in networks whose basic representations are population codes. population codes are ubiquitous in the brain  and involve the simultaneous activity of many units coding for some low dimensional quantity. a classic example are place cells in the rat hippocampus: these fire when the animal is at a particular place in an environment  so the underlying quantity has two dimensions of spatial location. we show how to interpret the activity as encoding whole probability distributions over the underlying variable rather then just single values  and propose a method of inductively learning mappings between population codes that are computationally tractable and yet offer good approximations to statistically optimal inference. we simulate the method on some simple examples to prove its competence. 
　in a population code  information about some lowdimensional quantity  such as the position of a visual feature  is represented in the activity of a collection of units  each responding to a limited range of stimuli within this low-dimensional space. strong evidence exists for this form of coding at the sensory input areas of the brain  eg retinotopic and tonotopic maps  as well as at the motor output level  georgopoulos et a/.  1 . evidence is mounting that many other intermediate neural processing areas also use population codes  tanaka  1 . certain important questions about population codes have been extensively investigated  including how to extract an optimal underlying value  salinas and abbott  1; snippe  1  and how to learn such representations  kohonen  1 . however  two important issues have been almost ignored  with the important exception of  anderson  1  . one is the treatment of population codes as encoding whole probability density functions  pdfs  over the underlying quantities rather than just a single 
neural networks 
peter dayan 
mit 
cambridge  ma 	1 	usa dayan psyche.mit.edu 
value. pdfs can convey significant additional information  such as certainty  eg in the existence in an image of the relevant object   as well as the mean and variance  eg in its position . the other issue is how to perform inference in networks whose basic representations are population codes. 
　zemel  dayan  and pouget  have recently presented a general framework for the probabilistic interpretation of population codes in terms of pdfs. in this paper we apply this framework to all the population codes in a processing hierarchy  and suggest an inference method that approximates  in a quantifiable manner  bayesian optimal methods of representing and combining the probability distributions. 
　we first discuss how to interpret pdfs from population codes  and then introduce our framework for combining these codes. we illustrate the techniques with an example based on a form of cue combination. 
1 	an example 
consider the case of a hunter attempting to shoot a pheasant as it flies out of a tree. we'll assume that the hunter uses two cues  a visual cue concerning motion in the tree and an auditory cue based on rustling of the leaves  to estimate the pheasant's size and velocity. based on this estimate  he selects a time and place to fire his shotgun. 
　the combination problem concerns how the two inputs should be combined to produce the output. in the simplest version of the combination problem for this example  visual motion is confined to one part of the tree  and the auditory signal directly corresponds to this visual signal. here these two single-valued inputs  which we will term v and a  give rise to a single output  and the hunter confidently aims his shotgun  to location s . 
　evidence exists that the two inputs and the output information in this example are each represented in neural population codes in some animals. that is  a fixed collection of neurons fire for each of the three variables of interest. the relevant visual input is represented by the 

activity of a population of motion detectors: in monkeys  a particular cortical area  mt  contains cells that selectively respond to motion of a particular velocity within a small range of visual locations. similarly  the relevant auditory input is represented in a population of detectors tuned to particular frequencies and spatial locations in owl auditory cortex  knudsen and konishi  1 ; the frequency may contain important information about the bird's size and speed. directional motor output is also represented in a population code in monkey motor cortex  georgopoulos et a/.  1 . 
　therefore even in the simple version of the problem  the brain does not directly represent the values v  a  and s  but instead represents each in a separate population code. the most straightforward way to solve this problem is to perform an intermediate step of extracting separate single values from the input population codes  combine these values  and then encode these into the motor output population code. however  this seems not to be the strategy actually implemented in the brain  where new population codes appear to be generated directly from old ones. 
　another level of complexity is introduced into the problem when we consider that the inputs may be uncertain or ambiguous. for example  if the wind is blowing  then leaves may be moving all over the tree giving rise to multiple plausible motion hypotheses  while at the same time the auditory cues may be too faint to confidently estimate the motion. the experienced hunter may then be able to narrow down the set of candidate motions based on his knowledge of the combinations of auditory and visual cues  but he might not be able to confidently select a single value. two additional problems are introduced in this more general case. first we must interpret a population code as representing a whole probability distribution over the underlying variable. and then the combination method must preserve the probabilistic in-
formation in the inputs. thus the aim of a combination network is to infer a population code for the motor action that preserves the statistical relationship between the input and output probability distributions. 
1 	theory 
the basic theory underlying the combination of population codes is extremely simple. population codes use the explicit activities  of multiple cells  as in area mt  to code information about the value of an implicit underlying variable x  such as the direction and speed of motion of the leaves . we are interested in the case that the activities r code a whole probability distribution over the underlying variable: 
	consider the example of the hunter. 	activities 
	zemel & dayan 	1 


neural networks 


	zemel & dayan 	1 

neural networks 

1 	discussion 
we have presented a general framework for mapping between population codes that approximates statistically correct inference. the framework applies and extends two recent methods for the probabilistic interpretation of population codes to the problem of combining these codes. this framework has a wide variety of applications  including any context in which probabilistic information from several sources  each represented in a distributed manner  must be combined. the simulation results demonstrate that a feedforward network can capture the appropriate probabilistic relationships between some simple population-coded pdfs. generally  several population-coded inputs should be multiplied  to compute a full joint pdf   but we found empirically that they can be combined reasonably using a non-linearity. 
　a straightforward alternative to the proposed framework would extract single values from the input population codes  combine these values  and then form a new population code at the output. aside from biological realism  the computational advantage of constructing direct mappings between population codes without requiring an intermediate step of extracting single values is that information about whole distributions can be brought to bear-including the ambiguity and uncertainty in the underlying variables. 
　integral to the framework is an interpretation of a population code as encoding a probability distribution over the underlying quantity. the framework can thus be seen as a generalization of  salinas and abbott  1   in which a network is trained to map one population code to another  where each code is interpreted as representing a single value. our method extends this mapping to probabilistic interpretations while maintaining the biologically realistic representations. 
　there are many open issues  particularly understanding the nature of encoding and decoding. both operations are only implicit in the system so some freedom exists in choosing ones appropriate for particular tasks. based on neurobiological and engineering considerations  one expects a consistent interpretation across levels; maintaining this interpretation should lead to a simple learning rule. noise is a second key issue. if constructing one population code from others introduces substantial extra noise  the system will be unable to convey information accurately. here the restriction of the network to feedforward connections might be relaxed in order to allow lateral connections between units within a population  which may be useful in cleaning up the codes. 
