
for many classification tasks a large number of instances available for training are unlabeled and the cost associated with the labeling process varies over the input space. meanwhile  virtually all these problems require classifiers that minimize a nonuniformloss functionassociated with the classification decisions  rather than the accuracy or number of errors . for example  to train pattern classification models for a network intrusion detection task  experts need to analyze network events and assign them labels. this can be a very costly procedure if the instances to be labeled are selected at random. in the meantime  the loss associated with mislabeling an intrusion is much higher than the loss associated with the opposite error  i.e.  labeling a legal event as being an intrusion .
as a result  to address these types of tasks  practitioners need tools that minimize the total cost computed as a sum of the cost of labeling and the loss associated with the decisions. this paper describes an approach for addressing this problem.
1 introduction
a number of applications require learning algorithms that are capable  1  to learn from both labeled and unlabeled examples   1  to minimize the cost non-uniform associated with the labeling efforts  and  1  to minimize the misclassification loss.
모the active learning framework  cohn et al.  1  relies on algorithms that select unlabeled instances and provide them to the expert for labeling and learn a classifier based on the labeled data. in most of the cases the data is labeled incrementally and the classification model tries to minimize the misclassification error rate. to our knowledge  virtually all research efforts in active learning have assumed both a uniform loss function  for which the goal was to reduce the number of misclassifications  and a uniformlabelingcost function  for which the goal was to reduce the number of instances that have to be labeled to achieve a certain accuracy .
meanwhile  research in cost-sensitive learning  elkan 
1  has focused mostly on the problem of minimizing the expected loss of the learned models  and has assumed that all  training  instances and their labels were readily available prior to the training phase.
모our approach in addressing the active cost-sensitive learning problem is based on learning algorithms that construct models for conditional density  or class probability  estimation p y|x   rather than class label predictors. the probability estimates provide an easy means for factoring in the misclassification losses in the classification decision making step. to address the labeling cost problem  we employ the same density estimation techniques over the available unlabeled data. the two methods are then combined into an algorithm that minimizes the combined cost.
모next section presents the general framework for our proposed techniques and discusses the challenges in implementing and applying these algorithms as well as some preliminary experimental results.
1 active learning for minimizing the combined costs for labeling and decisions
most learning algorithms can be transformed into class probability estimators that computeestimates p y|x  for the probabilities that an instance x is in class y  y 뫍 {1...k}  where k is the number of classes . we employ these estimates in our algorithm both for minimizing the labeling costs and the misclassification decisions. we make the assumption that the loss function associated with the decisions is represented as a static k-by-k loss matrix l available at learning time. the contents of l i j  specify the cost incurred when an example is predicted to be in class i when in fact it belongs to class j.
모the pseudo code for our approach  active-csl  is presented in table 1.
모the algorithm trains a base learner to compute the class probability estimates over the unlabeled data  line 1 . then  both the sampling step  line 1  and the decision making step  the hypothesis h  are based on those estimates. the unlabeled instance for which the next label is requested from the expert is selected in line 1. the selection rule chooses the instance that  if labeled provides the most expected gain in terms of the total cost  labeling + decision loss  on the labeled instances  or on a hold-out labeled validation set . it is important to note that iff c and l functions have a shape such that instances that are more expensive to label reduce the table 1: pseudo code for the active-csl active costsensitive learning algorithm.
input: a set sl  of m labeled examples:
sl =   xi yi  i = 1 ... m    a set su of v unlabeled examples: su =   뷅i  i = 1 ... v   
모모모l  a loss matrix   c  a labeling cost function  a stopping criterion  repeat
 for each j learn p y|뷅j  using sl as training data;  l = argmin c 뷅 +
뷅뫍s
;
 뷍l = requested label for 뷅l;
 remove 뷅l from su  add  뷅l 뷍l  to sl;
 while stopping criterion not met
                     k output: h x  = argmin
j=1
// the optimal classification with respect to l and p
misclassification cost more than instances that are less expensive to label - the selection rule will trade the loss associated with misclassifications against examples to be labeled. the procedure selecting for the next instance to be labeled  as employed by active-csl  and based on computing the maximum expected gain upon labeling  the second sum in line 1   is somewhat similar in nature to the querying rule of uncertainty sampling  lewis and catlett  1 .
모one important detail that needs to be addressed when applying this algorithm in practice is the choice for the algorithm used for estimating the probabilities  line 1 in table 1   given that active-csl and its predictions rely on these estimates. in general  the quality of learned density estimates is dependent on the amount and the distribution of the labeled data that is available and on the hypothesis constructed by the base learning algorithm. several research studies have addressed the problem of learning good probability estimates and calibrating classification scores and ranks into accurate probabilities  zadrozny and elkan  1 .
모we have implemented and tested active-csl by using bagged probability estimation trees  provost and domingos  1  as class probability estimators  in line 1 of the code . we have compared two procedures for computing probability estimates out of the bagged trees:  a  by averaging the probabilities computed by the individual trees and  b  by estimating the confidence for the individual probabilities based on the distribution of the estimates of the individual trees  as suggested by  margineantu  1  . for assessing the quality of the misclassification decisions we have employed active learning curves  showing the gain in terms of cost compared to a random selection of instances for labeling  and bdeltacost  margineantu and dietterich  1  - a paired test for cost-sensitive classification decisions. the loss matrices for our experiments were generated based on some generic loss models  and the labeling cost function mapped instances that were closer to the decision boundary to higher labeling costs  the actual function we employed was a bell-shaped function with a maximum on the decision boundary .
모we tested the two implementations of active-csl on five data sets from the uc irvinerepository  blake and merz  1   breast cancer wisconsin  horse colic  king-rook vs. king-pawn  liver disease  and sonar  and on the binary version of the kdd cup 1 donations data.
모the preliminary results show a minor advantage of the implementation employing confidence-based estimates over the implementation using averaged probability estimates. we have also run tests by employing random forests with logm attributes tested in a node  breiman  1  as the class probability estimator and the results show no significant difference between the classification decisions based on random forests and the decisions based on bagged probability estimation trees.
