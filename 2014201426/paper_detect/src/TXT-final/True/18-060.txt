. the method of differences refers to a technique for image matching that uses the intensity gradient of the image to iteratively improve the match between the two images. used in an iterative scheme combined with image smoothing  the method exhibits good accuracy and a wide convergence range. in this paper we show how the technique ran be used to directly solve for the parameters relating two cameras viewing the same scene. the resulting algorithm can be used for optical navigation  which has applications in robot arm guidance and autonomous roving vehicle navigation. because of the regular structure of the algorithm  the prospects of carrying it out with specialpurpose hardware for real-time control of a robot seem good. we present experimental results demonstrating the accuracy and range of convergence that can be expected from the algorithm. 
1. introduction 
　　optical navigation refers to the determination of the position and orientation of a camera analysis of the picture taken by the camera. the objective of such analysis is to determine some or all of the six parameters  three of position and three of orientation  that determine the position of that camera relative to some fixed frame of reference. in our method and in many others the fixed frame of reference is that of a second camera  so that the problem is that of image comparison. 
　　optical navigation has a number of applications in robotic tasks that require a knowledge of the position and orientation of the robot. this is because mechanical imperfections and environmental uncertainty make it impossible to know exactly how a robot will move in response to the commands sent to it and exactly what it will encounter in its surroundings. such applications include navigation of autonomous roving vehicles and navigation of a robot arm relative to the object on which it is performing its task. 
　　tin - research was sponsoied by the defense advanced research iv.nrrls a   '!   v  | oi  . aki'a order no ;:.v. 1. monitored by the an tore . aviom  laboratory lndei cont ra  t f .'l'io i f --1 l-k-1 vjo. the views .iiid eoiielusioiis contained m this doriiment are those of the  -nit|i ii  and should not be interpreted as representing the olli  la! policies  either expressed or implied  of the defense advanced research projects agency or the us  government. 
　　the approaches to matching for optical navigation may be divided into three categories; sparse twodimensional matching  continuous two-dimensional matching  and three-dimensional matching. the sparse twodimensional approach starts with a discrete set of matching points in the two images  and from them deduces the camera motion. the question of how many points are necessary to uniquely solve for the camera parameters has been addressed by tsai & huang  1 . with more points  the problem is overspecihed and a least squares approach is required  gennery  1 . the continuous twodimensional matching approach starts with a whole image field of matches  the  optical flow field  ; brass &' horn  1  have shown how how to determine the camera motion from the optical flow field  again using a least-squares formulation. obtaining the optical flow field has been investigated by  for example  horn & schunck  1  and cornelius k kanade  1   among others. in the threedimensional matching approach  corresponding points in three dimensions  obtained e.g. by stereo  are used to determine the camera motion; this technique was used by moraver  1  to navigate a rover. 
　　these approaches all split the process into two steps: finding the matches and using those matches to solve for the camera parameters. in this paper we show how to combine the two steps into one  by applying a generalized image matching technique that we term the method of dif-
ferences. the method of differences directly computes the six camera parameters  or any desired subset of them  much as standard matching techniques compute two parameters  the :r and i/ displacements . that is  the camera parameters are explicitly included in the matching process. the method takes advantage of the fact that  in many applications the approximate position and orientation of the camera are known. starting from that estimate we compute a better estimate by using the image intensity gradient as a 
guide. by using an iterative scheme our estimates converge to the correct value. the result is a technique that is fast and free of search. 
　　in the remainder of the paper  we first describe the method of differences in a one-dimensional case  which serves to illustrate many of the issues. then we show how the same technique can be used for multi-parameter estimation. finally  we present some experimental results and draw some conclusions. 

1 b. lucas and t. kanade 

　　we have shown elsewhere  lucas  1  how this method is easily extended to multi-parameter estimation  as required for navigation. briefly  the scalar disparity h is replaced by a vector of camera parameters; the derivatives become gradients  and the division becomes a matrix inversion. the stability of the matrix inversion is investigated in the work cited above  with the conclusion that the matching points should be well-distributed in three-space to guarantee good numerical accuracy. 
　　iteration and smoothing. two modifications are required to make the method work. first  because the method yields only an approximation h to the disparity h  we must use an iterative scheme to obtain an accurate result. the idea is to calculate an estimated disparity  move i1 by that amount  and calculate again. 
　　second  to improve the accuracy and range of validity of the linear estimate used in  1   we must smooth the image. this can be thought of as smoothing out purely local bumps and wrinkles in the image intensity profile that would make a linear estimate accurate only over a small range. this can be made more precise by a fourier analysis of  1 ; this shows that removing the high frequency components of the image by smoothing does indeed extend the range of convergence  in rough proportion to the size of the smoothing window  lucas  1 . this is because convergence to the correct value with an image consisting of a pure sine wave is possible only for disparities up to one-half the wavelength of the sine wave; for larger disparities  the algorithm will converge to the wrong value. 
　　since smoothing the image also reduces the accuracy of the method  it is necessary to use an iterative approach in which each successive step uses a less smoothed image  in a sort of coarse fine approach. this allows the algorithm to tolerate a large disparity yet yield an accurate answer. 
1. experimental results 
　　our experimental data consisted of three views of the same scene taken by a camera mounted on the stanford cart  moravec  1 ; they are shown in figure 1. the camera was mounted on a slider  so we had accurate knowledge of the relative positions of the cameras. the three views were pictures taken by the camera at the left  middle  and right slider positions  with 1 cm separating each position. the left picture was used as the reference image  and a number of points p were selected from this image as reference points. these points correspond to the points x that the sum in  i  runs over. 'then the right picture was used as the second image of a stereo pair to obtain  essentially by hand  the distances - p  of the reference points p. the method of differences was then used to determine position of the middle camera. since the exact position of the middle camera was known  we could assess the accuracy of the method. moreover  we could determine the range of convergence by varying the initial estimate of the middle camera's position around the correct value. 
　　convergence range. the convergence range for both the one-dimensional case and the multi-dimensional case was investigated using these pictures. as predicted  the convergence ranged was found to increase in rough proportion to the size of the smoothing window. the range for x and y motions was roughly ＼1 meter  and somewhat more in the z direction. the range for pan and tilt was approximately i 1 degrees  and about .1 degrees for roll. except for roll  these parameters are limited more by the angle of view of the camera than by the technique. for example  no matching technique could work if there angle of view is so small and the motion between the cameras so large that there is no overlap between the pictures. when this point is reached  the smoothing window required would be so large that each picture would be smoothed to a uniform gray. nevertheless  these results are useful in that they verify that a useful range of convergence is obtainable using the method. 
　　what is the relationship between these convergence ranges and the convergence ranges in the multi-parameter case  this is shown in figure 1. we see that if we solve for two parameters  pan and tilt  top graph   the range is smaller than the range that would he expected on the basis of the one-parameter results for pan and tilt alone; and if we solve for all six parameters  bottom graph   it is smaller still. nevertheless  the range is still quite adequate for the continuous feedback mode. whether it is adequate for  he stopand-go mode  which involves a larger motion at each step  depends on the accuracy of the aim and on the accuracy of other navigational aids that can provide the initial estimates. 
　　accuracy. to assess the accuracy under a variety of conditions  we select reference points using a variety of methods  including by hand and by computer  resulting in several sets of data points of various sizes. then we doubled the number of sets of reference points by either applying or not applying a pruning process to the sets we had. this pruning process  which is described elsewhere  lucas  
1   was based on the method of differences and served to improve the accuracy of the stereo matches. it also eliminated some points as being unlit for use by the method  for example because they were in a region of small gradient. the results are shown in figure 1. several general trends are observable. first  using more points produces more accurate results. second  the pruning process can to improve the results  as evidenced by the left endpoints of the lines in the figure being lower than the right endpoints. these two factors are of course in conflict  and the improvement due to the pruning process is apparent only provided the number of points is not reduced too much  finally  the accuracy does not seem to he affected much by the number of parameters solved for. 
　　implementation. the implementation may be divided into two parts: smoothing and camera parameter estimation. the smoothing must be done over a relatively large window  up to g1 x 1 in our experiments. it is the most time-consuming  part even though we implemented it as uniform smoothing over a rectangular region  which by a well known algorithm takes a constant number of operations  two additions and two subtractions  per pixel  regardless of the size of the smoothing window. however  it is fairly well understood how to build special-purpose hardware for doing smoothing quickly  essentially in real time. 
　　the parameter estimation step is more interesting. our implementation  in which no attention was paid to efficiency  requires approximately 1 to 1 ms per reference point per iteration on a vax 1. in the continuous feedback mode  only one iteration per time step would be used since only an approximate answer is needed. thus 1 reference points  the largest number used in the experiments reported above  would require less than 1 ms per time step. this figure could probably be improved severalfold by more careful coding and taking account of the fact that some of the entries in the matrices to be inverted are known a priori to be zero. this information  together with the fact that the algorithm has a regular structure free of 
b. lucas and t. kanade 1 
decision points that could easily be implemented in specialpurpose hardware  suggests that it is feasible for real-time control of a robot. 
1. conclusions 
　　we have demonstrated that the method of differences provides a useful technique for optical navigation. we have shown that the algorithm can successfully determine all six camera parameters. it converges to the correct position given an estimate within something on the order of a meter  less if more parameters are solved for   and converges to a result accurate to a centimeter or so  regardless of the number of parameters solved for . moreover  it can do so using 1 or less reference points. because of the regular structure of the algorithm  the prospects of carrying out the calculations in real time with special-purpose hardware seem good. 
1. 