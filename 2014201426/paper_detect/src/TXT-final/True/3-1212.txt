
the purpose of this paper is to address the problem of maintainingcoherentperceptualinformation in a mobile robotic system working over extended periods of time  interacting with a user and using multiple sensing modalities to gather information about the environment and specific objects. we present a system which is able to use spatial and olfactory sensors to patrol a corridor and execute user requested tasks. to cope with perceptualmaintenance we present an extension of the anchoring framework capable of maintaining the correspondence between sensor data and the symbolic descriptions referring to objects. it is also capable of tracking and acquiring information from observations derived from sensor-data as well as information from a priori symbolic concepts. the general system is described and an experimental validation on a mobile robot is presented.
1	introduction
consider a scenario where a mobile robot is patrolling a corridor. its task is to discover new objects and gather information about them using both traditional modalities such as vision and sonar and also non-traditional modalities such as an electronic nose. a user is able to monitor the robot  suggest actions to improve perceptual performance and request the robot to perform specific tasks. tasks are requested from the user using a symbolic representation consisting of natural language concepts. while no requests by the user are given  the robot autonomously prioritises tasks alternating between patrolling the corridor and inspecting objects or simply waiting on stand-by.
¡¡an important facet to this scenario  and scenarios of a similar nature  is the ability to maintain coherent perceptual information. this means that the system should be able to maintain the correspondence between the symbolic representation of objects  requests fromthe user  and the perceptualdata that refers to them. the system should collect information from different sensing modalities working concurrently and/or sequentially and correctly attribute that information to its internal representation of the object. the system should include the preservation of object consistency  so that new information about previously seen objects is also correctly attributed. all the while  the insertion and/or removal of objects from the environment needs to be considered and accounted for. from a cognitive perspective  the maintenance of perceptual information is an integral part of the binding problem  blackmore  1 . that is  how the conjunction of properties are represented  ranging from the binding of shape and colour in detecting blue triangles or red squares to the binding that must occur between and within the senses:  the way the smell and touch and sight of the sandwich in your hand all seem to belong to the same object   blackmore  1   p.1 .
¡¡for robotic systems  an important ingredient for maintaining perceptual information is an internal structure to store a representation of an object. such an internal structure needs to satisfy a series of requirements. on one hand  perception management  ronnie et al.  1   an extension of sensor management  adrian  1   is required to integrate highlevel informationabout the state of the object in orderto make situation dependent decisions  direct control and select sensing actions. on the other hand  tracking and data association are also fundamental ingredients necessary to propagate information about coherent perceptions over time  d.schulz et al.  1 . a third requirement  especially in the context of a cognitive robot  involves processes  which can create and maintain the link between high-level information  e.g. symbols  and low-level percepts.
¡¡in this paper  we show how the concept of anchoring can be used as a tool to confront some of the issues relating to perception management. the anchoring framework  coradeschi and saffiotti  1  aims at defining a theoretical basis for grounding symbols to percepts originating from physical objects. we present an extension of the framework that is able to cope with perception management considering multisensing resources and temporal factors. the pivot of this extension is the use of anchors as internal representations of objects that integrate symbolic and perceptual information across time and across sensing modalities. our ultimate aim is to shed light on this important aspect of cognitive robotics as applications extend into realistic environments involving human-robot interactions and lifelong acquisition of knowledge.
¡¡we begin our discussions with a description and review of the anchoring framework in section 1. we then present a modification of the anchoring framework in section 1 which is adapted for the task of perception maintanance. we proceed by detailing the robotic system architecture used in our experiments. section 1 gives the implementation details and provides a performanceexample of the complete system. the paper concludes with a summary of the presented work.
1	the anchoring framework
to date  the anchoring framework presented by  coradeschi and saffiotti  1  has mainly been considered in the context of abstraction of perceptual information. this includes association of words to visually recognised objects  knoblauch et al.  1   managing of dynamic object anchoring for highlevel reasoning  chella et al.  1  and preliminary works considering people tracking applications  kleinehagenbrock et al.  1 . a good overview of the range of applications of the anchoring concept is found in 1 robotics and autonomoussystems special issue on anchoringsymbols to sensor data  coradeschi and saffiotti  1 .
¡¡before we present our extension of the framework  we summarise here the basic elements of the computational theory of anchoring. see    for a full account. the theory considers an autonomous system that includes a symbol system and a perceptual system  and it focuses on the problem of creating and maintaining a correspondence between symbols and percepts that refer to the same physical object. the main ingredients of anchoring are the following  coradeschi and saffiotti  1 :
  a symbol system including: a set x = {x1 x1 ...} of individual symbols  variables and constants ; a set p = {p1 p1 ...} of predicate symbols; and an inference mechanism whose details are not relevant here.
  a perceptual system including: a set ¦° = {¦Ð1 ¦Ð1 ...} of percepts; a set ¦µ = {¦Õ1 ¦Õ1 ...} of attributes; and perceptual routines whose details are not relevant here. a percept is a structured collection of measurements assumed to originate from the same physical object; an attribute ¦Õi is a measurable property of percepts  with values in the domain di.
¡¡the symbol system manipulates individual symbols  like 'cup-1'  which are meant to denote physical objects and associates each individual symbol with a set of symbolic predicates  like 'red'  that assert properties of the corresponding object. the perceptual system generates percepts and associates each percept with the observed values of a set of measurable attributes. the task of anchoring is to create  and maintain in time  the correspondence between individual symbols and percepts that refer to the same physical objects.
¡¡the symbol-percept correspondence is reified in an internal data structure ¦Á  called an anchor. since new percepts are generated continuously within the perceptual system  this correspondence is indexed by time. it is important that the connections are dynamic  since the same symbol may be connected to new percepts every time a new observation of the corresponding object is acquired.
¡¡at every moment t  ¦Á t  contains: a symbol  meant to denote an object; a percept  generated by observing that object; and a signature  a collection of property values meant to provide the  best  estimate of the values of the observable properties of the object.
1	anchoring for perception management
in this section  we present our extension to the anchoring framework. what makes this contribution unique is that we extend the applications of anchoring beyond its traditional use of data abstraction to also include percepts from different modalities that may be accessible at different times.
¡¡to effectively present our extension  we refer to the three abstract functionalities defined by  coradeschi and saffiotti  1 . used to manage anchors  namely  find  reacquire  and track. the functionalities have been developed for the consideration of top-down approaches for information acquisition  i.e. imposed a priori symbolic concepts . in this paper  we revise these existing functionalities to include bottom-up approaches so that anchors can be created by perceptual observations derived from interactions with the environment. bottom-up approaches have previously been considered on anchoring frameworks  knoblauch et al.  1  but never in conjunction with top-down approaches. we advocate the presence of both approaches  in particular for robotic systems interacting with a human user. to accomplish this  an additional acquire functionality is introduced.
1	creation of anchors
the creation of anchors can occur in both a top-down and bottom-up fashion. bottom-up acquisition is driven by an event originating from a sensing resource  e.g. the recognition of a segmented region in an image  when perceptual information which cannot be associated to any existing anchor is perceived. top-down acquisition occurs when a symbol needs to be anchored to a percept  such a call may originate from an external user or a top-level module  e.g. planner .
acquire initiates a new anchor whenever a percept is received which currently does not match any existing anchor. it takes a percept ¦Ð  and return an anchor ¦Á defined at t and undefined elsewhere. to make this problem tractable  a priori information is given with regards to which percepts to consider. in bottom-up acquisition  a randomly generated symbol is attributed to the anchor. furthermore  information about the object and its properties are included into the world model used by the planner  in this way the object can be reasoned about and acted upon.
find takes a symbol x and a symbolic description and returns an anchor ¦Á defined at t  and possibly undefined elsewhere . it checks if existing anchors that have already been created by the acquire satisfy the symbolic description  and in that case  it selects one. otherwise  it performs a similar check with existing percepts  in case  the description does not satisfy the constraint of percepts considered by the acquire . if a matching percept is found an anchor is created. matching of anchor or percept can be either partial or complete. it is partial if all the observed properties in the percept or anchor match

figure 1: overview of the robotic system which uses the an-figure 1: graphical illustration of the extended anchoring functionalities where bottom-up and top-down information is possible and different sensing modalities are used.
the description  but there are some properties in the description that have not been observed.
1	maintenance of anchors
at each perceptual cycle  when new perceptual information is received  it is important to determine if the new perceptual information should be associated to existing anchors. the following functionality addresses the problem of tracking objects over time. in this extension  we include the previous reacquire functionality as an integral part of the track and make no special distinction for it.
track the track functionality takes an anchor ¦Á defined for t   k and extends its definition to t. the track assures that the percept pointed to by the anchor is the most recent and adequate perceptual representation of the object. we consider that the signatures can be updated as well as replaced but by preserving the anchor structure we affirm the persistence of the object so that it can be used even when the object is out of view. this facilitates the maintenance of information while the robot is moving as well as maintaining a longer term and stable representation of the world on a symbolic level without catering to perceptual glitches.
1	deletion of anchors
by having an anchor structure maintained over time  it is possible to preserve the perceptual information even if the object is not currently perceived  caused by the object being out of view and/or by the inaccuracy in the measurement of perceptual data . the challenge is to determine if the association of new percepts is justified or whether certain anchors should be removed. mechanisms for destroying anchors when the corresponding object has been removed need to be in place. this is a difficult problem  because conceptuallyit is not clear

choring module. arrows indicate the flow of information.
when it is appropriate to remove anchors from the system. anchors could be removed if they are not relevant for the current task  because the object to which it refers has been physically removed from the environment or the reliability of the perceptual information has expired. anchors may also need to be removed if they have been associated to invalid perceptual data such as sensory glitches. we currently adopt simple solutions in which objects that are not perceived when expected decrease in a  life  value of the respective anchor. when the anchor has no remaining life  the anchor is removed. the converse could be implemented where anchors are created with initially lowlife values and persistent percepts increase its life value. the decreasing life of anchors is shown in figure 1. a more adequate strategy to handle the maintenance of anchors may also be to include a  long term  memory where anchors may be stored for future use.
1 integration of the functionalities the event-based functionalities are now restricted to the find and acquire while the track functionalityis regularlycalled. figure 1 shows an overview and an exampleof the framework and its functionalities. in the example  anchors are created bottom-up from the visual percepts of a cup. later  additional features of that object are required  for example  the olfactory property. these features are stored in the anchor. when a top-down request is sent to the anchor module to find a cup with matching properties denoted by the symbol  cup-1   the find functionality anchors the symbol to the perceptual data.
figure 1:  left  the local space shows the detected objects  the robot is located in the center of the space. grey areas in the space are regions that are unexplored. objects are represented by their visual percepts and are placed within the local space. in this screen  the robot identifies 1 garbage cans  denoted by the percepts gar-1 and gar-1.  middle  the a priori map of the office environment to be patrolled. the robot starting position is shown at point x and a path of the robot is denoted by the¡¡as seen in the figure  properties can be collected at different time points using different modalities. even when certain perceptual properties are updated  such as the smell property  which may change over time  other perceptual properties are maintained. conversely  if the visual percepts of an anchor is replaced  the smell property previously obtained is not lost. in this way  the anchor is used to compensate for any dynamically changing features of an object. furthermore  the perceptual description of anchors can be accessed by the planner dotted line.  right  the olfactory interface.
to reason about perceptual knowledge. in certain cases  this may result in specific calls to perceptual actions in order to disambiguate between similar objects.
1	the system architecture
in this section  we present our own instantiation of the extended anchoring framework discussed. we begin our description at the sensor level and proceed to the higher levels which include a planner and user interfaces. an overview of the robotic system is given in figure 1.
1 sensing modalities and control our physical robot is a magellan pro compact robot and in the experiments we use its infrared sensors  sonars and tactile sensors. in addition  a ccd camera is mounted on the robot and the robot is able to recognise pre-defined signatures of objects using standard visual techniques. perhaps the most novel of sensors on the robot is an electronic nose. the electronic nose consists of 1 conducting black polymer sensors  pattern recognition and classification components  and an electronic repository of odours stored in the on-board computer in the robot. the classification algorithm uses the odour repository as a training set for online recognition of new odours. to navigate the robot  a collection of basic behaviours is used. these behavioursare based on fuzzy control techniques and can be combined and reasoned about through use of a behaviour planner  b-plan  explained in  saffiotti et al.  1 .
1	anchoring module
the anchoring module  besides creating and maintaining the anchor data structure  also serves a secondary purpose to function as a flag between top-level tasks given by a planner and low-level sensor data. although not immediately evident this function is important in order to co-ordinate perceptual processes such as a smelling action which may take up to several minutes. in such a case  specific calls to perceptual actions e.g.  smell gar-1  are generated from the toplevel planner  which then translates into several behaviours being activated e.g.  go near to gar-1  touch gar-1  and calls to an odour server which activates the respective pumps on valves on the nose. the odour classification provides the smell description e.g.  gar-1 smells ethanol  and the perceptual information is updated. here the anchoring module  polices  each event signalling to the respective modules when certain process need to be activated and when they have reached completion.
¡¡in our instance of the anchoringmodule  the track functionality is achieved by performing a fuzzy matching algorithm between newly created percepts and previously stored anchors in order to partly deal with sensor noise. however  the purpose of the anchoring framework allows different strategies for the track functionality. a part of the future aims to integrate more advanced solutions into the existing platform.
1	planner
ptlplanner karlsson  1 is a plannerfor partiallyobservable domains with uncertainty  probabilities . it searches in a space of epistemic states  or e-states for short  where an estate represents the agent's incomplete and uncertain knowledge aboutthe world at some point in time. althoughmuch of the planning component is standard  it is still worth emphasising that the planner can reason about perceptive actions  such as looking at or smelling an object. the consequence is that calls to perceptual actions may be made in order to gather more information about the environment.
1	interfaces
figure 1: the top row shows the camera images at different time points  the middle row shows the activity at the anchoring level. grey bars indicate anchors with olfactory properties. the bottom row shows the corresponding local perceptual spacein addition to the computations mentioned in the previous section for control  perception and autonomy  the system also has a number of processes for displaying the internal state of the robot as well as its current model of the external world. this model of the external world includes locally perceived objects and a gridmap of the environment built from sensor data. this is shown in figure 1. in the left window  the local view of the robot shows the incoming percepts of the vision given the changing representation of visual percepts.
and spatial modules. in the center figure  a map of the environment is shown. additional interfaces include a live feed of the images viewed from the ccd camera and an olfactory interface which shows clusters and data points for a loaded repository  figure 1  right  . certain points can be interactively selected to generate new plans for perceptual actions. it also shows the symbolic representation preserving the electronic perceptionof odoursused to classify new odours. more information about the olfactory interface and the categorisation of odours can be found in  loutfi and coradeschi  1; 1 .
1	experiments
the general experiment is performed in a series of corridors. in each corridor there may be several objects  in this case garbage cans. the robot automatically toggles between the task of patrolling the corridor  inspecting objects and waiting for commands from the user. patrolling the corridor involves moving from corridor to corridor in a discovery for new objects and recognition of previous objects. when an inspect is invoked  the robot visits each object collecting the odour property. the inspect is usually autonomously invoked when new objects are detected.
¡¡the purpose of the experiment is to evaluate the ability of the extended anchoring framework to maitain an internal representation of the objects in the corridors for an extended period of time. throughout the autonomous activity of patrolling the corridor  a user may interrupt tasks by requesting the acquisition of specific objects. object requests can be given by using the image feed from the camera and directly selecting a region in the screen. the sensory signature of the object will be matched against current anchors and current execution of the patrol will be interrupted to include a plan to visit and inspect the selected object. object can be requested by giving to the robot a sample of the smelling object and request to find similar objects. finally top-down requests can be given to find objects by giving to the system a symbolic description of the object. the anchor that most matches the description will be returned.
1	results
the a priori information given to the system consists of a rough map of the environment  shown in figure 1  middle   and a repository of interesting objects  namely garbage cans placed outside offices. the robot patrolled the corridors for a period of 1 days  with intermittent breaks during the day and longer breaks during the evening for charging the batteries. at any given time  garbage cans would be removed  displaced  or added into the environment. the total distance covered by the robot is approximately 1 km without the inclusion of the extra movementcaused by smelling actions and over 1 odour samples were collected.
¡¡the local space of the robot together with the visual image from the camera as well as the creation  deletion and updating of anchors is depicted in figure 1. the figure contains four snapshots throughout an experimental run described as follows:
  scene 1 - the robot begins patrolling the corridor  two visual percepts are detected and two anchors denoted by gar-1 and gar-1  are created. an inspect is performed and both anchors obtain olfactory properties  shown in the figure by the grey colouring. since the anchors are created in a bottom-up fashion their labels are arbitrary.
  scene 1 - as the robot continues its patrol  another object is inserted into the environment at a later time. note however  that the previous two anchors are still maintained by the track functionality. although the local space shows only the current percepts  the anchoring module updates the link between the anchor gar-1 and the percept gar-1. a new anchor is also created for the third object denoted by gar-1 with visual percept gar1.
  scene 1 - the robot approaches the object in order to acquire its odour property and the result is stored in the corresponding anchor. some time later  the object is removed from the environment. the life of the anchor slowly decreases when an expected percept is no longer detected.
  scene 1 - the anchor is removed from the system and unless it is perceived again  its properties cannot be accessed by the find functionalities described above.
¡¡this scenario shows how the anchoring module is used to create an internal structure which can then maintain the perceptual coherence of objects  considering each object has both spatial and olfactory properties. even when visual properties of anchors are being updated  the stored smell property remains until a new odour character is acquired by the next inspect action. the previous odour character is then stored in the odour repository.
1	conclusion
 take a coin  toss it  and catch it again in your hand...you see a single object fly up in the air  twist overand over and land in one piece on your hand. bits don't fly off. the silver doesn't depart from the shape  and the shape doesn't lag behind the motion.   blackmore  1   p.1 .
¡¡maintaining perceptual coherence of objects over extended periods of time involves the management of perceptual information from different sensing sources  tracking over time and maintaining object persistency. in this paper we showed how a modified anchoring framework could be used as a tool to satisfy these requirements. experiments on a mobile robot were performed where a robot used both spatial and olfactory sensors to monitor an office environment over an extended period of time.
¡¡the problem of perception management is far from being solved. in this paper  we have  scratched its surface  by recognizing the need to consider this problem  highlighting important issues that arise on an embedded system and presenting a first implemented solution.
acknowledgments this work has been supported by: vetenskapsra det  and by etri  electronics and telecommunications research institute  korea  through the project  embedded component technology and standardization for urc 1  . the authors would like to thank mathias broxvall and lars karlsson for their contribution to the experimental work.
