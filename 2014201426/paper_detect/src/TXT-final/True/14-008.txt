 
       the past few years have seen a growing interest in the application  of three-dimensional image processing. with the increasing demand for 1-d spatial information for tasks of passive navigation 1   automatic surveillance  aerial cartography l1 l1   and inspection in industrial automation  the importance of effective stereo analysis has been made quite clear. a particular challenge is to provide reliable and accurate depth data for input to object or terrain modelling systems  such as . this paper describes an algorithm for such stereo sensing it uses an edge-based line-by-line stereo correlation scheme  and appears to be fast  robust  and parallel implementable. the processing consists of extracting edge descriptions for a stereo pair of images  linking these edges to their nearest neighbors to obtain the edge connectivity structure  correlating the edge descriptions on the basis of local edge properties  then cooperatively removmg those edge correspondences determined to be in error - those which violate the connectivity structure of the two images. a further correlation process  using a technique similar to that used for the edges  is applied to the image intensity values over intervals defined by the previous correlation the result of the processing is a full image array disparity map of the scene viewed. 
mechanism and constraints 
       edge-based stereo uses operators to reduce an image to a depiction of its intensity boundaries  which are then correlated. area-based stereo uses area windowing mechanisms to measure local statistical properties of the intensities  which can then be correlated. the system described here deals  initially  with the former  edges  because of the: 
a  reduced combinatorics  there are fewer edges than pixels   
b  greater accuracy  edges can be positioned to sub-pixel preci-sion  while area positioning precision is inversely proportional to window size  and considerably poorer   and 
c  more realistic in variance assumptions  area-based analysis presupposes that the photometric properties of a scene arc invariant to viewing position  while edge-based analysis works with the assumption that it is the geometric properties that are invariant to viewing position . 
　　　　edges are found by a convolution operator they are located at positions in the image where a change in sign of second difference in intensity occurs. a particular operator  the one described here being 1 by 1 pixels in size  measures the directional first difference in intensity at each pixel' second differences are computed from these  and changes in sign of these second differences are used to interpolate sero crossings  i.e. peaks in first difference . certain local properties other than position are measured and associated with each edge contrast  image slope  and intensity to either side - and links are kept to nearest neighbours above  below  and to the sides. it is these properties that define an edge and provide the basis for the correlation  see the discussions in  1  . 
　　　　the correlation is & search for edge correspondence between images fig. 1 shows the edges found in the two images of fig. 1 with the second difference operator  note  all stereo pairs in this paper are drawn for cross-eyed viewing  although the operator works in both horizontal and vertical directions  it only allows correlation on edges whose horizontal gradient lies above the noise - one standard deviation of the first difference in intensity with no prior knowledge of the viewing situation  one could have any edge in one image matching any edge in the other. 
　　　　by constraining the geometry of the cameras during picture taking one can vastly limit the computation that is required in determining corresponding edges in the two images. consider fig. 1. if two balanced  equal focal length cameras are arranged with axes parallel  then they can be conceived of as sharing a single common image plane. any point in the scene will project to two points on that joint image plane  one through each of the two lens centers   the connection of which will produce a line parallel to the baseline between the cameras. thus corresponding edges in the two images must lie along the tame line in the joint image plane this line is termed an epipolar line. if the baseline between the two cameras happens to be parallel to an axis of the cameras  then the correlation only need consider edges lying along corresponding lines parallel to that axis in the two images. fig. 1 indicates this camera geometry - a geometry which produces rectified 
　the edge operator is simple  basically one dimensional  and is noteworthy only in that it it fast and fairly effective. 
1 
         
images. the algorithm described assumes the stereo pair to be rectified  and if this is not the case then the appropriate transformation of one image relative to the other mutt be made before further processing is done. note that a less restrictive solution would be to have the correlation informed of the camera geometries  and have it solve for the more general epipolar situation. 

     fig. 1 shows a pair of corresponding lines from the stereo pair of i g . 1  while fig. 1 plots the actual intensities of these lines  seen as dots  superimposed on the edges determined by the edge operator. since one needs to compare edges only from corresponding lines in the two images  the correlation can be applied to the edges shown in fig. 1. the process of correlating could proceed at this point by searching for the 'best' assignment of edges along such corresponding lines - one which optimises some goodness measure. however  normal combinatoric search is quite inadequate here. typical lines have upwards of n - 1 edges each and the combinatory space  with a naive upper bound of n!  grows rapidly with n  the cdc imagery above isn't typical  but rather is synthetic  and actually quite noise-free - in contrast sec the images of fig. 1 . even with extensive heuristic pruning  runs with a combinatoric search approach often take seconds per line ... and sometimes minutes  on a dec kl-1 . a superior approach to the correlation task lies in using the viterbi algorithm  1|  a dynamic programming technique used extensively in speech processing  and first used in vision research in some recent work at control data corporation 1 . 
         what distinguishes the viterbi technique from normal search is the requirement that one be able to partition the original problem into two subproblems  each of which can be solved optimally and whose results can be processed to yield a global optimum for the original problem  'optimal' with respect to an evaluation function on the chosen parameters . in a recursive way  each of the subproblems may be divided and the solution process repeated geometrically  the partitioning constraint here is one of monotomcity of edge order a left-right ordering of edges in one image cannot correspond to a right-left ordering in the other  i.e. there can be no positional reversals of edges in the image plane this constraint allows one to make n tentative assignments of an edge on one line with the edges of the corresponding line in the other image  with each tentative assignment partitioning the correspondence problem into two subproblems the two subproblems are the matching of edges lying to the left and right of the selected edge on the one line with edges lying to the left and right respectively of its tentative match on the other line the optimality criterion selects the series of such assignments judged 'best'. this constraint excludes from analysis  for the time being  features such as wives or over hanging surfaces which lead to positional reversals in the image. experience suggests that this reversal also causes the human vision system trouble - we can fuse one or the other  the nearer or the further  but not both at the same time. 
         the correlation could use the edges as indicated in fig. 1 above  but in the interests of robustness and efficiency a different approach is taken here. a large amount of small scale detail in the images will exponentially increase the cost of the correlation reducing the level of detail and narrowing the extent of the required search will reduce the computation time and enhance noise immunity this is achieved through the use of a coarse to fine analysis in which a reduced resolution correlation is first applied to bring the two images into rough correspondence. the removal of the small scale detail brings quite a reduction in the number of edges to be dealt with successive refinements in resolution bring successively finer detail into the analysis  and each such phase can use the results of the previous lower resolution analysis to narrow its search such an approach has had previous successful application in visual processing  e.g.  1 1    and has relevant ties to the neurophysiology of vision  where it is felt a multiple spatial frequency analysis is part of the human system's processing |1   although the filtering used here is low pass  and not bandpass  it was our intent to use the low resolution components of the images to determine local approximate disparities  and to use these as guides for the full resolution correlation to obtain the resolution reduction we use a linear smoothing filter to successively halve image resolutions  continuing until the image signal content reaches an acceptable level  smoothing reduces noise  so increases signal-to noise ratio  fig. 1 shows the edges in successive resolution reductions of a sample line pair from the images of fig. 1  again with dots marking the intensities 
1 1 
         
         the tame basic second difference operator is used throughout the resolution reduction analyses  but its size and noise-based thresholds are altered to keep it matched to the characteristics of the 'new' reduced resolution image. these lowest resolution edges are correlated in a manner to be described below. the intervals specified between nearest-correlated edge pairs and their mates in the other image define local disparities to be used by the full resolution correlation process. 
the correspondence process 
         the process of determining edge correspondences is basically the same for both the reduced resolution and the full resolution correlations; the only difference is in the set of parameters used by the optimization function. full resolution correlation uses edge angle  side intensities  relative disparity  as measured by the reduced resolution phase   and interval compression implied by the correspondence  which uses edge position to determine the foreshortening of scene surfaces |1| . in reduced resolution correlation  side intensities  contrast  and interval compression arc used these parameter measures all enter the computation as probabilistic weightings: 1   p   1. 
         each edge from a line in the reference image is associated with a set of possible matching edges from its corresponding line in the other image  including the null match  which would imply that the edge is either spurious or is obscured in the other image  slightly complicating this  each such edge in treated as a doublet  being a left side  the termination of the interval to its left  and a right side  the start of the interval to its right ; left sides of edges can only match left sides of edges  right sides only right sides  quite obviously  this left-right distinction is essential in domains where surfaces may occlude one another  leaving a surface to one side of an edge hidden from one viewpoint while it is visible to the other. each side of an edge is termed a half-edge. for each pairing in the set of possible matches the static probability of correspondence is determined - this is the product of all of the mentioned probability measures except interval compression  which is determined dynamically  the optimization process then uses these probabilities  composing them with the dynamic interval compression probabilities in determining the 'best' correspondence of half-edges along a line in one image with half-edges along the corresponding line in the other image  details in  1j . this computation is 1 n1  for n edges along either image line - it would be 1 n1  were it not for the use of interval compression probabilities. 
the connectivity constraint 
         fig 1 shows the results of the whole image line-by-line correlation wherever there is a noticeable horizontal jag across the image  there is an error in the correlation what is really being depicted here is change in disparity along connected edges in each image. this is achieved by plotting between the connected edges of an image  but rather than using just each edge's coordinate  use its coordinate plus associated disparity. thus  when a connected stretch of edges in one image is matched to various parts of the other image  the drawing will 
jump horizontally back and forth in the other image's space  touching the various parts correlated with the connected stretch. at these horizontal jumps  the process is suggesting that there is a large change in depth. this is a suggestion of a break in depth continuity. 

         let us emphasise  the dynamic programming algorithm above performs a local optimisation for the correlation of individual lines in the image - it uses no information outside of those lines. a very strong global constraint is apparent and available here  that of edge connectivity. it may be presumed  by general position  that  in the absence of other information  a connected sequence of edges in one image should be seen as a connected sequence of edges in the other  and that the structure in the scene underlying these observations may be inferred to be a continuous surface detail or a continuous surface contour. a cooperative procedure uses this connectivity assumption to remove edge correspondences which violate surface continuity. the evidence for these miscorrelations is found through the tracking of disparities along connected edges on adjacent lines  this is what fig. 1 depicts . the results of the correlation after this process has functioned are shown in fig. 1  with the same type of depiction as fig 1 . fig. 1 shows a perspective view of these connected edge elements in depth. notice that this figure drawn by the program shows that it has truly captured something of the 1-d structure of the scene. 

         figs 1 through 1 show the various stages of the edge-based stereo correlation process when applied to the image pair of fig. 1. this data  provided by the night vision laboratory of the u.s. army   an aerial view of natural terrain  is considerably noisier and significantly more detailed than the synthetic urban imagery of fig. 1. it more clearly demonstrates the importance of the interline connectivity constraint and  as shown in fig. 1  the use of resolution reduction during the correlation. 
         the description so far has been of an edge-based stereo correlation scheme - one which uses a viterbi optimality condition and a cooperative continuity enforcement process in establishing reliable correspondences between the intensity boundaries  or edges  of a stereo pair of images. yet there is much more information one could have about scenes such as those depicted in figs. 1 and 1 the edge descriptions of figs. 1 and 1 just highlight the structure of the scenes  providing rather sparse disparity measures. one would like fuller stereo detail from the correlation  and a subsequent correlation process  this time based on image intensity values  supplies this. 
1 
         
intensity bated correlation 
         the above edge-based correlation  in indicating corresponding edges in the two images  provides strong local 'vergence' information which greatly constrains the matching problem for any remaining correlation. one can take unpaired edges from an interval along one line  epipolar line  and correlate them  again  via viterbi  with unpaired edges from the corresponding interval of the same line in the other image  the intervals are bounded by either correlated edge pairs or the periphery of the image . this correlation serves to  fill in the gaps  of the primary edge-based correlation. a final correlation  the fourth!  takes intensity values from the intervals between paired edges along corresponding lines and does yet one more viterbi correlation on them we are still developing the metrics used in this correlation - at the present we use 1  intensity variance and 1  deviation from linearity of the interpolated surface 	fig 1 indicates the results of this procetsmg on two sample lines  cdc line to left  nvl to right  	arrowheads   -  and  --   show half edge pairings  to the ieft side and to the right side  respectively   and the plotted contours show the disparity values assigned by the intensity correlation  depth can easily be determined from disparity once the camera parameters are known . 
　　　　figs. 1 and 1 show stereo perspective views of the full correlation results for the two sets of imagery  disparities are those of the left camera image   and fig 1 shows single views of the same surfaces after convolution with a 1 x 1 smoother  for easier viewing  although with less surface clarity  these figures show that the correlation algorithm produces a full image array disparity map of the viewed scenes. 
we have not yet measured its accuracy. 
1 
         

1 
         
performance 
         the correlation algorithm described here provides this threedimensional sensing in a fast  robust  and parallel implementable way. 
 fast  the analyses as shown in figs. 1 and 1 took roughly 1 and 1 seconds apiece from image input to the final edge correlation results as depicted. the remaining edge and intensity correlations of figs. 1 and 1 required a further 1 and 1 seconds  respectively  on a kl-1 . 
 robust  the use of line-by-line correlation  each processed independently  accumulating a good deal of redundant evidence   and the use of a coarse-to-fine strategy  where the more reliable lower frequency components are correlated first  give a good basis for obtaining the correct global consensus in the subsequent cooperative process. 
 parallel tmplementable  since there is no interline dependence during the various correlations  and the subsequent cooperative process has only pairwise interline interactions  there is a high potential for a parallel  n-processors for n lines  realisation. 
ahead 
         there is still  of course  considerable research to be done within this depth determination process. we will be: 
  looking into improvement issues in the present algorithm  such as having the correlator use colour information  
  testing it on further stereo imagery  both aerial and near range  using digital terrain models for accuracy tests  where possible  and 
  studying the applicability of the disparity measures derived by the algorithm to surface and object modelling  as in acronym  . 
further afield  we are interested in developing such a correlation scheme into a continuous  multi-image correlator  capable of integrating analyses over a series of passively sensed stereo views in building a highly accurate and detailed map of scene depth. 
acknowledgements 
         this research has been supported by the defense advanced research projects agency on contract mda 1-c-1. special thanks to sid liebes and peter blicher for their comments on a draft of this paper. 
