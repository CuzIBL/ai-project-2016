
various approaches have been proposed to quantify the similarity between concepts in an ontology. we present a novel approach that allows similarities to be asymmetric while still using only information contained in the structure of the ontology. we show through experiments on the wordnet and geneontology that the new approach achieves better accuracy than existing techniques.
1	introduction
with the emergence of the semantic web and the growing number of heterogenous data sources  the benefits of ontologies are becoming widely accepted. the domain of application is widening every day  ranging from word sense disambiguation to search of biological macromolecules such as dna and proteins.
　initially  ontologies were used in an attempt to define all the concepts within a specific domain and their relationships. an example of a popular ontology is wordnet  miller et al.  1   which models the lexical knowledge of a native english speaker. information in wordnet is organized around lexical groupings called synsets and semantic pointers. informally  a synset represents a set of synonym words  while a semantic pointer models the semantic relationships between two synsets. e-commerce sites such as amazon.com or yahoo also use simple taxonomies to classify their products. more recently  biologists and computer scientists have developed an ontology named geneontology  go  1   which models biological processes  molecular functions and cellular components of genes.
　nowadays  the usage of ontologies goes far beyond domain specification. a very promising direction for ontologies is semantic search  guha  1   where ontologies can successfully be used to find documents  davies  1   pictures  janecek  1   and jobs  bradley et al.  1 . semantic search is in fact an information retrieval application  where semantic knowledgecaptured by an ontology is used to enrich the available vocabulary. in comparison  traditional information retrieval applications use the vector space model  vsm   frakes  1   to represent the set of possible items and input query into a common vector space in order to compute the similarity between them. unfortunately  if no document contains any of the input keywords  the vsm approach fails to find any relevant documents. to overcome this problem  semantic search uses domain ontologies to explore concepts similar to the stated keywords in order to build smarter search engines.
　as highlighted by the previously stated examples  evaluating semantic similarity between concepts is a fundamental task. most authors have focused their research on hierarchical ontologies  ho   which is not surprising as most ontologies are made of is-a relationships   1% of all the relations in wordnet 1 are is-a relationships  while geneontology has . furthermore   maguitman  1  has shown that a similarity metric defined on a hierarchical ontology can be generalized to any kind of ontology by using a weighted combination of the is-a metrics. thus  the problem of evaluating the semantic similarity between concepts in any kind of ontology can be simplified to hierarchical ontologies. to this day  there exist two main approaches for estimating similarity between concepts in a hierarchical ontology: the edge based and the node based approaches. unfortunately  existing approaches fail to achieve high correlation with human ratings  while experiments on the geneontology have shown that no technique is best everywhere.
　in this paper  we define a novel similarity measure for hierarchical ontologies called ontology structure based similarity  oss . oss computes the similarity between two concepts a and b in three basic steps. first  we start by inferring the score of the concept b from a. from this inferred score  we compute how much has been transferred between these two concepts. finally  we apply a distance function that transforms the transfer of score into a distance value.
　the remainder of the paper is organized as follows. first we review the most popular similarity metrics in section 1  while our oss approach is defined in section 1. then  in section 1  we present experimental results of oss on the wordnet and geneontology. finally  section 1 concludes this paper.
1	existing measures of similarity
many techniques have been proposed for evaluating the semantic similarity between two concepts in a ho. they can be classified into two categories: edge based and node based approaches. at the same time  authors have looked at this problem from either a distance or similarity point of view.
these approaches are duals  as the similarity can be defined as 1   distance when values are normalized to  1..1 .
　the edge based approachis the traditional  most intuitive  and simplest similarity measure. it computes the distance between two concepts based on the number of edges found on the path between them.  resnik  1  introduced a variant of the edge-counting method  converting it from a distance to a similarity metric by subtracting the path length from the maximum possible path length:
           simedge a b  =  1 〜 d    len a b   1  where a and b are concepts in ho  d is the maximumdepth of the ho  and len a b  is the shortest path between concepts a and b. another popular variant of the edge based approach is the metric proposed by  leacock  1   which scales the shortest path by twice the maximum depth of the ho.
		 1 
　the node based approach was proposed by  resnik  1  to overcome the drawbacks of the edge-counting approach  which considers the distance uniform on all edges. resnik defined the similarity between two concepts as the information content of the lowest common ancestors  lca a b . the information content  ic  of a concept c is defined as the negative log likelihood of the probability of encountering an instance of the concept  i.e. ic c  =  logp c . the intuition behind the use of the negative likelihood is that the more probable a concept is of appearing  then the less information it conveys. formally  the similarity is defined as follows.
	simresnik a b  =	max	ic c 	 1 
c（lca a b 
　while resnik defined the similarity based on the shared information   lin  1  defined the similarity between two concepts as the ratio between the amount of information needed to state the commonality between these two concepts and the information needed to fully describe them.
		 1 
　hybrid approaches combine both approaches defined above.  jiang and conrath  1  proposed a combined model that is derived from the edge based notion by adding the information content as a decision factor. they defined the link strength between two concepts as the difference of information content between them. following this  jiang's distance metric is defined as follows:
distjiang a b  = ic a  + ic b    1 〜 ic lca a b    1 
1	the oss approach
in this section  we define a novel similarity measure for hierarchical ontologies called ontology structure based similarity  oss .
　as shown in figure 1  oss computes the similarity between two concepts a and b in three basic steps. first  we start by inferring the score of the concept b from a  s b|a . it is based on assigning concepts in the ontology an a-priori score  aps   and computing the relations between the scores assigned to different concepts. from this inferred score  we compute how much has been transferred between these two concepts  t a b . finally  we transform the transfer of score into a distance value d a b .

figure 1: the oss approach
1	definitions and assumptions
in this work  an ontology λ is defined as a directed acyclic graph   dag   where a node represents a primitive concept  while an edge models the binary specialization relation  is  a  between two concepts. thus  the ontology establishes a hierarchy where each concept can have a set of sub-concepts known as the descendants.
　furthermore a conceptrepresents instances  i.e.:a group of objects  with the same features  but not all instances of a concept must belong to a sub-concept. consequently  instances of different sub-concepts are distinguished by differences in certain features. however  these are usually not made explicit in the ontology. concretely  we see a feature as a restriction on a property or a combination of properties that differentiates a concept from its parent. for example  the subclasses of red and white wines are distinguished by a combination of features that include color and also certain aspects of taste.
　we believe that the primary objective of a similarity measure is to simulate a user's behavior and closely correlate with it. in particular  a quantitative measure of similarity should express the ratio of numerical scores that may be assigned to each concept. the score could reflect how much an item is preferred  or how friendly it is to the environment. for this purpose  we assume that the score s of a concept is a realvalued function normalized to  1..1  that satisfies the following assumptions:
  a1: the score depends on features of the concept.
  a1: each feature contributes independently to the score.
  a1: unknown and disliked features make no contribution to the score  i.e. the score of a concept is a lower bound on the possible score of its instances.
　assumption a1 is very intuitive and reflects the fact that a concept is modeled by a set of features. thus  the score will only be influenced by the features making up the concept. it is also the basis of multi-attribute decision theory  maut -  keeney and raiffa  1    where the utility of an item depends on the preference value of the attributes making that item. thus  all instances of the same concept will have the same score as they share the same features.
　the second assumption eliminates the inter-dependence between the features and allows the score to be modeled as the sum of the scores assigned to each feature. in maut  an even stronger assumption  the mutual preferential independence  is used to build an additive value function for an item. independence is a strong assumption  but it is still more accurate that the assumption that all the features correlate positively to the score.
　the third assumption may appear counterintuitive  but it reflects the observation that users are risk averse. for example  if the score models the price that a user is willing to pay for an item  it is rational for users to adopt this pessimistic view  since one would not normally be willing to pay for features that have not been explicitly provided. thus  the score attached to a concept can be seen as a lower bound on the score that items belonging to that concept might have.
1	computing an a-priori score
an ontology is usually designed in such a way that its topology and structure reflects the information contained within and between the concepts. a major ingredient of oss is the computation of the a-priori score of a concept c  aps c   which captures this information. the aps models the expected score of each concept for an average user  but without using any user information. it is not used as a prediction of actual scores  but only to estimate constants  α and β  that determine how actual users scores propagate through the ontology.
　as we have no information about the user  we assume that all concepts have a score that is uniformly distributed between 1 and 1. this is often a reasonable assumption as each concept exists to satisfy the desire of some group of people. thus  the probability that the score of a concept c is superior to the threshold x   s c    x   is equal to 1   x. however  this probability ignores the fact that concepts can have descendants. furthermore  our model is by definition pessimistic  a1   which means that the score should be a lower bound of the score of its instances and the score of its descendants. therefore  the probability that the score of any concept c is superior to a threshold x is equal to  1   x n+1  where n is the number of descendants of c. note that we count all descendants  not just the leaves  to account for the fact that each concept has instances that do not belong to any sub-concept.
　following this  the probability distribution of the score for a concept c is p s c  ＋ x  = 1    1   x n+1  while the expected score can be obtained by integration of the density function of c. formally  e s  is defined as follows.

　equation 1 tells us that the expected score of a concept c will be inversely proportional to the number of its descendants + 1. following this  we define the a-priori score of a concept c with n descendants as:
		 1 
　the a-priori score defined in equation 1 implies that the leaves of the ontology will have an aps equal to 1  which is equal to the mean of a uniform distribution between 1 and 1. conversely  the lowest values will be found at the root. this means that when we travel up the ontology  the concept becomes more generalized  and therefore the aps decreases. another important aspect of this aps is the fact that the difference in score between concepts decreases when we travel up the ontology  due to the increasing number of descendants.
　resnik also uses the topology to compute the information content of a concept. the aps share some similarities with information content. for example  the difference in both aps and ic decreases when we travel up the ontology. however  some profound differences exist. first  the aps is a bottomup approach that considers the differences between the concepts  while resnik's is a top-down approach that considers the commonalities between two concepts. second  we use the 1/x function to computeour score  while resnik uses the logarithm to base 1. in the validation section  we show that this brings better results than the information content approach.
　to illustrate the computation of the a-priori score  consider the simple ontology λ shown in figure 1 a . first  the number of descendants of each concept nc is computed. then  we apply equation  1  to compute the aps of each concept in λ.

concepts nc apsx 1 1 u 1 1 z1 1 s 1 1 t1 1 y 1 1 root 1+d 1/ 1+d  	 a  	 b  
　　figure 1:  a  a simple ontology λ and its apss  b  1 inferring the score
re-consider the ontology λ shown in figure 1 a   and imagine a situation where we want to compute the similarity between the concepts x and z. to propagate the score between these concepts  a link between them must be found. thus  the first task in the propagation is to identify the chain that contains both concepts. to minimize the propagation  we construct the chain through the lowest common ancestor  lca.
　in a tree graph  a lowest common ancestor is defined as the closest upward reachable node shared by x and z  knappe et al.  1 . note that in a dag  there can be several lca nodes; in fact  the number of lca nodes can grow exponentially with the size of the graph. fortunately  this number tends to be small in reality  as most concepts have only a few parents. for example  a concept in the wordnet ontology has on average 1 parents.
　we use the followingheuristic method to select which lca to use to propagate the score. for each possible lca node y  we compute the following values:
  its depth d y   given as the distance of the longest path between the root and y  and
  its reinforcement r y   given as the number of different paths leading to y from x and z.
　we pick the lca as the node with the highest value of r y    1d y . the idea behind this heuristic is to consider the fact that a concept found higher in the ontology  low d y   can still be more meaningful to the user if it has many paths leading to it  high r y  .
upward inference 
the first situation that arises is when there is a path going from concept x to its kth parent y. from the construction of the ontology  both concepts have d features in common but the concept x has an extra k features that differentiate it from its ancestor. by definition of the model  we know that the score of a concept depends on the features defining that concept  a1 . informally  it means that the score of y can be estimated knowing the score of x  s y|x   by looking at the ratio of features they have in common. we define s y|x  as:
　　　　　　　　　s y|x  = α x y s x   1  where α x y  is a coefficient of generalization. for every pair of concept x and ancestor y in the ontology  we estimate α using their ratio of a-priori score.
	α  x y  = aps y /aps x 	 1 
downward inference 
inversely  we have the case where z is the lthdescendant of y. following equation 1  it is very tempting to assume that s z|y  = βs y   where β is a coefficient of specialization that contains the ratio of features in common. however  this reasoning is not compatible with our second assumption - features contribute to the score independently. to understand this assumption  imagine that the score of the object is equal to the maximum price a user is willing to pay. consider two concepts a and b  where a has one more feature than b. now consider two users a and b such that a values b more than b does. this does not automatically mean that a will also attach a higher value to the extra feature that distinguishes a from b. notice also that when we were traveling upwards  we were considering super concepts. this means that we were removing known features whose contribution to the score is likely to be proportionalto it. however when travelingdownwards  we are adding new  unknown  features to the concept. therefore  we need to consider the score of each new feature independently. formally  it means that s z|y  should be defined as follows.
　　　　　　　s z|y  = s y  + β z y   1  where β is a coefficient of specialization that we estimate
using the a-priori score:
	β  z y  = aps z    aps y 	 1 
1	transfer of score
our intuition is that the distance between two concepts a and b is correlated to the amount of score being transferred between them.
　formally  a distance measure is a real valued function that we would like to satisfy the following axioms:
  identity: d a b  = 1   a = b
  normalization: 1 ＋ d a b  ＋ 1
  triangle inequality: d a c  ＋ d a b  + d b c 
it is otherwise customary to also include a symmetry axiom; however  one innovation of our proposal is that distance can be asymmetric so we do not include it.
　similarity and distance between two conceptsmust furthermore be independent of any particular amount of score that is being assigned to the concept. in particular  it must be applicable to any score in the admissible range  1..1 . thus  distance can be related to the transfer of score only in a multiplicative  but not in an additive way. following this  we define the transfer of score from a concept a to b  t a b   as the amount of score being transferred from a to b  i.e.:
		 1 
　following our example  and using equation  1  and  1   t a b  can be decomposed as follows.
		 1 
 in our context  s x  is unknown  which renders the above computation for downwards transfer impossible. however  under the assumption that the score of any concept is uniformly distributed between 1 and 1  section 1   the expected score of a concepts is in fact equal to 1. thus  we approximate t y z  as 1 + 1β z y .
　when judging the distance of two concepts a and b  the transfer of score from a to b should not attempt to predict the expected value of the score assigned to b  but a lower bound on it in order to model the fact that unknown features do not contribute. for upward propagation  the factor α derived from the a-priori scores reflects this correctly  as the aps of an ancestor is constructed as a lower bound on scores of its descendants.
　on the other hand  for downward propagation  the term β derived from the a-priori score reflects that translation from the lower bound to the expected value at the descendants. thus  in order to produce a lower bound  the relation has to be inverted.
consequently  the transfer t a b  becomes as follows.
		 1 
1	similarity metric
we define the ontology structure based similarity similarity simoss a b  of two concepts a and b as 1   d a b   where
d a b  is a distance measure between the concepts.
　to guarantee that d a b  − 1  and in order to satisfy the identity relation  we transform the transfer of score into a distance by taking its negative logarithm: d x z  =  logt x z . however  this distance would not be normalized to fall in the interval  1..1 . we thus normalize to obtain:
		 1 
where maxd is longest distance between any two concepts in the ontology. thus  the distance measure satisfies the normalization. such a logarithmic measure has also been used elsewhere fordistance and similarity measure jiang and conrath  1  lin  1  resnik  1 .
　to verify that the distance measure satisfies the triangle inequality  we consider the transfer from concept x to z  figure 1 a    and the additional concepts s and t. assume that the ontology is tree-structured  so that there is a unique path from x to z with lca y. note that d x z  = d x y  + d y z .
　assume first that s is a node on the path from x to y. then if s is part of the upward path from x to y  equation  1  implies that t x s  = aps s /aps x  and t s y  =
aps y /aps s . furthermore  and because t x y  = aps y /aps x   we can show that
 log t x y   =  log t x s  〜 t s y  
                                1  =  log t x s     log t s y  
as a consequence  d x y  = d x s +d s y  and thus the triangle inequality holds as d x z  = d x s  + d s y  + d y z . if t is part of the downward path from y to z  then we get that t y t  = 1/ 1+ 1β t y   and t t z  = 1/ 1+ 1β z t  . by definition  t y z  is equal to 1/ 1β z y    and equation  1  implies that β z y  = β z t  + β t y . thus  we get the following equation:
1
 log t y z   =  log  
         1 + 1β z y  ＋  log  
1
	1 + 1β z y  + 1β z t β t y 	 1 
	1
	=  log	〜	 
	1 + 1β z t 	1 + 1β t y 
=  log t y t     log t t z   which shows that the triangle inequality also holds when t is
on the downwards path connecting y and z.
　now consider the case where s is not on the path from x to z. due to the tree structure  the paths from x to s and from s to z will both contain a common part between a node s and a node d that is on the path from x to z. since all transfers are ＋ 1  this part can only increase the combined distance  so the triangle inequality will still hold.
　using equations  1  and  1   we thus defined the distance between any two concepts in the ontology x and z  given the lca y as follows.
		 1 
　table 1 illustrates the distance computation between the concepts x and z of the example in figure 1 a .
conceptsdirectiontransferdistanced x y x  zx  yy  zlog 1	`	＞
table 1: distance between concepts x and z in ontology λ
1	experiments
1	experiment i - wordnet
when resnik introduced the node-based approach  he also established an evaluation procedure that has become widely used ever since. he evaluated his similarity metric by computing the similarity of word pairs using the wordnet ontology  and then considered how well it correlated with real human ratings of the same pairs. these word pairs were selected in such a way that they covered high  intermediate  and low levels of similarity.
　wordnet is the most widely used and one of the biggest ontologies in the world  1 concepts   which makes experiments credible. as many authors in the field do  we reproduced resnik's experiment with the wordnet 1 on the original 1 word pairs. the correlations between various metrics and human ratings are displayed in table 1.
edgeleacockresnik
1.1
　　table 1: correlation with various similarity metrics our approach using the a-priori score achieves over 1% correlation with real user ratings  and clearly demonstrates significant benefit over earlier approaches  t-obs  1 and pvalue   1 .
　as expected  the hybridapproach performedbetter than existing techniques  but the improvement over the information based approach was not statistically significant  t-obs = 1 and p-value  1 . the edge based approach is the worst performing metric as it supposes that the edges represent uniform distances  which is obviously not true in wordnet.
αα1 + 1β1 + 1β1 + 1βαα1 + 1βcorr.1111table 1: different combinations of the coefficients in oss
we tried different combinations of the coefficients α and β in order to test the upward and downward propagation. as expected  table 1 shows that the best correlation is obtained when using α going up and 1β going down. as mentioned earlier  these coefficients renders the metric asymmetric. in fact  experiments showed that the upwards distance is up to 1 times greater the the downwards distance when concepts are very dissimilar.
　in section 1  we estimated the downward transfer between two concepts by using the expected score of a concept  i.e.: s x  = 1. to verify this assumption  we tested our metric with various scores ranging from the minimum aps in the ontology to 1.
1 + β1 + 1β1 + 1β1 + minaps1	β11111　　　　table 1: different value for s x  in oss table  1  shows that the optimum value does in fact occur when s x  = 1  and any value around it will not greatly influence the correlation. however  big underestimations of the initial score tend to influence the correlation by over 1% as it will overestimate the coefficient β.
	1	experiment ii - geneontology
to show the generality of the results  we performed another experiment on a much bigger scale using the geneontology  go . go was chosen over others as it is one of the most important ontology within the bioinfomatics community  and with over 1 concepts  it is also one of the biggest.
　　as the name suggested  geneontology is an ontology describing gene products. formally  the ontology is a dag  where a concept represents a gene  and where an edge models is-a or part-of relationships. by definition  a gene product might be associated with or located in one or more cellular components; it is active in one or more biological processes  during which it performs one or more molecular functions. thus  the dag is further decomposed into three orthogonal sub-ontologies: molecular function  mf   biological process lin bp   andjiangcellular componentoss cc .
1as for most real life applications  there is no human1.1 data of similarity over which we could benchmark our metric. instead   lord et al.  1  proposed to use the basic local alignment search tool  blast -  altschul  1   as it shows some correlations with concept similarity. blast compares nucleotide or protein sequences to sequence databases and calculates the statistical significance of matches. in another word  blast finds regions of local similarity between sequences.
　formally  the experiment was conducted a follows. first  we downloaded the february 1 releases of the swissprot protein database1  spd   go1  and blast1. then  we went through all the concepts in go  and selected each concepts that was also present in spd. to reduce the noise and errors  we also removed all the proteins that were not annotated by a traceable authors  evidence code = tas . for all remaining concepts  we performed a blast search1 in order to get a list of similar proteins. from this list  three proteins were randomly selected; respectively one at the beginning  the middle and one at the end. the idea behind this selection is to cover high  intermediate  and low levels of concept similarity. during a search  blast associates a score to each result that measures the similarity with the input protein. therefore  it is this score  after normalization  that has been used as benchmark measure.
　after the blast searches  we measured the similarity between the concepts representing the input proteins and the result ones using all of the metrics mentioned in this paper. finally  we measured the deviation between the normalized blast score and the similarity values of all the concepts using the mean absolute error measure  mae -  herlocker et al.  1  . for each of go's sub-ontologies  table 1 shows the deviation values  mae  for all the similarity metrics.
edgeleacokresniklinjiangossmf111111bp111111cc111111table 1: mae of various similarity metrics on go
　the results are very interesting in two points. first  it shows that none of the existing techniques dominates another one. for example  jiang's metric has a lower deviation on the mf ontology than resnik's metric  but it is not true for the cc ontology. these results can be explained by the fact that the topology of the sub-ontologies differ widely. for example  bp has 1 concepts and 1% of is-a relations  mf has 1 concepts and 1% of is-a relations  while cc has only 1 concepts and 1% of is-a relations.
　finally  we can see that the oss approach has the lowest deviation  whatever the sub-ontology. this suggests that our approach is more robust than existing techniques  and that it is also more accurate.
1	conclusion
this paper makes two major contributions. first  we showed that a-priori scores can be used to exploit the implicit knowledge captured by the ontology. second  we introduced a new technique called ontology structure similarity to derive a similarity metric based on these a-priori scores. the similarity metric exploits the implicit knowledge of the person

1 ftp://ftp.ebi.ac.uk/pub/databases/
1
 http://www.geneontology.org/go.downloads.shtml#ont 1
 http://ncbi.nih.gov/blast/download.shtml 1
blastall -p blastp -d swissprot -i in.txt -o out.txt -e 1 -v 1
who wrote the ontology and gave it a certain structure. a major novelty is that similarities and distances are asymmetric. experimental evaluation has shown that oss outperformsexisting techniques on wordnet and geneontology.
