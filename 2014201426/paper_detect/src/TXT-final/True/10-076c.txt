generality and computational cost 
a z r i e l rosenfeld 
computer science center 
university of maryland 
college park  maryland 	1 u.s.a. 
　　　the purpose of t h i s note is pedagogic a l . it discusses how one can reduce the computational cost of applying a set of operators  or predicates  by breaking them up into combinations of commonly occurring  simpler ones. this can be thought of as a process of generalization  in the sense that the common  simple operators are more  general  than the o r i g i n a l   more complex ones. we are thus suggesting that even when one has a p r i o r i knowledge of a specialized nature   i . e .   that the complex operators are applicable    it may s t i l l be desirable to use generalized operators in order to reduce computational cost. 
　　　to i l l u s t r a t e t h i s idea  suppose that we want to apply a set of predicates p-  ... p to an input i  and suppose that the cost of applying predicate pi is  proportional to  the c a r d i n a l i t y  of i t s set of support  thus the t o t a l 
cost of applying the p's is 
	for example  applying p. might 
involve a template-matching process  where pi is true i f f . a perfect match to the template is found in i. here i could be an image  or a s t r i n g  where the  template  is the right-hand side of a rule in a grammar   or a graph  where the  template  is a subgraph . in what follows  we w i l l use the image/template 
metaphor. 
     suppose now that there exists a set of subtemplates qj  	 qm such t h a t   for support. 	if we store the match positions in a new array i 1   then to test for p.  
we need only apply a template of cardina l i t y n i to i'. thus testing for a l l the 
 and the t o t a l cost of 
the two-step matching process is 

　　　under what circumstances is the twostep cost less than the brute-force cost  of applying the  d i r e c t l y   	we 
claim that t h i s depends on the degree to which the q's  generalize  the p's - 
i . e .   on how few q's are needed to construct a l l the p's. 	for concreteness  suppose that a l l the q.'s have the same support size | and that each p. 
consists of the same number  of 
thus each p. has support size 
and the costs of the brute-
force and two-step approaches are nrs and mr+ns  respectively. if there are few q's  they must be used repeatedly  and we have m    ns  m=ns would mean that each q is used only once ; thus mr+ns w i l l be much smaller than nrs. the fewer q's we need  the greater a saving mr+ns is over nrs. thus the more we can generalize the p's  the lower the computational cost. 
　　　this template example is certainly not a universal one. it would be desirable to extend this type of analysis to other s i t u a t i o n s .  on the advantages of hierarchical matching in the graph/subgraph case see barrow et a l .  1 .  however  our example does i l l u s t r a t e the idea that it may be advantageous to use generalized rather than specialized knowledge  see zucker et a l .  1    because this can lead to savings in comput a t i o n a l cost. 
