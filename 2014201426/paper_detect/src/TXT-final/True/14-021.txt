 
a polyhedral approximation for the volumetric description of a moving r i g i d object from a real-world scene is derived  based on measurements in monocular tv-frame sequences. the trajectory and attitude of the object motion r e l a t i v e to the camera is simultaneously determined up to the same factor which scales the object description. results from one street scene sequence are presented. the approach is compared to related ones reported in the recent l i t e r a t u r e . 
1. introduction 
technological progress throughout the past decade has made it feasible to record  d i g i t i z e   store  and evaluate image sequences of real-world scenes with moving objects. a comprehensive survey of application-oriented research which attempts to exploit such p o s s i b i l i t i e s has been given by nagel . it provides clear evidence from numerous application areas that progress in the evaluation of image sequences is closely related to improvements in modeling the depicted scene and i t s temporal variations. 
nagel  outlined an approach to derive descriptions of r i g i d objects in motion from monocular tv-frame sequences. the current contribution reports results from e f f o r t s to implement this approach. 
despite a recent burst of publications about image sequence analysis  no d i r e c t l y comparable results are known to us  yet. numerous investigators have been concerned with problems 
which appear as subproblems in our context. 
object tracking in tv-frame sequences from real-world scenes has been reported recently by gilbert et a l .  1  1   radig   yachida et a l .   gerlach   landzettel and 
hirzinger   hirzinger et a l .   korn and kories   bers et a l .   1   . although some of these systems have provisions to cope with p a r t i a l or complete occlusion of the object to be tracked and  therefore  are more robust than our approach as far as tracking is concerned  none of them actually attempts to derive a 1d description of the moving object. 
various descriptors  ranging from the mere 1d position of a dot in a binary image up to complex relational structures have been used to characterize the image of the same space point in each frame of an image sequence. 
depending on the type of descriptors  different methods for matching descriptors from one image frame to the next have been developed in order to solve the correspondence problem  duda and hart   1     . we modified a relaxation approach reported by barnard and thompson   1   . other approaches are discussed by  e . g .   ullman   radig et a l .   kraasch et a l .   jacobus et a l .  and cheng and huang   1   . 
using such techniques  a series of corresponding image coordinates can be extracted from an image sequence for a set of points which are hypothesized to be located on the same r i g i d moving object. provided certain conditions are s a t i s f i e d   the 1d configuration of these points as well as their space trajectory can be determined from such measurements. in the case of orthographic projection  this is guaranteed by the 
 structure-from-motion  theorem of ullman . the determination of translation and rotation for the perspective case has been studied by 
nagel 	  meiri   and nagel and neuinmann 
. similar investigations  but based on optica  flow  have been retorted earlier by prazdny  1  1 . special situations in optical flow analysis for the derivation of 1d descriptions have been studied by clocksin  1  1  1   by lawton  and by williams . 
neumann  used simulated data in a search approach which attempts to solve simultaneously the problems of grouping image points together as representing the same object  of finding the correspondences between images of the same point from d i f f e r e n t frames and of determining the interframe translation and rotation parameters. a numerical minimization approach towards 1d reconstruction investigated with simulated data has been reported by roach and aggarwal . our results have been obtained with a minimization approach described by bonde and nagel  1  1 . 
since we are r e s t r i c t i n g ourselves to r i g i d 1d point configurations  recent work by rashid 
  asada et a l .   1     as 	well 	as 	webb 	and 
1 aggarwal  on jointed objects is outside our scope. we exclude  too  model-based approaches such as those of o'rourke and badler  or wallace and mitchell . these authors assume that object-specific knowledge in the form of 1d prototypes is available whereas we s t r i v e for deriving 1d descriptions based solely on the observed image sequence and on general assumptions l i k e the r i g i d i t y hypothesis. moreover  a l l approaches quoted in this paragraph employ simulated input data rather than image sequences from real-world 1d scenes as in our case. 
this highly condensed survey of the recently published l i t e r a t u r e should i l l u s t r a t e the conditions which characterize our approach: a model-free derivation of 1d descriptions based on perspective projections of moving r i g i d objects from real-world scenes as recorded in real-time by a monocular tv-frame sequence. 
1. decomposition of our approach 
the discussion of the relevant l i t e r a t u r e in the preceding section roughly reflected the main steps in our system: 
  i   i s o l a t i o n of nonstationary image areas around the image of a moving object; 
  i i   extraction of descriptors from the subimage corresponding to one object; 
  i i i   solution of 	the 	correspondence problem by 	matching 	descriptors 	between consecutive frames; 
 iv  derivation of a r i g i d 1d point configuration and i t s frame-to-frame motion relative to the camera; 
 v  determination of the convex h u l l for t h i s 1d point configuration as an approximation to a volumetric model of the moving object. 
in order to assess the result  the convex h u l l can be projected back into each image frame using computer graphic methods including hidden l i n e removal and surface shading. this backprojection can be compared visually with the o r i g i n a l object image in the corresponding frame. 
step   i   is based on an approach 	described 	by 
jain and nagel . details about the descriptor extraction and the interframe matching of descriptors w i l l be discussed in subsequent sections. the f i f t h section w i l l outline the derivation of 1d descriptions and present various results. the f i n a l section w i l l discuss areas where further research is required in order to obtain a more robust approach  to refine the description or to extend i t s range of a p p l i c a b i l i t y . 
1. extraction of descriptors for 	object 	point candidates 
despite extensive experimentation  no segmentation algorithm is known to us which could r e l i a b l y decompose d i g i t i z e d tv-images from real-world scenes i n t o semantically meaningful regions without recourse to object-specific knowledge. radig and coworkers segmented images from blocksworld scenes  f i t t e d straight line segments to region 
boundaries  and selected an intersection of such straight l i n e segments as candidate for a vertex image of a block  1  1 . an extension of such an approach to images of - for example cars did not appear to be immediately feasible. 
inspired by the work of barnard and thompson  1  1     we set out to select an image point with a high greyvalue variance in four directions - a  corner point  - as a candidate for the image of an i d e n t i f i a b l e point on the object surface. barnard and thompson  1  1  employed an operator proposed and used by moravec  1  1  1 . detailed investigations showed however  that t h i s operator could not cope adequately with data such as ours. 
we began therefore  to investigate the location of extreme values of the local greyvalue curvature as a function of the raster plane coordinates. beaudet  described operators to compute these curvatures from d i g i t i z e d images. since the gaussian curvature is the product of the two main curvatures  it appeared a t t r a c t i v e i n i t i a l l y to select local extrema of the gaussian curvature as the characteristic of candidates for images of important object points. experience has shown  however  that such extrema of gaussian curvature appear often along lines of pronounced greyvalue transitions: one of the two main curvatures is very large due to the steep greyvalue t r a n s i t i o n   but the other one  along the direction of a linear t r a n s i t i o n front  is rather small and may change i t s value more or less due to noise. nevertheless  the product of these two can give rise to sizable extrema. 
the characteristic greyvalue d i s t r i b u t i o n around an image point of interest to us may be likened to a promontory with steep slopes  extending into the sea with an acute angle of the shore l i n e - see  e . g .   the l e f t upper corner of the rear car window in f i g s   lb or l b : the dark greyvalues of the window correspond to the promontory and the surrounding bright car body to the sea. a magnification of t h i s image area is given in f i g . 1 where bright pixels correspond to small greyvalues and dark pixels to large ones  greyvalues extend between 1 and 1 . 
at the pinnacle of the promontory  we have a local minimum of both main curvatures because there the intensity drops towards three directions  north  west  and south . around the shoreline  we expect a local minimum  see remark above  of one main curvature - the one corresponding to the bend in the shoreline. moreover  the second main curvature must exhibit an extremum of opposite sign in t h i s image area because the steep slope of the promontory c l i f f has to f l a t t e n out i n t o the surrounding sea. thus  we expect a local minimum of the gaussian curvature somewhere in the sea close to the t i p of the promontory the product of both main curvatures which have opposite sign in t h i s s i t u a t i o n . 
fig. 1 presents the numerical values of the relevant parameters for a l l pixels in the enlarged section. the greyvalue is given in the upper l e f t corner. the top number at the r i g h t side of each pixel area represents the more positive main curvature  the second number from above the smaller one   i . e . more towards the negative  of the two main curvatures. the t h i r d number represents the gaussian curvature  i . e . the product of the two numbers above i t . the l i n e within each pixel area indicates the orientation of the more positive main curvature. gaussian curvatures printed white on dark background represent the local extrema selected by the algorithm. we now select as a candidate for the image of an important object point the pixel with the steepest greyvalue slope along the l i n e which connects the location of the maximum with the location of the minimum of the gaussian curvature. only one of the two main curvatures can change i t s sign if we trace along t h i s l i n e from the minimum to the maximum of the gaussian curvature. the steepest greyvalue slope occurs where t h i s main curvature crosses zero. we stipulate two additional checks that we have indeed combined a proper pair of extrema for the gaussian curvature: 
a  the orientation of the main curvature which changes i t s sign between the two extrema must indeed point i n t o the direction of the associated extremum with opposite sign of the gaussian curvature-
fa  the greyvalue at the location of the maximum of the gaussian curvature must be larger   i . e . darker in this example - pinnacle 1  than the greyvalue at the associated location of the gaussian curvature minimum  extremum with negative sign - at the base of the c l i f f corner 
1 . 
a l i t t l e white square is entered in f i g . 1 at the center of the p i x e l area which corresponds to these conditions. as w i l l be seen  there are other extrema of the gaussian curvature. a cutoff radius of d=1 pixels is used to exclude extrema from being tentatively combined to form a candidate point. the curvatures have been computed with the 1 p i x e l operators of beaudet   1   . since t h i s resolution appeared to be s l i g h t l y too coarse  we refined the candidate locations by repeating the search with 1 operators. since such a smaller operator mask is more sensitive to noise  it is applied only in environments where the 1 operator responded strongly. the result of t h i s refinement step is presented in f i g . 1. 
in order to avoid misunderstanding  we do not claim to have a method by which we can reliably detect the images of prominent points on a 1d object surface. our experience only indicates that we can select a reasonable set of candidates for such points. supporting evidence from other frames is required to f i l t e r out those candidates which appear to be indeed images from 1d object points. such evidence can be obtained by finding corresponding candidates in neighboring frames - and by a successful 1d description which appears to be compatible with observations throughout an image sequence. 
1. 	interframe matching of candidate descriptors 
we 	used 	the 	relaxation approach described by 
barnard and thompson   1   . since our descriptors catch more of the relevant greyvalue structure than the moravec operator employed by these authors  we could exclude candidate matches where the sign of the main curvatures at the corresponding extrema of the gaussian curvature did not match. the details of the relaxation procedure used here d i f f e r from that described by barnard and thompson   1     see  1  1 . 
every other frame between those shown in f i g s   la and lb  i.e. a t o t a l of 1 frames has been treated in this manner. the descriptors matched through the relaxation procedure between consecutive pairs of frames are chained together. fig. 1 depicts the resulting chains of descriptor locations  anchored at the car image from f i g . l b . operator interaction could 
be used to delete chains which appear unreliable  for example very short ones or those connected to an cluttered image area. 
1. 1d description and results 
a minimization approach has been developed which is based on the hypothesis that the image locations of a l l descriptors must be explained by a r i g i d 1d configuration of points which translate and rotate from frame to frame r e l a t i v e to the camera  for details see   1     . as explained in section 1  a convex h u l l is computed for the 1d point configuration in order to better visualize t h e i r 1d arrangement. the edges of the convex h u l l corresponding to the measurements discussed e a r l i e r have been projected back into the image of f i g . l a . this is possible because the r e l a t i v e location and attitude of the 1d point configuration with respect to the camera coordinate system have been determined in the course of the minimization for each frame used. this knowledge enables the suppression of edge lines which are hidden by the object i t s e l f in the depicted position - see f i g . 1. it should be realized that the backprojection may contain vertices which need not have been extracted from the current frame. the vertices of the convex 1d h u l l represent the global description of a l l observations throughout the evaluated fraction of the image sequence. 
since the location and attitude of the convex h u l l r e l a t i v e to the camera is known for each 

1 

frame time  	it is possible to depict the convex 
h u l l with a hypothetical illumination provided one assumes a r e f l e c t i v i t y law for the faces of the convex h u l l . a simple choice is to assume lambert's law. fig. 1 depicts the convex h u l l corresponding to f i g . 1  but illuminated by a hypothetical l i g h t source behind the camera. results from additional frames of t h i s sequence as well as from other sequences cannot 
be presented due to space l i m i t a t i o n s . 
1. conclusion 
we have presented an approach for the extraction of 1d descriptors for moving r i g i d objects from monocular tv-frame sequences of real-world scenes. currently  we approximate a volumetric representation of the moving object by the convex h u l l of the 1d point configuration which can be obtained by the methods described above. it is obvious that the 1d object description should be improved by extracting more information about it from the frames than merely the greyvalue  corners . 
there are several areas where we want to improve our approach. one subproblem is a more r e l i a b l e and more accurate estimate of the mask covering the image of the moving object in each frame. furthermore  we have to study our approach for extraction of descriptors more extensively. there is the question  by which methods it might be possible to select those descriptors which are indeed images of i d e n t i f i a b l e points on the object surface. it is tempting to exploit approximate knowledge about the object and i t s motion as obtained from an i n i t i a l evaluation of an image sequence in order to reevaluate the same image sequence. such knowledge could be exploited to segment subimages containing the moving object and to use inference processes to exclude descriptors incompatible with the segmentation results. an alternative would be to employ such knowledge to evaluate an extension of the image sequence covering additional observation periods of the same scene with the same moving object. 
another problem area is the technique used for interframe matching of descriptors. alternative approaches have to be investigated here. we would l i k e   too  to develop algorithms which screen the descriptor chains already before we use t h e i r 1d coordinate measurements for the derivation of a 1d point configuration. 
despite a l l these open subproblems it is encouraging to know that one may learn at least an approximate 1d object description merely by observing the moving object. it thus appears possible to design a system where methods of model-based image analysis and understanding can be employed without providing object-specific models a p r i o r i . 
1. acknowledgement 
we g r a t e f u l l y acknowledge many f r u i t f u l discussions with our collegues g. h i l i e   b. 
neumann  b. radig  and h. westphal. the opportunity to test our ideas on image sequences from real-world scenes has been provided by a long cooperation of a l l present and former members of our research group. in addition to those mentioned above  we gladly remember the continuing help of i. heer  h. kemen  k. kleemann  w. benn  h. faasch  b. fischer  st. shafer  on v i s i t from cmu  and many others who contributed to the hardware and software f a c i l i t i e s of our laboratory. we thank mrs. r. jancke for her help in editing t h i s text. we g r a t e f u l l y acknowledge a grant of the deutsche forschungsgemeinschaft which p a r t i a l l y supported these investigations. 
1. 