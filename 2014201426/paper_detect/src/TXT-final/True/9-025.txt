 of parts of spoken utterances. more importantly  we learned something about the problems of speech understanding. we already have begun work on a second ver-stanford research i n s t i t u t e is p a r t i c i p a t i n g in a sion that w i l l use a new parser  now under development  major program of research on the analysis of continuous and that w i l l involve a d i f f e r e n t task domain. 	this speech by computer. 	the goal is the development of a new system is s t i l l in the process of c o n s t r u c t i o n   	a l -speech understanding system capable of engaging a human though the parser is far enough along f o r us to present operator in a natural conversation about a s p e c i f i c it in a companion paper  paxton and robinson  	1 . problem domain. 	the approach being taken is d l s t i n c - we have chosen to describe the f i r s t version in t h i s t i v e in the extent to which it depends on syntactic and paper  	because we believe that the basic system concepts semantic processing to guide the acoustic analysis. we are t e s t i n g are i l l u s t r a t e d there. 	moreover  	the this paper provides a d e s c r i p t i o n of the f i r s t version problems we have i d e n t i f i e d are ones that we think are of the system  emphasizing the kinds of information worth presenting to other members of the a r t i f i c i a l 	i n -that need to be added for e f f e c t i v e r e s u l t s . t e l l i g e n c e community. 	thoroughgoing solutions to 
these problems w i l l require more than the resources a v a i l a b l e w i t h i n our project at sri or even those in the introduction arpa program as a whole. the problems involved in acoustic analysis are not examined here; only enough information is presented to c l a r i f y the nature of the 　　　stanford research i n s t i t u t e is p a r t i c i p a t i n g in a major program of research on the analysis of continuous approach being taken in the system design. speech by computer  see newell et a l .   1  	being most previous work on voice input lo a computer is sponsored by the advanced research projects agency r e f e r r e d to as  speech r e c o g n i t i o n   rather than as  arpa . 	the goal is the development of a speech un-  speech understanding.  	 see h i l l   1  and lea  1 . derstanding system capable of engaging a human operator research on speech recognition has aimed at providing in a natural conversation about a s p e c i f i c task domain. an 	orthographic t r a n s c r i p t i o n of the sounds and words our path toward t h i s goal has been a c h a r a c t e r i s t i c a l l y 	corresponding to the acoustic s i g n a l . 	the major empha-  a r t i f i c i a l i n t e l l i g e n c e   approach. 	we believe that 	sis 	in 	systems designed for that purpose has been on many of the c r i t i c a l problems involved cannot be a n t i c - 	acoustic processing; 	some groups have developed p a t t e r n ipated outside of the context of a functioning system. 	matching s t r a t e g i e s   	while others have t r i e d to i d e n t i f y as a r e s u l t   our f i r s t e f f o r t s were to b u i l d a pre- u n i t s p h o n e t i c a l l y or phonemically and to aggregate l i m i n a r y v e r s i o n   using  where possible  a v a i l a b l e 	them i n f o l a r g e r and l a r g e r u n i t s . 	while there have programs as components. 	because of the c r i t i c a l r o l e been some r e s u l t s with i s o l a t e d words from r e l a t i v e l y that we expect semantics to play in the f i n a l system  	small vocabularies  	e x t r a p o l a t i o n of these techniques we chose  as a base  winograd's programs f o r under- 
standing natural language  winograd  1 . 	accord-to 	continuous speech has not been successful. i n g l y   we accepted for our f i r s t task domain his simu- 	in 	contrast  research on speech understanding seeks l a t i o n of the actions of a robot that knows about and to 	determine for spoken utterances the message intended can manipulate blocks of various shapes  sizes  and in 	r e l a t i o n to the accomplishment of some task and in c o l o r s . 	the intent was to allow a person speaking to spite of indeterminacies and errors in the generation  the computer to ask questions about the  blocks w o r l d     	transmission  	and reception of an utterance. 	the pro-to give commands that would modify i t   and to add 	cessing of s y n t a c t i c   semantic  	and pragmatic i n f o r -information that would augment i t s s t r u c t u r e . 
during the f i r s t year of the p r o j e c t   we completed mation is considered e s s e n t i a l   and a question-answering system may even be used as a major component. a f i r s t version of our system that did allow us to use there are a v a r i e t y of approaches to speech under-s y n t a c t i c   	semantic  	and acoustic data in the analysis standing being taken by p a r t i c i p a n t s in the arpa program. it would be beyond the scope of t h i s paper to sketch them out; however  descriptions are presented at the work reported herein was sponsored by the advanced 	this 	conference of the work at carnegie-mellon univer-research p r o j e c t s agency of the department of defense s i t y  erman et a l .   1; reddy et a l .   1  and at under contract dahc1-c-1 with the u.s. army bolt beranek and newman  woods and makhoul  1 . 
research o f f i c e . elsewhere  	there are reports on the design of the system development corporation system  barnett  	1  	and references are l i s t e d at the end of the paper. on the work at lincoln laboratory  forgie  1a  1b . some of these e f f o r t s concentrate on acoustic analysis of the speech s i g n a l   segmenting and l a b e l i n g phonemel i k e u n i t s that w i l l be grouped i n t o words-and more 
complex grammatical structures-according to syntactic and perhaps semantic c r i t e r i a . others accept hypotheses from a number of sources  f o r example  acoustic  s y n t a c t i c   and semantic  each of which may be checked 
against  the r e s t . a c t u a l l y   the arpa program is s t i l l in i t s early stages  and none of these systems-our own included-can be said to have established f i n a l design s p e c i f i c a t i o n s   so s p e c i f i c contrasts arc hard to draw f i r m l y . moreover  d i f f e r e n t task domains would seem to 
respond d i f f e r e n t i a l l y to one approach rather than another  a point that w i l l be considered again l a t e r . 
       in the system we are developing at shi  knowledge about the task domain  the grammar  and the current state of the analysis are used to constrain the select i o n of the. word or words that might be expected to be present at a p a r t i c u l a r place in the speech stream representing an utterance. the acoustic data f o r that l o c a t i o n are analyzed to determine the degree of correspondence with each expected word by a program that characterizes i t s acoustic s t r u c t u r e . when the presence of a word is confirmed  this information  in conjunction with the other sources of knowledge in the system  leads to the selection of another word f o r testing at the 
next place in the speech stream. successive steps provide both a segmentation of the utterance into words and a s p e c i f i c a t i o n of i t s syntactic and semantic s t r u c t u r e . the d i s t i n c t i v e aspects of the design are i t s strong dependence on syntax and semantics and i t s 
deliberate minimization of hypotheses generated solely on the basis of acoustic data. 
　　　the c a p a b i l i t i e s developed for the f i r s t version of the sri speech understanding system were rudimentary  but it did predict words and tesi for their 
presence. more preprocessing of the acoustic data was done than we believe should be necessary. acoustic characterizations were prepared for only a few words  so it has not been possible to step through a complete utterance. other sources of knowledge are c l e a r l y d e s i r a b l e   for example  a model of the user and i n f o r mation about prosodies-stress  i n t o n a t i o n   pauses. nevertheless  the results of t h i s f i r s t implementation were s u f f i c i e n t both to encourage us to continue t h i s approach and to provide guidance for the revisions in progress. 
an integrated system for speech understanding 
introduct ion 
　　　the syntactic and semantic component  named p i n t l e   is a major modification   i n ways described below  of terry winograd's system for procedural analysis of l a n guage  winograd  1 . a grammar-written as a set of programs-is combined with semantic routines that model changes in the arrangement of a set of blocks. a sentence constitutes a path through the grammar. branching 
at choice points is determined by the order of the rules  by features on other constituents  and by semantic data. at the end of each branch in the parse tree is a set of words from a p a r t i c u l a r grammatical class   e . g .   determiners  adjectives  nouns  verbs   from which a subset can be selected on semantic grounds. 
　　　the acoustic routines convert the recorded analog voice input to d i g i t a l form. the d i g i t i z e d signal is then fed into a bank of d i g i t a l f i l t e r s   which make it 
possible to assign successive acoustic segments to one of a set of small  crude  but highly r e l i a b l e classes. the signal also is processed by a more complex acoustic analysis procedure that i d e n t i f i e s the frequency and amplitude for the f f r s t three spectral peaks of the 
vowel-like sounds. the parametrized data from these two analyses arc stored in f i l e s   
　　　the word v e r i f i c a t i o n routines take a set of words produced by p i n t l e and test each word against the acoustic data for a p a r t i c u l a r portion of the utterance. the result is a  possibly empty  subset of the words  ordered according to agreement with the acoustic data  with each word containing a pointer to i d e n t i f y i t s approximate endpolnt in the acoustic stream. p i n t l e takes the most l i k e l y word f i r s t and then proceeds on i t s path through the grammar to select the next set of 
words f o r processing by the word v e r i f i e r . 	testing t h i s 
new set against the acoustic data begins at the point designated by the endpolnt for the word previously accepted. 	if none of the proposed words agrees with tha acoustic data  p i n t l e backs up to the most 	recent 	choice 
point and t r i e s another a l t e r n a t i v e . 
　　　an example is considered next  and a more detailed description of each of the components is presented in section i i i . 
understanding a sample sentence 
　　　a b r i e f description of the  blocks world  problem domain used in the sri system is necessary as background for the analysis of the sample sentence. 	visualise a table containing a box and several objects of d i f f e r e n t sizes  	shapes  and colors. 	there are f i v e blocks  two 

       in the f i r s t version of the sri system for speech understanding  there were three major components: a 
       set of procedures for syntactic and semantic analysis; programs f o r acoustic processing; and a word v e r i f i e r routine that l i n k s the other two. successive versions 
w i l l include a d d i t i o n a l components and require major changes in a l l three of the present ones  as well as much more complex i n t e r r e l a t i o n s h i p s . nevertheless  t h i s version of the system does i l l u s t r a t e an approach to speech understanding that is d i s t i n c t i v e because of i t s dependence on syntactic and semantic processing. red  one black  one green  one blue  and three pyramids  green  blue  and red ; the box is white. the objects are arranged in a p a r t i c u l a r configuration in the computer representation of the scene  but the d e t a i l s of the arrangement are not necessary to understand the example. commands given to a simulated robot arm cause it to move the blocks. a l t e r n a t i v e l y   the person i n t e r acting with the system can ask questions or provide information that w i l l augment or change the semantic structure of the world in some way. 

1 
the sentence to be processed is the following: 	in 

put the black block in the box. 
it was recorded  digitized  and parametrized in advance  and the results stored in a f i l e that was loaded into the system for the test. all of the steps involved in its analysis are presented as they occurred in an acutal demonstration. the capabilities shown reflect the state of the system as of december 1.  the speech understanding system is implemented in bbn-lisp and is run on a pdp-1 computer under the tenex operating system. lines prefixed by an arrow represent entries by the user.  
 -#  put the  $ 1   $ *  in the  $ 1 .  
　　　analysis of the sentence by pintle is initiated. at the time this protocol was made  the word verifier did not have word functions available for the sets of 
words including put  the or in. under these circumstances-and in general to allow more flexible testing of the system-it is possible to enter text to specify a word. for convenience  the word verifier checks the input text f i r s t to see whether any of the words in the set predicted has been typed in. finding none  it w i l l 
use the appropriate word functions  if they are available. if none are present  the words in the set w i l l be rejected. 
put 
　　　pintle begins by looking for a major clause; branching along the imperative path  it looks for command verbs. the word put is among those in the set generated at this point  and it is found in the text input. 
the 
     having found a verb  pintle begins its search for a noun group by looking for a determiner  the is confirmed from the text input  
black 
　　　having found a determiner  pintle looks for an adjective. since there is no text input  the predicted words are tested against the acoustic data. beginning at a location 1 milliseconds into the utterance  the 1th 1-millisecond segment   the word verifier finds that black corresponds to the acoustic data at the highest of four confidence levels; red  green  blue  and white are rejected. 
block 
     pintle now looks for a noun to complete the noun group. it begins at the location in the acoustic data confirmed as the ending place for black  the previous 
word accepted. this condition is specified by the asterisk in the i n i t i a l entry for the sentence to be processed. the word verifier finds that block corresponds to the acoustic data at the highest confidence level; ball  pyramid  and thing are rejected. 
　　　with the noun group complete  pintle looks for a prepositional phrase to complete the action denoted by put. in is confirmed from the text input. 
the 
　　　looking for a noun group to complete the prepositional phrase  pintle begins with the determiners. the is confirmed from the text input. 
black 
     pintle next looks for adjectives. beginning at a location 1 milliseconds into the utterance  the 1th segment   the word verifier finds that black corresponds to the acoustic data at the third highest confidence level. red  green  blue  and white arc rejected. 
box 
　　　the location returned along with black proves to be the end of the utterance. consequently  black is rejected because the string so ending would be ungrammatical; it also would be semantically unacceptable. pintle backtracks and begins looking for nouns. box corresponds to the acoustic data at the highest confidence level; ball  pyramid  and thing are rejected. 
 put the black block in the box  
     the sentence as identified. at this point the system returns a printout showing the grammatical structure of the sentence. 
 clause major imper actv transl  
 vg imper  
put  inf past vb trans vprt mvb  
 ng obj 1bj1 noloc det def ns  
the  det npl ns def  
black  adj  
　　　block  noun ns   prepg place lobj  
in  place prep  
 ng obj prepobj det def ns  
the  det npl ns def  
box  noun ns  
1 　　　briefly summarized  the sentence is identified as an active imperative with the verb put  involving the movement of an object  the black block  to a location  in the box.  see winograd  1  and walker  1  for more extended discussions of the grammatical structure.  
this information is used to d i r e c t movements of the simulated robot arm in conjunction with the semantic d e f i n i t i o n s for the words and the determination of t h e i r relevance f o r the current state of the problem domain  as indicated in the following steps  
moveto 1 1 
　　　the arm moves to the black block  specified by the three coordinates given. 
grasp :b1 
	the arm grasps b1  	the black block. 
moveto 1 1 
　　　the arm with the black block moves to the box  specified by the three coordinates  
ungrasp 
the arm releases the black block inside the box. 
ok 
　　　the system indicates that it has completed the action i d e n t i f i e d in i t s  understanding  of the input utterance. 
provisional features of the implementation 
　　　in a n t i c i p a t i o n of a more detailed discussion of the system components in the next section  it is probably reasonable to note here some c h a r a c t e r i s t i c s of the analysis of the sample sentence that were temporary 
expediencies even in t h i s version of the system. 
　　　the system was not t o t a l l y o n - l i n e ; i . e .   it was not possible to speak d i r e c t l y i n t o the system and to i n i t i a t e processing accordingly. a n a l o g - t o - d i g i t a l conversion of the speech signal cannot be performed on our pdp-1 computer f a c i l i t y yet  pending completion of the necessary software. consequently  the signal was d i g i t i z e d on a pdp-1 and the r e s u l t i n g f i l e s transferred by tape to the pdp-1 f o r the rest of the acoustic a n a l y s i s . 
　　　the fortran f i l e s accessed by the word v e r i f i c a tion routines contained preprocessed data from both the d i g i t a l f i l t e r s and from the more complex analysis. i n i t i a l l y   we expected that in the f i n a l system we would only produce immediately on input the preliminary c l a s s i f i c a t i o n of acoustic segments provided by the d i g i t a l f i l t e r s . spectral analyses and other complicated acoustic processing were to be performed only ae required to make the kinds of decisions necessary to d i s t i n g u i s h among the predicted words in r e l a t i o n to the acoustic data. it now seems l i k e l y that complex 
analyses can be done in real time  so that we can get a r i c h e r parametric representation of the utterance. however  we s t i l l do not want to make s p e c i f i c c l a s s i f i c a t i o n decisions apart from the word v e r i f i c a t i o n procedure. 
　　　as noted in the analysis of the sample sentence  only a small number of word functions were w r i t t e n . consequently  t h i s version of the system was never used to process a complete sentence. the option of t e s t i n g predicted words against t e x t u a l   as well as acoustic  data proved useful for debugging the acoustic routines for p a r t i c u l a r sets of words. it also is useful in the absence of semantic and prosodic procedures for establishing constraints on paths through the grammar at the beginning of utterances  and  in p a r t i c u l a r   at the beginning of a dialog when no context has been established. 
　　　a f i n a l comment on the analysis embodied in the sample sentence is probably in order. we did not exercise t h i s f i r s t version of the speech understanding system to any great extent. there were only a few word functions  and they were tested against only two speakers. the flow of control was p r i m a r i l y from the syntactic and semantic component to the acoustic. it 
was clear from the beginning  however  that useful information could pass in the opposite d i r e c t i o n   not only from what a prosodic analysis might provide  but also from what might be expected to arise in the course of t e s t i n g words against the acoustic data. in a d d i t i o n   we envisioned ways in which the word v e r i f i e r   which in t h i s version of the system processed one word at a time  could operate more e f f i c i e n t l y on the whole set of predicted words in r e l a t i o n to the acoustic data  thus reducing the search space involved. 
components of the system 
pintle-procedures f o r syntactic and semantic analysis 
　　　p i n t l e   the syntactic and semantic component of t h i s version of the speech understanding system  is based on the winograd  computer program for understanding natural language   winograd  1 . it is a top-down system f o r l i n g u i s t i c analysis in which syntax  semantics  and inference are combined to d i r e c t the . processing of questions  statements  and commands. as implemented by sri in bbn-l1sp  p i n t l e constitutes a substantial modification of winograd's program. 
　　　in winograd's work  as in most e x i s t i n g parsing systems  successive words from a typed input s t r i n g guide the analysis. since we proposed to use the parsing procedure to help segment and i d e n t i f y the words in the speech input  it was necessary to find other ways to control the generation of paths through the grammar. so syntactic and semantic constraints 
were established to influence successive choices  leading to the selection of a subset of the words of a p a r t i c u l a r word class. in what follows  the i n f o r mation available in the grammar for t h i s purpose is presented  with an e x p l i c i t i d e n t i f i c a t i o n of the assumptions required for e f f e c t i v e use of the system in t h i s context  and with some additional elaborations where appropriate. 
1 　　　consider again the sample sentence discussed in the previous section  put the black block in the box. 
assuming that at the time this utterance is made in a hypothetical dialog of a user with the system it is reasonable to expect a command  the clause program 
would look for an imperative. semantic information would be critical here  but knowledge about the user also would be helpful  and pronodic data-discussed further below-could provide useful guidance. since imperative clauses generally start with verbs  the 
parser enters a verb group program looking for imperatives. since imperatives are in infinitive form  only those verbs with that feature are identified. the result of this path through the grammar is a small set 
of imperative verbs  one of which may correspond to the f i r s t word of the utterance. we expect to be able to constrain the set of verbs further by additional semantic information-perhaps regarding what command might be appropriate at this point in the dialog. and information specific to a particular user should be possible to capture; for example  the frequent use of certain commands. however this verb group is constrained  the i n i t i a l result is a set of words to check against the acoustic data. 
　　　confirming one  or more  of the words from this i n i l i a l set might result in pintle looking for a noun group  as is the case with the word put  which requires an object. the use of the word  might  is deliberate  to indicate the possibility of alternative choices. identification of a different imperative. pick  could result in pintle looking f i r s t for the particle up. accepting put in the sample sentence  pintle might begin the search for a noun group with a determiner. since the sot of determiners is small  off of them could be predicted. however  they are d i f f i c u l t to distinguish acoustically  and it might be reasonable  on semantic grounds  to look only for a definite or only for an indefinite determiner  e.g.  the or a. 
     finding a determiner  an adjective would be likely to follow. there are various classes of adjectives  
and in english there is an ordering controlling the sequence in which they typically modify a noun. 	for instance  size adjectives precede color adjectives; 
e.g.  dig red block but not red big block. again  in a dialog it would be reasonable at certain points to predict the amount of specificity required to identify an object on the basis of its qualities. furthermore  some people may make things perfectly clear  while others are more sparing in their characterizations. having models of the users could be valuable for providing this information. so  sets of adjectives would be checked against the acoustic data. subsequently  and in a similar fashion  various paths among the nouns 
would be selected for testing. the kind of verb would influence the choice; verbs of manipulation call for nouns that represent manipulable objects. this infor-
mation also could be used to influence the choice of an adjective in the prior search  limiting it to those adjectives appropriate to manipulable objects. 
　　　continuing the parse beyond the noun group would lead to consideration of preposition groups because put requires a location. identifying a place preposition would lead to a search for an object noun group  with decisions being made similar to those discussed for the preceding noun group. however  only those nouns that can have objects put in them need to be considered.. in this manner  a set of predictions can be made regarding the sequence of sets of words likely to occur in the utterance. 
     the foregoing description presumes the accuracy of the i n i t i a l predictions. in the sample sentence  however  the adjective i n i t i a l l y found in the second noun group proved to be in error. thus  backtracking and tracing down an alternate path were required to find the noun. an interpreter for programmar was added to provide a backtracking mechanism not available in winograd's system  and not necessary for winograd  see below . the interpreter made it possible to specify a set of alternatives at a particular point in the grammar and to try these in succession  backtracking automatically if the i n i t i a l choice was not subsequently confirmed. this same mechanism made recovery possible following acceptance of a word that proved to be in error  as in the sample sentence. 
　　　the requirement for speech input  the absence of words with identifiable features in the input string  and the availability of the backtracking f a c i l i t y resulted in other modifications to winograd's analysis procedure. winograd tested to eliminate the least likely alternatives f i r s t   checking the longest possible constituent and cutting back when that failed. programmar  in his original version  returned the f i r s t successful analysis  having provided both syntactic and semantic guidance to make that a likely interpretation within the model of the  blocks world.  selective backup was possible in a particular situation  but it involved specifying a location to return to for alternative processing. with voice input  it is necessary both to test for most likely alternatives first and to have a more general mechanism for following alternative paths through the grammar in case of f a i l ure. what is needed further for speech understanding is the f l e x i b i l i t y in the grammar to allow dynamic reordering of rules  depending on the state of the analysis at the moment. it would be desirable to be able to identify at any particular choice point in the grammar the alternatives that are possible. in winograd's system  alternative choices could only be identified serially after failure of the predecessor. 
　　　many more changes in the overall parsing strategy are needed to improve its ability to use syntactic  semantic  and-hopefully-pragmatic constraints to make accurate predictions about the words likely to be present at any particular place. in winograd and in our f i r s t version  checking against the actual configuration of objects on the  blocks world  could be done only after a group had been parsed. thus  in the sample sentence  both ball and pyramid were tested against the acoustic data. however  there were no balls in that configuration  although the word was in the lexicon   and there were no black pyramids. information of this kind can and should be used to influence the selection of words in a set as soon as it is relevant. 
     the introduction of new structures for managing semantic and pragmatic information could be expected to have major consequences for parsing. it certainly is necessary to replace winograd's microplanneft code; exploratory development has been done using qa1  a 
procedure-oriented programming system particularly suited for work in a r t i f i c i a l intelligence because of its f l e x i b i l i t y and special features  see rulifson  derksen  & waldlnger  1 . with revisions to the parser in qa1; new techniques are necessary to facilitate the accommodation of semantic and pragmatic information and to simplify the dynamic reordering of paths through the grammar. 
     at various times up to this point  prosodic information has been mentioned. knowledge about stress  intonation  and pauses should be valuable in any speech understanding system  but it assumes special importance in an approach like ours. prosodic data perform some 
of the functions for spoken language that punctuation does for text. intonation contours can suggest sentence type-question  command  statement; together with stress and pause they may help identifying clause and phrase boundaries and signal parts of an utterance with particular semantic import  see o'malley  1 . our system requires contexts  of various kinds  for useful prediction. prosodic information may provide guidance at the beginning of a dialog or even of an utterance when other kinds of constraints are less effective. 
acoustic processing 
     the speech data currently used in the sri system are obtained in a quiet room using a bx-k 1 condenser microphone and an ampex ag 1 tape recorder. an analog tape is produced at 1/1 inches per second recording speed. the speech data on the tape arc then digitized in segments of up to 1 seconds in length. a presampling low-pass f i l t e r with an 1-khz bandwidth is employed to reduce aliasing errors  and the digitization is accomplished by a 1-bit a/d converter operating at a rate of 1 samples per second. 
     the raw digital data are processed further by digital f i l t e r i n g . five rms values  root-mean-square  an energy measure  of the time series data are calculated in each 1-millisecond interval of time. the f i r s t provides an amplitude value for the unfiltered time series. the other four values are from digital' f i l t e r s with bandpass characteristics of 1 hz  1 hz  1 hz  and 1-1 khz. a linear predictive coding  lpc  analysis  using an algorithm developed by markel  1   provides formant frequencies and amplitudes by finding peaks in a 1-point spectrum. 
　　　in the f i r s t version of the system the strings of rms values were used in an algorithm that classified each 1-millisecond time segment as one of six events: silence  unvoiced turbulence  voiced turbulence  voiced stop  vowel-like  none of the preceding. the f i l t e r outputs and preliminary classifications of each segment are stored in disk files together with the formant frequency and amplitude data from the lpc analysis. 
word verification 
     procedures for word verification relate the words predicted by syntactic and semantic processing to the acoustic data. the input to the word verifier from pintle was a set of words that could be expected to occupy the next position in the utterance. the result of word verification is a subset  possibly empty  of the candidate words ordered according to degree of agreement with the acoustic data at that location in the utterance. 
　　　since pintle was written in lisp and the acoustic processing is done in fortran  it was necessary to develop procedures for communication between the two languages. an interface package makes it possible for a lisp program to create a fork  an independent process in the time-sharing system  containing a fortran program  to share directly accessible data with that program  and to call functions in that program according to standard fortran conventions. 
     for each candidate word  there is a function that tests for that particular word. the correspondence be-
tween the expected form specified in the function and the contents of the acoustic stream is expressed as one of four confidence levels: positive  possible  unlikely  and impossible. for the first three levels  the function also returns an estimate of the ending position of the word in the acoustic stream. 
　　　the word verifier collects the results for each word in a set  eliminates the impossible words  and constructs a l i s t ordering the rest of the words according to confidence level. the word with the highest ranking is returned to pintle; any others are saved on a backup l i s t to be used successively if their predecessor does not lead to the prediction of a new set of words  one or more of which can be found in the utterance. the ending position of the accepted word is used as the starting point for testing words in this new set. 
     to illustrate the word verification procedure  consider the word box in the sample sentence. it was one of the words predicted by pintle at a location beginning approximately 1 seconds after the beginning of the utterance. the word function for box produced the following actions: 
1. increment the time pointer by 1 milliseconds. 
1. attempt to find a vowel-like string in a 1milllsecond window centered at the incremented time pointer. 
1. if stop 1 is successful: 
 a  search for a voiced stop ahead of the vowel-like string. 
 b  search for silence at the end of the vowel-like string. 	if a silence is 
1 found  search for unvoiced turbulence after the silence. return a confidence level  where appropriate  for each search. 
1. examine the vowel-like string as follows: 
 a  calculate the average frequencies of the f i r s t and second formants. 
 b  calculate the average slope of the f i r s t and second formants. 
 c  look for discontinuities in the f i r s t and second formants. 
if there are significant discontinuities or rapid changes in formant frequencies  return the value impossible. 
1. combine the results of the consonant search from step 1 and the analysis of the vowel-like string in step 1 as follows: 
 a  if the average formant frequencies are reasonable for the vowel  a  and a l l consonant searches are successful  return positive. 
 b  if the average formant frequencies are reasonable  but a consonant search failed  return possible  
 c  if the average formant frequencies are unreasonable but a l l consonant searches are successful  return unlikely. 
 d  if the average formant frequencies are unreasonable and at least one consonant search failed  return impossible. 
　　　in the example  the confidence level for box was positive. the results showed a vowel-like string with f i r s t and second formant values consistent with ta  
in the interval 1 to 1  a voiced stop before the 
vowel-like string in the interval 1 to 1  silence after the vowel-like string from 1 to 1  and unvoiced turbulence from 1 to 1. 
　　　it should be clear that a word verification procedure of this kind was designed for use in a system with powerful syntactic and semantic constraints. 	in the analysis of the second noun group in the sample 
sentence  before box was confirmed  a set of adjectives was processed by the word verifier. 	all of the words were rejected except black  for which the confidence level was unlikely. 	pintle accepted black tentatively  
but that would have had to be the end of the sentence  and put the black block in the black is syntactically and semantically unacceptable in the current system. consequently  pintle backtracked and looked for nouns. of the set predicted  box was confirmed with the highest confidence level. if blocks had been a member of that set  the word verifier might have returned positive as well. however  since things cannot be put in blocks  that word would be excluded  on semantic groundb  from the set to be considered. 
　　　it is obvious that the word verification procedures in this form would not allow subtle discriminations. however  the addition of more complex and powerful acoustic/phonetic rules to the analysis and decision-making parts of each word function should permit significant expansions of the system capabilities. the word verifier strategy is particularly appropriate for our system design  since the syntactic and semant i c decisions involve words rather than phonemes  allophones  or other phone-like units. furthermore  the word verifier provides a way to deal with a significant subset of coarticulation problems that would 
be quite troublesome in a phoneme-verifier approach. 
　　　to a considerable extent  changes in the word verification procedures depend directly on increasing sophistication in acoustic processing. however  as indicated in the previous section  the need is not for new techniques for acoustic analysis but rather for ways to extract more information from the data we have. furthermore  we believe that the motivation for changes should come primarily from the requirements of word 
verification. our current efforts are directed toward providing more subroutines for acoustic parameterization in order to refine the i n i t i a l classification provided 
by the digital f i l t e r analysis and to provide additional formant data. for example  detectors have been added that allow fricatives to be distinguished reliably  so that s  sh  f - t h   and their voiced counterparts now are classified. we also have developed vowel segmentation and classification procedures that extract boundaries within vowel-like strings  smooth formant curves  and plot slopes and standard deviations of formants. our goal is to provide a variety of general 
procedures that can be used in the preparation of word functions for use in word verification. 
discussion 
     the major focus in this paper has been on the role of syntactic and semantic analysis in our speech 
understanding system--and appropriately so for presentation at a conference on a r t i f i c i a l intelligence. but in describing the f i r s t version of the system  we have emphasized the inadequacies of that implementation and the requirements we see as necessary in succeeding versions. probably the major result of this early work is the design of a parser that we believe can accommodate a l l of the sources of knowledge required for understanding speech. it is described in detail in the paper by paxton and robinson  1  presented at this conference. such a parser would be well suited to the word verification procedures and the kind of acoustic processing performed in our system. 
     another result of our f i r s t year is an appreciation of the interdependence of the task domain and the system design. a system like ours  which stresses syntax and semantics  is particularly appropriate for conversations with a person that involve some relatively com-
plex task and that require a sequence of interactions. dynamic changes in the situation reflecting progress toward some goal can provide the kind of semantic constraints that w i l l improve the accuracy of its predictions. the  blocks world  is relatively shallow; it does not easily accommodate dialogs of the kind 
desired. consequently  we have changed our task domain to the assembly and repair of small appliances  begin-
1 ning with a leaky faucet. 	in the course of modelling this world and establishing the knowledge necessary 
l o r i t s understanding  we w i l l be addressing problems c e n t r a l to the whole f i e l d of a r t i f i c i a l i n t e l l i g e n c e . 
　　　our p r o j e c t can benefit from any work in a r t i f i c i a l i n t e l l i g e n c e that illuminates semantics  pragmatics  and the process of representation. of course  we w i l l not r e j e c t i n s i g h t s that r e f l e c t on acoustics  phonetics  
prosodies  and a n c i l l a r y aspects of l i n g u i s t i c s . we do need to address a l l of these facets for a successful system.  but we c e r t a i n l y cannot expect to solve a l l of the problems ourselves. 
acknowledgements 
　　　the f o l l o w i n g people have been involved in the r e search on speech understanding at sri r e f l e c t e d in t h i s paper: sharon baranofsky  dick becker  steve coles  earl c r a i g h i l l   mike hecker  grant hoyt  bob mcpartland  
b i l l paxton  t i t o poza  ann robinson  jeff rulifson  jim young. we are also indebted to other participants in the arpa program on speech understanding f o r the perspectives they have provided. 
m a r k e l   j. d.   format trajectory estimation from a linear least-squares inverse f i l t e r formulation   scrl monograph no. 1  speech communication research 
	laboratory  	santa barbara  c a l i f o r n i a  october 1   
newell  a.  et a l .    speech understanding systems: 
final report of a study group   carnegie-mellon 
university  pittsburgh  pennsylvania  may 1 . to be published by north-holland publishing company  amsterdam  netherlands  1. 
o'malley  michael h.  the use of prosodic units in syntactic decoding.  presented at the session on l i n g u i s t i c units at the 1th meeting of the 
acoustical society of america  boston  1 a p r i l 1  university of michigan  ann arbor  michigan  1 . 
1  paxton  william h.; robinson  ann e   a parser f o r a speech understanding system   i n : third i n t e r national joint conference on a r t i f i c i a l i n t e l l i g e n c e   stanford  c a l i f o r n i a   1 august 1  advance papers of the conference. stanford research i n s t i t i t u t e   menlo park  c a l i f o r n i a   1. 

