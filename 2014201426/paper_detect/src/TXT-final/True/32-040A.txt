 
in the last several years the computational complexity of classical planning and htn planning have been studied. but in both cases it is assumed that the planner has complete knowledge about the initial state. recently  there has been proposal to use 'sensing' actions to plan in presence of incompleteness. in this paper we study the complexity of planning in such cases. in our study we use the action description language  proposed in 1 by m. gelfond and v. lifschitz and its extensions. 
the language  allows planning in the situations with complete information. it is known that  if we consider only plans of feasible  polynomial  length  the planning problem for such situations is np-complete: even checking whether a given objective is attainable from a given initial state is np-complete. in this paper  we show that the planning problem in presence of incompleteness is indeed harder: it belongs to the next level of complexity hierarchy  in precise terms  it is complete . to overcome the complexity of this problem  c. baral and t. son have proposed several approximations. we show that under certain conditions  one of these approximations - o-approximation - makes the problem np-complete  thus indeed reducing its complexity . 
1 	introduction 
the action description language  proposed in 1 by m. gelfond and v. lifschitz  gelfond and lifschitz  1  mid its successors have made it easier to understand the fundamentals  such as inertia  ramification  qualification  concurrency  sensing  etc.  involved in formalizing actions and their effects on a world  without getting into the details of particular logics. in this paper  we will be analyzing the complexity of planning based on this language and its extensions; let us  therefore  start with a brief description of this language. 
1 	planning and scheduling 
1 	language a: brief reminder 
in the language we start with a finite list of properties  fluents  which describe possible proper-
ties of a state. a state is then defined as a finite set of fluents  e.g.  {} or  we are assuming that we have a complete knowledge about the initial state: e.g.  means that in the initial state  properties and are true  while all the other properties are 
false. the properties of the initial state are described by formulas of the type 
initially  
where 	is a fluent literal  i.e.  either a 	fluent or its negation  
　to describe possible changes of states  we need a finite set of actions. in the language  the effect of each action a can be described by formulas of the type 
where  a reasonably straightforward semantics describes how the state changes after an action: 
  if before the action  were true  and the domain description contains a rule according to which causes if then this rule is activated  and after the action becomes true; thus  for some fluents we will conclude and for some other  that holds in the next state; 
  if for some fluent no activated rule enables us to conclude that is true or false  this means that the action a does not change the truth of this fluent; therefore   is true in a new state if and only if it is true in the old state. 
formally  a domain description d is a finite set of value propositions of the type initially  which describe the initial state   and a finite set of effect propositions of the type  a causes f if   which describe results of actions . a state s is a finite set of fluents. the initial state so consists of all the fluents for which the corresponding value proposition initially is contained in the domain description. we say that a fluent holds in s if otherwise  we say that holds in the transition function which describes the effect of an action a on a state s is defined as follows: 

  we say that an effect proposition  a causes f if 
is activated in a state s if all m fluent 
	literals 	hold in s; 
# we define as the set of all fluents fi for which a rule  a causes if is activated 
in s; 
  similarly  we define as the set of all fluents for which a rule  a causes if is 
activated in s; 
  if  we say that the result of the action a is undefined; 
  if the result of the action a is not undefined in a 
a plan p is defined as a sequence of actions  the result resrd p  s  of applying a plan p to the initial state so is defined as 

the planning problem is: given a domain d and a desired fluent literal f  to find a plan which leads to the state in which f is true.  more complicated goals can be reformulated in these terms.  
1 an extension of language  which describes sensing actions: brief reminder 
the language a describes planning in the situations with complete information  when we know exactly which flu-
ents hold in the initial state and which don't. in real life  we often have only partial information about the initial state: about some fluents  we know that they are true in the initial state  about some other fluents  we know that they are false in the initial state; and it is also possible that about some fluents  we do not know whether they are initially true or false. in such situations  the required action depends on the state: e.g.  if we want the door closed  the required action depends on whether the door was initially open  then we close it   or it was already closed  then we do nothing . therefore  for these situations  we must include sensing actions - e.g.  an action checki which checks whether the fluent /  holds in a given state - to our list of actions  and allow conditional plans  i.e.  plans in which the next action depends on the result of the previous sensing action. 
　some fluents may be difficult to detect  so we may have sensing actions only for some fluents; some reallife sensing actions may sense several fluents at a time. in view of these possibilities  the precise formulation of this language is as follows1. in the domain description d  in addition to value propositions and effect propositions  we can also have sensing propositions  of the type  a determines  a k-state is defined as pair  
1
　　the formulation given here is based on earlier work of formalizing sensing actions in  moore  1; scherl and levesqne  1 . 
where s is the actual state  and is the set of all possible states which are consistent with our current knowledge. initially  the set consists of all the states s for which: 
  a fluent is true 	if the domain description 
d contains the proposition  initially  
  a fluent fi is false 	if the domain description d contains the proposition  initially  
if neither the proposition  initially nor the proposition  initially are in the domain description  then  contains states with true and with false. the 
actual initial state 	can be any state from the set the transition function is defined as follows: 
  for proper  non-sensing  actions   is mapped into  where: 
- reso a  s  is defined as in the case of complete information  and 
  f o r a sensing action which senses fluents for which sensing propositions  a determines belong to the domain d ~ the actual state s remains unchanged while is down to only those states which have the same values of 

in the presence of sensing  an action plan is no longer a pre-determined sequence of actions: if one of these actions is sensing  then the next action may depend on the result of that sensing. in general  the choice of a next action may depend on the results of all previous sensing actions. such an action plan is called conditional. 
　examples have shown that adding sensing actions increases the computational complexity of the problem. in this paper  we show that the corresponding planning problem is indeed harder: it belongs to the next level of complexity hierarchy  in precise terms  it is complete . 
1 	the notion of a o-approximation 
to overcome the complexity of this problem  c. baral and t. son have proposed several approximations  whose plans are always correct but which can miss a plan. the first approximation - called o-approximation - is as follows: an a-state  approximate state  s is a finite set of fluent literals  i.e.  fluents and their negations . the initial a-state so consists of all the fluent literals f for which the corresponding value proposition  initially f  is contained in the domain description. we say that: 
  a fluent fi if true in s is  
  a fluent fi if false in s is  
  a fluent fi if unknown in s is neither 	not 

the transition function resi  a s  which describes the effect of a proper action a on an a-state is defined as follows: 
baral  kreinovich  and trejo 1 

  we say that an effect proposition  a causes if 
is activated in an a-state s if all m fluent 
	literals 	hold in  
  we say that an effect proposition  a causes f if is possibly activated in an a-state s if 
	all m fluent literals 	possibly hold in s 
 i.e.  are either true  or unknown in s ; 
  we define as the set of all fluent literals f for which a rule  a causes f if is activated in s  and no rule causes f if is possibly activated in s; 
  we then define resrd a s  as 

for sensing actions  the result of applying a to an a-state s simply means adding  to the a-state  the fluent literals which turned out to be true as a result of this sensing action. 
1 	results 
1 what kind of planning problems we are interested in 
informally speaking  we are interested in the following problem: 
  given a domain description  i.e.  the description of the initial state and of possible consequences of dif-
ferent actions  and a goal  i.e.  a fluent which we want to be true   
  determine whether it is possible to achieve this goal 
 i.e.  whether there exists a plan which achieves this goal . 
we are interested in analyzing the computational complexity of the planning problem  i.e.  analyzing the computation time which is necessary to solve this problem. 
　ideally  we want to find cases in which the planning problem can be solved by a  feasible algorithm  i.e.  by an algorithm whose computational time on each input is bounded by a polynomial of the length of the input  this length can be measured bit-wise or symbol-wise. problems which can be solved by such polynomial-time algorithms are called problems from the class  where stands for polynomial-time . if we cannot find a polynomial-time algorithm  then at least we would like to have an algorithm which is as close to the class of feasible algorithms as possible. 
　in short  we are interested in restricting the time which it takes to check whether the planning problem is solvable. this interest is justified because in planning applications we often want the resulting plan to be produced in real time  and if it is not possible to produce such a plan  we would like to know about this impossibility as early as possible  so that we will be able to add new actions  or simply give up . since we are operating in a time-bounded environment  we should worry not only about the time for computing the plan  but we should 
1 	planning and scheduling 
also worry about the time that it takes to actually implement the plan. if an action plan consists of a sequence of actions  then this plan is not feasible. it is therefore reasonable to restrict ourselves to feasible plans  i.e.  by plans whose length  = number of actions in it  is bounded by a polynomial of the input  with this feasibility in mind  we can now formulate the above planning problem in precise terms: 
  given: a polynomial  a domain descrip-
tion d  i.e.  the description of the initial state and of possible consequences of different actions  and a goal /  i.e.  a fluent which we want to be true   
  determine whether it is possible to feasibly achieve this goal  i.e.  whether there exists a feasible plan u  which achieves this goal. 
we are interested in analyzing the computational complexity of this planning problem. 
1 c o m p l e x i t y of the planning problem for situations w i t h complete information 
for situations with complete information  the above planning problem is  
theorem 1. for situations with complete information  the planning problem is  -complete. 
comments. 
  this result is similar to the result of liberatore  lib-eratore  1 . the main difference is that liberatore considers arbitrary queries from the language a  while we only consider queries about the existence of a feasible action plan. 
  the result of liberatore is preceded by the results of erol et al  erol et al.  1  where they study complexity of strips. here we use and its extensions instead of strips as to the best of our knowledge there has not been any formal treatment of extensions of strips dealing with sensing actions. 
  for lack of space we are not able to present all the proofs in this paper. 
  the problem remains np-complete even if we con-sider the planning problems with a fixed finite number of actions: even with two actions. if we only allow a single action  then there is no planning any more: the only possible plan is  in any state  to apply this only possible action and check whether we have achieved our goal yet; the corresponding  planning  problem is  of course  solvable in polynomial time. 
1 	useful complexity notions 
for situations with incomplete information  the planning problem is more complicated - actually  belongs to the next levels of polynomial hierarchy; see the exact results below. for precise definitions of the polynomial hierarchy  see  e.g.   papadimitriou  1 . crudely speaking  

a decision problem is a problem of deciding whether a given input satisfies a certain property  i.e.  in settheoretic terms  whether it belongs to the corresponding set  
  a decision problem belongs to the class  if there is a feasible  polynomial-time  algorithm for solving this problem. 
  a problem belongs to the class if the checked formula   e q u i v a l e n t l y   c a n be represented as where is a feasible 
property  and the quantifier runs over words of feasible length  i.e.  of length limited by some given polynomial of the length of the input . the class  is also denoted by  to indicate that formulas from this class can be defined by adding 1 existential quantifier  hence  and 1  to a polynomial predicate  
  a problem belongs to the class if the checked formula s  equivalently  can be represented as where is a feasible 
property  and the quantifier runs over words of feasible length  i.e.  of length limited by some given polynomial of the length of the input . the class  is also denoted by  to indicate that for-
mulas from this class can be defined by adding 1 universal quantifier  hence and 1  to a polynomial predicate  hence  
  for every positive integer 	a problem belongs to the class 	i f t h e 	checked 	formula 	 equivalently  	can be represented as 	where is a feasible property  and all 
quantifiers run over words of feasible length  i.e.  of length limited by some given polynomial of the length of the input . 
  similarly  for every positiveinteger 	a problem belongs to the class 	if the checked formula 	 equivalently  	can be represented as 	where is a feasible property  and all 
quantifiers run over words of feasible length  i.e.  of length limited by some given polynomial of the length of the input . 
  all these classes and are subclasses of a larger class formed by problems which 
can be solved by a polynomial-space algorithm. it is known  see  e.g.   papadimitriou  1   that this class can be equivalently reformulated as a class of problems for which the checked formula 
 equivalently  can be represented as where the number 
of quantifiers is bounded by a polynomial of the length of the input  j  is a feasible property  and all quantifiers run over words of feasible length  i.e.  of length limited by some given polynomial of the length of the input . 
　a problem is called complete in a certain class if. crudely speaking  this  is the toughest problem in this class  so that any other general problem from this class can be reduced to it by a feasible-time reduction . it is still not known  1  whether we can solve any problem from the class in polynomial time  i.e.  in precise terms  whether however  it is widely believed that we cannot  i.e.  that it is also believed that to solve a complete or a c o m p l e t e problem  we need exponential time and that solving a complete problem from one of the second-level classes or  requires more computation time than solving np-
complete problems  and solving complete problems from the class  takes even longer . 
1 complexity of the planning problem for situations w i t h incomplete information: situations w i t h no sensing actions 
let us start our analysis with the case of no sensing. 
theorem 1. for situations with incomplete information and without sensing  the planning problem is complete. 
proof. the problem is to check the existence of a feasible-length action plan for which  for every set of values  of the unknown fluents  is successful  i.e.  we check whether once we know and  i.e.  once we know the initial state and the actions   we can determine  step-by-step  all following states  and thus check  in polynomial time  whether in the final state  the desired predicate is true. so  
　to show that is complete  we reduce  to a known complete propositional problem of checking are propositional vari-
ables  	is a propositional formula . to reduce it to we first parse f  i.e.  we represent computing f as a sequence of elementary steps  on each of which we apply &  v  or 	to compute the intermediate results to compute 	we compute 	etc. in our planning problem  
we take two actions a and 	and fluents  
　　　　　 meaning: 	is true iff time = i . initially  is true  all other s  are false; 	is false  all other 
are unknown; goal: in the first moments of time  we select variables a selects  
selects 	 a causes 	i f   s a m e f o r a l s o   ev- 
ery action increases time by one: e.g.  a causes if and causes in moments  we  compute  then causes  if causes and causes  
if  + rules which increase time by 1 . a plan exists iff there exist values for which  for all is true. the reduction proves that is 
complete. 
the problem remains even if we consider the planning problems with a fixed finite number of actions: even with two actions. 
	baral  kreinovich  and trejo 	ssi 

theorem 1. for situations with incomplete information and without sensing  the 1-approximation to the planning problem is np-complete. 
in other words  the use of o-approximation cuts off one level from the complexity. so  for this problem  1approximation is indeed computationally very efficient. 
　this reduction is in good accordance with our intuitive understanding of this problem and its o-approximation: 
  in the case oi complete information  to represent a state  we must know which fluents are true and which are false. therefore  a state can be uniquely described by a subset of the set of all the fluents namely  the subset consisting of those fluents which are true in this state. the total number of states is therefore equal to the total number of such subsets  i.e.  to 1f  where f is the total number of fluents . 
  in the case of incomplete information  we  in gen-eral  do not know which states the system is. so  a state of our knowledge  called a k-state in  son and baral  1   can be represented by a set of possible complete-information states. therefore  the number of all possible k-states is equal to the number of all possible subsets of the set of all completeinformation states  i.e.  to  
  in o-approximation  an a-state is represented by stating which fluents are true  which are false  and which are unknown. for each of f fluents  there are three different possibilities  so totally  in this approximation  we have possible a-states. 
so  going from a full problem to its o-approximation decreases the number of possible  states  from doubly 
	exponential  to singly exponential 	since plan-
ning involves analyzing different possible states  it is no wonder that for o-approximation  the computation time should also be smaller. again  this argument is not a proof of theorem 1  but this argument makes the result of theorem 1 intuitively reasonable. 
1 complexity of the planning problem for situations with incomplete information: situations with sensing 
let us now consider what will happen if we allow sensing actions. if we allow unlimited sensing  then the situation changes radically-  the planning problem becomes so much more complicated that o-approximation is not helping anymore: 
theorem 1. for situations with incomplete information and with sensing  the planning problem is pspace-complete. 
theorem 1. for situations with incomplete information and with sensing  the o-approximation to the planning problem is pspace-complete. 
the proofs are similar to  littman  1 . both the planning problem itself and its o-approximation remain pspace-complete even if we consider the planning 
	1 	planning and scheduling 
problems with a fixed finite number of actions: even with two proper actions and a single sensing action which reveals the truth value of only one fluent - but we are allowed to repeat this sensing action at different moments of time. 
　in many real life control and planning situations  it is desirable to monitor the environment continuously  and to make sensing actions all the time. however  this necessity is caused by the fact that in many real-life situations  the consequences of each action are only statistically known  so we need to constantly monitor the situation to find out the actual state. in this paper  we consider the situations in which the result of each action is uniquely determined by this action and by the initial state. in such idealized situations  there is no such need for a constant monitoring. it therefore makes sense to allow only a limited repetition of sensing actions in an action plan. with such a limitation  the complexity of planning drops back  and o-approximation starts helping again: 
definition 1. let k be a positive integer. 
  we say that a sensing action is k-limited if it reveals the values of no more than k fluents. 
  we say that an action plan is k-bounded if it has no more than k sensing actions. 
theorem 1. for any given k  for situations with incomplete information and with k-limited sensing actions  the problem of checking the existence of a k-bounded action plan is  
theorem 1. for any given k  for situations with incomplete information and with k-limited sensing actions  the problem of checking the existence of a k-bounded 1approximation action plan is np-complete. 
comments. 
  the same result holds if instead of assuming that k is a constant  we allow to grow as as a square root of the logarithm of the length of the input . 
  a difficulty with the general situation with incom-plete information comes from the fact that we do not know the exact states  i.e.  we do not know the values of all the fluents. it is therefore reasonable to analyze the situations with full sensing  i.e.  situations in which  for every fluent fi  we have a sensing action checki which reveals the value of this fluent. full sensing does make the planning problem simpler  although not that simpler so that 1approximation will help: 
theorem 1. for situations with incomplete information and with full sensing  the planning problem is complete. 
theorem 1. for situations with incomplete information and with full sensing  the o-approximation to the 
planning problem is  
these results can be represented by the following table: 

comments. 
  an is defined in a similar manner  except that in an the result 
resd a  s  is defined not after a single action a  but after a sequence of proper actions between two sensing actions. in the particular case when there is exactly one proper action between the two sensing actions  -approximation reduces to 1-approximation. therefore  -approximation is also at least as complicated as conp-complete problems. 
  these results show that if we want an approximation to decrease the computational complexity of the planning problem  then  at least from 

unlimited number 
of sensing actions 
pspace-complete full sensing 	limited sensing 

 o-approximation or complete information np-complete 
1 	auxiliary result: 1-approximation is conp-complete 
in addition to o-approximation  the authors of  baral and son  1; son and baral  1  considered other types of approximations  including the so-called 1approximation. in 1-approximation  partial states are defined in the same manner as for o-approximation: i.e.  as lists of fluents and their negations. however  the result of a  proper  action a on an a-state s is defined differently: in this new approximation  a fluent literal f  fluent or its negation  is true after applying a to s if and only if f is true in all possible complete states complementing s. then  as a new a-state resrd a s   we take the set of all fluent literals which are true after applying a. 
　in this section  we will show that this new definition increases the computational complexity of an approximation. namely  while for o-approximation  computing the next a-state resd a s  was a polynomial-time procedure  for 1-approximation  computing the next state is already a conp-complete problem: 
theorem 1.  1-approximation  the problem of checking  for a given a-state s  for a given action a  and for a given fluent f  whether f is true in resd{a  s } is conpcomplete. 
the viewpoint of the worst-case complexity  1approximation is preferable to 1-approximation and w-approximation. 
