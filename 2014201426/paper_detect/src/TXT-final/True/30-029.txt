 
we propose a new model for representing and revising belief structures  which relies on a notion of partial language splitting and tolerates some amount of inconsistency while retaining classical logic. the model preserves an agent's ability to answer queries in a coherent way using belnap's four-valued logic. axioms analogous to the agm axioms hold for this new model. the distinction between implicit and explicit beliefs is represented and psychologically plausible  computationally tractable procedures for query answering and belief base revision are obtained. 
1 	introduction 
this paper is motivated by several concerns in the area of belief representation and belief revision. m i n i m a l change: when a belief structure is revised in the face of new information  we would like the new belief structure to be as similar to the old one as possible. this requirement goes back to quine and has been repeatedly emphasized by gardenfors as the preservation criterion  cf.  gardenfors  1 .  
computational tractability: since we are seeking to represent the beliefs of real people  and since the satisfiability problem is np-complete  even at the propositional level we need to be aware of the computational limitations of real people or even real computers and try  if possible  to take them into account in our belief representation models. 
explicit vs implicit beliefs: there are beliefs which are explicit - they may be actually asserted or at least agreed to. other beliefs are implicit in the sense that an agent can be made to agree to them after a discussion. if the set of explicit beliefs is consistent  then we can define the set of implicit beliefs as just their logical consequences. however  this becomes implausible if unknown to the agent - the explicit beliefs are inconsistent. 
inconsistency tolerance: the beliefs of real individuals are usually inconsistent from a global point of view. 
1 	automated reasoning this is also likely to be the case with large data bases. 
so we need to model how an agent deals with possible inconsistencies in its belief base. 
　in this paper we propose a model which comes to grips with all four issues. our work is related to the splitting languages framework of  parikh  1 . that paper 
showed how an agent's beliefs can be  uniquely  subdivided into sub-areas and how this division can be used in belief revision. however  it did not address the issue of explicit vs implicit beliefs  not did it tackle the question of inconsistent explicit beliefs. in the current paper we do both. 
　we take the celebrated agm axioms  alchourron et. al  1  as our starting point  but modify them some-
what and represent an agent's beliefs  not by a theory as is usual  but by what we call a b-structure  a notion which generalizes the notion of a theory. we begin by giving some notation and re-stating the agm axioms. 
notation: in the following  l is a finite propositional language.  however  most results continue to hold for a countably infinite first order language without equality.  the constants true  false are in l. the letter l stands both for a set of propositional symbols and for the formulae generated by that set. it will be clear from the context which is meant. a  b means that a  b is a tautology  i.e. true under all truth assignments. similarly  a  b means that a -1 b is a tautology. if x is a set of formulae then is the logical closure of 
x. thus x is a theory letters t t' denote theories. t a is the revision of t by a  and finally   a is .e. the result of a brute addition of a to t  followed by logical closure  without considering the need for consistency. slightly departing from the agm usage  we always assume that both t and a are individually consistent  only their union might not be. 
　agm have proposed the following widely accepted axioms for the revision operator *. we omit their axioms 1 having to do with conjunction. see  parikh 1  for a discussion of those two axioms and why they are less plausible than the other six. 
1. t * a is a theory. 
1. a 	t*a 

it is not the case that 
　however  the agm axioms are consistent with the trivial update  which is defined by: 
if a is consistent with t  then  otherwise t * a =  a . 
thus in case a is inconsistent with t  under this update  all information in t is simply discarded  which is not in the spirit of the minimal change requirement. the work in  parikh  1   discussed below  was motivated in part by a desire to block the trivial update. 
　we now give some details of the ls model on which our new notion of a b-structure is based. 
1 	the ls model 
 parikh  1  introduced a language splitting model which addressed two of the four issues we mentioned at the beginning  namely minimal change and computational tractability. we review his results below before going on to describe our new i -structures model which addresses inconsistency tolerance as well. 
　the intuition behind the ls model is that our beliefs are subdivided into disjoint areas which do not affect each other. this separation allows us to revise our beliefs locally and to minimize the amount of computation we have to do when we receive a new piece of information  both in checking whether it is consistent with the old set of beliefs and in revising our beliefs in view of the new information. 
definition l s i : 1  suppose t is a theory in the language l and let a partition of l. 
then 	split the theory t if there exist formulae such that 	 a1 ...  	an . we may also say 
that 	is a t-splitting. 
then we say that t is confined to l  if 
　　in part 1 of the definition  we can think of t as being generated by the various ti in languages li. then the condition implies that t contains no  cross-talk  between li and li for distinct part 1 of the definition says that t knows nothing about the part 
	example: 	then 
with corresponding theories  rvc  and further splitting is now impossible. suppose i believe that it will be either raining or clear tomorrow and that if i eat bananas then i will get a stomach ache. these beliefs can then be separated. 
lemma l s i :  parikh  1  given a theory t in the language l  there is a unique finest t-splitting of l  i.e. one which refines every other t-splitting. 
　lemma 1 says that there is a unique way to think of t as being composed of disjoint information about certain subject matters. 
lemma ls1: given a formula a  there is a smallest language in which a can be expressed  i.e.  there is and a formula with a b  and for all 
	and b  such that 	and a 	b   
　although a is equivalent to many different formulas in different languages  lemma 1 tells us that nonetheless  the question   what is a actually aboutv can be uniquely answered by providing a smallest language in which  a formula equivalent to  a can be stated. for example if a is the formula  then a  p 
and hence 	the language v will be referred 
to as   	then 
　the general rationale for axiom p  below  is that if we have information about two or more subject matters which  as far as we know  are unrelated  are split  then when we receive information about one of them  we should only update our information in that subject and leave the rest of our beliefs unchanged. 
axiom p: 	where a  b are in 
respectively and c is in li  then where  is a  local  update operator for li. 
　it follows from axiom p that if t is split between and l1  a  b are in  and  respectively  then t * a * 
 while axiom p looks binary  it implies the n-ary cause. axiom p is independent of the agm axioms. we now get 
theorem:  parikh  1  there is an update procedure which satisfies the six agm axioms and axiom p. moreover  the trivial update procedure does not satisfy axiom p. 
1 	comments on the ls m o d e l 
the ls model insists that the division of our beliefs uses disjoint sub-languages. but then global inconsistencies 
cannot be represented. suppose an agent believes theories ti in languages li and the  are mutually disjoint. then if the ti are individually consistent  they are also jointly consistent. thus the ls model cannot explain how an agent can be locally logically omniscient i.e. derive logical consequences within each li but still fail to be globally consistent. 
　we would like to model a more realistic agent  i.e. one who is locally logically omniscient  who does not believe any outright inconsistencies  but whose global belief structure might well be inconsistent without his being aware of it. this means that the languages li must be allowed to overlap on occasion. the b-structure model which we introduce below does just that and shows how the logic is handled using belnap's four truth values    belnap  1 . 
　we feel that this relaxation is psychologically realistic. e.g. we may imagine that clinton's problems with lewinsky might be connected with the bombing of iraq  which may affect the price of oil and which in turn may affect our airfare to a conference. but it is unrealistic to think that we might reason with all these beliefs together 
	chopra and parikh 	1 

at one time. rather they will be separated  though only partially; the connections may be noticed on occasion  if there is an article in the newspaper connecting a price hike in airfares with the bombing of iraq. 
　the sort of model we are considering will also apply to group reasoning. each agent will have its own language and be individually consistent in it. but the languages of different agents may overlap and a particular question a may be resolved by consulting those agents whose languages overlap with the language of a. options a and b discussed below will show how this is handled at a technical level. even a single agent may be thought of as consisting of a collective entity  see  minsky  1 . 
1 	the b-structure model 
definition 1: 	a belief structure b on l is a set 
     is a theory in   we can where the ti are the explicit 
beliefs of some agent in language  then b 
will be just a theory.  
　as in the case of belief bases  the object of revision is a set of beliefs that is not necessarily logically closed. 
　while we axe not requiring the li to be disjoint  we do want to retain some amount of disjointness. the following notion does that. 
definition 1: given a finite propositional language l 
and languages  such that 
 is a k-partition of l if any propositional sym-
bol q occurs in at most k of the li. 
　　the presence of such an overlap of symbols may be thought of as  cross-talk  amongst the ti; beliefs in some of the ti may be relevant or related to beliefs in others. a k-partition with a smaller k will be more disjoint than one with a larger k and indicates a finer partitioning of her beliefs by the agent. in particular  a normal partition is just a 1-partition. a k-partition is a fortiori a k + 1 partition and hence  for instance  a maximally fine 1partition will usually be finer than the finest 1-partition whose existence is guaranteed by lemma l s i . tolerating some overlap makes it easier to organize one's beliefs in smaller chunks. for example  if t is axiomatized by the formula  then  has only a trivial 1-partition. however  there is a 1-partition into sets with the two theories being generated b y r respectively. 
definition 1: b as in definition 1 is m-consistent if any m of the ti are jointly consistent. 
　we do not require that the whole collection be consistent  but the amount of inconsistency is limited by this requirement. the larger the m  the stronger the requirement imposed by m-consistency. thus  for instance  b is 1-consistent iff the ti are individually consistent  but  is n-consistent is con-
sistent. 
　a very natural example of such a collection with the bald person paradox. suppose that a person with 1 
1 	automated reasoning 
hairs is not bald but that a person with 1 hairs is bald. also  suppose that a non-bald person cannot become bald through the removal of just one hair. this gives us the axioms b n  -  b for n = 1 to 
 1  and  1 . these 1 axioms are inconsistent  but any 1 of them are consistent. this gives us a 1-consistent  inconsistent collection of axioms  all of which are accepted  and used. 
　for a more practical example  consider an airline which has 1 seats on a flight  and accepts 1 reservations. if  says that customer number i has a seat  then the airline is asserting ci for 1  and also that at most 1 of the hold. this gives a b-structure 
b with 1 languages: 	and theories here  f o r 1 1   is generated by and t1 is generated by a gigantic formula which says that at most 1 of the are true. this b-structure is 1-consistent  but inconsistent. but its inconsistency will not matter if fewer than 1 of the customers claim their seats. 
　to represent how an agent uses his b-structure and revises it  we make use of the four valued semantics  belnap  1    fitting  1   where the four truth values  true  false  stand for  respectively  no information  
true  false  and over-defined  or inconsistent . the first 
three truth values are intuitively obvious. the last  overdefined  can arise when we are given contradictory infor-
mation by two people both of whom are trustworthy. in this four valued bi-lattice there are two orderings  the knowledge ordering under which  true  false and the truth ordering under which false 
true  true is truer than  which is truer than false. but  are incomparable under the truth ordering. simi-
larly  true  false are incomparable under the knowledge ordering. the truth values with their orderings are displayed in the double hasse diagram below. 

　now we consider how a b-structure responds to queries and how it is revised. 
1 	answering queries 
given a formula a and b-structure b the query  a   is answered by giving the value  a  - abbreviated as 

v a  - which is defined as follows:  where l a  is the smallest language in which a can be expressed  cf. lemma ls1 . 
if ta is consistent  then 

　intuitively we see which of the theories ti could be relevant to a and put them together to get used to answer questions about a and the rest of the theories ti are not brought into play. 
controlling inconsistency: our approach  while seeking to handle this problem  is distinct from the usual paraconsistent approach in that we do allow full use of classical logic  albeit locally. 
limited consistency: suppose that a has at most / distinct symbols  the  are a k-partition  and then  will be a union of at most m of the theories if the collection  is m-consistent  then ta will be consistent and exactly one of the first three values will be given. in other words  an agent whose b-structure is fairly consistent  and who is responding to a short query  will always give a consistent response. 
　we say that the person with belief base b implicitly believes a if v a  = true. if so  it is true that a follows from her explicit beliefs but the converse does not hold in general. if the explicit beliefs are jointly inconsistent  then their consequences will include all formulae  but the agent may still have implicit beliefs which are a reasonable set. the implicit beliefs will always include the explicit ones and will be locally closed under logical rules. 
　　what about adjunction  if an agent implicitly believes a and b  i.e. if the answers to a and b are both true and l a b  has no more than / symbols  then the answer to a b will also be true. however  cases can arise where the longer formula a  b forces the agent to simultaneously consider several of his beliefs and the underlying inconsistency i s d e   
 p r  and then the answers to the queries 
be yes  but to  it will be 
1 	base refinement 
a person who has explicit beliefs t in language l may organize these beliefs in smaller or larger chunks. clearly if r is inconsistent  then it is un-workable to organize them in a single chunk. moreover  organizing in larger chunks can make the computational problems harder. on the other hand it does have the advantage that more implicit beliefs can be derived in the sense described below. definition 1: a b-structure b refines another  every language li is a subset of another  and  iii  every 
example: suppose that the b-structure b has the three languages 
 1 generated by the formulae 
1respectively  the b-structure b' has the two languages 
                           . and t h e o r i e s g e n e r a t e d by the formulae r and respectively. clearly b refines b'. now to the query b will give the answer  and b' will give the answer 'yes' or true. 
theorem 1: let b refine b' and a be a formula. then 
 a  where  respectively stand for 
vb' a  	and vb' a . 
proof: given a formula a and b-structure b the query 
a   is answered by giving the value vb a  = v a  which is defined using where 
l a  is the language of a. similarly 
　　now we note that if and l a  intersects then it also intersects hence this imme-
diately yields 
　in other words  b' always yields more information than b. the downside is that b1 may give the inconsistent answer  to a query a whereas b may have given a true or false answer to it. the partitioning of information into separate languages may on occasion miss some answers which might have been obtained without such partitioning  but it is more likely to be consistent in particular queries. 
1 	b-structure revision 
what will happen to a b-structure when an agent receives some information which overlaps two sublanguages  one possibility is that the agent accepts the consequences within each sub-language while still keeping them separate. if i learn that both beijing and london had cold winters  i am not likely to merge all my other beliefs about the two cities. however  if i repeatedly receive information which overlaps two sublanguages  i may decide that the division is artificial and should be abandoned. options a and b below correspond to these two different attitudes. 
option a - the non-merging option: assume that each of the languages  has its own agm style revision operator. given a belief structure b and a new input 
a  define  for each i  the i-shadow of a to be the set 
 this will be a theory 
is what a has to say about the language 
be such that . now define the theories by: 
if ai is consistent with ti  and otherwise where  is a local revision op-
then the revised b-structure b * a will equal 
in practice  if l a  is empty  we can just leave unchanged  saving computational time. we define 
     a analogously  except that we use the operator on the various 
option b - the merging option: given a formula 
	chopra and parikh 	1 

a as input and a belief base b  assume without loss of generality that a has been written in the smallest language in which it can be expressed  parikh  1 . 
let as before 	where l{a  
is the language of 	and 
now replace all those languages 
such that 	by the single language 
  which is their union. at the same time  
replace all the corresponding  by the theory  a. this new way will specialize to the procedure in  parikh  1  where the languages were all assumed to be disjoint but the receipt of information resulted in joining those theories whose languages overlapped the language of the new information. 
1 	properties of b-structure revision 
both options a and b are computationally efficient. 
generally we assume that each li has relatively small size  say under some fixed p  while the cardinality n of the whole language might be quite large. then given a k-partition and a formula a with at most / distinct symbols  the query answering procedures run in time which is exponential in  but linear in n.  for option a  the procedure is linear in n  k and exponential only in  thus if - the number of atomic propositions relevant to a - is small compared to n  as is usually the case  the computational cost will be much smaller than that of usual update procedures which are exponential in n. 
　the update procedures need not preserve refinements. if b refines b' and there is new information a  it may reveal an inconsistency in b'  even though b is unfazed. it may seem foolish not to notice one's own inconsistencies  but these are often unavoidable  as with the well known preface and lottery paradoxes  kyburg  1    kyburg  
1 . the ability to retain a measure of consistency and act on the basis of one's implicit beliefs may have much to say in its favour. 
　option b results in two formally distinct subject areas merging as the result of some new information which straddles them. in real life this is likely to happen only occasionally. suppose i have a b-structure which keeps my beliefs about turkey  iraq and iran separate. if i now receive a great many pieces of information about the kurds who are scattered over these three countries then i may simply create the new subject asia minor and give up my attempt to deal with the three countries separately. 
1 	analogues o f t h e a g m axioms 
let b * a denote the revision of b-structure b by the formula a according to option b. the axioms b1-b1 below hold. the set theoretic notions used in stating the agm axioms are now replaced by more sophisticated generalizations which enter in with belnap's four truth values. for option a  axiom b1 needs the caveat that a  li for some i or  at least that a where each  is in some  and p is small. however dis-
1 	automated reasoning 
junctive information which straddles two of the li may be lost if we insist  as we do in option a  on keeping the li separate. 
　let b be a belief structure  a a new piece of information  * the revision operator. we then have the following axioms:  read a b as ' a is an implicit belief according to b'.  
b l . b * a  the revision of b by a  is a belief structure. 
	b1. a 	b*a 
	b1. if a  b  then b * a 	b*b 
	b1. b * a c b 	a. i.e. if b * a and b  a give 
values 	then 
　b1. if a is consistent with b  i.e it is not the case that   a   {false  t}  then b *a = b + a 
other issues: issues commonly raised in belief revision literature include  for instance  the axiom of recovery  revision by conjunctions  by sets of propositions etc. most of these properties will hold at the local level provided that the original local operations have them. at the non-local level when several of the ti interact in a particular case of a belief revision  more complex patterns of behaviour will emerge. these require further investigation. 
1 	review of previous w o r k 
we briefly discuss how other authors have addressed the issues mentioned at the outset. 
　work on the minimal change model has concentrated on minimizing the number of beliefs given up during the contraction operation. to this end  operations such as partial meet contraction using selection functions were defined in  alchourron et al  1 . a motivation for the choice of beliefs to be dropped is given by the notion of epistemic entrenchment introduced by  gardenfors and makinson  1  and refined for iterated belief change by  nayak  1    darwiche and pearl  1    lehmann  1 .  williams  1  uses the concept of maxi-adjustment to achieve maximal inertia of information under iterated belief revision.  georgatos  1  presents a generalization of entrenchment that serves as a representation of the agm axioms. the notion of epistemic relevance is used for minimal contraction in  hansson  1  and  nebel  1 . 
　the distinction between implicit and explicit beliefs  has been explored by the proponents of the belief base method such as  fuhrmann  1    nebel  1    hansson 1; 1 .  rott  1  combines some intuitions in showing how epistemic entrenchment orderings can be carried out for safe contractions for belief bases. 
　belief revision for inconsistent belief bases has been studied in an alternative approach by  brewka  1 . the possibility of paraconsistent belief revision is explored by  tanaka  1  while  restall and slaney  1  have developed a paraconsistent semantical representation based on the revision of models approach suggested in  grove  1 . the work of  schotch and jennings  

1  predates the agm approach to belief revision. they consider an approach based on giving up the adjunction rule: from a and  b conclude  b. 
as we saw  our treatment retains this rule at the local level. 
the investigation of complexity procedures in  nebel  
1   via a fine-grained set of complexity classes  has shown that the complexity of base revision procedures satisfying agm postulates is that of ordinary propositional derivability. nebel's comparison of different revision methods shows that model-based revision methods such as those of  dalai  1  have a complexity which exceeds both np and co-np. 
conclusion: we started this paper by indicating four desiderata which a framework for answering queries and for belief revision should try to meet. the b-structures framework meets all four. in future work we intend to carry out a thorough study of this interesting new model for belief representation and revision and to implement the query answering and revision procedures. 
　acknowledgements: this research was supported in part by a grant from the research foundation of cuny. we thank ron fagin  melvin fitting  konstantinos georgatos  henry kyburg  graham priest and the referees for helpful comments. 
