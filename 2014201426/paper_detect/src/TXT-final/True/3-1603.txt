
planning involves using a model of an agent's actions to find a sequence of decisions which achieve a desired goal. it is usually assumed that the models are given  and such models often require expert knowledge of the domain. this paper explores subjective representations for planning that are learned directly from agent observations and actions  requiring no initial domain knowledge . a non-linear embedding technique called action respecting embedding is used to construct such a representation. it is then shown how to extract the effects of the agent's actions as operators in this learned representation. finally  the learned representation and operators are combined with search to find sequences of actions that achieve given goals. the efficacy of this technique is demonstrated in a challenging robot-vision-inspired image domain.
1 introduction
planning  at its essence  involves searching an appropriately defined state space. this state space is a consequence of the agent's model of the effects of its actions  e.g.  strips  fikes and nilsson  1   markov decision processes  puterman  1  . it is assumed that these models can be defined from domain experts and planning uses these models to find sequences of actions to achieve given goals. the problem is that models are not always known or easily built for a domain of interest. others have studied methods for learning or agumenting models  such as strips operators  wang  1  or mdp transitions  peng and williams  1 . all of these techniques still require expert intuition about the domain to provide  at the least  an appropriate state representation.
¡¡this paper focuses on learning an appropriate representation for planning  using only an agent's observations and actions. we call this a subjective representation as the learned representation is extracted based only on the agent's experi-
ence  and requires no expert knowledge of the domain. the approach solves two important problems:  i  learning an appropriate state-space representation  and  ii  learning the effects of the agent's actions in this representation.1 the required input is a sequence of actions and observations from the agent's subjective experience  but no semantic meaning  domain-specific or otherwise  is required. this input is used in a three step process.
¡¡first  section 1 reviews action respecting embedding  are . are is a technique for dimensionality reduction that specifically makes use of a temporal sequence of observations and actions. are learns manifolds that capture the important underlying dynamics of the high-dimensional data in much fewer dimensions  addressing the first problem . next  section 1 describes a method for learning operators for each action that can be applied to any point in the learned representation  addressing the second problem . examples of learned operators are provided along with a discussion of how the semantic meaning of the associated actions can sometimes be extracted. finally  section 1 shows the results of planning in the resulting representation using the learned operators. both the resulting plan in the learned representation  and the result of applying the plans in the original high-dimensional domain are compared.
1 action respecting embedding
high-dimensional data sets  such as sequences of images  can often be characterized by a low-dimensional representation that is related to the process generating the data. for example  a low-dimensional representation for image data may correspond to the degrees of freedom of a platform moving a camera. such a representation is ideal for planning as it directly captures the actions' effects on the world. the goal here is to take a temporal sequence of data points  z1 ... zn  and associated actions  a1 ... an 1  and find a low-dimensional representation for zi that is appropriate for planning.
¡¡recently  nonlinear manifold learning techniques have been used to map a high-dimensional dataset into a smaller dimensional space. semidefinite embedding  sde   weinberger and saul  1  is one such technique. sde learns a kernel matrix  which represents a non-linear projection of

closely resembles recent work on learning predictive representations  james and singh  1; rosencrantz et al.  1; jaeger  1  than previous work on augmenting operators or transition probabilities. this approach  though  is specifically designed for very high-dimensional observation spaces as it implicitly involves a dimensionality reduction component.table 1: algorithm: semidefinite embedding  sde .
the input data into a more linear representation. it then uses kernel pca  scholkopf and smola  1   a generalization of principle components analysis using feature spaces represented by kernels  to extract out a low-dimensional representation of the data. the kernel matrix k is learned in sde by solving a semidefinite program with a simple set of constraints. the most important constraints encode the common requirement in dimensionality reduction that the nonlinear embedding should preserve local distances. in other words  nearby points in the original input space should remain nearby in the resulting feature representation. therefore sde requires a distance metric ||¡¤|| on the original input space  and uses this metric to construct a k-nearest neighbors graph. it then adds constraints into the semidefinite program to ensure that the distance between neighbors is preserved. the optimization maximizes tr k   i.e.  the variance of the learned feature representation  which should minimize its dimensionality. the sde algorithm is shown in table 1.
¡¡sde does not take into account two important pieces of knowledge about the data: the temporal ordering of the input vectors  zi  and the action labels  ai. therefore  sde doesn't guarantee that temporally-nearby input points will be spatially nearby in the feature representation. also  sde won't necessarily result in a space where actions have a simple interpretation. the recent action respecting embedding  are  algorithm  bowling et al.  1  extends sde to make use of exactly this type of knowledge about the data.
algorithm: sde || ¡¤ ||  z1 ... zn  
construct neighbors  n  using k-nn with || ¡¤ ||.
	maximize tr k  subject to	  and
	 ij	nij   1 ¡Å  n n ij   1  
kii   1kij + kjj = ||zi   zj||1
run kernel pca with learned kernel  k.¡¡formally  are takes a set of d-dimensional input vectors  z1 ... zn  e.g.  images   in temporal order  along with associated discrete actions  a1 ... an 1  where action ai was executed between input zi and input zi+1. are then computes a set of d-dimensional output vectors x1 ... xn in one-toone correspondence with the input vectors. this provides a meaningful embedding in d   d dimensions. are modifies sde in two key ways. first  it exploits the knowledge that the images are given in a temporal sequence. it uses this knowledge to build an improved neighborhood graph based on each input's distances to its temporal neighbors using the provided local distance metric1. second  it constrains the embedding to respect the action labels that are associated with adjacent pairs of observations. this ensures that the actions have a
¡¡simple interpretation in the resulting feature space.
it is this second enhancement of are that is the critical
algorithm: are || ¡¤ ||  z1 ... zn   a1 ... an 1  
construct neighbors  n  as in  bowling et al.  1 .
	maximize tr k  subject to	 
	 ij	nij   1 ¡Å  n n ij   1  
kii   1kij + kjj ¡Ü ||zi   zj||1   and
	 ij	ai = aj  
k i+1  i+1    1k i+1  j+1  + k j+1  j+1  = kii   1kij + kjj
run kernel pca with learned kernel  k.table 1: algorithm: action respecting embedding  are .
feature for subjective planning. are constrains the learned manifold to be in a space where the labeled actions correspond to distance-preserving transformations-those consisting only of rotation and translation1. therefore  for any two inputs  zi and zj  the same action from these inputs must preserve their distance in the learned feature space. letting ¦µ zi  denote input zi's representation in the feature space  action a's transformation  fa  must satisfy:
	 i j	||fa ¦µ zi     fa ¦µ zj  || =
	||¦µ zi    ¦µ zj ||.	 1 
 now  let a = ai and consider the case where aj = ai. then  fa ¦µ zi   = ¦µ zi+1  and fa ¦µ zj   = ¦µ zj+1   and constraint 1 becomes:
¡¡¡¡||¦µ zi+1    ¦µ zj+1 || = ||¦µ zi    ¦µ zj ||.  1  in terms of the kernel matrix  this can be written as:
	 i j	ai = aj  
k i+1  i+1    1k i+1  j+1  + k j+1  j+1  =
	kii   1kij + kjj	 1 
¡¡are simply adds constraint 1 into sde's usual constraints to arrive at the optimization and algorithm shown in table 1.
experiments. here we define imagebot  a synthetic image interaction domain used for all experiments. given an image  imagine a virtual robot that can observe a small patch on that image and also take actions to move the patch around the larger image. this  image robot  provides an excellent domain in which subjective planning can be demonstrated.
¡¡for these experiments  imagebot will always be viewing a 1 by 1 patch of a 1 by 1 image displayed figure 1. imagebot has eight distinct actions: four translations  two zoom actions  and two rotation actions. the allowed translations are forward  f   back  b   left  l  and right  r  by 1 pixels the zoom changes the scale of the underlying image by a factor of 1  i  or 1/1  o . the rotation rotates the square left  l  or right   radians.
¡¡there are three distinct experimental data sets that are looked at in this paper.

	1	1	1	1	1	1	1

1	1	1	1	1	1	1	1

1	1	1	1	1	1	1	1
figure 1: imagebot's output  and are's input  for the at data set.
figure 1: imagebot's world.
at: imagebot follows a path which looks like an  a  using only the translation actions:
f ¡Á 1 l ¡Á 1 r ¡Á 1 b ¡Á 1 l ¡Á 1 f ¡Á 1 b ¡Á 1
az: imagebot follows the same a pattern but substituting zoom in for left actions and zoom out for right actions:
f ¡Á 1 i ¡Á 1 o ¡Á 1 b ¡Á 1 i ¡Á 1 f ¡Á 1 b ¡Á 1
fr: imagebot moves back and forth in a line  but only using f and r actions:
f ¡Á 1 r ¡Á 1 f ¡Á 1 r ¡Á 1 f ¡Á 1 r ¡Á 1 f ¡Á 1
¡¡note that in az the f and b actions only move half as much when zoomed in as when zoomed out. note that in fr there are no opposites for the two actions used. an example of the output of imagebot  and correspondingly an input for are  is shown in figure 1. these are the images seen in the at data set. note that while we know that  for example  action label 1 corresponds to action f  are gets no such semantic information-it gets as input only the images and the labels associated with them.
¡¡the effectiveness of are has been demonstrated previously  bowling et al.  1 . here evidence is shown of its power in capturing useful representations for planning. figure 1 shows the actual manifold underlying the at test set  i.e.  imagebot's path . figure 1 shows the manifold learned by are on that test set. clearly the structure has been captured.
figure 1: the path imagebot follows to generate at.

figure 1: the representation learned by are for at.

figure 1: two different views of the three-dimensional cylindrical manifold learned for the fr data set.¡¡figure 1 shows a  top  view and a  side  view of the 1dimensional manifold learned for the fr data set. here the portion of the manifold corresponding to rotating to the right  r  is a black line while the portion corresponding to moving forward  f  is a light-gray line. the point corresponding to the first image is circled. although not as clear as in the previous case  this manifold is clearly and distinctly capturing the structure of the original path  with two dimensions capturing the r action and a third capturing the f action. in figure 1  the original domain was one in which the actions were distance-preserving and this structure was  indeed  extracted. in figure 1 it is not immediately obvious what manifold will be learned which makes the resulting one all the more impressive-not just as a representation appropriate for planning but as an aid to intuitive understanding of the original underlying structure.
1 distance preserving operators
are learns a representation with explicit constraints that the actions correspond to distance-preserving transformations in that representation. before one can plan  though  one needs to discover these transformations. for each unique action a there is a collection of data point pairs  xt xt+1  which are connected by that action. another way of thinking of this is that there is a function fa where fa xt  = xt+1  and such a function needs to be learned for each action. because of the distance-preserving constraints  fa can be represented as:
fa xt  = aaxt + ba = xt+1
¡¡recall that transformations of the above form encode translation in the ba vector  and rotation and scaling in the aa matrix. aa and ba could be learned using simple linear regression but scaling is not distance preserving so there is the additional constraint that aa does not scale  i.e. . it turns out that this is similar to the extended orthonormal procrustes problem  schoenemann and carroll  1   but without allowing for a global scaling constant. here the solution to the regression problem is derived.
¡¡let xa be the d by n matrix whose columns are xt for all t such that at = a  and let ya be the d by n matrix whose columns are xt+1 for the same t. the goal is to learn a rotation matrix aa and a translation ba which maps xa to ya. formally  the following optimization problem needs to be solved.
minimize: ||aaxa + baet   ya|| subject to: 
where e is a column vector with n ones.
¡¡in order to obtain the least squares estimation of aa and ba  write the lagrangian function l:
l aa ba ¦«  =
tr  aaxa + baet   ya t aaxa + baet   ya   +
tr
where ¦« is a matrix of lagrangian multipliers  and tr .  stands for the trace of a matrix.
l aa ba ¦«  =
tr
 1tr yataaxa    1tr ebta ya 
+1tr ebta aaxa  + tr ¦« ata aa   i  
now take the derivative of the lagrangian function with respect to the unknowns and set to zero:
 1 
 1 
the translation vector from equation 1 gives:
		 1 
multiplying equation 1 by on the right:
aaxatxaata + aa ¦« + ¦«t ata /1 =
yaxatata   baetxatata
since the left hand side is symmetric  the right hand side must also be symmetric. substituting equation 1  the right hand side can be written as:

where the last term is symmetric. thus the rest of the expression must also be symmetric. this can be simplified as:
		 1 
since 1 is symmetric  it should be equivalent to its transpose:

one can easily verify that the following satisfies equation 1:
	v swt	=	svd
	aa	=	v wt	 1 
figure 1: demonstrating distance-preserving operators in the representation learned for at.
where svd ¡¤  is the singular value decomposition  so 
v swtwv t = v wtwstv t
because wtw = i  since w is orthonormal  and s = st
 since s is diagonal . thus equations 1 and 1 are a solution to the dual function  d = min¦« l aa ba ¦« . since this solution is also feasible with regards to the primal problem  strong duality holds even though the original problem is non-convex.
results. figure 1 shows the two-dimensional representation that are generated for at. the solid arrows show a path which consists of new points resulting from the application of operators learned for each action  f  b  l and r  as described above. clearly  the operators are intuitively capturing the essence of the actions used to generate the data.
¡¡note that while there is no semantic meaning given with the input actions  such meaning can now be derived. it can easily be tested whether a pair of actions are opposites  such as  f b  or  r l . also two actions can be tested for orthogonality or independence  such as f and r. if the learned representation captures some underlying structure within the data  the learned operators will maintain that structure and  from them  relationships can be successfully hypothesized.
¡¡figure 1 is similar to figure 1  except the underlying representation is from the az data set. here  note that while some actions are again opposite to each other  no actions are orthoganal-the f and b actions are not independent of the i and o actions. this critical facet of the original data set has been successfully captured in the representation learned by are and consequently in the action functions learned in that manifold. note  in particular  that when zoomed in all the way  i ¡Á 1  1 f actions are equivalent to 1 f actions when zoomed out all the way. although f action when zoomed in half way was never observed  the learned operators capture the fact that between 1 and 1 f actions at this scale are equivalent to 1 and 1 actions at the other scales.
1 planning
now that low-dimensional representations and operators in those representations can be learned  all the pieces are in place to perform planning. the points in the learned representation are states  and the operators learned in section 1 define transitions between the states. this new domain has two advantages over the original data set. first  the dimensionality has been reduced drastically  from 1 to 1 or 1 . second  figure 1: demonstrating distance-preserving operators in the representation learned for az.
from the action labels functions have been learned for each unique action that explicitly give the resulting state when that action is applied from any state. learning such a function in the orignal space is not only intractable  but would require application of knowledge specific to imagebot  or even the underlying image  in order to attain any success.
¡¡given any two images  one can find a shortest path between them  even if it traverses unobserved parts of the space. first  find the corresponding points in the low-dimensional representation  then find the shortest path between them using traditional search methods and the set of learned operators. since each operator in the low-dimensional space corresponds to an action label in the orginal space the list of action labels that indicate the desired path can be returned. for the following results  iterative-deepening depth-first search was used and the path whose final point was closest to the desired goal was returned. the quality of a path is demonstrated by starting imagebot at the initial state  applying the sequence of actions and showing the resulting image.
results. for each of the three test sets  two sub-figures will be shown. the first shows the representation learned for that data set and the shortest path between a chosen initial state  labelled with a triangle pointing right  and a chosen goal state  labelled with a triangle pointing left . the second figure contains two images. the left image shows the image at the initial state  the right image contains two highlighted boxes. the light-gray dotted box shows the image at the goal state  the darker-gray solid box highlights the image obtained after executing the resulting sequence of actions.
¡¡figures 1 a  and 1 b  show the results for at-the goal state image and the image corresponding to the final state in our path in figure 1 b  are the same. note that the shortest path was successfully found  even though it involves moving through portions of the space that we have never seen.

	 b 	 d 	 f 
figure 1: results of planning in three examples.  a    c   and  e  show the paths in the learned representation.  b    d   and  f  show the starting image  the sequence of actions  and outlines the resulting and goal images.¡¡figures 1 c  and 1 d  show the results for az-the goal state image and the image corresponding to the final state in the path in figure 1 d  are the same. note  the path found successfully identifies that action b must occur before action o-if taken after then the b action would jump over the desired end state to a state halfway between it and the next state. figures 1 e  and 1 f  show the results for fr-the goal state image and the image corresponding to the final state in the path in figure 1 f  are very close to each other. recall that for this data set  unlike the others  the only actions were f and r with no corresponding opposites. this means that such a path must rotate all the way around  step forward  then rotate all the way around again-a fairly complex path.
1 conclusion
are can be used to learn a subjective representation appropriate for planning. the only input required is a sequence of observations and actions-no additional domain-specific knowledge is necessary. the output from are is a new lowdimensional space which captures the critical dynamics of the environment. operators which reflect these dynamics can be recovered in the new space. simple search procedures can then can be used to find sequences of operators which achieve goals in the learned representation. since operators correspond to original actions  this sequence provides a plan in the original space. these plans are accurate  even though they can involve actions in unobserved parts of the space.
acknowledgments
we thank finnegan southey  dale schuurmans  and pascal poupart for discussions and insight. we thank wesley loh for helping with implementation details. we acknowledge alberta ingenuity fund for their support of this research through the alberta ingenuity centre for machine learning.
