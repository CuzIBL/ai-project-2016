 
　　an expert system was constructed to aid the military intelligence analyst in performing the indications & warning task: assimilating hundreds of incoming reports  and predicting where and when an armed conflict might erupt next the system currently contains 1 condition/action rules and 1 other frames that deal with the sorts of objects and processes that are being reported on. it employs a two-dimensional blackboard to accomodate reports from very different sources  to efficiently trigger relevant rules  and to keep the human analyst abreast of the situation. in the process of building this system  and testing it with professional analysts * we were led to some nonstandard design decisions which may be of general al interest: 
 1  each rule has strong and weak conditions  which are run in separate worlds. by examining which important  high-level conclusions differ  it is possible to pinpoint which few specific facts should be doublechecked  i.e.  facts whose certainty the system is very sensitive to ;  1  each rule is represented as a frame  facilitating browsing through the rules  adding new rules  and assigning credit and blame to rules. 
i. the i&w task 
　　intelligence analysts are charged with monitoring an area  say  the two fictitious countries upper and lower x   and must alert their superiors to any forthcoming outbreak of hostilities in that area. in particular  the analyst must explain where and when he predicts an attack on lower x will originate  and what specific evidence he has to support that expectation. this task is referred to as the indications -and warning  i&w  problem. to solve it  the analyst reads hundreds of incoming reports each day from various sources  media articles  broadcasts  reconnaisance reports  human operative repoits  etc.  and maintains a detailed model of what is happening in his assigned countries. for more information  see  wohlstetter 1    belden 1   and  clarkson 1 . 
　　the i&w task was deemed one of the most significant problems of national security by former us secretary of defense harold brown  in a visit to esl in the summer of 1. the overwhelming array of data confronting an analyst suggested a man-machine system to support him. 
an expert systems approach was called for because  i  the analysts themselves describe their reasoning in informal rules of thumb;  ii  experts for the task are clearly recognized nnd were accessible to us;  iii  expertise for this task is often not present where and when it is needed  due to the high job turnover rate among us defense analysts  and due to the relatively small number of such analysts compared to the number of trouble spots in today's world;  iv  analysts must justify their predictions with a line of reasoning  which is easily available in rulebased expert systems. 
ii. design of an expert system for the i&w task 
　　working in conjunction with current and former i&w analysts  we have built an expert system to aid in this task. the various kinds of incoming reports are posted on a 
blackboard  erman et al 1   see fig. 1   whose dimensions are time  marked off in days  and these three levels of abstraction: 
 i  specific reports:  expect a report of 1 troops assembling at area1 two days from now  
 ii  higher-level indicators:  ground forces are massing at embarkation points all over upper x  
 iii  very general states:  upper x's military forces are now at full readiness  
　　sixty rules react to changes on the blackboard by drawing conclusions and making predictions; i.e.  the system  works forward . a new report enters and is recorded on the blackboard  various rules fire  they cause additional enuies to be added  etc. eventually this process dies down  and the next report is read. a typical rule says: 
r1: 	if a barracks is suddenly reported to be empty  
then expect a report  within a day  of  those  troops moving by rail or road to a nearby staging area. 
when a barracksempty report is posted on the 
blackboard  this rule fires and synthesizes a new troopsmoving report  and posts it on the blackboard farther to the right  to indicate it's to occur one day later in time   with a tag indicating that it's only a prediction  not  yet!  an actual incoming report 
　　rule rl takes incoming reports and predicts future ones. similar rules exist which predict past events that were not recorded; this is important  since intelligence gathering is quite incomplete. for instance  the inverse to the former rule says that if troops are moving by rail  they must have come from somewhere  and a few days earlier 
　　
1 d. lenat et al. 
some barracks probably emptied out. it is important to make and record these pas/dictions  as they sometimes cause additional rules to fire which in turn make predictions reaching even farther ahead in time than the current day. if we were to redesign the system  aware of the frequency of these rule&inverse pairs  we would choose only state the single causal relationship  and have both rl and its inverse derived automatically from that. 
　　other types of rules add entries at a higher level of abstraction  namely the indicator level rather than the incoming report level. a typical such rule  which adds one high-level entry to the blackboard and several lowlevel ones as well  says: 
r1: if there have been  within a 1 day period  at least 1 reports of troops readying to leave their usual base  and at least 1 are real reports  not just predictions   and in at least 1 the number of troops exceeds 1 and there is also an air defense system with them  and civiliansupport&preparedness indicator is active  
then activate the groundforcesassembling indicator  and keep it active for at least the next 1 days  and add predicted reports of troops moving in those areas  for each of the next 1 days  
　　it's often quite important to know when an indicator stops being active  and thus there are rules whose thenparts deactivate indicators  or predict such deactivation events. 
iii. ai issues 
　　so far  this design sounds like a rather standard expert system  feigenbaum 1; hayes-roth et al 1 . the program has  however  a few nonstandard features of interest to the ai community: 
　　representation. knowledge is represented as framelike assemblages of attribute/value pairs. the program has separate frames for each abstract indicator 
 unusualnavalactivity   each type of incoming report  lcu'sabsent   and -- as actual reports filter in - the program creates a new frame for each such report  lcu'sabsent1 . in general  a frame is created for each entry made on the blackboard. 
　　most reports are of events  and each event is usually just a sub-process in an easily recognizable larger process. thus  emptying barracks is a subprocess of troop movement  which in turn is a subprocess of ground force readiness  which is a subprocess of military readiness for attack  etc. each frame for a type of report records what it might be a subprocess of  how long it takes  what subprocesses it entails  which of those can be done in parallel  etc. from this information  estimates can be derived of the minimal time to various states  such as full readiness . knowing what processes are going on  and how soon various states might be achieved   solves  the 
　　
i&w problem. the analyst reads off  at as high a level as desired  predictions of the content and date of future reports. 
　　besides the types of frames already described  there is a hierarchical network of frames for objects mentioned in reports. this is necesary so that  e.g.  a rile that specifies 'tracked vehicles' will trigger if the incoming report mentions 'tanks'. 
　　a separate frame also exists for each rule. for instance  r1 has not only an if and then slot  but a name  a numericaldesignator  a creator  a creationdate  a mightactivate  an isa  a certaintyofconclusion  an overall worth  and values for several other slots. this facilitates browsing through the rules  adding new rules  debugging a faulty set of rules  finding related rules when a rule is  almost  relevant  assigning credit and blame to rules  and  hence  automatically modifying the if and then parts of rules  their certainties  and their worths. 
　　control. an experimental aspect of the system is to provide rules with two different triggering conditions  an ifstrong and an if weak. usually  the former conditions imply the latter  though this is not essential to the idea  and in some cases in our system it is not what the experts told us; for instance  one rule's ifstrong has a conjunct of the form  ...seen 1 reports in 1 days   and its ifweak has a corresponding conjunct that tests  ...seen 1 reports in 1 day  - neither of these implies the other. 
　　two separate blackboards are in effect maintained  two entire runs of the program  if you will. in one case  riles' conditions are assumed to be their if strong's; in the other case  their ifweak's. naturally  this often leads to discrepancies of which rules fire  hence which predictions get made. if the  true  conditions lie somewhere between the ifstrong and ifweak  then the  true  best predictions ought to be a superset of the ifstrong world's blackboard  and a subset of the ifweak world's blackboard. in particular  if both of them make the same high-level prediction at nearly the same time  it is more likely to be correct. conversely  if there is a crucial difference between the blackboards  we can list the rules whose difference in ifweak and ifstrong conditions led to that discrepancy. the specific conditions can then serve to focus our attention on exactly what detailed data we should gather in the immediate future; this data is handed to collection tasking planners  whose job is to close such  information gaps   and is no longer part of the i&w problem. 
　　the important point to make here is that  even if there is a wide difference between the low-level predictions that are made on the two blackboards  only those differences which led to important high-level differences are worth paying attention to. for instance  in a typical run  the unusualactivityatnavalbases and unusualactivityatairfields indicators triggered on different days and in different orders in the ifstrong and ifweak cases  but still they were both close enough to each other in time that in each case the general air&naval readiness state was highlighted at the topmost level. 
d. lenat et al. 1 
　　explanation. the analyst must support his predictions  both qualitatively and quantitatively. as our program runs  the user can point  using a mouse-driven cursor  to an item posted anywhere on the blackboard. s/he then receives information on it  including  if it is not a primitive report coming in as raw data  a listing of the rules that led to its posting. the user gets a stylized english translation of those rules  and can inspect them in detail if s/he desires. by pointing to any clause in the rule's if part  the particular reports  or predictions or indicator activations  that were used to satisfy that clause are highlighted down below  on the display of the blackboard. the quantitative support the analyst requires is calculated from the times taken by all the subprocesses an event requires. 
　　interface. the program was written in interlisp-d  and runs on all xerox d  1 series  machines. even on a dolphin  1  itself  reports are handled so rapidly  1/minute  that we were forced to artifically slow the program down for demo purposes. the screen is divided into several windows  see fig. 1   the largest of which is a display of the current state of the blackboards. the x-axis represents time  the y-axis level of abstraction and certainty. other windows are used to display: the frame representing each incoming report; a running commentary by the program of what it's reasoning about; menus to customize the display or access the explanation facility; a tree of processes and subprocesses from which readiness time estimates are derived; and finally a list of information gaps  critical pieces of missing or uncertain information  as determined by running in two separate worlds  using strong and weak versions of the rules . a separate color screen is maintained  with a map of upper and lower x on it as each entry is made on the blackboard  it is also drawn on the map  at its proper location. figure 1 shows this map display  and figure 1 the primary 1 screen  during one run. 
iv. conclusions & future directions 
　　the small  1-rule  system we built is little more than a prototype system for aiding an intelligence analyst with the i&w task. although it is incomplete in some respects  it has served as a concrete example to stimulate analysts into giving many comments for the next generation system for this task. from an ai point of view  the way we overcame some obstacles in this problem may prove to be general methods to add to the knowledge engineer's toolkit. we are referring to the flexibility of what the user sees  the representation of rules as frames  and the use of two blackboards  driven respectively by ifstrong and ifweak conditions on rules  to find the most sensitive details in the reports  and hence to guide collection tasking. 
　　two directions are being pursued to continue this work in 1.  1  the existing system is being expanded  to cover a broader range of report types.  1  we are using techniques of open-ended exploration  lenat 1  to perform scenario generation  based on the same knowledge base of facts and rules used in the i&w 
　　
1 d. lenat et al. 
system. the goal of that project is to produce long chains of cause and effect which terminate in particularly undesirable results  and then suggest specific information to gather which  quite early on  could detect such a scenario being attempted. 
acknowledgements 
this work was pursued at esl  inc.  funded through internal 
r&d funds. 	ed richardson  paul clarke  and len karpf 
participated in the project along with the authors  and were largely responsible for the explanation facility and the map. ernie chaves provided useful management guidance. consultants from teknowledgc  inc. and analysts from government intelligence agencies were also crucial to its success. in particular  we thank penny nii and mike mitani. 
