 
     in this paper we examine the operationalityigenerality trade-off and how it affects performance of explanation-based learning systems. experience with the arms learning apprentice system  presented in the form of an empirical performance analysis  illustrates both sides of the trade-off. 
1. introduction 
     recent work in explanation-based learning  ebl  has attracted much attention from the machine learning community  dejong1 mitchell1 . a number of systems have been and are still being developed in a spectrum of domains from natural language processing  mooney1   to circuit design  mitchell1a  
     this paper discusses the operationality/generality trade-off and how it arises in ebl in general and the implementation of the arms  for acquiring robotic manufacturing schemata  system in particular  segre1 segre1a segre1b . arms is a learning apprentice system  mitchell1b  that learns to assemble simple mechanical devices using an idealized robot arm. by observing  analyzing  and generalizing a human planner's solution to an assembly episode  arms builds a new schema which can be used to synthesize assembly plans for future episodes. 
     we begin with an intuitive discussion of the operationality versus generality problem. we then proceed to give a short description of the arms system  segre1b  with emphasis on the generalization process. finally  we describe a simple arms example to illustrate this important trade-off. 
1. operationality versua generality 
     explanation-based learning  ebl  systems are capable of acquiring knowledge from a single example. using a domain theory  a sample problem solution is analyzed in order to account for how the goal is accomplished. this analysis  or explanation  is generalized to create a new knowledge structure. 
     if the newly acquired knowledge structure is available to the system  it is said to be operational. if the new structure does not improve the performance of the system in some fashion  it is not worth learning. however  not all operational knowledge is created equal: the cost of using the new knowledge structure is called its operationality. the more operational the structure  the easier  e.g.  less expensive  it is for the system to apply it. 
     the arms system was designed and implemented by the author as part of hit ph.d. research at the university of illinois at urbana-champaign. the author is indebted to professor q. dejong and the rest of the coordinated science laboratory artificial intelligence research group for their comments and suggestions. 
support for this research was provided by a caterpillar corporation graduate 
fellowship  the air force office of scientific research under grant p1-k 
1  and the national science foundation under grants nsf-i1t-1 and nsf-ist-1 
1 	knowledge acquisition      note that we have yet to address the issue of exactly how the new structure is used. the only important point is that the knowledge should increase some aspect of the system's capability or performance. the new knowledge structure might be used in order to construct explanations of more complex examples  thereby increasing a system's comprehension ability. on the other hand  it might be used by a system's performance element  e.g.  a planner  in similar problem-solving situations. 
     but just how similar is similar  the diversity of examples covered by the new structure is directly related to its generality: the more general the knowledge  the more situations where it is likely to be useful. unfortunately  the more general the structure the more expensive its application tends to be. we term this dichotomy the operationality/generality trade-off: a more general structure is less operational and vice versa. 
     consider an example form the game of chess. having observed the successful capture of the opponent's rook using the technique called a knight fork  a system could produce a very operational new structure describing exactly this board situation.1 for the system to use this new structure in a future game  every piece on the chess board would have to occupy exactly the same position as in the first example. 
     clearly this new structure  while operational to an extreme  is hardly general. the position of a pawn on the other side of the board can hardly affect the success of the knight fork. on the other hand  it is quite simple and inexpensive to use: in the same board situation  application of the structure is immediate and practically without cost. 
     if  however  the rook capture is analyzed and generalized  the resulting knight fork knowledge structure might well take into account the relative positions of the knight  the decoy  and the victim  a rook in the observed example . it should not rely on the actual positions of these pieces  since the knight fork is applicable anyplace on the chess board. in addition  the piece type is only important for the knight: the captured piece need not always be a rook. 
     such a new structure is more general  since it can be applied to many other board situations. naturally  the cost of applying this new structure is greater than the trivial case described above. first  we must decide whether the structure is applicable to the current situation. this involves more than a simple matching  since our structure does not fully specify the chess board. second  we must identify which pieces on the board play which roles in the structure. 
     designers of ebl systems must decide where the new structure produced by their system's generalizer lies in this operationality/generality spectrum. mitchell et al  mitchell1j 
　　
posit a fixed operationally criterion to specify the level of representation used for the new knowledge structure. they suggest that a fixed vocabulary be established a prion  so that any new structure described using this limited vocabulary is by definition considered operational. 
　　as pointed out by mooney and dejong  dejong1   there are obvious difficulties involved in finding such a fixed operational vocabulary for any given domain. even if a fixed operationally vocabulary could be specified  there is no guarantee that structures expressed with this vocabulary are easy to apply. as an example  mooney and dejong give the following two propositions: 
provable  1 + 1 = 1''  
provablecfermat's last theorem   
the first is clearly operational  while the second is not. yet both are described using the same vocabulary. 
　　in any case  the fixed vocabulary approach seems needlessly limiting  especially if one departs from the static classification type tasks of mitchell et al and considers acquiring problemsolving skills. when learning problem-solving skills  the system is acquiring the ability to plan solutions  sequences of operators  to other problems by analyzing a trace of a successful solution. 
　　mooney and dejong present an alternative  more dynamic  definition of operationality based on the problem-solving capabilities of a system. in their view  an ebl system makes previously known static concepts operational by learning how to achieve these concepts. for example  the concept of checkmate in the game of chess is easy to describe  a situation where one player's king cannot escape capture  but difficult to operationalize  planning a series of operators to achieve checkmate . a concept therefore becomes operational only when the system acquires and can index a plan to achieve it. 
　　making a plan operational makes no statement about the quality of the plan. from our earlier discussion  it is clear that there are many different levels of operationality  levels that will affect system performance. in the next section  we describe an example from the arms system which compares two different levels of operationality. 
1. the arms system 
　　we now turn our attention to an example taken from the arms learning-apprentice system  segre1 segre1a segre1b . 
arms is an ebl system that acquires the ability to plan sequences of robot motions to accomplish assembly of simple mechanisms. a complete description of the system is far beyond the scope of this paper  however  a short overview describing the general structure of the system will be helpful when describing the example. 
　　arms learns by unobtrusively observing an expert guide the robot through an assembly task via the robot arm's teach pendant. to the user  this method is indistinguishable from the teach-by-guiding robot retraining method used in most current robot arm installations. in contrast to teach-by-guiding systems which provide for rote memorization of the input sequence  arms acquires  from a single episode  the power to plan the assembly of an entire class of functionally similar mechanisms. 
　　the arms architecture is that shown in figure 1. it divides into two elements  the learning element and the performance element  which do not operate concurrently. the two elements share domain knowledge which is stored in the form of schemata in the schema library. 
　　the user specifies an assembly by giving a functional goal specification. the goal specification describes the mechanical behavior of the desired assembly  without specifying a physical description. if the performance element can derive a physical goal description from the functional goal specification  the design 

problem   it then attempts to derive a plan to transform the initial world state into a state containing an instance of the design-problem solution  the assembly problem . 
　　if the performance element fails to find solutions to the design and assembly problems  control is transferred back to the user  who now guides the learning element through the assembly process. as the user moves the arm about the workspace  the system observes the user's solution and produces a new schema to use in future problem-solving situations. 
1. world model 
　　the arms system relies on an emulation of the robot world in order to reason about how pieces fit and move together. this emulator is much like the modeling systems used for computer graphics and cad/cam applications. it is a simple constructive solid geometry  csg  modeler which represents pieces as the sum and/or difference of primitive volumes. 
　　the modeler is used to model the arms gripper and its interactions with the world.1 it must realize when the gtipper is manipulating a piece  what effects these manipulations have on the position of that piece and any piece interactions. the modeler maintains a copy of the world at each time tick by using a storage-efficient mechanism similar to those used for copying 
sparse matrices. 
　　the rest of the arms system does not have direct access to the emulation afforded by the csg world modeler: rather it only has access to descriptions of this world which are maintained by the database. any request for world information is shuttled through the database  which manipulates tokens representing relations between elements of the world model. this collection of tokens corresponds to the state of the problem-solving domain. note that it is the responsibility of the database to uniquify requests so that there is only one copy of a symbolic state to describe a particular partial world state. 
1. knowledge representation 
　　all domain knowledge in arms is represented as schemata. a schema  chafe1 charniak1 minsky1 schank1  is a general structure which  via the use of slots which can be filled with a variety of different values  can be used to represent a class of similar concepts. a schema is said to be instantiated when all of its slots are bound to constants or other instantiated schemata  in which case it represents a unique concept. arms schemata fall into five different categories. 
 1  physical object schemata represent the csg models of the pieces in the domain. while certain limitations are 
     1  while arms has been lined to drive a real robot arm  guatafoon1j ' its normal mode of operation involves driving the simulated robot arm in this simulated environment. 
	segre 	1 
imposed by the simplicity of the modeler  arms can model an infinite set of different pieces. 
 1  state schemata represent the vocabulary with which arms reasons about the real world. these are maintained by the database in an on-demand fashion: no state schema is ever generated or otherwise manipulated except as a result of an explicit request by the system. each state contains temporal information indicating start and end times for the state.1 
 1  constraint schemata are just like state schemata  except that they are time-invariant. certain aspects of the world are not mutable by applying system operators  e.g.  relations between sizes of pieces : thus the constraint schemata are maintained more efficiently by the database. constraint schemata are attached to state schemata to impose restrictions on the values the state schema slots may take. 
 1  joint schemata are also like state schemata in that they are maintained by the database and have temporal scope. they 
come in two flavors: abstract joint schemata describing the mechanical behavior of two related pieces  and physical 
joint schemata describing the implementation of the mechanism in terms of interacting surfaces. together  these joint schemata form the building blocks of the arms domain theory.1 
 1  operator schemata  which include the five primitive operator schemata  represent the plans the system can apply. the primitive operator schemata correspond to the idealized arms robot arm command set. they provide the lowest level of description for robot motion. operator schemata describe the context in which they can be applied  as well as what goals they achieve. the composite  e.g.  nonprimitive  operators are recursively defined in terms of other schemata. the system learns this kind of schema  and it is this case we will examine a bit more closely later in our operationality/generality discussion. 
1. the performance element 
inputs to the performance element are: 
1. the initial state of the world; 
1. a goal specification given as an abstract joint schema. 
the performance element produces a sequence of fully instantiated primitive operator schemata. 
　　the arms performance element begins with a design phase  where a physical joint schema consistent with the functional goal specification  an abstract joint schema  is derived. this physical joint schema is then used to index into the schema library and select a top-level plan. the planning phase recursively expands the top-level plan to produce a robot arm command sequence which achieves the final state from the specified initial state. 
　　the planning process is a depth-first search through the plan space defined by the operator schemata  both built-in and acquired  stored in the schema library. this schema planner  similar to the skeletal planner of  friedland1   is a simple design which selects an abstract plan  in the form of an operator 
1  even though state schemes are checked against the emulator only at a reeult of a request  the amount of time spent by the database in satisfying requests for symbolic information about the world accounts for a large portion  in some examples as much as 1% of the total  of the computational resources expended by the arms system. while arms runs on a serial machine  this kind of database mechanism is a prime example of those algorithms which seem best suited to large grain size parallel machines 
1  the system is capable of learning physical joint schemata  but the finite 
set of abstract joint schemata is built in  the reader is referred to  segre1  for a diacussion . 
1 	knowledge acquisition 
schema  to achieve the specified goal state  and repeatedly expands it until the process bottoms out with a robot arm command sequence.1 
1. the learning element 
　　the learning element is responsible for first understanding how the user solved the problem  and then generalizing the observed solution into something that can be used again later by the performance element. we divide this task into three distinct sub tasks: understanding  verifying  and generalizing. inputs to the learning element are: 
1. the initial state of the world; 
1. a goal specification given as an abstract joint schema; 1. a sequence of instantiated primitive operator schemata. 
the primitive operator schemata are echoed from the teach pendant of the robot arm being led through the assembly episode by the user. the understander builds a causal model of the external agent's problem solving behavior. 
　　when the user is finished  the system verifies that the function of the physical mechanism constructed by the user corresponds to the initial functional goal specification. the verification process relies on a naive kinematic domain theory to analyze the function of a mechanism. this process may result in the acquisition of a new schema via explanation-based specialization that operationalizes the functional goal specification and provides a solution to future design problems   see  segre1b  for a more thorough description of the verifier . 
　　next the generalizer produces another schema via explanation-based generalization. this newly acquired schema can then be used to solve an entire class of assembly problems which share the same functional goal specification. 
　　in this paper  we give a quick description of the generalizer only: the reader is again referred to  segre1b  for a more thorough discussion. 
1.1. the generalization process 
　　the generalizer takes as its input the verified goal specification given by the user and the causal model produced by the understander. the generalizer produces a new composite operator schema which can be used both in understanding and planning  see figure 1 . 
　　as a result of the verification process  an instantiated version of the user-specified abstract joint schema is tied to a set of physical joint schema tokens in the causal model. these tokens constitute the top-level sub goal set. 
　　we begin by ordering the top-level subgoal set on the basis of a causal dependency analysis. this causal analysis relies on the arms domain theory to determine if there are any ordering dependencies between elements. in short  the limits of travel in the individual subjoints of the mechanism are examined to see if their boundary conditions rely on other subjoints. 
     1  the arm1 planner stops at the level of primitive robot arm commands. when driving the robot arm  the primitive operator schemata are expanded into arm-dependent control statements: this is done with an arm-specific algorithm which takes robot level statements down to the kinematic level. note that arms does not deal with collision avoidance  an active research topic which goes well beyond the scope of this implementation. for now  arms assumes an un-
cluttered workspace so that collision avoidance is not a problem ' apologies to mcdermott: 
wa should avoid  for axample  labeling any part of our programs an  understaadsr   it is the job of the text accompanying the program to axamins carefuy how much understanding is prssent  how it got there  and what ita limits are 
 mcdermott1  
while we often use the alternate  but less illustrative  term justification analyzer  which is perhaps more acceptable from mcdermott's point of view  this practice conflicts with our goal of descriptive simplicity 
　　

　　to extract the explanation from the causal model  it is sufficient to follow the pointers established during the understanding process from the  now causally ordered  top-level sub goal set down to the primitive operator inputs. the relevant pointers are those connecting operators to their recursive expansions. note that an explanation should also contain pointers to all of the constraint schemata supporting states in the explanation. 
　　at this point  the generalizer must pick a level of representation for the new operator schema. the higher the level of representation  the more generally applicable the new schema will be: however  a price will be paid in the amount of work done by the planner in applying the new schema. the extra work comes from the added levels necessary in the recursive expansion of the plan. conversely  a more operational new schema will be easier to apply  but less generally applicable. 
　　depending on the value given by the user to the operationality/generality parameter  the arms generalizer expresses a new schema as follows: 
 1  as the abstraction of the top-level subgoal set  producing a more general new schema  see figure 1 . 
 1  by descending the explanation structure to a level where all of the state schemata are roots of independent subtrees in the explanation  a more operational new schema . the state schemata at this lower level become the subgoal set of the new composite operator schema. this produces a new subgoal set which preserves any causal dependency orderings established during the joint analysis  see figure 1 . 
　　having in this fashion collected a set of subgoals  we now complete the construction of the new operator schema and integrate it into the schema library. 

　level with no shared substructures in explanation the two elements of the top-level subgoal set are represented as white nodes at the root position of two overlapping explanation subtrees. when producing the more operational new schema  the generalizer descends into the explanation structure until it can produce a subgoal set  represented here as black nodes  with no shared substructure. this set then becomes the subgoal set model for the new schema. figure 1 
　　at first glance  the two schemata do not seem terribly different. in fact  both new schemata are equally capable of solving a set of similar problems  yielding identical solutions. while their operationality difference is obvious in the levels of recursive expansion required in planning  their generality difference is not immediately evident. 
　　closer examination shows that the more general new schema is better able to integrate subsequently acquired schemata in its planning behavior. in other words  as the system learns how to do things in other ways  the more general new schema  unlike the more operational new schema  is immediately able to take advantage of this new knowledge. 
1. an example 
　　consider as an example a mechanism  see figure 1  assembled from three pieces: a washer  a bored block  and a peg. the shaft of the peg is inserted first through the hole in the washer and then into the hole in the block. the washer spins freely about the peg  while the peg fits snugly into the bored block. we call this simple mechanism a widget. 
　　we can describe the widget physically by describing the pieces  call them $pegl  $washerl  and $boredblockl  and the mating conditions between them  this is the approach taken by most task level programming systems such as rapt 
 popplestone1  . we could also describe this mechanism at a functional level as a revolute joint  e.g.  a single rotational degree of freedom  between $ washerl and $boredblockl. unlike the 
	sogre 	1 
　　

physical description  the functional description need not explicitly mention $pegl. in fact  the same functional description would hold for any assembly having the requisite one rotational degree of freedom  regardless of the physical mechanism used to achieve this function. 
　　the system is first given the piece descriptions and their initial placements in the workspace 'see figure 1 for an example . when asked to achieve a revolute joint between the washer and the bored block  the system should automatically generate a sequence of fully instantiated  i.e.  with all parameters bound  primitive operators which  when applied by the robot arm  transform the initial state into the assembly described above. the sequence should take into account factors such as the proper grasping strategy for each piece  whether pieces are cleared off before attempting to move them  and so on. 
　　since the system currently has no plan to achieve this concept  in fact  the system does not yet possess a concept corresponding to this function's physical realization   the system admits defeat  and the user proceeds to show it how to build a mechanism which has the desired functionality. the user guides the system through an assembly episode which results in a physical assembly that fits the specified goal. note that the assembly sequence given by the user  input to the system as fully instantiated primitive operators  need not be an optimal sequence  but simply effective in accomplishing a physical instantiation of the functionally specified goal. 
　　the system verifies  using its domain theory  how the physical assembly realized instantiates the desired functional goal. during the verification process  a new concept corresponding to this physical realization of the functionally specified goal is acquired. 
　　if the verifier terminates successfully  the generalizer produces either a more general or a more operational new schema which can be used to solve similar problems. 
1. results 
　　in this section  we present some empirical results collected from the arms system. arms is implemented using the objectoriented language loops  which is in turn constructed in interlisp-d. these results were collected on a xerox 1 
lisp machine running the koto release of interlisp-d and the buttress version of loops. the 1 has 1 megabytes of main memory  a 1 megabyte hard disk drive  and a hardware floating point coprocessor. 
　　performance of the system is adversely affected during these tests by the information-collecting mechanism. the system suffers a factor of eight slowdown while collecting these statistics. however  since our only interest here is in comparing one example with the other  the slowdown effects are not relevant. 
1 	knowledge acquisition 

initial state 1 
the robot gripper is located in the center of the picture with fingers closed and pointed down. $boredblockl is to the right  $pegl is to the left  and $washerl is in the foreground just left of center. the functional goal specification is given as an abstract joint schema $revolutejointr$boredblockl  $washerll. 
figure 1 
1. learning episode 1 
　　given the initial configuration shown in figure 1  the system is presented with a sequence of 1 primitive operator schemata which complete the assembly of the widget shown in figure 1. the system constructs a new  more operational  schema which can plan the assembly of this and other functionally similar mechanisms. 

　　the size of the causal model and the explanation are given in terms of tokens  where each token represents a schema instance. this is a pretty good measure of the difficulty of the example: the larger the number  the more complex the analysis or the plan. 
　　the number of database queries  tokens created  requests issued and slot manipulations are a good general indicator of how much work is performed by the system. 
　　the total cpu time reflects the time for emulating  understanding  verifying  and generalizing the example. also provided is the cpu time for generalization alone. 
1. learning episode 1 
　　this example is identical to learning episode 1  except that the more general new schema is constructed. 
　　as expected  the results shown here are almost identical to the results of the previous  identical  episode. the only difference is in the time spent on generalization. the extra analysis required to produce the more operational new schema is clearly evident in the greater cpu time for generalization in the operational case. this is consistent with expected behavior. 
　　

1. problem-solving episode 1 
　　we again present the system with the initial configuration of figure 1. the system is asked to produce a revolute joint between $boredblockl and $ washer 1. the system solves the design problem and then applies the more operational version of the new schema to the assembly problem  generating a 1 step solution. 

1. problem-solving episode 1 
this example is identical to problem-solving episode 1  see 
figure 1   except that the new schema being applied is the more general version. we therefore expect this example to be less efficient  since the planner must work harder when applying a more general schema. 

　　the system generates the same solution as in problemsolving episode 1. the solution  however  is more expensive to generate as indicated by the number of tokens generated and requests issued this behavior is also evident in the total cpu time figure  1 minutes as compared to 1 minutes in the other case . in addition  the planner subtree is a bit larger: but since the additional nodes tend to be at the highest level of abstraction  the increase in cpu time tends to be more than linear in the increased subtree size. 

initial state 1 
the robot gripper is located in the center of the picture with fingers closed and pointed down. $boredcylinderl is to the left  with $pegl stacked on top of it. $peg1 and $washer1 are stacked  from left to right  on top of $blockl on the right side of the workspace. the functional goal specification is the same as in initial state i 
figure 1 
1. problem-solving episode 1 
　　this problem-solving episode demonstrates the power of the system in planning the assembly of physically different yet functionally similar mechanisms. the system is asked to plan for a revolute joint between $boredcylinderl and $washer1 there is no mention of $peg1: the system must decide for itself which of the other pieces in the workspace can be used to achieve a physical instance of the functionally specified goal. the initial state is shown in figure 1. 
　　in this example  we are asking the system to deal with not only a more complicated initial starting configuration  but also the system must construct a functionally specified assembly from physically different pieces. 

1. problem-solving episode 1 
　　problem-solving episode 1 is identical to problem-solving episode 1  see figure 1 . the system supplies the identical solution  but at greater computational expense. this is consistent with expected behavior. 

	segre 	1 
　　
1. conclusion 
　　in this paper  we have provided an overview of the operationality/generality trade-off for explanation-based learning systems. we have described one approach  that of the arms learning-apprentice system  for characterizing the operationality of a new schema based on the structure of the explanation itself. finally  we described an experiment that provides preliminary empirical evidence of the importance of this trade-off. 
　　what we are really dealing with is a set of plans covering a spectrum of operationality/generality characteristics. it is up to the system designer to decide what the best level s  of operationality are for a given system. given that there is no single solution  the best we can hope for is to understand the problem well enough to decide where on the continuum a given system's generalizer should reside. 
