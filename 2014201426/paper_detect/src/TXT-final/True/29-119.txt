 
communication can be more effective when several media  such as text  speech  or graphics  are integrated and coordinated to present information. this changes the nature of media specific generation  e.g.  language generation  which must take into account the multimedia context in which it occurs. in this paper  1 will present work on coordinating and integrating speech  text  static and animated 1d graphics  and stored images  as part of several systems we have developed at columbia university. a particular focus of our work has been on the generation of presentations that brief a user on information of interest. 
1 introduction 
in many contexts  explanations can be more effective if they use multiple media. in our work  we have explored the generation of multimedia explanations in the context of providing instructions for equipment maintenance and repair  feiner and mckeown  1   providing briefings on patient status after bypass for various caregivers {dalai et a/.  1a; 1b   and providing illustrated briefings over online documents in an internet environment  aho et a/.  1 . a key characteristic of our work is the dynamic generation of content and form at the time an explanation is required. this means that we can vary not only what is communicated  but also how different media are used in combination to best convey information depending upon the situation. 
　our work has integrated a range of media within an explanation  including the use of written text accompanied by static graphics  the use of spoken language  text  and animated graphics  and the use of textual summaries with representative images. our research has focused on coordinating the different media in a single explanation  using individual media to present aspects of the presentation for which they are particularly suited and ensuring 
   *a great number of people have collaborated on the  projects that are overviewed in this abstract of my invited talk. see the acknowledgments section for a list of contributors who in other situations have been co-authors. 
that generation within one medium enhances portions of the presentation in other media. 
　the nature of generation for an individual medium  such as language  is changed by the fact that it occurs in a multimedia environment. for example  how language refers to information and entities in the domain changes when there is an accompanying illustration of the same information or entities. furthermore  the nature of this change depends upon the specific media used. for example  coordination of spoken language and animated graphics requires that spoken references be temporally synchronized with the accompanying graphical reference. the combined use of text and speech  on the other hand  changes the content of generated references. spoken references can be shorter and more natural as long as the accompanying textual reference provides the full  unambiguous reference. 
　in our more recent work  multimedia explanations are generated for the goal of briefing a user  dalai et a/.  1a; aho et a/.  1 . in the healthcare domain  they provide a concise summary for time-pressured caregivers. in the internet environment  they highlight information contained in the underlying multimedia documents. in both scenarios  the nature of language generation differs from traditional text generation: summaries must be concise  using as few words as possible; at the same time  they must be informative  conveying as much information as possible in limited time or space. 
　in this paper  we present issues for language generation when produced as part of a multimedia briefing. we begin with a brief overview of the approaches we use in the three systems we have developed. we then discuss the modification of language generation for the multimedia context and finally  highlight questions for summarization. 
1 an overview of columbia university multimedia systems 
in this section  we provide a brief overview of several multimedia systems developed at columbia university  highlighting domain  types of media used  and the goals for generating explanations. for full details on each system  refer to the original papers cited below  from which 
	mckeown 	1 
the examples of generated explanations are drawn. 
1 c o m e t 
comet  coordinated multimedia explanation testbed  generates coordinated  interactive explanations that combine text and three-dimensional graphics  feiner and mckeown  1 . comet not only determines what information to communicate using a content planner  but also how to express it in each medium using medium-specific generators  mckeown et ai  1; seligmann and feiner  1; mckeown et ai  1   
text and graphics are coordinated by communication with a media coordinator  feiner and mckeown  1; mckeown et al  1 . comet was developed to provide explanations for equipment maintenance and repair. it generates explanations that instruct users how to carry out diagnostic tests on a particular piece of equipment  a military radio receiver-transmitter. explanations typically describe one or more steps in these tests that are presented in a series of displays  where each display includes an illustration and a caption providing the textual instruction. 
1 m a g i c 
magic  multimedia abstract generation for intensive care  is being developed to provide a multimedia interface to health care data. in particular  magic is designed to provide briefings on patient status immediately following a coronary bypass operation. in a cardiac intensive care unit  communication regarding patient status is critical during the hour immediately following bypass. it is at this critical point  when care is being transferred from the operating room to the intensive care unit and monitoring is at a minimum  that the patient is most vulnerable to delays in treatment. during this time  there are a number of caregivers who need information about patient status and plans for care. yet  the only people who can provide this information are those who were present during surgery and they are often too busy attending to the patient to communicate much detail. 
　magic takes as input online data collected during the surgical operation as well as information stored in the mainframe databases at columbia presbyterian medical center  roderer and clayton  1 . it generates a multimedia briefing that integrates speech  text  and animated graphics to provide an update on patient status  dalai et ai  1a . like comet  it dynamically determines both content and form of the explanation  but the focus here is on the coordination of temporal media  dalai et ai  1b . language generation addresses the issue of producing language  wording and sentence structure  appropriate for the spoken medium  pan and mckeown  1; mckeown et ai  1  as opposed to the more traditional task of generating written language. given the healthcare setting  magic also faces the added constraint of conciseness; the generation process must make coordinated use of speech and text to produce an overview that is short enough for time pressured caregivers to follow  but unambiguous in meaning. 
1 cdns 
research in cdns  columbia digital news system  focuses on the development of technologies to aid people in finding and tracking information on current events. we are developing a system  cdns  that provides upto-the-minute briefings on news of interest  linking the user into an integrated collection of related multimedia documents. our research aims at tracking news stories on the same event  producing a briefing that describes how the event has changed over time. a representative set of images or videos can be incorporated into the summary. the user can follow up with multimedia queries to obtain more details and further information. 
　the goal of summarization within cdns is to brief the user on information within the collection of related documents. in many cases  the summary provides enough information for the user to avoid reading the original document. in others  the user may want to check the original documents to verify information contained within the summary  to follow up on an item of interest  or to resolve conflicting information between sources. to meet the demands of this environment  our work features summarization over multiple articles  merging information from all relevant sources into a concise statement of the facts. this is in contrast to most previous work that summarizes single articles  luhn  1; paice and jones  1; rau et ai  1; kupiec et ai  
1 . summaries must identify how perception of the event changes over time  distinguishing between accounts of the event and the event itself  mckeown and radev  1 . eventually  given access to live news  the summarizer will be able to provide updates since the last generated summary  identifying new information and linking its presentation to earlier summaries. 
　unlike comet and magic  cdns must determine the content of a briefing through analysis of input textual documents. furthermore  while cdns generates the content and form of the written summary  images are selected as a whole from an online collection of images. 
1 language generation in a multimedia context 
in a multimedia explanation each medium presents information about the same subject. in some cases  the exact same information is presented in multiple media  providing different viewpoints of the same material. in other cases  media may present complementary information about the same topic when certain types of information are more easily communicated in one medium than another. for example  spatial information such as location may be more easily conveyed in graphics  while abstract information such as illness severity may be more easily conveyed in language. 


figure 1: cross reference generation in comet 
　the fact that each medium presents information about the same topic  sharing communicative goals  means that individual media can not be generated in isolation. how individual media generation is affected by other media depends on the types of media that are coordinated within the multimedia presentation. a multimedia presentation that coordinates speech and graphics engenders different influences on the language generation process than one that coordinates text and images. 
　as an example of the kind of influences that exist  consider that at the most basic level  different media refer to the same information or entities within the same multimedia presentation  often to satisfy the same high level goal. if they have knowledge about the references used in other media  they can use that to influence how referring expressions are generated in their own medium. in addition to changing how referring expressions are generated  in some cases an explicit cross reference may be effective to link information in one media with another. exactly how the generation of referring expressions is modified varies depending upon the media involved. 
　text and static graphics. in our earlier work on comet  multimedia presentations comprised written language and static graphics. in this scenario  text appears as a caption below an illustration. to signal where text and illustration refer to the same object or action  an explicit cross reference must be generated linking the two media. here  generating a textual cross reference must make use of knowledge about the graphical illustration to determine what kind of cross reference to generate. the language generator can make use of information about the illustration content to identify a referent for the hearer; the text  the old holding battery  shown in the cutaway view  uses information about special graphical features used in the illustration  here graphics cut away a portion of the radio to reveal the holding battery which is internal to the radio . alternatively  it can use information about illustration structure as shown in figure 1 or information about spatial location. to generate cross references  language generation must be modified to determine when a cross reference is needed  e.g.  when a user will not know the referent of a textual expression alone  and query the illustration representation to construct cross reference content. in comet  generating cross references is carried out cooperatively by the graphics and text components and can involve modifications to the illustration as well as to language  mckeown et a/.  1 . 
　spoken language and animated graphics. when spoken language and animated graphics are part of the multimedia presentation as is the case in magic  a more implicit means of linking references across media can be used. as references are spoken  graphical representations of the referenced information can be highlighted in the accompanying illustration. in this scenario  spoken references must be coordinated with accompanying highlighting that changes over time  involving negotiation between speech and graphics to arrive at both a compatible ordering and duration of references  dalai et al.  1b . in particular  speech has grammatical constraints on how references are linearly  and thus temporally  ordered within a sentence. at the same time  graphics has spatial constraints on how information is arranged within an illustration. taken individually  such constraints might result in an incoherent presentation which refers to graphical representations at random locations in the illustration. similarly  durations of both spoken references and highlighting must be coordinated to avoid changes in highlighting at semantically anomalous points in the sentence or blinking that might occur if highlighting is changed too frequently. 
   the problem for language generation in this context is to produce enough information to facilitate coordination. first  note that the full ordering of spoken references is only determined when all grammatical constraints have been applied and the final sentence generated. but it would be quite inefficient to wait until this point to coordinate with graphics as it could potentially involve generating many sentences that were never used in the final presentation. instead  we produce a partial ordering over references at an intermediate point in language generation  after words have been selected but before grammatical constraints are applied. second  given that any particular ordering of spoken references produced by the language generation component may not be compatible with graphics' orderings  the language generation process must be modified to produce several possibilities ordered by preference. third  since graphics does not understand the meaning of a string of words that forms the spoken reference  the language generator must maintain a mapping between the words of the reference and the semantic object they refer to in order to communicate with graphics via the media coordinator. finally  to facilitate synchronization of spoken references with highlighting  the spoken language generator must be able to compute duration of a spoken reference  to reason about 
	mckeown 	1 


figure 1: a portion of coordinated speech and graphics generated by magic 
where pauses can be adjusted in speech to allow more flexibility in coordinating with highlighting  and to select semantically appropriate points in the sentence between references which can be temporally coordinated with changes in highlighting  pan and mckeown  1 . 
　figure 1 shows a portion of a multimedia briefing generated by magic. here  as each part of the first sentence is spoken  the corresponding information in the demographics chart of the accompanying illustration is highlighted. just the chart is shown in figure 1. 
   spoken and w r i t t e n language. in magic  both speech and text are used within the same presentation. textual references are used to provide labels for objects and information displayed graphically. language generation takes advantage of the use of both media to keep spoken language shorter and more colloquial  thus better meeting our goal of briefing caregivers. as long as the text label on the screen is generated using the full  unambiguous reference  speech can use an abbreviated expression. for example  when referring to the medical devices which have been implanted as part of cardiac care  speech can use the term  pacemaker  so long as the textual label specifies it as  ventricular pacemaker . similarly  magic uses  balloon pump  in speech instead of  intra-aortic balloon pump   which is already shown on the screen. in order to do this  lexical choice in both media must be coordinated. lexical choice for text always selects the full reference  but lexical choice for speech must check what expression the text generator is using. the speech lexical chooser must check what attributes the text generator includes in its reference and omit those. 
　w r i t t e n language and images. in cdns  a written summary is generated along with several representative images as shown in figure 1. in this scenario  the specific objects contained in the image are unknown1  and 
     1  unless we use vision techniques to do image analysis and identify the objects the image contains  a prospect that is not yet feasible for domain independent image processing  query output 

figure 1: illustrated summary generated by cdns 
therefore  the written summary cannot explicitly refer to image content. unlike the other multimedia systems discussed here  the content and form of the accompanying image is not dynamically generated at the time of the presentation. instead  an image is selected for use when the briefing is generated. the problem here is to ensure that the images selected are relevant to the content of the summary. we are exploring the use of integrated processing of textual and image features to select appropriate images. this is done by classifying unlabeled images as part of an underlying ontology. image features can be used to reliably make certain categorizations; for example  image features can be used to determine if the image is a graphic  such as a map  or a photograph as well as more semantic categorizations such as whether it is a portrait showing a person or a landscape  smith and chang  1 . we are augmenting this by using statistical analysis of the text accompanying an image to provide a better semantic classification of image content  e.g.  whether an image pertains to a terrorist event or a particular political event such as a russia-us summit   aho et al.  1 . by applying standard text categorization techniques to different amounts of text surrounding an image in a multimedia document  from caption to text fragment to full document  we are experimenting with the improvement on classification over using image features alone. 
1 issues for summarization 
just as the nature of language generation changes in a multimedia context  so do problems for summary generation change from the generic problems in language generation. summaries must convey maximal information in a minimal amount of space. this requires selecting words and  sentence structures that can convey information concisely. sometimes  this means the we cannot reliably identify and label image content. 

use of complex sentence structure  including multiple modifiers of a noun or verb  conjunction  e.g.   and    and ellipsis  i.e.  deletion of repetitions across conjoined phrases . for example  phrases such as  hypertensive  and  undergoing cabg  use fewer words than if full sentences were used to convey each of these facts separately  see figure 1 . conciseness also means the selection of words that can convey multiple aspects of the information to be communicated. for example  a verb such as  surged  conveys both the direction and the speed of a gain on the stock market. furthermore  our research shows that some information is opportunistically added into the summary  depending on the words and syntactic structure already used  mckeown et al.  1; robin and mckeown  1 . 
　we characterize problems for summary generation as falling into two separate classes  conceptual summarization  or determining what information should be included in a summary  and linguistic summarization  the task of determining how to convey as much information as possible in a short amount of text. conceptual summarization takes input from multiple sources  whether databases or text  and determines how it can be merged together  often using semantic generalization to do so. our work in cdns addresses problems in conceptual summarization. information is extracted from each article and represented in a template using systems developed under the darpa message understanding program  muc  1 . cdns then uses planning operators to determine how to merge information from the separate templates representing each article. in particular  it looks for contradictions  agreements  and refinements of information  and makes generalizations. 
　our work in magic addresses problems in linguistic summarization. as in previous work on summarization over data  robin and mckeown  1; 1   we address the following issues: 
  how to use syntactic and lexical devices to convey information concisely  
  given the choice of a particular word or syntactic structure  how does this constrain  or allow  the attachment of additional information  
  how to fold multiple pieces of information into a single linguistic construction  
　in magic  this means conveying as many attributes from the underlying database as possible in one sentence through the use of modifiers such as adjectives or prepositional phrases. thus  in figure 1  the first sentence conveys nine separate attributes. in addition  coordinated use of speech and written language also aids in meeting our goal of conciseness; shorter references can be generated in speech since they are clarified in the written labels of the accompanying illustration. 
1 conclusion 
in this extended abstract  we have outlined issues for the generation of multimedia briefings and shown how we have addressed them in several different systems. while in this paper we focused on the problem of generating references in a multimedia environment  we have also looked at the interaction between generation in different media for other problems as well. for example  in work on comet we explored how separation of information into different pictures can influence sentence breaks. in general  style of generation in one media can and should influence generation in others. 
　of course  there are many other issues in the generation of multimedia briefings. in our current work  we are addressing the generation of different types of prosody for speech using information from language generation. we are particularly interested in the use of prosody that facilitates coordination within the multimedia environment such as pause duration. for example  by computing a range on pause duration and options on pause placement  we simplify the task of temporally synchronizing spoken and graphical actions. in cdns  we are continuing to exploit multimedia features in online news sources to improve both generation of illustrated briefings and search over online  multimedia documents. we are also working on the generation of summaries from live information that update a user over information already received. 
acknowledgments 
this extended abstract reflects the work of many individuals over the course of many years. my closest collaborator in work on multimedia explanation has been steven feiner  with whom i have enjoyed many long hours of thought-provoking discussion  joint meetings on system design and development  and mad races to deadlines. in our recent work on magic  mukesh dalai has also joined our collaboration on multimedia coordination. others who have contributed to work described here include: michael elhadad  doree seligmann  and jacques robin  comet ; desmond jordan  barry allen  shimei pan  james shaw  michelle zhou  tobias h1erer  and yi lang  magic ; alfred aho  
shih fu chang  dragomir radev  john smith  alex jaimes  and kazi zamen  cdns . 
references 
 aho et a/.  1  a. aho  s.-f. chang  k. r. mckeown  d. radev  j. smith  and k. zaman. columbia digital news system: an environment for briefing and search over multimedia information. in proceedings of adl-1  washington  d.c.  may 1. 
 dalai et ai  1a  m. dalai  s. feiner  k. r. mckeown  d. jordan  b. allen  and y. alsafadi. magic: an experimental system for generating multimedia briefings about post-bypass patient status. in proc. 1 amia annual fall symp.  pages 1  washington  dc  october 1  1. 
 dalai et ai  1b  m. dalai  s. feiner  k. r. mckeown  s. pan  m. zhou  t. hoellerer  j. shaw  y. feng  
	mckeown 	1 

and j. fromer. negotiation for automated generation of temporal multimedia presentations. in proc. acm multimedia '1  pages 1  boston  ma  november 1  1. 
 feiner and mckeown  1  s. k. feiner and k. r. mckeown. coordinating text and graphics in explanation generation. in proceedings of the national conference on artificial intelligence  boston  mass.  august 1. 
 feiner and mckeown  1  s. feiner and k. r. mckeown. automating the generation of coordinated multimedia explanations. ieee computer  1 :1  october 1. 
 kupiec et al  1  julian m. kupiec  jan pedersen  and francine chen. a trainable document summarizer. in edward a. fox  peter ingwersen  and raya fidel  editors  proceedings of the 1th annual international acm sigir conference on research and development in information retrieval  pages 1  seattle  washington  july 1. 
 luhn  1  hans p. luhn. the automatic creation of literature abstracts. ibm journal  pages 1  1. 
 mckeown and radev  1  k. r. mckeown and d.r. radev. generating summaries of multiple news articles. in edward a. fox  peter ingwersen  and raya fidel  editors  proceedings of the 1th annual international acm sigir conference on research and development in information retrieval  pages 1  seattle  washington  july 1. 
 mckeown et ai  1  k. r. mckeown  m. elhadad  y. fukumoto  j. lim  c. lombardi  j. robin  and 
	f. smadja. 	language generation in comet. 	in 
current research in language generation. academic press  london  1. 
 mckeown et al  1  k. r. mckeown  s. k. feiner  j. robin  d. seligmann  and m. tanenblatt. generating cross 