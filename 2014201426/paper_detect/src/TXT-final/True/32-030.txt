 
we introduce two abstraction mechanisms for streamlining the process of semantic interpretation. configurational descriptions of dependency graphs increase the linguistic generality of interpretation schemata  while interfacing them to lexical and conceptual inheritance hierarchies reduces the amount and complexity of semantic specifications. 
1 introduction 
natural language processing methodology has matured in the recent years considering the design of grammar formalisms and parsing algorithms. the development of computationally feasible semantic theories and  in particular  their linkage to the grammar level by an adequate semantic interface has not witnessed a comparable level of consolidation. so  only a low degree of consensus has emerged concerning the formulation of semantic interpretation rules by which syntactic structures are mapped onto semantic  or conceptual  representations. 
　hie lack of a mature and commonly shared methodology for semantic interpretation is not only deplorable from a theoretical standpoint but has immediate practical consequences for the design of nlp systems dealing with the diversity of real-world input on a larger scale. in such an environment  rule sets tend to be designed and updated in a less than systematic manna- to accomodate to the many complex phenomena in the language data  rule specifications confound different description layers  have heterogeneous formats and sometimes even ad hoc extensions- in the end  they become nonportable. often this also leads to an unwieldy growth of the number of rules for large-scale nlp systems. as a result  the rules' compatibility  mutual interactions  side effects  order constraints  etc. are likely to get out of hand. 
　in order to avoid these negative effects  we introduce two abstraction mechanisms by which the process of semantic interpretation can be streamlined. the first abstraction aims at increasing the linguistic generality of descriptions for semantic interpretation. the criteria we use address configurations within dependency graphs rather than hook on particular language phenomena. these configurations have a natural graph-theoretical reading in terms of  minimal  connected 
1 	natural language processing 
subgraphs of a syntactic dependency graph. this way  we are able to cover a variety of linguistic phenomena by instantiation of few and general interpretation schemata. the second abstraction relates to the way how these schemata interact with grammar and domain knowledge. by interfacing them to lexical and conceptual inheritance hierarchies  we further increase descriptional economy and supply a parsimonious semantic interpretation system. 
　our methodology crucially depends on a strict separation between linguistic grammar knowledge and conceptual domain knowledge  and their linkage via a lean semantic interface. granting such an organization of knowledge  portability of semantic interpretation schemata across different domains and applications is made feasible - a feature of advanced system design that was hard to achieve so far. 
1 framework for semantic interpretation 
we now sketch the knowledge sources required for semantic interpretation. grammatical knowledge for syntactic analysis is based on a fully lexicalized dependency grammar  hahn et al.y 1 . a dependency grammar captures binary constraints between a syntactic head  e.g.  a noun  and one of its possible modifiers  e.g.  a determiner or an adjective . our preference for dependency structures is motivated  among other things  by the observation that the correspondence of dependency relations  between lexical items  to conceptual relations  between the concepts they denote  is much closer than for any constituent-based grammar  hajicova  1 . hence  a dependency-based approach eases the description of the regularities underlying semantic interpretation. 
　in the dependency framework we have chosen  lexeme specifications form the leaf nodes of a lexicon tree  which are further abstracted in terms of word class specifications at different levels of generality. this leads to a word class hierarchy  which consists of word class names  {verb  
verbtrans  det  article  ...} and a subsumption relation 
{ verbtrans  verb    article  det   ...}  x inheritance of grammatical knowledge is based on the idea that constraints are attached to the most general word classes to which they apply  leaving room for more and more specific  possibly  even idiosyncratic  grammatical specifications when one descends this hierarchy. 

 mostly verbs  nouns and adjectives   gets 

　in order to establish a dependency relation {specifier  subject  dir-object ...} between a head and a modifier  the corresponding constraints on word order  compatibility of morphosyntactic features as well as semantic criteria have to be fulfilled. fig. 1 depicts a sample dependency graph in which word nodes are given in bold face and dependency relations are indicated by labeled edges. for example  the syntactic head  festplatte   hard disk  governs its modifier  computers   via the gen itive att ribute  dependency relation. 
conceptual knowledge is expressed in terms of a kl-
one-like knowledge representation language  woods and schmolze  1 . this choice is motivated by the requirement to express domain knowledge in terms of a formally sound representation language. a domain ontology consists of a set of concept names  
and a subsumption relation 	= { hard-disk  stor-
agedevice    transtec  company   ...} the set of relation names {has-part  deliver-agent  
...} contains the labels of conceptual relations which are also organized in a subsumption hierarchy = { has-harddisk  has-physical-part    has-physical-part  haspart   ...}.1 concept names are assigned conceptual roles  taken from the repertoire of conceptual relations  as part of the concept definition process. unless defined as being primitive  the terminological classifier computes subsumption relations between these concept definitions in order to generate a domain's concept hierarchy  similarly  for relations . 
　in our approach  the representation languages for semantics and domain knowledge coincide  for arguments supporting this view  cf. allen  . the basic mechanism for linking lexical items and conceptual entities proceeds as follows: upon entering the parsing process  each lexical item w that has a conceptual correlate c in the domain knowledge 
1
    all subsumption relations  isaw  isaf  and isan  are considered to be transitive and reflexive. 
immediately instantiated in the knowledge base  such that for any instance initially 1 holds  e.g.  
	 festplatte   	= hard-dlsk.1  w.c = type hard-
dlsk.1  = hard-disk . in case several conceptual correlates exist  either due to homonymy or polysemy  each lexical ambiguity is processed independently. 
　conceptual relations between instances are determined by different types of dependency relations that are established between their corresponding lexical items. semantic inter-
pretation mediates between both levels in a way as abstract and general as possible. first  static semantic constraints relate grammatical and conceptual knowledge via fixed mappings which take inheritance at both knowledge levels into account the illustration in fig. 1  left side  depicts a subset of the dependency relations contained in at the syntactic level proper. dependency relations that have a hard-wired mapping to conceptual relations are shown in italics. for instance  whenever the dependency relation dir-obj ect  is established it must conceptually be interpreted in terms of patient or co-patient including all their subrelations  e.g.  deliver-patient . gen itive att ributel however  has no fixed conceptual counterpart as this dependency relation does not restrict conceptual interpretation at all. 
　second  semantic interpretation schemata then dynamically incorporate these static constraints when translating a dependency graph  such as fig. 1  into a corresponding conceptual representation  as depicted in fig. 1 . schemata are high-level generalizations that abstract away from many linguistic details one encounters in specific dependency graphs  concrete lexical items  word classes  dependency relations . these abstract schemata get instantiated in the course of semantic interpretation by reference to the grammatical and conceptual hierarchies previously introduced. so  in our example  instantiating a general interpretation schema by con-
　1textual phenomena  figurative language  etc. might necessitate changes of this initial reference assignment  cf. hahn et al. . 
	romacker  markert  and hahn 	1 

crete lexical materia* like 'harddisk  and  deliver  automatically specializes high-level conceptual constraints like pa-
tient  from the schema  to low-level ones such as deliver-
patient  from the domain knowledge  by exploiting the hierarchy of conceptual relations  cf. fig. 1 . 
1 semantically interpretable subgraphs 
in die dependency parse tree from fig. 1  we can distinguish lexical nodes that have a conceptual correlate  e.g.   fest-
platte   hard disk    geliefert   delivered   from others that do not have such a correlate  e.g.   mit   with    von   by  . the basic configurations for semantic interpretation are based on this distinction: 
  direct linkage: if two word nodes with conceptual cor-relates are linked by a single dependency relation  a direct linkage is given. such a subgraph can immediately be interpreted in terms of a corresponding conceptual relation. this is illustrated in fig. 1 by the direct linkage between  festplatte   hard disk  and  computers  via the gen itive att ribute  relation  which gets mapped to the hard-disk-of role linking the corresponding conceptual correlates  viz  hard-dlsk.1 and computersystem.1  respectively  see fig. 1 . this interpretation uses knowledge about die conceptual correlates and die linking dependency relation  only. 
  mediated linkage: if two word nodes with concep-tual correlates are linked via a series of dependency relations and none of the intervening nodes have a conceptual correlate  a mediated linkage is given. such a  minimal  subgraph can only indirectly be interpreted in terms of a conceptual relation. in this case  we include lexical information from intervening nodes in addition to the knowledge about the conceptual correlates and dependency relations. in fig. 1 this is illustrated by the syntactic linkage between  computers  and  1mhzcpu  via the intervening node  mit   with  and the ppatt ribute  and pobj ect  relations  the result of which is a conceptual linkage between computer-system.1 and 1mhz-cpu.1 via the relation has-cpu in fig. 1. 
　in order to increase the generality and to preserve the simplicity of semantic interpretation we introduce a generalization of the notion of dependency relation such that it incorporates direct as well as indirect linkage: two content words  nouns  adjectives  adverbs or full verbs  stand in a mediated syntactic relation  if one can pass from one word to the other along the connecting edges of the dependency graph without traversing word nodes other than prepositions  modal or auxiliary verbs  i.e.  elements of closed word classes . in fig. 1  e.g. the tuples   festplatte    computers      computers    1mhz~cpu      festplatte    geliefert   and   geliefert    transtec   stand in mediated syntactic relations  whereas  e.g.  the tuple    transtec     festplatte    does not  since the connecting path contains  geliefert   delivered   a content word. 
1 natural language processing 
　this leads us to the following definition: let and be two content words in a sentence s. in addition  let be prepositions  auxiliary or 
modal verbs  and let and then we say that w and w' stand in q mediated syntactic relation  iff there 
exists an index  so that the following two conditions hold: 
a semantically inter-
pretable subgraph of the dependency graph of s. 
　the definition of a mediated syntactic relation encompasses the notion of a direct linkage so that an empty set of intervening nodes emerges . the special cases /  1 
and i  n yield an ascending and descending series of 
head-modifier relations  respectively.1 
　the cases of direct and mediated linkage are the two relevant configurational settings for semantic interpretation. thus  this paper is concerned with the translation of dependency graphs  like the one in fig. 1  to a concept graph as in fig. 1. the translation is achieved in a strictly compositional way  i.e.  by linking the conceptual representations of the semantically interpretable subgraphs within the entire dependency graph. 
　we do not  however  consider conceptual interpretation  the mechanisms of which reside at the conceptual level only and  therefore  are merely indirectly affected by syntactic structures. as an example of such an inference consider fig. 1  with the delivers relation linking transtec.1  a hardware supplier  and hard-dlsk.1. note that the corresponding lexical items   transtec  and  festplatte   are not linked via a mediated syntactic relation in fig. 1. hence  we may clearly discern semantic interpretation  as the interpretation of semantically interpretable subgraphs  and conceptual interpretation  where the interpretation of relationships among different subgraphs come into play. 

figure 1: a sample conceptual interpretation 
1 a model of lean semantic interpretation 
in the following  we shall describe a model of semantic interpretation that seamlessly integrates the processing of dependency relations either directly or indirectly linking conceptually interpretable word nodes. we distinguish two levels of semantic interpretation first  static constraints for semantic interpretation derived from mapping dependency relations to conceptual roles  and  second  a search of the knowledge base when conducting the semantic interpretation  which dynamically takes these static constraints into account. 

　static constraints on semantic interpretation  interlevel within the semantically interpretable subgraph  the tetpretation procedures for semantically interpretable subgraphs ter accounts for the particular dependency relation s betwi  may inherit restrictions from the type of dependency relations them. in technical terns  schema  1  describes a mapping  or even from the lexical material  occurring in these sub- from the conceptual correlates  and in sf graphs. constraint knowledge from the grammar level comes the two syntactically linked lexical items  h and m  respecin two varieties  viz. via a positive list  and a neg- tively  to connected relation paths  ative list  of dependency relations  from which ad-
mitted as well as excluded conceptual relations  and h    1  respectively  are derived by a simple static symbol mapping. 
	knowledge about 	and 	is part of the va-
lency specifications. it is encoded at the level of word classes such that lexvai and  thereby  it is inherited by all subsumed lexical instances. for instance  the word class of transitive verbs  verbtrans de- a relation path is called connected  if for all its n confines for its subject valency  stituent relations the concept type of the domain of the relation subsumes the concept type of the range of the rela-
and 	for an optional prepositional 	tion  
phrase valency  ppopt  we require  in order to compute a semantic interpretation  st triggers and := {subject  dir-object  indir-object}. a search through the concept graph of the domain knowledge 
we may then distinguish three basic cases: 	base and identifies all connected relation paths from to 
due to potential conceptual ambiguities in interpreting 
1. knowledge available from syntax determines the seman- syntactic relations more than one such path can exist  hence  tic interpretation  if 	and 	 e.g.  	we map to the power set of  
	the subject of a verb . 	as a filter for constraining connectivity  si takes into con-
1. knowledge available from syntax restricts the semantic sideration all conceptual relations a priori permitted interpretation  if for semantic interpretation  as well as all relations most prepositional phrases . 	a priori excluded from semantic interpretation. both of them 
reflect the constraints set up by particular dependency rela-
1. if no syntactic con- tions or non-content words figuring as lexical relators of constraints apply and semantic interpretation proceeds en- tent words  for examples  cf. section 1 . thus  tirely concept-driven  i.e.  it relies on the domain knowl-holds  if rel is a connected relation path from to 

edge only  e.g.  for genitive attributes .1 
　in order to transfer syntactic constraints to the conceptual level  we define i: a mapping from dependency relations onto sets of conceptual relations. this mapping generalizes the illustration depicted in figure 1  e.g.    subject  := {agent  patient} . for dependency relations r that cannot be linked a priori to a conceptual relation  e.g. 
	   	we 	require 	the conceptual re-
strictions  	and 	must be computed 	from 	and 
respectively  by applying the interpretation func-
tion i to each element of the corresponding sets. this leads 
basic schema for dynamic semantic interpretation. 
semantic interpretation is done via a search in the domain knowledge base which takes the just mentioned constraints obeying the restrictions imposed by and  
　if the function si returns the empty set  i.e.  no valid interpretation can be computed   no dependency relation will be established. otherwise  for all resulting relation paths   an assertional axiom is added to the knowledge base by 
asserting 	the 	proposition 	where rel* 
denotes the ith reading. if conceptual ambiguities occur  not an issue here . 
　to map a concept definition c against the constraints imposed by and 	we define the function get-rcles c  =: cr  which returns the set of all conceptual roles cr associ-
ated 	with 	c. 	extracts the roles that are used 
as starting points for the path search. as  for ease and generality of specification  r+ and r  consist of the most general conceptual relations only  the concrete conceptual roles cr and the general ones in r+ and r- may not always be compatible. prior to semantic interpretation  we therefore expand 

into account. two sorts of knowledge have to be combined- 	and 	into their transitive closures  incorporating all first  a pair of concepts for which a connecting relation path 	their subrelations in the relation hierarchy. thus   
has to be determined; second  conceptual constraints on the 	 correspondingly  	is 
kinds of permitted and excluded conceptual relations when defined. r+ restricts the search to relations contained in cr connected relations are being computed. the first constraint is not empty  otherwise  all cr are allowed   type incorporates the content words linked at the dependency whereas allows only for relations in  
	1
    we have currently no empirical evidence for the fourth possible 	 a number of additional constraints must hold  e.g.  composed case  where  	relations must be acyclic  cf. markert ami hahn  . 
	romagker  markert  and hahn 	1t 

phrases. unlike conceptually neutral auxiliaries  prepositions serve as relators carrying conceptual constraints for the corresponding instances of their syntactic head and modifier. the 

　interpreting direct linkage. consider a fragment of our sample sentence   die festplatte des computers   the hard disk of the computer  in fig. 1.  festplatte  and  computers   are directly linked by the dependency relation gen itive att ribute y  festplatte  being the syntactic head of its genitive modifier  computers . both have conceptual correlates  whose type is given by type hard-disk.1  = hard-disk and t pe computer-system.1  = computer-system. 
to relate the two instances conceptually  a slight specialization of the basic semantic interpretation schema  1   the direct linkage schema  1   will be applied  substituting by  
 festplatte   belongs to the word class of nouns. it inherits 
 thus  syntax 
does not at all restrict the search for valid conceptual relations  i.e.  no static constraints apply. hence  and 
　　　　　in order to dynamically incorporate constraints the function get-roles hard-dlsk  extracts all roles related to hard-disk at the domain knowledge level  e.g.  hasaccess-time  has-noise-level  hard-disk-of  etc. . 
it is iteratively checked for each of these roles whether die conceptual correlate of the modifier  computers   i.e.  computer-system  is a legal filler  this is only the case for hard-disk-of  cf. kg. 1 . 
　interpreting mediated linkage. when interpreting mediated syntactic relations  additional information about the intervening nodes becomes available such that further static constraints are imposed on  and in terms of a list  of permitted conceptual relations  which is specified at the lexeme level. note that  relates to closedclass items only  so the number of specifications required can be kept manageable. also  such a specification can be done  once and for all  in a domain-independent way. 
in our example  cf. fig. 1    festplatte   hard disk  and 
 geliefert   delivered  are linked by a mediating modal verb   kann   and a passive auxiliary   werden  . the semantic interpretation schema for passive auxiliaries  1  addresses the concept type of the instance for their syntactic subj ect f  i.e.  hard-disk   and that 
　　　　　　　　　　　　　　　　　　　 i.e.  delivery . the relation between these two  however  is deter-
mined by  {patient  co-patient}  constraint knowledge which resides in die lexeme specification for  werden    be  as passive auxiliary. 
 meaning  of a preposition is encoded by a set for each preposition prep  holding all permitted relations in terms of high-level conceptual relations. as an example  consider  von   by  from  of   with  {agent  source  starting-time-point  has-degree ...}. 
　in order to infer a valid semantic interpretation for each semantically interpretable subgraph containing a preposition a precompilation step for integrating static constraints from different sources is carried out these static constraints arise from the preposition itself and from the syntactic head of the preposition  e.g.   geliefert   delivered  governs the preposition  von   by  via the ppsubj ect  dependency relation . the information provided by the syntactic relation between the preposition and its head is exploited such that the positive 
list and negative l i s t o f the preposition's 
head are consulted prior to a semantic check in the knowledge base. by applying the function i to all elements contained in a new set  
     containing all conceptually permitted relations is created. by analogy  the corresponding set of conceptual relations is excluded from interpretation. expanding appropriately  we get 
 correspondingly  we define we say for non-empty   and  similarly  for empty 	if ther semantic interpretation is ob-
solete. this is due to the fact that the static constraints given by the syntax  derived by the interpretation function % applied 
to respectively  are incompatible with the set of constraints for the preposition  else  we determine for non-empty and 
	for empty 	and define a specialized 
interpretation schema for prepositions  
 1  
as far as the example  geliefert von transtec   delivered by transtec  in fig. 1 is concerned  the syntactic restrictions given by the syntactic head of the preposition 
  geliefert   are 	{ppsubj} and 
for the ppsubj valency  which is 
specified at the word class level for passive participles verbpartpass like  geliefert   delivered . since syntactic constraints are encountered  the precompilation step becomes necessary in order to compute  since ppsubj ect  statically maps to agent  cf. fig. 1  and agent is also contained in agent and all its subrelations are con-

		 1  
1 	natural language processing 

tained in 	 i.e.  the intersection of  since 

after integrating all static constraints  the semantic 
interpretation schema for prepmitions gets instantiated with l i   n u m r   {agent*}  transtbc .1 the roles to be considered are thus the roles contained in the intersection of the concept roles of delivery  extracted by getroje$ dblivbry  with r+. given the underlying ontology  this set of relations melt down to a single element  deliveragent isar agent. thus  satisfaction of dynamic constraints reduces to the check whether transtbc is a legal filler of deliver-agent. since transtbc is subsumed by legal-person which is-a person  the sortal constraints are met and transtec.1 is asserted to be the deliveragent of delivery. 1  cf. fig. 1 . 
1 evaluation of semantic interpretation 
in this section  we want to discuss  for a particular type of language phenomenon  the adequacy of our approach in the light of concrete language data taken from the corpora we work with. this part of the enterprise  the empirical assessment of semantic interpretation  is almost entirely neglected in the literature  for a notable exception  cf. bean et al.  . 
　the semantic interpretation task has to be clearly distinguished from the information extraction task and its standard evaluation setting  muc-1 . in the ie task  a subset of the templates from the entire domain is selected into which information from the texts are mapped. also  the design of these templates focus a priori on particularly interesting facets  roles  in our terminology   so that an ie system does not have to deal with the full range of qualifications that can be attributed even to a relevant concept that might occur. the semantic interpretation task  however  is far less constrained as we evaluate the adequacy of the conceptual representation structures relating to the entire domain of discourse  with all qualifications mentioned in a text. 
　this increased complexity of the task leads to many unsolved methodological questions  for a discussion  cf. friedman and hripcsak  . we may illustrate this claim within the framework of our approach. basically  a triple division of test scenarios have to be distinguished. the first class relates to checks whether each static constraint  effected by the mapping from a single dependency relation to one or more conceptual relations is valid. second  one may investigate the appropriateness of the results from the search of the domain knowledge base  i.e.  whether a relation between two concepts can be determined at all  and  if so  whether that relation  path  is adequate. third  interactions between static constraints and dynamic constraint propagation may occur  as illustrated by the interpretation of prepositions. 
　in the small-scale evaluation study we performed  we started from a domain ontology that is divided into an upper generic part  containing about 1 concepts and relations  and various domain-specific parts. in the study we report on two specialized domains were dealt with - an information technology  it  model and an ontology covering 
　　1 note that due to the precompilation step there is no need to expand r+ to its transitive closure. 
parts of anatomical medicine  med   each domain model  in addition  contributes 1 concepts and relations . omtresponding lexeme entries in the lexicon provide linkages to the ontology. we also assume a correct parse to be deliveied for the semantic interpretation process. 
　we then took a random selection of 1 texts  comprising 1 words  from our two text corpora. for evaluation purposes we concentrated on the interpretation of genitives  direct linkage   prepositional phrase attachments and auxiliary as well as modal verbs  both variants of mediated linkage . in the following  we will focus on the discussion of the results from the semantic interpretation of genitives  cf. table 1 . 
　at first glance  the choice of genitives may appear somewhat trivial. from a syntactic point of view  genitives are directly linked and  indeed  constitute an easy case to deal with at the dependency level. from a conceptual perspective  however  they provide a real challenge. since no static constraints are involved in the interpretation of genitives  an unconstrained search  apart from connectivity conditions  of the domain knowledge base is started. hence  the main burden rests on the dynamic constraint processing part of semantic interpretation  i.e.  the path finding procedure muddling through the complete domain knowledge base in order to select the adequate reading s . therefore  genitives make a strong case for the second test scenario mentioned above. 
　the following criteria guided the evaluation of genitives. we considered a semantic interpretation to be a correct one  if the conceptual relation between the two concepts involved was considered adequate by introspection  otherwise  incorrect . this qualification is not as subjective as it may sound  since we applied really strict conditions.1 correct interpretations were those that contain exactly one relation  as well as cases of ambiguities  up to three readings  the most   where the relation set contained the correct one. a special case of incorrectness  called nil  occurs when no relation path can be determined though the two concepts under scrutiny are contained in the domain knowledge base. 
　we also classified the cases where the system failed to produce an interpretation due to at least one concept specification missing  with respect to the two linked content words in a semantically interpretable subgraph . in those cases without interpretation  insufficient coverage of the generic model was contrasted with that of the two domain models and with cases in which concepts referred to other domains  e.g.  fashion or food. subareas that could neither be assigned to the generic model nor to particular domains were denoted by phrases re-
　　1 the majority of cases were easy to judge. for instance   the infiltration of the stroma  resulted in a correct reading - stroma being the patient of the infiltration -  as well as in an incorrect one - being the agent of the infiltration. among the incorrect semantic interpretations we also categorized  e.g.  the interpretation of the expression  the prices of the manufacturers  in terms of a conceptual linkage from price via price-of to product via hasm anufacturer to manufacturer  since it did not account for the interpretation that manufacturers fix prices as part of their marketing stragegies. correct interpretations always boiled down to evident cases  eg.  hard-disk part-of computer. 
romacker  markert. and hahn 1 

1 med l  	tt 1 # texts 1 # words 1 
1 1 
1 recall 
1 precision 1% 
1% 1% 
1% # genitives... 
... with interpretation 
correct  multiple readings  incorrect nil 
... without interpretation domain model generic model 
abstracta 
1 space   time 
evaluative j1 
1%  
1  1%  
1  1%  
1 
1 
1  1%  
1  1%  
1 
1 
1 
1 
1 
1 
 	1 
1 1 
1  1%  1%  
1%  
1 
1 
1  1%  
1%  
1 
1 
1 
1 
1 
1 
1 
1 j 
table 1: empirical results for the interpretation of genitives 
ferring to time  e.g.   the beginning of the year    space  e.g.  
 the surface of the storage medium    and abstract notions  e.g.   the acceptance of it technology  . these areas can be distinguished from evaluative expressions  e.g.   the advantages of plasma display   and figurative language  including idiomatic expressions  e.g.   the heart of the notebook  . 
　we considered a total of almost 1 genitives in all these texts  from which about 1%/1%  med/it  received an interpretation. of the total loss due to incomplete conceptual coverage  1%/1%  1 of 1 genitives/1 of 1 genitives  can be attributed to insufficient coverage in the domain model. only the remaining 1%/1% are due to the many other factors we have listed in table 1. 
　the results we present here are just a preliminary sketch of what has to be done as part of a more serious evaluation. the concrete values we present  disappointing as they may be for recall  1%/1%   encouraging  however  for precision  1%/1%   can only be interpreted relative to other data still lacking on a broader scale. one should keep in mind  however  that we neither narrowed semantic interpretation down to a very limited range of spatial relations in anatomy  bean et al  1   nor did we bias the result by preselecting only those phrases that were already covered by our domain models  gomez et al.  1   judged from the poor figures of our recall data  there is no doubt  whatsoever  that conceptual coverage of the domain constitutes the bottleneck for any knowledge-based approach to nlr sublanguage differences sore also mirrored in these data  since medical texts adhere more closely to well-established concept taxonomies than magazine articles in the it domain. 
　in our evaluation  we certainly have only scratched the surface. besides many open methodological questions related 
1 	natural language processing 
to the evaluation of conceptual structures  a lot of empirical material related to different syntactic structures still has to be considered. in our system  we currendy supply semantic interpretation schemata for declaratives  relatives  and passives at the clause level  complement subcategorization via pps  auxiliaries  tenses at the verb phrase level  pre- and and postnominal modifiers at the noun phrase level  and anaphoric expressions. we currently do not cover control verbs  coordination and quantification. 
1 related work 
the standard way of deriving a semantic interpretation is to assign each syntactic rule one or more semantic interpretation rules  e.g.  van eijck and moore    and to determine the meaning of the syntactic head from its constituents. there are no constraints on how to design and organize this rule set despite those that are implied by the choice of the semantic theory. in particular  abstraction mechanisms  going beyond the level of sortal taxonomies for semantic labels  cf.  
e.g.  creary and pollard    such as property inheritance  defaults  are lacking. accordingly  the number of rules increases rapidly and easily reaches orders of several hundreds in a real-world setting  bean et al  1 . as an alternative  we provide a small set of interpretation schemata instead of assigning specific interpretation rules to each grammar item  in our case  single lexemes   and incorporate inheritancebased abstraction in the use of these schemata during the interpretation process in the knowledge base. 
　sondheimer et al  and hirst  treat semantic interpretation as a direct mapping from syntactic to conceptual representations. they also share with us the representation of domain knowledge using kl-one-style terminological languages  and  hence  they make heavy use of property inheritance  or typing  mechanisms. the main difference to our approach lies in the status of the semantic information rules. sondheimer et al attach single interpretation rules to each role {filler  and  hence  have to provide utterly detailed specifications reflecting the idiosyncrasies of each semantically relevant  role  attachment. property inheritance comes only into play when the selection of alternative semantic rules is constrained to the one s  inherited from the most specific case frame. in a similar way  hirst uses strong typing at the conceptual object level only  while we use it simultaneously at the grammar and the domain knowledge level for the processing of semantic schemata. 
　charniak and goldman  and jacobs  already specify semantic rules in the context of inheritance hierarchies. so  they achieve a similar gain in generality as we do  e.g.  charniak and goldman's rule for case relations corresponds to our schema  1  . we differ  however  in that we specify semantic interpretation schemata rather than rules. this additional level of generality becomes evident  e.g.  in terms of schema  1   which also incorporates the interpretation of genitives  and many other direct linkage phenomena . indeed  charniak and goldman have to supply an extra semantic interpretation rule for every syntactic phenomenon as 

they base semantic interpretation on syntactic rules and not on abstract configurations in dependency graphs that cover more than one syntactic phenomenon. jacobs  goes even further and completely ties syntactic role specifications into conceptual ones. such an approach  however  mixes knowledge levels at the cost of clean modularization. 
1 conclusions 
we proposed a principled approach to the design of compact  yet highly expressive semantic interpretation schemata. they derive their power from two sources. first  the organization of grammar and domain knowledge  as well as semantic interpretation mechanisms  are based on inheritance principles. second  interpretation schemata abstract from particular linguistic phenomena in terms of general configuration patterns in dependency graphs. 
　underlying these design decisions is a strict separation of linguistic from conceptual knowledge. a clearly defined interface is provided which allows these specifications to make reference to fine-grained hierarchical knowledge  no matter whether it is of linguistic or conceptual origin. in addition  the interface is clearly divided into two levels. one makes use of static  high-level constraints supplied by the mapping of syntactic to conceptual roles or supplied as the meaning of closed word classes. the other uses these constraints in a dynamic search through a knowledge base  that is parametrized by few and simple schemata. 
　it should be clearly noted  however  that the power of this approach is  to a large degree  dependent on the fine granularity of the knowledge sources we incorporate  the domain knowledge base  in particular. given such an environment  the formulation of the regularities at the semantic description level can be kept fairly general. the need for detailed ontologies is by far not restricted to semantic interpretation. indeed  one cannot do without sophisticated domain representations for many other challenging understanding tasks such as the resolution of reference relations in texts  hahn et al  1   the acquisition of concepts from texts  hahn and schnattinger  1   or the interpretation of evaluative assertions  staab and hahn  1 . 
　also since the number of schemata at the semantic description layer remains rather small  their execution is easy to trace and thus supports the maintenance of large-scale nlp systems. hie high abstraction level provided by inheritancebased semantic specifications allows easy porting across different application domains. our experience rests on reusing the set of semantic schemata once developed for the it domain in the medical domain without further changes. 
acknowledgements. k. maikert was a member of the graduate 
program human and machine intelligence funded by dfg  while m. romacker is supported by a grant from dfg  ha 1-1 . 
