 	rj a weak theory domain 

　the paper presents an interactive approach to learning apprentice systems for weak theory domains. the approach consists of a combination of teaming by analogy and learning by generalizing instances. one main point of this approach is that it uses the explanations drawn from an example  both to reduce the version space of me rules to be learned  and to generate new examples  analogous to the given one. another im-
portant point is that it demonstrates not only that over-generalization is harmless but also useful and necessary  when interacting with a user. it allows to use the theory of the domain  though incomplete as it is  in order to extract the missing knowledge by asking  clever  questions to its user. this paper presents a first prototypical version of disciple and its use to the design of technologies for the manufacturing of loudspeakers. 
i introduction 
　if expert systems have proven useful in many domains  their applications are limited by their inability to acquire and to update their 
knowledge. this problem is largely recognized as the knowledge acquisition bottleneck of expert systems  feigenbaum 1    mitchell & al. 1    kodratoff 1   etc... recent machine learning achievements   mitchell  carbonell & michalski 1  offer new solutions to the knowledge acquisition problem and open a new area in the evolution of expert systems  that is  expert systems able of automatic knowledge acquisition and learning  such as learning apprentice systems  las . a las is an interactive knowledge-based consultant that directly assimilates new knowledge by observing  analyzing and questioning about the problem solving steps contributed by their users through their normal use of the system. the user gives to the system a problem to solve and the expert sub-system starts solving this problem by showing the user all the problem solving steps. the user may agree or reject them. therefore  in its expert system mode  a las may encounter two situations. 
 either the current problem-solving step  which we shall further call partial solution  is accepted by the user. then  the current state of the knowledge base is judged as satisfactory  and no learning will take place. 
 or it is unable to propose any partial solution  or the solution it proposes is rejected by the user . then  the user is compelled to give his own solution. 
once this solution is given  a learning process will take place. the las will try to learn a general rule so that  when faced with problems similar to the current one  which it has been unable to solve   it will become able to propose a solution simitar to the solution given by the user to the current problem. we are developing a las  called disciple  specialized for weak theory domains. in this paper we describe the learning mechanisms of disciple. to this purpose we use examples from technology design. the next section is a brief description of this domain. the following sections present the learning problem and the learning method of disciple 
　we have chosen  as a first domain to test our approach to interactive lass  the domain of designing technologies for the manufacturing of loudspeakers. before presenting in more details this domain we stress two of its important features. firstly  the domain is usually too complex for an autonomous system. secondly  small improvements in technology have important outcomes since a technology is usually used for a large number of products. therefore the best solution is searched. a consequence of these features is that such a domain is most appropriately handled with an interactive system as the expert  consultant  sub-system of a las  where the user and the system cooperate in finding the best solution to the current problem. 
technology design might well be viewed as successive decompositions of complex operations into simpler ones  and successive specializations of these simpler operations by choosing tools  materials or verifiers  which are in turn successively specialized. to design a technology  disciple needs some knowledge about the components of the loudspeakers  about the technological solutions for the manufacturing of loudspeakers  about the tools and the materials one can use to manufacture loudspeakers. all this knowledge constitutes the domain theory. this domain theory is inherently incomplete since we can not suppose that disciple knows all the objects of the domain  all the properties of a given object  all the actions that can be performed for manufacturing loudspeakers  all the properties of the known actions  preconditions  effects   all the ways of decomposing or specializing a given action  etc... 
iii the learning problem 
　in the domain we have chosen  disciple acts as an aid to a technology designer. the problem to be solved is that of planning the manufacturing of a certain loudspeaker. the solution to this problem is a plan of actions for manufacturing the loudspeaker. 
the problem-solving paradigm is problem-reduction. that is  disciple will successively decompose an action into simpler actions or specialize an action to a better defined one. in this way  disciple will build a 
problem-solving tree. this process continues untill the leaves of this tree are elementary actions. they represent the solution to the original problem  the top of the problem-solving tree . 
let us suppose that  during planning the manufacturing of a loudspeak er  disciple encounters the following problem 
attach sectors on chassis-membrane-assembly 
for which it is unable to propose a satisfactory solution. let us further 
suppose that the user indicated the following solution to disciple: 
apply mowicoll on sectors  
press sectors on chassis-membrane-assembly 
note that apply and press may be actions previously unkown to the system and  in such a case  it knows nothing about them except that the are means of attaching. 
now disciple knows a solution of the current problem 
	kodratoff and tecuci 	1 

attach sectors on chassis-membrane-assembly 
apply mowicoll on sectors  
press sectors on chassis-membrane-assembly. 
this solution will further be seen as an example of a general rule to be learned. 
in this paper  and in the present version of disciple  we use the following generalization method. we suppose that the above example represents with fidelity the structure of the general rule to be learned. in this case  learning a general rule reduces to learn the concepts   instantiated in the example by 'sectors'  'chassis-membrane-assembly' and 'mowicoll   for which the attach action can be safely decomposed into a sequence of apply and press actions. 
therefore  the rule disciple will try to learn has the following form: 
	if 	x. y  and z satisfy  constraints  
     then attach x on y  - apply z on x  press x on y the learning problem addressed by disciple is therefore : given an example rule  generalize it and find its domain of application. 
iv the learning method 
of explanation-
　　　　　figure 1. the learning method in disciple the learning starts by interpreting a user's solution as an instance of a more general rule to be learned. 
 firstly  in its explanation-based mode  disciple looks for plausible explanations of the validity of the user's solution. it is essential to the success of disciple that there should be a possible explanation in terms of the relations between the objects referred at in the example. one must nevertheless be well aware that  working in a weak theory domain  those explanations may sometimes be irrelevant   as opposed to the ones provided in well-formalized domain    and have to be validated by the user. 
 secondly  disciple enters its analogy-based mode. the analogy relies on the concept of similarity of the explanations : two rules are analogous when they are supported by similar explanations  and two explanations are similar when they both are instances of the same  over -generalized explanation. in its analogy-based mode  the work of disciple is two-fold. on the one hand it attempts to build such an over-generalization from the examples it has got. on the other hand  it consults its knowledge base in order to generate new instances of the current over-generalization. we shall use the following approximation : the explanation of the user's example will be said to be a sufficient condition to the rule application  and the over-generalization will be said to be a necessary condition to the rule application. in that way  they can be compared to the s-set and g-set of mitchell's version space  mitchell 1 . 
1 	knowledge acquisition 
 thirdly  disciple uses similarity-based generalization from examples. analogy does not garantee the validity of the generated conditions  which must once more be validated by the user. the generated examples rejected by the user will be treated as negative examples  and the accepted ones as positive examples. in the same way as other generalization algorithms   see  for instance  michalski 1  kodratoff & al. 1     positive examples will be used to generalize the set of sufficient conditions   otherwise stated : to increase the s-set . negative ones will be used to particularize the necessary conditions. this part of disciple has not yet be fully worked out  it will not be further described here. 
 finally  if it happens that the s-set and the g-set become identical  a necessary and sufficient condition has been reached   and an exact rule has been learned. this is seldom the case  especially in fields with a weak theory. in general  we shall keep the necessary and the sufficient conditions separately. we then say that we have obtained a symbolic uncertain condition for the application of the rule. 
v explanation-based mode 
　the system will try to explain why the solution indicated by the user is a good one. since disciple does not have a complete domain theory  it is unable to find alone such a  complete  explanation. recall  for instance  that apply may be an action previously unknown to the system. it does not mean that disciple is waiting for an explanation from the user  but simply that it will try to find an explanation with the user's help. more precisly  it will try to propose several partial explanations  asking the user to validate them. 
the heuristic used by disciple is that the explanation has to be expressible in terms of the relations between the objects from the rule instance  'sectors'  'chassis-membrane-assembly'  'mowicoll' . while  in general  there exist many relations between two objects  it is expected that  in the world of an expert system  only the relations relevant to the domain of expertise are present. 
therefore  disciple will look in its knowledge base for the links connecting 'sectors'  'chassis-membrane-assembly' and 'mowicoll'. they are illustrated in the following netoork: 
           figure 1. an incomplete knowledge base some of these links may be relevant for the rule to be learned when they are plausible pieces of explanation. since disciple does not have the necessary knowledge to make the difference between the relevant and the irrelevant links  it will have to rely on the user  by asking questions which are issued from a straithforward analysis of these links: disciple will initiate the following dialogue   where the user's answers are put between *  . 
is it relevant for the solution that: mowicoll glues sectors   * yes * mowicoll glues chassis-membrane-assembly   * yes * sectors part-of loudspeaker   * no* chassis-membrane-assembly part-of loudspeaker   * no * making use of this new knowledge  disciple will find an  explanation  represented by the following network. 

vi analogy-based mode 
　two situations are said to be analogous when a mapping can be done between the causal networks of these two situations  wiaston 1  kedar-cabelli 1 . the above network will be seen as a causal network of the decomposition in example rule. a heuristic used by disciple to find similar explanations is: two explanations are similar when the edges of their networks are indexed by the same values. 
vii discussion and conclusions 
　in the previous sections we have presented in some detail the learning mechanisms of disciple. it shares  of course  many features with leap  mitchell & al. 1   both relying on the same design principles: the interactive nature of problem solving  the association of each example to a single problem solving step  the partition of control and basic domain knowledge. on the other hand there are also important differences between leap and disciple. leap utilizes explanationbased generalization. therefore  it produces justifiable generalization from a single example  it allows rejecting incorrect training examples  it relies on a strong domain theory  vlsi design . disciple utilizes a combination of explanation-based learning  learning by analogy  and similarity-based learning. it relies on an incomplete and/or weak domain theory  it relies on user to reject incorrect training instances  it produces justifiable generalizations from examples. disciple learns not only generalizations but also particularizations of concepts  dejong 

for instance  the following network is similar with the above one  & mooney 1 . also  it uses the same interface paradigm for both 

problem-solving and learning  it proposes solutions and the user accepts or rejects them . 
disciple uses the similarity between networks  and proposes instantiated rules to its user. these rules are obtained by replacing the explanation pattern of the example rule by similar ones. 
for instance  disciple will propose the following new rule. 
attach centering-device on chassis-assembly h apply neoprene on centering-device  enough. other sources of knowledge are needed  as well as metarules for finding far-off explanations. the explanation-based method does not 
use goal regression. the use of theorems in the analogy-based mode is quite limited. from the practical point of view  disciple shows one more very important weakness. its analogy mechanism works through our over-generalization process  which actually reduces to turning constants into variables. it follows that diisciple is of interest if  and there are several weaknesses of disciple  that are currently under improvement. the method of finding an explanation is not powertull 
since the analogy is never proven to be valid  the user will have to validate it one can estimate the similarity between two networks  or concepts  by computing their  best generalization   kodratoff & tecuci 
1b . the less general is their generalization  the best their similarity. 
in disciple  we slightly modified the approach referred at in  kodratoff & tecuci 1b . instead of starting a costly generalization algorithm of the agape kind  kodratoff & ai. 1   disciple rather over-generalizes the explanation it disposes of  and states that any two instances of this over-generalization are similar. in disciple's present implementation state  this over-generalization is very elementary : turn constants into variables by giving the same variable name to all the occurences of a same constant. it is part of our planned improvements to disciple to refine this definition. we are quite aware that such a generalization may not be a necessary condition. this is part of the approximations of the present system to accept this lack of precision. 
it follows that the over-generalization of the above networks is their conditions and in their actions. 
disciple-1 has been implemented in lelisp  chailloux 1  and we are running it on vax-1  and macintosh computers. implementations on sun and explorer stations are under way. 
