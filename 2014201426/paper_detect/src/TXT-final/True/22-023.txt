 
existing explanation facilities are typically far more appropriate for knowledge engineers engaged in system maintenance than for endusers of the system. this is because the explanation is little more than a trace of the detailed problem-solving steps. an alternative approach recognizes that an effective explanation often needs to substantially reorganize the line of reasoning and bring to bear additional information to support the result. explanation itself becomes a complex problem-solving process that depends not only on the line of reasoning  but also on additional knowledge of the domain. we present a new computational model of explanation and argue that it results in significant improvements over traditional approaches. 
1 introduction 
a computer is generally poor at explaining its problem solving to a human user. early work on expert systems suggested an explicit knowledge base of expert-defined  problem-solving rules might be used to help such a program explain its reasoning. during the past decade  research has been conducted on ways of using this knowledge base to explain the expert system's actions and conclusions. although significant advances have been made  explanations still suffer from several important flaws. the underlying premise of previous work is that the basis of the explanation is the trace of the expert system's line of reasoning. we believe another approach is possible that  for certain audiences  will overcome many of the problems evident in earlier explanations. a human expert  when asked to account for complex reasoning  rarely does so exclusively in terms of the actual process used to solve the problem  ericsson and simon  1 . instead  an expert tends to reconstruct a  story  that accounts for the problem solving. this story reflects the expert's line of explanation  paris et al  1  that is not 
   * present address: computer science department  washington state university  pullman  washington 1. 
   this research is sponsored in part by the national science foundation  grant number iri-1. 
necessarily the same as the original line of reasoning. for example  consider the following line of reasoning taken by an inspector attempting to find the cause of the excessive load on a concrete dam  based on  franck  1  . 
...the debris on top of the dam suggests a recent flood. the water markings on the abutments do too. i suspect the flood is the cause of the excessive load. no  the duration of the flood wasn't long enough. sometimes settlement has these same features. perhaps settlement is involved. that would account for the high uplift pressures suggested by the slow drainage over time. but the damage to the drainage pipes isn't right. it must be erosion causing the dam to drop more at the toe. yes  erosion is causing the excessive load... 
note that the inspector is using a heuristic  data-driven problem-solving process. later  the field inspector is asked to explain the reasoning that led to the conclusion. 
...the symptoms led me to believe the problem is internal erosion of soil from under the dam. see  erosion would cause the selectively broken pipes under the dam  therefore slowing drainage and causing high uplift pressures that cause the dam to slide downstream... 
notice how the line of explanation is different from the line of reasoning. during problem solving  the line of reasoning is directed to settlement through a heuristic association with flood  and then on to erosion. however  the line of explanation moves to erosion directly. the line of explanation is not simply a version of the line of reasoning pruned for dead-ends. the heuristic association between flood and settlement that eventually led to the conclusion erosion has been replaced by relationships that bond the symptoms directly to erosion. 
   data introduction is another interesting feature of this explanation. during explanation  evidence not used during problem solving is introduced as additional support. this includes not only the underlying causality of many of the items  but also the introduction of new symptoms that further support the final conclusion  i.e. the movement of the dam . this type of data introduction is common in domains marked by nonexhaustive problem solving. in such domains  an expert will use a small set 
	wick and thompson 	1 

of cues from the data to reach a conclusion. once this conclusion has been made  the expert will support it with additional data items. in some explanations  the initial data cues are replaced with new more directly supporting data. in our example  the triggering data  i.e. the duration of the flood  is dropped as it is not needed to directly support the conclusion. 
   as illustrated by this example  the line of explanation and the line of reasoning are often considerably different in both form and content. in contrast to previous work  our research aims at creating the explanation as a product of a problem-solving activity largely distinct from the expert system's problem-solving process. this breaks the tight bond between explanation and problem solving. with this bond broken  the explanation system has freedom to reconstruct the explanation to create a more direct account of the expert system's conclusion. 
1 previous work 
mycin  shortliffe  1  was one of the first systems to explain its actions. mycin provided two basic explanation queries: why and how. these two queries form the foundation of nearly all explanation facilities to date. 
　swartout  swartout  1  introduced a system  called xplain  explicitly designed to attack the problem of explanation. swartout used domain principles and domain rationales to record the designer's rule justifications by using an automatic programmer to build the expert system. the xplain system produced excellent explanations. however  the information presented appears to be best suited for a knowledge engineer. 
　clancey  hasling et a/.  1  has built an explanation system that augments the facility provided by mycin. clancey's system  neomycin  shifts the focus from the domain knowledge to the strategic problemsolving knowledge  n e o m y c i n is capable of generating why and how explanations about the strategy used to 
solve the problem. 
　many previous systems  for example xplain  do not present a strict one-to-one mapping of the problemsolving steps but allow some of the steps to be omitted based on the type of user  i.e. knowledge engineer or domain expert . other systems  such as that by wallis and shortliffe  wallis and shortliffe  1   include measures of  complexity  and  importance  for pruning steps from the trace. however  none of these systems includes the ability to completely reconstruct the explanation or to introduce new data not originally used by the expert system. 
   tanner  tanner and josephson  1  has developed on a system to construct justifications that are designed  not necessarily to follow the problem-solving process  but instead to explicitly connect with the user's understanding of the problem. paris  paris  1  has found that explanations not only vary in abstraction level according to the user  but they also vary in content and emphasis. this work strongly suggests that an expert system must be able to change the content of the explanation  if it is to be practical for varying users. moore  moore and swartout  1  is also working on changing the content of an explanation based on the user. her work centers on 
tools 
the use of rhetorical techniques to plan an explanation of the execution trace to produce a context for follow-up questions. 
　our research differs from related work in several ways. most significantly  our research aims at using knowledge other than the execution trace as the basis for the explanation. previous work concentrated on methods for translating  presenting  or augmenting the execution trace. our work focuses on replacing the trace with an equally valid line of explanation. 
1 different kinds of explanation 
the nature of an effective explanation depends heavily on the user. knowledge engineers and others involved in the design and maintenance of an expert system require an explanation facility that elaborates on precisely what the system did to accomplish a specific result. this reflects the common thought that  justification must remain true to the expert system . however  an explanation for an end-user is intended to increase the user's confidence in the system and to aid the user in understanding the consequences of the system's conclusion. a system designer clearly needs a traced-based explanation that accurately reflects the line of reasoning used in the expert system. this line of reasoning may be inappropriate  however  for an end-user. a line of reasoning often proceeds to a conclusion via an obscure and indirect path. for instance  as illustrated in section 1  many complex domains involve heuristic reasoning  clancey  1 . an effective explanation of the conclusion erosion  although arrived at from a heuristic association with flood  may not only require a substantial reorganization of the line of reasoning  but may require the use of additional supporting information not part of the original reasoning process. generating such an explanation is possible only within a reconstructive explanation1 paradigm in which the explanation is reconstructed by an active  problemsolving process. 
   there are obvious costs associated with the adoption of a reconstructive explanation strategy. however  these costs may not be as great as might at first be supposed. a clearer separation between problem solving and explanation reduces the need to trade problem-solving competence for comprehensibility that often arises with conventional explanation systems. another possible problem with reconstructive explanation is the potential inconsistency between problem solving and explanation. however  better separation of problem solving and explanation might improve consistency. a recent study has shown that non-experts are not likely to catch reasoning errors when presented with trace-based explanations  erdman  1 . this may be because a non-expert  such as an end-user  often will not catch reasoning errors in a difficult to understand line of reasoning. reconstructive explanation can aid the end-user in a better understanding of the problem and thus provide a basis for the user 
     1it should be noted that this use of  reconstructive explanation  differs from an earlier use  paris et a/.  1 . the current use is more restrictive than the former  corresponding to what was previously called  plausible explanation.  independently evaluating a system's actions. overall  quality end-user explanation is not free and the designers of an expert system must determine if they require extensive end-user explanations. 
1 intuitive support for reconstructive explanation 
as reconstructive explanation is significantly different from previous explanation paradigms  we present some intuitive support for its use. research in psychology has discovered that  in certain situations  recall is reconstructive  dawes  1 . that is  during recall of an event  details are filled in that are not available from the memory of that particular event. this same notion of reconstruction has be shown to carry over to complex problem solving  ericsson and simon  1 . in expert problem solving  many of the details of how and why things happened are not available from a memory of the problem solving  anderson  1 . when asked to report this information  the expert will reconstruct an explanation that integrates the elements of a partial memory trace with the memory of other related entities  for example  textbook information . we believe this freedom to reconstruct an explanation based on information in addition to the information and processes used during problem solving is in part responsible for the high quality of human explanations. reconstructive expert system explanation is the study of how to give an expert system this reconstructive ability. 
1 the rex system 
rex  reconstructive explainer  is a test-bed system capable of producing reconstructive explanations for expert systems. r e x is designed to answer retrospective queries in an attempt to obtain the end-user's ratification of the expert system's conclusion. such retrospective queries have been shown to be a useful context for reconstructive explanation techniques  ericsson and simon  1 . r e x provides an explanation of the movement within the competitor set of conclusions  thus showing how the final conclusion was reached. 
1 	a m o d e l of reconstructive explanation 
the r e x system is built on a model of reconstructive explanation that maps the execution of the expert system onto a textbook representation of the domain. here  a textbook representation is simply a representation of the information presented in human explanations  much of which comes from domain textbooks. the process of explanation then becomes the process of mapping over key elements from the execution trace and expanding on them using the more structured textbook knowledge. this should not be confused with  decompiling  the rules used by the expert system. decompiling results in an explanation of the relationship between the antecedent and consequent of a rule. reconstruction results in textbook knowledge that accounts for the data uncovered by the expert system. 
　the execution trace is passed from the expert system to rex where it is mapped into a high-level specification of expertise that represents the knowledge required for this problem-solving task. the specification points to structures in the textbook knowledge base that represent methods and relationships involved in performing each particular problem-solving task. a search is conducted within the textbook knowledge base to find the information necessary to answer the end-user's query. 
   in the traditional approach to explanation the execution trace is mapped directly to the explanation text. sometimes pruning is done to remove unnecessary information and auxiliary knowledge  called support knowledge  is added. however  the line of the explanation is based exclusively on the trace or line of reasoning. in our reconstructive explanation approach the execution trace is mapped through a high-level specification to the textbook knowledge of the domain. as the trace is mapped through the specification  information on the processes and reasons used by the expert system  the  how  knowledge  is filtered out. this leaves only information on the data used during problem solving  the  what  knowledge . using this  what  knowledge as an index  textbook methods and relations are found that represent well-organized  how  knowledge. this textbook information  as opposed to the more obscure information found in the trace  forms the content and organizational structure of the explanation text. 
　an obvious question arises. why go through all the extra work of mapping the trace into the textbook knowledge  why not simply use the  textbook justifications  attached to the rules in the trace  the answer rests in the realization that explanation is a complex problemsolving task in its own right  requiring at a minimum a significant reorganization of the knowledge used for problem solving. for example  in medical school  knowledge is presented and explained as symptoms given disease. in the real world  problems are solved as disease given symptoms. however  conclusions are still explained as symptoms given disease as the explanation is then easier to understand and follow. likewise  when an expert is asked to explain complex problem-solving methods  what can be given is the textbook method of solving the problem  instantiated for the specific case at hand. this method explains the process for the same reason that it was used to teach the process  it is easier to understand than the more obscure and ad hoc method used during real problem solving. 
   this raises yet another question. if the textbook methods are so easy to explain  why not use them directly to solve the problem  the answer rests in the realization that real-world problem solving is also a complex task. experts often proceed from symptoms to conclusions through long diverted paths. it is rarely possible to identify what method of solving the problem is appropriate from the beginning. it is much easier to reconstruct an appropriate method once the answer is known. thus  explanation and problem solving are two largely distinct tasks  each requiring its own methods and knowledge. 
1 	specification of expertise 
before describing how r e x reconstructs an explanation  it is first necessary to briefly describe the representa-
	wick and thompson 	1 
tion used for the high-level specification. the specification represents what knowledge is required to solve the problem. in particular  this representation of expertise takes the form of a graph of hypotheses  each connect to other hypotheses by one or more  transitions   johnson et ai  1 . associated with each transition are two sets. a set  called the condition set  of cues defines the data that must be found for the transition to be valid. in other words  this set represents information from the problem solving that can lead to a movement between the two hypotheses. secondly  another set  called the goal set  defines the goals that must be posted in moving between the two hypotheses. these two sets combine to define what knowledge  cues and goals  is required to move between two hypotheses in the knowledge specification. 
　at first  this representation may sound like a representation of how to solve the problem. however  the representation is neither procedural or deterministic. in other words  each transition tells what information is required to move between two hypotheses  but does not enforce how that information will be used. for example  the condition and goal elements of a transition are supersets of the cues and goals needed to make the transition. different subset s  of cues and goals can be used to move between the two hypotheses. the following section will illustrate the use of such a specification for reconstructing explanations. 
cue uplift 
value 
type 
name 
nickname 
valuename true 
direct 
the high uplift pressures acting on the dam uplift pressures value 
name 
nickname 
valuename 
g o a l det-cause name 
nickname true the erosion of soil from under the dam erosion * hypothesis* 
determine causal relationships determine causes hypothesis erosion 
cue script erosion-to-sliding 
	uses 	: 	  drainage   uplift   sliding   
supports  erosion  achieves det-cause vconstraint  and  drainage   uplift   sliding   text    erosion   causes  broken-pipes  causing  drainage  resulting in 
 uplift  and in turn  sliding   
g o a l script causal holds 	  det-cause   
	text 	: 	 simply  det-cause   

1 	reconstruction of h o w f r o m w h a t 
to illustrate the process of explanation  consider the line of reasoning given in section 1. in that example  the domain expert was trying to identify the cause of the excessive load on a concrete darn. in the explanation  the expert was attempting to answer how that cause was determined. the expert's problem-solving leaves a trace of data corresponding to symptoms and inferences. the trace for this example contains: debris on dam  water marks  drainage  uplift pressure  and broken pipes. in r e x   the data in this trace are used to  activate  the same data in the high-level specification of the knowledge required to solve the problem. this enables r e x to determine what data cues were used by the expert system in moving to the conclusion. the line of reasoning illustrated in section 1 follows a path from the initial empty hypothesis through the hypothesis flood  onto the hypothesis settlement and stopping at the final solution erosion. however  the line of explanation  as shown in section 1  moves from the initial empty hypothesis directly to erosion  using the data cues uplift pressure  drainage  broken pipes and sliding. r e x   when given ac-
cess to the expert system to find additional supporting knowledge that was not activated from the expert system's problem-solving trace  reconstructs an explanation that closely resembles this line of explanation. this reconstruction involves three core elements of the r e x design: the textbook knowledge base  the explainer  and the story teller. the following paragraphs will describe how each of these elements helps reconstruct a line of explanation for the concrete dam example. 
tools 
figure 1: sample textbook knowledge representations. 
t h e textbook knowledge base is represented in r e x as a collection of relationships between cues  hypotheses  and goals as illustrated in figure 1. the cues  hypotheses  and goals themselves represent the domain objects that other relationships and methods manipulate. in r e x   each relationship is represented as a cue script and each method is represented as a goal script as shown in figure 1. each frame and script has text slots for english presentation. 
   using the representations illustrated in figure 1  a transition from one hypothesis to another is possible when a method and relationships are found such that each goal and cue used is a member of the goal and condition sets defined between the two hypotheses in the knowledge specification graph. in r e x   the structure built by combining the method and the relationships is called an explanation structure as it serves as an explanation of the movement between the hypotheses. 
t h e explainer is responsible for constructing the line of explanation that will eventually be presented to the end-user. this line of explanation represents a movement from the initial problem-solving state to the final conclusion reached by the expert system. in r e x   this corresponds to finding a path through the knowledge specification from the conclusion of the expert system to the empty hypothesis. each transition in this path must be supported by the existence of a valid explanation 

structure. r e x uses the a* algorithm to search through a space of knowledge specification transitions for which a valid explanation structure has been found. the search is carried out backwards from the final conclusion of the expert system towards the empty hypothesis. each state in this search corresponds to an emerging line of explanation that uses certain cues and a hypothesis as data  establishes other cues and a hypothesis as conclusions and traverses certain edges in the specification. transitions between states in the a* search correspond to expanding the bottom hypothesis by finding each edge with a valid explanation structure that moves to this hypothesis. as the precise explanation structure chosen will determine the cues included in the explanation  a separate transition in the a* search is constructed for each valid explanation structure on each incoming edge of the bottom hypothesis. a complete line of explanation represents a path from the initial problem state  the empty hypothesis  to the final conclusion reached by the expert system. 
t h e story teller takes the path found by the explainer and formats it for english presentation using the grammer of figure 1  thus creating what is called a story tree. figure 1 shows the story tree for our example. the 
r e x system output of this story tree is as follows:1 
we have a concrete dam under an excessive load. i attempted to find the cause of the excessive load. not knowing the solution and based on the broken pipes in the foundation of the dam  and the downstream sliding of the dam  and the high uplift pressures acting on the dam  and the slow drainage of water from the upstream side of the dam to the downstream side i was able to make an initial hypothesis. to achieve this 1 used the strategy of striving to simply determine causal relationships. in 
1
　　the verbose nature of the english output is a result of our focus on the content and structure of the story tree and not on its presentation. 
attempting to determine causes  i found that the internal erosion of soil from under the dam causes broken pipes causing slow drainage resulting in uplift and in turn sliding. this led me to hypothesize that internal erosion was the cause of the excessive load. feeling confident in this solution  i concluded that the internal erosion of soil from under the dam was the cause of the excessive load. 
　the expert system  using a reconstructive explanation system  is able to present a line of explanation that leads directly to the solution. whereas the expert system using a traditional explanation system would be restricted to a line of explanation moving first to flood  through settlement to erosion. even when the explanation system is not given access to the expert system and thus can not ask for additional supporting data  such as sliding  the reconstructive paradigm can still create a more direct explanation than is possible within the traditional paradigm. r e x can find the shortest path of  activated  data from the solution hypothesis to the initial empty condition. in other words  r e x can find the most direct path to the solution using only information uncovered by the expert system during problem solving. in our example  this path is found by moving from the initial empty set directly to settlement and on to erosion. this line of explanation  although less direct than the previous line of explanation  is still more direct than the path followed by the traditional explanation paradigm as it by-passes the need for the heuristic association with flood. 
1 significance 
reconstructive explanation is a significantly new approach to the automatic generation of expert system explanations. the feasibility of using the reconstructive explanation paradigm has been shown by the r e x system. 
   such a reconstructive explanation paradigm has several advantages that show its desirability:  1  the textbook methods and relations used to integrate the information uncovered during problem solving serve to reorganize the flow of the explanation to be more direct.  1  different methods and relations can be used to allow the explanations to be tailored to the needs of specific user types.  1  a reconstructive explanation system can provide independent feedback on the performance of the expert system. for example  if the explanation system can not find an explanation for the conclusion  this could suggest an error in the problem solving of the expert system.  1  an expert system with a reconstructive explanation facility will have the ability to use one approach for problem solving and another for explanation. thus  the system can be implemented with less concern for the tradeoff between problem-solving ability and end-user explanation.  1  under certain constraints  a reconstructive explanation has the freedom to present multiple lines of explanation leading to the same conclusion.  1  reconstructive explanation provides more flexibility than conventional explanation systems allowing explanations to be built on information other than a subset of the execution trace. 
	wick and thompson 	1 

