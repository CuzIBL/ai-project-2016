 
this paper addresses agents' intentions as building blocks of imitation learning that abstract local situations of the agent  and proposes a hierarchical hidden markov model  hmm  to represent cooperative behaviors of teamworks. the key of the proposed model is introduction of gate probabilities that restrict transition among agents' intentions according to others' intentions. using these probabilities  the framework can control transitions flexibly among basic behaviors in a cooperative behavior. 
1 introduction 
imitation learning is considered to be a method to acquire complex human and agent behaviors and as a way to provide seeds for further learning  ki1; sch1; mk1 . while those studies have focused on imitating behaviors of single agents  few works address imitation for teamwork among multiple agents because the complexity of the world state increases drastically in multi-agent systems. on the other hand  stochastic models like hidden markov models  hmm  have been studied as tools to model and to represent multiagent/human interactions  orp1; ib1 . it is  however  hard to apply these stochastic models to imitate teamworks by observation because of the complexity of the model of multiple agents. this study focuses upon intentions of agents as building blocks of an abstract state of the local world for the agent in order to overcome the problem. using intention  i formalize teamwork and propose a hierarchical hidden markov model for imitation learning of teamwork. 
1 teamwork and imitation 
1 intention and play 
we suppose that an intention is a short-term idea to achieve a certain condition from another condition. for example  in soccer  the intention 'to guide a ball in a certain direction' is an idea to move to a certain direction with the ball. we assume that an intention is an individual idea; therefore  an agent does not pay attention to others' efforts to achieve their intention. 
　a play is postulated as a sequence of atomic actions to achieve a single intention. the play is a basic building block 
of overall behavior of agents. for example  in soccer  a 'dribble' is a play to achieve the intention 'guide a ball in a certain direction'  which consists of atomic actions like 'turn'  'dash'  'kick'  and so on. a play for the intention is also an individual behavior without collaboration with other agents because an intention is an individual idea. as shown below  an intention and the corresponding play are used as a main trigger to synchronize team-plays among multiple agents. this means that the intention is treated as a kind of partial condition of the world. 
1 	team-play 
we suppose that team-play is a collection of plays performed by multiple agents to achieve a certain purpose. as mentioned in the previous section  an intention is an individual idea. this means that multiple agents who do not change their intentions can not perform a team-play because they have no way to synchronize their plays. instead  we assume that they can synchronize their plays by changing their intentions according to situations of environments and intentions of other agents. for example  in soccer  when two players  passer and receiver  guide a ball by dribble and pass  players will change their intentions as follows: 

in this example  the passer and the receiver initially have intentions 'dribbling' and 'supporting'  respectively. then  the passer changes the intention to 'seek-receiver'  followed by the receiver's change to 'free-run'  the passer's change to 'pass'  and so on. play synchronization is represented as conditions when agents can change the intention. in the example  the passer changes its intention from 'seek-receiver' to 'pass' when the teammate's intention is 'free-run'. 
1 	imitation learning of team-play 
the imitation learning of a teamplay is formalized as follows: 
 1  observation: to observe behaviors of mentor agents and estimate what intention each agent has at each time step.  1  extraction: to extract conditions prevailing when each agent 

1 	poster papers 

changes intentions. a condition is represented as a conjunction of others' intentions.  1  generation: to generate a sequence of intentions according to changes of environment and others' intentions. in the second step of this process  the intention plays an important role: that is  conditions of changes of intentions. as described in section 1  we consider that intention can represent world conditions. in addition to it  we use only intentions to construct rules for agents to change their intentions. 
1 hierarchical hidden markov model for agents 
1 	single behavior model 
we formalize behaviors of a basic play m performed by a single agent as a moore-type hmm as follows: 

1 	cooperative behavior model 
as discussed in the previous section  we consider that teamplay consists of a sequence of intentions of multiple agents. this means that cooperative behavior of a single agent in a 
team of agents is considered as transitions among several basic plays  hmms . therefore  we formalize cooperative behavior as the following modified mealy-type hmm  
	hmmc 	= 	{m u e f g h   

1 	joint-behavior model 
finally  we coupled multiple hmmcs  each of which represents the behavior of an agent. coupling is represented by gate probabilities h. for example  when agent x and agent y are collaborating with each other  the gate probability in hmmc for agent x indicates the probability that agent y is performing play u at time t when agent x changes the play from m to n during time  using the gate probability  the agent calculate a likelihood of the state snj at a certain time t + 1 according to the following equation: 
 1  
  where t + l 
1 experiments 
i applied the framework to collaborative play of soccer. the demonstration by mentors is dribble and pass play as shown in fig. 1: a player starts to dribble from the center of the left half field and brings the ball to the right half. at the same time  another player runs parallel along the upper  or lower  side of the field supporting the dribbling player. then  the first player slows to look-up the second player; it then passes the ball to that player. simultaneously  the second player starts to dash to the ball and dribbles after receiving the ball. after the pass  the first player exchanges roles with the teammate so that it becomes a supporting player for the second player. 
　to imitate this demonstration  1 trained six hmmss to model'dribble'  'slow-down and look-up'  'pass'  'free-run'  'chase-ball'  and 'support'. each of hjmmss has 1 states. the output of these hmm's consists of local situations  the relative position and the velocity to the ball  and agent's actions  'turn'  'dash'  'small-kick'  'long-kick  'trap'  and 'look' . note that there is no information about others' situations for output of hmmss. as described in section 1  others' situations are taken into account during the extraction phase in learning. 
　two hmmcs for agent x  the first player  and y  the second player  are constructed after the training of the hmjvts. then  the learner observes behaviors of the mentor and adjusts probabilities of the hmmcs. 
　figure 1 shows result of observation and estimation. this figure shows the relative likelihood of each play state for each agent at each timestep estimated by observation phase. in this figure  there are 1 rows of small squares: upper 1 rows correspond 1 plays of the first player  agent x   and the rest 1 are plays for the second player  agent y . each row corresponds to a play d  k  p  f  c  and s  each of which means 'dribble  d '  'slow-down and look-up  k   'pass  p '  'freerun  f '  'chase-ball  c '  and 'support  s   respectively. in each row  a column consists of 1 small squares each of which corresponds a state of hmmsfor one of the 1 plays at a certain timestep. the ratio of black area in the square indicates the relative likelihood with which the state of the hmmsis active at the timestep. columns are aligned along with time. so  a horizontal line of squares means changes of likelihood of a 
　state of hmms. from this figure  we can see that the learner estimates that the agent x starts the play with the intention of'dribble'  followed by 'slow-down'  'pass' and 'support'  while the player y starts 'support' play  followd by 'chaseball' and 'dribble' plays. 
　after the training by the observation  the learner can generate behaviors similar to the demonstration by using the acquired probabilities of the hmlvtas shown in fig. 1. this 

poster papers 	1 


figure 1: exp. 1: result of recognition of men- figure 1: exp.1: state transitions gener-
tor's behaviors 	ated by learned hmm 

figure is constructed in the same way as fig. 1  but only one square is filled in a timestep because the learner decides one of the possible states according to the likelihood shown in eq. 1. in this example  although the learner sometimes generates wrong state transitions  for example a transition to states to the 'free-run' play in agent y during agent x is doing 'slow-down'  it recovers to the suitable transitions and continues to imitate the demonstrator. this shows robustness of the model against accidents. because the model is coupled loosely with world and other's states by output probabilities of hmm  it can permit variation and misunderstanding of world and others' states. 
1 	discussion 
there are several works on coupling hmms that can represent combinational probabilistic phenomena like multi-agent collaboration  jgs1; gj1; jgjs1 . in these works  probabilistic relation among several hmms  agents  are represented as state-transition probabilities  such that the amount of memory complexity increases exponentially. this is a serious problem for imitation learning because we assume that the number of examples for imitation is small. in our model  the relation among agents is represented by gate probabilities h  in which others' states are treated as outputs instead of as conditions of state transition. using them  the likelihoods of state-transitions are simplified as products of several probabilities  eq. 1 . in addition  detailed states of other agents are abstracted by play  intention . as a result  the number of parameters is reduced drastically  so that learning requires very small number of examples as shown in above examples. although such simplification may decrease flexibility of representation as a probabilistic model  experiments show that the proposed model has enough power to represent team-play among agents. 
　intention in the model brings another aspect to communication among agents. we assume that there are no mutual communication in the proposed model. however  we can introduce communication as a bypass of observation and estimation of other's intention  play . the proposed model will be able to provide criteria for when an agent should inform their intention to others by comparing agents' actual intentions and estimated intention of the agent itself by simulating its own hmm1. 
　one important issue is the design of the intention. in the proposed model  intentions play various important roles like chanking of the actions and conditions of world state. therefore  we must design intentions carefully so that team-plays can be represented flexibly. 
