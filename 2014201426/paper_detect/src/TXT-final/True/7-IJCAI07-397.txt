
we introduce problog  a probabilistic extension of prolog. a problog program defines a distribution over logic programs by specifying for each clause the probability that it belongs to a randomly sampled program  and these probabilities are mutually independent. the semantics of problog is then defined by the success probability of a query  which corresponds to the probability that the query succeeds in a randomly sampled program. the key contribution of this paper is the introduction of an effective solver for computing success probabilities. it essentially combines sld-resolution with methods for computing the probability of boolean formulae. our implementation further employs an approximation algorithm that combines iterative deepening with binary decision diagrams. we report on experiments in the context of discovering links in real biological networks  a demonstration of the practical usefulness of the approach.
1 introduction
over the past two decades an increasing number of probabilistic logics has been developed. the most prominent examples include pha  poole  1   prism  sato and kameya  1   slps  muggleton  1   mlns  richardson and domingos  1  and probabilistic datalog  pd   fuhr  1 . these frameworks attach probabilities to logical formulae  most often definite clauses. in addition  they often impose various constraints on probabilities. for instance  in slps  clauses defining the same predicate are assumed to be mutually exclusive; prism and pha only attach probabilities to factual information  and again constraints are imposed that essentially exclude the possibility that certain combinations of facts are simultaneously true. these assumptions facilitate the computation of the probability of queries and simplify the learning algorithms for such representations. one approach  the pd formalism of  fuhr  1  that is intimately related to problog  does not impose such restrictions but its inference engine has severe limitations. at the same time 

  recently moved to the katholieke universiteit leuven.
  also at university of helsinki.it seems that there are - despite a great potential - still only few real-life applications of these probabilistic logics. the reasons for this might well be that the assumptions are too strong and sometimes hard to manage by the user  or that the solvers are often too slow or too limited.
　we introduce problog which is - in a sense - the simplest probabilistic extension of prolog one can design. problog is essentially prolog where all clauses are labeled with the probability that they are true  and - similar as pd but unlike the other approaches mentioned - these probabilities are mutually independent. problog has been motivated by the real-life application of mining large biological networks where edges are labeled with probabilities. such networks of biological concepts  genes  proteins  phenotypes  etc.  can be extracted from large public databases  and probabilistic links between concepts can be obtained by various prediction techniques. in this and many other applications  probabilistic links are mutually independent and can easily be described in problog.
　a problog program specifies a probability distribution over all possible non-probabilistic subprograms of the problog program. the success probability of a query is then defined simply as the probability that it succeeds in these subprograms. the semantics of problog is not really new  it closely corresponds to that of pd  fuhr  1  and of  dantsin  1 . the key contribution of this paper  however  is the introduction of an effective inference procedure for this semantics  and its application to a real-life link discovery task.
　the success probability of a problog query can be computed as the probability of a boolean monotone dnf  disjunctive normal form  formula of binary random variables. unfortunately  the latter problem is np-hard  valiant  1 . since pd employs a naive approach based on inclusionexclusion for computing the probabilities of these formulae  the evaluation of about 1 or more conjuncts is infeasible in the implementation of pd according to  fuhr  1 . in contrast  problog's approximation algorithm is able to deal with formulae containing up to 1 formulae. the problog solver has been motivated by and employs recent advances in binary decision diagrams  bdds  for dealing with boolean functions. at the same time  it employs an approximation algorithm for computing the success probability along the lines of  poole  1 . using this algorithm we report on experiments in biological networks that demonstrate the practical usefulness of the approach. obviously  it is straightforwardto transfer problog to other link and network mining domains.
　the paper is structured as follows. we describe a motivating application in section 1. in section 1  we introduce problog and its semantics. we shall assume some familiarity with the prolog programming language  see for instance  flach  1  for an introduction. in section 1  we show how problog queries can be represented by monotone dnf formulae and then computed with bdds. section 1 gives an approximation algorithm for problog queries  and experiments on real biological data are reported in section 1. finally  in sections 1 and 1  we discuss related work and conclude.
1 example: problog for biological graphs
as a motivating application for problog  consider link mining in large networks of biological concepts. enormous amounts of molecular biological data are available from public sources  such as ensembl1  ncbi entrez1  and many others. they contain information about various types of objects  such as genes  proteins  tissues  organisms  biological processes  and molecular functions. information about their known or predicted relationships is also available  e.g.  that gene a of organism b codes for protein c  which is expressed in tissue d  or that genes e and f are likely to be related since they co-occur often in scientific articles. mining this data has been identified as an important and challenging task  see  e.g.   perez-iratxeta et al.  1  .
　such a collection of interlinked heterogeneous biological data can be conveniently seen as a weighted graph or network of biological concepts  where the weight of an edge corresponds to the probability that the corresponding nodes are related  sevon et al.  1 . probabilities of edges can be obtained from methods that predict their existence based on  e.g.  co-occurrence frequencies or sequence similarities. a problog representation of such a graph could in the most simple case consist of probabilistic edge/1 facts though finer grained representations using relations such as codes/1  expresses/1 would also be possible.
　a typical query that a life scientist may want to ask from such a database of biological conceptsis whethera given gene is connected to a given disease. in a probabilistic graph  the importance of the connection can be measured as the probability that a path exists between the two given nodes  assuming that each edge is true with the specified probability  and that edges are mutually independent  sevon et al.  1 . such queries are easily expressed in logic by defining the  non-probabilistic  predicate path n1 n1  in the usual way. now the query  - path 'gene1'  'diseasealzheimer'  would look for paths between the given nodes. since edges were assumed probabilistic  this query has a certain success probability. this probability  defined below  directly corresponds to the probability that a path exists between the nodes  known as the two-terminal network reliability problem.
　obviously  logic - and problog - can easily be used to express much more complex possible relations. for instance  two proteins that both interact with a third one possibly also interact with each other if they are all expressed in the same tissue. or  two genes are possibly functionally related if they have closely related annotations from gene ontology1.
1 problog
a problog program consists - as prolog - of a set of definite clauses. however  in problog every clause ci is labeled with the probability pi.
example 1 as an example  consider:
1: likes x y :- friendof x y .
1: likes x y :- friendof x z   likes z y .
1: friendof john mary .
1: friendof mary pedro .
1: friendof mary tom .
1: friendof pedro tom .
even though we shall focus on the  pure  subset of prolog  i.e. definite clause logic  problog also allows one to use most built-in predicates in prolog by assuming that all clauses defining built-in predicates have label 1.
　a problog program t = {p1 : c1 ，，，  pn : cn} now defines a probability distribution over logic programs l   lt = {c1 ，，，  cn} in the following way:
		 1 
　unlike in prolog  where one is typically interested in determining whether a query succeeds or fails  in problog we are interested in computing the probability that it succeeds. the success probability p q|t  of a query q in a problog program t is defined by
 1 
 1 
 1 
　in other words  the success probability of query q corresponds to the probability that the query q has a proof  given the distribution over logic programs.
1 computing success probabilities
given a problog program t = {p1 : c1 ，，，  pn : cn} and a
query q  the trivial way of computing the success probability p q|t  proceeds by enumerating all possible logic programs m   lt  cf. equation 1 . clearly this is infeasible for all but the tiniest programs.
　we develop a method involving two components. the first is concerned with the computation of the proofs of the query q in the logical part of the theory t  that is in lt. its result will be a monotone dnf formula. the second component computes the probability of this formula.

figure 1: the sld-tree for the goal likes john tom   using obvious abbreviations.
1 problog queries as dnf formulae
to study the set of logic programs where a given query can be proved we consider the logical part lt of the theory t. we now show how this set of logic programs can be represented by a dnf formula.
　we employ sld-resolution  from which the execution mechanism of prolog is derived. as an example  the sldtree for the query  - likes john tom . is depicted in figure 1. the paths from the root to individual leaves of the sld-tree represent either a successful or a failed proof. from a path that ends in the empty goal denoted by   one can construct an answer substitution θ making the original goal true. the other proofs end at an  underlined  goal that fails.
　the standard sld-resolution computes the sld-tree in a top-down fashion. it initializes the root of the sld-tree with the query  l1 ，，，  ln to be proven and then recursively generates a subgoal of the form     b1θ ，，，  bmθ l1θ ，，，  lnθ for each clause h :  b1 ，，，  bm in the logic program for which the most general unifier of h and l1 is the substitution θ. see e.g.  flach  1  for a more extensive treatment.
　each succesful proof in the sld-tree has a set of clauses {p1 : d1 ，，，  pk : dk}   t employed in that proof. these clauses are necessary for the proof  and the proof is independent of other clauses in t. as a consequence  the probability that this proof succeeds is .  in other words  the sum of probabilities of programs containing these clauses is
　let us now introducea boolean randomvariablebi for each clause pi : ci （ t  indicating whether ci is in logic program; i.e.  bi has probability pi of being true. the probability of a particular proof involving clauses {p1 : d1 ，，，  pk : dk}   t is then the probability of the conjunctive formula b1…，，，… bk. since a goal can have multiple proofs  the probability that goal q succeeds equals the probability that the disjunction of these conjunctions is true. more formally  this yields:
		 1 
where we use the convention that pr q  denotes the set of proofs of the goal q and cl b  denotes the set of boolean variables  clauses  used in the proof b. thus the problem of computing the success probability of a problog query can be reduced to that of computing the probability of a dnf formula  which is monotone as all variables appear positively.
example 1 continuing our running example  and using l1 l1 as names  and boolean variables  for the two clauses defining likes and f1 ，，，  f1 for friendof 
p likes john  tom |t 
   = p  l1 … l1 … f1 … f1 … f1  ‥  l1 … l1 … f1 … f1  .  1  since p l1  = 1  this is equal to
	p  l1 … f1 … f1 … f1  ‥  l1 … f1 … f1  .	 1 
1 computing the probability of dnf formulae
computing the probability of dnf formulae is an np-hard problem even if all variables are independent  as they are in our case. there are several algorithms for transforming a disjunction of conjunctions into mutually disjoint conjunctions  for which the probability is obtained simply as a sum. in the literature  this is sometimes referred to as the problem of transforming sum-of-products into sum-of-disjoint-products. one basic approach relies on the inclusion-exclusion principle from set theory. it requires the computation of conjunctive probabilities of all sets of conjunctions appearing in the dnf formula. this is clearly intractable in general. more advanced techniques expand the conjunctions also with negated subformulae  in order to disjoin each of them from all previous ones  luo and trivedi  1 . however  these algorithms seem to be limited to a few dozens of variables and a few hundreds of sums. motivated by the advances made in the manipulation and representation of boolean formulae using binary decision diagrams  bdds  since their introduction by  bryant  1   we employ this class of techniques.
　a bdd is an efficient graphical representation of a boolean function over a set of variables. a bdd representing the formula in equation 1 is shown in figure 1. given a fixed variable ordering  a boolean function f can be represented as a full boolean decision tree where each node on the ith level is labeled with the ith variable and has two children called low and high. each path from the root to some leaf stands for one complete variable assignment. if variable x is assigned 1  1   the branch to the low  high  child is taken. each leaf is labeled by the outcome of f given the variable assignment represented by the corresponding path. starting from such a tree  one obtains a bdd by merging isomorphic subgraphs and deleting redundant nodes until no further reduction is possible. a node is redundant iff the subgraphs rooted at its children are isomorphic. in figure 1  dashed edges indicate 1's and lead to low children  solid ones indicate 1's and lead to high children.
　in practice  the chosen variable ordering determines the extent to which substructures can be shared in the bdd and thus has an enormous influence on the size and complexity of the resulting bdd. state-of-the-art bdd implementations therefore employ heuristics to automatically reorder the variables during bdd construction  which help to control the combinatorial explosion.

1 	 1 	 1 	 1 
figure 1: a bdd representing the boolean in equation 1.
　given a bdd  it is easy to compute the probability of the corresponding boolean function by traversing the bdd from the root node to a leaf. at each inner node  probabilities from both children are calculated recursively and combined afterwards as it is done in the following procedure. in practice  memorization of intermediate results is used to avoid the recomputation at nodes that are shared between multiple paths.
probability input: bdd node n  
1 if n is the 1-terminal then return 1
1 if n is the 1-terminal then return 1
1 let h and l be the high and low children of n
1 prob h  := call probability h 
 
　as we shall see in section 1  the resulting algorithm can be applied to problog programs containing hundreds of clauses  boolean variables in the bdd  and tens of thousands of proofs  products of variables . in our implementation of problog  we store the conjunctions corresponding to proofs in a prefix-tree for reasons of efficiency.
　one interesting further use of the already constructed bdd for a given query q is that it becomes very efficient to answer conditionalprobability questions of the form  q| 1
 where thes are possibly negated booleans representing the truth-values of clauses. to compute the answer  one only needs to reset the probabilities of the corresponding nodes to 1 or 1  and call the procedure probability.
1 an approximation algorithm
in this section we introduce an algorithm for approximating the success probability of queries in problog. this is useful for large problog programs  since the size of the monotone dnf formula can explode.
　a first obvious observation leading towards a faster algorithm is that - as in example 1 - one can remove all boolean variables that correspond to clauses with probability 1.
　a second and more important observation allows one to eliminate complete proofs from the monotone dnf formula. during the computation of the sld-tree  which proceeds depth-first  from left to right in prolog  we keep track of a dnf formula d that represents the dnf of the already computed proofs. if further proofs are encountered whose conjunction b1 … ... … bn is logically entailed by d  i.e. d |= b1 … ... … bn  then these proofs can be removed from further consideration. because we work with monotone dnf formulae  this condition can be checked efficiently by verifying that b1 … ... … bn is not entailed by any of the conjuncts d1 …，，，…dk in d. this corresponds to testing whether {d1 ，，，  dk}   {b1 ，，，  bn}  a kind of subsumption.
　this observation motivates the use of iterative deepening instead of depth-first search to compute the sld-tree and the corresponding dnf formula. in this way  it becomes more likely that later proofs will be subsumed by already computed ones. iterative deepening essentially proceeds as depthfirst search but does not expand goals in the sld-tree whose depth exceeds a threshold. it then iteratively increases this depth-bound. iterative deepening also avoids getting trapped into possibly infinite paths in the sld-tree. instead of using a depth-bound one can also employ a probability bound in problog  resulting in a best-first kind of search.
　a final observation  leading to approximations of success probabilities  is that an incomplete sld-tree can be used  during iterative deepening  to derive an upper and a lower bound on the success probability of the query. this observation and the corresponding algorithm are related to work by  poole  1  in the context of pha  but adapted towards problog. for problog  the bounds can be obtained by constructing two dnf formulae from the incomplete sld-tree. the first dnf formula d1 encodes the successful proofs already occurring in the tree. the second dnf formula d1 encodes the successful proofs already occurring in the tree as well as the proofs that have been cut off. we then have that
	p d1  ＋ p q|t  ＋ p d1 .	 1 
this directly follows from the fact that d1 |= d |= d1 where d is the boolean dnf formula corresponding to the full sldtree of the query.
example 1 consider the sld-tree in figure 1 only till depth 1. in this case  d1 encodes the left success path while d1 additionally encodes the paths up to likes pedro tom  and likes tom tom   i.e.
d1 =  l1 … l1 … f1 … f1  d1 =  l1 … l1 … f1 … f1  ‥  l1 … f1 … f1  ‥  l1 … f1 … f1 
the formula for the full sld-tree is given in equation 1.
　better approximations will be obtained by stretching the bound on the depth of sld-trees. the following algorithm approximates the success probability of a problog query q to .
approximate query q; program t; bound  
1 depthbound := 1;
1 d1 := false
1 repeat
1 d1 := d1
1 call iterate q  true  depthbound  d1  d1  1 p1 := call probability d1 
1 p1 := call probability d1 
1 increment depthbound
1 until
1 return p1  p1
iterate query q; conjunction c; depthbound d; dnf d1  d1 
1 if q is empty and
1 then d1 := d1 ‥ c
1 d1 := d1 ‥ c
1 elseif
1 then d1 := d1 ‥ c
1 else let q be l q1 ，，，  qn
1 select rule h :  b1 ，，，  bm
1 such that mgu h l  = θ and the rule is
1 represented by boolean variable b
1 d := d   1
1 call iterate b1θ ，，，  bmθ q1θ ，，，  qnθ;c … b; d 
theorem 1 upon termination  the procedure approximate q  t    returns values p1 and p1 such that p1 ＋ p q|t  ＋ p1 and.
the algorithm may not always terminate for all inputs  but this is hardly avoidable given that prolog does not always terminate  even when using iterative deepening .
example 1 consider calling approximate with the query
    p; the program 1 p :  p; and the bound . the procedure will never terminate  because the sld-tree is infinite and repetetive .
1 experiments
we implemented the approximation algorithm in prolog  yap-1.1 and used cudd1 for bdd operations. motivated by the fact that even for simple connection queries  the number of proofs quickly explodes in our biological networks  we primarily try to answer the following question: q how well does our approximation algorithm scale 
　as our test graph g  we used a real biological grapharound four random alzheimer genes  hgnc ids 1  1  1  and 1   with 1 edges and 1 nodes. the graph was extracted from ncbi and some other databases by taking the union of subgraphs of radius 1 from the four genes and producing weights as described in  sevon et al.  1 . as a test case  we focused on evaluating the connection between two of the genes  1  1 . for scaling experiments  we randomly subsampled edges from g to obtain subgraphs g1   g1   ... of sizes 1 ... 1 edges. each gi contains the two genes and consists of one connected component. average degree of nodes ranges in gis approximately from 1 to 1. subsampling was repeated 1 times.
　the problog approximation algorithm was then run on the data sets with the goal of obtaining approximations. as the minimal length of paths in between those two nodes is 1 in the original graph  we initialized the iterative deepening threshold  number of used clauses  to 1.
　in this setting  the connection query could be solved to  for graphs with up to 1 to 1 edges  depending on the random sample. as an illustrative example  figure 1 a  shows the convergenceof the bounds for one graph with 1 edges. figure 1 b  shows the average width of the probability interval for the 1 random subgraphs of 1 edges. in most cases  results are quite accurate already after levels 1. the maximal level used over all gi was 1 clauses  corresponding to at most eleven search levels. running times for one subgraph typically range from seconds for small graphs up to four hours for the largest successful runs. figure 1 c  shows running times for the 1 random graphs of 1 edges on a 1 ghz machine. in our tests  bdd construction typically became infeasible if the number of conjunctions used for the upper bound exceeded 1. in all those cases  the width of the last calculated probability interval was already smaller than 1. together all these results indicate that the approach can give good bounds for quite large problems  which answers question q positively.
　a partial explanation of the good scalability is given in figure 1 d . it shows the total number of proofs as well as the numbers of proofs needed for the bounds    for two illustrative random sequences of subgraphs. the numbers are given as a function of the maximal size of the bdd  used here as an approximation of the problem complexity. as can be seen  the number of proofs explodes badly  while the numbers of proofs needed for the bounds scale up much nicer.
1 related work
the problog semantics is not really new  it closely corresponds to the semantics proposed by  dantsin  1  and of pd  fuhr  1  even though there are some subtle differences. whereas problog and the approach by dantsin employ prolog  pd focusses on datalog and hence  does not allow for functors. furthermore  the work on pd comes more from a database perspective and has also devoted a lot of attention to negation. whereas dantsin does not report on an implementation  pd has been implemented in the hyspirit system  which computes success probabilities in two steps. the first step employs magic sets to compute the answers to the datalog component of the query  and in a second step employs the inclusion-exclusion principle to compute the probability of the resulting dnf expressions. this second step makes the approach severely limited. indeed   fuhr  1  states:  practical experimentation with hyspirit has shown that the evaluation of about 1 or more conjuncts is not feasible.  in contrast  using problog's approximation algorithm one can deal with up to 1 conjuncts as shown in the experiments. this is also needed in order to cope with realistic applications in link mining.

figure 1:  a  convergence of bounds for one graph with 1 edges  as a function of the search level.  b  convergence of the probability interval for 1 test graphs with 1 edges.  c  running times for 1 test graphs with 1 edges.  d  total number of proofs and numbers of proofs needed for bounds    for two illustrative test graph sequences  'a' and 'b' .　second  the problog semantics extends also the distributional semantics by  sato and kameya  1  and the proposal by  dantsin  1  in that it also allows for attaching probabilities to clauses  not just to ground facts. although this ability has to be exercised with caution  as the truth of two clauses  or non-ground facts  need not be independent  e.g. when one clause subsumes the other one   it does provide new abilities  as illustrated in the likes/1 example. more importantly  systems such as prism  sato and kameya  1  and also pha  poole  1   avoid the combinatorial problem of the second step by imposing various constraints on the allowed programs which basically guarantee that the formula describing all proofs of a query is a sum-of-disjoint-products. whereas such conditions may be natural for some types of applications  such as those involving context-free grammars  they hinder the application of these frameworks to some other applications. for instance  the characteristics of the biological network mining task are incompatiblewith the restrictions imposed by systems such as prism and pha.
　finally  pure slps  muggleton  1  differ in the way the clauses are labeled and  hence  possesses a quite different semantics. the labels in slps correspond - as in probabilistic context-free grammars - to the probability that the clause is used to continue a proof if some atom having the same predicate as the head of the clause has to be proven.
1 conclusions
we have defined problog  a probabilistic version of prolog  and have shown that the success probability of problog queries can be computed using a reduction to a monotone dnf formula  whose probability can then be determined using bdds  and we have also introduced an effective and efficient approximation algorithm for computing these probabilities. the technique has been experimentally evaluated on a challenging and involved real-life problem of mining biological networks. problog's key advantage in this type of application is its simplicity as well as the flexibility for posing complex queries that support the analyst. there are several questions for further research. the most prominent ones are whether techniques employed for learning prism programs or slps could be adapted for learning problog  and vice versa  whether the independence assumption made in problog could be adapted for use in prism or pha.
acknowledgements
we thank sevon et al.  sevon et al.  1  for the biological data. hannu toivonen has been supported by alexander von humboldt foundation and tekes. this work was also partly supported by the eu ist fet projects april and iq.
