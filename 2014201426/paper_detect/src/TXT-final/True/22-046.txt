 
a fundamental problem for most ai problem solvers is how to control search to avoid searching subspaces which previously have been determined to be inconsistent. two of the standard approaches to this problem are embodied in the constraint satisfaction problem  csp  techniques which evolved from vision tasks and assumptionbased truth maintenance system  atms  techniques which evolved from applying constraint propagation techniques to reasoning about the physical world. this paper argues that both approaches embody similar intuitions for avoiding thrashing and shows how csps can be mapped to atms problems and vice versa. in particular  mackworth's notions of node  arc  and path consistency  freuder's notion of it-consistency  and dechter and pearl's notion of directed kconsistency have precise analogs in the atms framework. 
1 	introduction 
both constraint satisfaction techniques and truth maintenance systems are used widely in artificial intelligence applications. a variety of refinements have been developed to avoid the thrashing behavior that often accompanies them. this paper demonstrates that the intuitions underlying these refinements are essentially similar. in particular  mackworth's  notions of node  arc  path consistency  freuder's  inconsistency  and dechter and pearl's  directed k-consistency for constraint satisfaction problems csps  and techniques for assumption-based truth maintenance  atms   1  1  are encompassed by a few propositional resolution rules. this paper shows that in many cases the constraint networks produced by the standard local consistency algorithms are identical to ones produced by the atms for the same input constraint network. a longer version of this paper  explores these issues in far greater detail. 
　this paper details how both csp techniques and atms's are based on a few resolution rules. by outlining the relationship between these two sets of techniques  a connection in terminology and algorithms is established between two distinct subfields of artificial intelligence. this holds the promise that any advance in one subfield is easily communicated to the other. at the moment both have incorporated essentially the same intuitions. however  we hope that this synthesis will lead to faster progress on these issues of mutual interest. 
	1 	search 
1 	search vs. inference 
although csp and atms tasks seem  on the surface  to be very different  both require combining two distinct modes of reasoning to minimize overall computational cost to complete tasks. in the following sections we define more precisely what atms's and csps are. before diving into those details  we address the frameworks within which csp and atms techniques are used. 
　csps are typically solved by backtrack search. however  as mackworth  demonstrated  backtracking suffers from numerous maladies often making it  grotesquely inefficient.  mackworth pointed out that if the constraints are preprocessed then many of backtracking's maladies can be eliminated. this preprocessing involves tightening  via local consistency algorithms  the initial constraints so that backtracking detects futile states earlier leading to fewer backtracks. freuder  generalized mackworth's results and showed that with sufficient preprocessing most or all of the futile backtracks can be avoided. however  the expense of the preprocessing to avoid all futile backtracks typically outweighs the cost of the futile backtracks in the first place. a fundamental issue for csp solvers is to determine how much preprocessing is necessary to minimize total effort  preprocessing plus backtracking . 
   an atms task cannot be so cleanly stated as a csp. instead an atms is always used interactively with some kind of inference engine. the inference engine is roughly analogous to the backtracker while the atms is roughly analogous to the module which enforces csp local consistency. the inference engine supplies the atms with a stream of clauses  as opposed to a csp where the input problem is fixed  and queries about those clauses. the most typical query the inference engine makes is whether a particular set of propositional symbols is consistent  i.e.  is part of a global solution . ensuring that the atms never replies that a set is consistent when it is not is computationally disastrous in practice. however  answering that a set is consistent when in fact it is not results in futile inference engine effort on that set of assumptions. 
　we thus see that atms and csp techniques embody the same computational trade-offs. futile backtracking is analogous to futile inference engine work  but avoiding all futile backtracking or all futile inference engine work is too expensive also. thus  the csp local consistency algorithms are motivated by exactly the same set of problem solving concerns as the atms algorithms. but even more surprising  most of the csp local consistency algorithms themselves have almost identical analogs in the atms framework. 
　due to the nature of the atms task  all atms algorithms are incremental. csp techniques are typically used to solve completely specified problems  and need not be in-



   we have encoded the three conditions which define a constraint problem: every variable has a value  no variable can have more than one value  and no combination of variable assignments violates any constraint. therefore  every complete assignment of truth values to the propositional symbols which satisfies every clause in c  corresponds to a solution to the original csp. conversely  every solution to the csp corresponds to an assignment of truth values to the propositional symbols which satisfies every clause of c. 
1 	example continued 
we were given the variables x1 x1 x1 with domains d1 = {a  b}  d1 = { e   / }   and d1 = {c  d g  and binary constraints c1 = {be bf}  c 1 = {bc.bd.bg}  and c1 = {ed fg}. c consists of the following clause set. each variable must have a value: 

the negative clauses stating that each variable can have only one value: 

the constraints: 

1 	csp-propositional mapping 
every constraint network cn has a unique encoding c =  as a set of clauses. the inverse  
exists only under the following conditions: 
1. all clauses are either positive or negative. 
1. every symbol appears in at most one positive clause. 
1. for every pair of symbols in every positive clause  the binary negative clause of these two symbols is in the clause set. 
1. no negative clause of three or more literals contains two symbols occurring in the same positive clause. 
　the following defines  every positive clause defines a variable and  1  every negative clause mentioning only symbols which occur in positive clauses but which does not mention two symbols from the same positive clause indicates a disallowed combination for the constraint among the variables of the symbols. note that for every constraint network 
1 	backtrack search 
both atms and csp techniques exploit backtrack search for identifying global solutions. the following is a simple generic backtrack algorithm for constructing solutions to a csp encoded as a set of clauses c. let subsumed  s  c  be a function which checks whether the negative clause constructed from the symbols of s is subsumed by c  equivalently  the function checks whether interpreting the symbols of s to be true falsifies any clause of c . let the global variable b count the number of backtracks  i.e.  the 
	1 	search 
number of times bt was called without producing a solution   b is initialized to be 1. 
algorithm bt s c : 
1.  termination check  if every variable has a value in s  then mark s as a solution and return. 
1.  subsumption check  pick a variable xi which does not have a value in s. if subsumed    holds for every value a i j   then set b = b + 1 and return. 
1.  iterate  for every j  unless subsumed  call 
note that bt implicitly incorporates the binary negative clauses involving elements of the same variable. 
　unfortunately  using bt to find all solutions can involve an enormous amount of often futile  1  1  backtracking  i.e.  1 will be very large . both atms and csp algorithms incorporate the strategy which  in propositional terms  amounts to constructing additional clauses  entailed by c. adding to c a clause entailed by it  can only reduce the number of backtracks required to find a solution. adding all clauses to c entailed by it  guarantees backtrack-free search. 
1 	propositional inference rules 
all atms and csp local consistency techniques can be viewed as implementing a few basic resolution rules. all of these inference rules change the clause set  preserving the set of global solutions  but improving the efficiency of the backtrack search used to find the solutions. this section presents a set of inference rules referred to as i which we use in subsequent sections to characterize the atms and csp local consistency algorithms. the names of these rules are chosen for compatibility with the equivalent atms rules. 
　ho: this rule removes subsumed clauses from c. if clause d c is subsumed by some other clause e c  then d is removed from c. 
h1: a unit resolution rule: 

　h1: this rule does the main work. n b  indicates the negative clause with symbols b. given a set of negative clauses n ai : 

an instance of this rule is: 

h1 can a generate a very large number of clauses  therefore it is useful to define two restrictions of h1. 
　h1-k:: h1 restricted to only infer negative clauses below size k. the basic intuition behind this restriction is that it 

reduces overall computational complexity by reducing the number of clauses h1 introduces. in addition  when h1 is used as part of search  smaller clauses are more valuable than larger ones because they provide more pruning. given a set of negative clauses n a  : 

1 	local consistency conditions 
the local consistency algorithms enforce local consistency conditions by adding clauses. these added clauses reduce the backtracking needed to find solutions. 
　in discussing these theorems it is important recognize that the constraints in a constraint network  by construction  do not contain spurious information. for example  if a constraint network has the constraint c1 = {ab}  then 
necessarily  thus  all csp local consis-
tency algorithms implicitly incorporate a limited form of subsumption: when an element is removed from a domain of some variable  all constraints referring to that variable are simplified to no longer to refer to the deleted element.  note that this happens automatically if constraints are represented by allowed combinations  however  how a constraint is represented is not specified in the csp approach.  
1 	node consistency 
node consistency ensures that the singleton constraint ci{x  for every node i and any value  node consistency ensures that all unary constraints are used to delete disallowed domain elements. in the clausal encoding  the domain of a variable is represented by a single disjunction and unary constraints appear as singleton negative clauses. 
theorem 1 a constraint network cn is node consistent iff no application of iis to  produces a clause. 
1 	arc consistency 
arc consistency is ambiguously defined in the csp literature. here we adopt the definition of  which is slightly stronger than the one in . note that arc consistency does not necessarily imply node consistency  although all so-called arc consistency algorithms in the literature enforce node consistency as well. arc consistency ensures that for every pair of nodes i and j  for every value there exists a value  which is not excluded by cij. 
 to avoid double subscripts  i write x for x  and y for xj.  
theorem 1 a constraint network cn is arc consistent iff no application of  produces a singleton negative clause. 
proof. let the y1 be the elements of dj. this is represented by the disjunction: 
such 
that every value was excluded by c . these exclusions are represented by binary negative clauses. 
thus  there must exist a set of binary negative clauses all of which contain x:x and each of the possible values 


applying h1 to these binary clauses we obtain the singleton negative clause -ix:x. 
the converse is straight forward. 
1 	path consistency 
as with arc consistency  path consistency is also ambiguously defined. we adopt the stronger definition of path consistency from : if for every three nodes r  s and / if for every value  not excluded by the constraint between nodes crt there exists a value such that the values x and y are not excluded by cre  and the values y and z are not excluded by cst. 
theorem 1 a constraint network cn is path consistent iff no application of h1 to  produces a binary clause not subsumed by c. 
1 	k-consistency 
 generalizes the preceding result to obtain: 
theorem 1 a constraint network cn is strongly kconsistent iff no application of h1-k to   introduces a new clause not subsumed by c. 
1 	local consistency algorithms 
all atms and csp local consistency algorithms employ some subset of the inference rules j  from section 1  to modify the clause set c to achieve local consistency. given the theorems of the preceding section and the set of inference rules i  the following useful algorithmic properties hold for a clausal encoding of a csp. 
proposition 1 given any subset of inference rules from 
i  any order of application will lead to the same resulting clause set as long as the clause set closed under those rules. 
proposition 1 any algorithm incorporating any subset of inference rules from 1 achieves node consistency as long as the resulting clause set is closed under h1. 
proposition 1 any algorithm incorporating any subset of inference rules from 1 achieves node and arc consistency as long as the resulting clause set is closed under h1 and h1-s. 
proposition 1 any algorithm incorporating any subset of inference rules from 1 achieves node  arc and path consistency as long as the resulting clause set is closed under h1 and h1-s. 
proposition 1 any algorithm incorporating any subset of inference rules from 1 achieves strong k-consistency as long as the resulting clause set is closed under h1-k. 
	de kleer 	1 

1 	the importance of the algorithms 
the basic motivation for applying the local consistency algorithms to constraint networks is to reduce or even totally eliminate the number of backtracks required to identify the solutions. this issue is extensively discussed in the csp literature. a general result from freuder stated in propositional terms is: 
theorem 1 // the clause set c = a cn  is closed under h1} then the solutions can be found via backtrack-free 
search. 
　the local consistency conditions are similarly important to atms operations - often backtrack search is used to construct problem solutions. the local consistency conditions however play an even more central role in atms functioning. fundamental to the atms is its ability to efficiently answer queries whether the conjunction of a set of symbols is known to be inconsistent. if the atms replies that the symbol set is consistent when  in actual fact  it is not  the inference engine may perform an unbounded amount of futile work. therefore  it is important that the atms answer such queries correctly. if the clause set is closed under h1  then the atms can correctly answer the queries by a simple subsumption test with n. 
　extensive experience with the atms has shown that closing the initial clause set under h1 usually yields a total increase in overall problem-solving effort. this is because the inference engine effort saved by correctly answering the queries is outweighed by the computational effort of closing the clause set under h1. usually  it is globally optimal to close the clause set under 1-k for some small value of k. these conditions  of course  correspond to the atms notions of arc and path consistency. 
1 	csp algorithms 
both   and   definitions of local consistency admit more ambiguity than first meets the eye. consider just the simple case of achieving node consistency. a node consistency algorithm converts a constraint network to an equivalent one which is node consistent. unfortunately  there may be a very large number of equivalent networks which are node consistent. the node consistency condition  although well-defined  does not specify which of these networks a node consistency algorithm must find. although rarely specified  all consistency algorithms incrementally remove local consistency violations by minimally tightening the constraints to find an equivalent consistent network meeting the local consistency condition. 
　the common csp local consistency algorithms can be analyzed in terms of the inference rules of 1. the node consistency algorithm nc-1 repeatedly applies rule 1. 
theorem 1 	executing nc-1 to constraint network cn has the same result as applying a 1 	to the closure of a cn  	under h1 and h1. 
　all arc consistency algorithms close the clause set under h1 and h1  applying h1 first whenever possible. the different arc consistency algorithms do various amounts of bookkeeping to prevent futile applications of h1. 
theorem 1 executing ac-1  ac-1  or acs to constraint network cn has the same result as applying a   1 to the closure of a cn  under h1 and h1. 
	1 	search 
　analogously  the path consistency algorithms close the clause set under h1 and h1. 
theorem 1 executing pc-1 or pc-1 to constraint network cn has the same result as applying a   1 to the closure ofa{cn  under h1 and h1-s. 
1 	a t m s algorithms 
the atms contains a variety of mechanisms to maintain node labels which we do not discuss here. instead  this paper focuses on atms techniques to construct nogoods entailed by c. the atms represents the clauses as n a set of nogoods  i.e.  negative clauses  and v a set of chooses  i.e.  positive clauses  where every symbol representing an assignment is an atms assumption. as the atms explicitly represents clauses it can directly incorporate the inference rules i. all versions of the atms algorithms incorporate some subset of these inference rules. 
1 	efficiency considerations 
all atms algorithms incorporate the subsumption rule 
ho. the motivation for incorporating ho is that there are an exponential number of potential clauses to construct  but  on average  the subsumption rule will eliminate most of them from the clause set. therefore  in all atms algorithms ho is always performed first. 
　property 1 of section 1 guarantees that the application order of inference rules is irrelevant. therefore atms implementations order the application of inference rules to minimize total effort. the basic intuitions behind the ordering heuristics are that h1 is extremely expensive and should always be applied last and to smaller nogoods first - smaller nogoods should be discovered first as they subsume far more higher-order nogoods which the algorithm might futilely have to process. 
　it should be noted that neither rules ho or h1 are necessary to ensure backtrack free search. both are included for efficiency considerations. note that the use of rule ho makes the overall algorithm adaptive - it allows an atms algorithm to dynamically adapt the set of nogoods to resolve as it eliminates nogoods from consideration. 
1 	a t m s algorithm 
whenever a nogood becomes subsumed  as well as being removed from n it is removed from all pending queues  and all processing on it is halted. the algorithm maintains a queue l of pending nogoods ordered by size  initially l is all new nogoods of size k or less. in usual practice resolve is invoked after every atomic atms operation. 
algorithm resolve: 
1.  unit preference for h1  if there is a singleton choose  its single literal is set to true  and every nogood ng mentioning the literal is replaced by a new nogood with that literal deleted. 
1. if l is empty  return. pick and remove ng a smallest nogood from l. if l is empty  return. 
1. if ng is the empty nogood  halt. the constraints are unsatisfiable. 
1.  h1  if ng is a singleton  it is removed from the choose s  in which it appears. all processed un-



this approach maximizes the use of atms justificationhandling facilities which are efficient  minimizes the number of assumptions necessary to encode a csp  and minimizes the use of the relatively inefficient hyperresolution rules. 
　if constraints are properly  encoded as justifications and problem-solving rules  then neither soundness nor completeness is lost. a great deal of efficiency is gained and the reasoning that underlies the construction of the constraints is explicit and under the control of the problem solver. taking a bird'seye view of constraint propagation applied to csps we recognize that  it transforms a csp into a smaller and more tractable one but doing so under explicit problem solving control such that search and predicate evaluation is minimized. 
	1 	acknowledgments 
this paper profited greatly from lengthy discussions with 
john lamping  alan mackworth and ramin zabih. also  
daniel g. bobrow  rina dechter  mike dixon  ken forbus  
felix frayman  ken kahn  sanjay mittal  judea pearl  
raymond reiter  jeffrey siskind  mark stefik  and brian williams provided valuable comments on this paper. 
