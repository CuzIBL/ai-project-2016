
we study the problem of computing a leximinoptimal solution of a constraint network. this problem is highly motivated by fairness and efficiency requirements in many real-world applications implying human agents. we compare several generic algorithms which solve this problem in a constraint programming framework. the first one is entirely original  and the other ones are partially based on existing works adapted to fit with this problem.
1 introduction
many advances have been done in recent years in modeling and solving combinatorial problems with constraint programming  cp . these advances concern  among others  the ability of this framework to deal with human reasoning schemes  such as  for example  the expression of preferences with soft constraints. however  one aspect of importance has only received a few attention in the constraints community to date: the way to handle fairness requirements in multiagent combinatorial problems.
모the seek for fairness stands as a subjective but strong requirement in a wide set of real-world problems implying human agents. it is particularly relevant in crew or worker timetabling and rostering problems  or the optimization of long and short-term planning for firemen and emergency services. fairness is also ubiquitous in multiagent resource allocation problems  like  among others  bandwidth allocation among network users  fair share of airspace and airport resources among several airlines or earth observing satellite scheduling and sharing problems  lema  tre et al.  1 .
모in spite of the wide range of problems concerned by fairness issues  it often lacks a theoretical and generic approach. in many constraint programming and operational research works  fairness is only enforced by specific heuristic local choices guiding the search towards supposed equitable solutions. however  a few works may be cited for their approach of this fairness requirement.  lema  tre et al.  1  make use of an earth observation satellite scheduling and sharing problem to investigate three ways of handling fairness among agents in the context of constraint satisfaction. more recently  pesant and re뫣gin  1  proposed a new constraint based on statistics  which enforces the relative balance of a given set of variables  and can possibly be used to ensure a kind of equity among a set of agents. equity is also studied in operational research  with for example  ogryczak and sliwin뫣ski  1뫣    who investigate a way of solving linear programs by aggregating multiple criteria using an ordered weighted average operator  owa   yager  1 . depending on the weights used in the owa  this kind of aggregators can provide equitable compromises.
모microeconomy and social choice theory provide an important literature on fairness in collective decision making. from this theoretical background we borrow the idea of representing the agents preferences by utility levels  and we adopt the leximin preorder on utility profiles for conveying the fairness and efficiency requirements. being a refinement of the maximin approach1  it has an inclination to fairness  while avoiding the so-called drowning effect of this approach.
모apart from the fact that it conveys and formalizes the concept of equity in multiagent contexts  the leximin preorder is also a subject of interest in other contexts  such as fuzzy csp  fargier et al.  1   and symmetry-breaking in constraint satisfaction problems  frisch et al.  1 .
모this contribution is organized as follows. section 1 gives a minimal background in social choice theory and justifies the interest of the leximin preorder as a fairness criterion. section 1 defines the search for leximin-optimality in a constraint programming framework. the main contribution of this paper is section 1  which presents three algorithms for computing leximin-optimal solutions  the first one being entirely original  and the other ones adapted from existing works. the proposed algorithms have been implemented and tested within a constraint programming system. section 1 presents an experimental comparison of these algorithms.
1 background on social choice theory
we first introduce some notations. calligraphic letters  e.g. x  will stand for sets. vectors will be written with an arrow
 e.g. 뫸x    or between brackets   will be used as a shortcut for   x will stand for the vector composed by each element of  뫸x rearranged in increasing order. we will write x뫺i the ith component of vector  뫸x 뫺. finally  the interval of integers between k and l will be written .
1 collective decision making and welfarism
let n be a set of n agents  and s be a set of admissible alternatives concerning all of them  among which a benevolent arbitrator has to choose one. the most classical model describing this situation is welfarism  see e.g.  keeney and raiffa  1; moulin  1  : the choice of the arbitrator is made on the basis of the utility levels enjoyed by the individual agents and on those levels only. each agent i 뫍 n has an individual utility function ui that maps each admissible alternative s 뫍 s to a numerical index ui s . we make here the classical assumption that the individual utilities are comparable between the agents1. thereforeeach alternative s can be attached to a single utility profile. according to welfarism  comparing two alternatives is performed by comparing their respective utility profiles.
모a standard way to compare individual utility profiles is to aggregate each of them into a collective utility index  standing for the collective welfare of the agents community. if g is a well-chosen aggregation function  we thus have a collective utility function uc that maps each alternative s to a collective utility level uc s  = g u1 s  ... un s  . an optimal alternative is one of those maximizing the collective utility.
1 the leximin preorder as a fairness and efficiency criterion
the main difficulty of equitable decision problems is that we have to reconcile the contradictory wishes of the agents. since generally no solution fully satisfies everyone  the aggregation function g must lead to fair and pareto-efficient1 compromises.
모the problem of choosing the right aggregation function g is far beyond the scope of this paper. we only describe the two classical ones corresponding to two opposite points of view on social welfare1: classical utilitarianism and egalitarianism. the rule advocated by the defenders of classical utilitarianism is that the best decision is the one that maximizes the sum of individual utilities  thus corresponding to g = + . however this kind of aggregation function can lead to huge differences of utility levels among the agents  thus ruling out this aggregator in the context of equitable decisions. from the egalitarian point of view  the best decision is the one that maximizes the happiness of the least satisfied agent  thus corresponding to g = min . whereas this kind of aggregation function is particularly well-suited forproblemsin which fairness is essential  it has a major drawback  due to the idempotency of the min operator  and known as  drowning effect  in the community of fuzzy csp  see e.g. dubois and fortemps  1  . indeed  it leaves many alternatives indistinguishable  such as for example the ones with utility profiles 
and  even if the second one appears to be

1
 in other words  they are expressed using a common utility scale. 1
모모a decision is pareto-efficient if and only if we cannot strictly increase the satisfaction of an agent unless we strictly decrease the satisfaction of another agent. pareto-efficiency is generally taken as a basic postulate in collective decision making. 1
모모compromises between these two extremes are possible. see e.g.  moulin  1  page 1  or  yager  1   owa aggregators .
much better than the first one. in other words  the min aggregation function can lead to non pareto-optimal decisions  which is not desirable.
모the leximin preorder is a well-known refinement of the order induced by the min function that overcomes this drawback. it is classically introduced in the social choice literature  see  moulin  1   as the social welfare ordering that reconcile egalitarianism and pareto-efficiency  and also in fuzzy csp  fargier et al.  1 . it is defined as follows:
definition 1  leximin preorder  moulin  1   let  뫸x and  뫸y be two vectors of and  뫸y are said leximinindifferent  written  x 몲leximin  y   if and only if  뫸x 뫺 =  뫸y 뫺. the vector  뫸y is leximin-preferred to  뫸x  written 뫸 x  leximin
뫸 y   if and only if  such that 
. we write for  뫸x  leximin  뫸y or  뫸x 몲leximin  뫸y . the binary relation  is a total preorder.
in other words  the leximin preorder is the lexicographic preorder over ordered utility vectors. for example  we have
.
모a known result is that no collective utility function can represent the leximin preorder1  unless the set of possible utility profiles is finite. in this latter case  it can be represented by the following non-linear functions:
 adapted for leximin from a remark in  frisch et al.  1   and  where q   1 is large enough
 moulin  1 . using this kind of functions has however a main drawback: it rapidly becomes unreasonable when the upper bound of the possible values of  뫸x increases. moreover  it hides the semantics of the leximin preorder and hinders the computational benefits we can possibly take advantage of.
모in the following  we will use the leximin preorder as a criterion for ensuring fairness and pareto-efficiency  and we will be seeking the non-dominated solutions in the sense of the leximin preorder. those solutions will be called leximinoptimal. this problem will be expressed in the next section in a cp framework.
1 constraint programming and leximin-optimality
the constraint programming framework is an effective and flexible tool for modeling and solving many different combinatorial problems such as planning and scheduling problems  resource allocation problems  or configuration problems. this paradigm is based on the notion of constraint network  montanari  1 . a constraint network consists of a set of variables x = {x1 ... xp}  in the following  variables will be written with uppercase letters   a set of associated domains d = {dx1 ... dxp}  where dxi is the set of possible values for xi  and a set of constraints c  where each c 뫍 c specifies a set of allowed tuples r c  over a set of variables x c . we make the additional assumption that all the domains are in n  and we will use the following notations:
.
모an instantiation v of a set s of variables is a function that maps each variable x 뫍 s to a value v x  of its domain dx. if s = x  this instantiation is said to be complete  otherwise it is partial. if  the projection of an instantiation of s over s is the restriction of this instantiation to s and is written. an instantiation is said to be consistent if and only if it satisfies all the constraints. a complete consistent instantiation of a constraint network is called a solution. the set of solutions of  x d c  is written sol x d c . we will also write v x 뫹 a  the instantiation v where the value of x is replaced by a.
모given a constraint network  the problem of determining whether it has a solution is called a constraint satisfaction problem  csp  and is np-complete. the csp can be classically adapted to become an optimization problem in the following way. given a constraint network  x d c  and an objective variable o 뫍 x  find the value m of do such that m = max{v o  | v 뫍 sol x d c }. we will write max x d c o  for the subset of those solutions that maximize the objective variable o.
모expressing a collective decision making problem with a numerical collective utility criterion as a csp with objective variable is straightforward: consider the collective utility as the objective variable  and link it to the variables representing individual utilities with a constraint. however this cannot directly encode our problem of computing a leximin-optimal solution  which is a kind of multicriteria optimization problem. we introduce formally the maxleximincsp problem as follows :
definition 1  maxleximincsp problem  input: a constraint network  x d c ; a vector of variables
  called an objective vector.
output:  inconsistent  if sol x d c  =  . otherwise a so-
모모모모모모모모모모모모모모모모 뫸	 뫸 lution v such that.
모we describe in the next section several generic constraint programming algorithms that solve this problem. the first one is entirely original  and the other ones are based on existing works that are adapted to fit with our problem.
1 proposed algorithms
1 using a cardinality combinator
our first algorithm is based on an iterative computation of the components of the leximin-optimal vector. it first computes the maximal value y1 such that there is a solution v with  i  y1 뫞 v ui   or in other words  where by convention the value of  y1 뫞 v ui   is 1 if the inequality is satisfied and 1 otherwise1. then  after having fixed this value for y1  it computes the maximal value y1 such that there is a solution v with   and so on until the maximal value yn such that there is a solution v with
.
모to enforce the constraint on the yi  we make use of the meta-constraint atleast  derived from a cardinality combinator introduced by  van hentenryck et al.  1   and present in most of cp systems:
definition 1  meta-constraint atleast  let 붞 be a set of p constraints  and be an integer. the meta-constraint atleast 붞 k  holds on the union of the scopes of the constraints in 붞  and allows a tuple if and only if at least k constraints from 붞 are satisfied.
모due to its genericity  this meta-constraint cannot provide very efficient filtering procedures. in our case where the constraints of 붞 are linear  this meta-constraint is simply a counting constraint  and bound-consistency can be achieved in o n . the specific meta-constraint atleast can also be implemented with a set of linear constraints  garfinkel and nemhauser  1  p.1   by introducing n 1 variables {붟1 ... 붟n}  and a set of linear constraints {x1 + 붟1y 뫟
n
.
모our first approach for computing a leximin-optimal solution is presented in algorithm 1.

algorithm 1: computation of a leximin-optimal solution using a cardinality combinator.
input : a const. network	n output: a solution to the maxleximincsp problem
1 if solve x d c  =  inconsistent  return  inconsistent ;
;
1 for i 뫹 1 to n do
1xi 뫹 xi 1 뫋 {yi};
1	with;
1
{atleast {yi 뫞 u1 ... yi 뫞 un} n i+1 };
1vb i  뫹 maximize xi di ci yi ;
1di 뫹 di with dyi 뫹 {vb i  yi };
1 return;

모the functionssolve and maximize  the detail of which is the concern of solving techniques for constraints satisfaction problems  of lines 1 and 1 respectively return one solution v 뫍 sol x d c   or  inconsistent  if such a solution does not exist   and an optimal solution
 or  inconsistent  if sol xi di ci  =   . we assume - contrary to usual constraint solvers - that these two functions do not modify the input constraint network.
a1a1a1o11o11o11모the following example illustrates the behavior of the algorithm. it is a simple resource allocation problem  where 1 objects must be allocated to 1 agents  with the following constraints: each agent must get one and only one object  and one object cannot be allocated to more than one agent  i.e. a perfect matching agent/objects . a utility is associated with each pair  agent object  with respect to the array above.
모this problem has 1 feasible solutions  one for each permutation of    producing the 1 utility profiles shown in the columns of the following array:
p1p1p1p1p1p1u1111u1111u1111모the algorithm runs in 1 steps: step 1: after having introduced one variable y1  we look for the maximal value of
y1 such that each  at least 1  agent gets at least y1. we find
. the variable y1 is fixed to this value  implicitly removing profiles p1 and p1. step 1: after having introduced one variable y1  we look for the maximal value such that at least 1 agents get at least y1. we find. the variable y1 is fixed to this value  implicitly removing profile p1. step 1: after having introduced one variable y1  we look for the maximal value such that at least 1 agent gets at least y1. we find. only one instantiation maximizes y1: p1. finally  the returned leximin-optimal allocation is: a1 뫹 o1  a1 뫹 o1 and a1 뫹 o1.
proposition 1 if the two functions maximize and solve are both correct and both halt  then algorithm 1 halts and solves the maxleximincsp problem.
모in the next proofs  we will writefor respectively sol xi di ci  and. we will also write  for the same sets of solutions projected on xj  with j   i . we can notice that sol1 = sol x d c   and that.
lemma 1 let  뫸x be a vector of size n. at least n   i + 1 components of  뫸x are greater than or equal to x뫺i .
the proof of this useful lemma is obvious  so we omit it.
lemma 1 ifthen is well-defined and not equal to  inconsistent .
proof: let  suppose that  and let v i  뫍
. then extending v i  by instantiating leads to a solution of  xi di ci   only one constraint has been added and it is satisfied by the latter instantiation . therefore and  if maximize is correct   inconsistent  and. so 
. it proves lemma 1 by induction. 
lemma 1 if  then .
모proof: we have  and   since from  we just add a constraint . more generally    and  soli+1 뫻xj  
lemma 1 if is equal to.
모proof: for all  is a solution of soli by lemma 1. by lemma 1   satisfies the cardinality constraint of iteration i  and is then a solution of soli. by definition of function maximize  we thus have  뫸
	.	since vb i  yi  = vb n  yi   we have
	since	is a solution of soln  at least n   i + 1 numbers from
 
vector vb n  u   are greater than or equal to vb n  yi . at least the n i+1 greatest numbers from must then be greater than or equal to . these components include  which
모모모모모모모모모모  뫺	 leads to vb n  yi  뫞 vb n  u  i   proving the lemma.
we can now put things together and prove proposition 1.
모proof of proposition 1: if sol x d c  =    and if solve is correct  then algorithm 1 obviously returns  inconsistent . otherwise  following lemma 1  it outputs an instantiation  vb n  뫻x which is  according to lemma 1  a solution of  x1 d1 c1  =  x d c .
	suppose	that	there	is	a v	뫍	sol x d c  such	that
 뫸
	 n 	. then following definition 1 	
                  뫸	 뫸 such that.
let be the extension of v respectively instantiating y1 ...yi 1
 뫸 뫺
to vb n  y1  ...vb n  yi 1  and yi to v u  i . following lemma 1 
	 n 	j	 n 	j. by gathering all the previous equalities 
	뫸 	뫸 
we have. we also have. by lemma 1   j 뫞 i at least n j +1 numbers from  are greater than or equal to
  proving that satisfies all the cardinality constraints at iteration i. since it also satisfies each constraint in c and maps each
variable of xi to one of its possible values  it is a solution of soli 
	 뫸	 뫸
and. it contradicts the definition of maximize  proving the proposition 1. 
1 using a sorting constraint
our second algorithm is directly based on the definition 1 of the leximin preorder  which involves the sorted version of the
objective vector. this can be naturally expressed in the cp
 뫸
paradigm by introducing a vector of variables y and enforc-
 뫸  뫸
ing the constraint sort u   y   which is defined as follows:
 뫸
definition 1  constraint sort  let x andbe two vectors of variables of the same length  and v be an instantiation.
the constraint sortholds on the set of variables be-
            뫸 ing either in x or in  and is satisfied by v if and only if
 뫸
is the sorted version of v x  in increasing order.
모this constraint has been particularly studied in two works  which both introduce a filtering algorithm for enforcing bound consistency on this constraint. the first algorithm
comes from  bleuzen-guernalec and colmerauer  1  and 뫸 
runs in o nlogn   n being the size of x .  mehlhorn and thiel  1  designed a simpler algorithm that runs in plus the time required to sort the interval endpoints of x  which can asymptotically be faster than o nlogn .

algorithm 1: computation of a leximin-optimal solution using a sorting constraint.
input : a const. network output: a solution to the maxleximincsp problem
1 if solve x d c  =  inconsistent  return  inconsistent ;
;
;
 뫸  뫸
sort u   y  };
1 for i 뫹 1 to n do
1 vb i  뫹 maximize;
1dyi 뫹 {vb i  yi };
1 return;

proposition 1 if the two functions maximize and solve are both correct and both halt  then algorithm 1 halts and solves the maxleximincsp problem.
모proof: if sol x d c  =   and if solve is correct  then algorithm 1 obviously returns  inconsistent . we will suppose in the following thatand we will use the following notations: soli andare the sets of solutions of  respectively at the beginning and at the end of iteration i.
모we have obviously  which proves that if     then the call to maximize at line 1 does not return  inconsistent   and  . thus vb n  is well-defined  and obviously  vb n  뫻x is a solution of  x d c .
모we note  the instantiation computed by the last maximize in algorithm 1. suppose that there is an instantiation
	 뫸	 뫸	+
v 뫍 sol x d c  such that vb u    leximin v u  . we define v
 뫸 뫺
the extension of	that instantiates each yi to v u  i . then  due
                  	+ to constraint sort  bv y   and v  y   are the respective sorted verb 뫸 u   and v+ u . following definition 1  there is an i 뫍
sion of v 1 n   1 such that v+ yi+1 . due to line 1  we have 
vb i+1  yi+1 .	thus v+ is a solution in
with objective value strictly greater than  which contradicts the hypothesis about maximize. 
1 using a multiset ordering constraint
our third algorithm computing a leximin-optimal solution is perhaps the most intuitive one. it proceeds in a pseudo branch and bound manner: it computes a first solution  then tries to improve it by specifying that the next solution has to be better  in the sense of the leximin preorder than the currentone  and so on until the constraint network becomes inconsistent. this approach is based on the following constraint:
 뫸
definition 1  constraint leximin  let x be a vector of
          뫸 variables  뷂 be a vector of integers  and v be an instanti-
뫸  뫸 
ation. the constraint leximin  뷂   x  holds on the set of
뫸
  and is satisfied by v if and only if
뷂  leximin	 	 .
모although this constraint does not exist in the literature  the work of  frisch et al.  1  introduces an algorithm for enforcing generalized arc-consistency on a quite similar constraint: the multiset ordering constraint  which is  in the context of multisets  the equivalent of a leximax1 constraint on vectors of variables. at the price of some slight modifications  the algorithm they introduce can easily be used to enforce the latter constraint leximin.
proposition 1 if the function solve is correct and halts  then algorithm 1 halts and solves the maxleximincsp problem.
the proof is rather straightforward  so we omit it.
1 other approaches
in the context of fuzzy constraints  two algorithms dedicated to the computation of leximin-optimal solutions have been published by  dubois and fortemps  1 . these algorithms

algorithm 1: computation of a leximin-optimal solution in a branch and bound manner.
input : a const. network output: a solution to the maxleximincsp problem
1 vb 뫹 null; v 뫹 solve x d c ;
1 while  inconsistent  do
1vb 뫹 v;
1	c 뫹 c 뫋 {leximin;
1v 뫹 solve x d c ;
 null then return bv else return  inconsistent ;

work by enumerating  at each step  all the subsets of fuzzy constraints  corresponding to our agents  having a property connected to the notion of consistency degree.
모 ehrgott  1  p. 1  describes two very simple algorithms for solving the closely related  lexicographic maxordering  problem  that could be called  leximax-optimal  in our terms . however  they do not seem realistic in the context of combinatorial problems  since they are based on an enumeration of all utility profiles.
1 experimental results
the algorithms 1  1  1 and the first algorithm proposed in  dubois and fortemps  1  have been implemented and tested using the constraint programming tool choco  laburthe  1 . so as to test them on realistic instances  we have extracted  from a real-world problem  a simplified multiagent resource allocation problem. in this problem  the resourceis a set of objects o  that must be allocated to some agents under volume and consumption constraints. the individual utility functions are specified by a set of weights wa o  one per pair  agent object  : given an allocation of the objects  the individual utility of an agent i is the sum of the weights wi o of the objects o that she receives. the weights can be generated uniformly or can be concentrated around some powers of 1  so as to simulate some kind of priorities1.
모we have developed a customizable generator of random instances  available online1. we tested our algorithms on several instances  with very different characteristics  leading to very different kind of problems. here is a brief description of each kind of instances appearing in table 1  by default  the weights are non-uniformlydistributed  and the constraints are of medium tightness :
모 1  1 agents  1 objects.  1  1 agents  1 objects.  1  1 agents  1 objects.  1  1 agents  1 objects  low-tightness constraints.  1  1 agents  1 objects  hard-tightness constraints.  1  1 agents  1 objects  uniform weights  with low values   hard-tightness constraints.  1  1 agents  1 objects.
kindalgorithm 1  atleast algorithm 1  sort algorithm 1  leximin  dubois and fortemps  1 avgminmaxn%avgminmaxn%avgminmaxn%avgminmaxn%1.1.1.111111111111111.1.1.11111.111111111.1.1.1111.1.1.11111.11.1.1.11.1.1.11111.1.1.111111111.1.1.11111.1.1.11111.1111111table 1: cpu times  in seconds  and percentage of instances solved within 1 minutes for each algorithm. each algorithm has been run on 1 instances of each kind  on a 1ghz pentium m pc under linux.모the results from table 1 show that algorithm 1 has the best running times with most of the instances  followed by algorithm 1 which is almost as fast  but is less efficient when the number of agents increases  instances of kind 1   whereas algorithm 1 is better on this kind of instances. as expected  the algorithm from  dubois and fortemps  1  explodes when the number of equal components in the leximin-optimal vector increases  kinds  1  and  1  .
모these results must however be considered with care  since they are subject to our implementation of the filtering algorithms. in particular  not every optimizations given in  mehlhorn and thiel  1  for the constraint sort have been implemented yet. moreover  the running times are highly affected by the variable choice heuristics. in our tests  we used the following particular heuristics  that are specially efficient: choose as the next variable to instantiate the one that will the most increase the lowest objective value  in our application problem we first allocate the objects that have the highest weight for the currently least satisfied agent .
1 conclusion
the leximin preorder cannot be ignored when dealing with optimization problems in which some kind of fairness must be enforced between utilities of agents or equally important criteria. this paper brings a contribution to the computation of leximin-optimal solutions of combinatorial problems. it describes  in a constraint programming framework  three generic algorithms solving this problem. the first one  based on a cardinality combinator  is entirely new  and gives slightly better results than two algorithms based on the sort and leximin constraints.
