
traditionally  information extraction  ie  has focused on satisfying precise  narrow  pre-specified requests from small homogeneous corpora  e.g.  extract the location and time of seminars from a set of announcements . shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. this manual labor scales linearly with the number of target relations.
this paper introduces open ie  oie   a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiringany human input. the paper also introduces textrunner  a fully implemented  highly scalable oie system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries.
we report on experiments over a 1 1 web page corpus that compare textrunner with knowitall  a state-of-the-art web ie system.
textrunner achieves an error reduction of 1% on a comparable set of extractions. furthermore  in the amount of time it takes knowitall to perform extraction for a handful of pre-specified relations  textrunner extracts a far broader set of facts reflecting orders of magnitude more relations  discovered on the fly. we report statistics on textrunner's 1 1 highest probability tuples  and show that they contain over 1 1 concrete facts and over 1 1 more abstract assertions.
1 introduction and motivation
this paper introduces open information extraction  oie - a novel extraction paradigm that facilitates domainindependent discovery of relations extracted from text and readily scales to the diversity and size of the web corpus. the sole input to an oie system is a corpus  and its output is a set of extracted relations. an oie system makes a single pass over its corpus guaranteeing scalability with the size of the corpus.
　information extraction  ie  has traditionally relied on extensive human involvement in the form of hand-crafted extraction rules or hand-tagged training examples. moreover  the user is required to explicitly pre-specify each relation of interest. while ie has become increasingly automated over time  enumerating all potential relations of interest for extraction by an ie system is highly problematic for corpora as large and varied as the web. to make it possible for users to issue diverse queries over heterogeneous corpora  ie systems must move away from architectures that require relations to be specified prior to query time in favor of those that aim to discover all possible relations in the text.
　in the past  ie has been used on small  homogeneous corpora such as newswire stories or seminar announcements. as a result  traditional ie systems are able to rely on  heavy  linguistic technologies tuned to the domain of interest  such as dependency parsers and named-entity recognizers  ners . these systems were not designed to scale relative to the size of the corpus or the number of relations extracted  as both parameters were fixed and small.
　the problem of extracting information from the web violates all of these assumptions. corpora are massive and heterogeneous  the relations of interest are unanticipated  and their number can be large. below  we consider these challenges in more detail.
automation the first step in automating ie was moving from knowledge-based ie systems to trainable systems that took as input hand-tagged instances  riloff  1  or document segments  craven et al.  1  and automatically learned domain-specific extraction patterns. dipre  brin  1   snowball  agichtein and gravano  1   and webbased question answering systems  ravichandran and hovy  1  further reduced manual labor needed for relationspecific text extraction by requiring only a small set of tagged seed instances or a few hand-crafted extraction patterns  per relation  to launch the training process. still  the creation of suitable training data required substantial expertise as well as non-trivial manual effort for every relation extracted  and the relations have to be specified in advance.
corpus heterogeneity previous approaches to relation extraction have employed kernel-based methods  bunescu and mooney  1   maximum-entropy models  kambhatla  1   graphical models  rosario and hearst  1; culotta et al.  1   and co-occurrence statistics  lin and pantel  1; ciaramita et al.  1  over small  domain-specific corpora and limited sets of relations. the use of ners as well as syntactic or dependency parsers is a common thread that unifies most previous work. but this rather  heavy  linguistic technology runs into problems when applied to the heterogeneous text found on the web. while the parsers work well when trained and applied to a particular genre of text  such as financial news data in the penn treebank  they make many more parsing errors when confronted with the diversity of web text. moreover  the number and complexity of entity types on the web means that existing ner systems are inapplicable  downey et al.  1 .
efficiency knowitall  etzioni et al.  1  is a state-ofthe-art web extraction system that addresses the automation challenge by learning to label its own training examples using a small set of domain-independent extraction patterns. knowitall also addresses corpus heterogeneity by relying on a part-of-speech tagger instead of a parser  and by not requiring a ner. however  knowitall requires large numbers of search engine queries and web page downloads. as a result  experiments using knowitall can take weeks to complete. finally  knowitall takes relation names as input. thus  the extraction process has to be run  and rerun  each time a relation of interest is identified. the oie paradigm retains knowitall's benefits but eliminates its inefficiencies.
　the paper reports on textrunner  the first scalable  domain-independent oie system. textrunner is a fully implemented system that extracts relational tuples from text. the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. the main contributions of this paper are to:
  introduce open information extraction  oie -a new extraction paradigm that obviates relation specificity by automatically discovering possible relations of interest while making only a single pass over its corpus.
  introduce textrunner  a fully implemented oie system  and highlight the key elements of its novel architecture. the paper compares textrunner experimentally with the state-of-the-art web ie system  knowitall  and show that textrunner achieves a 1% relative error reduction for a comparable number of extractions.
  report on statistics over textrunner's 1 1 highest probability extractions  which demonstrates its scalability  helps to assess the quality of its extractions  and suggests directions for future work.
the remainderof the paper is organizedas follows. section
1 introduces textrunner  focusing on the novel elements of its architecture. section 1 reports on our experimental results. section 1 considers related work  and the paper concludes with a discussion of future work.
1 open ie in textrunner
this section describes textrunner's architecture focusing on its novel components  and then considers how textrunner addresses each of the challenges outlined in section 1. textrunner's sole input is a corpus and its output is a set of extractions that are efficiently indexed to support exploration via user queries.
textrunner consists of three key modules:
1. self-supervised learner: given a small corpus sample as input  the learner outputs a classifier that labels candidate extractions as  trustworthy  or not. the learner requires no hand-tagged data.
1. single-pass extractor: the extractor makes a single pass over the entire corpus to extract tuples for all possible relations. the extractordoesnot utilize a parser. the extractor generates one or more candidate tuples from each sentence  sends each candidate to the classifier  and retains the ones labeled as trustworthy.
1. redundancy-based assessor: the assessor assigns a probability to each retained tuple based on a probabilistic model of redundancy in text introduced in  downey et al.  1 .
below  we describe each module in more detail  discuss
textrunner's ability to efficiently process queries over its extraction set  and analyze the system's time complexity and speed.
1 self-supervised learner
the learner operates in two steps. first  it automatically labels its own training data as positive or negative. second  it uses this labeled data to train a naive bayes classifier  which is then used by the extractor module.
　while deploying a deep linguistic parser to extract relationships between objects is not practical at web scale  we hypothesized that a parser can help to train an extractor. thus  prior to full-scale relation extraction  the learner uses a parser  klein and manning  1  to automatically identify and label a set of trustworthy  and untrustworthy extractions. these extractions are are used as positive  or negative  training examples to a naive bayes classifier.1 our use of a noisetolerant learning algorithm helps the system recover from the errors made by the parser when applied to heterogeneousweb text.
　extractions take the form of a tuple t =  ei ri j ej   where ei and ej are strings meant to denote entities  and ri j is a string meant to denote a relationship between them. the trainer parses several thousand sentences to obtain their dependency graph representations. for each parsed sentence  the system finds all base noun phrase constituents ei.1 for each pair of noun phrases  ei ej  i   j   the system traverses the parse structure connecting them to locate a sequence of words that becomes a potential relation ri j in the tuple t. the learner labels t as a positive example if certain constraints on the syntactic structure shared by ei and ej are met. these constraints seek to extract relationships that are likely to be correct even when the parse tree contains some local errors; if any constraint fails  t is labeled as a negative instance. some of the heuristics the system uses are:
  there exists a dependency chain between ei and ej that is no longer than a certain length.
  the path from ei to ej along the syntax tree does not cross a sentence-like boundary  e.g. relative clauses .
  neither ei nor ej consist solely of a pronoun.
　once the learner has found and labeled a set of tuples of the form t =  ei ri j ej   it maps each tuple to a feature vector representation. all features are domain independent  and can be evaluated at extraction time without the use of a parser. examples of features include the presence of part-of-speech tag sequences in the relation ri j  the numberof tokens in ri j  the number of stopwords in ri j  whether or not an object e is found to be a proper noun  the part-of-speech tag to the left of ei  the part-of-speech tag to the right of ej. following feature extraction  the learner uses this set of automatically labeled feature vectors as input to a naive bayes classifier.
　the classifier output by the learner is language-specific but contains no relation-specific or lexical features. thus  it can be used in a domain-independent manner.
　prior to using a learning approach  one of the authors invested several weeks in manually constructing a relationindependent extraction classifier. a first attempt at relation extraction took the entire string between two entities detected to be of interest. not surprisingly  this permissive approach captured an excess of extraneous and incoherent information. at the other extreme  a strict approach that simply looks for verbs in relation to a pair of nouns resulted in a loss of other links of importance  such as those that specify noun or attribute-centric properties  for example   oppenheimer  professor of  theoretical physics  and  trade schools  similar to  colleges . a purely verb-centric method was prone to extracting incomplete relationships  for example   berkeley  located  bay area  instead of  berkeley  located in  bay area . the heuristic-based approaches that were attempted exposed the difficulties involved in anticipating the form of a relation and its arguments in a general manner. at best  a final handbuilt classifier  which is a natural baseline for the learned one  achieved a mere one third of the accuracy of that obtained by the learner.
1 single-pass extractor
the extractor makes a single pass over its corpus  automatically tagging each word in each sentence with its most probable part-of-speech. using these tags  entities are found by identifying noun phrases using a lightweight noun phrase chunker.1 relations are found by examining the text between the noun phrases and heuristically eliminating non-essential phrases  such as prepositional phrases that overspecify an entity  e.g. scientists from many universities are studying ...  is analyzed as  scientists are studying...    or individual tokens  such as adverbs  e.g. definitely developed  is reduced to  developed  .
　for each noun phrase it finds  the chunker also provides the probability with which each word is believed to be part of the entity. these probabilities are subsequently used to discard tuples containingentities found with low levels of confidence. finally  each candidate tuple t is presented to the classifier. if the classifier labels t as trustworthy  it is extracted and stored by textrunner.
1 redundancy-based assessor
during the extraction process  textrunner creates a normalized form of the relation that omits non-essential modifiers to verbs and nouns  e.g. was developed by as a normalized form of was originally developed by. after extraction has been performed over the entire corpus  textrunner automatically merges tuples where both entities and normalized relation are identical and counts the number of distinct sentences from which each extraction was found.
　following extraction  the assessor uses these counts to assign a probability to each tuple using the probabilistic model previously applied to unsupervised ie in the knowitall system. without hand-tagged data  the model efficiently estimates the probability that a tuple t =  ei ri j ej  is a correct instance of the relation ri j between ei and ej given that it was extracted from k different sentences. the model was shown to estimate far more accurate probabilities for ie than noisyor and pointwise mutual informationbased methods downey et al.  1 .
1 query processing
textrunner is capable of responding to queries over millions of tuples at interactive speeds due to a inverted index distributed over a pool of machines. each relation found during tuple extraction is assigned to a single machine in the pool. every machine then computes an inverted index over the text of the locally-stored tuples  ensuring that each machine is guaranteed to store all of the tuples containing a reference to any relation assigned to that machine.1
　the efficient indexing of tuples in textrunner means that when a user  or application  wants to access a subset of tuples by naming one or more of its elements  the relevant subset can be retrieved in a manner of seconds  and irrelevant extractions remain unrevealed to the user. since the relation names in textrunner are drawn directly form the text  the intuitions that they implicitly use in formulating a search query are effective. querying relational triples will be easier once textrunner is able to know which relations are synonymous with others. however  asking the user to  guess the right word  is a problem that is shared by search engines  which suggests that it is manageable for na： ve users.

niques enables textrunner to be more robust to the highly diverse corpus of text on the web. 1
　　the inverted index itself is built using the lucene open source search engine.
　finally  textrunner's relation-centric index enables complex relational queries that are not currently possible using a standard inverted index used by today's search engines. these include relationship queries  unnamed-item queries  and multiple-attribute queries  each of which is described in detail in  cafarella et al.  1 .
1 analysis
tuple extraction in textrunner happens in o d  time  where d is the number of documents in the corpus. it subsequently takes o t logt  time to sort  count and assess the set of t tuples found by the system. in contrast  each time a traditional ie system is asked to find instances of a new set of relations r it may be forced to examine a substantial fraction of the documents in the corpus  making system run-time o r ， d . thus  when d and r are large  as is typically the case on the web  textrunner's ability to extract information for all relations at once  without having them named explicitly in its input  results in a significant scalability advantage over previous ie systems  including knowitall .
　textrunner extracts facts at an average speed of 1 cpu seconds per sentence. compared to dependency parsers which take an average of 1 seconds to process a single sentence  textrunner runs more than 1 times faster on our corpus. on average  a web page in our corpus contains 1 sentences  making textrunner's averageprocessing speed per document 1 cpu seconds and the total cpu time to extract tuples from our 1 million web page corpus less than 1 cpu hours. because the corpus is easily divided into separate chunks  the total time for the process on our 1 machine cluster was less than 1 hours. it takes an additional 1 hours for textrunner to merge and sort the extracted tuples. we compare the performance of textrunner relative to a state-of-the-art web ie system in section 1.
　the key to textrunner's scalability is processing time that is linear in d  and constant in r . but  as the above measurements show  textrunner is not only scalable in theory  but also fast in practice.
1 experimental results
we first compare recall and error rate of textrunner with that of a closed ie system on a set of relations in section 1. we then turn to the fascinating challenge of characterizing the far broader set of facts and relations extracted by textrunner in section 1.
1 comparison with traditional ie
one means of evaluating open ie is to compare its performance with a state-of-the-art web ie system. for this comparison we used knowitall  etzioni et al.  1   a unsupervised ie system capable of performing large-scale extraction from the web. to control the experiments  both textrunner and knowitall were tested on the task of extracting facts from our 1 million web page corpus.
　since knowitall is a closed ie system  we needed to select a set of relations in advance. we randomly selected the following 1 relations that could be found in at least 1 sentences in the corpus  manually filtering out relations that were overly vague  e.g. includes  :
  proper noun   acquired   proper noun  
  proper noun   graduated from   proper noun  
  proper noun   is author of   proper noun  
  proper noun   is based in   proper noun  
  proper noun   studied   noun phrase  
  proper noun   studied at   proper noun  
  proper noun   was developed by   proper noun  
  proper noun   was formed in   year  
  proper noun   was founded by   proper noun  
  proper noun   worked with   proper noun  
　table 1 shows the average error rate over the ten relations and the total number of correct extractions for each of the two systems. textrunner's average error rate is 1% lower than knowitall's  but it finds an almost identical number of correct extractions. textrunner's improvement over knowitall can be largely attributed to its ability to better identify appropriate arguments to relations.
　still  a large proportion of the errors of both systems were from noun phrase analysis  where arguments were truncated or stray words added. it is difficult to find extraction boundaries accurately when the intended type of arguments such as company names  person names  or book titles is not specified to the system. this was particularly the case for the authorof relation  where many arguments reflecting book titles were truncated and the error rate was was 1% for textrunner and 1% for knowitall. with this outlier excluded  the average error rate is 1% for textrunner and 1% for
knowitall.
even when extracting information for only ten relations 
textrunner's efficiency advantage is apparent. even though they were run over the same 1 million page corpus  textrunner's distributed extraction process took a total of 1 cpu hours  to perform extraction for all relations in the corpus at once  whereas knowitall  which analyzed all sentences in the corpus that potentially matched its rules  took an average of 1 hours per relation. in the amount of time that knowitall can extract data for 1 pre-specified relations  textrunner discovers orders of magnitude more relations from the same corpus.
　beyond the ten relations sampled  there is a fundamental difference between the two systems. standard ie systems can only operate on relations given to it a priori by the user  and are only practical for a relatively small number of relations. in contrast  open ie operates without knowing the relations a priori  and extracts information from all relations at once. we consider statistics on textrunner's extractions next.
1 global statistics on facts learned
given a corpus of 1 million web pages  containing 1 million sentences  textrunner automatically extracted a set of 1 million tuples at an extraction rate of 1 tuples per sentence.
when analyzing the output of open ie system such as
textrunner  several question naturally arise: how many of the tuples found represent actual relationships with plausible arguments  what subset of these tuples is correct  how many of these tuples are distinct  as opposed to identical or synonymous  answering these questions is challenging due to both the size and diversity of the tuple set. as explained
averagecorrecterror rateextractionstextrunner1%1knowitall1%1table 1: over a set of ten relations  textrunner achieved a 1% lower error rate than knowitall  while finding approximately as many correct extractions.
below  we made a series of estimates and approximations in order to address the questions.
　as a first step  we restricted our analysis to the subset of tuples that textrunner extracted with high probability. specifically  the tuples we evaluated met the following criteria: 1  textrunner assigned a probability of at least 1 to the tuple; 1  the tuple's relation is supported by at least 1 distinct sentences in the corpus; 1  the tuple's relation is not found to be in the top 1% of relations by number of supporting sentences.  these relations were so general as to be nearly vacuous  such as  np1  has  np1  . this filtered set consists of 1 million tuples containing 1 distinct relation strings. this filtered set is the one used in all the measurements described in this section.
estimating the correctness of facts
we randomly selected four hundred tuples from the filtered set as our sample. the measurements below are extrapolated based on hand tagging the sample. three authors of this paper inspected the tuples in order to characterize the data extracted by textrunner. each evaluator first judged whether the relation was well-formed. a relation r is considered to be well-formed if there is some pair of entities x and y such that  x r y   is a relation between x and y . for example   fci  specializes in  software development  contains a wellformed relation  but  demands  of securing  border  does not. if a tuple was found to possess a well-formed relation  it was then judged to see if the arguments were reasonable for the relation. x and y are well-formed arguments for the relation r if x and y are of a  type  of entity that can form a relation  x r y  . an example of a tuple whose arguments are not well-formed is  1  dropped  instruments .
　we further classified the tuples that met these criteria as either concrete or abstract. concrete means that the truth of the tuple is grounded in particular entities  for example   tesla  invented  coil transformer . abstract tuples are underspecified  such as  einstein  derived  theory   or refer to entities specified elsewhere  but imply properties of general classes  such as  executive  hired by  company .
　finally  we judged each concrete or abstract tuple as true or false  based on whether it was consistent with the truth value of the sentence from which it was extracted. figure 1 summarizes this analysis of the extracted tuples.
　textrunner finds 1 million facts having both a wellformed relation and arguments and probability at least 1. of those facts  1% were deemed to be correct according to human reviewers. within a given relation  an average of 1% of the tuples are concrete facts of which 1% are correct  and 1% are abstract facts of which 1% are correct. concrete facts are potentially useful for information extraction or question answering  while abstract assertions are useful for

figure 1: overview of the tuples extracted from 1 million web page corpus. 1 million well-formed tuples are found having probability − 1. of those  textrunner finds 1 million concrete tuples with arguments grounded in particular real-world entities  1% of which are correct  and 1 million tuples reflecting abstract assertions  1% of which are correct.
ontology learning and other applications. of course  only a small subset of the universe of tuples would be of interest in any particular application  e.g.  the tuples corresponding to the relations in the experiment in section 1 .
estimating the number of distinct facts
of the millions of tuples extracted by textrunner  how many reflect distinct statements as opposed to reformulations of existing extractions  in order to answer this question  one needs to be able to detect when one relation is synonymous with another  as well as when an entity is referred to by multiple names. both problems are very difficult in an unsupervised  domain-independent context with a very large number of relations and entities of widely varying types. in our measurements  we were only able to address relation synonymy  which means that the measurements reported below should be viewed as rough approximations.
　in order to assess the number of distinct relations found by textrunner  we further merged relations differing only in leading or trailing punctuation  auxiliary verbs  or in leading stopwords such as that  who and which. for example   are consistent with  is merged with    which is consistent with . we also merged relations differing only by their use of active and passive voice  e.g.  invented is merged with was invented by . this procedure reduced the number of distinct relations to 1% of the number before merging.
　even after the above merge  the question remains: how many of the relation strings are synonymous  this is exceedingly difficult to answer because many of the relations that textrunner finds have multiple senses. the relation developed  for example  may be a relation between a person and an invention but also between a person and a disease. it is rare to find two distinct relations that are truly synonymous in all senses of each phrase unless domain-specific type checking is performed on one or both arguments. if the first argument is the name of a scientist  then developed is synonymous with invented and created  and is closely related to patented. without such argumenttype checking  these relations will pick out overlapping  but quite distinct sets of tuples.1
　it is  however  easier for a human to assess similarity at the tuple level  where context in the form of entities grounding the relationship is available. in order to estimate the number of similar facts extracted by textrunner  we began with our filtered set of 1 million tuples. for each tuple  we found clusters of concrete tuples of the form  e1 r e1   e1 q e1  where  that is tuples where the entities match but the relation strings are distinct. we found that only one third of the tuples belonged to such  synonymy clusters .
　next  we randomly sampled 1 synonymy clusters and asked one author of this paper to determinehow many distinct facts existed within each cluster. for example  the cluster of 1 tuples below describes 1 distinct relations r1 and r1 between bletchley park and station x as delineated below:
	r1	 bletchley park 	was location of	  station x 
	r1	 bletchley park 	being called	  station x 
	r1	 bletchley park 	  known as	  station x 
	r1	 bletchley park 	  codenamed	  station x 
　overall  we found that roughly one quarter of the tuples in our sample were reformulations of other tuples contained somewhere in the filtered set of 1 million tuples. given our previous measurement that two thirds of the concrete fact tuples do not belong to synonymy clusters  we can compute that  or roughly 1% of the tuples found by
textrunner express distinct assertions. as pointed out earlier  this is an overestimate of the number of unique facts because we have not been able to factor in the impact of multiple entity names  which is a topic for future work.
1 related work
traditional  closed  ie work was discussed in section 1. recent efforts  pasca et al.  1  seeking to undertake largescale extraction indicate a growing interest in the problem.
　this year  sekine  sekine  1  proposed a paradigm for  on-demand information extraction   which aims to eliminate customization involved with adapting ie systems to new topics. using unsupervised learning methods  the system automatically creates patterns and performs extraction based on a topic that has been specified by a user.
　also this year  shinyama and sekine  shinyama and sekine  1  described an approach to  unrestricted relation discovery  that was developed independently of our work  and tested on a collection of 1 newswire articles.
this work contains the important idea of avoiding relationspecificity  but does not scale to the web as explained below.
　given a collection of documents  their system first performs clustering of the entire set of articles  partitioning the corpus into sets of articles believed to discuss similar topics. within each cluster  named-entity recognition  co-reference resolution and deep linguistic parse structures are computed and then used to automatically identify relations between sets of entities. this use of  heavy  linguistic machinery would be problematic if applied to the web.
　shinyama and sekine's system  which uses pairwise vector-space clustering  initially requires an o d1  effort where d is the number of documents. each document assigned to a cluster is then subject to linguistic processing  potentially resulting in another pass through the set of input documents. this is far more expensive for large document collections than textrunner's o d+t logt  runtime as presented earlier.
　from a collection of 1 newswire articles  shinyama and sekine were able to discover 1 relations. while it is difficult to measure the exact number of relations found by textrunner on its 1 1web page corpus  it is at least two or three orders of magnitude greater than 1.
1 conclusions
this paper introduces open ie from the web  an unsupervised extraction paradigm that eschews relation-specific extraction in favor of a single extraction pass over the corpus during which relations of interest are automatically discovered and efficiently stored. unlike traditional ie systems that repeatedly incur the cost of corpus analysis with the naming of each new relation  open ie's one-time relation discovery procedure allows a user to name and explore relationships at interactive speeds.
　the paper also introduces textrunner  a fully implemented open ie system  and demonstrates its ability to extract massive amounts of high-quality information from a nine million web page corpus. we have shown that textrunner is able to match the recall of the knowitall state-of-the-art web ie system  while achieving higher precision.
　in the future  we plan to integrate scalable methods for detecting synonyms and resolving multiple mentions of entities in textrunner. the system would also benefit from the ability to learn the types of entities commonly taken by relations. this would enable the system to make a distinction between different senses of a relation  as well as better locate entity boundaries. finally we plan to unify tuples output by textrunner into a graph-based structure  enabling complex relational queries.
acknowledegments
we thank the following people for helpful comments on previous drafts: dan weld  eytan adar  and doug downey.
　this research was supported in part by nsf grants iis-1 and iis-1  darpa contract nbchd1  onr grant n1-1 as well as gifts from google  and carried out at the university of washington's turing center. the first author of this paper received additional support thanks to a google anita borg memorial scholarship.
