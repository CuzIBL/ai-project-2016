 
a heuristic improvement technique referred to as multi-dimensional heuristics is presented. instead of only applying the heuristic between two states x1 and x1  when a distance estimate of x1 is needed  this technique uses a reference state r and applies the heuristic function to {x1 r  and  x'1 r  and compares the resulting values. if two states are close to each other  then they should also be approximately equidistant to a third reference state. it is possible to use many such reference states to improve some heuristics. the reference states are used to map the search into an n-dimensional search space. the process of choosing reference states can be automated and is in fact a learning procedure. test results using the 1-puzzle are presented in support of the effectiveness of multi-dimensional heuristics. this method has been shown to improve both a weak 1-puzzle heuristic  the tile reversal heuristic  as well as the stronger manhattan distance heuristic. 
1 introduction 
traditional heuristic search involves ordering state expansions relative to their estimated costs of participating in a solution. this cost is computed by a function f = g + h where g is the known cost  depth  arid h is an estimate of the remaining cost or distance to the goal  hart et a/.  1 . this paper proposes a general method of improving h. instead of estimating h by evaluating a given state x with respect to the goal g. several new reference states are used to gain perspective  nelson  1 . the relative position of x and g among the reference states will be used to estimate the distance between x and g. 
　assuming h is of a general nature and can be used to estimate the distance between any two states in the search space  then h can be used to estimate the distances from the reference states to both g and x. for each reference state ri -  a difference value ari = | h x  ri  - h g  ri  | is computed  which is the absolute value of the difference between the estimated distances from x to ri and from g to ri. note that 
1 	search 
heuristic searching 
lawrence j. henschen dept. of electrical engineering and computer science northwestern university evanston  illinois 	1 
if the goal is used as a reference state rk  then ark is 
just the traditional heuristic estimate h. these difference values ari  where 1   i   n and n is the number of reference states  will be used to give a better estimate of the actual distance from the x to g. the new estimate will be referred to as hn and will be proportional to the values of ar1  ar1 . .. arn as will be discussed in section 1. the method for combining the ar values to get hu is based on mapping the search space into an n-dimensional space which is why hn is referred to as a multi-dimensional heuristic or mdh. another key part of the calculation of hn is that the ar values are independent of each other and can be computed simultaneously on a multiprocessor architecture. also h g r i   is fixed and need only be computed once for each ri. 
　we would hope that a smaller ari value for reference state ri would indicate that x is closer to g. the intuition is that if x is close to g  then both states should be approximately the same distance from any given reference state  thus yielding a small ar value. the farther x is from g  then the greater the ar value will be. figure 1 illustrates this. in this example only one reference 

figure 1: ordering nodes using reference nodes 
node is being used. nodes x  x'  and g are estimated to be 1  1 and 1 units away from r 1 respectively. the  rx value for x is 1 while  r1  for x' is 1. with respect to r1 we see that x' has a smaller ar  value than does x which is obviously farther away from g than x'. also note that because h1 will be proportional to  r1  
　
1
　of course  if x lies directly opposite ri.  from g  it may have a small  ri - and still be far away from g. for each reference node there will be such a region of declination relative to a given goal  nelson  1 . the fix for this involves adding more reference nodes and positioning these reference nodes so their  estimated  distances to each other is relatively large and their  estimated  distances to the goal node varies. 
　the calculation of hn and the reasons for viewing the search space as an n-dimensional space are explained in section 1. section 1 reports on some empirical data using mdhs for the 1-puzzle. concluding remarks and ideas for further research are contained in section 1. 
1 viewing the search as an n-space 
at this point we demonstrate why a planar view cannot be used satisfactorily to compute a distance from x to g using reference nodes and explain why the term  multi-dimensional  has been chosen to refer to this idea of using many reference states to estimate a distance to the goal. figure 1 shows a typical case in using mdhs. the distance in question is between x and g. estimates of the distances between the reference states to x and g are known. this planar or 1-dimensional view yields many possible values for the estimated distance between the states x and g. two of these distance estimates are shown in figure 1. the solid lines indicate one possible layout while the dotted lines show another. geometry can be used to explain the difficulty here even though the concept of an angle in a problem space is undefined. because the angle values in figure 1 are not known  an infinite number of distance estimates can be found for xg by varying the angles lr1xr1 and lr1gr1  or equivalently moving r  or r1  while still preserving all the distances between x and g and the reference states. if these angles are set by using h to estimate the distance from r  to r1  the resulting value of r1 r1 may lead to other inconsistencies. for example we know that r1   a+d  but perhaps  the estimated value of r1  h{r1  r1    a +d. the computation of these different distances is relatively expensive and it is not known which to use as an estimate. that is  should h1 be xg xg  or one of the other possible distance values. the addition of a third reference state does not remedy this problem of multiple values for xg  nelson  1 . 
　this inability to uniquely determine a distance for xg in the planar view is the impetus for a different model of the search space and reference states. this new model uses the reference states to set up an n-dimerisional search space. the number of dimensions is equal to the number of reference states. the current and the goal states are mapped into this n-space and their distance estimate is computed using; the standard distance 
formula  the mapping of the states into the n-space is done by letting the estimated distance of the goal  current state  to any given reference point ri be the coordinate value of the goal  current state  with respect to the ri axis. the example shown in figure 1 would be mapped into a 1-space depicted by figure 1. 
　this representation solves the problems associated with the planar view. there is only one distance value associated with any two states mapped into the n-space. the computational cost of hn is also quite reasonable. 
this model yields the desired property that for any given  r i   if  ri decreases while everything else is constant  then so does the distance estimate between the two states. this requirement was mentioned in section 1 which stated that hn should be proportional to the at  values. 
　one quest ion has been raised as to how the mdh value should be computed if the original h consists of k components. although this would really have to be examined on a case by case basis  there are really two reasonable approaches to consider: 
1. ignore that h is a vector of components since it is still a distance estimator and can be used to estimate distances between the reference nodes. 
1. analyze each component of h to see which components  if any  can be improved by using the multidimensional scheme. for each component which can 
	nelson and henschen 	1 
be improved using mdhs  pick a set of  possibly distinct  reference nodes and redefine h such that the appropriate components are actually mdhs. for example let 

where hi is replaced with the improved mdh component h-hi . 
probably most heuristics which are built with a number of different components are already quite good and may not be able to achieve much of an improvement by using the first approach which ignores the different components. it may be more likely to improve such a heuristic by focusing on improving specific components of the heuristic with mdhs. the improvement of a specific component in this case would of course be defined in terms of how this component affects the accuracy of 
h. 
　for any given state space problem and the h being used to estimate distances to the reference states  there are at least two questions that need to be answered in order to apply mdhs: 
1. what should the value of n be  that is how many reference states should be used  and 
1. which reference states should be used to approximate the n-space. 
the next section addresses these questions. 
1 test results 
the multi-dimensional approach was tested on the 1puzzle using the a* algorithm as described by  rich  1 . the goal of the testing was not to show that there exists an mdh which is more effective than any other existing heuristic  but rather to show that mdhs may be used to improve some existing heuristics. therefore  initially a heuristic was chosen for the 1-puzzle which had room for much improvement  this heuristic being a tile reversal count. later the multi-dimensional scheme was tested on a much stronger 1-puzzle heuristic  the manhattan distance heuristic. 
1 	tile reversals and m d h s 
the first set of tests used h as the number of tile reversals. a tile reversal in state a with respect to state b 
has the meaning that a i  = b j  and b i  = a j  where i and j are adjacent tiles  de champeaux and sint  1 . the rationale for the heuristic is that if a reversal occurs between a state and the goal  then it takes many moves to get the tile positioned correctly. the problem with tile reversals is that they do not occur often  so most of the heuristic values are 1  and the search just flattens out into a breadth first search. usually tile reversals are one component of a more sophisticated heuristic for the 1-puzzle. note also that this choice for h is general in that it may be applied to any two nodes in the 1-puzzle search space. 
　the reference states were picked by first generating a number of states in a random fashion from which the 
1 	search 
reference states would be chosen. then several hundred legal states  i.e. reachable from the goal  for which the distances to the goal were known were evaluated with an mdh using all the randomly generated reference states. 
 these legal states were found with their distances by generating nodes in reverse from the goal node.  ideally an mdh would have reference states that yield distance estimates proportional to the actual distances. therefore a score was kept to determine the predictive accuracy of each reference state. this was done by first computing the average of h x  / hn x  for every x where x is one of the several hundred legal states  h x  is the actual distance from x to the goal  and hn x  is the mdh value for x using the n randomly generated reference states. once this average is computed  h x  / hn x  was  retrieved  recomputed for every state x. the ratio for each state x was compared with the average ratio taken for all the states. if this ratio was close to the average ratio  then every reference node which participated in the calculation received a  good  mark. if the ratio was not close to the average ratio  then all the reference nodes which helped to calculate it received a  bad  mark. at the end the score was tallied by subtracting the number of bad marks from the number of good marks. the score for a reference state indicates whether that ri helps or hinders the mdh in achieving the goal of yielding distance estimates proportional to actual distances. these scores were computed for each of the possible reference states and a few of these states with the lowest scores  net goodness values  were eliminated from the set of possible reference states. this process was repeated many times with each iteration eliminating possible reference states until there remained 1 possible reference states. this learning procedure  which is described more formally in  nelson  1   is general and could be applied to other problem domains as long as states can be generated in reverse order from the goal state. 
   figure 1 shows the results from tests run on 1 puzzles using from 1 to 1 reference states. the goal state was added as a reference state and was ordered as the first reference state  thus the 1-dimensional trial is exactly identical to a traditional a* search using tile reversals as the h. the number of nodes expanded is inversely proportional to the number of dimensions used by the mdh with the exception of some relative maxima at dimensions 1 and 1. with the addition of each of the first 1 dimensions  the search space is cut in half. the graph in figure 1 shows that for these puzzles the best value for n is probably 1  since there is relatively little improvement in adding any dimension past the fourth dimension. 
　the initial set of tests for the tile reversal case were run on puzzles with solution paths of length 1. although the average path lengths for the 1-puzzle is about 1  these shorter puzzles were simple enough so that every dimension was capable of finding a solution without running out of memory. using the same 1 reference nodes more tests were run on puzzles with solution paths of length 1  or a 1% increase from the previous tests. the results were consistent with the tests run on shorter puzzles. the biggest difference is that no puzzles were solved 
　
by dimensions 1 or 1 because the algorithm ran out of memory. only one puzzle was solved in dimension 1. in the higher dimensions we see a dramatic decrease in the number of nodes expanded as extra reference nodes are added. these results are shown in figure 1. although dimension 1 is no longer a relative maxima  dimension 1 still is. another difference in these tests is that it appears that the best value for n would be 1. dimension 1 is a relative minima but by going out to dimension 1 the average number of nodes expanded is cut in half as opposed to using only 1 reference nodes. if the puzzle lengths are increased further the results are similar in that there is the same downward trend in the number of nodes expanded as extra reference nodes are added. as would also be expected the lowest dimension capable of solving these more difficult puzzles also increases as the path length increases. 
　the test results demonstrate how it may be possible to develop an mdh for a given problem domain. in this case the rather simple concept of tile reversals was by itself an inadequate heuristic. however with the addition of the multiple reference states to map the search into an n-space  the use of tile reversals as the h was a much better heuristic for solving 1-puzzles. this suggests that mdhs might prove especially useful for search spaces where relatively little is known about the problem. a simple heuristic h could be derived and a corresponding mdh might still be effective even if h was not. 
1 manhattan distance and m d h s 
an interesting question is whether mdiis could be used to improve a good heuristic for the 1-puzzle. some tests were run to determine the effect of mdhs when applied to the manhattan distance heuristic. this heuristic is an admissible heuristic that is also quite good; it gives the number of moves to reach the goal if the tiles could be moved  through  each other. 
　the learning procedure used to find reference nodes for tile reversals proved ineffective for the manhattan distance. instead another  learning  procedure was used to choose reference nodes which would improve the manhattan heuristic. reference nodes 1 and 1 were set to be the goal and a  reversed  goal respectively. now the 1 randomly generated nodes in  korf  1  were targeted as the superset for the additional reference nodes to be added. each of the 1 random puzzles was chosen as reference node 1 and the resulting mdh was tested on solving 1 trial puzzles. after looping through all 1 possible choices for r1 it was found that puzzle 1 minimized the number of node expansions using 1 dimensions. puzzle 1 was therefore chosen as r1. this process was repeated 1 more times to pick  dimensions  reference nodes 1 through 1. this resulted in adding 1 distinct reference nodes  selected from the 1 randomly generated puzzles  which minimize node expansions when solving the 1 test puzzles. the addition of these 1 reference nodes with the original two yields an mdii with 1 dimensions. figure 1 shows the result of solving the 1 puzzles using these reference nodes. this new mdh shows an improvement with the addition of every reference node. it also turns out that the path lengths were optimal for every puzzle solved which is surprising since this mdii is obviously not admissible. 
　it is a reasonable question to wonder if the improvement offered by mdhs to the manhattan distance resulted from extra weight being placed on the heuristic. the heuristic distance estimate  h  obviously increases as more reference nodes are added  while the known 
	nelson and henschen 	1 
　
distance component  g  remains the same. to explore this possibility some tests were run where all 1 reference nodes were chosen to be the goal state. the result of doing this is really just an increase in weight. there was no improvement offered by using the goal as the reference nodes. for these trials dimension 1 is the minimum or optimal mdh. it also turned out that almost half of the solutions found using these reference nodes were not optimal with respect to the length of their solution paths. thus we can conclude that the improvement is not the result of a weight change in the heuristic. 
　the results in figure 1 look very promising. the set of reference nodes form an mdh which significantly improves an already good heuristic. however the manner in which the reference nodes were picked suggest the possibility that these reference nodes are  tuned  or suitable for only these 1 puzzles. after all  reference nodes 1 through 1 were chosen by a trial and error process which involved solving each of these 1 puzzles hundreds of times. if the reference nodes are only suitable for these puzzles  it is quite obvious that the overhead in choosing the reference nodes far outweighs the benefit provided by using them. 
　in order to test the general effectiveness of these reference nodes on other puzzles  some more tests were run using the mdh created by these 1 reference nodes to solve randomly generated 1-puzzles. most randomly generated puzzles are not solvable by a*  using the manhattan distance heuristic with or without this mdh instance  because of exponential memory requirements. a  pre-screening  was conducted on these randomly generated puzzles by using the manhattan distance to estimate a minimum path length. any puzzle whose lower bound was greater than 1 was immediately discarded. 
1 	search 
1 puzzles were generated with a lower bound path length   1. of these 1 puzzles  only 1 were able to be successfully solved by any of the 1 dimensions. the path lengths of these puzzles ranged from 1 to 1 with the average being 1. the worst case  with respect to the number of node expansions  for each of the 1 puzzles occurred in dimension 1  while the best cases were distributed over dimensions 1 through 1. for these randomly generated puzzles the mdh proved very successful. a graph of the results is shown in figure 1. there is a significant downward trend in the average number of nodes expanded as extra reference nodes or dimensions are added. so it appears that the reference nodes which were originally found for 1 specific puzzles are also capable of reducing search costs for randomly generated puzzles. in fact no randomly generated puzzle was found to expand fewer nodes in dimension 1  which is equivalent to using a* without mdhs  than in any of the higher dimensions. of course many puzzles were not solvable for any of the 1 dimensions. additionally the path lengths were again optimal in every dimension for at least 1 of the 1 puzzles. the seventh puzzle was not solvable for dimension 1  the only provably admissible dimension  and therefore the optimal path length for this puzzle is not known. 
　the reasons for the success of mdhs in improving the 1-puzzle manhattan distance heuristic is not as intuitive as to why mdhs improve the 1-puzzle tile reversal heuristic. although the existence of a tile reversal between two states a and b is known to imply a significant difference between states a and b  the occurrence of a tile reversal is not likely. using mdhs with numerous reference states in effect multiplies the likelihood of detecting tile reversals enabling the detection of previously 
　
　mdhs have been tested on the 1-puzzle for 1 different heuristics. mdhs were first shown to offer a significant improvement in decreasing the number of nodes expanded when a tile reversal count is used as the h. these tests demonstrated that a weak heuristic based on a simple concept might be greatly improved by using the multi-dimensional scheme. furthermore once an h is chosen  the process of creating the mdh  that is the picking of the reference nodes  can be automated. this may prove very beneficial for a sort of  computer-aided'' generation of heuristics for problems where there exist easily identifiable simple heuristic information  but for which no good heuristics are known. the second set of tests experimented with using mdhs to improve the already good manhattan distance heuristic. mdhs were shown to be capable of improving this heuristic as well. this is somewhat surprising since the manhattan distance heuristic is known to be one of the best 1-puzzle heuristics and shows that an mdh improvement is not exclusive to weak heuristics. an additional interesting result of the testing is that optimal solutions were found with respect to path lengths. this was unexpected since the higher dimensions of both mdh instances  particularly the manhattan distance mdh  obviously overestimate distance values. 
　further research concerning mdhs is planned in several different areas. in addition to the multi-dimensional model  there may be other models which could effectively represent  the concept of using reference states for heuristic improvement. new and improved learning procedures could be developed to pick reference states. it would also be nice to identify other problems for which mdhs may offer an improvement. 
acknowledgments 
rich korf has been generous in allowing us to use some of his programs which included a random 1-puzzle generator. 
