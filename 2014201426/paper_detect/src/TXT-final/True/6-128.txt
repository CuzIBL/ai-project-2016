 
we propose an answer to the  what is ai   question  namely  that al is really  or at least really ought in significant part to be  psychometric ai  pai . along the way  we: set out and rebut five objections to pa1; describe peri  a robot in our lab who exemplifies pai; and briefly treat the future of psychometric ai  first by pointing toward some promising pal-based applications  and then by raising some of the  big  philosophical questions the success of psychometric ai will raise. 
1 introduction 
what exactly is ai  we'd be willing to wager that many of you have been asked this question - by colleagues  reporters  friends and family  and others. even if by some fluke you've dodged the question  perhaps you've asked it yourself  maybe even perhaps  in secret moments  if you're a practitioner  to yourself  without an immediate answer coming to mind. at any rate  ai itself repeatedly asks the question - as the first chapter of many ai textbooks reveals. in this paper we want to propose an answer  namely  that al is really  or at least really ought in significant part to be  psychometric ai  sometimes just 'pai1  rhymes with for short . we also want to tell you something about both phri  a robot in our lab who exemplifies pai  and the future we envision for pai. 
　our plan herein is as follows. in the next section  1  we answer the  what is ai   question from the standpoint of psychometric ai  and introduce some of the tests at the heart of this brand of ai. in section 1 we rebut some objections that will inevitably be brought against psychometric al. the rebuttal to the first of these objections will reveal the foundation for pai: the turing test  tt  and its more demanding cousin  the total tt  ttt . in section 1 we introduce you to peri. our penultimate section briefly treats the future of psychometric al  first by pointing toward some promising pai-based applications  and then by raising some of the  big  philosophical questions the success of psychometric ai will raise. we end by addressing a second round of objections  formulated by those who read earlier versions of the present paper. 
ontologies and foundations 
1 what is ai  psychometric ai as an answer 
presumably the 'a' part of 'a1' isn't the challenge: we seem to have a fairly good handle on what it means to say that something is an artifact  or artificial.  we can ignore here conundrums arising from self-reproducing systems  systems that evolve without human oversight  etc.  it's the t part that seems to throw us for a bit of a loop. what's intelligence  this is the big  and hard  question. innumerable answers have been given  but most thinkers seem to forget that there is a particularly clear and straightforward answer available  courtesy of the field that has sought to operationalizc the concept in question; that field is psychometrics. psychomctrics is devoted to systematically measuring psychological properties  usually via tests. these properties include the one most important in the present context: intelligence. in a nutshell  then  the initial version of our account of intelligence is this: some agent is intelligent if and only if it excels at all established  validated tests of intelligence.  this account is inadequate  for reasons we explain below before supplanting it with a more sophisticated one.  ai then reduces to psychometric ai: the field devoted to building a computational system able to score well on such tests. this may strike you as a preposterously narrow definition of ai. the first step  in a series taken as this paper unfolds  in diffusing this attitude is to take a look at some intelligence tests  some of which  we surmise  are a good deal richer than you might at present think. 

figure i: sample problem solved by evan's  1  analogy program. a is to b as c is to ...  
　in the early days of ai  psychometric ai was at least implicitly entertained. after all  in the mid 1s  the largest lisp program on earth was evans' 1 analogy program  which could solve problems like those shown in figure 1. evans himself predicted that systems able to solve such problems would  be of great practical importance in the near future   and he pointed out that performance on such tests is often regarded to be the  touchstone  of human intelligence. unfortunately  analogy simply hasn't turned out to be the first system in a longstanding  comprehensive research program: after all  we find ourselves  at present  trying to start that very program. what went wrong  well  certainly psychometric ai would be patently untenable if the tests upon which it is based consist solely of geometric analogies. this point is entailed by such observations as this one from fischler & firschein 1: 
if one were offered a machine purported to be intelligent  what would be an appropriate method of evaluating this claim  the most obvious approach might be to give the machine an iq test. ... however   good performance on tasks seen in iq tests would not  be completely satisfactory because the machine would have to be specially prepared for any specific task that it was asked to perform. the task could not be described to the machine in a normal conversation  verbal or written  if the specific nature of the task was not already programmed into the machine. such considerations led many people to believe that the ability to communicate freely using some form of natural language is an essential attribute of an intelligent entity. 
  fischler & firschein  1   p. 1  
　unfortunately  while this quote helps explain why analogy in and of itself didn't ignite a research program to drive ai  fischler & firschein apparently are familiar with only what we call narrow  as opposed to broad  intelligence tests. arguably  this distinction goes back to descartes'  descartcs.haldane.ross.voll  p. 1  claim that while a machine could in the future pass any test for a particular mental power  no machine could pass a test for any mental power whatsoever. this rather speculative claim can be seen to be cashed out in two different and longstanding views of intelligence within psychology: thurstone's 1 and spearman's 1. in thurstone's view  put barbarically   intelligence consists in the capacity to solve a broad range of problems  e.g.  verbal analogies  geometric analogies  digit recall  story understanding  commonsense reasoning  arithmetical calculation  and so on. in spearman's view  again  put roughly   intelligence is a specific  narrow  underlying capacity  notoriously  referred to as g  summoned up to the highest degree when solving highly focused and abstract problems like those analogy solved. the most famous set of  g-relevant  problems is the tightly guarded and much-used raven's 1 progressive matrices  or just 'rpm.' an example of a problem from rpm is shown in figure 1  which is taken from  carpenter et al.  1 . as part of peri  we have built theorem prover-based agents able to infallibly crack not only geometric analogies  but rpm items they have never seen before  figure 1 shows part of an ottrr  wos etal  1  proof that serves to identify the solution .  the algorithms deployed by these agents were devised as part of contracted research for the educational testing service  or ets.  it is much harder to build agents able to solve broad tests of intelligence ets tests that include sub-tasks demanding the kinds of communicative capacities fischler & firschein have in mind. 

figure 1: simple rpm problem  cracked  by ra1r lab's peri 
　psychological corporation's popular wais  wechsler adult intelligent scale  is a paradigmatic example of a broad intelligence test that includes the full array of  thurstonean  sub-tests  the complete array is enumerated in baron 1 . while we don't have enough space to explain all these sub-tests  we point out that fischler & firschein's criticism of simplistic versions of psychometric ai certainly evaporates in the face of the wais. that this is so follows from the sub-test on the wais known as  comprehension   in which  in ordinary conversation  subjects are asked fiendishly tricky  general knowledge  questions. for example  examinees might be asked to explain why the tires on automobiles are made of rubber  rather than  say  plastic. perhaps you'll agree that such a question would make a nice challenge to any system purported to have commonsense intelligence. were cycorp  http://www.cyc.com  to herald a system having general  common-sense intelligence  the wais would be a vehicle for verification. there are other sub-tests on the wais that are just as challenging. 
　with help from additional researchers in the rair lab  we are in the process of  cracking  the wais  by way of the design and construction of peri. the sub-test we have cracked most recently is  block design:  peri  when given any configuration of blocks in the space of all possible ones  deduces the solution in under a second of cpu time  and proceeds to assemble this solution with its manipulator/gripper. in section 1 we provide some details about perl's exploits.  readers wanting to peek ahead should see figures 1  1  1  and 1.  at present we are tackling the much more difficult subtest  picture arrangement   which requires of examinees that they arrange jumbled snapshots to form coherent stories.  for readers wanting to look ahead  a home-grown example is shown in figure 1. for legal reasons  actual wais examples cannot be shown.  here our research attempts to make use of prior work in story generation  e.g.  bringsjord & ferrucci 1 . 
　we anticipate that some will insist that intelligence tests  even broad ones  are still just too narrow  when put in the context of the full array of cognitive capacities seen in homo sapiens. well  we agree! but we are understanding intelligence  from the standpoint of psychometrics  to include many varied 
ontologies and foundations 

figure 1: examinees must arrange to make a coherent story. 
tests of intellectual ability. accordingly  we now move to a less naive definition of pai: 
psychometric al is the field devoted to building information-processing entities capable of at least solid performance on all established  validated tests of intelligence and mental ability  a class of tests that includes not 
just the rather restrictive iq tests  but also tests of artistic 
and literary creativity  mechanical ability  and so on. 
　this definition replaces the old  provisional one: the new definition  when referring to tests of mental ability  is referring to much more than iq tests. for example  following sternberg  someone with much musical aptitude would count as brilliant even if their scores on tests of  academic  aptitude  e.g.  on the sat  gre  lsat  etc.  were low. but specifically what sorts of additional tests would be involved  we don't have space to canvass the myriad tests that psychometricians have validated. to give a quick sense of how latitudinarian  and therefore challenging  psychometric ai is intended to be  we mention the torrance tests of creative thinking  torrance  1; 1 . this test comes in both  visual  and  verbal  forms. in the visual form  test takers are asked to draw pictures  often by enriching existing sketches ; in the verbal form  test takers are asked to write - creatively. for example  one of the activities subjects engage in on the verbal test is the following. 
most people throw their tin cans away  but they have thousands of interesting and unusual uses. in the spaces below and on the next page  list as many of these interesting and unusual uses as you can think of. do not limit yourself to any one size of can. you may use as many cans as you like. do not limit yourself to the uses you have seen or heard about; think about as many possible new uses as you can.  from the verbal version of  torrance  
1 .  
　believe it or not  after the torrance test is administered  one can send it out to be professionally judged by fixed and reliable criteria. building an intelligent agent capable of scoring well on the torrance test is a tall order  but some researchers hitherto unaware of psychometric al are apparently in the process of working specifically toward this aim  and variants thereof  e.g. see bringsjord & ferrucci 1 and bringsjord 1 . 
ontologies and foundations 
1 objections 
objection j:  can you be serious  pai is so idiosyncratic!  recall that we mentioned at the outset that ai textbooks tend to be self-reflective. let's look a bit at some of these volumes. doing so will reveal that psychometric ai is far from idiosyncratic  because it is  at least arguably  a generalization of a longstanding answer to the  what is ai   question  namely  the answer that appeals to the turing test  tt  and its relatives. to see this answer in action  let's turn to aima  russell & norvig  1   which tells us that there arc four general  different ways to define intelligence  pp. 1 : we can say that an entity is intelligent if and only if it  thinks like humans    acts like humans    thinks rationally   or  acts rationally.  
　russell & norvig 1 opt for the fourth route  but we want to draw your attention to the first and third ones  which don't seem exactly promising  because 'thinking' is probably no clearer than 'intelligence.' however  turing came up with the test that now bears his name precisely because he found the concept of thinking hopelessly vague. as russell and norvig point out  tt and other more stringent tests  e.g.  stevan harnad's 1 total turing test  in which a passing robot must display not only human-level linguistic performance  but sensorimotor performance at this level as well   provide a way to clarify the first route in the quartet. specifically  it can be said that ai is the field devoted to building artificial entities  or systems  able to pass ttt. 
　we could go on to present case after case in which tt or variants are used to define ai  e.g.  see ginsberg's 1 introductory al text   but perhaps you will agree that whether or not you affirm the tt-based answer to the  what is ai   question  you have to admit that turing  by the lights of a good many  is definitely on to something. but what  exactly  well  no doubt there is more than one reason for the apparent immortality of the tt. but surely one reason for its longevity is simply that it's a clean  crisp test. tests are attractive in no small part because they have determinate starts and ends  and yield concrete verdicts that can silence unproductive debate.  of course  computability theory relics heavily on tests. e.g.  when we say that a set a is decidable  we are among other things saying that we can successfully apply a test to some ob-
ject o in order to determine whether or not o a.  turing's 1 goal in his seminal  computing machinery and intelligence  was indeed to supplant the maddeningly vague  can a computing machine think   with  can a computing machine pass the turing test   we're not concerned here with whether he reached his goal. rather  the idea is that pai extends and clarifies turing's approach. 
　objection 1:  but don 't tt and ttt subsume psychometric ai    we offer a three-part rebuttal:  1  in an attempt to build a robot able to pass for a human  certainly  divide and conquer  is a prudent strategy  and psychometric ai automatically enforces that methodology: tests are crafted to check for different capacities in focused fashion. since all topics are fair game in tt and ttt  they have much less value as engineering goals.  1  there is another reason why pai can be viewed as a helpful generalization of the turing/harnad approach. this reason is that  let's face it  neither tt nor ttt is currently a meaningful objective: they are both gi-
　
gantically ambitious goals  so much so that no one has really made any progress toward reaching them.  at turing 1  the conference held at dartmouth to commemorate both turing's 1 prediction that a tt-passing machine would be created before the new millennium and al's inaugural 1 conference at dartmouth  no system better at conversation than a toddler appeared.  psychometrics offers us an abundance of tests  many of which are reasonable challenges for an artificial agent. psychometric al appropriates these tests.  1  the tests in question haven't been picked out of thin air. these tests allow us to look into the heart of mind/brain. that's the beauty and power of tests  when they have been empirically and statistically validated. tests have a gem-like character  and pa1 piggybacks on this. given this  if we build an agent able to pass established tests  we can be fairly confident that as a welcome side-effect we will have an agent capable of many significant higher-level feats. 
　objection 1:  but ai has applications that need to be built!  of course. and turing wasn't saying all that anybody would work on was passing the tt. after all  few work directly on building an agent able to pass it. an agent able to pass the tests in question will have the capacity to provide the desired applications. momentarily we present some applications we are working toward that stem directly from pal 
　objection 1:  but pai will only tap logicistai!  actually  the tasks in question will unite logicist and sub-symbolic approaches. for example   block design  on the wais requires robotic manipulation  and therefore cognitive processing that is rapid and reactive. this processing is not reasoning-based in peri. the same can be said for peri's vision and speech systems. 
　objection 1:  butplenty of al researchers don't do pai'  this objection can be fleshed out as follows:  1 fail to sec how you can be seriously proposing a foundation for ai  given that plenty of ai researchers don't deal with tests of any kind. would we be wrong in regarding such people to be doing ai   
　this is an important objection. it raises the general question of whether we are promoting psychometric ai as descriptive or prescriptive. do we mean to suggest that ai is in fact pai  or do we mean to maintain that al ought to be  or at least be viewed as  pai  
　the answer is this: our overall claim about psychometric al is that it's both descriptive and prescriptive. if an ai application is sufficiently ambitious  we hold that psychometric ai will automatically kick in: the theory is descriptive  in that the developers will inevitably modularize the challenge  and set about building sub-agents that successfully negotiate the tests associated with these modules. on the other hand  if the al application is a  humble  one  it probably itself constitutes a miniature test: our claim is once again that pai is descriptive. but how is it then that the theory is also prescriptive  well  again  we submit that r&d dedicated to building testtaking agents will produce building blocks for accomplishing some very helpful systems. some examples of such systems are presented in section 1. but first  as planned  we say a few things about peri. 
1 the robot peri 
peri  whose name stands for  psychometric experimental 
robotic intelligence   is a system capable of logic/reasoning  vision  physical manipulation  speech  and hearing. it is important to note that peri was not designed to simulate how a human thinks. our work in connection with this robot is ai  not cognitive modeling. 
　peri interacts with the environment via its fivc-degree-offreedom vertically articulated mechanical arm  a scorboter ix model from the intelitek corporation  and a pneumatic two-finger parallel grippcr which can either be completely open or closed around an object. its vision is based' on the output of a sony black-and-white xc1 video camera and cognex mvs-1m frame grabber. peri's speech is transmitted through computer speakers and it hears through a microphone attached to the speaker's head while using the dragon naturally-speaking professional solutions version 1 software. at the core of peri resides its brain and nervous system - a complex lisp program and an associated scorbot advanced control language library. due to the lack of space  this is as much technical detail as we can prudently reveal about peri. 
　the rest of this section will focus on the block design task and peri's success with it. peri can not only solve the particular block design problems in the wais  but any block design puzzle given to it. for legal reasons we are unable to disclose the block design task from the wais  therefore we discuss another similar yet even more challenging block puzzle  courtesy of the binary arts corporation .  in the intents of space  and in keeping with the  philosophical foundations  category under which this paper falls  we leave aside the mathematization of the wais block puzzle and the harder one from binary arts. for ease of exposition  we refer to the space in question as s.  

figure 1: one puzzle block folded out 
　in this particular puzzle there are a total of four blocks  each of which is different. there are only three colors  pink  purple  and yellow  used to make the design on each side; that design is either a combination of up to four triangles or one solid color. this is done merely to give a specific color to each edge of a block. in fact  all the sides of all four cubes are different from one another. this means there are a total of 1 unique sides. refer to figures 1 and 1 for a closer look. 
　the task is  after having been presented with the cubes for the first time  to place them together so that every edge that touches another is the same color. all cubes must be used  but obviously there are quite a few different solutions. one solution is shown in figure 1. does the task sound easy to you  if so  you are supremely confident. while peri solves the hard-
ontologies and foundations 
　
1  scattered 
est configuration in a matter of seconds  after having visually examined the blocks  in our experience it can take a clever human several long minutes  if not a half hour  to conquer the entire task. figure 1 shows peri assembling a solution. 

figure 1: a solution to binary arts corp.'s puzzle 1 
　the same basic algorithm  described below  that peri uses for the wais block design task can be used to solve any such puzzle in the overall mathematical space s 1d regular solid with each side having a characteristic capturable in extensional first-order fashion . the first step is to encode the pieces as declarative information about geometric shapes in perl's  mind.  before the test is administered to a human participant  he is given a chance to examine the blocks  or other shapes   as would peri. what follows is a general algorithm which peri can apply to any 1d physical shapes within a limit of size  i.e.  which its gripper can properly hold and manipulate . 
general algorithm fur  cracking  any 1d block design in s 
1. document original pieces by color  dimension  characteristics on each side  and total number. 
1 input goal configuration  a picture that will need to be deciphered  
1. partition the goal into distinguishable pieces that match similar as-pects of those that are available pieces in the original. start first with the entire goal as one piece. some aspects of the pieces may be ignored at this stage. 
1. once the goal has been partitioned  determine if original puzzle pieces match the partitioned ones if not  go back to step 1 and partition it into two pieces  three pieces  etc.  an exceedingly large cutoff is imposed to handle cases where no partitioning is valid  otherwise non-halting is possible.  if there are matching original puzzle pieces to the goal partitioning  go on to step 1. 
1. start with a goal piece and match it to an original piece that has not yet been used there will be a finite search for each matching piece since step 1 has been passed  indicating the goal is known to be solvable. when a match is found  the onginal piece is physically added to the solution  arena  by changing the po-
sitioning of the onginal piece as well as the angle  side  or any other necessary aspect. continue the present step until no more pieces in the goal exist that need a match. 
　in the case of the puzzle from the binary arts corporation  the goal configuration is not specified ahead of time  as it is in the wais . therefore  we assume that the goal is given ahead of time and are then able to use the above general algorithm without any modification. peri can solve the original version of binary arts' puzzle; however  the original version doesn't correspond to the wais block design task  the cracking of which was our goal. the next challenge peri faces is the more 
ontologies and foundations 
difficult  picture arrangement  subtask of the wais  which is discussed in the next section. 

figure 1: peri solving a block design puzzle 
1 the future of psychometric ai 
we very briefly offer some thoughts on the future of pai  from the standpoints of both applications and philosophical foundations. 
　much of our prior al work in automated test generation has been supported by ets  in connection with wide-scale  high stakes  tests. our efforts to crack the wais should lead to systems able to generate both new items for other established tests  and new tests. in general  it seems to us that there is a growing symbiosis between ai and the test industry. it isn't just the generation side that holds promise: essays written by examinees taking the educational testing service's gmat  graduate management admission test  are now read and graded by machine  though there is human input as well   and this trend promises to accelerate. another application is the use of tests as security devices. for example  our work in psychometric ai yields a fairly rigorous account  presenta-

tests a machine can solve  versus what tests positively stump machines  but are solvable by humans. this account can be used  for instance  to devise tests designed to weed out troublesome softbots from human users in situations where hackers attempt to build bots in order to overwhelm online systems  e.g.  polling systems . 
　we believe that the  picture arrangement  task  see again figure 1  provides a helpful microworld for another application: the problem of threat anticipation in the the intelligence community. currently  ets is supporting research in our lab devoted to augmenting the predictive power of intelligence analysts  as that power is described  for example  in  heuer  1 . however  we intend to pursue a new dimension in this work  one based on the notion that predicting what  say  a terrorist will do is in significant measure the completion of a story based on  snapshots  earlier in the  narrative  in which the terrorist is an actor. our attempt to enable peri to crack  picture arrangement  is the first step in the exploration of this new dimension. in our initial work on this problem  once a snapshot in a group like that shown in figure 1 is selected  a search for a consistency proof that a particular successor is possible under narrative constraints is fired. if a proof is found  the successor is selected  and the process iterates. narrative constraints are declarative formalizations of plots  themes  and characters. 
　
　we end by briefly discussing two philosophical issues raised by psychometric ai. 
　it's perhaps not uninteresting to ponder the philosophical consequences of a future peri able to excel on all established tests. would we declare peri in this case to be a bona fide genius  or would we instead infer that since a  mere  machine is displaying such mastery  human intelligence must go well beyond what can be tested for  we don't have the answers to such questions  but we will be doing our best  through concrete engineering  to raise these questions. we suspect that the degree to which these questions are debated will relate directly to the degree to which our engineering  and those joining us  succeeds. 
　finally  we point out that psychometric ai seems to clarify the dividing line between so-called  strong  and  weak  ai. this is so because pai is fundamentally driven by how things appear  not by whether or not some invisible property is in play.  weak  ai strives for artifacts which  as a matter of directly observable fact  display certain behaviors.  strong  ai  on the other hand  aims for machines having such mysterious properties as consciousness and qualia. the distinction can be traced back to the  objection from consciousness  in turing's 1 defense of tt. the objection is famously encapsulated in professor jefferson's lister oration of 1: not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt  and not by the chance fall of symbols  could we agree that machine equals brain - that is  not only write it  but know that it had written it. no mechanism could feel  and not merely artifically signal  an easy contrivance  pleasure at its successes  grief when its valves fuse  be warmed by flattery  be made miserable by mistakes  be charmed by sex  be angry or depressed when it cannot get what it wants   p. 1 of turing 1  
　turing responds:  this argument appears to be a denial of the validity of our test.  precisely! he goes on to stick to his guns: he proclaims that if the computer produces the kind of language normally taken to justify ascriptions of consciousness  and he gives examples of such language in connection with a deep understanding of shakespeare   we ought to go ahead and make those ascriptions: we ought to hold that the computer is conscious. psychometric ai and  weak  ai are firmly in this camp. if there is some sensible  established test for consciousness  if appearance is both demanded and supplied  then members of this camp confidently declare the underlying properties to be in place. in light of this  we readily admit that some proponents of  strong  ai will not be fans of psychometric ai. our readers must judge whether or not that is a virtue or a vice for the form of ai we have defended. 
1 objections - second round 
objection 1:  you argue that your approach is much in line with turing's tt and hamad's ttt  yet those two are concerned with machines behaving like humans  whereas psychometric ai is concerned with doing well on iq tests  and the like   which many humans obviously do not necessarily do! one crucial question which surprisingly you don't address at all is: what are the cognitive limitations that stop us from doing much better on such tests  should similar limitations be put into pai systems just to make their performance more human-like and thus give them a chance to behave humanlike  and pass tt and ttt   or should pai systems be built to perform as well as possible  but without a chance of passing tt and ttt   should pai  for example  be concerned with building mediocre chess players with human-like limitations instead of really good ones  assuming that chess could count as some kind of test . and if so  wouldn't pai have to be cognitive modeling  including modeling of limitations   not  just  ai  contrary to what you say  at least about your work with peri    
　rest assured that we are doing ai first and foremost; cognitive modeling is subsidiary  and can be derived from success on the ai front. this objection is plagued by a non sequitur. it doesn't follow from the fact that pai aims at perfectperforming artificial test-takers that there is there no chance of such systems passing tt and ttt. as an engineering technique  it is wise to  crack  tests via algorithms that can enable us to build artificial agents able to perform flawlessly on them. once that is accomplished  it will be easy to  desmart  these agents to produce ones able to match any level of poor performance seen in the human sphere. as turing  1  pointed out  if a robotic interlocutor in the tt is sufficiently smart  a query to it like  what is 1 1 x 1  1  1   will return a suitably incompetent  = humanesque  response  e.g.   1 would need my trusty calculator for that!    despite the fact that the machine has the power to 
produce the correct answer instantly. 
　objection 1:  i think you are making a mistake in the end by identifying your approach with 'weak ai ' which according to searle is just the claim that computers are  merely  useful tools in the study of mind. the position of'strong ai ' on the other hand  claims that computers  or computer programs  actually can have human-like mental states  if running the right program . you argue that ascriptions of consciousness  etc.  to computers  or computer-controlled robots  could and should be made  and that in my opinion puts you in the 
'strong'ai camp.  
　unfortunately  our critic misunderstands the distinction between  strong  and  weak  ai.  strong  ai is indeed the view that cognition  including subjective awareness or phenomenal consciousness  is computation  and that an appropriately programmed information processing machine operating at or below the turing limit can literally be subjectively aware.  weak  ai holds that though the external behavior of such machines might convince external observers to ascribe subjective awareness to them  such machines can't possibly have the relevant mental states. some opponents of  strong  ai  such as bringsjord himself  are actively seeking to engineer artifacts  such as peri himself!  that would convince everyone  or at least nearly everyone  that such artificial creatures are literally subjectively aware! - so the objection obviously rests on a confusion  see bringsjord 1  bringsjord & ferrucci 1  and the just-published bringsjord & zenzen 1 . 
　some additional objections are inevitable. we have space here to but rebut some of them in rapid-fire fashion. more thorough rebuttals are of course forthcoming  in a more capacious venue. 
ontologies and foundations 
　
   the statement that pa1 requires a system to perform well in 'any possibly existing' psychometric tests makes 
pa1 ill-defined.  
- not at all. the great challenge we're willing to face up to is to engineer peri with the capacity to crack tests he has never seen before. we ask only that the test be validated via the ordinary statisticomathematical standards used in psychometrics. 
   your presented example for peri to tackle - block de-sign - is too simple even in the general case to justify your deep claims.  
- with all due respect: get serious. herbert simon  at the 1 inception of al  proclaimed that thinking computers were just around the corner  on the strength of logic theorist's ability to prove such marvelously subtle theorems as that q -  -q; can be derived from p -  q.  for the verbatim sanguine proclamation  see russell & norvig 1.  today  ai has yet to produce a machine with the conversational power of a sharp toddler. peri is a research program moving now onto tests that no current al technology can crack  and we will avail ourselves not only of logic-based formalisms  tools  and techniques that are at the heart of the rair lab  but also - to give peri robust perception/action capability - ammunition from cognitive robotics that may well be outside the logicist paradigm. 
- turing  1  certainly made some rather deep claims  e.g.  that all of human cognition is at bottom computational  and that by the year 1 not only the conversational power of a toddler would be matched by machines  but that of a novelist would be   and as far as we can tell  the only implementations he could point to for justification were painfully primitive. 
acknowledgments 
we are indebted to the educational testing service for sponsoring applied al in the intersection of ai and testing  the ewriter project   that led us to ponder the philosophical foundations of ai in connection with this applied work. 
