
this paper investigates the problem of policy learning in multiagent environments using the stochastic game framework  which we briefly overview. we introduce two properties as desirable for a learning agent when in the presence of other learning agents  namely rationality and convergence. we examine existing reinforcement learning algorithms according to these two properties and notice that they fail to simultaneously meet both criteria. we then contribute a new learning algorithm  wolf policy hillclimbing  that is based on a simple principle:  learn quickly while losing  slowly while winning.  the algorithm is proven to be rational and we present empirical results for a number of stochastic games showing the algorithm converges.
1	introduction
the multiagent learning problem consists of devising a learning algorithm for our single agent to learn a policy in the presence of other learning agents that are outside of our control. since the other agents are also adapting  learning in the presence of multiple learners can be viewed as a problem of a  moving target   where the optimal policy may be changing while we learn. multiple approaches to multiagent learning have been pursued with different degrees of success  as surveyed in  wei  and sen  1  and  stone and veloso  1  . previous learning algorithms either converge to a policy that is not optimal with respect to the other player's policies  or they may not converge at all. in this paper we contribute an algorithm to overcome these shortcomings.
¡¡we examine the multiagent learning problem using the framework of stochastic games. stochastic games  sgs  are a very natural multiagent extension of markov decision processes  mdps   which have been studied extensively as a model of single agent learning. reinforcement learning  sutton and barto  1  has been successful at finding optimal control policies in the mdp framework  and has also been examined as the basis for learning in stochastic games  claus and boutilier  1; hu and wellman  1; littman  1 . additionally  sgs have a rich background in game theory  being first introduced in 1  shapley .
¡¡in section 1 we provide a rudimentary review of the necessary game theory concepts: stochastic games  best-responses  and nash equilibria. in section 1 we present two desirable properties  rationality and convergence  that help to elucidate the shortcomings of previous algorithms. in section 1 we contribute a new algorithm toward achieving these properties called wolf   win or learn fast   policy hill-climbing  and prove that this algorithm is rational. finally  in section 1 we present empirical results of the convergence of this algorithm in a number and variety of domains.
1	stochastic games
a stochastic game is a tuple  n s a1...n t r1...n   where n is the number of agents  s is a set of states  ai is the set of actions available to agent i with a being the joint action space a1¡Á...¡Áan  t is a transition function s¡Áa¡Ás¡ú  1   and ri is a reward function for the ith agent s¡Áa¡ú
r. this is very similar to the mdp framework except we have multiple agents selecting actions and the next state and rewards depend on the joint action of the agents. also notice that each agent has its own separate reward function. the goal for each agent is to select actions in order to maximize its discounted future reward with discount factor ¦Ã.
¡¡sgs are a very natural extension of mdps to multiple agents. they are also an extension of matrix games to multiple states. two common matrix games are in figure 1. in these games there are two players; one selects a row and the other selects a column of the matrix. the entry of the matrix they jointly select determines the payoffs. the games in figure 1 are zero-sum games  where the row player receives the payoff in the matrix  and the column player receives the negative of that payoff. in the general case  general-sum games  each player has a separate matrix that determines its payoff.
matching pennies	rock-paper-scissors figure 1: two example matrix games.
¡¡each state in a stochastic game can be viewed as a matrix game with the payoffs for each joint action determined by the matrix entries ri s a . after playing the matrix game and receiving their payoffs the players are transitioned to another state  or matrix game  determined by their joint action. we can see that sgs then contain both mdps and matrix games as subsets of the framework.
mixed policies. unlike in single-agent settings  deterministic policies in multiagent settings can often be exploited by the other agents. consider the matching pennies matrix game as shown in figure 1. if the column player were to play either action deterministically  the row player could win a payoff of one every time. this requires us to consider mixed strategies or policies. a mixed policy  ¦Ñ : s¡ú pd ai   is a function that maps states to mixed strategies  which are probability distributions over the player's actions.
nash equilibria. even with the concept of mixed strategies there are still no optimal strategies that are independent of the other players' strategies. we can  though  define a notion of best-response. a strategy is a best-response to the other players' strategies if it is optimal given their strategies. the major advancement that has driven much of the development of matrix games  game theory  and even stochastic games is the notion of a best-response equilibrium  or nash equilibrium  nash  jr.  1 .
¡¡a nash equilibrium is a collection of strategies for each of the players such that each player's strategy is a best-response to the other players' strategies. so  no player can get a higher payoff by changing strategies given that the other players also don't change strategies. what makes the notion of equilibrium compelling is that all matrix games have such an equilibrium  possibly having multiple equilibria. in the zero-sum examples in figure 1  both games have an equilibrium consisting of each player playing the mixed strategy where all the actions have equal probability.
¡¡the concept of equilibria also extends to stochastic games. this is a non-trivial result  proven by shapley  for zerosum stochastic games and by fink  for general-sum stochastic games.
1	motivation
the multiagent learning problem is one of a  moving target.  the best-response policy changes as the other players  which are outside of our control  change their policies. equilibrium solutions do not solve this problem since the agent does not know which equilibrium the other players will play  or even if they will tend to an equilibrium at all.
¡¡devising a learning algorithm for our agent is also challenging because we don't know which learning algorithms the other learning agents are using. assuming a general case where other players may be changing their policies in a completely arbitrary manner is neither useful nor practical. on the other hand  making restrictive assumptions on the other players' specific methods of adaptation is not acceptable  as the other learners are outside of our control and therefore we don't know which restrictions to assume.
¡¡we address this multiagent learning problem by defining two properties of a learner that make requirements on its behavior in concrete situations. after presenting these properties we examine previous multiagent reinforcement learning techniques showing that they fail to simultaneously achieve these properties.
1	properties
we contribute two desirable properties of multiagent learning algorithms: rationality and convergence.
property 1  rationality  if the other players' policies converge to stationary policies then the learning algorithm will converge to a policy that is a best-response to their policies.
¡¡this is a fairly basic property requiring the player to behave optimally when the other players play stationary strategies. this requires the player to learn a best-response policy in this case where one indeed exists. algorithms that are not rational often opt to learn some policy independent of the other players' policies  such as their part of some equilibrium solution. this completely fails in games with multiple equilibria where the agents cannot independently select and play an equilibrium.
property 1  convergence  the learner will necessarily converge to a stationary policy. this property will usually be conditioned on the other agents using an algorithm from some class of learning algorithms.
¡¡the second property requires that  against some class of other players' learning algorithms  ideally a class encompassing most  useful  algorithms   the learner's policy will converge. for example  one might refer to convergence with respect to players with stationary policies  or convergence with respect to rational players.
¡¡in this paper  we focus on convergence in the case of selfplay. that is  if all the players use the same learning algorithm do the players' policies converge  this is a crucial and difficult step towards convergence against more general classes of players. in addition  ignoring the possibility of self-play makes the naive assumption that other players are inferior since they cannot be using an identical algorithm.
¡¡in combination  these two properties guarantee that the learner will converge to a stationary strategy that is optimal given the play of the other players. there is also a connection between these properties and nash equilibria. when all players are rational  if they converge  then they must have converged to a nash equilibrium. since all players converge to a stationary policy  each player  being rational  must converge to a best response to their policies. since this is true of each player  then their policies by definition must be an equilibrium. in addition  if all players are rational and convergent with respect to the other players' algorithms  then convergence to a nash equilibrium is guaranteed.
1	other reinforcement learners
there are few rl techniques that directly address learning in a multiagent system. we examine three rl techniques: single-agent learners  joint-action learners  jals   and minimax-q.
single-agent learners. although not truly a multiagent learning algorithm  one of the most common approaches is to apply a single-agent learning algorithm  e.g. q-learning  td ¦Ë   prioritized sweeping  etc.  to a multi-agent domain.
they  of course  ignore the existence of other agents  assuming their rewards and the transitions are markovian. they essentially treat other agents as part of the environment.
¡¡this naive approach does satisfy one of the two properties. if the other agents play  or converge to  stationary strategies then their markovian assumption holds and they converge to an optimal response. so  single agent learning is rational. on the other hand  it is not generally convergent in self-play. this is obvious to see for algorithms that learn only deterministic policies. since they are rational  if they converge it must be to a nash equilibrium. in games where the only equilibria are mixed equilibria  e.g. matching pennies   they could not converge. there are single-agent learning algorithms capable of playing stochastic policies  jaakkola et al.  1; baird and moore  1 . in general though just the ability to play stochastic policies is not sufficient for convergence  as will be shown in section 1.
joint action learners. jals  claus and boutilier  1  observe the actions of the other agents. they assume the other players are selecting actions based on a stationary policy  which they estimate. they then play optimally with respect to this learned estimate. like single-agent learners they are rational but not convergent  since they also cannot converge to mixed equilibria in self-play.
minimax-q. minimax-q  littman  1  and hu & wellman's extension of it to general-sum sgs  take a different approach. these algorithms observe both the actions and rewards of the other players and try to learn a nash equilibrium explicitly. the algorithms learn and play the equilibrium independent of the behavior of other players. these algorithms are convergent  since they always converge to a stationary policy. however  these algorithms are not rational. this is most obvious when considering a game of rockpaper-scissors against an opponent that almost always plays  rock . minimax-q will still converge to the equilibrium solution  which is not optimal given the opponent's policy.
 in this work we are looking for a learning technique that is rational  and therefore plays a best-response in the obvious case where one exists. yet  its policy should still converge. we want the rational behavior of single-agent learners and jals  and the convergent behavior of minimax-q.
1	a new algorithm
in this section we contribute an algorithm towards the goal of a rational and convergent learner. we first introduce an algorithm that is rational and capable of playing mixed policies  but does not converge in experiments. we then introduce a modification to this algorithm that results in a rational learner that does in experiments converge to mixed policies.
1	policy hill climbing
a simple extension of q-learning to play mixed strategies is policy hill-climbing  phc  as shown in table 1. the algorithm  in essence  performs hill-climbing in the space of mixed policies. q-values are maintained just as in normal q-learning. in addition the algorithm maintains the current

table 1: policy hill-climbing algorithm  phc  for player i.
mixed policy. the policy is improved by increasing the probability that it selects the highest valued action according to a learning rate ¦Ä ¡Ê  1 . notice that when ¦Ä = 1 the algorithm is equivalent to q-learning  since with each step the policy moves to the greedy policy executing the highest valued action with probability 1  modulo exploration .
¡¡this technique  like q-learning  is rational and will converge to an optimal policy if the other players are playing stationary strategies. the proof follows from the proof of qlearning  which guarantees the q values will converge to q  with a suitable exploration policy.1 similarly  ¦Ð will converge to a policy that is greedy according to q  which is converging to q   the optimal response q-values. despite the fact that it is rational and can play mixed policies  it still doesn't show any promise of being convergent. we show examples of its convergence failures in section 1.
1	wolf policy hill-climbing
we now introduce the main contribution of this paper. the contribution is two-fold: using a variable learning rate  and the wolf principle. we demonstrate these ideas as a modification to the naive policy hill-climbing algorithm.
¡¡the basic idea is to vary the learning rate used by the algorithm in such a way as to encourage convergence  without sacrificing rationality. we propose the wolf principle as an appropriate method. the principle has a simple intuition  learn quickly while losing and slowly while winning. the specific method for determining when the agent is winning is by comparing the current policy's expected payoff with that of the average policy over time. this principle aids in convergence by giving more time for the other players to adapt to changes in the player's strategy that at first appear beneficial  while allowing the player to adapt more quickly to other players' strategy changes when they are harmful.
¡¡the required changes for wolf policy hill-climbing are shown in table 1. practically  the algorithm requires two

table 1: wolf policy hill-climbing algorithm for player i.
learning learning rate parameters  ¦Äl and ¦Äw  with ¦Äl   ¦Äw. the learning rate that is used to update the policy depends on whether the agent is currently winning  ¦Äw  or losing  ¦Äl . this is determined by comparing the expected value  using the current q-value estimates  of following the current policy ¦Ð in the current state with that of following the average policy ¦Ð¡¥. if the expectation of the current policy is smaller  i.e. the agent is  losing   then the larger learning rate  ¦Äl is used.
¡¡wolf policy hill-climbing remains rational  since only the speed of learning is altered. in fact  any bounded variation of the learning rate would retain rationality. its convergence properties  though  are quite different. in the next section we show empirical results that this technique converges to rational policies for a number and variety of stochastic games. the wolf principle also has theoretical justification for a restricted class of games. for two-player  two-action  iterated matrix games  gradient ascent  which is known not to converge  singh et al.  1b   when using a wolf varied learning rate is guaranteed to converge to a nash equilibrium in self-play  bowling and veloso  1 .
¡¡something similar to the wolf principle has also been studied in some form in other areas  notably when considering an adversary. in evolutionary game theory the adjusted replicator dynamics  weibull  1  scales the individuals' growth rate by the inverse of the overall success of the population. this will cause the population's composition to change more quickly when the population as a whole is performing poorly. a form of this also appears as a modification to the randomized weighted majority algorithm  blum and burch  1 . in this algorithm  when an expert makes a mistake  a portion of its weight loss is redistributed among the other experts. if the algorithm is placing large weights on mistaken experts  i.e. the algorithm is  losing    then a larger portion of the weights are redistributed  i.e. the algorithm adapts more quickly.  neither research lines recognized their modification as essentially involving a variable learning rate  nor has such an approach been applied to learning in stochastic games.
1	results
in this section we show results of applying policy hillclimbing and wolf policy hill-climbing to a number of different games  from the multiagent reinforcement learning literature. the domains include two matrix games that help to show how the algorithms work and the effect of the wolf principle on convergence. the algorithms were also applied to two multi-state sgs. one is a general-sum grid world domain used by hu & wellman . the other is a zero-sum soccer game introduced by littman .
¡¡the experiments involve training the players using the same learning algorithm. since phc and wolf-phc are rational  we know that if they converge against themselves  then they must have converged to a nash equilibrium. for the matrix game experiments ¦Äl/¦Äw = 1  but for the other results a more aggressive ¦Äl/¦Äw = 1 was used. in all cases both the ¦Ä and ¦Á were decreased proportionately to 1/c s   although the exact proportion varied between domains.
1	matrix games
the algorithms were applied to the two matrix games  from figure 1. in both games  the nash equilibrium is a mixed policy consisting of executing the actions with equal probability. the large number of trials and small ratio of the learning rates were used for the purpose of illustrating how the algorithm learns and converges.
¡¡the results of applying both policy hill-climbing and wolf policy hill-climbing to the matching pennies game is shown in figure 1 a . wolf-phc quickly begins to oscillate around the equilibrium  with ever decreasing amplitude. on the other hand  phc oscillates around the equilibrium but without any appearance of converging. this is even more obvious in the game of rock-paper-scissors. the results are shown in figure 1 b   and show trajectories of the players' strategies in policy space through one million steps. policy hill-climbing circles the equilibrium policy without any hint of converging  while wolf policy hill-climbing very nicely spirals towards the equilibrium.
1	gridworld
we also examined a gridworld domain introduced by hu and

	 a  matching pennies game	 b  rock-paper-scissors game
figure 1:  a  results for matching pennies: the policy for one of the players as a probability distribution while learning with phc and wolf-phc. the other player's policy looks similar.  b  results for rock-paper-scissors: trajectories of one player's policy. the bottom-left shows phc in self-play  and the upper-right shows wolf-phc in self-play.wellman  to demonstrate their extension of minimaxq to general-sum games. the game consists of a small grid shown in figure 1 a . the agents start in two corners and are trying to reach the goal square on the opposite wall. the players have the four compass actions  i.e. n  s  e  and w   which are in most cases deterministic. if the two players attempt to move to the same square  both moves fail. to make the game interesting and force the players to interact  while in the initial starting position the north action is uncertain  and is only executed with probability 1. the optimal path for each agent is to move laterally on the first move and then move north to the goal  but if both players move laterally then the actions will fail. there are two nash equilibria for this game. they involve one player taking the lateral move and the other trying to move north. hence the game requires that the players coordinate their behaviors.
¡¡wolf policy hill-climbing successfully converges to one of these equilibria. figure 1 a  shows an example trajectory of the players' strategies for the initial state while learning over 1 steps. in this example the players converged to the equilibrium where player one moves east and player two moves north from the initial state. this is evidence that wolf policy hill-climbing can learn an equilibrium even in a general-sum game with multiple equilibria.
1	soccer
the final domain is a comparatively large zero-sum soccer game introduced by littman  to demonstrate minimaxq. an example of an initial state in this game is shown in figure 1 b   where player 'b' has possession of the ball. the goal is for the players to carry the ball into the goal on the opposite side of the field. the actions available are the four compass directions and the option to not move. the players select actions simultaneously but they are executed in a random order  which adds non-determinism to their actions. if a player attempts to move to the square occupied by its opponent  the stationary player gets possession of the ball  and the move fails. unlike the grid world domain  the nash equilibrium for this game requires a mixed policy. in fact any deterministic policy  therefore anything learned by an single-agent learner or jal  can always be defeated  littman  1 .
¡¡our experimental setup resembles that used by littman in order to compare with his results for minimax-q. each player was trained for one million steps. after training  its policy was fixed and a challenger using q-learning was trained against the player. this determines the learned policy's worst-case performance  and gives an idea of how close the player was to the equilibrium policy  which would perform no worse than losing half its games to its challenger. unlike minimax-q  wolf-phc and phc generally oscillate around the target solution. in order to account for this in the results  training was continued for another 1 steps and evaluated after every 1 steps. the worst performing policy was then used for the value of that learning run.
¡¡figure 1 b  shows the percentage of games won by the different players when playing their challengers.  minimaxq  represents minimax-q when learning against itself  the results were taken from littman's original paper.   wolf  represents wolf policy hill-climbing learning against itself.  phc l   and  phc w   represents policy hill-climbing with ¦Ä = ¦Äl and ¦Ä = ¦Äw  respectively.  wolf 1x   represents wolf policy hill-climbing learning with twice the training  i.e. two million steps . the performance of the policies were averaged over fifty training runs and the standard deviations are shown by the lines beside the bars. the relative ordering by performance is statistically significant.
¡¡wolf-phc does extremely well  performing equivalently to minimax-q with the same amount of training1 and continues to improve with more training. the exact effect of the wolf principle can be seen by its out-performance of phc  using either the larger or smaller learning rate. this shows that the success of wolf-phc is not simply due to changing learning rates  but rather to changing the learning rate at the appropriate time to encourage convergence.
1	conclusion
in this paper we present two properties  rationality and convergence  that are desirable for a multiagent learning algorithm. we present a new algorithm that uses a variable learning rate based on the wolf   win or learn fast   principle. we then showed how this algorithm takes large steps towards achieving these properties on a number and variety of stochastic games. the algorithm is rational and is shown empirically to converge in self-play to an equilibrium even in games with multiple or mixed policy equilibria  which previous multiagent reinforcement learners have not achieved.

	 a  gridworld game	 b  soccer game
figure 1:  a  gridworld game. the dashed walls represent the actions that are uncertain. the results show trajectories of two players' policies while learning with wolf-phc.  b  soccer game. the results show the percentage of games won against a specifically trained worst-case opponent after one million steps of training.acknowledgements. thanks to will uther for ideas and discussions. this research was sponsored by the united states air force under grants nos f1-1 and f1-1. the content of this publication does not necessarily reflect the position or the policy of the sponsors and no official endorsement should be inferred.
references
 baird and moore  1  l. c. baird and a. w. moore. gradient descent for general reinforcement learning. in advances in neural information processing systems 1. the mit press  1.
 blum and burch  1  a. blum and c. burch. on-line learning and the metrical task system problem. in tenth annual conference on computational learning theory  1.
 bowling and veloso  1  m. bowling and m. veloso. convergence of gradient dynamics with a variable learning rate. in proceedings of the eighteenth international conference on machine learning  1. to appear.
 claus and boutilier  1  c. claus and c. boutilier. the dyanmics of reinforcement learning in cooperative multiagent systems. in proceedings of the fifteenth national conference on artificial intelligence. aaai press  1.
 fink  1  a. m. fink. equilibrium in a stochastic nperson game. journal of science in hiroshima university  series a-i  1-1  1.
 hu and wellman  1  j. hu and m. p. wellman. multiagent reinforcement learning: theoretical framework and an algorithm. in proceedings of the fifteenth international conference on machine learning  pages 1  1.  jaakkola et al.  1  t. jaakkola  s. p. singh  and m. i. jordan. reinforcement learning algorithm for partially observable markov decision problems. in advances in neural information processing systems 1  1.
 littman  1  m. l. littman. markov games as a framework for multi-agent reinforcement learning. in proceedings of the eleventh international conference on machine learning  pages 1  1.
 nash  jr.  1  j. f. nash  jr. equilibrium points in nperson games. pnas  1-1  1.
 shapley  1  l. s. shapley. stochastic games. pnas  1-1  1.
 singh et al.  1a  s. singh  t. jaakkola  m. l. littman  and c. szepesvari.¡ä convergence results for single-step on-policy reinforcement-learning algorithms. machine learning  1.
 singh et al.  1b  s. singh  m. kearns  and y. mansour. nash convergence of gradient dynamics in general-sum games. in proceedings of the sixteenth conference on uncertainty in artificial intelligence  pages 1  1.
 stone and veloso  1  p. stone and m. veloso. multiagent systems: a survey from a machine learning perspective. autonomous robots  1   1.
 sutton and barto  1  r. s. sutton and a. g. barto. reinforcement learning. the mit press  1.
 weibull  1  j. w. weibull. evolutionary game theory. the mit press  1.
 wei  and sen  1  g. wei  and s. sen  editors. adaptation and learning in multiagent systems. springer  1.

multi-agent influence diagrams for representing and solving games
¡¡¡¡daphne koller computer science dept.
stanford university
stanford  ca 1 koller cs.stanford.edubrian milch computer science dept.
stanford university
stanford  ca 1 milch cs.stanford.edu
abstract
the traditional representations of games using the extensive form or the strategic  normal  form obscure much of the structure that is present in real-world games. in this paper  we propose a new representation language for general multiplayer games - multi-agent influence diagrams  maids . this representation extends graphical models for probability distributions to a multi-agent decision-making context. maids explicitly encode structure involving the dependence relationships among variables. as a consequence  we can define a notion of strategic relevance of one decision variable to another: is strategically relevant to if  to optimize the decision rule at   the decision maker needs to take into consideration the decision rule at . we provide a sound and complete graphical criterion for determining strategic relevance. we then show how strategic relevance can be used to detect structure in games  allowing a large game to be broken up into a set of interacting smaller games  which can be solved in sequence. we show that this decomposition can lead to substantial savings in the computational cost of finding nash equilibria in these games.
1	introduction
game theory  fudenberg and tirole  1  provides a mathematical framework for determining what behavior is rational for agents interacting with each other in a partially observable environment. however  the traditional representations of games are primarily designed to be amenable to abstract mathematical formulation and analysis. as a consequence  the standard game representations  both the normal  matrix  form and the extensive  game tree  form  obscure certain important structure that is often present in real-world scenarios - the decomposition of the situation into chance and decision variables  and the dependence relationships between these variables. in this paper  we provide a representationthat captures this type of structure. we also show that capturing this structure explicitly has several advantages  both in our ability to analyze the game in novel ways  and in our ability to compute nash equilibria efficiently.
¡¡our frameworkof multi-agentinfluencediagrams maids  extends the formalisms of bayesian networks  bns   pearl  1  and influence diagrams  howard and matheson  1  to represent decision problems involving multiple agents.
maids have clearly defined semantics as noncooperative games: a maid can be reduced to an equivalent game tree  albeit at the cost of obscuring the variable-level interaction structure that the maid makes explicit. maids allow us to describe complex games using a natural representation  whose size is no larger than that of the extensive form  but which can be exponentially more compact.
¡¡just as bayesian networks make explicit the dependencies between probabilistic variables  maids make explicit the dependencies between decision variables. they allow us to define a qualitative notion of strategic relevance: a decision variable strategically relies on another decision variable when  to optimize the decision rule at   the decisionmaking agent needs to take into consideration the decision rule at . this notion provides new insight about the relationships between the agents' decisions in a strategic interaction. we provide a graph-based criterion  which we call sreachability  for determining strategic relevance based purely on the graph structure  and show that it is sound and complete in the same sense that d-separation is sound and complete for probabilistic dependence. we also provide a polynomial time algorithm for computing s-reachability.
¡¡the notion of strategic relevance allows us to define a data structure that we call the relevance graph - a directed graph that indicates when one decision variable in the maid relies on another. we show that this data structure can be used to provide a natural decomposition of a complex game into interacting fragments  and provide an algorithm that finds equilibria for these smaller games in a way that is guaranteed to produce a global equilibrium for the entire game. we show that our algorithm can be exponentially more efficient than an application of standard game-theoretic solution algorithms  including the more efficient solution algorithms of  romanovskii  1; koller et al.  1  that work directly on the game tree.
1	multi-agent influence diagrams  maids 
we will introduce maids using a simple two-agent scenario:
example 1 alice is considering building a patio behind her house  and the patio would be more valuable to her if she could get a clear view of the ocean. unfortunately  there is a tree in her neighbor bob's yard that blocks her view. being somewhat unscrupulous  alice considers poisoning bob's tree  which might cause it to become sick. bob cannot tell whether alice has poisoned his tree  but he can tell if the tree is getting sick  and he has the option of calling in a tree doctor  at some cost . the attention of a tree doctor reduces the chance that the tree will die during the coming winter. meanwhile  alice must make a decision about building her patio before the weather gets too cold. when she makes this decision  she knows whether a tree doctor has come  but she cannot observe the health of the tree directly. a maid for this scenario is shown in fig. 1.

figure 1: a maid for the tree killer example; alice's decision and utility variables are in dark gray and bob's in light gray.
¡¡to define a maid  we begin with a set of agents. the world in which the agents act is represented by the set of chance variables  and a set of decision variables for each agent . chance variables correspond to decisions of nature  as in bayesian networks  pearl  1 . they are represented in the diagram as ovals. the decision variables for agent are variables whose values gets to choose  and are represented as rectangles in the diagram. we use to denote
¡¡¡¡¡¡¡¡. the agents' utility functions are specified using utility variables: for each agent   we have a set of utility variables  represented as diamonds in the diagram. each variable has a finite set dom of possible values  called its domain. the domain of a utility variable is always a finite set of real numbers  a chance or decision variable can have any finite domain . we use to denote . and to denote	.
¡¡like a bn  a maid defines a directed acyclic graph with its variables as the nodes  where each variable is associated with a set of parents . note that utility variables cannot be parents of other variables. for each chance variable   the maid specifies a conditional probability distribution  cpd : a distribution pa for each instantiation pa of . for a decision variable
         is the set of variables whose values agent knows when he chooses a value for . thus  the choice agent makes for can be contingent only on these variables.  see definition 1 below.  for a utility variable   the maid also specifies a cpd pa for each instantiation pa of . however  we require that the value of a utility variable be a deterministic function of the values of its parents: for each pa dom   there is one value of that has probability 1  and all other values of have probability 1. we use pa to denote the value of node that has probability 1 when pa. the total utility that an agent derives from an instantiation of is the sum of the values of in this instantiation; thus  we are defining an additive decomposition of the agent's utility function.
¡¡the agents get to select their behavior at each of their decision nodes. an agent's decision at a variable can depend on the variables that the agent observes prior to making - 's parents. the agent's choice of strategy is specified via a set of decision rules.
definition 1 a decision rule for a decision variable is a function that maps each instantiation pa of to a probability distribution over dom . an assignment of decision rules to every decision for a particular agent is called a strategy.
an assignment of decision rules to every decision is called a strategy profile. a partial strategy profile is an assignment of decision rules to a subset of . we will also use to denote the restriction of to   and to denote the restriction of to variables not in .
¡¡note that a decision rule has exactly the same form as a cpd. thus  if we have a maid   then a partial strategy profile that assigns decision rules to a set of decision variables induces a new maid where the elements of have become chance variables. that is  each
corresponds to a chance variable in with as its cpd. when assigns a decision rule to every decision variable in   the induced maid is simply a bn: it has no more decision variables. this bn defines a joint probability distribution over all the variables in .
definition 1 if	is a maid and	is a strategy profile for
	  then the joint distribution for	induced by	  denoted
       is the joint distribution over defined by the bayes net where:
	the set of variables is	;
for	  there is an edge	iff	; for all	  the cpd for	is	; for all	  the cpd for	is	.
¡¡we can now write an equation for the utility that agent expects to receive in a maid	if the agents play a given strategy profile	. suppose	. then:
eu
dom
 1 
where dom	is the joint domain of	.
¡¡because the expectationof a sum of randomvariables is the same as the sum of the expectations of the individual random variables  we can also write this equation as:
	eu	 1 
dom
¡¡having defined the notion of an expected utility  we can now define what it means for an agent to optimizehis decision at one or more of his decision rules  relative to a given set of decision rules for the other variables.
definition 1 let be a subset of   and let be a strategy profile. we say that is optimal for the strategy profile if  in the induced maid   where the only remaining decisions are those in   the strategy is optimal  i.e.  for all strategies :
	eu	eu
note that  in this definition  it does not matter what decision rules assigns to the variables in .
¡¡in the game-theoretic framework  we typically consider a strategy profile to represent rational behavior if it is a nash equilibrium  nash  1 . intuitively  a strategy profile is a nash equilibrium if no agent has an incentive to deviate from the strategy specified for him by the profile  as long as the other agents do not deviate from their specified strategies.
definition 1 a strategy profile is a nash equilibrium for a maid if for all agents   is optimal for the strategy profile .
1	maids and games
a maid provides a compact representation of a scenario that can also be represented as a game in strategic or extensive form. in this section  we discuss how to convert a maid into an extensive-form game. we also show how  once we have found an equilibrium strategy profile for a maid  we can convert it into a behavior strategy profile for the extensive form game. the word  node  in this section refers solely to a nodein the tree  as distinguishedfromthe nodesin the maid. we use a straightforward extension of a construction of  pearl  1  for converting an influence diagram into a decision tree. the basic idea is to construct a tree with splits for decision and chance nodes in the maid. however  to reduce the exponential blowup  we observe that we do not need to split on every chance variable in the maid. a chance variable that is never observed by any decision can be eliminated by summing it out in the probability and utility computations. we present the construction below  referring the reader to  pearl  1  for a complete discussion.
the set of variables included in our game tree is
	. we define a total ordering	over	that
is consistent with the topological order of the maid: if there is a directed path from to   then . our tree
is a symmetric tree  with each path containing splits over all the variables in in the order defined by . each node is labeled with a partial instantiation inst of   in the obvious way. for each agent   the nodes corresponding to variables are decision nodes for ; the other nodes are all chance nodes. to define the information sets  consider two decision nodes and that correspond to a variable . we place and into the same information set if and only if inst and inst assign the same values to .
¡¡our next task is to determine the split probabilities at the chance nodes. consider a chance node corresponding to a chance variable . for each value dom   let be the child of corresponding to the choice . we want to compute the probability of going from to . the problem  of course  is that a maid does not define a full joint probability distribution until decision rules for the agents are selected. it turns out that we can choose an arbitrary fully mixed strategy profile for our maid  one where no decision has probability zero   and do inference in the bn induced by this strategy profile  by computing
	inst	inst	 1 
the value of this expression does not depend on our choice of . to see why this is true  note that if we split on a decision variable before   then the decision rule does not affect the computation of inst inst   because inst includes values for and all its parents. if we split on after   then cannot be an ancestor of in the maid. also  by the topological ordering of the nodes in the tree  we know that inst cannot specify evidence on or any of its descendants. therefore  cannot affect the computation. hence  the probabilities of the chance nodes are well-defined.
¡¡we define the payoffs at the leaves by computing a distribution over the utility nodes  given an instantiation of . for a leaf   the payoff for agent is:
	inst	 1 
dom
we can also show that the value of  1  does not depend on our choice of . the basic idea here is that inst determines the values of and for each decision variable .
hence  the agents' moves and information are all fully determined  and the probabilities with which different actions are chosen in are irrelevant. we omit details.
¡¡the mapping between maids and trees also induces an obvious mapping between strategy profiles in the different representations. a maid strategy profile specifies a probability distribution over dom for each pair pa   where pa is an instantiation of . the information sets in the game tree correspond one-to-one with these pairs  and a behavior strategy in the game tree is a mapping from information sets to probability distributions. clearly the two are equivalent.
¡¡based on this construction  we can now state the following equivalence proposition:
proposition 1 let be a maid and be its corresponding game tree. then for any strategy profile   the payoff vector for in is the same as the payoff vector for in .
¡¡the number of nodes in is exponential in the number of decision variables  and in the number of chance variables that are observed during the course of the game. while this blowup is unavoidable in a tree representation  it can be quite significant. in some games  a maid can be exponentially smaller than the extensive game it corresponds to.
example 1 suppose a road is being built from north to south throughundevelopedland  and agents have purchasedplots of land along the road. as the road reaches each agent's plot  the agent needs to choose what to build on his land. his utility depends on what he builds  on some private information about the suitability of his land for various purposes  and on what is built north  south  and across the road from his land. the agent can observe what has already been built immediately to the north of his land  on both sides of the road   but he cannot observe further north; nor can he observe what will be built across from his land or south of it.

	figure 1: a maid for the road example with	.
¡¡the maid representation  shown in fig. 1 for   is very compact. there are chance nodes  corresponding to the private information about each agent's land  and decision variables. each decision variable has at most three parents: the agent's private information  and the two decisions regarding the two plots to the north of the agent's land. thus  the size of the maid is linear in . conversely  any game tree for this situation must split on each of the chance nodes and each of the decisions  leading to a representation that is exponential in . concretely  suppose the chance and decision variables each have three possible values  corresponding to three types of buildings. then the game tree corresponding to the road maid has leaves.
¡¡a maid representation is not always more compact. if the game tree is naturally asymmetric  a naive maid representation can be exponentially larger than the tree. we return to the problem of asymmetric scenarios in section 1.
1	strategic relevance
to take advantage of the independence structure in a maid  we would like to find a global equilibrium through a series of relatively simple local computations. the difficulty is that  in order to determine the optimal decision rule for a single decision variable  we usually need to know the decision rules for some other variables. in example 1  when alice is deciding whether to poison the tree  she needs to compare the expected utilities of her two alternatives. however  the probability of the tree dying depends on the probability of bob calling a tree doctor if he observes that the tree is sick. thus  we need to know the decision rule for calltreedoctor to determine the optimal decision rule for poisontree. in such situations  we will say that poisontree  strategically  relies on calltreedoctor  or that calltreedoctor is relevant to poisontree. on the other hand  calltreedoctor does not rely on poisontree. bob gets to observe whether the tree is sick  and treedead is conditionally independent of poisontree given treesick  so the decision rule for poisontree is not relevant to bob's decision.
we will now formalize this intuitive discussion of strategic relevance. suppose we have a strategy profile  and we would like to find a decision rule for a single decision variable that maximizes 's expected utility  assuming the rest of
the strategy profile remains fixed.
¡¡according to definition 1  to determine whether a decision rule for is optimal for   we construct the induced maid where all decision nodes except are turned into chance nodes  with their cpds specified by . then is optimal for if it maximizes 's expected utility in this singledecision maid. the key question that motivates our definition of strategic relevance is the following: what other decision rules are relevant for optimizing the decision rule at  
definition 1 let be a decision node in a maid   be a decision rule for   and be a strategy profile such that is optimal for . strategically relies on a decision node in if there is another strategy profile such that
differs from only at   but is not optimal for   and neither is any decision rule that agrees with on all parent instantiations pa dom where pa .
¡¡in other words  if a decision rule for is optimal for a strategy profile   and does not rely on   then is also optimal for any strategy profile that differs from only at . the last clause of this definition is needed to deal with a problem that arises in many other places in game theory - the problem of suboptimal decisions in response to observations that have zero probability  such as observing an irrational move by another agent .
¡¡relevance is a numeric criterion that depends on the specific probabilities and utilities in the maid. it is not obvious how we would check for strategic relevance without testing all possible pairs of strategy profiles and . we would like to find a qualitative criterion which can help us determine strategic relevance purely from the structure of the graph. in other words  we would like to find a criterion which is analogous to the d-separation criterion for determining conditional independence in bayesian networks.
¡¡first  the optimality of the decision rule at depends only on the utility nodes that are descendants of in the maid. the other utility nodes are irrelevant  because the decision at cannot influence them. now  consider another decision variable . the decision rule at is relevant to only if it can influence the probability distribution over the utility nodes . to determine whether the cpd for a node can affect the probability distribution over a set of other nodes  we can build on a graphical criterion already defined for bayesian networks  that of a requisite probability node:
definition 1 let be a bn structure  and let and be sets of variables in the bn. then a node is a requisite probability node for the query if there exist two bayesian networks and over   that are identical except in the cpd they assign to   but
.
as we will see  the decision rule at	is only relevant to	if
    viewed as a chance node  is a requisite probability node for	.
¡¡geiger et al.  providea graphical criterion for testing whether a node is a requisite probability node for a query . we add to a new  dummy  parent whose
values correspond to cpds for   selected from some set of possible cpds. then is a requisite probability node for if and only if can influence given .
¡¡based on these considerations  we can define sreachability  a graphical criterion for detecting strategic relevance. note that unlike d-separation in bayesian networks  s-reachability is not necessarily a symmetric relation.
definition 1 a node is s-reachable from a node in a maid if there is some utility node such that if a new parent were added to   there would be an active path in from to given   where a path is active in a maid if it is active in the same graph  viewed as a bn.
¡¡we can show that s-reachability is sound and complete for strategic relevance  almost  in the same sense that d-separation is sound and complete for independence in bayesian networks. as for d-separation  the soundness result is very strong: without s-reachability  one decision cannot be relevant to another.
theorem 1  soundness  if and are two decisionnodes in a maid and is not s-reachable from in   then does not rely on .
¡¡as for bns  the result is not as strong in the other direction: s-reachability does not imply relevance in every maid. we can choose the probabilities and utilities in the maid in such a way that the influence of one decision rule on another does not manifest itself. however  s-reachability is the most precise graphical criterion we can use: it will not identify a strategic relevance unless that relevance actually exists in some maid that has the given graph structure. we say that two maids have the same graph structure when the two maids have the same sets of variables and agents  each variable has the same parents in the two maids  and the assignment of decision and utility variables to agents is the same in both maids. the chance and decision variables must have the same domains in both maids  but we allow the actual utility values of the utility variables  their domains  to vary. the cpds in the two maids may also be different.
theorem 1  completeness  if a node is s-reachable from a node in a maid  then there is some maid with the same graph structure in which relies on .
¡¡since s-reachability is a binary relation  we can represent it as a directed graph. as we show below  this graph turns out to be extremely useful.
definition 1 the relevance graph for a maid is a directed graph whose nodes are the decision nodes of   and which contains an edge if and only if is sreachable from .
the relevance graph for the tree killer example is shown in fig. 1 a . by theorem 1  if relies on   then there is an edge from to in the relevance graph.
¡¡to construct the graph for a given maid  we need to determine  for each decision node   the set of nodes that are s-reachable from . using an algorithm such as shachter's bayes-ball  shachter  1   we can find this set for any given in time linear in the number of nodes in the maid.

figure 1: five simple maids  top   and their relevance graphs  bottom . a two-color diamond represents a pair of utility nodes  one for each agent  with the same parents.
by repeatingthe algorithm for each   we can derive the relevance graph in time quadratic in the number of maid nodes.
¡¡recall our original statement that a decision node strategically relies on a decision node if one needs to know the decision rule for in order to evaluate possible decision rules for . although we now have a graph-theoretic characterization of strategic relevance  it will be helpful to develop some intuition by examiningsome simple maids  and seeing when one decision node relies on another. in the five examples shown in fig. 1  the decision node belongs to agent   and belongs to agent . example  a  represents a perfectinformation game. since agent can observe the value of   he does not need to know the decision rule for in order to evaluate his options. thus  does not rely on . on the other hand  agent cannot observe when she makes decision   and is relevant to 's utility  so relies on . example  b  represents a game where the agents do not have perfect information: agent cannot observe when making decision . however  the information is  perfect enough : the utility for does not depend on directly  but only on the chance node  which can observe. hence does not rely on . examples  c  and  d  represent scenarios where the agents move simultaneously  and thus neither can observe the other's move. in  c   each agent's utility node is influenced by both decisions  so relies on and relies on . thus  the relevance graph is cyclic. in  d   however  the relevance graph is acyclic despite the fact that the agents move simultaneously. the difference here is that agent no longer cares what agent does  because her utility is not influenced by 's decision. in graphical terms  there is no active path from to 's utility node given .
¡¡one might conclude that a decision node never relies on a decision node when is observed by   but the situation is more subtle. consider example  e   which represents a simple card game: agent observes a card  and decides whether to bet    ; agent observes only agent 's bet  and decides whether to bet    ; the utility of both depends on their bets and the value of the card. even though agent observes the actual decision in   he needs to know the decision rule for in order to know what the value of tells him about the chance node. thus  relies on ; indeed 

when is observed  there is an active path from that runs through the chance node to the utility node.
1	computing equilibria
the computationof a nash equilibriumfor a game is arguably the key computational task in game theory. in this section  we show how the structure of the maid can be exploited to provide efficient algorithms for finding equilibria in certain games. the key insight behind our algorithm is the use of the relevance graph to break up the task of finding an equilibrium into a series of subtasks  each over a much smaller game. since algorithms for finding equilibria in general games have complexity that is superlinear in the number of levels in the game tree  breakingthe game into smaller games significantly improves the complexity of finding a global equilibrium.
¡¡our algorithm is a generalization of existing backward induction algorithms for decision trees and perfect information games  zermelo  1  and for influence diagrams  jensen et al.  1 . the basic idea is as follows: in order to optimize the decision rule for   we need to know the decision rule for all decisions that are relevant for . for example  the relevance graph for the tree killer example  fig. 1 a   shows that to optimize poisontree  we must first decide on the decision rules for buildpatio and treedoctor. however  we can optimize treedoctor without knowing the decision rules for either of the other decision variables. having decided on the decision rule for treedoctor  we can now optimize buildpatio and then finally poisontree.
po is o n
t re e
b u ild
pa tio
t re e
d o c to r
	 a 	 b 
figure 1: relevance graphs for  a  the tree killer example;  b  the road example with .
¡¡we can apply this simple backward induction procedure in any maid which  like the tree killer example  has an acyclic relevance graph. when the relevance graph is acyclic  we can construct a topological orderingof the decision nodes: an ordering such that if   then is not sreachable from . we can then iterate backward from to
     deriving an optimal decision rule for each decision node in turn. each decision relies only on the decisions that succeed it in the order  and these will have been computed by the time we have to select the decision rule for .
¡¡the relevance graph is acyclic in all perfect-information games  and in all single-agent decision problems with perfect recall. there are also some games of imperfect information  such as the tree killer example  that have acyclic relevance graphs. but in most games we will encounter cycles in the relevance graph. consider  for example  any simple twoplayer simultaneous move game with two decisions and
     where both players' payoffs depend on the decisions at both and   as in fig. 1 c . in this case  the optimality of one player's decision rule is clearly intertwined with the other player's choice of decision rule  and the two decision rules must  match  in order to be in equilibrium. indeed  as we discussed  the relevance graph in such a situation is cyclic.
¡¡however  we can often utilize relevance structure even in games where the relevance graph is cyclic.
example 1 consider the relevance graph for the road example  shown in fig. 1 b  for agents. we can see that we have pairs of interdependent decision variables  corresponding to the two agents whose lots are across the road from each other. also  the decision for a given plot relies on the decision for the plot directly to the south. however  it does not rely on the decision about the land directly north of it  because this decision is observed. none of the other decisions affect this agent's utility directly  and therefore they are not s-reachable.
intuitively  although the last pair of nodes in the relevance graph rely on each other  they rely on nothing else. hence  we can compute an equilibrium for the pair together  regardless of any other decision rules. once we have computed an equilibrium for this last pair  the decision variables can be treated as chance nodes  and we can proceed to compute an equilibrium for the next pair.
we formalize this intuition in the following definition:
definition 1 a set of nodes in a directed graph is a strongly connected component  scc  if for every pair of nodes   there exists a directed path from
to	. a maximal scc is an scc that is not a strict subset of any other scc.
the maximal sccs for the road example are outlined in
fig. 1 b .
¡¡we can find the maximal sccs of a relevance graph in linear time  by constructing a component graph whose nodes are the maximal sccs of the graph  cormen et al.  1 . there is an edge from component to component in the component graph if and only if there is an edge in the relevance graph from some element of to some element of . the component graph is always acyclic  so we can define an ordering over the sccs  such that whenever   no element of is s-reachable from any element of .
¡¡we can now provide a divide-and-conquer algorithm for computing nash equilibria in general maids.
algorithm 1
given a maid a topological ordering	of the component graph derived from the relevance graph for 1	let	be an arbitrary fully mixed strategy profile
1 for	through	:
1 let	be a partial strategy profile for	that is a
nash equilibrium in
1 let
1 output	as an equilibrium of
multi-agent systems
¡¡the algorithm iterates backwards over the scc's  finding an equilibrium strategy profile for each scc in the maid induced by the previously selected decision rules  with arbitrary decision rules for some decisions that are not relevant for this scc . in this induced maid  the only remaining decision nodes are those in the current scc; all the other decision nodes have been converted to chance nodes. finding the equilibrium in this induced maid requires the use of a subroutine for finding equilibria in games. we simply convert the induced maid into a game tree  as described in section 1  and use a standard game-solving algorithm  mckelvey and mclennan  1  as a subroutine. note that if the relevance graph is acyclic  each scc consists of a single decision node. thus  step 1 involves finding a nash equilbrium in a singleplayer game  which reduces to simply finding a decision rule that maximizes the single agent's expected utility.
¡¡in proving the correctness of algorithm 1  we encounter a subtle technical difficulty. the definition of strategic relevance  def. 1  only deals with the optimality of a single decision rule for a strategy profile. but in algorithm 1  we derive not just single decision rules  but a complete strategy for each agent. to make the leap from the optimality of single decision rules to the optimality of whole strategies in our proof  we must make the standard assumption of perfect recall - that agents neverforgettheir previousactions or observations. more formally:
definition 1 an agent has perfect recall with respect to a total order over if for all   implies that and .
we can now prove the correctness of algorithm 1.
theorem 1 let be a maid where every agent has perfect recall  and let be a topological ordering of the sccs in the relevance graph for . then the strategy profile produced by running algorithm 1 with and as inputs is a nash equilibrium for .
¡¡to demonstrate the potential savings resulting from our algorithm  we tried it on the road example  for different numbers of agents . note that the model we used differs slightly from that shown in fig. 1: in our experiments  each agent had not just one utility node  but a separate utility node for each neighboring plot of land  and an additional node that depends on the suitability of the plot for different purposes. the agent's decision node is a parent of all these utility nodes. the idea is that an agent gets some base payoff for the building he builds  and then the neighboring plots and the suitability node apply additive bonuses and penalties to his payoff. thus  instead of having one utility node with parent instantiations  we have 1 utility nodes with parent instantiations each. this change has no effect on the structure of the relevance graph  which is shown for in fig. 1 b . the sccs in the relevance graph all have size 1; as we discussed  they correspond to pairs of decisions about plots that are across the road from each other.
¡¡even for small values of   it is infeasible to solve the road example with standard game-solving algorithms. as we discussed  the game tree for the maid has leaves  whereas the maid representation is linear in . the normal form adds another exponential factor. since each agent  except the first two  can observe three ternary variables  he has 1 information sets. hence  the number of possible pure  deterministic  strategies for each agent is   and the number of pure strategy profiles for all players is . in the simplest interesting case  where   we obtain a game tree with 1 terminal nodes  and standard solution algorithms  that very often use the normal form  would need to operate on a game matrix with about entries
 one for each pure strategy profile .

figure 1: performance results for the road example.
¡¡solving the road game either in its extensive form or in the normal form is infeasible even for . by contrast  our divide-and-conquer algorithm ends up generating a sequence of small games  each with two decision variables. fig. 1 shows the computational cost of the algorithm as grows. we converted each of the induced maids constructed during the algorithm into a small game tree  and used the game solver gambit  to solve it. as expected  the time required by our algorithm grows approximately linearly with . thus  for example  we can solve a road maid with 1 agents  correspondingto a game tree with terminal nodes  in 1 minutes 1 seconds.
1	discussion and future work
we have introduced a new formalism  multi-agent influence diagrams  maids   for modeling multi-agent scenarios with imperfect information. maids use a representation where variables are the basic unit  and allow the dependencies between these variables to be represented explicitly  in a graphical form. they therefore reveal important qualitative structure in a game  which can be useful both for understanding the game and as the basis for algorithms that find equilibria efficiently. in particular  we have shown that our divide-andconquer algorithm for finding equilibria provides exponential savings over existing solution algorithms in some cases  such as the road example  where the maximal size of an scc in the relevance graph is much smaller than the total number of decision variables. in the worst case  the relevance graph forms a single large scc  and our algorithm simply solves the game in its entirety  with no computational benefits.
¡¡although the possibility of extending influence diagrams to multi-agent scenarios was recognized at least fifteen years ago  shachter  1   the idea seems to have been dormant for some time. suryadi and gmytrasiewicz  have used influence diagrams as a frameworkfor learning in multi-agent systems. milch and koller  use multi-agent influence diagrams as a representational frameworkfor reasoning about agents' beliefs and decisions. however  the focus of both these papers is very different  and they do not consider the structural properties of the influence diagram representation  nor the computational benefits derived from it. nilsson and lauritzen  have done related work on limited memory influence diagrams  but they focus on the task of speeding up inference in single-agent settings. maids are also related to la mura's  game networks  which incorporate both probabilistic and utility independence. la mura defines a notion of strategic independence  and also uses it to break up the game into separate components. however  his notion of strategic independence is an undirected one  and thus does not allow as fine-grained a decomposition as the directed relevance graph used in this paper  nor the use of a backward induction process for interacting decisions.
¡¡this work opens the door to a variety of possible extensions. on the representational front  it is important to extend maids to deal with asymmetric situations  where the decisions to be made and the information available depend on previous decisions or chance moves. game trees represent such asymmetry in a natural way  whereas in maids  as in influence diagrams and bns   a naive representation of an asymmetric situation leads to unnecessary blowup. we believe we can avoid these difficulties in maids by explicitly representing context-specificity  as in  boutilier et al.  1; smith et al.  1   integrating the best of the game tree and maid representations.
¡¡another direction relates to additional structure that is revealed by the notion of strategic relevance. in particular  even if a group of nodes forms an scc in the relevance graph  it might not be a fully connected subgraph; for example  we might have a situation where relies on   which relies on
     which relies on . clearly  this type of structure tells us something about the interaction between the decisions in the game. an important open question is to analyze the meaning of these types of structures  and to see whether they can be exploited for computational gain.  see  kearns et al.  1  for results in one class of maids. 
¡¡finally  the notion of strategic relevance is not the only type of insight that we can obtain from the maid representation. we can use a similar type of path-based analysis in the maid graph to determine which of the variables that an agent can observe before making a decision actually provide relevant information for that decision. in complex scenarios  especially those that are extended over time  agents tend to accumulate a great many observations. the amount of space needed to specify a decision rule for the current decision increases exponentially with the number of observed variables. thus  there has been considerable work on identifying irrelevant parents of decision nodes in single-agent influence diagrams  howard and matheson  1; shachter  1; 1 . however the multi-agentcase raises subtleties that are absent in the single-agent case. this is another problem we plan to address in future work.
acknowledgements this work was supportedby air force contract f1-1 under darpa's task program and by onr muri n1-1 under the program  decision making under uncertainty .
references
 boutilier et al.  1  c. boutilier  n. friedman  m. goldszmidt  and d. koller. context-specific independence in bayesian networks. in proc. 1th uai  pages 1  1.
 cormen et al.  1  t.h. cormen  c.e. leiserson  and r.l. rivest. introduction to algorithms. mit press  1.  fudenberg and tirole  1  d. fudenberg and j. tirole. game theory. mit press  1.
 gambit  1  gambit software  california institute of technology  1. http://www.hss.caltech.edu/gambit/gambit.html.
 geiger et al.  1  d. geiger  t. verma  and j. pearl. identifying independence in bayesian networks. networks  1-1  1.
 howard and matheson  1  r. a. howard and j. e. matheson. influence diagrams. in readings on the principles and applications of decision analysis  pages 1. strategic decisions group  1.
 jensen et al.  1  f. jensen  f.v. jensen  and s.l. dittmer. from influence diagrams to junction trees. in proc. 1th uai  pages 1  1.
 kearns et al.  1  m. kearns  m.l. littman  and s. singh. graphical models for game theory. submitted  1.
 koller et al.  1  d. koller  n. megiddo  and b. von stengel. fast algorithms for finding randomized strategies in game trees. in proc. 1th stoc  pages 1  1.
 lamura  1  p. lamura. game networks. in proc. 1th uai  pages 1  1.
 mckelvey and mclennan  1  r.d. mckelvey and a. mclennan. computation of equilibria in finite games. in handbook of computational economics  volume 1  pages 1. elsevier science  amsterdam  1.
 milch and koller  1  b. milch and d. koller. probabilistic models for agents' beliefs and decisions. in proc. 1th uai  1.  nash  1  j. nash. equilibrium points in n-person games. proc. national academy of sciences of the usa  1-1  1.
 nilsson and lauritzen  1  d. nilsson and s.l. lauritzen. evaluating influence diagrams with limids. in proc. 1th uai  pages 1  1.
 pearl  1  j. pearl. probabilistic reasoning in intelligent systems. morgan kaufmann  san francisco  1.
 romanovskii  1  i. v. romanovskii. reduction of a game with complete memory to a matrix game. soviet mathematics  1- 1  1.
 shachter  1  r. d. shachter. evaluating influence diagrams. operations research  1-1  1.
 shachter  1  r. d. shachter. an ordered examination of influence diagrams. networks  1-1  1.
 shachter  1  r. d. shachter. bayes-ball: the rational pastime. in proc. 1th uai  pages 1  1.
 smith et al.  1  j. e. smith  s. holtzman  and j. e. matheson. structuring conditional relationships in influence diagrams. operations research  1 :1  1.
 suryadi and gmytrasiewicz  1  d. suryadi and p.j. gmytrasiewicz. learning models of other agents using influence diagrams. in proc. 1th int'l conf. on user modeling  um-1   pages 1  1.
 zermelo  1  e. zermelo. uber¡§ eine anwendung der mengenlehre auf der theorie des schachspiels. in proceedings of the fifth international congress on mathematics  1.
multi-agent systems

multi-agent systems
multi-agent systems

multiagent coordination by stochastic cellular automata
t d barfoot and g m t d'eleuterio
tim.barfoot utoronto.ca  gde utias.utoronto.ca
university of toronto institute for aerospace studies
1 dufferin street  toronto  ontario  canada  m1h 1

abstract
a coordination mechanism for a system of sparsely communicating agents is described. the mechanism is based on a stochastic version of cellular automata. a parameter similar to a temperature can be tuned to change the behaviour of the system. it is found that the best coordination occurs near a phase transition between order and chaos. coordination does not rely on any particular structure of the connections between agents  thus it may be applicable to a large array of sparsely communicating mobile robots.
1	introduction
the term multiagent system encompasses large bodies of work from engineering  computer science  and mathematics. examples include networks of mobile robots  mataric¡ä  1   software agents  bonabeau et al.  1   and cellular automata  wolfram  1 . a common thread in all multiagent systems is the issue of coordination. how are a large number of sparsely coupled agents able to produce a coherent global behaviourusing simple rules  answeringthis question will not only permit the construction of interesting and useful artificial systems but may allow us to understand more about the natural world. ants and the other social insects are perfect examples of local interaction producinga coherentglobal behaviour. it is possible for millions of ants to act as a superorganism through local pheromone communication. we seek to reproduce this ability on a fundamental level in order to coordinate artificial systems.
¡¡it can be argued that cellular automata  ca  are the simplest example of a multiagent system. originally studied by  von neumann  1   the term ca is used to describe systems of sparsely coupled difference equations. despite their simple mechanics  some extremely interesting behaviours have been catalogued  e.g.  conway's game of life . the word self-organization is used in many contexts when discussing multiagent systems which can lead to confusion. here we use it to mean multiagent coordination in the face of more than one alternative. we will be describing a stochastic version of cellular automata. the goal will be to have all cells choose the same symbol from a number of possibilities using only sparse communication. we maintain that rules able to succeed at this task are self-organizing because the cells are not told which symbol to choose  yet they must all coordinate their choices to produce a globally coherent decision. if we told the cells which symbol to choose  the task would be very easy and no communication between cells would be necessary. this can be dubbed centralized organization and is in stark contrast to self- or decentralized organization. we believe that coordinationin the face of more than one alternative is at the very heart of all multiagent systems.
¡¡this paper is organized as follows. related work is described  followed by a description of the model under consideration. results of its performance on the multiagent coordination task are presented. statistical analysis of the rule are provided followed by discussions and conclusions.
1	related work
in the following note that typically cellular automata do not operate in a stochastic but rather a deterministic manner. unless explicitly stated  e.g.  stochastic cellular automata  sca    the term cellular automata will imply determinism.
¡¡ von neumann  1  originally studied cellular automata in the context of self-reproducing mechanisms. the goal was to devise local rules which would reproduce and thus spread an initial pattern over a large area of cells  in a tiled fashion. the current work can be thought of as a simple case of this where the tile size is only a single cell but there are multiple possibilities for that tile. futhermore  we wish our rules to work starting fromanyrandominitial conditionof the system.
¡¡cellular automata were categorized by the work of  wolfram  1  in which four universality classes were identified. all rules were shown to belong to one of class i  fixed point   class ii  oscillatory   class iii  chaotic   or class iv  long transient . these universality classes can also be identified in sca and we will show that in our particular model  choosing a parameter such that the system displays long transient behaviour  e.g.  class iv  results in the best performance on our multiagent coordination task.
¡¡ langton  1  has argued that natural computation may be linked to the universality classes. it was shown that by tuning a parameter to produce different ca rules  a phase transition was exhibited. the relation between the phase transition and the universality classes was explored. it was found that class iv behaviour appeared in the vicinity of the phase transition. the current work is very comparable to this study in that we also have a parameter which can be tuned to produce different ca rules. however  our parameter tunes the amount of randomness that is incorporated into the system. at one end of the spectrum  completely random behaviour ensues while at the other completely deterministic behaviour ensues. we also relate the universality classes to particular ranges of our parameter and find a correlation between performance on our multiagent coordination task and class iv behaviour. we attempt to use similar statistical measures to  langton  1  to quantify our findings.
¡¡ mitchell et al.  1    das et al.  1  study the same coordination task as will be examined here in the case of deterministic ca. however  their approach is to use a genetic algorithm to evolve rules successful at the task whereas here hand-coded rules are described. they found that the best solutions were able to send long range particles  similar to those in the game of life   andre et al.  1  in order to achieve coordination. these particles rely on the underlying structure of the connections between cells  specifically that each cell is connected to its neighbours in an identical manner. the current work assumes that no such underlying structure may be exploited and that the same mechanism should work for different connective architectures. the cost for this increased versatility is that the resulting rules are less efficient  in terms of time to coordinate  than their particle-based counterparts.
¡¡ tanaka-yamawaki et al.  1  studies the same problem to that considered here. they use totalistic  wolfram  1  rules which do not permit exploitation of the underlying structure of the connections between cells but rather rely on the intensity of each incoming symbol. they also vary a parameter to produce different rules and find that above a certain threshold   global consensus  occurs but below it does not. however  they consider large clusters of symbols to be a successful global consensus. we do not and thus turn to a stochastic version of their totalistic rules to destroy these clusters and complete the job of global coordination.
1	the model
in deterministic cellular automata there is an alphabet of symbols  one of which may be adopted by each cell. incoming connections each provide a cell with one of these symbols. the combination of all incoming symbols uniquely determines which symbol the cell will display as output. stochastic cellular automata  sca  work in the very same
way except at the output level. instead of there being a sin-
gle unique symbol which is adopted with probability   there can be multiple symbols adopted with probability less than
 . based on this outgoing probability distribution over the symbols  a single unique symbol is drawn to be the output of
the cell. this is done for all cells simultaneously. it should be noted that deterministic ca are a special case of sca.
¡¡we consider a specific sub-case of sca in this paper which corresponds to the totalistic rules of ca. assume that cells cannot tell which symbols came from which connections. in this case  it is only the intensity of each incoming symbol which becomes important. furthermore  we desire that our rules work with any number of incoming connections thus rather than using the number of each of the incoming symbols  we use this number normalized by the number of connections which can be thought of as an incoming probability distribution. in summary the model we consider is as follows.
totalistic sca. consider a system of cells  each of which is connected to a number of other cells. let represent an alphabet of symbols. the state of cell at time-step is
¡¡¡¡¡¡¡¡. the input probability distribution  pin  for cell is given by
¡¡¡¡¡¡¡¡¡¡¡¡pin	 1  where	accounts for the connections of cell	to the other cells. the output probability distribution pout is given by the map 	 
	pout	pin	 1 
the probability distributions pin and pout are stochastic columns. the new state of cell	at time-step	is randomly drawn according to the distribution pout	and is represented by	.
it should be noted that in  1  if the connections between the cells are not changing over time then the functions    will not be functions of time. however  we could allow these connections to change which would make them functions of time.
¡¡once the connections are described throughthe functions  the only thing that remains to be defined is the -map. we assume that each cell has the same -map but this need not be the case. the possibilities for this map are infinite and thus for the remainder of this paper we discuss a parameterized subset of these possibilities. this subset will be called piecewise- and is defined as follows.
piecewise- . let
	pin	in	in	 1 
the  unnormalized  output probabilities are given by
	if 	in	
	out	if 	in	
		in		otherwise
 1 
where	is derived from the tunable parameter	as follows:
	if	
 1 
		if 
the  normalized  output probability column is
	pout		out	out	 1 
out
where	out	out.
note that in  1   the tunable parameter  acts in a similar manner to a temperature parameter. when we have a completely deterministic rule while when we have a completely random rule. figure 1 shows what the rule looks like for different when .

	figure 1: the piecewise-	rule for different values of	and	.¡¡an equilibrium point  p   in a -map is one for which the following is true
	p	p	 1 
the idea behind the piecewise- rule was to create an instability in the probability map at the uniform distribution equilibrium point
	puni		 1 
such that a small perturbation from this point would drive the probability towards one of the stable equilibria
p	 1  p	 1 
     ...	 1  p	 1 
it turns out that when   the equilibrium point  puni  is the only stable equilibrium. however when    puni becomes unstable and the other equilibria  p p   become stable. this is similar to the classic pitchfork bifurcation as depicted in figure 1 for . however  with symbols in the alphabet the pitchfork will have tines.
¡¡it is important to stress that we have designed the stability of our system at a local level. the question of global stability and success on the multiagent coordination problem does not follow directly from the local stability of each cell. it might be possible to study the global stability of a system of cells with the piecewise- rule analytically. the approach in this paper has been to study it through simulation and statistical measures.
1	simulation
we now present simulations of cells running the piecewiserule. in order to ensure that the connections between cells are not regular  we consider each cell to exist in a cartesian box  of size by  . the cells are randomly positioned in this

figure 1: pitchfork stability of the piecewise- rule for . is a parameter analogous to a temperature.
box and symmetrical connections are formed between two cells if they are closer than a threshold euclidean distance    from one another. figure 1 shows example connections between cells with . figure 1 shows example time series for different values of . when   chaotic global behaviour arises  with fairly successful behaviour results but with clusters form. the formation of clusters means that the global system has stable equilibria which we did not predict from the local rule. however  as is decreased towards   these equilibria are no longer stable and the system continues to coordinate.
¡¡it would seem that there is a good correlation between the stability on the local level and the behaviourtype of the global system. as moves from below to above  it appears there is a dramatic phase transition in the behaviour of the system  totally chaotic to fixed point . in the neighbourhood of there is long transient behaviour. it turns out that the best value for   from the point of view of multiagent coordination  is approximately .
1	statistics
in an attempt to quantify the qualitative observations of the previous section a number of statistical measures were employed in the analysis of the sca time series. these were used also by  langton  1 . the first measure is taken from  shannon  1  and will be referred to as entropy    . it is defined as follows.


coordination   right  clusters. the	colours represent the	symbols of the alphabet.figure 1: example connections between	cells with
   . colours represent the symbols of the alphabet. here an initial random condition is displayed for .
entropy given a sequence of	symbols
 1 
from an alphabet of size   the entropy of the sequence may be computed as follows. first compute the frequency    of each of the symbols which is simply the number of occurrences of symbol in the sequence  . from
the frequencies  compute the probability 	  of each of the symbols	as
		 1 
where	.	finally  the entropy of sequence 
  is defined as
		 1 
where the	denominator is a normalization constant to make	.
this entropy function produces a value of	when all the sym-
bols in are identical and a value of when all symbols are equally common. the second measure is based on the first and will be referred to as mutual information    . it is defined as
mutual information given two sequences of	symbols
 1 
 1 
from an alphabet of size   the mutual information of the sequence    may be defined as
 1 
where is the entropy of the two sequences considered as a joint process  i.e.  with an alphabet of size  .
these two measures may be computed on any sequence of symbols. we tested them on spatial sequences  e.g.  time series columns from figure 1  and temporal sequences  e.g.  time series rows from figure 1 . the most interesting measures were average spatial entropy  average of entropies computed from all columns in a time series  and average temporal mutual information  average of all s computed from all rows in a time series. was computed between a row and itself shifted by one time-step .
¡¡figure 1 show various measures for values of . at each value of   simulations were done on different random connections between cells and initial conditions. thus  all displayed measures are actually averaged over simulations. each simulation was run for time-steps with
	 	  and	.
¡¡figure 1  left  shows the average number of clusters1 at the final time-step for different values of . clearly there is an optimal value of near . figure 1  middle  shows average spatial entropy for different values of . this measure has a good correlation with average number of clusters. again  there is a minimum occurring at approximately which corresponds to the best performance at multiagent coordination.
¡¡figure 1  right  displays average temporal mutual information for different values of . this is a very interesting plot.

 right  average temporal mutual information for	values of	. all plots show average of	simulations at each value of	.temporal mutual information seems to capture the length of the global transient behaviour of the system. as discussed in  langton  1   the random pattern in the chaotic region is not considered transient but rather the steady state behaviour. the peak in temporal mutual information occurs at   the phase transition  and drops away on either side.  langton  1  has a similar plot. figure 1 shows how the number of clusters at the final time-step   time-steps  changes as the problem scales up to more cells; it appears to be a linear relationship. figure 1 shows how the number of clusters at the final time-step changes for different message sizes.
1	discussion
the strong correlation between the local stability of the piecewise- rule and the type of global behaviour is quite interesting. it appears that corresponds to fixed point behaviour  class i   corresponds to chaotic behaviour  class iii   and near corresponds to long transient behaviour  class iv . the correlation most likely has something to do with the way in which the incoming probability distribution is computed in  1 . this step delivers information averaged from all connected cells. this averaging serves to smooth out differences between connected cells. however  if this smoothing occurs too quickly  i.e.    the system does not have time to smooth globally resulting in the formation of clusters. the addition of noise in the particular form of the piecewise- rule aids in slowing the smoothing process thus destroying the clusters. this has been called critical slowing down  haken  1  in other systems. as we approach the critical point   or   from above  the strength of the instability decreases which slows down the decision-making process. it is a balance of these two effects which seems to be the most effective at multiagent coordination. the optimal operating value of is not right at the phase transition but a little bit towards the deterministic end of the spectrum  approximately  .
¡¡note that we did not find any oscillatory behaviour  class ii  which is likely because the connections between the cells are symmetrical. however  if the piecewise- rule in figure 1 is reflected  left-right  then the system 'blinks' and global coordination corresponds to all cells blinking in phase with one another.
¡¡in this model of multiagent coordination  the boundaries between clusters have purposely been made unstable. this forces them to move randomly until they contact one another and annihilate  leaving a single cluster. the results presented here used cells and required on average timesteps to get to a single cluster with   and
       . clearly the time required to form a single cluster will increase with the number of cells in the system. figure 1 confirms this by showing that at the end of time-steps  increasing the number of cells    results in more clusters. the linear relationship suggests that scaling-up may be possible but more in depth studies are required. figure 1 shows how the system scales to differentmessage sizes  . here the relationship between number of clusters  after time-steps  to message size is a bit surprising  first dropping then increasing as increases. it levels off again as the number of symbols exceeds the number of cells  since at most symbols can be represented in the random initial condition . again  the nature of this scaling should be studied more closely.
¡¡the piecewise- rule is not the only map that can be used to achieve multiagent coordination in sca. replacing it with other monotonically increasing functions  i.e.  in figure 1  with the same equilibria also works. we had comparable success to the piecewise- map using
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡out	in	 1  with the outgoing probability column normalized as in  1 .
¡¡the model considered here does not require knowledge of the underlying structure of the connections between cells. this was a design requirement as it was originally motivated by a network of communicating mobile robots whose connections might be changing over time and thus difficult to exploit. it is thus natural to question whether the model still works as the connections are varied over time. to this end  a small amount of gaussian noise was added to the positions of the cells in the cartesian box of figure 1 at each time-step. as the cells moved  the connections between them changed  since they are limited by the range   . the sca model was still able to form single clusters. this was possible even when which does make sense since there is still some noise being added. however  the nature of the noise is at the connection level rather than the signal level. this aspect is currently under further investigation.

figure 1: number of clusters at final time-step as the number of cells is varied from to . parameters for each run were time-steps    and  to
keep the density of connections constant. plot shows average of simulations at each value of .

figure 1: number of clusters at the final time-step as the message size is varied from  1 bit  to  1 bits . parameters for each run were time-steps    and .
plot shows average of	simulations at each value of	.
1	conclusion
a mechanism for multiagent coordination has been presented based on stochastic cellular automata. we consider this to be an example of self-organizing behaviour in that global coordination occurs in the face of more than one alternative. it was shown that by using stochastic rules  sparsely communicating agents could come to a global consensus. a parameter in the coordination mechanism was tuned and it was found that coordination occurred best when the system was near a phase transition between chaotic and ordered behaviour  the optimum was a little bit towards the ordered side .
¡¡it is hoped that this model will shed light on selforganization as a general concept while at the same time providing a simple algorithm to be used in practice.
acknowledgements
we would like to acknowledge support of this work by nserc  natural science and engineering research council  and csa  canadian space agency .
references
 andre et al.  1  david andre  forrest h. bennett  and john r. koza. evolution of intricate long-distance communication signals in cellular automata using genetic programming. in chris g. langton and katsunori shimohara  editors  artificial life v  proceedings of the fifth international workshop on the synthesis and simulation of living systems. mit press  1.
 bonabeau et al.  1  eric bonabeau  guy theraulaz  eric arpin  and emmanual sardet. the building behaviour of lattice swarms. in rodney a. brooks and pattie maes  editors  artificial life iv: proceedings of the fourth international workshop on the synthesis and simulation of living systems. mit press  1.
 das et al.  1  rajarshi das  james p. crutchfield  melanie mitchell  and james e. hanson. evolving globally synchronized cellular automata. in l.j. eshelman  editor  proceedings of the sixth international conference on genetic algorithms  pages 1  san fransisco  ca  april 1.
 haken  1  h. haken. synergetics  an introduction  1rd edition. springer-verlag  berlin  1.
 langton  1  chris g. langton. computationsat the edge of chaos: phase transitions and emergent computation. physica d  1-1  1.
 mataric¡ä  1  maja j. mataric¡ä. designing emergent behaviours: from local interactions to collective intelligence. in j. a. meyer  h.l. roitblat  and s. w. wilson  editors  simulation of adaptive behaviour: from animals to animats 1. mit press  1.
 mitchell et al.  1  melanie mitchell  peter t. hraber  and james p. crutchfield. revisiting the edge of chaos: evolving cellular automata to perform computations. complex systems  1-1  1. sfi working paper 1-1.
 shannon  1  c e shannon. a mathematical theory of communication. the bell system technical journal  1-1  july 1.
 tanaka-yamawaki et al.  1  mieko tanaka-yamawaki  sachiko kitamikado  and toshio fukuda. consensus formation and the cellular automata. robotics and autonomous systems  1-1  1.
 von neumann  1  jon von neumann. theory of selfreproducing automata. university of illinois press  urbana and london  1.
 wolfram  1  stephen wolfram. universality and complexity in cellular automata. physica d  1-1  1.



1	multi-agent systems




1	multi-agent systems
positions:  1   1   1   1   1   1 
batteries:      1        1         1         1           1          1
		positions:  1   1   1   1   1   1 


1	multi-agent systems

multi-agent systems
lifelike characters

a layered brain architecture for synthetic creatures 
 	damian isla 	robert burke 	marc downie 	bruce blumberg 
 naimad media.mit.edu rob media.mit.edu 	marcd media.mit.edu bruce media.mit.edu 
 
the media laboratory massachusetts institute of technology 
 	1 ames st. 
cambridge  ma 1 

 
 
abstract 
this paper describes a new layered brain architecture for simulated autonomous and semi-autonomous creatures that inhabit graphical worlds. the main feature of the brain is its division into distinct systems  which communicate through common access to an internal mental blackboard. the brain was designed to encourage experimentation with various systems and architectures. it has so far proven flexible enough to accommodate research advancing in a number of different directions by a small team of researchers. 
1 introduction 
one approach to designing intelligent systems is to look to existing biological systems for clues and design principles. this paper describes c1  the latest in a series of brain architectures built on this principle by our group. this architecture is used for simulating the behavior of agents  or creatures  that inhabit a graphical world. these creatures are able to sense their environment  learn appropriate actions based on expectation of external reward and navigate their environment. c1 sets up a framework to support these and many other mental abilities. the content and structure of this framework are inspired by the abilities of real animals and attempt to deal with some of the constraints that they face. 
¡¡¡¡some of the goals for the system were completely practical: it needed to support graphics with at least a 1hz frame rate  input devices  mice and microphones as well as more exotic interfaces  and network rendering. it also needed to be scalable enough to support a reasonable number of autonomous creatures all sensing and reacting to each other and the world.  
¡¡¡¡but more importantly  the architecture needed to facilitate the construction and control of synthetic creatures. intelligence is often seen as the confluent effect of many individually unintelligent components  as in  minsky 1   and the architecture needed not only to support those components individually but also to allow them to coexist 
 
figure 1: duncan the highland terrier and communicate coherently within one brain. therefore the primary goal was to build a system that facilitated:  
  reactive behavior: it should be easy to design and implement the kind of reactive behavior that many previous works in the field of autonomous agents support.  brooks 1  tu et al 1  blumberg 1  perlin 1  yoon 1 ; 
  learning: creatures should adapt their behavior based on reward and punishment feedback from the world; 
  extensibility: the architecture should be easily extensible in order to support research in various different directions by different researchers. 
¡¡¡¡the result is a highly modular architecture with few essential subsystems and many opportunities for expansion. the canonical brain includes an internal blackboard  sensory and perception systems  working memory  a short-term memory model   and action  navigation and motor systems. 
¡¡¡¡we have implemented two significant projects to date with c1. one project is sheep|dog  figure 1   an interactive installation piece in which a user plays the role of a shepherd who must interact through a series of vocal commands with duncan  a virtual sheepdog  to herd a flock of sheep. this system demonstrated some of the basic reactive  perceptual and spatial abilities of the creatures built under c1. the other project is clicker  in which the user trains duncan to perform a variety of tricks using the same  clicker training  technique used to train real dogs.  
¡¡¡¡the paper proceeds as follows: section 1 will outline the world model being used; section 1 will delve into the architecture of the brain itself  and the make-up and function of the various systems that comprise c1; section 1 will present the results of building c1 and the installations that use it; section 1 will present a discussion of various successful design elements of c1 and sections 1 and 1 will describe some future and related work. 
1 world model 
a formal abstraction exists between the agent and the world. the world model's primary function is to maintain the list of creatures and objects and to act as an event blackboard for the posting and distribution of world events. it also coordinates network synchronization and manages rendering. 
¡¡¡¡world events take the form of datarecords  perceptual nuggets that can be processed by a creature's sensory and perception systems. a datarecord can represent anything from an acoustic pattern  sheep|dog allowed the user to  speak  to the dog through a microphone interface  to a visual or symbolic event. whether a specific form of datarecord can be interpreted depends entirely on the sensory and perceptual abilities of the sensing creature.  
¡¡¡¡in a single execution of the update loop  events are fed to each of the creatures and objects and each is prompted to update itself  this process can happen in parallel . most creatures and objects will themselves produce events that the world will harvest and make available in the next timestep. pre- and post-update tasks  including ui updating  network coordination and rendering  are also performed.  
1 brain overview 
figure 1 shows the layout of a typical creature's brain. c1 is organized into a collection of discrete systems that communicate through an internal blackboard. any part of the brain can write to or read from specific  slots  in this blackboard  differentiated by string labels . 


 
figure 1: the brain architecture 

figure 1: the percept tree. the head location percept is derived from the root of the tree because  at present  all events have locality. retinal location and shape only apply to visual events  just as an event can only be classified as an utterance or a specific utterance if it is an auditory event. 
a detailed description of each system follows. 
1 sensory system 
physical intelligent systems  biological or otherwise  by necessity feature a set of well-defined sensors through which information about world-state and world-events pass. we protect the integrity of this world-agent division by making use of a sensory system abstraction. 
¡¡¡¡the sensory system is a filter through which all worldevents  represented by datarecords  must pass. unlike its physical equivalents  where any data that passes through is fair game  in c1 the sensory system plays an active role in keeping the virtual creature's virtual sensation honest. in a simulated world  there is potentially much more accessible information than the creature  limited by its sensory apparatus  should be able to sense. for example  though duncan the sheepdog could be given the location of the sheep that is behind him  he shouldn't be given it. while often the role of the sensory system is to filter out data that can not be sensed  other times its role is to transform it.  for example  it converts visual location information into the local space of the sensing creature  duncan receives all location information from the world in the coordinate frame of his left eye  or in attenuating the intensity of a sound or acoustic event proportionally to the square of the distance from the source. it is because the same piece of data will be viewed differently by each creature in the world  and because sometimes we want some creatures to be able to cheat and not others  that the individual creature's sensory system performs the event filtering rather than the world itself. 
¡¡¡¡perceptual honesty is an important theme for our research  since we feel that more honest perception leads to more believable behavior. more importantly  creatures in the real world are able to make generally good decisions despite noisy  unreliable and occasionally entirely missing data. this is the point of brooks' insistence on situatedness  brooks 1 . while we do not claim that our virtual world holds anything close to the complexity of a physical environment  the sensory system allows us to begin to face some of the problems like noisy sensation and mccallum's perceptual aliasing  mccallum 1 .  
1 perception system 
once the stimulus from the world has been  sensed  it can then be  perceived.  the distinction between sensing and perceiving is important. a creature may  sense  an acoustic event  but it is up to the perception system to recognize and process the event as something that has meaning to the creature. thus  it is within the perception system that  meaning  is assigned to events in the world. 
¡¡¡¡the perception system takes the form of a percept tree  figure 1 . a percept is an atomic classification and data extraction unit that models some aspect of the sensory inputs passed in by the sensory system. given a datarecord it returns both a match probability  the sheepshapepercept will return the probability that a datarecord represents the experience of seeing a sheep  and  if the match is above a threshold  a piece of extracted data  such as body-space coordinates of the sheep . the details of how the confidence is computed and what exact data is extracted are left to the individual percept. the percept structure might encapsulate a neural net or it might encapsulate a simple  if ... then ...else  clause. this freedom of form is one of the keys to making the c1 perception system extensible  since the system makes no assumptions about what a percept will detect  what type of data it will extract or how it will be implemented. 
¡¡¡¡percepts are organized hierarchically in terms of their specificity. for example  a shapepercept will activate on the presence of any kind of shape whereas one of its children may activate only on a specific type of shape  e.g. a sheepshapepercept . the children of a percept will receive only the data that was extracted by its parent to process. this hierarchical structure is primarily an efficiency mechanism  no point in testing whether an event is the spoken word  sit  if it has already been determined that the event was not an acoustic one  and is very similar to previous hierarchy-of-sensors approaches. 
¡¡¡¡many percepts are plastic  using statistical models to characterize and refine their response properties. these percepts can not only modulate their  receptive fields   the space of inputs to which they will respond positively   but  in concert with the action system  can modify the topology of the tree itself  dynamically growing a hierarchy of children in a process called innovation. as will be described in section 1  the process of innovation is reward-driven  with only percepts that are believed to be correlated with increasing the reliability of an action in producing a desirable outcome being prompted to innovate.  
¡¡¡¡both the confidence and the extracted data of every percept are cached in a perceptmemory object. when a datarecord enters the perception system  a new perceptmemory is created  and as the datarecord is pushed through the percept tree  each percept that registers a positive match adds its respective data to the new perceptmemory. thus  given a sensory stimulus  the perceptmemory represents all the creature can know about that stimulus. 
1 working memory 
like other agent-control architectures  e.g.   rosenbloom et al. 1    c1 contains a working memory structure whose function mirrors that of the pyschological conception of working memory - an object-based memory that contains information about the immediate task or context. the ultimate goal of working memory is to provide a sensory history of objects in the world. it is on the basis of these histories that action-decisions will be made  internal credit for reward assigned  motor-movements modulated  etc. in c1  working memory is a repository for persistent perceptmemory objects. taken together  they constitute the creature's  view  of the world. 
¡¡¡¡the perceptmemory is itself a useful structure. by caching together the various perceptual impressions made by a world event   the thing that was in front of me was also blue   blueness and relative location being separate percepts  they solve  or perhaps avoid  the infamous perceptual binding problem   treisman 1  . they also allow us to submit complex queries to workingmemory:  which is the sheep that is nearest me    
¡¡¡¡perceptmemory objects become even more useful when they incorporate a time dimension with the data they contain. on any one timestep  the perceptmemory objects that come out of the perception system will by necessity only contain information gathered in that timestep. however  as events often extend through time  it is possible to match perceptmemory objects from previous timesteps. thus a recent visual event may represent only the latest sighting of an object that we have been tracking for some time. in the case of visual events  matching is done on the basis of shape  or on the basis of location when shape is not enough to disambiguate incoming visual events  e.g. distinguishing between two sheep . location matching is also used to combine perception information of different modalities  for example a visual event and an auditory one that originate from the same location. assuming that a match is found  the data from the new perceptmemory is added to the history being kept in the old one.  
¡¡¡¡the new confidence is also added to a history of confidences. on timesteps in which percept data is not observed  the confidence in the existing data is decayed. the rate of decay is in part determined by the percept. roughly  the rate of decay should be proportional to the observed variability of the data. 
1 prediction and surprise 
the  view  that working memory provides of the world can be informed by more than just direct perception. much like our own perception  where unobserved data is subconsciously  filled in  by low level predictions and assumptions  creatures implemented under c1 can be designed to act upon events that are likely to occur  or qualities that objects are likely to have. we believe that the ability to recognize temporal patterns and act on them is an essential component of common sense intelligence. 
¡¡¡¡sometimes prediction is used not to predict the future but simply to maintain a coherent view of the present. the stream of sensory data coming from an object can easily be interrupted - for example  because the object is out of the creature's visual field  or because it is occluded by another object. in these cases  prediction can allow a creature to maintain a reasonable estimate of where the object is  even though it is not being observed. 
¡¡¡¡the actual mechanisms of prediction can take many forms. since perceptmemory objects contain histories of percept data  it is possible  if the data are vector or scalar  to use function approximation techniques to extrapolate values. in more complex cases  periodic behaviors or perceptactivity correlations  the bell always rings before the food appears - classical conditioning  essentially  can be recognized and exploited. these prediction-mechanisms could conceivably extend to common sense knowledge about the world - if an object is suspended with no visible support  it might be predicted to fall. 
¡¡¡¡the occasional deviation of predictions from the actual state of the world - and the magnitude of that deviation - also provide a basis for surprise. surprise is an excellent method for focusing perception  and a perceptmemory which has just provided a surprising stimulus is an excellent candidate for the creature's object of attention.  kline 1  includes an excellent discussion of expectation and surprise in synthetic characters. c1 does not currently make use of surprise. 
1 action system 
given a set of perceptmemory objects that detail the perceived state of the world  the creature must decide what action s  it is appropriate to perform. many types of decision-making processes are possible here  however  this section will discuss the action system that we have implemented in c1.  
1.1 actiontuples 
any action-representation must address a number of fundamental questions  namely: 
  what do i do  
  when do i do it  
  what do i do it to  
  how long do i do it for  
  what is it worth  
our representation of action  the actiontuple  directly addresses these five questions through its five subcomponents: 
primitive action s   what do i do  : a piece of code that actually executes the action in question. an 
actiontuple's set of primitive actions typically modify the contents of the blackboard. these postings in turn act as messages to other parts of the system. for example  the motor desired posting holds the name of a physical behavior requested of the motor or navigation systems.  
triggercontext  when do i do it  : a piece of code that returns a scalar value representing the relevance of an actiontuple given the current state of working memory. triggers are typically references to percepts in the percept tree  a trigger that points to the  sheep shape  percept will return a high relevance given any perceptmemory that has a high  sheep shape  confidence . however  the triggercontext is general enough that more complex trigger-conditions can be hand-crafted. as we will see  percept-based triggers are useful because they can be automatically generated through the learning process. 
objectcontext  what do i do it to  : a piece of code that chooses a target for the action. again  it is often defined in terms of percepts   perform the action on something that is sheep-shaped and blue  . when an actiontuple is active  the objectcontext posts the perceptmemory chosen into the object of attention posting of the internal blackboard  thereby making it available to the rest of the system. the objectcontext is an optional component  since not all actions are necessarily targeted. 
dountilcontext  how long do i do it for  : a piece of code that returns a scalar representing the continuing relevance of an actiontuple while it is active. this could take the form of a timer  which drops to zero after a specific period of time  or some code that looks for more complicated ending conditions in working memory. 
intrinsic value  what is it worth  : actiontuples are ascribed an intrinsic value  which is an indicator of how generally  good  the actiontuple is. this is similar to the q-value in q-learning  see  ballard 1  . this value can be used to bias the action-selection process and can be modified through learning  see below . 
1.1 action-selection 
the intrinsic value and the relevance  as determined by the trigger or the dountil contexts  can be combined into a single evaluated value corresponding to the amount of reward expected to result from performing an action. actiontuples can then compete for expression on the basis of this evaluated value. 
¡¡¡¡actiontuples are grouped into actiongroups that are responsible for deciding at each moment which single actiontuple will execute. each actiongroup can have a unique action-selection scheme  but the most common scheme is described below. 
¡¡¡¡when actiontuples are added to an actiongroup they may be placed on either the startle or the default tuple list. the startle list contains high priority actiontuples that compete deterministically  i.e. the one with the highest nonzero evaluated-value wins. if no actiontuple on the startle list is relevant  the actiontuples on the default list are allowed to compete probabilistically for expression on the basis of their e-values.  
¡¡¡¡if an actiontuple is active  it is generally allowed to stay active until its dountil condition is met. when it is met  the selection process takes place again. there are two cases in which an active actiontuple can be interrupted: if a startletuple becomes relevant  or more relevant than the current one  if the current one is also a startle  or if the world changes significantly. this change is measured in terms of the evaluated values of inactive tuples: if an inactive actiontuple's evaluated value has more than doubled recently  then another probabilistic tuple selection takes place between that tuple and the current one. 
¡¡¡¡in c1's canonical action system  there are two main actiongroups. these are  in order of execution : 
  attentiongroup: chooses the creature's focus of attention  e.g. things that are large  things that are moving fast  etc. . this decision will often be overridden by laterexecuted actions. 
  primary actiongroup: the actiongroup whose actions determine large-scale body motion. 
1.1 learning in the action system 
learning is an important focus of our research  particularly the kind of learning that is observed in animals. the action system implements three types of learning that together allow creatures to be trained in a manner similar to that used to train real dogs    wilkes  personal communication  . 
credit assignment: when a new actiontuple with a high intrinsic value is activated  for example  the startle tuple  eat   which can only be run in the presence of food  we wish to give credit to the action that led to that tuple being activated. this back-propagation of value scheme is very similar to that seen in temporal difference learning  sutton 1 . however  unlike classical temporal difference learning  it is not always the tuple that actually ran that is given credit - it can be a tuple with a similar primitive action list with a more specific trigger that was relevant at the time. this choice is based on a combination of reliability and novelty metrics  the length of the paper precludes going into too much detail . whichever tuple is ultimately given credit  some percentage of the intrinsic value of the newly-activated tuple is added to the intrinsic value of the credited tuple. 
state-space discovery: when duncan the sheepdog is rewarded for sitting in response to the utterance  sit   there are two conclusions he can make: first  that sitting in response to  sit  is a good idea; second  the specific acoustic pattern that was reacted to must be a good example of the utterance  sit.  since the  sit  classifier  in the form of a percept in the perception system  is actually represented by an example-based statistical model  we can use reward information to update that model. when duncan receives a large amount of reward for responding to an utterance  that utterance is added back into the statistical model that recognized it in the first place. thus at the same time as duncan learns the value of actions  he refines his conception of the appropriate context for those actions. 
innovation: most actiontuple triggers are direct references to percepts in the percept tree. when they are  the triggers keep statistics about the reliability of the percept's children in predicting reward. the hope is that one of the children of the current trigger is actually a better predictor. for example  sitting in response to  any utterance   assume  any utterance  is a percept with several children  may be quite a good thing  but sometimes fails entirely to procure reward. by examining the reliability statistics  however  we may discover that sitting in response to a  sit utterance   assume a  sit utterance  percept is a child of  any utterance   is far better and more reliable. if this is the case  the actiontuple in question will create a copy of itself  replacing its trigger with a new trigger that references the  sit utterance  percept. this new actiontuple will be added as a  child  to the old one  and will supercede its parent when both are relevant in an action selection round. this approach was inspired  in part  by  drescher 1  who proposed a very similar scheme for exploring what are essentially state-action pairs. 
¡¡¡¡innovation can also be prompted in the percept tree. some forms of statistical models allow hierarchical classifications to be grown  for example  hierarchical clustering algorithms . if an actiontuple that references such a classifier decides to innovate  it prompts the classifier also to innovate. how this mechanism works ultimately depends on the kind of model the percept contains  clustering algorithms can isolate subclusters and spawn new percepts to represent them . thus reward feedback can also drive the growth of the percept tree. 
¡¡¡¡both state-space discovery and innovation illustrate the intimate coupling between perception and action selection. the creature only bothers to refine senses that ultimately allow it to make better decisions about what to do. 
1 navigation system 
the deceptively simple act of  eating the food  involves a host of problems: the creature must be near the food  be oriented toward it and if approaching it is necessary  must avoid physical obstacles on the way. the navigation system allows such spatial competencies to be included implicitly in the action system's high-level behaviors. 
¡¡¡¡the navigation system typically functions by overriding the motor commands passed down by the action system. in some cases this command is for an explicit 
navigation task  such as  approach.  in other cases  the command is directed to the motor system but with extra approach and orientation conditions specified which the navigation system must work to satisfy. in either case  the original decision of the action system is overridden with a more immediately appropriate motor command. if the action system requests an  approach   the navigation system might decide that the best way to implement that request is through a  gallop . if the action system requests a  beg  but the navigation system is instructed to orient the creature first  that command might be replaced with a  turn . the  beg  will continue to be overridden until the orientation condition is satisfied. 
¡¡¡¡the navigation system allows a convenient level of representation in the action system  because it relieves the action system of the burden of implementing the decisions it makes.  approaching  may indeed precede each  eating   but behaviorally  both should be part of a single  eating  act - especially from the point of view of any learning that takes place. ultimately  the majority of animal behaviors follow the  approach  orient and do  model  and the navigation system allows these behaviors to be represented with high-level atoms. 
1 motor system 
ultimately  the primary output of a virtual creature is motion  whether it be motion for the purposes of locomotion  gesticulation or expressivity. this lowest level - the level of joint-angle control of the transform hierarchy that represents the body of the creature - is controlled by the 
motor system. this system takes its inputs from motor desired and motor adverb entries of the internal blackboard.  
¡¡¡¡the design of the motor system was inspired by the work of rose et al  rose 1 . the system is organized as a verb graph in which the nodes represent hand-made animations  verbs  and the edges represent allowed transitions between verbs. the verb graph in this way represents some of the basic physical and continuity constraints of having a body. multiple labeled examples of the same verb may be provided that span an adverb space. if multiple examples are provided  the motor system does multi-target interpolation at runtime based on blend coefficients provided externally by the motor adverb entry of the blackboard. for example  examples of left-  straight- and right-walks are used to create a continuous space of directional walks.  
¡¡¡¡layering as discussed in  perlin et al. 1  is also supported by the motor system. layering allows multiple non-conflicting animations to be played concurrently  for example  walking and waving hand . duncan the sheepdog has a number of layers corresponding to body-pose  headlayer   for look-ats   tail-layer etc. 
¡¡¡¡space limitations preclude a full discussion of recent research in motor control  which has centered around an extension of the verb graph system called a pose-graph. pose-graphs allow source animation files to be decomposed into atomic animation-chunks which can then be connected into a directed graph through a  pose-space . creatures can then use this graph to explore new animations  potentially adding these new animations to its existing list of motor skills. this system can also be used to demonstrate simple and complex shaping  a  training technique through which motor skills are perfected through successive approximations  and luring  in which a trainer can lure a creature into a certain pose and then reward that pose. for a complete discussion of the pose-graph motor system and its integration into learning  see  downie 1 . 
1 results 
sheep|dog was created to demonstrate some of the basic abilities of the creatures implemented under c1. the project showed creatures acting and reacting to each other and the world. it also employed some of the group's acoustic pattern recognition research to allow duncan to classify user utterances as one of six possible commands. this classification could be trained through a  one-shot learning  interface so that a new user could achieve a high recognition rate after a very short  about 1 seconds  training routine. 
¡¡¡¡the project also served as a stress test for the system's engineering. it featured two creatures with full brains  duncan and the shepherd  and six sheep  flocking according to reynolds' boids algorithm  reynolds 1   and a number of world-obstacles  all running scaled-down versions of c1. the project also featured distributed rendering  with two clones running subsets of the system rendering the same world from different views. 
¡¡¡¡the learning algorithms being developed by our group were put to use in clicker  in which a user can train duncan using  clicker training  - an actual dog-training technique in which behaviors are  marked   by a salient click sound  and then reinforced with food reward. in this simulation  duncan can be trained to associate vocal commands with behaviors  and demonstrates a number of the phenomena that one sees in real dog training  i.e. thorndike's law of effect  shaping  resistance to extinction etc. . given an initial repertoire of a dozen basic behaviors  e.g.  sit    shake    lie-down    beg    jump    go-out   together with basic navigational and behavioral competencies we have been able to train him to respond to both symbolic gestures  i.e. game-pad button presses   and more significantly to arbitrary acoustic patterns  indeed one user trained duncan to respond to commands in gha  the language of ghana . a dozen such tricks can be trained in real-time within the space of 1 minutes. we have also demonstrated simple shaping with both motor systems and complex shaping and luring with the pose-graph based motor system 
1 discussion 
1 heterogeneous design 
heterogeneity of decision-policy and representation is seen at multiple levels in c1. the motor system uses the verb graph structure to plan movements. the action system makes decisions using actiontuples. within the action system itself  different decision-making policies are employed - startle actiontuples are treated differently from default actiontuples. this variety  we feel  contributes to the system's robustness and generality. the many kinds of problems that animals can solve entail many kinds of solutions. in order to be a viable platform for intelligence in all its multitude of forms  c1 needed to support and encourage this heterogeneity. 
¡¡¡¡in acting as the go-between for these disparate systems and representations  the creature's internal blackboard plays an important role. this generic communication device allows the easy reordering or omission of entire systems as well as the overriding of the output of one system by another in a way that would be very difficult if input and output pairs were directly coupled. 
1 simulation- vs. mental-representations 
c1 enforces a strict split between simulation representations and mental representations. the former constitute the  ground truth  of the virtual world  and are used  for example  in generating the graphics output. the latter are the perceptmemory objects. forcing a creature to act strictly on the contents of its own memory demands that it make decisions not on the basis of the world's state  but on the basis of its view of that state. 
¡¡¡¡by divorcing these two representations  many  secondlevel  effects become possible  most of them arising from situations in which the two representations fail to match  i.e. mistakes. these effects include mistaken identity  surprise  confusion and the ability to be teased. paradoxically  these  mistakes  can add greatly to a creature's realism. they also provide some insight into how real creatures commit and recover from these kinds of errors. 
1 supersumption 
two architectural themes are seen throughout c1. the first  reminiscent of brooks' subsumption  is when high-level systems send control signals to low-level systems in order to change their behavior  in this case  high-level  and  lowlevel  are not intended to reflect  degree of sophistication  . another technique for control is when the decisions of highlevel systems  which have a good general idea of what to do  are overridden by specialized low-level systems that have specific knowledge of how to do it. we call this supersumption. 
¡¡¡¡this technique is seen in the action system  when an object of attention chosen by the attention group is overridden by an object of attention chosen by the primary action group  since it controls overall action  it probably has a more appropriate choice . it is seen again in the navigation system  where motor commands sent by the action system are overridden with more immediately appropriate motor commands. in this case  the motor 
system does not know where its instructions come from and the action system need not concern itself with the details of how its instructions are implemented. 
1 easy behavior design 
throughout c1  there is much machinery to make it easy for creature designers to specify behavior. believable behavior involves many details: the creature's gaze and physical positioning must be controlled as appropriate for the active behavior  the creature's physical emotion-layers must reflect an attitude toward the behavior or the behavior's target  etc. one strength of c1 is the system's ability to handle many of these details automatically through mechanisms like the attention system  which also directs eye gaze   the navigation system  which hides behavior implementation details from the action system and the designer  and layers and adverbs in the motor system. it remains for the designer to fill in a few critical components of the behavior  such as specifying triggers and objectcontexts. the extensibility of the system also makes it clear where and how a creature's brain needs to be expanded when new abilities are added.  perhaps the perception system needs a percept to detect a new type of world event  or perhaps the motor system needs a new motor skill.  whatever the case  the system conspires to make simple things simple and complex things possible. 
1 building the entire system 
no actual brain center ever functions in isolation  but instead feeds and is fed by a myriad of other centers. intelligent behavior is the combination of all their effects. c1  through its extensibility and easy reconfigurability allows us to explore some of the basic interactions between the various components of the brain. this is why building the entire creature is critical. 
1 future work 
c1 continues to be a work in progress. work over the next year will continue to emphasize behavioral adaptation and motor learning. we are also exploring how to model development  physical and mental  and social behavior.  indeed  c1 is being used as the behavioral engine for a simulated wolf pack. we are also integrating a model of hippocampal spatial learning using landmark and pathintegration navigation that will soon give the creatures a truer sense of space. inspired by the work of gallistel  gallistel 1   we are continuing to formalize our ideas about time  rate and conditioning. 
1 related work 
our work borrows heavily from the impressive work that has come before. our ideas about super and subsumption between layers follow from brooks' work  e.g.   brooks 
1   as does our emphasis on building the whole creature. however  in contrast to brooks' work  our layers communicate through working memory which seems to us to be a more general approach and one which reflects our belief that it is difficult to impose a strict layering in practice. our emphasis on the value of taking an ethologically inspired approach follows from  reynolds 1  tu 1  blumberg 1  yoon 1   whose behavior systems were inspired by the behavioral models of ethologists such as tindbergen and lorenz. we go beyond this work in our representation of action that admits  time and rate  as first class objects  and in our integration of learning.  in addition  our approach to perception  from the percept tree to perceptmemory objects  is a good deal more sophisticated and powerful than that proposed in these earlier systems. we also allow a  behavior designer  to work at a higher level of abstraction and one which is more familiar to most people. the tangible benefit of this approach is that it is far easier to develop creatures using our system than in our previous work. for example  the creatures described in yoon 1 typically required 1 pages of source code to specify their behavior systems. by contrast  duncan is specified in less than 1 pages of source. finally  our action selection mechanism balances the pragmatic need for both deterministic and probabilistic choice of action. our representation of action sits between that typically used in reactive systems and that used in planning systems. as such it borrows from the work of maes and firby  maes 1  firby 1  and in its emphasis on choosing a few good representations  from minsky  minsky 1 . however  by focusing on the 1 big questions  when  to whom  what  for how long  and how much is it worth   the actiontuple goes beyond these previous representations in providing a surprisingly powerful and intuitive representation for action. our system also is novel in showing how learning may be integrated into this representation. our approach to learning borrows ideas from traditional reinforcement learning  ballard 1 for a review   animal psychology  gallistel 1  and dog training  gary wilkes  personal communication . our approach to innovation is directly inspired by drescher's seminal work  drescher 1 . while only touched on briefly in this paper  our system is novel in its ability to perform state-space discovery  i.e. learning new percepts   behavioral adaptation  i.e. learning new actiontuples   and motor learning  i.e. learning new motor actions  in an integrated framework. through the use of heuristics such as temporal proximity  simple statistics such as reliability and novelty  and by using the consequences of actions to help discriminate between good and bad examples from which to build models of relevant state  our system provides an interesting example of how learning may be successfully and powerfully integrated into a larger behavioral framework. while our system does not do  cognitive modeling  as proposed by funge  funge 1   the system described could easily be integrated into funge's architecture. our motor system design borrows heavily from the ideas of rose  rose 1  and perlin  perlin 1 . our contribution  particularly with respect to rose  is to demonstrate the usefulness of his approach. 
acknowledgements 
many thanks to everyone in the synthetic characters group who worked hard on c1 and sheep|dog: scott eaton  yuri ivanov  ben resner  bill tomlinson  matt berlin  jesse gray and geoff beatty. 
references 
 ballard 1  ballard  d.  an introduction to natural computation  mit press  cambridge 1. 
 blumberg et al. 1  blumberg  b.m.  gaylean  t.  multi-level direction of autonomous creatures for real-time virtual environments  siggraph 1 conference proceedings  1.  brooks  1  brooks  r.  intelligence without reason   computers and thought  ijcai 1.  
 downie 1  behavior  animation and music: the music and movement of synthetic characters  unpublished s.m. thesis  mit media lab  1.  
 drescher 1  drescher  g.l. made-up minds:a constructivist approach to artificial intelligence  mit press  cambridge 1   
 firby 1  building symbolic primitives with continuous control routines. in: proceedings of the first international conference on ai planning systems  college park md  june 1  pp 1.  
 funge et al. 1  funge  j.  tu  x.  terzopolous  d.  cognitive modeling: knowledge  reasoning and planning for intelligent characters  siggraph 1 conference proceedings  1. 
 gallistel et al. 1  gallistel  c. r.  & gibbon  j. time  rate and conditioning. psychological review  1  pp 1.  kline 1  kline  c.  observation-based expectation generation and response for behavior-based artificial creatures  unpublished s.m. thesis  mit media lab  1.  maes 1  maes  p.  situated agents can have goals   robotics and autonomous systems  vol 1. 
 mccallum 1   mccallum  a. k.  reinforcement learning with selective perception and hidden state   ph.d. thesis  cs department  university of rochester  1. 
 minsky 1  minsky  m.  society of mind  simon & schuster  new york 1. 
 perlin et al. 1  perlin  k.  goldberg  a.  improv: a system for scripting interactive actors in virtual worlds  siggraph 1. 
 reynolds 1  reynolds  c. w.  flocks  herds  and schools: a distributed behavioral model  siggraph 1 conference proceedings  1. 
 rose et al. 1  rose  c.f.  cohen  m.  bodenheimer  b.  verbs and adverbs: multidimensional motion interpolation - ieee computer graphics and applications  vol 1  number 1  1. 
 rosenbloom et al. 1  rosenbloom  p.s.  laird  j.e. & newell  a.  1  the soar papers: readings on integrated 
intelligence.cambridge  ma: mit press. 
 treisman 1  treisman  a.  1 . the binding problem. in l. squire & s. kosslyn  eds.   findings and current opinion in cognitive neuroscience. cambridge: mit press  pp 1  or  current opinion in neurobiology  1  1  pp 1.  tu et al. 1  tu  x.  terzopoulos  d.  artificial fishes: physics  locomotion  perception  behavior  siggraph 1. 
 yoon et al. 1  yoon  s.  blumberg  b.m.  schneider  g.e.  motivation-driven learning for interactive synthetic characters  autonomous agents 1 conference proceedings  1. 
behavior planning for a reflexive agent
berardina de carolis1  catherine pelachaud1  isabella poggi1  and fiorella de rosis1
1 
dipartimento di informatica e sistemistica  universit¨¤ la sapienza  roma
1
dipartimento di scienze dell'educazione  universita' roma 1
1
dipartimento di informatica  universit¨¤ di bariabstract
the aim of our research is to build a reflexive agent  that is able to either manifest an emotion it is feeling or to hide it. if the agent decides to manifest its emotion  it can establish what verbal or nonverbal signals to employ in its communication and how to combine and synchronize them. in the decision of whether to express an emotion in a given context  a number of factors are considered  such as the agent's own personality and goals  the interlocutor's characteristics and the context. in planning how to communicate an emotion  various factors are considered as well: the available modalities  face  gaze  voice etc ; the cognitive ease in producing and processing the various signals; the expressiveness of every signal in communicating specific meanings; and  finally  the appropriateness of signals to social situations.
1	introduction
artificial agents are not yet endowed with the capacity of 'feeling' emotions  mainly because emotions would imply an involvement of the hardware of a machine and this will be impossible  or at least difficult  still for some years  picard  1 . but let us suppose that we have an agent that is able to feel emotions; what could it do  how could it behave  would it manifest its emotions to a potential interlocutor or would it ruminate on its own emotion by itself  without showing its feeling 
 the effects of sharing an emotion  to the person who feels  are described in the psychology literature  rim¨¦  1 : it has been shown  for example  that people who have undergone severe shocks and share their emotions are better adapted  undergo fewer heart and pressure problems and have longer life  pennebaker  1 . of course  people differ in their proneness to display emotions: some of us are very impulsive and tend to display their emotions whatever the consequences of this display  while others are more reflexive and follow the rule  think it over seven times seven before . in fact  if i show to my boss that i am angry at him  this may make me feel better at the moment but i may risk being fired. in some cases  though  this may also show that i'm not afraid of him  and he might respect or admire me. now  the decision of whether to display my anger at my boss may be a very cold  calculated and utilitarian one. but we may also decide whether to display our emotion on the spot  in a not so conscious and rational way; still  also in this case we think it is possible to speak of a  decision  of whether to display emotions  even if this decision is not deliberate and conscious. the aim of our research is to build an agent that is able to express its emotions but also to refrain from expressing them: a reflexive  not impulsive agent.
 the idea is to build a behavior planner that starts from a discourse plan which represents the information content and the structure of a  non-affective  text  and enriches it so as to include the 'order' of displaying some emotion. this emotion will be finally expressed by verbal or non-verbal signals  or both. this generation process allows our system to synchronize various kinds of signals and to scatter them across the media  voice  face  gesture . for example: emphasis  or topiccomment  information may be outputted by means of a pitch accent  by raising eyebrows or with a head nod. the occurrence of all signals at the same time denotes an emphasis of the emotion to be manifested. therefore  representing detailed information on verbal and nonverbal signals in the behaviour planner ensures a more subtle and refined multi-modal discourse generation.
 after reviewing works related to ours  we present a general overview of the factors that affect the decision of whether to display an emotion. then  we give on overview of our system by emphasizing how our discourse plan is enriched with emotion display information  and we provide an example of how our system works. we end this paper with some concluding remarks and a view on our future work.
1	related work
in the construction of embodied agents capable of expressive and communicative behaviors  an important step is to reproduce affective and conversational facial expressions on synthetic faces  ball and breese  1  cassell et al.  1  cassell et al.  1  lester et al.  1  poggi et al.  1  rickel and johnson  1 . for example  rea is an interactive agent that is able to converse with a user in real-time  cassell et al.  1 . rea exhibits refined interactional behaviors such as gestures for feedback or turn-taking functions. cassell and stone  cassell and stone  1  designed a multimodal manager whose role is to supervise the distribution of behaviors across the several channels  verbal  head  hand  face  body and gaze . cosmo  lester et al.  1  is a pedagogical agent particularly keen on space deixis and on emotional behavior: a mapping between pedagogical speech acts and emotional behavior is created by applying elliott's theory  elliott  1 . ball and breese  ball and breese  1  apply bayesian networks to link emotions and personality to  verbal and non-verbal  behaviors of their agents. andr¨¦ et al. developed a rule-based system to simulate dialogues between lifelike characters with different personality traits  extroversion and agreeableness   andr¨¦ et al.  1 . marsella developed an interactive drama generator  in which the behaviors of the characters are consistent with their emotional state and individuality  marsella  1 .
    in most of the mentioned agents  behaviors are viewed as responses to events and actions and to the way they affect emotional reactions: what is simulated is how the agent responds with an emotion to what happens in the external context  and how an emotion affects its behavior  marsella.  1 . the system we propose in this paper aims at developing an agent that is able to be affected by the emotion  but at the same time to decide whether to express it or to refrain from expressing it  not only on the basis of the emotion per se but also according to the context in which interaction takes place. formalization of this reasoning considers  as we will see  several variables  such as the agent's goals and personality and information about the interlocutor.
1	emotion triggering factors
emotions are a biological feed-back device whose function is to provide information about the state of achievement or thwarting of our most important goals. every time something relevant happens  or is assumed to happen  in the environment  in such a way that an important goal of the agent  the goal of survival  of body safety  of reproduction etc  is  or is likely to be  achieved or thwarted  the feed-back device of emotion is activated. this consists of a set of somatic  physiological  psychological  expressive and motivational issues that alert the agent and  at the same time  provide the necessary energy and resources for reaction  castelfranchi  1 .
  ortony et al. ortony et al.  1  and  subsequently  elliott  elliott  1  defined three entities that may be responsible for the arousal of an emotion: events  actions and objects. the occurrence of an event or some particular aspects of an object may fire appraisal of an emotion; actions of oneself or others can give rise  as well  to emotions  say  reproach or shame . based on the agent's interpretation of the situation  an emotion is triggered. in this work  we refer to emotion types as defined in elliott's affective reasoner  in which 1 emotions are described  elliott  1 .
1	emotion regulation factors
the expressive part of the emotional reaction  the fact  for example  that we open eyes wide in fear  or make a frown in anger  or blush in shame  usually has a precise function. showing my rival i am angry with him may induce him to leave the field; showing my terror with wide open eyes may alert other co-specifics that a serious danger is present. this is why all theories of emotions also elaborate on the expressive aspects of the emotions and consider the expressive device as an integral part of the emotion itself  ekman and friesen  1 .
   sometimes  though  expressing our emotion may be dangerous rather than useful. if i show fear in front of a rival  this may give him a weapon and may oblige me to leave the field. humans  then  learned to be flexible in the use of the expressive part of the emotion syndrome: that we are biologically endowed with a repertoire of display devices does not necessarily mean that any time we feel an emotion  we immediately and unthoughtfully display it. a famous elaboration around the topic of what drives the decision of whether to display an emotion is the notion of display rules  that is of culturedependent rules that establish when  how and to whom to express one's own emotions. ekman and friesen studied how people tend to intensify  de-intensify  hide or mask their emotions according to social and cultural norms  ekman and friesen  1 .
   in this paper  we propose a formalization of some of these rules: we concentrate on whether one displays one's emotion or not without taking into account the subtlety of more intense or less intense display or  a fortiori  the masking of felt emotions  this will be the subject of our future work . we start from the following question. suppose i am feeling a quite strong emotion  triggered by an event  an action or an object: on what basis will i decide whether to display it or not  which are the factors that affect this decision  in our view  this depends on two aspects of the emotion: on one side  on the very nature of the emotion itself  emotional nature  ortony et al.  1  castelfranchi  1  ; on the other side  on its interaction with 'scenario factors'  poggi and bartolucci  in prep. . in sect. 1 we overview some of these factors  while being conscious that the factors and the associated values we are proposing may not be exhaustive  due to the complex nature of the emotional phenomena.
1 emotional nature
emotion valence: emotions may be either positive  when a goal is achieved  i.e.  a desirable event occurs  or negative  when a goal is thwarted  an undesirable event occurs : feeling them may therefore be pleasant or unpleasant.
emotion social evaluation: emotions are subject to social evaluations; for instance: showing envy is sanctioned  castelfranchi  1  . they may therefore be approved or sanctioned.
emotion addressee: we may distinguish between social emotions  that are necessarily felt towards some person  as love or sense of guilt  and non-social emotions  as joy or fear . social emotions may be addressed to the interlocutor itself  i  or towards a third person  o .
1 scenario factors
agent's display motive: we call display motive the reason - the specific goal - that induces us to display a particular emotion in a particular situation  poggi and bartolucci  in prep. . an agent may want her
interlocutor s  to feel the same emotion she is feeling. here  the display motive is the goal that others feel empathy with her  that  at least  they participate to her emotion. in other cases the agent displays her emotion because she wants the other to console her  to give her advice  to help her  to pity her or to reassure her about her feeling that emotion. sometimes  she may just want an objectivation  in order to better understand herself.  if the agent's goal is just to give vent to her emotion  this goal does not imply another person: she wants to display it just to give vent to the physiological energy caused by the emotion  without needing another person to cause this process. there are  though  other cases where the agent needs the presence of another person to display her emotion: i may confide a sad experience to a person in order to show her she's not more unlucky than others  or to strengthen relationships; even  i may show admiration to a person  to adulate him. a non-exhaustive list of the display motive factor includes the following: vent  empathy  consolation  advice  help  reassurance  objectivation...
agent's personality: an impulsive person will tend to display emotions more often than a shy or ruminative  non-impulsive  person.
interlocutor's features: the agent may take into account  as well  some features she attributes to the interlocutor. the following features may be relevant:
  interlocutor's personality: the interlocutor's personality interacts with the agent's display motive: if i look for empathy  but i believe that you are a 'cold' and 'egocentric' person  i will probably avoid displaying my emotion to you. this factor also interacts with the specific emotion to display: i will not display my fear to someone who is apprehensive. a non-exhaustive list of these factors is the following: envious  modest  egocentric  altruist...
  interlocutor's cognitive capacity: the factors in the following categories may take yes/no values.
 comprehension: ability to cognitively understand  the causes of the agent's emotion.
	 	experience: 	previous 	experience  	by 	the
interlocutor  of similar events that elicited the agent's emotion. experience interacts with the display motive.
 problem solving: the planning capacity of the interlocutor  to solve practical problems may be relevant  e.g. when the agent's display motive is to get help or advice .
agent-interlocutor role relationship  or power relationship between people: i may avoid displaying my anger to my boss because he has power over me and can retaliate. for the sake of simplicity  we consider the following power relationships between agent  ag  and interlocutor  i : ag has power over i  i has power over ag  neutral.
agent-interlocutor personal relationship  that is  the aggressive or friendly attitude between them: this may take four values  depending on the sense of the relationship  either ag-to-i or i-to-ag  and on its valence  either aggressive or adoptive . notice that we call 'adoptive' a relationship in which one is taking care of the other's goals. the values are then: ag adoptive i  ag aggressive i; i adoptive ag  i aggressive ag.
type of social interaction: the last important factor in the regulation of emotions is whether interaction occurs in public or not. this interacts with the agent's personality: the more impulsive i am  the more i'll be likely to display emotions even in public; the more shy i am  the more interaction  in public will inhibit my display.
1	the agent's behavior planner
in order to build  the reflexive component of our agent's mind and to interface it with its body  we developed a prototype of a behavior planner that is based on the architecture shown in figure 1. we will use the following example to describe  step by step  how the system works.
 a 1 year old girl wants to give a present to her mummy; she cuts some stripes from mummy's suit and knots them together as to make a ribbon. mummy comes in and sees the massacre .
   in such a situation  the agent  mummy  reproaches her daughter of such an action. the input of our discourse generator is therefore the communicative goal: reproach  mummy daughter 'cut suit' . the first step of the process consists in producing a 'discourse step of the process consists in producing a 'discourse plan'  d-plan  to achieve this communicative goal. this plan does not yet contain any emotional content or reference  we call it a  non-affective  d-plan ; it can be produced by a planning algorithm  from a library of plan operators  moore and paris  1  or may be retrieved from a library of plans  de carolis et al.  1 .

figure 1. the behavior planner
   in both cases  the output is a plan tree that defines the content and order of presentation of information to be conveyed in the discourse. in our case  the planner uses a library of non-instantiated plans to select the one that satisfies the posted goal. if such a plan is not available in the library  the planner builds it by appropriately combining the existing plans. the generic plan is  then  instantiated by filling the variable-slots with domain data. part of the d-plan that is generated in our example is shown in figure 1.
    after generating the  non-affective  d-plan  the hamlet component is activated. hamlet takes as an input the triggering rules  that decide whether to fire the emotion; it then applies the regulation rules by processing the scenario factors  to decide whether to display the fired emotion. the triggering rules are drawn by elliott's affective reasoner  elliott  1   while the regulation rules are similar to the display rules in  ekman and friesen  1 ; they are  however  enriched to encompass the scenario factors described above. as we anticipated in section 1  our system does not take only cultural norms into account  but a very detailed model of the context and of the interlocutor. the structure of the hamlet module is shown in figure 1.

figure 1: an example of d-plan

figure 1: the hamlet module
   let us now see some examples of triggering and regulation rules.
   the general structure of the triggering  rules is the following:
if dc-cond then  feel ag e  
where dc-cond represents a condition on the context or the domain  ag denotes the agent that is conveying the signal  and e an emotion. the evaluation of dc-cond as  for example  a desirable or undesirable event or object  is determined through a pattern-matching with the domain kb; feel is a predicate which applies to the two mentioned terms  to denote that 'the agent ag feels the emotion e'. for social emotions  this predicate applies  instead  to three terms: the agent  the emotion  and the one to whom the emotion is addressed  the interlocutor i or another agent o . events  objects and actions are represented  in d-plan  in the 'discourse focus' that is associated with every node.
¡¡¡¡let  for instance  n1 be the considered node in dplan; the focus of this node is  cut i suit   which is an 'undesirable action'  to the agent ag. the triggering rule that will applied in this case is the following:
  r1:if  focus ni  act  and  undesirable act  and performed i act  and  blames ag i act  
       then  feel ag anger 
that is:  ag feels anger if the focus of ni refers to an 'undesirable' action that was performed by the interlocutor i and ag disapproves this action.
   in our example  r1 is activated because the domain kb mentions that the action 'cut suit' is labelled as 'undesirable' in i is the agent who performed it.
   once an emotion has been triggered  the regulation rules are activated  to decide whether this emotion has to be displayed in the given context. this decision is taken by considering context features  such as: the agent's display motive  personality and role  the interlocutor's attitudes and the relation between the two agents.
   the general structure of the regulation rules is the following:
if  feel ag e  and dc-cond
         then  display ag e   or
if  feel ag e  and dc-cond     then not  display ag e .
   as for the triggering rules  dc-cond is instantiated  also in this case  by matching its variables with the content of the domain kb. if we go back to our example  the following regulation rules are activated to decide whether to display the emotion:
  in the first case  mummy is angry but she loves her daughter and knows she could not understand how distructive was the action she was doing. therefore  mummy will not display her anger.
r1:if  feel ag anger  and  adoptive ag i 
and not  understandconsequences i act 
then not display ag anger 
  in the second case  mummy thinks her daughter had comprehension capacity:
r1:if  feel ag anger  and  adoptive ag i 
and  understandconsequences i act  then  display ag anger .
     the enriched plan e-plan is produced by augmenting d-plan with the 'display' commands through application of these rules. the e-plan corresponding to the second case is shown in figure 1. notice that every node inherits the 'display' label from its parent-node  while the 'notdisplay' label is simply not inserted in the plan: so  anger will be felt but not displayed in this case  while joy is felt and displayed  because 'present' is a 'desirable object' and there is no reason for hiding the joy emotion it triggers. on the contrary  anger would be felt and displayed in the second case.
   in the next step  e-plan is transformed into an xml document and is sent to the goal-media prioritizer. this module decides how to distribute the signals that enable displaying an emotion over the different media. for example: anger might be displayed in one of the following ways  or  if very intense  in the three of them: verbally  through the hyperbole  i told you a hundred times...  ; vocally  through a loud or a high pitch voice   and facially  with tense lips and an angry frown . so  this module revises the enriched plan by deciding the type of non-verbal signals to employ at every conversational step  their combination and their synchronization with verbal communication. this is done according  again  to the context and also to the type of body that has been chosen for the agent. the xmloutput of this module is the final presentation plan  where the media have been instantiated and  when necessary  synchronized or linearized. when the goalmedia prioritizer has selected the appropriate output form  1d/1d model  audio  text...   the xml tags are interpreted and translated into parameters to drive the given output signals.

figure 1. an example of e-plan
at present  we are concentrating on the animation of a 1d facial model: the xml tags are converted into mpeg-1 facial parameters that drive the final animation. the xml tags are interpreted and translated into parameters to drive the given output signals; the natural language 'surface' generation step is adapted  as well  to the emotional state of the agent. to go back to our example  in the first case  the subplan originating from node n1 will be rendered by the following sentence  pronounced with a 'not angry' face expression:  the ribbon you used is made from my suit  that i need for my work. if you cut it  i can't wear it anymore. 
while in the second case  the mummy will say  with an 'angry' face:
 the ribbon you used is made from my suit  that i need for work. i already told you a hundred times not to touch to my things! 
1  conclusions and future work
in this work  we have presented the architecture of a system that builds a reflexive agent  that is  an agent who  when feeling an emotion   decides  whether to display it immediately or not. we have also defined the different elements on which this  decision  is based  emotional nature and scenario factors . our behaviour planner formalises these elements and then plans how to produce and synchronize the verbal and nonverbal parts of a discourse that satisfy a given communicative goal. two sets of rules are considered: trigerring rules  that fire an emotion  and regulation rules  that make the agent 'reflexive'. in the future  we plan to evaluate how believable is our reflexive agent.
references
 andre et al  1  e. andre  t. rist  s. van mulken  m. klesen  and s. baldes. the automated design of believable dialogues for animated presentation teams. in s. prevost j. cassell  j. sullivan and e. churchill  editors  embodied conversational characters. cambridge  ma: mit press  1.
 ball and breese  1  g. ball and j. breese. emotion and personality in a conversational agent. in s. prevost j. cassell  j. sullivan and e. churchill editors. embodied conversational characters. cambridge  ma: mit press  1.
 cassell et al  1  j. cassell  c. pelachaud  n.i. badler  m. steedman  b. achorn  t. becket   b. douville  s. prevost  and m. stone. animated conversation: rulebased generation of facial expression   gesture and spoken intonation for multiple conversational agents. in computer graphics proceedings  annual conference series   pages 1--1. acm siggraph  1.
 cassell et al  1  j. cassell  j. bickmore  m. billinghurst  l. campbell  k. chang   h. vilhjalmsson  and h. yan. embodiment in conversational interfaces: rea. in proceedings of chi'1  pages 1--1  pittsburgh  pa  1.
 cassell and stone  1  j. cassell and m. stone. living hand and mouth. psychological theories about speech and gestures in interactive dialogue systems. in proceedings of aaai1 fall symposium on psychological models of communication in
collaborative systems  1.
 castelfranchi  1  c.castelfranchi. affective appraisal versus cognitive evaluation in social emotions and interactions. in a.paiva editor. affective interactions. towards a new generation of computer interfaces. berlin:  springer  1.
 de carolis et al.  1  b. de carolis.  c. pelachaud and i. poggi. verbal and nonverbal discourse planning. in proceedings of international agents 1 workshop on achieving human-like behavior in interactive animated agents. barcelona  1.
 ekman and friesen  1  p.ekman and w. friesen. unmasking the face: a guide to recognizing emotions from facial clues. prentice-hall  inc.  1.
 elliott  1  c. elliott. an affective reasoner: a process model of emotions in a multiagent system  technical report no. 1 of the institute for the learning sciences northwestern university 1.
 lester et al.  1  j.c. lester  s.g. stuart  c.b. callaway  j.l. voerman  and p.j.fitzgerald. deictic and emotive communication in animated pedagogical agents. in s. prevost j. cassell  j. sullivan and e. churchill  editors  embodied conversational characters. mitpress  1.
 mann and thompson  1  w.c mann and s. thompson. rhetorical structure theory: towards a functional theory of text organization. text  1 :1  1.
 marsella  1  s c marsella. sympathy for the agent: controlling an agent's nonverbal repertoire. in: achieving  human-like behavior in interactive animated agents. 1th int conf autonomous agents  barcelona  1.
 moore and paris  1  j.d. moore and c. paris. planning text for advisory dialogues: capturing intentional and rhetorical information. computational linguistics  1   1  1.
 ortony et al.  1  a. ortony  g.l. clore and a. collins. the cognitive structure of emotions. cambridge university press  1.
 pennebaker  1  j.w. pennebaker. confession  inhibition and disease. in l.berkowitz  ed.   advances in experimental social psychology 1. orlando  fl.: academic press   1  1.
 picard  1  r. picard. affective computing  mit press  1.
 poggi et al.  1  i. poggi  c. pelachaud  and f. de rosis. eye communication in a conversational 1d synthetic agent. special issue on behavior planning for life-like characters and  avatars of ai
communications  1.
 poggi and bartolucci  in prep.  i.poggi and l.bartolucci. factors affecting the displaying of emotions. in preparation.
 rickel and johnson  1  j. rickel and w.l. johnson. animated agents for procedural training in virtual reality: perception  cognition  and motor control. applied artificial intelligence  1--1  1.
  rim¨¦  1  b.rim¨¦. le partage social des emotions. in b.rim¨¦ et k. scherer editors. les emotions. gen¨¨ve: delachaux et niestl¨¦  1.

multi-agent systems
cooperative behavior















learning procedural knowledge to better coordinate1
andrew garland and richard alterman
volen center for complex systems
brandeis university waltham  ma 1
{aeg alterman} cs.brandeis.edu

abstract
a fundamental difficulty faced by groups of agents that work together is how to efficiently coordinate their efforts. this paper presents techniques that allow heterogeneous agents to more efficiently solve coordination problems by acquiring procedural knowledge. in particular  each agent autonomously learns coordinated procedures that reflect her contributions towards successful past joint behavior. empirical results validate the significant benefits of coordinated procedures.
1	introduction
research on groups of agents that work together is a large and growing field that covers topics such as autonomous robots  software agents  and smart objects. a fundamental difficulty faced by such agents is how to coordinate their efforts when they have overlapping objectives. this coordination problem is both ubiquitous and challenging  especially in environments where agents have limited knowledge about  and control over  other agents and the world around them.
¡¡this work is part of a line of research interested in groups of agents that interleave planning and execution  desjardins et al.  1; grosz and sidner  1; levesque et al.  1; durfee andlesser  1;decker and lesser  1;grosz and kraus  1; tambe  1 . in the present work  individual agents are motivated by personal objectives and do not reason about group-wide objectives or attempt to establish or maintain group-wide mental attitudes. the extent to which their activity can be successful depends on the degree to which the individuals' objectives converge.
¡¡one approach to the coordination problem is to design agents to have common built-in knowledge about the group  such as knowledge of the planning or execution abilities of all agents. this common knowledgemakes agents more likely to be able to efficiently solve coordination problems that occur at runtime. unfortunately  for many domains there will continue to be coordination problems that lie outside the initial design because of the difficulty of foreseeing all possible interactions in complex  dynamic environments.
¡¡in this paper  an agent acquires knowledge about the environment and other agents from experience  supplementing any a priori common knowledge she might have. thus  individual agents learn to better coordinate their actions so that the agents' future behavior more accurately reflects what works in practice.
¡¡the learning techniques are memory-based and a novel contribution is a technique to learn coordinated procedures based on past  possibly unplanned  successful joint behavior. these procedures are extracts of execution traces  which are the result of multiple planning sessions occurring at various times during the activity  and are composed around  and organized by  coordination points  alterman and garland  1 . unexpected requests and responses allow an agent to acquire coordination knowledge about other agents  and constitute the building blocks of learned coordinated procedures.
¡¡this paper begins by outlining the framework within which the coordination problem is studied. the next section presents the key technical details that allow agents to learn coordinatedprocedures. empirical results then demonstratethat coordinated procedures provide a statistically significant improvement in run-time performance and are used efficiently when planning. the paper ends with a discussion of related work.
1	coordinating independent agents
this section describes the aspects of the system framework that are relevant to studying the coordination problem. the most noteworthy features are the autonomy of the agents  the distribution of both problem-solving knowledge and execution ability  and the role of communication as a coordination mechanism. given these attributes  even seemingly simple problems create imposing hurdles to efficient coordination.
1	an example of a coordination problem
in the test-bed domain  called movers-world  the task is to move boxes from a house onto a truck or vice versa. movers-world has multiple agents of different types: some are  lifters  and some are  hand-truck operators . the agents do not know their type or even have an internal representation of the concept of type. most actions are type-
specific  but all agents are able to move and communicate. the duration of conversations between two agents varies


state 1 l1's private knowledge	state 1
figure 1: the distribution of problem-solving knowledge.

based on the content of the dialog. the agents have no builtin planning knowledge about the execution abilities of agents of other types. each agent has the autonomy to decide which goal s  to work on at any time.
¡¡the rest of this subsection discusses how coordination problems arises in movers-world. the plans a lifter can generate and the plans a hand-truck operator can generate are contrasted in the context of moving a single box onto a truck. by expanding the problem to include more boxes  the difference in planning ability makes achieving optimal coordination impossible and achieving even near-optimal behavior unlikely.
¡¡a solution path for a simple situation where a lifter  l1  and a hand-truck operator  hto  could work together to get a box onto the truck is shown in figure 1. over the course of the solution  the box  moves  through eight different states  represented by ovals listing the salient predicates . only l1 knows how to transform the box from state 1 to state 1. only hto knows how to get from state 1 to state 1. and only l1 knows how to get the box from state 1 to state 1.
¡¡l1 cannotgenerate a plan to match this solution path on her own since l1 has no planning knowledge of the hand-truckor of hto's capabilities. backward chaining can identify state 1 as a precursor to state 1 and forward-chaining can identify state 1 as a successor to state 1. however  l1 cannot distinguish the pair of states  state 1  state 1  that is relevant to this solution path from the many other pairs of states that are not relevant to any solution path.
¡¡coordination becomes more of an issue when the agents want to move two boxes onto the truck in as little time as possible. optimal performance involves no communication whatsoever and would take 1 ticks of a simulated clock. however  without communication  l1 would never construct a plan to load box1 onto the hand-truck! l1's expectation at the outset would be to move both boxes to the truck by carrying them; hto's expectation is that both boxes would be moved via the hand-truck. furthermore  neither knows that the other is working on the same two goals.
ticks 1 to 1: hto and l1 converse
 l1  would you help me achieve  on box1 handtr   
 hto  i'll help  but you'll have to wait a bit. 
ticks 1 to 1:  lift l1 box1 
ticks 1 to 1:  load l1 box1 handtr 
ticks 1 to 1:  tilt-handtr hto handtr 
ticks 1 to 1:  lift l1 box1 
ticks 1 to 1:  push-handtr hto handtr street 
ticks 1 to 1:  carry l1 box1 street 
ticks 1 to 1:  stand-handtr hto handtr 
tick	1: hto trying to contact l1 ...
ticks 1 to 1: hto and l1 converse
 l1  would you help me achieve  on box1 truck   
 hto  i'll help  but you'll have to wait a bit. 
ticks 1 to 1:  load l1 box1 truck 
ticks 1 to 1:  unload l1 box1 handtr 
ticks 1 to 1:  load l1 box1 truck 
figure 1: a near-optimal solution to a coordination problem.

¡¡the closest to optimal that is possible given baseline coordination abilities is 1 ticks as shown in figure 1. that solution requires that l1 agrees to help hto on both occasions and that l1 correctly adapts her plan. while none of these is unlikely independently  neither agent possesses enough knowledge to reliably act in this way. as the complexity of the problems increases by including other agents and increasing the number of boxes  there is an exponential increase in the number of decisions that all must be made  correctly  for the community to perform even this close to optimal.
¡¡coordination problems in this domain are not solely a consequence of the distribution of planning knowledge. even if both agents had common goals and planning knowledge  there is ambiguity about the order on which to work on the goals. also  when there is uncertainty about the outcome of actions  they may have different preferences among alternative solutions.1 finally  agents may have different beliefs about the current state of the world  leading to different beliefs about the best course of action.
1	communication as a coordination mechanism
in terms of the coordination problems faced by the agents  a central feature of this system is that communication  cooperation  and coordination are shaped by the autonomy of the agents. agents do not communicate at planning time; they plan independently act independently and only communicate when necessary to establish cooperation or to maintain coordination. each problem includes some goal s  that can only be solved by agents that work together  so communication is an essential part of the community activity.
¡¡communication happens at coordination points  which are defined as points in the activity where an actor cannot progress without the assistance of someone else. if all actions are reversible and the goals of the agents do not conflict  conversing at individual coordination points at the time when they arise is sufficient to ensure that the activity will be completed.
¡¡agents' decision-making strategies are based upon personal  rather than group-wide  objectives. if an agent is willing to cooperate  she may be unable to construct a plan to do so; an agent who is unwilling or unable to assist can propose an alternative that the original requester may now contemplate adopting. after agreeing to cooperate  an agent can  opt out  at any time  without obligation to notify other agents.
¡¡when cooperation is first established during communication  the agents must determine how they will coordinate. sometimes  nothing needs to be done to begin coordinating; more often  though  the requester will idle for several time steps - for example  if a lifter is not currently ready to lift the box. an agent will stop waiting if another agent initiates communication  either to establish a new agreement or to indicate progress on a current agreement  e.g.  the other lifter now indicates she is ready to act . the agent will also stop waiting upon observing the completion of the request  e.g.  the box appears on the hand-truck . finally  if an agent is idle  too  long  i.e.  longer than a pre-set threshold   the agent inquires about the status of her request  possibly discovering that the other agent has opted out .
¡¡communicationis the onlymechanismwherebyagents can check if they are working on the same goals since there are no global structures  such as blackboards  available. while observation is sufficient to engineer the exit from coordination problems  the agents are not assumed to possess the common goals and knowledge of each other required in order to solve coordination problems without any communication  cf. genesereth et al.  1; huber and durfee  1 .
1	leveraging past experience
this section will describe the case-based reasoning  kolodner  1  techniques that individual agents use to acquire and use coordinated procedures in order to better coordinate. a guidingprincipleof these techniquesis that memoryshould be organizedaroundcoordinationpoints. there is no communication between the agents during the learning process; the memories are created and maintained by each agent independently.
1	learning coordinated procedures
coordination points influence three facets of the learning process. most importantly  coordination devices that represent past successful joint achievement of coordination points form the skeleton of future plans. next  memories are primarily indexed based on expected future requests in order to make the memory more likely to be recalled during communication. third  coordination points influence the determination of state-based secondary indices.
figure 1 contains pseudo-code for learncoordinated-
procedure  which is the method by which agents transform experience into memories. coordinated procedures are derived fromexecutiontraces  which are quite noisy because actions and requests can fail or be ineffective for other reasons. there are many details involved in the process of transforming such noisy data into something suitable for learning that have not been addressed in prior work on procedurallearning. space prevents covering many of them here; the interested
learncoordinatedprocedures  executiontrace ¡Ô cleantrace ¡û clean executiontrace 
segmentgoalspairs ¡û segment cleantrace 
forall
coresegment ¡û removeinefficiencies segment goals  storecoordinatedprocedure coresegment goals 
storecoordinatedprocedure  coresegment goals  ¡Ô procedure ¡û list   times ¡û list   requests ¡û list   forall step in reverse coresegment  if keep step procedure 
procedure ¡û push step procedure  times ¡û list   requests ¡û list  
times ¡û push starttime step  times  if step is an agreement to achieve a coordination point
requests ¡û push step requests 
if head procedure  is not a member of requests
   addcasebaseentry procedure goals null times  forall r in requests
rtimes ¡û removelaterthan times starttime r   addcasebaseentry procedure goals r rtimes 
figure 1: algorithms to learn coordinated procedures.

reader is directed elsewhere  garland  1  for more about cleaning  segmenting  and removing inefficiencies from execution traces. there are two other non-trivial procedures  keep and addcasebaseentry  whose pseudo-code is not given but whose important aspects will be described below.
¡¡storecoordinatedprocedure converts an execution trace segment into a coupling of a coordinated procedure and its indexing information. the primary tasks of storecoordinatedprocedure are:
1. construct a coordinated procedure by summarizing andoptimizing the execution trace segment.
1. determine the set of expected requests that the agentcould use as retrieval cues in the future.
1. for each entry to be added to the case base  determinethe set of states in which the agent should consider retrieving the entry.
¡¡the motives for summarizing an execution trace segment are: the particular time at which subordinate goals were achieved at runtime may be misleading; the stored plan will be more easily adapted in the future  at the cost of regenerating the original action if it is needed again ; and the statebased indices for case-base entries are generalized each time the same procedure is stored under different indices. optimizations allow agents to improve upon  rather than just repeat  the way in which some coordination points are jointly achieved.
¡¡storing procedures under several indices is a good heuristic when agents do not share indexing information and there is uncertainty about the setting at the outset of cooperation. in addition  the state of the world at the start of the first step of the coordinated procedure is not the only reasonable benchmark for determining future settings in which the procedure will be effective. alternative indexing states are provided by the  removed  steps in the execution trace summary that precede the first kept step.
the pseudo-code in figure 1 sets forth how storecoor-
dinatedprocedure records indexing information while adding actions to the coordinated procedure. a call to the keep function determines which actions from the execution trace segment are added to the procedure. for each step  whether it is kept or not  the time at which it was started is added to a list of indexing times and agreements are added to a list of expected requests. when a step is added to the procedure  these lists are reset.
¡¡after the coordinated procedure has been determined  it is stored into memory without any reference to an expected request  unless the first step in the plan is an expected request . next  the procedure is stored again for each expected request so that the request is part of the primary storage index. indexing in this way facilitates retrieving coordinated procedures during conversations. the means by which coordination points influence the state-based secondary indices is less direct  and is determined by addcasebaseentry.
¡¡addcasebaseentry makes representational changes to the procedure and maintains the structure of the underlying case base. in terms of the organization of memory  a notable division is that storecoordinatedprocedure computes the relevant times to check the state of the world; addcase-
baseentry converts those states into concrete case-base indices. for this work  the secondary indexing scheme is influenced by the top-level goals and the expected requests of the entry. the literals from these are culled and then all relevant predicates in the state relating to the literals are identified. relevancy is determined from the surface features of the environment  rather than from analysis of the stored plan  cf. hammond  1; veloso and carbonell  1 .
¡¡the most interesting aspect of keep is the treatment of coordination points. the principle summarization criteria is to remove actions that are planner-reconstructible - this produces a skeleton of coordination mechanisms that is fleshed out by the essential individual actions needed to support the achievement of coordination. an important characteristic of summarization is that it never removes:  1  coordination mechanisms for agreements   1  coordination points that correspond to unexpected requests  or  1  actions that end a shift between goals. requests for joint action require special handling to ensure that the initiator only keeps the joint action and the assistant only remembers to expect a request.
¡¡the heuristic optimizations currently implemented are intended to eliminate some conversations altogether. for example  based on past experience  a lifter learns to load the hand-truck without being explicitly told to do so. likewise  the hand-truck operator learns to expect the lifter to load the hand-truck without the hand-truck operator's guidance. the risk of the heuristics is that if agents do not recall compatible memories  time and effort may be wasted.
¡¡one optimization rule  implemented in keep  is that an agent who agreed to a request removes the corresponding coordination mechanism from the coordinated procedure. this
time	actionoutcome1 agreed with l1 to ...summarized1  lift-together xlbox1 summarized1 hto asked to  on xlbox1 handtr1  optimized
1 l1 agreed to ...	summarized
1  load-together xlbox1 handtr1 	kept
1  lift mbox1 	summarized
1  carry mbox1 street1 	summarized
1  load mbox1 truck1 	kept
1 hto asked to  on xlbox1 truck1 	optimized
1 l1 agreed to ...	summarized
1  unload-together xlbox1 handtr1  summarized
1 l1 agreed to ...	summarized
1  load-together xlbox1 truck1 	kept
l1 adding case-base entry mem1
procedure:   load-together  l1  l1 
 load  l1  l1 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡ load-together  l1  l1   top-level goals:   on  l1  l1 
 on  l1  l1  
request: nil
state indices based on ticks 1  1  1  1  1
l1 adding case-base entry mem1 derived from mem1
request:  lift-together  l1  by  l1 state indices based on tick 1
l1 adding case-base entry mem1 derived from mem1
request:  on  l1  l1  by  l1 state indices based on ticks 1  1  1
figure 1: three entries for a single coordinated procedure.

guideline reflects an optimistic belief that the agent knows the right time to accomplish the request without being specifically asked. a second guideline  dual to the first  is part of the representational changes performed by addcasebaseentry. for an initiator of a request  the procedure passed into
addcasebaseentry contains a coordination mechanism that will prompt the agent to establish the same request again in the future. this mechanism is heuristically converted into an  optimistic  expectation that the request for service will be satisfied without a direct request. these two optimizations currentlyonly relate to requests for service and not to requests for joint action  which require more precise timing.
¡¡figure 1 shows some  lightly edited  output when agent l1 is adding multiple case-base entries for the same coordinated procedure. in this example  the agent is creating one top-level entry and two request entries. the performance that led to learning this procedure was exceptional  1% fewer ticks than average  and was chosen for illustrative purposes; execution traces are normally much more chaotic. the only failure  which is not shown in the figure  is an attempt at time 1 by the two lifters to jointly carry the box to the street.
1	acting from shared past experience
acting from shared past experience can lead agents to coordinate more efficiently. for example  when an agent receives a familiar request  she can retrieve a plan which anticipates future requests rather than merely creating a plan to satisfy that single request. when different agents anticipate the same

points of coordination  they can coordinate more effectively for three reasons:
1. they will not waste time discussing alternatives that willprove to be unproductive.
1. they will not waste time negotiating over two viable alternatives.
1. in some cases  they can eliminate communication entirely.
¡¡unfortunately  acting from past experience does not guarantee that agents will coordinate more efficiently. first of all  there may not be regularity in the types of coordination problems faced by the community. second  agents will sometimes assess the same situation in disparate manners. this reflects both differences in experience between agents and the openendedness of interpretationin general. thus  it is important to store procedures so that different agents are likely to retrieve compatible memories in many situations. in this paper  compatible viewpoints on which past activities to recall develop when storage is guided by coordination points and surface features of the environment.
¡¡when planning  agents prefer coordinatedprocedures from similar past activities to plans constructed by the baseline planner. however  an agent does not search her case base when a planning session immediately follows the failure of a retrieved plan. for the experiments in the next section  coordinated procedures are recalled during planning slightly more than 1% of the time during the last problem-solvingepisode.
¡¡an agent measures the similarity of a case-base entry to the current setting by determining what percentage of the stored predicates can be made true given the possible mappings of literals in the current state to required role-fillers for the entry. for those entries that meet or exceed the current highest similarity  at least above a pre-set threshold of 1   the coordinated procedure stored in the entry is checked to see if it can be adapted to the current state of the world. if so  the current highest similarity is updated. finally  the best of the best is selected from the entries with maximal similarity. there are various ways to determine the best of the best such as randomly or by the number of storages for the entry. the results in the next section rank the plans using the same heuristic as the baseline planner  most time-efficient  and break any remaining ties randomly.
¡¡in experiments conducted so far  the number of entries in each agent's case base has been less than 1  so neither storage nor retrieval was a bottleneck. in general  a more refined secondary indexing scheme  such as indexing by differences  kolodner  1a b  might be needed. further refinements such as distinguishing between short and long term memory or selectively  forgetting  past cases  smyth and keane  1  may also be fruitful.
1	empirical results and analysis
this section supports the claim that learning coordinated procedures leads agents to better coordinate with empirical studies from an implemented testbed. the experimental methodology takes into account the possible influence of sampling bias and ordering effects; each data point reported is the average of 1 trials.
¡¡in all of the experiments in this section  agents acquire coordination knowledge independently of learning coordinated procedures - agents learn more accurate probability estimates of the likelihood of success of possible actions. agents use probabilities when planning from scratch  when deciding who to ask for help  when deciding whether to cooperate  and when adapting coordinated procedures to match the current problem setting. having more accurate probability estimates  therefore  can cause agents to behave more efficiently. a learning structure  based on cobweb  fisher  1  trees  enables agents to increase the accuracy of probability estimates by generalizing past experiences interacting with the domain and other agents. for more details  see garland .
¡¡there are many ways to measure the performance of the agent community  such as the number of primitive actions attempted and the number conversations that occur. the best overall measure of community effort  however  is the number of ticks of a simulated clock that transpire during the course of the community solving the problem. the number of ticks measures both action and communication effort  in addition to time when the agents are idle for one reason or another  see figure 1 .
¡¡in order to measure the advantages of learning coordinated procedures under various conditions  the type of coordinated procedures learned and the initial ability of agents to solve coordination problems were varied. the possible types of coordinated procedures are:
basic a basic coordinated procedure is not optimized and only achieves a single goal.
improved an improved coordinated procedure is optimized and may achieve multiple goals  as in figure 1 .
a third possibility is to learn better probability estimates only and not learn any coordinated procedures.
¡¡the three initial levels of ability to solve coordinationproblems are:
minimal the minimal amount of coordination knowledge is a predicate-based communication language based on goals  coordination points  and the ability to make unambiguous external references.
basic basic agents have additional planning knowledge of other agents and the ability to make goal-selection choices based on past experience. the coordination information built into basic agents was determined by analyzing the coordination knowledge implicitly acquired by basic coordinated procedures.
expert expert agents have additional hand-crafted goalselection and coordination strategies  including an extension of the heuristic optimizations.
note that basic and expert agents have abilities that exceed those assumed in section 1.
             
¡¡table 1 presents a tabular summary of the results of running the system for each of the combinations of initial ability and type of coordinated procedures learned. for each of these nine runs  the chart shows the number of ticks required to solve the tenth problem-solving episode faced by the community. the data in the first column indicate that improving the initial coordinationability of non-learningagents substantially reduces the number of ticks. scanning across each row of table 1 shows that  regardless of the initial coordination ability of the agents  learning basic coordinated procedures
led to significant reductions in the number of ticks  with 1% confidence . improved coordinated procedures are always significantly more effective than basic ones.
¡¡the second row of table 1 warrants special attention. by design  agents with basic initial coordination abilities have access to the same goal-selection and planning knowledge as agents can learn over time through basic coordinated procedures. the fact that agents with basic abilities nonetheless benefit from learning such procedures shows that these pieces of knowledge are more useful as a unit  when retrieved from the case base  than when accessed separately.
¡¡the benefits of learning coordinated procedures are immediate. this is evinced by the learning curves  plotted with their 1% confidence intervals  shown in figure 1. a comparison of curves mn and en  two runs when agents are not learning coordinated procedures  points out that the impact of augmenting the initial ability to solve coordination problems does not diminish over time. a comparison of curves mi and mn  two runs when agents have minimal initial abilities to solve coordination problems  shows that the importance of learning coordinated procedures grows over time. most importantly  comparing curves mi and en reveals that learning coordinatedprocedures is more effective than initial expertise by the second problem-solving episode.
             

	1	1	1	1	1
problem solving episode number
figure 1: comparing runtime effort.

	1	1	1	1	1
   problem solving episode number figure 1: comparing planning effort.

¡¡another significant advantage of learning coordinated procedures is in controlling the amount of planner search. figure 1 depicts planning effort  as measured by the average number of planning nodes expanded per call to the planner. the disparity between curves mn and en provides evidence that initial expertise comes with a price - the increased amount of planning information can lead to a large increase in planner search. however  learning and acting from past experience controls planner search so effectively that experts who learn coordinated procedures  curve ei  expanded fewer planning nodes than agents with minimal initial knowledge who do not learn them  curve mn .1
¡¡learning coordinated procedures leads to similar statistical improvement in the number of conversations  the number of ticks spent conversing  the number of attempted actions  and the number of successful actions. furthermore  these results hold across a wide spectrum of possible goal-selection strategies  cooperation strategies  and communication costs  garland  1 .
¡¡overall  the results clearly demonstrate that coordinated procedures are an effective resource for agents to learn to better coordinate their run-time activities. learning coordinated procedures benefits agents regardless of the initial ability to solve coordination problems. there is leverage in storing and retrieving plans based on the surface features of the environment  rather than having access to similar information that is accessed at separate times. finally  the techniques are very effective in preventing increased planner search.
1	related research
learning coordination knowledge in multi-agent systems has been studied in frameworks with different assumptions than those made in this paper  such as in homogeneous systems  sugawara and lesser  1  and communication-free domains  haynes and sen  1; ho and kamel  1 . in a system with similar underpinnings  prasad and lesser  implement a learning system that extends the generalized partial global planning  decker and lesser  1  architecture by allowing the agents to choose a coordination mechanism  from a commonly known set of choices  based upon the results of training runs. all agents make the same choice because agents communicate their local viewpoints to all other agents to form a consistent global viewpoint and each agents records the same training data. by contrast  in this paper  each agent learns independently on the basis of their own experiences. also  the techniques are applicable in the absence of built-in common knowledgeand agents acquire procedures in addition to compatible viewpoints about how to coordinate activity.
¡¡in this work  procedural learning is based on run-time behavior  which differs from learning techniques based upon the output of planning sessions  carbonell  1; veloso and carbonell  1; laird et al.  1; kambhampati and hendler  1; sugawara  1 . reusing a plan derivation will not produce a sequence of actions to better solve a similar problem in the future if the derivation was deficient  due to the agent's incomplete knowledge . on the other hand  execution traces encapsulate the history of both planned and unplanned agent interactions with the domain. consequently  procedures are learned that were not developed in a single  or multiple  planning histories. thus  some coordinated procedures stored in memory can represent unplanned successes. remembering examples of past successes differs from previous approaches to changing run-time behavior that have emphasized learning from failures  hammond  1; haynes and sen  1 .
references
richard alterman and andrew garland. convention in joint activity. cognitive science  1   1.
jaime carbonell. derivationalanalogy and its role in problem solving. in proc. third national conference on artificial intelligence  pages 1  1.
keith s. decker and victor r. lesser. generalized partial global planning. intl. journal of intelligent and cooperative information systems  1 :1  1.
marie e. desjardins  edmund h. durfee  charles l. ortiz  and michael j. wolverton. a survey of research in distributed  continual planning. ai magazine  1 :1  1.
edmund h. durfee and victor r. lesser. partial global planning: a coordination framework for distributed hypothesis formation. ieee transactions on systems  man  and cybernetics  1 :1  1.
douglas h. fisher. knowledge acquisition via incremental conceptual clustering. machine learning  1-1  1.
andrew garland. learning to better coordinate in joint activities. phd thesis  brandeis university  1.
michael genesereth  matt ginsberg  and jeffrey rosenschien. cooperationwithoutcommunication. in proc. fifth national conference on artificial intelligence  pages 1- 1  1.
barbara grosz and sarit kraus. collaborative plans for complex group action. artificial intelligence  1-1  1.
barbara grosz and candace sidner. plans for discourse. in philip r. cohen  jerry morgan  and martha e. pollack  editors  intentions in communication  pages 1. bradford books  1.
kristian j. hammond. case-based planning: a frameworkfor planning from experience. cognitive science  1-1  1.
thomas haynes and sandip sen. learning cases to resolve conflicts and improve group behavior. intl. journal of human-computer studies  1-1  1.
fenton ho and mohamed kamel. learning coordination strategies for cooperative multiagent systems. machine learning  1-1 :1 1.
marcus j. huber and edmund h. durfee. deciding when to commit to action during observation-based coordination. in proc. first intl. conference on multiagent systems  pages 1  1.
subbarao kambhampati and james a. hendler. control of refitting during plan reuse. artificial intelligence  1- 1  1.
janet l. kolodner. maintaining organization in a dynamic long-term memory. cognitive science  1-1  1.
janet l. kolodner. reconstructive memory: a computer model. cognitive science  1-1  1.
janet l. kolodner. case-based reasoning. morgan kaufmann publishers  san mateo  ca  1.
john e. laird  paul s. rosenbloom  and alan newell. chunking in soar: the anatomy of a general learning mechanism. machine learning  1-1  1.
hector j. levesque  philip r. cohen  and jose h. t. nunes.¡ä on acting together. in proc. eighth national conference on artificial intelligence  pages 1  july 1.
m. v. nagendra prasad and victor r. lesser. learning situation-specific coordination in cooperative multi-agent systems. autonomous agents and multi-agent systems  1-1  1.
barry smyth and mark t. keane. remembering to forget. in proc. fourteenth intl. joint conference on artificial intelligence  pages 1  1.
toshiharu sugawara and victor lesser. learning to improve coordinated actions in cooperative distributed problemsolving environments. machine learning  1-1 :1- 1  1.
toshiharu sugawara. reusing past plans in distributed planning. in proc. first intl. conference on multiagent systems  pages 1  1.
milind tambe. towards flexible teamwork. journal of artificial intelligence research  1-1  1.
manuela veloso and jaime carbonell. derivational analogy in prodigy: automating case acquisition  storage  and utilization. machine learning  1-1  1.

multi-agent systems
multi-agent systems


1	multi-agent systems

















1	multi-agent systems


1	multi-agent systems
robust multi-unit auction protocol against false-name bids
makoto yokoo  yuko sakurai  and shigeo matsubara
ntt communication science laboratories
1 hikaridai  seika-cho
soraku-gun  kyoto 1 japan email: {yokoo  yuko  matsubara} cslab.kecl.ntt.co.jp
url: http://www.kecl.ntt.co.jp/csl/ccrg/members/{yokoo  yuko  matubara}

abstract
this paper presents a new multi-unit auction protocol  ir protocol  that is robust against false-name bids. internetauctions have become an integral part of electronic commerce and a promising field for applying agent and artificial intelligence technologies. although the internet provides an excellent infrastructure for executing auctions  the possibility of a new type of cheating called false-name bids has been pointed out. a false-name bid is a bid submitted under a fictitious name. a protocolcalled lds has been developed forcombinatorial auctions of multiple different items and has proven tobe robustagainst false-name bids. although we can modify the lds protocol to handle multi-unit auctions  in which multiple units of an identical item are auctioned  the protocol is complicated and requires the auctioneer to carefully predetermine the combination of bundles to obtain a high social surplus or revenue. for the auctioneer  our newly developed ir protocol is easier to use than the lds  since the combination of bundles is automatically determined in a flexible manner according to the declared evaluation values of agents. the evaluationresultsshow that the irprotocolcan obtain a better social surplus than that obtained by the lds protocol.
1	introduction
internet auctions have become an especially popular part of electronic commerce  ec . the internet provides an excellent infrastructure for executing much cheaper auctions with many more sellers and buyers from all over the world. however  in  sakurai et al.  1   the authors pointed out the possibility of a new type of cheating called false-name bids  i.e.  an agent may try to profit from submitting false bids made under fictitious names  e.g.  multiple e-mail addresses. such a dishonest action is very difficult to detect since identifying each participant on the internet is virtually impossible. compared with collusion  rasmusen  1; varian  1   a false-name bid is easier to execute since it can be done by someone acting alone  while a bidder has to seek out and persuade other bidders to join in collusion.
¡¡auctionscan be classified into three types by the numberof items/units auctioned:  i  single item  single unit   ii  single item  multiple units  and  iii  multiple items. in  sakurai et al.  1; yokoo et al.  1a   we analyzed the effects of false-name bids on auction protocols. the obtained results can be summarized as follows.
  for multi-unit auctions  where the demand of a participant can be multiple units  or for combinatorial auctions of multiple items  the generalized vickrey auction protocol  gva   varian  1  is not robust against falsename bids.
  there exists no auction protocolthat simultaneously satisfies incentive compatibility  pareto efficiency  and individual rationality for all cases in the above situations if agents can submit false-name bids.
¡¡in this paper  we concentrate on private value auctions  mas-colell et al.  1 . in private value auctions  each agent knows its own evaluation values of goods  which are independent of the other agents' evaluation values. we define an agent's utility as the difference between the true evaluation value of the allocated goods and the payment for the allocated goods. such a utility is called a quasi-linear utility  mas-colell et al.  1 . these assumptions are commonly used for making theoretical analyses tractable.
¡¡in a traditional definition  mas-colell et al.  1   an auction protocol is  dominant strategy  incentive compatible  if bidding the true private values of goods is the dominant strategy for each agent  i.e.  the optimal strategy regardless of the actions of other agents. the revelation principle states that in the design of an auction protocol we can restrict our attention to incentive compatible protocols without loss of generality  mas-colell et al.  1; yokoo et al.  1a . in other words  if a certain property  e.g.  pareto efficiency  can be achieved using some auction protocol in a dominant strategy equilibrium  i.e.  the combination of dominant strategies of agents  the property can also be achieved using an incentive compatible auction protocol.
¡¡in this paper  we extend the traditional definition of incentive-compatibility so that it can address false-name bid manipulations  i.e.  we define that an auction protocol is  dominant strategy  incentive compatible  if bidding the true private values of goods by using the true identifier is the dominant strategy for each agent. also  we say that auction pro-

tocols are robust against false-name bids if each agent cannot obtainadditional profitby submittingfalse-name bids. ifsuch robustnessis notsatisfied  theauction protocol lacks incentive compatibility.
¡¡we say an auction protocolis pareto efficient when the sum of all participants' utilities  including that of the auctioneer  
i.e.  the social surplus  is maximized in a dominant strategy equilibrium. in a more general setting  pareto efficiency does not necessarily mean maximizing the social surplus. in an auction setting  however  agents can transfer money among themselves  and the utility of each agent is quasi-linear; thus the sum of the utilities is always maximized in a pareto efficient allocation.
¡¡an auction protocol is individually rational if no participant suffers any loss in a dominant strategy equilibrium  i.e.  the payment never exceeds the evaluation value of the obtained goods. in a private value auction  individual rationality is indispensable; no agent wants to participate in an auction where it might be charged more money than it is willing to pay.
¡¡in this paper  we concentrate on multi-unit auctions  in which multiple units of an identical item are sold. multi-unit auctions have practical importance and are widely executed already in current internet auction sites such as ebay  yahoo!. in current internet auctions  a participant is assumed to want only one unit of an item. by allowing a participant to bid on multiple units  e.g.  he/she needs two units of the item at the same time  as in combinatorial auctions  sandholm  1; fujishima et al.  1; lehmann et al.  1   we can increase both the utility of the participants and the revenue of the seller.
¡¡the gva protocol  varian  1  is one instance of the well-known clarke mechanism  mas-colell et al.  1 . it satisfies incentive compatibility  pareto efficiency  and individual rationality in multi-unit auctions when there exists no false-name bid; however  this protocol is not robust against false-name bids  sakurai et al.  1 .
¡¡if the marginal utility of a unit always decreases for all agents  the gva is robust against false-name bids  sakurai et al.  1 . the marginal utility of an item means an increase in the agent's utility as a result of obtaining one additional unit. if the number of units becomes very large  the marginal utility of a unit tends to decrease. for example  if we already have one million units of an item  the utility of having additional one unit would be close to zero. on the other hand  if the number of units are relatively small  which is common in many auction settings  we cannot assume that the marginal utility of each agent always decreases. a typical example where the marginal utility increases is an all-or-nothing case  where an agent needs a certain number of units  otherwise the good is useless  e.g.  airplane tickets for a family trip .
¡¡in  yokoo et al.  1b   we developed a combinatorial auction protocol called the leveled division set  lds  protocol. this protocol satisfies incentive compatibility and individual rationality even if agents can submit false-name bids. we can modify the lds protocol so that it can handle multiunit auctions. as far as the authors know  this is the only existing non-trivial multi-unit auction protocol that is robust against false-name bids. however  this protocol is complicated and requires the auctioneer to carefully pre-determine the combination of bundles in order to obtain a high social surplus or revenue.
¡¡in this paper  we develop a new multi-unit auction protocol that satisfies incentive compatibility and individual rationality. we call this protocol the iterative reducing  ir  protocol. in this protocol  the combination of bundles is automatically determined in a flexible manner according to the declared evaluation values of agents.
¡¡in the following  we first show how the lds protocol can be modified to handle multi-unit auctions. then  we describe the details of the ir protocol and prove that it satisfies incentive compatibility. furthermore  we compare the obtained social surplus of the ir protocol with that of the lds protocol.
1	leveled division set protocol
we show how the lds protocol can be modified for multiunit auctions. in the following  we define several terms and notations. to help readability  we use two different types of parentheses to represent sets: {} and .
  a set of agents: {1 ... n}
  the number of units of an item: m
  a declared evaluation value of agent i for j units of an item: bi j  which may or may not be true .   an auctioneer determines a reservation  minimal  price r for one unit of an item.
  a reservation price of a bundle of j units is r ¡Á j.
  a	division	d	is	defined	as	a	set	of	bundles
{m1 m1 ...}  where. for example  a division {1} means that the auctioneer is going to sell a bundle of 1 units and a bundle of 1 units.
¡¡also  an auctioneer determines a leveled division set. figure 1 shows examples of leveled division sets. case 1 shows one instance where there exist three units of an item  and cases 1 and 1 show instances where there exist ten units of an item. a leveled division set is defined as follows.
  levels are defined as 1 ... max level.
  for each level k  a division set sdk =  dk1 dk1 ...  is defined so that the sum of multiple bundles that appear in a division must appear in an earlier level. for example  in case 1 of figure 1  there is a division {1 1 1 1 1} in level 1. therefore  the sum of the multiple bundles of this division  i.e.  1 ...  or 1  appears in earlier levels.
¡¡to execute the lds protocol  the auctioneer must predefine the leveled division set and the reservation price of one unit r. each agent i declares bi j for all 1 ¡Ü j ¡Ü m. the winners and payments are determined by calling the procedure lds 1 . lds k  is a recursive procedure defined as follows.
procedure lds k 
step 1: if there exists only one agent i whose evaluation value of a bundle of j units satisfies bi j ¡Ý r ¡Á j 
case 1case 1case 1level 1 level 1 level 1 level 1 level 1  {{1}}    {1}  {{1 1 1 1 1  1}  {{1}}  {1}1 }{1  1}    {1}  {1}   {{1 
  1 1 1 1 1   {1  1 1 {1} }1{}1  }1}  {1 }  	{	}
figure 1: example of leveled division setsand j is included in an element of sdk  then compare the results obtained by the procedure gva k  and by lds k + 1   and choose the one that gives the larger utility for agent i.
step 1: if there exist at least two agents i i whose evaluation valuesof bundles ofunits satisfy
 are included in
elements of sdk  then apply the procedure gva k .
step 1: otherwise: call lds k + 1   or terminate if k = maxlevel.
procedure gva k : for a division d = {m1 m1 ...} and one possible allocation of units g  we say g is allowed under d if each bundle in d is allocated to different agents in g. also  we allow that some bundles are not allocated to any agent. in that case  we assume that the bundles are allocated to the auctioneer  denoted by 1   whose evaluation value for a bundle of j units is equal to r ¡Á j. the declared evaluation value of agent i for an allocationg  represented as ei g   is defined as bi j  if j units are allocated to agent i in g  otherwise ei g  = 1. choose an allocation g  such that it is allowed under the divisions in sdk and it maximizes
. the payment of agent i  represented as pi  is calculated as 
  where  is the allocation that is allowed under the divisions in sdk and maximizes the sum of all agents' including the auctioneer 1  evaluation values except that of agent i. this procedure is basically identical to the gva.
example 1 let us assume there exist ten units of an item. the evaluation values of agents are defined as follows.
11  1agent 111agent 111agent 111agent 111agent 111agent 111agent 1 ...11agent 111in this case  the evaluation values of agent 1  and 1 are allor-nothing  i.e.  they need three units at once. other agents need only one unit  and agents 1 ... 1 have identical evaluation values. also  let us assume the reservation price for one unit is 1 and the leveled division set is defined as case 1 in figure 1. since there exists no evaluation value that is larger than the reservation price in levels 1 and 1  units are sold using the level 1 division. as a result  each of the agents 1  and 1 obtains a bundle of three units  and each pays the reservation price 1.
the intuitive explanation that the lds protocol is robust against false-name bids is as follows. let us assume that an agent uses two identifiers  and obtains one unit by each identifier in the level 1 of case 1. if this agent uses a single identifier  it can obtain a bundle of two units in the level 1 by paying the reservation price  which is the minimum price for obtaining two units.
1	ir protocol
1	limitations of lds protocol
one limitation of the lds protocol is that the auctioneer must pre-define the possible combinations of bundles as a leveled division set. to increase the social surplus or the revenue  the auctioneer must choose an appropriate leveled division set  but this task is not easy. even if the auctioneer has some knowledge of the distributions of agents' evaluation values  the auctioneer must solve a very complicated optimization problem to find an appropriate leveled division set.
¡¡also  in the lds protocol  if there exists an evaluation value that is larger than the reservation price for any single bundle in the level  the auctioneer must sell units using the current level. for example  in the situation of example 1  when the reservation price for a unit is 1 and the leveled division set of case 1 in figure 1 is used  there exists an evaluation value for a bundle of three units. therefore  the auctioneer must sell units using the divisions of level 1. in this case  only three units can be sold  although there exist many participants whose evaluation values for a single unit are larger than the reservation price.
¡¡when there are many demands for smaller bundles  such as for two or three units  using the leveled division set of case 1 in figure 1 is inappropriate. if we use the leveled division set of case 1  the result would be better  but we still must pre-define the possible combinations of bundles and cannot flexibly combine bundles according to demands.
1	overview of ir protocol
in our newly developed iterative reducing  ir  protocol  instead of determining the possible divisions of units in advance  we determine the allocations of bundles sequentially from larger bundles. more specifically  as in the lds protocol  we first check whether there exists an agent whose evaluation value for a bundle of m units is larger than the reservation price r ¡Á m. if not  we reduce the number of units ink units are al-
a bundle one by one. when some bundles of located  and there exist enough remaining units  we allocate smaller bundles.
1	details of ir protocol
the protocol is executed by calling the procedure ir m m {1 ... n}   which is defined as follows. procedure ir  m j participants 
step 1: when j = 1  terminate the protocol.
step 1: set k to the largest integer where j ¡Á bki j¡Ü¡Ýmrholds.¡Á j}  set candidates ¡û {i | i ¡Ê participants n ¡û |candidates|.
step 1: when n   k:
1: candidates andset winners to a set of agentsbi j is within k-th highest evaluai  where i ¡Êtion values in candidates  and set p to the k + 1-th highestevaluation value in candidates  ties are broken randomly .
1: and payseach agentp. terminate the protocol.i ¡Ê winners gets a bundle of j units 
step 1: when n = k:
1: for each
1: taining a bundle ofset winnersi ¡Ê¡ûwinners  compare its utility for ob-candidates  andj units by payingp ¡ûpr  and that for¡Á j.
the resultof ir m j¡Á n 1  j 1  participants  winners  ¡È {i}   and choose the one that gives the higher utility for agent i. terminate the protocol.
step 1: when n   k:
1: set winners ¡û candidates  and p ¡û r ¡Á j.
1: taining a bundle offor each i ¡Ê winners  compare its utility for ob-j units by paying p  and that for the resultof irwinners  ¡È {i} m   and choose the one that gives the j¡Á in.  1  j 1  participants 
higher utility for agent
¡¡¡¡1 call ir m   j ¡Á n j   1 participants   winners . when the result of ir m j ¡Á n 1  j  1  participants  we calculate the allocated units and payment of agentwinners  ¡È {i}  is used in step 1 or step 1  althoughi as if agents other than winners could obtain some units  we don't assign any units nor transfer money to agents except winners.
1	examples of protocol application
example 1 let us assume there are 1 units of an item  and the reservation price of one unit is 1. the evaluation values of agents are identical to example 1. from comesir 1 in step 1. in ir {1 ... 1} 1  to ir 1 { 1  1 ...  {1 ... }   the condition1}   n be-
of step 1 holds. each of the agents 1  and 1 obtains a bundle of three units and pays the reservation price 1. then  ir 1 {1 ... 1}  is called. in ir 1 {1 ... 1}   the condition of step 1 holds  and each of the agents 1  1  and 1 obtains one unit bundle and pays 1.
example 1 let us assume there are 1 units of an item and the reservation price of one unit is 1. the evaluation values of agents are defined as follows.
  11  1agent 111agent 111agent 111in ir 1 {1 1}   the condition of step 1 holds. each of the agents 1 and 1 obtains a bundle of five units at the reservation price 1. however  in the procedure of step 1  agent 1 prefers the result of ir 1 {1}   i.e.  obtaining a bundle of four units at 1. thus  this result is applied for agent 1.
example 1 the procedures in steps 1 and 1  which compare the results and choose the one that gives higher utility for an agent  are necessary to guarantee incentive compatibility.
¡¡let us assume we omit these procedures. then  in the situation of example 1  agent 1 obtains a bundle of five units when it truthfully declares its evaluation values and its utility is 1   1 = 1. when agent 1 understates its evaluation values as 1 for a bundle of four and five units  then agent 1 can obtain a bundle of four units and its utility becomes 1   1 = 1. thus  for agent 1  declaring its true evaluation value cannot be a dominant strategy without these procedures.
example 1 in steps 1 and 1  even if there exist remaining units  the protocol is terminated. this might seem wasteful  but it is necessary to guarantee incentive compatibility. let us assume the protocol is continued as long as there exists at least one remaining unit. in the situation of example 1  agent 1 cannot obtain any unit when it truthfully declares its utility  thus its utility is 1. on the other hand  agent 1 can use a false name agent 1 and changes its declarations as follows.
111  1agent 1111agent 1111agent 1111agent 1111then  in ir 1 {1 1}   the condition of step 1 holds  and each of the agents 1 and 1 obtains a bundle of five units. when the protocol is continued as long as there exists at least one remaining unit  we must apply a similar comparison procedure instep 1 as wellas insteps 1 and1. since these agents prefer obtaining a bundle of two units  each agent obtains a bundle of two units by paying the reservation price 1. in reality  agent 1 obtains four units by paying 1 and its utility is 1  1 = 1  thus using a false-name bid is profitable.
¡¡in the ir protocol  when a bundle of j units are sold  and the number of remaining units is smaller than j  the protocol will be terminated. therefore  an agent cannot obtain a fraction of units at a lower price nor gather a fraction of units by using multiple identifiers.
1	proof of incentive compatibility
we are now going to prove the following theorem.
theorem 1 the ir protocol satisfies incentive compatibility. to prove this theorem  we use the following lemmas.
lemma 1 if an agent i uses two identifiers   and obtains a bundle of x and y units under the identifiers i and i  respectively  then agent i can obtain z = x + y units at a price that is less than  or equal to  the sum of the prices for x and y by using a single identifier.
the proof is as follows. for the price of x units px and the price of y units py  px ¡Ý r ¡Á x and py ¡Ý r ¡Á y hold. since agent i obtains x and y units  m ¡Ý z holds.
¡¡now  let us consider the situation where agent does not participate in the auction. when selling bundles of z units  let us assume the condition of step 1 or step 1 holds. in this case  when another agent participates  the agent cannot obtain a bundle smaller than z. this is because the protocol is terminated before or just after selling bundles of z units. this contradicts the assumption that agent i obtains a bundle of x units and i obtains a bundle of y units. thus  when bundles of z units are sold  the condition of step 1 must hold.
¡¡now  let us assume that agent i participates and declares its evaluation value for z units  where 
is a very small amount. since without i's participation  the condition of step 1 holds. by adding this declaration  the condition of step 1 or step 1 holds. in either case  agent i can obtain a bundle of z units with a payment of p = r ¡Á z  which is smaller than  or equal to  px + py  i.e.  the sum of the payments when agent i uses multiple identifiers.  
¡¡using a similar method of the proof of lemma 1  we can show that if an agent uses more than two identifiers  it can obtain the same number of units with a smaller  or equal  payment by using a single identifier.
¡¡so far  we have shown that an agent cannot increase its utility by using false-name bids. now  we are going to show that truth-telling is the dominant strategy for each agent under the assumption that the agent uses a single identifier.
lemma 1 an agent cannot increase its utility by overstating its evaluation value.
the proof is as follows. assume that agent i's true evaluation value of j units is vi j  and it overstates its evaluation value as bi j  where bi j   vi j. it is clear that if agent i cannot be in winners by declaring bi j when selling bundles of j units  overstating is useless. furthermore  if agent i is in winners when it declares vi j  since its payment is independent from its declared evaluation value  overstating is useless.
¡¡the only possible case where overstating might be effective is when agent i declares vi j  it is not in winners  and when it declares bi j  it becomes a part of winners. however  in this case  the payment becomes larger than the true evaluation value vi j. therefore  to obtain a positive utility  the procedures of step 1 or step 1 must be applied and agent i obtains a bundle smaller than j. however  the situations considered in these procedures are identical to the situation when agent i truthfully declares its utility as vi j. thus  overstating is useless.  
lemma 1 an agent cannot increase its utility by understating its evaluation value.
the proof is as follows. assume that agent i's true evaluation value of j units is vi j  and it understates its evaluation value as bi j  where bi j   vi j. it is clear that if agent i cannot be in winners when declaring vi j  understating is useless. furthermore  ifagent i is still inwinners when itdeclares bi j  since its payment is independent from its declared evaluation value  understating is useless.
¡¡the only possible case where understating might be effective is when agent i declares vi j  it is in winners  and when it declares bi j  it can be excluded from winners. however  in this case  if the condition of step 1 holds when agent i truthfully declares vi j  by understating  either the condition of step 1 or step 1 holds. in both cases  the protocol is terminated and agent i cannot obtain any units. on the other hand  let us assume the condition of step 1 or 1 holds when agent i truthfully declares vi j. then  the situation that occurs when agent i declares bi j is identical to the situation considered in step 1 or step 1 when agent i truthfully declares vi j. if agent i prefers this result  the result is applied when agent i truthfully declares vi j. thus  understating is useless.   from these lemmas  we can derive theorem 1.
1	evaluations
in this section  we compare the obtained social surplus of the ir protocol and that of the lds protocol using a simulation. we determine the evaluation values of agent i by the following method. this method is based on the binomial distribution used in  fujishima et al.  1  for evaluating winner determination algorithms in combinatorial auctions.
  determine the size of a bundle j that agent i wants to have by using a binomial distribution b m p   i.e.  the probability that the size of the bundle is j is given by pj 1   p m jm!/ j! m   j ! .
  randomly choose vi j  i.e.  i's evaluation value for the bundle of j  from within the range of  1 j . we assume that the evaluation values of an agent are all-or-nothing  i.e.  the evaluation value for a bundle smaller than j is 1. also  we set the evaluation value for a bundle larger than j to vi j  i.e.  having additional units is useless.
¡¡we generated 1 problem instances by settingthe number of agents n = 1  the number of units m = 1  and p =
1. figure 1 shows the average ratio of the obtained social surplus to the pareto efficient social surplus by varying the reservation price. we show the results of the ir protocol and those of the lds protocol  in which the leveled division sets are case 1 and case 1 in figure 1. since we set m = 1 and p = 1  the size of a bundle is most likely to be 1  and 1 and 1 are also likely to exist. thus  the leveled division set of case 1 seems to be a reasonable choice.
¡¡if the gva is used and agents cannot submit false-name bids  then the obtained social surplus is pareto efficient and the ratio becomes 1%. on the other hand  when agents can submit false-name bids  we cannot predict the obtained result of the gva  since declaring true evaluation values is no longer a dominant strategy for each agent.

figure 1: comparison of social surplus
¡¡as shown in figure 1  by setting the reservation price to an appropriate value  the social surplus of the ir protocol becomes about1%of the pareto efficient social surplus. on the other hand  in the lds protocol  the social surplus becomes at most 1% of the pareto efficient social surplus. in both protocols  when the reservation price is small  one bundle of m units is sold to a single agent. by increasing the reservation price  the units are divided among multiple agents. in the ir protocol  the combination of bundles is determined in a flexible manner  and by increasing the reservation price  the protocol can select the combination of bundles that increases the obtained social surplus. on the other hand  in the lds protocol  the possible combinations of bundles must be pre-defined; thus the protocol cannot adjust to various problem instances. we have obtained very similar results for the problem instances generated using different parameter settings and different distributions of agents' evaluation values.
¡¡if the auctioneer has some knowledge of the distributions of agents' evaluation values  optimizing the reservation price for the ir protocol would be relatively easy compared with optimizing both the reservation price and the leveled division set for the lds protocol. of course  we cannot say that the ir protocol always achieves a better social surplus than that of the lds. if agents require very large bundles  then the ir protocol might end up selling only m + 1 units out of m = 1m units. in such a case  the lds protocol with a carefully designed leveled division set could beat the ir protocol.
1	conclusions
in this paper  we developed a multi-unit auction protocol  ir protocol  that is robust against false-name bids. compared with the lds protocol  this protocol is easier for an auctioneer to use  since he/she only needs to determine the reservation price of one unit  while he/she must pre-define possible combinations of bundles as well as the reservation price in the lds protocol. we showed that the ir protocol can obtain a much better social surplus than that obtained by the lds protocol  since it can determine the combination of bundles in a flexible manner according to the declared evaluationvalues of agents. our future works will include developing combinatorial and double auction protocols  yokoo et al.  1  that are robust against false-name bids based on the ir protocol.
references
 fujishima et al.  1  yuzo fujishima  kevin leytonbrown  and yoav shoham. taming the computation complexity of combinatorial auctions: optimal and approximate approaches. in proceedings of the 1th international joint conference on artificial intelligence  ijcai1   pages 1  1.
 lehmann et al.  1  daniel lehmann  liadan ita o'callaghan  and yoav shoham. truth revelation in approximately efficient combinatorial auction. in proceedings of the first acm conference on electronic commerce  ec-1   pages 1  1.
 mas-colell et al.  1  andreu mas-colell  michael d. whinston  and jerry r. green. microeconomic theory. oxford university press  1.
 rasmusen  1  eric rasmusen. games and information. blackwell  1.
 sakurai et al.  1  yuko sakurai  makoto yokoo  and shigeo matsubara. a limitation of the generalized vickrey auction in electronic commerce: robustness against false-name bids. in proceedings of the 1th national conference on artificial intelligence  aaai-1   pages 1  1.
 sandholm  1  tuomas sandholm. an algorithm for optimal winner determination in combinatorial auction. in proceedings of the 1th international joint conference on artificial intelligence  ijcai-1   pages 1  1.
 varian  1  hal r. varian. economic mechanism design for computerized agents. in proceedings of the first usenix workshop on electronic commerce  1.
 yokoo et al.  1a  makoto yokoo  yuko sakurai  and shigeo matsubara. the effect of false-name declarations in mechanism design: towards collective decision making on the internet. in proceedings of the 1th international conference on distributed computing systems  icdcs1   pages 1  1.
 yokoo et al.  1b  makoto yokoo  yuko sakurai  and shigeo matsubara. robust combinatorial auction protocol against false-name bids. in proceedings of the 1th national conference on artificial intelligence  aaai-1   pages 1  1.
 yokoo et al.  1  makoto yokoo  yuko sakurai  and shigeo matsubara. robust double auction protocol against false-name bids. in proceedings of the 1st international conference on distributed computing systems  icdcs1   1.  to appear .
bundle design in robust combinatorial auction protocol against false-name bids
makoto yokoo  yuko sakurai  and shigeo matsubara
ntt communication science laboratories
1 hikaridai  seika-cho
soraku-gun  kyoto 1 japan email: {yokoo  yuko  matsubara} cslab.kecl.ntt.co.jp url: http://www.kecl.ntt.co.jp/csl/ccrg/members/{yokoo  yuko  matubara}abstract
this paper presents a method for designing bundles in a combinatorial auction protocol that is robust against false-name bids. internet auctions have become an integral part of electronic commerce and a promising field for applying ai technologies. however  the possibility of a new type of cheating called a false-name bid  i.e.  a bid submitted under a fictitious name  has been pointed out.
a protocol called leveled division set  lds  protocol thatis robustagainst false-name bids has been developed. however  this protocolrequires the auctioneer to define a leveled division set. a leveled division set is a series of division sets  where a division set is a set of divisions and a division is a combination of bundles of goods. we need to solve a very complicated optimization problem to constructa leveled division set in order toobtaina good social surplus.
we have developed a heuristic method for overcoming this problem. in this method  we first find a good division with a winner determination algorithm  and then construct a leveled division set by using this division as a seed. through a simulation  we showthat ourmethod can obtaina social surplus that is very close to optimal.
1	introduction
internet auctions have become an especially popular part of electronic commerce  ec . various theoretical and practical studies on internet auctions have already been conducted  monderer and tennenholtz  1; wurman et al.  1 . among these studies  those on combinatorial auctions have lately attracted considerable attention  fujishima et al.  1; leyton-brown et al.  1; klemperer  1; sandholm  1; lehmann et al.  1 . although conventional auctions sell a single item at a time  combinatorial auctions sell multiple items with interdependent values simultaneously and allow the bidders to bid on any combination of items. in a combinatorial auction  a bidder can express complementary/substitutional preferences over multiple bids. by taking into account complementary/substitutional preferences  we can increase the participants' utilities and the revenue of the seller.
¡¡however  in  sakurai et al.  1   the authors pointed out the possibility of a new type of cheating called false-name bids  i.e.  an agent may try to profit from submitting false bids made under fictitious names  e.g.  multiple e-mail addresses. such a dishonest action is very difficult to detect since identifying each participant on the internet is virtually impossible. compared with collusion  rasmusen  1; klemperer  1   a false-name bid is easier to execute since it can be done by someone acting alone  while a bidder has to seek out and persuade other bidders to join in collusion. the results reported in  sakurai et al.  1; yokoo et al.  1a  can be summarized as follows.
  the generalized vickrey auction protocol  gva   varian  1  is not robust against false-name bids in combinatorial auctions.
  there exists no combinatorial auction protocol that simultaneously satisfies incentive compatibility  pareto efficiency  and individual rationality for all cases if agents can submit false-name bids.
¡¡in this paper  we concentrate on private value auctions  mas-colell et al.  1 . in private value auctions  each agent knows its own evaluation values of goods  which are independent of the other agents' evaluation values. we define an agent's utility as the difference between the true evaluation value of the allocated goods and the payment for the allocated goods. such a utility is called a quasi-linear utility  mas-colell et al.  1 . these assumptions are commonly used for making theoretical analyses tractable.
¡¡in a traditional definition  mas-colell et al.  1   an auction protocol is  dominant strategy  incentive compatible  if bidding the true private values of goods is the dominant strategy for each agent  i.e.  the optimal strategy regardless of the actions of other agents. the revelation principle states that in the design of an auction protocol we can restrict our attention to incentive compatible protocols without loss of generality  mas-colell et al.  1; yokoo et al.  1a . in other words  if a certain property  e.g.  pareto efficiency  can be achieved using some auction protocol in a dominant strategy equilibrium  i.e.  the combination of dominant strategies of agents  the property can also be achieved using an incentive compatible auction protocol.
¡¡in this paper  we extend the traditional definition of incentive-compatibility so that it can address false-name bid manipulations  i.e.  we define that an auction protocol is  dominant strategy  incentive compatible  if bidding the true private values of goods by using the true identifier is the dominant strategy for each agent. also  we say that auction protocols are robust against false-name bids if each agent cannot obtainadditional profitby submittingfalse-name bids. ifsuch robustnessis notsatisfied  theauction protocol lacks incentive compatibility.
¡¡we say an auction protocolis pareto efficient when the sum of all participants' utilities  including that of the auctioneer  
i.e.  the social surplus  is maximized in a dominant strategy equilibrium. in a more general setting  pareto efficiency does not necessarily mean maximizing the social surplus. in an auction setting  however  agents can transfer money among themselves  and the utility of each agent is quasi-linear; thus the sum of the utilities is always maximized in a pareto efficient allocation.
¡¡an auction protocol is individually rational if no participant suffers any loss in a dominant strategy equilibrium  i.e.  the payment never exceeds the evaluation value of the obtained goods. in a private value auction  individual rationality is indispensable  i.e.  no agent wants to participate in an auction where it might be charged more money than it is willing to pay.
¡¡the gva protocol  varian  1  is one instance of the well-known clarke mechanism  mas-colell et al.  1 . it satisfies incentive compatibility  pareto efficiency  and individual rationality in combinatorial auctions when there exists no false-name bid; however  this protocol is not robustagainst false-name bids  sakurai et al.  1 .
¡¡in  yokoo et al.  1b   we developed a combinatorial auction protocol called the leveled division set  lds  protocol. this protocol satisfies incentive compatibility and individual rationality even if agents can submit false-name bids. this protocol does not satisfy pareto efficiency  but it can achieve a better social surplus than that obtained by a trivial protocol that always sells goods in one bundle.
¡¡however  the lds protocol requires the auctioneer to design a leveled division set  which is a series of division sets. a division set is a set of divisions and a division is a combination of bundles of goods. the auctioneer sells goods using these bundles. the obtained social surplus or the revenue of the auctioneer can vary significantly depending on the selection of the leveled division set. although we presented the conditions that the leveled division set must satisfy to guarantee incentive compatibility  yokoo et al.  1b   how to construct a leveled division set that could obtain a good social surplus is still an open question.
¡¡we need to solve a very complicated optimization problem in order to construct a leveled division set in such a way that a good social surplus can be obtained. this problem is much more complicated than winner determination problems  fujishima et al.  1; sandholm  1 . in a winner determination problem  given a set of bids  we try to find a combination of bids that maximizes the sum of the values of the bids. on the other hand  to construct a leveled division set  we need some model of the possible bids  e.g.  a probability distribution of the values of the bids. we try to maximize the expected social surplus based on such a model. also  a leveled division set is a series of division sets  where each division is a combination of bundles. finding an optimal solution for this problem becomes infeasible when the number of goods is large.
¡¡in this paper  we develop a heuristic method to construct a good leveled division set. this method uses a winner determination algorithm as a building block  i.e.  this method first finds a good division using a winner determination algorithm  and then constructs a leveled division set using this division as a seed.
¡¡in the following  we first describe the lds protocol. then  we show the method for constructing a good leveled division set. finally  we show evaluation results through a simulation.
1	lds protocol
in the following  we define several terms and notations. to help readability  we use three different types of parentheses to represent sets:     {}  and .
  a set of agents n = {1 ... n}
  a set of all auctioned goods m =  1 ... m 
  a division  which is a set of bundles  d = {s   m |
for every
  for each good j  the reservation price rj is defined.
  for a bundle s  we define.
a leveled division set is defined as follows:
  levels are defined as 1 ... max level.
  for each level i  a division set sdi =  di1 di1 ...  is defined.
a leveled division set must satisfy the following three conditions.
  sd1 =  {m}  - the division set of level 1 contains only one division  which consists of a bundle of all goods.
  for each level and its division set  a union of multiple bundles in a division is always included in a division of a smaller level  i.e.   where  there exists a level j   i  with a division set sdj  where djl ¡Ê sdj and su ¡Ê djl.
  for each level and its division set  each bundle in a divi-
¡¡figure 1 shows examples of leveled division sets. case 1 shows one instance where there are two goods  a and b   and case 1 and case 1 show instances where there are three and four goods  respectively.
case 1case 1case 1level 1 level 1 level 1  {{ a   b a b  }}    { a b   }  {a   b   c{ a b c b c }  } {  a c 	 }    { a b c     }{a   d   b c  a b c d{ b c d  }}   {  a d }  	{	}	{	}
figure 1: example of leveled division sets¡¡to execute the lds protocol  the auctioneer must predefine the leveled division set and the reservation prices of goods. each agent x declares its evaluation value b x s  for each bundle s  which may or may not be true. we show a detailed description of the lds protocol in the appendix. the outline of the protocol is as follows. the lds protocol first tries to sell goods using the division in level 1  i.e.  if there exists an evaluation value that is larger than r m   the goods are sold in one bundle. otherwise  the protocol tries to sell goods using level 1 divisions  and so on. we say that the applied level of the lds protocol is i if the goods are sold using a division in level i.
¡¡an intuitive explanation of why the lds protocol satisfies incentive compatibility is as follows. let us assume that agent x uses two false names to obtain bundles
  respectively  at level i. now  let us assume that agent x declares the evaluation value r s  for the bundle  by using a single identifier. from the condition of a leveled division set  there exists a level j   i  where s ¡Ê djl  djl ¡Ê sdj holds. in this case  the condition in step 1 of lds j  is satisfied  i.e.  only agent x declares evaluation values that are larger than or equal to the sum of reservation prices. thus  agent x can obtain s by paying the minimal price r s . therefore  by using a single identifier  the payment of agent x becomes smaller than  or equal to  the payment when agent x uses two false names.
1	constructing leveled division set
1	basic concepts
we assume that the auctioneer knows the probability distributionofthe possibleevaluationvalues ofparticipants. the goal is to find a leveled division set and the reservation prices of goods so that the expected social surplus can be maximized.
¡¡for the number of goods m  the number of possible bundles of goods is 1m. a division is a set of bundles and a leveled division set is a series of division sets. clearly  enumerating all possible leveled division sets and finding the optimal one becomes infeasible when the number of goods is large. even if we use a best-first search algorithm such as a*  it is difficult to find an optimal leveled division without a very accurate function that estimates the expected social surplus for a partially defined leveled division set. furthermore  we need to optimize the reservation prices of goods as well as the leveled division set.
¡¡in this paper  we make the following assumptions to attack this problem by a heuristic method.
  as in winner determination problems  fujishima et al.  1; sandholm  1   the number of bundles that participants actually need is relatively small compared with the number of all possible bundles 1m  sparseness of bids .
  the auctioneer knows the probability distributions of the1 highest evaluation values of these bundles . also  these probabilities are mutually independent.
withthese assumptions  we can find a candidate for a division that can obtain a good social surplus using a winner determination algorithm  fujishima et al.  1; sandholm  1 . more specifically  instead of the actual value of a bid for each bundle  we use the expected value of the highest evaluation value for each bundle to solve the winner determination problem and obtain a division  we call this division goal division . if we can sell goods using this goal division  the obtained social surplus would be relatively good on average.
¡¡however  to sell goods using this goal division  we need to include additional divisions in earlier levels to satisfy the conditions ofthe leveled division set described inthe previous section. therefore  we put the goal division at level 1  and put additional divisions at level 1. by setting the reservation price of each good in an appropriate range  we can expect that goods will not be sold at level 1 or level 1  and we can sell goods using the goal division.
¡¡for example  let us assume that there are five goods a b c d and e. also  let us assume that by running a winner determination algorithm using the average value of each bundle  we obtain a goal division { a   b   c   d e }. then  we set level 1 of the leveled division set as  { a   b   c   d e } .
¡¡to satisfy the conditions of the leveled division set  we must put all unions of multiple bundles in this goal division at level 1 or level 1. there are four bundles in this goal division  so we must create unions of two bundles and three bundles and put them in the divisions at level 1. if two newly created bundles  each of which is a union of two bundles  do not have any goods in common  we can construct a division using these bundles. for example  we can put divisions { a b   c d e } { a c   b d e } and { a d e   b c } in level 1. then  all unions of two bundles appear in level 1. for a bundle that is a union of three bundles  we create a division that consists of only this bundle  and add them to level 1  e.g.  we add { a b c }  { a b d e } { a c d e }  and { b c d e }.
¡¡also  we can add a new goal division in level 1  as long as the division does not contain a bundle that appears in level 1.	for example  we can add a division

¡¡¡¡¡¡1if we assume that the auctioneer has knowledge of the probability distributions of the evaluation values of agents  the probability distributions of the highest evaluation valuescan be calculatedbased on this knowledge. since the lds protocol is incentive compatible  we can assume that agents truthfully bid their true evaluation values.
{ a   b   c d   e }  since it does not contain any bundles in level 1. to add this division in level 1  we must add divisions { a b c d } { a b e } { a c d   b e }  and { a e   b c d } in level 1.
¡¡it must be noted that even if the above assumptions do not hold  i.e.  there might be unexpected bids or bids might be correlated  the lds protocol using the leveled division set obtained by this method satisfies incentive compatibility  and the robustness against false-name bids . the violations of the above assumptions mightdegrade the obtained social surplus  butthe protocolsatisfies incentive compatibility as longas the required conditions of the leveled division set are satisfied.
1 details of method for constructing leveled division set
we show the details of the method for constructing a leveled division set. let us represent the set of bundles that participants actually need as bs. for each bundle s ¡Ê bs  we assume that the auctioneer knows the probability distribution of the the highest evaluation value bmax s . let us represent the expected value of bmax s  as e bmax s  . to help readability  for a division d = {s1 s1 ...}  we represent a set of unions of k elements of d as u d k .
¡¡we execute the following procedure. in the initial state  the level 1 division set sd1 is  {m}   and the level 1 and level 1 division sets sd1 and sd1 are empty sets .
step 1: find a goal division d that maximizes  using a winner determination algorithm1. add d to sd1. we exclude a division that is already an element of sd1. also  we exclude a division d where any element of u d k  for all k ¡Ý 1 is also an element of bs. this is because we need to put each element of u d k  at level 1. therefore  if any element is also a member of bs  there might be a relatively high evaluation value for this element and we would need to sell goods using the level 1 division. also  we exclude a division d that contains a bundle that is already included in level 1. this is because we cannot put such d at level 1 by the conditions of the leveled division set.
step 1: for all  where  we add. furthermore  for all 
	s	u d u  s	u d t	u   u ¡Ý 1 and
step 1: when adding another goal division  go to step 1  otherwise  terminate the procedure.
the appropriate number of goal divisions in level 1 varies depending on the problem setting. in the problem settings used in the next section  we found that improvement of the obtained social surplus was saturated after adding about 1 goal divisions.
¡¡for solving a winner determination problem  we don't have to find the optimal solution. since we use the expected value instead of the actual value  we cannot say that the optimal solution for the winner determination problem always gives the best goal division. therefore  using an approximate algorithm  such as  sakurai et al.  1   would be sufficient.
1	evaluations
in this section  we show simulation results that demonstrate the quality of the obtained leveled division set using our heuristic method. we determine a bundle s that participants actually need and the probability distribution of the highest evaluation value bmax s  by the following method.
  for each bundle s  we determine the number of goods ins  represented as |s|  by usinga binomialdistribution b p m   i.e.  the probability that the number of goods is j is given by pj 1   p m jm!/ j! m   j !   fujishima et al.  1 . next  we randomly choose |s| goods included in s. also  we choose e bmax s   randomly fromwithinthe range of. then  we set the distribution of bmax sk  as a uniform distribu-
  where
if q is very small  the auctioneer has very good knowledge of the highest evaluation value of s. if q is relatively large compared with   the auctioneer has little knowledge of the possible highest evaluation value of s  and the probability that the goal division can actually achieve a pareto efficient social surplus becomes low.
¡¡figure 1  a  shows the average ratio of the obtained social surplus to the pareto efficient social surplus by varying the reservation price1. in figure 1  we set m = 1  the number of bundles. each data point is the average of 1 problem instances  in which the evaluation values of bundles are generated based on the probability distribution determined by the above method. in figure 1  a   we plot the results where we put only one goal division  lds:1   1 goal divisions  lds:1   and 1 goal divisions  lds:1 . also  figure 1  b  shows the trends of how the applied levels change according to the reservation price in lds:1. more specifically  for each value of the reservation price  we show the cumulative frequency of three levels in which the goods are sold 
¡¡as shownin figure 1  b   when the reservationprice is low  the applied level is 1  i.e.  the lds protocol sells goods using the level 1 division  which means that the protocolalways sell goods in one bundle to a single agent. when the reservation price is around 1  the applied level becomes 1. also  the social surplus drops when the reservation price is around 1. this is because only one bundle in a level 1 division  which consists of two bundles  is sold in some problem instances.
¡¡if we set the reservation price in an appropriate range  in this case  around 1   the applied level becomes 1 and the protocol can sell goods using the goal divisions; thus the obtained social surplus becomes very good  more than 1% of the optimal  even if we put only one division at level 1. by

 b  applied levels  lds:1 
figure 1: evaluation results  m=1  q=1 
putting 1 goal divisions at level 1  the obtained social surplus becomes very close to the optimal. we found the improvement of the obtained social surplus becomes saturated after adding 1 goal divisions.
¡¡in figure 1  we show the results of lds:1  where we set q = 1 1  and 1. as expected  when q becomes relatively large compared with  the probability that the goal division can actually obtain a pareto efficient social surplus becomes very low and the obtained social surplus of the lds protocol becomes low. however  even when q = 1  the lds protocol can obtain a social surplus that is around 1% of the optimal.
¡¡figure 1 shows the results obtained when the number of goods becomes large  i.e.  we set m = 1  |bs| = 1 
  and q = 1. each data point is the average of 1 problem instances. we can see that even though

figure 1: obtained social surplus  m=1  q=1  1  1 

figure 1: obtained social surplus  m=1  q=1 
q is relatively large  the obtained social surplus is very close to the optimal. in this case  the sizes of bundles in the goal division tend to be large  e.g.  a bundle of 1 goods. therefore  the possibility that goods are sold by level 1 divisions  which contain very large bundles  e.g.  1 goods   becomes very small. thus  we can easily set the reservation price so that the applied level becomes 1.
¡¡figure 1 shows the results obtained when adding some noise to problem instances. more specifically  we add several unexpected bids  i.e.  the bids submitted by agents whose evaluation values do not correspond to the model the auctioneer has. a noise bid is generated using basically the same method for generating original bids. in figure 1  the x-axis shows the number of additional noise bids. the parameter settings are identical to those of figure 1  and we show the results of lds:1  where the reservation price is 1. we can

figure 1: effect of adding noise
see that our method is very robust against additional noise bids. even if we add 1 noise bids  which is equal to |bs|  the obtained social surplus is around 1% of the optimal.
1	conclusions
in this paper  we developed a heuristic method for constructing a good division set that can be used in the lds protocol. this method uses a winner determination algorithm to find a good division  and then constructs a leveled division set by using this division as a seed. evaluation results showed that the lds protocol using the leveled division set constructed by our method can obtain a social surplus that is very close to optimal when the auctioneer has reasonably good knowledge of the highest evaluation values of agents. furthermore  the protocol can still obtain a good social surplus when the knowledge of the auctioneer is relatively poor. our future works include evaluating this method in more realistic problem settings based on real application problems such as  leyton-brown et al.  1   and extending a double auction protocol that is robust against false-name bids  yokoo et al.  1  so that it can handle multiple items.
references
 fujishima et al.  1  yuzo fujishima  kevin leytonbrown  and yoav shoham. taming the computation complexity of combinatorial auctions: optimal and approximate approaches. in proceedings of the sixteenth international joint conference on artificial intelligence  ijcai1   pages 1  1.
 klemperer  1  paul klemperer. auction theory: a guide to the literature. journal of economics surveys  1 :1  1.
 lehmann et al.  1  daniel lehmann  liadan ita o'callaghan  and yoav shoham. truth revelation in approximately efficient combinatorial auction. in proceedings of the first acm conference on electronic commerce  ec-1   pages 1  1.
 leyton-brown et al.  1  kevin leyton-brown  mark pearson  and yoav shoham. towards a universal test suite for combinatorial auction algorithms. in proceedings of the second acm conference on electronic commerce  ec-1   pages 1  1.
 mas-colell et al.  1  andreu mas-colell  michael d. whinston  and jerry r. green. microeconomic theory. oxford university press  1.
 monderer and tennenholtz  1  dov monderer and moshe tennenholtz. optimal auctions revisited. in proceedings of the fifteenth national conference on artificial intelligence  aaai-1   pages 1  1.
 rasmusen  1  eric rasmusen. games and information. blackwell  1.
 sakurai et al.  1  yuko sakurai  makoto yokoo  and shigeo matsubara. a limitation of the generalized vickrey auction in electronic commerce: robustness against false-name bids. in proceedings of the sixteenth national conference on artificialintelligence  aaai-1   pages 1- 1  1.
 sakurai et al.  1  yuko sakurai  makoto yokoo  and koji kamei. an efficient approximate algorithm for winner determination in combinatorial auctions. in proceedings of the second acm conference on electronic commerce  ec-1   pages 1  1.
 sandholm  1  tuomas sandholm. an algorithm for optimal winner determination in combinatorial auction. in proceedings of the sixteenth international joint conference on artificial intelligence  ijcai-1   pages 1  1.
 varian  1  hal r. varian. economic mechanism design for computerized agents. in proceedings of the first usenix workshop on electronic commerce  1.
 wurman et al.  1  peter r. wurman  michael p. wellman  and william e. walsh. the michigan internet auctionbot: a configurable auction server for human and software agents. in proceedings of the second international conference on autonomous agents  agents-1   pages 1  1.
 yokoo et al.  1a  makoto yokoo  yuko sakurai  and shigeo matsubara. the effect of false-name declarations in mechanism design: towards collective decision making on the internet. in proceedings of the twentieth international conference on distributed computing systems  icdcs-1   pages 1  1.
 yokoo et al.  1b  makoto yokoo  yuko sakurai  and shigeo matsubara. robust combinatorial auction protocol against false-name bids. in proceedings of the seventeenth national conference on artificial intelligence  aaai-1   pages 1  1.
 yokoo et al.  1  makoto yokoo  yuko sakurai  and shigeo matsubara. robust double auction protocol against false-name bids. in proceedings of the 1st international conference on distributed computing systems  icdcs1   1.  to appear .
appendix: details of lds protocol
for a division d = {s1 s1 ...} and one possible allocation of goods g  we say g is allowed under d if each bundle in d is allocated to different agents in g. also  we allow that some bundle is not allocated to any agent. in that case  we assume that the bundle is allocated to a dummy agent d  whose evaluation value of the bundle s is equal to r s . for each level i and its division set sdi =  di1 di1 ...   we represent a union of all allowed allocations for each element of sdi as sgi. the declared evaluation value of agent x for an allocation g  represented as vx g   is defined as b x s  if s is allocated to agent x in g  otherwise vx g  = 1. also  we define the evaluation value of a dummy agent d for an allocation g as the sum of the reservation prices of goods that are not allocated to real agents in g.
¡¡the winners and payments are determined by calling the procedure lds 1 . lds i  is a recursive procedure defined as follows. note that the procedures in gva i  are equivalent to those in the gva  varian  1   except that the possible allocations are restricted to sgi.
procedure lds i 
step 1: if there exists only one agent x ¡Ê n whose evaluation values satisfy the following condition:  dik ¡Ê sdi  sx ¡Ê dik  where b x sx  ¡Ý r sx   then compare the results obtained by the procedure
gva i  and lds i + 1   and choose the one that gives the larger utility for agent x. if the condition of step 1 is also satisfied for lds i + 1   then also compare with the results of gva i + 1  and lds i + 1   and so on. when choosingthe result of lds i+1   we don't assign any good  nor transfer money  to agents other than x  although the assigned goods for agent x and its payment are calculated as if goods were allocated to the other agents.
step 1: if there exist at least twoagents whose evaluation values satisfy the following condition:
 dik ¡Ê sdi  dil ¡Ê sdi  sx1 ¡Ê dik  sx1 ¡Ê dil  where b x1 sx1  ¡Ý r sx1   b x1 sx1  ¡Ý r sx1   then apply the procedure gva i .
step 1: otherwise: call lds i + 1   or terminate if i = maxlevel.
procedure gva i : choose an allocation g  ¡Ê sgi such that it maximizes . the payment of agent x  represented as px  is calculated as
  where 
is the allocation that maximizes the sum of all agents'  including the dummy agent d  evaluation values except that of agent x.

cabob: a fast optimal algorithm for combinatorial auctions
 tuomas sandholm sandholm cs.cmu.edu
computer science department
carnegie mellon university
pittsburgh  pa 1subhash suri
suri cs.ucsb.edu
department of computer science
university of california
santa barbara  ca 1andrew gilpin	david levine
agilpin dlevine  combinenet.com combinenet  inc.
1 s. craig st
pittsburgh  pa 1
abstract
combinatorial auctions where bidders can bid on bundles of items can lead to more economical allocations  but determining the winners is
   -complete and inapproximable. we present cabob  a sophisticated search algorithm for the problem. it uses decomposition techniques  upper and lower bounding  also across components   elaborate and dynamically chosen bid ordering heuristics  and a host of structural observations. experiments against cplex 1 show that cabob is usually faster  never drastically slower  and in many cases drastically faster. we also uncover interesting aspects of the problem itself. first  the problems with short bids that were hard for the first-generation of specialized algorithms are easy. second  almost all of the cats distributions are easy  and become easier with more bids. third  we test a number of random restart strategies  and show that they do not help on this problem because the run-time distribution does not have a heavy tail  at least not for cabob .
1	introduction
¡¡auctions are important mechanisms for resource and task allocation in multiagentsystems. in many auctions  a bidder's valuation for a combination of distinguishable items is not the sum of the individual items' valuations-it can be more or less. combinatorial auctions  cas  where bidders can bid on bundles of items allow bidders to express complementarity  and  with a rich enough bidding language  also substitutability among the items  sandholm  1; fujishima et al.  1; sandholm  1; nisan  1  . this expressiveness can lead to more economical allocations of the items because bidders do not get stuck with partial bundles of low value. this has been demonstrated  for example  in airport landing slot allocation  rassenti et al.  1   and in transportation exchanges  sandholm  1 .
¡¡however  determining the winners in a combinatorial auctions is computationally complex. there has recently been a surge of research into addressing that  rothkopf et al.  1; sandholm  1; fujishima et al.  1; lehmann et al.  1; sandholm and suri  1; andersson et al.  1; hoos and boutilier  1; de vries and vohra  1 . in this

this work was funded by  and conducted at  combinenet  inc.
paper we present a fast optimal search algorithm for the problem. section 1 defines the problem. our algorithm is presented in section 1. section 1 discusses bid ordering heuristics. experimentalresults are presented in sections 1. random restart strategies are discussed in section 1. section 1 presents conclusions and future research directions.
1	the winner determination problem
in this section we define the winnerdetermination problem.
definition 1 the auctioneer has a set of items 
  to sell  and the buyers submit a set of bids 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡. a bid is a tuple   where is a set of items and is a price. the binary combinatorial auction winner determination problem is to label the bids as winning or losing so as to maximize the auctioneer's revenue under the constraint that each item can be allocated to at most one bidder:
s.t.
¡¡this is -complete  rothkopf et al.  1   and it cannot even be approximated to a ratio of in polynomial time  unless    sandholm  1 .
¡¡if bids could be accepted partially  the problem would become a linear program  lp  which can be solved in polynomial time. here we present the lp-formulation and its dual because we will use them in several ways in our algorithm.
¡¡in this continuous setting  the shadow price gives the price for each individual item . in the binary case individual items cannot generally be given prices  but each value from dual gives an upper bound on the price of item .

¡¡¡¡if there are some items that are not included in any bids  we have to add to the dual the constraint for those items. alternatively  and preferably   such items can simply be removed as a preprocessing step.
1	description of the algorithm
¡¡our algorithm  cabob  combinatorial auction branch on bids   is a tree search algorithm that branches on bids. the high-level idea of branching on bids was already proposed by  sandholm and suri  1  in the bob algorithm. however  bob was not implemented. cabob incorporates many of the techniques proposed in bob and a host of additional ones. all of them have been implemented.
¡¡the skeleton of cabob is a depth-first branch-and-bound tree search that branches on bids. the value of the best solution found so far is a global variable . initially  .
¡¡a data structure called the bid graph is maintained. we denote it by . the nodes of the graph correspond to bids that are still available to be appended to the search path  i.e.  bids that do not include any items that have already been allocated. two vertices in share an edge whenever the corresponding bids share items. as vertices are removed from when going down a search path  the edges that they are connected to are also removed. as vertices are re-inserted into when backtracking  the edges are also reinserted.
¡¡the following pseudocode of cabob makes calls to several special cases which will be introducedlater. for readability  we omit how the solution  set of winning bids  is updated in conjunction with every update of .
¡¡as will be discussed later  we use a technique for pruning across independent subproblems  components of  . to support this  we use a parameter    to denote the minimum revenuethat the call to cabob must return  not including the revenue from the path so far or from neighbor components  to be competitive with the best solution found so far. the revenue from the bids that are winning on the search path so far is called . it includes the lower bounds  or actual values  of neighbor components of each search node on the path so far.
	the search is invoked by calling	.
algorithm 1
1. apply special cases complete and noedges
1. run dfs on ; let be number of components found  and let be the independent bid graphs
1. calculate an upper bound	for each component
1. if	  then return
1. apply special case integer1. calculate a lower bound	for each component
1.
1. if	  then
1. if	then goto  1 
1. choose next bid to branch on  use articulating bids first if any 
1.a.

¡¡¡¡since	can be constructed incrementally as bids are submitted  its construction does not add to winner determination time after the auction closes. therefore  in the experiments  the time to construct	is not included  in almost all cases it was negligible anyway  but for instances with very long bids it sometimes took almost as much time as the search .
	1.b. for all	s.t.	and	 
1.c.
1.d.
1.e.
1.f. for all	s.t.	and	 
1.g. 1.h.
1.i.
1.j.
       1.k. return 1.
1.  
1. for each component	do
	1.a. if	  return
1.b.
1.c.
1.d.
1.e.
1.f.
1.g. 1.h.
1. return
we now discuss the techniques of cabob in more length.
upper bounding
¡¡in step  1   cabob uses an upper bound on the revenue the unallocated items can contribute. if the current solution cannot be extended to a new optimal solution under the optimistic assumption that the upper bound is met  cabob prunes the search path.
¡¡any technique for devising an upper bound could be used here. we solve the remaining lp  whose objective function value gives an upper bound. cabob does not make copies of the lp table  but incrementally adds  deletes  rows from the lp table as bids are removed  re-inserted  into as the search proceeds down a path  backtracks . also  as cabob moves down a search path  it remembers the lp solution from the parent and uses it as a starting solution for the child's lp.
¡¡it is not always necessary to run the lp to optimality. before starting the lp  one could look at the condition in step  1  to determine the minimum revenue the lp has to produce so that the search branch would not be pruned. once the lp solver finds a solution that exceeds the threshold  it could be stopped without pruning the search branch. if the lp solver does not find a solution that exceeds the threshold and runs to completion  the branch could be pruned. however  cabob always runs the lp to completion since it uses the solutions from the lp and the dual in several ways.

¡¡¡¡in the case of multiple components  when determining how high a revenue one component's lp has to return  the exact solution values from solved neighbor components would be included  as well as the upper bounds from the unsolved neighbor components.
¡¡our experiments showed that the upper bound from lp is significantly tighter than those proposed for previous combinatorial auction winner determination algorithms  sandholm  1; fujishima et al.  1; sandholm and suri  1 . the time taken to solve the lp at every node is negligible compared to the savings in search due to enhanced pruning.
the integer special case
	if the lp happens to return integer values  	or
¡¡¡¡¡¡  for each bid  this occurs more often than we expected   cabob makes the bids with winning  and those with losing. this is clearly an optimal solution for the remaining bids. cabob updates if the solution is better than the best so far. cabob then returns from the call without searching further under that node.
¡¡it is easy to show that if some of the values are not integer  we cannot simply accept the bids with . neither can we simply reject the bids with . either approach can compromise optimality.
lower bounding
¡¡in step  1   cabob calculates a lower bound on the revenue that the remaining items can contribute. if the lower bound is high  it can allow to be updated  leading to more pruning and less search in the subtree rooted at that node.
¡¡any lower bounding technique could be used here. we use the following rounding technique. in step  1   cabob solves the remaining lp anyway  which gives an  acceptance level  for every remaining bid . we insert all bids with into the lower bound solution. we then try to insert the rest of the bids in decreasing order of   skipping bids that share items with bids already in the lower bound. it is easy to prove that this method gives a lower bound.
¡¡while rounding techniques are known to provide reasonably good lower bounds on average  in the future we are planning to try other lower bounding techniques within cabob such as stochastic local search  hoos and boutilier  1 .
exploiting decomposition
¡¡in step  1   cabob runs an time depth-firstsearch  dfs  in the bid graph . each tree in the depth-first forest is a connected component of . winner determination is then conducted in each component independently. since search time is superlinear in the size of   this decomposition leads to a time savings. the winners are determined by calling cabob on each component separately. as the experiments show  this can lead to a drastic speedup.
upper and lower bounding across components
¡¡in addition to regular upper and lower bounding somewhat unintuitively  we can achieve further pruning  without compromising optimality  by exploiting information across the independent components. when starting to solve a component  cabob checks how much that component would have to contribute to revenue in the context of what is already known about bids on the search path so far and the neighboring components. specifically  when determining the value for calling cabob on a component  the revenue that the current call to cabob has to produce  the current value   is decremented by the revenues from solved neighbor components and the lower bounds from unsolved neighbor components. our use of a value allows the algorithm to work correctly even if on a single search path there may be several search nodeswhere decompositionoccurred  interleaved with search nodes where decomposition did not occur.
¡¡every time a better global solution is found and is updated  all values in the search tree should be incremented by the amount of the improvement since now the bar of when search is useful has been raised. cabob handles these updates without separately traversing the tree when an update occurs. cabob directly updates in step  1   and updates the value of any parent node after the recursive call to cabob returns.
¡¡cabob also uses lower bounding across components. at any search node  the lower bound includes the revenues from the bids that are winning on the path  the revenues from the solved neighbor components of search nodes on the path  the lower bounds of the unsolved neighbor components of search nodes on the path  and the lower bound on the revenuethat the unallocated items in the current search node can contribute.
¡¡due to upper and lower bounding across components  and due to updating of    the order of tackling the components can potentially make a differencein speed. cabob currently tackles components in the order that they are found in the dfs. we plan to study more elaborate component ordering in future research.
forcing a decomposition via articulation bids
¡¡in addition to checking whether a decomposition has occurred  cabob strives for a decomposition. in the bid choice in step  1   it picks a bid that leads to a decomposition  if such a bid exists. such bids whose deletion disconnects are called articulation bids. articulation bids are identified in time by a slightly modified dfs in   as proposed in  sandholm and suri  1 .
¡¡the scheme of always branching on an articulation bid  if one exists  is often at odds with price-based bid ordering schemes  discussed later. as proved in  sandholm and suri  1   no scheme from the articulation-based family dominates any scheme from the price-based family  or vice versa  in general. however  our experiments showed that in practice it almost always pays off to branch on articulation bids if they exist  because decomposition reduces search drastically .
¡¡even if a bid is not an articulation bid  and would not lead to a decomposition if the bid is assigned losing  it might lead to a decomposition if it is assigned winning because that removes the bid's neighbors from as well. this is yet another reason to assign a bid that we branch on to be winning before assigning it to be losing  value ordering . also  in bid ordering  variable ordering   one could give first preference to articulation bids  second preference to bids that articulate on the winning branch only  and third preference to bids that do not articulate on either branch  among them  price-based bid ordering could be used . one could also try to identify sets of bids that articulate the bid graph  and branch on all of the bids in the set. however  to keep the computation linear time in the size of   cabob simply gives first priority to articulation bids  and if there are none  uses other bid ordering schemes  discussed later. if there are several articulation bids  cabob brancheson the one that is found first  theothers will be found at subsequent levels of the search . one could also use a more elaborate scheme for choosing among articulation bids.
the complete special case
¡¡in step  1   cabob checks whether the bid graph is complete:  . if so  only one of the remaining bids can be accepted. cabob thus picks the bid with highest price  updates if appropriate  and prunes the search path.
the noedges special case
¡¡in step  1   cabob checks whether the bid graph has any edges    . if not  it accepts all of the remaining bids  updates if appropriate  and prunes the search path.
preprocessing
¡¡several preprocessing techniques have been proposed for search-based winner determination algorithms  sandholm  1   and any of them could be used in conjunction with cabob. however  in cabob the search itself is fast  so we did not want to spend significant time preprocessing  since that could dwarf the search time . the only preprocessingthat cabob does is that as a bid arrives  cabob discards every bid that dominates   and    and discards bid if it is dominated by any earlier bid.
1	bid ordering heuristics
¡¡in step  1  of cabob  there are potentially a large number of bids on which cabob could branch on. we developed several bid ordering heuristics for making this choice.
normalized bid price  nbp :  sandholm and suri  1 . branch on a bid with the highest .
it was conjectured  sandholm and suri  1  that slightly less than 1 would be best  since gives the best worst-case bound within a greedy algorithm  lehmann et al.  1    but we determined experimentally that yields fastest performance.
normalized shadow surplus  nss : the problem with nbp is that it treats each item as equally valuable. it could be modified to weight different items differently based on static prices that  e.g.  the seller guesses before the auction. we propose a more sophisticated method where the items are weighted by their  values  in the remaining subproblem. we use the shadow price from the remaining dual problem as a proxy for the worth of an item. we then branch on the bid whose price gives the highest surplus above the worth of the items  normalized by the worths so the surplus has to be greater if
	the bid uses valuable items :	. next

¡¡¡¡this corresponds to variable ordering. choosing between the in-branch     and the out-branch     first corresponds to value ordering. in the current version of cabob  we always try the in-branch first. the reason is that we try to include good bids early so as to find good solutions early. this enables more pruning through upper bounding. it also improves the anytime performance. cplex  on the other hand  uses value ordering as well in that it sometimes tries the out-branch first. in future research we plan to experiment with that option in cabob as well.
we showed experimentally that the following modification to the normalization leads to faster performance:  we call this scheme nss.
bid graph neighbors  bgn : branch on a bid with the largest number of neighbors in the bid graph . the motivation is that this will allow cabob to exclude the largest number of still eligible bids from consideration.
number of items  ni : branch on a bid with the largest number of items. the motivation is the same as in bgn.
one bids  ob : branch on a bid whose -value from lp is closest to 1. the idea is that the more of the bid is accepted in the lp  the more likely it is to be competitive.
fractional bids  fb : branch on a bid with closest to 1. this strategy is advocated in the operations research literature  wolsey  1 . the idea is that the lp is least sure about these bids  so it makes sense to resolve that uncertainty rather than to invest branching on bids about which the lp is  more certain . more often than not  the bids whose values are close to 1 or 1 tend to get closer to those extreme values as search proceeds down a path  and in the end  lp will give an integer solution. therefore those bids never end up being branched on.
1	choosing bid ordering heuristics dynamically
¡¡we ran experiments on several distributions  discussed later  using each one of the heuristics as the primary heuristic  while using each of the other heuristics as a tie-breaker. we also tried using a third heuristic to break remaining ties  but that never helped. the best composite heuristic  ob+nss  used ob first  and broke ties using nss.
¡¡we noticed that on certain distributions  ob+nss was best while on distributions where the bids included a large number of items  nss alone was best. the selective superiority of the heuristics led us to the idea of choosing the bid ordering heuristic dynamically based on the characteristics of the remaining subproblem. we determined that the distinguishing characteristic between the distributions was lp density: number of nonzero coefficients in lp
	density	
	number of lp rows	number of lp columns
ob+nss was best when density was less than 1 and nss was best otherwise. intuitively  when the lp table is sparse  lp is good at  guessing which bids to accept. when the table is dense  the lp makes poor guesses  most bids are accepted to a small extent . in those cases the price-based scheme nss  that still uses the shadow prices from the lp  was better.
so  at every search node in cabob  the density is com-
puted  and the bid ordering scheme is chosen dynamically  ob+nss if density is less than 1  nss otherwise .
¡¡as a fundamentallydifferentbid orderingmethodology we observe that stochastic local search-or any other approximate algorithm for the problem-could be used to come up with a good solution fast  and then that solution could be forced to be the left branch  in-branch  of cabob  with the  most sure  bids nearest the root  so as to give cabob a more global form of guidance in bid ordering.
1	design philosophy of cabob vs. cplex
¡¡we benchmarked cabob against a general-purpose integer programming package  cplex 1. it was recently shown  andersson et al.  1  that cplex 1 is faster  or comparable  in determining winners in combinatorial auctions than are the first-generation special-purpose search algorithms  sandholm  1; fujishima et al.  1 . cplex 1 is about 1 times faster than cplex 1  so when we compare cabob against cplex 1  to our knowledge  we are comparing it against the state-of-the-art.
¡¡there are some fundamental differences between cabob and cplex that we want to explain to put the experiments in context. cplex uses best-bound search  a*   wolsey  1  which requires exponential space  it also has an option to force depth-first search  but that makes cplex somewhat slower   while cabob uses depth-first branch-and-bound  dfbnb  which runs in linear space. thus  on some hard problems  cplex ran out of virtual memory. in our experiments we only show cases where cplex was able to run in ram. dfbnb puts cabob at a disadvantage when it comes to reaching the optimal solution fast since it does not allow cabob to explore the most promising leaves of the search tree first. at the same time  we believe that the memory issue make a* unusable for combinatorial auctions in practice. like cabob  cplex uses lp to obtain upper bounds.
¡¡cplex uses a  presolver  to manipulate the lp table algebraically  wolsey  1  to reduce it before search. in the experiments  we ran cabob without any presolving. naturally  that could be added to cabob as a preprocessing step.
¡¡put together  everything else being equal  cplex should find an optimal solution and prove optimality faster than dfbnb  but one would expect the anytime behavior to be worse.
1	experimental setup
¡¡we tested cabob and cplex on the common combinatorial auction benchmarks distributions: those of  sandholm  1   and the cats distributions  leyton-brown et al.  1 . in addition  we tested them on new distributions. the distributions from  sandholm  1  are:
random: for each bid  pick the number of items randomly from . randomly choose that many items without replacement. pick a price from .
weighted random: as above  but pick the price between 1 and the number of items in the bid.
uniform: draw the same number of randomly chosen items for each bid. pick the prices from .
decay: give the bid one random item. then repeatedly add a new random item with probability until an item is not added or the bid includes all items. pick the price between 1 and the number of items in the bid. in the tests we used since the graphs in  sandholm  1  show that this setting leads to the hardest instances on average  at least for that algorithm .
¡¡we tested the algorithms on all of the cats distributions: paths  regions  matching  scheduling  and arbitrary. for each one of them  we used the default parameters in the cats instance generators  and varied the number of bids.
¡¡we also tested the algorithms on the following new benchmark distributions:
bounded: for each bid  draw the number of items randomly between a lower bound and an upper bound. randomly include that many distinct items in the bid. pick the price between 1 and the number of items in the bid.
components: a number of independent problems  each from the uniform distribution.
¡¡we generate bids so no two bids have the same set of items. the experiments were conducted on a 1 mhz pentium iii pc with 1mb ram. each point in each plot is the median run time for 1 instances. cabob and cplex both use the default lp solver that comes with cplex  dual simplex . cabob and cplex were tested on the same instances.
1	experimental results
¡¡on the random distribution  fig 1 left   cabob is faster than cplex and the difference grows with the number of bids. the preprocessor of cabob eliminates a large number of bids. cabob always resorted to search while cplex's presolve+lp solved the problem without search on 1% of the instances. on the weighted random distribution  fig 1

   1 bids 1 1 1 figure 1: run times on the random and weighted random distributions.
right   the performance of cabob and cplex is almost identical. however  they achieve this very differently. with 1 bids  cplex's presolve+lp solves the problem 1% of the time while cabob resorts to search 1% of the time.
¡¡interestingly  on the decay distribution  fig. 1 left -which is perhaps the most realistic distribution of those of  sandholm  1   and was reported to be difficult for the earlier winner determination algorithms-both algorithms solve the problem using lp in almost all cases. cplex goes to search 1% of the time while cabob resorts to search only 1% of the time. cabob is faster than cplex  mainly because cplex uses presolve while cabob does not.
¡¡on the uniform distribution  fig. 1 right   both algorithms resort to search. the speeds are comparable  but cplex is faster. for the first-generation winner determination algorithms  sandholm  1; fujishima et al.  1   the instances with small numbers of items per bid were much harder than instances with long bids. for both cabob and cplex  complexity is almost invariant to the number of items per bid  except that complexity drops significantly as the bids include less than 1 items each! this is because lp can handle cases with short bids well  both in terms of upper bounding and finding integer solutions.  if each bid contains only one item  lp always finds an integer solution .
¡¡the components distribution demonstrates the power of cabob's decomposition technique and pruning across com-

figure 1: run times on the decay and uniform distributions.
ponents. cabob's run-time increases linearly with the number of components while cplex's time is exponential  fig. 1 . already at 1 components  cplex ran out of virtual memory. the same performance would be observed even if there were a  glue  bid that included items from each component  since cabob would identify that bid as an articulation bid.

figure 1: run times on the components distribution.
¡¡on the bounded distribution  fig. 1 -which is a more realistic version of the uniform distribution-the relative performance of cabob and cplex depended on the bounds. for short bids  cplex was somewhat faster  but the relative speed difference decreased with the number of bids. for long bids  cabob was much faster  mainly due to checking for completeness of the bid graph    and the difference grew dramatically with the number of bids.

1	1	1 bids 1
figure 1: run times on the bounded distribution.
¡¡surprisingly  the cats distributions were very easy. lp solved them in almost all cases. interestingly  even the rare cases where the algorithms resorted to search disappeared as the number of bids increased  except for cats arbitrary where the complexity did not vary much with the number of bids . as fig. 1 shows  cabob was faster than cplex  mainly because the preprocessor discards a large number of bids . the difference grows with the number of bids.

1 bids 1	1	1 figure 1: run times on cats paths and matching.
1	anytime performance
¡¡as expected from their designs  cabob has better anytime performancethan cplex. fig. 1 shows a run that is typical in the sense of anytime performance  but which was carefully selected so that cabob and cplex take equal time to prove that an optimal solution has been reached. cabob dominates cplex throughout  and finds the optimal solution in 1% of the time it takes cplex to find it.

1 1 1 1 1 1
figure 1: solution quality on the bounded distribution  reported by each algorithm once per second.
1	random restarts
¡¡random restarts have been widely used in local search algorithms  but recently they have been shown to speed up tree search algorithms as well  gomes et al.  1 . we conjectured that random restarts  combined with randomized bid ordering  could avoid the perils of unlucky bid ordering. to see whether we could improve cabob using random restarts  we implemented the random restarts methods that are best  to our knowledge  and improved them further to try to capitalize on the special properties of the problem.
we implemented the following restart strategies:
double: double the execution time between restarts.
constant: restart after every	backtracks  gomeset al.  1 .
luby-sinclair-zuckerman:  luby et al.  1  showed that the constant scheme above is optimal if is tailored to the run-time distribution  which is  unfortunately usually not known in practice. therefore  they constructed a scheme that suffers only an asymptotically logarithmic time penalty  independent of the run-time distribution. in the scheme  each run time is a power of 1. each time a pair of runs of the same length has been executed  a run time of twice that length is immediately executed:
.
¡¡we implemented the following bid ordering techniques to use with the restart strategies:
random: randomly pick a remaining bid.

	boltzmann: pick a bid with probability	 

where . the value is from the nss bid ordering heuristic  and is the objective function value from lp. higher values of result in more randomness.
bound: each bid whose value is within a bound of the highest value is equally probable.
¡¡we tried every bid ordering with every restart strategy  and varied the initial time allotment and the parameters     and . cabob was always faster than cabob with restarts!
¡¡it turns out that this is not just a facet of our restart schemes or parameters settings. random restarts tend to lead to speedup when the run-time distribution has a heavy tail  gomes et al.  1 . we decided to test whether cabob exhibits heavy-tailed run-times on the winner determination problem. we chose the distribution on which cabob's runtime varied the most so as to increase the chance of finding a heavy tail. this was the uniform distribution with 1 items per bid. if a distribution has a heavy tail  the variance and usually also the mean are unbounded  gomes et al.  1 . as can be seen in fig. 1  our mean and variance are not only bounded  but constant. this means that the run-time distribution does not have a heavy tail. this explains our negative results with restarts  and suggests that random restarts are not a fruitful avenue for future improvement in this setting.

figure 1: the mean and variance of cabob's search time as a function of the number of instances in the sample.
1	conclusions and future research
¡¡combinatorial auctions where bidders can bid on bundles of items can lead to more economical allocations  but determining the winners is -complete and inapproximable. we presented cabob  a sophisticated search algorithm for the problem. it uses decomposition techniques  upper and lower bounding  also across components   a host of structural observations  elaborate and dynamically chosen bid ordering heuristics  and other techniques to increase speed- especially on problems with different types of special structure  which we expect to be common in real combinatorial auctions. experiments against the fastest prior algorithm  cplex 1  show that cabob is usually faster  never drastically slower  and in many cases drastically faster. overall  this makes cabob  to our knowledge  the currently fastest optimal algorithm for the problem. cabob's search runs in linear space while cplex takes exponential space. cabob also has significantly better anytime behavior than cplex.
¡¡we also uncovered interesting aspects of the problem itself. first  the problems with short bids that were hard for the first-generation of specialized algorithms are easy. second  almost all of the cats distributions are easy  and become easier with more bids. third  we tested a number of random restart strategies  and showed that random restarts do not help on this problem because the run-time distribution does not have a heavy tail  at least not for cabob .
we are currently working not only on designing faster algorithms for winner determination in combinatorial auctions  but also on winner determination in combinatorial reverse auctions and exchanges  sandholm et al.  1   as well as in combinatorial markets with additional side constraints  sandholm and suri  1 . we are also developing methods for intelligent  selective elicitation of combinatorial bids from the market participants  conen and sandholm  1 .
references
 andersson et al.  1  arne andersson  mattias tenhunen  and fredrik ygge. integer programming for combinatorial auction winner determination. in icmas  pages 1.
 conen and sandholm  1  wolfram conen and tuomas sandholm. minimal preference elicitation in combinatorial auctions. in ijcai-1 workshop on economic agents  models  and mechanisms.
 de vries and vohra  1  sven de vries and rakesh vohra. combinatorial auctions: a survey. august 1th.
 fujishima et al.  1  yuzo fujishima  kevin leyton-brown  and yoav shoham. taming the computational complexity of combinatorial auctions: optimal and approximate approaches. in ijcai  pages 1.
 gomes et al.  1  carla gomes  bart selman  and henry kautz. boosting combinatorial search through randomization. in aaai.
 hoos and boutilier  1  holger hoos and craig boutilier. solving combinatorial auctions using stochastic local search. in aaai  pages 1.
 lehmann et al.  1  daniel lehmann  lidian ita o'callaghan  and yoav shoham. truth revelation in rapid  approximately efficient combinatorial auctions. in acm conference on electronic commerce   pages 1.
 leyton-brown et al.  1  kevin leyton-brown  mark pearson  and yoav shoham. towards a universal test suite for combinatorial auction algorithms. in acm conference on electronic commerce   pages 1.
 luby et al.  1  michael luby  alistair sinclair  and david zuckerman. optimal speedup of las vegas algorithms. information processing letters  1-1.
 nisan  1  noam nisan. bidding and allocation in combinatorial auctions. in acm conference on electronic commerce   pages 1.
 rassenti et al.  1  s j rassenti  v l smith  and r l bulfin. a combinatorial auction mechanism for airport time slot allocation. bell j. of economics  1-1.
 rothkopf et al.  1  michael h rothkopf  aleksandar pekec¡¦  and ronald m harstad. computationally manageable combinatorial auctions. management science  1 :1.
 sandholm and suri  1  tuomas sandholm and subhash suri. improved algorithms for optimal winner determination in combinatorial auctions and generalizations. in aaai  pages 1.
 sandholm and suri  1  tuomas sandholm and subhash suri. side constraints and non-price attributes in combinatorial markets. in ijcai-1 workshop on distributed constraint reasoning.
 sandholm et al.  1  tuomas sandholm  subhash suri  andrew gilpin  and david levine. winner determination in combinatorial auction generalizations. in agents workshop on agent-based approaches to b1b.
 sandholm  1  tuomas sandholm. an implementation of the contract net protocol based on marginal cost calculations. in aaai  p. 1.
 sandholm  1  tuomas sandholm. an algorithm for optimal winner determination in combinatorial auctions. in ijcai  pages 1  1. first appeared as washington univ.  dept. of computer science  wucs1  jan. 1th.
 sandholm  1  tuomas sandholm. emediator: a next generation electronic commerce server. in agents  pages 1  1. early version: aaai-1 workshop on ai in electronic commerce  orlando  fl  pp. 1- 1  july 1  and washington university  st. louis  dept. of computer science wu-cs-1  jan. 1.
 wolsey  1  laurence wolsey. integer programming. john wiley.
a software architecture for dynamically generated adaptive web stores
liliana ardissono  anna goy  giovanna petrone and marino segnan
dipartimento di informatica - universita` di torino
corso svizzera 1  torino  italy liliana goy giovanna marino di.unito.itabstract
we provide technical details about the software and hardware architecture of seta  a prototype toolkit for the creation of web stores which personalize the interaction with customers. seta is based on a multi-agent architecture and on the use of mas technologies  which support a seamless communication among the system agents and an easy distribution of such agents on different computers.
1	introduction
personalization has recently become a central focus of attention for web-based systems  riecken  1 . this paper describes the software and hardware architecture of seta  ardissono et al.  1; 1   a prototype toolkit for the creation of adaptive web stores  which tailor the suggestion and the presentation of products to the individual customer's needs. we will provide details about the seta multi-agent architecture  the class hierarchy which defines the internal architecture of the system agents and the technologies used to support agent distribution  communication and specific agent activities. the main prototype store created using our system presents telecommunication products  like phones and faxes.
¡¡sections 1 and 1 sketch the application domain and the adaptivity functionalities offered by the web store. section 1 describes multi-agent architecture. sections 1 and 1 describe the management of multi-user access and communication among system agents. sections 1 and 1 specify the internal design of a seta agent and the external software used to obtain specific system functionalities. section 1 provides technical details and section 1

¡¡¡¡this paper describes the evolution of a system developed at the cs department of the university of torino  within the project  servizi telematici adattativi   funded by telecom italia. we thank l. console  l. lesmo  c. simone and p. torasso for their comments to this work.
compares our approach to the one of other commercial web-based systems. section 1 closes the paper.
1	application domain
we designed our system to satisfy personalization requirements in the business to customer area of e-commerce  focusing on the presentation of massively sold  medium-complexity products  such as home appliances. in this area  personalizing the presentation of goods is important because the customer has to select items out of a rich pool of alternatives. this decision depends on factors ranging from the price of the items to their features and the customer needs a lot of information to choose the item suiting her needs at best. moreover  depending on her interests  not all the product features might be equally important: thus  the presentation can be dramatically improved by focusing on the most relevant information. another reason for personalization is that the customer might not be aware of all the functionalities offered by a product class  therefore needing to be assisted in the identification of the relevant goods. thus  the system should both personalize the presentation of the catalog and elicit information about the user's needs  in order to actively suggest alternative products.
¡¡although e-commerce has strong adaptivity demands  it constraints the development of user interfaces in several ways. for instance  web stores must be accessible via standard equipments  such as a personal computer  a  usually slow  internet connection and a web browser. moreover  the time needed to browse the catalog and find the needed products must be as short as possible and the run-time efficiency of the system is essential. finally  web store shells  such as seta  must satisfy the requirements of the store designer  possibly reducing the overhead in the configuration of a new web store.
1	adaptivity in seta
a web store catalog generated by seta is organized as a hypertext containing two main page types:
 1  pages presenting product classes in a synthetic style  specifying the main functionalities offered by the related items: e.g.  the description of the faxes product class specifies that faxes transmit documents and some of them also make photocopies. these pages also provide the user with the hypertextual links for navigating the catalog.
 1  pages showing detailed information about the items of a product class. these pages present the features offered by the individual items and provide the user with rich interaction functionalities: e.g.  they enable her to ask for technical details  to create comparison tables  on the fly  and to put items into the shopping cart.
¡¡seta dynamically generates the pages of a web store catalog by exploiting personalization strategies for selecting the information to be presented on the basis of the user's interests and familiarity with the products. moreover  the system presents the available items for a product class  e.g.  the available fax models  sorting them on the basis of the user's preferences  ardissono and goy  1 . during the interaction  the system monitors the user's selections to identify her needs for product functionalitiesand suggest potentiallyinterestingproduct classes which the user has not visited. in this way  the assistance is extended to the search for alternative products.
1	architecture of seta
the management of personalized interactions results from the coordination of several activities like user modeling  dynamic page generation  etc.  requiring the exploitation of different knowledge and techniques; e.g.  specific strategies are needed for tailoring layout  content and structure of the pages to the users. to address such complexity  modular architectures  integrating components devoted to the different tasks  are applied in the design of adaptive systems on the web. the exploitation of agent-based technologies is even more effective  as mas technologies support the development of distributed systems where heterogeneous agents offer specialized services and interact to produce the overall service in an open environment; e.g.   jennings et al.  1; giampapa et al.  1; macho et al.  1 .
¡¡in the development of our system  we have exploited knowledge representation techniques and agent-based technologies to improve the configurability of the toolkit and its scalability. seta is based on a multi-agent architecture where specialized agents fill the main roles for the management of personalized interactions with customers; e.g.  user modeling and generation of web pages  ardissono et al.  1 . each agent handles multiple user sessions and maintains session-specific data in parallel session environments. in the following we sketch the most relevant agents.
at the web store starting time  the session manager creates the seta agents and provides them with the ref-

figure 1: parallel sessions within two seta agents.
erences to the other seta agents they might need to send messages to. during the life-span of the web store  the session manager handles the communication with the browsers  catching the user's actions and forwarding them to the dialog manager.
the dialog manager monitors the user's actions and maintains an interaction context storing information about the navigation in the catalog; after each user action  this agent choses the page to be produced next  asks the personalization agent to generate it and forwards the page to the session manager  to send it to the browser.
the user modeling component  umc  maintains the models of customers  revising them during the interaction  on the basis of their behavior.
the product extractor supports the personalized suggestion of goods by ranking items on the basis of how strictly they match the user's preferences. the personalization agent dynamically generates the code for the catalog pages by exploiting the information about the user provided by the umc and a set of personalization rules for selecting information about products and type of description to be produced  ardissono and goy  1 .
1	management of parallel user sessions

figure 1: parallel threads in the management of multiple user sessions.the multi-user access to the web store is managed by performing the session tracking within the session manager  a servlet   and forwarding the session-specific messages to the agents of the architecture  so that they can process such messages and perform the related activities. each seta agent is composed of an interface  the  dispatcher   which handles the delivery and reception of messages  and of a set of user-session agents which maintain the session-dependent environments and carry on the activities to be performed within each user session; e.g.  in figure 1  the dialog manager and the personalization agent use two user-session agents each:  dialsession-i j  and  perssession-i j . each dispatcher acts as a wrapper and supports a uniform communication with the other seta agents  by separating the communication flows related to the active sessions and forwarding incoming messages to the appropriate usersession agent. moreover  the dispatcher creates and removes user-session agents  depending on the users connected to the store. the presence of dispatchers and usersession agents supports a simple management of sessiondependent activities: user-session agents have separate internal states and work in parallel threads of execution within a seta agent  performing services and activities related to the active sessions in an independent way.
1	communication among seta agents
as the number of distinct roles in the system architecture is fixed and well-determined  each agent knows which agents have to be contacted for requesting services and only needs their references; thus  there is no need to exploit middle agents: the session manager communicates such references after the creation of agents.
¡¡our approach is integrated in the environment of the objectspace voyager tool  objectspace  1   which we used to wrap the seta agents  enabling them to run in parallel and to communicate via synchronous and asynchronous messages. the messages can be mapped to a subset of the kqml performatives. at the moment  the seta agents do not need to communicate externally  therefore we did not comply with the fipa acl. according to the voyager specification  the seta agents exchange messages whose parameters contain  respectively  the name of the method to invoke and the array of its arguments. voyager transforms the parameters of a message in a java method call  so that the invocation of methods offered by a seta agent is straightforward.1
¡¡each dispatcher is a voyager object and handles the incoming messages in parallel threads of execution  invoking the appropriate user-session agent to perform the requested task. as more than one message related to the same user session can be received at the same time  a user-session agent can perform parallel tasks; this fact raises mutual exclusion issues  resolved by inhibiting concurrent accesses to shared resources by means of java synchronization facilities.
¡¡figure 1 shows an example where two browsers   usera   represented as a dotted rounded square  and  user-b   a dashed one  access the system. the black oval represents the servlet running within the http server and

figure 1: class hierarchy defining a seta agent.
the grey circles represent seta agents: we have shown only the dialog manager  extractor agent and umc. the figure shows multiple threads  related with the two active user sessions   user-a    user-b    running withinthe http server and the seta agents; the lines used to depict the threads correspond to the related sessions.
1	design of a seta agent
figure 1 shows the class hierarchy defining the agents: the  dispatcher  class specifies that a seta agent has a list of references to the seta agents it may send messages to   agentreferences  ; moreover  it has a set of user-session agents   usersessions  . the class also offers the methods for initializing a seta agent   init      setting references of other seta agents   addagentreference      creating and removing a user-session agent   add/removeusersession     and forwarding messages to a user-session agent  to process a session-dependent request   forwardmessage    . the dispatcher uses the communication facilities offered by voyager for interacting with the other seta agents.
¡¡each seta agent extends the  dispatcher  class and may override the definition of its variables and methods. this is very useful for the definition of the usersession agents: to support the development of heterogeneous agents  specialized in the execution of different tasks  the seta agents have to exploit user-session agents based on different technologies and designed following different approaches. for instance:
in addition to the provision of services to the other seta agents  the activities carried on by the dialog manager and the umc include  respectively  the conditional execution of state transitions representing the evolution of the interaction with the user and the autonomous management of internal tasks. to satisfy these requirements  we have designed actionbased user-session agents  where the agent state and the tasks to be performed are explicitly represented. tasks are described as actions with preconditions determining the state conditions where they can be performed. in the dialog manager  the declarative representation of tasks supports an easy definition of the admissible state transitions in the interaction with the user. in the umc  the presence of an interpreter selecting and performing actions  given the agent state  enables the agent to autonomously trigger its own internal activities  as soon as they can be performed  ardissono et al.  1 .
in contrast  the action-based formalism is not suitable to other seta agents  such as the personalization agent. in fact  the offered services can be handled by user-session agents responding to method invocations associated to potentially complex  but deterministic  tasks. moreover  as such services must be based on the most recent information about the interaction with the user  situation of the user model  etc.   these agents do not need to explicitly manage an internal state: in fact  they have to retrieve such informationfrom the other seta agents  at each incoming request.
figure 1 shows the class hierarchy of the action-based user-session agents defined in seta. the  actusersessionagent  class specifies their variables and generic behavior: it defines an explicit  state   representing the session-dependent data  an action list   actionlist   specifying the list of actions they can perform  and a pending list   pendinglist   used to store the suspended tasks. moreover  the class offers an initialization method   init     and the  interpreter   . the user-session agents extend this class by redefining their own state  which may contain specific session-dependent data  and the action list  where their actions are listed. for clarity  the figure also shows the  action  class  which provides the generic definition of an action specifying the basic components  i.e.  the action type  preconditions  body and the method to check the preconditions  when the action is selected for execution; see  ardissono et al.  1  for details.
1	integration of heterogeneous software
we have integrated in the seta agents external software tools for the management of very specific tasks. the modularity of the architecture enabled us to make them harmonically cooperate with the other components of the seta agents. for instance  the umc exploits the jess rule-based system  sandia  b  to maintain a structured

action- type
- preconditions
- goal- body   
- checkprecond   figure 1: class hierarchy defining an action-based usersession agent.
representation of the interaction context and to produce a synthetic description of the user's behavior: such description is then used within a bayesian network to reason about the user's interests and preferences.
¡¡the natural language generator module of the personalization agent exploits jtg1  dfki and celi  1  to generate the linguistic descriptions to be included in the web pages presenting products and items. the jtg1 engine performs efficient and flexible generation in natural language. in its simplest conception it takes an object as input and returns a string. the crucial source of information is represented by the grammar rules: to integrate the engine in a new application  rules mapping the input object to the string have to be defined. the rules are augmented  if-then  statements spanning the input object top-down  left to right; to perform their task  the rules can access external modules that can be plugged into jtg1 to increase its own flexibility. in seta  we have designed and implemented a set of nl grammar rules and two external modules: a test performer  which enables the engine to perform complex tests on the input object or on external sources  and a parameter getter  which enables the insertion of strings based on data coming from external sources. the input is a complex java object representing a product and the output is the nl description to be included in the web page. the grammar rules are used to fill in the slots in the templates defining descriptions. jtg1 offers applicability tests to specify when a rule can be applied. in seta  such tests are handled by the test performer and enable the grammar rules to be partially context-sensitive. in fact  they are essential to provide the nl generator with the personalized content of the descriptions. such content is represented by a selection of features  provided as a sorted list by the personalization agent on the basis of the contents of the user model. the applicability tests are used in seta to integrate content personalization and nlg. in fact they make the nl generator sensitive to the variation of input data  represented by the personalized list of product features to be described  and directly to the data in the user model; the nl generator module  generates different linguistic descriptions  depending on the user's domain expertise. the use of nlg techniques reduces the amount of precompiled information to be defined at configuration time  as the information about products is stored in a unique internal format. moreover  it supports the generation of multilingual text  italian and english  and the production of descriptions tailored to different user characteristics.
1	technical details
the seta system is implemented in java  jdk 1  and is based on a three-tier architecture. the first tier runs on standard java-enabled browsers  such as netscape navigator and microsoft explorer. in the second tier  the communication with the web is supported by the apache http server; moreover  we have exploited the functionalities offered by the servlets to track the interaction with browsers. the bulk of the system resides in this tier and runs on a unix environment: the seta agents are distributed on two workstations for experimental purposes. the third tier includes the databases storing data about products and users and resides on a windows nt computer. as shown in figure 1  the communication between the second and the third tier is based on rmi  for historical reasons   while the agents in the middle tier communicate by exchanging voyager messages.
1	comments
1	other three-tier architectures
as n-tier architectures are a popular solution for complex web-based systems  the relation between our architecture and the other approaches has to be discussed  with specific reference to frameworks like j1ee  sandia  a   which are industry standards for developing web-based systems. the most important differences are in the organization of the middle tier of such architectures:
the middle tier of seta exploits servlets for the communication with the web  while it relies on the facilities offered by voyager to exploit permanent distributed objects  seta agents   which cooperate to carry on the interaction with the user. the whole logic for the generation of the web pages resides in such permanent objects  with a specific object  the dialog manager  in charge of the selection of each interaction step  i.e.  of choosing the next page to be produced  on the basis of the whole interaction context and of the last action performed by the user.
the middle-tier of the j1ee framework uses java server pages  jsps  for the communication with the web  and it uses enterprise java beans  ejbs  to implement the other modules of the system.
the combined jsp-ejb paradigm is suited to a pagecentric web based system  where the interaction with the user is mostly based on the presentation of forms to be filled in and of pages containing the results of a  possibly complex  query. the typical content of such pages is the presentation of the results of a query to a database.
¡¡in contrast  the interaction with a web store developed using seta is not limited to a question-answer sequence: the user can navigate the catalog handling parallel contexts  searching for goods addressed to several beneficiaries during the same session. the system maintains parallel navigation contexts and supports the user in the switch among them. moreover  the system can take the initiative and suggest alternative products to be analyzed  possibly interrupting the user's navigation. all these functionalities require the presence of an agent specialized in the management of the dialog with the user: this agent has to identify the next interaction step by using a declarative representation of the admissible turn sequences  e.g.  a finite state automaton .
¡¡of course  within a commercial application development  jsps have a noticeable advantage with respect to pure servlet-based approaches: the exploitation of jsps facilitates the cooperation between web authors and java developers  letting web authors concentrate on the development of html templates within the jsps and the java developers write the ejbs implementing db access  legacy system interfaces  and so forth.
1	technical user-interface issues
although the exploitation of applets has enhanced the functionalities offered by the user interface of seta  we have experienced serious drawbacks. the most relevant problem is the fact that  to run an applet containing non basic user interface components  swing   the browsers need to use plug-ins  sometimes incompatible with those installed on the computers. this requirement could make the access to the web store complex and time-consuming  seriously reducing the portability of the system.
¡¡a second drawback concerns the combined use of servlets and applets within a system. on the one hand  the servlets used to send html code to browsers can only receive string return values; on the other hand  for security purposes  applets downloaded outside a lan can only return values to the same http server from which they are downloaded  and firewalls forbid the communication with rmi servers. together  these constraints impose that  whenever complex objects have to be returned by an applet as the results of the decentralized interaction with the user  different servlets within the same http server have to be exploited in the same application: one servlet will forward web pages to the browser and the other one will catch the complex return values produced by applets. this approach has a subtle impact on the capability to track the state of the user sessions because it introduces parallel interaction flows between the browsers and the http server.
1	conclusions
we have provided architectural and technological insights of seta  a prototype toolkit for the development of adaptive web stores developed at the cs department of the university of torino. while this architecture has been described at the abstract level in  ardissono et al.  1; 1   this paper specifies the implementation of the system and the class hierarchy underlying the definition of the agents composing the multi-agent architecture.
¡¡in the development of our system  we exploited a basic and light agent-buildingtool  such as voyager  to manage a seamless communication among agents  but we preferred to design our own infrastructure for developing the system agents because  as seta is a specialized architecture for the creation of web stores  it does not need the full capabilities offered by general-purpose agentbuildingtools  which typically provide facilities for agent communication  coordination  self-diagnosis  mobility  and many other functionalities. for example  seta does not support the development of open systems interacting with middle agents. thus  popular coordination models  such as abs  barbuceanu and teigen  1   exceed the demands of our application example  because they are focused on a more complex issue  i.e.  describing the external behavior of social agents. other tools for the development of multi-agentsystems  such as decaf  graham and decker  1   seem to exceed our needs as well  as they support complex activities such as the coordination of a multiagent system to reach non-local goals and real time flexibility in the execution of tasks. in our system one agent is associated to each main role of the architecture; thus  we do not need to exploit schedulers for distributing tasks among alternative agents.
¡¡scalability is a critical aspect and concerns several issues  among which load balancing. being seta a prototype  we did not explicitly address such aspect in our implementation; however  this problem can be bypassed by using the voyager 1 professional edition  which provides services that would take care of this issue.
¡¡we are now working to enhance the configurability of seta  to support its instantiation on new domains for creating new web stores  or generic recommender systems. a graphical tool currently enables the store designer to introduce the knowledge about customer classes  stereotype kb  without writing any java code. moreover  the knowledge base containing information about products and their features  is automatically created by the system  given the structure of the products db  which contains a classification of items in product classes . finally  we are integrating xml-based representations of the content of the web pages generated by the system: different page types are defined in a dtd  document type definition  and xslt  extended stylesheet language transformations  are used to produce the final user interface  on the basis of the personalized content of the page  encoded as an xml object: in the simplest case  such interface is generated as html code.
references
 ardissono and goy  1  l. ardissono and a. goy. tailoringthe interaction with users in web stores. user modeling and user-adapted interaction  1 :1- 1  1.
 ardissono et al.  1  l. ardissono  c. barbero  a. goy  and g. petrone. an agent architecture for personalized web stores. in proc. 1rd int. conf. on autonomous agents  pp. 1  seattle  wa  1.
 ardissono et al.  1  l. ardissono  a. goy  g. petrone  and m. segnan. configurability within a multi-agent web store shell. in proc. 1th int. conf. on autonomous agents  pp. 1  barcelona  1.
 barbuceanu and teigen  1  m. barbuceanu and r. teigen. higher level integration by multi-agent architectures. in p. bernus  ed.  handbook of information system architectures. springer verlag  1.
 dfki and celi  1  dfki and celi. jtg1. www.celi.it/english/tecnologia/tecling.html/  1.
 giampapa et al.  1  j.a. giampapa  m. paolucci  and k. sycara. agent interoperation across multiagent system boundaries. in proc. of 1th int. conf. on autonomous agents  pp. 1  barcelona  1.
 graham and decker  1  j. graham and k. decker. tools for developing and monitoring agents in distributed multi agent systems. in proc. of the agents'1 workshop on infrastructure for scalable multi-agent systems  barcelona  1.
 jennings et al.  1  n.r. jennings  k.p. sycara  and m. wooldridge. a roadmap of agent research and development. in autonomous agents and multi-agent systems  pp. 1. kluwer academic publishers  boston  1.
 sandia  a  sandia national laboratories. java 1 platform enterprise edition. http://java.sun.com/j1ee/.
 sandia  b  sandia national laboratories. jess  the java expert system shell. http://herzberg.ca.sandia.gov/jess/.
 macho et al.  1  s. macho  m. torrens  and b. faltings. a multi-agent recommender system for planning meetings. in proc. of the agents'1 workshop on agent-based recommender systems  wars'1   barcelona  1.
 objectspace  1  objectspace. voyager. http://www.objectspace.com/index.asp  1.
 riecken  1  d. riecken  editor. special issue on personalization  volume 1. 1.
modularity and design in reactive intelligence
joanna j. bryson and lynn andrea stein
mit artificial intelligence laboratory  ne1
cambridge  ma 1  usa joanna ai.mit.edu  lynn.stein olin.eduabstract
software design is the hardest part of creating intelligent agents. therefore agent architectures should be optimized as design tools. this paper presents an architectural synthesis between the three-layer architectures which dominate autonomous robotics and virtual reality  and a more agent-oriented approach to viewing behavior modules. we provide an approach  behavior oriented design  bod   for rapid  maintainable development. we demonstrate our approach by modeling primate learning.
1	introduction
the last decade of research has shown impressive convergence on the gross characteristics of software architectures for complete agents such as autonomous robots or virtual reality  vr  characters  kortenkamp et al.  1; sengers  1; bryson  1a . the field is now dominated by 'hybrid'  three-layer architectures  gat  1 . the hybrids combine:  1  behavior-based ai  the decomposition of intelligence into simple  robust  reliable modules   1  reactive planning  the ordering of expressed actions via carefully specified program structures  and  optionally   1  deliberative planning  which may inform or create new plans or behaviors.
¡¡in this paper  we take the view that software design and methodology are critical to the advances that have been made in complete agents. we contribute architectural features that further facilitate the human engineering of these agents  including the effort to incorporate reliable learning and planning into the agent. we do this by enhancing the programmability of reactive plans and reintroducing modularity to the organization of the 'plan primitives'. in our system  plan primitives are not themselves modules  but interfaces to semi-autonomous behavior modules encapsulating specialized state for learning and control. this brings hybrid architectures closer to multi-agent systems  mas  and behaviors closer to active objects  van eijk et al.  1 . we also present a methodology for constructing complete agents in the architecture we describe  and some example agents.
1	intelligence by design
one of the most important aspects of the reactive revolution of the late 1's is often overlooked. the break-throughs in robotics associated with reactive and behavior-based systems are usually attributed to the loss of deliberate planning and/or explicit representations. the real contribution of the reactive paradigm was explained nearly a decade earlier: you can't learn something you don't practically already know  winston  1   nor  by extension  plan something you can't nearly already do. the reason is simple combinatorics  chapman  1; wolpert  1 . as evolutionary linguists and casebased reasoning researchers often tell us  what makes humans so intelligent are our exceptional ability to store and transmit solutions we manage to find  e.g. hammond  1; knight et al.  1 .
¡¡reactive and behavior-based ai thus facilitate the advance of ai in two ways. first  by severely deprecating both planning and state  and consequently learning   the reactive approach increased by default the emphasis on one of the largest problems of ai and software in general: design. second  the behavior-based approach made fashionable a proven software design methodology: modularity.
¡¡the primary contributions of this paper are methodological. we provide more productive ways of creating hybrid systems. this is not to say that developing good software is ever easy  or that learning or productive planning should not be used to the fullest extent practical. in fact  we emphasize the role of learning in our methodology. what we are saying is that we favor approaches to hybrid systems that facilitate human design  because humans designers do most of the hard work in artificial intelligence.
1	fundamentals of reactive plans
the terms 'reactive intelligence'  'reactive planning' and 'reactive plan' appear to be closely related  but actually signify the development of several different ideas. reactive intelligence controls a reactive agent - one that can respond very quickly to changes in its situation. reactive intelligence has sometimes been equated with statelessness  but that association is exaggerated. reactive intelligence is associated with minimal representations and the lack of deliberation.
¡¡reactive planning is something of an oxymoron. it describes the way reactive systems handle the problem traditionally addressed by conventional planning: action selection. action selection is the ongoing problem  for an autonomous agent  of deciding what to do next. conventional deliberate planning assumes the segmentation of intelligent behavior into the achievement of discrete goals. a deliberate planner constructs a sequence of steps guaranteed to move an agent from its present state toward a goal state. reactive planning  in contrast  chooses only the immediate next action  and bases this choice on the current context. in most architectures utilizing this technique  reactive planning is facilitated by the presence of reactive plans. reactive plans are stored structures which  given the current context  both internal and environmental   specify the next act.
¡¡we will quickly address the concerns some researchers have with reactive planning. hierarchical plans and centralized behavior arbitration are biologically plausible  byrne and russon  1; prescott et al.  to appear . they are sufficiently reactive to control robots in complex dynamic domains  e.g. kortenkamp et al.  1  and have been shown experimentally to be as reactive as non-hierarchical  decentralized systems  bryson  1b . although they do provide a single failure point  this can be addressed either by standard mas techniques  e.g. bansal et al.  1   or accepted as a critical system  like a power supply or a brain. finally  as demonstrated by coordinated mas and in section 1 below  they do not preclude semi-autonomous behavior modules operating in parallel.
1	basic elements of reactive plans
reactive plans support action selection. at any given time step  most agents have a number of actions which could potentially be expressed  at least some of which cannot be expressed simultaneously  for example sitting and walking. in architectures without centralized action selection   e.g. arkin  1; maes  1   the designer must fully characterize for each action how to determine when it might be expressed. for engineers  it is generally easier to describe the desired behavior in terms of sequences of events. this strategy is complicated by the non-determinism of environments. several types of events may interrupt the completion of an intended action sequence. these events fall into two categories:  1  some combination of alarms  requests or opportunities may make pursuing a different plan more relevant  and  1  some combination of opportunities or difficulties may require the current 'sequence' to be reordered. we have determined 1 element types for reactive plans which  when combined  support both of these situations.
simple sequences
the first element type is a simple sequence of primitive actions: ¦É1 ¦É1 ...¦Én. in our own architecture  we call this element an action pattern. including the sequence as an element type is useful for two reasons. first  it allows an agent designer to keep the system as simple as possible  which both makes it more likely to succeed  and communicates more clearly to a subsequent designer the expected behavior of that plan segment. second  it allows for speed optimization of elements that are reliably run in order  which can be particularly useful in sequences of preconditions or in fine motor control.
¡¡executing a sequential plan involves priming or activating the sequence  then releasing for execution the first primitive act ¦É1. the completion of any ¦Éi releases the following ¦Éi+1 until no active elements remain. notice that this is not equivalent to the process of chaining  where each element is essentially an independent production  with a precondition set to the firing of the prior element. a sequence is an additional piece of control state; its elements may also occur in different orders in other sequences.
basic reactive plans
the next element type supports the case when changes in circumstance can affect the order in which a plan is executed. we developed this idiom independently  and called it a competence. however  it occurs in a number of other architectures  e.g. fikes et al.  1; nilsson  1; correia and steigergarc ao  1  and is so characteristic of reactive planning   that we refer to the generic idiom as a basic reactive plan or brp.
¡¡a brp step is a tuple h¦Ð ¦Ñ ¦Ái  where ¦Ð is a priority  ¦Ñ is a releaser  and ¦Á is an action. a brp is a small set  typically 1  of plan steps {h¦Ði ¦Ñi ¦Áii } associated with achieving a particular goal condition. the releaser ¦Ñi is a conjunction of boolean perceptual primitives which determine whether the step can execute. each priority ¦Ði is drawn from a total order. each action ¦Ái may be either another brp or a sequence as described above.
¡¡the order in which plan steps are expressed is determined by two means: the releaser and the priority. if more than one step is operable  then the priority determines which step's ¦Á is executed. if no step can fire  then the brp terminates. the top priority step of a brp is often  though not necessarily a goal condition. in that case  its releaser  ¦Ñ1  recognizes that the brp has succeeded  and its action  ¦Á1 terminates the brp. the details of the operation of a brp are best explained through an example. brps have been used to control such complex systems as mobile robots and flight simulators  correia and steiger-garc ao  1; benson  1; bryson and  mcgonigle  1 . however  for clarity we draw this example from blocks world. assume that the world consists of stacks of colored blocks  and that an agent wants to hold a blue block. x
   priority	releaser   action	+
 holding   held 'blue    goal
 holding    drop-held  lose-fix
 fixed-on 'blue    grasp-top-of-stack
 blue-in-scene    fixate-blue
 1 
¡¡in this case priority is strictly ordered and represented by position  with the highest priority step at the top. we refer to steps by priority.
¡¡this single reactive plan can generate a large number of expressed sequential plans. in the initial context of a red block stacked on a blue block  we might expect the plan 1-1- 1 to execute. but if the agent is already fixated on blue and fails to grasp the red block successfully on first attempt  the expressed plan would look like 1-1-1-1. if the unsuccessful grasp knocked the red block off the blue  the expressed plan might be 1-1. this brp is identically robust and opportunistic to changes caused by another agent.
¡¡if an action fails repeatedly  then the above construction might lead to an indefinite behavior cycle. this can be prevented through several means. our competences allow a retry limit to be set at the step level. thus a competence step is really a quadruple h¦Ð ¦Ñ ¦Á ¦Çi  where ¦Ç is an optional maximum number of retries. other systems often have generic rules for absence of progress or change.
¡¡the most significant feature of a brp is that it is relatively easy to engineer. to build a brp  the developer imagines a worst-case scenario for solving a particular goal. the priorities are then set in the inverse order that the steps might have to be executed. next  preconditions are set  starting from the highest priority step  to determine whether it can fire. for each step  the preconditions are simplified by the assurance that the agent is already in the context of the current brp  and that no higher priority step can fire.
plan manipulation
finally  a reactive system must be able arbitrate between plans. we do this with a third element type called a drive collection  also based on the brp. a 'step'  or in this case  drive element  now has five elements h¦Ð ¦Ñ ¦Á a ¦Íi. for a drive  the priority and releaser ¦Ð and ¦Ñ are as in a brp  but the actions are different. a is the root of a brp hierarchy  while ¦Á is the currently active element of the drive. if a drive element is selected for action  but its ¦Á is null because a brp or sequence has just terminated  then ¦Á is set to the a for that drive. the drive element begins action selection again from the root of its hierarchy.
¡¡this system improves reaction time by eliminating the stack that might be produced when traversing a plan hierarchy. on every program cycle  the agent checks only the drive-collection priorities  and at most one other set of priorities  if ¦Á is currently a brp rather than a sequence. it also allows the agent to periodically re-traverse its decision tree and notice any context change. this approach also allows the hierarchy of brps to contain cycles or oscillations  which are frequently useful patterns of behavior. since there is no stack  there is no obligation for a competence chain to terminate.
¡¡the fifth member of a drive element  ¦Í  is an optional maximum frequency at which this element is visited. this is a convenience for clarity  like the retry limit ¦Ç on the competence steps - either could also be controlled through preconditions. the frequency in a real-time system sets a temporal limit on how frequently a drive element may be executed. for example  on a mobile robot  bryson and mcgonigle  1  we had the highest priority drive-element check robot's battery level  but this was only executed every two minutes. the next highest priority was checking the robot's sensors  which happened at 1hz. other  lower-priority processes then used the remaining interspersed cycles.
¡¡one further characteristic discriminates drive collections from competences / brps. only one element of a competence is expected to be operating at any one time  but for a drive collection  multiple drives may be effectively active simultaneously. if a high-priority drive takes the attention of the action-selection mechanism  the program state of any active lower drive is preserved. in the case of our robot  if the navigation drive is in the process of selecting a destination when the battery needs to be checked  attention returns to the selection process exactly where it left off once the battery drive is finished. further  action primitives in our system are not stand-alone  consumatory acts  but are interfaces to semi-autonomous behaviors which may be operating in parallel  see section 1 below.  thus the action 'move' in the robot's script merely confirms or transmits current target velocities to already active controllers. a moving robot does not stop rolling while its executive attends to its batteries or its sensors.
1	discussion - other reactive architectures
we refer to reactive plan structures as described above as parallel-rooted  ordered slip-stack hierarchical  posh  action selection. although we freely distribute implementations of this architecture in both c++ and lisp / clos  we have also implemented versions of posh action selection in other architectures  bryson and stein  1 .
¡¡the functionality of the brp  which in our experience is a critical element of reactive planning  is surprisingly missing from several popular architectures. in effect  architectures using middle layers like prs  georgeff and lansky  1  seem to expect that most of behavior can be sequenced in advance  and that being reactive is only necessary for dealing with external interruptions by switching plans. on the other hand  architectures such as subsumption  brooks  1  or ana  maes  1  expect that there is so little regularity in the arbitration of behavior that all actions must be considered for execution at all times. we have found the most expedient solution to the design problem of reactive planning is to categorize selection into things that need to be checked regularly  things that only need to be checked in a particular context  and things that one can get by not checking at all. these categories correspond to our three types of plan elements: drive collections  competences  and action patterns.
1	semi-autonomous behavior modules and the role of perceptual state
besides emphasizing the use of modularity  the behaviorbased movement also made an important engineering contribution by emphasizing specialized learning  e.g brooks  1  pp. 1 . specializing learning increases its probability of success  thus increasing its utility in a reliable agent. similarly  modularity simplifies program design  at least locally  thus increasing the probability of correctness. governing the interaction of multiple independent behavioral modules can be a difficulty  but we have already addressed this issue in the previous section.
consider this description of standard hybrid systems:
the three-layer architecture arises from the empirical observation that effective algorithms for controlling mobile robots tend to fall into three distinct categories:  1  reactive control algorithms which map sensors directly onto actuators with little or no internal state;  1  algorithms for governing routine sequences of activity which rely extensively on internal state but perform no search; and  1  timeconsuming search-based algorithms such as planners.  gat  1  p. 1 
gat's view of three-layer architectures is particularly close to our own view of agent intelligence  because it puts control firmly in the middle  reactive-plan layer. the deliberative 'layer' operates when prompted by requests. however  we differ on the notion that there are many actions which can really map sensors to actuators with little internal state or consideration for the past.
¡¡nearly all perception is ambiguous  and requires expectations rooted in experience to discriminate. for a mobile robot  this 'experience' may be from the last half a second  for discriminating sonar 'ghosts'  half a minute  to move around a bumped object invisible to sonar  or days  as in remembering a local map. primitive actions governed by the reactive plans may depend on any of this information. we do not believe this information should be passed between 'layers' either by micro-management or as parameters. rather  in our model  the primitives of a reactive plan interface directly to semi-autonomous behavior modules. each module maintains its own state and may possibly perform its own 'time-consuming' processes  such as memory consolidation or search  in parallel to the main activity of the complete agent. thus our view of agent control is very similar to gat's  except that  1  we increase the number  specificity and potential simplicity of the modules composing his top layer  and  1  we replace the notion of a bottom layer with the that of an interface between the action selection module of the robot and its  other  behavior modules.
1	developing an agent
the process of developing an agent with these two attributes  posh action selection and a behavior library  we call behavior oriented design. the analogy between bod and ood is not limited to the metaphor of the behavior and the object  nor to the use of methods on the behavior objects as primitives to the reactive plans. the most critical aspect of bod is its emphasis on the design process itself. the old problem of behavior decomposition  and new  analogous one for mas  is solved by using state requirements  as in modern object decomposition. also as in ood  bod emphasizes cyclic design with rapid prototyping. the process of developing an agent alternates between developing libraries of behaviors  and developing reactive plans to control the expression of those behaviors.
1	the initial decomposition
the steps of initial decomposition are as follows.  1  specify at a high level what the agent is intended to do.  1  describe likely activities in terms of sequences of actions  prototype reactive plans.   1  identify sensory and action primitives from these sequences.  1  identify the state necessary for these primitives  clustering them by shared state  prototype behaviors .  1  identify and prioritize goals or drives that the agent may need to attend to  prototype posh drive roots .  1  select a first behavior to implement.
1	the development process
the remainder of the development process is not linear. it consists of the following elements  applied repeatedly as appropriate: coding behaviors  coding reactive plans  testing and debugging code  and revising the specifications made in the initial phase.
¡¡usually only one behavior and one reactive plan will be actively developed at a time. we strongly suggest maintaining the lists developed in the initial phase as documentation. where possible  such documentation should be part of active code. for example  the primitive list should be a file of code specifying the interface calls. similarly  old reactive plans should be preserved with their development history and used as a test suite as modifications are made to the behavior libraries.
1	revising the specifications
the most interesting part of the bod methodology is the set of rules for revising the specifications. the main design principle of bod is when in doubt  favor simplicity. a primitive is preferred to an action sequence  a sequence to a competence. heuristics then indicate when the simple element must be decomposed into a more complex one. one guiding principle is to reduce redundancy. if a particular plan or behavior can be reused  it should be. if only part of a plan or a primitive action can be used  then a change in decomposition is called for. in the case of an action primitive  the primitive should be decomposed into two or more primitives  and the original action replaced by a sequence. if a sequence sometimes needs to contain a cycle  or often does not need some of its elements to fire  then it should really be a competence. a new plan element should have the same name and functionality as the primitive or sequence it replaces. this allows established plans to continue operating without change.
¡¡reactive plan elements should not require long or complex triggers. perception should be handled at the behavior level; it should be a skill. a large number of triggers should be converted into a single perceptual primitive. another problem that crops up in competence design can be the presence of too many elements. more than seven elements in a competence  or difficulty in appropriately prioritizing or setting triggers  indicates that a competence needs to be decomposed into two. if several of the elements can be seen as working to complete a subgoal  they may be moved to a child competence. if two or more of the elements always follow each other in sequence  they should be converted into an action pattern. if the competence is actually trying to achieve its goal by two different means  then it should be broken into two sibling competences which are both inserted into the original competence's parent.
1	example: modeling transitivity in a non-human primate
although we have used our methodology on a mobile robot  bryson and mcgonigle  1  and on virtual reality characters  bryson and thorisson  1   we find artificial life¡ä  alife  more conducive for quantitative comparisons  e.g. bryson  1b  and for communicating with researchers. we thus illustrate bod by building an alife model of primate intelligence. unfortunately  this shows only degenerate examples of drive collections  but space is limited.
¡¡we begin by modeling the ability of a monkey to perform transitive inference  mcgonigle and chalmers  1 . this task is interesting  because it was initially believed to require reasoning  which was in turn considered to require language. squirrel monkeys  saimiri scuireus  were trained on four pairs of colored pucks; ab  bc  cd  and de; to favor the earlier element of the pair. transitivity is the ability to generalize this pairing spontaneously  without further training  when first presented with the novel pairs such as ac  ad  bd and so on. the behavior of the monkeys on this task has already been modeled by harris and mcgonigle   who modeled the transitive capability as a prioritized stack of production rules of the type 'avoid e' or 'select a'. based on the nature of the errors the monkeys made  and their separate performance on three-item sets  different stacks were built representing the rules learned by each monkey.
¡¡we begin by replicating a simplified version of harris's system modeling a skilled monkey. to simplify the simulation task  we model both the monkey and its testing environment as a single intelligent agent with two behaviors. the 'monkey' has two pieces of variable state - its hand and its visual attention  the test box has only a test-board for holding two or three items.
	**	++
¡¡¡¡¡¡¡¡¡¡¡¡ no-test    new-test life    grasping    finish-test
  elvis-choice *  see-red    noisy-grasp +
	elvis-choice  	 see-white see-blue      grasp-seengrasp-seen	 1 
¡¡¡¡¡¡¡¡ see-green    grasp-seen noisy-grasp  hscreech ¡ú grasp-seeni
¡¡this plan gives an example of each element type described in section 1  though the action pattern is gratuitous. priority is again listed from the top. the drive collection  life  has no goal  so it never ends. new-test is a call to the test behavior which randomly resets the test board; finish-test clears it. the seeing primitives all map to a single method on the monkey behavior  which performs a 'visual' scan of the test board and leaves visual attention on an appropriately colored object  if it exists. grasp-seen  also a method on the monkey behavior  is thus able to use deictic reference without variable passing.
¡¡we now enhance the model by forcing the monkey to learn the ordering of the pucks. this also requires augmenting the test-behavior to reward the monkey appropriately.
	**  no-test    new-test	++
life  	  rewardedgrasping      end-of-testelvis-reward   educated-grasp
*  find-red    reward-found +
elvis-reward  	 find-white find-blue      reward-foundreward-found	 1 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡ find-green    reward-found educated-grasp  hadaptive-choice ¡ú grasp-seeni end-of-test  hconsider-reward ¡ú finish-testi
¡¡we add a new behavior  sequence learning  to the system  which though ascribable to the monkey  is separate from the existing monkey-body behavior. the sequencelearner contains a list of known objects with weights  a 'significant difference' and a 'weight shift'. if the monkey is correct in its discrimination  but its certainty was less than significant-difference  then consider-reward adds weight-shift to the weight of the winner  and renormalizes the weights in the list. if it is wrong  consider-reward shifts the weight to the loser.
¡¡the test machine is now in charge of both setting and rewarding the behavior. the new primitive 'find' searches the world for a colored puck  then if it is found  a reward  or lack of reward  is given based on whether the machine is attending to the monkey's hand or the test-board. the end-of-test action-pattern calls actions in sequence from two different behaviors - the monkey's sequence learner learns  then the test box records and resets. educated-grasp is now a method on sequence-learner; it does visual examination  evaluation  and the grasp.
¡¡the above is just the first two steps of the development of a learning version of harris' model. this example demonstrates how functionality can be easily added  and shifted between plans and behaviors. the second model above converges to a correct solution within 1 trials  with significantdifference set to .1  and weight-shift to .1. we have additional forthcoming results showing that adding another layer of learning  the select-avoid rules  results in further characteristics typical of primate learning.
¡¡the sequence-learning task is interesting because it illustrates not only the interaction between reactive plans and modular behaviors  but also begins to model how a behavior might be designed to learn a reactive plan. however  the bod methodology is not constrained to modeling only a single agent. we are currently modeling conflict resolution in primate colony social interactions in collaboration with jessica flack of emory university. in this work  we use different processes to model different agents. each agent has its own instance of the behavior objects and its local copy of a posh plan.
1	conclusions
software engineering is the key problem of developing complete agents. the advances made due to the reactive and behavior-based movements come primarily because they trade off slow or unreliable on-line processes of search and learning for the one-time cost of development  and by emphasizing the use of modularity. these are not reasons to fully abandon learning and search  but they are reasons to use it only in constrained ways likely to be successful.
¡¡it is easiest to design action selection if one exploits the sequencing and prioritization skills of programmers. we have shown how sequences can be adapted into powerful reactive plans. one of the components we consider critical to successful reactive planning  the brp  is present to our knowledge in only one architecture with a reasonably large user base  tr  nilsson  1 . most other architectures either only allow for reactivity between plans  or don't allow for structured plan elements at all. we have also created a mapping between the three layer architectures that dominate complete agent research today  and the original behavior-based architectures  which are more like today's mas architectures. we suggest that the primitive elements typical of the lowest layer of a three-layer architecture should interface to semi-autonomous behavior modules  which are comparable to high-level processes in some three-layer architectures. this allows the basic actions coordinated by the reactive plans direct access to appropriately processed state necessary for informing perception and determining the parameters of actuation.
references
ronald arkin. integrating behavioral  perceptual and world knowledge in reactive navigation. robotics and automation  1 :1  1.
arvind k. bansal  kotagiri ramohanarao  and anand rao. distributed storage of replicated beliefs to facilitate recovery of distributed intelligent agents. in munindar p. singh  anand s. rao  and michael j. wooldridge  editors  intelligent agents iv  atal1   pages 1  providence  ri  1. springer.
scott benson. learning action models for reactive autonomous agents. phd thesis  stanford university  december 1. department of computer science.
rodney a. brooks. intelligence without representation. artificial intelligence  1-1  1.
joanna bryson and brendan mcgonigle. agent architecture as object oriented design. in munindar p. singh  anand s. rao  and michael j. wooldridge  editors  the fourth international workshop on agent theories  architectures  and languages  atal1   pages 1  providence  ri  1. springer.
joanna bryson and lynn andrea stein. architectures and idioms: making progress in agent design. in c. castelfranchi and y. lesperance  editors ¡ä the seventh international workshop on agent theories  architectures  and languages  atal1 . springer  1. in press.
joanna bryson and kristinn r. thorisson. dragons  bats &¡ä evil knights: a three-layer design approach to character based creative play. virtual reality  1. in press.
joanna bryson. cross-paradigm analysis of autonomous agent architecture. journal of experimental and theoretical artificial intelligence  1 :1  1.
joanna bryson. hierarchy and sequence vs. full parallelism in reactive action selection architectures. in from animals to animats 1  sab1   pages 1  cambridge  ma  1. mit press.
richard w. byrne and anne e. russon. learning by imitation: a hierarchical approach. brain and behavioral sciences  1 :1  1.
david chapman. planning for conjunctive goals. artificial intelligence  1-1  1.
luis correia and a. steiger-garc ao. a useful autonomous  vehicle with a hierarchical behavior control. in f. moran  a. moreno  j.j. merelo  and p. chacon  editors  advances
in artificial life  third european conference on artificial life   pages 1  berlin  1. springer.
richard e. fikes  peter e. hart  and nils j. nilsson. learning and executing generalized robot plans. artificial intelligence  1-1  1.
erran gat. three-layer architectures. in david kortenkamp  r. peter bonasso  and robin murphy  editors  artificial intelligence and mobile robots: case studies of successful robot systems  chapter 1  pages 1. mit press  cambridge  ma  1.
m. p. georgeff and a. l. lansky. reactive reasoning and planning. in proceedings of the sixth national conference on artificial intelligence  aaai-1   pages 1  seattle  wa  1.
kristian j. hammond. case-based planning: a framework for planning from experience. the journal of cognitive science  1   september 1.
mitch r. harris and brendan o. mcgonigle. a modle of transitive choice. the quarterly journal of experimental psychology  1b 1 :1  1.
chris knight  michael studdert-kennedy  and james r. hurford  editors. the evolutionary emergence of language: social function and the origins of linguistic form. cambridge university press  1.
david kortenkamp  r. peter bonasso  and robin murphy  editors. artificial intelligence and mobile robots: case studies of successful robot systems. mit press  cambridge  ma  1.
pattie maes. situated agents can have goals. in pattie maes  editor  designing autonomous agents : theory and practice from biology to engineering and back  pages 1. mit press  cambridge  ma  1.
brendan mcgonigle and margaret chalmers. are monkeys logical  nature  1  1.
nils nilsson. teleo-reactive programs for agent control. journal of artificial intelligence research  1-1  1.
tony j. prescott  kevin gurney  f. montes gonzalez  and peter redgrave. the evolution of action selection. in david mcfarland and o. holland  editors  towards the whole iguana. mit press  cambridge  ma  to appear.
phoebe sengers. anti-boxology: agent design in cultural context. phd thesis  school of computer science  carnegie mellon university  1.
rogier m. van eijk  frank s. de boer  wiebe van der hoek  and john-jules ch. meyer. generalised object-oriented concepts for inter-agent communication. in c. castelfranchi and y. lesperance  editors ¡ä intelligent agents vii  atal1 . springer  1.
patrick winston. learning structural descriptions from examples. in patrick winston  editor  the psychology of computer vision. mcgraw-hill book company  new york  1.
david h. wolpert. the lack of a priori distinctions between learning algorithms. neural computation  1 :1- 1  1.
reflective negotiating agents for real-time multisensor target tracking
leen-kiat soh and costas tsatsoulis
information and telecommunication technology center  ittc 
department of electrical engineering and computer science
the university of kansas
irving hill road  lawrence  ks 1 usa
{lksoh  tsatsoul} ittc.ukans.eduabstract
in this paper we describe a multiagent system in which agents negotiate to allocate resources and satisfy constraints in a real-time environment of multisensor target tracking. the agents attempt to optimize the use of their own consumable resources while adhering to the global goal  i.e.  accurate and effective multisensor target tracking. agents negotiate based on different strategies which are selected and instantiated using case-based reasoning  cbr .  agents are also fully reflective in that they are aware of all their resources including system-level ones such as cpu allocation  and this allows them to achieve real-time behavior. we focus our discussion on multisensor target racking  case-based negotiation  and real-time behavior  and present experimental results comparing our methodology to ones using either no negotiation or using a static negotiation protocol.
1 introduction
we describe a negotiating agent approach to multisensor target tracking and distributed resource allocation in a realtime environment.  each agent controls a set of resources  and is motivated to use these resources to track targets appearing in its coverage area  and also to make the resources available to other agents in an effort to satisfy the global tracking goals.  the act of balancing the local use of tracking resources and the global goal satisfaction increases the complexity of the problem.  the agents have to incorporate real-time issues into their decision making process since global tasks and resources are bounded by time.  each agent in the system is autonomous  monitors its environment through a sensor  reacts to changes that it observes  and maintains its own knowledge bases.  there is no hierarchical organization among the agents allowing the system as a whole to react to world events more quickly.  since there is also no centralized information shared by the agents  information can only be exchanged directly during negotiation sessions and only what is considered relevant and useful information is communicated.  this increases the autonomy of each agent and consequently strengthens the system's robustness.  since there is no top-down coordination  our agents dynamically form temporary coalitions to perform a task  with each agent in the coalition using and also making available its resources.
¡¡the driving application for our system is multisensor target tracking  a distributed resource allocation and constraint satisfaction problem.  the objective is to track as many targets as possible and as accurately as possible using a network of sensors.  each sensor has a set of consumable resources  such as beam-seconds  the amount of time a sensor is active   battery power  and communication channels  that each sensor desires to utilize efficiently.  each sensor is at a fixed physical location and  as a target passes through its coverage area  it has to collaborate with neighboring sensors to triangulate their measurements to obtain an accurate estimate of the position and velocity of the target.  as more targets appear in the environment  the sensors need to decide which ones to track  when to track them  and when not to track them  always being aware of the status and usage of sensor resources.
¡¡the problem is further complicated by the real-time constraints of the environment and the fact that agents have to share physical resources such as communication channels and disk storage.  for example  for a target moving at one foot per second  accurate tracking requires one measurement each from at least three different sensors within a time interval of less than 1 seconds.  the real-time constraints force our agents to deal with issues such as cpu allocation  since speed of execution depends on it   disk space allocation  communication latency  and processing times.  finally  the environment is noisy and subject to uncertainty and error: messages may be lost  a sensor may fail to operate  or a communication channel could be jammed.  thus  in addition to improving autonomy  one is required to promote noiseresistance in agent reasoning  sensor control  and communications.
¡¡the sensors are 1 ghz doppler mti radars that communicate using a 1 mhz wireless  radio-frequency  rf  transmitter with a total of eight available channels.  each sensor can at any time scan one of three sectors  each covering a 1-degree swath.  sensors are connected to a network of cpu platforms on which the agents controlling each sensor reside.  the agents  and sensors  must communicate over the eight-channel rf link  leading to potential channel jamming and lost messages.  finally  there is software  the  tracker   that  given a set of radar measurements  produces a possible location and velocity for a target; the accuracy of the location and velocity estimates depend on the quality and frequency of the radar measurements: as we mentioned  the target must be sensed by at least three radars within a two second interval for accurate tracking. our solution to the problem is to use reflective  case-based  negotiating agents.  the agents are reflective since they are aware of their resources  including computational ones  and of how their actions and commitments affect these resources.  they also integrate case-based reasoning  cbr  and negotiation to dynamically form target-tracking coalitions and to determine how resources should be shared and used.  cbr allows the negotiation to adapt to the dynamically changing environment.  negotiation allows a bottomup generation of an any-time solution.  all agents are peers  each responsible for initiating and responding to negotiations.  when an agent senses an event that it cannot solve on its own  it dynamically forms a coalition from a subset of its known neighbors.  it then initiates negotiation requests to the members of the coalition and conducts 1-to-1 negotiations. this way  the common goal of target tracking is divided into subgoals by the initiating agent.
¡¡the integration of real-time  cbr  and negotiation is a unique and innovative approach to the solution of a general class of dynamic  distributed  time-bound  over-constrained resource allocation problems represented by our domain of real-time multisensor target tracking.
1 agent negotiation
in our system negotiation is used to allocate sensor and computational resources and to allow the agents to reach an agreement on tracking a target. an agent is connected to and controls a sensor  and is aware of its state and the status of the resources it controls.  each agent operates in one of three different modes: tracking  negotiating  or both.
¡¡in this paper we will not discuss in detail how an agent tracks a target  since the topic is only tangentially related to negotiating agents.  in a few words  an agent polls its sensor at predefined time intervals and if a radar return is considered  interesting   it then follows the potential target for one second sending all radar measurements to the tracker  the software component that computes target location and velocity given a set of radar measurements .
¡¡since accurate target tracking requires triangulation  an agent that finds a potential target must contact other sensorcontrolling agents to ask for their help.  illuminating a target by a radar implies the use of consumable resources: first  the radar will have to abandon its own target tracking  if any  to accommodate the request; second  using the radar consumes battery power; third  sending the measurements to the tracker occupies one of the eight globally available communication channels; fourth  the simple act of communicating between agents and handling the cognitive cost of this communication requires cpu resources.  agents are cooperative and desire the completion of the high-level goal of target tracking.  at the same time  they are individualistic  in that they want to preserve their resources for their own goal satisfaction  and they are also reliable  in that they do not easily break a resource commitment made to another agent. consequently  when an agent requests the use of the resources of another agent  it needs to convince that agent that it has priority in the use of these resources. to do so our agents use negotiation.
¡¡negotiation can be used by agents to perform problem solving and to achieve coherent behavior in a multiagent system. agents can negotiate in a fully prescribed manner where the negotiating parties know exactly what each other's cost and utility functions are  or when such knowledge is learned during the first step of interaction in a negotiation  kraus  1; kraus et al.  1 .  there are agents that negotiate using the unified negotiation protocol in worth-  state-  and task-driven domains where agents look for mutually beneficial deals to perform task distribution  rosenschein and zlotkin  1; zlotkin and rosenschein  1 . agents can also conduct argumentation-based negotiation in which an agent sends over its inference rules to its neighbor to demonstrate the soundness of its arguments  jennings et al.  1 .  finally  there are agents that incorporate ai techniques  chavez and maes  1; laasri et al.  1; zeng and sycara  1  and logical models  kraus et al.  1  into negotiation.
1. negotiation model
our agents use a variation of the argumentative negotiation model.  traditionally  in argumentative negotiation  an argument is a representation of a sequence of inferences leading to a conclusion  jennings et al.  1 .  since our agents are assumed to share the same reasoning mechanism  it is not necessary for them to exchange their inference model with their negotiation partners.  in addition  we assume that an agent reasons rationally and in good faith and is cooperative.
¡¡before describing our negotiation model in detail we introduce some terminology: an initiator or initiating agent is the agent that requires a resource and contacts another agent to start a negotiating session; a responder or responding agent is the one that is contacted by the initiator; a persuasion threshold is a value associated with each resource or percentage of a resource that indicates the degree to which an agent needs to be convinced in order to free or share a resource  alternatively  one can view the persuasion threshold as the degree to which an agent tries to hold on to a resource .  finally  a negotiation strategy dictates how an agent should behave before the start of a negotiation process; it spells out the time allowed for the agent to complete the negotiation  what type of information to send over as arguments  how agreeable the responding agent should be  and so on.
¡¡after the initiator determines that it requires assistance in tracking a target  it establishes a set of negotiation partners  a coalition  discussed in the next section   and contacts them to start negotiating.  the initiator sends to the responders a message requesting a resource and a time interval it needs this resource  the resource  for example  can be turning on a radar beam at time t .  the responder determines if it can satisfy the request immediately  for example  if the radar beam is already on   if it cannot negotiate at all  it is too busy  implying that it has no cpu resources available or no more threads   or if it can negotiate.
¡¡if both agents determine that negotiation is possible  they establish a negotiation strategy  see section 1  and start negotiating.  each agent has a local view of the world based on its sensor information.  the initiator attempts to convince the responder by sharing parts of its local information.  for example  it may share with the responder the speed with which the target is traveling or the other tasks it is currently performing; the responder uses this data to  see through the initiator's eyes   and determine if its needs are more pressing than its own.  the responder uses a set of domainspecific rules to establish whether the information provided by the initiator pushes it above a resource's persuasion threshold  in which case it would free the resource.  for example  a target being tracked by an initiating agent that is already busy tracking another target is a more convincing argument than a target that is already being tracked by multiple sensors.
¡¡if the responder is not convinced by the evidential support provided by the initiator  it requests more information from the initiator.  the initiator  guided by its negotiation strategy  sends over what it views as its most useful arguments first.  the responder evaluates these new arguments and updates the evidence support.  this process iterates until either the agents reach an agreement  in which case a resource or a percentage of a resource is freed  or the negotiation fails.
1. coalition formation
in order to negotiate  an initiating agent must identify a group of other agents that it can talk to.  this group is a negotiating coalition and is established dynamically by the initiator.  to become a member of a coalition an agent must  first  be known to the initiator  and  second  have the potential to provide useful resources.
¡¡an agent knows a subset of the agents in the multiagent system.  usually it knows the agents in its physical neighborhood  since they all control radars that cover a certain area. since  as mentioned  the radars are sessile  an agent only needs to be told once who its physical neighbors are. to establish who can provide useful resources  the initiator calculates the velocity of the target it is tracking and establishes a potential future path that the target will follow. next  the initiator finds the radar coverage areas that the path crosses and identifies areas where at least three radars can track the target  remember that tracking requires almost simultaneous measurement from at least three sensors .  the agents controlling these radars become members of the negotiating coalition.
¡¡since computational resources are limited  and negotiating consumes cpu and bandwidth  the initiator does not start negotiation with all members of the coalition  but first ranks them and then initiates negotiation with the highestranked ones. ranking of the coalition members is done using a multi-criterion utility-theoretic evaluation technique. the evaluation criteria are:
1. the target's projected time of arrival at the coverage area of a sensor: there has to be a balance between too short arrival times which do not allow enough time to negotiate and too long arrival times which do not allow adequate tracking;
1. the target's projected time of departure from the coverage area of a sensor: the target needs to be in the coverage area long enough to be illuminated by the radar;
1. the number of overlapping radar sectors: the more sectors that overlap the higher the chance that three agents will agree on measurements  thus achieving target triangulation;
1. whether the initiator's coverage overlaps the coverage area of the coalition agent: in this case the initiator needs to convince only two agents to measure  since it is the third one   which may be easier than convincing three;
1. the success rate in previous negotiations between the initiator and the agent in the coalition: previous successes are an indicator that an agent is more willing to be persuaded to free resources  since all agents are collaborative this is an indirect indication that an agent is mostly idle or has more resources than it needs .
¡¡at the end of the evaluation all coalition members are ranked and the initiator activates negotiations with as many high-ranked agents as possible  there have to be at least two and the maximum is established by the negotiation threads available to the initiator at the time  since it may be responding to negotiation requests even as it is initiating other negotiations .
1. case-based negotiation strategy
as negotiation strategy we define the set of guidelines  or protocol  that govern the behavior of an agent during a particular negotiation.  in contrast to other work in negotiation where the negotiating parties followed a predefined  static protocol  our agents dynamically establish a new strategy depending on their current state and the state of the world.
the goal is to situate a negotiation and to improve the chances of its success by taking into account the dynamically changing world state.  this is accomplished by using cbr to select  adapt  and eventually learn negotiation strategies.
¡¡since initiating a negotiation and responding to one are fundamentally different tasks  although still governed by the same methodology  each agent has two different case bases: one with strategies for initiating negotiations and one with strategies for responding to negotiation requests.  cases of both initiating and responding negotiation strategies have the same description  but different strategies.  in the following we discuss the joint situation description of the two case types and then discuss the two types of strategies separately.
¡¡a case contains a description of a situation that allows an agent  using simple weighted matching  to establish similarity between the current situation and the cases in the case base.  the situation describes the state of the agent  tasks it is performing  state of the radar  its battery  etc.   the state of the target  current location and speed  projected path  type  etc.   and the model of the potential coalition members  how many  the number that actually were used in negotiation  their capabilities  etc.   since an agent is always aware of this information  it can match the current situation with the description of the cases in the case base  find the best match  and apply  after adaptation  the negotiation strategy in the case to the current negotiation task.
¡¡each case also contains the negotiation strategy that was used in the past together with the outcome of the negotiation  such as:  offer accepted    offer rejected    ran out of time   or  ran out of resources.   the strategy tells the agent how to conduct the negotiation.  for the initiator the negotiation strategy consists of the following:
1. a ranking of the classes of information it should use as arguments: during a negotiation each agent attempts to minimize the number and length of messages sent  since with fewer messages the agents can avoid message loss due to communication failures  and reduce traffic among the agents.  the agents want to send short messages as well since the transfer is faster and the bandwidth is constrained.  thus  it is important for an initiating agent to decide which information pieces are more important to send to the responding agent;
1. the time constraint: how long  in real time  the agent should be negotiating  since the target may leave the area;
1. the number of negotiation steps: a  step  is a complete negotiation communication act where the initiator sends arguments and the responder makes a counter-offer or requests more convincing arguments.  clearly the more steps that are allowed the higher the chance of reaching an agreement  but also the more time and resources are spent;
1. the cpu usage: more cpu resources for a negotiation mean faster negotiation  but also less cpu available for other tasks.
¡¡the responder has a slightly different negotiation strategy. it shares some elements of the initiator's protocol  specifically the time constraint  the number of negotiation steps  and the maximum cpu usage  but it also introduces two more parameters:
1. the power usage: this defines how much power the responder is willing to use to turn on its radar;
1. persuasion thresholds for resources: as already mentioned  each resource has a persuasion threshold associated with it which determines how difficult it will be to convince the responder to free the resource.  the resources are radar sectors for performing frequency or amplitude measurements to track a target  cpu allocation  and usage of the rf communication channels.  discrete resources like turning on a radar  have a single valued persuasion threshold. continuous resources like cpu  where a responder may agree to free a percentage of it  have a linear or an exponential function of evidence support  as persuasion thresholds  so  if an initiator convinces a responder by degree x  then the responder is willing to free n% of its cpu allocation; if it is convinced by degree  x+y  it will be willing to free  n+m % of its cpu  where n = f x   m = f x+y  - f x   and f is either a linear or an exponential function depending on the actual situation .  we have chosen these two functions since they are easy to compute and represent two different conceding behaviors-the linear function has a uniform conceding rate whereas the exponential function models agents willing to concede quickly.
¡¡after a case has been selected and an old negotiation strategy has been retrieved  the agent adapts the strategy to best fit the current situation.  our adaptation technique uses two sets of rules: one that maps the differences between the case description and the current world state into strategy fixes  and a second one that uses the outcomes of the old negotiation strategy to guide its adaptation into a more potentially successful one.  for example  if the current target is faster than the target in the case  then the agent reduces the negotiation time in its strategy.  or  if the old negotiation failed because the agents could not reach an agreement  then the agent may want to use fewer cpu resources and plan to spend less time on the negotiation  since it may fail again. currently  we have 1 difference-driven and seven outcome-driven domain-specific adaptation rules.  on average  each rule has two conditions to facilitate fast token matching and has about three conclusions such as  increase the number of negotiation steps by x    decrease the time by y   and so on.
¡¡finally  when a negotiation strategy has been created  the agents engage in negotiation  as discussed in section 1. after the negotiation is concluded  the agents involved in it decide whether it is worthwhile to learn the strategy they used  and to add it to their respective case base. an agent matches the new case to all cases in the case base and if it is significantly different from all of them it learns the new strategy by storing the case in the case base.  by learning cases whose description differs sufficiently from the ones in the case base the agents attempt to improve their negotiation strategies by covering a larger part of the problem domain. if  though  the new case is not sufficiently different from the ones in the case base  the agent determines which one to keep: the new one or the old case which best matches the new one  to do so the agent attempts to increase the diversity of the case base by computing the sum of differences between that old case and the entire case base  minus the best matching old case  and the sum of differences between the new case and the entire case base  minus the best matching old case .  if the second sum is greater than the first sum  then it replaces the old case with the new case. the heuristics we use to evaluate whether a new case should be learned or not are similar to the similarity evaluation performed during retrieval  with the additional evaluation of the solution parameters.  since learning is performed by the agent on-line  we have designed it to be of only linearly related to the number of cases in the case base.  consequently  the diversity measurement is between the new case and every case in the case base instead of between all case pairs.  this allows us to improve the speed of the learning step when a new case comes in and to reduce the computational requirements.
¡¡there has been work in off-line learning of negotiation strategies using genetic algorithms  matos et al.  1   but in our work learning is continuous and on-line.
1 real-time reflective agents
a fundamental concern in multisensor target tracking is the timeliness of the measurements: a radar must be active and illuminating an area when a target is passing through it and when other radars are measuring  too.  this introduces realtime constraints to the sensor management by the agents: negotiations must be concluded within sufficient time to allow execution of sensing commands  or must be aborted to allow negotiation with other members of the coalition. to achieve real-time behavior the agents must be fully aware of the status of system-level resources and of the passage of time.  this awareness defines a real-time reflective agent.
¡¡our agents use the real-time scheduling services  rtss  that reside on top of the ku real-time system  kurt   srinivasan et al.  1  that adds real-time functionality to linux.  first  the rtss provides an interface between the agents and the system timers  allowing agents to:  1  query the os about the current time;  1  ask the rtss to notify them after the passage of certain length of time; and  1  ask the rtss to ping them at fixed time intervals.  this allows agents to know when to  for example  conclude a negotiation process or turn on a radar sector. second  the agents may ask the rtss to notify them when certain system-level events occur  such as process threads being activated  or communication messages going out or coming into the system.  third  the agents can ask the rtss to allocate them a percentage of the cpu for each one of their threads  such as the ones controlling the radar and tracking or the ones used in negotiations  and to schedule this allocation within an interval of time.  this way agents residing on the same computational platform can establish execution priorities and can control how fast an operation can be performed  clearly  more cpu scheduled in consecutive time intervals implies faster execution for a thread  leading to faster reasoning and negotiation .
¡¡the rtss may be unable to perform such a cpu allocation and scheduling  if  for example  all available cpu resources are already occupied.  then  the requesting agent is notified and is also informed of which agents are using the cpu resources. this allows the agent to initiate a negotiation for cpu with the other agents.  this is when the fourth function of the rtss comes into play: an agent needs to know what percentage of its allocated cpu it is using  to be able to determine whether it is willing to give up part of its cpu allocation to a requesting agent. after agents have negotiated a new sharing of cpu resources they request a rescheduling of the allocations  and the rtss dynamically performs it.
¡¡the rtss allows agents to be full masters of all their resources  including system-level ones.  agents can negotiate about cpu and can simply cede part of their allocation to other agents.  knowledge of the passage of real time  of the occurrence of system-level events  and of cpu usage and load make our agents reflective and allow them to function effectively in a real-time domain.
¡¡previous work in real-time ai fell under two general categories:  1  anytime algorithms  dean and boddy  1  where a solution to a problem can be incrementally refined and can be applied at anytime during the refinement process  and  1  multiple methods or approximate processing  lesser et al.  1  where different approaches to a solution are available and can be combined.
1 experimental results
the reflective  real-time  case-based negotiating agents described in the previous sections have been implemented and tested using real sensors and targets moving in a physical environment.  the agents exhibit all of the behavior described: they use cbr to select and adapt a negotiation strategy  use the rtss to request cpu resources and to have time and system awareness  negotiate for radar use  and learn the new negotiation strategies they have developed.  most importantly  the agents achieve the high-level goal of the system: they track targets traversing an area covered by many radars.
¡¡our experiments concentrated on evaluating whether negotiating agents can track targets better  and whether cbr results in better negotiation strategies.  our hypotheses were  first  that negotiating agents can track targets better since they can coordinate radar measurements and achieve better triangulation  and  second  that negotiation using cbr will result in better tracking than using a static negotiation protocol  since cbr will allow adaptation of the strategy to the current situation.  our experiments support these hypotheses.  in addition to the accuracy of tracking  we used communication as a measure of quality  length of messages  frequency of messages and message cost  i.e. length times frequency   since communication is an important bottleneck of scale up.
¡¡first we compared our system to a multiagent  sensorcontrolling network where there is no communication between the agents  and where when a target appears in the coverage area of a sensor it is tracked.  next  we compared our case-based negotiating agents to a system where negotiation uses a predefined  static strategy.  we selected the static strategy carefully to make sure it should be adequate for most cases.
¡¡in general  the results  summarized in figures 1  were very encouraging. the agents which used no negotiation sent almost 1% more messages but had almost 1% worse tracking accuracy than negotiating agents.  the nonnegotiating agents exchanged no messages  and only sent their radar measurements to the tracking software.  since there was no coordination of the measurements  there were too many messages sent to the tracker.  on the other hand  we also found that such messages are short compared to arguments exchanged between agents during negotiation  resulting in lower message costs-the product of the average length and the total number of messages sent per second.  since there was no cooperation to triangulate measurements  the resulting accuracy was poor.

figure 1: tracking accuracy vs. agent behavior
¡¡the agents that used a static negotiation strategy fared worse than the ones that used a case-based  adaptive strategy.  specifically  the agents using a static protocol sent approximately 1% fewer messages  though with a slightly higher message cost  and had almost 1% worse accuracy than the case-based negotiating agents.  the message cost is due to the fact that the case-based agents change the ranking of the arguments they communicate based on the situation; this leads to overall more effective communication acts. the accuracy is due to the fact that case-based agents adapt their negotiation to the current situation and have a higher chance of achieving agreement for resource allocation; on the other hand the static strategy agents failed to agree more often and this led to failure to perform the multiple  simultaneous radar measurements that are required for accurate tracking.

figure 1: number of messages to agents and to tracking software vs. agent behavior.

figure 1: message statistics vs. agent behavior.  message cost is the product of the average length and the total number of messages sent per second.

figure 1: percentage of successful negotiations vs. negotiation strategy type.  a successful negotiation is one that completes with a deal between the two negotiating agents.
1 conclusions
we have described a multiagent approach to distributed resource allocation problems  particularly to multisensor tracking of targets in a real-time environment.  our approach uses negotiations among agents to exchange information based on strategies retrieved using a case-based reasoning system.  this allows the agents to learn negotiation strategies based on previous experiences  adapt to the current situations  and avoid repeating past failures.  we have shown experimentally that cbr-based negotiations helped agents to negotiate more efficiently and more successfully  indirectly helping the agents track their targets more accurately.  the agents in our system use real-time scheduling services to become reflective of the system-level resources they use and to be time-aware; this allows the agents to work in an environment of real-time constraints.  finally  we showed experimentally that reflective negotiating agents can track targets much better than agents that simply react to the presence of targets in their environment.  the reflective nature of the agents allows them to schedule the precise time of measurement and also exchange computational resources  leading to faster and more efficient processing.
acknowledgments
the authors would like to thank kelly corn  will dinkel  jim emery  arun gautam  douglas niehaus  pete prasad  and huseyin sevay for their work on the ants project at the university of kansas.  the work described in this paper is sponsored by the defense advanced research projects agency  darpa  and the air force research laboratory  air force materiel command  usaf  under agreement number f1-1.  the u.s. government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation thereon.  the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements  either expressed or implied  of the defense advanced research projects agency  darpa   the air force research laboratory  or the u.s. government.
references
 chavez and maes  1  chavez  a.  and maes  p.  kasbah: an agent marketplace for buying and selling goods. in proceedings of 1st int. conf. on practical application of intelligent agents & multi-agent technology  1.
 dean and boddy  1   t. dean and m. boddy.  an analysis of time-dependent planning.  in proc. of the seventh national conf. on artificial intelligence  st. paul  mn   august  1 
 jennings et al.  1  jennings  n. r.  parsons  s.  noriega  p.  and sierra  c.  on argumentation-based negotiation. in
proc. of int. workshop on multi-agent systems  boston  ma .
 kraus  1  kraus  s.  beliefs  time  and incomplete information in multiple encounter negotiations among autonomous agents  annals of mathematics and artificial intelligence 1  1  1.
 kraus et al.  1  kraus  s.  sycara  k.  and evenchik  a. reaching agreements through argumentation: a logical model and implementation  ai journal 1  1  1.
 kraus et al.  1  kraus  s.  wilkenfeld  j.  and zlotkin  g.  multiagent negotiation under time constraints. artificial intelligence 1  1.
 laasri et al.  1  laasri  b.  laasri  h.  lander  s.  and lesser  v.  a generic model for intelligent negotiating agents. int. j. of intelligent & cooperative information systems 1  1.
 lesser et al.  1  lesser  v. r.  pavlin  j.  and durfee  e. approximate processing in real-time problem solving.  ai magazine 1  1  1.
 matos et al.  1  matos  n.  sierra  c.  and jennings  n. r. negotiation strategies: an evolutionary approach. in proc. of int. conf. on multiagent systems  icmas'1   paris  france   july 1  1.
 rosenschein and zlotkin  1  rosenschein  j. s.  and zlotkin  g.  designing conventions for automated negotiation  ai magazine 1  1  1.
 srinivasan et al.  1  srinivasan  b.  pather  s.  hill  r.  ansari  f.  and niehaus  d. a firm real-time system implementation using commercial off-the shelf hardware and free software. in proc. of the real-time technology and applications symposium   denver  co .
 zeng and sycara  1  zeng  d.  and sycara  k.  bayesian learning in negotiation  int. j. of human-computer studies 1  1.
 zlotkin and rosenschein  1  zlotkin  g.  and rosenschein  j. s.  mechanism design for automated negotiation  and its application to task oriented domains  artificial intelligence 1  1  1.



multi-agent systems	1









n periods model: expected utility and equilibrium conditions


punish after k out of n periods: expected utility and equilibrium conditions


cast: collaborative agents for simulating teamwork 
 
john yen  jianwen yin  thomas r. ioerger  michael s. miller  dianxiang xu  and richard a. volz 
department of computer science 
h. r. bright building 
texas a&m university 
college station  tx 1  usa 
{yen  jianweny  ioerger  mmiller  xudian  volz} cs.tamu.edu 

 
 
abstract 
psychological studies on teamwork have shown that an effective team often can anticipate information needs of teammates based on a shared mental model.  existing multi-agent models for teamwork are limited in their ability to support proactive information exchange among teammates. to address this issue  we have developed and implemented a multi-agent architecture called cast that simulates teamwork and supports proactive information exchange in a dynamic environment. we present a formal model for proactive information exchange. knowledge regarding the structure and process of a team is described in a language called mallet. beliefs about shared team processes and their states are represented using petri nets. based on this model  cast agents offer information proactively to those who might need it using an algorithm called diarg. empirical evaluations using a multi-agent synthetic testbed application indicate that cast enhances the effectiveness of teamwork among agents without sacrificing a high cost for communications. 
1 	introduction 
teamwork has been the focus of a great deal of research  spanning diverse disciplines from business management to psychology  ilgen et al.  1 .  there are many different 
types of teams  from those that are hierarchical to those that are more egalitarian. some teams have fixed  clearlydefined roles  while others allow for dynamic re-allocation of tasks and responsibilities on the fly. measuring the performance of a team can involve both  outcome  as well as  process  measures  cannon-bowers and salas  1 .  
   several computational models of teamwork have been developed for producing cooperative behavior among intelligent agents. the fundamental aspect of a team that distinguishes them from just a group of interacting agents is that they share common goals. in the bdi framework  rao and georgeff  1; wooldridge and jennings  1   the mental state of having a team goal has been characterized in terms of joint intentions  cohen and levesque  1  jennings  1 . tambe  tambe  1  and his steam group have shown how these mental states can be established and maintained through communication protocols. another framework for modeling teams is through sharedplans  via intentions to do certain steps together  grosz and kraus  1 . these approaches have been shown to be effective for simulating teamwork in a wide range of agent-only environments  jones et al  1; 
tidhar et al.  1; stone and veloso  1 .   
   however  these existing multi-agent teamwork models have not been designed for supporting mixed human/agent teams. having humans in the loop places an additional constraint on the agents  such that they must interact with teammates in a natural way  e.g. by exchanging only the most important information necessary for coordination  without excessive or redundant communication. efficient teamwork relies heavily on information sharing  especially in dynamic environments  but it must be done judiciously not to overwhelm the human participants with message passing. the key is to try to supply only the most relevant information  and this requires reasoning about their goals and responsibilities on the team. 
   motivated by this observation  we have developed cast  collaborative agents for simulating teamwork   a multi-agent architecture that simulates and supports teamwork. while our ultimate goal involves supporting both humans and agents  in this paper we will focus on reducing communication with software agents  in preparation for inclusion of humans  as a first step. our architecture provides a mechanism for building virtual teams using software agents. we will first give an overview about the goals and issues addressed by cast. a formal foundation for proactive information exchange in cast is then introduced. this is followed by a description of the major components and features of the cast architecture. 
an empirical evaluation is used to assess the effectiveness of teamwork simulated in cast. finally  we summarize the main contribution of the work. 
1 	cast overview 
cast is designed to achieve two goals. first  it aims to model effective teamwork by capturing both team structures and teamwork processes. a well-defined team structure is based on specifying pre-defined roles and the responsibilities associated with them. a well-defined teamwork process specifies goals  strategies  and plans for accomplishing the team's goal. the common prior knowledge about the structure and the process of the team enables members of the team to develop an  overlapping shared mental model   which is the source for team members to reason about the states and the needs of others.   one of the major criticisms of other approaches toward the goal above has been that they lack flexibility for dealing with dynamic environments. hence  another equally important goal is to enable agents in a team to have flexibility in adapting to changes in the environment. more specifically  assignment of responsibilities to suitable agents needs to be adapted to the current state of the world and the team.  
   while both goals are desirable  they conflict with each other. the emphasis on predefined team structures and processes often reduces the flexibility of the team  while maximizing the flexibility of the team usually requires making shared  redundant  and hence ambiguous role assignments. to balance these two conflicting goals  we need a practical and flexible computational framework for representing and reasoning about the overlapping shared mental models among teammates. such a framework would enable an agent to dynamically reason about the status of the entire team and adapt its behavior accordingly.  
   representing a shared mental model is a challenging problem. it can be viewed as a kind of belief reasoning  which is generally intractable  halpern and moses  1 . moreover  the content of the shared mental model is quite broad  ranging from shared domain knowledge to a common relevant picture of the situation. we tackle this problem by focusing on two specific uses of the shared mental model: making teamwork efficient through 
anticipating the actions and expectations of others  e.g. by knowing others' roles  capabilities  and commitments   and by information exchange  knowing who to ask for information  or providing information proactively just when it is needed by someone else to accomplish their task .  to avoid issues of computational complexity with belief reasoning  e.g. higher-order modal logics   we use petri nets as an approximate finite and computable model of mental states.  
   the petri net is a natural representation for parallel action and synchronization in a multi-agent world  sowa  1 . transitions can represent actions  with input places corresponding to pre-conditions and output places corresponding to effects.  we extend the standard  colored  petri net formalism with special kinds of places called control nodes and belief nodes. control nodes represent the belief an agent has about the current goals and activities of others in the team. belief nodes represent the belief an agent has about the world  when coupled with a unification-based theorem-prover  can represent first-order knowledge  including dynamic facts and inferences about the world. in addition to serving as the shared mental model  petri nets also play the dual role of monitoring and tracking the execution of team plans. 
   cast generates the petri net-based representation using two kinds of knowledge: 1  team structures  roles and responsibilities   and 1  teamwork process knowledge  e.g.  individual plans  team plans . they are described in a knowledge representation language called mallet  a multi-agent logic-based language for encoding teamwork . a petri net for a given team member represents both the background knowledge for their individual responsibilities  e.g. goals  operators   and how their role is integrated with the rest of the team.   
   based on the shared mental model  the cast kernel enables cast agents to decide on the fly how to accomplish desired goals  how to select responsibilities to commit to or delegate  how to proactively assist others in the team  and how to effectively communicate within the team. this is achieved by dynamic role selection and proactive information change. we will give a more detailed description in later sections. 
1 	 formal foundation of proactive 
information flows 
in this section  we discuss the formal foundations underlying the type of information exchange addressed in cast. in particular  we think it is important to specify  under ideal conditions  what information should be exchanged between whom  and at what time. the purpose of information exchange must be oriented toward improving the efficiency or performance of a team  but otherwise is desired to be kept to a minimum to avoid the cost of communications overhead  however this is defined in the domain .  in fact  a quantitative utility function that incorporates such costs is actually used in steam  tambe  1  to help evaluate tradeoffs and decide when to communicate within a team. 
   in cast  we take a different approach to optimizing information exchange by defining narrow criteria for the exchange of only the most critical information.  specifically  we want agents who know some fact to communicate it to exactly those teammates who need the information in the present context to carry out their goals  and who furthermore  probably  do not already know it.  clearly  this might involve some complex reasoning about beliefs and goals  as well as tracking the state of other agents. however  to the degree that some of these inferences can be approximated  the team members can make intelligent decisions to selectively choose their interactions with one another. 
   we start by defining a simple belief language and model theory to be able to talk about the mental states of various.  we model beliefs using a modal operator bel  e.g.  bel bill  have joe hammer    with the usual possible worlds semantics  cohen & levesque  1 .  we need to be able to talk about 'pieces' of information  which in this present context refer syntactically to sentences  but semantically are equivalent to constraints over possible worlds  i.e. those worlds satisfying the expression.  goals  however  refer to specific steps in plans in mallet  to which agents can make commitments. 
using this framework  we can formally characterize the 
 normative  conditions under which information exchange should take place. information i should be sent from one agent a to another agent b when: 1  agent a knows the truth-value of i  1  agent a believes that agent b does not currently know i  and 1  b has a current goal g  the achievement of which depends on knowing i  i.e. if b does not believe i  then it will never be able to accomplish it's goal  but if it knew i  it would be able to: 
 bel a i  ¡Ä  bel a   bel b i   ¡Ä  
 bel a  goal b g   ¡Ä  
   bel b i  ¡ú    done b g   ¡Ä  
  bel b i  ¡ú     done b g   
¡¡¡¡¡¡¡ú   goal a  inform b i   where   is the temporal operator for 'always'. in cast  we use the pre-conditions of operators to determine the information i that an agent needs to know to achieve its goals.  note  the communication is suppressed only when  a believes that  b already believes i is true; but if b does not have a belief about the truth value of i at all  or b incorrectly believes it is false  then the message will be sent. for simplicity  we assume that all agents share common  and correct  knowledge of the team  e.g. team goals and plans  roles and responsibilities  operator preconditions  etc.    
   clearly this approach requires a to monitor b's mental state  both in terms of what his beliefs and goals  commitments  are. this might be easy to do in a highly observable environment  but might require extensive communication in other cases  e.g. verbal updates of what each teammate is currently doing . alternatively  agents might use a probabilistic mechanism like bayesian reasoning to infer the likely states of their teammates  based on observations of the effects of their actions reflected in the environment.  regardless of how difficult this state estimation or tracking might be to implement  the definition above describes the ideal conditions under which one would want to communicate.  as much as possible  we want to restrict communication to cases where it can be inferred to be useful  which is what the diarg algorithm below is designed to approximate. 
1 	 specifying team knowledge in mallet  
in this section  we briefly describe mallet  the team knowledge representation language in cast. mallet provides descriptors for encoding knowledge about operators and plans of individuals and the team  as well as definitions of roles and responsibilities on the team. an important ontological commitment in mallet is that roles are fundamentally treated as references to specific steps in team plans  to which certain agents on the team can externally be assigned.  that is  the meaning of a role is defined by a certain step in a team plan that is dedicated for the agents playing that role to carry out.  
   mallet syntax is based loosely on lisp  in the sense of using s-expressions and prefix notation. variables are indicated with ' ' prefix. operators are simply names of atomic actions that can be taken in the environment.  operators may list a set of pre-conditions and/or postconditions  each as a conjunction of literals  first-order predicates or their negations .  here is an example for climbing over a pit: 
 operator climb-over   pit   
 pre-cond  have-ladder    
there are two types of operators: individual operators and team operators.  individual operators are assumed to be executed by only one agent at a time. however  team operators have the possibility of being invoked on a set of agents  e.g. those playing a given role .  how the agents handle the team operators depends on what sub-type it has. we have identified three modes of operator-sharing:  
  and operators  which require simultaneous action by all the agents involved 
  xor operators  which require at most one agent to act  mutual exclusion  e.g. to avoid conflicts  
  or operators  which can be execute by any of the agents  possibly  1  without conflict hence team operators contain an extra component that defines the  share-type.  for example  an operator for lifting a heavy object might be written as: 
 t-operator lift-heavy   x   
 share-type and  
 pre-cond  movable  x     
¡¡¡¡¡¡¡¡¡¡ effect  holding  x    plans in mallet are essentially designed to describe processes. processes consist of invocations of atomic actions  or arbitrary combinations using various constructs such as sequential  parallel  contingent  or iterative.  the syntax of processes can be defined recursively according to five constructs  with obvious intuitive meanings:  
 seq p q    par p q    if  cond c  p 
 q     while  cond c  p    do t  
where p and q are sub-processes  c is condition 
 conjunction   and t is an operator or plan instantiation  with arguments . these constructs for describing complex processes can be given a semantics in various formalisms such as dynamic logic  harel  1 . 
   individual plans have pre-conditions and effects  and also a process description. team plans are similar to individual plans  but they have two extra features related to assignment of roles. first  we have declarations of role variables of the form  role  role-name   rolevariable   constraints    where the constraints are a conjunctive set of conditions that put restriction on the role variable  which candidates must satisfy.  for example  the team plan below requires two agents  one with the carrier role  the other with the fighter role.  the fighter agent has an additional constraint  i.e. satisfying the predicate closesttowumpus.  
 
  t-plan explore-cave    
   role carrier  ca  
   role fighter  fi   closesttowumpus  fi    
   process  seq 
             do  ca  find-wumpus   
             do  fi  moveto-wumpus   
           do  fi  kill-wumpus         
 
the general idea is that an appropriate agent meeting the constraints will be selected from the set of those assigned to play the role  and bound to the role variable within the plan. these role variables can then be used within processes to specify which agents will do certain steps  operators or sub-plans . an important implication of allowing constraints in the role specification is that it introduces flexibility to the teamwork process because the selection of such roles needs to be made dynamically at run time to assure that the constraint is satisfied. we will elaborate on the role selection scheme in the next section. 
   finally  mallet also provides simple descriptors for defining the members on the team  the roles they play  and their capabilities and responsibilities. while capabilities are treated simplistically  as static associations between agents and operators   the meaning of a responsibility is more interesting.  it is similar to a role  in the sense that it defines agents who are supposed to do certain actions  but they are not tied to specific steps in the context of specific plans. instead  the responsibility of an agent for an operator means that  whenever the action needs to be done at any time  the agent knows that it should act or at least coordinate with others who share the responsibility.   
   mallet descriptions are converted into petri nets on which the agent's reasoning algorithm operate. a petri-net generation algorithm constructs transitions for each atomic operator in a team plan  connects them with control nodes  and links their inputs and outputs to appropriate belief nodes based on pre- and post-conditions. since plans can be hierarchical  the sub-plans are expanded by calling the petri-net generation algorithm recursively  and linked into the main petri net through control nodes such that all the action nodes ground out in operators.  thus for each team goal  there is a single petri net that describes its plan for solving it. by placing tokens on the topologically-first node s  of the petri net  and moving them forward whenever steps are completed  agents can keep track of the progress of the team. though not every agent is involved in or responsible for every step  this petri-net model of the overall team plan forms a common understanding of the team's goals and process  which they use to determine how their individual actions fit together  and is thus a primary constituent of their shared mental model.   
   the knowledge compiler also performs a static information-flow analysis  yin et al.  1  for the online diarg algorithm. an information-flow relation i is defined as a 1-tuple   info needers providers   where info is the predicate name together with 1 or more arguments  needers is a list of agents who might need to know such information  and providers is a list of agents who might know the information. we determine the needers of information by analyzing the pre-conditions of operators for which each agent might be responsible. and we determine the potential providers of information by analyzing the post-conditions of operators for which the agents might be responsible.  in particular  if p is a postcondition of operator o  then we assume that an agent will know p after executing o  since we can expect agents to know the  direct  consequences of their own actions. 
1 	cast agent kernel 
the cast kernel refers to a set of algorithms that cast agents use to determine what actions and communications they will take at each time step.  cast agents execute a standard sense/decide/act loop.  during the sense phase  they make queries to the simulation server to update their knowledge of the state of the world.  agents also check a queue for messages from other agents at this time.  during the decide phase  each agent examines the petri-net representation of the team plan to see if there are any pending actions for which it is responsible.  in cases of ambiguity  the agents might have to communicate in order to determine who will take the action and when. before finally taking actions  the agents attempt to determine if there are any interactions they can initiate. for proactive information exchange  this is accomplished by diarg.  
   cast also uses a back-chaining theorem-prover called jare  also implemented in java  for making inferences using domain knowledge written in the form of a separate horn-clause knowledge base. jare is used to determine the truth-value of conditions or constraints that need to be evaluated in interpreting mallet expressions at run-time. 
1 	dynamic role selection 
the algorithm for dynamic role selection  drs  is used to support reasoning about role assignments and to generate the necessary interactions among agents to correctly execute the team plan with appropriate actors for each step. it has the following main steps: 
 
drs step  
1 let a be the set of agents potentially involved in the step  a=involvedagents step  
1 remove from a any agents that are incapable of taking the action 
1 remove from a any agents that do not satisfy the role constraints  if defined for that step 
1 if a is empty  do nothing  
1 if |a|=1 and member self a   do step  
1 else 
1a. if step is an and operator    synchronize step  
1b. if step is an or operator     attempt-in-parallel step  
1c. if step is an xor operator     disambiguate step  
 
for each active step in the team plan  nodes marked with a token in the process net   drs starts by determining the set of agents that could be involved. this is done by considering several different ways of assignment  in a particular order of precedence: 
 
involvedagents step  if step is of the form do agent action      then return {agent} if step is of the form do role action    then return {ai} forall agents that were assigned to play that role  
¡¡¡¡ai¡Êroleset role  if step refers to an operator op for which some agent has been assigned responsibility  then return {ai} forall agents such that resp ai op  
else return all the agents on the team    {ai} forall agents such that ai¡Êteam 
 
assignments of specific agents are considered first  and then role specifications  where several agents may be assigned to the role for a given step in the plan.  if no agents or roles are directly assigned  then the search for involved agents expands to considering any agents that might be responsible in general for such actions.  finally  if it is still undefined who should perform a step  then all the agents in the team are included  since this is ultimately a step in a plan to which they are all jointly committed. 
 after determining the set of agents potentially involved in the action  those agents that are unacceptable are filtered out.  for example  if an agent is incapable of performing the action  then it is removed from the set.  in addition  if any constraints were associated with the role definition  then only those agents that satisfy the constraints are retained.  this is accomplished by making a query to the agent's knowledge base that is constructed from the conjunctive conditions of the constraint by substituting any variables that are bound in the current scope  plus replacing the agent/role variable with the identity of each candidate.  those agents that do not satisfy the query are removed from the set of involved agents.  other factors could also be considered at this stage  such as removing agents from consideration whose workload is too high.  after determining the set of involved agents  steps 1 are used by the agents to decide what to do based on the size of this set.  if the set is empty  then there is simply nothing to do; the team must wait until an acceptable agent becomes available. if there is a single  unique  agent involved in the step  then the agent may act right away  without any coordination.  in these cases  cast agents are intelligent enough to act on their own.  this illustrates one of the sources of efficiency in teamwork gained from a priori role assignments - agents can sometimes figure out what to do on their own. if there are multiple agents involved in the step  line 1 in the algorithm   then each agent's response depends on the type of operator it is.  if it is an and operator  then all the involved agents must act simultaneously. this synchronization can be accomplished by broadcasting a ready signal and waiting until they have heard the same from all the other agents.  if the operator is an or operator  then any of the agents may take the action.  hence they all commit to trying to carry it out. several might actually succeed  independently  in performing the act.  however  not be too wasteful  we require agents to broadcast a success message when they have completed the step  at which point the other agents involved are permitted to drop their commitment  this is what attempt-inparallel means in step 1b of the drs algorithm above .  finally  if the step refers to an xor operator  only one of the agents involved may take the action  otherwise some interference might occur.  therefore  agents must agree amongst themselves who will take responsibility for the action.  this disambiguation can be accomplished through a variety of protocols  such as first-come-first-served  but they all require communication.  hence agents exchange messages to select a delegate  and then this agent make a commitment to do the action and the others do not have to. 
 	while the current algorithm for dynamic role 
selection produces flexible teamwork that is adaptive to specific situations  it does not handle all possible situations.  for example  if agents could die  lose their connection to the team  or become incapable dynamically within the environment  then the team might need to react to these changes and adjust its operation.  the possibilities range on a spectrum of complexity from using redundant role assignments for providing backup behavior and loadbalancing  to dynamic re-configuration of the whole team. these features could be added to the drs algorithm  but are left for future work. 
1 	diarg algorithm 
the 	diarg 	algorithm 	 dynamic 	inter-agent 	rule 
generator   an extension of iarg  yin et al.  1    is responsible for identifying opportunities for proactive information exchange. instead of sending information to all possible needers and asking all possible providers for information  agents with diarg can keep track of the teamwork status and only send information to whom it is relevant in the current context  and ask those agent who might know the information at the moment. this makes the diarg algorithm more dynamic. diarg is run by each agent during each cycle  independent of the other decisionmaking activities  and could result in agents sending additional messages to one another.  in particular  agents attempt to identify pieces of information that other agents might need to know and inform them via tell operations. in addition  if agents need some information and they can figure out who might know it  they can generate ask operations. these inferences are accomplished partly by examining the information-flow relations  coupled with analysis of the current state of the team.   
 
proactivetell   
  if i is a newly-sensed piece of information        or i is a post-condition of the last action       p taken by self  then      if i is not in the knowledge base   
   assert i into knowledge base   for each information-flow  
         predicate  needers  providers         if i matches predicate name and self is            included in the providers  then        for each agent x in the needers   
       if agent x plays a role in an active 
       step   
          tell x i  
 
activeask   for each active step s in the plan in which self is involved  
let o be the operator to which s refers  for each pre-condition i of s    if not know self  i    then  
let info-flow =  predicate  needers  providers  be the information flow in which i matches predicate name  select the agent y from providers 
¡¡¡¡ active agents first       do ask y i  
 
these algorithms are designed to generate inter-agent communications based on approximation of the criteria set forth in section 1 for ideal conditions under which it is desirable to exchange information.  in principle  we want agents to communicate only when it is likely to be useful  to minimize network traffic  use of bandwidth . the formal criteria are difficult to achieve in practice  particularly due to the need for belief reasoning. while we do not model the complete belief state of other agents  our static analysis of information flow identifies agents which might know or need to know certain information based on their involvement in the team plan  i.e. through actions for which they might be responsible . when some information changes  for example due to the action of an agent  and there is an effect of the action that others cannot observe  or when an agent observes some new information  then it might want to inform the others  proactively .  the sending of these messages is restricted to those agents who conceivably might need to know the information. whether or not an agent really needs to know a piece of information also depends on whether it supports one of their current goals  which we predict from active nodes in the petri net.  
   however  these algorithms cannot guarantee perfectly optimal information flow. for example  it depends on what they can observe and what they can infer.  also  while we assume that agents are never forgetful  information might change dynamically  non-deterministically  at different rates in different environments  and not all agents might be able to observe changes in all information  making the problem of maintaining consistent and correct distributed 
knowledge in a team very difficult in general  singhal and zyda  1 . however  the diarg algorithm is implemented at an appropriate level for supporting interactions in mixed human-agent teams  since it does not require direct access to  or simulation of  the mental state of other team members  and is able to derive potentially useful information flows based only on analysis of common  shared  knowledge of the team plan  individuals' roles  and the current state of progress  which can be assumed to be monitored by all the members of the team. 
1 	a testbed application 
   we have constructed a testbed application based on a multi-agent extension of the wumpus world  russell and norvig  1 . these agents can act as part of a team by playing the role of a fighter  to shoot the wumpus  or a carrier  to carry the gold they find. to generate the need for information flow between team members  the two types of roles have different sensing capabilities. while both of them can sense a stench  from a wumpus   a breeze  from pits   and glitter  from gold   only the carrier can pin-point the exact location of the wumpus when it is in an adjacent room in the cave. these experiments use a team plan and individual plans  along with other related teamwork knowledge  to find and kill multiple wumpuses and collect gold. agents can communicate in three ways:  1  proactive tell   1  broadcast information  and  1  broadcast control tokens for coordination purposes.   
 
table 1. different teams used in experiments 
 
exper iment  team #of 
carriers #of 
fighters team work communication drs 1 a 1 1 yes proactive 	info exchange no b 1 1 yes broadcast 
every new info no c 1 1 no no no 1 d 1 1 yes proactive 	info exchange no e 1 1 yes proactive 	info exchange yes  
    in order to evaluate the effectiveness of different features supported by cast - shared mental models  proactive information exchange  and dynamic role selection - we have devised two sets of experiments and five multi-agent teams for comparison. the differences among the five teams are listed in table 1. experiment 1 is run on team a  team b  and team c to show the benefit of using shared mental models and proactive information exchange. experiment 1 is run on team d and team e to show the benefit of dynamic role selection. 
   in experiment 1  teams a and b both use teamwork  whereas c does not.  furthermore  team a uses proactive information exchange  the diarg algorithm is turned on   whereas agents in team b just broadcast each new piece of information indiscriminately to all the members on the team. agents in teams a and b use a mallet specification of a team plan that requires the carrier to first find the wumpus  then navigate a fighter to a room adjacent to the wumpus and shoot the wumpus. agents in team c merely wander around randomly  independently looking for wumpuses to shoot and gold to pick up.  to make the comparison fair  agents in team a and team b also use individual plans in mallet to perform this wandering behavior when not busy. so there is teamwork based on the shared mental model of the team plan for agents in team a and team b  but in team c  there is no communication and no teamwork.  experiment 1 is meant to show the benefit of dynamic role selection. team d is similar to team a except that team d has more fighters; however  team d does not use dynamic role selection. team e implements the dynamic role selection protocol for each of its agents. all five teams use the same knowledge base  i.e. jare rules  for reasoning about the environment and for determining the priority of actions. 
 
table 1. comparison of performance for teams that differ in teamwork and information exchange. 
 
team static v1 v1 v1 v1 v1 a average 1 1 	1 	1 1std. dev. 1 1 1 	1 1b average 1 1 1 1 1std. dev. 1 1 1 1 1c average 1 1 	1 	1 1std. dev. 1 1 1 	1 1 	v1: # wumpuses killed v1: # of arrows used 
 	v1: # of gold found  	v1: # of messages broadcast 
 v1: # of proactive information exchanges experiment 1 was performed on 1 randomly generated maps for a world  cave  with 1 by 1 cells  rooms   1 wumpuses  1 pits  and 1 piles of gold. each team is allowed to operate for a fixed number of total actions. the performance of each team for each case is measured by  1  the number of wumpuses killed   1  the number of arrows used   1  the amount of gold gathered  1  the number of  messages broadcast  and  1  the number of proactive tell messages.  the average and standard deviation of the experiments are summarized in table 1. 
   as shown in the table 1  team a and team b achieve comparable performance  because they use an identical shared mental model specified in mallet. however  
team b has a much higher communication overhead  v1 . team a and team b both have better performance in terms of number of wumpuses killed  because there is teamwork among agents in team a and team b. whenever the carrier in team a and team b finds any wumpus  it will tell the fighter to go kill it  which gives the whole team a better chance to kill more wumpuses. however  picking up gold is an individual activity  so from the table  we can not see much difference among the three teams. one more advantage of team a is that the fighter only needs one arrow to shoot a wumpus with known location.  this is achieved because the carrier agent tells the fighter agent proactively about the location of the wumpus  using diarg to infer that the fighter needs the information to navigate to the wumpus. in contrast  the fighter in team c has to randomly choose a direction for shooting when it senses a stench  and cannot get any help from the carrier to locate the wumpus. consequently  team c consumes the same number of arrows to get half as many wumpuses as both team a and team b  and thus has worse resource utilization. 

 
figure 1 - the comparison of teamwork with and without dynamic role selection in increasingly complex environments 
   experiment 1 was performed on 1 sets of 1 randomly generated maps for a world with 1 by 1 cells  1 wumpus  and 1 piles of gold. the difference between the sets of maps is that we incrementally increase the complexity of the world by changing the number of pits in the cave  from 1 to 1 to 1 to 1 pits respectively. each team is allowed to operate for a fixed number of actions. the performance of each team for each case is measured by the same metrics we used in the first experiment. the performance difference is shown in figure 1. 
   from figure 1  we can see that with dynamic role selection  team e performed better than team d and the difference becomes larger when the complexity of the problem scales up. because the most appropriate fighter will always be chosen to kill the wumpus whenever the carrier finds one  more wumpuses can be killed in a limited number of actions. and in worlds with more pits  it is even harder for the fighter to navigate to the wumpus found  so choosing the closest fighter becomes much more important. 
but when the world has so many pits that even the carrier gets trapped  teamwork becomes impossible and the performance of both teams will drop significantly. 
1 	conclusion 
developing a computational framework for capturing the shared mental model among members of effective teams is a challenging and critical issue for applications ranging from team training to supporting teamwork. the cast architecture supports flexibility in its teamwork knowledge specification and in dynamic role selection at run time.  at the same time  it leverages shared knowledge about the structure and the process of a team to reason about information needs of teammates efficiently. we believe the cast architecture achieves a reasonable tradeoff between the flexibility and the efficiency for simulating proactive information exchange among teammates. while our experimental results demonstrate anticipated benefits of cast  it also reveals some limitations of the current cast implementation.  for example  we plan to extend the role selection method for finding backups when an agent dies or becomes non-functional. with such an extension  we hope to simulate more complex teamwork behavior.  
1 	acknowledgements 
this research described in this paper is supported by a dod muri grant f1-1 administered through afosr and partially supported by internal seed funds from the college of engineering through the training systems science and technology initiative. 
references 
 cannon-bowers and salas  1   canon-bowers  j. a. and salas  e. a framework for developing team performance measures in training  in brannick  m. 
t.  salas  e. and prince  c. editors  team performance assessment and measurement: theory  methods  and applications  lawrence erlbaum associates: hillsdale  nj. 1. 
  cohen and levesque  1  cohen  p.r. and levesque  h.j. intention is choice with commitment. artificial intelligence  1   1.  
 cohen and levesque  1  cohen  p.r. and levesque  h.j. teamwork.  nous  1 :1  
1. 
  grosz and kraus  1  grosz  b.  and kraus  s. 
collaborative plans for complex group action. 
artificial intelligence  1-1  1. 
 halpern  and moses  1  halpern  j.y. and moses  y. a guide to completeness and complexity for modal logics of knowledge and belief  artificial intelligence  1-1  1. 
 harel  1  harel  d. dynamic logic. in handbook of philosophical logic. gabbay  d. &  guenther  f.  eds. . reidel publishing : dordrecht  netherlands  1.  
 ilgen et al.  1  ilgen  d. r.  major  d. a.  and 
hollenbeck j. r. leadership and research: perspectives and directions  san diego: academic press  1. 
 jennings  1  jennings  n. controlling cooperative problem solving in industrial multi-agent systems using joint intentions. artificial intelligence  
1 :1  1. 
 jones et al  1  jones  r.  laird  j.  nielson  p.  coulter  k.  kenny  p.  and koss  f. automated intelligent pilots for combat flight simulation. ai magazine  1 :1  1. 
 rao and georgeff  1  rao  a.s. and georgeff  m.p. 
modeling rational agents within a bdi architecture. 
principles of knowledge representation and reasoning  proceedings of the second international conference  1  1. 
 russell and norvig  1  russell  s. and norvig p. 
artificial intelligence: a modern approach. prentice hall  new jersey  1. 
  singhal and zyda 1  singhal  s. and zyda m. networked virtual environments. new york  new york  acm press  1. 
 sowa  1  sowa  j.f. knowledge representation: 
	logical  	philosophical  	and 	computational 
foundation.  brooks/cole: pacific grove  ca  1. 
 stone and veloso  1  stone  p.  and veloso  m. 
task decomposition  dynamic role assignment  and low-bandwidth communication for real-time 
strategic teamwork. artificial intelligence  1-
1  1. 
 tambe  1  tambe  m. towards flexible teamwork. journal of artificial intelligence research  1-
1  1. 
 tidhar et al.  1  tidhar  g. and heinze  c. and selvestrel  m. flying together: modelling air mission teams. journal of applied intelligence  1  pp1  1. 
 wooldridge and jennings  1  wooldridge  m.  and 
jennings  n.  intelligence agents: theory and practice. knowledge engineering review  
1 :1  1. 
 yin et al.  1 yin  j.  miller  m.  ioerger  t.r.  yen  j.  and volz  r.a. a knowledge-based approach for designing intelligent team training systems. in: 
proc. of the fourth international conference on autonomous agents  pp. 1  1. 

multi-agent systems
market mechanisms

market clearability
 tuomas sandholm sandholm cs.cmu.edu
computer science department
carnegie mellon university
pittsburgh  pa 1subhash suri suri cs.ucsb.edu
department of computer science
university of california
santa barbara  ca 1
abstract
market mechanisms play a central role in ai as a coordination tool in multiagent systems and as an application area for algorithm design. mechanisms where buyers are directly cleared with sellers  and thus do not require an external liquidity provider  are highly desirable for electronic marketplaces for several reasons. in this paper we study the inherent complexity of  and design algorithms for  clearing auctions and reverse auctions with multiple indistinguishable units for sale. we consider settings where bidders express their preferences via price-quantity curves  and settings where the bids are price-quantity pairs. we show that markets with piecewise linear supply/demand curves and non-discriminatory pricing can always be cleared in polynomial time. surprisingly  if discriminatory pricing is used to clear the market  the problem becomes -complete  even for step function curves . if the price-quantity curves are all linear  then  in most variants  the problem admits a poly-time solution even for discriminatory pricing. when bidders express their preferences with price-quantity pairs  the problem is -complete  but solvable in pseudo-polynomial time. with free disposal  the problem admits a poly-time approximation scheme  but no such approximation scheme is possible without free disposal. we also present pseudo-polynomial algorithms for xor bids and -of- s bids  and analyze the approximability.
1	introduction
market mechanisms play a central role in ai for several reasons. first  they provide a tool for resource and task allocation in multiagent systems where the agents may be selfinterested. second  ai techniques can be used to clear markets. for example  there has been a recent surge of research in the ai community on search algorithms  sandholm  1; fujishima et al.  1;sandholmand suri  1 and specialcase polynomial algorithms  tennenholtz  1  for clearing combinatorial auctions. third  recent electronic commerce server prototypes such as emediator  sandholm  1  and auctionbot  wurman et al.  1  from academic ai groups have led to the uncovering of a need for fast clearing algorithms for a vast space of market designs.
¡¡in this paper we analyze the inherent complexity of  and design algorithms for  clearing auctions and reverse auctions

¡¡¡¡this work was funded by  and conducted at  combinenet  inc.  1 s. craig st.  pittsburgh  pa 1.
in the ubiquitous setting where there are multiple indistinguishable units of an item for sale.
¡¡in the largest securities markets where there are multiple units of each item  e.g.  stock  for sale  there usually are liquidity providers  market makers on the nasdaq and a specialist on the nyse  that carry inventory  and guarantee that trades are possible at essentially any quantity. therefore  direct matching between buyers and sellers is not absolutely necessary. however  we argue that if technically possible  it would be highly desirable to construct market clearing algorithms that directly match buyers and sellers  and do not rely on an external liquidity provider  for several reasons. first  most ecommerce marketplaces do not have external liquidity providers. second  liquidity providers incur operating cost  and need to be compensated. this compensation tends to be paid  implicitly  by the market participants. third  if the items that are being traded are not securities  the sec does not impose or monitor rules on liquidity-provisioning parties. finally  even in markets where the liquidity providers are regulated  they frequently violate the regulations  the most famous recent cases are from the nasdaq .
¡¡we study the possibility of algorithms for accomplishing this in the context of price-quantity curves first  and pricequantity pairs second. we analyze markets with and without free disposal of units. we also uncover the complexity implications of non-discriminatory vs. discriminatory pricing.
1	auctions with demand curve bids
we consider the auction setting where each bidder submits a demandcurve indicating the quantity he will accept at each unit price . if his bid is cleared at price   he receives units  for a total price of . recently  several computational markets have been built that use piecewise linear  sandholm  1  or step function  lupien and rickard  1; sandholm  1  demand curves.
¡¡we focus mainly on piecewise linear curves because they can approximate any curve arbitrarily closely  and because their complexity  in the sense of measuring the length of the input  can be characterized systematically. in order to keep our discussion simple  we use a single parameter to denote the complexity of the piecewise linear curves. that is  is the largest number of pieces in any bidder's demand curve.
¡¡we begin with an elementary lemma  which will be used repeatedly in the following discussion. for now  in order to keep the discussion simple  let us assume that the seller has an infinite supply of units to sell. when the number of units available is finite  the solution follows as an easy corollary of lemmata 1 and 1  as is discussed after those lemmata.
lemma 1 consider a linear demand curve subject to .
	if	  then an infinite revenue is achievable.
if   then the revenue is maximized at price . the corresponding quantity sold at this price is   and the revenue is .
proof. if the slope is non-negative  the revenue is maximized by setting . the second case is more interesting. the revenue at price equals .
setting the first derivative with respect to	to zero  we get
¡¡¡¡¡¡¡¡  which yields	. the second derivative is negative  since	   so the revenue is maximized at this . the values of	and	follow easily.
¡¡the demand curve could also have boundaries  meaning that the bidder expresses his preference by specifying the linear demand curve but with explicit bounds on the price. if the curve is restricted to the price range   where   we call it a bounded linear demand curve.
lemma 1 consider a bounded linear demand curve    restricted to the price range .
	if	  then the revenue is maximized at price	.
	if	  then the revenue is maximized either at
	 provided		  or at that endpoint of
	the range	which is closer to	.
proof. let us first consider the case of non-negative slope 
     . when   we have whenever   and so . thus  the maximum revenue is achieved at the highest permissible price  which is .
¡¡when the demand curve has negative slope  lemma 1 tells us that the optimal solution without price boundaries is
¡¡¡¡¡¡¡¡¡¡. if this optimal price is within the range   then it obviously maximizes the revenue  and we are done.
so  let us now assume that	.

figure 1: revenue maximization for a linear demand curve with boundaries.
¡¡we consider the effect on revenue of changing the price by an amount from the unconstrained optimum .  see figure 1.  let   where   be an arbitrary point on the linear curve . since is the slope of the demand curve  we note that  let be the change in the price  and let be the corresponding change in the quantity. then  it follows that . the revenue at point is
 in line 1 we used the fact that  and . since the demand curveslope is negative this shows that a change of from the unconstrained optimal price  reduces the revenue by . thus  if the price curve is bound to the
range   and   the maximum revenue is achieved at either or   whichever is closer to .
¡¡in the preceding discussion  we assumed that the seller has an unlimited supply of units. when this supply is bounded by some quantity   the optimal solution can be derived easily  as follows. of course  a feasible solution exists if and only if
¡¡¡¡¡¡¡¡¡¡¡¡¡¡. when the slope is positive  the seller sells units. when the slope is negative and   revenue is maximized at . but if   then the revenue is maximized at .
¡¡a piecewise linear demand curve consists of one or more boundedlinear curves. we do not require the demand curveto be continuous  i.e.  the quantity can  jump  between pieces . given a single piecewise linear demand curve bid  we can use lemma 1 on each linear piece separately to determine the revenue-maximizing allocation. to lay the groundwork for our auction-clearing algorithm  we next discuss the problem of aggregatingthe demand over multiple piecewise linear curves.
demand curve aggregation: consider a set of piecewise linear curves . their aggregate curve is a piecewise linear function such that is the total
demand at unit price . that is 
	where	is the demand by curve	at unit price
. for instance  if the demand curves are linear functions
               then their aggregate curve is easily shown to be the linear function .
breakpoints of aggregate curve: the aggregate curve changes only when one of the component curve changes; that is  the breakpoints of are the union of the breakpoints of the component curves. thus  given a set of piecewise linear curves each of which has at most pieces  their aggregate curve has at most breakpoints.
¡¡given piecewise linear curves  we can compute their aggregate curve in time   as follows  where is maximum number of pieces in any curve. let   where   denote the breakpoints of all the component curves  in sorted order. we scan these breakpoints in right to left order  decreasing order of price   and determine the linear aggregate curve between two consecutive breakpoints.
¡¡initially  we compute the linear aggregate function in the range   in time. next  as we move to the next breakpoint  at most one linear piece changes-one piece may end and another may begin.  if multiple curves begin or end at the same point  we can enforce an artificial order among
those  and consider them one at a time.  we can update the linear aggregate by deleting the coefficients of the leaving curve and adding those of the entering curve  and so each update takes time. thus  the complete aggregate curve can be determined in time   after an initial sorting cost of	.
¡¡while the construction just described should be sufficiently fast for most practical applications  we can build the aggregate curve even faster if only part of the curve is needed.
lemma 1 given piecewise linear demand curves  we can construct the rightmost pieces of their aggregate curve in time   where   and each curve has at most pieces.
proof. we maintain a priority queue that stores the  next  breakpoint  end  begin  or change  of each component curve. we process events in the order presented by the priority queue: when we delete a breakpoint from the queue  we insert the next linear piece  if any  of the same curve. we initially compute the rightmost piece of the aggregate curve in time. after that the aggregate curve is updated at each event point in time. inserting or deleting an event from the priority queue takes time  and so the total cost to construct rightmost pieces of the aggregate curve is
.
1	auctions with non-discriminatory pricing
say that the seller wants to auction off indistinguishable units of an item. each of the bidders submits a piecewise linear demand curve bid. in a non-discriminatory auction  the seller determines an optimal price to maximize his revenue  and every buyer pays the same unit price .  the number of items received by bidder is computed using his demand curve  evaluated at price . 
¡¡as lemma 1 shows  if the seller wants to maximize his revenue  he might not sell all the units. we therefore consider the auction both with and without free disposal. with free disposal  the seller may choose to keep some units  because he can dispose of them for free   but without free disposal  he must sell all the units.
theorem 1 consider a single-item  multi-unit auction with bidders  each with a piecewise linear demand curve. under non-discriminatory pricing  the auction can be cleared so as to maximize the seller's revenue in time with or without free disposal  where is the maximum number of pieces in any bidder's demand curve.
proof.
 without free disposal.  we construct the aggregate demand curve  incrementally from the right  as described in lemma 1. for each linear piece of the aggregate curve  we check to see if it intersects the supply line
¡¡¡¡¡¡. if there is an intersection  then the intersection point is a feasible solution. since the goal is to maximize seller's revenue  we want the rightmost  highest price  intersection. thus  we can stop the algorithm as soon as we find an intersection. from this price we can determine the quantities sold to each bidder  using their demand curves.  the problem is clearly infeasible when there is no intersection between the line and the aggregate curve. 
 with free disposal.  in this case  we compute the entire aggregate curve  since we cannot stop at the rightmost feasible solution. for each linear piece of the aggregate curve  we compute the maximum feasible revenue and keep track of the optimum found so far.
1. if the piece lies entirely above the line   no feasible solution exists for this piece.
1. if the piece is entirely below the line  we take thesolution given by lemma 1. in other words  we compute the unconstrained optimum for this linear curve. if is within the price bounds of the piece  we take that solution; otherwise  we choose the endpoint of the linear piece whose price is closer to .
1. if the piece intersects the line   we compute the unconstrained optimum . if   we take the unconstrained solution; otherwise  we sell units.
each of the three cases takes constant time to evaluate. thus the complexity is dominated by the time to build the aggregate curve  which is .
1	auctions with discriminatory pricing
in a discriminatory price auction  the seller determines for each buyer a distinct unit price with the objective of maximizing his revenue subject to the supply constraint . the quantity sold to buyer is determined from 's demand curve at price . for a fixed set of demand curve bids  the seller's revenue in a discriminatory auction is generally higher  and never lower  than in a non-discriminatoryauction  but the latter offers a stronger notion of fairness among bidders. discriminatory price auctions however do offer a weak form of ex ante fairness: they are anonymous in the sense that had two players swapped their bids  their allocations would also have been swapped.
intractability under piecewise linear demand curves
in sharp contrast to a non-discriminatory auction  we show that clearing a discriminatory auction with piecewise linear demand curves is -complete. in fact  this complexity jump occurs even for the simplest piecewise linear demand curve  a step function.
step function demand curve: a step function demand curve is defined by a tuple   indicating a buyer's willingness to buy units at or below the unit price ; the buyer is not willing to buy any units at price strictly greater than .
theorem 1 consider a single-item  multi-unit auction with bidders  each making a step function demand curve bid. then the problem of determining a revenue-maximizing allocation using discriminatory pricing  is -complete. this holds with or without free disposal.
proof.
 with free disposal. 
we reduce the knapsack problem to our auction problem. let	be an instance of the knapsack problem- is the knapsack capacity  and   respectively  are the size and value of item . the goal is to choose a subset of items of maximum value with total size at most . we create an instance of the single-item multi-unit auction using step function demand curves  as follows. bidder places a step function bid   meaning he is willing to buy units at lot price  ormaximumunit price    and no units for a higher price. the total number of units available is . since we are using discriminatory pricing  the goal is to choose a subset of bids maximizing the total revenue subject to the total quantity constraint . now  it is easy to see that any solution to the auction problem is a solution to the knapsack  and vice versa.
 without free disposal. 
we reduce the subset sum problem  garey and johnson  1  to the auction problem. in the subset sum problem  we are given a set of integers
¡¡¡¡¡¡¡¡¡¡¡¡¡¡  an integer   and the goal is to choose a subset of whose elements sum to exactly . we create bids  where the bidder places a step function demand curve bid -that is  the buyer is willing to pay one dollar per unit for units  but does not accept any other quantity.  actually  the price is immaterial in this transformation  so we use a default value of $1.  the total number of units available is . it is easy to see that the auction without free disposal has a feasible solution if and only if the original subset sum problem has a solution.
¡¡thus  we conclude that even with step function demand curve bids  or more generally piecewise linear curve bids  the discriminatory auction becomes intractable.
polynomial algorithm for linear demand curves
there is an important case of the discriminatory price auction for which we can clear the market in polynomial time. this is the case where all bids are downward sloping linear demand curves  that is  in the demand curve   we have and . in other words  the buyer's demand decreases linearly as the price increases. we begin by describing the algorithm for auctions with free disposal. let us suppose that the auctioneer has units of the item for sale. then  the algorithm has the following steps.
1. let	denote the index set of bids.
1. computethe unconstrainedoptimal solution for each bidindependently:  .
1. if   then these unconstrained pricequantity pairs are the optimal solution.
1. otherwise  let	  and let	be the index of the bid that achieves this minimum.
1. set   and   for . that is  increase each bid's unit price by   and determine the new quantity.  note that because is negative. 
1. if	  then set	  where
  and stop. this is
the optimalquantity sold to buyer   at the corresponding price .  notethat both and are negative 
	and so	and	. 
1. otherwise  set	  and go to step 1.
the correctness of the algorithm depends on three facts:
   if the unconstrained solution is quantity-infeasible  then one must increase the unit price uniformly for all bids  until either the solution becomes feasible or the price becomes infeasible for some bid  when the price becomes infeasible for some bid  that bid receives zero units in the optimal solution  and in the price-interval where the set of feasible bids remains constant  the formula of line  1  gives the optimal solution. due to lack of space  we omit the proofs of these claims. instead  we briefly discuss the time complexity of the algorithm. step  1  repeatedly chooses a bid with the next smallest unconstrained optimal price . in order to facilitate this choice  we initially sort the bids in increasing order of 's. the key step is to determine whether . however  it is easy to see that
. thus  we can calculate
¡¡¡¡¡¡¡¡in time  by simply keeping track of the sums and . these sums only change when a bid is removed from   and can be maintained in time per update to . in summary  once the bids have been sorted  the total cost of running the algorithm is . we summarize this result in the following theorem.
theorem 1 consider a single-item  multi-unit auction with bidders  each making a downward sloping linear demand curve bid. under discriminatory pricing  the auction can be cleared so as to maximize revenue in time  with or without free disposal.
remark. for completeness  we now discuss the complexity of clearing absurd types of linear demand curves. if all the demand curves are upward sloping  the higher the unit price  the more the bidder will buy   then the optimal solution is easily obtained  with or without free disposal  by selling all units to the bidder whose demand line intersects the constant line at the highest unit price. this can be determined in time by calculating the intersection point for every demand line. next we consider the case where all demand curves are constant      i.e.  the bidders do not care about price. with free disposal  the seller's revenue can be maximized in time by choosing any bidder  whose quantity is positive  i.e.     and chargingan infinite price. without free disposal  finding a feasible solution  finding a combination of the constant curves whose quantities sum up to exactly   is -complete because that is equivalent to the subset sum problem. if a feasible solution is found  the seller can charge an infinite price.
1	reverse auctions with supply curve bids
in this section  we consider reverse  or  buyer-based  auctions using an analogof demandcurvebidding. these types of auctions are frequently used for requests for proposals  rfps  and requests for quotes  rfqs . the buyer posts the items  goods  services  etc.  she wants to purchase  and sellers compete for the business by bidding to sell the items. we assume that a buyer wishes to acquire indistinguishable units of a certain item  and each seller submits a supply curve bid.
¡¡we start by establishing simple properties of linear supply curves. as in auctions  we consider two settings: free disposal and no free disposal. under free disposal  the buyer is willing to accept more than the desired units if it leads to lower cost  at worst he can dispose of the extra units for

¡¡¡¡when free disposal is not allowed  the only change to the algorithm is this: if the initial unconstrained optimal solution is quantityfeasible  meaning   instead of stopping  we decrease the price uniformly over all bids  until either the total demand reaches   or some bid becomes infeasible  its price reaches zero . when a bid becomes infeasible  we remove it from and continue.
free . without free disposal  the buyer wants exactly units  or none if the solution is infeasible .
lemma 1 consider a linear supply curve subject to . suppose that the buyer wishes to acquire units of the item.
	if	  then there is a feasible solution if and only if
¡¡¡¡¡¡. if   the cost to the buyer is with free disposal  and without free disposal. if   then the cost of acquiring the items is
proof. when the supply curve has non-positive slope  the maximum number of items that can be purchased is . thus  the trade is feasible if and only if . if free disposal is allowed  the buyer buys units at price ; without free disposal  the buyer pays per unit.
¡¡if the supply curve has positive slope  the price per unit is increasing with the number of units. if   then the buyer can buy units at zero cost. otherwise  the buyer purchases exactly units at the unit cost of .
lemma 1 consider a bounded linear supply curve 
	  restricted to the price range	  where	.
suppose the buyer wishes to acquire	units of the item.
without free disposal  a feasible solution exists iff
  and if feasible  the solution has cost
.
with free disposal and  a feasible solution existsiff	. set. if feasible  the so-lution has cost corresponding to	.	  where	is the pricewith free disposal and  a feasible solution ex-	ists iff	  and in that case the solution has cost
.
proof. see figure 1 for illustration. the first case follows easily  since the boundaries of the supply curve dictate that the quantity supplied is in the range . if lies in this range  the cost equals .

figure 1: bounded linear supply curves.
¡¡in the second case  since the slope is negative  the maximum quantity supplied is   and so for feasibility  we must have . since the buyer admits free disposal  we can purchase any quantity between and   in order to minimize the cost. we define so that the feasible range of quantity is . we now invoke the algebra of lemma 1 to observe that quantity decreases the farther the price deviates from .  recall that we have in this case.  thus  the cost of acquiring at least units in the range is minimized at one of the endpoints of the range. so  we take the smaller of the two values.
¡¡finally  in the third case  the largest quantity supplied by the curve is   so the feasibility condition checks whether
¡¡¡¡¡¡. if   then we can set   and our cost is   where is the price corresponding to .
1	reverse auctions with non-discriminatory pricing
consider a reverse auction where a buyer wants units of an item. each of the sellers submits a piecewise linear supply curve. in a non-discriminatory reverse auction  the buyer determines an optimum price to minimize his cost  and sellers supply their share of units at price .  the number of items purchased from seller is computed using his supply curve  evaluated at price .  the proof of the following theorem is similar to the proof of theorem 1.
theorem 1 consider a single-item  multi-unit reverse auctions with bidders  each making a -piece supply curve bid. under non-discriminatory pricing  the auction can be solved so as to minimize cost in time with or without free disposal.
1	reverse auctions with discriminatory pricing
in a discriminatory reverse auction  the buyer determines for each seller a distinct price with the objective of minimizing the total cost subject to the supply constraint
         .  without free disposal  the quantity constraint is an equality.  the problem of clearing such an auction with piecewise linear supply curves again turns out to be complete.
theorem 1 a single-item  multi-unit reverse auction with discriminatory pricing and piecewise linear  specifically step function  supply curve bids is -complete to clear so as to minimize cost  with or without free disposal .
proof. the proofwithout free disposal is the same as in theorem 1. the details of the free disposal case are different  so we discuss that here. we reduce the knapsack problem to the reverse auction  but since knapsack is a value-maximization problem  while the reverse auction is a cost-minimization problem  we need a minor transformation in between.
¡¡let	be an instance of the knapsack problem-the knapsack has capacity   and item has size and value . let us create an instance of the single-item multi-unit reverse auction  as follows.
¡¡bidder places a step function bid   meaning he is willing to supply units at lot price  or at any price higher than    and no units for a price less than . let be the total number of units in all the bids. we set up the auction so that the buyer wishes to purchase at least units  at minimum possible price. let be the set of bids that are winning bids in the reverse auction. then  we claim that the remaining bids  those not in   form a solution to the knapsack problem. first  since the bids in have a total of at least units  the remaining units are at most   and so the solution is knapsack feasible. second  since the bids in provide units at least possible price  the total price of the remaining bids is largest possible subject to the knapsack constraint. thus  the auction problem is -complete.
¡¡in fact  the reverse auction without free disposal is complete even with linear downward sloping supply curves  unlike the seller auction with linear demand curves which is polytime solvable  except in the absurd case of constant demand lines and no free disposal   cf. theorem 1.
theorem 1 a single-item  multi-unit reverse auction with discriminatory pricing and no free disposal is -complete to clear so as to minimize cost with downward sloping linear supply curve bids.
proof. consider an instance of the subset sum problem: set of non-negative integers	  and an integer	. corresponding to	  we create a linear supply curve
           . the subset sum problem has a solution if and only if the reverse auction without free disposal has a solution for quantity and cost 1.
remark. in the preceding theorem  the price zero is only for convenience. we can easily truncate the supply curves  for example at   to enforce a minimum unit price of one. in that case  the subset sum has solution if and only if the buyer can acquire exactly units at total price .
remark. with free disposal and downward sloping or constant supply lines  that start at    the optimal solution is obtained in time by accepting all supply lines at . if the aggregate quantity is at least   then the solution is feasible and optimal. otherwise  no solution is feasible.
remark. with constant supply lines and no free disposal  finding a feasible solution to the reverse auction is complete because that corresponds to the subset sum problem. if a feasible solution exists  and the lines start at   then the optimal solution has zero cost  accept at each one of the lines that are part of the feasible solution .
remark. in reverse auctions  downward sloping supply corresponds to quantity discounts. a more common case would be upward sloping supply  i.e.  the higher the price  the more the supplier is willing to sell. we analyze upward sloping supply lines in another paper  sandholm and suri  1   showing clearing complexity of -the same complexity as auctions with downward sloping demand lines.
1	price-quantity pair bids
in this section we consider auctions where the auctioneer has multiple indistinguishable units of one item to sell  and bidders express their preferences via price-quantity pairs.
definition 1 in a price-quantity pair bid   the bidder states a price that he is willing to pay for units. the bid is atomic  meaning it must be accepted as a whole or rejected-it cannot be accepted fractionally.
theorem 1  known  if the seller has units  and each buyer submits one price-quantity bid  then the problem of maximizing revenue is equivalent to the -complete knapsack problem. it is solvable in pseudo-polynomial time
        garey and johnson  1   where	is the number of bids and	is the maximum price of any bid. it is approximable within a	factor of the optimum in polynomial time		 lawler  1 .

¡¡¡¡in this section we consider the case where is the price for the entire lot . if a unit price is stated instead  it can be trivially converted to a lot price by multiplying by .
¡¡if there is free disposal  the auctioneer can always sell fewer than units because  at worst  he can dispose of the extra units for free. on the other hand  for many real goods there is no free disposal.
theorem 1 if the seller has to sell exactly units  or none if the instance is infeasible   and each buyer submits one price-quantity bid  then even finding a feasible solution is
   -complete. the problem of maximizing revenue can be solved optimally in pseudo-polynomial time.
proof. finding a feasible solution is -complete because the special case where for all is equivalent to the subset sum problem  which is -complete. the problem can be solved in pseudo-polynomial time using a straightforward dynamic program. we omit it due to limited space.
¡¡in many settings  a bidder could accept alternative quantities at different prices. this can be enabled by allowing each bidder to submit multiple price-quantity bids which are combined with .
theorem 1 if a seller can sell at most units  and each buyer submits a set of alternative price-quantity bids  i.e.  bids   then the problem is -complete. it can be solved in pseudo-polynomial time   where is the number of bidders  is the maximum number of alternative bids by any buyer  and is the maximum price of any bid. the problem can also be approximated within a factor of the optimum in  time.
proof. -completeness follows from theorem 1 since each bidder might only submit one price-quantity pair.
¡¡we now devise a pseudo-polynomial algorithm. we label the bidders  arbitrarily   through . observe that
is an upper bound on the revenue. let denote the smallest number of units that can be sold to bidders in the set with total revenue exactly .
1.  initialize:  let the alternative price-quantity bids of buyer 1 be	. set
	  for	.
	  for all other values of	.
1. for to for	to
¡¡¡¡if buyer has bid	  then
for	to if	then
	else	.
	this algorithm computes a solution in	time.
this pseudo-polynomial algorithm can be converted to an approximationalgorithm with running time using the scheme of lawler  lawler  1 .
¡¡while bids are fully expressive in the sense that they allow a bidder to express any valuation  mapping from the number of units to a price   in many cases  a more compact  and never less compact  representation of the same valuation can be obtained using the -of- s bidding language . an

¡¡¡¡¡¡¡¡bids and -of- s bids were originally introduced for combinatorial auctions where there are multiple distinguish-

market typelinear curves piecewise linear curvesupwardconstantdownwardslopingslopingnondiscriminatory auctiondiscriminatoryfd:-completeauctionnfd:-completenondiscriminatory reverse auctiondiscriminatoryfd:fd:-completereverse auction sandholm and suri  1 nfd:-completenfd:-complete
table 1: summary of our results on clearing supply/demand curves  fd = free disposal  nfd = no free disposal . the nontrivialresults are marked with a  * .
¡¡-of- s bid is a bid where multiple price-quantity bids are offered and any number of these can be accepted  subject to honoring the overall quantity  :
theorem 1 if the auctioneer can sell at most units  and each bidder submits an -of- s bid  then the problem can be solved and approximated with the time complexities stated in theorem 1  where now is the number of disjuncts submitted overall  and is the maximum number of bids within any -disjunct.
proof. we can treat different bids from the same bidder as coming from different bidders. since each bidder can be awarded any number of bids  this transformation is sound.
we can thus assume that each bidder has submitted only one bid  and solve the problemusing the algorithm described
in the proof of theorem 1.
¡¡now  consider xor bids and -of- s bids in settings where the auctioneer has to sell exactly units. it follows from theorem 1 that finding a feasible solution  and therefore also approximation  is -complete  unlike in the free disposal setting . the problem can be solved in pseudopolynomial time using a dynamic program akin to the ones abovewhere the auctioneercan keep any of the units  we omit these due to limited space .
1	conclusions
market mechanisms play a central role in ai as a coordination tool in multiagent systems  and as an application area for algorithm design. market mechanisms where buyers are directly cleared with sellers  and thus do not require an external liquidity provider  are highly desirable for electronic marketplaces for several reasons. in this paper we studied the inherent complexity of  and designed algorithms for  clearing auctions and reverse auctions with multiple indistinguishable units for sale.
¡¡table 1 summarizes our results on market clearability under demand/supply curves. note that in non-discriminatory settings  even when each bidder's curve is linear  the aggregate curve might not be linear but piecewise linear  because the bidder's curves have to be ignored below zero quantity .

able items for sale  and bids can be submitted on combinations of items  sandholm  1; 1 
¡¡in addition to the results summarized in the table  we believe that one of the most surprising result of our paper is the following property of discriminatory auctions: at the unconstrained optimum  each bidder generally gets a different price  but interestingly  to accommodate the constraint of limited supply  each bidder's price is incremented equally from the unconstrained optimum.
¡¡when bidders express their preferenceswith price-quantity pairs  the market clearing problem is essentially equivalent to the knapsack problem  and therefore -complete but solvable in pseudo-polynomialtime. with free disposal  the problem admits a polynomial-time approximation scheme  but no such approximation scheme is possible without free disposal. we also describe pseudo-polynomialalgorithms for xor bids and -of- s bids  and their polynomial approximability when free disposal is allowed.
¡¡our -completeness results carry over to exchanges  where the objective is to maximize surplus  i.e.  sum of accepted bids minus sum of accepted asks  directly since auctions and reverse auctions are special cases of exchanges.
¡¡our algorithms help pave the way toward automated electronic markets without external liquidity providers  but at the same time  our -completeness results curtail the space of automated market designs that are computationally tractable.
references
 fujishima et al.  1  yuzo fujishima  kevin leyton-brown  and yoav shoham. taming the computational complexity of combinatorial auctions: optimal and approximate approaches. in ijcai  pages 1.
 garey and johnson  1  michael r garey and david s johnson. computers and intractability. w. h. freeman and company.
 lawler  1  e. l. lawler. combinatorial optimization: networks and matroids. holt  rinehart and winston.
 lupien and rickard  1  william a lupien and john t rickard. crossing network utilizing optimal mutual satisfaction density profile. us patent 1 1  granted nov. 1 to optimark technologies.
 sandholm and suri  1  tuomas sandholm and subhash suri. improved algorithms for optimal winner determination in combinatorial auctions and generalizations. in aaai  pages 1.
 sandholm and suri  1  tuomas sandholm and subhash suri. computational complexity of clearing exchanges. technical report  1. in progress.
 sandholm  1  tuomas sandholm. an algorithm for optimal winner determination in combinatorial auctions. in ijcai  pages 1. first appeared: washington univ.  dept. of computer science wucs-1  jan. 1th.
 sandholm  1  tuomas sandholm. emediator: a next generation electronic commerce server. in agents  pages 1  barcelona  spain  june 1. early version: aaai-1 workshop on ai in electronic commerce  pp. 1  july 1  and washington univ.  st. louis  dept. of computer science wu-cs-1  jan. 1.
 tennenholtz  1  moshe tennenholtz.some tractable combinatorial auctions.aaai.
 wurman et al.  1  peter r wurman  michael p wellman  and william e walsh. the michigan internet auctionbot: a configurable auction server for human and software agents. in agents  pages 1.
on market-inspired approaches to propositional satisfiability
william e. walsh
university of michigan ai laboratory
beal ave  ann arbor  mi
1  usa wew umich.edumakoto yokoo
ntt communication science laboratories
1 hikaridai  seika-cho  soraku-gun 
kyoto 1  japan yokoo cslab.kecl.ntt.co.jpkatsutoshi hirayama
kobe university of mercantile marine
1-1 fukaeminami-machi  higashinada-ku 
¡¡kobe 1  japan hirayama ti.kshosen.ac.jpmichael p. wellman
university of michigan ai laboratory
beal ave  ann arbor  mi
1  usa wellman umich.eduabstract
we describe two market-inspired approaches to propositional satisfiability. whereas a previous market-inspired approach exhibited extremely slow performance  we find that variations on the pricing method with a simplified market structure can improve performance significantly. we compare the performance of the new protocols with the previous market protocol and with the distributed breakout algorithm on benchmark 1-sat problems. we identify a tradeoff between performance and economic realism in the new market protocols  and a tradeoff between performance and the degree of decentralization between the new market protocols and distributed breakout. we also conduct informal and experimental analyses to gain insight into the operation of price-guided search.
1	introduction
agents must often engage in activities with complex  interrelated dependencies. even finding a satisficing solution for problems such as resource allocation  scheduling  and production in a supply chain is often intractable for a central problem solver with global knowledge. the problem is further complicated when decentralization constraints such as locality of interest  knowledge  communication  and authority must be respected.
¡¡yokoo and hirayama    yokoo  1  formalize such problems as distributed constraint satisfaction problems  discsps  and  with others  have designed a variety of effective algorithms. these approaches are generally distributed adaptationsof centralized algorithms. recent interest in market-based approaches to distributed decision making  and open questions about the computational power of markets  shoham and tennenholtz  to appear   prompted walsh and wellman  to apply a market-based supply chain formation protocol  walsh and wellman  1  to a 1-sat reductionof the supplychain formationproblem  an approach they called marketsat. they found that  although market prices can guide decentralized search  the approach was impractically slow.
¡¡in this paper we present alternate  simpler market-inspired approaches that provide more satisfactoryperformance  while respectingwell-defineddecentralization constraints. we evaluate the protocols on benchmark propositional satisfiability  sat  problems. as the fundamental np-complete problem  formally equivalent to a large class of combinatorial problems  sat serves as a convenient problem class on which to systematically evaluate our protocols.
¡¡in section 1 we introduce two new marketsat protocols with qualitatively different pricing mechanisms. in section 1 we provide an economic interpretation of the protocols and discuss the rationality of the assumed agent behavior. in section 1 we convey our understanding of price-guided search and in section 1 we show that the protocols are incomplete. in section 1 we compare the performance of the new protocols with the original marketsat and with the distributed breakout  db  algorithm  yokoo and hirayama  1 . we also perform further experiments to explain the operation of the protocols. in section 1 we compare the decentralization of the marketsat protocols relative to distributed breakout. we conclude in section 1.
1	marketsat protocols
following the notation of walsh and wellman   we consider propositional satisfiability problems with variables u and clauses q  each containing sets of literals over u in conjunctive normal form  cnf . a clause is satisfied if at least one literal in the clause evaluates to t. the problem is to determine whether there exists a truth assignment t : u ¡ú {t f} that satisfies each q ¡Ê q.
¡¡a variable u fails to satisfy a clause q under truth assignment t iff either:  1  t u  = t  u ¡Ê/ q  and ¡¥u ¡Ê q  or   1  t u =f  ¡¥u¡Ê/ q  and u¡Êq. a marketsat economy consists of agents representing variable assignments and a set of goods specifying licenses to fail to satisfy clauses. agents choose assignments for their corresponding variables  but must acquire the necessary licenses for their chosen truth assignments. clearly  q ¡Ê q is satisfied under t iff at most |q| 1 variables in q fail to satisfy q. hence  we make available |q| 1 such licenses.1 it follows that a problem is satisfiable iff all agents can choose assignments such that they can obtain all necessary licenses to support their assignments.
¡¡observe that our notion of failing to satisfy a clause is equivalent to the notion of a nogood in csps  which in sat is just a negated clause. marketsat could be applied to more general csps by specifying the licenses to correspond to nogoods  with |q| 1 licenses available for each nogood of size
|q|.
¡¡in a marketsat protocol  the agents search for a satisfying solution in a decentralized fashion by negotiating to acquire the licenses. a market protocol consists of an auction mechanism and agent bidding policies. the negotiation for each license type is mediated by a separate auction. although the two new marketsat protocols differ in the auction rules and bidding policies  they share common high-level features. a marketsat protocol iterates through the following steps:
1. agents select tentative truth assignments and submitbids to a subset of the auctions corresponding to their chosen truth assignments.
1. auctions send price quote messages to the agents indicating the current going prices of the licenses.
the protocol continues until quiescence  a state in which no agent chooses to update any of its bids or the auctions terminate negotiation according to certain protocol-specific conditions. the auctions allocate their respective licenses to agents when quiescence is reached. for our empirical studies we assume synchronous instantaneous communication. nothing in our protocols requires synchrony  but this allows us to fix certain parameters  focusing our studies.
¡¡the present market structure is a simplification of the original marketsat economy  walsh and wellman  1  based on a supply chain formation model  walsh and wellman  1 . in the original economy  there was a separate agent for positive and negative assignments of variables. an auction for each variable mediated the negotiation of the assignment agents to provide an assignment for the respective variables. an end consumer bid to acquire an assignment to each variable. experiments show that the new protocols perform much faster with the new structure  section 1 .
¡¡in the followingsections we describe the detailsof twonew variants of marketsat.
1	uniform pricing
we describe a marketsat protocol with uniform pricing  ms-u  based on the original marketsat protocol  ms-o   but adapted to the present simplified structure. an auction allows an agent to place a bid to buy a license at a specified price. an agent may update its bid only if it increases the price of the bid by at least some publicly known increment ¦Ä. agents may not withdraw bids.
¡¡given a set of buy bids and |q| 1 units of license g available  for the right to fail to satisfy a clause q   an auction reports a price quote comprised two parts: 1  the bid price  ¦Â g   is the  |q| th highest price of all bids  and 1  the ask price  ¦Á g   is the  |q| 1 st highest price of all bids. if there are fewer than |q|  1 bids in the auction  the bid and ask prices are zero. if there are |q| 1 bids in the auction  the bid price is zero and the ask price equals the price of the lowest bid. the bid price specifies the price that the winning bidders would pay if the auction stopped in the current state and the ask price specifies how much a losing agent must bid in order to be a winning bidder. the price quote also indicates to a bidder whether its bid is one of the |q| 1 highest  winning  bids. in quiescence  an auction allocates its units of license g according to the  m+1 st price auction rules  wurman et al.  1 -the agents with the |q| 1 highest bids win g and pay ¦Â g . for the price quotes and final allocation  the auction breaks ties in favor of earlier received bids  and randomly between simultaneously received bids.
¡¡an agent randomly chooses the initial assignment for its variable and places bids at price zero for the necessary licenses. when it subsequently receives price quotes  it chooses an assignment that minimizes its assignment cost  defined for an assignment as the maximum of the sum of its current perceived costs for the licenses needed for that assignment  and the previously computed assignment cost. in the case of ties  the agent keeps its current assignment. an agent's perceived cost for license g is ¦Â g  if it is winning  ¦Á g  if it has not submitted a bid  ¦Á g  if it is both losing and ¦Á g   ¦Â g   and ¦Á g +¦Ä if it is bothlosingand ¦Á g = ¦Â g . after an agent chooses its assignment  it increments by ¦Ä any losing bid it has sent to the auction  if it needs the license
for its chosen assignment. if it hasn't submitted a bid for some needed license  it submits a bid at price zero. an agent does not update its bids if it is winning all the licenses necessary for its current assignment. observe that if the market reaches quiescence in this way  then the agents' local assignments constitute a globally satisfying assignment.
1	differential pricing
in this section we describe a marketsat protocol with differential pricing  ms-d . an auction allows an agent to place a bid to demand either either zero or one units of the license  without specifying a price. agents may switch between zero and one quantity demands without constraint.
¡¡an auction may report different price quotes to each bidder  depending on the demand for the license. an auction maintains a nondecreasing premium price for its license. if the auction has |q| 1 units of the license available  and the total demand expressed by the bids is d  then the auction reports price quotes as follows:
  if d   |q| 1  then the auction reports a price of zero to all bidders.
  if d = |q| 1  then the auction reports a price of zero to all bidders with demand of one  and reports the premium price to the single bidder with demand of zero.
  if d   |q| 1  then the auction increases the premium by one  reports the premium price to one randomly chosen bidder with a demand of one  and reports a price of zero to all other bidders with demand of one.
in quiescence  if d   |q| 1  then the auction randomly allocates the license to |q| 1 agents that bid with demand one for the license  otherwise it allocates a license to each of the current bidders with demand one. each agent that receives a license pays according the price specified in the last price quote it received.
¡¡an agent randomly chooses the initial assignment for its variable. when it subsequently receives price quotes  it chooses an assignment that minimizes the sum of the prices of licenses as reported by the last price quote  withpreference for its current assignment when the costs are equal. when an agent is in its initial state  or when it flips its assignment  it places bids of quantity one for all licenses it needs for the assignment and places bids for quantity zero for all licenses necessary for the opposite assignment. when an agent does not flip its assignment  it resubmits any bid needed for that assignment and for which it received a premium price quote. if an agent does not flip its assignment and if received a zero price quote for all its bids for the assignment  the agent does not update any of its bids. observe that if the market reaches quiescence in this way  then the agents' local assignments constitute a globally satisfying assignment. furthermore  in this case every agent pays zero for the licenses it receives.
1	economic interpretation and rational behavior
the interpretation of the market-inspired protocols in economic terms requires a model of agent values under which the assumed behavior would be plausibly rational. for an agent a to be willing to participate in these protocols  and hence be willing to pay money for their allocations  it must obtain some individual value va from participatingin a satisfying solution. an agent obtains no value if it does not participate in a initialize the weight of all nogoods to 1
until current state is solution do
if current state is not a local minimum
then make any local change that reduces the total weights of violated nogoods
else increase weights of all currently violated nogoods
end
figure 1: the breakout algorithm  morris  1 .
satisfying solution. an agent wishes to maximize its surplus value  which is the difference between the value it obtains and the total price it pays for the licenses it acquires.
¡¡in both protocols  the bidding policies are non-strategic in that agents do not account for the behavior of other agents. this assumption may be reasonable in large networks for which agents have little information about other agent preferences and behavior.
¡¡the bidding policies are myopic and best-response in that agents always bid to optimize their surplus given the current price quotes  without speculating about future price changes. the plausibility of this approach depends on how accurately the price quotes indicate the prices agents may actually have to pay for their final allocations. for both protocols  the price quotes indicate what the agents would pay if the bidding stopped in the current state.
¡¡however  the protocols differ significantly in how price quotes signal future price movements. in ms-u  the nondecreasing price quotes indicate lower bounds on the amount that agents would have to pay  providing a basis for agents' belief in the price quotes. since prices do not decrease  we would also expect that  in addition to the agent quiescence condition specified in section 1  a rational agent would stop bidding when the total cost of an assignment exceeds va.
¡¡in ms-d  agents actually pay nothing for a globally satisfying allocation  and would have positive payments only if the protocol were to terminate with an unsatisfying allocation. thus  unlike in ms-u  we would expect rational agents to stop bidding only when they reach a satisfying allocation  as specified in section 1 . but this calls into question the usefulness of the price quotes as meaningful future price indicators. the bidding policies in ms-d would be more plausibly rational if the agents had a reasonable expectation that the protocol could terminate at any time  for instance if the auctions terminated negotiations based on a random signal. indeed  such a mechanism may be useful both to encourage desirable behavior and to bound the length of negotiations.
1	price-guided search
intuitively  market prices indicate the relative global value of licenses  and agents use the prices to guide their local decisions. the bidding process can be seen as a distributed search for prices that support a satisfying allocation. in the marketsat protocols  prices are closely analogous to the weights of nogoods  which correspond exactly to failing to satisfy a clause  in the breakout algorithm  morris  1   presented in figure 1. in breakout  weights are a measure of how often the nogoods appear in local minima visited by the algorithm. the weights thus bias the search away from local minima.
¡¡in contrast to breakout  which increases the costs of nogoodsonlywhen theglobalstate is a localminimum  themarketsat protocols increase the prices of licenses in response to local state. the price of a license increases whenever the corresponding clause is not satisfied for the current assignment  which can and does occur outside of local minima of the global state.
¡¡the breakout algorithm sequentially flips variable assignments to reduce the global weight of the violated nogoods. the nogood weights are counted only for clauses that are not satisfied. in ms-u  because bids cannot be withdrawn  once a license has an excess demand  it will always have excess demand  even if the current choices of variable assignments would indicate that the clause is currently satisfied. thus the prices never decrease and agents attribute a cost to a license even if the clause is satisfied. in contrast  in ms-d an agent will only attribute a positive cost to a license if either the license is overdemanded or if flipping its own assignment would make the license overdemanded  assuming no other agent would also flip . in this sense  the cost evaluation in ms-d is closer to the breakout algorithm than in ms-u.
¡¡in breakout  current nogood costs are evaluated uniformly for all variables. in ms-u  an agent distinguishes its cost evaluation depending on whether it is winning or losing and assumes that its total cost over all licenses never decreases. this difference in perceived prices gives extra  friction  to the currently winning agents because they assume lower costs  hence are somewhat less likely to swap assignments. however  this friction is relatively small because agents increase their bids by ¦Ä only when they are losing  hence the bid and ask prices never differ by more than ¦Ä. in ms-d  agents can attribute widely varying costs to a license  with at most one agent attributing the premium cost and others attributing a zero cost.
¡¡unlike breakout  variables can flip simultaneously in the marketsat protocols. this could be beneficial to performance when agents operate in parallel  if the right flips occur simultaneously. yokoo and hirayama  observed that it could be detrimental if neighbor variables-those that share a clause-flip simultaneously  and thusincorporatedsynchronizing steps into db to prevent simultaneous neighbor flips.
¡¡of particular concern are simultaneous  satisfying neighbor flips-neighbors simultaneously flipping to satisfy a clause  e.g.  variables x and y simultaneously flipping to t to satisfy clause  x ¡Å y   which we expect to be prevalent in the marketsat protocols. when neighbor variables simultaneously flip to satisfy the same clause  other clauses may become needlessly unsatisfied. unlike db  the marketsat protocols have no explicit mechanism to prevent simultaneous neighbor flips  yet we expect the different protocols to differ in the number of simultaneous  satisfying neighbor flips. in ms-u  because the bid/ask spread on any license is small  agents that desire common licenses are likely to have similar total cost evaluations. hence  when the price of a shared license increases  they may be likely to simultaneously flip to satisfy the clause. in ms-d  because agents can attribute widely varying costs to licenses  the cost evaluations of neighbor agents are less likely to be close than in ms-u. we expect this would reduce the number of simultaneous  satisfying neighbor flips.
1	completeness
we can show that ms-u is incomplete using a close variant of the example that morris  used to show that the  centralized  breakout algorithm is incomplete. we assume synchrony  noting that this implies the same for an asynchronous system. the cnf clauses are:  x¡¥¡Åy    x¡¥¡Åz    x¡¥¡Åw    y¡¥¡Åx  
 y¡¥ ¡Å z    y¡¥ ¡Å w    z¡¥ ¡Å x    z¡¥¡Å y    z¡¥¡Å w    w¡¥ ¡Å x    w¡¥ ¡Å y  
 w¡¥ ¡Åz . observe that the only solution for the problem assigns all variables t or all variables f. consider the case when the initial random assignments are t x = t z = t and t y =t w = f. assume that the random tie breaking occurs as follows in the first round: x wins  x¡¥¡Åy   y wins  z¡¥¡Åy   z wins  z¡¥¡Åw   and w wins  x¡¥¡Åw . assume that the random tie breaking occurs as follows in the second round: y wins  y¡¥¡Åx   x wins  w¡¥ ¡Åx   z wins  y¡¥¡Åz   and w wins  z¡Åw¡¥ . in all subsequent rounds  auction tie breaking is deterministic. throughout  all agents flip simultaneously  hence the protocol oscillates indefinitely.
¡¡with the same sat instance we used to show incompleteness of ms-u  but with different initial assignments and tie breakings   our simulation results strongly suggest to us that ms-o is not guaranteed to converge to a solution. we refrain from describing a trace of a non-converging run due to the greater complexity of the agent interactions in ms-o.
¡¡we can also show that ms-d is incomplete using moris's exact example. the cnf clauses are:  x¡Åy¡Åz¡Åw    x¡¥¡Åy  
 x¡¥¡Åz    x¡¥¡Åw    y¡¥¡Åx    y¡¥¡Åz    y¡¥¡Åw    z¡¥¡Åx    z¡¥¡Åy    z¡¥¡Åw    w¡¥ ¡Åx    w¡¥ ¡Åy    w¡¥ ¡Åz . observe that the only solution assigns all variables t. consider the initial random assignment t  such that t x = t and all other variables are f. the premium increases in each of the unsatisfied clauses so long as they remain unsatisfied  but the choice of which variable in the clauses pays the premium is chosen randomly. with positive probability  x can always be the only variable chosen to pay the premium  in which case it will flip indefinitely and no other variables will flip.
¡¡if the breakout algorithm reaches truth assignment t as described in the preceding  it cannot converge to the satisfying truth assignment  morris  1 . but because ms-d has variable-specific pricing  it does not necessarily make a flip when it would be a global improvement  which can delay undesirable flips. in fact  ms-d can always converge  with positive probability  to some satisfying truth assignment t  . with positive probability  an auction for a license corresponding to an unsatisfied clause will always report the premium price to some variable x such that t. but then the protocol would clearly converge to t . we do not know if a similar result holds for ms-u.
1	experiments
we compared the marketsat protocols with ms-o and db using satisfiable  unforced  filtered  uniform random 1sat problems at the phase transition  between 1 and 1 clause/variable ratio  from the satlib benchmark library1. this is generally considered the hardest class of 1-sat problems to solve  cheeseman et al.  1; mitchell et al.  1  and has been used widely to benchmark sat algorithms. note that  to generate hard satisfiable problems  it is important togenerate problems randomly and filter the unsatisfiable instances. forcing the problems to satisfy a particular assignment makes them much easier  achlioptas et al.  1 .
¡¡to bound the computational time  for a problem instance of n variables  we ran a protocol for at most 1n rounds. for marketsat  a round is a synchronous bidding round  and for db  a round corresponds to a cycle as described by yokoo and hirayama . agents participateuntilthey reach quiescence  with a satisfying solution   or until the maximum rounds is reached. we recognize that the artificial limit on the bidding rounds reduces the plausibility that agents may use the specified bidding policies  see section 1   but chose this approach to consistently compare the performance of the protocols. we compared these protocols in terms of bidding rounds  which is the best measure of performance when agents operate in parallel. the performance is summarized in table 1. comparing the protocols from top to bottom  each subsequent protocolimproves by about a factor of twoto seven compared to the previous on all performance measures.
¡¡¡¡success average median ¦Ò n ratio rounds rounds roundsprotocol: ms-o1.1.1¡Á1.1¡Á1.1¡Á1
1
1.1
1
11
1
1protocol: ms-u.1¡Á1.1
.1¡Á1.1
.1¡Á1.1¡Á1 ¡Á1
¡Á1¡Á1.1¡Á1
1¡Á1
1
1
1
1
1.1
1
1 1 1
11
1
1
1
1protocol: ms-d1
1
¡Á1
¡Á1
¡Á1
¡Á1.1¡Á1
1¡Á1
1¡Á1.1¡Á1.1¡Á1
1¡Á11
.1¡Á1 .1¡Á1.1
.1¡Á1.1
.1¡Á1.1
.1¡Á1.1 1.1	1	1. 1.1.
1.1.
1.1.
1.1.protocol: db	1	1
	1.1¡Á1
	1.1¡Á1
¡Á1.1¡Á1
¡Á1.1¡Á1
	1.11
1¡Á1¡Á1
1¡Á1.1
1¡Á1.1
1	1	¡Á	¡Á	¡Á
table 1: performance of protocols with n variables.
¡¡we attempted to determine the causes of differing performance of the protocols. we believe that the improvement of ms-u over ms-o is due to the simplified network structure  since ms-u is otherwise essentially the same as ms-o. one plausible conjecture for the difference between ms-u  msd  and db is differing numbers of simultaneous  satisfying neighbor flips. we predict that an ordering of the protocols by increasing simultaneous  satisfying neighbor flips would be the same as by increasing performance.
¡¡to test this conjecture we measured the simultaneous  satisfying neighbor flips in both ms-d and ms-u. also  recognizing that the marketsat protocols are much like breakout  but with simultaneous flips  we modified the breakout algorithm to allow simultaneous flips  with some ad hoc parameters to control the number of simultaneous flips and simultaneous  satisfying neighbor flips . to gain insight about the effects of simultaneous  satisfying neighbor flips  we tested breakout with simultaneous flips  sfb  with varying fractions of such neighbor flips. we also varied the number of generic simultaneous flips to help distinguish their contribution to performance from neighbor flips.
	flips	neighbor
	per flip	flips
protocol	rounds	flips	round	ratioms-u	1¡Á1.1¡Á1.1.1ms-d	1	1	1	db	1	1	1sfb 1 1 1 1.1
	1	1	1
	1	1	1
	1	1	1
	1	1	1
	1	1	1table 1: comparison of simultaneous  satisfying flips for 1variable problems.
¡¡table 1 shows the average number of flips  flips per flip round  flips per round in which a flip actually occurred  and average fraction of simultaneous  satisfying neighbor flips for ms-u  ms-d  db  and sfb. as expected  ms-u performs
substantially more simultaneous  satisfying neighborflips absolutely  and as a fraction of the total flips than does ms-d. however  the results from sfb do not support the conjecture that the neighbor flips contribute significantly to the performance difference. the performance of sfb does not appear to be sensitive to  or even monotonic in  the fraction of simultaneous  satisfying neighbor flips.
¡¡table 1 suggests an alternate explanation of the performance difference between db and ms-d. for 1-variable problems  ms-d requires nearly 1 times as many rounds as db  but only 1 times as many flips. we also measured the number of rounds in which ms-d and db performed flips and found found that  in fact  the average number of rounds in which variables actually flip in ms-d is 1  only 1% of the average total rounds. the average number of rounds in which db performed a flip is 1% of its average total rounds. thus it seems that the poor performance of ms-d relative to db is due to the extra rounds to required to produce flips.
we conjecture that these extra rounds in ms-d happen because auctions randomly reassign the premium price at each round. thus the agents' costs fluctuate randomly  and do not directly progress every time the premium increases. to verify this conjecture  we tested a variation of ms-d whereby pricing is reported as the premium and a fraction b of the premium  rather than the premium or zero as in ms-d . with a positive b  an agent's costs would not fluctuate so heavily from random assignments of the premium cost. we tried b = 1 on 1-variable problems and found that it required only 1 rounds  1 flips  and 1 flip rounds. the ratio of rounds to flip rounds is only 1 with b = 1  compared to 1 for ms-d. furthermore  althoughthe variant withb = 1 outperformed ms-d  the fraction of satisfying neighbor flips was 1-significantly more than in ms-d. this evidence suggests that difference in performance between ms-d and db is largely due to the extra rounds required to produce flips in ms-d  rather than simultaneous  satisfying neighbor flips.
¡¡appealing to extra  non-flipping rounds does not seem to explain the relative performance difference between ms-u and ms-d  as the ratio of rounds to flip rounds is only 1 for ms-u  significantly less than in ms-d. an alternate explanation we propose is that the relatively poor performance of ms-u is due to the fact thatcosts continue tobe attributed toa license when its respective clause becomes satisfied  note that prices are increased only for unsatisfied clauses though . if the prices do not distinguish between satisfied and unsatisfied clauses  it would seem that ms-u pricing may not provide a effective indication of the relative difficulty of satisfying a clause. in contrast  recall that  in ms-d  when a clause is satisfied  the agents currently demanding the associated license receive price quotes of zero. breakout attributes no cost to satisfied clauses. to test whether attributing costs to satisfied clauses can be detrimental  we modified the breakout algorithm so that it does just that and found that the algorithm rarely found satisfying assignments. of course ms-u did not perform this poorly  but it does differ from breakout in other ways  as described in section 1. still  our test suggests that we have identified a significant cause of the relatively poor performance of ms-u.
1	discussion of decentralization
the marketsat protocols are highly decentralized in the sense that agents need only know about and communicate with auctions for their own licenses  which in turn requires knowledge about the clauses in which they are contained  and auctions need only communicate with the agents that participate in them. agents need not communicate with  or even know the existence of other variables. similarly  auctions need not communicate with each other. in db  an agent must know in which clauses its variable is contained and must also communicate with all variables in those clauses. marketsat can operate fully asynchronously. in db  variables synchronize with their neighbors to detect quasi-local minima and to ensure that neighbor variables do not flip simultaneously.
¡¡in their previous work  walsh and wellman  suggested that the highly decentralized nature of ms-o necessarily engenders poor performance. however  our experiments with ms-d suggest that a highly decentralized marketinspired protocol can perform reasonably well. indeed  our experiments with variants on ms-d suggest that further improvements can be obtained with the same degree of decentralization. still  it is an open question whether decentralized approaches could perform as well as the centralized sat algorithms. centralized algorithms can utilize techniques such as restarts  which contributed significantly to the success of gsat  selman et al.  1  and subsequent hill-climbing based algorithms  to help reduce heavy tails in the performance distribution. we found that restarts can also significantly improve the performance of ms-d. for example  with 1n max flips and 1max restarts  ms-d can solve all 1variable problem instances within the bound  with average rounds 1¡Á1  median 1¡Á1  and ¦Ò = 1¡Á1. although restarts could be implemented in a synchronous system with cooperating agents it is not obvious how such techniques might be utilized in a distributed  asynchronous system. moreover  we do not have any intuition for an economic interpretation of restarts.
1	conclusions
we described two market-inspired protocols for propositional satisfiability and compared them withthe distributed breakout algorithm. we found thatthe pricing method can significantly affect the performance  with the differential pricing protocol about a half magnitude better than uniform pricing. however  the differential pricing protocol is less justifiable in terms of rational economic agent behavior. although the marketsat protocols we consider perform significantly better than the original marketsat  the less decentralized distributed breakout algorithm still outperforms the differential pricing marketsat by a factor of three to four.
¡¡an informal analysis suggests that the price-guided search of marketsat works because the protocols resemble the centralized breakout algorithm. we found that the fraction of simultaneous  satisfyingneighborflips does not explain the difference in performance across protocols  but that the performance of marketsat with differential pricing suffers largely from the extra rounds needed to produce a flip.
¡¡we have identified tradeoffs in terms of runtime performance  decentralization  and the plausibility of assumed agent behaviors. understanding these tradeoffs is necessary to make informed engineering decisions about the appropriateness and applicability of alternate decentralized approaches to a particular problem environment.
¡¡the market approach has the benefit of providing a pricebased interface for an agent to evaluate and direct its behavior in the context of its broader decision making. to better understand and further develop market approaches to complex coordination problems  we must explicitly incorporate a model of the agents' economic motivations in the context of the problem to be solved. future work should also include a deeper analysis of rational agent behavior.
acknowledgments
the basic ideas for this project were developed during a visit to the university of michigan by the second author. the authors wish to thank ntt and edmund h. durfee for supporting the visit. the first author was supported by a nasa/jpl graduate student researcher fellowship.
references
 achlioptas et al.  1  dimitris achlioptas  carla gomes  henry kautz  and bart selman. generating satisfiable problem instances. in seventeenth national converence on artificial intelligence  pages 1  1.
 cheeseman et al.  1  peter cheeseman  bob kanefsky  and william m. taylor. where the really hard problems are. in twelfth international joint conference on artificial intelligence  pages 1  1.
 mitchell et al.  1  david mitchell  bart selman  and hector levesque. hard and easy distributions of sat problems. in tenth national conference on artificial intelligence  pages 1  1.
 morris  1  paul morris. the breakout method for escaping from local minima. in eleventh national conference on aritificial intelligence  pages 1  1.
 selman et al.  1  bart selman  hector levesque  and david mitchell. a new method for solvinghard satisfiability problems. in tenth national conference on artificial intelligence  pages 1  1.
 shoham and tennenholtz  to appear  yoav shoham and moshe tennenholtz. on rational computability and communication complexity. games and economic behavior  to appear.
 walsh and wellman  1  william e. walsh and michael p. wellman. a market protocol for decen-
tralized task allocation. in third international conference on multi-agent systems  pages 1  1.
 walsh and wellman  1  william e. walsh and michael p. wellman. marketsat: an extremely decentralized  but really slow  algorithm for propositional satisfiability. in seventeenth national conference on artificial intelligence  pages 1  1.
 wurman et al.  1  peter r. wurman  william e. walsh  and michael p. wellman. flexible double auctions for electronic commerce: theory and implementation. decision support systems  1-1  1.
 yokoo and hirayama  1  makoto yokoo and katsutoshi hirayama. distributed breakout algorithm for solving distributed constraint satisfaction problems. in second international conference on multi-agent systems  pages 1- 1  1.
 yokoo and hirayama  1  makoto yokoo and katsutoshi hirayama. algorithms for distributed constraint satisfaction: a review. autonomous agents and multi-agent systems  1 :1  1.
 yokoo  1  makoto yokoo. distributed constraint satisfaction: foundation of cooperation in multi-agent systems. springer  1.

multi-agent systems
multi-agent systems

achieving budget-balance with vickrey-based payment schemes in exchanges

david c. parkes
computer and information science department university of pennsylvania
1 south 1rd street  philadelphia  pa 1 dparkes unagi.cis.upenn.edu
jayant kalagnanam and marta eso
ibm t.j. watson research center p.o. box 1 
¡¡¡¡¡¡yorktown heights  ny 1 jayant us.ibm.com  martaeso us.ibm.com

abstract
generalized vickrey mechanisms have received wide attention in the literature because they are efficient and strategyproof  i.e. truthful bidding is optimal whatever the bids of other agents. however it is well-known that it is impossible for an exchange  with multiple buyers and sellers  to be efficient and budget-balanced  even putting strategy-proofness to one side. a market-maker in an efficient exchange must make more payments than it collects. we enforce budget-balance as a hard constraint  and explore payment rules to distribute surplus after an exchange clears to minimize distance to vickrey payments. different rules lead to different levels of truthrevelation and efficiency. experimental and theoretical analysis suggest a simple threshold scheme  which gives surplus to agents with payments further than a certain threshold value from their vickrey payments. the scheme appears able to exploit agent uncertainty about bids from other agents to reduce manipulation and boost allocative efficiency in comparison with other simple rules.
introduction
the participants in an exchange  or agents  can submit both bids  i.e. requests to buy items for no more than a bid price  and asks  i.e. requests to sell items for at least an ask price. exchanges allow multiple buyers to trade with multiple sellers  with aggregation across bids and asks as necessary to clear the market. an exchange might also allow agents to express logical conditions across bundles of different items; for example  an agent might want to buy   and    or sell   and   or  . following the literature on combinatorial auctions  rothkopf et al. 1; de vries & vohra 1  we call this a combinatorial exchange. applications of combinatorial exchanges have been suggested to excess steel inventory procurement  kalagnanam et al. 1  and to supply chain coordination  walsh et al. 1 .
¡¡the market maker in an exchange collects bids and asks and clears the exchange by computing:  i  a set of trades  and  ii  the payments made and received by agents. in designing a mechanism to compute trades and payments we must consider the bidding strategies of self-interested agents  i.e. rational agents that follow expected-utility maximizing strategies. we take as our primary goal that of allocative-efficiency: to compute a set of trades that maximize value. in addition  we require:

copyright c 1  american association for artificial intelligence  www.aaai.org . all rights reserved.
-individual-rationality  ir   or voluntary participation  such that all agents have positive expected utility to participate. - budget-balance  bb   such that the exchange does not run at a loss.
¡¡another useful property is incentive-compatibility  ic   which states that truthful bidding  submitting bid and ask prices equal to an agent's value  forms a bayesian-nash equilibrium. in other words  every agent can maximize its expected utility by bidding its true values  given that every other agent also bids truthfully. a stronger condition is strategy-proofness  such that truthful bidding is optimal whatever the bids of other agents. strategy-proofness is useful computationally because agents can avoid gametheoretic reasoning about other agents.
¡¡unfortunately  the well-known result of myerson & satterthwaite  1  demonstrates that no exchange can be efficient  budget-balanced  even in the average-case   and individual-rational. this impossibility result holds with or without incentive-compatibility1  and even in bayesiannash equilibrium. instead  one must:
 a  impose bb and ir  and design a fairly efficient but incentive-compatible  or perhaps strategy-proof  scheme.  b  impose bb and ir  and design a fairly efficient and fairly incentive-compatible scheme.
¡¡we follow  b   and design a mechanism for combinatorial exchanges  with multi-unit and regular exchanges as special cases  that promotesreasonable truth-revelationand reasonable allocative-efficiency. the mechanism computes the value-maximizingallocation given agent bids  and computes payments to reduce the utility for non-truthful bidding.
¡¡earlier authors  myerson & satterthwaite 1; mcafee 1; barbera & jackson 1  have followed approach  a   deliberately computing allocations that are inefficient for truthful bids from agents to achieve incentive-compatibility or strategy-proofness. we do not believe their schemes extend easily to combinatorial problems. furthermore  we believe that our scheme is particularly useful with boundedrational agents with incomplete information about other agents  because such agents are unable to fully exploit the  holes  for manipulation that remain in our designs.
a vickrey-based payment scheme
our particular approach takes the vickrey payment scheme  and adapts it to make it budget-balanced. without the problem of bb  vickrey payments support an efficient  ir  and strategy-proof exchange.
¡¡we interpret vickrey payments as an assignment of discounts to agents after the exchange clears. bb is achieved so long as the market maker distributes no more than the available surplus when the exchange clears. the pricing problem is formulated as an optimization problem  to compute discounts to minimize the distance to vickrey discounts. we derive the payment schemes that correspond to optimal solutions to a number of different distance functions.
¡¡theoretical and experimental analysis compares the utility to an agent for misstating its value in bids and asks in each payment scheme across a suite of problem instances. the results  both theoretical and experimental  make quite a compelling argument for a simple threshold payment scheme which provides discounts to agents with payments more than a threshold distance than their vickrey payments. the threshold rule increases the amount by which an agent with a large degree of manipulation freedom must adjust its bid to have a useful effect on the price it finally pays  while leaving unaffected the manipulation properties for agents with a small degree of manipulation freedom. the effect is to reduce manipulation and boost allocativeefficiency in comparison with other schemes.
¡¡let us introduce an example problem  that we will return to later in the paper.
example. suppose agents 1  1  1  1. agents 1 and 1 want to sell and respectively  with values and
¡¡¡¡¡¡¡¡¡¡. agents 1 and 1 want to buy the bundle   with values and . the efficient allocation is for agents 1 and 1 to trade with agent 1  for a net increase in value of $1.
¡¡the mechanism design problem is: given bid and ask prices for   and from the agents  what trades should take place and what payments should be made and received 
vickrey based surplus distribution
the market maker in an exchange has two problems to solve: winner determination  to determine the trades executed  and pricing  to determine agent payments. a common goal in winner-determination is to compute trades that maximize surplus  the difference between bid prices and ask prices.1these trades implement the efficient allocation with truthful bids and asks.
¡¡the pricing problem is to determine agent payments when the exchange clears. in this section we describe an application of the vickrey-clarke-groves pricing mechanism  vickrey 1; clarke 1; groves 1  to an exchange  which often fails bb. the presentation is for a combinatorial exchange  in which agents can bid and ask for bundles of items and express logical constraints  e.g.  exclusive-or  and  additive-or  constraints  across bids and asks.1computing payments in a vickrey-based exchange also requires solving a number of winner-determination problems  once without each agent that trades. winnerdetermination is np-hard for general combinatorial exchange problems and intractable as problems become large. however  our current focus is on the incentive properties of novel vickrey-based payment schemes. tractable winner-determinationis not our present concern. this noted  the payment schemes proposed are immediately applicable to tractable special cases of combinatorial exchanges  see kalagnanam et al.  future work should explore the effect of layering our schemes on top of approximate winnerdetermination algorithms.
¡¡we first define the vickrey payments in an exchange  and then argue that the failure of bb is quite pervasive with vickrey payments in exchanges.
vickrey payments
let denote the set of agents and denote the set of items. we need notation for a trade; let denote an indicator vector for a trade  such that agent buys items and sells
items	. let denote a complete trade between all agents.
	bids and asks define a reported value 	for a trade
¡¡  comprising buys and sells. bids indicate positive value for buying a bundle of items  while asks indicate negative value for selling a bundle of items. for example  if agent
1 submits bid	and ask	  then
. the values for
other trades are constructed to be consistent with value for selling anything other than item   zero value for buying
¡¡¡¡¡¡¡¡¡¡  and no additional value for buying more than bundle	.
¡¡let denote the value-maximizingtrade  given reported values    from each agent  with total surplus
         . trades must be feasible  so that supply and demand is balanced  given a model of aggregation. also  let denote surplus from the value-maximizing trade without bids  or asks  from agent .
¡¡by definition  the vickrey payment to agent is computed as:
where	is the value of trade	to all agents except agent
  i.e.	. negative payments
indicate that the agent receives money from the exchange after it clears.
we can express an agent's vickrey payment as a discount 
¡¡¡¡¡¡  from the payment    the agent would make given its bid and ask prices; i.e.   where the vickrey discount is computed as:
the vickrey discount is always non-negative  representing smaller payments by buyers and higher payments to sellers.

man et al. 1 .
economic properties. vickrey payments are ir  because by a simple feasibility argument  and also strategy-proof. the proof of strategy-proofness is omitted due to lack of space  but closely follows standard vickrey proofs  for example see varian & mackie-mason  1 . however  bb will often fail in an exchange  as we show in the next section.
vickrey budget-balance: success & failure
now that we have defined vickrey payments in a combinatorial exchange  let us outline some cases in which bb is achieved and some cases in which bb fails. we will see that budget-balance failure is quite pervasive with vickrey payments in exchanges.
standard exchange. first  consider a standard exchange with bids and asks for single units of a homogeneous item. in this case the exchange is cleared by sorting bids in order of decreasing price and asks in order of increasing price. bids are matched with asks while the bid price is greater than the ask price. it is well known that vickrey payments are not bb in this environment.
¡¡let denote the smallest successful bid and denote the largest unsuccessful bid. similarly  let denote the largest successful ask and denote the smallest unsuccessful ask. in the vickrey scheme  every winning seller receives payment   whatever its own ask price  and every winning buyer pays   whatever its own bid price. the following condition is required for bb:
claim 1. budget-balance is achieved in a simple exchange for homogeneous items and single-item bids and asks if and only if one  or more  of the following conditions hold:  1 
	;  1 	;  1 	.
proof sketch. bb holds if and only if
	  leading to cases:  1 	and
 ;  1  and ;  1  and	.
¡¡in other words  either one or more of the supply or demand curves must be  smooth  at the clearing point  with the first excluded bid at approximately the same bid price as the last accepted bid  or the winning bid and ask prices must precisely coincide. thus  we cannot expect bb with vickrey payments even in a standard  non-combinatorial  exchange except in special cases.
combinatorial exchange as an example of bb failure  consider that agents submit truthful bids in the earlier example; i.e. asks     $1       $1  and bids     $1      
$1 .	 	 
             and . agent 1's vickrey payment is -1 -  1 - 1  = -1  agent 1's is -1 -  1 - 1  = -1  agent 1's is 1 -  1 - 1  = 1. the exchange runs at a loss of $1 to the market maker.
one-sided vickrey-payments first  a positive specialcase. claim 1 gives a sufficient condition for bb in the special-case that vickrey discounts are only allocated to agents on one-side of an exchange  i.e. to all buyers or to all sellers  but not to buyers and sellers .
¡¡we define aggregation on the sell-side as when bids from multiple buyers can be combined to match an ask from a single seller  and aggregation on the buy-side as when asks from multiple sellers can be combined to match a bid from a single buyer.
claim 1. budget-balance holds if vickrey payments are implemented on one-side of an exchange  and when that side has no aggregation.
¡¡proof sketch. simple  just show that this bb holds for each  cluster  of trading agents  and therefore for the entire exchange.
¡¡bilateral matching is a special-case  with no aggregation on either side; i.e. vickrey payments are budget-balanced if implemented for at most one agent in each trade  for example with trades cleared at either the ask price  buyside strategy-proofness  or the bid price  sell-side strategyproofness . similarly  the single-item vickrey auction is a special case  and strategy-proof to buyers but not the seller . the generalized vickrey auction  gva  is the vcg mechanism for a combinatorial auction  in which there is a single seller and sell-side aggregation. the gva is bb because the buyers  but not the seller  receive vickrey payments. the auctioneer simply collects the total payment made by the buyers and passes it on to the seller. as such the gva is strategy-proof for buyers but not for the seller. another problem is that the seller can sometimes receive less than her ask price. consider a seller with an ask price of     $1  and bids of     $1  and     $1  from different buyers. each buyer receives vickrey discount $1 and pays $1  but the seller needs at least $1.
one-to-n models we can state a general negative result for vickrey payments to all agents  buyers and sellers  in a combinatorial auction.
claim 1. budget-balance fails with vickrey payments to all agents in a combinatorial auction except in the case that no buyer requires a vickrey discount.
¡¡proof sketch. simple  just show that the seller extracts all of the surplus as its vickrey discount.
¡¡intuitively  bb fails in this case unless the marginal value contributed by each buyer is zero  i.e. unless the surplus in the exchange is the same with any one of the buyers removed.
budget-balanced payment rules
in this section we take bb and ir as hard constraints and propose methods to distribute surplus when an exchange clears to minimize the distance between discounts and vickrey discounts. the choice of distance function has a distributional effect on the allocation of surplus and changes the incentive-compatibilityproperties of the exchange. in a later section we demonstrate useful truth-revelation properties for the vickrey-based schemes. we do the following:
formulate the pricing problem as a mathematical program  to minimize the distance to vickrey payments with bb and ir as hard constraints.
introduce possible distance functions and construct corresponding budget-balanced payment schemes.
present a theoretical analysis of each payment scheme in a simple bidding model.
mathematical programming model
we formulate the pricing problem as a linear program  to assign surplus to agents to minimize distance to vickrey discounts. let denote the available surplus when the exchange clears  before any discounts  and denote the set of agents that trade. each agent may perform a number of buys and sells  depending on its bids and asks of other agents. we compute discounts to minimize the distance l to vickrey discounts  for a suitable distance function l.
¡¡¡¡l	 pp  s.t.	 bb 
 vd 
 ir 
constraint  bb  gives worst-case  or ex post  budgetbalance  such that the exchange never makes a net payment to agents. we might also substitute an expected surplus

   for and implement average-case  or ex ante  budgetbalance. constraints  ir  ensure that truthful bids and asks are individual-rational for an agent  with a worst-case  or ex post  non-negative expected utility. constraints  vd  ensure that no agent receives more than its vickrey discount.1
¡¡in addition to the standard l and l distance metrics  we also consider the following functions:  a 
l   a relative error function;  b  l   a product error function;
 c  l	  a squared relative
error function;  d  l
     a weighted error function. the l metric provides no distributional information.
¡¡we drop agents with from all models  and simply set for these agents.
payment rules rather than solving problem  pp  directly  we can compute an analytic expression for the family of solutions that correspond to each distance function. each family of solutions is a parameterized payment rule. for example  the threshold rule 	for some parameter   solves  pp  for the l distance metric. for large   threshold allocates small  or no  discounts  while for threshold allocates vickrey discounts.
¡¡to understand the construction of threshold from l consider the simplest case  when constraints  vd  and  ir  are
distance function payment schemediscount definitionl   lthresholdlsmalliflfractionalllargeiflreverse-no-discount1-equaltable 1: distance functions and payment schemes.
rule	vick equal frac thresh reverselarge	smallagent 1 -1	-1	-1	-1	-1-1 or -1 -1 or -1agent 1 -1	-1	-1	-1	-1-1	-1	-1	-1agent 1	1.1	1	1	1table 1: payments with different rules in the simple problem.
not binding  and perform lagrangian optimization. dropping the outer square root from the l metric and introducing lagrange multiplier   we have
. now  computing first derivatives
w.r.t.	and setting to zero  we have
for all .1 solving  this equates the distance to vickrey dis-
counts across all agents 
  and with budget-balance we find
                     . this is the threshold rule with parameter	.
¡¡table 1 tabulates the paymentrules for each distance function  and also includes the equal rule which is not vickreybased but divides surplus equally across all agents  and the no-discount rule  see also figure 1 . each payment rule is parameterized with   except for fractional  which has parameter . the parameters that give bb in each scheme can be easily computed from vickrey discounts and available surplus.
example. in table 1 we compare the payments made with each payment scheme in our simple problem. notice that neither the large or small schemes provide useful guidance
about how to distribute the discount across the two sellers  this depends on how the tie is broken.
theoretical analysis
in this section we develop simple analytic results for the amount of manipulation an agent will perform with each payment scheme. the model permits tractable analysis  and proves interesting both for the insight it provides and for the close correspondence that we find with later experimental results for combinatorial exchange problems.
¡¡we choose to analyze an exchange in which bids and asks are for single items. later  in our experimental analysis we compare the payment schemes in combinatorial problems. for buyers  the analysis is symmetric for sellers :
 1  every agent has value for a single item  drawn from some distribution   and chooses to manipulate by

	x	v	x	v	x	v
equalreverselargex d
	x	v	 x 	x+c	 v 	 x 	x+c	 v 
smallthresh	 x 	x+c	 v 	 x 	x+c	 v 
figure 1: bid price  x-axis  against adjusted bid price  y-axis  in each payment scheme. agent value   highest outside bid   payment scheme parameters     .
	  and bid	.
 1  the maximum bid from another agent for the item  or ask price  whichever is higher   is uniformly distributed about   i.e. for some constant  .
 1  the average surplus available to the market maker when the exchange clears is per-agent  for some constant that defines the amount of surplus.
 1  in equilibrium  the market maker selects a parameter  e.g.   for the payment scheme to achieve average-case budget-balance. payment rules are computed before agents bid  and the parameters are known to bidding agents.
¡¡agent has a quasi-linear utility function    for submitting the highest bid where is its payment to the exchange  i.e. . figure 1 illustrates each payment rule in this simple model  plotting bid price against adjusted price ; e.g.  in vickrey the agent pays only for any bid   in threshold the agent pays
for	  and	for	  given parameter
  etc.
¡¡for each payment scheme we determine:  a  an agent's optimal bidding strategy as a function of the parameters of the rule  e.g. or ; and  b  the equilibrium parameterization of the rule  e.g. value for   that leads to budget-balance given that agents follow this optimal bidding strategy. the analysis leads to a relationship between the available surplus and the degree of manipulation for each payment rule  see figure 1 .
¡¡one can be critical of our assumptions. we leave undefined both the valuation distribution functions and the distribution that defines the item an individual agent values. it is quite likely that there are no that are consistent with our assumption of a uniformly distributed second-highest bid in equilibrium. in addition  we adopt average-case budget-balanceand compute paymentrules before agents bid  but ignore any effect that rules have on surplus via agents' bidding strategies.
¡¡however  we believe that this analysis has significant value. its main success is that it clearly demonstrates the effect that different types of budget-balanced vickrey-based payment rules can have on agent manipulation. we leave a full equilibrium analysis for future work.
graphical intuition. manipulation has two effects on the expected utility for an agent:  i  the probability of the adjusted bid being accepted decreases  and  ii  the total utility if the bid is accepted can go up because the agent's payment might be reduced. payment rules change  ii  but not  i   and in turn effect agents' bids and the efficiency of the exchange. in figure 1 we plot the utility for a particular bid 
¡¡¡¡  as the value of the outside bid varies  for payment schemes vickrey  no-discount  threshold and fractional. each subplot is for a single scheme  with individual curves corresponding to different bids.1

figure 1: utility of bids with     as the best outside bid varies between and . in threshold  and in fractional.
¡¡in the vickrey scheme a lower bid reduces the agent's expected utility because it decreases the probability of success without increasing the utility of a successful bid. in comparison  with no discount the agent gains utility on all successful bids by the amount of deviation from truthful bidding. in the threshold scheme a lower bid only reduces the price paid for a limited range of outside bids  closer than to the bid price   while in the fractional scheme a lower bid reduces the price paid on all successful bids  but by less than in the no discount scheme .
¡¡making our assumption about the distribution of around an agent's value   we can compute the expected utility for different levels of manipulation under each scheme as the area under a particular curve in a plot like figure 1 the expected-utility maximizing bid corresponds to the curve with maximum area. in figure 1 we plot the expectedgain in utility  in comparison with truthful bidding     for bid in each payment rule. rule parameters are set to give bb with surplus at optimal agent strate-

figure 1: expected gain in utility for different bids
under each payment scheme  with rule parameters set to give bb with surplus .
gies. notice that the level of manipulation    that maximizes the agent's gain in utility is smallest in the threshold scheme for this value of surplus.
¡¡the results  below  show that the large and threshold rules perform well in this model  and lead to the following intuitive remarks about payment rules  see figure 1 :
1. a large flat section for bids close to the agent's true valueis useful  i.e. with adjusted bid price independent of the agent's bid price.
1. nowhere should the adjusted bid price be greater than theagent's bid price  for ir with truthful bidding   which constrains the line to lie to the right of the  no-discount  line.
1. it is more important to implement the flat section for values    far from the highest outside bid    than values close to the highest outside bid  i.e. large rather than small   because manipulation is already more risky for true values
close to	than far from	.1
¡¡it is useful to think about the  degree of manipulation freedom  available to an agent  which in this simple singlebundle model is the difference between an agent's value and the highest outside bid . in general  this is simply measured by the vickrey discount to an agent that bids truthfully  i.e. the amount by which it could have reduced its bid price and still participated in the same trades. the large and threshold schemes are effective because they make manipulation more difficult and less useful for an agent with a large degree of manipulation freedom  while leaving the ability to manipulate of agents with a small degree of manipulation freedom unchanged. this is a good incentive strategy because it attacks the  low risk  manipulation opportunities  but leaves the  high risk  opportunities. agents are uncertain about the bids from other agents and always run the risk of bidding too low and forfeiting a profitable trade.
results. table 1 summarizes the analytical results  giving an agent's optimal bidding strategy    as a function of the parameter in each scheme  and the expected discount per-
ruleoptimal manipulation expected discountno-discount	1
vickrey
fractional		
threshold	
	equal		
small

	large	1  if	  if
	  otherwise	  otherwise
	reverse	

table 1: analytical results.

	figure 1: optimal agent manipulation 	   as a proportion of
   under each payment scheme as the amount of available surplus increases from 1 to per-agent.
agent given that optimal strategy.1 we present an example derivation  for the threshold rule  below.
¡¡in figure 1 we enforce bb  computing parameters in the payment schemes to set the expected discount equal to surplus   and plot the equilibrium manipulation performed in each payment scheme as the amount of surplus varies. the
vickrey payment scheme can be implemented with surplus per-agent  so all schemes except equal and no-discount prevent manipulation completely for . for smaller amounts of surplus the market maker is forced to deviate from vickrey  and move left in figure 1. at no schemes can provide any discount  and the agent manipulates by .
¡¡first  notice that the simple minded equal scheme appears to have bad incentive properties. in fact  the threshold method dominates all other schemes in this model except large. large has an interesting bad-good phase transition at   and can prevent manipulation completely for even though agents with small vickrey discounts might have benefited from manipulation with hindsight. agent uncertainty coupled with the risk of bidding too low and either falling from the flat section or under-bidding the highest outside bid lead agents to bid truthfully.
example derivation: threshold rule.	each agent receives discount	  for some constant
     . the agent's utility given bid   value   highest outside bid   and threshold   is computed as:
if if
otherwise
¡¡assume that   so that the agent will receive a discount for some choice of . consider three cases.
case  1  	. the expected utility for bid	given	  is:

in case  1  	 
¡¡¡¡¡¡¡¡¡¡. in case  1     then .  from this  the agent's optimal bidding strategy  denoted   by differentiation w.r.t. and case analysis  is:
the discount to the agent for bid	is:
. the expected dis-
count  first in the case that	  is:

or in the case . substituting for the agent's optimal bidding strategy we have:
 . now  with per-agent
surplus	and budget-balance  such that	 

the exchange should set to minimize manipulation.
experimental analysis
in this section we provide an experimental analysis of the payment schemes in a set of combinatorial problem instances. agents are either buyers or sellers  and values are assigned to agents for bundles following the random  weighted random  decay  and uniform distributions from sandholm  1   adapted in this case to a combinatorial exchange. each agent submits bids  asks  for multiple bundles  with exclusive-or constraints across bids  asks . we test problems with 1  1  and 1 agents  a total of 1 bids and asks  evenly distributed across agents   1 goods  and with different proportions of buyers and sellers.1

figure 1: average single-agent gain in utility from manipulation by %  vs. truthful bidding   in a system in which every other agent manipulates by %. problem size: 1 buyers/1 sellers.
¡¡in our theoretical model we adopted average-case budgetbalance to make the analysis tractable. we now revert to the more natural worst-case  or every-time  budget-balance in which the market maker distributes exactly the available surplus every time the exchange is cleared. payment rules are now computed after bids are received.
¡¡we perform a limited strategic analysis. first  we assume that the strategy of agent is to adjust all its bids and asks by the same fractional amount  %  i.e. submitting bid prices % below value and ask prices % above value. second  we look for a symmetric nash equilibrium in which every agent follows the same strategy  for some %. finally  we compute an approximation to this equilibrium for computational tractability. we compute the average utility gain to a single agent for 1% vs. % manipulation  given that every other agent manipulates by %  and determine the amount of manipulation    that maximizes this utility gain. we assume that this is also the optimal strategy for an individual agent against a population of agents with fixed strategies   and therefore the nash equilibrium.1
¡¡given this  we read off the symmetric nash equilibrium under a particular payment rule as the peak of a plot such as that in figure 1  which plots the gain in utility for strategy % vs. 1% in a system in which every agent follows strategy %  in this case for the 1 buyers/1 sellers problem set. in this case  notice that the equilibrium manipulation level in large and threshold is less than under the other rules  in this case around 1% and 1% in large and threshold  compared with 1%  1% and 1% in fractional  equal and no-discount. in addition  the amount of utility gain in large and threshold is much less than in the other schemes.
¡¡in table 1 we summarize the results of experiments across all problem sets. we compare: the average utility gain  and the correlation with vickrey discounts  at manipulation levels of 1%  1% and 1% in each scheme; and the average optimal degree of manipulation by agents in each scheme 
no-discountvickreysmallfracutility gain1-111correlation1111manipulation 11efficiency  % 11thresholdequallargereverseutility gain1111correlation1111manipulation 11efficiency  % 11table 1: experimental results. utility gain and correlation with vickrey discounts computed for manip. 1%  1% and 1%  and averaged over all problem instances  for 1 agents .
and the corresponding allocative efficiency. the allocative efficiency in the large and threshold schemes is considerably higher than in the other schemes.
discussion
the partial ordering large  threshold fractional reverse equal  small from the experimental results is remarkably consistent with the results of our theoretical analysis. although the large scheme generates slightly less manipulation and higher allocative efficiency than threshold  the correlation between discounts and vickrey discounts is much greater in threshold than large. an agent's discount in large is very sensitive to its bid  and we expect large to be less robust than threshold in practice because of this all-or-nothing characteristic.
¡¡as discussed earlier  we have made a number of assumptions  both in the analytic models of agent manipulation and also in the manipulation structure considered experimentally. in addition to understanding the effects of these assumptions  in future work we would also like to: quantify worst-case and average-case utility gains from manipulation in each payment scheme  given a particular amount of surplus; and derive optimal payment schemes  for example minimizing worst-case gains from manipulation. one avenue is to ask how bad would the efficiency get if every agent was perfectly informed about the other agents  and followed a best-possible bidding strategy given the payment rules. finally  we suspect that stochastic payment rules might prove to have interesting incentive properties.
conclusions
we constructed budget-balanced payment schemes to minimize different distance functions to vickrey payments  and showed analytically and experimentally that a simple threshold rule has better incentive propertiesthan other payment schemes. the effect of the payment scheme is to implement a distribution of manipulation-preventing discounts across a population of agents to exploit an agent's inherent uncertainty about bids from other agents and the degree to which manipulation can be useful. the threshold rule increases the amount by which an agent with a large degree of manipulation freedom must adjust its bid to have a useful effect on the price it finally pays  while leaving unaffected the manipulation properties for agents with a small degree of manipulation freedom.
¡¡finally  we note that the schemes outlined here can also allow a market maker to make a small profit by taking a sliver of budget-balance  or used in combination with a participation charge to move payments closer to vickrey payments.
acknowledgments
we thank william walsh  and the anonymous reviewers  for their helpful comments and suggestions. this research was funded in part by national science foundation grant sbr 1. the first author gratefully acknowledges financial support from an ibm research fellowship.
references
barbera  s.  and jackson  m. o. 1. strategy-proof exchange. econometrica 1 :1.
clarke  e. h. 1. multipart pricing of public goods. public choice 1-1.
de vries  s.  and vohra  r. 1. combinatorial auctions: a brief survey. tech. report  meds department  kellogg graduate school of management  northwestern
university.
groves  t.	1.	incentives in teams.	econometrica 1-1.
kalagnanam  j. r.; davenport  a. j.; and lee  h. s. 1. computational aspects of clearing continous double auctions with assignment constraints and indivisible demand. ibm research report rc 1  1 . to appear in electronic commerce research journal.
mcafee  r. p. 1. a dominant strategy double auction. j. of economic theory 1-1.
myerson  r. b.  and satterthwaite  m. a. 1. efficient mechanisms for bilateral trading. journal of economic theory 1-1.
rothkopf  m. h.; pekec¡¦  a.; and harstad  r. m. 1. computationally manageable combinatorial auctions. management science 1 :1.
sandholm  t. 1. an algorithm for optimal winner determination in combinatorial auctions. in proc. 1th international joint conference on artificial intelligence  ijcai1   1.
varian  h.  and mackie-mason  j. k. 1. generalized vickrey auctions. tech. report  university of michigan.
vickrey  w. 1. counterspeculation  auctions  and competitive sealed tenders. journal of finance 1-1.
walsh  w.; wellman  m.; and ygge  f. 1. combinatorial auctions for supply chain formation. in proc. acm conference on electronic commerce  1.
wurman  p. r.; walsh  w. e.; and wellman  m. p. 1. flexible double auctions for electronic commerce: theory and implementation. decision support systems 1-1.
agent-human interactions in the continuous double auction
rajarshi das  james e. hanson  jeffrey o. kephart and gerald tesauro
institute for advanced commerce
ibm t.j. watson research center
saw mill river road  hawthorne  ny 1  usaabstract
the continuous double auction  cda  is the dominant market institution for real-world trading of equities  commodities  derivatives  etc. we describe a series of laboratory experiments that  for the first time  allow human subjects to interact with software bidding agents in a cda. our bidding agents use strategies based on extensions of the gjerstad-dickhaut and zero-intelligence-plus algorithms. we find that agents consistently obtain significantly larger gains from trade than their human counterparts. this was unexpected because both humans and agents have approached theoretically perfect efficiency in prior all-human or allagent cda experiments. another unexpected finding is persistent far-from-equilibrium trading  in sharp contrast to the robust convergence observed in previous all-human or all-agent experiments. we consider possible explanations for our empirical findings  and speculate on the implications for future agent-human interactions in electronic markets.
1	introduction
we envision a future in which economically intelligent and economicallymotivatedsoftware agents will play an essential role in electronic commerce. among the present-day glimmerings of such a future are simple bidding agents offered by auction sites such as ebay and amazon and by third-party bidding services such as esnipe1  pricebots such as buy.com that automatically undercut the competition  and shopbots such as dealtime that minimize the total cost of a bundle of goods by partitioning it across one or more vendors  taking shipping cost schedules into account. it is natural to expect continued growth in the variety and sophistication of automated economic decision-making technologies such as these. in addition  we anticipate the emergenceof an even larger and more diverse class of agents for which economic decisionmaking capabilities are still essential  but ancillary to the primary function of providing information goods and services to humans or other agents  kephart et al.  1 .  throughout this paper we use the term  agent  to refer exclusively to a software agent  as opposed to a human economic agent.  whether their main business is ontology translation  matchmaking  network service provision  or anything else  these agents will charge a fee for their goods or services  and will negotiateboth as buyersand as sellers with other agents. thus they will have to be economically intelligent  capable of making effective decisions about pricing  purchasing  or bidding.
¡¡if this vision is to be realized  then it must be demonstrated that  within their domain of application  agents can attain a level of economic performance that rivals or exceeds that of humans on average  without introducing undue risk. otherwise  people would not entrust agents with making economic decisions.
¡¡the purpose of this paper is to provide such a demonstration. through a series of controlled laboratory experiments in which humans and agents participate simultaneously in a realistic auction  a continuous double auction  or cda   we show that software agents can consistently obtain greater gains from trade than their human counterparts. in a sense  this work can be viewed as another chapter in the venerable ai tradition of human vs. machine challenges. already  machine supremacy has been demonstrated in twoplayer games such as backgammon  checkers  and chess  and a serious attack is now being made on games such as bridge and poker  schaeffer  1   in which there are slightly more than two players who play in a well-defined sequence. in contrast  the number of players in the cda is typically much greater  we limit it to 1 in this report  and the moves by individual players are completely independentand asynchronous. these and other features make game-theoretic analysis of the cda intractable. another notable difference is that the successful demonstration of machine superiority in the cda and other common auctions could have a much more direct and powerful financial impact-one that might be measured in billions of dollars annually.
¡¡this paper is organized as follows. section 1 defines the cda and discusses the relationship of our work to previous studies by economists and computer scientists. section 1 provides a brief overviewof the technologicalinfrastructureused in the experiments. section 1 describes the agent environment and the individual agent strategies. section 1 provides details of the market rules and experimental parameters  and section 1 presents the results for two different agent strategies. we conclude with a brief summary and discussion of implications and future directions in section 1.
1	background on the cda
our laboratory study of economic interactions between agents and humans utilizes a simplified model of a continuous double auction  cda  market. the cda is one of the most common exchange institutions  and is in fact the primary institution for trading of equities  commodities and derivatives in markets such as nasdaq and the nyse. in the cda  there is a fixed-duration trading period  and buy orders   bids   and sell orders   asks   may be submitted at any point during the period. if at any time there are open bids and asks that are compatible in terms of price and quantity of good  a trade is executed immediately. typically  an announcementis broadcast immediately to all participants when orders are placed or trades are executed.
¡¡in our model cda  multiple units of a single hypothetical commodity can be bought or sold. participants are assigned a fixed role of either buyer  only submits bids  or seller  only submits asks . there are several periods of trading; at the start of each period  participants are given a list of  limit prices   values for buyers and costs for sellers  for each unit to be bought or sold. the limit prices are held constant for several periods and periodically shifted by random amounts to test responsiveness to changing market conditions. each participant's objective is to maximize  surplus   defined as  limit price - trade price  for buyers and  trade price - limit price  for sellers.
¡¡the assumptions of fixed roles and fixed limit prices conform to extensive prior studies of the cda  including experiments involving human subjects  smith  1; 1  and automated bidding agents  cliff and bruten  1; gjerstad and dickhaut  1 . under such assumptions  a market consisting of rational players will eventually converge to steady trading at an equilibrium price   at which there is a balance between supply  the total number of units that can be sold for positive surplus  and demand  the total that can be bought for positive surplus . for each participant  one can define a theoretical surplus as the total surplus that would be obtained if all units traded at . one can also define a participant's efficiency as the ratio of actual surplus to theoretical surplus. in human subject studies  smith  1; 1   convergence close to equilibrium was found within several periods  with the approach towards exhibiting a  scalloped  shape  i.e.  a decelerating curved trajectory  of progressively smaller amplitude in each successive period. robust convergence to equilibrium was also found in homogeneous populations of agents  cliff and bruten  1; gjerstad and dickhaut  1   with smaller-amplitude scallops than in the all-human experiments. both all-human and all-agent cda studies claimed very high population efficiency  ranging between 1 and 1.
¡¡our work differs from prior cda studies in two significant ways. first  we are interested in studying and understanding interactions between agent and human bidding strategies. second  we focus primarily on measuring and understanding the performance of individual agents  instead of global measures of aggregate market behavior. as agent designers  we would like to understand the principles by which robust bidding strategies can be designed that perform well against both human and computerized opposition. our focus on competition in heterogeneous bidder populations is similar to that of the agent vs. agent competition held at the santa fe double auction tournament  sfdat   rust et al.  1 . the sfdat was an intrinsically discrete-time auction  with nonpersistent orders  synchronized bidding of all agents at every time step  and a coarse time step size deliberately chosen to allow all agents enough time to calculate and place their bids. thus the conclusions may not apply to trading in normal real-time cda markets. another market-based tournament for bidding agents  the trading agent competition  tac   wellman et al.  1  was held in conjunction with icmas-1. this competition was much more realistic in design  and required the agents to simultaneously participate in multiple markets  each of which required a different bidding strategy. our study incorporates a degree of realism in market dynamics and messaging/communication similar to that of tac  while preserving a classical cda design. this allows both agents and humans to participate  as well as facilitating comparisons with prior all-human and all-agent cda studies.
1	overview of the experiments
for our experiments with humans and agents  we developed a hybrid system that combined gem  a special-purpose distributed system for experimental economics developed by members of the ibm watson experimental economics laboratory  weel   with magenta  a prototype agent environment developed at ibm research. the hybrid configuration is illustrated in figure 1.
¡¡a real-time  asynchronous cda was administered by a gem auctioneer process running on a windows nt workstation  which communicated with all bidders and executed trades when appropriate. to ensure that agents and humans could interact seamlessly with one another  and that there would be no subtle bias in their treatment  humans and agents used the same set of messages to communicate with the gem auctioneer. each human bidder was given a windows nt workstation running a gem client process that interpreted messages from the gem auctioneer  and encoded messages to be sent back to it. this gem client offered a gui that permitted its user to view the order queue  the trade history  and his/her assigned parameters. it also permitted the user to enter bids or asks. each magenta bidder agent participated in the auction through a modified version of the gem client that forwarded messages via tcp/ip to a unix workstation running the magenta environment and the agents themselves. each agent received messages forwarded to it by its modified gem client. whenever it wished  the agent could send messages to its gem client  which forwarded them as quickly as possible to the gem auctioneer. thus the magenta agents and the human bidders had access to identical streams of data from the auctioneer  and the auctioneer could not distinguish orders placed by humans from those placed by agents.

figure 1: hybrid gem-magenta configuration. at the left is the gem system  showing a gem auctioneer communicating with a set of gem clients. each gem client either presents a gui to a human trader or communicates via tcp/ip with one of the magenta bidding agents shown at right. also at right is an expanded view of an agent's architecture  showing the three internal modules described in the text and sketching the control flow within the brain module.1	agents for the cda
1	agent environment and architecture
the bidder agents were implemented on top of magenta  which provides messaging  naming  and directory services  and supports both one-shot messaging and conversations  correlated sequences of messages . each bidder agent contained a messagehandler module  a bookkeeper module  and a brain module  all of which were specifically tailored for the cda.
¡¡the messagehandler was responsible for formatting and sending outgoing messages  and for receiving and parsing incoming messages. incoming messages included initialization information  notifications of bids and asks placed by other agents  of trades  and of time remaining in an auction period. upon receipt of a message  the messagehandler would parse it and take an appropriate action  such as handing the record of the bid  ask  or trade to the bookkeeper module.
¡¡the bookkeeper maintained the agent's internal representation of the market state  e.g.  the history of orders and trades  currentopen orders  time remainingin the period  etc.  and of the agent's internal state  e.g.  orders the agent had placed  the agent's inventory and available funds  etc. .
¡¡the brain module was responsible for placing bids and asks. each brain placed orders on its own thread of execution  with its own activation schedule. each brain contained a modulefor a biddingstrategy that determinedorderparameters based on the information stored in the bookkeeper  and a timing module that governed the circumstances under which the brain's execution thread would wake up  apply the bidding strategy and  possibly  place an order. outgoing order messages were formatted and sent back to the gem client by the messagehandler. optionally  the timing module would awaken the brain's execution thread whenever a trade occurred and/or when a particularly attractive bid or ask was placed by another player.
1	agent strategies
the magenta bidding agents face the following task in a live auction: given the time remaining in the trading period  a number of tradeable units  a vector of limit prices  one for each unit   and the history of previous activity in the market  calculate an order time and a price .
¡¡the timing of orders was governed by a simple heuristic based on a sleep-wake cycle. the sleep time was set to a fixed interval of seconds  with small random jitter added. in our experiments   fast  agents were defined by setting and by permitting wakeup on all orders and trades.  slow  agents were defined by setting and allowing wakeups only on trades. when an agent wakes up  it computes an order price using its pricing algorithm. the agent will then submit the order  provided that the computed price is compatible with the market rules and its understanding of the current market conditions. if the agent currently has an open order  the order will be a replacement order; otherwise it will be a new one.
¡¡the pricing algorithms employed in these experiments are based on algorithms originally introduced for simpler versions of the cda that lacked a persistent order queue  and made assumptions about market dynamics that are inconsistent with the notion of real-time  independentagents. we now describe modifications that we made to these algorithms to tailor them to our version of the cda.
zero-intelligence-plus  zip  strategy
cliff  cliff and bruten  1  proposed an algorithm called  zero-intelligence-plus   zip  to explore the minimum degree of agent intelligence required to reach market equilibrium in a simple version of the cda. the market dynamics
studied in  cliff and bruten  1  were unrealistic in that there was no explicit notion of time  no definite period length  and no persistent orders: submitted orders were either traded or removed instantaneously. we have modified zip to function in a real-time market with a definite period length and persistent open orders. the primary modification has to do with outbidding or undercutting existing orders. this now happens when orders remain open for a certain amount of real time without being traded. our modifications turn out to be related to those independently proposed by preist & van tol  preist and van tol  1 .
¡¡in our zip implementation  each agent maintains a vector of internal price variables ; the -th component of     is used to set the order price when trading the -th unit. at the start of trading  is initialized to random positive-surplus values  and is adjusted during the period according to the observed trading action.
¡¡when a trade occurs at trade price   each is adjusted by a small random increment in the direction of . if the adjustment is in the direction of increasing profit margin  i.e. raising for sellers and lowering for buyers   the change is always made regardless of whether or not the -th unit has already been traded. however  for adjustments in the direction of decreasing profit margin  the change is made only for units that are  active   i.e.  have not yet been traded. the size of the adjustment is proportional to a learning rate parameter  similar to that used in widrow-hoff or in back-propagation learning. the difference between and is also stored for use at the next trade  when a further adjustment in the same direction is made  proportionalto a separate  momentum parameter. this is analogous to the use of momentum to speed up convergence in back-propagation learning.
¡¡if a sufficiently long time has passed without a trade taking place  1 seconds in our implementation   zip buyers and sellers adjust in the direction of improving upon the best open competing bid or ask  if the -th unit is still active. finally  there is a global constraint that each must always correspond to non-negative agent surplus  i.e. it must always be below the buyer's value  or above the seller's cost.
¡¡in all-agent tests  we find that homogeneous populations of zip traders achieve robust convergenceto theoretical equilibria with high efficiency. depending on the precise market rules and initial conditions  efficiencies ranging from 1 to 1 have been obtained with this strategy.
gjerstad-dickhaut  gd  strategy
gjerstad and dickhaut  gjerstad and dickhaut  1  introduced a more sophisticated trading algorithm for buyers and sellers in the cda  which we shall term  gd . they showed via simulation that a homogeneous population of such agents could attain high allocative efficiency and rapid convergence to the theoretical equilibrium price. a gd agent constructs an order and trade history   consisting of all orders and trades occurring since the earliest order contributing to the th most recent trade. from the history   a gd buyer or seller forms a subjective  belief  function that represents its estimated probability for a bid or ask at price to be accepted. for example  for a seller 
		 1 
where is the number of accepted asks in with price   is the number of bids in   and is the number of unaccepted asks in with price
¡¡¡¡. interpolation is used to provide values for for prices at which no orders or trades are registered in . the gd agent then chooses a price that maximizes its expected surplus  definedas the productof and the gainfrom trade at that price  equal to for sellers and for buyers  where is the seller cost or buyer value . thus the algorithm does not require the knowledge or estimation of other agents' costs or valuations.
¡¡the original gd algorithm was developed for a market in which there was no queue  i.e. old bids or asks were erased as soon as there was a more favorable bid/ask or a trade. in our version of the cda  unmatched orders can be retained in a queue  and therefore the notion of an unaccepted bid or ask becomes ill-defined. we addressed this problem by introducing into the gd algorithm a  grace period  . unmatched orders were not included in unless at least the grace period had passed since that order had been placed. another modification to gd addressed the need to handle a vector of limit prices  since the original algorithm assumed a single tradeable unit.
¡¡we also found empirically that the original gd algorithm could behave pathologically  particularly for  fast  agents  which placed orders whenever an order or trade had been placed in the market. this often resulted in rapid bursts of orders and trades. if the last orders resulted in successful trades  then there were no unsuccessful orders in the history . laboringunder the false assumption that any price would be accepted  the agents would then place absurdly low bids or high asks  gradually lowering them until trades finally began to occur once again  often in another burst. this cyclical behavior was associated with high trade price volatility.
¡¡to greatly reduce the chances of this occurring  we used a softer form of history truncation. all of the simple tally terms in eq. 1  and the analogous expression for buyers  were replaced by weighted sums that placed exponentially more emphasis on events that occurred most recently  and the truncation parameter was increased to a much larger value. as hoped  soft truncation led to more sensible and stable pricing. it allowed the desired responsiveness to recent events  but also permitted information from old events to be used whenever there was insufficient information from recent events.
¡¡homogeneous populations of modified gd agents also achieve robust convergence to equilibrium  with efficiencies comparable to those obtained by zip agents.
1	experimental setup
our experiments used the following cda market rules:
1. the  nyse  spread-improvementrule was in effect  requiring that new bids be priced higher than the current best bid  and the equivalent for asks . this conforms to prior cda studies and is believed to facilitate convergence to equilibrium.
1. all orders were for a single unit only  and a player couldhave at most one open order. this was meant to simplify the task for both agents and humans  and again conforms to prior cda studies.
1. submitted orders remained open until they were tradedor the period ended.
1. submitted orders could be modified  subject to thenyse rule   but not withdrawn.
1. trades occurred when the best bid and best ask matchedor crossed in price. if they crossed  i.e.  bid price exceeded the ask price   the trade price was the price of the order submitted first.
1. at the start of each period  players were given a freshsupply of cash or commodity.
¡¡each player was given a list of 1 limit prices for the units to be traded  arranged in order from most to least valuable  i.e.  the buyer values decreased and the seller costs increased . roughlyhalf of the players' units were tradeablefor positive surplus at equilibrium. the limit prices were generated from a base set of three linear schedules in which each successive unit increased in cost or decreased in value at a constant rate. these rates varied in the three schedules; however  the total theoretical surplus was designed to be about the same in each. each human had an agent counterpart with the same role and the same limit prices  and hence the same theoretical surplus. the total theoretical surplus was designed to split about evenly between buyers and sellers.
¡¡an experimentconsisted of 1 tradingperiods of 1 minutes each. every 1 periods  each player's limit prices were changedby rotatingthe three limit price schedules  e.g.  seller a received seller b's previous schedule  b received c's  and c received a's  and adding or subtracting a constant value to all limit prices  so as to change the equilibrium price.
¡¡our target configuration for the experiments consisted of 1 agents and 1 humans1  both split evenly between buyers and sellers. in each experiment  all agents used the same bidding strategy-either zip or gd-and were all either the  fast  or  slow  variant. human subjects in four experiments were undergraduates from local colleges; in two others  they were employees of ibm research. before the start of each experiment  subjects received instruction on the auction rules and the profit objective  and practiced using the gui. no discussion of bidding strategies was given. subjects were told they would receive cash payments proportionate to profits earned in the auction; the conversion factor was set so that the expected payouts were per player.
1	experimental results
table 1 summarizes the results of the six agent-human cda experiments. several noteworthy findings were obtained. first  there were significant interactions and trades between agents and humans  even though the agents were potentially much faster. roughly 1% or more of all trades were between agents and humans. this is a reasonable fraction of the naive expectation of 1% if any trade partner  agent or human  is equally likely  and shows that the laboratory markets did genuinely test agent-human interactivity  as opposed to merely creating two non-interacting sub-markets operating on different time scales.
¡¡second  when considered as a group  the agents outperformed the humans in all six experiments: the total surplus obtained by agents was on average more than the total human surplus. this was true for both fast and slow agent populations  showing that speed was not the sole factor accounting for the agents' edge in performance. in terms of average efficiency  agents in aggregate tended to achieve greater than 1% efficiency  which necessarily implies that they were exploiting human errors or weaknesses. humans  on the other hand  tended to score in the range of   and on two occasions they did much worse. to check our market design  we ran a baseline experiment in which all 1 traders were human  measuring an efficiency of 1  which is consistent with what is typically found in all-human cda experiments. the fact that humans play better against other humans than they do against agents corroborates the evidence that  as a group  the agents are stronger players.
¡¡third  as in prior all-human cdas  human performance tended to improve during the course of an experiment  as the subjects became more familiar with the gui and the market behavior  and got a better idea of how to execute a good bidding strategy. nevertheless  we still found a consistent edge in agent surplus over human surplus by about in the final periods of each experiment.
¡¡finally  althoughit is not documentedin table 1  our agenthuman markets tended to have a lopsided character in which either buyers consistently exploited sellers  or vice versa. the previously-described scalloping behavior was observed to be more pronounced and longer-lasting than in prior all-human or all-agentcdas. this will be discussed in detail in sections 1 and 1  which examine two specific experiments with different agent bidding strategies  fast gd and slow zip   yielding distinctly different market dynamics.
1	fast gd agents vs. humans
 1 gd fast agent-1 human cda exp. oct. 1: periods 1

time  seconds 
figure 1: trade price vs. time for experiment oct1 with 1 gd fast agents and 1 humans. the vertical dashed lines indicate the start of a new trading period. the 1 trading periods were divided into four phases  each with its own set of limit prices. in each phase  is shown by the horizontal dashed lines. trades between two agents are shown with open circles  between two humans with open squares  and between an agent and a human with solid circles. the labels ab  as  hb  and hs refer to the average efficiency of agent buyers  agent sellers  human buyers  and human sellers  respectively.figure 1 shows the trading activity in experiment oct1  which was conducted over 1 periods divided equally among four phases with shifts in limit prices. in each period  the time series of trades tends to show scalloping  as trade prices converge towards the equilibrium price . such scalloping was not observed in agent-only cda experiments with gd fast  or slow  agents. in this experiment  the buyers were able to extract more surplus from the market than the sellers as most trades occurred below   a fact that is also reflected in the average efficiency measures. however  the differences in surpluses  and efficiencies  between the two sides of the market shrank over time  due to improving overall market efficiency  which we attribute to human improvement during the course of the experiment. note that in all four phases  the agent buyers and the agent sellers are able to extract more surplus than their human counterparts.
¡¡figure 1 also shows that most of the lowest-priced trades  occurring well below   were between agents and humans. an inspection of experimental records reveals that these trades were mostly between human sellers and agent buyers. apparently the human sellers were consistently offering excessively low asks  and the agent buyers were able to pounce on such mistakes more quicklythan their humancounterparts.
1	slow zip agents vs. humans
figure 1 shows the trading activity in the third phase of experiment oct1a with 1 zip slow agents and 1 humans. the figure shows several interesting features. first  pronounced and repeated scalloping in trade prices is evident  with buyers extracting much more surplus than sellers. this is surprising since such large scalloping is not seen in markets with only zip agents. second  in each period  trades typically tended to occur first between agents  then between agents and humans  and finally between humans. third  although the agents as a group outperformed the humans  agent sellers actually obtained less surplus than human sellers.
¡¡subsequent interviews with human subjects helped to explain the behaviorand ultimately reveal a weakness in the zip strategy. it turned out that two of the human sellers in this experiment consistently followed a 'fixed-profit-ratio' strategy  that is  their asking price for each unit was a fixed percentage greater than its cost. these sellers repeatedly submitted asks at prices much lower than and most often  agent buyers quickly accepted such offers. having traded their units at extremely low prices  the zip buyers ignored subsequent trades at higher prices  and maintained very low bid prices at the start of the next period. the resulting bid-ask spread at the start of each period was centered well below   and once the human sellers made a few low-priced sales  the zip sellers  which were waking up on trades  began quickly dumping their inventory at very low prices. hence we attribute the unusual market behavior  and the performance ranking of the agent and human traders  to a set of odd interactions between the zip strategy and a specific non-optimal human strategy.
experimentagenthumanid# periods# tradesinteractionstrategysurplusefficiency# traderssurplusefficiencyoct11.1gd fast1.11.1oct11.1zip fast1.11.1oct11.1gd fast1.11.1oct1a11zip slow1.11.1oct1b11gd fast1.11.1oct11.1gd fast1.11.1
table 1: summary of the six agent-human cda experiments. for each experiment  the table presents: the number of trading periods  the total number of successful trades  the fraction of trades between agents and humans  the bidding strategy employed by all six agents  the number of human traders  and the aggregate agent and human performances in terms of total surplus accumulated over the entire experiment and the average efficiency.¡¡to test our hypothesis  we performed separate all-agent experiments with a fixed-profit-ratio agent in a population of only zip agents. the resulting dynamics exhibited large scallops in trade prices similar to those in figure 1. we also  1 zip slow agent-1 human cda exp. oct1a: periods 1

figure 1: trade price vs time for experiment oct1a with 1 zip slow agents and 1 humans. trading activity in periods 1  out of 1 total  is shown. other details are similar to those in figure 1.
implemented a modification to the zip strategy that is more reluctant to lower its profit margin based on where trades occurred in the last period. preliminary results show that the modified zip agents retain high efficiency and are not easily misled by the fixed-profit-ratio agent.
1	conclusion
given the simplicity of our agent bidding strategies  we are encouraged by the results of these first-ever tests against human subjects.  we remark that  while substantial agenthuman interactions have already occurred in financial markets  such interactions have an unknown and uncontrolled nature.  our agents make relatively simple time-independent price calculations  based on established algorithms  and their timing decisions are equally simple  yet they are able to outperform non-expert human subjects by a clear margin. it would be interesting to test our bidding agents against a higher caliber of human opposition  e.g.  professional equities or commodities traders. we suspect that such opponents would uncover weaknesses in the agent strategies  and that this would eventually lead to significant algorithmic improvements in the strategies. we are optimistic that cda strategies can be improved to the point where they outperform all human opposition by making better price inferences based on market history  and by taking time remaining into account in pricing and timing decisions.
¡¡several aspects of the market behavior in our experiments differed from prior studies of all-agent or all-human traders. convergence to equilibrium in our experiments was generally slower than in prior studies  and in two experiments  there was no evidence of convergence by the end of the experiment. we observed scalloped price trajectories that were more pronounced and longer lasting than seen previously. also  our markets tended to be much more lopsided  either buyers systematically exploiting sellers  or vice versa  than in earlier studies. such novel market phenomena merit further investigation: they might be due to specifics of our market design  or they may be more general outcomes of agenthuman interactions. hence it will be important to conduct further agent-human experiments in other types of markets  possibly including greater complexity and real-world detail. candidates include combinatorial auctions  tac-type markets  wellman et al.  1   and more realistic models of financial markets. the development and deployment of effective automated trading strategies in such markets would have immense practical importance  and could mark the beginning of a large-scale introductionof economicsoftware agents into the world economy  kephart et al.  1 .
¡¡while our results are preliminary some aspects of our findings may be indicative of what one can expect to occur more generally as economic software agents are developed for realworld markets. we suspect that  in many real marketplaces  agents of sufficient quality will be developed such that most agents beat most humans. a significant component of their advantage will come from their ability to initiate actions  and to react to market events  much faster than humans. as a result  there will be significant economic incentive for humans to employ agents to act on their behalf. then the competition between agents and humans will evolve into a competition among agents.
acknowledgments
the authors are especially indebted to steven gjerstad  who made several invaluable contributions to these experiments.
steven co-authored the paper that first described the gd bidding algorithm  which we adapted and extended to handle different market rules. steven was also responsible for the design of the watson experimental economics laboratory  weel  where the experiments were conducted; for the design of the double auction market rules; for the design of the gem system that was used as the electronic auctioneer and the auction clients for human traders; and for recruiting most of the experimental subjects.
¡¡we would like to thank several other people for their significant contributions. jason shachat helped develop the experimental protocol and supervise some of the experiments. amit shah helped implement the messaging link between the gem and magenta systems. oconel johnson  system administrator for weel  helped ensure that the gem hardware and software were ready for the experiments. weng-keen wong and jonathan bredin developed the magenta message handling components for the agents and a magenta auctioneer used for stand-alone testing  and they implemented and tested several bidding algorithms. david levine resolved several bugs and inefficiences in the gem-magenta link  and was an invaluable resource on architectural questions.
¡¡we would also like to thank the many students and ibm researchers who participated in the experiments  including some early trial experiments not reported here. finally  we would like to acknowledge the support of the ibm institute for advanced commerce.
references
 cliff and bruten  1  d. cliff and j. bruten. minimalintelligence agents for bargaining behaviors in marketbased environments. technical report hpl-1  hewlett packard labs  1.
 gjerstad and dickhaut  1  s. gjerstad and j. dickhaut. price formation in double auctions. games and economic behavior  1-1  1.
 kephart et al.  1  j. o. kephart  j. e. hanson  and a. r. greenwald. dynamic pricing by software agents. computer networks  1-1  1.
 preist and van tol  1  c. preist and m. van tol. adaptive agents in a persistent shout double auction. in proceedings of the first international conference on information and computation economies  pages 1. acm press  1.
 rust et al.  1  j. rust  j. miller  and r. palmer. behavior of trading automata in a computerized double auction market. in d. friedman and j. rust  editors  the double auction market: institutions  theories  and evidence  redwood city  ca  1. addison-wesley.
 schaeffer  1  j. schaeffer. the games computers  and people  play. in m. zelkowitz  editor  advances in computers 1  pages 1. academic press  1.
 smith  1  v. l. smith. an experimental study of competitive market behavior. journal of political economy  1-1  1.
 smith  1  v. l. smith. microeconomicsystems as an experimental science. american economic review  1- 1  1.
 wellman et al.  1  m.	wellman 	p.	wurman 
k. o'malley  r. bangera  s. lin  d. reeves  and w. walsh. designing the market game for a trading agent competition. ieee internet computing  pages 1  march/april 1.

multi-agent systems
user interfaces

usability guidelines for interactive search in direct manipulation systems
robert st. amant and christopher g. healey
department of computer science
north carolina state university
egrc-csc box 1
raleigh  nc 1  u.s.

abstract
as ai systems make their way into the mainstream of interactive applications  usability becomes an increasingly important factor in their success. a wide range of user interface design guidelines have been developedfor the direct manipulationand graphical user interface conventionsof modern software. unfortunately  it is not always clear how these should be applied to ai systems. this paper discusses a visualization assistant  an e-commerce simulation domain we have applied it to  and the guidelines we found relevant in the construction of its user interface. the goal of this paper is to explain how an interactive system can incorporates searchbased intelligent behavior while still respecting well-established rules for effective user interaction.
keywords: user interfaces  expert systems  simulation
1	introduction
designing a good user interface may appear to be straightforward  especially with the help of a user interface builder  but this ease is deceptive. the construction process involves much more than adopting the surface conventions of graphical user interfaces  mapping inputs to menus and type-in boxes  outputs to icons and related graphics. good graphical user interfaces also follow heuristic guidelines that govern almost every aspect of design  from the manipulation properties of widgets to the decomposition and organizationof tasks to the overall visual layout of an interface  dix et al.  1 . determininghow a general guidelineshould be appliedin any given situation is notoriously difficult.1
¡¡this is a newly important issue for ai  as search-based techniques find their way into conventional interactive applications. interactive ai systems usually depend on direct manipulation in some form  by virtue of their integration into modernsoftware environments. direct manipulationsystems rely on continuous representation of objects of interest  physical actions or labeled button presses for commands  and rapid  incremental  reversible operations with visible feedback  shneiderman  1 .
¡¡unfortunately  intelligent behavior sometimes makes demands on the interaction process that do not naturally fit into a direct manipulation framework  shneiderman and maes  1 . ai systems have traditionally treated interaction with a user as a kind of communication. in contrast  direct manipulation relies on what hutchins calls model world interaction  hutchins  1 : the interface provides an environment and a set of tools that the user directly applies to reach a problem solution. more concisely  the user acts through a direct manipulation interface  rather than talks to it. the difference between the communication and model world paradigms is more than skin deep  in that what constitutes an effective set of rules for interaction under one paradigm may be drastically inappropriate under the other. for example  in a collaborative problem-solvingprocess  it is common for agents to negotiate about the appropriate means to solve a problem. in contrast  tools do not negotiate with their users; they simply perform their assigned tasks. if the effectiveness of an interactive system depends on simple tools that give the user predictable  consistent behavior  then redesigning the tools so that they can communicate and negotiate with the user about their use is likely to degrade the overall usability of the system.
¡¡this is not to say that agents cannot behave as tools  or that tools cannot be extended to incorporate some agentlike behavior  e.g.  anderson et al.  1; horvitz  1; lieberman  1; maes  1  . on the contrary  we believe that the line between agents and tools will continue to blur. a key issue in this evolution is whether we understand the differences in user interaction that the agent-based and tool-based approaches require. with this understanding we can make better decisions about how conventional user interface guidelines should be adapted to unconventional  from a human-computer interaction perspective  application properties  such as a reliance on search.
¡¡this paper lays out a set of design guidelines for incorporating a search process into a conventional direct manipulation interface. we describe several design principles from the hci literature and work out their general implications for systems that provide intelligent assistance through search. we further discuss how these implications affect the design of a search-based system for visualization.
hotel/airline purchase activity

figure 1: icmas '1 tac data visualization  in grayscale   with agent id	color  price	height  quantity	width1	a visualization domain
we begin with a example  using a problem domain that illustrates our motivation as well as producing results of general interest in ai. via is an intelligent assistant for building scientific visualizations. scientific visualization is the conversion of collections of strings and numbers  or datasets  into images that allow viewers to perform visual exploration and analysis. very large datasets with millions of data elements representing multiple independent data attributes are not uncommon. the challenge is to design methods that present some or all of this information simultaneously in a single display  without overwhelming a viewer's ability to make sense of the resulting images. the choice of which visual features to use  e.g. color  size  or contrast  to represent each data attribute is called a data-feature mapping. via takes as input a dataset  a short description of the dataset's properties  and a set of viewer-defined analysis tasks  and produces as output a set of appropriate data-feature mappings.
¡¡one currenttestbed application  the tradingagent competition 1 illustrates the goal of via. the tac is a simulated ecommerce auction environment run on the michigan internet auctionbot platform.theauctionbot is a tcp-based auction server that implements numerous types of auction rules. this allows the simulation of a wide variety of market games. intelligent auction agents are designed and tested within these markets to study different buying and selling strategies.
¡¡during the tac  each agent acts as a  travel advisor  whose goal is to assemble a travel package for eight fictitious customers. a travel package consists of a round-trip flight from tactown to boston  a hotel reservation  and tickets to entertainment events  a baseball game  the symphony and the theater . customers specify preferences for the different aspects of their trip: which days they want to be in boston  the type of hotel they prefer  economy or luxury   and the entertainment events they want to attend. obvious dependencies must be met; for example  customers need hotel rooms for the duration of their trip  and can only attend entertainment events during that interval. the goal of the agent is to maximize the total satisfaction of its customers  i.e.  the sum of their utility functions .
¡¡via was used to identify effective real-time visualizations for agent activity in a tac run during the icmas '1 conference. five separate attributes were selected by hand for visualization: the time  auction id  agent id  price  and quantity for every bid made during the simulation. time and auction id were used to define a bid's and -position on a two-dimensional grid. perceptual texture elements  or pexels  healey and enns  1   that vary in their color  combined hue and luminance   height  density  and regularity of placement were used to represent the remaining attributes: agent id  price  and quantity.
¡¡tac competitors  acting as domain experts  assigned normalized importance weights of 1  very important  to agent id  and 1  somewhat important  to quantity and price. they also defined the analysis tasks  searching for specific agents  identifying price boundaries  and estimating the relative frequency of particular quantities  they wanted to perform. via automatically identified additional properties like the spatial frequency and value range of each attribute in the dataset. this application-independent information is used together with a collection of perceptual guidelines to select the mappings that are most appropriate for tac visualizations.
¡¡based on dataset properties and viewer-imposed restrictions  via produced several perceptually salient visualizations. figure 1 shows a modified version of a via-generated mapping  with agent id color  price height  and quantity width. rectangular towers are used to represent each bid made during the game. time and auction id define a tower's location on the underlying grid. time increases from left to right along the horizontal axis. each row corresponds to a separate auction. a tower's color  height  and width show the bid's agent id  price  and quantity  respectively. different colorsidentify bids by differentagents. buy bids lie above the grid  while sell bids lie below the grid; a higher buy  or sell  price increases the height of the tower. bids for larger quantities produce wider towers. simultaneous bids made by an agent in a particular auction are displayed as a horizontal row of towers in the appropriate grid cell  each with its height and width defined by the particular bid's price and quantity . bids made by different agents at the same time in the same auction are shown as rows of towers drawn on above another in a common cell. this arrangement uses spatial density to represent the level of bid activity at different locations in the game.
¡¡many aspects of the agents' strategies and game play can quickly be identified using such visualizations. for example:
1. some agents periodicallymade verylow buy bids forhotel rooms to ensure the hotel auctions  stay alive   hotel auctions automatically close after a period of inactivity .
1. most agents deferred purchasing hotel rooms and airlinetickets until just before the simulation ended  judging there was no advantage to early purchase  particularly for hotel rooms  where attempts at early purchase can drive up the final price .
1. if hotel rooms for a given customer cannot be found  thecustomer's entire trip is canceled  and the agent is penalized the cost of any airline and entertainment tickets they may have purchased on the customer's behalf. some agents estimated the marginal cost of this penalty  then made late bids for hotel rooms at a buy price of . these agents decided that paying for a hotel room was no worse than paying a penalty of for unused airline and entertainment tickets. more importantly  there is a good chance that the hotel rooms will sell for less than . if this happens  the agent will make a profit relative to the scenario of not securing the hotel room.
¡¡via casts scientific visualization as a straightforward search problem: finding a mapping between dataset attributes and visualization features that respects dataset and user constraints. via's exploration  at its core  is an incremental bestfirst search. the evaluation function is composed from the results of a set of critics. a critic exists for each visual feature available for use in a mapping  e.g. a hue critic  a height critic  and so on . the critic examines the data attribute associated with its visual feature  and reports on its perceptual correctness  healey and enns  1 . critics also generate search operators for improving particular associations. via uses the critics' results to compute an overall evaluation of its current mapping  and to extend the search in the direction of modifications that should produce better mappings.
¡¡our discussion up to this point has skirted the issue of user interaction. even for the tac domain  which poses a very small problem in computational terms  the design of an interface for via must address a number of nontrivial questions.
how can user preferences be taken into account to guide the search process  what kind of incremental feedback should the system provide  for lengthy processing times  should the user see all of the solutions via generates  or only the best  answers are provided in the hci literature  but require interpretation to be applied correctly.
1	interaction design for an ai system
the hci literature contains dozens of general principles for user interface design  leading to thousands of detailed guidelines. for example  smith and mosier produced an early set of over 1 guidelines for text-based interfaces  smith and mosier  1 . the sophisticated user interfaces of macintosh and windows systems are driven by a small set of high level principles  including metaphor  direct manipulation  user control  and consistency  that expand to much more detailed guidelines. we draw on a recent concise summary of concepts due to dix et al . the category of learnability in an interface includes predictability  synthesizability  familiarity  generalizability  and consistency. flexibility includes dialog initiative  multi-threading  task migratability  i.e.  from the user to the system  and vice versa   substitutivity of input and output forms  and customizability. robustness includes observability  recoverability  responsiveness  and task conformance. some of these concepts are applicable to all user interfaces. those we consider in this section pose some novel requirements that we have not seen explicitly compiled and discussed in the ai or hci literature.
¡¡let's consider a hypothetical interactive ai system  a generalization of the via system  to see how these guidelines should be interpreted. the system is given a problem that it must solve through search. its evaluation function  while accurate to an approximation  is incomplete; the search process requires input from the user to reach the best results  e.g.  prefer this data-feature mapping to that  due to domain-specific interpretations of color.  this means that the system must show the user some representation of the state space  in order to elicit feedback and guidance. this interaction requirement in turn means that a significant part of the system's design must be devoted to managing interaction with the user. unlike conventionalapplications  an ai system takes actions that are determined as much by the properties of the state space as by the actions of the user. the interaction is thus more likely to be opportunistic  less likely to be predictable with respect to the type of information exchanged  the duration of the entire task  how control of initiative shifts between the system and the user  and related properties.
¡¡given this broad description  we now turn to an interpretation of the usability concepts listed above  organizedinto four broad areas. following these guidelines generally improves conventional interfaces; we show how they can be applied to interactive ai systems.
incremental processing is an important property for an interactive ai system  if for no other reason than that the user must be given some opportunity to contribute to the problem solving process. this general point has several related components.
responsiveness. an interface is responsive when the response times of its operators match the user's expectation. some  though not all  usability studies have found that consistency in response time is preferable to raw speed  myers  1 . for example  users will generally prefer a constant response time  i.e. search duration  of  say  five seconds  to responses with a mean time of four seconds but varying between zero and eight seconds. for a search-based system  this suggests a design that combines anytime processing with continuous computing concerns  horvitz  1 .
task migratability. task migratability is supported when problem solving responsibility can be handed off from the user to the system  and vice versa. this suggests that the system and the user should have access to a common set of search operators  though user operators will often be abstractions or compositions of system operators.  this kind of facility is supported  for example  by scripting and end-user programming in conventional software  and by some systems for programming by example  pbe   lieberman  1 . migratability is impaired if a search-based system can reach states that the user cannot reasonably evaluate  or if the user would like to override specific system behavior but cannot.
observability implies that the user is able to infer internal properties of the system's state from its external representation. an important aspect of observability in an ai system is making clear the  maturity  of a solution. the pitfall to avoid is the system prematurely focusing the user's attention on an early solution that is likely to be superseded by a later incompatible solution. this can be viewed from the system side as a search horizon issue  from the user side as a potential anchoring problem.
dialog initiative. an interface respects dialog initiative when problem-solving initiative can shift between the system and the user to follow the task. as with task migratability  mixed dialog initiative should be supported by presentation of information at an appropriate level of detail for the user to make a meaningful contribution.
adaptation refers to the dynamic adjustment of the system's behavior to the user's actions. this adaptation can occur at the direction of the user or automatically.
customizability entails that an interface be adaptable to the abilities and needs of the user. this kind of customization  for a search-based system  can be thought of as modification of preferences that influence the system's operational characteristics. candidates for customization include the number of states incrementally searched  and the number of potential solution states retained and presented.
search adaptation is a more important point. suppose that the system presents the user with the current best state   as determined by its evaluation function . the user reviews this information and decides that a modification is appropriate  leading to a state that the system has already considered internally and given a lower value. when the system resumes its search  it must modify
or some state property to avoid again indicating that is a better solution. a further useful capability is generalization of the differences between and to support comparisons of other states that have not yet been evaluated or presented; some pbe systems have this capability.
coherence. although direct manipulation systems tend to support a style of interaction in which operator sequences are short and goals interact as little as possible  an incremental search process necessarily involves maintenance of context between exchanges with the user.
predictability and consistency are two important aspects of coherence. an interface is predictable when a user can determine  from a specific operation in a given state  what the consequences will be. consistency promotes predictability. direct manipulation systems tend to present a comprehensive visual environment to the user  with the assumption that the user can judge relevance better than the system. in an incremental search  a system might reserve some information that is simultaneously less likely to change and less likely to be immediately relevant. instead of giving the user a complete representation of the best states  for example  the system might limit its display to a few selected properties  leaving itself  wiggle room   space to maneuver. a related issue deals with predictability in response to user actions. to continue the search adaptation example  suppose that the user has selected a specific operator to improve state   and that has been effective in the past  but this time it is not. if the reason for this is not apparent  an observability issue   the user's confidence in the effectiveness of or the system's evaluation function may suffer. additional explanation may be warranted to improve predictability.
support for user orientation. one of the difficulties implied in the foregoing discussion is that of managing interaction between the system and the user  such that each party can make real contributions. many of these difficulties can be understood in terms of user orientation during a navigation process  kim and hirtle  1 .
reachability between states in an interface generalizes the idea of recoverability; it implies that from any state  any other state can be reached  in particular non-error states from error states. for an intelligent interactive system this goes beyondthe completeness of a search algorithm. in addition it means that the user can recall and re-visit past states  to review and re-evaluate earlier decisions. navigational support  e.g. generation of landmarks  can improve orientation for this task.
synthesizability can be understood as the ease with which the user can form a conceptual model of the problemsolving process. in an interactive ai system  part of synthesizability means that the system partitions the state space so that the user can grasp individual portions more easily. in navigation terms  this kind of synthesizability is supported by region differentiation.
property	via mechanism

responsivenessresponse time tailored to platformdialog initiativeuser controlled incremental searchtask migratabilityexternal availability of operators  executable between search epochscustomizabilityuser-editable preferences for search step size and filtering of results
table 1: usability properties in via search
property	via mechanism

predictabilityclustering and filtering of best states; presentation of partial state informationsynthesizabilityallowing user to explore  nearby  and  distant  solutions of comparable value  with region partitioning by windowsobservabilityprogress messages and navigation supportreachabilitynavigation support
table 1: usability properties in via presentation
1	interaction with via
in the user interface to via we are exploring the implications of these guidelines. a functional prototype is shown in figure 1  with an intermediate step in the search for data-feature mappings visible.  this section describes a weather dataset rather than the tac dataset  which is too small to exercise some of the capabilities of the interactive system.  via's interface design accounts for most of the concerns identified in section 1  although not with complete generality. relevant design features can be divided into those that affect the search directly  as summarized in table 1  and those that affect presentation and user interaction  as shown in table 1. these design features will appear to be straightforward  even obvious  for the most part  but it is surprising how often they are neglected in interactive ai systems; hence the need for guidelines.
¡¡via's search is incremental  with a default but editable response time of about a second. the search step size is computed automatically when the user loads an initial dataset description  by running the critics on the dataset to gain timing estimates for the currentplatform. the user can incrementally modify the mappings that the system returns; these editing capabilities provide most of the functionality of via's search operators.
¡¡in via's domain  a search usually produces several candidate solutions with essentially equal evaluation results. the system maintains a list of the best     solutions it has encountered in its search  and performs a simple clustering on the contents of the list at the end of each search epoch. if a cluster is found among the top-ranked solutions in which the majority of attributes are assigned to the same features  then the remaining  differingassignments are stripped out and only the common assignments of the solutions are presented. this capability is intended to focus the user's attention on the

figure 1: via user interface
more influential assignments; whether the filtering occurs at
all  however  is under user control.
¡¡via's search can be directed toward solutions that are near the currently displayed mapping  or those that are distant. when the user chooses to search nearby solutions  the system selects the best solution it finds that is nearest to the solution most recently presented. distant solutions are handled by selecting farthest solution among the top candidates. this organizationof search results is a compromisebetween showing all promising solutions at once and showing them one at a time in an arbitrary order. the nearby/distant distinction allows the user to conceptually organize the space of mappings into distinct regions during its traversal. toward this end  a distant solution operation generates results in a new window  to create a new visual  context  for the search. as another navigational aid  the user can bookmark or discard individual solutions to impose further structure on the space.
¡¡a global search overview shows all of the presented solutions  across all nearby and distant searches. currently the overview information is presented as text in outline form  but the intention is to build an annotated graphical representation of the search space  to show the non-linear paths that the user may have taken throughit. other areas of incomplete or missing functionality include the adequacy of explanations provided to the user  explanations currently only describe critic results and the number of states searched   the completeness of the set of search operators available to the user  discretization and task removal operators are missing   and functionality related to search adaptation.
¡¡the interface that has resulted from our work supports a more flexible  less burdensome interaction with the search component of via than is provided by conventional means  e.g.  interaction through a command line  within a text editor  or through a simpler graphical interface dialog.  as with many systems in the intelligent user interfaces and hci literature  however  the interactive aspects of via outlined above have not been evaluated in a formal sense. the application discussed here should not be treated as validation of via's interface design. rather  our examples act as illustrations and an early means of formative evaluation. evaluating a user interface of any complexity is an extensive undertaking and remains yet to be done for via.
1	discussion
our work is partly inspired by earlier work on interface softbots  which operate through the user interface of an application  rather than a programmatic interface  st. amant and zettlemoyer  1 . interface softbots are motivated by a claim that characteristic properties and behaviors of a graphical user interface can be exploited by planning agents  due to a similarity between planning assumptions and user interface guidelines  st. amant  1 . in this paper we take a more conventional route in showing how such interface guidelines can be applied to improve interactive ai systems.
¡¡otherwise  usability for interactive ai systems has been a small but active area of research  hendler and lewis  1; ho¡§ok  1; kaasinen  1¡§  . horvitz provides a representative study  presenting a set of principles for mixed-initiative user interfaces  horvitz  1 . as is commonly the case  these extend beyond conventional guidelines for direct manipulation systems  encompassing such issues as social behavior and the explicit use of dialog. our intention is not to describe new guidelines for new technology  but rather to clarify how new techniques can be fit into an existing interaction paradigm  and to explain how existing guidelines apply.
acknowledgments
thanks to peter wurman for his contribution of tac material and to three anonymous reviewers for helpful comments on the draft of this paper. this research was partially supported by the national science foundation  award numbers iis-1 and iis-1. the u.s. government is authorized to reproduceand distribute reprints for governmental purposes not withstanding any copyright notation hereon.
references
 anderson et al.  1  david anderson  emily anderson  neal lesh  joe marks  brian mirtich  david ratajczak  and kathy ryall. human-guided simple search. in proceedings of aaai  pages 1. aaai press  1.
 dix et al.  1  alan j. dix  janet e. finlay  gregory d. abowd  and russell beale. human-computer interaction. prentice hall  1nd edition  1.
 healey and enns  1  christopher g. healey and james t. enns. large datasets at a glance: combining textures and colors in scientific visualization. ieee transactions on visualization and computer graphics  1   1.
 hendler and lewis  1  james hendler and clayton lewis. introduction: designing interfaces for expert systems. in james hendler  editor  expert systems: the user interface  pages 1. ablex  1.
 ho¡§ok  1¡§   kristina ho¡§ok. steps to take before intelligent¡§ user interfaces become real. interacting with computers  1 :1  1.
 horvitz  1  eric horvitz. models of continual computation. in proceedings of aaai  1.
 horvitz  1  eric horvitz. principles of mixed-initiative user interfaces. in proceedings of chi'1  pages 1  1.
 hutchins  1  edwin hutchins. metaphors for interface design. in m. m. taylor  f. neel  and d. g. bouwhuis  editors  the structure of multimodal dialogue  pages 1. north-holland  elsevier science publishers  amsterdam  1.
 kaasinen  1  eija kaasinen. usability issues in agent applications: what should the designer be aware of. technical report  usinacts  1.
 kim and hirtle  1  hanhwe kim and stephen c. hirtle. spatial metaphors and disorientation in hypertext browsing. behaviour and information technology  1 :1- 1  1.
 lieberman  1  henry lieberman. letizia: an agent that assists web browsing. in proceedings of the international joint conference on artificial intelligence  pages 1- 1  1.
 lieberman  1  henry lieberman  editor. your wish is my command: programming by example. morgan kaufmann  san francisco  ca  1.
 maes  1  pattie maes. agents that reduce work and information overload. communications of the acm  1 :1  july 1.
 myers  1  brad a. myers. the importance of percentdone progress indicators for computer-human interfaces. in proceedings of chi'1  pages 1  1.
 raskin  1  jef raskin. the humane interface: new directions for designing interactive systems. addison wesley  reading  ma  1.
 shneiderman and maes  1  ben shneiderman and pattie maes. debate: direct manipulation vs. interface agents. interactions  1 :1  november/december 1.
 shneiderman  1  ben shneiderman. designing the user interface: strategies for effective human-computer interaction. addison-wesley  1.
 smith and mosier  1  sidney l. smith and jane n.
mosier. guidelines for designing user interface software. technical report esd-tr-1  the mitre corporation  bedford  ma  1.
 st. amant and zettlemoyer  1  robert st. amant and luke s. zettlemoyer. the user interface as an agent environment. in proceedings of the fourth international conference on autonomous agents  pages 1  1.
 st. amant  1  robert st. amant. user interface affordances in a planning representation. human computer interaction  1 :1  1.
 thimbleby  1  harold thimbleby. calculators are needlessly bad. international journal of human-computer studies  1 :1 1.
leveraging data about users in general in the learning of individual user models
anthony jameson and frank wittig
department of computer science 	saarland university
 p.o. box 1 1  1 saarbru¡§cken  germany jameson dfki.de  wittig cs.uni-sb.deabstract
models of computer users that are learned on the basis of data can make use of two types of information: data about users in general and data about the current individual user. focusing on user models that take the form of bayesian networks  we compare four types of model that represent different ways of combining these two types of data. models of the four types are applied to the data of an experiment  and they are evaluated according to theoretical  empirical  and practical criteria. one of the model types is a new variant of the ahugin method for adapting the probabilities of a bayesian network while it is being used: differential adaptation is a principled way of determining the speed with which each aspect of a network is adapted to an individual user.
1	introduction
machine learning techniques are being used increasingly in the development of interactive systems that adapt to individual users. two contrasting approaches can be distinguished:  learning general user models: a system processes observations acquired from a sample of users so as to learn a model that applies to users in general  see  e.g.   walker et al.  1  .
 learning individual user models: while a user is operating a system   processes observations about so as to learn a model of this particular  see  e.g.   segal and kephart  1  .
¡¡each of these types of learning has its own typical benefits  which will be discussed later in this paper. a natural strategy is to combine the advantages of general and individual models: learn a general user model which can be applied to a new user; adapt the model to each user during the interaction.

¡¡¡¡this research was supported by the german science foundation  dfg  in its collaborative research center on resource-adaptive cognitive processes  sfb 1  project b1  ready . the experiment described in section 1 was conducted in collaboration with barbara gro mann-hutter  christian mu¡§ller  and ralf rummer. the suggestions of the three anonymous reviewers led to significant improvements. the first author is currently at dfki  saarbru¡§cken.
¡¡one broad approach that applies this strategy is collaborative filtering  which has been applied widely in systems that recommend products  such as cds  to users  see  e.g.   herlocker et al.  1  . here  the  general model  is essentially just the database of ratings  or other actions  that have been contributed by users so far. a system could predict how a given user will rate a given object simply on the basis of this general model  by computing the average of all ratings given for that object. instead  of course  collaborative filtering systems usually make individualized predictions that are based on the ratings of a subset of users who are especially similar to .
¡¡although collaborative filtering systems have been highly successful  there are some application scenarios in which it is desirable to learn a more interpretable type of user model  in which causal relationships among variables are represented explicitly. for example  a system may need to predict how the behavior of the user will be influenced by particular contextual factors; or it may need to make uncertain inferences about unobserved contextual factors on the basis of 's behavior. collaborative filtering is less straightforwardly applicable to this type of problem than another popular type of model: bayesian networks  bns .1
¡¡the main issue addressed in the present paper is: how can systems that employ bayesian networks to model users most effectively exploit data about users in general and data about the current individual user 
¡¡our investigation makes use of data from a controlled experiment.
1	brief description of experiment
we begin by briefly summarizing the methods and results of the experiment  see  mu¡§ller et al.  1  for a more complete account . the experimental environmentsimulated on a computer workstation a situation in which a user is navigating through a crowded airport terminal while asking questions to a mobile assistance system via speech. in each trial  a picture appeared in a corner of the computer screen  and the subject was to introduceand ask a question related to the picture  e.g.   i'm getting thirsty. will it be possible to get a beer on the plane   .
¡¡two independent variables were manipulated orthogonally:
 time pressure : whether the subject was instructed  a  to finish each utterance as quickly as possible or  b  to create an especially clear and comprehensible utterance  without regard to time.
 secondary task : whether or not the subject was re-

quired to  navigate  through the terminal depicted on the screen by pressing arrow keys in order to move the cursor on the screen  avoiding obstacles in the process.
¡¡in each of the 1     conditions  each of the 1 subjects produced 1 utterances. there are therefore 1  observations  of each subject.
¡¡the subjects' speech input was later coded semiautomatically with respect to a wide range of features  including pauses  length  quality of content  and various types of disfluency. for the present study of learning methods  we selected a representative subset of four speech-related variables:
 articulation rate: the number of syllables articulated per second of speaking time  not including silent pauses.
 number of syllables: the number of syllables in the utterance.
 disfluencies: a binary variable that takes the value  true  when any one of four types of disfluency  e.g.  starting a sentence but failing to complete it  is present in the utterance.
 silent pauses: the total duration of the silent pauses in the utterance  relative to the length of the utterance in words.
¡¡the practical relevance of this experiment lies mainly in the prospect that a mobile assistance system could interpret the features of a user's speech to make inferences about 's current psychological state   mu¡§ller et al.  1  . in addition  there are situations in which it can be useful for to be able to predict particular features of 's speech in a given situation-for example  so as to determine whether to request input via speech or via another modality.
1	method and model types
the basic bn structure used for the models developed for the experimentis shown in the top two rows of figure 1. we wish to simulate a situation in which a system is interacting with a user in this experimental situation and obtaining successive observations about . we will introduce four types of model  each of which will be tested according to the same procedure  which is shown in table 1.
¡¡the characteristics of the four model types are summarized in table 1; some further comments follow:
¡¡the general model is learned from the experimental data via the usual maximum-likelihood method for learning fully observable bayesian networks  see  e.g.   buntine  1  : the estimate of each  conditional  probability is computed simply in terms of the  relative  frequencies in the data. during the application to an individual user  the model is not adapted further: essentially  a fresh copy of the model is used

figure 1. basicbnstructureusedforthecomparisonof models.
 thefourvariablesinthebottomrowareincludedonlyintheparametrizedmodel.thenumberinparenthesesforeachvariableisthe numberofstatesofthatvariable. 
for the prediction of each observation.
¡¡the parametrized model is initially learned in the same way as the general model  except that the four parameter variables shown in the bottom row of figure 1 are included. each of these variables represents the mean value of the corresponding variable above it for the user in question.
¡¡the adaptive model makes use of the ahugin   adaptive hugin   method that was introduced by olesen et al. . in contrast to the parametrized model  there is no explicit representation of the dimensions along which users may differ. instead  the probabilities in the conditional probability tables  cpts  of the bn are adapted whenevera new observation is processed. in this way  a great variety of individual differences can be adapted to  without any need for the designer of the bn to anticipate the nature of these differences. one question that arises in the application of the ahugin method concerns the speed with which the cpts should adapt to the individual user. one simple approach  which is frequently used in other contexts  is to specify for the entire bn a single parameter  called the equivalent sample size  ess ; the ess essentially represents the extent of the system's reliance on the initial general model  relative to the new data that will be obtained for each user. as we will see below  it is in general not obvious a priori what the most appropriate ess for a given bn is. moreover  the optimal value of the ess can be quite different for different parts of the bn; in the context of our experiment  we may need a different ess for each combination of a speech variable  e.g.  number of syllables  and an experimental condition. one original contribution of this paper is a principled method of estimating the optimal esss on the basis of the data collected with previous users. application of this method yields a bn in which the various parts of the variables' cpts adapt at different rates to each new user; hence the name differential adaptation. this method is described in detail in the appendix.
¡¡the purely individual model is simply learned entirely on the basis of data from the current subject. so that some sort of inference can be performed right from the start  each cpt is initialized with uniform distributions. but as soon as the first observation for a given configuration of the values of the parent variables time pressure  and secondary task  has been
initial model 
  a bn defined in the way specified for type t  see table 1  on the basis of the data from the other subjects in the experiment 
preparation of the test data 
1. determine a single random ordering of the 1 experimental testing the model for a single user u with respect to a variable v 
for each observation o in the set of observations for u  
1. derive a belief about o: 
  instantiate all variables for o other than v 
  evaluate the bn to arrive at a belief regarding v 
1. determine the quadratic loss of the derived belief with presentation of results 
  in each curve in a graph  the quadratic loss for each observation is aggregated over all subjects in the experiment 
  moreover  each value plotted is the mean quadratic loss for a block of 1 observations respect to the actual value of v 
stimuli  to be employed for all 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡1. learn from the observation: users 
1. for each individual user u  select 	  use the values of all of the variables for the observation o the 1 observations for u 	to adapt the model  in the way specified for this type of model  see table 1  according to this ordering 
table 1. procedureforevaluatingthelearning ifany andperformanceofamodeloftypet.learning from previous users 	adaptation during use by the current user 

general model 
learned on the basis of all 	no adaptation during use 
observations of other subjects in the experiment  with no variables for individual parameters 
parametrized model 
learned on the basis of all 	the bn is built up as a dynamic observations of other subjects  	bn  a new time slice being 
with variables for individual 	created for each observation; 
parameters 	parameter nodes are updated as 
       static nodes adaptive model 
individual models are learned 	after each observation  the cpt for the other subjects as with the entries for the instantiated purely general model; 	configurations of values of 
on the basis of these models  an parent variables are updated initial model for u is created 	according to the ahugin that includes an equivalent 	algorithm  using the ess sample size  ess  for each 	computed for that configuration 
configuration of values of parent variables in each conditional probability table  cpt  
individual model 
no prior learning: in the initial 	adaptation is done as for the model for u  for each parent 	adaptive model  but the same configuration in each cpt the 	minimal ess is used for all probabilities are uniformly 	parent configurations 
distributed and a minimal ess of .1 is specified 

table 1. overviewofthefourmodeltypescompared.
obtained  the initial model has essentially no further impact on the corresponding part of the cpt in question.
1	results
we will now look at the results for these four models for each of the variables in the experiment. we first consider the four dependent variables in the second row of figure 1  which need to be predicted by the model. then we turn to the two independent variables in the top row. the derivation of a belief about one of these variables is essentially a classification

1 
	1 	1 	1 	1 	1 	1 	1 	1 	1 	1 
number of observations 
figure 1. predictionaccuracyfor articulation rate.
 highervaluesofquadratic loss representloweraccuracy. 
task for the system: on the basis of an observation  the system attempts to assign to a given experimental condition.
1	predicting a variable with simple individual differences
the results for the general model for the variable articulation rate are shown by the solid thick curve in figure 1. first  note that the only reason why this curve is not a straight horizontal line is that there is considerable random fluctuation in
the quadratic loss variable; so there is no point in trying to interpret the individual zig-zags in the curves for the general model.
¡¡it is meaningful  on the other hand  to compare the overall performance of the general model with that of the parametrized and the adaptive models. as with all other comparisons that follow  we will use simple sign tests that take into account only the last 1 observations  1 blocks in the figures .1 each of these models performs consistently better than the general

figure 1. predictionaccuracyfor number of syllables.
model during the last 1 observations    . this fact is understandable given that stable individual differences in articulation rate are known to exist. for this variable  the parametrized and the adaptive models perform very similarly.
¡¡the curve for the individual model shows a pattern that we will see to be typical: at first  the predictions are very inaccurate  as would be expected given that they are initially based on an arbitrary set of probabilities. but after about 1 observations the individual model does as well as the general model; and during the last 1 observations it is somewhat better    .
1 predicting a variable with more complex individual differences
it is likewise generally known that people differ in their verbosity: the amount that they say in any given situation. figure 1 shows the results for the variable number of syllables. the individual differences are apparently even more important than for articulation rate: the individual model catches up with the general model in the third block  and by the last three blocks it is tied for first place.
¡¡moreover  the adaptive model significantly outperforms the parametrizedmodel   for the last 1 observations . figure 1 helps to explain this advantage by displaying the accuracy levels for each of the four experimental conditions  without showing the time course of learning . the figure shows that the superior performance of the adaptive model occurs in just one of the four experimental conditions: q   in which subjects were instructed to produce high-quality utterances without having to navigate. some subjects responded to this condition by creating elaborate  lengthy formulations  while others simply aimed to increase the clarity of an utterance of normal length. it is understandable that these individual differences should be hard to predict in terms of a single dimension of  verbosity   which is what the parametrized model has to use. the ability of the adaptive and individual models to learn 's behavior in each individual condition proves to be an advantage here. note also that the ess employed for the condition q is lower than that for the other conditions. in effect  the system has noticed that people re-

figure 1. predictionaccuracyfor disfluencies.
spond very differently to this condition with respect to this variable and that it should therefore base its model largely on what it observes in the individual 's behavior.
1	predicting low-frequency behaviors
the variable disfluencies  figure 1  is an example of a variable for which there is little to be gainedthroughadaptationto the individual user. on the average  only about 1 utterance in 1 contains one or more of the disfluencies in question. consequently  it is inherently difficult for a system  given a limited number of observations  to acquire a model of a user's tendency to produce disfluencies which is better than the general model-eventhough stable differences among users might be found  given enough data. this fact is shown by the strong similarity of all four curves during the last few blocks of observations.
¡¡measurable silent pauses  figure 1  within an utterance are also rather infrequent events  occurring only about once in every 1 utterances overall. still  the parametrized model does manage to outperformthe general model here    .

figure 1. predictionaccuracyfor silent pauses.
1	inferring the experimental condition
figure 1 shows the results for a classification task: instead of predicting a particular aspect of 's behavior  has to infer whether was working under time pressure or with an emphasis on quality  given the features of one of 's utterances and knowledge of the value of the other independent variable
 secondary task  .
¡¡the pattern of relative accuracy shown in the figure is somewhat inconsistent with the pattern shown in the previous figures:
 the individual model never catches up with the other models in terms of accuracy  whereas it had done so for each of the prediction tasks.
 the parametrized and adaptive models do not show a very clear advantage over the general model   and   respectively -although one might have expected such an advantage  given that these models performed clearly better in the prediction of two of the four speech variables  articulation rate and number of syllables .
¡¡for classification with regard to secondary task   figure 1   there are no reliable differences at all except that the individual model is much worse than the others throughout. this particular classification task-determining on the basis of a single utterance whether the subject is navigating or not-is very difficult  with performance being at best marginally above the chance level  which corresponds to a quadratic loss of 1 .
¡¡these results remind us of the general point  arguedby previous authors  that there is not necessarily one best model for a given set of data. for example  friedman et al.  discuss the reasons why a bn that is optimal with respect to some general accuracy criterion may perform suboptimally on classification tasks; and they propose methods for optimizing the classification accuracy of a learned bn. greiner et al.  have argued more generally that learning should take into account the specific queries that a bn is intended to answer.
figure 1. classificationaccuracyforsecondary task .
1	discussion
1	overall comparison of model types
table 1 summarizes the points that have been made in the preceding sections about  a  the theoretical strengths and weaknesses of the four model types   b  the empirical results for them that were obtained in our experiment  and  c  practical considerations that may be equally important for the choice of a type of model.
¡¡the empirical results do not appear to depend on specific properties of this one experiment: when we performed the corresponding analyses for a quite different experiment  described in  jameson et al.  1    a very similar pattern emerged: in particular  for each of the categories of variables discussed in the subsections of the previous section  there was at least one variable in the other experiment that fell into that category and yielded similar results with regard to the performance of the four model types.
¡¡regarding the empirical results: although the parametrized and adaptive models perform best overall  the general and individual models each show competitive performance

theoretical considerations empirical results 
general model practical considerations   individual differences are never taken into account   out-performed in the long run by the parametrized and adaptive models  except where individual differences are small or very hard to learn; and sometimes by the individual model 
parametrized model   ample prior data required 
+ no overhead for run-time adaptation + knowledge about the nature of individual differences can be represented explicitly 
  many parameters may be required if individual differences are complex + generally better than the general and individual models and competitive with the adaptive model 
  somewhat poorer than the adaptive or even the individual model when individual differences are complex 
adaptive model   ample prior data required 
  dynamic bayesian networks can raise complexity problems 
+ parameters can be shared with other user models + specific parts of the model are adapted at different rates in a principled manner + permits smooth transition from a general model to an individual model   the number of degrees of freedom for the learning may be unnecessarily high  relative to the paramaterized model  so that learning is unnecessarily slow + generally good performance  especially on prediction tasks with complex individual differences 
individual model   ample prior data required 
+ no prior explicit knowledge about individual differences required   the adaptation mechanism must be invoked repeatedly during system use   since no use is made of prior knowledge or data  inference is likely to be very inaccurate during the initial phase of use 
+ there is no bias against entirely unexpected patterns of behavior   very poor performance during some initial phase of use 
  the phase of poor performance is especially long for classification tasks + good ultimate prediction performance where behavior is highly idiosyncratic + no prior knowledge or data required   the adaptation mechanism must be invoked repeatedly during system use table 1. overviewofthestrengthsandlimitationsofthefourmodeltypes.under certain conditions. consequently  one of these models may be turn out to be the most suitable one when these conditions are met and the practical considerations favor the model in question.
¡¡the use of table 1 to select a model type for a given application scenario is made more difficult by the fact that some of the conditions mentioned  e.g.  individual differences are complex   refer to properties of the data that may or may not be known a priori. it may therefore be necessary to test two or more types of model empirically on data from the domain in question before arriving at a decision. even in these cases  table 1 should be helpful in that it calls attention to the key considerations and the most promising model types.
1	novel aspects of the differential adaptation method
the most salient features of the method of differential adaptation are the following:
1. it leverages data about previous users not only to learn an initial general user model but also to learn how fast the various aspects of this model should adapt to each new individual user.
1. it does so without requiring the explicit representation of dimensions along which individual users may differ  as is the case with parametrized models.
¡¡as another example of a scenario in which this method might be useful  consider the system syskill & webert   pazzani and billsus  1    which predicts whether a given web page will be interesting to the current user. in the main version of the system  the user model consists essentially of a set of probabilities for each word in a set of relevant words: w is present page is interesting and w is present page is uninteresting . pazzani and billsus note that it can take inconveniently long for the system to learn the necessary probabilities solely on the basis of 's page ratings  and they propose solutions to this problem. in accordance with the basic idea of differential adaptation  this problem could be dealt with as follows: for each word   the system would derive a prior expectation  more precisely  a beta distribution   for w is present page is interesting on the basis of the data of other users  through the procedure described in the appendix  along with a corresponding expectation for w is present page is uninteresting ; and these expectations would be used and updated as in the tests described above. this method might be especially useful in the case of words that  a  occur infrequently but  b  exhibit similar probabilities for most users.
1	summary of contributions
as the learning of user models for adaptive systems becomes more widespread  increasing attention will be devoted to the

figure 1. comparisonbetweenthedifferentialadaptation methodandtheuseoffixedesss.
 thesolidlineshowstheresultsfortheadaptivemodelwhichwere showninfigure1;thedashedlinesshowtheresultsformodels usingfixedesssof1 1 and1 respectively withthelengthof thedashesreflectingtheesss. 
goal of making optimal use of the available data. focusing on models that take the form of bayesian networks  this paper has  a  systematically compared  with regard to several criteria  four representative ways of exploiting data about users in general and/or individual users; and  b  introduced a variant of the ahugin adaptation method called differential adaptation  which represents a principled way of determining the speed with which the various aspects of a general model should be adapted to an individual user.
a	appendix: the differential adaptation method
as was noted in section 1  the simplest type of adaptive model that can be realized with ahugin is one in which a single equivalent sample size  ess  is specified for an entire bn. figure 1 illustrates the limitations of this method: the solid line  which is repeated from figure 1  shows the predictive accuracy of the adaptive model that used the method of differential adaptation; recall that this model computed and used the four esss shown under the x-axis  one for each experimental condition for the variable number of syllables. each of the dashed lines shows the results for a model that used a constant ess of 1  1  1  or 1  respectively. the results for the esss of 1  1  and 1 are noticeably worse than those for the ess of 1 and for differential adaptation; that is  the choice of an ess really does make a difference. the fact that the accuracy for the ess of 1 is only slightly worse than that for differential adaptation is not surprising  given that the esss computedby differential adaptationare fairly close to 1. the main contribution of the differential adaptation method here is to compute the right general level of the esss automatically  avoiding the need for trial and error on the part of the designer of the bn. differential adaptation also gains a bit of additional accuracy by computing a different ess for each experimental condition  in particular choosing a lower value for the condition  q-   in which individual differences are especially large  cf. 1 .
¡¡similarly  for each of the other variables examined in this experiment and the experiment mentioned in 1  differential adaptation consistently performed at least as well as the best fixed-ess model  deriving esss ranging from 1 to essentially 1. the differences from the fixed-ess models were in most cases smaller than those shown in figure 1. still  since differential adaptation is computationallyquite straightforward  see below   there appears to be no reason not to use it whenever it is applicable.
¡¡the rest of this appendix explains in more detail the differential adaptation method and the relevant aspects of the ahugin adaptation facility.1
¡¡suppose that a variable has possible states. to simplify notation  all mathematical expressions that follow refer to one particular configuration of states of the parent variables of . for this configuration  there are probabilities in the conditional probability table  cpt  for . in addition to storing these probabilities  ahugin maintains for each a dirichlet distribution  see  e.g.   heckerman  1  section 1 ;  olesen et al.  1   that represents the system's current expectationconcerningthe true vector of probabilities of which are simply the current estimates. the parameters of each such dirichlet distribution are as follows:  a vector of means ;
 an equivalent sample size  ess  denoted in the formulas as  .
¡¡the means are numerically identical to the cpt entries   but it will be helpful to denote them with when we are viewing them as parameters of the dirichlet distribution.
¡¡whenever a new observation is obtained in which the configuration of states of 's parents is realized  is incremented by 1 and the are updated according to the usual method for dirichlet distributions.
¡¡in the context of learning user models  the ahugin algorithm gives us the opportunity to specify a dirichlet distribution for each configuration of states of parent variables of each cpt in a bn for a new user . this opportunity can be exploited as follows if we have complete data from other users:
¡¡1. learn separate bns from the data  one for each previous user  using the standard maximum likelihood method for learning fully observable bns with known structure  see  e.g.   buntine  1  .
¡¡1. for each configuration of states of parent variables of a variable   each learned bn yields a vector of empirically determined conditional probabilities . these vectors can be viewed as a sample of vectors upon which we can base our expectation concerning the corresponding vector that we will obtain for a new user after collecting a lot of data on that user.
¡¡the question now is how we can represent this expectation as an initial dirichlet distribution with dimensions  as is required by the ahugin method. olesen et al.  describe a straightforward method for specifying a dirichlet distribution that comes close to matching a given distribution that is specified in another way. first  the means of the dirichlet distribution should match the means of the original distribution exactly. in our case  this implies that each initial mean should be defined as follows:
		 1 
¡¡that is  each is simply the mean of the cpt entries from the existing bns.
¡¡ideally  each of the variances of the dirichlet distribution should match the variance of the corresponding existing cpt entries. in general this goal will be unattainable  since there is only one degree of freedom available for determining the variance of the dirichlet distribution  namely the ess . olesen et al.  propose choosing the ess so that the  weighted  average of the variances of the dirichlet distribution  denoted with   equals the weighted average of the variances of the original distribution. given the formula for the variance of one dimension of a dirichlet distribution 
		 1 
we have the following formula for the weighted average variance:
		 1 
solving for   we obtain:
		 1 
¡¡to obtain the appropriate ess  we need only to replace in this formula with   the computedaverageof the variances in the empirically obtained cpts. each of these variances is given by the formula
		 1 
since has already been computed as the mean of the corresponding .
¡¡to compute the weighted average variance  we can likewise use as weights the values :
 1 
¡¡putting it all together  the most appropriate ess can be computed directly from the original cpt entries and the corresponding means as follows:
		 1 
references
 buntine  1  wray buntine. a guide to the literature on learning probabilistic networks from data. ieee transactions on knowledge and data engineering  1-1  1.
 friedman et al.  1  nir friedman  dan geiger  and moises goldszmidt. bayesian network classifiers. machine learning  1-1  1.
 greiner et al.  1  russell greiner  adam j. grove  and dale schuurmans. learning bayesian nets that perform well. in dan geiger and prakash p. shenoy  editors  uncertainty in artificial intelligence: proceedings of the thirteenth conference  pages 1. morgan kaufmann  san francisco  1.
 heckerman  1  david heckerman. a tutorial on learning with bayesian networks. technical report msr-tr-1  microsoft research  1. revised november 1.
 herlocker et al.  1  jonathan l. herlocker  joseph a. konstan  al borchers  and john riedl. an algorithmic framework for performing collaborative filtering. in proceedings of the 1 conference on research and development in information retrieval  1.
 jameson et al.  1  anthony jameson  barbara gro mannhutter  leonie march  ralf rummer  thorsten bohnenberger  and frank wittig. when actions have consequences: empirically based decision making for intelligent user interfaces. knowledgebased systems  1-1  1.
 jameson  1  anthony jameson. numerical uncertainty management in user and student modeling: an overview of systems and issues. user modelingand user-adaptedinteraction  1- 1  1.
 mu¡§ller et al.  1  christian mu¡§ller  barbara gro mann-hutter  anthony jameson  ralf rummer  and frank wittig. recognizing time pressure and cognitive load on the basis of speech: an experimental study. in julita vassileva and piotr gmytrasiewicz  editors  um1  user modeling: proceedings of the eighth international conference. springer  berlin  1.
 olesen et al.  1  kristian g. olesen  steffen l. lauritzen  and finn v. jensen. ahugin: a system creating adaptive causal probabilistic networks. in didier dubois  michael p. wellman  bruce d'ambrosio  and phillipe smets  editors  uncertainty in artificial intelligence: proceedings of the eighth conference  pages 1. morgan kaufmann  san mateo  1.
 pazzani and billsus  1  michael pazzani and daniel billsus. learning and revising user profiles: the identification of interesting web sites. machine learning  1-1  1.
 pearl  1  judea pearl. probabilistic reasoning in intelligent systems: networks of plausible inference. morgan kaufmann  san mateo  ca  1.
 segal and kephart  1  richard b. segaland jeffrey o. kephart. mailcat: an intelligent assistant for organizing e-mail. in proceedings of the third international conference on autonomous agents  pages 1  1.
 walker et al.  1  marilyn a. walker  irene langkilde  jerry wright  allen gorin  and diane j. litman. learning to predict problematic situations in a spoken dialogue system: experiments with how may i help you  in proceedings of the first meeting of the north american chapter of the association for computational linguistics  naacl'1   pages 1  seattle  wa  1.

multi-agent systems
multi-agent systems applications

an agent architecture for multi-attribute negotiation
catholijn m. jonker and jan treur
vrije universiteit amsterdam  department of artificial intelligence
de boelelaan 1a  1 hv amsterdam  the netherlands
email: {jonker  treur} cs.vu.nl   url: http://www.cs.vu.nl/{~jonker ~treur}

abstract
a component-based generic agent architecture for multi-attribute  integrative  negotiation is introduced and its application is described in a prototype system for negotiation about cars  developed in co-operation with  among others  dutch telecom kpn. the approach can be characterised as co-operative one-toone multi-criteria negotiation in which the privacy of both parties is protected as much as possible.
1  introduction
in  gutman and maes  1  the difference between competitive and co-operative negotiation is discussed. guttman and maes state that the competitive negotiations in retail markets are unnecessarily hostile to customers and offer no long-term benefits to merchants. essentially  in competitive negotiations the merchant is pitted against the customer in price-tug-of-wars. based on  forrester  1   in  gutman and maes  1  it is concluded that merchants often care less about profit on any given transaction and care more about long-term profitability  which implies customer satisfaction and long-term customer relationships. their analysis makes a strong case for co-operative negotiation for the retail market:
 ...the multi-attribute utility theory  maut   keeny and raifa  1   can help customers make complex buying decisions taking into account multiple factors including merchants' unique added value  e.g.  extended warranty options  delivery options  etc. . 
their argument is supported by  rosenschein and zlotkin  1   which makes clear that co-operative negotiation can be described as a non-zero-sum game where  as the values along multiple dimensions shift in different directions  it is possible for all parties to be better of. thus co-operative negotiation is a win-win type of negotiation. the consumer buying behaviour model  cbb   see
 gutman and maes  1   consists of six main stages: need identification  product brokering  merchant brokering  negotiation  purchase and delivery  and service and evaluation. the model discussed in this paper addresses the first four of these stages  where the product brokering is an integrated part of the entire brokering process and overlaps with the need identification. this is in line with normal procedures  as  cbb stages often overlap and migration from one to another is sometimes non-linear and iterative . the buyer contacts the broker agent  the broker agent provides the buyer with forms in order to determine the wishes of the buyer. then the broker matches products and suppliers against the wishes of the buyer presenting him with the best three options. the buyer can then select one of these proposals. a special buyer representative agent negotiates with the representative agent of the supplier to obtain the best configuration of the selected option. the different attributes of the object under negotiation  the possible values for each of those attributes  and the different wishes  profiles  of consumer and provider  allow for co-operative negotiation: co-operative negotiation can be seen as a decision-making process of resolving a conflict involving two or more parties over multiple interdependent  but non-mutually exclusive goals; cf.  lewicki et al.  1 .
   the multi-agent system in which the negotiation agent can be and has been applied consists of the following types of agents: human buyers  human dealers  buyer representative agents  dealer representative agents  broker agent. moreover  to model retrieval of information from databases  a number of components is used; one of them is the external world from which buyer
representative agents can retrieve third party information  consumer organisations like the aa of the us and the dutch anwb . furthermore  specific dealer-dependent dealer databases for all dealers are included  from which the dealer representative agent can retrieve information about the cars offered by that particular dealer. because of space limitation  this paper focuses on the negotiation process within this overall architecture. the generic agent architecture for multi-attribute negotiation was designed and formally specified using desire  as a refinement of the generic agent model gam  brazier et al.  1 .
   in this paper  in section 1 the most sophisticated component within the agent architecture  cooperation management  which models the negotiation process  is described in more detail. in section 1 the prototype system developed on the basis of the agent architecture is discussed; example results are shown. section 1 concludes the paper by a discussion.
1  the negotiation model
in multi-attribute negotiation a bid has the form of values assigned to a number of attributes. for example  if the negotiation is about cars  and the relevant attributes are cd player  extra speakers  airco  tow hedge  price  then a bid consists of an indication of which cd player is meant  which extra speakers  airco and tow hedge  and what the price of the bid is. in the current section the generic negotiation model is described; for instantiations  see section 1.
   to assess a bid of the other party  it is important to have evaluation methods. evaluation can be done at two levels: the level of each of the specific attributes  attribute evaluation   and the level of the bid as a whole  overall bid utility . taking this into account  some characteristics of the multi-attribute negotiation model presented here are:
  explicit reasoning about the negotiation strategy and co-ordination of the negotiation process
  evaluation of a bid takes into account both the attributes separately and the overall utility of the bid
  planning of a new bid takes into account both the overall utility level and the level of attributes separately
in particular  in the model it is possible to work on two levels: the level of the overall bid  and the level of each of the attributes separately. the negotiation model has been specified as a compositional structure within the component cooperation management of gam  brazier et al.  1 . globally speaking  the process runs as follows:
  for each negotiation round  first evaluations of the attributes of the previous bids are determined.
  then these evaluations are aggregated into overall utilities of these previous bids.
  next  it is determined which concession step is made for the next bid  expressed in terms of the overall utility; this provides a target utility.
  to obtain the next bid  given the target utility  first according to some distribution over attributes  target attribute evaluation values are determined  chosen in such a manner that they aggregate exactly to the target utility 
  finally  for each of these target attribute evaluation values  an attribute value is chosen that has an evaluation value as close as possible to the target evaluation value for the attribute.
in the last step  if only discrete attribute values exist  it may be the case that the target utility is not reached. however  if at least one of the attributes has continuous values  then this attribute can be chosen to compensate for differences that are created due to the mapping to discrete values for the other attributes. in our application  the price attribute is such a continuous attribute  and chosen to compensate for differences. in this manner bids are created that exactly match the target utilities. to realise the compositional process structure sketched above  at its top level the component cooperation management is composed of the five components in figure 1: negotiation coordination  attribute evaluation  bid utility determination  utility planning  and attribute planning. each of these components is discussed in more detail.

figure 1  the multi-attribute negotiation model
1  negotiation coordination
within the component negotiation coordination the negotiation process state is analysed  component process analysis  and the process is controlled  component process control . process analysis determines which of the following are true and which are false:
a  repetition of steps takes place: steps without enough progress  depending on the impatience factor  ¦Ð  which specifies the acceptable number of steps in which nothing changes 
b  a utility gap  larger than some threshold ¦Ø  remains;
i.e.  a significant difference between the utility of the own bid and that of the other agent's bid.
c  a configuration mismatch  larger than some threshold
¦Í  remains between the own bid and the other agent's bid.
here a configuration mismatch means that for at least one attribute  between the two values  in the two bids  a significant difference exists. depending on the outcome of the analysis within component process control the following actions can be decided upon:
1. start a next negotiation round
1. contact the user to discuss whether the concession factor  ¦Ã  can be changed.
1. contact the user to discuss whether the configuration tolerance  ¦Ó  can be changed.
1. communicate to the user that an agreement has been reached.
1. communicate to the user that the negotiation has failed  only when the user is unwilling to change the characteristics .
actionrepetitionutility gapconfig. matchnext roundnonodiscuss concession factoryesyesnodiscuss config. toleranceyesnonoreport successnoyesreport failureyesnotable 1 action decision table
1  attribute evaluation
evaluation of the attributes is made on the basis of the evaluation functions that are part of the user profile maintained within component maintenance of agent information of the agent. component attribute evaluation evaluates the attributes of available objects based on the preferences of the user represented by the agent.
   the evaluation functions either have a table form or another specific function description. a table form is used for discrete attributes such as accessories. specific function descriptions are used for continuous attributes such as mileage or price. the form of specific function descriptions are of a type such as 'linear'  or 'uphill'. for the attributes for which a specific  non-table  type of evaluation function is given  depending on this type  knowledge is specified to obtain the object evaluations.  currently  only specific function types are used that consist of linear parts  cut off between 1 and 1: linear function  normal distribution function  downhill function  uphill function.
   if desired  in all evaluations and utilities  the model supports that two aspects can be modelled separately and integrated: ease evaluation and ease utility eu and financial evaluation and financial utility fu. the latter aspect covers the financial rationality in the agent's behaviour. the former aspect models all other aspects within the decision making such as a resistance against more complicated transactions  even if in terms of economic gain they are more favourable . the balance between these two aspects within the overall evaluations is defined by the financial rationality factor ¦Ñ. if this factor is 1  then only the financial utility is taken into account  completely financially driven   if it is 1  only the ease utility  completely ease driven . any factor in between 1 and 1 defines the relative weight of the economic aspect compared to the ease aspect in the decision making. for example  for a certain accessory the financial aspect of the evaluation value is the cost it takes to provide it  both the price of the accessory and the cost of installing it .
1  bid utility determination
within the model  the utility ub of a bid b is taken as a weighted sum of the attribute evaluation values eb j for the different negotiant attributes denoted by j.
ub = ¦²j  w j  e b  j  
here the weights w j are relative importance factors based on the importance factors pk for the different attributes:
w j = p j / ¦²k p k
if a financial utility is used separately  then the above utility  called the ease utility eub  is determined on the basis of all attributes except price. financial utility fub is based on the financial balance gb for a given bid b:
gb = pb -  b -  ab
where b denotes the basic costs  the cost of the object without additional accessories  and ab denotes the additional costs of bid b  and pb price within bid b.
ab  =   ¦²j feb  j
that is based on the financial evaluations  feb j  of the values of the different attributes j. however  to be able to relate fub to the ease utility eub  fub  is the normalisation of the financial balance to a number between 1 and 1:
fub  j = gb / ¦Äb
the fraction ¦Ä is the fraction of the basic cost that is maximally additionally  to be  earned  e.g. 1  a maximum margin of 1% . some notes can be made.
  the financial utility fu is defined on the interval between 1 and 1 in such a manner that financial utility 1 means cost price plus maximal margin  b + ¦Äb +  ab .
  let b1 be the initial bid of the seller  then by taking price pb1 = b + ¦Äb +  ab1  the financial utility of this bid is
       fub1 =  pb1 - b - ab1  / ¦Äb = 1.
  by setting ¦Ä properly  the seller makes sure that  s he is not asking unrealistic prices.
  the financial utility is defined on the interval between
1 and 1 in such a manner that fub = 1 implies pb = b  + ab  i.e.  the cost price. so  if a buyer makes a bid b with pb   b  +  ab  then fub   1 from the perspective of the seller.
on the basis of the ease utility and the financial utility  the overall utility is determined as a weighted sum. here the weights are based on the financial rationality factor ¦Ñ  part of the dealer profile .
ub   =  ¦Ñ fub +    1 - ¦Ñ  eub
1  utility planning
for determination of the target utility tu the following formula is used within the model:
         tu  = ubs +  cs with ubs the utility of the own bid  and the concession step cs determined by
cs  =  ¦Â  1 - ¦Ì / ubs   ubo - ubs 
where ubo is the utility of the other agent's bid. in this formula the factor ubo - ubs expresses the current utility gap. the factor  1 - ¦Ì / ubs  expresses that the concession step will decrease to 1 if the ubs approximates the minimal utility ¦Ì. this ensures ubs ¡Ý ¦Ì. the factor ¦Â stands for the negotiation speed. the minimal utility is taken as ¦Ì =  1  -   ¦Ã with ¦Ã the concession factor  expressing a measure in how far concessions can be made. determination of the target utility can also address the ease and financial aspect separately  indicated by e or f added to the parameters . for each of these aspects the same model is used. for example  for the ease aspect the following  formula is used:
teu  =  eubs +  ecs      with
ecs  =  ¦Âe  1 - ¦Ìe / eubs   eubo - eubs 
in this formula ¦Âe is the negotiation speed factor for the ease part  and ¦Ìe is the minimal ease utility. similarly  for the financial aspect the target utility is:
tfu  =  fubs +  fcs   with
fcs  =  ¦Âf  1 - ¦Ìf / fubs   fubo - fubs 
the speed factors ¦Âe for ease and ¦Âf  for financial parts are based on the negotiation speed factor ¦Â and the financial rationality factor ¦Ñ as follows
¦Âe  =    1 - ¦Ñ  ¦Â       ¦Âf  =   ¦Ñ ¦Â
the minimal ease utility is taken as ¦Ìe  =   1  -   ¦Ã. the minimal financial utility is taken as ¦Ìf =  ¦Å / ¦Ä where ¦Å is the minimal financial margin. the explanation is as follows. if the minimal margin is achieved  then the price minp is
minp  =  ¦Å b  +  b  +  ab
given minp  the minimal acceptable financial utility can be calculated as follows:
     	¦Ìf      =   minp - b - ab  / ¦Ä b   =   ¦Å b /  ¦Ä b   =   ¦Å  /  ¦Ä
for example  if ¦Ä = 1  1%  and ¦Å = 1  1%   then ¦Ìf = 1 
i.e.  the dealer is not willing to sell with a financial utility lower than half of its maximal financial utility  based on the maximal margin ; a financial utility of 1 means selling against the cost price  i.e.  no margin at all  a financial utility of 1 means selling with a margin of 1% on the cost price.
1  attribute planning
the attribute planning process uses as input the target utility and determines as output the configuration for the next  own  bid in the following two main steps:   first  within the component target evaluation determination  for each attribute a target evaluation is determined.
  next  given these target evaluations per attribute  within the component configuration determination  a configuration for the next bid is determined.
target evaluation determination
target evaluations per attribute tej are determined in the model in two steps. first a basic target evaluation per attribute btej is determined in such a way that ¦²j w j btej = tu. then the target evaluations tej are combinations of the btej with the evaluations of the attributes in the bid of the negotiation partner. the basic target evaluation per attribute btej is determined according to the following format:
bte j  =  ebs  j +   ¦Áj / n   tu  - ubs 
here the ¦Áj can be chosen arbitrarily  and n is a normalisation factor. factor n is defined as the weighted sum of the ¦Á's with the relative importance factors as weights: n   = ¦²j w j ¦Áj. due to this normalisation factor  the utility determined as a combination of the target evaluations leads to exactly the target utility:
¦²j w j btej  = ¦²j w j  ebs  j +   ¦Áj / n   tu  - ubs  
= ¦²j w j ebs  j +  ¦²j w j  ¦Áj / n    tu  - ubs 
= ubs + 1/n  ¦²j w j ¦Áj   tu  - ubs 
= ubs + 1/n *n* tu  - ubs 
= tu
the choice for the ¦Á's is made as: ¦Áj =  1 - w j   1 - ebs  j . the first factor expresses the influence of the user's own importance factors  similar to the choice made in  benn  et al.  1  ; the second factor takes care that the target evaluation values remain scaled in the interval between 1 and 1. besides the influence on the target attribute evaluations as described  also a concession to the opponent's attribute evaluations is made. this depends on the configuration tolerance ¦Ó  as follows:
      	tej  =        1 - ¦Ó  btej +   ¦Ó ebo  j
if the configuration tolerance is 1  then only the user's importance factors are taken into account. if the configuration tolerance is 1  then with respect to the configuration maximal concession to the negotiation partner is made.
configuration determination
to determine a configuration for the next bid the following three steps are made.
  first  for each  attribute  given the target evaluation  attribute values are determined with an evaluation that is as close as possible to the target evaluation value.
  next  a partial configuration  price attribute not yet filled  is determined based on these closest values.
  finally  to complete the configuration for the next bid  also the price attribute value is determined.
the partial configuration is selected from the closest attribute values. if more than one choice with closest value is possible  then  if it is among the options  the value in the opponent's bid is chosen  otherwise the choice is made in a random manner. the partial configuration is completed by determining the price attribute value in such a manner that the overall target utility is achieved.
   within the dealer representative agent a simple possibility would be to take the target financial utility as the aim to be achieved. however  due to the discrete values of the accessory attributes  the ease utility will probably not be exactly achieved. the choice has been made that this difference is compensated in the financial utility. for example  if the ease utility of the partial configuration is lower than the target ease utility  then the dealer representative agent aims at a financial utility which is  in proportion  higher than the target financial utility.
   first the ease utility of the partial configuration is determined. next the financial utility that has to be achieved  afu  is determined  as the  weighted  difference between overall target utility and the realised ease utility:
afu  = tu  -   1 - ¦Ñ  up  e / ¦Ñ
where up  e is the ease utility of the partial configuration p. finally  the price attribute value is determined  as the sum of all costs and the fraction of the maximum margin given by the financial utility aimed for:
price = b + ap + afu ¦Ä b
1  implementation: example
a trace was generated on the basis of the data presented in the tables 1 to 1. in these tables   buyer representative  is abbreviated to br  similarly dr stands for dealer representative. basic negotiation parameters are depicted in table 1 above. the buyer representative only uses the  ease  evaluations and utilities; therefore  the special financial factors are not applicable in table 1. in table 1 the importance factors are depicted. in table 1  for the dealer representative the price attribute has no value  since it is only part of the financial utility function. within financial terms the importance factors are irrelevant.
negotiation parameterbrdrnegotiation speed ¦Â11impatience factor ¦Ð1configuration gap size in price ¦Í1utility gap size ¦Ø11concession factor ¦Ã11configuration tolerance ¦Ó11financial rationality factor ¦Ñnot applicable1minimal financial margin ¦Ånot applicable1maximal financial margin ¦Änot applicable1table 1  negotiation parameters in the example
	 ease  importance factor	br	dr
cd11extra speakers11airco11tow hedge11price1not applicabletable 1  importance factors   pk
in table 1 below the evalution descriptions for the different attributes are depicted.
evaluation description for  cd playerbr	drgood1.1fairly good11standard11meager11none1.1evaluation description for extra speakersbrdrgood1.1fairly good11standard11meager11none1.1evaluation description for airconditioningbrdrgood11fairly good11standard11meager1.1none1.1evaluation description for tow hedgebrdrgood11fairly good11standard11meager1.1none1.1evaluation description for pricebrdrfunction formdownhillnot applicablecritical value1not applicablesteepness-1not applicabletable 1  evaluation descriptions for the attributes
furthermore  the dealer representative also needs the financial evaluation descriptions for the different accessories and it needs to know the basic costs of the car under negotiation  in this case the basic costs are 1 . the dealer representative's financial evaluation descriptions are depicted in table 1 below.
accessorygoodfairly
goodstandardmeagernonecd111extra speakers111airco111tow hedge111table 1  financial evaluation descriptions for dealer
a trace of the negotiation process is depicted in the tables 1 and 1 below. the buyer representative's bid  his opinion of his bid and his opinion of the bid of the dealer representative in the previous round are presented in table 1 below.
brround 111closing:1 bid price111tow hedgemeagermeagermeagermeagermeagermeageraircomeagermeagermeagermeagermeagermeagerextra speakersgoodgoodgoodgoodgoodgoodcd playergoodgoodgoodmeagergoodgoodutility
own1.1.1.1.1.1dr's111111table 1  example negotiation process from buyer perspective
the dealer representative's bid  his opinion of his bid  and his opinion of the bid of the buyer representative in the same round are presented in table 1 below.
drround 111accept:1 bid price111tow hedgegoodmeagermeagermeagermeagermeageraircomeagermeagermeagermeagermeagermeagerextra speakersgoodgoodgoodgoodgoodgoodcd playerstandardstandardnonegoodgoodgoodutility
own111111br's111111table 1  example negotiation process from dealer perspective
note that the price attribute is monotonically increasing for the buyer' s bids  but for the dealer' s bids it does not monotonically decrease: from round 1 to 1 it increases  appearantly to compensate for a change in the cd player attribute from ' none' to ' good'  . the overall utilities attributed to the own bids for both buyer and dealer are monotonic  as may be expected from the negotiation model. however  this may not be true for the utility attributed by one of the parties to the other party' s bid. actually  from the perspective of the buyer  the dealer bid is getting a lower utility in round 1. what is perceived as a concession from one party' s perspective can provide a worse bid in the perception of the other party.
   note that the values in round 1 are such that  to the buyer representative's opinion  the utility gap has disappeared  and also the configuration gap is gone. the buyer representative  therefore  concludes after round 1 has been completed  that is: the dealer representative's reaction to his bid in round 1 has been received  that a match has been found  and asks the buyer he represents permission to close the deal instead of continuing with round 1. given the permission of his user  the buyer representative does not call out round 1  but sends to the dealer representative an acceptance of the previous bid of the dealer representative. the dealer representative now also asks his user  the dealer  to close the deal. given permission  the dealer representative finishes the deal with an acceptance.
   initially  the dealer asked 1 for the car without any accessories. for him  this would be ideal  scoring a 1% gain on the car. however  this bid is unacceptable to the buyer  who starts to negotiate. the agents quickly converge on the preferred values for tow hedge  airco  extra speakers  and cd-player  but hagle a few rounds over the price. in the final round  the buyer accepts the offer of the dealer having a car with a meager tow hedge  meager airco  good extra speakers  and good cd-player for 1 guilders. based on the consumer organisations prices for such accessories  the buyer payed 1 for accessories  and therefore  1 for the car without accessories. this means that the buyer was able to negotiate a reasonable price for himself. from the dealer' s point of view the deal is reasonable as well. he was able to sell a good cd player which he had in stock  and although he had to order the other accessories  the price still gives him a profit of 1  = price - basiccost - sum of accessories = 1 - 1 - 1 . this corresponds to a financial utility of 1 = profit / max financial margin * basiccost = 1 * 1 . the reason that his total utility is lower  1  is due to the low ease utility  it takes him rather some work to do equip the car . all in all  both are satisfied.
1  discussion
in  gutman and maes  1  a number of criteria and benefits are discussed of some different approaches to negotiation. for example  in the competitive negotiation system kasbah three negotiation strategies are mentioned: anxious  linear increase of bids over time   cool-headed  quadratic   and frugal  exponential . in the model presented here  these strategies can be used to determine the negotiation speed. another important issue discussed in  gutman and maes  1  is the argument for co-operative negotiation that merchants often care less about profit on any given transaction and care more about long-term profitability  which implies customer satisfaction and longterm customer relationships. that argument supports the importance of the following factors in our model for negotiation: configuration tolerance  consumer satisfaction   concession factor  profit   minimal financial margin  profit   and financial rationality  profit . furthermore  the remark that co-operative negotiation is a win-win type of negotiation is supported by our model in that consumers and providers both have an extensive multiattribute profile  importance factors  evaluation descriptions  that influence the outcome of the negotiation aiming to satisfy both parties.
   a main difference of our work to the work described in  benn et al.  1  is that in our approach it is possible to specify heuristics both for the overall utilities and for separate attributes  with their values and evaluations . in their approach no overall view is made; a compensation matrix is used to compensate a concession in one attribute by other attributes. in our approach it is possible to decide about the overall concession  in terms of the overall utility  in a negotiation step  independent of specific concessions for separate attributes. moreover  in their approach a neural  hopfield  network is used to find the compensations for attributes by an approximation process. in contrast  our approach uses explicit knowledge to determine the attributes of a new bid  which makes it more transparent and better explainable.
   in  sierra  et al.  1  an argumentation-based approach to negotiation is put forward. one of the issues that was left open is how the argumentation-based approach relates to utilities. this is in contrast to our approach where utilities play a main role.
   both a design description  formally specified in desire  and a prototype implementation of the architecture has been constructed and tested by a group of users. due to the various parameters making up a very detailed profile  the multi-attribute negotiation architecture for agents that is presented in this paper is more flexible with respect to user preference modelling than the existing approaches. a drawback may be  however  that to acquire such a detailed profile users may need some patience. an issue for further research is to develop automated support for this acquisition process  for example  on the basis of information acquired by monitoring the user.
   the model respects the privacy of both parties  since profile information is kept local  and still is capable of adjusting to the profile of the opponent if such is desired by the user. the model allows for flexible heuristics both for the overall utilities and for the attribute evaluations. an issue for further study is how relationships between evaluations of different attributes can be exploited  for example to express that a buyer only has a high evaluation value for speakers if a cd player is present.
references
 benn et al.  1  w. benn  o. goerlitz and r. neubert. enabling integrative negotiation by adaptive software agents. in: m. klusch  o.m. shehory  and g. weiss  eds. . cooperative information agents iii. proceedings of the third international workshop on cooperative information agents  cia'1  lecture notes in ai  vol. 1  springer verlag  1  pp. 1.
 brazier et al.  1   brazier  f.m.t.  jonker  c.m.  and treur  j. compositional design and reuse of a generic agent model. applied artificial intelligence journal  vol. 1  1  pp. 1.
 forrester  1   forrester research report. affordable intimacy strengthens online stores  1.
 gutman and maes  1  r. guttman  and p. maes. cooperative vs. competitive multi-agent negotiation in retail electronic commerce  in: proceedings of the second international workshop on cooperative
information agents  cia'1   paris  1.
 keeney and raifa  1  r. keeney  and h. raiffa. decisions with multiple objectives: preferences and value tradeoffs. john wiley & sons  1.
 lewicki et al.  1  r. lewicki  d. saunders and j. minton. essentials of negotiation  irwin  1.
 rosenschein and zlotkin  1  j. rosenschein  and g. zlotkin. rules of encounter: designing conventions for automated negotiation among computers. mit press  1.
 sierra et al.  1  c. sierra  n.r. jennings  p. noriega  and s. parsons. a framework for argumentation-based negotiation. in: m.p. singh  a. rao  and m.j.
wooldridge  eds. . intelligent agents iv. proceedings of the fourth international workshop on agent theories  architectures and languages  atal'1. lecture notes in ai  vol. 1  springer verlag  pp. 1.
a multiagent system for helping urban traffic management
luis a. garc¡ä a and f. toledo
universitat jaume i
 castello¡än  spain garcial  toledo  icc.uji.esabstract
this paper describes the mashgreen dm prototype following three goals: 1  the identification and implementation of the tasks related to urban traffic control that use deep reasoning mechanisms as main tools for their resolution. the chosen model for explaining urban traffic behaviour is a qualitative model  which includes among its main features their low temporal and spatial computational costs. 1  the definition of a functional architecture with soft real time constraints that integrates the developed tasks. a specilized component named agent  composed by four functional modules executes every task. these modules are the following ones: communication protocols  methods  agent specilization   data space and control. this architecture verifies that the execution performances of every agent are not compromised by the inclusion of new agents in the system  or by the interactions due to the active system agents. 1  the implementation of a prototype in a high performance computational architecture  a beowulf computer system.
1	introduction
in the last two decades there was a broad interest in the research and development of new methods and tools suited to intelligent traffic systems  its . however  the amount of public funds devoted to this action has been continually reduced. the main reason is that a small number of enterprises dominate the market of urban traffic control systems  utcs . current utcs  including both  software and hardware components  are closed systems in the sense that they belong to the enterprises that sell them. the cities which adopt these systems have their traffic operational enlargement possibilities seriously constrained by high economic cost.
¡¡nevertheless  the great development in the telecommunications and information technologies area  is promoting a change of mentality about the development of new its. this change is being used by the european union to try to open the monopolies to the competence  as much in infrastructure supply as in the provision of services.
¡¡in the usa the workshop in support advanced traffic management systems  atms  held in florida  may of 1  funded by the us department of transportation and the federal highway administration  pointed out the current trends in the development of new atms:
the development of traffic models and the corresponding copyright of the software used to programming them. this development involves the use of quality public software  mainly free software foundationsoftware  to programming existing and new traffic models.
the application of models to deal with lost of significant data to help traffic decision taken. it is important to continue the research on traffic flow and data fusion from different kinds of traffic sensors.
the development of models and algorithms for dealing with real time characteristics. it must be identified which are the real-time operative constraints related to every task in atms.
the search of models to perform dynamic settings of traffic signals. it is proposed to develop advanced traffic models related to real time traffic surveillance and automatic incident detection.
in order to follow these trends  the mashgreen dm prototype  a multiagent system for helping urban traffic decision taken using distributed memory  prototype is developed and described in this paper. the organization of this paper is as follows. section 1 describes the ai architectures that are being applied to traffic control. an urban traffic deep reasoning mechanism is exposed as a basic tool to deal with the above mentioned trends in atms. in section 1  the main features of the mashgreen dm prototype are exposed  including the definition of an abstract architecture suited to their agents. in section 1 the implementation and the main results of the execution of this software prototype in a beowulf cluster system is exposed. the paper finishes with the main results achieved.
1	ai architectures in utcs
current utcs are generally composed of two layers. a first layer uses quantitative models  data and algorithms. a second layer uses intensively the control engineer experience. given the complexity and the big size of the domain of the urban traffic control problem  the supervision and actions of these engineers must be continuously provided. therefore  the two layers utcs are insufficient for achieving an adequate control  bell et al.  1 . this analysis has led to several authors to introduce knowledge based systems  kbs  in the utcs architecture  foraste and scemama  1; bell et al.  1; ambrosino et al.  1 .
¡¡the prototypes developed up to now have been influenced by two factors: the experience learned in the implementation and evaluation of previous prototypes  considering the technologies used to manage the functionality of the system as well as the knowledge representation used  and the broad availability of faster and cheaper computers  therefore  the responses can be given early and it is possible to add new capabilities to the prototype .
¡¡the first kbs applied to traffic control  like the sage system  foraste and scemama  1   have a shallow reasoning mechanism  that is big sets of cause/effect rules implemented in a classical functional architecture of production systems. this kind of knowledge representation is very fragile. the cause/effect rules typically reflect empirical associations derived from experience  rather than a theory of how the device under diagnosis actually works  jackson  1 . therefore  several authors proposed the integration of a model of urban traffic behaviour in the prototypes  i.e. the integration of a deep reasoning mechanism for urban traffic  moreno et al.  1; ambrosino et al.  1; irgens et al.  1 .
¡¡the second generation kbs integrate a deep model to explain the behaviour of the system. besides it  they usually adopt functional collaborative architectures to integrate their components. the blackboard architecture  carver and lesser  1  was used in the intelligent utcs prototype developed under the drive i & ii european strategic programs  ambrosino et al.  1 . nevertheless  these prototypes were developed and implemented using conventional computers  although the underlying theory on blackboard systems was to use a shared memory multiprocessor computer . this was due because  although there were a broad availability of shared memory parallel computers  the tools needed for programming them were not evolved at the same rate. due to the great effort to develop better shared memory programming tools  the distributed systems were getting more significance because their lower economic cost  their performances close to the shared memory parallel computers and the wide availability of public domain tools  as mpi  for programming them.
¡¡moreover the prototypes based on blackboard models have a strong dependency of every component with respect to the rightness and integrity of the information stored in the blackboard  as much as its great generality  what is its strength and weakness  i.e. it is very difficult to forecast the execution sequence of their components. therefore  it is needed a new functional collaborative architecture to reduce in a significance way the result and data dependency on execution among their main components.
¡¡the multiagent architecture fulfills these needs. the kits system  irgens et al.  1  implements an architecture called supervised cooperative agents built on features of the iutcs prototype. the key point introduced in the kits system is to split the urban network in different areas. every area is composed of a set of elements. the set of elements of each area requires a common analysis and operation process  i.e. it is an environment based architecture. each area is managed by a different agent. the prototype exposed in this paper uses a different approach. every agent is able to see the whole urban network. a very reliable and fast deep model reasoning is used to understand the evolution of the urban traffic. communication among agents are performed to share knowledge and control actions. the next subsections expose the deep knowledge reasoning model used and its applications on computing several urban traffic control operations.
1	the deep reasoning model
the main idea behind its definition is to model the spatiotemporal fluctuations in traffic levels by defining a discrete qualitative space. every point with the same density of vehicles define a qualitative region. the spatio-temporal limit that divide two adjacent regions is represented by a straight line. the vertexes of each qualitative region are events which represent changes in the dynamics of the system: the appearance or disappearance of qualitative regions  the change from increase to decrease in the size of a qualitative region and so on. in this way  it is possible to achieve entities with cognitive meaning due to the selection of events as primitive ones that represent the evolution of the system. the urban traffic network is modeled as a set of objects  streets  intersections  traffic lights  inputs  outputs  etc.  that have associated parameters. the evolution of these parameters is described by uni- or bi-directional constraints. this qualitative simulator is broadly explained in  moreno et al.  1 .

figure 1: temporal qualitative representation of a queue generation process due to the change from red to green in its
traffic light
¡¡the evolution of the urban traffic is achieved by using the qualitative simulator and data preprocessed from sensors. they are both necessary because the current traffic status cannot be obtained just from sensors mainly for two reasons.
first  the sensors usually integrate in periods  therefore current information from sensors is not always available. secondly  there is a limited number of sensors due to economical and operational restrictions therefore  sensors give only a small part of the information necessary to reconstruct the current traffic status. when sensor data arrives  the actual traffic status is calculated by reconstructing all the events produced during the last temporal interval without real sensor data. the time overhead of the adjustment process between the simulated and the reconstructed traffic status is small due to:  1  the time complexity of the qualitative simulator is small  quadratic on the number of intersections  segments and the length of the simulation interval in the urban network   i.e.  the simulator runs much faster than real time;  1  the length of the temporal interval without real sensor data is also small  usually five minutes .
1	application to utcs capabilities
the deep reasoning model previously exposed can be applied to several utcs capabilities: preprocessing and monitoring  detection and diagnosis of problems  short term prediction and the search of suitable control operations  among others. the function for preprocessing and monitoring translates data from sensors into the qualitative representation described. in this way  a qualitative representation of the system independent of the sensors is obtained  which allow us to use data from several types of sensors. the current state of the system is generated by using qualitative simulation from the previous qualitative state  instead of using direct analysis of sensor data. the qualitative simulation from the previous state will give a whole image of the state of the system assuming that the previous state is correct  the prediction process is correct  and no unpredictable events  i.e. urban traffic incidents  have happened during the simulation. sensor data is used to verify these facts when they are available.
¡¡the function for detection and diagnosis of problems analyzes the past and present qualitative states of the system to detect problems. this task should not consider transient problems. on the other hand  a problem belonging to a zone must not be detected as the sum of the problems over the spatial components of the zone. a hierarchical classification of urban traffic problems based on the general representation formalism  equator  1   an extension of the event calculus of kowalsky with temporal granularity and continuous change  is used to accomplish this task. the matching between the traffic status reconstructed with real sensor data and the traffic status provided by the qualitative simulation is used to detect incident situations  garc¡ä a  1 .
¡¡the function for prediction predicts which would be the qualitative state of the system at short and medium terms. this task is done by supposing that the previous states are correct  the prediction process is correct  and have not occurred urban traffic incidents during the prediction. the low computational cost of the simulation qualitative process allows this task to be done. the aim is to detect the future problems that will arise if the current control strategy is kept. once this overall state is computed then the system must look for problems. if there are enough detected problems then the system should search for solutions for minimizing them. this task does not need to perform a diagnosis of urban incidents process  because future detected problems are caused by bad regulation traffic settings. this behaviour is very important for an utcs because it should have the capacity to anticipate problems. for example  one of the most common actions is to prevent a primary congestion  which has arisen as a result of the excess of traffic volume  turning into a secondary blockage. this blockage can be due to a growing queue at an intersection located afterward  with the consequent extension of the blockage over other urban network zones.
¡¡the last function exposed is the search of suitable control operations. if the detected problems are due to bad regulation traffic settings  then the system tries to compute other traffic settings that minimize these problems. the solution mainly consists of correcting the global effects of these bad control actions  which usually is more complicated than simply to remove the bad control actions. this is because the implementation of local solutions will produce undesirable effects  for example  that these problems will disappear from a zone but will appear in other zones of the urban network. the length reached in a traffic queue is completely determined by two conditions: the traffic status when the traffic light is green  and 1  the time allowed for red light. therefore  it is necessary to know which are the possible red times for every intersection in the system. there are eight possible values for the red time of every input link to an intersection. the split of an intersection is defined as the set formed by the active red time value of every one of its input links. the set formed by the splits of all the intersections is known as a traffic plan. it is impossible to evaluate exhaustively every traffic plan  because its temporal complexity is traffic plans  where n is the number of intersections. the size of this search space is drastically reduced by using two strategies:  1  to sort the set of intersection splits in relation with the red time allowed to its main direction; and  1  to apply a branch and bound method limited to a maximum time for execution. the method consists of the qualitative simulation of the urban traffic by evaluating the profits that it can be obtained by changing the splits of the intersections in relation to their qualitative evolution  garc¡ä a  1a . this method  with lightly modifications  can also be applied to compute other kind of control actions: values for coordination of intersections  and values for the length of the working cycles in groups of intersections  garc¡ä a  1b .
1	the mashgreen dm prototype
the mashgreen dm prototype is a collaborative software architecture developedfor urban traffic management tasks. its main behaviour features are the following:
it works with soft real-time deadlines. the execution of its tasks are interrupted at periodic time  except exceptional situations .
it is software reusable. it can integrates tasks with different computational costs.
it contains a heterogeneous and distributed computer implementation.
¡¡the prototype integrates software agents to perform several tasks: monitorization and data preprocessing  short-medium term prediction of urban traffic  bad regulation urban traffic problems identification  urban traffic incident detection  continuous search of best urban traffic plans and cycle lengths  the coordination of the execution of the agents  and a friendly interface to the human operator. the actions allowed for the prototype to urban control are: the automatic and manual execution of the best control actions proposed by the prototype and the punctual modification of the working features of whatever controlled element in the urban network  proposed by the human operator in any moment. therefore  the main objective of the prototype is to coordinate skills  knowledge  plans and experience among several agents to monitorize  propose and execute control actions that could improve the urban traffic status.
¡¡four design decisions were taken in the development of the prototype: 1  organization and distribution of the data among agents  1  integration of tasks with different computational costs  1  implementation of a unique and common temporal reference for every agent of the prototype  and 1  the definition of an agent software architecture to be shared by every agent of the prototype.
1	data organization and distribution
there are two kinds of data: static  does not change on execution  and dynamic  change on time . there were two options to organize the data of the prototype: 1  store all the data in the same location  e.g. using a blackboard organization  or  1  assign different data subsets to different agents  where every agent is responsible of the integrity and correctness of the data that stores. the first option has the advantage that every agent can access to static and dynamic domain data at any time  but it also needs a complex maintenance of the data coherence. the second option overcomes this problem  but it introduces a latency in data request between agents. however  this second option also overcomes the strong centralized component that is the blackboard.
¡¡a deep study of the data dependencies among the agents shows that there are a few data which can be accessed simultaneously. moreover  in these cases  the data access is for reading operations. therefore  the option chosen is to replicate static data in every agent  while dynamic data are assigned to the agents that make the best use of them.
1	execution mode
current trends in ai distributed programming pointed out the high interest in the application of distributed control methods. in these methods every agent knows when and how to perform its work. nevertheless  the choice of a lightly centralized control has several advantages in this application domain: 1  the task of the agents must be synchronized every time the sensor data arrives to the system  therefore a coordination agent can organize these synchronizations  1  the inner clocks of the agents must be synchronized to avoid lack of coherence between the real system and the controlled system implemented in the prototype  so a coordination agent can provide the temporal referee for every agent of the prototype  and 1  a coordination agent can be used to monitor the prototype on execution and for storing the configuration parameters of the prototype  so this feature allows us to integrate fault tolerant mechanism and to perform dynamic adding and deleting of agents. these behaviour features can be also implemented with a distributed control  but it requires a deeper knowledge in the evolution of the execution of the prototype. therefore  the option chosen is to develop a first prototype to be improved in those undesirable behaviours as result of its later evaluation.
1	common temporal reference
the mashgreen dm prototype implements a synchronization mechanism to maintain a common temporal clock value for every component of the prototype. this mechanism is based on the following characteristics: 1  the basic temporal unit is the second  1  the interconnection network transmission time for a single message of whatever size is less than one second  1  there is an agent  the coordination agent  that contains the right value for all other agents of the prototype  and 1  there is possible to apply communication primitives to perform barrier synchronization and broadcasting. the applied method is the following:
1. the coordination agent sends at time a broadcast message to request for time synchronization.
1. every agent receives the request and sends its agreement to the coordination agent. then  it waits until the reception of the time value message from the coordination agent.
1. the coordination agent send at time the time value message when it has received the agreement message from every agent of the prototype.
¡¡every agent that is in wait state must guarantee response to whatever message received from other agents. the returned message must notifies that the original receiver agent is executing a synchronization barrier. in this way  it is prevented deadlock situations between agents of the prototype. the method exposed has some drawbacks. the final value stored in every agent is or due to the latency in the reception of the time value message sent by the coordination agent. but this is not important due to the application domain features. another drawback is that there is an unbalanced wasted time on the time waited for the agents until the last of them had arrived to the barrier. therefore  to avoid these undesirable behaviour  the synchronization method is executed only at the beginning of the execution of the system and every time there were dynamic agents be added or deleted in execution time.
1	agent architecture
the software architecture of every agent is composed of four modules to deal with communications  methods  data workspace and control. the communication module implements the communication primitives  broadcasting  barrier synchronization  isolated synchronous/asynchronoussending and receiving of messages . the methods module implements two kind of methods: primary methods and secondary methods. primary methods represent the specialization skills of the agent. secondary methods implements administrative work for the agent  which can be inner tasks  coherence maintenance of its data workspace  and outer tasks  knowledge coherence with the beliefs of other agents  synchronization tasks among agents and analysis of alerts . every data belonging to the knowledge of the agent is stored in the data workspace module that is organized as a blackboard. finally  the control module takes the decision on the action to be done at any moment depending on actual time  the messages received and the specialization skills of the agent.

figure 1: module decomposition of an agent
¡¡the interaction among these modules can be described by using the following formal notation: an agent of the mashgreen dm prototype is a tuple of eight components:
where	 
¡¡¡¡¡¡¡¡¡¡¡¡represents the initialization task of the agent  is a function that returns the common virtual time of the system    i.e. the local time in an agent is the virtual time common to every agent  is the set of possible agents identification  is the finite set of kind of messages that an agent can receive or send  is the finite set of communication primitives the agent can use  is the function that returns the active agents at the common temporal time   and is the function that selects which message to analyze at any moment given the active set of received messages. the function defines a total order among the messages received that must fulfill two basic properties: liveness  i.e. every received message must be analyzed or effectively deleted  and deadlock free  i.e. it must not be possible to cause a deadlock situation between two or more agents. the definition of the components and must be common to every agent belonging to the same multiagent system.
¡¡the formal definition of the best urban traffic plan agent is given as an example of the application of the above formal definition of the agents. in this agent the primary method is calculate traffic plan. the secondary methods are:  1  startup agent which prepares the agent to be included in the set of active current agents   1  cease agent which prepare the agent to be deleted of the set of current active agents   1  external action to deal with external control actions performed by the human operator   1  chg mode which set up the way that the results are communicated to other agents  and  1  monitor which measures and communicates to the coordination agent the main behaviour features in the execution of this agent.
¡¡messages from other agents can be receivedwhen the agent is idle or when the agent is executing one of its methods. the function is defined in both situations. there is no mutual data dependency between this agent and whatever other agent  so this function is deadlock free. the liveness property is also fulfilled because more important messages related with the evolution and control of the traffic status are analyzed earlier  and as result of this analysis  other messages are deleted from the active set of messages received.
1	implementation issues
the mashgreen dm prototype has been implemented in a beowuf computer network. this kind of computers are composed by low cost hardware components  commonly personal computers. they are programming using distribution free software  commonly linux and public communication libraries. the communication workload is determined only by the application on execution. a unique node of the cluster has communication with the output network from the cluster  so the nodes of the cluster only execute tasks belonging to the cluster. the beowulf cluster used is composed of one server  a biprocessor personal computer at 1 mhz  and 1 working nodes  which are personal computers working at 1 mhz. there are two active interconection networks in the system  a fast ethernet one running at 1 mbits per second  and a high performance one running at 1 gbits per second. the operating system running in the beowulf cluster is linux and the programming language used for programming the agents is constraint logic programming extended with linda distributed programming model and tcl/tk script language interfaces.
¡¡the interface agent runs on the server of the cluster because this agent must interact with the human operator of the prototype. the rest of agents implemented run on different working nodes of the cluster. another working node of the cluster is used to maintain the communications in the linda model. the fast ethernet network is used for performing the communications between the agents of the prototype. this network has enough capacity because the urban traffic domain features  the lower simultaneously number of messages sent  and time needed for its transmission is not a critical feature for the agents. moreover  the fast ethernet is a standard network model cheaper than the high performance network.
¡¡every agent of the mashgreen dm prototype has been evaluated using isolated and collaborative off-line executions in laboratory tests. their executions show a stable behaviour working with different input data sets with and without the interaction with the human operator  in  garc¡ä a  1a  it is analyzed the best urban traffic plan agent and in  garc¡ä a  1b  it is analyzed the best cycle length agent . the coordination agent stores the monitoring messages sent by the rest of agents. these messages are stored in disk for later analysis. figure 1 shows an example of how this analysis is done.

figure 1: relationship between the time used to the execution of the primary method of the most relevant agents  vertical axis  with regard to the time available when data from sensors are not available  every 1 seconds  horizontal axis . the graphic shows that the behaviour of every agent is stable
1	conclusions
multiagent systems are a relatively new kind of ai architectures applied to utc that has provideda small number of prototypes up to now. the kits prototype is the most referenced. in kits the urban network is divided in zones. every zone is associated with an agent that deals with every feature of its area. this is an important difference with the mashgreen dm prototype because  in the mashgreen dm prototype every agent has a domain that includes the complete urban network. therefore  the results provided by its agents have a global view of the urban network. these agents operate by using a deep model of urban traffic which has a very low temporal computational cost. besides that  the mashgreen dm prototype provides methods to integrate tasks with different computational cost. therefore  it is possible to integrate software previously developed. every agent of the prototype has the same architecture. this architecture is divided in four modules. the first module deals with the definition and implementation of the communication mechanism common to every agent. the second module stores the data needed to obtain its operational objectives. the data distribution among the agents allows us to increment the reliability of the system in the presence of crashed agents. moreover  this data distribution does not significantly decrease the performances of the system  but it needs the following two conditions to be hold:  1  the agents know where every information is located: and  1  the agents know how the information is represented  i.e. they share the same data structures. the third module stores the methods suitable to be executed. these methods are primary  representing the main operational objectives of the agent  and secondary  representing administrative work for the agent. the last module deals with the control of the agent  i.e. what to do in every moment. the definition of these modules is simple to allow us the easy integration and cooperation between the agents of the prototype. the complex mechanism of their acts are settled by an inner way  depending on how these four modules are implemented and their interactions.
¡¡the mashgreen dm prototype has been implemented in a multiprocessor distributed computer that has three main features:  1  it has an low economic cost;  1  it has a good level of computational performances; and  1  there are stable public domain tools for programming them. the behaviour of this prototype in execution is stable  i.e. the prototype works well in laboratory tests.
acknowledgments
this work is partly supported by the spanish cicyt project tap1-c1 and bancaixa project p1-1.
references
 ambrosino et al.  1  g. ambrosino  m. bielli  boero m.  mastreta m. application of artificial intelligence and expert systems to traffic control. advanced vehicles and infrastructure systems  john wiley & sons  1.
 bell et al.  1  m.c. bell  g. scemana  l.j. ibbetson. claire: an expert system for congestion management. advanced telematics in road transport  proceedings of the drive conference:1  elsevier  1.
 carver and lesser  1  n. carver  v. lesser. the evolution of the blackboard control architectures. expert systems with applications  special issue of the blackboard paradigm and it's applications  1   1.
 equator  1  equator final. esprit p. 1  1.
 foraste and scemama  1  b. foraste  g. scemama. surveillance and congested traffic control in paris by expert system. second iee conference on road traffic control  london  1.
 garc¡ä a  1  l. a. garc¡ä a  f. toledo. urban traffic incident detection using qualitative data and temporal intervals. in proc. of the ic-ai  las vegas  usa  june 1.
 garc¡ä a  1a  l. a. garc¡ä a  f. toledo. an agent for calculating the best urban traffic plan constrained by soft temporal deadlines. in proc. of the soco/isfi-1  paisley  scotland  june 1.
 garc¡ä a  1b  l. a. garc¡ä a  f. toledo. an agent for providing the optimum cycle length value in urban traffic areas constrained by soft temporal deadlines. in proc. of the iea/aie-1  budapest  hungary  june 1.
 irgens et al.  1  m. irgens  c. krogh  h. traettebers. model based collaboration architectures for traffic control. advanced vehicles and infrastructure systems  john wiley & sons  1.
 jackson  1  p. jackson. introduction to expert systems. addison-wesley publishing company  1.
 moreno et al.  1  s. moreno  f. toledo  f. rosisch  g. martin. qualitative simulation for temporal reasoning in urban traffic control. qualitative reasoning and decision technologies  n. piera carrete and m.g. singh editors  cimne  barcelona  1.

multi-agent systems
multi-agent systems

bidding languages for combinatorial auctions

craig boutilier
department of computer science university of toronto
toronto  on  m1s 1  canada cebly cs.toronto.edu
holger h. hoos
department of computer science
university of british columbia
vancouver  bc  v1t 1  canada hoos cs.ubc.ca

abstract
combinatorial auctions provide a valuable mechanism for the allocation of goods in settings where buyer valuations exhibit complex structure with respect to substitutabilityand complementarity. most algorithms are designed to work with explicit bids for concrete bundles of goods. however  logical biddinglanguages allow the expression of complex utility functions in a natural and concise way. we introduce a new  generalized language where bids are given by propositional formulae whose subformulae can be annotated with prices. this language allows bidder utilities to be formulated more naturally and concisely than existing languages. furthermore  we outline a general algorithmic techniquefor winnerdeterminationfor auctionsthat use this bidding language.
1	introduction
combinatorialauctions cas have been proposedas a means of dealing with the allocation of goods to buyers whose preferences exhibitcomplex structurewithrespect tocomplementarity and substitutability  rassenti et al.  1; rothkopf et al.  1; wellman et al.  1 . instead of sellingitems individually  the seller allows bids on bundles of items  allowing biddersto deal withthe entitiesof direct interest and avoid the risk of obtaining incomplete bundles. given a set of combinatorial bids  the seller then decides how best to allocate individual goods to those bundles for which bids were placed  with the aim of maximizing revenue. because bundles generally overlap  this is-conceptually-a straightforwardoptimization problem  equivalent to weighted set packing. as a result  optimal winner determinationfor cas is np-complete  rothkopf et al.  1 .
¡¡by expressing her preferences  prices  directly over bundles  a potential buyer can  in principle  very accurately reflect her utility function  regardless of its structure. in practice  however  specifying explicit bids over all relevant bundles may be difficult: many utility functions will require the specification of a number of bundle bids that is exponential in the number of goods of interest to the bidder. this is especially true for utility functions involving the complementaritiesand substitutabilityforwhichcas are best-suited. in contrast  the logical structure of a complex utilityfunction might allow such preferences to be expressed relatively concisely in a suitablelanguage. several researchers have proposedmechanisms for expressing bids logically  sandholm  1; 1; hoos and boutilier  1; nisan  1 .
¡¡in this paper  we describe a generalized language for expressingbids that captures the most important elements of existing bidding languages. in our logical combination of bids and goods model  one specifies a bid using a logical formula  but is allowed to associate prices with arbitrary subformulae. for example  suppose in an auction for shipping capacity a bidder can send her shipment using two standard containers  and   or one oversized container . the shipment has an inherent value of   but the convenience of using an oversize container is worth . we can express a suitable bid for services as in our language  capturing the overall value of 1 for satisfying the requirement   as well as the premium of 1 for the oversized container. we will see examples like this below where our language allows the logical structure of a utility function to be expressed directly within a bid. furthermore  our language allows one to make theveryimportantdistinctionsbetween sharableandconsumable goods  unlike existing bidding languages. we show that our language affords complete expressiveness  and that for certain natural classes of utility functions  it can express bids exponentiallymore compactly thanexistinglanguages. in addition  we argue that it provides a natural and concise mechanism for expressing complex bids.
¡¡we also propose an algorithmic framework for solving the winner determination problem for a set of bids expressed in our generalized logical language. we formulate a stochastic search procedure that works directly with our logical bids  sidestepping the problem of converting a logical bid into a  potentially  exponentially  large number of explicit bids. though we have yet to study its computational properties  we expect this approach to offer a significant advance over existing algorithms.
¡¡we briefly review cas and logical bidding languages in section1. insection1 we present ourgeneralized logical bidding language  describing its syntax and semantics  discuss various properties of this language  and illustrate its ability to handle certain types of utility functions much more naturally and concisely than existing logical languages. in section 1  we describe a stochastic local search procedure that exploits the structure of our logical bids to search through the space of bid allocations to solve the winner determination problem. we conclude in section 1 with a discussion of future work.
1	logical languages for schematic bids
in this section  we briefly review cas and prior proposals for logical bidding languages.
1	combinatorial auctions
we suppose a seller has a set ofgoods tobe auctioned. potential buyers value different subsets or bundles of goods    and offer bids of the form where is the amount the buyer is willing to pay for bundle . given a collection of bids   the seller must find an allocation of goods to bids that maximizes revenue. we define an allocationto be any such that thebundles making up are disjoint. the value ofan allocation is given by . an optimal allocation is any allocation withmaximal value  taken over the space ofallocations . the winner determinationproblem is that of finding an optimal allocation given a bid set . we sometimes consider assignments of goods to bids. assignment induces allocation whose bids are those that have been assigned all goods  i.e.   .
¡¡the winner determination problem is equivalent to the weighted set packing problem  rothkopf et al.  1  and as such is np-complete. algorithms for weighted set packing and related combinatorial problems can be used for winner determination. search algorithms-both complete methods  fujisima et al.  1; sandholm  1  as well as stochastic techniques  hoos and boutilier  1 -have been proposed intheai literatureand have provenquitesuccessful at solving medium-sized problems. though the problem is known not to be approximable in polynomial time  the afore-mentioned stochastic approximation technique tends to find optimal solutions very quickly for problems that can be handled by the complete methods.
1	logical languages
most workon combinatorialauctionsassumes that a bidisexpressed usinga simplebundleofgoodsassociated witha price for that bundle. such a bundle naturally captures the complementarities among the goods within that bundle. however  a buyer with a complex utility function will often need to express multiple bundle bids in order to accurately reflect her utility function.
¡¡logical bidding languages can overcome this by allowing a bidder to express complex bids in which the logical structure of the utility function is captured. there are two distinctclasses of logicalbiddinglanguages intheliterature: languages that allow logical combinations of goods as formulae  and associate a price with each such formula  we call this the g family of languages ; and languages that allow logical combinations of bundle bids as formulae  where the subformulae  or atomic bids  themselves have prices associated with them  we call this the b family of languages . we discuss these briefly in turn in this section  but refer to the cited papers for further details. in what follows we assume a set of goods over which bids are expressed.
¡¡an g language is one in which logical formulae are constructed from goods; that is  goods are taken as atomic propositionsand are combined using logical connectives to express a bid. a price is attached to this formula expressing the amount the bidder is prepared to offer for the satisfaction of that formula. such languages can be used to capture some of the logical structure of a utility function. the language posg proposed by hoos and boutilier  is of this type  with the restriction that only positive formulae  i.e.  without negation  are considered. formally  if then posg ; and if
	pos	pos	pos
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡g   then g and g . a logical bid is simply a formula posg and an associated price . semantically  an assignment of goods to this bid satisfies the bid if the corresponding logical formula is satisfied viewing the assignment as a truth assignment  i.e.  those goodsassigned to the bidare  true  and those not are  false  . as an example  should a bidder desire  for price   either
or   and or   and or   and or   she must formulate sixteen explicit bids of the form  
¡¡¡¡¡¡¡¡¡¡¡¡  etc. in contrast 	posg allows such preferences to be expressed relatively concisely using a logical bid of the form:
¡¡variants of this language have been proposed by hoos and boutilier  includingthe use of k-of clauses  expressing a desire to have any goods from a givenset  and focusingon special forms such as cnf. it is important to note that a bidder generally must express a number of logical bids in posg to capture her utilityfunction: the fact that onlyone price can be attached to a formula means that independent preferences are captured by independent bids  e.g.  the same bidder might bid both and  . while perfect substitution is captured bydisjunctionin posg   imperfect substitutesmust be dealt with using multiple bids and dummy goods  fujisima et al.  1 . for example  if an agent wants only one of or   and slightlyprefers   she could specify two bids 
and
with . the insertion of dummy good prevents both bids from being satisfied. there is an implicit assumption of free disposal in the semantics of posg . if a bid is offered  the same price is paid if the bid is assigned alone  alone  or both and . if this assumption is violated  this bid must be broken into multiple  exclusive  bids.
¡¡a different approach is taken by sandholm  1; 1  and nisan   who use b languages. intuitively  these languages take bundle bids as their atomic elements and combine these using various logical connectives. for instance  sandholmproposed the use of orb   combiningatomic bids using disjunction  as in . semantically 
¡¡b languages are interpreted by assigning goods to the component atomic bids  e.g.  to and in the example above   rather than to the formula as a whole  in contrast with the g model . the price paid is determined by the logical relationshipof the component bids. in orb   forinstance  the sum of the prices of satisfied atomic bids is paid.
¡¡several interesting varieties of b languages are studiedby bothsandholmand nisan  whoconsider languages usingor  xor   xorb    and two-level nesting of such connectives  orof-xor and xor-of-or . the use of bundle bids as atomic elements allows one to express complementarities; or  as in orb   allows one to capture independent preferences; and xor allows the expression of substitutability. nisan also proposes  and favors  the language or*b   essentially orb with dummy goods allowed within atomic bids. or*b is fully expressive and is generally more compact than the other b languages for many types of utility functions. we refer to nisan  for a discussion of the relative merits of these languages. because multiple prices occur within a single formula  a bidder can express her preferences completely using a single bid  in contrast with the g model . however  preferences involving disjunctionare oftenexpressiblemuchmore compactlywithin g than b. for instance  the preference function above involving multiple clauses of the form requires a bid of exponential size in any b language.
1	a generalized language for logical bids
bothlanguage families	g and	b have certain drawbacks. in
¡¡g languages a bidder who wants to offer different prices for related logical combinations of goods is forced to specify distinct bids for those combinations. this prevents the bids from exploiting any logically common substructure. b languages are unable to exploit the logical structure of disjunctive combinations of goods that exhibit perfect substitutability. furthermore  b languages are unable to exploit the fact that a good may be  sharable   that is  it may contribute to the satisfaction of multiple atomic bids within a single bidder's logical bid. this is due to the fact that each good is assigned to an atomic bid within the b semantics and cannot be shared. this can be a severe drawback. consideran example inwhich a bidder desires a single reusable resource  say a machine   and some number of consumable resources  say raw materials     etc. to be processed on . the bidder may value each of the independently  but only if the machine is available on which to process these materials. in such a case  it is most natural to express preferences for the pairs  allowing to contribute to the satisfaction of each such bid or subformula.
¡¡in this section  we introduce the language gb of generalized logical bids that allows for the logical combination of both goods and bids within a single formula. specifically  a positivepropositionalformulaovergoodsmay haveprices associated with arbitrary subformulae. as such  bothgoods and bids can be combined in arbitrary ways. we will see that the expressivepoweraffordedbythisapproachoffersa numberof advantages  both in terms of the naturalness and conciseness of the representation of certain classes of utility functions. it inherits the fundamental advantages of both g and b languages.
¡¡our new language will allow us to formulate logical bids that reflect such structured utility functions directly and concisely. we first describe the syntax and semantics of our language infairly abstract terms. we then discuss various formal and informal properties of our language  comparing it to the languages mentioned above in terms of expressiveness  naturalness  and conciseness.
1	syntax
let denote the set of goods  formingthe atomic elements of our language. the language of gb is defined as follows:
¡¡¡¡¡¡¡¡¡¡¡¡¡¡gb  for any good	and any non-negative price	.
if gb  then     and are all in gb for any non-negative price .
bids so-defined correspond to arbitrary propositional formulae over the goods  using connectives  conjunction    disjunction and  valuativexor  the naming of which will become clear below   where each subformula is annotated with a price. we often don't mention the price for a subformula if   and call such a subformula priceless. a sentence
¡¡¡¡¡¡¡¡gb is called a generalized logical bid  glb . examples of glbs include and	.
the formula associated with   denoted   is the logical formula obtained by removing all prices from subformulae.
1	semantics
the semantics ofglbs defines thepricetobe paidbya bidder given a particular assignment of goods to her glb. roughly  the underlying idea is that the value of a glb is given by summing the prices associated with all satisfied subformulae  with one exception . we first define what it means for an assignment to satisfy a  priceless  formula.
	let	be an assignment	of goods to
glbs. let be the formula associated with . we write to denote that satisfies   and
to denote that does not satisfy . the satisfaction relation is defined as follows:
iffor sometheniff.ifthenifthenifthennoticethat the satisfactionrelationis identical forthe connectives and . the difference between the connectives will become evident when we define the value of a bid.
¡¡given a bid and assignment of goods to bids  we define the value of under   denoted   recursively. if is a good  are bids  and is a price:
intuitively  the value of a bid is the value of its components  together with the additional price if certain logical conditions are met. pays price if the formulae associated with both and are both satisfied;
and both pay price if either  or both  of or are satisfied. the semantics of and differ in how subformula value is used. specifically  the value of a disjunctive bid given an assignment is the sum of the values of the subformulae: in this sense  both subformulae are of value to the bidder. incontrast  a valuativexor bid  orvxor bid allows only the maximum value of its subformulae to be paid: thus the subformulae are viewed as substitutes  see below .
¡¡note how  under this definition  zero prices can be used to represent subformulae to which no price is attached  such as for the conjunctive bids defined in the previous section . let ' ' denotesemantic equivalence  i.e.  twoglbs have exactly the same value under any assignment of goods . we summarize the intuitive semantics of gb  examples are provided in the next section :
bids and are bothvaluedas thesumofcomponent values for and  i.e.  their utilities are independent . without prices  conjunction and disjunction  when they appear at the top-level of a glb  are semantically equivalent. when such formulae are priced  e.g. 
¡¡¡¡¡¡¡¡¡¡   or when they appear as subformulae in a more complex glb  however  the meaning is quite different.
	bid	expresses the complementarity of	and
¡¡ with value  . however  it allows intrinsic value to be expressed within the subbids  see below .
	bid	expresses the partial substitutability of
      with value  . however  it allows intrinsic value to be expressed within the subbids  so satisfying both may have greater value than satisfying either one alone. if are completely priceless  then disjunctionrepresents full and perfect substitutability.
bid expresses the complete substitutability of . only one of the values of or can be paid.
if the values are distinct then they are imperfect substitutes. perfect substitutes can be captured using or  see above .
	bid	is much like	  but with price
paid if either or both are satisfied. no  penalty  is paid if both are satisfied  so there is an implicit assumption of free disposal. a variation we do not pursue here would pay iff one of the subbids held. in what follows  we assume formulae have no prices  since
.
1	properties and examples
we begin by illustrating the key features of the generalized language gb with several examples. we then describe some of the formal properties of our language.
¡¡the ability to associate prices with subformulae gives gb the abilityto express certain complex preferences much more concisely and naturally than existing languages in either the g of b families. and complex preferences often exhibit considerable structure  as studied in multiattributeutilitytheory  keeney and raiffa  1   that can be exploited by gb. to illustrate  consider the bid
intuitively  this might reflect that       and are complementary goods with joint value 1  and that the individual goodshave someintrinsic e.g.  salvage value overandabove that of their role within the group. the use of subformula prices allows the direct expression of the natural decomposition of the underlying utility function. this bid can be expressed reasonably concisely in b  e.g.  or*  and  hence 
g: the disjunction of five atomic bids-	 	 	 
       -would suffice. however  this set of bids disguises the true structure of the utility function. moreover  if the atoms were replaced by disjunctive formulae  the required size of the b or g formulae would blow up  since we would need to distributethe disjunctionacross each of the conjuncts to form suitable atomic bids.
¡¡a relatedbidis	. here the individual goods are substitutes: they provide a basic functionalityof value 1  but perhaps do so with differing quality  or each has different intrinsic value  reflected in the  bonus  associated with each good. once again the use of subformula prices allows one to express this preference naturally. the most natural way to express this bid in or*b would be as the disjunctionofall1combinationsofthefourgoods in g this wouldrequire1 bids insteadof 1 disjuncts . in general  this would require an exponential blowup of the bid. it turns out one can express this bid more concisely as the disjunction of the following 1 bids  where is a dummy good :1  
¡¡¡¡¡¡            . the dummy good is needed to ensure that 1 is not paid more than once. while the blowup is only linear  any natural structure in the utilityfunction is buried. furthermore  this conversion onlyapplies when the disjunctsare goods; if theyare arbitrary glbs  then the b  or g  expression will blow up.
¡¡an important feature of the semantics of gb is that goods are assigned to logical bids  as in g  as opposed to component subformulae  as in b . this means that a good assigned toa logicalbidmakes all occurrences ofthatgood true . this allows the natural distinction between  sharable  resources thatcomplement multiplegoods and  consumable  resources whoseutilitycan onlybe  counted  once. considera scenario in which we have a number of goods whose utilities/prices are conditionally dependent on the presence of another good but are  conditionally  additive independent of each other. for instance  think of the as raw materials  and of as a machine used for processing those raw materials. this situation can be captured using a single glb of the form:
to express the same utility function using any b language would require a number of bids exponential in  essentially requiring the enumeration of all subsets of consumable goods . for example  with one sharable and four consumables  worth 1  1  1  and 1  respectively   we'd
need the following bid  in	orb or	or*b  :
again we see that	gb allows the natural and concise expression of certain types of utilityfunctions.
¡¡we observe that goods that complement multiple goods in a nonsharable fashion can be captured either using or by using multiple glbs. for instance  in the example above  if the machine is to be treated as consumable  replacing the disjunction with vxor:
wouldensure that themachine was not shared across the  or at least no value was associated with more than one  . similarly  we could break up each disjunct into a separate glb  all belonging to the same bidder : since goods are assigned to only one glb  this approach too prevents from being shared.
¡¡since a bidder can offer multiple glbs  it is important to note the distinction between the appearance of a good in multiple bids and its appearance it multiple subformulae within a single bid. in the former case  is treated as nonsharable  since it can be assigned to only one bid. in the latter case  each occurrence of is satisfied by the assignment of to that bid  hence can be viewed as being shared by each
of the component subformulae containing it. this distinction arises precisely because our notion of satisfaction is defined with respect to the assignment of goods to bids rather than bidders. we note that other purely logical means for distinguishingsharable and nonsharableresources may be possible  rather than relying on whether a multiple good occurrences lie  above the bid level  or below it. for instance  resourceoriented logics  e.g.  linear logic  girard  1   are designed primarily to deal with the issue of resource consumption and sharing. the connections to this work seem worthy of deeper exploration.1
¡¡when a bidder offers multipleglbs  we must enforce substitutability constraints by using dummy goods. this is not necessary when the bid is contained within a single glb: vxor can be used to ensure that only a single good from some set of  perfect or imperfect  substitutable goods is valued  assuming free disposal .
¡¡it is not hard to show that the connectives in	gb are commutative and  in a certain sense  associative.
proposition 1 let	gb. then
 a   similarly for	 	 .
 b  ; note thattheinnerconjunctionshave nopriceassociated with them  similarly for    .
this justifies the informal use of conjunction  etc.  of a set of glbs  with a price paid for the conjunction. certain distributionlaws can be derived as well forprice-free subformulae  andforpriced subformulaeifwe allowmanipulation e.g.  addition and subtraction  of prices. we conjecture that several useful normal forms for gb exist.
¡¡while there are preferences for which gb offers much more concise expression than either g or b  the converse is not true. any bid expressed in orb   or*b   xorb   or g can be expressed equally concisely in gb. g bids are simply special cases of glbs. similarly  gb can represent each disjunct in an orb or or*b bid as a separate glb for the specified bidder  resulting in a collection of smaller bids whose total size  structure  and meaning is the same. as a corollary to the results of sandholm and nisan  that show that xorb and or*b are both fully expressive  we have:
proposition 1 gb can represent any utility function over a set of goods .
1	stochastic search for glbs
as we have seen logical languages for bid expression have been considered by several authors. however  the logical structure of bids formulated in these languages has not been directly exploited computationally in winner determination. for instance  in the the computational study of g languages for winner determination undertaken in  hoos and boutilier  1   compact logical bids were converted into a  large  set of explicit bids and the behavior of winner determinationwas examined. despite the conversion  the stochastic local search algorithm  casanova  proposed in that study proved to work extremely well. in this section  we formulate a stochastic search procedure for the winner determination problem for glbs that works directly with logical bids  sidestepping the problem of converting a logical bid into a  potentially exponentially  large number of explicit bids. though we have yet tostudy itscomputational properties  we expect this approach to offer a significant advance over existing algorithms.
¡¡given a set of glbs  our aim is to find an assignment of goods to bids that maximizes revenue; that is  whose value	is maximal. in the spirit of the casanova algorithm for standard combinatorial auctions  and motivated by the success of stochastic local search  sls  techniques for a broad range of hard combinatorial problems  we devise an sls procedure that operates directly on the space of assignments and uses the objective function to guide the search. in this search space  intuitively  we want to consider two assignments to be neighbors if we can construct from by shifting certain goods from some bids to others. for example  one could imagine defining the neighborhood relation as follows: a neighbor of is reached by moving exactly one good from itsassigned bid in toa newbid . whilethiswouldrender each reachable from any other assignment  selecting good moves based on the objective function would be difficult  as many single-good moves are unlikely to cause a change in   leading to large plateaus in the searchscape. alternatively  one could follow the casls approach  hoos and boutilier  1   and consider assignments and to be neighbors if can be reached by selecting an unsatisfied bid in and shiftinggoods from some other bid to so that it becomes  maximally  satisfied. we feel  however  that this approach wouldnotadequately reflect thefact thatglbs have degrees of satisfaction  i.e.  values . furthermore  revenue maximizing assignments need not necessarily maximally satisfy any bid; thus this neighborhood relation would not necessarily allow one to reach optimal solutions from arbitrary points in search space.
¡¡the neighborhood relation we propose can be seen as a compromise between these two extremes; it is based on the observation that the existence of priced subformulae in glbs providesthe means to improve the value of a bid in natural increments by movinggoods from bidto bid inprice-improving bundles. the value of a glb under an assignment is determined precisely by the priced subformulae that are satisfied by . we then define assignment to be a neighbor of   if it can be reached from by selecting an unsatisfied priced subformula in some bid and by moving just enough goods to that bid to satisfy this subformula.
¡¡to complete the definition of an sls procedure  we need to specify methods for selecting an initial assignment and for choosing a neighboring assignment at each search step. analogous to the casls scheme  we propose to start the search at an empty assignment where all goodsare unassigned and all the bids are fully unsatisfied  i.e.  their value is zero .
¡¡to formally define the method for selecting neighbors  we use the notionof a logical bid tree: each glb can be represented as a logical bid tree whose subtrees correspond to the priced subformulae of ; this tree is simply the parse tree for with prices attached to each node. a subformula without a  top-level  price attached is semantically equivalent to the same subformula with price zero; we call such subformulae and thecorrespondingnodespriceless  whileall othersubformulae  and nodes  are called priced. since each subtree of a logical bid tree is itself a glb  notions of value under a given assignment and maximal value under any assignment are well-defined for subtrees; the  maximal  value of a node is the  maximal  value of the subtree rooted at that node.
¡¡our method for selecting a neighbor of the current assignment in each search step proceeds in two stages: first  choose from some partiallyunsatisfied bid an unsatisfied price node whose ancestors do not have maximal value.1 then  select a set of goods that  when assigned to bid   will satisfy node . together  these two choices determine a neighboring assignment  which is reached by reassigning all goods in to bid . more precisely  we restrict this second selection to minimal satisfying sets    i.e.  to sets that contain only goodsthat are necessary to satisfy  . findingsuch a minimal set satisfying is rather straightforward using the procedure satisfy   recursively computed as follows:
 a  let be a leaf node labeled with good . then return .
 b  let   and w.l.o.g. assume that     are unsatisfied  and are satisfied. since is not satisfied  at least one subnode must be unsatisfied.  satisfaction information is recorded for each node.  then return satisfy   callingthe satisfy in random order.
 c  let	.  note that since
is not satisfied  each subnode must be unsatisfied.  randomly choose one   . then return satisfy .
 d  let .  note that the satisfactionofsuch a subformulais defined exactlyas inthe case of . hence  since is notsatisfied  each subnode must be unsatisfied.  randomly choose one   . then return satisfy .
¡¡to obtain minimal assignments  we update the assignment of goods incrementally as we work recursively through the tree. this way  once a good is assigned in one part of the tree this fact will be reflected in the other parts of the tree. due to the stochastic choice of subformula to satisfy within ors and vxors  and the random order in which subformulae beneath and nodes are visited  satisfy can find any minimal assignment of goods to bid that will satisfy node .
¡¡the schematic stochastic local search algorithm we propose initializes the search at an empty assignment and then iteratively moves from the current assignment to a neighboring assignment by transferring a set of goods between bids as described above. after each such search step  the satisfaction information for all bids  and all subformulae within bids  is updated based on the new assignment. in practice  to deal withpremature stagnation thissls technique willbe extended with standard restart mechanisms such that the search is reinitialized from an empty assignment after a fixed number of steps have been performed since the last initialization  fixed cutoff restart  or whenever no improvement in revenue has been achieved for a given number of steps  soft restart .
¡¡concrete instantiations of this algorithmic framework are obtained by specifying mechanisms for the various selections in each search step: the choice of a subformula to be satisfied  and the choice of a minimal assignment  as implemented by satisfy   possibly extended by an additional selection from a number of minimal assignments that satisfy  . there is a broad range of possibly suitable and effective mechanismsfor these selections; whichofmany strategieswill work best will have to be determined based on empirical analyses. however  it seems clear that the choices should be made in a biased randomized fashion such that alternatives that lead to higher direct increases in are selected with higher probability while any possible alternative can be chosen with some small  lower-bounded probability. the former criterion is based on analogous results for standard combinatorial auctions  hoos and boutilier  1  and other well-known combinatorial problems such as propositional satisfiability  while the latter is a sufficient condition to ensure that for arbitrarily long runs  the sls procedure will find an optimal solution withprobabilityapproaching one  i.e.  it ensures probabilistic approximate completeness  see  hoos  1  for details .
¡¡the general approach we propose here can also be used to obtain a systematic search algorithm capable of finding optimal solutionsand provingtheir optimality. the overall search method could be very similar  starting with an empty assignment and selecting subformulae that are satisfied by assigning a set of goods in each step. to guarantee completeness of the algorithm  all choices would have to be done in a systematic fashion such that when using a backtracking mechanism  the full search space of a given problem instance will be explored after a finitely bounded amount of time. notice that this is possible even for randomized choices. the practical efficiency of such an algorithm would depend on suitable heuristics for ordering the alternatives to be explored at each choice point  and on sufficiently powerful pruning or boundingtechniques. thisapproachcouldbeveryuseful forsolving relatively small problem instances provably optimally. however  considering the np-hardness of the given problem and well-known results for other hard combinatorial optimization problems  such as max-sat  tsp  or standard combinatorial auctions  we believe that sls techniques likethe one outlined above will most likely show better absolute performance and anytime behavior on large and complex problem instances.
1	concluding remarks
we have proposed a new logical bidding language for cas that exploits structure in utilityfunctions  thereby facilitating the natural and concise expression of bids. by associating prices withsubformulae and adequately dealingwithsharable resources  gb can express certain bids exponentially more compactly than existing languages. we have also sketched a search procedure for solving cas that does not require the conversion of logical bids to atomic bids. though this procedure has not been tested empirically  we are confident that it will work well. we are currently developing an implementation suitable for extensive experimentation.
¡¡apart from empirical work  we are also exploring extensions of gb to deal with k-of expressions and multiunit cas. the distinctionbetween sharable and consumable goods also deserves further exploration. clearly an important concept for cas  gb's ability to make this distinction implicitly is very desirable for the natural  concise expression of preferences. finally  we are currently pursuing the connection to work in resource-oriented logics  e.g.  linear logic  girard  1    though existing logics do not seem to able to handle complementarities.
references
 fujisima et al.  1  yuzo fujisima  kevin leyton-brown  and yoav shoham. taming the computational complexity of combinatorial auctions. in proceedings of the sixteenth international joint conference on artificial intelligence  pages 1  stockholm  1.
 girard  1  jean-yves girard. linear logic. theoretical computer science  1-1  1.
 hoos and boutilier  1  holger	h.	hoos	and	craig
boutilier. solving combinatorial auctions using stochastic local search. in proceedings of the seventeenth national conference onartificial intelligence  pages 1  austin  tx  1.
 hoos  1  holger h. hoos. stochastic local search - methods  models  applications. infix-verlag  sankt augustin  germany  1.
 keeney and raiffa  1  r. l. keeney and h. raiffa. decisions with multiple objectives: preferences and value trade-offs. wiley  new york  1.
 nisan  1  noam nisan. bidding and allocations in combinatorial auctions. in acm conference on electronic commerce  ec-1   minneapolis  mi  1.
 rassenti et al.  1  s. j. rassenti  v. l. smith  and r. l. bulfin. a combinatorial auction mechanism for airport time slot allocation. bell journal of economics  1- 1  1.
 rothkopf et al.  1  michael h. rothkopf  aleksander pekec¡¦  and ronald m. harstad. computationally manageable combinatorial auctions. management science  1 :1  1.
 sandholm  1  tuomas sandholm. an algorithm for optimal winner determination in combinatorial auctions. in proceedings of the sixteenth international joint conference on artificial intelligence  pages 1  stockholm  1. extendedversion washingtonuniv.reportwucs1.
 sandholm  1  tuomas sandholm. emediator: a gext generation electronic commerce server. in proceedings of the fourth international conference on autonomous agents  pages 1  barcelona  1.
 wellman et al.  1  michael p. wellman  william e. walsh  peter r. wurman  and jeffrey k. mackie-mason. auction protocols for decentralized scheduling. games and economic behavior  1. to appear.
partitioning activities for agents
	fatma ozcan¡§	and v.s. subrahmanian
department of computer science
university of maryland  college park fatma vs  cs.umd.eduabstract
there are now numerous agent applications that track interests of thousands of users in situations where changes occur continuously.  shim et al.  1  suggested that such agents can be made efficient by merging commonalities in their activities. however  past algorithms cannot merge more than 1 or 1 concurrent activities. we develop techniques so that a large number of concurrent activities  typically over 1  can be partitioned into components  groupsof activities of small size  e.g. 1 to 1  so that each component's activities can be merged usingpreviouslydevelopedalgorithms e.g.  shim et al.  1  . we first formalize the problem and show that finding optimal partitions is nphard. we then develop three algorithms - greedy 
¡¡-based and bab  branch and bound . -based and bab are both guaranteed to compute optimal solutions. greedy on the other hand uses heuristics and typically finds suboptimal solutions. we implemented all three algorithms. we experimentallyshow that the greedy algorithmfinds partitions whose costs are at most 1% worse than that found by -based and bab - however  greedy is able to handle over thousand concurrent requests very fast while the other two methods are much slower and able to handle only 1 requests. hence  greedy appears to be the best.
1	introduction
the number of software agents deployed on the internet has grown dramatically over the last few years. major corporations have agents that continuouslytrack events - some corporationsuse such agents toidentifyand exclude ip addresses that  scrape  data from their sites. other corporations use agents that track some phenomenon  e.g. stock quotes  and take different actions for different clients who have registered parameters to be tracked and actions to be taken when certain

parts of this research were supported by army research
lab contract daal1  army research office grant
daad1and darpa/rome labs grant f1
some proofs are omitted due to space limitations
conditions are satisfied. yet other corporations have agents that dynamically adjust plans  e.g. airlines  when events occur that cause those plans to go awry  e.g. a snowstorm .
¡¡in this paper  we focus on agents that have a high volume of activity. our work is not going to help  very much  agents that have a relatively low amount of activity. if the agent can leverage common aspects across its diverse activities so as to reduce its load  its performance will improve greatly. much workhas been done on mergingactivitiesto minimize load- such work spans databases  shim et al.  1  and planning  yang et al.  1  - however the problem of merging such activities in an optimal way is known to be np-complete  and hence these algorithmstend toperform well when 1 to1activities or fewer are being merged. however  agents tracking user interests for major news organizations like cnn have a huge number of users with registered interests  and an enormous number of changes occurring continuously. the same is true in the case of stock market agents.
¡¡in this paper  we develop partitioning techniques. such techniques work as follows: when a large set of activities  e.g. 1 are waitingtobe performed  thenourmethodspartition . such a partition breaks into disjoint components where . the activities in a single component may then be merged by methods for mergingactivities  whetherthey are queries orplans usingmethods such as those of  shim et al.  1; yang et al.  1 . the cost of executing a component is just the cost of executing the activities in the component after merging activities. the cost of a partition is the sum of the costs of the components. the cost  after merging  of the activities in a partition may be estimated using techniques such as those in  shim et al.  1; yang et al.  1 . we wouldlike to find a partitionwith minimal  estimated  cost.
¡¡section 1 formalizes this problem and shows that finding a partition with minimal expected cost is np-hard. section 1 develops three algorithms to address this problem. the first algorithm is based on the algorithm - we introduce a heuristic function and show that it is admissible  nilsson  1 . hence  this algorithm is guaranteed to find a partition with minimal cost. the second algorithm is a greedy algo-
rithmwhich is not guaranteed to find a minimal cost partition. the thirdalgorithm is a branch and bound algorithm which is also guaranteed to find an optimal cost solution. we have implemented all the algorithms. section 1 describes the results ofdetailed experimentationwiththese algorithms. the experiments show that though the greedy algorithm finds suboptimal solutions typically1% worse savings are realized when compared to the optimal savings realizable   it is able to handle 1 concurrent activities in about 1 seconds  while the other two algorithms are unable to handle a large number of activities.
1	problem definition
an agent may engage in some space of activities. for example  the space of activities associated with a database agent may be all sql queries. the space of activities associated with a planning agent may be the set of all possible planning problems. thespace ofactivitiesassociated witha cnn-style news agent may be the set of all interests that could possibly be associated with users. in the sequel  we use to denote some set of activities drawn from such an activity space. denotes activitiesthat the agent has to perform  but has not yet performed.
definition 1  partition  a partition of a set of activities is a set where each is a non-empty subset of and
1. =
1. .
	each	is called a component of the partition	. when
the first conditionis replaced by	  is called a subpartition.
a partition of splits a set of activities  to be done  into components. the activities in each component can be separately merged  perhaps using methods for query merging  shim et al.  1  or plan merging  yang et al.  1 .
definition 1  cost estimation function  a cost estimation function takes a set of activities as input and returns a real
number asoutput. is required tosatisfyat least the following axioms:  i     ii 	.
intuitively  denotes the estimated cost of executing the activities in after merging. when is a singleton set  we will abuse notation and write instead of
¡¡¡¡¡¡. we will also assume that the computation of takes polynomial time. this is consistent with algorithms to estimate merged costs of sets of queries such as those of  shim et al.  1 as well as task mergingmethods  yanget al.  1 . in this paper  capitalized 's denote sets of activities. lower case 's denote individual activities.
problem 1  activity partitioning problem app   a set of activities  a cost estimation function   and a partition of . is it the case that there is no other partition of such that	 
we will prove below that app is np-hard by using the zeroone multipleknapsack problem  mkp   martelloand toth  1;kellerer  1 . mkp canbe statedas: givenaset of items  a set of knapsacks  profit and weight vectors
and	 	   and the capacity vector	 	   subject to
¡¡the decision problem version of mkp takes in addition to the above parameters  an assignment of items to knapsacks. it returns true if the assignment is an optimal solution to the search problem and false otherwise.
theorem 1 the activity partitioningproblem is np-hard.
proof sketch: we will transform the mkp decision problem to app. let be the number of components in . create three tables with the following database schemas:
    knapsackid capacity    itemid  profit  weight  and  knapsackid  itemid .
insert an entry for each item into   and an entry for each knapsack into . create an entry in for each item  knapsack pair present in the assignment . then  for each item   we create an sql query given by:
select * from     where .itemid = and .itemid = .itemid and .knapsackid = .knapsackid and sum  .weight  .capacity
let the cost 	.
¡¡it is easy to see that the tables and queries can be constructed in polynomial time. therefore  when we solve this instanceofapp  we willminimizethe totalcost ofthe queries. as a result  the sum of the profits will be maximized in the solution. hence  app is np-hard.
1	activity partitioning algorithms
although  we can transform the mkp problem into app  we cannot immediately use the available approximationalgorithms martelloand toth  1; kellerer  1 for themkp problem. this is because in mkp the profits of items are constants  that is they donot vary withdifferent knapsacks. however  in our case  the cost of a set of activities not only depends on which component it belongs to  but also depends on which other activities are present in the component. hence  we will describe new algorithms based on different heuristics to solve the query partitioningproblem. we will start with an a -based algorithm  which is guaranteed to find an optimal solution.
1	a -based algorithm
toadapt the algorithm nilsson 1   we first needtodefine the state space  the cost function and the heuristic function .
definition 1  state  a state is any subpartition of . state is a goal state if it is a partitionof . finally  the start state
.
definition 1  functionsand  supposenode	has state  and let	. then 	and	are defined as follows:
where	is the cost estimation function.
intuitively  says the cost of node is the sum ofthe costs ofthe individualcomponents. underestimates the cost to a goal state. this is done as follows. consider each activity that is in but that is not in the subpartition associated with node . such an activity can either be placed in one of the components of node or may be in a new component. evaluate the cost of each of these alternatives and choose the minimal increase in cost for adding to node . to obtain a partition  every activity that is not in the current subpartition must be added to node eventually  so the cost of a solution must be at least greater than the current cost by for all such activities . this provides the rationale for .
¡¡our -basedalgorithmisgiveninfigure1. the algorithm makes use of a function  pick     that chooses an activity from which has not been assigned toany of the components in state .
¡¡if the while loop of the algorithm terminates  this implies that no goal state was reached and hence there is no solution. note that if the heuristic function used by the algorithm is admissible  then the algorithm is guaranteed to find the optimum solution nilsson  1 . the heuristic is admissible iff where is the lowest actual cost of getting to a goal node from node . the following result shows that our heuristic is admissible.
theorem 1  admissibility of   for all nodes n 
     . hence  -based algorithmfinds an optimal partition of	.
theorem 1 the heuristic function	satisfies the monotone restriction.
	the monotone restriction requires that for all	 
	. since  the	function satisfies the
monotone restriction  the first goal state found by the based algorithm is guaranteed to be the optimal solution.
1	greedy algorithm
our greedy algorithm uses the notion of a cluster graph to solve the activity partitioning problem. given a set of activities a cluster graph is a weighted graph whose vertices are disjoint sets of activities. given any set of activities  we may associate with it  a canonical cluster graph.
definition 1  canonical cluster graph      a cluster graph for a set of activitiesis an undirected weightedgraph where:
1.	 
1.
 
1.
intuitively  when we have an edge between activities then this means that there is some savings to be derived by

	figure 1: the	-based algorithm
merging the two activities together. the edge label  denotes that saving.	 again  we abuse notation and write instead of	and	instead of
.  
¡¡the greedy algorithm is shown in figure 1. intuitively  greedy tries to build a partition iteratively. in each iteration  it finds an edge with highest weight  savings  in the cluster graph and deletes it. if more than one such edge exists  one is arbitrarily picked. it examines the two activities associated with that edge and checks to see if either of those activities already occur in a partition. there are four cases to check depending on whether one  both or neither activities occur in an existing partition. if both occur in existing different components thenitmaybepossibletomoveoneofthemfrom one component into the other. this should be done only if it yieldssavings. if one of is inan existingcomponent but not the other  then the other can be placed in the same component. it is easy to see that the number of iterations of the loop of this algorithmis . each execution of the loop may take time inthe worst case tocheck if
occur in a component. it is therefore easy to see that greedy is certainly polynomial in the size of the input as long as
1	branch and bound algorithm
in this section  we describe a branch and bound algorithm  which is similar to the -based algorithm  but uses a different search strategy.
¡¡the bab algorithm maintains nodes which having the following fields: state  as defined in def. 1    gval and uval defined below. gval specifies the value  cf. def. 1   while uval contains which is defined below.
definition 1 let node	have state	  then	. where	  and is the cost estimation function.
intuitively  overestimates the cost of the minimal cost solution reachable from node .1 bab  figure 1  also startsout withan empty partitionand uses the same expansion strategy as the -based algorithm. the open list which is organized in ascending order of and the bab algorithmalways chooses thefirst nodeinopen forexpansion. if the valueof thisfirst node exceeds that ofthe best solution figure 1: the branch and bound algorithm
foundso far  then we do not need to expand thisnode. if however  the -value is less than that of the best solutionfound so far  then there is a chance that this node leads to a better solutionand hence we expand it  unless it is a solutionin which case we discard it .
theorem 1 bab 	  finds an optimal partition of	.
1	implementation/experimental results
we have implemented all three algorithms described in this paper in c++ on a sun ultra1 machine with 1 mb memory running solaris 1. there is a total of 1 lines of code for our implementation and experiments. we ran two sets of experiments - one todetermine which algorithmwas fastest  and how many concurrent activitiescould be handled  and another to determine how the algorithms performed in terms of savings generated by them.
experiment 1: we first fixed an overlap probability. given a pair of activities from   the overlap probability gives the

figure 1: scalability of the greedy algorithm
probability that the pair will overlap. we then fixed an overlapdegree which measures thesavings obtainedwhen twoactivities overlap. suppose we know activities overlap.
the overlap degree in this case is . intuitively the larger the overlap degree  the greater the savings obtained by merging two activities.
¡¡once an overlap degree and overlap probability are fixed  we automatically generated sets of activities that have that overlap degree  on the average  and that overlap probability. we then ran all three algorithms on the data. for each number of activities  we took an average over 1 sets of data. table 1 shows the results of experiments when overlap probability varies between and and when the overlap degree is
  1 .
no. of activitiesgreedybab-based1.1.1.11111.1.1.111.111111.1table 1: execution times  millisecs   overlapdegree=1 
¡¡it turns out that both -basedand bab ran out of memory when the number of activities exceeded about 1. the reason for this is that the open list quickly grows overwhelmingly large. hence  the above table has only 1 activities. in contrast  greedy did not run out of space. in order to see how well greedy could do  we continuedtorun experiments by increasing the number ofactivities. figure 1shows that greedy scales well and can handle 1concurrent activitiesin about 1 seconds.
experiment 1: as both -basedand bab compute optimal solutions  but greedy does not always do so  we wanted to see how much  worse  the solution produced by greedy was compared to the optimal solution. when we have a set of activities  and a partition of   the savings realized by is given by	.
¡¡figure 1 shows that in our experiments  optimal solution produced by -based whose savings equals that produced

figure 1: cost reduction percentage comparison
by bab  yielded a saving of 1%  while greedy yields savings of 1%.
¡¡althoughwe could not get the optimal solutionafter 1 activities we still ran the greedy algorithmup to 1activities to see the quality of partitions it produced. figure 1 shows the results. as seen from the graph  the performance of the greedy algorithm did not degrade  and stayed about the same as we increased the number of activities in the input sets.
¡¡both -basedand bab are unable to perform at all when there are more than 1concurrent activities. on larger sets of activities  they both quickly run out of memory - in contrast  greedy scales up very effectively when many activities occur. in a few seconds  it can partition over a thousand concurrent activities  and produce a solution that is at most 1% worse than the optimal.
1	related work and conclusions
over the last few years  there has been tremendous interest in collaborativeinformationagents. techniques from thisfertile field have found ample applications in online news sources that monitor user interests and changing news events and create personalized news reports. they have also been used extensively to make trades in financial markets for different users as stock conditions change. they have been used to dynamically bid for a variety of clients in online auctions  schwartz and kraus  1 . there are many impressive agent systems - these include internetsoftbot  etzioni and weld  1   retzina  decker et al.  1   infosleuth  bayardo et al.  1   sims  arens et al.  1  and many others.
¡¡there have been important efforts to optimize the performance of such agents. for instance   adali et al.  1; ashishet al.  1 showhowtouse intelligentcaching methods to improve the performance of systems that access different data sources.
¡¡in both planning and databases  researchers have noticed that when a server receives numerous requests  then it may make sense to leverage commonalities across those requests instead of serially processing the requests. this is accomplishedby merging  planningrequests orquery requests . importantadvances inthisfield were made by yanget al.  1  and  shim et al.  1 . however  in both cases  the problem of merging plans and merging queries to minimize expected

figure 1: cost reduction percentage of the greedy algorithm
cost ofexecutionisnp-hardandhence  thesemethodsworked well when the numbers of activities  planning or querying  were limited.  shim et al.  1  conducted experiments with 1 concurrent queries  while  yang et al.  1 handled up to 1 concurrent planning problems.
¡¡inthispaper  we buildonthese importantadvances. specifically  we start by assuming the existence of some way of merging activities or fewer. thus  if the activities are database queries  then may be set to and the  shim et al.  1  algorithm may be used. alternatively  if the activities are planning problems  the perhaps one could set to 1 and use the methods of  yang et al.  1  to merge plans. now considerthe situationwhere sucha database or planningagent has hundreds or thousands of activities it is currently engaged in. sucha set ofactivitiesmay be partitionedintocomponents of size  or less  so that each component's activities can be merged using an aforementioned merging algorithm such as  yanget al.  1;shimet al.  1 . ifthesumofthecostsof the individual components of the partitionis minimized  then we would have an optimal way of executing such a large set of activities.
¡¡unfortunately  this problem - which we call the activity partitioning problem  app  in this paper - is shown to be np-hard. as a consequence  there is no exact algorithm to solve this problem in polynomial time  unless p np which is widely believed to not be the case . we propose two exact algorithms  -basedand bab  to solve this problem. as these algorithmscompute exact solutions they are easily seen to take exponential time. as expected from earlier results of  yang et al.  1; shim et al.  1   these algorithms stop performingwell when over1activitiesare beingmerged. to alleviate thisproblem  we propose a polynomial algorithm called greedy which exhibits the following nice properties. first  it can  in a matter of seconds  partition a set of thousands of activities which reflects an order of magnitude improvement over -basedand bab. second  the partitions it computes turn out to have at most 1% worse savings than those computed by -basedandbab. as a consequence  we believe that greedy is superior to both -basedand bab for real world problems.
