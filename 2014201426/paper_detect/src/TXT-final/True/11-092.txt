 
　　　　the knowledge engineer p r a c t i c e s the a r t of b r i n g i n g the p r i n c i p l e s and t o o l s of ai research to bear on d i f f i c u l t a p p l i c a t i o n s problems r e q u i r i n g e x p e r t s ' knowledge f o r t h e i r s o l u t i o n . the t e c h n i c a l issues of a c q u i r i n g t h i s knowledge  representing i t   and using i t a p p r o p r i a t e l y t o construct and explain l i n e s - o f - r e a s o n i n g   are important problems in the design of knowledgebased systems. various systems that have achieved expert l e v e l performance in s c i e n t i f i c and medical inference i l l u m i n a t e the a r t of knowledge engineering and i t s parent science  a r t i f i c i a l i n t e l l i g e n c e . 
	1 	introduction: an example 
　　　　this is the f i r s t of a p a i r of papers that w i l l examine emerging themes of knowledge e n g i n e e r i n g   i l l u s t r a t e them w i t h case studies drawn from the work of the stanford h e u r i s t i c programming p r o j e c t   and discuss general issues of knowledge engineering a r t and p r a c t i c e . 
　　　　let me begin w i t h an example new to our workbench: a system c a l l e d puff  the e a r l y f r u i t of a c o l l a b o r a t i o n between our p r o j e c t and a group at the p a c i f i c medical center  pmc  in san 
francisco. 
　　　　a physician r e f e r s a p a t i e n t to pmc's pulmonary f u n c t i o n t e s t i n g lab f o r diagnosis of p o s s i b l e pulmonary f u n c t i o n d i s o r d e r . for one of the t e s t s   the p a t i e n t inhales and exhales a few times in a tube connected to an 
instrument/computer combination. the instrument acquires data on flow rates and volumes  the soc a l l e d flow-volume loop of the p a t i e n t ' s lungs and airways. the computer measures c e r t a i n parameters of the curve and presents them to the d i a g n o s t i c i a n  physician or puff  f o r i n t e r p r e t a t i o n . the diagnosis is made along these l i n e s : normal or diseased; r e s t r i c t e d lung disease or o b s t r u c t i v e airways disease or a combination of b o t h ; the s e v e r i t y ; the l i k e l y disease type s    e . g . emphysema  b r o n c h i t i s   e t c .   ; and other f a c t o r s important f o r d i a g n o s i s . 
　　　　puff is given not only the measured data but also c e r t a i n items of i n f o r m a t i o n from the p a t i e n t r e c o r d   e . g . sex  age  number of pack-years of c i g a r e t t e smoking. the task of the puff system is to i n f e r a diagnosis and p r i n t it out in english in the normal medical summary form of the i n t e r p r e t a t i o n expected by the r e f e r r i n g p h y s i c i a n . 
　　　　everything puff knows about pulmonary f u n c t i o n diagnosis is contained in   c u r r e n t l y   1 r u l e s of the i f . . . t h e n . . . form. no textbook of medicine c u r r e n t l y records these r u l e s . they c o n s t i t u t e the p a r t l y - p u b l i c   p a r t l y - p r i v a t e knowledge of an expert pulmonary p h y s i o l o g i s t at pmc  and were e x t r a c t e d and polished by p r o j e c t engineers working i n t e n s i v e l y w i t h the expert over a period of t i m e . here is an example of a puff r u l e  the unexplained acronyms r e f e r to various data measurements : 
rule 1 
i f : 
1  the s e v e r i t y of o b s t r u c t i v e airways disease of the p a t i e n t is greater than or equal to m i l d   and 
1  the degree of d i f f u s i o n defect of 	the p a t i e n t is greater than or equal to m i l d   and 
1  the t l c   b o d y box observed/predicted of the p a t i e n t is greater than or equal to 1 and 
1  the observed-predicted d i f f e r e n c e in r v / t l c of the p a t i e n t is greater than or equal to 1 
then: 
1  there is s t r o n g l y suggestive evidence  .1  that the subtype of o b s t r u c t i v e airways disease is emphysema  and 
	1   i t 	i s d e f i n i t e 	  1 . 1   	that 	 oad  
d i f f u s i o n d e f e c t   elevated tlc  and elevated rv together i n d i c a t e emphysema.  is one of the f i n d i n g s . 

invited papers-1: feigenbaum 1 

　　　　one hundred cases  c a r e f u l l y chosen to span the v a r i e t y of disease states w i t h s u f f i c i e n t exemplary i n f o r m a t i o n f o r each  were used to e x t r a c t the 1 r u l e s . as the knowledge emerged  it was represented in r u l e form  added to the system and tested by running a d d i t i o n a l cases. the expert was sometimes s u r p r i s e d   sometimes f r u s t r a t e d   by the occasional gaps and i n c o n s i s t e n c i e s in the knowledge  and the i n c o r r e c t diagnoses that were l o g i c a l consequences of the e x i s t i n g r u l e s e t . the i n t e r p l a y between knowledge engineer and expert gradually expanded the set of rules to remove most of these problems. 
　　　　as cumulation of techniques in the a r t demands and a l l o w s   a new t o o l was not invented when an old one would do. the knowledge engineers p u l l e d out of t h e i r t o o l k i t a version of the mycin system   t o be discussed l a t e r     w i t h the rules about i n f e c t i o u s diseases removed  and used it as the inference engine for the puff diagnoses. thus puff  l i k e mycin  is a r e l a t i v e l y simple backwardchaining inference system. it seeks a v a l i d l i n e o f - r e a s o n i n g based on i t s r u l e s and rooted in the instrument and p a t i e n t data. with a l i t t l e more work at f i t t i n g some e x i s t i n g t o o l s together  puff w i l l be able to e x p l a i n t h i s l i n e - o f - r e a s o n i n g   j u s t as mycin does. 
　　　　as it i s   puff only p r i n t s out the f i n a l i n t e r p r e t a t i o n   of which the f o l l o w i n g is an example: 
patient data: 
	the degree of dyspnea: 	moderately-severe 
	the s e v e r i t y of coughing: 	mild 
sputum production moderately-severe the number of pack-years of smoking: 1 r e f e r r a l d i a g n o s i s : bronchitis ivc/ivc-predicted: 1 
	rv/rv-predicted: 	1 
	fvc/fvc-predicted: 	1 
tlc body box observed/predicted: 1 predicted fev1/fvc: 1 
tlc dlco observed/predicted: 1 fev1/fvc r a t i o : 1 
rv/tlc observed-predicted: 1 mmf/mmf-predicted: 1 the dlco/dlco-predicted: 1 the slope  f1 obs-f1 obs  /fvc obs: 1 degree of obstructive airways disease: 
	oad degree by slope: 	 moderately-severe 
1  
	oad degree by mmf: 	 severe 1  
	oad degree by fev1: 	 moderately-severe 
1  
	final oad degree: 	 moderately-severe 
	1  	 severe 1  
	no c o n f l i c t . 	f i n a l degree: 
 moderately-severe 1  
interpretation: 
obstruction is i n d i c a t e d by curvature of the flow-volume loop. 
forced v i t a l capacity is normal and peak flow rates are reduced  suggesting airway o b s t r u c t i o n . 
flow rate from 1 of expired volume is reduced  i n d i c a t i n g severe airway o b s t r u c t i o n . 
oad  d i f f u s i o n defect  elevated tlc  and elevated rv together i n d i c a t e emphysema. oad  d i f f u s i o n defect  and elevated rv i n d i c a t e emphysema. 
change in expired flow rates f o l l o w i n g b r o n c h o d i l a t i o n shows that 	there is r e v e r s i b i l i t y o f airway o b s t r u c t i o n . the presence of a productive cough is an i n d i c a t i o n that the oad is of the 
b r o n c h i t i c type. elevated lung volumes i n d i c a t e o v e r i n f l a t i o n . 
a i r trapping is i n d i c a t e d by the elevated d i f f e r e n c e between observed and predicted rv/tlc r a t i o s . 
improvement in airway resistance i n d i c a t e s some r e v e r s i b i l i t y of airway airway o b s t r u c t i o n is consistent w i t h the p a t i e n t ' s smoking h i s t o r y . the airway o b s t r u c t i o n accounts f o r the p a t i e n t ' s dyspnea. although b r o n c h o d i l a t o r s were not u s e f u l in t h i s one case  prolonged use may prove to be b e n e f i c i a l to the p a t i e n t . the reduced d i f f u s i o n capacity i n d i c a t e s airway o b s t r u c t i o n of the mixed b r o n c h i t i c and emphysematous types. low d i f f u s i n g capacity i n d i c a t e s loss of a l v e o l a r c a p i l l a r y s u r f a c e . o b s t r u c t i v e airways disease of mixed types 
　　　　1 cases not studied during the knowledge a c q u i s i t i o n process were used f o r a t e s t and v a l i d a t i o n of the r u l e s e t . puff i n f e r r e d a diagnosis f o r each. puff-produced and e x p e r t produced i n t e r p r e t a t i o n s were coded f o r s t a t i s t i c a l analysis to discover the degree of agreement. over various types of disease s t a t e s   and f o r two c o n d i t i o n s of match between human and computer diagnoses   same degree of s e v e r i t y   and   w i t h i n one degree of s e v e r i t y       agreement ranged between approximately 1z and 1x. 
invited papers-1: feigenbaum 1 　　　　the puff s t o r y is j u s t beginning and w i l l be t o l d perhaps at the next ijcai. the s u r p r i s i n g punchline to my synopsis is that the c u r r e n t s t a t e 
　　　　of the puff system as described above was achieved in less than 1 hours of i n t e r a c t i o n w i t h the expert and less than 1 man-weeks of e f f o r t by the knowledge engineers. we have learned much in the 
past decade of the art of engineering knowledgebased intelligent agents! 
       in the remainder of this essay  i would like to discuss the route that one research group  the stanford heuristic programming project  has taken  illustrating progress with case studies  and discussing themes of the work. 
1 	artificial intelligence & knowledge engineering 
       the dichotomy that was used to 	classify the collected 	papers 	in 	the 	volume 
computers and thought s t i l l characterizes well the motivations and research efforts of the al community. first  there are some who work toward the construction of intelligent a r t i f a c t s   or seek to uncover principles  methods  and techniques useful in such construction. second  there are those who view a r t i f i c i a l intelligence as  to use newell's phrase   theoretical psychology   seeking explicit and valid information processing models of human thought. 
       for purposes of this essay  i wish to focus on the motivations of the f i r s t group  these days by far the larger of the two. i label these motivations  the intelligent agent viewpoint  and here is my understanding of that viewpoint: 
        the potential uses of computers by people to accomplish tasks can be 'onedimensionalized' into a spectrum representing the nature of instruction that must be given the computer to do i t s job. call it the what-to-how spectrum. 
at one extreme of the spectrum  the user supplies his intelligence to instruct the machine with precision exactly how to do his job  step-by-step. progress in computer science can be seen as steps away from the extreme 'how' point on the spectrum: the familiar panoply of assembly languages  subroutine libraries  compilers  extensible languages  etc. at the other extreme of the spectrum is the user with his real problem  what he wishes the computer  as his instrument  to do for him   he aspires to communicate what he wants done in a language that is comfortable to him  perhaps english ; via communication modes that are convenient for him  including perhaps  speech or pictures ; with some generality  some vagueness  imprecision  even error; without having to lay out in detail a l l necessary subgoals for adequate performance - with reasonable assurance that he is addressing an intelligent agent that is using knowledge of his world to understand his intent  to f i l l in his vagueness  to make specific his abstractions  to correct his errors  to discover appropriate subgoals  and ultimately to translate what he really wants done into processing steps that define how it shall be done by a real computer. the research activity aimed at creating computer programs that act as  intelligent agents  near the what end of the what-to-how spectrum can be viewed as the long-range goal of ai research.   feigenbaum  1  
       our young science is s t i l l more art than science. art:  the principles or methods governing any craft or branch of learning.  art:  skilled workmanship execution  or agency.  these the dictionary teaches us. knuth t e l l s us that the endeavor of computer programming is an art  in just these ways. the art of constructing intelligent agents is both part of and an extension of the programming art. it is the art of building complex computer programs that represent and reason with knowledge of the world. our art therefore lives in symbiosis with the other worldly arts  whose practitioners - experts of their art - hold the knowledge we need to construct intelligent agents. in most  crafts or branches of learning  what we call  expertise  is the essence of the art. and for the domains of knowledge that we touch with our a r t   it is the  rules of expertise  or the rules of  good judgment  of the expert practitioners of that domain that we seek to transfer to our programs. 
1 	lessons of the past 
       two 	insights 	from 	previous 	work 	are pertinent to this essay. 
       the f i r s t concerns the quest for generality and power of the inference engine used in the performance of intelligent acts  what minsky and papert  see goldstein and papert  1  have labeled  the power strategy  . we must hypothesize from our experience to date that the problem solving power exhibited in an intelligent agent's performance is primarily a consequence of the specialist's knowledge employed by the agent  and only very secondarily related to the generality and power of the inference method employed. our agents must be knowledge-rich  even if they are methods-poor. in 1  reporting the f i r s t major summary-of-results of the dendral program  to be discussed l a t e r     we addressed this issue as follows: 
        ...general problem-solvers are too weak to be used as the basis for building high-performance systems. the behavior of the best general problem-solvers we know  human problem-solvers  is observed to be weak and shallow  except in the areas in which the human problem-solver is a specialist. and it is observed that the transfer of expertise between specialty 

invited pepers-1: feigenbaum 1 

areas is s l i g h t . a chess master is u n l i k e l y to be an expert a l g e b r a i s t or an expert mass spectrum a n a l y s t   e t c . in t h i s view  the expert is the s p e c i a l i s t   w i t h a s p e c i a l i s t ' s knowledge of his area and a s p e c i a l i s t ' s methods and h e u r i s t i c s .    feigenbaum  buchanan and 
lederberg  1  p. 1  
　　　　subsequent evidence from our 	laboratory and a l l others has only confirmed t h i s b e l i e f . 
　　　　ai researchers have d r a m a t i c a l l y s h i f t e d t h e i r view on g e n e r a l i t y and power in the past decade. in 1  the canonical question about the dendral program was:   i t sounds l i k e good chemistry but what does it have to do with a i     in 1  g o l d s t e i n and papert w r i t e of a paradigm s h i f t i n a i : 
　　　　 today there has been a s h i f t in paradigm. the fundamental problem of understanding i n t e l l i g e n c e is not the i d e n t i f i c a t i o n of a few powerful techniques  but rather the question of how to represent large amounts of knowledge in a fashion that permits t h e i r e f f e c t i v e use and i n t e r a c t i o n .    goldstein and papert  
1  
　　　　the second i n s i g h t from past work concerns the nature of the knowledge that an expert b r i n g s to the performance of a task. experience has shown us that t h i s knowledge is l a r g e l y h e u r i s t i c knowledge  e x p e r i e n t i a l   uncertain - mostly  good guesses  and  good p r a c t i c e     in l i e u of facts and r i g o r . experience has also taught us that much of t h i s knowledge is p r i v a t e to the expert  not because he is u n w i l l i n g to share p u b l i c l y how he performs  but because he is unable. he knows more than he is aware of knowing.  why else is the ph.d. or the i n t e r n s h i p a g u i l d - l i k e 
　　　　apprenticeship to a presumed  master of the c r a f t     what the masters r e a l l y know is not w r i t t e n in the textbooks of the masters.  but we have learned also that t h i s p r i v a t e knowledge can be uncovered by the c a r e f u l   painstaking analysis of a second p a r t y   or sometimes by the expert h i m s e l f   operating in the context of a large number of h i g h l y s p e c i f i c performance problems. f i n a l l y   we have learned that expertise is m u l t i f a c e t e d   that the expert brings to bear many and v a r i e d sources of knowledge in performance. the approach to capturing his expertise must proceed on many f r o n t s simultaneously. 
1 	the knowledge engineer 
　　　　the knowledge engineer is that second party j u s t discussed.  an h i s t o r i c a l note about the term. in the mid-1s  john mccarthy  f o r reasons obvious from h i s work  had been d e s c r i b i n g a r t i f i c i a l i n t e l l i g e n c e as  applied epistemology.  
when 	1 	f i r s t described 	the 	dendral 	program to 
donald 	michie in 	1  he 	remarked that 	it was 
 epistemological e n g i n e e r i n g     a clever but ponderous and unpronounceable turn-of-phrase that i s i m p l i f i e d i n t o  knowledge e n g i n e e r i n g .     she   i n deference to my f a v o r i t e knowledge engineer  works i n t e n s i v e l y w i t h an expert to acquire domain-specific knowledge and organize it for use by a program. simultaneously she is matching the t o o l s of the ai workbench to the task at hand - program o r g a n i z a t i o n s   methods of symbolic inference  techniques f o r the s t r u c t u r i n g of symbolic i n f o r m a t i o n   and the l i k e . if the t o o l f i t s   o r nearly f i t s   she uses i t . i f n o t   necessity mothers ai i n v e n t i o n   and a new t o o l gets created. she b u i l d s the e a r l y versions of the i n t e l l i g e n t agent  guided always by her i n t e n t that the program e v e n t u a l l y achieve expert l e v e l s of performance in the task. she r e f i n e s or reconceptualizes the system as the increasing amount of acquired knowledge causes the ai t o o l to  break  or slow down i n t o l e r a b l y . she also r e f i n e s the human interface to the i n t e l l i g e n t agent w i t h several aims: to make the system appear 
 comfortable  to the human user in his l i n g u i s t i c transactions w i t h i t ; to make the system's inference processes understandable to the user; and to make the assistance c o n t r o l l a b l e by the user when  in the context of a r e a l problem  he has an i n s i g h t that p r e v i o u s l y was not e l i c i t e d and therefore not i n c o r p o r a t e d . 
　　　　in the next s e c t i o n   1 wish to explore   i n 
　　　　summary form  some case studies of the knowledge engineer's a r t . 
1 	cases from the knowledge engineer's workshop 
　　　　i w i l l draw m a t e r i a l for t h i s section from the work of my group at stanford. much e x c i t i n g work in knowledge engineering is going on elsewhere. since my i n t e n t is not to survey l i t e r a t u r e but to i l l u s t r a t e themes  at the r i s k 
　　　　of appearing parochial i have used as case s t u d i e s the work i know b e s t . 
invited papers-1: feigenbaum 1 　　　　my c o l l a b o r a t o r s  professors lederberg and buchanan  and i began a series of p r o j e c t s   i n i t i a l l y the development of the dendral program  in 1. we had dual motives: f i r s t   to study s c i e n t i f i c problem solving and d i s c o v e r y   p a r t i c u l a r l y the processes s c i e n t i s t s do use or should use in i n f e r r i n g hypotheses and t h e o r i e s from e m p i r i c a l evidence; and second  to conduct t h i s study in such a way that our experimental programs would one day be of use to working s c i e n t i s t s   p r o v i d i n g i n t e l l i g e n t assistance o n important and d i f f i c u l t problems. by 1  we and our co-workers had gained enough experience that we f e l t comfortable in laying out a program of research encompassing work on theory f o r m a t i o n   knowledge u t i l i z a t i o n   knowledge a c q u i s i t i o n   e x p l a n a t i o n   and knowledge engineering techniques. although there were some surprises along the way 
  l i k e the am program   the general l i n e s of the research are proceeding as envisioned. 
themes 
　　　　as a road map 	to these case s t u d i e s   	it is useful to keep in mind c e r t a i n major themes: 
g e n e r a t l o n - a n d - t e s t : omnipresent in our experiments is the   c l a s s i c a l   generation-andtest framework that has been the hallmark of ai programs for two decades. this is not a consequence of a d o c t r i n a i r e a t t i t u d e on our part about h e u r i s t i c search  but rather of the usefulness and s u f f i c i e n c y of the concept. 
s i t u a t i o n =  action rules: we have chosen to represent the knowledge of experts in t h i s form. making no d o c t r i n a i r e claims for the u n i v e r s a l a p p l i c a b i l i t y of t h i s r e p r e s e n t a t i o n   we nonetheless point to the demonstrated u t i l i t y of the rule-based r e p r e s e n t a t i o n . from t h i s representation flow rather d i r e c t l y many of the c h a r a c t e r i s t i c s of our programs: for example  ease of m o d i f i c a t i o n of the knowledge  ease of explanation. the essence of our approach is that a r u l e must capture a  chunk  of domain knowledge that is meaningful  in and of i t s e l f   to the domain s p e c i a l i s t . thus our rules bear only a h i s t o r i c a l r e l a t i o n s h i p to the production rules used by newell and simon  1  which we view as 
 machine-language programming  of a recognize    act machine. 
the domain-specific knowledge: it plays a c r i t i c a l r o l e in organizing and c o n s t r a i n i n g search. the theme is that in the knowledge is the power. the i n t e r e s t i n g action arises from the knowledge base  not the inference engine. we use knowledge in r u l e form  discussed above   in the form of i n f e r e n t i a l l y - r i c h models based on theory  and in the form of tableaus of symbolic data and r e l a t i o n s h i p s   i . e . f r a m e - l i k e s t r u c t u r e s   . system pr1cesses are made to conform to n a t u r a l 
and convenient representations of the domains p e c i f i c knowledge. 
f l e x i b i l i t y to modify the knowledge base: if the s o - c a l l e d   g r a i n s i z e   of the knowledge r e p r e s e n t a t i o n is chosen properly   i . e . small enough to be comprehensible but large enough to be meaningful to the domain s p e c i a l i s t     then the rule-based approach allows great f l e x i b i l i t y f o r adding  removing  or changing knowledge in the system. 
l i n e - o f - r e a s o n l n g : a c e n t r a l organizing p r i n c i p l e in the design of knowledge-based i n t e l l i g e n t 
agents is the maintenance of a l i n e - o f - r e a s o n i n g that is comprehensible to the domain s p e c i a l i s t . 
this p r i n c i p l e i s   of course  not a l o g i c a l 
necessity  but seems to us to be an engineering p r i n c i p l e of major importance. 
m u l t i p l e sources of knowledge: 	the 	formation and maintenance 	 support  	of 	the l i n e - o f - r e a s o n i n g usually require 	the i n t e g r a t i o n of many disparate sources of 	knowledge. 	the 	r e p r e s e n t a t i o n a l and i n f e r e n t i a l 	problems in 	achieving a 	smooth and e f f e c t i v e i n t e g r a t i o n are 	formidable engineering problems. 
explanation: the a b i l i t y to e x p l a i n the l i n e - o f reasoning in a language convenient to the user is necessary f o r a p p l i c a t i o n and f o r system development   e . g . f o r debugging and for extending the knowledge base . once a g a i n   t h i s is an engineering p r i n c i p l e   but very important. what c o n s t i t u t e s  an e x p l a n a t i o n   is not a simple concept  and considerable thought needs to be g i v e n   in each case  to the s t r u c t u r i n g of explanations. 
cas1 studies 
　　　　in t h i s section i w i l l t r y to i l l u s t r a t e these themes w i t h various case s t u d i e s . 
1 	dendral: 	i n f e r r i n g chemical structures 
1.1 	h i s t o r i c a l note 
　　　　begun in 1  t h i s c o l l a b o r a t i v e project w i t h the stanford mass spectrometry laboratory has become one of the l o n g e s t - l i v e d continuous e f f o r t s in the h i s t o r y of ai  a f a c t that in no small way has c o n t r i b u t e d to i t s success . the basic framework of generation-and-test and rule-based representation has proved rugged and extendable. for us the dendral system has been a fountain of ideas  many of which have found t h e i r way  h i g h l y metamorphosed  i n t o our other p r o j e c t s . for example  our long-standing commitment to r u l e based representations arose out of our  successful  attempt to head off the imminent o s s i f i c a t i o n of dendral caused by the rapid accumulation of new knowledge in the system around 1. 
1.1 	task 
　　　　to enumerate p l a u s i b l e s t r u c t u r e s  atom-bond graphs  f o r organic molecules  given two kinds of i n f o r m a t i o n : a n a l y t i c instrument data from a mass spectrometer and a nuclear magnetic resonance spectrometer; and user-supplied c o n s t r a i n t s on the answers  derived from any other source of knowledge   i n s t r u m e n t a l or contextual  a v a i l a b l e to the user. 

invited papers-1: feigenbaurn 1 

1.1 	representations 
       chemical structures are represented as nodelink graphs of atoms  nodes  and bonds  links . constraints on search are represented as subgraphs  atomic configurations  to be denied or preferred. the empirical theory of mass spectrometry is represented by a set of rules of the general form: 
situation: particular atomic configuration  subgraph  
probability  p  
of occurring 
action: fragmentation of the particular configuration 
 breaking links  
rules of this form are natural and expressive to mass spectrometrlsts. 
1.a 	sketch of method 
       dendral's inference procedure is a heuristic search that takes place in three stages  without feedback: plan-generate-test. 
        generate   a program called congen  is a generation process for plausible structures. its foundation is a combinatorial algorithm  with mathematically proven properties of completeness and non-redundant generation  that can produce a l l the topologically legal candidate structures. constraints supplied by the user or by the  plan  process prune and steer the generation to produce the plausible set   i . e . those satisfying the constraints  and not the enormous legal set. 
        test  refines the evaluation of plausibility  discarding less worthy candidates and rank-ordering the remainder for examination by the user.  test  f i r s t produces a  predicted  set of instrument data for each plausible candidate  using the rules described  it then evaluates the worth of each candidate by comparing its predicted data with the actual input data. the evaluation is based on heuristic criteria of goodness-of-fit. thus   test  selects the  best  explanations of the data. 
        plan  produces direct   i . e . not chained  inference about likely substructure in the molecule from patterns in the data that are indicative of the presence of the substructure.  patterns in the data trigger the left-hand-sides of substructure rules . though composed of many atoms whose interconnections are given  the substructure can be manipulated as atom-like by  generate.  aggregating many units entering into a combinatorial process into fewer higher-level units reduces the size of the combinatorial search space.  plan  sets up the search space so as to be relevent to the input data.  generate is the inference tactician;  plan  is the inference strategist. there is a separate  plan  package for each type of instrument data  but each package passes substructures  subgraphs  to  generate.  thus  there is a uniform interface between  plan  and  generate.  user-supplied constraints enter this interface  directly or from user-assist packages  in the form of substructures. 
1.1 	sources of knowledge 
       the various sources of knowledge used by the dendral system are: 
       valences  legal connections of atoms ; stable and unstable configurations of atoms; rules for mass spectrometry fragmentations; rules for nmr shifts; expert's rules for planning and evaluation; user-supplied constraints 
 contextual   
1.1 	results 
       dendral's structure elucidation abilities are  paradoxically  both very general and very narrow. in general  dendral handles a l l molecules  cyclic and tree-like. in pure structure elucidation under constraints  without instrument data  congen is unrivaled by human performance. in structure elucidation with instrument data  dendral's performance rivals expert human performance only for a small number of molecular families for which the program has been given specialist's knowledge  namely the families of interest to our chemist collaborators. 1 w i l l spare this computer science audience the l i s t of names of these families. within these areas of knowledge-intensive specialization  dendral's performance is usually not only much faster but also more accurate than expert human performance. 
       the statement just made summarizes thousands of runs of dendral on problems of interest to our experts  their colleagues  and their students. the results obtained  along with the knowledge that had to be given to dendral to obtain them  are published in major journals of chemistry. to date  1 papers have been published there  under a series t i t l e  applications of a r t i f i c i a l intelligence for chemical inference:  specific subject    see references . 
	the 	dendral system 	is in 	everyday 	use by 
invited papers-1: feisenbaum 1 stanford chemists  their collaborators at other universities and collaborating or otherwise interested chemists in industry. users outside stanford access the system over commercial computer/communications network. the problems they are solving are often d i f f i c u l t and novel. the british government is currently supporting work at edinburgh aimed at transferring dendral to 
industrial user communities in the uk.. 
1.1 	discussion 
       representation and extensibility. the representation chosen for the molecules  constraints  and rules of instrument data interpretation is sufficiently close to that used by chemists in thinking about structure elucidation that the knowledge base has been extended smoothly and easily  mostly by chemists themselves in recent years. only one major reprogramming effort took place in last 1 years - when a new generator was created to deal with 
cyclic structures. 
       representation and the integration of multiple sources of knowledge. the generally d i f f i c u l t problem of integrating various sources of knowledge has been made easy in dendral by careful engineering of the representations of objects  constraints  and rules. we insisted on a common language of compatibility of the representations with each other and with the inference processes: the language of molecular structure expressed as graphs. this leads to a straightforward procedure for adding a new source of knowledge  say  for example  the knowledge associated with a new type of instrument data. the procedure is this: write rules that describe the effect of the physical processes of the instrument on molecules using the situation    action form with molecular graphs on both sides; any special inference process using these rules must pass its results to the generator only !  in the common graph language. 
       it is today widely believed in ai that the use of many diverse sources of knowledge in problem solving and data interpretation has a strong effect on quality of performance. how strong i s   of course  domain-dependent  but the impact of bringing just one additional source of knowledge to bear on a problem can be startling. in one d i f f i c u l t  but not unusually d i f f i c u l t   mass spectrum analysis problem*  the program using its mass spectrometry knowledge alone would have generated an impossibly large set of plausible candidates  over 1 million! . our engineering response to this was to add another source of data and knowledge  proton nmr. the addition on a simple interpretive theory of this nmr data  from which the program could infer a few additional constraints  reduced the set of plausible candidates to one  the right structure! this was not an isolated result but showed up dozens of times in subsequent analyses. 
* the 	analysis of an 	acyclic amine 	with formula c1n. 
	dendral 	and data. 	dendral's 	robust models 
 topological  chemical  instrumental  permit a strategy of finding solutions by generating hypothetical  correct answers  and choosing among these with c r i t i c a l tests. this strategy is opposite to that of piecing together the implications of each data point to form a hypothesis. we call dendral's strategy largely model-driven  and the other data-driven. the consequence of having enough knowledge to do model-driven analysis is a large reduction in the amount of data that must be examined since data is being used mostly for verification of possible answers  in a typical dendral mass spectrum analysis  usually no more than about 1 data points out of a typical total of 1 points are processed. this important point about data reduction and focus-of-attention has been discussed before by gregory  1  and by the vision and speech research groups  but is not 
widely understood. 
	conclusion. 	dendral was an early 	herald of 
ai's shift to the knowledge-based paradigm. it demonstrated the point of the primacy of domainspecific knowledge in achieving expert levels of performance. its development brought to the surface important problems of knowledge representation  acquisition  and use. it showed that  by and large  the ai tools of the f i r s t decade were sufficient to cope with the demands of a complex scientific problem-solving task or were readily extended to handle unforseen d i f f i c u l t i e s . it demonstrated that ai's conceptual and programming tools were capable of producing programs of applications interest  albeit in narrow specialties. such a demonstration of competence and sufficiency was important for the credibility of the ai field at a c r i t i c a l juncture in its history. 
1 	meta-dendral: inferring rules of mass spectrometry 
1.1 	historical note 
       the meta-dendral program is a case study in automatic acquisition of domain knowledge. it arose out of our dendral work for two reasons: f i r s t   a decision that with dendral we had a sufficiently firm foundation on which to pursue our long-standing interest in processes of scientific theory formation; second  by a recognition that the acquisition of domain knowledge was the bottleneck problem in the building of applications-oriented intelligent agents. 
1.1 	task 
invited papers-1: feignbaum 1        meta-dendral's job is to infer rules of fragmentation of molecules in a mass spectrometer for possible later use by the dendral performance program. the inference is to be made from actual spectra recorded from known molecular structures. the output of the system is the set of fragmentation rules discovered  summary of the evidence supporting each rule  and a summary of contra-indicating evidence. user-supplied constraints can also be input to force the form of rules along desired lines. 
1.1 	representations 
       the rules are  of course  of the same form as used by dendral that was described earlier. 
1.a 	sketch of method 
       meta-dendral  like dendral  uses the generation-and-test framework. the process is organized in three stages: reinterpret the data and summarize evidence  intsum ; generate plausible candidates for rules  rulegen ; test and refine the set of plausible rules  rulemod . 
       intsum: gives every data point in every spectrum an interpretation as a possible  highly specific  fragmentation. it then summarizes statistically the  weight of evidence  for fragmentations and for atomic configurations that cause these fragmentations. thus  the job of intsum is to translate data to dendral subgraphs and bond-breaks  and to summarize the evidence accordingly. 
       rulegen: conducts a heuristic search of the space of a l l rules that are legal under the dendral rule syntax and the user-supplied constraints. it searches for plausible rules  i.e. those for which positive evidence exists. a search path is pruned when there is no evidence for rules of the class just generated. the search tree begins with the  single  most general rule 
 loosely 	put  	 anything  	fragments 	from 
 anything   and proceeds level-by-level toward more detailed specifications of the  anything.  the heuristic stopping criterion measures whether a rule being generated has become too specific  in particular whether it is applicable to too few molecules of the input set. similarly there is a criterion for deciding whether an emerging rule is too general. thus  the output of rulegen is a set of candidate rules for which there is positive evidence. 
       rulemod: tests the candidate rule set using more complex c r i t e r i a   including the presence of negative evidence. it removes redundancies in the candidate rule set; merges rules that are supported by the same evidence; tries further specialization of candidates to remove negative evidence; and tries further generalization that preserves positive evidence. 
1.1 	results 
       meta-dendral produces rule sets that r i v a l in quality those produced by our collaborating experts. in some tests  meta-dendral recreated rule sets that we had previously acquired from our experts during the dendral project. in a more stringent test involving members of a family of complex ringed molecules for which the mass spectral theory had not been completely worked out by chemists  meta-dendral discovered rule sets for each subfamily. the rules were judged by experts to be excellent and a paper describing them was recently published in a major chemical journal  buchanan  smith  et a l   1 . 
       in a test of the generality of the approach  a version of the meta-dendral program is currently being applied to the discovery of rules for the analysis of nuclear magnetic resonance data. 
1 	mycin and teiresias: medical diagnosis 
1.1 	historical note 
       mycin originated in the ph.d. thesis of e. shortliffe  now shortliffe  m.d. as well   in collaboration with the infectious disease group at the stanford medical school  shortliffe  1 . teiresias  the ph.d. thesis work of r. davis  arose from issues and problems indicated by the mycin project but generalized by davis beyond the bounds of medical diagnosis applications  davis  1 . other mycin-related theses are in progress. 
1.1 	tasks 
       the mycin performance task is diagnosis of blood infections and meningitis infections and the recommendation of drug treatment. mycin conducts a consultation  in english  with a physician-user about a patient case  constructing llnes-ofreasonlng leading to the diagnosis and treatment plan. 
       the teiresias knowledge acquisition task can be described as follows: 
       in the context of a particular consultation  confront the expert with a diagnosis with which he does not agree. lead him systematically back through the line-of-reasonlng that produced the diagnosis to the point at which he indicates the analysis went awry. interact with the expert to modify offending rules or to acquire new rules. rerun the consultation to test the solution and gain the expert's concurrence. 
1.1 	representations: 
mycin's rules are of the form: 

invited papers-1: feigenbaun 1 

if   c o n j u n c t i v e clauses  then  implication  	1 a 	sketch of method 
here is an example of a mycin r u l e f o r blood 	mycin 	employs 	a 	g e n e r a t i o n - a n d - t e s t 
i n f e c t i o n s . 	procedure of 	a f a m i l i a r 	s o r t . the 	generation of 
	steps in the l i n e - o f - r e a s o n i n g is 	accomplished by 
	backward chaining of the r u l e s . an 	i f - s i d e clause 
	is e i t h e r immediately true or f a l s e 	 as determined 
	by p a t i e n t or 	t e s t data entered by 	the physician 
	in 	the 	c o n s u l t a t i o n   ; 	or is 	to 	be 	decided by 
rule 1 	subgoaling. 	thus  	  t e s t   	i s 	i n t e r l e a v e d 	w i t h 
	' generation  	and 	serves to 	prune 	out i n c o r r e c t 
i f : 	l i n e s - o f - r e a s o n i n g . 
1  the s i t e of 	the c u l t u r e is b l o o d   and 
1  the gram s t a i n of the organism is 	each 	r u l e 	supplied 	by 	an 	expert 	has 
	gramneg  and 	associated 	w i t h 	it 	a 	 degree 	of 	c e r t a i n t y   
1  the morphology of the organism is 	representing 	the 	e x p e r t ' s 	confidence 	in 	the 
	r o d   and 	v a l i d i t y 	of the 	r u l e  a 	number from 	i 	to 1 . 
1  the p a t i e n t is a compromised host 	mycin uses a p a r t i c u l a r ad-hoc but simple model of 
	inexact 	reasoning 	to 	cumulate 	the 	degrees 	of 
then: 	c e r t a i n t y of the r u l e s used in an 	inference chain 
there is suggestive evidence 	 .1  	that 	  s h o r t l i f f e and buchanan  	1 . 
the i d e n t i t y of the organism is 
pseudomonas-aeruglnosa 	it 	f o l l o w s that 	there may 	be a 	number of 
	 somewhat 	t r u e   	l i n e s - o f - r e a s o n i n g - some 
	i n d i c a t i n g one d i a g n o s i s   	some i n d i c a t i n g another. 
	a l l  above a threshold  are used by the 	system as 
	sources of 	knowledge i n d i c a t i n g 	p l a u s i b l e l i n e s -
o f - r e a s o n i n g . 
	teiresias' 	r u l e a c q u i s i t i o n process is based 
on a record of mycin's search. rule a c q u i s i t i o n is 
	guided by 	a set of 	r u l e models that 	d i c t a t e the 
teiresias 	allows 	the 	r e p r e s e n t a t i o n 	of 	form and i n d i c a t e the l i k e l y content of new r u l e s . 
mycin-like 	r u l e s 	governing 	the 	use 	of 	other 	rule 	models are 	not 	given in 	advance  	but are 
r u l e s   i . e . 	rule-based 	s t r a t e g i e s . 	an 	example 	i n f e r r e d 	from 	the 	knowledge 	base 	of 	e x i s t i n g 
f o l l o w s . 	r u l e s . 
	1.1 	language of i n t e r a c t i o n 
	the 	language used 	looks l i k e 	it 	might be 
	english but 	is a c t u a l l y the 	d i a l e c t 	    doctor-ese  
	used 	by 	members 	of the 	t r i b e 	of 	healing a r t s 
	p r a c t i t i o n e r s . 	reasonably 	simple 	language 
	processing 	methods s u f f i c e . 	when 	ambiguities of 
	i n t e r p r e t a t i o n are encountered  	they are 	fed back 
metarule 1 	to the user f o r decisions about meaning. 
i f : 
1  the p a t i e n t is a compromised host  and 	1.1 	example diagnosis and treatment plan 
1  there are r u l e s which mention in t h e i r 
	premise 	pseudomonas 	the f o l l o w i n g is 	an example of 	a diagnosis 
1  there are r u l e s which mention in t h e i r 	reported by mycin to one of i t s users 	f o l l o w i n g a 
	premise 	k l e b s i e l l a s 	c o n s u l t a t i o n . an example c o n s u l t a t i o n w i l l 	not be 
	shown  but one 	can be found in 	s h o r t l i f f e ' s book 
then: 	  s h o r t l i f f e   	1 . 
there is suggestive evidence 	 .1  	that 	the 
former should be done before the l a t t e r . 
 my therapy recommendations w i l l be designed to t r e a t f o r organisms that are e i t h e r very l i k e l y o r   although less l i k e l y   would have 
a s i g n i f i c a n t e f f e c t on therapy s e l e c t i o n 
	i f they were present. 	i t i s 	important 	t o 
invited papers-1: feigenbaum 
1 

cover for the following probable infection s  and associated organism s : 
infection-1 is cystitis 
 ltem 1  pseudomonas-cepacia  organism-1  
 ltem 1  citrobacter-diversus  organism-1  
 item 1  e.coli  organism-1  
infection-1 is upper-respiratory-infection 
	 itero 1  listeria 	 organism-1  
infection-1 is bacteremia 
 item 1  enterococcus  organism-i  
 rec-1  my preferred therapy recommendation is as follows: 
in order to cover for items  1 1 a 1 : 
give the following in combination: 
1  kanamycin 
dose: 1 mg  1 mg/kg  ql1h im  or iv  for 1 days 
comments: modify dose in renal failure 
1  penicillin 
dose: 1 1 units  1 units/kg  q1h iv for 1 days 
1.1 	results 
       mycin is currently being prepared for clinical evaluation. in a preliminary evaluation  done outside of the clinical setting  a panel of expert judges was asked to rate mycin's performance along a number of dimensions  e.g. infecting organism identification  organism significance . in 1% of the cases submitted to the judges  a majority of the judges said that the program's decisions were the-same-as or as-good-as the decisions they would have made. 
1.1 	explanation 
       mycin can expose its line of reasoning by offering explanations of various kinds.  why  and  how  questions can be asked by the user during the consultation.  why  is the user's way of inquiring   why do you want to know that    how  is his way of asking   how did you conclude t h a t . . .     in a post-consultation  he can similarly inquire about how the diagnostic conclusions were reached  and inquire about the reasons why certain other conclusions were ruled out. examples of the mycin-teiresias explanation capabilities follow: 
mycin: is the patient's illness with organism-1 a hospital-acquired infection  user: why 
teiresias:   i . e . why is it important to determine whether or not the infection with organism-l was acquired while the patient was hospitalized   
 1  this w i l l aid in determining the category of organism-1. 
it has already been established that 
 1  the gram stain of organism-l is gramneg  and 
 1 the morphology of organism-1 is rod  and 
 1  the aerobicity of organism-1 is facultative 
therefore  	if 
 1  the infection with organism-1 was not acquired while the patient was hospitalized then 
there is strongly suggestive evidence  .1  that the category of organism-1 is 
enterobacteriaceae 
also: 	there is weakly suggestive evidence 
 .1  that the identity of 
organism-1 is pseudomonas-aeruginosa 
 rule 1  
user: 	how 1 
teiresias:   i . e . how was it established that the aerobicity of organism-1 is facultative   
the following were used: 
 1  rule 1 indicated there is strongly suggestive evidence  .1  that the aerobicity of organism-1 is facultative 
 1  rule 1 indicated there is weakly suggestive evidence  .1  that the aerobicity of organism-1 is anaerobic 
since this gave a cumulative cf of  .1  for facultative  and  .1  for anaerobic  it has been established that the aerobicity of organism-1 is facultative. 
user: 	why didn't you consider 

invitert paoers-1: feigenbaum 1 

streptococcus as a possibility for organism-1  
teiresias: the f o l l o w i n g r u l e could have been used to determine that the i d e n t i f y of organism-1 was streptococcus: rule 1 
but clause 1   the morphology of the organism is coccus   was already known to be f a l s e f o r organism-1  so the r u l e was never t r i e d . 
1.1 	discussion 
　　　　a few short comments aimed at knowledge engineering are in order. 
　　　　english is the language most n a t u r a l and comfortable f o r our experts and users  and was t h e r e f o r e the language chosen for i n t e r a c t i v e c o n s u l t a t i o n   e x p l a n a t i o n   and e x t e r n a l 
　　　　r e p r e s e n t a t i o n of the r u l e s  the i n t e r n a l format is interlisp . this s i t u a t i o n is not p e c u l i a r to d o c t o r s ; in most areas of a p p l i c a t i o n of i n t e l l i g e n t agents i b e l i e v e that english   i . e . n a t u r a l language  w i l l be the language of choice. programming an english language processor and f r o n t - e n d to such systems is not a scary e n t e r p r i s e because: 
	a  the 	domain 	is 	s p e c i a l i z e d   	so 	that 
p o s s i b l e i n t e r p r e t a t i o n s are c o n s t r a i n e d . 
　　　　b   s p e c i a l i s t - t a l k i s r e p l e t e w i t h standard j a r g o n and stereotyped ways of expressing knowledge and q u e r i e s - j u s t r i g h t f o r t e x t templates  simple grammars and other simple processing schemes. 
　　　　c the ambiguity of i n t e r p r e t a t i o n r e s u l t i n g from simple schemes can be d e a l t w i t h e a s i l y by feeding back i n t e r p r e t a t i o n s f o r c o n f i r m a t i o n . i f t h i s is done w i t h a pleasant  i d i d n ' t q u i t e understand y o u . . .   tone  i t i s not i r r i t a t i n g t o 
　　　　the user. 
　　　　english may be e x a c t l y the wrong language for r e p r e s e n t a t i o n and i n t e r a c t i o n in some domains. it would be awkward  to say the l e a s t   to represent dendral's chemical s t r u c t u r e s and knowledge of mass spectrometry in e n g l i s h   or to i n t e r a c t about these w i t h a user. 
　　　　simple explanation schemes have been a part of the ai scene f o r a number of years and are not hard to implement. really good models of what explanation is as a t r a n s a c t i o n between user and agent  w i t h programs to implement these models  w i l l be the subject  1 p r e d i c t   of much f u t u r e research i n a i . 
　　　　without the explanation c a p a b i l i t y   i a s s e r t   user acceptance of mycin would have been n i l   and there would have been a g r e a t l y diminished e f f e c t i v e n e s s and c o n t r i b u t i o n of our e x p e r t s . 
　　　　mycin was the f i r s t of our programs that forced us to deal w i t h what we had always understood: that e x p e r t s ' knowledge is u n c e r t a i n and that our inference engines had to be made to reason w i t h t h i s u n c e r t a i n t y . i t i s less important that the inexact reasoning scheme be f o r m a l   r i g o r o u s   and uniform than it is f o r the scheme to be n a t u r a l to and e a s i l y understandable by the experts and users. 
　　　　a l l of these points can be summarized by saying that mycin and i t s teiresias adjunct are experiments in the design of a see-through system  whose representations and processes are almost t r a n s p a r e n t l y c l e a r to the domain s p e c i a l i s t .  almost  here is equivalent to   w i t h a few minutes of i n t r o d u c t o r y d e s c r i p t i o n   . the various pieces of mycin - the backward c h a i n i n g   the english t r a n s a c t i o n s   the e x p l a n a t i o n s   e t c . - are each simple in concept and r e a l i z a t i o n . but there are great v i r t u e s to s i m p l i c i t y in system design; and viewed as a t o t a l i n t e l l i g e n t agent system  mycin/teiresias is one of the best engineered. 
1 	su/x: 	s i g n a l understanding 
1.1 	h i s t o r i c a l note 
　　　　su/x is a system design that was tested in an a p p l i c a t i o n whose d e t a i l s are c l a s s i f i e d . because of t h i s   the ensuing discussion w i l l appear considerably less concrete and t a n g i b l e than the preceding case s t u d i e s . this system design was done by h.p. n i l and me  and was s t r o n g l y influenced by the cmu hearsay ii system design. 
1.1 	task 
　　　　su/x's task is the formation and c o n t i n u a l 
　　　　u p d a t i n g   over long periods of time  of hypotheses about the i d e n t i t y   l o c a t i o n   and v e l o c i t y of o b j e c t s in a physical space. the output desired is a d i s p l a y of the   c u r r e n t best hypotheses  w i t h f u l l explanation of the support f o r each. there are two types of input d a t a : the primary s i g n a l   t o be understood ; and a u x i l i a r y symbolic data   t o supply context f o r the understanding . the primary s i g n a l s are s p e c t r a   represented as d e s c r i p t i o n s of the s p e c t r a l l i n e s . the various spectra cover the p h y s i c a l space w i t h some s p a t i a l 
　　　　o v e r l a p . 

invited papers-1: felgenbaum 1 

1.1 	representations 
       the rules given by the expert about objects  their behavior  and the interpretation of signal data from them are a l l represented in the situation =  action form. the  situations  constitute invoking conditions and the  actions  are processes that modify the current hypotheses  post unresolved issues  recompute evaluations  etc. the expert's knowledge of how to do analysis in the task is also represented in rule form. these strategy rules replace the normal executive program. 
       the situation-hypothesis is represented as a node-link graph  tree-like in that it has distinct  levels   each representing a degree of abstraction  or aggregation  that is natural to the expert in his understanding of the domain. a node represents an hypothesis; a link to that node represents support for that hypothesis  as in hearsay 1   support from above  or  support from below  .  lower  levels are concerned with the specifics of the signal data.  higher  levels represent symbolic abstractions. 
1.1 	sketch of method 
       the situation-hypothesis is formed incrementally. as the situation unfolds over time  the triggering of rules modifies or discards existing hypotheses  adds new ones  or changes support values. the situation-hypothesis is a common workspace   blackboard   in hearsay jargon  for a l l the rules. 
       in general  the incremental steps toward a more complete and refined situation-hypothesis can be viewed as a sequence of local generate-and-test a c t i v i t i e s . some of the rules are plausible move generators  generating either nodes or links. other rules are evaluators  testing and modifying node descriptions. 
       in typical operation  new data is submitted for processing  say  n time-units of new data . this initiates a flurry of rule-triggerings and consequently rule-actions  called  events  . some events are direct consequences of the data; other events arise in a cascade-like fashion from the triggering of rules. auxiliary symbolic data also cause events  usually affecting the higher levels of the hypothesis. as a consequence  supportfrom-above for the lower level processes is made available; and expectations of possible lower level events can be formed. eventually a l l the relevant rules have their say and the system becomes quiescent  thereby triggering the input of new data to re-energize the inference activity. 
       the system uses the simplifying strategy of maintaining only one  best  situation-hypothesis at any moment  modifying it incrementally as required by the changing data. this approach is made feasible by several characteristics of the domain. first  there is the strong continuity over time of objects and their behaviors  specifically  they do not change radically over time  or behave radically differently over short periods . second  a single problem  identity  location and velocity of a particular set of 
objects  persists over numerous data gathering periods.  compare this to speech understanding in which each sentence is spoken just once  and each presents a new and different problem.  finally  the system's hypothesis is typically  almost right   in part because it gets numerous opportunities to refine the solution   i . e . the numerous data gathering periods   and in part because the availability of many knowledge sources tends to over-determine the solution. as a result of a l l of these  the current best hypothesis changes only slowly with time  and hence keeping only the current best is a feasible approach. 
       of interest are the time-based events. these rule-like expressions  created by certain rules  trigger upon the passage of specified amounts of time. they implement various  wait-and-see  strategies of analysis that are useful in the domain. 
1.1 	results 
       in the test application  using signal data generated by a simulation program because real data was not available  the program achieved expert levels of performance over a span of test problems. some problems were d i f f i c u l t because there was very l i t t l e primary signal to support inference. others were d i f f i c u l t because too much signal induced a plethora of alternatives with much ambiguity. 
       a modified su/x design is currently being used as the basis for an application to the interpretation of x-ray crystallographic data  the crysalis program mentioned later. 
1.1 	discussion 
       the role of the auxiliary symbolic sources of data is of c r i t i c a l importance. they supply a symbolic model of the existing situation that is used to generate expectations of events to be observed in the data stream. this allows flow of inferences from higher levels of abstraction to lower. such a process  so familiar to al researchers  apparently is almost unrecognized among signal processing engineers. in the application task  the expectation-driven analysis is essential in controlling the combinatorial processing explosion at the lower levels exactly the explosion that forces the traditional signal processing engineers to seek out the largest possible number-cruncher for their work. 
       the design of appropriate explanations for the user takes an interesting twist in su/x. the 

invited papers-1: feisenbaum 1 

situation-hypothesis unfolds piecemeal over time  but the  appropriate  explanation for the user is one that focuses on individual objects over time. thus the appropriate explanation must be synthesized from a history of a l l the events that led up to the current hypothesis. contrast this with the mycin-teiresias reporting of rule invocations in the construction of a reasoning chain. 
       since its knowledge base and its auxiliary symbolic data give it a model-of-the-situation that strongly constrains interpretation of the primary data stream  su/x is relatively unperturbed by errorful or missing data. these data conditions merely cause fluctuations in the c r e d i b i l i t y of individual hypotheses and/or the. creation of the  wait-and-see  events. su/x can be  but has not yet been  used to control sensors. since its rules specify what types and values of evidence are necessary to establish support  and since it is constantly processing a complete hypothesis structure  it can request   c r i t i c a l readings  from the sensors. in general  this allows an efficient use of limited sensor bandwidth and data acquisition processing capability. 
1 	other case studies 
       space does not allow more than just a brief sketch of other interesting projects that have been completed or are in progress. 
1.1 	am; mathematical discovery 
       am is a knowledge-based system that conjectures interesting concepts in elementary mathematics. it is a discoverer of interesting theorems to prove  not a theorem proving program. it was conceived and executed by d. lenat for his ph.d. thesis  and is reported by him in these proceedings   an overview of am  . 
       am's knowledge is basically of two types: rules that suggest possibly interesting new concepts from previously conjectured concepts; and rules that evaluate the mathematical 
 interestingness  	of 	a 	conjecture. 	these rules 
attempt 	to capture 	the 	expertise 	of 	the professional mathematician 	at 	the 	task 	of mathematical discovery. 	though lenat 	is 	not a professional 	mathematician  	he 	was 	able successfully to serve 	as his 	own expert 	in the building of this program. 
       am conducts a heuristic search through the space of concepts creatable from its rules. its basic framework is generation-and-test. the generation is plausible move generation  as indicated by the rules for formation of new concepts. the test is the evaluation of  interestingness.  of particular note is the method of test-by-example that lends the flavor of scientific hypothesis testing to the enterprise of mathematical discovery. 
       initialized with concepts of elementary set theory  it conjectured concepts in elementary number theory  such as  add    multiply   by four distinct paths!    primes   the unique factorization theorem  and a concept similar to primes but previously not much studied called  maximally divisible numbers.  
1.1 	molgen; planning experiments in molecular genetics 
       molgen   a collaboration with the stanford genetics department  is work in progress. molgen's task is to provide intelligent advice to a molecular geneticist on the planning of experiments involving the manipulation of dna. the geneticist has various kinds of laboratory techniques available for changing dna material  cuts  joins  insertions  deletions  and so on ; techniques for determining the biological consequences of the changes; various instruments for measuring effects; various chemical methods for inducing  f a c i l i t a t i n g   or inhibiting changes; and many other tools. 
       molgen w i l l offer planning assistance in organizing and sequencing such tools to accomplish an experimental goal. in addition molgen w i l l check user-provided experiment plans for f e a s i b i l i t y ; and its knowledge base w i l l be a repository for the rapidly expanding knowledge of this specialty  available by interrogation. 
       current efforts to engineer a knowledge-base management system for molgen are described by martin et. a l . in a paper in these proceedings. 
this subsystem uses and extends the techniques of the teiresias system discussed earlier. 
       in molgen the problem of integration of many diverse sources of knowledge is central since the essence of the experiment planning process is the successful merging of biological  genetic  chemical  topological  and instrument knowledge. in molgen the problem of representing processes is also brought into focus since the expert's knowledge of experimental strategies - protoplans - must also be represented and put to use. 
1.1 crysal1s; inferring protein structure from electron density maps 
invited papers-1: feigenbaum 1        crysalis  too  is work in progress. its task is to hypothesize the structure of a protein from a map of electron density that is derived from xray crystallographic data. the map is threedimensional  and the contour information is crude and highly ambiguous. interpretation is guided and supported by auxiliary information  of which the amino acid sequence of the protein's backbone is the most important. density map interpretation 
is a p r o t e i n chemist's a r t . as always  capturing t h i s a r t in h e u r i s t i c rules and p u t t i n g it to use 
w i t h an inference engine is the p r o j e c t ' s g o a l . 
　　　　the inference engine for crysalis is a m o d i f i c a t i o n of the su/x system design described above. the hypothesis formation process must deal w i t h many l e v e l s of possibly u s e f u l aggregation and a b s t r a c t i o n . for example  the map i t s e l f can be viewed as c o n s i s t i n g of  peaks   or  peaks and v a l l e y s     or   s k e l e t o n .   the p r o t e i n model has  atoms    amide p l a n e s      amino acid s i d e c h a i n s     and even massive substructures such as   h e l i c e s .   p r o t e i n molecules are so complex that a systematic generation-and-test s t r a t e g y l i k e dendral's is not f e a s i b l e . incremental piecing together of the hypothesis using region-growing methods is necessary. 
　　　　the crysalis design   a l i a s su/p  is described in a recent paper by n i l and feigenbaum  1 . 
	a 	summary of case studies 
　　　　some of the themes presented e a r l i e r need no r e c a p i t u l a t i o n   but i wish to r e v i s i t three here: g e n e r a t i o n - a n d - t e s t ; s i t u a t i o n =  a c t i o n r u l e s ; and explanations. 
1 	generation and test 
　　　　a i r c r a f t come in a wide v a r i e t y of s i z e s   shapes  and f u n c t i o n a l designs and they are applied in very many ways. but almost a l l that f l y do so because of the u n i f y i n g physical p r i n c i p l e of l i f t by a i r f l o w ; the others are described by e x c e p t i o n . so it is w i t h i n t e l l i g e n t agent programs and  the i n f o r m a t i o n processing psychologists t e l l us  w i t h people. one u n i f y i n g p r i n c i p l e o f   i n t e l l i g e n c e   i s generation-andt e s t . no wonder that it has been so thoroughly studied in ai research! 
　　　　in the case s t u d i e s   generation is manifested in a v a r i e t y of forms and processing schemes. there are l e g a l move generators defined f o r m a l l y by a generating a l g o r i t h m  dendral's graph generating a l g o r i t h m   ; or by a l o g i c a l r u l e of inference  mycin's backward c h a i n i n g   . when l e g a l move generation is not possible or not e f f i c i e n t   there are p l a u s i b l e move generators  as in su/x and am . sometimes generation is i n t e r l e a v e d w i t h t e s t i n g  as in mycin  su/x  and am . in one case  a l l generation precedes t e s t i n g 
 dendral . one case  meta-dendral  is mixed  w i t h some t e s t i n g taking place during generation  some a f t e r . 
　　　　test also shows great v a r i e t y . there are simple t e s t s  mycin:   i s the organism a e r o b i c     ; su/x:  has a s p e c t r a l l i n e appeared at p o s i t i o n 
p    some t e s t s are complex h e u r i s t i c evaluations  am:   i s the new concept ' i n t e r e s t i n g '     ; molgen:   w i l l the r e a c t i o n a c t u a l l y take place    sometimes a complex test can involve feedback to modify the object being tested  as in meta-
dendral . 
　　　　the evidence from our case studies supports the a s s e r t i o n by newell and simon that g e n e r a t i o n and-test is a law of our science  newell and simon  1 . 
1 	s i t u a t i o n ＊   a c t i o n r u l e s 
　　　　s i t u a t i o n    a c t i o n r u l e s are used to represent e x p e r t s ' knowledge in a l l of the case s t u d i e s . always the s i t u a t i o n part i n d i c a t e s the s p e c i f i c c o n d i t i o n s under which the r u l e is r e l e v a n t . the a c t i o n part can be simple  mycin: conclude presence of p a r t i c u l a r organism; dendral: conclude break of p a r t i c u l a r bond . or it can be q u i t e complex  molgen: an e x p e r i e n t i a l procedure . the o v e r r i d i n g c o n s i d e r a t i o n in making design choices is that the r u l e form chosen be able to represent c l e a r l y and d i r e c t l y what the expert wishes to express about the domain. as i l l u s t r a t e d   t h i s may necessitate a wide v a r i a t i o n 
　　　　in r u l e syntax and semantics. 
　　　　from a study of a l l the p r o j e c t s   a r e g u l a r i t y emerges. a s a l i e n t feature of the s i t u a t i o n -  a c t i o n r u l e technique for representing e x p e r t ' s knowledge is the modularity of the knowledge base  w i t h the concomitant f l e x i b i l i t y to add or change the knowledge e a s i l y as the e x p e r t s ' understanding of the domain changes. here too one must be pragmatic  not d o c t r i n a i r e . a technique such as t h i s can not represent modularity of knowledge if that modularity does not e x i s t in the domain. the v i r t u e of t h i s technique is that it serves as a 
　　　　framework f o r d i s c o v e r i n g what modularity e x i s t s in the domain. discovery may feed back to cause r e f o r m u l a t i o n of the knowledge toward greater m o d u l a r i t y . 
　　　　f i n a l l y   our case studies have shown that s t r a t e g y knowledge can be captured in r u l e form. in teires1as  the metarules capture knowledge of how to deploy domain knowledge; in su/x  the s t r a t e g y r u l e s represent the e x p e r t s ' knowledge of  how to analyze  in the domain. 
1 	explanation 
　　　　most of the programs  and a l l of the more recent ones  make a v a i l a b l e an e x p l a n a t i o n c a p a b i l i t y f o r the user  be he end-user or system developer. our focus on end-users in a p p l i c a t i o n s domains has forced a t t e n t i o n to human engineering issues  in p a r t i c u l a r making the need f o r the explanation c a p a b i l i t y imperative. 
　　　　the i n t e l l i g e n t agent viewpoint seems to us to demand that the agent be able to e x p l a i n i t s a c t i v i t y ; else the question arises of who is in 

invited papers-1: feigenbaum 1 

c o n t r o l of the agent's a c t i v i t y . the issue is not academic or p h i l o s o p h i c a l . it is an engineering issue that has a r i s e n in medical and m i l i t a r y a p p l i c a t i o n s o f i n t e l l i g e n t agents  and w i l l govern f u t u r e acceptance of ai work in a p p l i c a t i o n s areas. and on the p h i l o s o p h i c a l l e v e l 
one might even argue that there is a moral imperative to provide accurate explanations to end-users whose i n t u i t i o n s about our systems are almost n i l . 
　　　　f i n a l l y   the explanation c a p a b i l i t y i s needed as part of the concerted a t t a c k on the knowledge a c q u i s i t i o n problem. explanation of the reasoning process is c e n t r a l to the i n t e r a c t i v e t r a n s f e r of e x p e r t i s e to the knowledge base  and it is our most powerful t o o l f o r the debugging of the knowledge base. 
	1 	epilogue 
　　　　what we have learned about knowledge engineering goes beyond what is d i s c e r n i b l e in the behavior of our case study programs. in the next paper of t h i s two-part s e r i e s   i w i l l r a i s e and discuss many of the general concerns of knowledge engineers  including these: 
　　　　what c o n s t i t u t e s an   a p p l i c a t i o n   of ai techniques  
　　there is 	a d i f f e r e n c e between 	a serious a p p l i c a t i o n and an 	a p p l i c a t i o n - f l a v o r e d toy problem. 
　　　　what are some c r i t e r i a f o r the j u d i c i o u s s e l e c t i o n of an a p p l i c a t i o n of ai techniques  
　　　　what are some a p p l i c a t i o n s areas worthy of serious a t t e n t i o n by knowledge engineers  
　　for example  a p p l i c a t i o n s to science  to s i g n a l i n t e r p r e t a t i o n   and to human i n t e r a c t i o n w i t h complex systems. 
how to f i n d and fascinate an expert. 
　　the background and p r i o r t r a i n i n g of the e x p e r t . 
　　the l e v e l of commitment that can be e l i c i t e d . 
	designing systems 	that   t h i n k the 	way i 
d o .   
　　sustaining a t t e n t i o n by quick feedback and incremental progress. 
　　focusing a t t e n t i o n 	to data 	and s p e c i f i c problems. 
　　p r o v i d i n g ways to express u n c e r t a i n t y of expert knowledge. 
　　the side b e n e f i t s to the expert of his investment in the knowledge engineering a c t i v i t y . 
　　　　gaining consensus among experts about the knowledge of a domain. 
　　the consensus may be a more valuable outcome of the knowledge engineering e f f o r t than the b u i l d i n g of the program. 
problems faced by knowledge engineers today: 
　　the lack of adequate and appropriate computer hardware. 
　　the d i f f i c u l t y of export of systems to end-users  caused by the lack of p r o p e r l y sized and -packaged combinations of hardware and software 
　　the chronic absence of cumulation of ai techniques in the form of software packages than can achieve wide use. 
　　the 	shortage 	of 	t r a i n e d 	knowledge engineers. 
　　the d i f f i c u l t y of o b t a i n i n g and s u s t a i n i n g funding for i n t e r e s t i n g knowledge engineering p r o j e c t s . 
	1 	acknowledgment 
　　　　the work reported herein has received l o n g term support from the defense advanced research projects agency. the n a t i o n a l i n s t i t u t e s of health has supported dendral  meta-dendral  mycin  and the sumex-aim computer f a c i l i t y on which we compute. the n a t i o n a l science foundation has supported research on crysalis and m1lgen. i am g r a t e f u l to these agencies f o r t h e i r c o n t i n u i n g support of our work. 
　　　　i wish to express my deep admiration and thanks to the f a c u l t y   s t a f f and students of the h e u r i s t i c programming p r o j e c t   and to our c o l l a b o r a t o r s i n the various w o r l d l y a r t s   f o r the c r e a t i v i t y and d e d i c a t i o n that has made our work e x c i t i n g and f r u i t f u l . my p a r t i c u l a r thanks f o r assistance in preparing t h i s manuscript go to randy davis  penny n i l   reld smith  and carolyn taynai. 
	1 	