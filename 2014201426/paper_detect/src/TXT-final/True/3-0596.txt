
beam search reduces the memory consumption of bestfirst search at the cost of finding longer paths but its memory consumption can still exceed the given memory capacity quickly. we therefore develop bulb  beam search using limited discrepancy backtracking   a complete memory-bounded search method that is able to solve more problem instances of large search problems than beam search and does so with a reasonable runtime. at the same time  bulb tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory. we demonstrate these properties of bulb experimentally for three standard benchmark domains.
1 introduction
best-first search methods  such as a*  do not scale up to large search problems due to their memory consumption  and linear-space best first search methods  korf  1 have unacceptable runtimes for large search problems. beam search reduces the memory consumption of best-first search at the cost of finding longer paths. it uses breadth-first search to build its search tree but keeps at most the b states at each level of the search tree with the smallest heuristic values  where the value of the beam width b is set at the beginning of the search. the smaller the beam width  the more states beam search prunes at each step of the search and the less memory it needs to store each level of the search tree. unfortunately  more pruning typically increases the probability of pruning states on short paths from the start state to a goal state and thus often increases the lengths of the paths found. excessive pruning can even prevent one from finding any path. thus  the beam width has to be large. our experiments show  for example  that beam search with a beam width of 1 solves about eighty percent of random problem instances of the 1-puzzle. the average path length found is on average about one order of magnitude smaller than the one found by variants of wa*
 pearl  1   which are alternatives to beam search that also

figure 1: visualization of search methods
reduce the memory consumption of best-first search at the cost of finding longerpaths. we developbulb  beam search using limited discrepancy backtracking  that is able to solve more problem instances of large search problems than beam search  and does so with a reasonable runtime. at the same time  bulb tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory. it behaves like beam search until it exhausts the memory capacity without finding a path. it then uses limited discrepancy backtracking to retract its previous pruning decisions. the choice of a good backtracking strategy is important since  for example  beam search with chronological backtracking has unacceptable runtimes.
1 beam search
bpathgeneratedstoredruntimeproblemslengthstatesstates seconds solved1n/an/an/an/a1 %1 11111 %1 11111 %1 11 1 111 %1 11 1 111 %1 11 1 111 %11.1 11 1.1 %111 1 111 %111 1 111 %1n/an/an/an/a1 %beam search is any search technique  in which a number of  ...  alternatives  the beam  are examined in parallel.  it  is a heuristic technique because heuristic rules are used to discard  prune  non-promising alternatives in order to keep the size table 1: beam search on the 1-puzzle of the beam as small as possible   bisiani  1 . we assume that all actions have a cost of one and study beam-search variants of breadth-first search in this paper. their objective is to reduce the memory consumption of breadth-first search from exponential to linear in the depth of the search tree  as illustrated by the shaded areas of figure 1  a  and  b  for breadthfirst search and beam search  respectively. beam search uses breadth-first search to build its search tree but splits each level of the search tree into slices of at most b states  where b is called the beam width. the number of slices stored in memory is limited to one at each level. when beam search expands a level  it generates all successors of the states at the current level  sorts them in order of increasing heuristic values  from left to right in the figure   splits them into slices of at most b states each  and then extends the beam by storing the first slice only. beam search terminates when it generates a goal state or runs out of memory.
¡¡table 1 shows experimental results for beam search on the 1-puzzle with a memory limitation of 1 1 states. we created 1 problem instances with random start configurations in which the goal configuration had the blank in the upper left corner. we used the manhattan distance as heuristic function.  we could have used pattern databases instead  korf and taylor  1  but did not since we use them later in this paper in the context of 1 additional benchmark domains.  the runtime of beam search was always small since it ran out of memory in seconds. beam search with a beam width of 1 solved none of the problem instances. this is not surprising since it is similar to greedy search  gradient descent  and thus likely to find rather long paths unless it gets stuck in dead ends because the current state has only successors that are already in memory  in which case it does not find any path at all. beam search with a beam width of 1 solved all of the problem instances. as the beam width increased  its memory consumption increased  the average path length of the solved problem instances decreased  and the number of solved problem instances eventually decreased. beam search with beam width 1 solved none of the problem instances. this is not surprising since beam search with a beam width of infinity is breadth-first search and thus guaranteed to find shortest paths unless it runs out of memory and then does not find any path at all  which is likely given the exponential memory consumption of breadth-first search. consider beam search with a large beam width that still solved a substantial number of problem instances  say beam search with a beam width of 1 that solved eighty percent of the problem instances. the average path length of the solved problem instances was an order of magnitudesmaller than the one reportedin  furcy  1  for several variants of wa*.
1 improving beam search
we study how to increase the number of solved problem instances to one hundred percent while reducing the path lengths of the solved problem instances. this cannot be done by varying the beam width since increasing it reduces the number of solved problem instances while decreasing it increases the average path length of the solved problem instances. rather  we notice that many of the unsolved problem instances are due to misleading heuristic values that prevent states from being included in the beam. for example  the goal state g is put into the third slice of the seventh layer in figure 1  b . beam search thus does not find the goal state since it visits only the first slice of each layer. our solution to this problem is to backtrack and choose a different slice. figure 1  c  shows db  depth-first beam search   our simplest variant of beam search with backtracking. db behaves like beam search until it exhausts the memory capacity without finding a path. it then uses chronological backtracking to purge existing slices and replace them with others. db  unfortunately  has unacceptable runtimes  which we explain as follows: chronological backtracking revisits the most recent decisions first  that is  the decisions close to the bottom of the search tree. this is problematic since the heuristic values are usually the more inaccurate the farther a state is away from the goal state and thus the closer it is to the top of the search tree. thus  it is important to revisit decisions close to the top of the search tree more quickly. we therefore use limited discrepancy search rather than chronological backtracking to build a more sophisticated variant of beam search with backtracking.
1 original limited discrepancy search
lds  limited discrepancy search   harvey and ginsberg  1  was designed to work on finite binary trees. the successors of a state are sorted in order of increasing heuristic values. thus  the heuristic values always recommend the left successor over the right one. choosing the right successor against the recommendation of the heuristic values is called a discrepancy. first  lds searches the tree greedily  that is  with no discrepancy. if lds does not find a goal state  then it made at least one wrong decision due to misleading heuristic values. lds then searches the tree with increasing numbers of allowed discrepancies. figure 1 contains the pseudo code of lds. the top-level function lds   repeatedly performs a limited discrepancy search from the start state  line 1  by calling ldsprobe   with an increasing numberof allowed discrepancies  line 1   starting with no discrepancy  line 1 . unless the current state is a leaf of the tree  line 1   ldsprobe   generates its successors and recursively calls itself on them. if the maximum number of allowed discrepancies is zero  then only the sub-tree below the best successor is visited with no discrepancy allowed  line 1 . otherwise  the sub-tree under the worst successor is visited with one less discrepancy allowed  since one was just consumed  line 1   then the sub-tree under the best successor is visited with the same number of allowed discrepancies  since none was con-
1. procedure lds sstart  h .  : path length
1. discrepancies := 1
1. while   true   do
1. cost := ldsprobe sstart  1  discrepancies  h .  
1. if   cost   ¡Þ   then return cost 1. discrepancies := discrepancies + 1
1. end while
1. procedure ldsprobe state  depth  discrepancies  h .  : path length
1. if   state is a leaf   then return ¡Þ
1. else hbest  secondi := generatesuccessors state 
1. if    best = sgoal  or  second = sgoal    then return depth + 1
1. if   discrepancies = 1   then return ldsprobe best  depth + 1  1  h .  
1. else
1. cost := ldsprobe second  depth + 1  discrepancies   1  h .  
1. if   cost   ¡Þ   then return cost
1. return ldsprobe best  depth + 1  discrepancies  h .  figure 1: original limited discrepancy search
1. procedure glds sstart  h .  : pathlength
1. discrepancies := 1; hashtable := {sstart}
1. while   true   do
1. pathlength := gldsprobe sstart  1  discrepancies  h .  
1. if   pathlength   ¡Þ   then return pathlength 1. discrepancies := discrepancies + 1
1. end while
1. procedure gldsprobe state  depth  discrepancies  h .  : path length
1. set :=  
1. for each successor s of state do
1. if   s = sgoal   then return depth + 1. if   s ¡Ê/ hashtable   then set := set ¡È{s}
1. end for
1. if   set =     then return ¡Þ
1. if   hashtable has only one empty slot   then return ¡Þ 1. best := arg mins¡Êset { h s  }
1. if   discrepancies = 1   then
1. hashtable := hashtable ¡È{best} 1. pathlength := gldsprobe best  depth + 1  1  h .  
1. else
1. set := set {best}
1. while   set 1=     do
1. state := arg mins¡Êset { h s  }
1. set := set {state}
1. hashtable := hashtable ¡È{state}
1. pathlength :=	gldsprobe state  depth + 1  discrepancies   1 
h .  
1. hashtable := hashtable {state}
1. if   pathlength   ¡Þ   then return pathlength
1. end while
1. hashtable := hashtable ¡È{best}
1. pathlength := ldsprobe best  depth + 1  discrepancies  h .  
1. hashtable := hashtable {best}
1. return pathlengthfigure 1: generalized limited discrepancy search
sumed at the current level by following the heuristic recommendation  line 1 . lds terminates when it generates the goal state  line 1 .
1 generalized limited discrepancy search
to apply lds to beam search  we need to generalize it from binary trees to arbitrary graphs. first  lds must be able to handle branching factors that are nonuniform and larger than two. second  lds must be able to avoid cycles. glds  generalized limited discrepancy search  addresses the first issue by picking a successor s of a given state with a smallest heuristic value h s . choosing any other successor is counted as one discrepancy  and the successors are tried from left to right. glds addresses the second issue by performing cycle detection with a hash table and not generating successors that are already in the hash table. figure 1 shows the pseudo code for glds. the top-level function glds   repeatedly performs generalized limited discrepancy searches from the start state  line 1  by calling gldsprobe  with an increasing number of allowed discrepancies  line 1   starting with no discrepancy  line 1 . gldsprobe   performs a generalized
1. procedure bulb sstart  h .   b : path length
1. discrepancies := 1; g sstart  := 1; hashtable := {sstart} 1. while   true   do
1. pathlength := bulbprobe  1  discrepancies  h .   b 
1. if   pathlength   ¡Þ   then return pathlength 1. discrepancies := discrepancies + 1
1. end while
1. procedure bulbprobe depth  discrepancies  h .   b : path length 1.	hslice  value indexi := nextslice depth  1  h .   b 
1. if   value ¡Ý 1   then return value
1. if   discrepancies = 1   then
1. if   slice =     then return ¡Þ
1. pathlength := bulbprobe depth + 1  1  h .   b 
1. for each s in slice do hashtable := hashtable {s} end for
1. return pathlength
1. else
1. if   slice 1=     then
1. for each s in slice do hashtable := hashtable {s} end for 1.	while   true   do
1. hslice value indexi := nextslice depth  index  h .   b 
1. if   value ¡Ý 1   then
1. if   value   ¡Þ   then return value
1. else break
1. if   slice =     then continue
1. pathlength := bulbprobe depth +1  discrepancies  1  h .   b 
1. for each s in slice do hashtable := hashtable {s} end for
1. if   pathlength   ¡Þ   then return pathlength
1. end while
1. hslice  value indexi := nextslice depth  1  h .   b 
1. if   value ¡Ý 1   then return value
1. if   slice =     then return ¡Þ
1. pathlength := bulbprobe depth + 1  discrepancies  h .   b 
1. for each s in slice do hashtable := hashtable {s} end for
1. return pathlength
1. procedure nextslice depth index h .  b : h array of states  integer  integer i
1. currentlayer := {s ¡Ê hashtable |g s  = depth}
1. succs := generatenewsuccessors currentlayer  h .  
1. if    succs =    or  index = |succs|    then return h  ¡Þ  1i 1. if   sgoal ¡Ê succs   return h  depth + 1  1i
1. slice :=  ; i := index
1. while    i   |succs|  and  |slice|   b    do
1. if   succs i  ¡Ê/ hashtable   then
1. g succs i   := depth; slice := slice ¡È {succs i } 1. hashtable := hashtable ¡È{succs i }
1. if   hashtable is full   then
1. for each s in slice do hashtable := hashtable {s} end for
1. return h  ¡Þ  1i 1.	i := i + 1
1. end while
1. return hslice  1 ii
1. procedure generatenewsuccessors stateset  h .  : array of states
1. index := 1
1. for each state in stateset do
1. for each successor s of state do
1. if   s ¡Ê/ hashtable   then
1. succs index  := s; index := index + 1
1. end for
1. end for
1. sort states in succs in order of increasing h . -values 1.	return succsfigure 1: bulb
limited discrepancysearch froma givenstate for a givennumber of allowed discrepancies. first  it generates all successors of the state that are not already in the hash table  lines 1 . it backtracks if the goal state is found  line 1   there are no successors  line 1   or the hash table is full  line 1 . otherwise  it identifies the best successor as one with a smallest heuristic value  line 1 . if the number of allowed discrepancies is zero  then gldsprobe   calls itself on the best successor with no allowed discrepancies  line 1 . otherwise  gldsprobe   calls itself repeatedly on the remaining successors with one less allowed discrepancy  line 1  and then calls itself on the best successor with the same number of allowed discrepancies  line 1 .
1 bulb
bulb  beam search using limited discrepancy backtracking  combines beam search with glds. figure 1 shows the table 1: taxonomy of search methods
beam widthnonetype of backtracking
chronologicallimited discrepancy1greedy search
 gradient descent guided
depth-first searchlimited discrepancy search  lds/glds intermediatebeamdepth-first beam searchbeam search using limitedvaluessearch db discrepancy backtracking  bulb ¡Þbreadth-first searchbreadth-first searchbreadth-first searchpseudo code for bulb. the top-level function bulb   is basically identical to glds  . the function bulbprobe   performs beam search with generalized limited discrepancy search for a given number of allowed discrepancies. it first generates the first slice of the next level  line 1 . if the slice contains a goal state  the slice is empty  the subtree has been searched exhaustively  or the hash table  which stores the beam  is full  then it aborts  lines 1 and 1 . if the number of allowed discrepancies is zero  line 1  and the slice is not empty  line 1   then bulbprobe   calls itself with no allowed discrepancies  line 1   and clears the hash table of the slice  line 1 . otherwise  bulbprobe   clears the hash table of the slice  line 1   calls itself repeatedly on the remaining slices with one less allowed discrepancy  line 1  and then calls itself on the best slice with the same number of allowed discrepancies  line 1 . the function nextslice   generates a successor slice for a slice that is already in the hash table at a given depth. it first locates the given slice  line 1   generates all successors of its states  line 1   and then locates the slice of the given index within the successors. it does this by inserting successors into both an empty slice  line 1  and the hash table  line 1   starting with the successor at the given index  line 1   until either b successors have been inserted into the slice or the end of the layer has been reached  line 1 . if the hash table is full  line 1   then it clears the hash table of the incomplete slice  line 1  and aborts  line 1 . the function generatenewsuccessors   generates the successors s of a given set of states that are not already in the hash table and sorts them in order of increasing heuristic values h s .  the successors can contain duplicates. 
1 properties of bulb
heuristic search methods that repeatedly fill up and purge memory can be rather complicated  chakrabarti et al.  1; russell  1; kaindl and khorsand  1; zhou and hansen  1 . in contrast  bulb is relatively simple because it purges contiguous regions of memory and is only an approximation algorithm that does not necessarily find shortest paths. table 1 shows a taxonomy of search methods. bulb generalizes beam search to beam search with backtracking  limited discrepancy search to beam widths larger than one  and breadth-first search to beam widths smaller than infinity.
  the memory consumption of bulb is o bd   where d is the maximum search tree depth. this is achieved by only storing one slice for each level  which requires bulb to re-generate all successors of the states of a slice every time it backtracks. the resulting small memory consumption allows for deeper searches with wider beams.  other linear-space search methods often store the siblings of states as well  which makes it unnecessary to re-generate the successors of states but increases the memory consumption substantially.  bulb is a memory-bounded search method and thus continues its search after memory runs out by purging states from memory  resulting in a complete search method. this means that bulb finds a path as long as there is one with a length of the maximum search tree depth or smaller  which approximately equals m/b  where m is the memory capacity measured by the maximal number of states one can store. bulb thus improves on beam search  which is incomplete  and on breadth-first search  which is complete but whose maximum search tree depth approximately equals logb m   where b is the average branching factor of the search tree  and can thus solve only smaller search problems than bulb.
  the runtime of bulb is often small. in fact  bulb frequently finds a path without any backtracking or with only a very limited amount of backtracking. it also eliminates all cycles  loops  and some transpositions  different paths from the start state to a given state   which are often responsible for the large runtimes of depthfirst search. bulb  as a generalization of breadth-first search  eliminates all cycles since it never generates states that are already in the hash table. bulb does not make any effort at eliminating transpositions. nevertheless  bulb  as a generalization of beam search  eliminates some transpositions since it does not re-expand states that are already in its beam.
1 experimental evaluation
we now present an experimentalstudy of bulb in three standard benchmark domains: the n-puzzle  the 1-peg towers of hanoi and the rubik's cube. note that our figures show graphs only for search methods that were able to solve all random problem instances since we are interested in increasing the number of solved problem instances to one hundred percent. additional results are reported in  furcy  1 .
1 n-puzzle
our first benchmark domain was the n-puzzle  as already described in the context of table 1. beam search solved all problem instances of small n-puzzles with a small average path length and did so in fractions of a second. it is therefore not surprising that neither db nor bulb significantly improved on beam search for n smaller than 1. the situation was different for the 1-puzzle. db did not significantly improve on beam search for the 1-puzzle either. on the other hand  bulb was able to solve all problem instances with a beam width of 1 while beam search was only able to solve all problem instances with beam widths of 1 or smaller. bulb was able to find paths of average length 1 with this beam width while beam search was only able to find paths of average length 1 with beam widths that allowed it to solve all problem instances  for b = 1  which is not shown in table 1 . thus  bulb was able to reduce
a  path length

b  memory usage

figure 1: bulb on the 1-puzzle  b varies 

figure 1: search methods on the 1-puzzle  b varies 
the path length or  synonymously  solution cost by a factor of about 1. at the same time  the average runtime of bulb was still on the order of 1 seconds on a pentium 1 pc clocked at a 1 ghz. figure 1 contains detailed data points about bulb. since bulb generates states in exactly the same order as beam search  the graphs of bulb simply extend the ones of beam search to larger beam widths. for the 1-puzzle and a memory capacity of 1 1 states  there table 1: beam search on the towers of hanoi
bpathgeneratedstoredruntimeproblemslengthstatesstates seconds solved1n/an/an/an/a1 %1 11111 %1 11 1 1.1 %1 11 1 1.1 %1 11 1 1.1 %1 11 1 1.1 %111 1 1.1 %1n/an/an/an/a1 %was no beam width that allowed beam search to solve all 1 random problem instances but bulb was able to solve them for a wide range of beam widths. the smallest average runtime of bulb with a beam width that solved all problem instances was about 1 seconds. it was obtained with a beam width of 1 and resulted in an average path length of about 1. a larger beam width of 1  that still solved all problem instances  increased its average runtime to about 1 seconds but reduced the average path length to 1  which is less than 1 times the shortest path length. figure 1 shows that bulb was also able to improve the average path length of two multi-state commitment search methods for the 1-puzzle by at least one order of magnitude with an average runtime of only about 1 seconds. these alternatives to beam search are msc-kwa*  furcy and koenig  1   a combination of kwa*  felner et al.  1  and msc-wa*  kitamura et al.  1   and msc-krta*  furcy  1   a combination of kwa*  felner et al.  1   msc-wa*  kitamura et al.  1  and rta*  korf  1 .
1 towers of hanoi
our second benchmark domain was the 1-peg towers of hanoi. we created 1 random problem instances with 1 disks in which the goal state had all disks stacked on one peg. we set the memory capacity to 1 1 states and used a pattern database similar to that of  felner et al.  1  as the heuristic function. table 1 shows that  similarly to the 1-puzzle  beam search with large beam widths solved many problem instances  and the average length of the paths found was short. however  there was no beam width that allowed beam search to solve all 1 random problem instances  which is the reason why figure 1 contains no graphs for beam search  but bulb was able to solve them for a wide range of beam widths. the smallest average runtime of bulb with a beam width that solved all problem instances was about 1 seconds. it was obtained with a beam width of 1 and resulted in an average path length of about 1. a larger beam width of 1  that still solved all problem instances  increased its average runtime to about 1 seconds but reduced the average path length to about 1. figure 1 contains detailed data points about bulb.
1 rubik's cube
our third benchmark domain was the rubik's cube. we created 1 random problem instances in which the goal state was the original configuration of the cube. we set the memory capacity to 1 1states and used the pattern databases from  korf  1  as the heuristic function. beam search was only able to find paths of average length 1 with beam widths
a  path length

b  memory usage

figure 1: bulb on the towers of hanoi  b varies 
table 1: beam search on the rubik's cube
bpathgeneratedstoredruntimeproblemslengthstatesstates seconds solved1 11 1 1.1 %1 11 1 1.1 %1 11 1 1.1 %1.1 1111 %111 1 1.1 %111 1 1.1 %111 1 1.1 %111 1 1.1 %1n/an/an/an/a1 %that allowed it to solve all problem instances  for b = 1  which is not shown in table 1   which is similar to the average path length found by a recent powerful rubik's cube solver based on macro-operators  even though this rubik's cube solver uses both a larger number of pattern databases to build the macro-operators and a post-processing step on the paths it finds  herna¡ädvolgyi ¡§ 1 . beam search solved all 1 problem instances for several beam widths but bulb was able to solve them for all tested beam widths. bulb with a beam width of 1 solved all problem instances and found an average path length of 1 with an average runtime of about 1 seconds. this average path length is already smaller than the one of the rubik's cube solver mentioned above  even though bulb is a domain-independent search method without any pre- or post-processing and used only about 1
a  path length

b  memory usage

figure 1: bulb on the rubik's cube  b varies 
mbytes of memory in our experiments  1 mbytes for the pattern database and 1 mbytes for the hash table . bulb with a beam width of 1 found a path of length 1 with an average runtime of about 1 minutes. a larger beam width of 1  that still solved all problem instances  increased its average runtime to about 1 minutes but reduced the average path length to about 1. figure 1 contains detailed data points about bulb.
1 related work
existing variants of beam search differ from bulb in that they either 1  use no backtracking at all or 1  use chronological backtracking. in the first category  diversity beam search  shell et al.  1  deals with imperfect heuristic values by introducing diversity at all levels of the search tree. it differs from bulb in that it is incomplete and requires additional knowledge to measure the level of dissimilarity among states. divide-and-conquer beam search  zhou and hansen  1  does not store all of the beam in memory. instead  it purges some of its slices from memory and uses a divide-and-conquer strategy to reconstruct the path after it finds a goal state  which makes backtracking impossible  at least on the parts of the beam that have been purged from memory. in the second category  band search  chu and wah  1  is the search method most similar to bulb. it differs from bulb in that it extends beam search with chronological backtracking and is designed for search trees. it does not detect loops and therefore performs best for small search problems. complete anytime beam search  zhang  1  does not extend beam search but depth-first search. it uses chronological backtracking  with a beam width of one  while iteratively weakening its pruning rule. like all depth-first search methods  it performs best on finite trees of shallow depths with large goal densities  such as travelling salesperson problems   which are very different from our benchmark domains.
1 conclusion
in this paper  we developed bulb  beam search using limited discrepancy backtracking   a memory-bounded search method that generalizes beam search to beam search with backtracking  limited discrepancy search to beam widths larger than one  and breadth-first search to beam widths smaller than infinity. bulb makes beam search complete  provided that there is sufficient memory to store the beam along a shortest path from the start state to a goal state   tends to find shorter paths than beam search because it is able to use larger beam widths without running out of memory  and can be transformed into an admissible anytime algorithm  for example  by letting it continue its search after it has found a path  resulting in an anytime extension of beam search that is similar in spirit to the anytime extension of wa* described in  hansen et al.  1 . bulb outperformed beam search and variants of wa* in our experiments  solved all of our test problems for the 1-puzzle  and resulted in a state-of-theart rubik's cube solver without any pre- or post-processing  even though it is a domain-independent search method. it is future work to enhance bulb with more complex variants of beam search  for example  variants that change the beam width during the search. it is also future work to enhance bulb with more complex variants of backtracking  for example  variants that give a higher priority to decisions close to the top of the search tree than decisions close to the bottom of the search tree  variants that use depth-bounded discrepancy search  walsh  1  or variants that calculate the discrepancies differently.
