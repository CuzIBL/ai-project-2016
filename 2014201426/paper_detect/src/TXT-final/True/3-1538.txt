
this paper demonstrates how a model for temporal context reasoning can be implemented. the approachis to detect temporallyrelated events in natural language text and convert the events into an enriched logical representation. reasoning is provided by a first order logic theorem prover adapted to text. results show that temporal context reasoning boosts the performance of a question answering system.
1 introduction
representing and reasoning about time-dependent information is important for applications ranging from databases  planning  natural language processing  and others. for example  temporal reasoning is essential in question answering to successfully addressing a time sensitive and dynamic world. questions requiring temporal relations are not currently solvable in most state of the art question answering systems. of the factoid trec questions from 1 approximately 1% require temporal context reasoning. a temporal context scopes changing world views and serves as a tool for disambiguating time dependent events or intervals. questions such as who was the president of south korea when bill clinton was president of the us  need temporal event detection and context based reasoning.
　while there has been much theoretical research and modeling of context reasoning in the temporal domain  few systems have reported an evaluation of end to end temporal context enhanced question answering. this paper presents such a system. we report on  1  temporal context indexing for passage retrieval   1  a fast and robust representation of time and annotation of time events   1  the implementation of a machine learning based temporal event recognition module   1  a model for a knowledgerepresentation that maps natural language context into first order logic suggested upper merged ontology sumo  niles and pease  1  predicates  and  1  a temporal context reasoning engine.
1 approach
several logic or semantic standard approaches to represent time  or events in time  have been defined. the most common ones include absolute dating schemes  relative event ordering or duration based approaches. decisions about the nature of the event  instantaneous or extended  have to be made. the problem with many discrete schemes for natural language applications  such as mani and wilson  1  is the lack of absolute timestamps for many events. propagationapproaches to assign absolute time stamps to event clauses for sequence recognition have been implemented  filatova and hovy  1 . however  besides the recognition problems  filatova and hovy report 1% accuracy  these approaches do not capture temporal relations that are based on duration of events.
　relative event orderings and duration relations that hold true at all times should not be labeled with absolute timestamps as in: people are born before they die. this holds true also for event orderings commonly found in user manuals  like it support information or cookbooks as in: what process do i need to terminate after a failed query 
　 allen  1  demonstrates a constraint propagation approach based on a set of possible interval relations that could capture this  but the recognition of these events and their relations is still an open research area.
　our approach uses a hybrid of the above mentioned methods. passage retrieval makes use of a descrete time scale in the form of temporal indexing so as to capture all the relevant candidate passages that may not have absolute time specified in the document text. for the time-event model  high coverage signal words and phrases that specify how temporal elements should be related are used. the chosen signals are based on the annotations in timeml used in the terqas project  pustejovsky et al.  1  and are mined for and annotated in a sampling of articles from the trec collection. the signals are then classified by the type of temporal relation they express  such as overlapping  inclusion  ordering  and more. this data is used for training the automatic temporal event detection module that recognizes 1 distinct temporal event interval relations on the question and its answer candidates. the detected temporal events enrich a logical form representation of the question and answer candidates with sumo predicates and functions. based on these temporal constraints  a context resolution engine operates as an answer candidate filter.
1 passage retrieval with temporal context
one common class of time dependent questions targets facts that are rooted in an absolute time  such as: who led the nhl in playoff goals in june 1  to ensure that all passages relevant to a temporally constrained question are retrieved it is necessary to index the temporal contexts in a document. the approach is to scan each document in a collection for its time stamp as well as any underspecified or relative references to time. a date resolution module processes all underspecified and relative dates to accurately anchor these temporal references in a calendar year. the context field consists of a  year  month  day  hour  minute  second  tuple  where any member in the tuple is optional. for a document with time  t 1  1  1  x  x  x   the following temporal context entries are computed and displayed in table 1:
temporal referenceresolved datelast yeart 1 x x x x x next weekt 1 1 x x x in a weekt 1 1 x x x todayt 1 1 x x x table 1: resolved temporal context
　the resolved references as well as the document time stamp is indexed and made searchable for time dependent queries. for the question above the query issued to the index is:
 human  and  lead  and  nhl or  national and hockey and league 1  and  playoff  and  goal  and t 1  1  x  x x x x 
　for questions involving a time range  the query is translated into a conjunction of time operators. as an example  what chinese dynasty was during 1  translates to:
 organization  and  chinese  and  dynasty  and  t 1 x x x x x  or t 1 x x x x x   or ... or t 1 x x x x x   
　internally the search engine computes the allowed range and searches for dates indexed in that range. the temporal context for the question is enforced by searching the index for the context detected in the question and applying document dates to all passages retrieved that do not have an explicit context within a window of 1 sentences. these resolved dates are passed along to the answer processing module which invokes the signal based temporal event recognizer and the context resolution modules to verify that the candidate answers do meet the temporal constraints in the question
1 data annotation
for an initial analysis of the signal words  the timeml  pustejovsky et al.  1  timebank1 data functioned as a source of time signal expressions to be used as seeding material in the trec 1 corpus. the signal list served as a means to bootstrap a sample of the trec collection for annotation purposes. the goal of the annotation was to provide data for a machine learning algorithm aimed at disambiguating signal words  detecting time events  and determining the boundaries of the time event.
category  example interpretation%
distsequence  before  after e1 happened in full before e1.1containment  in  of e1 is contained by e1.1overlap  at as on an interval exists that is contained by e1 and e1.1right	open	interval
 from  since e1 is the left boundary of e1  right is undefined1left open interval  to  until e1 is the right boundary of e1  left is undefined1closed interval  for  all e1 lasts for the duration of e1.1absolute	ordering
 first  last e1 has an ordering relative to e1.1table 1: signal annotation categories and their distribution
the requirements of the annotation scheme used to mark up 1 sentences from nyt  1 fromapw  and 1 sentences from xin were robustness  simplicity  and sufficient granularity of the time events.
　time events are defined as related intervals  which are bound by a signal expression indicating the relation of the time events. additionally  each signal can modify up to two events and can determine one of the following relations: sequence  containment  overlap  open interval  left or right   duration and absolute ordering. an event is interpreted as an interval bound by signal words or phrases and can be noun phrases  the bombing  or verb groups  participated .
　since the current model operates at the sentence level  a marker is added to signals that need more information to resolve its arguments such as implicit context or missing discourse. table 1 lists the categories of signal words  their natural language interpretation  and their distribution across a sampling of the trec collection. example annotations based on the signal categories:
which country e1 id=1 declared /e1 id=1 independence s id=1 class=contain in /s id=1 e1 id=1 /e1 id=1  
s id=1 class=sequence after /s id=1 quickly e1 id=1 decapitating /e1 id=1 the bird  susan e1 id=1 scalded /e1 id=1 the carcass.
1 detection of temporally ordered events
automated discovery of temporally ordered events requires detecting a temporal triple  s e1 e1  which consists of a time dependent signal word  s  and its corresponding temporal event arguments   e1  and  e1 . detection of a temporal triple is complicated by two issues:
 1  disambiguation of signal words: not all signal words are unambiguously classified as time indicators.  a  he stood before the judge vs he proofread the manuscripts before mailing it to the publisher
 b  he woke up at 1 vs he looked through the window at the rising sun
 1  attaching events to signal words: although some temporal events are found near their signal  many signals occur with their temporal events underspecified  non-local .  a  the problem was resolved after 1 hours of intensive maintenance but before anybody was harmed.
　in the above example the signal word after easily attaches to resolved and 1 hours  while the second signal word  before has a non-local e1 reference  also resolved .
　to address these issues machine learning is employed in two stages  first to recognize and disambiguate signals  and second to discover and attach temporal events to their signals. the input to the learner is the data annotated. the predictive classifiers that result from learning are used to automatically detect temporal triples  signals with their attached temporal events  in natural language text.
signal disambiguation
in the first stage of the machine learning process  a signal's surface form is classified either as a temporal  signal  or non-temporal occurrence  with signals classified further as to how they order their events  see table 1.
　a chunk parse tree is examined for text segments that match the surface form of a signal which are placed in their own chunk if necessary. a set of features  listed in table 1  is then computed and used to classify each of these chunks. the hyperterm feature can be described as a broadly applicable feature space constructed from sumo. each sumo class  instance  or relation is a unique string  here called a term. all terms are collected and connected to their hyperterm via the sumo axioms  subclass   subrelation  and  instance . the result is a directed acyclic graph connecting all 1 terms to their hyperterms and rooted at the sumo class entity. this hypertermtree along with the wordnet to sumo mappings  niles and pease  1  is prepared offline. using this resource to generate the hyperterm feature consists of computing the union of the hyperterms for all wordnet concepts  senses  for each word in the chunk.
　the intuition behind using sumo is:  1  coarse grained distinctions appear to be better represented in sumo hypterterm tree than in wordnet  that is  a single term  process  appears to capture the idea of eventness easily where several wordnet hypernyms would be required to capture the same distinction.  1  all open class words are united in a single hyperterm tree whereas in wordnet verbs have shallow hypernymy and adjective and adverbs have no hypernymy. this allows for i  better generalization and similarity across chunks that have words not seen during training since unseen words will still share a significant set of hyperterm features and for ii  unified treatment of all four open lexical classes in the software. the resulting decision will be one of 1 choices corresponding to  no signal  and the 1 types of signals listed in table 1.
temporal event attachment
once a signal has been identified  its associated events  e1 and e1  must be attached. this task is achieved with a
feature descriptionoriginsignal surface form hindle and rooth  1 chunk's phrase tag kudo and matsumoto  1 chunk's hyperterms new +/- 1 chunk's phrase tag kudo and matsumoto  1 +/- 1 chunk's hyperterms new +/- 1 chunk's phrase tag kudo and matsumoto  1 +/- 1 chunk's hyperterms new table 1: signal and local attachment features and their origin
local attachment algorithm followed by a signal chaining attachment algorithm.
　the local attachment algorithm proceeds from left to right evaluating each unattached chunk to its nearest signal by generating features for classification. the decision associated with the features is one of skip  do not attach   e1  attach as e1   or e1  attach as e1 . the features used and their origin are listed in table 1.
　the signal chaining attachment algorithm enables signals that are missing an attachment to pick up an attachment from another signal  called link signals. the algorithm proceeds left to right evaluating a signal's missing argument against another signal's existing argument. the decision is either skip  e1  or e1 wherein the latter two result in an attachment. the algorithm iterates until no attachments are made. although this algorithm uses the features in table 1  their contribution is low and so motivated the additional features listed in table 1.
feature descriptionoriginmissing signal argument  e1 e1  new signal class mod. from  allen  1  link	signal	surface form hindle and rooth  1 link	signal	argument  e1 e1  new link signal class mod. from  allen  1  parsing	direction
 left right standardtable 1: signal chaining features and their origin
results
each classifier was built using the libsvm 1 implementation of support vector machines  with the radial basis kernel 
　　　　　　　  and included performing a grid search to find the best model parameters. measurements were taken by randomizing the annotated sentences and evaluating each tenth of the data by training on the other 1%  1-fold crossvalidation . the results measure the performance of the module as a whole. measuring individual decisions of the classifiers are not instructive due to the dominance of nosignal decisions during disambiguation and skip decisions during attachment parsing.
taskf-measuresignal detection1%attachment1%table 1: automated detection results
the attachment results are affected negatively by parsed chunk boundaries not matching the temporal event text segment marked by the annotator  which results in an annotated attachment being scored as incorrect. an attachment will also score as incorrectif it is not the correct argumentof the signal  or if the signal was not classified correctly. no partial credit is given. in the current data set 1% of the attachment annotations fail to align with a chunk boundary. this indicates that temporal event boundaries should not always rely on the parse chunk boundaries. an attachment will also score as incorrect if it is not the correct argument of the signal  or if the signal was not classified correctly. the scoring program is strict in that a temporally ordered event is correct only when the signal has been classified correctly and both event arguments have been detected and assigned in the proper order. based on the results of our experiments reported in table 1  with 1 sentences from the trec corpus  it seems apparent that more training data is needed. in order to verify that  the method and algorithm used for the current implementation is sound and scalable  another experiment was conducted using the same methodology over half the corpus  1 sentences . the results of that experiment posted an fmeasure of 1% for signal detection and 1% for attachment. comparing that to the original results it is clear that the technique outlined in this section scales well and will benefit from the ongoing effort to annotate more training data.
1 a knowledge representation with temporal context
the output of the temporal event detection  described in section 1  is transferred to the sumo enhanced logical form module. the function of this module is to translate the natural language candidate sentences  marked up with time event chunks  to a temporally enhanced first order logic assertion. the input time event chunks are labeled with the class of the signal from the list in table 1  along with the parsed chunks identified as the time event arguments to the signal.
　the knowledge representation for the temporally enhanced logic form is layered on top of the logical representation proposed in  rus and moldovan  1   where the first order logic structure is derived from the syntactic parse of the text and each token in the text is converted to a predicate. from this structure temporally related sumo predicates are generated based on hand coded interpretation rules for the signal classes. the purpose of the interpretation rules is to define an algorithm for assigning a signal word to a sumo predicate and defining the manner in which the slots for the predicate are determined. table 1 enumerates the signal classes  and the sumo predicate corresponding to the interpretation rule.
signal classsumo logics sequence  e1  e1earlier e1 e1 s contain  e1  e1during e1 e1 s overlap  e1  e1overlapstemporally e1 e1 s open right  e1  e1meetstemporally e1 e1 s open left  e1  e1meetstemporally e1 e1 s closed  e1  e1duration e1 e1 table 1: signal class to sumo mapping
　once the sumo predicate is chosen  the arguments to the predicate are the event argument ids from the heads of the chunks passed as attachments to the signal expression. since all temporal sumo predicates operate on time intervals  absolute times stated in the text are translated into a pair of time point predicates to specify the begin and end of the interval. a detailed example follows for the text: that compares with about 1 arrests in 1 before operation gatekeeper started.
　the temporal event recognizer disambiguates in and before as temporal signals  and classifies  1  in as a contain interval signal  and  1  before as a sequence interval signal. the local attachment and signal chaining algorithms then determine the time event arguments for each signal. the output triples are  s1:contain=in  e1=arrests  e1  and  s1:before=before  e1=arrests  e1=started . once the mapping for the temporally ordered events and the absolute time events are complete  the sumo predicates are generated. predicates that were derived from signal words replace the signals in the logical form.
... 1 nn x1  & arrest nn x1  & 1 nn x1  & operation nn x1  & gatekeeper nn x1  & nn nnc x1 x1 x1  & startvb e1 x1 x1  & earlier whenfn x1   whenfn e1   & time beginfn x1   1  1  1  1  1  1  & time endfn x1   1  1  1  1  1  1  & during whenfn x1   x1  & during whenfn x1   x1 
1 temporally enhanced inference
the temporal context resolution module employs a first order logic resolution style theorem prover adapted for natural language text processing  moldovan et al  1 . the set of support  sos  is the search strategy employed by the prover to partition the axioms into those that have support and those that are considered auxiliary  wos  1 . this strategy restricts the search such that a new clause is inferred if and only if one of its parent clauses come from the sos. the inference rule sets are based on hypperresolution  paramdodulation  and demodulation. hyperresolution is an inference rule that does multiple steps in one  paramodulation introduces the notion of equality substitution for the demodulators required on the temporal axioms. since temporal reasoning is intensive and may require long proofs  hyperresolution and paramodulation inference rules are necessary as they allow for a more compact and efficient proof by condensing multiple steps into one.
the inputs to the context resolution module include:
 1  the context relevant pieces of the natural language questions and candidate answers converted to a sumo enhanced first order logical form  rus and moldovan  1 . the question predicates are negated to invoke a proof by contradiction  1  a set of empiricallyderivedworld knowledgeaxioms. ex:
evidence is support for a claim evidence nn x1  - support nn x1  & for in x1 x1  & claim nn x1 
 1  linguistic transformation rules derived from the input parse of the question and its candidate answers.
ex: the leader of x  leads x. human ne x1  & leader nn x1  & of in x1 x1  -
lead vb e1 x1 x1 
 1  wordnet derived axioms such as lexical chains moldovan and novischi  1  and glosses. ex: to start some-
thing is semantically related to establishing
something
start vb e1 x1 x1  -	establish vb e1 x1 x1 
 1  a sumo knowledge base of temporal reasoning axioms that consists of axioms for a representation of time points and time intervals  allen primitives  and temporal functions.
ex: during is a transitive allen primitive during time1  time1  & during time1  time1  - during time1  time1 
　axioms in set  1  are loaded into the set of support. the predicates representing the temporally relevant information in the question are anded together  negated  and universally quantified  so as to invoke a proof by contradiction. the temporal predicates for the candidate answer are also anded together  existentially quantified and loaded into the sos. the axioms in sets  1  -  1  are loaded into the usable list to assist in the inference process between the question and the answer.
　the output of the temporal context module comprises filtered and re-ranked answers that are scored based on their semantic and temporal similarity to the question. the inference engine will continue seeking a proof until any of the time predicates are unsatisfied. partial satisfiability is permitted for other predicates in the question via a backoff algorithm integrated in the inference engine  moldovan et al  1 .
　the following example illustrates how a temporal context resolution module is used to verify the temporal constraints of a question over a candidate answer:
question: what country controlled syria in 1 
question logical form:
country at x1  & control vb e1 x1 x1  & syria nn x1  & overlapstemporally ctmp e1 x1 
&	timectmp beginfn x1  1 1 1 	&
time ctmp endfn x1  1 1 1  question axiom:
- exists e1 x1 x1 x1   country at x1  & control vb e1 x1 x1  & syria nn x1  & overlapstemporally ctmp e1 x1  & timectmp beginfn x1  1 1 1  &
time ctmp endfn x1  1 1 1    candidate answer 1:
france has a different relationship with syria  partly because it was once a french-mandated territory  from 1 answer logical form:
france nn x1  & country ne x1  & have vb e1 x1 x1  & different jj x1  & relationship nn x1  & with in x1 x1  & syria nn x1  & partly rb e1  & because in e1 e1  & once rb e1  & french nn x1  & mandate vb e1 x1 x1  &	territory nn x1 	&	during ctmp x1 x1 
&	timectmp beginfn x1  1 1 1 	&
time ctmp endfn x1  1 1 1  answer axiom:
exists e1 e1 x1 x1 x1 x1 x1 x1 x1 x1  france nn x1  & country ne x1  & have vb e1 x1 x1  & different jj x1  & relationship nn x1  & with in x1 x1  & syria nn x1  & partly rb e1  & because in e1 e1  & once rb e1  & french nn x1  & mandate vb e1 x1 x1  & territory nn x1  & during ctmp x1 x1 
&	timectmp beginfn x1  1 1 1 	&
time ctmp endfn x1  1 1 1   linguistic axiom:
all x1  french nn x1  france nn x1   lexical chain axiom:
all e1 x1 x1  mandate vb e1 x1 x1  control vb e1 x1 x1   sumo axioms:
two time intervals overlapstemporally if and only if each one is a temporalpart of the other: all i1 i1  isa i1  timeinterval  & isa i1  timeinterval  & overlapstemporally ctmp i1  i1   exists i1  isa i1  timeinterval  & temporalpart ctmp i1  i1  & temporalpart ctmp i1  i1    
interval1 is temporalpart of interval1 if interval1 is during interval1: all t1 t1  isa t1  timeinterval  & isa t1  timeinterval  & during ctmp t1  t1  temporalpart ctmp t1  t1  . interval1 is during interval1 if interval1 starts after interval1 and interval1 ends before interval1:
all i1 i1   before ctmp endfn i1   endfn i1   & before ctmp beginfn i1   beginfn i1    during ctmp i1 i1  .
a mapping of question predicates to the inferred answer predicates is provided in table 1:
question predicatesanswer predicatescountry at x1 frenchnn x1  france nn x1 control vb e1 x1 x1 mandate vb e1 x1 x1 syria nn x1 syria nn x1 overlapstemporallyctmp e1  x1 	&
time ctmp beginfn x1  
1 	1 	1 	1 	1 	1 	&
time ctmp endfn x1  
1  1  1  1  1  1 duringctmp x1  x1  & time ctmp beginfn x1  
1 	1  1  1  1  1  &
time ctmp endfn x1  
1  1  1  1  1  1 table 1: question to answer predicate resolution
　proofs for answers which do not have the correct context will fail  resulting in the candidate answer being pruned from the answer list. this in turn promotes all candidates below. as an example  the context resolution module will fail to find a proof for the first candidate answer returned by the answer processing module  without temporal reasoning   whose document date is 1:
the united states did not punish israel when it occupied territories of some arab countries such as palestine and syria  and refused to comply with relevant u.n.resolutions on the middle east issues.
　since the document date of the candidate does not meet the temporal constraints of the question  the incorrect answer is filtered from the list and correct answer  candidate 1 is rightly promoted to position 1.
1 question answering results
a set of 1 time dependent questions was used as a benchmark for measuring the contribution of temporal context to a state of the art question answering system. the benchmark was created primarily of questions that required temporal reasoning and so were previously unanswerable. further  they were derived from a 1 mb sub-collection of the trec corpus that included a sample of xin  apw  and nyt articles. table 1 summarizes the results of the system at the exact and sentence answer level with and without temporalcontext. the first two columns list qa results for the percent of correct answers in the first position and the mean reciprocal rank  without temporal context. the second two columns list the corresponding results for temporally enhanced qa. the final column gives the percent increase for answers in the first position.
answer
typeno contextcontextincrease in
firstfirstmrrfirstmrrexact1%.1.1%.1.1%sentence1%.1.1%.1.1%table 1: qa results
1 discussion
a means to represent and reason about context is crucial for the performance of a question answering system over a time sensitive corpus. advantages include: retrieving answer passages with relative or underspecified dates  discarding temporally inaccurate answers  and capturing the ordering of events via signal words. temporal inference is expensive  however  and should be ameliorated by development of a special purpose reasoner. further  the performance of signal and event detection should be improved by the ongoing effort to annotate training data  as demonstrated by the scaling experiments. despite this  the results presented in this paper have shown that significant improvement in open domain question answering can in fact be achieved by integrating temporal context reasoning.
1 acknowledgements
this work was supported in part by the arda aquaint program. special thanks to bob hauser  arthur dexter  and jens stephan for their invaluable research  implementation  and annotation efforts.
