 
in this paper we explore issues in learning such as the role of agenda mechanisms  noticers  history keepers  i n i t i a l seed sets of knowledge  and problem sequences in the context of our constrained exampled generation  ceg  system working problems in the mini-domain of linear functions. 
1. introduction 
　　　we have explored the robustness of this model  and i t s lisp realization  in such domains as: generating specific atoms and l i s t s in lisp  generating simple recursive programs in 
lisp  generating lines in algebra  generating scenes in a simple blocks world  and generating tactics in a game . effectively  the same system was used in each domain; only the domain specific knowledge was changed. the core system operates in a gps-like fashion  applying a set of difference-detectors and a set of difference-reducers in order to modify examples to meet the desired constraints. thus  in this work  the system could undertake remedial 

　　　in past work  we have investigated the structure of knowledge in complex domains like mathematics and computer science  cm  1 in particular the important role played by examples and the process of generating examples that meet specified properties or constraints   1     1     1   . we have built a computational model of the process of constrained example generation which was motivated in part by our observations of human subjects. 
　　　the basic idea behind the ceg system is as follows: given the goal of producing an entity with certain properties  instead of generating the entity from f i r s t principles  find an example in the data base which  most closely  matches the desired constraints  and then apply difference*reducing operators in order to modify that example to f i t the given constraints. the architecture of the ceg system is given in fig. 
1. 
 this work supported  in part  by 	the 	national science foundation under grant ist-1 1. 
  this work was also supported  in part  by the army research institute for the behavioral and social sciences  under ari grant 
no. mda1-c-1. 
any opinions  findings  conclusions or recommendations expressed in this report are those of the authors  and do not necessarily reflect the views of the u.s. government. modifications since it  knew what to do . 
	currently  we are 	investigating 	learning. 
1 to learn  a system must acquire experience and be able to review and summarize it c1c1. the design of the ceg system has the necessary modules to allow it to do so; in particular  the judge  agenda-keeper  history-keeper  and noticer/generalizer can be used to allow the system to monitor i t s own performance  and provide feedback  which as noted by smith et al  is c r i t i c a l to learning. 

　　　the specific task we have set for the learning-ceg system is to learn under which circumstances a particular reducer is appropriate. neves  explored a similar problem. this task allows us to explore the space of factors involved in learning: 
1. the role of agenda mechanisms 
1. the role of history-taking and -summarization 1. the role of i n i t i a l  seed  sets of examples i*. the role of posed problems  their content and order. 
the ceg system provides a vehicle in which to empirically explore the tradeoffs and interactions of these factors. the contribution of each of these components is a  parameter  to the current system. we are in the process of systematically testing various settings of these parameters. 
　　　for example  learning the appropriateness of an action implies learning something about the order in which to apply i t . this is particularly important in the case of interacting constraints where remediation of one constraint deficiency might destroy satisfaction of another constraint. 
　　　the agenda mechanism also affects the exploration of sequences of actions and modified examples. for instance  if a particular modification routine has just made the candidate example  better   e.g.  closer to meeting a constraint  should it be tried again  and if so  for how many times  on the other hand  should other routines be given an opportunity to demonstrate their effects  the latter technique would lead to discovering routines which are a mixed sequence of actions  whereas the former technique would lead to discovering routines composed of multiple copies of the same actions. 
1. an example from the lines domain 
the domain chosen for our investigations is that 	of 	linear 	functions on the real numbers  
i . e .   lines like y = 1x  ＊ 1. a typical ceg problem might be to generate a line such that: 
　　　1. it is steeper than a given l i n e   and 1. it has a negative slope. for a general l i n e   ay = bx + c  	steepness 	is the 	absolute 	value 	of the slope  i . e .   ib/ai. the sign of the slope is the sign of  b/a . 
　　　the ceg system has an i n i t i a l data base of example  i . e .   an  examples space.  an example is a specific l i n e   ay = bx + c  represented as a frame  whose value slot contains the three-tuple  a b c   . other slots include  derived-from  pointers indicating from which other example the example is constructed  and scaring and history information gathered during attempted modifications. 
　　　the  goodness  of a modification is measured by the judge module and expressed in terms of two scores:  1  the  global esc   constraint satisfaction count  which measures the example's satisfaction of a l l posed constraints;  1  the  local csc  which measures i t s satisfaction of the constraint currently being worked on. the scores are expressed discretely as  success    better    no-change   or  worse . 
　　　the system possesses five  primitive  routines that modify the x-coeffie lent: 
1. make-steeperl  ms1  which adds 1 to the x-eoefficient; 
1. make-steeper1  ms1  which 	doubles 	the x-coefficient; 
1. make-steeper1  ms1  which 	squares 	the x-coefficient. 
1. make-steeper1  ms1  which subtracts 1 from the x-coefficient; 
1. make-negative  mn  which changes the sign of the x-coefficient. 
thus  there are four routines that modify the steepness and one that modifies the sign of the slope. the system starts out  knowing  that msl  ms1  ms1 and msl affect the steepness and thus  implicitly that steepness has something to do with the x-coeffiecient of a l i n e . it does not know of the role of the y-coefficient. 
　　　some specific  facts  we wish to have the system acquire are: 
1. ms1  doubling  always works; 
1. ms1  add!  works for slopes   1; 1. ms1  squaring  works where islope!   1. 
1. ms1 is  faster  than ms1 which is  faster  than ms1. 
1. it is better to fix the steepness before 	the sign. 
1. experiments and results 
　　　thus far  our experiments have involved variation of the following: 
1. the agenda 	mechanism  	in 	particular  the 	search 	of 	sequences 	of 
modifications; 
1. the scoring of problems  in particular  whleh sequences count as  successes   
	 better   	e t c ; 
1. the i n i t i a l seed set of examples possessed by the system; 
1 
1. the order 	of 	problems 	posed 	to 	the system; 
1. the  remembering  and  forgetting  of examples created by the system  e.g.  the addition of successful solution examples to the system's 
 examples-space . 
a sample of the observations made on our experiments are: 
1. selection of operators: random selection  which allows the system to try the powerful ms1 routine more often  does in fact perform better than the regime that does not vary from the i n i t i a l choice of operator. however  the sequences of operators obtained under random selection are effectively  impossible  to analyze  even by humans. thus the style of the agenda-keeper influences the credit assignment task of the 
noticer/generalizer. 
1. influence of i n i t i a l knowledge base. the i n i t i a l seed set of examples should include a variety of examples  for instance  some likely-to-cause-trouble examples like y=1  some nicely-behaved examples like y=1x. the variety affects what is accessible to discovery; for instance  without lines with !slope!   1  the system would never learn ms1's weakness  and without lines with negative slopes  ms1's strengths. there is a trade-off between the variety of the knowledge base and the complexity of the agenda mechanism: the system didn't need a highly tuned agenda-keeper if the kb contained variety. this is related to mesa and false peak problems in hill-climbing. 
1. tuning the data-base. the  goodness  of certain examples  leading to successes   like y=1x  and the  troublesome-ness  of others  leading to worse-es   like ys1  became readily apparent. 
1. remembering/forgetting. to force exercise and learning of a b i l i t i e s   don't save answers. 
1. persistence. don't give up evaluating even if the situation looks locally worse. for instance  one agenda mechanism stops the modification attempts at the f i r s t encountered  local worse*; it never led to evaluations that might have showed that ms1l and ms1 tried in sequence lead to  global no-change  which could lead to discovery of their relation as inverses. 
1. conclusions 
in summary  we are using ceg to systematically explore alternative work-loads  influences  and contributions of modules in a learning system. we feel strongly that an empirical testbed is necessary for the understanding of ai systems which evolve in complex ways. there is a difference between making a system perform better and learning how it can learn to perform better. while expert system research often emphasizes the former  we feel it can benefit from study of the latter  which is our focus. 
