 
this paper presents a new efficient algorithm for simultaneous localization and mapping  slam   using multiple overlapping submaps  each built with respect to a local frame of reference defined by one of the features in the submap. the global position of each submap is estimated using information from other submaps in an efficient  provably consistent manner. for situations where the mobile robot is able to make repeated visits to all regions of the environment  the method achieves convergence to a near-optimal result with  time complexity while maintaining consistent error bounds. simulation results demonstrate the ability of the technique to converge to errors that are only slightly greater than the full solution  while maintaining consistency. 
1 introduction 
the capability of simultaneous localization and mapping 
 slam  is considered vital for the creation of long-lived autonomous mobile agents. because of the difficulties encountered by slam algorithms when applied to larger environments  the  map scaling  problem has been identified as one of the key issues for research in this area. in this paper  we adopt the feature-based  state-space formulation of slam  smith et al  1. recent related work in slam includes submap decomposition methods  leonard and feder  
1; guivant and nebot  1; julier and uhlmann  1; williams et al  1; tard1s et al  1   fastslam imontemerlo et al  1   sparse extended information filters  self's   thrun et al  1   scan-matching  gutmann and konolige  1; thrun  1; hahnel et al 1  and topological approaches  kuipers and beeson  1; choset and nagatani 1 . 
*this research has been funded in part by nsf career award 
bes-1  the mit sea grant college program under grant 
na1rg1  and the office of naval research under grant n1-1. 
　　　tp. newman is at the robotics research group  university of oxford and j. leonard is at the department of ocean engineering at 
mit  email: pnewman robots.ox.ac.ukjleonard mit.edu 
　this paper examines the slam problem using submaps. while there has been a considerable amount of work in 
slam along these lines  no previous method satisfies each of the three criteria of  1  provable consistency   1  spatial convergence  and  1  constant-time updates. for example  julier and uhlmann  1 provide a consistent  constanttime algorithm for large-scale slam  based on split covariance intersection  but this method does not achieve  tight  convergence to the error bounds that would be obtained with a full covariance solution. methods such as the compressed filter  guivant and nebot  1 j  the constrained local submap filter  williams et al  1   and sequential map 
joining  tardos et al  1 are provably consistent and convergent  but are  where  is the number of the fea-
tures in the environment. other techniques such as decoupled stochastic mapping  dsm   leonard and feder  1 and seif's  thrun et al  1  achieve 1  performance  but make approximations that require empirical testing to verify state estimation consistency. the atlas framework for largescale slam  bosse et al  1  achieves constant-time performance during the motion of the robot  enabling closing of large loops  but does not compute state estimates with respect to a single global reference frame. 
　the fastslam technique stands out in the literature as perhaps the only published technique which has been successfully posed for the general nonlinear slam problem with computational effort  the performance of 
fastslam  however  depends linearly on a  parameter  the number of particles   whose scaling with environmental size is still poorly understood  thrun et al  1  . 
this paper considers slam with known data association. 
this is a major assumption  but it enables us to focus on the underlying structure of slam state estimation with submaps for the linear gaussian case. other research has shown the ability to perform feature detection and measurement association using techniques such as random sample consensus and joint compatibility testing  neira and tardos  1  . 
　in this paper  we demonstrate how the three criteria of consistency  convergence  and constant-time updates can be achieved with multiple  locally referenced submaps. the key idea is to decouple the estimate of a map's global location from any of the state estimates within the map. this ''insideout  decomposition strategy succeeds because state estimates from one map are never mixed with state estimates from other maps. this enables us to guarantee the consistency of the state estimates for the linear gaussian case. 
　the structure of this paper is as follows. after reviewing the full  single map  slam problem in section 1  we define our terminology in section 1. section 1 summarizes the new slam algorithm and section 1 discusses its consistency and convergence properties. section 1 describes the performance of the algorithm using simulations and section 1 provides a concluding discussion. 
1 	slam within a single map 
let us assume that there are  features in the environment  and that they are static. the global frame  designated by g  is a unique  immutable coordinate-frame that is defined at the beginning of a mission. the true state at time is designated 
by 	  where 	rep-
resent the location of the vehicle  and represents the locations of the environmental features. we assume that the vehicle moves from time to time in response to a known control input  u k   that is corrupted by noise. designate the set of all control inputs from time 1 through time designate the set of sensor measurements obtained at time designate the set of all measurements obtained from time 1 through time  for each measurement there is a corresponding assignment index the value of if measurement originates from feature designate the set of all assignment indices from time 1 through time assuming that the associations are known  the objective is to compute recursively the probability distribution for the location of the robot and the features  with reference to the global reference frame g  given the measurements  control inputs  and assignments: 
		 1  
for the linear-gaussian  lg  slam problem  the kalman filter provides the optimal estimate of this pdf  which is described by its mean 	and covariance the properties of single-map lg slam solution are well-known ldissanayake et al  1  . 
1 	machinery for slam using multiple maps 
we now proceed to define several terms and basic operations that will facilitate description of the new method. a location vector is a parameterization of both position and orientation of one coordinate-frame  with respect to another   in 1 this is represented as a translation by followed by a rotation these three parameters are encapsulated in the 1 vector 
   an entity is a parameterization of a vehicle or landmark. each entity is labelled with a unique positive integer - this is referred to as the entity's id. we can attach a coordinate frame to any entity i and describe it using a location vector in another coordinate frame. the vector  should be understood to be a parameterization of a transformation from  to  the uncertainty in this transformation is represented by 
　a map is a collection of entities all described with respect to a local coordinate frame. each map has a unique integer id. each map has associated with it a map root entity i and a map location vector  the map location vector describes the pose of a map's local coordinate frame in the global frame g. the local coordinate frame of a map is coincident with one of the entities in the local map; this entity is referred to as the map root. in other words  the map root lies at the origin of the local map  and it is the entity to which all other entities in a map are referenced. if an entity is the map root  then by definition its location vector will be  and its global location vector given by - the 
location of the map in global coordinates.l we use the presuperscript notation to denote that all entities in map are referenced to where is the root entity of the map. the notation is summarized as: 

using this notation we can write the transformation from 
to  in map m with root entity . we simplify notation by dropping the right superscript when describing a transformation with respect to the map root: 
the term is the pose of an entity in the local frame of the map  which has its map root as entity 
we can manipulate location vectors using the binary trans-
formation operator where 
using the notation described above  we can describe the relationship between entities in any given map. consider the case of map referenced to feature denoted taking two entities ve can express the transformation from 
 1  
where the last step uses the simplification in notation described above. 
　we define root-shifting to be the operation  s  that changes the root of a map from  after this operation all location vectors in a map will be referenced to rather than this operation is is simply an extension of 
equation 1 to act on all entities in the map: 
 1  
 1  
1 	robotics    in the slam literature  the term  base reference   tardos et a/.  1  is a synonym for our term map root. note that in the general case with orientation  a single point feature will be insufficient to define a reference frame. in 1-d  two points will be required and in 1-d three points will be required. 

figure 1: flow chart for each cycle of the algorithm. 
　the global location of a feature j in a local map is computed by simple composition of the local location vector and the already globally referenced map location vector: 
		 1  
1 	the constant-time slam algorithm 
figure 1 illustrates the processing steps that are performed by the algorithm. the four key elements are  1  slam processing within local maps   1  map management  performing transitions between maps and creating new maps    1  map location estimation  determining the best global location estimate for a submap   and  1  computation of global state estimates for all features in a map. each of these processes are described in detail below. 
1 	s l a m within local maps 
at any one time  there is a single active map. for each map we compute a partial solution  
where 	designates the local map state  and and 	represent subsets of the measurements  associations  and control inputs  respectively. 	each measurement is used in only a single map. 	 this is vital for ensuring consistency of the global map location estimation process.  	each map m contains an estimated mean  and covariance 	cor-
responding to selected vehicle locations  for time steps when map m is the active map   and only a subset of the features. these estimates are the same as the location vectors and associated uncertainty for the features in the local map. 
1 	map management 
in our scheme  each map has a center  which is defined as the vehicle location at the time of the creation of a map. about this center is defined a region of radius  this defines a bound of vehicle location and not feature locations - any feature that is observed from a position inside the map region will be added to the local map. the estimated location of the vehicle is used to deduce which map s  the vehicle is in  and when to make transitions. when the vehicle travels more than from the center  the vehicle is considered to have left the current map. the parameter is a hysteresis term  to prevent excessive map switching. in the simulation results below  we use   an alternative to circular map re-
gions is the use of convex hulls  but this makes no difference to the fundamental performance of the algorithm.  
　we assume that the density of discernible features in a local area is bounded. this provides a bound on the number of features that can belong to a map. 
　when a vehicle leaves a map  we must determine which map  if any  the vehicle has transitioned to. a list of possible candidates is drawn up from a look up table indexed by quantized vehicle locations. if more than one candidate exists  we choose the map with the lowest id  i.e.  the oldest map. if no candidates are found  then a new map is created at the current location  a distance from the center of the previous map . all of these operations can be performed in constant time. 
1 	map location estimation 
map location estimation is the procedure by which global estimates for feature locations in each local map are improved  resulting in global convergence. this procedure is described as follows: 
1. select a map p  to improve which is currently referenced to the root entity i. 
1. create a set   containing the id's of all nearby maps including p - the map to be improved. 
1. for each create a s e t o f id's of features that are present in both maps. 
1. for the frame ; attached to feature calculate its globally referenced location and uncertainty using the location estimate of feature within 
map q and its current location estimate. 
1. pick the map 	and entity id 	such that: 
1. then stop. the map p cannot be improved 
1. root shift map p to reference all entities in map p to a coordinate frame attached to entity 
　for constant-time operation. map location estimation is performed only when the vehicle transitions from one map to another. alternatively  the procedure can be performed periodically  or at the end of the mission  to all maps. multiple iterations result in global convergence to a near-optimal solution  but the computation complexity is no longer o l . 
　the work presented in this paper differs from that proposed in  leonard and feder  1  on the following counts: 

  no vehicle information is carried between maps upon map transitions 
  the slam scheme adopted within each map need not be based on a kalman filter. 
  mapped entities are represented in local coordinate frames - one frame per map. in contrast  the dsm approach used multiple maps but all registered in one global coordinate frame. 
1 	obtaining global location estimates for map features 
given an independent  consistent estimate of the location of a submap p  with root i  with respect to the global frame  g  we can produce a consistent global estimate of the location of any feature j in map p by composition of map and feature locations: 
　　 1  are inde-
pendent  to the map. 
　the existence of a  shared  feature. s  between two maps p and q allows the location estimate   of map p   with root feature s   to be replaced with where 
 1  
and the root of map q is any feature id in map q. equation 1 should be interpreted as finding an alternative expression for the global location of a shared feature s using quantities associated with map q instead of p. as map p has a root at the shared feature s this expression is by definition an alternative expression for the map location. the minimization step of the algorithm is concerned with finding the best choice of shared feature s. 
　in the limit each map becomes internally fully correlated and the  min  operation will have no further effect so that for any feature j 
		 1  
where   is any choice of root. in other words no root-shifting and replace operation can be found that improves the global uncertainty of feature j. for the linear case 
　　　 1  then 
 1  
and so 
 1  
which is true for all choices of p and q. therefore the globally referenced feature location uncertainty is the same independent of choice of map    . the value of this limiting value is clearly given by the smallest possible uncertainty in map location which is the uncertainty of the first feature initialized in the first map idissanayake et ai  1  . this point is considered further in section 1. 
1 	consistency and convergence 
we begin by defining the term consistency with regard to an estimate of an r . v a t time k given all information up until time defining the estimated error vector and the estimate covariance as we write the condition of consistency as: 
 1  
 1  
to show that the global location estimates produced by equation 1 are consistent  we rely on the following three properties:  1  local map state estimates  obtained from the local slam solution 	are 
consistent   1  global state estimates tor map locations are consistent  and  1  the composition of these two pieces of information - local state estimates within a map and global information concerning the location of the map - is consistent. 
　the consistency of local maps follows directly from the properties of the kalman filter which in the linear gaussian case is the optimal bayesian estimator. clearly  choosing to use a possibly inconsistent estimator such as the ekf in a nonlinear scenario will invalidate these claims. however  the lg case allows statements to be made regarding the underlying properties of the cts algorithm. in a non-linear implementation  the consistency of the lg case can be matched to an arbitrary degree by using monte-carlo estimators in each sub-map. regardless of local estimation techniques  the cts algorithm preserves its constant time property. 
　local maps have three differences from the full solution  a  their base reference  root  is defined by one of the features in the map   b  relocation is periodically performed to re-initialize the local map when the vehicle transitions back into it  and  c  the base reference of the local map is periodically shifted from one feature in the local map to another  root shifting . none of these three differences result in a loss of consistency for the local slam solution. 
　the global map location estimate for a given map  m  is consistent because it is created via the composition of transformations derived from other local maps  and each local map is independent of other local maps. the composition of transformations from different local maps is a consistent operation  for the linear case . 
　finally  the composition of the local map state estimates performed in equation 1 is a consistent operation  because and are independent of one another. 
　while the location estimates for different maps are correlated with one another  and this correlation is not computed by the algorithm  the method in none-the-less consistent because this correlation is never needed. we never fuse map location estimates estimates  but rather  perform wholesale replacement. the algorithm keeps track of the best estimate for the global location of the root entity of a given map. a guiding principle of this algorithm is that estimated quantities that are  external  to a map never effect an internal quantity. 
　due to the relocation step for map transitions  the information from dead-reckoning measurements for the time step 

1 	robotics 

proceeding the map transition is effectively  lost . this information  however  does not affect absolute convergence but only the rate of convergence. because relocation is a consistent operation  knight  1  each partial solution retains all the properties of a kalman filter slam solution fdissanayake et al  1   and hence is provably consistent and convergent. because each map is local with its base reference as one of the features in the map  in the limit the uncertainty for each local map converges to zero  dissanayake et al  1  . this implies that  in the limit  in any local map utilizing only a subset of the relationship between features becomes perfectly known as a consequence of this is that the covariance of the transformation between any two features  i and j  in any given map tends to zero as hence  for local maps in which the base reference  root  is a feature in the local map  the covariance of any feature tends to zero. the key driver for convergence is the behavior in the first submap - submap 1. to illustrate this  consider a robot which moves swiftly outside submap 1 and spends the rest of its mission driving just outside submap 1 's borders. eventually the maps bordering submap 1 become completely known  including most of the features which appear in submap 1. the global uncertainty of any feature in the bordering submaps can never be less than the global uncertainty in the location of submap 1. hence  in this scenario  the root shifting mechanism can never decrease the global uncertainty of features in submap 1  nothing has lower global uncertainty . however as soon as submap 1 is re-entered and begins to be refined  the global uncertainties of maps sharing features with map 1 can be reduced by root-shifting. hence it is the precision of the first submap built  submap 1  that drives the ultimate performance of the entire system. in addition it is the precision of the first feature mapped within it that drives ultimate performance of submap 1. 
thus in the limit  the lower bound achieved in submap 1 is 
 inherited  by all other submaps. there are two differences between what occurs in submap 1 in comparison to a full covariance solution that couples estimates for all features in a single map:  a  submap 1 has fewer features in it  and  b  not all of the observations of features that are contained in submap 1 are processed in the submap 1 solution. we believe that consideration  a   the fact that submap 1 has fewer features in it  is what is sacrificed in this approach. even if some measurements are ignored in submap 1  vs. the full solution   in the limit as  both maps will converge to a well-defined lower bound. with enough additional time the submap 1 solution can  catch up  to the full solution. however  the fact that the full solution has more features enables in it cannot be compensated for  and hence the full solution achieves a slightly tighter bound. this in effect is the  cost  of computing multiple partial solutions and subsequently combining them  rather than computing one full solution. our simulations have shown that this result is extremely small  as shown below in figure 1 . 
1 	results 
this section analyzes the behavior of the technique presented using simulations analysis. the simulations consider an  point  vehicle that moves in the plane with process noise q of 1 or 1  monte-carlo  m/sec standard deviation in both and and measurement noise r of 1 m/scc standard deviation in both and features are visible if they are within 1 meters of the vehicle location. one visible feature is selected at random each time step to generate the observations. results are presented for three different scenarios: 
1. a simulation involving six cycles through an environment in which eight maps are created  to illustrate basic error convergence behavior   
1. monte-carlo analysis of 1 independent trials of a mission involving ten cycles through an environment in which twelve submaps are created  for empirical consistency verification   and 
1. results off-line map adjustment for a mission involving a single cycle through an environment in which eighteen maps are created  
1 comparison with the full covariance solution 
figure 1 show the vehicle path for a mission in which eight maps are created. figure 1 shows the vehicle error as a function of time as a function of time and active map id. spikes in the vehicle error estimate occur at each map transition when relocation  consistent re-initialization of the vehicle pose  is performed. this is particularly obvious towards the end of the experiment when the features are well known and subsequent observations swiftly bring the vehicle covariance down following relocation. figure 1 shows the difference between the new method and the full solution in the determinant of error covariance for the feature marginals in each map  demonstrating the tight convergence of the method to near-optimal estimates  while never going below the minimum permissible error bounds. 
1 monte-carlo consistency testing 
for the purposes of consistency testing  two relative states were logged in the active submap:  1  the difference between the first feature in the state vector and the vehicle  and  1  the difference between the first and second features in the state vector. these two states are stored in a single vector with covariance formed from the active map  with id 
this relative vector can be compared to the 'true' relative relationships declared by the simulator producing the noise corrupted measurements. the difference between these vectors is the error vector . the vector calculated for each map m will in general involve different features  by definition as each map contains a subset of the set of all features with only some features in common . however each estimated component of should be consistent  hence any sequence where m is the 
total number of maps built  should also be consistent. figure 1 illustrates the results obtained from monte-carlo experiments of the cts algorithm. the parameters used in the simulation of sensor data and its subsequent processing are given in table 1. all the plots are concerned with the statistical properties of . the first plot of figure 1 shows the 


figure 1: vehicle path for a mission with eight maps. the eight shaded circles indicate the extent of the submaps in terms of vehicle location alone. hence features can belong to maps even though they lie outside the submap boundaries. the map id's are in bold. the right hand plot shows the distribution and sharing of features between maps. some features are common to several submaps - for example feature 1 is found in submaps 1 1 and 1 whereas others are found in one alone - feature 1 is only mapped in submap 1. the lower plot shows the map transitions occurring as the vehicle moves. the basic trajectory is one of two overlapping rectangles aligned in north-east direction. the vehicle then returns to the origin  1  and repeats the pattern another six times. the feature estimate error ellipses are those resulting at the end of the simulations  in global coordinates  and are threc-sigma bounds. the full covariance solution is also plotted on the central figure with its estimated feature locations are plotted with squares. the covariance bounds on features are at this resolution indistinguishable from those 
of the produced by the cts algorithm. 
| parameter value 1 monte-carlo runs 
vehicle process noise  std  sensor noise  std  cycle length 
cycles per run 
total distance driven per run 
loops per cycle 
initial vehicle uncertainty sensor range 
sensor field of view feature density map radius 
vehicle velocity 1 
1 iris 1.1 m 1 m 
1 
1 m 
1 
1m 
1 m 
1deg 
every 1m in x and y 
1m 
1 ms-1 mean values of - the difference for each time step between the  true  relative vector and the the estimate the upper two plots correspond to the vehicle to feature relative states. note how the error does not converge to a zero value owing to the continual injection of process noise  odometry table 1: monte-carlo simulation parameters. errors etc  into the vehicle as it moves. the lower two plots however correspond to the error in the relative location of the first two features in what ever the active map is. no pro-
cess noise is added to the feature estimate covariances during the prediction stage of the estimation process. the result is the expected convergence to zero error. the second plot of figure 1 shows the plots the characteristics of the n-run average of the nees  normalized estimated error squared  of 
. the 1% confidence region bounds for estimation consistency are plotted on the same axes  the final plot of figure 1 shows the normalized mean estimated error  nmee  and the associated 1% confidence bounds of the hypothesis that the nmee sequences are from a consistent estimator. 
1 	off-line adjustment 
the root shifting operation which searches for a better representation  in terms of uncertainty  of map location and features need not be done as the vehicle transitions between maps. table 1 shows the improvement in successively ap-1 robotics 

figure 1: convergence of vehicle state estimates for the eight map example. the left hand plots show the time steps at the opening stages of the mission while the right hand plots show the closing stages. the straight line is the lowest possible bound on vehicle uncertainty possible for either algorithm in the zero plant noise case. the full vehicle uncertainty given by the full covariance solution is the lighter of the two plots and is always less than or equal to the the cts solution - the cts solution is always consistent. 

figure 1: the log of the full-covariance / cts difference between the determinants of the covariances in the first feature mapped in three randomly chosen submaps. before the first submap transition occurs  submap 1 computes an answer that is identical to the full solution. subsequently  submap one performs slightly worse due to the inclusion of less features. note also that the convergence of submap 1 appears to be slower than the other maps and indeed at times the difference between full and cts solutions seems to increase. this is because features in submap 1 can only be improved when this submap is active  whereas the full covariance solution updates all features with each new observation. 

figure 1: monte-carlo consistency testing. the left hand plot shows the four components of the vector  which encodes the errors in relative positions of vehicle and the first two features  in the state vector of the active map  the map in which the vehicle is currently moving . the first upper two sequences are the x and y components of the error in the relative position between vehicle and  the second two are the and components of the error in the relative positions of and . the central plot is the nees of y. the bounds are the 1% confidence intervals on the nees variable. the right hand plot shows the normalized mean error 
 nmee  for the components of for consistency the mean 

estimated error should be zero. the limits plotted are the 1% confidence interval bounds for the consistency hypothesis. 
robotics 	1 

table 1: percentage decrease in disparity between full covariance and cts calculated feature uncertainties during sequential off-line adjustments using the cts root shifting procedure. after three iterations all eighteen maps in this example showed no further improvement. 
| 	mup iteration 1 iteration 1 itcrution 1 1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 1 
1. 
1 
1 1 
1 
1 
1 
1 1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1   
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 1 
1 
1 1 
1 
1 
1 
1 
1 
1 1 
1 
1 
1 
1 
1 
1 
1 
1 
1 
1 plying the cts algorithm to maps at the termination of the mission for a scenario with 1 maps. the simple approach adopted here begins with submap 1 and seeks to improve the map location estimate  it then progresses to submap 1 and so on until the highest index map has been adjusted. this then repeats until no maps show any further improvement. it is a topic of future research to determine  as a function of shared feature topography  the optimal adjustment sequence rather than the linear one used here. the adjustment was applied to a mission with a vehicle trajectory defined by six overlapping rectangles  similar to figure 1 but the course was not repeated leading to a more uncertain collection of submaps at the end of the mission . the entries in the table are the percentage decrease in median disparity between the full covariance and cts calculated feature uncertainties. as expected  the table shows no improvement for submap 1. 
1 	conclusion 
in this paper  we have presented a new technique for slam with multiple maps that achieves consistency of global state estimates with with 1  1  time complexity. if the mobile robot is able to make repeated visits to all parts of the environment  by performing map improvement operations only when a map is exited  near-optimal convergence is demonstrated in constant-time. 
　in this approach  all slam filtering is performed in local submaps. each submap has an associated reference frame  whose global position is estimated using information from other submaps. the transition of the vehicle between submaps is consistently performed using relocation fneira et at.  1; knight  1 . by never mixing information between maps  the method yields provably consistent global state estimates  while still achieving global convergence. 
　the method successfully exploits the fact that overlapping features are estimated in different maps. by changing the base reference of a map to be the feature within the map that has the  best  globally referenced position estimate  the global location estimates for all the features in a local region get improved via operations in other maps. 
　ongoing research includes testing of the method with real data  the incorporation of probabilistic data association techniques  and extension of the approach to the nonlinear case. 
