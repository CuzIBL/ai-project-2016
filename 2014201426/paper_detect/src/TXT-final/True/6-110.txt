 
we describe algorithms for computing nash equilibria in structured game representations  including both graphical games and multi-agent influence diagrams  maids . the algorithms are derived from a continuation method for normal-form and extensive-form games due to govindan and wilson; they follow a trajectory through the space of perturbed games and their equilibria. our algorithms exploit game structure through fast computation of the jacobian of the game's payoff function. they are guaranteed to find at least one equilibrium of the game and may find more. our approach provides the first exact algorithm for computing an exact equilibrium in graphical games with arbitrary topology  and the first algorithm to exploit fine-grain structural properties of maids. we present experimental results for our algorithms. the running time for our graphical game algorithm is similar to  and often better than  the running time of previous approximate algorithms. our algorithm for maids can effectively solve games that arc much larger than those that could be solved using previous methods. 
1 introduction 
game theory is a mathematical framework that describes interactions between multiple rational agents and allows for reasoning about their outcomes. however  the complexity of standard game descriptions grows exponentially with the number of agents involved. for many multi-agent situations  this blowup presents a serious problem. recent work in artificial intelligence  la mura  1; kearns et al  1; koller and milch  1   proposes the use of structured game representations that utilize a notion of locality of interaction; these representations allow a wide range of complex games to be represented compactly. 
　in this paper we consider the task of computing nash equilibria for structured games. a nash equilibrium is a strategy profile such that it is no agent's interest to deviate unilaterally. a naive approach to finding nash equilibria is to convert the structured game into a standard game representation  and apply a standard game-theoretic solution algorithm imckelvey and mclennan  1 . this approach is  in general  infeasible for all but the simplest games. we would like an algorithm that exploits the structure in these game representations for efficient computation. 
　in this paper  we describe a set of algorithms that use continuation methods for solving structured games. these algorithms follow a trajectory of equilibria of perturbed games until an equilibrium of the original game is found. our algorithms are based on the recent work of govindan and wilson  1; 1a; 1b   gw hereafter   which apply to standard game representations  normal-form and extensiveform . we show how the structure of the games can be exploited to perform the key computational step of the algorithms of gw. 
　our methods address both graphical games  kearns et ai  1  and multi-agent influence diagrams  maids   koller and milch  1 . we present the first algorithm for finding exact equilibria in graphical games of arbitrary structure. we also provide the first algorithm that can take advantage of the fine-grained structure of maids  and therefore can handle maids which are significantly outside the scope of previous methods. we provide experimental results demonstrating the efficiency of our approach relative to previous methods. 
1 game representations and equilibria 
1 game theory 
we begin by briefly reviewing concepts from game theory used in this paper  referring to owen  for a good introduction. a game defines an interaction between a set n of agents. each agent n e n has a set of available strategies 
  where a strategy determines the agent's behavior in the game. the precise definition of the set  depends on the game representation  as we discuss below. a strategy profile a defines a strategy for each given a strategy profile   the game defines a payoff for each agent we use to denote the strategy profiles of the agents n -   . similarly  we use to refer to the set of all strategy profiles of agents in  
　a solution to a game is a prescription of a strategy profile for the agents. the agent's goal is to maximize its payoff. thus  a basic desideratum for a solution profile is stability - it should not be in any agent's interests to deviate from it. more precisely  the fundamental notion of a nash equilibrium  nash  1  is defined to be a strategy profile a such that  for all for all 
other strategies ' ~~ . thus  if an agent knew that the others were playing according to an equilibrium profile  it would have no incentive to deviate. 

　an e-equilibrium is a strategy profile such that no agent can improve its expected payoff by more than by unilaterally changing its strategy. unfortunately  finding an -equilibrium is not necessarily a step toward finding an exact equilibrium: the fact that is an -equilibrium does not guarantee the existence of an exact equilibrium in the neighborhood of a. 
normal-form games 
a general-sum normal-form game defines a simultaneousmove multiagent scenario in which each agent independently selects an action and then receives a payoff that depends on the actions selected by all of the agents. more precisely  let g be a normal-form game with a set n of agents. each agent n  n has a discrete action set sn and a payoff array gn with entries for every action profile in  
　equilibrium strategies often require that agents randomize their choice of action. a mixed strategy  is a probability distribution over sn. the set   is the set of all mixed strategies. the support of a mixed strategy is the set of actions in sn that have non-zero probability. a strategy for agent n is said to be a pure strategy if it has only a single action in its support. the set of mixed strategy profiles is a mixed strategy profile is thus an m-vector  where m = every game is guaranteed to have at least one mixed-strategy equilibrium  and the number of equilibria may be exponential in the number of agents. 
extensive-form games 
an extensive-form game is represented by a tree in which each node represents a choice either of an agent or of nature. each of nature's choice nodes is associated with a probability distribution over its outgoing branches. each leaf of the tree is associated with a vector of payoffs   where  denotes the payoff to agent  at leaf . the choices 
of the agents and nature dictate which path of the tree is followed and therefore the payoffs to the agents. 
　the decision nodes belonging to each agent are partitioned into information sets  where each information set is a set of states among which the agent cannot distinguish. thus  an agent's strategy must take the same action at all nodes in the same information set. we define an agent history for a node y in the tree and an agent n to be a sequence containing the information sets traversed in the path from the root to y  and the action selected at each one. thus  two nodes have the same agent-n history if the paths used to reach them are indistinguishable to n.  the paths may differ in other ways  such as nature's decisions or the decisions of other agents.  we make the common assumption of perfect recall: an agent does not forget information known nor the choices made at previous decisions. more precisely  if two nodes y  y' are in the same information set for agent then  
　we need a representation of a strategy for an extensiveform game; unlike the case of normal-form games  there are several quite different choices. for our purposes  the most appropriate representation is the sequence form  koller and megiddo  1; von stengel  1 . here  the strategy an for an agent n is represented as a vector of real values of size hn  one for each distinct history for a leaf z in the tree. the number   abbreviated   is the product of the probabilities controlled by agent n along the history  from this representation  we can easily derive the probability of taking an action at a particular information set. 
　the set of sequence form strategies for agent n is therefore a subset of   where  is at most the number of leaves in the tree. the set of legal sequence form strategies for agent n is defined by a set of linear constraints on vectors in . the set of sequence form strategy profiles is then defined as the payoff to agent n in an extensive-form game can be shown to be 
		 1  
thus  the payoffs arc a sum  over the leaves in the tree  of the payoff at a leaf times the product of the sequence form parameters for that leaf.1 importantly  this expression has a similar multi-linear form to the payoff in a normal-form game  but using sequence form strategies rather than mixed strategies. in an extensive form game satisfying perfect recall  any mixed strategy equilibrium can be represented using an essentially equivalent sequence form strategy profile. 
1 	structured representations 
graphical games 
the size of the payoff arrays required to describe a normalform game grows exponentially with the number of agents. kearns et al. 1  introduced the framework ol  graphical games  which provide a more structured representation based on probabilistic graphical models. graphical games capture local structure in multi-agent interactions  allowing a compact representation for scenarios where each agent's payoff is only affected by a small subset of other agents. examples of interactions where this structure occurs include agents that interact along organization hierarchies and agents that interact according to geographic proximity. 
　a graphical game is described like a normal-form game. the basic representation  slightly generalized  is a directed graph with one node for each agent. an edge from agent n1 to agent n in the graph indicates that agent n's payoffs depend on the action of agent n'. more precisely  we define famn to be the set of agents consisting of n itself and its parents in the graph. the agent's payoff  is an array indexed only by the actions of the agents in famn. thus  the description of the game is exponential in the in-degree of the graph and not in the total number of agents. in this case  we use to refer to strategy profiles of the agent in famn  
multi-agent influence diagrams 
the description length of extensive-form games often also grows exponentially with the number of agents. in many situations this large tree can be represented more compactly. multi-agent influence diagrams  maids   koller and milch  1  allow a structured representation of games involving time and information by extending influence diagrams  howard and matheson  1  to the multi-agent case. 
　a maid is represented as a directed acyclic graph over nodes of three types: chance  decision  and utility.  utility 
1
 for notational simplicity  gn{z  includes nature's probabilities. 
multiagent systems 

nodes are assumed to have no children.  chance nodes represent nature's actions  and a conditional probability distribution  cpd  is associated with each such node  describing the distribution over outcomes of that variable conditioned on the values of its parents. each decision node is associated with a single agent. the parents of a decision node represent the variables whose values are known to the agent when making that decision. thus  an agent's decision rule for a node can specify a different strategy for each assignment of values to the node's parents. in effect  each such assignment corresponds to an information set. a randomizing decision rule for a decision node is simply a cpd: a distribution over its values for each instantiation of its parents. 
　each utility node is associated with an agent  and represents a component in that agent's payoff. the utility node takes real values as a deterministic function of its parents. thus  that component of the agent's payoff depends only on a subset of the variables in the maid. the agent's overall utility is the sum of the utilities obtained at its different utility nodes. it is easy to show that a maid defines an extensiveform game. if we use cpds and decision rules that are treestructured  then the maid representation is no larger than the corresponding extensive-form representation  and is exponentially smaller in many cases. note that a graphical game is simply a maid where each agent has a single decision node and a single utility node  and where the parents of an agent n's utility node are the decision nodes for the agents in famn. 
1 continuation methods 
we begin with a high-level overview of continuation methods  referring the reader to  watson  1  for a more detailed discussion. continuation methods work by solving a simpler perturbed problem and then tracing the solution as the magnitude of the perturbation decreases  converging to a solution to the original problem. 
　more precisely  let be a scalar parameterizing a continuum of perturbed problems. when = 1  the perturbed problem is the original one; when = 1  the perturbed problem is one for which the solution is known. let w represent the vector of real values of the solution. for any perturbed problem defined by - we characterize solutions by the equation 
         = 1  where f is a real-valued vector function  so that 1 is a vector of zeros . the function f is such that if 
       = 1 holds then w is a solution to the problem perturbed by . 
　the continuation method traces solutions along the manifold of solution pairs satisfying = 1. specifically  if we have a solution pair we would like to trace that solution to adjacent solutions. differential changes to w and  must cancel out so that f remains equal to 1. 
thus  locally  changes dw and dx along the path must obey which is equivalent to 
the matrix equation 
 1  
	if the matrix 	has a null-space of rank 1 every-
where  the curve is uniquely defined. if properly constructed  the curve starting at  = 1 is guaranteed to cross = 1  at which point the corresponding value of w is a solution to the original problem. a continuation method begins at the known solution for = 1 . the null-space of the jacobian  at a current solution defines a direction  along which the solution is moved by a small amount. the process then repeats  tracing the curve until  = 1. the cost of each step in this computation  given the jacobian  is cubic in the size of the jacobian  due to the required matrix operations. 
　continuation methods involve the tracing of a dynamical system through the continuous variation of the parameter . for computational purposes  discrete steps must be taken. as a result  error inevitably accumulates as the path is traced. one can use several techniques to reduce the error  which we do not describe for lack of space. unfortunately  these techniques can potentially send the algorithm into a cycle  and in practice they occasionally do. if the algorithm cycles  random restarts and a decrease in step size can improve convergence. 
1 continuation methods for games 
we now review the work of kohlberg and mertens  and gw on applying the continuation method to the task of finding equilibria in games. these algorithms form the basis for our extension to structured games  described in the next section. the continuation method perturbs the game by adding a times a fixed bonus to each agent's payoffs  such that an agent's bonus depends only on its own actions. if the bonuses are large enough  and unique   the bonuses dominate the original game structure  and the agents need not consider their opponents' plays. thus  for  = 1  the perturbed game has only one equilibrium: each agent plays the action with the largest bonus. we then use the continuation method to follow a path in the space of  and equilibrium profiles for the resulting perturbed game  decreasing  until it is zero; at this point  the corresponding strategy profile is an equilibrium of the original game. we now make this intuition more precise. 
1 normal form games 
in order to apply eq.  1   we need to characterize the equilibria of perturbed games as the zeros of a function f. we first define an auxiliary function measuring the benefit of deviating from a given strategy profile. specifically   is a vector payoff function of the payoff to agent n for deviating from the mixed strategy profile a by playing each action s: 
　we now define a retraction operator r : to be an operator that maps arbitrary ra-vectors w to the point in the space  of mixed strategies which is nearest to w in euclidean distance. as outlined in the structure theorem of kohlberg and mertens   an equilibrium  is recoverable from by the retraction operator r: 
in fact  this condition is a full charac-
terization of equilibria. thus  we can define an equilibrium as a solution to the equation conversely  if and we have the equivalent condition that thus  we can search for a point   which satisfies this equality  in which case is guaranteed to be an equilibrium. 

　we now define the game perturbation and associated continuation method. for a target game g with payoff function v  we create an easily soluble perturbed game by adding an rn-vector 1 of unique bonuses that agents receive for playing certain actions  independently of what all other agents do. in perturbing the game g by b  we arrive at a new game in which for each   and for any t  
if we make 1 sufficiently 
large  then has a unique equilibrium  in which each agent plays the pure strategy s for which is maximal. 
now  let v be the payoff function for the target game g. 
the induced payoff function is also perturbed from . thus  the form of our continuation equation is: 
 1  
we have that is the payoff function for the perturbed game is zero if and only if is an equilibrium of the game is unperturbed  so 
is an equilibrium of g. 
　the expensive step in the continuation method is the calculation of the jacobian  required for the computation that maintains the constraint of eq.  1 . here  we have that 
	  where i is the 	identity ma-
trix. the hard part is the calculation of for pure strategies and   the value at location  s1  s1  in is equal to the expected payoff to agent n1 when it plays the pure strategy s1  agent plays the pure strategy .s1  and all other agents act according to the strategy profile a: 

computing eq.  1  requires a number of multiplications which is exponential in the game size; the sum is over the exponentially large space  
1 	extensive form games 
the same method applies to extensive-form games  using the sequence form parameterization of strategies. we first need to define the bonus vector  and the retraction operator which allows us to characterize equilibria. 
　the bonus vector in the extensive-form adds a bonus for each sequence of each agent. gw show that a sufficiently large bonus guarantees a unique equilibrium for the perturbed game. the retraction operator r takes a general vector and projects it onto the valid region of sequence forms. as all of the constraints are linear  the projection amounts to a decomposable quadratic program  qp  that can be solved quickly. we employ standard qp methods. the jacobian of the retraction is easily computable from the set of active constraints. 
　the solution for the sequence form is now surprisingly similar to that of the normal-form. the key property of the sequence form strategy representation is that the payoff function is a multi-linear function of the extensive-form parameters  as shown in eq.  1 . the elements of the jacobian also have the same general structure. in particular the element corresponding to sequence s1 for agent n1 and sequence s1 for agent n1 is 


figure 1:  a  an abstract diagram of the path. the horizontal axis represents  and the vertical axis represents the space of strategy profiles  actually multidimensional . the algorithm starts on the right at  =1 and follows the dynamical system until  = 1 at point 1  where it has found an equilibrium of the original game. it can continue to trace the path and find the equilibria labeled 1 and 1.  b  two-stage road building maid tor three agents. 
where  is the set of leaves that are consistent with the sequences s1  for agent n1  and s1  for agent n1 - we take  to be the empty set  and hence  if s1 and s1 are incompatible. eq.  1  is precisely analogous to eq.  1  for normal-form games. we have a sum  over outcomes  of the utility of the outcome multiplied by the strategy probabilities for all other agents. note that this sum is over the leaves of the tree  which may be exponential in the number of agents. 
　zero-probability actions in extensive-form games give rise to an additional subtlety. such actions induce a probability of zero for entire trajectories in the tree  possibly leading to equilibria based on unrealizable threats and other undesirable phenomena. for us  they can also lead to bifurcations in the continuation path  preventing convergence. thus  we constrain all sequence form parameters to be greater than or equal to e for some small e. this constraint ensures that the continuation path is a 1-manifold. the algorithm thus finds an equilibrium to a perturbed game  where agents have a small probability of choosing an unintended action. as c tends to zero  these equilibria converge to perfect equilibria of the original game  owen  1   a  nonempty  subset of all equilibria. for e small enough  continuity implies that there is always an exact perfect equilibrium in the vicinity of the perturbed equilibrium  which can easily be found using local search. 
1 	path properties 
in the case of normal-form games  the structure theorem of 
kohlberg and mertens  implies that  with probability one over all choices for 1  the path of the algorithm is a onemanifold without boundary. gw provide an analogous structure theorem that guarantees the same property for extensiveform games. figure 1  a  shows an abstract representation of the path followed by the continuation method. the equilibrium for large positive  is unique  so the one-manifold cannot double back to the side of = furthermore  the perturbed games along the path can have only a finite number of discrete equilibria  so the path cannot travel back and forth indefinitely. therefore  it must cross the  = 1 hyperplane at least once  yielding an equilibrium. in fact  the path may cross multiple times  yielding many equilibria in a single run. as the path must eventually continue to the  side  it will find an odd number of equilibria when run to completion. 
　in both normal-form and extensive-form games  the path is piece-wise polynomial  with each piece corresponding to a 
multiagent systems 

different support set of the strategy profile. these pieces are called support cells. the path is not smooth at cell boundaries  due to discontinuities in the jacobian of the retraction operator  and hence in  when the support changes. thus  in following the path  care must be taken to step up to these boundaries exactly. 
　in the case of two agents  the path is piece-wise linear and  rather than taking steps  the algorithm can jump from  elbow  to  elbow  along this path. when this algorithm is applied to a two-agent game and a particular bonus vector is used  the steps from support cell to support cell that the algorithm takes are exactly equal to the pivots of the lemke-howson solution algorithm  lemke and howson  1  for two-agent games  and the two algorithms find precisely the same set of solutions. thus  the continuation method is a strict generalization of the lemke-howson algorithm that allows different perturbation rays and games of more than two agents. 
1 	iterated polymatrix approximation 
because perturbed games may themselves have an exponential number of equilibria  and the path may wind back and forth through any number of them  the continuation algorithm can take a while to trace its way back to a solution to the original game. we can speed up the algorithm using an initialization procedure based on the iterated polymatrix approximation  ipa  algorithm of gw. a polymatrix game is a normalform game where the payoffs to a agent n are equal to the sum of the payoffs from a set of two-agent games  each involving n and another agent. polymatrix games can be solved quickly using the lemke-howson algorithm . 
　given a normal-form game g and a strategy profile c we can construct a polymatrix game pa whose jacobian at o is the same as the jacobian of g's payoff function v at a. the game pa is a linearized approximation to g around cr  and can be computed efficiently from the jacobian of g. gw provide an iterative algorithm that  in each step  takes a profile o and improves it using the solution of the polymatrix approximation pa. this algorithm is not guaranteed to converge  but in practice  it quickly moves  near  a good solution. we then construct a perturbed game close to the original game for which this approximate equilibrium is an exact equilibrium. the continuation method is then run from this starting point to find an exact equilibrium of the original game. 
1 exploiting structure 
as mentioned above  the calculation of at each step of the algorithm consumes most of the time. both in normal-form and  in the worst case  in extensive-form games  it requires time that is exponential in the number of agents. however  as we show in this section  when using a structured representation such as a graphical game or a maid  we can effectively exploit the structure of the game to drastically reduce the computational time required. 
1 graphical games 
consider the computation of the normal-form jacobian in 
eq.  1 . the key insight is that the choice of strategy for an agent outside the family of n1 does not affect . this observation allows us to compute the n1 entries in the jacobian locally  considering only n1 's family. more precisely  we can 

　letting / be the maximal family size  and d the maximal number of actions per agent  we have that the computation of the jacobian requires time  
1 maids 
the jacobian for maids 
to find equilibria in maids  we extend the sequence form continuation method of section 1. as above  our key task is computing the jacobian of eq.  1 . the jacobian has an entry for each pair of sequences in the game  one for each agent . we therefore begin by noting that the sequence form representation for maids with perfect recall is no larger than the agent's decision rules for that maid. due to perfect recall  the last decision node  in topological order  must have incoming edges from all of its previous actions and all parents of previous actions. moreover  it must have an information set for any distinct agent history. thus  the agent's decision rule for that final decision has the same size as the sequence form. hence  the dimension m of the jacobian ma-
trix is linear in the size of the maid  where size  as usual  includes the size of the parameterization . 
　we next turn to the computation of the jacobian entries. eq.  1  can be rewritten as 
		 1  
a leaf node z in the extensive-form game is simply an assignment x to all of the variables in the maid  and is n1's utility given x. the sequence probability the product of the probabilities for the decisions of agent n in the assignment x. thus  eq.  1  is an expectation of 
. the expectation is over the distribu-
tion defined by the bayesian network  whose structure is the same as the maid  and where the agents' decision nodes have cpds determined by  
　the agent's utility is the sum of its utility nodes. due to linearity of expectation  we can perform the computation separately for each of the agent's utility nodes  and then simply add up the separate contributions. thus  we assume from here on  without loss of generality  that n1 has only a single utility node u. 
　the value of  depends only on the values of the set of nodes ♀    consisting of n1;'s decision nodes and 

their parents. thus  instead of computing the probabilities for all assignments to all variables  we need only to compute the marginal joint distribution over  from this distribution  we can compute the expectation in eq.  1 . 
using bayesian network inference 
our analysis above reduces the required computations significantly. we need only compute one joint distribution for every pair of agents ri1  n1. this joint distribution is the one defined by the bayesian network . naively  this computation requires that we execute bayesian network inference times: once for each ordered pair of agents n1  n-1. for-
tunately  we can exploit the structure of the maid to perform this computation much more efficiently. 
　the basis for our method is the clique tree algorithm of lauritzen and spiegelhalter . a clique tree for a bayesian network is a data structure defined over an undirected tree over a set of nodes c. each node is a subset of the nodes in b called a clique. the clique tree satisfies certain important properties. it must be family preserving: for each node x in b  there exists a clique such that x and its parents are a subset of ci. it also satisfies a separation requirement: if c1 blocks the path from c1 to c1  then  in the distribution defined by  we have that the variables in c  are conditionally independent of those in c1 given those in c1. 
　each clique maintains a data structure  called a potential  which is an unnormalized distribution over the variables in ci. the size of the potential for ci is therefore exponential in 
. the clique tree inference algorithm proceeds by passing messages from one clique to another in the tree. the messages are used to update the potential in the receiving clique. after a process in which messages have been sent in both directions over each edge in the tree  the tree is said to be calibrated; at this point  the potential of every clique ci contains precisely the joint distribution over the variables in ci according to b. 
　we can use the clique tree algorithm to perform inference over ba. now  consider the final decision node for agent ni. due to the perfect recall assumption  all of nis previous decisions and all of their parents are also parents of this decision node. the family preservation property therefore implies that dni is fully contained in some clique. thus  the expectation of eq.  1  requires the computation of the joint distribution over three cliques in the tree: the one containing  1  the one containing dni  and the one containing dn1. we need to compute this joint distribution for every pair of agents n1  n1. 
　the first key insight is that we can reduce this problem to one of computing the joint marginal distribution for all pairs of cliques in the tree. assume we have computed pb ci cj  for every pair of cliques ci  cj. now  consider any triple of cliques c1  c1  c1- there are two cases: either one of these cliques is on the path between the other two  or not. in the first case  assume without loss of generality that c1 is on the path from c  to c1. in this case  by the separation requirement  we have that pb c1  c1  c1  = pb c1 pb{c1 c1 /pb c1 - in the second case  there exists a unique clique c* which blocks the paths between any pair of these cliques. again  by the separation property  c* renders these cliques conditionally independent  so we can use a similar method to compute p b { c 1   c1  c1 . 
　thus  we have reduced the problem to one of computing the marginals over all pairs of cliques in a calibrated cliquetree. we can use dynamic programming to execute this process efficiently. we construct a table that contains pb ci  cj  for each pair of cliques ci cj. we construct the table in order of length of the path from ci to cj. the base case is when 
ci and cj are adjacent in the tree. in this case  we have that 
the probability 
expressions in the numerator are simply the clique potentials in the calibrated tree. the denominator can be obtained by marginalizing either of the two cliques. for cliques ci and cj that are not adjacent  we let ck be the node adjacent to 
cj on the path from ci to cj. the clique ck is one step closer to ci  so  by construction  we have already computed p ci  ck . we can now apply the separation property again: 
　let be the number of cliques in the tree  and d be size of the largest clique  the number of entries in its potential . the cost of calibrating the clique tree for is . the cost of computing eq.  1  for all pairs of cliques is finally  the cost of computing the si sj entry of the jacobian is 1 d1 . in games where interactions between the agents are highly structured  the size d of the largest clique can be a constant even as the number of agents grows. in this case  the complexity grows only quadratically in the number of cliques  and hence also in the number of agents. 
1 results 
1 graphical games 
we compared two versions of our algorithm: cont  the simple continuation method  and  the continuation method with the ipa initialization. we compared our results to the published results of the the algorithm of vickrey and roller 1   vk hereafter . the vk method only returns e-equilibria  but their approach is the only one that applies to graphical games whose interaction structure is not a  biconnected  tree and for which timing results are available. the vk paper contains several different algorithms. we compared against the algorithm which had the smallest approximation error for a given problem. 
　following vk  our algorithms were run on two classes of games  of varying size. the road game  denoting a situation where agents must build in land plots along a road  is played on a 1-by-l grid; each agent has three actions  and its payoffs depend only on the actions of its  grid  neighbors. following vk  we constructed a game where the payoff for an agent is simply the sum of payoffs of games played separately with its neighbors  and where each such subgame has the payoff structure of rock-paper-scissors. this game is  in fact  a polymatrix game  and hence is very easy to solve using our methods. we also experimented with a ring graph with three actions per agent and random payoffs. 
　for each class of games  we chose a set of game sizes to run on. for each  we selected  randomly in cases where the payoffs were random  a set of at least ten  and up to one hundred for maids  test games to solve. we then solved each game 
multiagent systems 


figure 1: results for graphical games:  a  running time for road game with rock-paper-scissors payoffs. results for ring game with random payoffs:  b  running time;  c  number of iterations of cont;  d  average time per iteration of cont. 

with a different random perturbation vector  1  and recorded the time and number of iterations necessary to reach the first equilibrium. we then averaged over test cases. the error bars show the variance due to the choice of perturbation vector and  for random games  the choice of game. for smaller games  the algorithms always converged to an equilibrium. in about 1% of the larger games  more than 1 agents   the algorithms did not converge on the first trial; in these cases  we restarted the same game with a different random perturbation vector. on average  about 1 restarts were sufficient for these difficult games. in a few large graphical games  e.g. 1% of games with 1 agents   ipa did not converge after 1 restarts; in these cases we did not record results for ipa+cont. in the other restarted cases  we recorded the time for the converging run. our results are shown in figures 1 a b . 
　in all cases  our algorithm found an equilibrium with error at most   essentially machine precision. in the road games  we compared against the times for vk using their hill climbing method which found -equilibria with error of 1 - 1 . in these games  the cont method is more efficient for smaller games  but then becomes more costly. due to the polymatrix nature of this game  the cont solves it immediately with the lemke-howson algorithm  and is therefore significantly less expensive than  
　in the random-payoff ring games   had an equilibrium error of about 1 using their cost minimization method with a grid discretization of here  our algorithms are more efficient than for smaller games  up to 1 agents   with performing considerably better than cont. how-
ever  the running time of our algorithms grows more rapidly than that of  so that for larger games  they become impractical. nevertheless  our algorithms performed well in games with up to 1 agents and 1 actions per agent  games which were previously intractable for exact algorithms. 
　here  we also plotted the number of iterations and time per iteration for cont in figures 1 c d . the number of iterations varies based both on the game and perturbation ray chosen. however  the time per iteration is almost exactly cubic as predicted. we note that  when is used  the continuation method converges almost immediately  within a second . 
1 	maids 
roller and milch  define a relevance graph over the decision nodes in a  where there is an edge from di to d1 if the decision rule at d  impacts the choice of decision rule at d1- they show that the task of finding equilibria for a maid can be decomposed  in that only decision nodes in the same strongly connected component in the relevance graph must be considered together. however  their approach is unable to deal with structure within a strongly connected component  and they resorted to converting the game to extensive form  and using a standard equilibrium solver. our approach addresses the complementary problem  dealing specifically with this finer-grained structure. thus  we focused our experiments on maids with cyclic relevance graphs. 
　we ran our algorithms on two classes of games  with varying sizes. the first  a simple chain  alternates between decision and chance nodes with each decision node belonging to a different agent. each agent has two utility nodes  each connected to its decision node and to a neighbor's  except for the end agents who have one utility node for their single neighbor . all probability tables and payoff matrices are random. our second example is shown in figure 1 b . it is an extension of the graphical road game from above. each agent must submit plans simultaneously for the type of building  home or store  that they will build along a road. however  building  proceeds from left to right and so before committing to a build  an agent can see a noisy estimate of the plans of the agent to its left . agents would pre-
fer to be the first one to start a new type of building  i.e.  be different than their left neighbors  but the same as their right neighbors . they also take a penalty if their building and plan decisions differ. carefully chosen payoffs ensure non-trivial mixed strategies. 
　figures 1 a b  show the running times for computing an equilibrium as the number of agents is increased for both types of games. we compared our results to those achieved by converting the game to extensive-form and running bit  a standard equilibrium computation package. our timing results for gambit do not include the time for the conversion to extensive-form. 
　figures 1 c d  show the number of iterations and running time per iteration for the case of the two-stage road game. the running time per iteration is once again well fit by a cubic. the variance is mainly due to the execution of the retraction operator whose running time depends on the number of strategies in the support. 
1 discussion and conclusions 
in the last few years  several papers have addressed the issue of finding equilibria in structured games. for graphical games  the exact algorithms proposed so far apply only to the very restricted class of games where the interaction structure 


figure 1: results for maids:  a  running times for the chain maid. results for two-stage road maid:  b  running time;  c  number of 

iterations;  d  time per iteration. 
is an undirected tree  and where each has only two possible actions  kearns et ai  1; littman et al  1 . 
   there have been several algorithms proposed for the computation of e-equilibria in general graphical games  most of which  implicitly or explicitly  define an equilibrium as a set of constraints over a discretized space of mixed strategies  and then use some constraint solving method: kearns et al  use a tree-propagation algorithm; vickrey  and koller  use variable elimination methods  vk1 ; and ortiz and kearns  use arc-consi;.tency constraint propagation followed by search. vickrey and koller  also propose a gradient ascent algorithm  vk1 . the running times of kls and v k 1 both depend on the tree-width of the graph  whereas the running times of our algorithm  vk1  and ok depend on the degree of the graph. however  these latter three algorithms all require multiple iterations and no bounds are currently known on the number of iterations required. 
   for maids  koller and milch   km  define a notion of independence between agents' decision  and provide an algorithm that can decompose the problem based on fairly coarse independence structure. our algorithm is able to exploit a much finer-grained structure  resolving an open problem left by k m . la mura   lm  proposes a continuation method for finding one or all equilibria in a g net  a representation which is very similar to maids. this proposal only exploits a very limited set of structural properties  a strict subset of km and of our algorithm . the proposal was also never implemented  and several issues regarding non-converging paths seem unresolved. 
   we have presented an algorithm for computing exact equilibria in structured games. our algorithm is based on the methods of gw  but shows how the key computational steps in their approach can be performed much more efficiently by exploiting the game structure. our method allows us to provide the first exact algorithm for general graphical games  and the first algorithm that takes full advantage of the independence structure of a maid. our methods can find exact equilibria in games with large numbers of agents  games which were previously intractable for exact methods. 
acknowledgments. 	this work was supported by onr 
muri grant n1-1  and by air force contract f1-1 under darpa's task program. 
