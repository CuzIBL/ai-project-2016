
this paper investigates the effect of predefining semantics in modelling the evolution of compositional languages versus allowing agents to develop these semantics in parallel with the development of language. the study is done using a multi-agent model of language evolution that is based on the talking heads experiment. the experiments show that when allowing a co-evolution of semantics with language  compositional languages develop faster than when the semantics are predefined  but compositionality appears more stable in the latter case. the paper concludes that conclusions drawn from simulations with predefined meanings  which most studies use  may need revision.
1 introduction
the field of evolutionary linguistics is a rapidly growing field in contemporary cognitive science. many studies are based on computational modelling  where the researchers typically study aspects of language evolution using models that integrate ai techniquessuch as multi-agentsystems  evolutionary computation  machine learning  natural language processing and robotics. see  cangelosi and parisi  1  for an extensive overview.
　one of the most prominent aspects of human language that is researched concerns the origins and evolution of grammatical structures  such as compositionality. compositionality refers to representations  typically utterances in languages  in which the meaning of the whole is a function of the meaning of its parts. studies into the origins and evolution of compositionality have yielded models that can successfully explain how compositionality may emerge. most models have semantic structures built in  so the agents only have to acquire a mapping from signals to these meanings  together with their syntactic structures  brighton  1; kirby  1; smith et al.  1 . only few models have considered how compositional structures can arise through a coevolution between syntax and semantics  where the semantics are grounded through interactions with the world and develop from scratch  steels  1; vogt  1 .
　naturally  the two approaches yield different results. whereas in  brighton  1; kirby  1; smith et al.  1  it takes a number of generations until compositionality arises  in studies where the syntax co-develops with the semantics compositionality arises from the first generation  steels  1; vogt  1 . why is this difference  in this paper  the answer is sought by starting off with an implementation of vogt's model  which was based on kirby's model  but without predefined semantics  and then comparing this with a model in which the semantics is predefined  as in kirby's model.
　the next section presents some background relating to kirby's and vogt's model. section 1 presents the model which is our starting point. the results are presented in section 1 and discussed in section 1.
1 background
in the context of this paper  compositionality is defined as a representation of which the meaning of the whole can be described as a function of the meaning of its parts. for instance  the meaning of the expression  red apple  is a function of the meaning of  red  and the meaning of  apple . as a consequence  it is possible to substitute one part with another to form a new meaning as in the expression  green apple . in contrast  there are holistic representations in which the meaning of the whole cannot be described as a function of the meaning of its parts. for instance  the expression  kick the bucket  in the meaning of dying is a holistic phrase.
　it has been repeatedly shown that compositional structures can arise from initially holistic structures  i.e. structures with no compositionality  using the iterated learning model  ilm   brighton  1; kirby  1; smith et al.  1 . in the ilm the population at any time consists of adults and children.1the children learn from the linguistic behaviour of adults. after a learning episode  or iteration   the adults are removed from the population  the children becomes new adults and new children enter the population and the process repeats. kirby and others have shown that  given an induction mechanism that can induce compositional structures  an initially holistic language can change into a compositional one after a number of iterations  provided the language is transmitted through a bottleneck.
　the transmission bottleneck entails that children only observe a part of the expressible meanings of the language. assuming the children are equipped with a learning mechanism to discover and store compositional structures whenever possible  these structures tend to remain in the language because they allow an agent to communicate about previously unseen meanings. suppose  for instance  you only have observed the expressions  ab    ad  and  cb  meaning p m   q m  and p n  resp.. if you have no way to discover a compositional structure  you would not be able to express the meaning q n . however  if you have the ability to acquire compositional structures such as s -  a/x b/y  where a/m
-  a or a/n -  c  and b/p x  -  b or b/q x  -  d  you would be able to form the sentence  cd  to express the meaning q n . if an agent has acquired the language through a bottleneck  it may have to produce expressions about previously unseen meanings when it has become an adult. if there is no bottleneck  the children are expected to have learnt the entire language  so no compositionality is required and typically does not evolve.
　in kirby's model  all agents  adults and children alike  are equipped with the same predefined predicate argument semantics. naturally this is unrealistic  since it is widely acknowledged that human children are born without innate semantics. the question is therefore: to what extent does predefining the agents' semantics influence the results of such simulations 
　to investigate this question  vogt  implemented a simulation based on kirby's model  but without predefining the semantics. in vogt's model  described below   the semantics of individual agents develop in parallel with the language learning. this way  the semantics of adult agents differ from the children's.
　vogt  showed that  even without a bottleneck  relatively high levels of compositionality developed very early in the simulation. it was hypothesised that this rapid emergence of compositionality has to do with the statistical nature of the input given to the agents  both from the environment and signals . furthermore  it was shown that under certain conditions  e.g.  when a bottleneck on transmission was absent  this compositionality was unstable. in those cases  the languages gradually  though sometimes suddenly  transformed into holistic languages. one possible explanation for such a transition was based on the ontogenetical development of meaning.
　the study in this paper investigates the effect of predefining the semantics as opposed to semantic development with respect to the rapid development of compositionality and to the stability of the compositional structures. more concrete  a number of simulations will be presented in which the model is gradually changed from the model reported by vogt  to a model with predefined semantics as reported in kirby . the aim is to verify the two possible explanations mentioned.
1 the model
the model is implemented in vogt's talking heads simulator thsim  vogt  1 .1 in this simulation  a population of agents can develop a language that allows them to communicate about a set of geometrical coloured objects that form
actionresult1sensing the environmentcontext1select topictopic1discrimination gamemeaning1decodingexpression1encodingtopic1evaluate successfeedback1inductiongrammartable 1: a brief outline of the guessing game. step 1 and 1 are performed only by the speaker  steps 1 and 1 only by the hearer  and all other steps by both agents.
the agents' world. language development is controlled by agents playing a series of guessing games  cf.  steels  1 . the description of the model provided below lacks many details and motivations. unfortunately this is unavoidable due to the lack of space in this paper. for further details  consult  vogt  1 .
　the guessing game  gg  is briefly outlined in table 1. the game is played by two agents: a speaker and a hearer. both agents sense the situation  or context  of the game. the context consists of a given number of geometrical coloured objects. for each object   the agents extract a feature vector   where are features in a specified quality dimension  ga：rdenfors  1 . these dimensions relate to a sensed quality  which in the current implementation is one of the components of the rgb colour space     or a shape feature indicating the shape of the object.
　the speaker selects one object from the context as the topic of the game  step 1  table 1  and plays a discrimination game  steels  1  to find a category that distinguishes the topic from the other objects in the context
 step 1 . to this aim  each individual agent constructs an ontology containing categorical features  cf   which are points in some quality dimension . each feature is categorised with that categorical feature such that the distance is smallest.
　combining the cfs of each quality dimension constructs a category for object . the category is a point in a dimensional space. if the category for the topic is different from the categories of all other objects in the context  the dg succeeds. if no distinctive category is found  then each feature of the topic's feature vector is used as an exemplar to form new cfs   which are added to the ontology. this way  the ontology is built up from scratch.
　the distinctive category resulting from the dg serves as the 'whole meaning' of   where the whole meaning can be considered as a holistic semantic category. semantic categories are represented by conceptual spaces  ga：rdenfors  1 . a conceptual space is spanned by quality dimensions and contain -dimensional categories formed from cfs . the holistic semantic category is spanned by all 1 quality dimensions. other semantic categories include any possible configuration of quality dimensions  such as a colour conceptual space  spanned by the rgb qualities   a 1-dimensional shape space and a 'redgreen' space spanned by the r and g components of the rgb space. the whole s -  greycircle/
s -  a/rgb b/s
a -  red/
b -  square/
b -  triangle/
table 1: a constructed example grammar. in the example s  a and b are non-terminals. is a holistic rule that rewrites to an expressiongreycirclewith meaning . is a compositional rule that rewrites to non-terminals a and b that form linguistic categories associated with the semantic categories indicated by the quality dimensions rgb  for the colour space  and s  for the shape space . each nonterminal rewrites to another expression and meaning.  note that an expression can be associated with more than one meaning as in . 
meaning can thus be formed by a holistic category  of by a combinationof more lower dimensional categories. there are two constraints in the current model:  1  all quality dimensions should be used exactly once.  1  only combinations of 1 semantic categories are allowed. during their development  agents learn  or discover  which semantic categories are useful to form a compositional language.  in one experiment  though  these are predefined. 
a composition may be of only one holistic rule  e.g.  in table 1   or of several rules  such as
             which combines a colour with shape  note that the operator is used to connect terminal rules   and   with compositional rules such as  . each rule has a rule weight and - for the terminal rules - each possible meaning of a rule has the weight weight   both indicating the effectiveness of a rule and meaning.1 these weights are used to compute a score indicating the effectiveness of the rule based on past experiences. if the rule is a terminal rule  ; if is a compositionalrule  such as    . given the composition   one can calculate the composition score . when a rule/meaning pair is
used successfully in the guessing game  the weights	and
are increased  while the weights of competing rules/meanings are inhibited. the score is used to select amongcompeting compositions.
　when the speaker obtained a distinctive category from the dg  it tries to decode an expression  step 1  table 1 . to this aim  the speaker searches its grammar for compositions of rules that match the distinctive category or meaning .
so  the meaning can be decoded into the expression greycircleusing and meaning into redsquare using .  note that elements such as and are cfs with value 1 and dimension r and s respectively.  if there is more than one composition that can decode a meaning  the compositionwith the highest score is selected. this implements a selection mechanism
favouring effective compositions.
　if there is no composition that decodes the meaning  a new rule is constructed that either decodes a part of the meaning  or that decodes the meaning holistically. the former case is true if the speaker wanted to decode  for instance  meaning using the grammar of table 1. the part can be decoded using composition   where is the undecodedpart. a new rule of the form b -  circle/ is then constructed to fill in . in the model  expressions are constructed at random from a limited alphabet of size and with length   where   with a frequency distribution  to implement a bias toward short strings.
　the decoded expression is uttered to the hearer  which tries to encode this expression  step 1 . the hearer does not know which object is the topic  and its aim is to guess this using the verbal hint received. to do this  the hearer first plays a dg for each individual object   thus resulting in a set of possible meanings for the expression. then the hearer searches its grammar for compositions that can parse the expression and of which the meaning matches one of the possible meanings. if there are more than one  the hearer selects the one with highest score and guesses that the object of the corresponding meaning is the topic.
　this informationis passed back to the speaker  who verifies if the guess is correct and provides the hearer with feedback regarding to the outcome  step 1 . if the game succeeds  the weights of used rules are increased  while competing ones are inhibited using the equation   where is a weight   or    and if the weight is increased and if it is inhibited.  note that a rule is competing if it can decode an expression for the topic or encode the expression received. meanings compete when they belong to the same used rule  but are not the ones used  see  e.g.  .  if the game fails  the speaker provides the hearer with the correct topic and the hearer will then try to induce new knowledge  step 1 .
　induction proceeds in up to three of the following steps  if one step succeeds  induction stops :
1. exploitation. if there is a composition that partially decodes the expression  the remaining gaps are filled. for instance  if the hearer hears  redcircle  and the topic  indicated by the speaker  has distinctive category
　　　　　　  then it can decode the expression partially using composition   covering meaning
　　　　. in that case  the hearer will add the rule b -  circle/ to its grammar.
1. chunking. if exploitation fails  the hearer will investigate whether it can chunk the expression-meaning pair based on stored  holistic  expression-meaning pairs received in the past.  these pairs are stored in an instance base.  this is done by looking for alignments in the received expression with stored expressions and alignments in the distinctive category with stored meanings. if more chunks are possible  the chunk that has occurred most frequently or that has the largest common string is actually pursued.
for instance  if the instance base contains an entry with expression-meaning pair  pinkcircle -
and the hearer tries to induce knowledge from receiving the expression-meaning pair  greencircle   the following alignment is present:  greencircle - .1 based on this align-

ment the following new rules are added: s - 
c/rgb d/s  c -  pink/	  c -  green/	and d -  circle/ .
1. incorporation. if chunking fails too  the hearer will incorporate the expression-meaning pair holistically. for instance  if the expression-meaning pair is:  wateva -   the rule s -  wateva/ is added to the grammar.
　at the end of the induction step  a post-operation called generalise and merge is performed to generalise even further and to eliminate redundancies. redundancies can occur when new rules are created that are basically similar to already existing ones. the above example of chunking  for instance  yielded the construction of the rule s -  c/rgb d/s with additional filler rules. this rule  however  is in essence the same as rule from table 1. therefore  this new rule is removed  merged  and the non-terminals of the additional filler rules are replaced with the letters a and b. in addition  given a newly added rule b -  circle/ and the rules of table 1  rule can be chunked  generalised  as well  leading to the new rule a -  grey/ .  note that the old rules such as remain in the grammar. 
　the language game model is integrated with the iterated learning model. in this model  the population contains adults and children. whenever a gg is played  the speaker is selected from the adult population and the hearer from the child population. after a given number of guessing games  all adults are replaced by the children  and new children enter the population. such an iteration then repeats.
1 results
a number of experiments were done with the above model  three of which are reported here. each condition was carried out both without and with a transmission bottleneck. if a transmission bottleneck was imposed  a set of 1 objects were selected at random from the world of 1 objects at the start of each iteration. these 1 objects were then the objects about which the agents could communicate during that iteration.
　each experiment contained a population of 1 adults and 1 children. the experiments were run for 1 iterations of 1 guessing games each. at the end of an iteration  the population was tested before the adults were replaced by the children and new children entered the population. in each test phase  1 contexts were constructed. in every context one object was chosen as topic  and all agents then tried to encode an expression  which in turn all other agents tried to decode. from this phase  various measures were calculated of which compositionality is the measure reported in this paper. compositionality is calculated as the ratio between the number of compositional rules used  both encoded and decoded  and the total number of utterances produced and interpreted. the testing phase always used the entire world of 1 objects.

figure 1: compositionality as a function of iterations for experiments 1  top   1  middle  and 1  bottom . all experiments were done both without  left  and with  right  a transmission bottleneck. each line represents one simulation run.
no bottleneckbottleneck111.1.1.1.1.1.1.1.1111	1111	11.1.1.1.1.1.1.1.1table 1: the results of the first three experiments  both without and with bottleneck. for each condition compositionality is given for the end of the 1nd iteration and the end of the
1st iteration.
experiment 1 the first experiment was done with exactly the same model as described in the previous section. here all meanings developed from scratch in parallel to the development of the grammar.
experiment 1 in experiment two  all agents were given a repertoire of categorical features. with these cfs  the agents could form categories right from the start  but they did not have any idea how to combine the different dimensions to form conceptual spaces as the basis of the semantic structures.
experiment 1 in the third experiment  the semantic structure was predefined. all agents were given cfs as in experiment 1 and an additional constraint that semantic categories  i.e. conceptual spaces  were either colours  shapes or the whole  holistic  meaning.
figure 1 and table 1 show the results of these three experiments both without  left  and with  right  a transmission bottleneck. the development of compositionality in experiment 1 is shown in the top graphs. as can be seen  in both cases compositionalityemergedto a rather high level in the first few iterations   without and with a bottleneck  see table 1  row 1 . after that  compositionality tended to be instable and eventually died away in favour of holistic languages if no bottleneck was present  this was confirmed in simulations run for 1 iterations . with a transmission bottleneck  compositionality rapidly kept rising to a stable value of around 1. only one simulation showed a sudden dramatic decrease in compositionality around iteration 1  but soon recovered to its previous level.
　when the agents have predefined cfs  but had to learn the semantic structures  experiment 1  middle graphs   the initial levels of compositionality were slightly lower than in experiment 1. in the case where there was no bottleneck  compositionality remained in most cases at the same level  and in some cases even increased to levels near 1. when there was a bottleneck  compositionality rose in the same way to similar levels as in experiment 1.
　in the case where the semantics  including their structures  were predefined  experiment 1  bottom graphs   the results were quite different from the other two experiments. in both cases  the initial levels were substantially lower  although - in contrast to the other experiments - compositionality was lower without a bottleneck     than with a bottleneck    . when no bottleneck was imposed  compositionality increased to 1 in one simulation run  it rose in a few other cases  but often it remained at the same level or decreased. when a bottleneck was imposed  the compositionality revealed a similar increase as in the two other experiments with a bottleneck.
1 discussion
the experiments in this paper investigate the hypothesis that the statistical nature of the semantic structure can explain the rapid development of compositionalityand the hypothesis that the instability of compositionality in some circumstances had to do with the ontogenetical development of meaning. the experiments further investigate the effect of imposing a bottleneck on the transmission of language on the development of compositionality.
　all experiments reveal that when a bottleneck is imposed  compositionalitydevelops rapidly to a high and stable degree  thus confirming the results achieved earlier by kirby and others  brighton  1; kirby  1; smith et al.  1 . when no bottleneck is imposed  the behaviour of the different experiments is more different from each other  which will be discussed in the remainder of this section.
　there are two types of observations: first  when no semantic structure is imposed  experiments 1 and 1   high levels of compositionality are achieved within two iterations. second  when no categorical features are predefined  experiment 1   compositionality is unstable  whereas in other cases  compositionality is either stable  experiment 1  or may emerge at a later stage  experiment 1 .
let me start discussing the first observation. the prob-
rgbs1grbs1brgs1rgbs1rbgs1gbrs1rgbs1table 1: probability of finding co-occurring structures in dimension in two different games  assuming the values in differ. assuming that can have any possible value in the space of  indicated by   and any value in the space of   then	and
. the values are based on
the distribution of feature values  which are not presented in this text.
lems the agents learn is to discover regularities in the semantic space  which reflects the feature space of the objects  in combination with regularities in the signal space. it was hypothesised that the rapid development of compositionality in experiment 1  and 1  was caused by the statistical properties of the semantic space on one hand and the signal space on the other  vogt  1 . because signals tend to be short and are constructed from a limited alphabet  the likelihood of finding alignments in this space is high. since this aspect is not varied  all experiments had the same likelihood.
　the chances for finding regularities in the semantic space  however  is much higher when no structure is predefined. in experiment 1  the structure for combining the rgb space with the shape s space was imposed. given there are 1 colours and 1 shapes  there are different ways to form semantic structures of these 1 objects. however  when no structure is imposed  the combinations r-gbs  g-rbs  b-rgs  rg-bs  rb-gs and bg-rs are possible ways to combine the 1 quality dimensions as well. since  for instance  in the r dimension there are 1 different objects  1 colours and 1 shapes  that can have feature value . in a rough estimation  the probability of finding a one of these objects in game is proportional to . the probability of finding another object with in another game is . so  the probability of finding a co-occurring structure in the r dimension with in two consecutive games is: . now  if we look at objects of the same colour  e.g.  blue  i.e. with and    then the chance of finding a blue object in the first game is  and a different blue object in the second game is
	  so finding this co-occurrence is	.
　table 1 shows the co-occurrence probabilities for all objects involving similar values in one or more dimensions of the colour space. the values shown are the probabilities summed over all possible values in a conceptual space. as the table shows  when considering the entire colour space rgb  the co-occurrence probability is much lower than when searching for a co-occurring structure in the r space. so clearly  when an agent is able to construct any possible combination of semantic categories as in experiment 1  the chances of finding co-occurring structures is much higher than when it is restricted only to using rgb-s as in experiment 1. hence  compositionality in experiment 1 emerges faster than in experiment 1.
　interestingly  when there is a bottleneck on the transmission of language and stable compositional systems emerge  the most dominant rules  i.e. the type of rules that were used most frequently combine the colour space rgb and the shape space s. when there is no bottleneck  the most frequently used compositional rule combined r with gbs. this can be understood by realising that when half of the objects are discarded  the co-occurrence probability in the rgb-s structure is more or less maintained  while the other probabilities are affected differently in each iteration. this is because the distribution of colours and shapes is less skewed than the distributions in the other dimensions.  recall that each iteration a different set of objects is selected to learn from.  as a result  the rgb-s structure can be learnt most reliably.
　the second observationthat compositionalityis unstable in the absence of bottlenecks when categorical features are not predefined can be explained by realising the consequences of the gradual development of cfs. the foremost difference is that at the start of an iteration adults have a well developed set of cfs  while the children have none. during development  the children gradually acquire a similar set of cfs  but initially these cfs are overgeneralisations of the final categories. nevertheless  the children may - in certain situations - categorise some objects distinctively  thus successfully finishing a discrimination game.
　as a consequence  these children can successfully learn the words associated with these categories. however  since the cfs are overgeneralisations of the adults' cfs  the children's cfs may be associated with more than one word. this is even more the case when realising that different adults can have different words to name a cf. when the children acquire more fine grained cfs  the words may become associated with different cfs than was the case for the adults. this way  the words can drift through the conceptual space. when the language is compositional  the movement in one semantic category affects a larger part of the language than it would when the language is holistic. hence  holistic languages are more stable and thus easier to learn. when the cfs are predefined  there is less or no reason for overgeneralisations. this  in turn  allows children to acquire any compositional structure of their adults more reliably  which - in part - explains why compositionality is more stable  experiment 1  or even emerges  experiment 1 . the results of experiment 1 are very similar to those reported in  smith et al.  1   while the results of experiment 1 is highly dissimilar. it is yet unclear whether the predefined semantics of smith et al. are more similar to the ones used in experiment 1 or 1  though the results suggest that the semantics are more similar to the one used in experiment 1.
　concluding  both hypotheses tested in this paper are confirmed. in addition  the major findings of  brighton  1; kirby  1; smith et al.  1  that compositionality emerges under the pressure of a transmission bottleneck are confirmed in all tested conditions. hence  the assumption they made on predefining semantics to simplify their models appears valid. however  predefining the meanings - either with or without structure - can affect the results achieved in simulations of language evolution to a great extent  so one should be very careful in interpreting results achieved with such ungroundedmodels. this does not mean that the current grounded model on language evolution is sufficiently realistic to make hard claims regarding the evolution of language. however  the model is more realistic than ungrounded models in that in this model children do not have the same fullfletched semantic structures as adults.
acknowledgements
this work is sponsored by a ec marie curie fellowship and a veni grant provided by the netherlands organisation for scientific research  nwo . the author thanks andrew and kenny smith and three anonymous reviewers for comments on earlier versions of this manuscript.
