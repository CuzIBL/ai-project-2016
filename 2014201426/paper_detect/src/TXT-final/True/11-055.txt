 
       the hearsay model has heen presented as a paradigm for attacking errorful knowledge-intensive problems requiring multiple  cooperating knowledge sources. the hearsay-ii architecture is the latest attempt to explore the model. this paper describes experiences gained while successfully applying this architecture to the problem of speech understanding. the major conclusions are: 
1. the paradigm of viewing problem solving in terms of hypothesize-and-test actions distributed among distinct representations of the problem has been shown to be computationally feasible. 
1. a global working memory  the  blackboard    in which the distinct representations are integrated in a uniform manner  has made it convenient to construct and integrate the individual sources of knowledge needed for the problem solution. 
1. the use of a uniform data-directed structure for controlling knowledge-source activity has made the system easy to understand and modify. 
1. a solution has been demonstrated to the problem of focusof-attention in this type of control environment. this solution does not need to be modified when the sources of knowledge in the system are changed. 
introduction 
       the hearsay model  red1mo  has been developed for problem-solving in domains which must use large amounts of diverse  errorful  and incomplete knowledge in order to search in a large space. the hearsay-1 architecture and system  red1hx and erm1en  represented a first  and successful  attempt to apply that model to the problem of understanding connected speech in specialized task domains. in this first application  the size of the vocabulary  less than 1 words  and complexity of the grammar were very limited. 
       experiences with hearsay-1 led to the more generalized hearsay-ii architecture  les1r and erm1mu  in order to handle more difficult problems  e.g.  larger vocabularies and lessconstrained grammars . the first configuration of knowledge sources  kss  for hearsay-ii -- configuration ci - was complete in january  1  cmu1 . this implementation had poor performance  e.g.  1 sentences correct in 1 mipss  million instructions per second of speech  on a 1-word vocabulary . experience with this configuration has led to a substantially different set of kss - configuration c1  cmu1su . this configuration performs substantially better  e.g.  1. correct in 1 mipss on a 1-word vocabulary . 
       the hearsay-ii system  with the second configuration  has been successful: it comes close to the original performance goals set out in 1 to be met by the end of 1 for the arpa speech understanding effort  new1sp  and does so with a system organization that is of interest because of the potential for its application to other problem areas. several other problems have been attacked with organizations strongly influenced by the 
1 author's 	current 	address: 	department 	of 	computer 	and 
information science  university of mass.  amherst  mass. 1. 
1 this work was supported by the defense advanced research projects agency  f1-c-1  and is monitored by the air force office of scientific research. 
1 other approaches for solving this class of problem include production systems  frames  min1fr   heterarchical structures  wal1v and woo1fi   relaxation techniques  bar1ms and ros1sc   planner  hew1de   qa1  rul1qa   and the locus model  low1ha and rub1lo . 
hearsay-ii structure: image understanding  pra1se   reading comprehension  rum1to   protein-crystallographic analysis  eng1kn   signal understanding  nii1ru   and complex learning  sol1kn . 
       this paper is divided into two major parts. the first part presents an overview of the hearsay model  the hearsay-ii architecture  which is a further specification of this model  and the two ks configurations.  more detailed descriptions of these configurations are contained in the appendix.  the second part of the paper discusses the implication of these experiences for the hearsay model and the hearsay-ii architecture. in particular  those aspects of the architecture are identified that have contributed most strongly to the success of the system  as well as those parts that need the most future work.** this discussion is structured around two themes -- the multi-level global data base  blackboard  for ks cooperation  and the asynchronous  data-directed control structure for ks activation.1 
overview of the hearsay model 
       a number of characteristics of the problem drive the hearsay model: 
1. large search space. 
1. diverse sources of knowledge. many of the kss are large; some have large internal search problems of their own. 
1. error and variability. these are characteristics of both the input data  the acoustic signal  and the processing of knowledge sources. 
1. experimental approach needed for system development. this implies the need for iterating the system and running over large amounts of data. 
1. performance requirement -- accuracy and speed. this is true of any practical solution to the problem as well as during development  because of the experimental nature . 
       the basic notions of the hearsay model  red1mo  were developed in response to the requirements just stated: 
1. the kss are kept separate  independent  and anonymous. this separation is felt to be a decomposition which is natural and also can help make the combinatoric problems more tractable. for development purposes  the separation should help with system modifications  especially adding and modifying kss  and evaluation. 
1. a global data structure -- the blackboard -- is the means of communication and interaction of kss. this provides an hypothesize-and-test means of interaction. each ks accesses and modifies the blackboard in a uniform way. 
1. a ks responds to changes to the blackboard which it is concerned with; it applies its knowledge within the context' 
1 the fact that certain parts of the implementation need further work does not necessarily indicate deficiencies with the basic hearsay model  but rather points out inadequacies in the hearsay-ii implementation of the model. it is to the model's credit that even though some of its more sophisticated capabilities are not implemented effectively  it still provides an appropriate framework for the successful solution of a complex task. thus  one of the intents of this paper is to define some of the major design goals for the next iteration in the implementation of the hearsay model. 
1 while this paper discusses the means of organizing the knowledge and applying it to the problem  it does not describe in detail nor quantify the knowledge in the system. at least as much work has been expended on specifying and debugging the knowledge in the system as on building and refining the structure to hold and apply that knowledge. 
       
specialalized svstems-1: lesser 1 
       
of such a change. this implies data-directed activation of kss. 
overview of the hearsay-ii architecture 
       the hearsay-ii architecture is one framework for implementing the hearsay model. in this section  a very brief overview of that architecture is given. more details are described in  les1r and erm1mu . 
the blackboard 
       the blackboard is partitioned into distinct information levels; each level is used to hold a different representation of the problem space.  examples of levels are  phrase    word    syllable   and  segment .  the decomposition of the problem space into levels is a natural parallel to the decomposition of the knowledge into separate kss. for most kss  the ks needs to deal with only a few  usually two  levels to apply its knowledge. its interface to the rest of the system is in units and concepts that are natural to it. 
       the sequence of levels forms a loose hierarchical structure in which the elements at each level can be described approximately as abstractions of elements at the next lower level. the possible hypotheses at a level form a problem space for kss operating at that level. a partial solution  i.e.  a group of hypotheses  at one level can be used to constrain the search at an adjacent level. for example  consider a ks which can predict and rate words based on acoustic information and another ks which knows about the grammar of the language. the first ks can generate a set of candidate word hypotheses. the second ks can use these hypotheses to generate phrase hypotheses which can be used  in turn  to predict words likely to precede or follow. these predictions can now constrain the search for the first ks. 
       associated with each level is a set of primitive elements appropriate for representing the problem at that level; e.g.  the elements at the word level are the words of the vocabulary to be recognized. the major units on the blackboard are hypotheses. an hypothesis is an interpretation of a portion of the spoken utterance at a particular level. e.g.  an hypothesis might represent the assertion that the word  give  was spoken at the beginning of the utterance. each hypothesis at a given level is labeled as being a particular element of the set of primitive elements at that level. 
       each hypothesis  no matter what its level  has a uniform attribute-value structure. some attributes  and values  are required of all hypotheses and others are optional  as needed. included among the required attributes of an hypothesis are its level  e.g.  word   its element name  e.g.   give    and an estimate of its time coordinates within the spoken utterance  which can include notions of  fuzziness  of estimate . the level and time attributes place a two-dimensional structure on hypotheses which partitions the blackboard and can be used for addressing hypotheses. note that two or more hypotheses at the same level with significantly overlapping times are competitors  i.e.  they represent competing interpretations of a portion of the utterance. 
       other attributes of an hypothesis include information about its structural relationships with other hypotheses  forming an and/or graph   validity ratings  i.e.  estimates by kss of the  truth  of the hypothesis   and processing state. the processing state attributes are summaries and classifications of the other attributes. e.g.  the values of the rating attributes are summarized by the 
 rating state  attribute that takes a value from the set  unrated    neutral    verified    guaranteed   or  rejected . new attributes can be created by any ks and may be used for passing arbitrary information about an hypothesis between instantiations of the same or different kss. 
       a ks can create new hypotheses  specifying values for attributes of the new hypothesis. given the  name  of an hypothesis  a ks can examine or modify attributes of that hypothesis. in addition  sets of hypotheses may be retrieved associatively  based on the values of their attributes  e.g.  all hypotheses at the syllable level whose durations are greater than 1 msec . the hypothesis structure is uniform across all levels in the blackboard. thus  the form of access and modification to hypotheses by kss can also be uniform and is accomplished by calling kernel procedures; the set of these procedures comprises the blackboard handler. 
       in addition to the information in each hypothesis which can be accessed by kss  auxiliary state information is maintained by the blackboard handler in specialized data structures. examples of this information are  1  a representation of hypotheses at each level arranged for efficient associative retrieval by time and  1  the name of the highest-rated hypothesis in each time area. these auxiliary structures are updated by the blackboard handler automatically as kss make changes to the blackboard. 
structure of knowledge-sources 
       each ks has two major components: a precondition and an action. the purpose of the precondition is to find a subset of hypotheses that are appropriate for action by the ks and to invoke the ks on that subset; the subset is called the stimulus frame of the ks instantiation. for example  the precondition of the ks that generates word hypotheses based on syllables looks for new syllable hypotheses. when invoking the ks  the precondition provides the system scheduler with  in addition to the stimulus frame  a stylized description of the likely action that the ks instantiation will perform  if and when it is allowed to execute ; this estimate of action is called the response frame. for example  a response frame for the syllable-based word hypothesizer  mow  indicates that the action will be to generate hypotheses at the word level and in a time area that includes at least that of the stimulus frame. the action part of a ks is a program  written in sail  rei1sa   for applying the knowledge to the stimulus frame and making appropriate changes to the blackboard. in general  the changes made will serve to trigger more ks activations. 
       to keep from having to fire the precondition continuously to search the blackboard  each precondition declares to the blackboard handler in a non-procedural way the primitive kinds of blackboard changes in which it is interested. each precondition is triggered only when such primitive changes occur  and is then given pointers to all of them . this changes a polling action into an interruptdriven one and is more efficient  especially as the number of preconditions gets large. after being triggered  and when scheduled for execution   the precondition  also a sail procedure  can do arbitrary searching of the blackboard for hypothesis configurations of interest to its ks. 
       several kss may be grouped together into modules. the kss within a module may share code and long-term built-in data. a discussion of the module construct  including its implications for ks independence  is given below in the section on  ks independence . 
scheduling 
       whenever a precondition is executed  it checks all blackboard events in which it is interested that have occurred since the last time it executed. for example  a  new hypothesis  to a precondition is any hypothesis which was created between the last time the precondition executed and its current execution. thus  a precondition may be thought of as executing  then  sleeping  for a 
       time while retaining state  then waking  executing again  and being able to find all new events of interest to it. 
       however  whenever a ks executes  it uses the stimulus frame specific to that invocation. each ks execution goes to completion; that is  the ks cannot put itself to  sleep   waiting for some other event  on the blackboard  to occur. 
       at any point  there are  in general  a number of pending tasks to execute - both invoked kss and triggered preconditions.  in practice  the number of pending tasks often exceeds 1.  a scheduler in the kernel  hay1fo  calculates a priority for each waiting task and selects for execution the task with the highest priority. the priority calculation attempts to estimate the usefulness of the action in fulfilling the overall system goal of recognizing the utterance. this estimation is based on the specific stimulus and response frames of the actions and on overall blackboard state information  which includes such notions as the best hypotheses in each time area in the utterance  and how much time has elapsed since the current best hypothesis was generated. 
       
s p e c i a l i z e systems-1: lesser 
1 
       
the priority of a ks is recalculated if the validity of its stimulus frame is changed or the auxiliary state pertinent to evaluating the significance of the response frame is modified. 
       some kss are not directly involved in hypothesizing and testing partial solutions; instead  these control the search by influencing the activation of other kss. these policy kss can be used to impose global search strategies on the basic priority scheduling mechanism. 
the configurations 
       following are brief overviews of configurations ci and c1  to provide a basis for subsequent discussion. the appendix contains more detailed descriptions of the kss  as well as pointers to published papers. 
       figure 1 gives a schematic of configuration c1 as it was operational in january  1. the levels are indicated by solid horizontal lines and are labeled at the left. kss are indicated by vertical arcs with the circled end indicating the level where its stimulus frame is and the pointed end indicating the level of its response frame. the name of a ks is connected to its arc by a dashed horizontal line. as segment hypotheses were generated from the acoustic data  seg   they might be combined to form larger segment hypotheses  cseg . phone hypotheses were created  based on one or more contiguous segments  psyn . syllables were predicted from the phones  pom  and words from the syllables  mow . phrase hypotheses were constructed from contiguous word or phrase hypotheses which were syntactically consistent  recog . other kss  predict  respell  and postdict  accomplished various syntactic extension and prediction functions at the phrase and word levels. verification of predicted words was carried out by expanding the words into their expected syllables  wom   expanding the syllables into expected phonemes  mos   and matching the sequences of expected phonemes with the recognized phones  time and search . changes of ratings of hypotheses were propagated to structurally connected hypotheses  rpol . the focus policy ks controlled the search by setting priorities for various kinds of ks actions. 
       figure 1 gives a schematic of configuration c1 as it was operational in september  1. first  all segment hypotheses are generated from the parametric representation of the acoustic signal  seg . next  syllables are predicted from the segments  pom . then  words are predicted from the syllables  mow ; the most likely words in each time interval placed on the blackboard  wordctl . next  a heuristic word-sequence hypothesizer  woseq  attempts to identify the most probable sequences of word hypotheses  consisting of successive language-adjacent word pairs . because this ks exploits statistical methods to improve credibility  the initial word sequence hypotheses are much more accurate than are hypotheses based on single words. subsequently  kss are invoked to attempt to parse the hypothesized word sequences to determine if they are grammatical  parse   to predict possible time-adjacent grammatical word extensions  extend   to hypothesize and verify new words satisfying these predictions  mew   to concatenate grammatical and time-adj-acent word sequences  concat   to propagate ratings  rpol   to reject phrases and to determine when the serach should be terminated  stop   and to generate new word sequence hypotheses  wosctl . 
       the major system-related differences between these configurations1 are listed here; they will be discussed individually throughout the paper. 
1. ci has asynchronous processing throughout. c1 has an initial pass of sequential  bottom-up processing to the word 
1 though we are here concerned with systems issues  it is worth pointing out that woseq is a novel ks which significantly contributes to the success of c1. it limits the search space by providing large hypotheses which act as islands of reliability and bases for further search. this ks uses approximate syntactic knowledge to examine efficiently many alternative sequences of low-reliability word hypotheses and generate a small number of more reliable phrase hypotheses. 
level; i.e.  all segments are created  then all syllables  then a selection of words. 
1. ci used the blackboard extensively for intra-ks statesaving between instantiations of a ks  e.g.  search and recog-predict-respell-postdict . in c1  this was greatly reduced  with kss doing more computation internally and in larger units  e.g.  mew and parse-extend-concat . 
1. c1 generated simpler hypothesis networks than those in ci. for example  search and time built complex structures to represent verifications of words; mew builds very simple ones for the same purpose. 
experiences with hearsay-ii 
       this section addresses the following questions: how well did the hearsay-ii system meet its original design goals and were these goals appropriate for problem solving in the speech understanding domain  and more generally in errorful domains which require extensive search   this discussion is based on approximately three years of experience with the hearsay-ii architecture  including numerous iterations of both the system architecture and ks configurations/ these questions will be discussed in the context of two major aspects of the hearsay-ii architecture: the blackboard global data base  and ks interaction and control. 
blackboard data base 
       there are two major design themes reflected in the structure of the blackboard. the first theme is the avoidance of expensive and complicated backtracking control structures by the representation of alternative  distributed hypotheses in an integrated multi-level manner. the second design theme is the representation of all information levels with a high-level  uniform structure  in order to allow all kss to contribute their information to the blackboard in an identical and anonymous manner. 
distributed representation 
       it was hoped that the first design theme would  a  avoid the redundant calculation of previously-generated results and  b  allow kss to apply their knowledge selectively to places in the blackboard where further processing would resolve contradictory evidence supporting likely  alternative hypotheses. 
       the ability to save partial results on the blackboard in an integrated manner  in terms of hypothesis sub-networks  has been a very positive characteristic of the architecture; it avoids a significant amount of unnecessary recalculation of results previously generated. this was especially true for kss operating at the word and phrase levels. this was also true for kss in the ci configuration operating at lower information levels  for example  the time and search kss. however  later versions of these kss  e.g.  mew in c1   for reasons of efficiency  to be discussed later   do not save partial results on the blackboard. 
       the use of an integrated representation as a way of efficiently resolving competition among kss wanting to work on the same hypotheses has not been exploited  nor has the ability to bring to bear specialized knowledge dynamically to resolve the conflict among competing  alternative hypotheses  for example  a specialized ks to resolve ambiguity between two word hypotheses 
1 the emphasis on the two configurations as fixed points can be misleading; rather than appearing full-grown  the configurations evolved over time  with numerous iterations required first to develop ci and then c1 from ci. 
1 hayes-roth  hay1ro   in discussing how to evaluate the potential usefulness of a ks action  introduces the concept of diagnostictty as an important component in a ks priority function. diagnosticity is a measure of how much contradictory evidence could potentially be resolved by a particular ks action. 
specialized systems-1 : lesser 1 1 the usual manner of accomplishing this is having each ks  as it is about to create a new hypothesis  first check that a hypothesis does not already exist which is sufficiently similar to the one it is about to create. 
that are very close acoustically - e.g.   sit  and  split  . in addition  the ability given by the integrated representation to re-evaluate automatically  i.e.  without ks intervention  an hypothesis* credibility when its supporting environment is modified is not exploited in the c1 configuration  although it was c1 . in the c1 configuration  hypothesis credibility is never modified in an explicit sense; rather  new and different hypotheses are created. a side effect of this approach is that hypotheses are never deleted from the blackboard. 
       one explanation for the lack of full use of the integrated  multi-level representation of hypotheses could be just that the particular task domain of speech understanding does not need these capabilities. however  it is our feeling that there are fundamental weaknesses in the hearsay-ii representation of an integrated  multi-level hypothesis; these weaknesses  to be discussed below  make it difficult  both in terms of execution time and programming complexity  to perform the desired analyses of the hypothesis structure and its surrounding environment. this type of analysis is the key to the effective use of the sophisticated processing capabilities that are possible within the framework of the hearsay model. 
hypothesis network structure 
       a major problem in using the blackboard is that one cannot operate on a network  in its simplest form  a tree  of interconnected hypotheses as a composite unit. there is a basic confusion in hearsay-ips implementation of hypothesis networks between  a  the hypothesis at the top of the tree  the highest level of interpretation  and  b  the whole tree; the state information associated with an hypothesis is very local and does not adequately characterize the state s  of the hypothesis network s  connected to it. in order to operate effectively in a distributed manner on interconnected multi-level hypothesis networks  the state information associated with an individual hypothesis must allow a ks to analyze quickly the local environment of an hypothesis and  more importantly  the role that the hypothesis plays in the larger context of the hypothesis networks it is part of. one of the consequences of this deficiency is the difficulty encountered in making appropriate scheduling decisions because the more global import of a potential ks action cannot be determined easily. 
       for example  in configuration ci  an hypothesis at the phrase level was constructed out of hypotheses at the phrase  word  syllable  surface-phoneme  phone  and segment levels. because of the asynchronous nature of processing  a phrase hypothesis could be supported by word hypotheses in different stages of verification -- some might be fully verified  others only partially verified  or some totally unverified. possible ks actions waiting to work on this hypothesis network could be a separate verification of each unverified word  an attempt to extend the phrase in either the right or left direction  a search for co-articulation effects among different word pairs  or a full verification of a partially verified word. these actions represent processing at different information levels. given the existing hypothesis interconnection primitives  there is no way to determine easily that all these actions relate to the same hypothesis network  nor what import each action could potentially have in judging the credibility of the entire network. 
       another symptom of this problem is the inability to express  except in a very limited way  what type of processing has already been applied to* an hypothesis network and what further processing could possibly be applied. this inability again impacts the scheduler because it makes it difficult to schedule  competing  kss  i.e.  kss 
1 it is expensive to trace through an hypothesis network to determine the global import of a potential ks action. but this cost is not unreasonable relative to the total system execution time for a configuration which contains kss that perform moderately large amounts of internal computation. however  the major computational expense comes in dynamically updating the global import of a pending ks action as modifications are made to the blackboard since there are a large number of these modifications: it is necessary both to find which waiting ks instantiations have priorities that are affected by the modification and then to recalculate the priorities for those affected. 
which could work on the same or different parts of a specific hypothesis network  appropriately. because of these difficulties there has been  in later ks configurations  only a very limited  and simply represented and analyzable  form of ks competition. 
       another aspect of the inadequate network structure is that the primitives for specifying structural relationships between hypotheses require many intermediate levels to represent certain types of connectivity patterns. this need for many intermediate levels is expensive in in storage space and  more importantly  time; it requires a great deal of network searching through the connection structure to analyze the relationship of an hypothesis to its immediate surrounding environment. these intermediate levels represent a level of detail which is unnecessary for some types of ks analysis and which interfere with these analyses by making them unwarrantedly complex. once it has been constructed  it is impossible to bypass this level of detail in situations in which it is not pertinent. for example  an information level may contain many intermediate sublevels built out of the connection primitives; a ks using information at this level may want only to examine those hypotheses which are the highest sublevel in each time area. this type of operation  given the current blackboard retrieval primitives  requires the examination of all hypotheses in a specified time area. another complication of not being able to hide these intermediate levels is that a ks in some cases has to know the exact structure of the intermediate levels used by another ks in order to be able to skip over them  thus making the kss less independent. 
       in summary  the experience to date on the distributed representation approach indicates that the implementations of this concept explored so far are neither general nor efficient enough in two major interrelated aspects -- how hypotheses can be combined into a network and how the state information associated with an individual hypothesis reflects the hypothesis networks connected to it. to elaborate further  what is missing from the blackboard structure is a way of viewing the shared network structure from a different perspective. this perspective should permit the particular path through the network that defines a specific composite hypothesis to be both viewed in isolation from other paths that are intertwined with it  and also in a way that eliminates superfluous sub-structure. from this type of perspective  the importance of potential ks actions could be judged efficiently and related to the history of previous processing.1 
uniform blackboard structure 
       let us now examine the second major design theme used to structure the blackboard: a uniform structure at all information levels. from a programming point of view  both in terms of ks writers and system implementors  the uniform structure of the blackboard has been a good design choice. by having a uniform structure  a variety of standard blackboard creation  accessing  display  analysis  and debugging functions could be developed that are usable by all kss. these standard functions  some of which are quite complex  make it convenient for a ks writer to interface his knowledge source with the system. the ease with which this interfacing could be accomplished is exemplified by the fact that  in a period of six months  configuration c1  which is almost entirely new relative to ci  was developed and debugged. because of this uniform structure of hypotheses and their connections  it is often possible for a ks to be recoded so that it generates a different local hypothesis structure without requiring the recoding of other kss in the system; this is true because a ks can probe the blackboard with sophisticated built-in retrieval operations which  in many cases  shield the ks from changes made by other kss. for example  there is the structural-adjacency blackboard primitive which  given a hypothesis  finds all hypotheses at a particular information level that are immediately adjacent to the given hypothesis based on the and/or connection structure among hypotheses. 
the uniformity of the attribute structure of hypotheses also 
specialized 	systems-1: lesser 
1 1 a possible approach for implementing this different type of perspective is discussed in work by hendrix  hen1ex  on partitioned semantic networks. 
makes it possible to monitor efficiently for blackboard changes which are to trigger preconditions. each precondition needs only to declare to the blackboard handler the names of the attributes at each level in which it is interested. when an attribute is changed  the blackboard handler then triggers all preconditions interested in it. 
       the uniform blackboard structure  though efficiently implemented  is not appropriate as a scratchpad for the internal computations of a ks. this type of use of the blackboard is often inappropriate because its uniform  general structure does not come completely free in the storage requirements for an hypothesis and the cost of creation and access; most internal computations of a ks do not need this generality. an example of a misuse of the blackboard was the case of the syntax analyzer knowledge source  sass  hay1un   in early versions of this ks  the blackboard was used to hold the partial parse trees developed in attempting to parse a language fragment; current versions of this ks  which use a tailored  internal data structure for parsing  are two orders of magnitude faster than the original blackboard-based version of this ks. this case history seems to confirm the notion that there are advantages to specialization of structures: one for ks interaction  i.e.  the blackboard   and separate ones for each ks. 
       the blackboard has also proven to be useful as a data base for the scheduler  hay1fo . because of the uniform hypothesis structure  instantiations of kss can specify scheduling information in a uniform way  as stimulus and response frames   allowing new kss to be introduced without having to modify the scheduler. the representation of alternative hypotheses in an integrated  uniform fashion also makes it possible to compare directly the pending ks instantiations to determine which will likely contribute most to further progress; the scheduler 1  can determine those areas on the blackboard that most need further work and locate the pending ks instantiations that are relevent to those areas and 1  estimate the amount that a ks instantiation will improve the quality of hypotheses in the area of its action. 
long-term information structures 
       associated with each information level of the blackboard  there is  as previously discussed  a set of primitive elements that are used to label hypotheses at that level. the kernel interface provides facilities for creating  accessing  and displaying these labels. in addition  arbitrary data structures can be associated with each label. these structures  for example at the word information level  can be simple  such as the average expected duration of each word  or complex  such as a network which specifies alternative syllabic spellings for each word. in the complex case  this structure often is used to relate labels at one information level with labels at another; this relationship is used by a ks which operates between different levels  e.g.  in the example given here  wom in configuration ci . these data structures related to labels constitute much of the long-term  built-in  ks-defined information structures of the system and often represent most of the problem-specific knowledge in a ks. 
       each ks  or group of kss  defines whatever ad hoc structure seems appropriate for the particular kind of information to be represented. there has been no attempt to define a uniform set of kernel interfaces for creating and accessing these long-term data structures  nor a set of relationships  connection primitives  for relating labels at different levels. however  it seems possible to attempt to define a small number of representations within the kernel; these structures would mimic the hierarchical structure of the blackboard.  hanson and riseman in their work on image understanding have a system architecture  pra1se  very similar to the blackboard and have included a complementary long-term memory structure.  
       the major drawback of not having a predefined long-term memory is that if kss want to share this information they have to agree among themselves upon a specific structure  thus violating independence considerations. in addition  uniform structures could make kss easier to understand  develop  and analyze. 
       on the other hand  these long-term structures must be highly optimized because of their large size and the high frequency with which they are accessed.1 the approach taken of tailoring these structures to the particular ks s  using them allowed for efficient implementations in terms of both time and space. it is also possible that explicit tailoring has led to kss which are easier to understand than if they were forced to fit their requirements into a uniform structure. 
       thus  there are still open questions about the desirability of providing uniform structures for representing the knowledge in kss; hopefully  future implementations will explore these possibilities. 
conclusions about blackboard usage 
       in trying to draw some conclusions about our experiences with the use of the blackboard  the main issue that constantly comes up is time and space efficiency. in errorful task domains  such as speech understanding  a large number of alternative interpretations of the data must be examined and analyzed. the blackboard concept is effective in the hearsay-ii implementation to the degree that it allows this search to be efficient. analysis of the ci configuration indicated that certain types of ks processing on the blackboard were not efficient. reimplementation of the kss in order to eliminate those types of processing resulted in the c1 configuration. the major uses of the blackboard in the c1 configuration are: 
1. a storage  area for high-level intermediate results generated by the search. this storage area avoids the unnecessary recalculation of these results if they are encountered on future search paths. 
1. a communication area for kss  with strong and simplified assumptions by a ks of what structures can be generated by other kss. 
1. a data base for the scheduler. 
1. a common display  debugging  and performance evaluation area. 
knowledge-source interaction and control 
       the asynchronous  data-directed control structure used in hearsay-ii was designed to permit: 
1. the quick refocusing of attention to appropriate hypotheses in the blackboard. 
1. the flexible reconfiguration of the system with different sets of independent  and possibly competing  kss  and different global control strategies. 
1. the exploration of parallel processing. 
       this section will examine each of these requirements along two dimensions: were the capabilities embodied in the requirement important to the project  and how well did the control structure  in terms of time  space  and ease of representation  implement these capabilities  
appropriateness of a data-directed control structure 
       the first requirement  quick refocussing  was based on the following model for processing in the speech domain. processing can be organized in terms of the incremental additions of small units of information to a limited number of alternative hypotheses. the limited number of alternatives derives from the view that there are islands of reliability in the acoustic data that can be used to anchor the search. each small increment of information should help to verify  refute  or augment  expand  an hypothesis. a ks action  though performed in a local context  could also have the side effect of contributing information useful in the evaluation of alternative hypotheses  i.e.  in other contexts . thus  after each incremental addition of information  through the execution of a ks   it is necessary to re-examine the set of potential actions that now can be activated and determine which of these will most likely resolve 
specialized 	s y s t e n s - 1 : 	lesser 
1 1 for example  the description of the grammar used by the kss within the sass module in configuration c1 is a network of 1 nodes. each node has about seven pointers to other nodes  plus several pieces of auxiliary information. a typical ks action  e.g.  parsing a four-word phrase  might make 1 to 1 node accesses. 
ambiguity. an asynchronous  data-directed architecture makes it convenient to implement such a processing strategy by permitting ks action to be directed by the data: it delays the application of 
knowledge until there is enough information for a meaningful result  decision   and it re-applies the knowledge when  at a later time  additional information is generated that bears on the original decision. 
       in those parts of the blackboard where processing followed this model  the data-directed control structure was very effective. however  at lower levels of speech processing  i.e.  segmentation and labeling  syllable hypothesis generation based on segments  and word spotting based on syllables   this model was found to be inappropriate because there is not enough reliability in credibility scores of hypotheses to form hypothesis islands that can reliably anchor the search. thus  processing at these levels cannot be selective  depth-first   and instead requires a complete scan  breadth-first   for which asynchronous control has no advantages  and considerable costs . 
       a major change in going from configuration ci to c1 was making the lower levels of processing more sequential and bottomup. not until the word level is reached do hypothesis credibility scores have enough reliability to justify the more complex processing required of an asynchronous  data-directed control structure. the presence of these islands of reliability is in itself not a sufficient condition for the use of this sophisticated control structure. what is additionally required is that there is either a significant cost to evaluate each alternative or a large number of alternatives  combinatoric explosion in the search space ; only then is the overhead involved in implementing a data-directed control structure worthwhile. 
       in addition to the control overhead  an asynchronous control structure requires a more complex internal structure for a ks. this complexity arises because  as new information is asynchronously generated  a ks must have the additional logic to determine whether this new information allows it to make a decision it could not previously make or whether this information contradicts a previous decision. in the latter case  it must modify the previous decision  which may involve modifying decisions made as a consequence of the original one. where processing involves a complex hypothesis network structure with much detailed structure  the nature of asynchronous processing in response to a change at the detailed level is costly  both in terms of processing time and complexity of the ks  and should be avoided unless the compensatory benefits are large. as previously mentioned  the inadequacies in the blackboard structure which make it difficult to skip over detailed structure exacerbate these problems.  the search ks in configuration ci is an example of a ks working asynchronously at a detailed level. although the acoustic-phonetic knowledge applied by search was represented by a relatively simple data structure within the ks  the code necessary for examining and incrementally building large  integrated  and competing and/or structures on the blackboard was very complex and the number of ks executions needed to verify a word was large -- on the order of ten to one hundred. in c1  the function of word verification was replaced by the mew ks -- here  verifying a word is an atomic act  as far as other ks actions are concerned  and is carried out using tailored structures internal to the ks. each execution of mew forced a recalculation of the detailed structure  rather than sharing such structures across executions.  
overhead costs of data-directed control 
       the overhead cost of implementing an asynchronous datadirected control structure for computation of medium level granularity  i.e.  a ks action which involves greater than 1 second of internal computation  is not significant. the major cost involves monitoring each modify operation to the blackboard to determine whether any preconditions are interested in being notified of this specific change. this cost of monitoring and notification makes a modify operation 1 times as expensive as a read operation. however  in the c1 configuration there are 1 times as many reads as modify operations  thus making this aspect of implementing a data-directed control only 1% of the total cost of a run. 
       another cost associated with implementing this type of control structure involves maintaining a scheduler queue of waiting ks instantiations and performing priority calculations to decide which instantiation to run next. however  these focus of control calculations  possibly expressed in a different way  are necessary in any problem-solving system that involves a dynamic search. the more general implementation of these calculations in the context of an asynchronous control structure does not appear to generate significantly more system overhead than a specialized implementation of them in a system with more explicit control structure. the cost of maintaining and updating the scheduler queues and calculating the priorities was about 1 to 1 of a total run. 
       further costs involved in implementing this type of asynchronous control structure arise because of the delay between the invocation of a ks and its execution. the ks must  in general  contain code that revalidates its invocation context before beginning execution. however  by making some assumptions about the type of processing other kss could effect at particular information levels  
there was in practice very little need for context revalidation. kss did not in general interact by modifying previously-made assumptions and detailed structures constructed by other kss  but rather through the incremental addition of new hypotheses to existing structures or the verification of previously unverified hypotheses. 
ks independence 
       as indicated above  complete independence among kss was not accomplished. however  information about the processing characteristics of other kss is generally very restricted  and relates only to kss which share either dynamic information on the blackboard or long-term static information. to facilitate such data sharing  the concept of a module was introduced into the architecture. a module contains a set of preconditions and kss which share common structures and related accessing procedures. the kss contained in a module generally operate at the same or adjacent information levels and thus also share specialized accessing and display routines for these information levels of the blackboard. a module usually represents the code of one ks programmer and typically contains one to four kss and one to four preconditions. the clustering of kss by their long-term information structures turned out to be a convenient decomposition for separably instantiable but related activity. the ks module is the atomic unit which is the basic building block for different ks configurations.1 
       how important is the property of independence of kss  for the two configurations discussed here  the ks modules are not completely independent. however  during the lifetime of the project  which involved numerous iterations of kss  there has been very little difficulty encountered by this lack of complete independence  i.e.  the  subroutine interaction problem  did not haunt us . it has been possible to configure systems with subsets of ks modules  e.g.  a  top-end  system that deals only with word and phrase hypotheses or a  bottom-end  system which deals only at and below the word level  without modifications to the modules involved. 
       the reason for having little difficulty with the subroutine interaction problem can be traced to the data-directed activation of kss. in general  interaction among kss is accomplished by having a 
ks modify the attribute structure of an hypothesis in a way which causes some other ks s  to be activated and attend to that hypothesis. in order for kss to communicate information which is not representable using the standard  kernel-supplied attributes  the communicating kss need only agree on the name of a new attribute and the form of its value; this new attribute can then be used to pass the information. thus  it is not necessary for a ks to know the names of the other kss involved. individual kss which 
s p p c l a l f t   h 	systems-1: 	lesser 
1 1 each module is implemented as a separately compiled body of code. a configuration is specified at load time by selecting the desired modules. additionally  any ks or precondition can be inhibited at run-time  effectively excising it from the system. 
create  are activated by  or use this information may be added to or deleted from the system without requiring modifications to the other kss. 
a ks as a hypothesis generator 
       there are two major reasons  in addition to the one already discussed about context validation  why total independence was not achieved; both of these relate to a ks as a generator of hypotheses. the first reason concerns the control of the number of hypotheses a ks should initially generate and the reinvocation of it to generate additional  alternative hypotheses. the parameters associated with hypothesis generation should be set by a policy ks which has a more global view of the current state of the recognition process. the need then arises for a mechanism by which a policy ks can transmit its desires  in an anonymous and independent manner  to the appropriate ks. 
       it was hoped initially that these  processing goals  could be specified in terms of the basic hypothesize-and-test paradigm  i.e.  by having the policy ks create the appropriate type of hypotheses which would in turn trigger the desired activity . however   asking for something to be done  cannot always be specified conveniently in this way nor in an anonymous manner. for example  if there is a need for more word hypotheses to be generated in a particular time area  the action of creating a new hypothesis at the phrase level which will then be expanded at the word level does not precisely capture the desired activity  nor does the somewhat clumsy approach of modifying some attribute of the lower level data  e.g.  the syllable level  to force a ks to reprocess this data so as to accomplish the desired activity. note in this example  that by trying to force the concept of processing goal into the hypothesize-andtest paradigm  the policy ks must know the type of input stimulus that will trigger a ks to produce the desired results  thus violating the independence among modules. in addition  a ks which is designed to do hypothesizing-and-testing does not necessarily produce a response that will precisely match the desired processing goal. due to these difficulties of directly embedding goal processing control in the hypothesize-and-test paradigm  an alternative approach was developed  but not implemented  which integrates smoothly with the data-directed control flow of hearsay-1. 
       this alternative approach is based on introducing the concept of a goal node into the blackboard  with types of attributes distinct from those of an hypothesis and a means of relating goals at different levels. the action of creating a goal at a particular level is a monitorable event that triggers a ks that can do processing at that level. by making a goal node distinct from an hypothesis  a policy ks can generate goals without interfering with kss that operate at that information level but that cannot respond to the goal. if the triggered ks cannot directly satisfy the goal  it can generate a subgoal  linked to the original goal  to generate data at another level which could be used by the ks to satisfy the original goal. in this way  a policy ks can interact with kss in an anonymous and independent way. for example  if there is no ks to react to the goal  processing can still continue. in the same manner  if there is more than one ks that can respond to the goal  i.e.  competing kss   the scheduler can resolve this conflict without the need for any action by the ks that generated the goal. a goal node can also be used as a convenient place for a generator type of ks action to leave internal state information about how much and what type of further processing it can do in this area. 
       the other major reason for violating the independence criterion was based on an efficiency consideration. as previously mentioned  it is comparatively expensive to create an hypothesis on the blackboard. the cost of hypothesis creation is especially critical with a ks that can potentially generate a large number of hypotheses. for example  the syntax prediction ks  extend  in c1  can create  based on a prediction from a single phrase hypothesis  several hundred word hypotheses. each of these must then be processed by the word verifier ks  mew  and verified or rejected. before these hypotheses are verified they share almost identical structures. all but twenty  perhaps  will be rejected by mew. to avoid the expense of expanding these as distinct blackboard word hypotheses  special data structures have been constructed to store the predicted words compactly  these data structures are then attached as an attribute of the phrase hypothesis. this example further illustrates the weakness in the current hearsay-ii implementation of efficiently representing and processing groups of hypotheses. 
uniformity of control 
       another issue associated with the data-directed control structure is the ease with which different global control strategies can be explored. the uniform interface conventions used for specifying and activating kss and preconditions  together with treating policy  strategy  kss in the same way as other kss makes the total system easy to modify and understand. 
       as part of the uniform convention for specifying each ks  non-procedural declarations are required which tell the system the type of pattern that triggers the ks and the type of action that can result from the activation of the ks. by separating the activation of a ks from its scheduling  it has been easy to introduce new global strategies by applying a new priority evaluation function to the information supplied by each ks. in addition  by allowing a policy ks to be able to trigger upon certain conditions that occur in the scheduling  data base   such as the absence of any invoked kss  or the lack of any invoked kss above a certain priority level   it is possible to add different types of policy kss into the system in a modular manner  e.g.  wosctl in configuration c1 . 
       in the initial specification of the hearsay-ii architecture  the approach required for focus of control was not well developed and represented one of the major conceptual problems which would determine the success of the design. as a result of work on this problem over the last three years  it is felt that the problem  though not completely solved  is now understood well enough so that it no longer represents a major obstacle to the effective use of the architecture. it is interesting to note that much of the discussion in preceding sections is based on a better understanding of what features need to be present in the architecture in order to efficiently support complex focus of control strategies. 
parallel processing 
       one of the initial design goals of the hearsay-ii architecture was that it should be efficiently  and correctly  executable on a multiprocessor  les1pa and fen1mu . in order to test the parallel processing capabilities of this architecture on an actual ks configuration  a multiprocessor simulation system was embedded in the multiprocess implementation of hearsay-ii. each ks in this configuration was modified with the appropriate synchronization primitives. 
       the result of this simulation  which used an early version of the ci configuration that was strictly bottom-up in its processing  because it did not include the sass module   showed that effective parallelism factors of four to six could be achieved  fen1pa . unfortunately  there does not exist similar simulation data for a fully configured ci or c1 configuration  both of which include top-down processing. however  it is expected that the c1 configuration would exhibit a much higher degree of parallelism  because ks interaction is more loosely-coupled and the system does a large amount of breadth-first type of search. 
       the parallelism factors of four to six that were achieved were less than expected. further experiments were performed to determine the reason for these low factors. one of these experiments was to run the system with all uses of the synchronization primitives turned off. in this mode  the parallelism factors increased to fourteen. this dramatic increase is due to the fact that much superfluous synchronization was performed in each ks to maintain data consistency because no assumptions were made about how the blackboard was modified by other kss. this superfluous synchronization  combined with synchronization primitives whose granularity of locking was too coarse  led to unnecessarily large areas of the blackboard being locked in order to maintain data consistency; this resulted both in significant interference among concurrently executing ks processes and a high system overhead  between 1 and 1 percent  in order to support parallel processing. as with context validation  discussed above   this was a price paid for complete independence among kss. 
       
specialized 	systems-1: 	lesser 
1g 
       
       a surprising result was that system performance  in terms of accuracy  was as good with the synchronization disabled as its performance with the full synchronization. the explanation for this phenomenon is that the asynchronous  data-directed control of hearsay-ii is robust in the face of certain types of synchronization errors. for example  consider the normal activity sequence of a ks which involves first examining the blackboard  and then  based on the values read  modifying the blackboard. suppose that between the time when the ks read the value of an attribute on the blackboard and when it modified the blackboard  the value of the attribute was changed; therefore  the modification was inconsistent with the current state of the blackboard data. however  because of the data-directed nature of ks activation  the changing of the attribute will probably trigger the same ks to be reinvoked to recalculate its original modification. thus  the need is obviated for a ks  while executing  to lockout the areas of the blackboard it has read  in order to maintain the consistency of its modifications. in addition  other types of inconsistency can often be resolved because another ks with a different view of the problem will correct an incorrect hypothesis whether it resulted from a synchronization error  a mistake in the theory used by the ks  or from errorful data. thus  this self-correcting nature of information flow among kss  created through the use of a data-directed form of the hypothesize-and-test paradigm  in many cases obviates the need for explicit use of synchronization. 
conclusions 
       the major conclusions on the use of the multi-level blackboard structure are the following: 
1. the paradigm of viewing problem solving in terms of hypothesize-and-test actions distributed among distinct representations of the problem  where these representations form a hierarchy of abstractions  has been shown to be a computationally feasible approach to solving knowledge-intensive tasks. this paradigm also provides a convenient framework for structuring and applying knowledge. this has been demonstrated both by the successful application of the hearsay-ii architecture to the speech understanding task and also its adoption as an approach to problem-solving in a diverse set of other 
' domains such as image understanding  pra1se   reading comprehension  rum1to   protein-crystallographic analysis  eng1kn   signal understanding  nii1ru   and complex learning  sol1kn . 
1. the representation of alternative hypotheses in an integrated manner on the blackboard has been shown to have positive aspects. in particular  the integrated representation avoids unnecessary recalculation and makes it easy to compute a global view of the current state of the problem solution  for the purpose of focussing. the problems still to be resolved arise because the integrated representation permits hypotheses to be used simultaneously in  shared by  multiple contexts  hypothesis networks . existing primitives for grouping alternative hypotheses are inefficient in space  and  more importantly  make it difficult to determine easily the different contexts that use a hypothesis; these primitives also do not provide a convenient framework for representing and determining the fact that two contexts have very similar hypothesis structures. 
1. there are problems with the current formulation of a partial solution as a distributed network of hypotheses at different information levels. there is a basic confusion in the hearsay-ii implementation between the hypothesis in the network which is at the highest level of abstraction  interpretation  and the entire network. this confusion  combined with the problem of handling of multiple uses of a 
hypothesis  makes it difficult to perform some of the complex focus-of-attention strategies possible in the architecture. 
1. the uniform structure of the blackboard at all information levels has turned out to be a very positive feature of the architecture. it has made it possible to integrate new kss into the system easily and to develop a large set of utilities applicable to all kss. it has also permitted numerous reimplementations of the internal structure of the blackboard without requiring ks modification. 
       the major conclusions on the uniform  asynchronous  datadirected control structure are the following: 
1. the use of an implicit and uniform control structure for ks cooperation makes the system easy to modify and understand. the separation permitted between the invocation of a ks and its scheduling makes it convenient to implement a variety of scheduling policies without ks modification. 
1. the overhead costs involved in implementing this type of control structure are acceptable for kss which do moderate amounts of internal computation at each invocation  e.g.  more than 1 second in the current implementation . 
1. this control structure is not appropriate for domains in which the hypothesis credibility ratings are not selective enough to suggest strongly good paths to search. 
1. the problem of focus of attention in this type of control environment  though not completely solved  is now understood well enough so that it no longers represents a major obstacle to the effective use of the architecture. the integrated representation of alternatives on the blackboard  which permits a global view of the current state of problem solution  and the data-directed control structure make it possible to quickly refocus attention to the appropriate places in the blackboard. 
1. the initial attempt to have complete ks independence  in both a sequential and parallel processing environment  resulted in a significant amount of overhead  and thus seems not to be worth the cost. a more balanced approach  based on some knowledge about the type of processing done by other kss in the configuration  has been more effective. this knowledge does not violate anonymity of kss because it is based on a functional characterization of their activity and not on their  names . using this approach  ks configurations are still highly modular  i.e.  there has been no serious subroutine interaction problem  without paying the severe costs  in complexity of ks programming and execution time  of complete independence. 
1.parallel processing can be exploited effectively in this architecture. the techniques which are needed because of the errorful nature of the processing in this problem domain provide a form of processing which is also robust in the face of data inconsistency caused by not imposing complete synchronization among parallel processes. thus  the overhead costs of the synchronization are reduced substantially  allowing effective use of parallelism. 
       
1 another example of this self-correcting type of computational structure is a class of iterative refinement methods used to solve partial differential equations. this type of computational structure can be decomposed for multiprocessor implementation so as to avoid most explicit synchronization at the expense of more cycles to reach convergence  bau1as . this decomposition is accomplished by not requiring each point in the differential grid to be calculated based on the most up-to-date value of its neighboring points. 
acknowledgments 
       raj reddy has provided much of the vision and energy for this work  most of the central ideas in the hearsay model  and much technical expertise in many of the knowledge sources in the hearsay-ii system. richard fennell and rick hayes-roth have been particularly instrumental in formulating and testing the hearsay-ii architecture. all members of the cmu  speech group  have contributed to this work; their substantial efforts are gratefully acknowledged. oan corkhill  mark fox  doug lenat  jack mostow  
       
specialized 	systens-1; lesser 1 
       
don mccracken  john mcdermott  allen newell  ed riseman  and elliot soloway have made helpful suggestions for this paper. 
appendix - configurations of knowledge sources 
configuration ci 
       the kss of ci  see figure 1  are functionally described here briefly. the name given in parentheses following the name of the ks is the module in which it was embedded. 
       seg  seg  - the seg ks  gol1se  generated  from the digitized acoustic signal  a sequence of contiguous  variable-length segment hypotheses. 
       cseg  psyn  -- this ks  sho1ph  combined segment hypotheses into larger segment hypotheses. the stimulus frame was a sequence of three contiguous segment hypotheses; the action was to generate one or more new segment hypotheses  each of whose times lay within the time span of the three hypotheses in the stimulus frame. the precondition for this ks was triggered highly asynchronously - whenever a new segment hypothesis was created. the ks was then invoked once for every pair of segment hypotheses immediately preceding and following the new one. 
       psyn  psyn  - this ks  sho1ph  created phone hypotheses  based on segment hypotheses. the stimulus frame was also a sequence of three contiguous segment hypotheses; the action was to generate one or more phonetic hypotheses  again with times within the boundaries of the stimulus hypotheses. the comment above about asynchrony of execution of cseg also holds for psyn. 
       pom  pomow  - the pom ks  smi1wo  generated syllable hypotheses from phone hypotheses. the stimulus frame contained phone hypotheses that were classified as syllable nuclei; the action of the ks was to create syllable hypotheses based on the stimulus frame and adjacent segment hypotheses. the precondition for this ks was very complex because it made no assumptions about the order in which phone hypotheses would be created. thus  the creation of a new phone hypothesis of any kind  syllable nucleus or other  triggered the precondition and caused an invocation of the ks for each nucleus hypothesis with which the new phone hypothesis might possibly interact. 
       mow  pomow  -- the mow ks  smi1wo  generated word hypotheses from contiguous syllable hypotheses. the stimulus frame consisted of a newly-created syllable hypothesis; the output word hypotheses covered the same time as the stimulus hypothesis  but could also encompass syllable hypotheses on either side of the stimulus hypothesis  i.e.  for multi-syllabic words.  if the stimulus hypothesis suggested a multi-syllabic word but the hypothesis for the other syllables did not exist  the word would not be hypothesized; however  if at some later time the required syllable hypothesis did appear  the ks would be triggered  by the new syllable  and the word hypothesized. 
       recog  sass  -- this recognition ks  hay1sy  used syntactic knowledge to generate phrase hypotheses from contiguous word or phrase hypotheses. the precondition triggered on a new phrase or word hypothesis  or one with a changed rating . if the triggering hypothesis completed  with existing hypotheses  a phrase and the constituents were rated sufficiently high  the ks was invoked. this was a bottom-up parsing action. 
       predict  sass  - the prediction ks  hay1sy  used syntactic knowledge to generate a new phrase hypothesis  given another phrase hypothesis that was highly rated. this was essentially a  sidewise  or  outward*' action. 
       respell  sass  - this ks  hay1sy   given a predicted phrase hypothesis  i.e.  one with no links to lower level hypotheses  either phrase or word  with a sufficiently high prediction rating  generated hypotheses of the constituents  words and/or phrases  of the predicted hypothesis. thus  respelling drove processing downward  from predicted hypotheses towards the word level  so that predictions could ultimately be matched to acoustic data and verified or rejected. 
       postdict  sass  - given a weakly recognized or predicted phrase or word hypothesis  this ks  hay1$y  looked for other hypotheses that tended to confirm it. such hypotheses were linked to the  postdicted  hypothesis  increasing its rating. 
       wom  womos  -- this ks  cro1wo  was triggered on new word hypotheses that were not linked to syllable hypotheses  i.e.  ones that were generated  from above   by respell or predict . for each such hypothesis  it generated  via a dictionary lookup  expected syllable hypotheses which were likely to describe it. 
       mps  womos  -- the mos ks  cro1wo   given a new syllable hypothesis  generated  via a dictionary lookup  a set of surface-phonemic hypotheses which described the syllable. 
       time  posse  - this ks  cro1wo  responded to the creation of a new phone or surface-phonemic hypothesis and attempted to create a link between the new hypothesis and an existing hypothesis at the other level. 
       search  posse  - this ks  cro1wo  responded to the creation of a new link between a phone hypothesis and a surfacephoneme hypothesis and attempted to create new links adjacent to the triggering one. thus  time and search together incrementally built  through structural connections on the blackboard  a synchronization of a sequence of surface-phonemes representing a syllable with a sequence of lower-level  acoustically-based phones. the search ks was very complex in that it built up competing synchronizations  multiple interpretations ; this was done with localized  incremental actions and while attempting to have the competing interpretations share maximal consistent sub-structures. 
       rpql  rpol  - this policy ks  hay1hy  was responsible for propagating validity ratings. it triggered on the creation of an hypothesis  the establishment of a structural connection between two hypotheses  or the change of rating of an hypothesis. it calculated ratings for an hypothesis based on the values of ksassigned attributes and the ratings of its structurally connected neighboring hypotheses. 
       focus  focus  -this policy ks imposed a global control strategy on the function of ail other kss in the system. it imposed this control through the setting of goal hypotheses which indicated to a ks both that it should attempt to generate particular types of hypotheses and also what internal criterion  thresholds  it should apply in order to generate such hypotheses. 
       the strategy implemented by this ks was based on a progressive enlarging of the search space of hypotheses as existing hypotheses prove fruitless; the idea behind this strategy is that one should open up the combinatorics in the search space only when absolutely necessary. the strategy was implemented by setting up initial goal hypotheses with very high criteria for hypothesis generation and then successively lowering these thresholds when the search stagnated. 
configuration c1  see figure 1  
seg  seg  - functionally similar to seg in ci. 
       pom  pomow  - this ks is similar to pom in ci  but hypothesizes directly from segment hypotheses  rather than phone hypotheses . another difference from pom in ci is that the precondition here assumes that by the time it responds to the creation of a syllable nucleus segment hypothesis  all other segment hypotheses in the vicinity have also been created  thus simplifying the precondition considerably. 
mow  pomow  -- functionally similar to mow in ci. 
       wordctl  woseq  - this policy ks controls the generation of word hypotheses by mow by creating  goal  hypotheses at each time area in the utterance which are interpreted by mow as indicating how many word hypotheses are desirable in that area. 
       woseq  woseq  - this ks  les1se  uses pair-wise syntactic knowledge to create  from contiguous word hypotheses  word-sequence hypotheses. two preconditions can invoke this ks: one precondition responds to the creation of new word hypotheses bottom-up  and typically fires once per utterance  after all such word hypotheses have been created . the other precondition is triggered by previously-created word-sequence hypotheses being marked  rejected . 
       wosctl  woseq  - this policy ks monitors for stagnation in the search process; this condition is recognized if there are no 
       
specialized systens-1: lesser 
1 
       
waiting ks instantiations above a certain priority or if the global measures of current state of the problem solution have not increased in the last n ks executions. if stagnation is recognized  this ks attempts to generate new word-sequence islands from which the search may be more fruitful. this is accomplished by decomposing existing word-sequence islands already on the blackboard or generating new islands which were initially discarded because their rating were too low. 
       parse  sass  ~ this ks  hay1sy  uses the full constraints of the grammar to parse word-sequence hypotheses by searching a graph representation of the grammar. each such parsing action is done internally to the ks; the parse trees themselves do not appear on the blackboard. the stimulus hypothesis is a newly-created word-sequence hypothesis. if the words do not parse  the stimulus hypothesis is marked as  rejected . if the words do parse  i.e.  can occur contiguously in some sentence of the language defined by the grammar   a phrase hypothesis is created. 
       extend  sass  - the extend ks  hay1sy  uses the grammar to predict words that might occur immediately preceding and following a phrase hypothesis. the stimulus hypothesis is a newly-created phrase hypothesis; the action is to a attach a  wordprediction  attribute to the hypothesis which names the predicted words. 
       mew  pomow  - the mew ks is used to verify words which are predicted adjacent to a phrase hypothesis. the precondition triggers on a phrase hypothesis which has a word-prediction attribute added. an attempt is made to verify or reject each predicted word. the ks first checks the blackboard for a 
       previously-hypothesized word that satisfies the time-adjacency criteria  i.e.  immediately precedes/follows the predicting phrase . if none is found  a search is made of pomow's internal store to see if the candidate can be matched by a word previously generated by mow which has not been hypothesized on the blackboard. if one is still not found  the wizard procedure  mck1wo  is called; this compares the segment hypotheses in the predicted area to a network description of possible pronunciations for the word. the result of the call to wizard is either a rejection of the predicted word  or else a verification  including a rating and an estimated endtime  or begin-time  if predicted preceding the phrase .1 in general  several different  versions  of the word may be verified which differ in their end-times  begin-times ; a word hypothesis is created for each such version and a  word-verification  attribute is added to the phrase hypothesis which names all the verified word hypotheses. 
       concat  sass  - the concat ks  hay1sy  responds to a phrase hypothesis which has a word-verification attribute added. the action is  for each verified word  to parse the words of the original phrase augmented by the newly verified word. the extended phrase is then hypothesized. if all predictions to the right or left of the phrase are rejected  the phrase hypothesis is marked as rejected  as is the underlying word-sequence hypothesis.  note that this last action will re-trigger woseq to generate more word sequences.  
       rpol  rpol  - this ks  hay1po  is similar to its counterpart in ci except that ratings of hypotheses above the word level  i.e.  word sequences and phrases  are based on the word hypotheses that ultimately -underly them  rather than on the hypotheses that are directly connected to them from below  which are usually other word sequence or phrase hypotheses . 
       stop  rpol  - this policy ks  mos1ha  triggers on the creation of each phrase hypothesis whose initial and final supporting hypotheses are the unique  begin-  and  end-ofutterance  word hypotheses  respectively. each such phrase hypothesis is a complete sentence and spans the entire utterance and thus is a candidate for selection as the system's recognition result. in general  the control and rating strategies do not guarantee that the first such complete spanning hypothesis found 
1 wizard is  in effect  a miniature version of the harpy speech recognition system  low1ha   except that it has one network for each word  rather than one network with all words and all sentences. the wizard procedure is also used in the mow ks. 
 will have the highest rating of all poss.ble spanning sentence hypotheses that might be found if the search were allowed to continue  so the system should not just stop with the first one generated. however  the characteristics of such an hypothesis are used by stop to prune from further consideration  by marking as  rejected   other partial hypotheses which  because of their low ratings  are unlikely to be extendible into spanning hypotheses with ratings higher than the best already-discovered spanning sentence. if the pruning process is severe enough  there will be no more partial phrase hypotheses left to consider by extend; thus  ks activity will die out. this also triggers stop  which then halts the system and selects the highest-rating complete spanning hypothesis as the  result . if this quiescence does not occur  the stop ks will eventually force a halt after the expenditure of a predefined amount of computing resources  time or space . in this case  it also selects the highest-rated complete spanning hypothesis; if no such hypothesis exists  it selects several of the highest-rated partial phrase hypotheses as the  result .  this set of fragments is interpreted by the semantic interpretation program  fox1ma  which interfaces to the hearsay-ii system.  

at aii levels: rpol 
fiaury 1: the levels and knowledge-sources of configuration c1. 
 as operational in september  1.  
       
specialized systems-1: lesser 1 
       
