 
traditional best-first search for optimal solutions quickly runs out of space even for problem instances of moderate size  and linearspace search has unnecessarily long running times since it cannot make use of available memory. for using available memory effectively  we developed a new generic approach to heuristie search. it integrates various strategies and includes ideas from bidirectional search. due to insights into different utilizations of available memory  it allows the search to use limited memory effectively. instantiations of 
this approach for two different benchmark domains showed excellent results that are statistically significant improvements over previously reported results: for finding optimal solutions in the 1-puzzle we achieved the fastest searches of all those using the manhattan distance heuristic as the only knowledge source  and for a scheduling domain our approach can solve much more difficult problems than the best competitor. the most important lessons we learned from the experiments are first  that also in domains with symmetric graph topology selecting the right search direction can be very important  and second  that memory can- under certain conditions-be used much more effectively than by traditional best-first search. 
1 	introduction 
best-first search in the tradition of a*  hart et a/.  
1  typically requires exponential space. therefore  it quickly runs out of space even for problem instances of moderate size when searching for optimal solutions. 
　in contrast  linear-space search like ida*  korf  1   rbfs  korf  1  and dfbb  lawl er and wood  1  does not suffer from memory limitations. typically  there is even much more memory available than needed by such algorithms. since they cannot make use of such memory  however  their running time is unnecessarily long. 
　one of the major problems of heuristic search is how to use available but limited memory effectively. pure unidirectional approaches to utilizing limited memory still did not lead to convincing results  chakrabarti et al  
1; ghosh et ai  1; reinefeld and marsland  1; russell  1; sen and bagchi  1 . therefore  we propose to consider in addition ideas from bidirectional search  kaindl and khorsand  1; koll and kaindl  1; kwa  1; pohl  1 . 
　in this paper we integrate various unidirectional strategies and include ideas from bidirectional search in a generic approach to heuristic search. due to insights into different utilizations of available memory  our approach allows the search to use limited memory effectively. 
　first  we present our new generic approach to heuristic search that specifically focuses on using limited memory. then we show how this approach can be appropriately instantiated for two very different domains with few and many distinct cost values  respectively. for both domains  we report experimental data that represent significant improvements over previously published results. finally  we compare our approach more generally with related work. 
1 a generic approach to heuristic search using limited memory 
we developed a new generic approach to heuristic search that integrates various approaches and typically leads to hybrid combinations of search algorithms. one of the main ideas to address the memory problem is to combine linear-space search with conventional best-first search in a bidirectional style. fig. 1 gives an overview and indicates how our new algorithms integrate ideas from various approaches in hybrid combinations--this will be discussed in detail below. first  we explain the generic approach generally. its major steps are: 
1. assign the search directions and the available memory to the traditional best-first and the linear-space algorithm  respectively. 
1. perform traditional best-first search using some or even nearly all of the available memory. 
1. unless the best-first search has already found an optimal solution  use a linear-space algorithm in the reverse direction. use the memory structure built up by the previous best-first search  possibly to-
　　gether with additional memory that is still available. note  that the linear-space algorithm per se only requires little memory  but it can utilize additional mem-

ory tnrougn direct  access  e.g.  via nasning. 
　since this approach does not allow for changing the search direction more than once  it can be viewed as a non-traditional form of bidirectional search. in particular  the recently proposed perimeter search  dillenburg and nelson  1  fits into it. however  we explicitly do not propose to use a wave-shaping strategy1  see also  do champeaux  1    since it is inefficient in terms of running time. 
　under certain circumstances to be discussed below  one or more of the steps can also be omitted during instantiation. for instance  if the domain shows a strong asymmetry  the search direction is known before the search begins. moreover  our generic approach can also be instantiated as unidirectional search. 
　since this generic approach has to be instantiated for appropriate use  we must give guidelines for doing so. first of all  it is important to understand how given memory can be utilized during heuristic search. while some of these utilizations appear to be well understood  we could not find a clear categorization in the literature. note that item 1 b  given below appears to have been previously overlooked. we distinguish the following utilizations of given memory: 
1. for ordering the sequence of node generations: traditional best-first search like a* organizes the memory as a priority queue for this purpose  while more recent linear-space rbfs has to backtrack; 
1. for storing state information of generated nodes: for instance  in the well-known 1-puzzle the configuration of tile positions can be stored; 
1. for finding transpositions  in a directed acyclic graph in order to avoid  treeification  during search: 
again  a* is a well-known example  while ida* 
　1 wave-shaping has to compute heuristic estimates between all nodes in one search frontier and all nodes in the other  i.e.  the effort is proportional to the cross product of the numbers of nodes in the frontiers. 
　1transpositions arise when different paths lead to the same node. 

and dfbb normally cannot recognize transpositions without extra memory  which may also be used as in  taylor an d korf  1  ; 
1. for caching information about heuristic estimates: 
three cases can be distinguished here: 
 a  static heuristic value: storing such values avoids recomputation; 
 b  more accurate information closer to a goal: memory-bounded algorithms like mrec  sen and bagchi  1  propagate better heuristic estimates found during their linear-space searches back to the stored part of the search graph; 
 c  heuristic information computed between two search frontiers: 
wave-shaping approaches to bidirectional search utilize memory to store such values computed during the search; 
1. for finding solutions: two cases can be distinguished here: 
 a  finding solutions at all: traditional bidirectional search like bhpa  pohl  1  and ibs*  k1 and kaindl  1  needs the memory to find solutions by recognizing meetings of the search frontiers; 
 b  finding solutions earlier: 
the non-traditional approach to bidirectional search described below uses memory to find solutions earlier than without the memory. 
1. for proving solution quality: bidirectional heuristic search utilizes given memory for storing estimates of the optimal solution cost to be used for proving the quality of a solution found. 
　the combination of search ideas to be chosen during an instantiation of our generic approach should utilize the given memory in several different ways. this typically leads to higher efficiency since their advantages are more or less disjoint and nearly add up  while using the same amount of storage just for one purpose may not give the same pay-oft. fig. 1 shows a useful specialization of our generic approach that uses memory on both sides of the search space: a transposition table  reinefeld and marsland  1  on one side  and the memory of a traditional best-first search on the other. the former is used for finding transpositions and caching more accurate heuristic evaluations closer to the goal. the latter first of all orders the sequence of node generations and helps finding transpositions in another part of the search space  and finally it supports finding solutions earlier. 
　of course  an instantiation should make use of any domain-specific information available. in particular  it should combine those unidirectional search algorithms 
kaindl  etal 
that best suit the properties of the domain  see  e.g.   rao et al  1; zhang and korf  1  . for instance  in some domains ida* is the choice  while in others dfbb is much better. 
1 instantiating for a domain with few distinct cost values: 1-puzzle 
first we show how our generic approach can be instantiated for a domain that is characterized by having only few distinct cost values: the well-known 1-puzzle. under this condition  it is reasonable to select ida* for the linear-space search part. 
　moreover  we can assume to have a monotone evaluation function: the manhattan distance. since a* makes good use of monotone heuristics  dechter and pearl  1   we select it for the part of the best-first search. 
based on the key idea of bidirectional search  we let 
a* and ida* search in opposite directions in steps 1 and 
1 of our generic approach  respectively. fig. 1 illustrates this instantiation that leads to bai  bidirectional a* ida* . 
　according to the idea of using memory in various ways  we may also give the ida* search some part of the available memory as a transposition table. fig. 1 illustrates this approach generally. we call this variant of bai due to the use of this table bai-trans  see also fig. 1 . 
　if a* cannot find a solution using the given memory  then ida* searches in the reverse direction towards the frontier of the prior search. since we consider the case of finding optimal solutions  this search cannot always terminate immediately after a solution is found. a better solution may exist  and the algorithm must find an optimal one and subsequently prove that it is optimal. 
　more technically  the ida* part must be changed slightly. instead of having to find the goal node  a solution is found whenever the depth-first search meets the frontier of the opposing a* search. if the cost of this solution is smaller than the cost of the best solution found so far  or if it is the first solution found  then its value is stored. of course  the cost of the best solution found so far may be sub-optimal  or the algorithm does not yet know that  it is already optimal. however  if the stored value does not exceed the non-overestimating threshold of the ida* part  then its depth-first search is exited successfully with an optimal solution. 
　in addition to these necessary changes  the ida* part has the advantage to start with an increased initial threshold based on an admissible estimate of the optimal solution cost as determined by the a* part. since we assume a monotone heuristic h  the minimum of / = g + h for all nodes in open is always an admissible estimate. therefore  if this estimate is higher than the usual initial threshold of ida*  then it can be used here instead. 
　moreover  it is not necessary to have the ida* part search again in the space already explored by a*. more technically  when the depth-first search invoked by ida* meets a closed node of the opposing a* search frontier  this branch can be cut off  meeting an open node is in general insufficient . we call this nipping according to an analogous method described in  kwa  1 . 
　in an efficient implementation of the 1-puzzle even the effort of hashing at every node causes an overhead that cannot be ignored. therefore  we implemented bai in such a way that it avoids hashing at those nodes where-based on the heuristic estimate-it knows that the frontier of the opposing a* search is yet out of reach. according to step 1 of our generic approach  the search directions must be assigned to the a* and the ida* part  respectively. for traditional bidirectional search  pohl  pohl  1  proposed and used a cardinality criterion for the problem of determining the frontier from which to select a node for expansion: continue searching from the frontier with fewer open nodes. while this is utilized for each node expansion in traditional bidirectional search algorithms  bai has to decide this issue once at the very beginning of the whole search. when the search space is sufficiently symmetric  the initial search direction can be determined at random. when the search space is at least slightly asymmetric and no specific knowledge for determining the search direction is available  it seems reasonable to make shallow probes into the search space from both sides and to use the idea of the cardinality criterion. since bai incorporates ida*  using this algorithm also for probing is consistent with the overall approach. for instance in the 1-puzzle  the first few iterations of ida* are searched from both sides  and the direction with fewer generated nodes is assigned to the ida* part of the overall search  since especially for difficult problems it will have to search much deeper than the a* part. 
　let us shortly discuss the behavior of bai. in the best case  it would seem to be the same as a*. in fact  bai can even be better than pure a*. bai assigns the search direction dynamically  which can lead to better results than systematically going in one direction. in the worst case  bai has to perform the part of a*  without savings 
in the ida* part  except the effect of nipping . 
　a key question is how bai saves effort without having enough memory available for completing the a* search. primarily  it can save one or more of ida*'s iterations. due to the better initial threshold  some of the early iterations can be saved. since the earlier iterations are comparably cheap  this helps much less than saving the last iteration. the search can also be terminated after a complete iteration of ida* if the cost of the best solution already found is not larger than the new increased threshold. therefore  large savings are possible when bai terminates earlier than pure ida*. 
1 	instantiating for a domain with 
many distinct cost values: single 
machine scheduling 
now let us show how our generic approach can be instantiated for a domain that is characterized by having many distinct cost values: a scheduling domain described and used for experiments in  sen and bagchi  1; 
townsend  1 .1 
   1  since this benchmark domain is not widely known  we sketch it shortly. it deals with one-machine job sequence problems of the following form. jobs j  with processing times 

　for problems with many distinct cost values  ida* is known to be much less efficient. but it is reasonable to select dfbb for the linear-space search part  assuming that a good upper bound can be determined quickly- which is the case in this kind of problem. 
　again  a monotone evaluation function is available  so we can analogously to baj select a* for the part of the best-first search. based on the key idea of bidirectional search  we let a* and dfbb search in opposite directions in steps 1 and 1 of our generic approach  respectively. fig. 1 illustrates this instantiation that leads to babb  bidirectional a* depth-first branch-andbound . technically  the computation of the heuristic is different in the backward direction  and the necessary modification is not completely trivial. while in the forward direction all the jobs on the current path are already included  in the backward direction the jobs on the path have not yet been included. the best approach we found is to define a new problem that excludes all these 
jobs  and to compute the heuristic for this problem. 
　due to the above mentioned asymmetry of the arc cost distribution  the better search direction can be determined a priori in this domain.  the reasons are discussed below.  therefore  step 1 of our generic approach can be omitted here. 
　for the same reason  another possibility to instantiate our generic approach here is to omit also the best-first search part completely and to provide all the available memory in the form of a transposition table. analogously to its use in ida*  it both finds transpositions and caches dynamically acquired heuristic information. therefore  we call this algorithm tcbb   transpose-aridcache - depth-first branch-and-bound . still  the bidirectional idea of starting on either side of the space is important here  which is illustrated by the dotted arrow in fig. 1. 
　an obvious advantage of both babb and tcbb over a* is their ability to continue searching although the memory is too small to store all the nodes. a much less obvious advantage of tcbb over a* is that-under certain conditions-tcbb utilizes available memory much more effectively. this will be explained together with empirical results below. 
1 experimental results 
in our experiments  we compared bai  bai-trans  
babb and tcbb with other algorithms on the task of finding optimal solutions in two different domains. from the derivations of our algorithms  it should be intuitively clear that these algorithms are admissible  i.e.  if a solution exists  they terminate with an optimal solution. formal proofs can be found in  kainz  1 . 
a  and penalty constants p   associated with completing a job at time ti  are submitted to a one-machine job-shop. ti is the sum of the times aj of all jobs j on the currently evaluated path. the penalty function is gi t   = pxt1. all the jobs must be sequenced on the machine in such a way that the sum of all penalties is minimized. important properties of this domain are a symmetric graph topology and an asymmetric distribution of arc costs that is due to the quadratic penalty function. 

1 	1-puzzle 
now let us have a look on specific experimental results for finding optimal solutions to a set of  sliding-tile  1puzzle problems.1 we compare our new algorithms bai and bai-trans on these problems with other algorithms that achieve the best results known here yet without using domain-specific knowledge about the puzzle other than the manhattan distance heuristic: ida*  trans  reinefeld and marsland  1  and idps*  perimeter search   dillenburg and nelson  1 . rbfs has the potential to be better than ida* on the sliding-tile puzzle  but actually its results are slightly worse on this specific problem set according to  korf  1  due to noise in the tie-breaking on the last iteration. 
　fig. 1 shows a comparison of these algorithms in terms of the average number of node generations and their running times. the data are normalized to the respective search effort of ida*. trans  using 1k nodes of memory  achieves savings of nearly half of the nodes compared to ida*  and although the effort for hashing slows it down  trans is faster than ida* since it utilizes its memory well.1 idps* saves even 1 percent of the nodes 
　1 we used the complete set of 1 instances from  korf  1 . 
　1in an efficient implementation of the 1-puzzle  even checking of whether a node generated by ida* is in the opposing search frontier means a measurable overhead  although this can be done efficiently via hashing. the reason is that node generation and evaluation can be done very efficiently for the sliding-tile puzzles  korf  1 . even the machine architecture can influence the relative running time up to a certain degree. therefore  we note that our data were gained using a convex c1. on this machine  ida* searches 1k nodes per second. 
　1 the data in the figure were gained using a reimplementation of trans based on efficient code provided by jonathan shaeffer. note the different way of presenting the results: absolute data in our figure vs. relative to problem difficulty in  reinefeld and marsland  1 . we had to reimplement trans  since the detailed data in terms of node generation numbers provided by alexander reinefeld and the data reported in  reinefeld and marsland  1  were insufficient to get comparable data on the running times. actually  trans+move is the best algorithm described in  reinefeld and marsland  1   but its absolute results are less than one percent better than those of trans. therefore  we did 
kaindletal 
generated by ida*  but due to its wave-shaping overhead only 1 percent of the running time.1 
　the results of our new algorithms shown in fig. 1 were generated by giving them also 1k nodes of memory  and determining the search direction via probing through ida* searching its first three iterations  this generates only very few nodes but already indicates the better search direction with a relatively high reliability of 1 percent . baisaves more nodes than trans  and it is also faster. the overhead through hashing is smaller due to our strategy of avoiding it if possible. our combination bai-trans saves three quarters of ida*ys nodes and 1 percent of its running time. this shows that the respective advantages of using memory in these different ways nearly add up  although the available memory for each of its parts is just half of the memory given to each bai and trans  i.e.  bai-trans altogether has 1k nodes of memory available here. although baitrans does not use wave shaping  it generates slightly fewer nodes than idps* with perimeter depth 1. because of avoiding the overhead of wave shaping  baitrans is clearly faster than idps*  although with this perimeter depth this overhead is relatively very small . in order to make sure that these results are not due to chance fluctuations  we performed statistic tests.1 the superiority of bai- trans in terms of running time over pure ida*  pure trans and idps* as shown in the figure is statistically significant. 
　although the search space of the sliding-tile puzzle appears to be quite symmetric  it is interesting to see how much can be gained here just by selecting the search direction dynamically. therefore  we conducted a special experiment with a variant of ida* that just uses our approach for selecting the search direction: ida*-probing. fig. 1 shows that even this simple linear-space algorithm is slightly faster than trans  since it has no overhead in running time. moreover  the advantage of ida*-probing over pure ida* is statistically significant. in order to see how well probing via three iterations already indicates the better search direction  we compared its result with that of a perfect oracle. using it would still generate 1 percent of ida*'s nodes  i.e.  ida*-probing with an overhead in generated nodes for determining the 
not re-implement trans+ move a.nd cannot include it into the figure  lacking data on the running times. 
　1the results reported in  dillenburg and nelson  1  are based on runs using a different sample set of the 1puzzle  and a different perimeter depth. using the same perimeter depth  1   the results on korf's set with our reimplementation are even better in terms of the number of node generations  but very much slower in terms of running time  even slower than ida* . in personal communication with john dillenburg it turned out that their implementation of ida* is slower than korf's one that we are using by a factor of about 1 per generated node. in such an implementation the overhead especially of wave shaping does not show up that clearly as it does in an efficient one. since smaller perimeter depth means fewer stored nodes and therefore less overhead through wave shaping  the perimeter depth 1 results in better running time  and consequently we show these data in our figure. 
　1 more details on the statistic tests used can be found in  kaindl et a/.  1; kaindl and smetana  1 . 

figure 1: comparison on the scheduling problems. 
search direction of only less than 1 percent is overall just 1 percent worse than this. systematically searching in the backward direction  however  is not significantly better due to high standard deviations  although it saves 1 percent over systematically searching in the forward direction. 
　in summary  instantiating our generic approach as described lead to the fastest searches for finding optimal solutions on the 1-puzzle of all those using the manhattan distance heuristic as the only knowledge source. while saving 1 percent of the running time of pure ida* may not seem impressive  the difficulty of significantly improving its results may be appreciated when looking at the many less successful attempts with various algorithms  see the section on related work below . 
1 	single machine scheduling 
the best results yet reported for the scheduling problem that we chose for our experiments are those of a* that searches systematically in the forward direction: finding optimal solutions to random problems of 1 jobs in an average of some few seconds each with less than 1k nodes of memory. as compared in  sen and bagchi  1   these results signified a very strong improvement over previous approaches that did not utilize the graph structure of the search space. 
　fig. 1 shows a* data and the results of dfbb in comparison to the results that we achieved through instantiating our generic approach appropriately. except dfbb and dfbb-reverse  all the algorithms were given the same amount of memory: 1k nodes.1 the data point 
　1 we chose this amount of memory for showing the high efficiency of tcbb in regard to memory utilization. we used the same 1 randomly generated problem instances per  number of jobs  as  sen and bagchi  1   since anup sen made the generator available to us. the figure shows the results in terms of running time  but the numbers of generated nodes are quite the same  since computing the heuristic values dominates the running time. note  that the data are shown on a logarithmic scale. 

annotated in the figure via  a*  indicates the result with the previously best method. the main discovery was that systematically searching in the reverse direction- from the goal to the start-yields much better results: see the data of dfbb-reverse and a*-reverse. these results are very surprising since the graph topology of the search space is symmetric. according to current theory  such a strong effect of reversing the search direction would have been attributed to a strong asymmetry of the graph topology. 
　actually  the reason for this phenomenon is due to the asymmetric distribution of arc costs induced by the quadratic penalty function in these problems. in order to find this reason  we made special experiments  and since this phenomenon also occurs without using heuristic values  it is at least not primarily related to their accuracy. we can explain it as follows: when searching in the forward direction  many nodes must be generated in order to find that a path is bad since the arc costs are initially small; in the backward direction  however  the arc costs are initially large and vary strongly  which allows the identification of bad paths already after relatively few node generations. 
　independently of search direction  a* still runs out of space with increasing problem difficulty  and pure dfbb cannot recognize transpositions and has excessive running times due to the huge number of nodes searched. our algorithm babe is better than a* insofar as it can continue searching when a* already has to quit due to lack of memory on difficult problems with many jobs. however  it does not utilize the given resources optimally. 
　although a* is slightly faster than tcbb due to generating slightly fewer nodes  our new algorithm tcbb utilizes its memory much better than a*  and babb . while a* runs out of 1k nodes of memory  in the forward direction  even for problems with more than 1 jobs  tcbb needs no more memory for problems of 1 jobs. even when it cannot store all of the searched nodes on more difficult problems  it still finds solutions. 
　one reason for the better utilization of memory by tcbb compared to a* in this domain is that it is possible here for tcbb to find a good upper bound quickly that avoids storing all the nodes with a higher estimated cost. in contrast  a* is unaware of an upper bound and stores many nodes with bad values. another reason is that in these problems the branching degree is relatively high  and tcbb can avoid storing many nodes  which reinforces the effect above. in contrast  a* stores all of them due to its strategy of generating and storing all the successors at once at node expansion. 
　due to the strong asymmetry of the arc cost distribution  this unidirectional search algorithm is even much better in the reverse direction: tcbb-reverse-but the bidirectional view was necessary to discover the strong asymmetry in this domain. tcbb-reverse can solve even problems with 1 jobs in an average of about 1 seconds  which shows how well our approach scales up. while a*-reverse is much better than a* in the forward direction  it still runs out of 1k nodes of memory for problems with more than 1 jobs. 
in summary  we achieved very strong overall improvements with our approach in this scheduling domain compared to the best results reported in the literature. in particular  our approach can solve much more difficult problems with the same amount of memory and within reasonable time. 
1 	related work 
originally  bidirectional heuristic search did not work as expected  de champeaux  1; kwa  1; pohl  1 . recent results show that bidirectional search has the potential to improve on unidirectional search  kaindl and khorsand  1; koll and kaindl  1 . unfortunately  traditional bidirectional search requires rather complicated mechanisms that make it difficult to implement. moreover  in domains that can be implemented with fast node generation and computation of the heuristic function like the 1-puzzle  these mechanisms imply a certain overhead. therefore  the generic approach in this paper tries to utilize key ideas of bidirectional search in an efficient manner. 
　a bidirectional algorithm sketched in  korf  1  employs dfid  depth-first iterative-deepening without using heuristic knowledge . since its space requirement is still 1d/1   it cannot solve difficult problems. 
　perimeter search  dillenburg and nelson  1  is a non-traditional approach to bidirectional search that may look very similar to our algorithm ba1. however  the key difference is the use of a form of wave shaping in perimeter search  that makes it inefficient in terms of running time. 
　apart from bidirectional search there are some relations to unidirectional search algorithms with reduced space requirements: mrec  sen and bagchi  1   ma* 
 chakrabarti et al.  1   sma*  russell  1   its  ghosh et a/.  1   and the approach of using certain tables for ida*  reinefeld and marsland  1 . from these  trans and trans- -move  reinefeld and marsland  1  gave the best results on the 1-puzzle in terms of running time that we are aware of. similarly to some of this referenced work  our bai algorithm can be viewed as saving nodes otherwise searched by ida*. our new algorithm tcbb is clearly analogous to trans  but due to including dfbb instead of ida* it is much more efficient in domains with many distinct cost values and the possibility of getting reasonable upper bounds on the solution cost. 
1 	conclusion 
our approach makes use of some known ideas and algorithms. however  this paper contains several new ideas and results: 
  we developed a generic approach to heuristic search that utilizes limited memory effectively. 
  we categorize several different utilizations of given memory for heuristic search and identify a new one in our approach. 
  during experiments with instantiations of our ap-proach in two different domains  we learned that even for nearly symmetric graph topology  selecting the search direction can be important. especially the distribution of arc costs can be crucial. 
kaindl  etal 

  we found that-under certain conditions-available memory can be utilized much more effectively than by a*. 
* in both selected domains-the 1-puzzle and a special scheduling domain-we achieved significantly better results with our approach than those previously reported in the literature. 
　in summary  our new generic approach to heuristic search integrates various strategies and includes ideas from bidirectional search. due to insights into different utilizations of available memory  it allows the search to utilize limited memory effectively. 
acknowledgments 
our implementations are based on the very efficient code of ida* and a* for the puzzle made available by richard korf and an efficient hashing schema by jonathan shaeffer  as well as on code of a* and dfbb for the scheduling domain by anup sen. alexander reinefeld and tony marsland provided the data on the generated nodes for 
trans and trans+move as well as comments on an earlier draft of this paper. finally  we acknowledge the useful comments on an earlier draft by wilhelm barth  wolfgang schmid and anup sen. 
