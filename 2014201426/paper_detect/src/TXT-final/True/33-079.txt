 
   glp is a general linguistic processor for the analysis and generation of natural language. it is part of a speech understanding system currently under development at the computer science depart-
ment of our university . 
1. the structure of glp 
   glp is based on a second generation version of the general syntactic processor gsp of kaplan and kay . its architecture is shown in fig. 1. 
   glp uses two central data structures  chart and agenda. the chart is a directed graph which represents the utterance being analysed  or generated  together with all its component structures for any point of time of the processor's operation. for the sake of simplicity our illustration of the chart's usage is limited to the simpler case of text processing. in this case the chart is initialized by a sequence of vertices which mark the start and the end of the sentence and the boundaries between words. the vertices are connected by edges which are labelled by the words themselves and lexical information  see fig. 1. . during processing glp introduces more and more edges into the chart representing constituents  partial derivations  etc. processing is finished when at least one spanning edge from the first to the last vertex is found which represents a completely specified interpretation of the sentence  see fig. 1 . all edges along one path through the chart belong to the same decomposition of the sentence. besides these inactive edges during processing there are also active ones which represent only a part of a phrase  together with an indication which kind of information would be necessary to complete i t   i.e. to make an inactive edge out of i t . 
   the agenda is a list of tasks to be carried out over the chart. each task is the procedural incarnation of a rule of the grammer  or a part of it. as glp realizes a multiprocessing scheme all tasks can be executed independently of one another as asynchronous parallel processes. 
   the underlying grammar is a procedural one similar to an augmented transition network  atn . its rules contain linguistically defined operators  a-
mong which are operators for the formation of structures  selectors for accessing structures  predicates for testing the applicability of a rule or of parts of it  operators to cause side effects and to affect the flow of control. the formalism used is similar to that of kay's reversible grammar system in which the rules are treated as coroutines. 
   the whole processing is controlled by a monitor which is responsible for the initialization of the system and the generation and management of processes. it is the monitor which creates new tasks  splits complex tasks into potentially parallel executable subtasks  and maintains process and state information. the tasks themselves are executed by 
an interpreter  or processor  whose instruction set is the set of grammatical operators. whenever a task sends an interrupt the monitor has to update the chart with the information sent along with it and to look at inactive edges whether there are suspended processes which would need exactly this information to be resumed. the monitor causes the selection of tasks from the agenda by means of a 
selector in an order determined by strategical reasons which are based on linguistic theory. the parsing strategy is realized by a scheduler which gives priorities to tasks and so fixes their order of execution. thus the strategy may be flexible over the whole parsing process; top-down or bottomup processing are not characteristic for the processing as a whole but only for parts of it. 
   clearly the structure of glp does not limit its ability to perform syntactic analysis; with a suitable linguistic data base  lexicon and grammar  it can be applied from phonological/morphological to semantic processing. the desire to break down the traditional borders between morphological  syntactic and semantic processing was not the least reason to choose this kind of systems architecture. particularly in systems for processing continuous speech  because of uncertain data  progress in one level of analysis can only be achieved by confirmations from different levels so that a common data structure for all levels so that a common data structure for all levels of processing and a unique control structure allowing a flexible strategy become essential 
1. special features of glp 
1    besides an improved set of grammatical operators  glp is able 
- to perform direction-independent island parsing  
- to deal with gaps in the input utterance and to handle quality scores for word and phrase 
hypotheses  and 
- to tie syntactic and semantic analysis closely together. 
¡¡¡¡in order to process input data containing gaps and errors as is the case in speech understanding  glp is able to start its operation at any point within the chart at a word hypothesis with a high quality score and continues by trying to expand this island on both sides by making predictions on words and word categories according to the grammar. predictions are based on the entire context of the island as well as on its internal syntactic structure. if there is more than one island glp tries to find appropriate syntactic hypotheses in order to merge the islands. this is achieved automatically by processing the tasks which seek to complete inactive edges in the chart. to perform these steps efficiently  the grammar has been preprocessed in a simple way to provide information about the word categories of potential predecessors or successors of the already recognized islands. parsing from right to left is performed by a new class of tasks  the socalled scantasks  which look for a grammatically fitting expansion of the island determined by the information about it represented in the chart. to 
be precise  a scan-task tries to identify a starting node for a fitting category left of the island 
which is then verified by the corresponding syntax task. 
   the chart is initialized in such a way that it contains about ten  eventually overlapping  robust word hypotheses. the gaps between them are closed by specially labelled edges. if a gap-edge is found while attempting to expand an island  glp starts processes which try a match with a set of permissible sequences of word categories of the word edges at its left and right end which are accessible through the preprocessed grammar. if the match is successful  a task is generated automatically which requests word hypotheses with the desired features. 
   word hypotheses carry quality scores from which priority scores are derived which in turn influence the scoring of the constituents containing them. the scoring methods we are currently experimenting with are essentially woods'  shortfall and density scoring. in this fashion the scores determine the priorities of the tasks which shall work on these edges which in turn are subject to the parsing strategy obeying a  best-first  discipline. 
   to achieve an overall adaptive behavior leading to an acceptable recognition rate it is necessary to tie syntactic and semantic analysis closely together. similar to the approaches by miller   r. bobrow   l   and woods  in our system we provide the following processing stages: first the utterance is analyzed bottom-up in order to expand islands to local constituents. at this stage  the phase of semantic clustering is started by generating semantics-tasks which use semantic relationships in the form of case-/valence-frames from the lexicon  in which the semantic and pragmatic knowledge resides  mainly associated with the head word of a phrase. these tasks apply semantic interpretation rules from the grammar to generate semantic hypotheses at the phrase level. these are represented by edges to which instantiated case-frames are attached. in a third stage these hypotheses are evaluated syntactically in a top-down fashion which may cause the generation of new syntactic hypotheses by means of corresponding tasks or may give new scores to syntax-tasks which have been suspended in the appropriate portion of the chart. from the strategic point of view this means assigning new priorities to the newly generated or still present but not yet finished tasks. in this way constituents are interpreted as soon as they are parsed  and the structure of the semantic interpretations thus produced is checked when filling the case-/valence frames. this organization permits the semantic and pragmatic knowledge to control the syntactic anal-
ysis tightly  while at the same time syntactic and semantic processing are cleanly separated. 
   glp tries to clarify remaining areas of uncertainty  which can only be resolved by means of contextual inference  e.g. by resolving references  by generating pragmatics-tasks which trigger the inference-processor. for this we chose the frl-system   which offers a unique and - for our purpose sufficient knowledge representation formalism and reasoning framework. 
1. 