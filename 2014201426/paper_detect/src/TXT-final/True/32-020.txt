 
metaquery  also known as metapattem  is a datamining tool useful for learning rules involving more than one relation in the database. a metaquery is a template  or a second-order proposition in a language l  that describes the type of pattern to be discovered. this tool has already been successfully applied to several real-world applications. 
in this paper we advance the state of the art in metaqueries research in several ways. first  we analyze the related computational problem and classify it as np-hard  with a tractable subset that is quite immediately evident. second  we argue that the notion of support for metaqueries  where support is intuitively some indication to the relevance of the rules to be discovered  is not adequately defined in the literature  and propose our own definition. third  we propose some efficient algorithms for computing support and present preliminary experimental results that indicate that our algorithms are indeed quite useful. 
1 	introduction 
with the tremendous growth in information around us  datamining is emerging as a vital research area among the ai and databases communities  fayyad et a/.  1 . metaquerying  shen  1; wei-min shen and zaniolo  1  is a very promising approach for datamining in relational or deductive databases. metaqueries serve as a generic description of the class of patterns to be discovered and help guide the process of data analysis and pattern generation. unlike many other discovery systems  patterns discovered using metaqueries can link information from many tables in databases. these patterns are all relational  while most machine-learning systems can only learn prepositional patterns. 
　metaqueries can be specified by human experts or alternatively  they can be automatically generated from the database schema. either way  they serve as a very important interface between human ''discoverers   and the discovery system. 
1 	machine learning 

figure 1: the relations student-course  coursedepartment  and student-department 
a metaquery r has the form 
 1  
where t and are literal schemas. each literal schema  has the form where all non-predicate variables are implicitly universally quantified. the expression is called a relation pattern. the right-hand-side is called the body of the metaquery  and t is called the head of the metaquery. the predicate variable  can be instantiated only to a predicate symbol of the specified arity  the instantiation must be done in a way which is consistent with the variable names. 
　for example  suppose that you have a database having the relations depicted in figure 1. let p q  and r be variables for predicates  then the metaquery 
		 1  
specifies that the patterns to be discovered are transitivity relations 

where p g  and r are specific predicates. one possible result of this metaquery on the database in figure 1 is the pattern 
  1  
which means intuitively that if a student takes a course from a certain department then he must be a student of that department. 


figure 1: the new relations student-course and studentdepartment 
1 	t h e notion of support and confidence for metaqueries 
suppose that we are given the metaquery  1  again  but instead of the relations shown in figure 1  we have the relations shown in figure 1  the relation coursedepartment is the same as in figure 1 . 
　the rule  1  doesn't hold in all cases anymore. but we can say that it holds in 1% of the cases  or in other words  that it has confidence 1. 
　let us now consider another set of relations from an employee database of an israeli high-tech company having 1 employees. the company is located in beersheva  and all the employees except ana live in beersheva. ana lives in kibutz shoval near by. none of the employees  except guy  where born in the area. guy was born in kibutz shoval and ana is the boss of guy. 
now suppose that we pose the following metaquery: 
 1  
 1  
with confidence 1. so we are going to learn the rule that if an employee was born in some place and a second employee lives in that same place  then the first employee must be the boss of the second. this rule is useless because it is based on a very weak evidence two people out of the 1 who work in this company. rules in which the rule body is satisfied by only a very low fraction of the relations involved should be avoided  or in other words  we would like rules with high support. 
　hence  each answer to a metaquery is a rule accompanied by two numbers: the support and the confidence. the threshold for the support and confidence is provided by the user. intuitively  the support indicates how frequently the body of the rule is satisfied  and the confidence indicates what fraction of the tuples which satisfy 
the body also satisfy the head. similar to the case of association rules  the notions of support and confidence have two purposes: to avoid presenting negligible information to the user and to cut off the search space by early detection of low support and confidence. 
formally  given a rule 
		 1  
let j denote the relation which is the equijoin of and let jt be the relation which is the eqinjoin1 
of j and t. where y and x are some relations  let be the projection of y over the fields which are common to y and x  and let be the number of tuples in x. for each i  i = l...m define to be the fraction . the sup- . port of the rule  1  is the maximum over t = l...m. less formally  the support is the maximum fraction of any relation  in j. the confidence of  1  is the fraction of t that appears in j  or  formally  the confidence of  1  is 
　the support that we have defined has the following useful property: 
claim 1 for any two relations and in the rule  1  that have at least one common attribute variable  
is not bigger the the fraction of that participates in the equijoin between and 
this property enables us to get an upper bound on the support of the rule  1  by performing pairwise equijoins instead of equijoin of all the relations in the body of the rule. 
　shen et al.  wei-min shen and zaniolo  1  are to best of our knowledge the first who have presented a framework that uses metaqueries to integrate inductive learning methods with deductive database technologies. the confidence measure that we use is similar to the one used by shen et al. . however  we do not agree with their definition of support  and hence developed our own. according to shen and leng  shen and leng  1   the support  called  base by shen and leng  should be the fraction . we believe that our definition of support reflects better its intuitive meaning. consider again the students database of figure 1  and suppose that there are 1 tuples in the relation student-course and 1 tuples in the relation course-department. according to shen and leng  the support for the rule  1  will be  the support will shrink even more as the number of courses grow  no matter how many students are in the relation student-course. this low support will render the rule  1  uninteresting  although this rule involves all the tuples in the relation studentcourse. note that according to our definition  the support for this rule is 1  because there is one relation  student-course which participate in the equijoin of the body of the rule in full capacity. 
1 	c o m p l e x i t y 
how hard is answering a metaquery  in this section we will show that the computation task is np-hard. first  let us rephrase the problem as a decision problem. 
definition 1  the mq problem  
instance: a database vb and a metaquery mq of the form l . 
　　1 the equijoins are accomplished by enforcing values of attributes that are bound to the same variable name in the metaquery to be equivalent. 
	ben-euyahu-zohary and gums 	1 

we claim that the answer to the mq problem composed of the above vb and mq will be  yes* iff there is a hamiltonian path  in g. and indeed  if 
there is a hamiltonian path in g  then the rule 

holds with support   1 and confidence   1  and so the answer to the given mq problem will be  yes . on the other hand  if the answer to this mq problem is yes  then  since we require that the support and confidence be positive  and since rv has only one tuple and re is the only binary relation  it must be the case that there is a hamiltonian path in g. ＊ 
it is worthwhile to mention a tractable subset. if the database scheme is fixed in advance  and we do not allow a predicate variable to appear more than once in a query  then the number and maximum size of all possible different metaqueries is a constant. in this case every metaquery has a constant number of instantiations and hence can be answered by a join of a constant number of relations. 
　the reader might wonder whether the complexity analysis done on inductive logic programs  e.g.  dzeroski et al  1   is relevant here. the answer is no. in inductive logic programming the goal is to construct a program that will generate a given goal relation out of other relations and positive and negative examples. here  we are interested in finding to what extent some rule on given relations and goal relation holds. we don't have to find a rule that accurately generates the goal relation  said we do not have negative examples. 
1 	machine learning 
figure 1: algotithm for the instantiation stage 
1 	efficient algorithms for metaqueries 
in this section we discuss the algorithms for generating all rules resulting from a given metaquery. 
　the process of answering a metaquery can be divided into two stages. in the first stage  which we call the instantiation stage  we are looking for sets of relations that match the pattern determined by the metaquery. in the second stage  which we call the filtration stage  we filter out all rules that match the pattern of the metaquery but do not have enough support and confidence. 
1 	t h e instantiation stage 
the process of instantiating a metaquery is similar to solving a constraint satisfaction problem  csp   dechter  1  where we sure basically looking for all solutions of the csp problem. in our experiments we used a very simple csp algorithm  forward checking with back-jumping  dechter  1   but other more advanced algorithms may be used. 
the basic instantiation algorithm is shown in figure 1. 
if this stage suceeds  at the end of this stage each relation pattern r x1 ... xn  that appear in the metaquery is instantiated. that is  r is bound to some relation name r and each variable is bound to an attribute   field   of the relation. we assume that a procedure att r  x  can return the attribute in r to which the variable x is bound. 
1 	t h e filtration stage 
the filtration stage itself is composed of two steps: filtering out rules with low support  and filtering out rules 

with low confidence. we compute confidence only for rules with sufficient support. in our research we have focused so far on algorithms for computing support. we will discuss three alternatives: 
the join approach the straightforward way: computing the equijoin of the body of the rule  then computing as defined in section 1  for each relation in the body  and then taking the maximum. 
the histogram approach using histograms for estimating support. computing the support using the join approach only for rules with high estimated support. 
the histogram + memory approach same as the histogram approach  except that we store intermediate results in memory  and reuse them when we are called to make the same computation. 
　the procedure computes the support of each relation by performing the join as explained in section 1. and then returns 
　　　　. since the join is an expensive operation  we try to detect rules with low support using some lowcost procedures. the other two approaches compute an upper bound on the support and then compute the exact support only for rules with high enough upper bound of support. the idea is summarized in algorithm computesupport in figure 1. note that once one relation with high  is found  we turn to compute the exact support using join. 
　the procedure -upbound called by the algorithm compute-support returns an upper bound for the value for a single relation  in the body of the rule. this can be done by one of the two procedure: -upbound-brave or .-upbound-cautious  shown in figures 1 and 1  respectively. the basic idea is that an upper bound can be achieved by taking the join of a relation ri with any other figure 1: computing si cautiously 
relation with which  has a variables in common. procedure -upbound-brave does this by picking one arbitrary relation with which  has a common variable  and procedure -upbound-cautious does this by considering all relations with which has variables in common  and taking the minimum. procedure -upbound-cautious works harder than procedure -upbound-brave but it achieves a tighter upper bound and hence can save more join computations. 
　the 	procedure upbound called by procedure -upbound-cautious or procedure -upbound-brave founds an upper bound on   as in section 1  for a given relation  using one of two approaches: the histogram approach or the histogram+memory approach. 
　the histograms approach exploits the fact that histograms are easy to construct and are quite useful for support estimation. a histogram of an attribute of some relation is a mapping h between the set of values that this attribute can take and the set of natural numbers  such that for each possible value v  h v  is the number of tuples in the relation in which v appears as the value of the attribute. given two relations and procedure upbound-histo shown in figure 1 achieves an upper bound on the support of the equijoin between them. procedure upbound-histo prepares the histograms and then calls the procedure histo which actually computes the 
ben-eliyahu-zohary and gudes 1 

directly because first it estimates the support  finds out that it is high  and then calls the join procedure. 
　our working assumption is that rules with high support are much less likely. in any case  however  the above analysis calls for an experimental evaluation of the algorithms. in this subsection we present some preliminary results on such experiments. the evaluation was done on the studentgrades database supported by the fleximine system  domshlak et a/.  1 . this database contains information on students and some of their demographic characteristics  courses  and grades. the relevant ta-

support. 
　according to claim 1 of section 1  the number returned by histo is also an upper bound on the support of the rule in which only and appear in the body with a common variable x. 
　the problem with the procedure upbound-histo is that it doesn't exploit the fact that pairs of instantiated relations can appear again and again in many different instantiations of the same metaquery. in the procedure upbound-histo-mem  shown in figure 1  we save in memory estimated support of pairs of relations and retrieve this information if necessary. 
1 	evaluation 
the efficiency of algorithm compute-support depends on the likelihood of finding a rule with high support. if a large fraction of the rules has a high support  then this algorithm will work harder then the straightforward algorithm which computes support by performing join without trying to estimate the result before. note that for rules with high support algorithm compute-support works harder than the algorithm which performs a join 
1 machine 	learning 
bles for our experiment are: the student table with 1 rows  the course table with 1 rows  the family table with 1 rows  the studentcourse table with 1 rows. each table contains between 1 and 1 attributes. 
　we have compared the performance of our algorithms by measuring the time it took them to compute support of 1 different rules involving four relations each. all the rules were instances of the same metaquery. the experiments were done on a sun / sunos workstation with one spare cpu and 1 mb main memory. 
　the time  in seconds  for the support computation were measured for the following configurations: 
1. the support is computed by performing the join  procedure join-support   
1. the support is computed by histogram without using memory  procedure upbound-histo in figure 1 . 
1. the support is computed by our histogram using memory  procedure upbound-histo-mem in figure 
1 -
all the above methods were tested using the procedure 
1 -upbound-brave. procedure -upbound-cautious was not tested yet. 


figure 1: comparison of support computations 
　table 1 shows the results obtained when the support threshold was set to 1. the columns is as follows: num - the serial number of the rule  conf- the confi- dence of the rule. 
sjoin - the support computed by the definition  i.e first performing the join and then computing the support 
shisto - the estimated support computed by our histo method  figure 1 . 
join - the time to compute the support by the join method  accumulated. 
histo - the time to compute the support by the histogram method  accumulated  including time for computing the histograms. 
mem - the time to compute the support by the histogram method with memory  accumulated. 
it can be seen that the histogram method achieves about 
1% savings in time  while the memory method has even improved on that. 
　figure 1 shows the behavior of all three methods with a varying support threshold  1 - 1 . line 1 is the time for the join method  line 1 - for the histogram method  and line 1 for the histogram+memory method. in that figure the time for the join method is normalized to 1  while the other time lines are relative to this time  e.g. the value 1 for the histogram method means that for that value of support  the histogram method time was 1 of the join method . it can be seen that the larger is the support threshold  the better the methods which estimate first perform. this is because the highest the threshold is  the more rules do not pass it and can be cut by using support estimates. 
1 	conclusion 
this paper contributes to the research on metaqueries in several ways. we analyze the complexity of the related computational problem  we propose a new notion of support for a rule generated according to a pattern  and we present novel and efficient algorithms for computing 

support. although more experimental work is needed for real evaluation of the algorithms we have developed  preliminary experimental evaluation is quite promising. 
