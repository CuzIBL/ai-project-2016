 
goal recognition for dialogue systems needs to be fast  make early predictions  and be portable. we present initial work which shows that using statistical  corpus-based methods to build goal recognizers may be a viable way to meet those needs. our goal recognizer is trained on data from apian corpus and then used to determine the agent's most likely goal based on that data. the algorithm is linear in the number of goals  and performs very well in terms of accuracy and early prediction. in addition  it is more easily portable to new domains as does not require a hand-crafted plan library. 
1 	introduction 
much work has been done over the years in plan recognition  which is the task of inferring an agent's goal and plan based on observed actions. goal recognition is a special case of plan recognition  in which only the goal is recognized. 
　goal and plan recognition have been used in a variety of applications including intelligent user interfaces  lesh et al  1   dialogue systems  carberry  1b; allen et a/.  1  and machine translation  alexandersson  1 . 
　we are especially interested in applying goal recognition to dialogue systems  in order to aid natural language understanding and intention recognition. we do not intend to use a goal recognizer to directly recognize communicative intentions  the goals behind a user's utterance ; rather  we intend to use it to identify a user's domain goals to quickly help narrow the search space for more costly intention recognition routines  e.g.   lochbaum  1; chu-carroll and carberry  1  . 
　this application places several demands on our goal recognizer: 
1. speed: dialogues happen in real-time  and the system is expected to understand a user's utterance and generate a response in a short amount of time. 
1. early/partial prediction: we need accurate goal predictions very early on in the exchange  as the system needs this information to better respond to a user's utterance. if full recognition is not immediately available  
user modeling 
the system needs at least partial information to allow it to act on the user's utterance. 
1. portability: we want to be able to rapidly port our dialogue system to new domains. 
　we present initial work in which we use corpus-based methods to build a goal recognizer. our recognizer is fast  linear in the number of possible goals   makes early predictions  and is easier to port to new domains than many systems  as it does not require a hand-crafted domain plan library. 
　we first discuss the corpus-based approach we take in goal recognition. we then report on initial experiments that we have performed and discuss results. finally  we comment on related work and then discuss future directions for our work. 
1 the corpus-based approach 
the use of statistical methods  based on corpora  has revolutionized the field of natural language processing over the past 1+ years. the method is as follows: one uses a corpus of data to train a statistical model which is then used to make predictions on future data. seemingly simple methods have yielded good results in many areas of nlp.1 
　we apply a similar approach to the task of goal recognition. we use a plan corpus  a list of goals and the plans an agent executed to achieve them  to train statistical models which can predict an agent's goal based on an observed sequence of actions. as we show below  initially work shows several possible advantages over previous work on goal and plan recognition: recognition is fast  linear in the number of goals   robust  can handle unknown actions and plans  and does not require a hand-crafted plan library. 
1 	recognition using n-gram models 
we define the task of goal recognition as follows: given an observed sequence of n actions so far  which  for compactness  we will represent as most likely goal g: 


| goal# goal description sessions       ' 1 find a file named 'core' 1 1 find a file that contains the word 'motivating' and whose name ends in '.tex' 1 1 find a machine that has low   1  load; and determine if oren etzioni is logged into the machine named chum 1 1 compress all large files    1 bytes  in the testgrounds subdirectory tree 1 1 compress all files in the directory named 'backups'  don't use *  1 1 find a large file    1 bytes  that hasn't been changed for over a month 1 1 find a file that contains less than 1 words 1 1 find a laser printer in sieg hall that has an active print job 1 1 find a sun on that has low   1  load; and determine if dan weld is active on the machine named chum 1 1 find a file named oldpaper in neal/testgrounds subdirectory 1 1 find a file of length 1 in neal/testgrounds subdirectory 1 1 see if dan weld is logged in to chum 1 total 1 j table 1: goals and their counts in the unix corpus 

since  is constant in the argmax  we can drop it: 
		 1  
using the chain rule  we can rewrite this as: 

 1  
　these conditional distributions are very large and difficult to estimate  therefore  we make an n-gram assumption  i.e.  we assume that an action ai is only dependent on the goal g and the j actions preceding it  for a unigram model  we assume that at is independent of all other actions. in this case  our goal recognition equation becomes: 
		 1  
　if we assume that ai is independent of everything but g and a  i  we get a bigram model: 
 1  
	n	g a 
plan corpus. then  for recognition  we first initialize our goal probabilities with p g . for each action we observe  we multiply each goal's score by the corresponding conditional probability. 
　this algorithm has the nice feature of compositionality - new observations produce conditional probabilities  which are simply multiplied with the previous predictions. this results in computational savings  since updates are linear in the number of goals. it also gives us a good model for early prediction  as desired for our dialogue system   since the model is based on actions observed so far and does not require all actions in the plan execution. 
goal types 1 goal sessions 1 action types 1 total actions 1 average actions/goal 1 table 1: statistics for the unix corpus 
1 experiments 
1 	the plan corpus 
we performed several experiments using lesh's unix plan corpus  lesh  1 . the corpus was gathered from human unix users  cs undergraduates  at the university of washington. users were given a task in unix  a goal   and were instructed to solve it using a subset of unix commands  no pipes  no awk  etc.  the students' commands and results were recorded  as well as whether or not they successfully accomplished the goal. there were 1 successful goal sessions which involved 1 different goals. table 1 shows the individual goals and the number of successful goal sessions for each. 
　we automatically removed unsuccessful commands  such as typos  from each execution. remaining commands were stripped of arguments to a base command type form. this means our training set consisted only of action types  such as i s   grep  etc.   and did not consider flags or arguments. we hope to extend our model to incorporate that additional information in the future  see below . 
　table 1 shows some relevant statistics from the resulting plan corpus. there were 1 possible goals and 1 different action types used in the goal sessions. on average  there were 1 actions per goal session. 
we used cross-validation testing on 1 test cases.1 because 
　　1 thc total number of goal sessions was 1  but sessions involving goals 1  1 and 1 were not used as test data  since these were the only exemplars of their goals  see table 1 . these cases were 

1 	user modeling 

of the small size of the unix corpus  the training set was formed by removing only the test case from the corpus for each test case. 
1 evaluation metrics 
as pointed out by lesh  lesh  1   there is a lack of agreedupon metrics and benchmarks for reporting results for plan and goal recognizers. we use the following metrics to report our results as they measure the attributes we are seeking for a goal recognizer  as described above . a test case is the set of actions executed for a goal. the actions are fed one by one to the recognizer  which makes predictions after every action. each metric is for a single test case. for reporting multiple test cases  the metric is averaged across all cases. 
  accuracy: the number of correct predictions divided by the total number of observed actions. 
  converged: whether or not the final prediction was correct  i.e.  whether the recognizer finish with the correct answer . 
  convergence point: if the recognizer converged  at which point in the input it started giving only the correct answer. this is reported as an action number  i.e.  after observing x actions ; it is also reported as a percentage of the input according to the following equation: 

intuitively  this shows how far through the plan execution the recognizer started  exclusively  predicting the right goal  with 1% meaning after the first action  and 1% after the final action. a low percentage indicates that the recognizer is making accurate early predictions. 
1 	unigram model 
for our first experiment  we trained unigram models on the data  based on equation 1 . to provide for unseen data  where p at g  was 1  p al g  was set to be a very small constant. this smoothing technique allows goal g to still remain possible  in case other evidence makes it likely  despite the fact that action al was not seen in relation to it in the training data. 
　with the unigram model  our recognizer achieved an accuracy of 1%  with 1% of the cases converging. for cases which converged  the average point of convergence was 1% through the input  or after observing an average of 1 actions. 
　because a unigram model assumes independence of all actions  it is equivalent to treating actions as an unordered list.1 this assumption is partly to blame for the relatively low accuracy and convergence  since action ordering is important in the domain. we attempt to rectify this by using a bigram model below. 
　it is interesting to note the low point of convergence. this shows that  for the tests which did converge  they converged fairly quickly  i.e.  the recognizer was able to tell fairly quickly what the goal was. this quick convergence seems 
still used in training for other test cases  however  and were still candidate goals for recognition. 
1 this is a list and not a set since actions can be repeated. 
user modeling 
partly due to the fact that some goals  such as goal 1  for example  were highly correlated with a single command  such as l p q in this case   which immediately boosted the probability of the correct goal. 
1 	bigram model 
in our next experiment  we used a bigram model  based on equation 1   which encodes at least some ordering into the actions by considering both the current action and the preceding action. 
　we prepend a special s t a r t action to the front of each execution  which handles the special case of equation 1 in which n = 1  i.e.  when we've only seen one action so far. this also encodes information about which actions tend to begin executions  which may or may not be correlated to the goal. 
　for the case where  equals 1  i.e.  the bigram was never seen in conjunction with the goal  we use a unigram back-off model which uses the estimation 
	as with the unigram model 
above  if p ai g  equals 1  we smooth this with a small constant. 
　as expected  the bigram model performed much better than the unigram model  with an accuracy of 1% and with 1% of cases converging. for the tests cases which converged  they converged on average 1% through the input  or after 1 actions. 
　while accuracy and convergence were markedly better than the unigram model  the convergence point only improved slightly in the bigram model. however  this was already quite good  and may simply mean that we are approaching a limit on how soon the prediction can be made in this particular domain. 
　as for convergence  it is illustrative to look at a goal-bygoal breakdown of results. table 1 shows convergence results for each goal type. for the 1 cases which didn't converge  1 arc goal 1  which is often misclassified as either goal 1 or goal 1. this seems mostly to be due to the fact that these three goals are very similar. goal 1 is to find a file named 'core  goal 1 is to find a large file that hasn't been changed for over a month  and goal 1 is to find a file of length 1. all of these have to do with finding a file with a certain set of attributes  and in fact  the command is can be used to learn all of these attributes about a file. goal sessions for all three of these goals mostly consisted of the commands cd and is. 
1 	goal abstractions 
in our final experiment  we defined an abstraction hierarchy for goal types. the abstract types and goals they encompass are shown in table 1. 
　as we discussed above  a dialogue system needs to be able to reason quickly  accurately and early about a user's goals and intentions. if the user's specific goal cannot be determined  a dialogue system can often use partial information in formulating a response to the user. these abstract goal classes represent that partial information. if we are unable to determine a specific goal  the system can perhaps determine what the user's abstract goal is  and this may be enough to formulate a response. 

goal# convergence competitors   	1 1 1%  1 1 1 1%  none 1 1  1%  1 1 1 1%  none 1 1  1%  1 1 1  1%  1 1 1 1  1%  none 1 1  1%  none 1 1  1%  1 table 1: convergence by goal in the bigram experiment 
abstract goal goals which 
instantiate find a file with attributes 1 1  1  1 find a machine with attributes 1 1 compress files with attributes 1 find a printer with attributes 1 table 1: abstract goal types 
　the probability of an abstract goal is calculated by simply summing the probabilities of each of its children. for this experiment  we use the same bigram model as before and perform an additional summing at each step to calculate the most likely abstract goal. 
　the recognizer predicted abstract goals very well  with 1% accuracy and 1% of the cases converging. the average convergence point was 1% through the input  or after 1 actions. table 1 summarizes the results of all three experiments. 
　it is important to note that abstract goal recognition does not occur in competition to  but rather in conjunction with the specific goal recognition. of course  it is best to recognize the specific goal  which our bigram model seemed to do fairly well  but we can also recognize the abstract goal more quickly and more accurately. and  there may be many cases where it will be sufficient for the dialogue system to have just the abstract goal in order to help the user. 
1 	discussion 
these initial results are encouraging  but there still remain significant challenges for scaling up the system to sufficiently complex domains. in this section  we discuss our goal recognizer in light of the desiderata for dialogue systems we men-
unigram bigram abstract goals accuracy 1% 1% 1% converged 1% 1% 1% conv. point 1% 1% 1% conv. action# 1 1 1 table 1: results of the experiments on the unix corpus tioned above. we then discuss several challenges that remain. 
1 	desiderata 
speed because it involves a simple probability lookup  our recognizer is linear in the number of goals  and training it is linear in the amount of training data . speed is a big advantage to this approach. by comparison  logic-based reasoning recognizers like  kautz  1  are exponential in the size of the plan library.1 several systems  vilain  1; lesh  1  improve on this time complexity  but at the expense of expressiveness. 
early/partial prediction our recognizer was able to make correct predictions 1%  1 actions  through the input with 1% overall accuracy  and give correct abstract results 1%  1 actions  through the input with 1% overall accuracy. this early prediction is crucial to our domain of dialogue systems. 
　most work does not report how early the recognizer makes correct predictions. lesh  lesh  1  simulates a taskcompletion agent  which  upon recognizing the user's goal  steps in to complete the task. he reports1 a convergence point of 1%  after 1 actions for an average plan length of 1 actions  for the task of searching for a printer with attributes  1 predicates  and a convergence point of 1%  after 1 actions for an average plan length of 1 actions  for a restricted cooking domain  both with 1% accuracy because lesh uses a 'strict consistency' approach. for most domains  however   like the full unix corpus   it is unclear if it could make such early predictions. because it is based on 'strict consistency'  a goal hypothesis must become logically impossible before it can be ruled out. in fact  even in for the domains he reports statistics in  the recognizer rarely recognizes the user's actual goal exclusively  rather  based on the set of possible goals  it tries to recognize a sufficient goal that covers all possible goals. as lesh points out  many domains do not lend themselves to the prediction of sufficient goals. 
portability the portability of our goal recognizer depends on the existence of a plan corpus. if a plan corpus exists or can be created for the new domain  see section below   all we have to do is use it to train models for the new domain.1 on the other hand  most goal recognizers  e.g.   vilain  1; carberry  1a; kautz  1; charniak and goldman  1; 
paek and horvitz  1    require a complete  hand-crafted plan library in order to perform recognition  which can require a significant amount of knowledge engineering for each domain. 
   1 granted  these systems are performing plan recognition and not just goal recognition  which makes the comparison unfair. however  very little work has been done on goal recognition in its own right  so plan recognizers are all we have to compare against. 
1 	user modeling    1  lesh reports the average length of plan with and without the task-completion agent  which we used to calculate these convergence points. 1 models could also be trained for different individuals within a single domain by using a user-  or group-  specific corpus. with other approaches  user-specific models have greatly improved recognition  e.g.   lesh  1  . 
　hong's recognizer  hong  1  only requires knowledge of plan operators  not the library  but it is unable to make early predictions  as it usually does not make end-goal predictions until after it has seen the entire executed plan. lesh  lesh  1  requires only knowledge of plan operators and domain goal predicates. 
1 	challenges 
domain size with only 1 goals and 1 action types  the 
unix domain is quite small  and it is unclear whether our recognizer would scale to larger domains. one immediate fault of our recognizer is that it does not handle parameterized goals. each of the 1 goals above is treated as an atomic unit  and not as a goal schema instantiated with parameters. one straightforward way to handle parameters would be to treat a goal schema as an abstract goal  with each possible set of parameter instantiations as a separate  more specific goal. however  this would explode the number of goals and  in the case of 1 or more parameters  lead to a multiple-inheritance abstraction hierarchy  which is not supported by our current abstract goal score calculation model. 
hierarchical plans another shortcoming of the current recognizer is that  although it handles goal abstraction  it does not handle hierarchical plans. complex plans covering longer time-scales are less likely to be identifiable from a few observations alone  which tend to reflect more immediate subgoals . ideally  we would want to recognize subgoals for partial results  even if we still cannot recognize the high-level goal. 
data collection in some domains  like operating systems   it may be possible to collect enough data from users to train a recognizer. in most domains  however  it will be infeasible to collect enough data on users solving goals in order to build effective statistical models. furthermore  even it this data could be collected  the inner structure of the user's hierarchical plan would not be explicit from the data  i.e.  we can only observe the primitive actions  not the subgoal structure that motivates the actions . 
　as the next step in our research  we plan to explore the use of ai planners to generate artificial plan corpora to be used for training. the approach we plan to take combines planning and monte-carlo simulation to generate plan corpora. the idea is to generate plans stochastically  allowing distributions over different aspects of the planning process  such as the goals  situations and action decompositions . by combining  context-free  monte-carlo simulation techniques with richly context-dependent planning algorithms  we hope to obtain a corpus that captures likely user behavior. in addition  this generated corpus has the big advantage that the subgoal hierarchy that generates the observed actions is also known. 
1 	related work 
as mentioned above   vilain  1; lesh  1  improve speed over  kautz  1   but do so at the expense of expressiveness. also  these goal recognizers are typically not able to make early predictions  as they are unable to distinguish 
user modeling 
between consistent goals  even if one is more likely than the other. 
　there are several lines of research which incorporate probabilistic reasoning into plan and goal recognition.  carberry  
1a  and  bauer  1  use dempster-shafer theory and 
 charniak and goldman  1    pynadath and wellman  1   and  paek and horvitz  1  use belief networks to represent the likelihood of possible plans and goals to be attributed to the user. all of these methods  however  require a complete plan library as well as the assignment of probability distributions over the library. 
　 appelt and pollack  1  and  goldman et ai  1  cast plan recognition as weighted abduction. however  this also requires a plan library and the acquisition of weights for abductive rules. abduction is also computationally hard  and it is unclear whether such routines would be fast enough for complex domains. 
　probably the closest work to ours is  albrecht et ai  1   which uses a dynamic belief network  dbn  to do goal  quest  recognition in a multi-user dungeon  mud  domain. the belief network takes into account actions  locations  and previous quest in recognizing the player's current quest. similar to our own work  their model uses bigram independence assumptions for both actions and locations. conditional probability distributions for the network are estimated from a corpus of mud sessions. 
　although our approaches are similar in terms of the use of corpora for training  there appear to be a few significant differences. albrecht et ai encode state into their model  in the form of location and previous quest   whereas our current system considers only actions. perhaps more significantly  they note that the bigram independence assumption is an inherent part of dbns  since relaxing it  say  by using trigram or 1-gram models  would cause a state-space explosion for the dbn  albrecht et ai  1  1 . relaxing the bigram assumption in our approach should have negligible effect on system speed  as probability updates are done by simple lookup  regardless of the size of the n-gram. to help alleviate space issues  we can store only the higher-order n-grams that we have good estimates for and use a backoff model similar to that used in our bigram model. we believe that higher-order n-grams will have significant predictive power  and plan to test their use in future research. 
1 	conclusions and future work 
we have presented our initial work on using statistical corpusbased techniques for goal recognition. our recognizer is fast  linear time   does early and partial prediction  and can be ported to new domains more easily than many recognizers. we showed several initial experiments using the goal recognizer  in which we achieved high recognition rates with high accuracy early prediction. 
　there are several areas of fiiture work that we are interested in. several were alluded to above: scaling to larger domains  incorporating hierarchical plans  and using ai planners to generate artificial plan corpora. 
　in addition  we plan to collect a larger human-generated corpus in the unix domain. with more training data  we would like to explore using trigram and 1-gram models as well as more advanced data mining techniques to train the statistical model. 
　finally  as mentioned above  we would like to see how performance can be improved by training on a user-specific corpus. similarly  we would like to see how different planners  say a reactive versus a deliberative planner  predict user behavior. perhaps different planners could be used to model different domains  say domains with time pressure   or even different personality types. 
acknowledgments 
we would like to thank neal lesh and jun hong for sharing their data with us. we would also like to thank the anonymous reviewers for their helpful comments. 
　this material is based upon work supported by department of education grant no. p1; onr research grant no. n1-1; and national science foundation grant no. e1a-1. any opinions  findings  and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the above-mentioned organizations. 
