 
emotions involve complex processes produced by interactions between motives/ beliefs/ percepts  etc. e.g. real or imagined fulfilment or violation of a motive/ or triggering of a 'motive-generator'/ can disturb processes produced by other motives. to understand emotions/ therefore/ we need to understand motives and the types of processes they can produce. this leads to a study of the global architecture of a mind. some constraints on the evolution of minds are disussed. types of motives and the processes they generate are sketched. 
introduction 
we all know a lot about the differences and similarities between states like anger/ embarrassment/ elation/ dismay  etc./ but it is not easy to articulate this knowledge. the task of making such knowledge explicit could be called  following heider  naive psychology. this paper makes some steps towards naive psychology  and partly goes beyond i t / showing that: 
　the need to cope with a changing and partly unpredictable world makes it very likely that any intelligent system with multiple motives and limited powers will have emotions. so the belief that emotions and intellect are somehow quite separate is mistaken. 
　　to constrain our search for a model of mental processes we recommend a multidisciplinary approach combining  a  conceptual analysis  used by philosophers to articulate common implicit knowledge  see c1 ch 1      b  analysis of constraints within which organisms have to operate/ and which determine what would make them well adapted/  c  a survey of a b i l ities of different animals and  d  the design of possible systems. this should yield a grammar of possible types of minds  natural and a r t i f i c i a l . we need to explore types of environmental constraints/ types of needs or motives organisms or robots may have  types of information-processing mechanisms and strategies relevant to achieving these motives within different sorts of constraints. 
   there is a huge array of possible cases  from systems with verysimple feedback loops to those containing all the complexity sketched below. 
arguing about where to draw the line between cases of real intelligence or mentality and the rest is quite pointless  like arguing over whether it is s t i l l 'really' chess if one player accepts the han-
dicap of playing without a queen.  in the end/ some of the decisions are ethical.  
constraints on intelligent systems 
here are some  constraints  on the design of i n t e l ligent systems. some involve physical needs  some 
mental needs  the need for powerful inference strategies  etc / some the needs of a social system  and some the needs of the comparatively helpless 
young  
 * goals  obstacles/ opportunities/ friends and foes do not come with simple physical patterns to identify them. recognition w i l l often require the use of structural descriptions. motives w i l l need to incorporate structural descriptions of states to be achieved/ preserved/ avoided/ etc. 
 * the collection of motives will not be static. the physical needs of an organism can vary. old motives can generate new ones as subgoals for achieving some task. mechanisms for changing the current set of motives and their priorities are required. the revision of goals makes it necessary for the system to be able to interrupt and re-
direct processing. 
 * the environment is not static: opportunities and 
dangers  may all vary from time to time. changes will need to be perceived or predicted. predictions will not always be reliable. this implies a need for constant monitoring/ and ability to notice and deal with the unexpected. 
 * speed of computation may often be important. events may happen quickly. the organism may have to decide and move quickly. often there is no time for normal processes of inference/ and deliberation. 
 * some opportunities exist only during a relatively short time interval/ often long before they are needed. the ability to store things is therefore important. some subgoals may have to be achieved long in advance of the main goal. there may be intense/ though less important/ motives which conflict with a long term goal. it is necessary to be able to interleave pursuit of different intentions. this implies an a b i l i t y to notice conditions for continuation. 
 * the complexity of the environment will often lead to mistaken beliefs/ plans  and actions. later 
1 

the mistaken belief may be corrected. it is then necessary to modify plans or actions  accordingly. this requires storage of reasons for motives and decisions  so that when the new information turns up  chains of relevance can be identified. 
 * if the organism or machine has a complex body  it w i l l need to have many monitors capable of detecting shortages  disturbances  etc.  and either causing automatic corrective action or causing a new motive to be created  possibly with a high p r i o r i t y . 
 * making f u l l use of different parts of the body requires f a c i l i t i e s for different processes to exist in parallel. this considerably complicates the problems of interrupting and re-directing thoughts and actions. 
 * different motives in the same individual may 	be inconsistent. mechanisms and strategies for dealing with inconsistencies will be needed. 
 * where the actions or attitudes of other agents matter it w i l l be necessary to have the a b i l i t y to represent the mental states of others. this plays an important role in many human emotions  such as embarrassment. 
 * individuals may perish  and new ones be produced. transmission of information to offspring requires mechanisms and strategies for such communication and motives which ensure that they are used. the task of communicating skills and knowledge to the young may be a considerable burden to the older individuals  and conflict with many of their motives. 
 * in co-operative communities  individuals 	should 
develop motives which do not necessarily maximise their own advantage  but which enable the community as a whole to function well. this can  of course  lead to conflicting motives within and between 
individuals. 
the need to learn mc ives  including tastes  aesthetic and ethical principles  standards of behaviour  etc.  could apply to machines capable of functioning  in collaboration with human beings  in a wide variety of cultures. 
 * the young w i l l need motives concerned with exploring  practising  noting information  and stimulating older individuals to communicate with them. 
 * choosing between alternatives will not be simple. the notion of an optimal choice w i l l not necessarily even be well-defined. achieving a long term balance between different needs of the i n d i v i dual or the community can be a major problem. decision-making processes will have to be capable of coping with such conflicts. 
　　such constraints define a set of questions to be asked about organisms  and a set of possible tasks for the robot designer. 
　　if individuals contain such complex collections of motives and a b i l i t i e s   with delicately balanced conflicts between motives  they are likely to be very unstable  with relatively small external changes producing new motives decisions and actions  which in turn can lead to further internal changes. thus i n i t i a l l y similar individuals can 
develop in very different ways. 
the computational architecture of a mind 
chapters 1 to 1 of c1 sketched some of the computational architecture of the human mind. it turned out useful to distinguish at least the following: 
 * a store of 'springs of action'  motives . 
 * a store of resources  including facts  procedures  e t c .   . 
 * indexes to resources. 
 * a collection of concurrent on-going goaldirected processes. 
 * many stores of temporary information  local to the various processes. 
 * indexes to current processes and their generating purposes. 
 * many kinds of monitoring processes  perceiving external and internal objects end events  and able to cause interruptions. 
 * a 'central' administrative process concerned with deciding: forming intentions  making or selecting plans and resolving major conflicts in the light of motives  tastes  principles  e t c .   . since not all decisions can be taken independently  and sub-processes w i l l sometimes generate incompatible goals  it w i l l be necessary for conflicts to be resolved at a high level in the light of major goals  policies  etc. 
   these ideas need to be refined. the rest of this paper f i l l s in some details. 
processing motives 
motives include representations of states of affairs or events to be achieved  preserved  prevented  etc. there are very many different sorts of motives  and the next section will enlarge on t h i s . similarly  there are many sorts of internal processes involving motives  such as: 
 * adding motives to and 	removing 	them 	from 	the store. 
 * selecting motives to act on  forming intentions :- not a l l motives can be acted on. those which are selected w i l l be described as operative. those which are rejected  are inoperative. some may be left for further consideration later  i.e. suspended. the word 'intention' covers operative motives. desires may be operative or inoperative. even strong desires can be over-ridden by other motives. motives may be suspended because there is not yet enough information  or because measures of importance  or rules for comparing  f a i l to yield a clear cut decision. 
 * drawing attention to suspended or inoperative motives:- suspended and inoperative motives may have to be reconsidered. some may be assigned a monitoring process which decides when to interrupt the administrator. others may constantly request attention. the power to request attention we call 

1 

t h e  intensity of a motive. 
 * changing the intensity of motives:- intensity of a motive is a measure of how hard it attempts to get itself selected. we contrast intensity with importance. intensity is the power to be considered for selection  whereas importance* or strength  is the power to be selected for action  and to override alternative motives. sometimes the importance as well as intensity will change  in which case an inoperative motive may be reconsidered and selected for action. 
 * abandoning an intention:- an operative motive may revert to an inoperative state. goals which have been achieved can be removed from the store. 
 * deciding when to act on operative motives:motives will need to be temporally ordered  or even interleaved. operative motives not currently being acted on we call dormant  the others active. some dormant motives are very general  and when the relevant circumstances turn up produce more specific intentions. hence a motive may be a motive generator.  most of the time you are not in the process of trying to do anything to help people in distress  yet if you observe someone have an accident  a dormant but operative general motive may generate a new specific active and operative intention to help.  sometimes a motive will be ren-
dered dormant because some other motive has been assigned higher priority. dormant motives may require some kind of monitoring process. 
 * waking up dormant motives. 
 * making or choosing plans:- sometimes alternative plans will be available  and relevant motives may have to be invoked for choosing between them. so some motives need to take the form of preferences.  the planning process can be made more efficient by letting pre-compiled preferences control the pro-
cess of 	construction 	so 	that 	instead 	of 	being rejected 	after 	construction 	bad alternatives are 
not even constructed.  
 * executing plans:- this may involve adding new subgoals to the store  removing subgoals when they have been achieved  monitoring progress  etc. in some cases the plan can be executed by a lowerlevel process  which allows the central administrator to carry on with more d i f f i c u l t tasks. this includes both automatic processes like breathing and processes for which fully debugged and reliable strategies ere available  like walking. 
 * retrospective analysis:- failures sometimes pro-vide information from which the organism can learn. so can unexpected successes. even actions which go as expected can provide new information revealing redundancy  missed opportunities  risks  etc. 
 * inductive learning:- if doipg something is consistently followed by satisfaction of existing motives  then it might be useful to develop a new motive to do that thing whenever possible  or increase the intensity or strength of an existing motive  or motive-generator . similarly  if a type of action or situation is frequently followed by the frustration of other motives. this sort of mechanism would explain some results of behaviourist research. 
 * interruptions:- inoperative or suspended motives can interrupt the process which selects motives for action  if something makes their intensity high enough. a new motive becoming operative  or detection of conditions relevant to operative but dormant motives can interrupt the processes of planning or execution  as can detection of new c i r cumstances relevant to the current action. some interrupts may be capable of being handled by a lower-level specialist subsystem  e.g. reflexes. other interrupts require global re-organisation. 
some interrupts may involve matters of such urgency and importance that the new motive bypasses normal selection and planning processes and directly causes a strategy to be invoked. 
 * suppressing interruptions:- when something which is very important and requires f u l l attention is in 
progress  then it may be necessary to prevent interruptions. this could be handled by priority mechanisms. for instance  people who art injured in battle sometimes don't notice the injury t i l l long afterwards. the inability of relatively intense desires  pains  etc. to get any attention at a l l during the performance of some actions  might seem to imply that not all the processes run in parallel on independent processors. alternatively  it may be the case that what we are conscious of is restricted to information accessed by some one process  all of whose resources are reserved for certain tasks. 
　　we now have a framework to account for different sorts of motives. we see a need for many parallel processes  monitoring internal and external events for significant occurrences. these may trigger  or re-awaken  processes  which may involve interrupting others. 
types of motives 
motives are representations used in deciding what to do  i.e. desires  wishes  tastes  preferences  ideals  and so on. this includes 'motive generat o r s '   and 'motive comparators'. what makes a representation function as a motive is not where it is stored or what its structure i s   but its role in processing. there art many different sorts of motives: 
 * motives may have any of the logical complexity of factual statements. including negation  disjunction  conditionals  universal quantification  
and so on. 
 * some motives constitute desires or preferences  unlike mere sub-goals of other motives. not a l l goals are valued i n t r i n s i c a l l y . sometimes  in people  a mere subgoal comes to be valued as an end  perhaps because 'reason' information gets lost somehow  
 * first-order motives directly specify goals  while second-order motives are concerned with generating new motives or deciding relative priorities of conflicting motives: motive generators and motive comparators. a motive produced by a motive generator may have the status of a desire. 
1 
 * motives may vary in intensity. intensity can be thought of as an interrupt priority level. the process interrupted is the administrative process concerned with choosing motives to act on. this may also cause other processes to be disturbed. 
 * some motives may be genetically programmed  such as a motive generator which produces desires to find things out: a 'curiosity i n s t i n c t ' . others are generated by cognitive processes  such as the interaction of existing motive-generators with new perceptions. others are generated by bodily processes. 
 * some motives  e.g. some pains  do not contain specific goals to be achieved  yet indicate a need for something to be done  leaving it to other processes to determine what the problem i s . the motive may include information about the location 
or
	 	seriousness  even if the precise nature or cure 
is left unspecified. 
 * some motives are concerned with preserving a state or process. these may involve physical sensations  physical or mental activities  e.g. sex  eating or drinking  developing some s k i l l   .  pleasure' and 'enjoyment' characterise this sort of thing. 
 * pleasure and displeasure may be associated with success and failure of actions. the desire for the situation to be different from what it i s   is at least part of what is involved in finding the 
failure unpleasant. the desire to dwell on a success is part of gaining pleasure from success. 
 * motivation to persevere in the face of failure is often important since repeated actions don't always produce the same result. however  sometimes f l e x i b i l i t y 1s preferable. 
 * inability to decide between alternatives can lead to disasters. it may be important to be able to detect when deciding is taking too long and generate a motive to speed up the decision-making process. 
 * some kind of priority system w i l l be needed. different motives w i l l have different degrees of urgency associated with them  concerned with how much time is l e f t . this is not the same as intens i t y : something not wanted very much may be urgent. in addition there may be a measure of importance of the motive. this 1s different from both urgency and intensity: e.g. important but unattractive duties. importance may be linked to effects of not achieving the motive. 
 * besides measures  there may be a collection of heuristics for choosing when conflicts arise: motive-comparators 
　　it 1s d i f f i c u l t to specify what the task of a decision-maker 1s  when so many complex motives interact without any well defined concept of what constitutes the best decision. some cases may be dealt with by very general strategies  e.g. choosing at random  or choosing the urgent one. even where importance 1s represented by a measure  this may be very coarsely quantised  leaving a need for additional choice heuristics. there may be several incommensurable measures. the notion of an optimal decision  and therefore of an optimal decisionmaking system is probably not well-defined. an entirely rational decision making process is therefore not to be expected. 
　　many people deny that machines could ever be said to have their own motives. machines hitherto familiar to us either are not goal-directed at a l l  clocks  etc.  or else  like current game-playing computer programs  have a simple hierarchical set of goals  with the highest-level goal put there by a programmer. if machines were designed with a system of motives and motive generators as complex as that described above  then the machine could develop and change over time in such a way that it would be misleading to say that the machine was pursuing the goals of its designer. ultimately the decision whether to say such machines have motives is a moral decision  concerned with how we ought to 
treat them. 
anger 
consider a familiar emotion  anger. typically if some individual x is angry  there is another individual y with whom x is angry  and something x believes y to have done or failed to do. y is believed to be responsible for violating one of x's motives  and x wants to hurt or harm y: a new motive in x directed against y. this motive need not be selected for action: it may remain intense yet inoperative  e.g. for fear of consequences. the existence of the desire is s t i l l not sufficient for x's state to be one of anger. he may have the desire  but put it out of mind  and calmly get on with something else  and in that case he would not be angry. anger involves an intense desire to do something to y  that i s   the desire should frequently 'request attention' from x's decisionmaking processes. so unless acted on  the desire w i l l frequently come back into x's thoughts  making it hard for him to concentrate on other a c t i v i t i e s .  unconscious anger is possible too.  
　　it is possible  in human beings  for the anger to produce physical disturbances. however  if x satisfied enough cognitive conditions he could rightly describe himself as being very angry  despite not having the physical symptoms. the anger could be strong  insofar as it constantly intruded into his thoughts and decisions  and insofar as he strongly desired to make y suffer  and suffer a great deal. 
　　strength of an emotion can vary along different dimensions: anger can vary according to how much x minds what he thinks y has done  which w i l l depend on how important the violated motive was. it can vary according to how much harm x wants to do to y. it can vary also with how important the wish to harm y i s : the desire may or may not be hard to override. finally  the strength of the anger can vary according to how much general disturbance it produces  or tends to produce 1n x. emotion need 

1 

not actually interfere with other motives: for instance if the new motive to punish y is acted on  there need be no disturbance. but the anger has the potential to disturb other activities if they are attempted. 
　　when there is no desire to cause harm to y  the emotion is more like exasperation than anger. if there is no attribution of responsibility  then the emotion is some form of annoyance  and if the motive that is violated is very important  and cannot readily be satisfied by some alternative  then the emotion is dismay. 
towards a grammar of emotions 
we can now generalise towards a l i s t of components of a grammar of emotional states. 
 * an emotional state normally involves having at least one f a i r l y strong motive. real or imagined or expected satisfaction or violation of this motive produces the emotion. this generates several sorts of cases  depending on whether the motive is concerned with something strongly desired  or something strongly disliked  whether the desire is thought to be satisfied or violated  or whether there is uncertainty about which is the case. 
 * the combination of motive and belief  or uncertainty  must be capable of producing a disturbance  i.e. continually interrupting thinking and deciding  and influencing one's decision-making criteria and perceptions. 
 * the disturbance may or may not involve specific new motives  for instance a desire to right what has gone wrong  or a desire to inform other people. where there is no new motive: there may simply be a constant dwelling on what has happened. 
 * the new motives need not be selected for action. some emotional states such as fright may involve the direct production of actions  by-passing the processes of deliberation and planning. a violated motive may be able directly to activate some existing strategy  interrupting other actions. this would include cases of 'impulsive' action. this could make it possible to take very rapid remedial action in times of great danger  or when sudden opportunities art recognized. 
 * some emotional states arise out of actions performed by the individual  for instance fear about possible errors  and secondary motives may be generated to take extra care  etc. these secondary motives may generate so much disturbance that they lead to disaster. 
 * in some cases  an emotion involves interrupting and redirecting a large number of ongoing processes  for instance processes controlling different parts of the body. sensory detectors may record local changes produced by the interruptions  and the system's perception of its own state will be changed. however  this kind of experience is not a necessary part of all emotions. internal monitoring need not produce recognition. the abili t y to discriminate and recognise complex internal states may have to be learnt  and may involve perceptual processes no less complex than recognising a face or a typewriter. 
 * one need not be conscious of  or f e e l   the emotion: the disturbance  or tendency to disturb need not be recognised  e.g. because relevant schemata have not been learnt  see  ch 1 . if it is recognised  this may activate further dormant motives or motive-generators  and possibly lead to a second-order emotion  recursive escalation . 
　　our conjecture is that the interruptions  disturbances and departures from rationality which characterise emotions are a natural consequence of the sorts of mechanisms required by the constraints on the design of intelligent systems listed earl i e r . our theory does nothing  as yet  to characterise the detailed phenomenology of the experiences involved in emotions. these are as rich and varied as other perceptions  e.g. vision  where there is also much work to be done yet. the fine structure of human emotional experience often includes awareness and interpretation of bodily changes. a f u l l account of what it is typically like to feel anger  elation  fear  etc. would have 
to include descriptions of this fine structure. yet what makes many emotions important in our lives is not this sort of d e t a i l   but the more global structure. and that is what we have tried to describe. this is what would make it possible for us to use terms like 'angry'  ' a f r a i d '   'disappointed'   embarrased'  'ecstatic' to describe the state of mind of an alien being  or possibly a sufficiently sophisticated robot. 
moods and attitudes are not emotions 
a mood is partly like an emotion in that it involves some kind of global disturbance of  or disposition to disturb  mental processes. but it need not be the intrusion of specific thoughts  desires and inclinations to act  etc. in humans  moods can be induced by chemical processes  or by cognitive processes  for instance hearing good or bad news. a mood can colour the way one perceives things  interprets the actions of others  predicts the outcome of actions  makes plans  etc. as with an emotional state  a mood may or may not be perceived and classified by the individual concerned. 
   attitudes are often confused with emotions. it is possible to love  p i t y   admire  or hate someone 
without being at all emotional about i t . the a t t i tude will be expressed in tendencies to take certain decisions rather than others when the opportunity arises  but there need not be any continual disturbance of thoughts and decisions. a mother may love her children without their being constantly in her mind  though a specific occurrence  such as news of danger to them may well interact with this attitude to produce an emotion  such as anxiety. there is no sharp dividing line between attitudes or moods and emotions. the space of possible mental states and processes is too rich and complex for simple divisions to be useful. 

1 

　　there are many kinds of experiences which can be deep and 1n some sense moving  and which we may describe as emotions  for lack of a richer  wore fine-grained vocabulary: for instance delight in a landscape  reading poetry  hearing music  being absorbed in a film or a problem. these seen to involve processes in which what 1s currently perceived interacts powerfully with a large number of processes  sometimes physical as well as mental. for instance  listening to music can produce a tendency to move physically in time to the music and also a great deal of mental 'movement': memories  perceptions  ripples of association a l l under the control of the music. these sorts of processes 1re not explained by the present theory  but they might be accounted for in terms of some aspects of the design of intelligent systems not discussed here  such as the need for subtle forms of integration and synchronisation of many processes in controlling physical movement. the synchronisation is 
needed both within an individual and between individuals engaged in co-operative tasks. music seems to be able to take control of some such processes. 
conclusion 
this sketch of some aspects of the architecture of the human mind  provides a framework for thinking about a range of possible types of intelligent systems  natural and a r t i f i c i a l   though the analysis s t i l l has gaps. in particular  our account of pleasure and pain requires development  and we are not yet able to give an acceptable analysis of what it is to find something funny! 
　　we have outlined a number of mechanisms and processes  which probably don't occur in a l l animals. in some less flexible forms of i n t e l l i gence  the process of selection of a motive could be inseparable from the process of i n i t i a t i n g action: operative motives could not be dormant. so not every intelligent system w i l l necessarily have emotions  though it is very likely for any machine or animal whose collection of motives and motive generators is comparable in variety to those of human beings  ans whose perceptual and reasoning a b i l i t i e s are similar. the mechanisms producing emotions are also the mechanisms required for great f l e x i b i l i t y in a complex environment. 
　　the model is relevant to a number of old philosophical problems  for instance the relationship between mind and body  and the question whether free w i l l is possible. it can be argued that the only significant form of free w i l l 1s that which involves taking decisions on the basis of one's own motives  beliefs  etc.  as opposed to being externally constrained. we have begun to sketch an explanation of the possibility of this sort of freedom. in this sense a robot might also be free.  whether we would be wise to make such robots 1s another question.  
　　the model may be important for psychotherapy and education  since it reveals enormous scope for 'bugs'. for instance  recursive escalation of emotions might account for some catatonic states. moreover  there are many ways in which the processes by which motives are generated  compared  selected for action  related to planning  triggered when dormant  etc. may go wrong. the theory also implies that processes of learning and cognitive development  which are often studied as if they were autonomous  w i l l occur within the framework of a complex and frequently changing collection of motives and motive-generators. these  and the emotional and other processes they generate must have a profound influence on what is learnt when  and it is to be expected that there w i l l be enormous v a r i -
ation between individuals. a deep understanding of the f u l l range of computational possibilities is surely a prerequisite for bny systematic attempt to deal with the human problems. 
acknowledgements 
this paper was written by the f i r s t author  using some ideas of the second author. margaret boden also helped see c1 . discussions in an src-funded distributed computing project  including jim hunter  keith baker  paul bennett  david owen and 
allan ramsay provided some of the background. sue adams and judith dennison helped with production. c1 is a longer fuller version of this paper. 
