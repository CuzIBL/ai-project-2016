 
although backpropagation neural networks generally predict better than decision trees do for pattern classification problems  they are often regarded as black boxes  i.e.  their predictions are not as interpretable as those of decision trees. this paper argues that this is because there has been no proper technique that enables us to do so. with an algorithm that can extract rules1  by drawing parallels with those of decision trees  we show that the predictions of a network can be explained via rules extracted from it  thereby  the network can be understood. experiments demonstrate that rules extracted from neural networks are comparable with those of decision trees in terms of predictive accuracy  number of rules and average number of conditions for a rule; they preserve high predictive accuracy of original networks. 
1 	introduction 
researchers  dietterich et a/.  1; quinlan  1; shavlik et a/.  1  have compared experimentally the performance of learning algorithms of decision trees and neural networks  nns . a general picture of these comparisons is that:  1  backpropagation  an nn learning method  usually requires a great deal more computation;  1  the predictive accuracy of both approaches is roughly the same  with backpropagation often slightly more accurate  quinlan  1 ; and  1  symbolic learning  decision trees induction  can produce interpretable rules while networks of weights are harder to interpret  shavlik et a/.  1 . in effect  a neural network is widely regarded as a black box due to the fact that little is known about how its prediction is made. 
　our view is that this is because we are not equipped with proper techniques to know more about how a neural network makes a prediction. if we can extract rules from neural networks as generating rules from decision trees  we can certainly understand better how 
   'rules are in forms of  if x1 = v x1  and x1 = v x1  ... and xn = v xn  then cj  where xi's are the inputs to the network  v xi 's are one of the values xi can have  and cj is the network's prediction. 
1 	c1nnecti1nist models 
a prediction is made. in addition  rules are a form of knowledge that can be easily verified by experts  passed on and expanded. some recent works  fu  1; saito and nakano  1; towell and shavlik  1  have shown that rules can be extracted from networks. these algorithms are search-based methods that have exponential complexity. subsets of incoming weights that exceed the bias on a unit are searched. such sets are then rewritten as rules. to simplify the search process  some assumptions are made. one assumption is that the activation of a unit is either very close to 1 or very close to 1. this can restrict the capability of the network since when the sigmoid transfer function is used as the the activation function  the activation of a unit can have any value in the interval  1 . 
　in this paper  a novel way to understand a neural network is proposed. understanding a neural network is achieved by extracting rules with a three-phase algorithm: first  a weight-decay backpropagation network is built so that important connections are reflected by their bigger weights; second  the network is pruned such that insignificant connections are deleted while its predictive accuracy is still maintained; and last  rules are extracted by recursively discretizing the hidden unit activation values. by drawing parallels with the rules generated from decision trees  we show that networks can be interpreted by the extracted rules; the rules in general preserve the accuracy of the networks; and they also explain how a prediction is made. 
1 	a three-phase algorithm 
a standard three layer feedforward network is the base of the algorithm. weight decay is implemented while backpropagation is carried out. after the network is pruned  its hidden units activation values are discretized. rules are extracted by examining the discretized activation values of the hidden units. the algorithm is described in steps below. 
1 	backpropagation with weight decay 
the basic structure of the neural network in this work is a standard three-layer feedforward network  which consists of an input layer  i  a hidden layer  h  and an output layer  1. the number of input units corresponds to the dimensionality of the examples of a classification prob-


	setiono and liu 	1 

　when the clustering is done  the network's accuracy is checked to see if it drops or not. a very small c can guarantee that the network with discretized activation values is as accurate as the original network with continuous activation values. so if it's accuracy does not drop and there are still many discrete values  clustering can be performed again with a larger e. otherwise  e should be reduced to a smaller value. 
　after network pruning and activation value discretization  rules can be extracted by examining the possible combinations in the network outputs  explained in detail in section 1 . the actual rule extraction is done by an algorithm that generates 1% accurate rules  liu  1 . however  when there are still too many connections  e.g.  more than 1  between a hidden unit and input units  the extracted rules may not be easy to understand. another three layer feedforward subnetwork may be employed to simplify rule extraction for the hidden unit. this subnetwork is trained in the same ways as is the original network  but in a reduced scale: the number of output units is the number of discrete values of the hidden unit  while the input units are those connected to the hidden unit in the original network. examples are grouped according to their discretized activation values. given d discrete activation values d1  d1 ...  dd  all examples with activation values equal to dj are given a d-dimensional target value of all zeros except for one 1 in position j. a new hidden layer is introduced for this subnetwork and it is then trained  pruned  and the activation values of its hidden units are discretized for rule extraction. if necessary  another subnetwork is created until the number of connection is small enough or the new subnetwork cannot simplify the connections between the inputs and the hidden unit at the higher level. the creation of subnetworks is rarely needed. for example  in our experiments  it was only used for the splice-junction problem. 
1 experiments and results 
in this section  we describe the datasets and representations used in experiments. a detailed example is given to show how the three-phase algorithm is applied to extracting rules. summary of the results on all datasets are given with a comparison to those produced by the decision tree induction methods. understanding a neural network is achieved by being able to explain  based on the rules  how each prediction is made in parallel with understanding a decision tree by having rules generated from it  quinlan  1 . 
1 	datasets and representations 
three datasets used are: 1. iris - a classic dataset introduced by r. a. fisher ; 1. breast cancer - a widely tested real-world dataset for the wisconsin breast cancer diagnosis; and 1. splice-junction - a dataset used in splice-junction determination originally described by noordewier et al . the datasets are obtainable from the university of california irvine data repository for machine learning  via anonymous ftp from ics.uci.edu . the summary of these datasets  their representations  and how each dataset is used in experiments are given below. 
1 	c1nnecti1nist models 
  iris - the dataset contains 1 examples each of the classes iris setosa  iris versicolor  and iris virginica  species of iris . each example is described using four numeric attributes  a1  a1  a1 and a1 : sepallength  sepal-width  petal-length  and petal-width. since each attribute takes a continuous value  the chimerge algorithm proposed by kerber  1j was reimplemented to discretize attribute values. the thermometer code  smith  1  is used to bin arize the discretized values; 1  1  1  and 1 inputs  discrete values  for a 1 a 1   a 1 and a1respectively. 
with 1 input for bias  there are total 1 inputs and three outputs. examples in odd positions in the original dataset form the training set and the rest are for testing as was done in  fu  1 . 
  breast cancer - the dataset consists of 1 examples  of which 1 examples are classified as benign  and 1 are malignant. 1% examples of each class were randomly selected  i.e.  1 benign and 1 malignant examples  for training  the rest for testing in the experiments. each example is described by 1 attributes  each attribute takes an ordinal integer from 1 to 1  1 values . due to the ordinal nature  the thermometer code is used again to code each attribute value. ten inputs correspond to 1 values of each attribute with all 1 inputs on representing value 1  the rightmost input on for value 1  and the two rightmost inputs on for value 1  etc. 
  splice-junction - the data set contains 1 examples1  approximately 1% are exon/intron boundaries  el   1% are intron/exon boundaries  ie   and remaining 1% are neither  n . each example consists of a 1-nucleotide-long dna sequence categorized with ei  ie or n. each of these 1 attributes takes one of the four values: g  t  c or a that are coded as 1  1  1  and 1  respectively. the class values  ei  ie  n  are similarly coded as 1  1  and 1  respectively.for the results presented here  the training data set consists of 1 examples while the testing data set consists of all 1 examples. 
1 	a detailed example - iris data classification 
this example shows in detail how rules are extracted from a pruned network. in the experiment  1 fully connected neural networks were used as the starting networks. each of these networks consists of 1 input units  1 hidden units and 1 output units. these networks were trained with initial weights that had been randomly generated in the interval  -1 . each of the trained networks was pruned until its accuracy on the training data dropped below 1%. the weights and topology of networks with the smallest number of connections and an accuracy rate of more than 1% were saved for possible rule extraction. the results of these experiments are summarized in table 1 in which we list the average number of connections in the pruned networks and their 
   1  another 1 examples in the original dataset contain invalid values so these examples are not included in experiment. 

ond hidden unit are -1 and 1 respectively  it is easy to conclude that if 1 = 1  then h 1 is 1  otherwise  h 1 is -1. this implies that an example will be classified 

average accuracy rates on the training data and the testing data. statistics in the second column of this table were obtained from 1 pruned networks  all of which have accuracy rates on the training data of at least 1 
%. in the third column  the figures were obtained from 1 pruned networks with accuracy of at least 1 % on the training data. 
   one of the smallest pruned networks is depicted in figure 1. it has only 1 hidden units and a total of 1 connections with 1% accuracy on the training set and 1% on the testing set. we ran the clustering algorithm of section 1 on this network and found only 1 discrete values are needed at each of the two hidden units to maintain the same level of accuracy on the training data. at hidden unit 1  1 of 1 training examples have activation values equal to 1 and the remaining 1 have activation values equal to 1. at hidden unit 1  the activation value of 1 examples is 1 and the activation value of the remaining 1 examples is -1. since we have two activation values at each of the two hidden units  four different outcomes at the output units are possible  table 1 . from this table  it is clear that an example will be classified as iris setosa as long as its activation value at the second hidden unit is equal to 1. otherwise  the example is classified as iris versicolor provided that its first hidden unit activation value h l = 1. the default class will then be iris virginica. 
　as seen in figure 1  only two inputs  l1 and 1  determine the activation values of the second hidden unit  
h 1. however  since l1 is 1 for all the training data  
h 1 is effectively determined by i-1. since the weights of the arcs connecting input units 1 and 1 to the secas iris setosa only if l 1 is 1  hence h 1 is 1 . 
　the activation value of the first hidden unit  h l  depends only on l1 and l1. the weights of the arcs connecting input units 1 and 1 to the first hidden unit are 1 and 1  respectively  hence h l is 1 if and only if l1 = l1 = 1. other input combinations will yield value 1 for h l. hence  an example with 1 = 1  l1 = l1 = 1 will be classified as iris versicolor. 
　with the thermometer coding scheme used for the input  a complete set of rules can be easily obtained in terms of the original attributes of the iris data set. the accuracy of this rule set is summarized in table 1: 
n n rules 1 
rule 1: if petal-length   1 then iris setosa 
rule 1: if petal-length   1 and petal-width   1 then ins versicolor 
	default rule: 	iris virginica. 
　for reference  the rule set  dt rules  generated by c1rules  based on a decision tree method but generate more concise rules than the tree itself  is included here: 
d t rules 
rule 1: if petal-length   1 then ins setosa 
rule 1: if petal-length   1 and petal-width   1 then iris versicolor 
rule 1: if petal-width   1 then ins virginica default rule: iris setosa. 
1 	c o m p a r i s o n s 
in this section  parallels are drawn between rules extracted from both neural networks and decision trees 
1 the rules are fired in a top-down and left-to-right fashion. 
	seti1 and liu 	1 

 nn rules vs. dt rules . understand ability is partly defined as being explicable in the sense that a prediction can be explained in terms of inputs  or attribute values . choosing to compare nn rules with dt rules is due to the fact that dt rules are considered best understandable among the available choices. a rule in discussion consists of two parts: the if-part is made of a conjunction of conditions  and the then-part specifies a class value. the conditions of a rule are in forms of  ai =vj   i.e.  attribute a  takes value vj. when a rule is fired  a prediction is given that the example under consideration belongs to class ck. by examining the fired rule  it can be explained how the prediction is attained. if necessary  the intermediate process can also be explicitly explained. 
　c1 and c1rules  quinlan  1  were run on the above three datasets to generate dt rules. briefly  c1 generates a decision tree which c1rules generalizes to rules. since researchers  cheng et a/.  1; shavlik et a/.  1  observed that mapping many-valued variables to two-valued variables results in decision trees with higher classification accuracy1  the same binary coded data for neural networks were used for c1 and c1rules. 
　being explicable is only one aspect of understandability. a rule with many conditions is harder to understand than a rule with fewer conditions. too many rules also hinder humans understanding of the data under examination. in addition to understandability  rules without generalization  i.e.  high accuracy on testing data  are not much of use. hence  the comparison is performed along three dimensions: 1. predictive accuracy; 1. average number of conditions of a rule; and 1. number of rules  see figures 1 . 
　the reasoning behind the comparisons is that if nn rules are comparable with dt rules  since the latter are admittedly interpretable  so should the former. now that each prediction can be explained in light of some rule  and those rules have direct links to the neural network  it can be concluded that the network's behavior can be understood via those rules. 
a
 it's true indeed for the three datasets in our experiments. 
1 	connectionist models 
1 	discussion 
the comparisons made in figures 1 indicate that nn rules are comparable with  if not better than  dt rules in terms of our understanding measures. the average number of conditions in nn rules is higher than that of dt for 1 of the 1 problems tested  however  the total number of nn rules is less than dt rules for all the 1 problems. these observations are consistent with the nature of each learning algorithm  i.e.  parallel vs. sequential. other issues of interests arc: 
  the training time. it takes much longer time to train a neural network than to learn a decision tree. this is also true for nn rules and dt rules extraction. due to the existence of sequential and parallel data types  and decision trees and neural networks are best suited to one type only  quinlan  1   the two approaches are expected to coexist. when time is really scarce  the decision tree approach should be taken. otherwise  it is worthwhile trying both because of backpropagation's other advantages  generalizing better on a smaller dataset  predicting better in general  etc.  towell and shavlik  1  . 
  average performance of nn rules. because of neural networks' nondeterministic nature  it is not uncommon that many runs of networks are needed with 

different initial weights. as was shown in table 1  the average performance for 1 pruned networks is very impressive  1% . this displays the robustness of the presented algorithm. 
  accuracy of neural networks and nn rules. there is a trade-off between the accuracy of the the rules extracted from the network and the complexity of the rules. a network can be further pruned and simpler rules obtained at the cost of sacrificing its accuracy. a notable feature of our rule extraction algorithm is that while it allows us to extract rules with the same accuracy level as that of the pruned network  it is also possible to simplify the rules by considering a smaller number of hidden unit activation values. 
  understanding the weights of connections. unlike m-of-n rules  towell and shavlik  1   nn rules here reflect precisely how the network works. nn rules given here are actually the merge of the two sets: 1. from the input layer to the hidden layer; and 1. from the hidden layer to the output layer. nn rules cover all the possible combinations of the connections with various input values and discrete activation values of hidden units. this is a significant improvement over search-based methods  towell and shavlik  1; fu  1  where all possible input combinations are searched for subsets that will exceed the bias on a unit. to reduce the cost of searching  they normally limit the number of antecedents in extracted rules. our algorithm imposes no such limit. 
  consistency between nn and dt rules. consistency checking is not an easy task. in general  the possible rule space is very large since the training data is only a sample of the world under consideration. it is not surprising that there exist many equally good rule sets. using the binary code for the iris data  for example  the possible size of the rule space is 1  but there are only 1 examples for training. however  for simple problem like the iris problem  the rules extracted by nn and the rules generated by dt are remarkably similar. 
1 	conclusion 
neural networks have been considered black boxes. in this paper  we propose to understand a network by rules extracted from it. we describe a three-phase algorithm that can extract rules from a standard feedforward neural network. network training and pruning is done via the simple and widely-used backpropagation method. no restriction is imposed on the activation values of the hidden units or output units. extracted rules are a oneto-one mapping of the network. they are compact and comprehensible  and do not involve any weight values. the accuracy of the rules from a pruned network is as high as the accuracy of the network. experiments show that nn rules and dt rules are quite comparable. since dt rules are regarded as explicit and understandable  we conclude that nn rules are likewise. with the rules extracted by the method introduced here  neural networks should no longer be regarded as black boxes. 
