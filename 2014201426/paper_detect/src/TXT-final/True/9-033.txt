 
　　　a versatile assembly system  using tv cameras and oomputer-controlled arm and moving table  is described. it makes almple assemblies such aa a peg and rings and a toy car. it separates parts from a heap  recognising 
them with an overhead camera  then assembles them by feel. it can be instructed to perform a new task 
with different parte by spending an hour showing it the parts and a day or two programming the assembly manipulations. a hierarchical description of parts  views  outlines etc. is used to construct models  and a structure matching algorithm is used in recognition. 
	1  	introduction 
       a computer-controlled versatile assembly system has been programmed during the past 1 months using  the edinburgh hand-eye hardware  barrow aid crawford   the equipment  fig. 1  consists of a moveable table  a mechanical hand with sensors and rotating palms  and two tv cameras  all conneoted via an 1x honeywell 1 to a 1k time-shared icl 1 running pop-1 programs. several other programs are running on thia equipment  including a program for recognising irregular objects and one which packs arbitrarily shaped objects into a box  mlchie et al  . the program described here is our most ambitious effort. it is capable of assembling a variety of structures  and much of our effort has been spent in enabling the machine to acquire descriptions of the parts for itself using an overhead tv camera. 
related work has been carried out at hitachi 
 ejiri et al   at mit  winston1   and at stanford university  feldman . the hitachi program could build a variety of simple structures of blocks from line drawings of the structure  the hit programs can learn concepts about structures and copy an arbitrary structure of simple blocks given spare parts  and a recent stanford program can assemble a simple automobile water pump using preprogrammed hand manipulations. 
1. the task 
　　　a number of parta are placed by the operator in a heap on the table  fig. 1  peg and rings . 	the machine's task is to separate the parts and recognise them  then to assemble them into some predetermined configuration  fig. 1 . 	figs. 1 and 1 show another 
example  a toy oar. we are currently thinking in terms of up to a dozen parts with outlines described by up to twenty or so straight or ourved segments from any one view  possibly with some holes of similar complexity. 
       in order to explore the capabilities of a computer-controlled system aa opposed to a conventional electromechanical device we seek a versatile assembly system. the demand for versatility is also calculated to raise interesting 
aspects from an artificial intelligence point of view. 
　　　our goal has been to develop a system which enables one to:-
　　　 i  think up a new aaaembly involving a kit of parta which have not been used before  
　　　 ii  spend a day or so familiarising the machine with the appearance and manipulation of the parts and instructing it how to assemble them into the required structure  
　　　 iii  leave the machine unattended  busily making the structures ad nauseam  provided that a fresh heap of parte is dumped on the table from time to time. 
　　　we have achieved this goal for simple structures. we can show the machine half a dozen new parts and instruct it how to lay them out ready for assembly in about two hours; interactively programming the assembly operations themselves takes four hours or so. the machine can make the structures like the peg and rings  the toy car or a toy ship unassisted but slowly  taking an hour or two to find and assemble the parts. it completes the assembly correctly about four times out of five. it should be possible to ease the programming of the assembly operations somewhat  but removing the need to program movements in terms of numerical co-ordinates would need a new approach. the system is about 1k of pop-1 code. 
	1. 	how the syatem performs the task 
　　　the system transforms a heap of parts into a completed assembly  typically going through the following step:-
　　　layout: identify parts visually and put them in standard positions. 
       1. locate all parts or heaps of parts on the table using the side camera  wide angle . 
       1. inspect each part or heap with the overhead camera. 	if it is recognisable as an isolated part pick it up and lay it out in a standard position and orientation. 
       1. if there are no parts or heaps left  or if all the required parts have been found go to step 1. 
       1. using the overhead oamera look for a protrusion in the smallest heap  grasp the protruding part or parts and separate them from the heap and go to step 1. if it has no protrusions try to break up the heap by picking it up as a whole and turning it over so that it falls apart. if this does not work  try pushing it with the hand at various heights. if stil no success  try another heap. go to step 1. 
       1. if some parts are missing  complain. if there are more parte than are needed  clear them away. assembly: 
　　　pick up each part from its standard position and insert it into the assembly  by feel. a workbench 
with a simple vice and various working surfaces is used. 
       the program is written as two quite distinct subprograms  layout and assembly. at present they do not communicate; they both know the standard 
positions and orientations of the parts. the layout subprogram uses descriptions of the parts  acquired during the instruction phase  to recognise them  pick them up  turn them over if necessary and put them into standard positions. the assembly subprogram works blind  using no internal descriptions of the parts. it is written interactively during the instruction phase. 
     the system carries cut the steps listed above at 'execution time'. it is able to do so because the following steps have been carried out previously at 'instruction time'. 
a. instructing the layout program 
　　　for each part in each stable state  e.g. right way up  or on i t s side . 
　　　1. the operator places the part on the table under the vertical camera  the machine takes a picture and creates from it an internal deacription of that view of the part. 	this is repeated several times  and the machine adjusts i t s descriptions each time  taking note of the variations caused by reorientation of the part and imperfect picture information. 
　　　1  the programmer types in on-line commands to move the hand  to pick up the object  turn it over  put it down and pick it up again if necessary  then to put it down in the standard position and orientation    i f the assembly has several identical parts separate commands are given for putting each one down in i t s own place.  the programmer intersperses these commands with instructions to remember the current state  e.g. when the hand has closed over the part. the system takes a note of these specified states and at execute time constructs a sequence of actions to put the part into i t s standard position and orientation  
b.  writing 	the assembly program 
for each part 
　　　1. the programmer puts the part on the table in i t s standard position and orientation  and he interactively devises and edits some pop-1 program to make the machine pick up the part and f i t it into the 
assembly. his program uses basic move and grasp operations  and two high level manipulation operations provided for constrained moves and hole f i t t i n g . 
	1. 	the layout subprogram; 	descriptions 
　　　we must f i r s t explain the kind of internal descriptions of parts used in the layout program. we can then show how it creates these descriptions at instruction time and how it uses them to recognise partb at execution time. for c l a r i t y we have simplified a few programming details  glossing over some unnecessary or uninteresting distinctions. 
　　　the program works in terms of a hierarchy of concepts called entities  each represented by program data structures  having other entities as i t s components. 	the entities used are summarised in table 1 and table 1 gives a brief description of each. 
table 
	. 	- 	- 
hierarchical structure of entitles 
an entity is either a table top  or an object-set  or an object  or a part  or a hand  or a workbench  or a heap  or a stable state  or a view  or a region  or a hole-set  or a hole  or an outline  or a segment. 
a table top has an object-set. 
an object-set has objects. 
an object is either a part  or a hand  or a workbench  or a heap. 
a part has stable states. 
a stable state has a view. 
a view has a region. 
a region has an outline and a hole-set. 
a hole-set has holes. 
a hole has an outline. 
an outline has segments. 
table 1 
the entities used 
the table top is the whole collection of things on the table. 
an object is any physical thing on the table which can be seen or touched; it is i n i t i a l l y distinguished from i t s surroundings by clear space on the table. a part is one of the separate pieces needed for the assembly e.g. one of the wheels of the car. 
a stable-state is one of the states in which a part can rest on the table  irrespective of orientation or position e.g. on i t s side  upside down. there should be only a small number of distinguishable such states. 
a view is an analysed tv picture. 
a region is a connected light area in a picture  possibly with darker holes  we use light objects on a dark background . 
a hole is a dark area inside a region. 
an outline is the outer boundary of a region or hole. 
a segment is a segment of a circle  up to 1   with specific length and curvature  zero curvature means a straight segment . the irregular boundary of a region or hole is analysed into a small number of segments by curve f i t t i n g  fig. 1 . 
　　　bach entity either has an n-tuple of components  or it has a aet of components. the size of the n-tuple is fixed as in the above 'syntax'  for example a region has a pair of components; but the size of the set is not fixed u n t i l instruct time  for example the system discovers that the hole-set of a car body side view has two holes. 
     an entity may possess properties and some relations  at present only binary ones  may subsist between i t s components. the properties and relations have names and may be truth-valued or take values in some other domain such as numbers. 
　　　we make an important distinction between two kinds of entities: model and individual. bach has entities of i t s own kind as components. an individual entity is an internal description generated by a particular exposure to a physical objeot using information from tv camera and hand aensors. thus when the operator puts a car body on the table  the machine takes a picture  turns it over and takes another picture  one individual entity of type 'part' is generated and two individual entitiea of type 'view' are generated  together with individual outlines  holes  segments etc. a model entity  on the other hand  is a summary or composite of a number of such experiences. the end result of the instruction phase is a collection of model entities incorporating the system's knowledge about the parts  their views  outlines etc.; the individual parts  view and out-
1 
lines which gave rise to these w i l l have been dis-
carded. 
　　　the important operation in recognition is the creation  from visual and t a c t i l e sense data  of an individual entity which matches a model entity and 
whose components match the components of the model entity. the individual entity contains a pointer to i t s model and one to i t s sense data  thus binding them together; it also contains certain specific information  e.g. position and orientation  not appropriate to model entities. 
　　　there are a few exceptions to the above. 	the system does not create models for i t s hand or the workbench at instruction time; 	these are given beforehand. 	there is no model for a heap since an individual heap is generated by elimination  on 
failure to recognise a part  hand or workbench. 
　　　the system has a data structure for each model entity and individual 	entity; 	these are pop-1 records linked by pointers to their components into tree structures. 	there is also a data structure for each entity class  for example the class 'view' and the class 'region'. 	each model or individual entity belongs to some class and certain data pertains to the class as a whole - for example a l i s t of the 
properties which an entity of that class enjoys and functions for computing their values. 
　　　to build entities the machine needs raw material which we shall c a l l 'sense data1  information from the tv camera or possibly the hand sensors which has not yet been recognised as referring to any known entity. the recognition process  which we describe below  takes a model entity and some sense data and tries to create an individual entity which corresponds to the model. 
　　　table 1 summarises the four notions of entity class  model entity  individual entity and sense data showing what information is associated with each. the use of this information w i l l be clearer when we discuss the recognition process. 
the matching process which recognises parts 
　　　to understand the recognition process l e t us consider what happens when the system has taken a tv picture and tries to interpret it as a side view of a car body. this may be during the instructionphass when it has been told that it is looking at the side view of a car body  or during the execution phase after it had found an upright car body and turned it over. or again it might be dealing with an unknown object  and  sideview of car body' might be just one possible interpretation among several which it was trying. 
　　　the tv picture  a 1-dimensional array of brightness levels  constitutes a sense datum  d in d  	a matching function is now applied to this sense datum and the model of the side view of the car 	body. this function produces a set of individual side views of car bodies  an empty set if there is no way of interpreting the picture as such a view  otherwise one element for each possible interpretation. 	thus matchi 	sense data x models -  set of individuals 
　　　the matching function works i t s way recursively down the hierarchy from top to bottom  comparing gross properties on the way down and f a i l i n g if they are too discrepant. thus it might f a i l because the area of the region it is looking at in the picture is too small for a car body  without bothering to analyse the outline of the region. as it goes down it refines the sense data  using a thresholding region finder routine to set region level sense data from the view level brightness array  finding holes with the same routine to get hole data and f i t t i n g 

curves to the perimeters to get segment data.  we have called the region finder and curve f i t t e r 'component finding functions' * when it gets to the bottom level the recursion unwinds and passes up the hierarchy descriptions of individual entities  using their finer properties and relations between them to establish correspondence with the model. at each level the matching function produces a set of individual entities each of which might correspond to the model  thus dealing with ambiguity essentially as would a 'back-track' or nondeteministic process. 
　　　to be more precise  the function 'match' works as followst-
function mateh d m  let c be the entity class of m. 
let f be the special matching function of class 
c. 
result = f d m  
　　　the special matching function f may vary from class to class  but normally f is 'general-match'  defined as follows:-
general-match : sense data x models -  sets of individua;s 
function general-mateh d m  
let c be the entity class of m. 
let f be the set of properties for class c. 
for each p in p  oompare f  d   the value of property d for the senaepdatum  with the value of p in the model m. 	if there is too much discrepancy exit with result = empty set. 
case 1. m has an n-tuple of components  m1... m. . apply the component finding functions of the class c to d  to f i n d sense data relevant to the components say d1.......... dn . as each d. is computed  match it against the oomponentjm   thus l e t ii=match d.fm  . if some i. is empty then exit immediately with result  empty set. otherwise use each element of. i  the cartesian product of the setsjof individual components  to construct a new individual with these components. the result is the set of 

these individuals. 
case 1. m has a set of components  s . apply the component finding functions for class c to find a set of sense data relevant to the components  s.. use the relation value finding functions of e  f for r in r  to compute the values of relations between the sd. compare 
these with the known values of the relations for the s   and use the relational structure matching 
algorithm  described below   together with the function match  to find the largest subsets of 1. which correspond. if these subsets are sufficiently large construct a new individual entity from eaoh correspondence among the components. the result is the set of individuals so constructed. 
	1 	matching relational structures 
　　　a set of segments forming the outline of a part can be regarded as a relational structure endowed with properties  such as length and curvature  and relations  such as adjacency  distance or relative orientation  similarly for holes or objects on the table top. although the properties and relations usually take numerical values  length  it w i l l simplify the discussion to talk in terms of truth 
valued ones  long  medium  short . in the algorithm given in the last section there is a point  case 1  where we need to put two sets  of segments  say  into correspondence on the basis of these properties and relations. tv picture processing being what it is 
we expect discrepancies  segments missing  two segments coalesced  but we want to match as many elements as possible. pig. 1 shows two simple outlines and corresponding relational structures; they have several common substructures  e.g. { 1 '   1 '   1*  1' . 
　　　more precisely  by a relational structure we mean a set s of elements together with a set of properties p and a set of relations r over it  we consider only binary relations here . given two relational structures  s  p r  and  s1 p r  we define a match between them as a set t1 c s1 a set t1c s1 and an isomorphism  ~   between t1 and t1 preserving properties and relations. thus s1 = s1 implies p s1  i f f p s1  for each p in p  also s1=s1 and ＊' s1 imply r s1 s1'  i f f r s1 s1'  for each r in r  and a match represents a common substructure in our two relational structures. 
	we can find matches as follows. 	by an assign-
nwijivment we mean a pair  s1 s1  with s1  we mean a pair  a1 a1  with s1 in sj and s1 in 
s1 such that p s1  i f f p s1  for each p in p. in fig. 1 the assignments are 1 '   1'  1'  1'  1 '   
1'  1'.etc. we say two assignments  s1  and  s1' s'  are compatible if r s1 s'  i f f r s  s|  for a l l r in r  new by definition a match is just a set of assignments such that each assignment is compatible with every other assignment in the set. indeed we may think of the assignments as forming the nodes of a graph with compatibility as the  symmetric  relation forming the arcs. our problem then is to find totally oonnected subsets of this graph  often called cliques. 
     a clique is said to be maximal if no other clique properly includes i t . finding maximal cliques is a well known problem  karp1  a 
graph of n assignments may have  n/1  maximal oliques in a theoretical bad case  but at least we can find each maximal clique in time proportional to n  or n log n if we push i t   . we can do this by using a refinement of a simple binary search algorithm given by burstall1. knsdel  gives a similar algorithm. in fact for our recognition problem it seems adequate to generate only largest 

heap long enough. our program does not detect internal lines  relying on the outline of the heap. it attacks the smallest heap f i r s t . 
     the f i r s t tactic used is to look for a protrusion in the heap outline with a 'neck' which 
might indicate a part which is easily separable. a number of possible hand positions are then considered so as to pick up the protruding part or parts without fouling the rest of the heap. if it succeeds in 
picking something up the machine examines both this and the rest of the heap  trying to recognise an isolated part. the second  cruder  tactic is to try 
and pick up the whole heap  then rotate the palms to let pieces f a l l off. the third is to push the heap 
clearly there are 
loop. 
　　　this snables it to cope with too many or too few parts. if one of the lower level routines enoounters d i f f i c u l t i e s it simply jumps out to loop. at a lower level various routines on entry assign a label to the variable pick-up-fail  and failure to pick something up satisfactorily causes a jump out to the current label. 
　　　our recognition process is basically recursive  we have experimented with some process-swapping techniques but they are not in our program at present . this does not lead to too much r i g i d i t y   because we make rather extensive use of 'memo-functions'  michie1  for example  when an analysis of the outline of a region is required the analysing function remembers the result and  when asked for it again  simply returns it immediately. thus outline analysis is only done when needed and never repeated. 
	1. 	the assembly subprogram 
　　　this program works blind  using only hand sensing. it is written interactively at instruction time in terms of basic hand moving and sensing operations together with two higher level operations. 
　　　the basic operations include 'raise z centime-tea'  'move to   x   y   '   'grasp to w centimetres'  'rotate palm by o '  and functions for reading forces on the hand by means of strain guages  namely gripping force  
weight of the object held and torque. there are two higher level operational constrained move and hole f i t t i n g . 
　　　constrained move. this operation has two parameters  both force vectors  f a force opposing movement and f a constraining force   fig. 1 . let u and u be tne unit vectors in these two directions. let 1 and ♀ be small scalar distances. the hand attempts to move in direction -u u n t i l it is opposed by a force larger than f . ~1t the same time it keeps in contact with a surface which offers a resisting force f . the resulting movement w i l l not necessarily be in direction -u but along the surface 
	til 	 * 
according to the component of -um tangential to the surface. 	the operation works in detail as follows:-

ment which a single call on the constrained move operation might produce. the constraining force parameter may be l e f t undefined giving an unconstrained move in direction -u u n t i l an opposing force is f e l t . 
this operation was suggested to us by work at hit draper laboratory  kevins et al 1 . 
　　　the wooden car assembly gives an idea of how the program proceeds. a 'workbench1 is used  fixed to one corner of the table  fig. 1 . it has a 'vice' for holding a wheel while an axle is being inserted  consisting of an l-shaped corner piece and a pivoted bar which the hand closes so that the wheel is held between the bar and the l. it also has a vertical ' w a l l ' so that the car body can be held firmly while the second wheel is pushed onto each axle. 
the sequence of events  in outline i s : -
　　　  i   the hand puts a wheel in the vice and inserts an axle. 
       i i   it turns the car body upside down  picks up the axle with the wheel on it and inserts it into the body. 
　　  i i i   repeat   i   and   i i   for the second wheel and axle. 
      iv  put the car body against the wall upside down with the two wheels against the w a l l . 
      v  push the remaining two wheels onto the protruding axles. 
      vi  pick up the assembled oar and place it on the table. 
　　　assembly programming is s t i l l quite tedious  involving choice of numerical parameter* for distances and forces  and we have some ideas for easing i t   popplestone1  there is clearly a l o t of thinking to be done before we could make the assembly phase as versatile and easily instrucable as the layout  
e.g. by replacing numerical commands with instructions using relations like 'on top of and ' f i t t i n g i n t o ' or by showing the machine intermediate assemblies. in particular our present assembly subprogram does not use the internal descriptions of the parts which have been acquired during instruction by the layout pro-
gram. such descriptions would have to be recast so as to be useful for assembly as well as recognition. 
	1  	concluding 	remarks 
writing this program has been a valuable exercise 
from the point of view of understanding- what problems are important for an integrated assembly system. by tackling a definite task but imposing the requirement of v e r s a t i l i t y   we hare raised some interesting a r t i f i c i a l intelligence questions without writing a program just to j u s t i f y a . i . dogmas. we hope to work in future on   i   making the learning system more 
coherent   i l   extending the vision system to deal better with side views  essentially requiring 1-dimensional teohnigues  and to analyse half-completedl assemblies  and   i i i   making it easier to program assembly manipulations  being less specific about nuaerical co-ordinates and the magnitudes of forces. 
acknowledgements 
　　　donald michie i n i t i a t e d our work on robotics and directed the' efforts to produce a working handeye system. steve salter and gregan crawford made the main contributions to the hardware. ban bobrow made helpful suggestions about the vision and recognition side  also about this paper. ken turner contributed the outline segmentation routines to our 
vision work. valuable ideas about assembly came from mit draper labs. we are grateful to eleanor kerse for typing. the project had support from the science research council and from the general post office. 
references 
 1  barrow  h.g. and crawford  c.f. the mark 1 edinburgh robot facility. machine intelligence 1  eds. b. meltzer and d. michie  edinburgh: edinburgh university press  pp. 1.  1 . 
 1  michie  d.  ambler  a.p.  barrow  h.g.  burstall  r.m.  popplestone  r.j. and turner  k. 
vision and manipulation as a programming problem. 
proceedings of the 1st conference on industrial robot technology. nottingham.  1  
 1  e j i r i   m.  uno  t.  yoda  h.  goto  t. and takeyasu  k. an intelligent robot with cognition and decision-making a b i l i t y . proceedings of second international joint conference on a r t i f i c i a l intelligence. imperial college  london  pp. 1.  1 . 
 1  winston  p.h. 	wandering about on the top of the 
robot. 	vision flash 1. a r t i f i c i a l intelligence laboratory  mit  cambridge  massachusetts.  1 . 
 1  winston  p.h. the mit robot. machine intelligence 1  eds. b. meltzer and d. michie  edinburgh: edinburgh university press  pp. 1.  1 . 
 1  feldman  j.a. 	private communication.  1 . 
 1  karp  r.m. 	redueibility among combinatorial 
problems  	complexity of computer computations  ed. k.e. miller and j.w  thatcher  new york: plenum press  pp. 1.  1 . 
 1  burstall  r.m. tree-searching methods with an application to a network design problem. machine 
intelligence 1  eds. n.l. collins and d. michie  edinburgh: oliver and boyd  pp. 1.  1 . 
 1  khodel  w. bestimmung a l l e r maximalen vollstandigen teilgraphen eines graphen g nach stoffers. 
computing. vol. 1. ho. 1  pp. 1.  1 . correction in fbi d. 1  p. 1. 
 1  walts   d.l. 	generating semantic descriptions f r r 
drawings of scenes with shadows. a r t i f i c i a l intelligence laboratories report ai tr-1. mit  cambridge  mass.  1 . 
  i l   winston  p.h. learning structural descriptions from examples. a r t i f i c i a l intelligence technioal report 1  a r t i f i c i a l intelligence laboratory  mit  cambridge  mass.  1 . 
 1  cornell  d.g. and gottlieb  c.c. an efficient algorithm for graph isomorphism. j. assoc  comput. mach.  1.  1.  1 . 
 1  barrow  h.g.  ambler  a.p. and burstall  l.m. 
some techniques for recognizing structures in pictures. frontiers of pattern recognition  ed. s. watanabe  new york: academic press  pp. 1.  1 . 
 1  michie  d  'memo' functions and machine learning. nature  1  1.  1 . 
 1  nevins  j.l.  sheridan  t.b.  whitney  d.e. and 
woodin  a.e. the multi-moded remote manipulator system. e-1o. charles stark draper laboratory  mit  cambridge  massachusetts.  1 . 
 1  popplestone  r.j  solving equations involving rotations. research memorandum mip-r-1. department of machine intelligence  school of 
a r t i f i c i a l intelligence  university of edinburgh   l1  
reference on cliques which came to hand after paper was typed:-   
 1  akkoyunlu  e.a. the enumeration of maximal cliques of large graphs. siam journal on computing. 
vol. 1. no. 1. march.  1  


	figure 1 	figure 1 

	figure 1 	figure 1 

figure 1 
	figure 	1 
1 

maximal cliques 

	figure 	1 
1 
a constrained move 

	figure 	1 

	figure 	1 
session 1 	robot implementations 
planning considerations for a roving robot with a r m * 
richard a. lewis and antat k. bejczy 
guidance and control division 
jet propulsion laboratory 
california institute of technology 
	pasadena  california 	1 

abstract 
       the jet propulsion laboratory is engaged in a robot research program. the program is aimed at the development and demonstration of technology r e q u i r e d to integrate a v a r i e t y of robntic functions {locomotion  manipulation  sensing and perception  decision making  and man-robot interaction  into a working robot unit operating in a real world environment and dealing with both man-made and natural objects. this paper briefly describes the hardware and software system architecture of the robot breadboard and summarizes the developments to date. the content of the paper is focused on the unique planning considerations involved in incorporating a manipulator as part of an autonomous robot system. in particular  the effects of system architecture  arm trajectory calculations  and arm dynamics and control are discussed in the context of planning arm motion in complex and changing sensory and workspace environments. 
       key terms: robot system; robot system planning; robot breadboard architecture; a r m motion planning; a r m control; a r m dynamics; sensors for manipulation; manipulating in natural and constrained environment. 
1. 1 introduction 
       autonomous goal-directed coordination of locomotion  manipulation  and sensation and perception in a semi-natural environment is the capability being sought by the jpl robot research program. the initial goal of the program is to demonstrate the integration of sensory and motor functions in the autonomous performance of manipulation and locomotion tasks in response to global commands issued by an operator. the long-range goal is to develop  test  and display concepts of robot structure  system integration and operation  and machine intelligence for the design and use of adaptive autonomous machines for advanced space and planetary exploration. the jpl program utilizes results of progress obtained at other institutions engaged in robotics and artificial intelligence work reviewed in ref. 1.  ref. 1 contains an extensive list of related literature.   the robot breadboard itself is a mobile vehicle  similar to that used by the astronauts on the moon  equipped with a six degree-of-freedom manipulator  a modified version of the stanford electric a r m   see ref. 1   a complement of sensors  tv  laser range finder  navigation and guidance sensors  tactile sensors  and  eventually  proximity sensors   and a local mini-computer in communication with remote computers  graphic displays  and operator consoles. 
*this paper presents the results of one phase of research carried out at the jet propulsion laboratory  
california institute of technology  under contract no. nas1  sponsored by the national aeronautics and space administration. 
       in this paper  we focus on the particular planning considerations involved in incorporating a manipulator as part of a total robot system operating in a complex sensory environment and dealing with 
both man-made and natural objects. 	first the architecture of the jpl robot breadboard and then the 
different aspects of planning manipulator motion are discussed. 
	1. 1 	breadboard system architecture 
       the breadboard is divided into six functional subsystems: locomotion  manipulation  environment sensing and perception  computing and data handling facilities  robot executive  rex   and operator-
robot interface. 	each subsystem contains both hard-
ware and software. subsystem design is based solely on criteria of functional compatibility  performance  growth capability  and convenient interfacing. total robot system integration will be studied experimentally and different concepts wil! be demonstrated in successive stages. 
1. 1 breadboard hardware 
       the major subsystem hardware elements are shown in fig. 1  indicating also the physica  size of the moving part of the breadboard. 

	fig. 1. 	breadboard hardware configuration 
1        the vehicle  on loan from marshall space flight center  provides a flat and relatively stable platform for mounting breadboard elements to be moved around in the environment. total effective load capacity o♀ the vehicle is about 1 pounds. travel speed will be limited to 1 mile/hour. the vehicle has ackerman-type double steering; the two ends can be steered in the same or opposite directions. alternatively  one or the other end only can be steered. each wheel is independently driven by a dc torque motor. currently  the vehicle has only dynamic braking. the suspension has a modified independent spring action at each wheel. inputs to the vehicle navigation  guidance  and control system are furnished by odometers mounted on the front wheels  providing vehicle center line distance travel information   a  ruggedized  directional gyro compass  providing directional reference   and wheel drive motor tachometers  providing information on vehicle velocity . 
       the manipulator is a modified version of the stanford electric a r m described in detail in ref. 1. it has six degrees of freedom  allowing any desired hand position and orientation in an open or slightly obscured workspace. 	the reachable set of points  the workspace  is within a radius of 1 inches measured from the origin of the manipulator base reference frame. 	 see fig. 1.   	the six joints connecting tv cameras which will provide'digitized stereoscopic input to both scene analysis and operator display  ref. 1 . a 1 by 1 resolution sequential column digitizer furnishes video data for computer-rate digital picture processing and operator display. the tv cameras and laser are mounted on a pan and tilt mechanisms referenced to a common coordinate system and will be used as an integrated scene analysis subsystem. arm-mounted proximity sensors {described in ref. 1  and tactile sensors will at a later date augment the environment sensing and 
perception subsystem. 
	sensor. 	if this proximity sensor is mounted to an 
appropriate place on the hand  the sensitive volume 
will move with and ahead of the hand at a known distance relative to a reference point on the hand. a voltage signal will appear when the sensitive volume  touches  a solid surface as the hand approaches the surface. this voltage signal can be used to guide 
and control the terminal motion of the hand in direct response to sensed relative hand-object position and 
orientation. of course  several proximity sensors can be mounted on the hand  providing several sensi-
tive volumes in a known pattern around the hand and facilitating the design of a versatile conditional terminal guidance and control logic for hand motion. 
       the computing and data handling subsystem architecture is currently based on a remote pdp-1 in the arpa net as an off-line computer. 	this will be connected to a local real time computer perfor-
	ming realtime robot control and i/o functions. 	 see 
fig. 1.   the remote computer system will be used 
fig. 1. 	reference frames      the proximity sensor is a small  about 1. 1 cubic inch  electro-optical device with a small ellipsoid-shaped sensitive volume permanently focused at a distance of a few inches in front of the 

	for .link-joint pairs of 	a r m 
the links from the base to the hand are in the following sequence: two rotary joints  providing shoulder azimuth and elevation action   a linear joint {providing in and out reach action   and three rotary joints  providing the wrist action . the hand is presently a simple parallel jaw mechanism. the joints are driven by permanent magnet dc torque motors geared directly to the corresponding links. depending on the relative position of the links  the arm can handle loads of up to 1 pounds earth weight. the arm servo control utilizes analog position measurements from the joint outputs and analog velocity measurements from the motor shafts. holding torque at each joint is provided by electromagnetic brakes. the arm's structural stiffness and tight 
servo control can provide hand positioning accuracy 
within a few tenths of an inch. a suitable articulated and adaptively controlled hand will be added at a later date. 
       environment sensing and perception is mainly obtained from two sources: tv cameras and laser ranging. the laser ranging device is a gaas pulsed mode laser with fast pulse  ~1 ns . the beam is pointed by a gimballed m i r r o r and detected by a photomultiplier. provisions are made for multipulse averaging using analog integration and variable averaging time. the sensing range is tentatively up to 1 feet. the design is based on previous jpl experiments  ref. 1 . related data handling problems are treated in ref. 1. the vision system consists of two identical and optically parallel vidicon fig. 1. computing and data handling subsystem architecture 
to process tv and laser pictures  to construct the  world model    to operate the different subsystem planning programs  and to execute top-level decisionmaking programs of the robot executive  rex . rex is described in detail below. 
       the realtime computer will interface with the robot through input and output units which contain a / d and d/a converters. 	a cable unit will contain the necessary logic devices allowing the robot to be tethered to the cpu via a 1 foot cable. 	tv data from the robot will interface directly  via the video converter  to the cpu through a separate cable. 	a disk storage unit will be used for fast  random access mass storage and will serve to store the operating system routines  robot eupport programs  tv and laser pictures  and status files for the operator terminal. 	a magnetic tape unit will be used for performing system diagnostics and for entering operating system programs and any robot subsystem programs developed in the off-line computer. 	the operator console will allow operator interaction with the system and development of subsystem support programs. 
       the operator-robot interface functions will be performed through an imlac terminal connected to the realtime computer. 	 see fig. 1.  during program development  the imlac will also be used for simulation studies. 	the imlac terminal includes a crt display  a teletype  and a read/write cassette recorder. 
1. z breadboard software 
       the software system architecture is essentially hierarchical with the robot executive  rex  controlling and monitoring the various software subsystems. rex performs problem solving  interacts with the human input command structure  manages the  world model   and calls the major subsystem software modules  vehicle  arm  etc. . the major subsystems are designed to be largely independent of each other. necessary data concerning the state of the robot and environment used by the various subsystems are fur-
nished through the  world model    
       a master control program  mcp  ties the various subsystem programs together and acts as an operating system for them. present plans are to design the mcp in the remote computer using the mechanisms in sail  stanford artificial intelligence language   refs. 1 and 1  for the creation and control of concurrent processes. operating system modifications are also planned based on the use of the tenex paging system  ref. 1  which makes available interrupts of various types not incorporated into sail  subsystem programs can be written in sail or possibly in other languages. sail provides easy linkages to fortran and assembly languages. 
       the total breadboard system is of experimental nature. thus  the software system is intended to be expandable and evolutionary. 
1. 1 	planning manipulator motion 
       this task involves three separate efforts: system architecture effects  trajectory planning  and manipulator dynamics and control. these are  r e spectively  planning for manipulator motion  planning 
o{ motion  and execution of planning. planning tor manipulator motion occurs at the system level in the selection  design  and placement of robot hardware. planning of motion involves the selection and implementation of methods of specifying particular motions and motion constraints. execution planning deals with motion control implementation schemes. we now consider each of these three separately. 
1. 1 	system architecture effects 
       placement of the manipulator along the center line of the vehicle about 1 inches from the front edge of the vehicle platform allows a reasonable workspace for the manipulator on the ground  which is 1 inches below the platform  while still permitting access to tools and sample storage bins near the center of the platform. this placement does  however  give rise to several motion constraints; the manipulator can easily collide with the platform  the front edge of the platform  the wheels  and the wheel drive motors  even though the basic vehicle was modified extensively to minimize this problem. 
       the selection and placement of sensors give rise to additional motion constraints for the manipulator as well as allowing the manipulator to know its world. 	the manipulator makes use of both external and internal sensors. 	in the initial configuration of the robot  the primary external sensors to be used by the manipulator are the dual tv and laser range finder. 	these are used to determine a priori manipulator targets and are assumed to have sufficient 
resolution in the initial simplified robot environment 
for effective target specification. later operation of the robot in richer and more perceptually complex environments rendering the sole use of these sensors open to question will be accompanied by the use of conditional arm control loops regulated by direct inputs from tactile and proximity sensors. use of these latter devices in conjunction with an adaptive  articulated terminal effector will permit the arm to respond directly to relevant aspects of the environment. 
       fig. 1a shows a proximity sensor mounted on the hand   while fig. 1b shows the concept of proximity sensor application for terminal guidance and control of hand motion in  distance seeking  and  distance keeping  modes of operation. a more detailed treatment of proximity sensor application to manipulator control can be found in ref. 1. 
i ＊ uniform distance between a 
fixed point on the hand and 
solid objects during motion 

concept of proximity sensor application for closed-loop guidance and control 
op hand motion 
	fig- 1. 	terminal guidance and control 
of hand motion using proximity sensing 
       our robot-hand application calls for handling a variety of both regular  man-made  and irregular  natural  objects of different size and weight in various manipulative tasks. therefore  a versatile hand-finger mechanism will ultimately be required. an articulated and adaptively controlled hand  using design and control principles similar to those applied in prosthetic hand research; see refs. 1 and 1  will not require detailed a priori information on objects to be handled and will ease the control of many details of a grasping motion since the hand  while gripping an object and monitoring only one actuator  adapts itself  reflexively  to the shape  size  orientation  and weight of the object. 
       placement of tactile and proximity sensors on the manipulator itself creates no new obstacles or additional constraints  but placement of the tv/laser head is a berious problem. 	the present configuration places these sensors on a mast above the a r m support 

1 

post and represents a tradeoff between good viewing angle and keeping out of the way of the manipulator. even so  it is possible for the manipulator to collide with the tv/laaer head  either in normal motion or in switching from a right arm to left arm configuration. however  since the manipulator and tv/laser systems are not run simultaneously in this breadboard and the tv/laser head is mounted on a pan/tilt mechanism  these sensors can be moved out of the 
way. 
       the physical dimensions of the manipulator have been modified from the original stanford design to permit a greater workspace on the ground. specifically  the a r m support post has been reduced by two inches and the extendable boom lengthened considerably. 
       the initial configuration of the robot thus provides the tools for deterministic planning of arm motion based on a priori tv/laser data with motion implementation based on feedback fronvinternal position  pot  and rate  tach  sensors. only primitive tactile feedback in the initial configuration allows for some conditional modification of plan. in subsequent configurations  proximity sensing and an adaptive terminal effector will permit more flexible and environment-responsive manipulator motion planning. in all cases  rover hardware design constrains manipulator motion by presenting a series of permanent obstacles to the arm. 
1 	trajectory planning 
       the term  trajectory  is here meant to refer to some description  partial or complete  of the path that the arm follows. 
       trajectory  planning  is the activity preceding arm motion  that is  trajectory execution   the purpose of which is to constrain or otherwise define that motion. target and environmental obstacle information are here assumed to be provided by rex and the  world model.  
       the degree to which the trajectory is to respond to external sensing during trajectory execution defines a continuum of trajectory planning. at one extreme is purely deterministic trajectory planning. any external sensing to be done is performed during the planning stage; only a catastrophe halts execution of the planned path. internal sensing is used throughout execution to maintain the adherence of actual motion to plan. deterministic planning assumes a static world during arm motion as well as sufficient a priori knowledge and execution accuracy capabilities  and limits adaptive control. towards the other extreme is conditional planning  the nature of which is highly dependent on the specific external sensors used. the benefits of conditional planning are flexibility of response and possible reduction of planning time at the possible cost of increased realtime computation requirements. 
       in the initial configuration  deterministic planning similar to that used in the stanford hand-eye project  refs. 1 and 1  is to be employed. 	reasons include the initial lack of proximity sensing  the adequacy of tv/laser a priori information in the initial simplified environment  and the fact that most of the obstacles to arm motion are  in the initial configuration  permanent obstacles known a priori and resulting from the placement of vehicle hardware. conditional planning is to be implemented and interfaced with existing deterministic planning at a later time. 
       a related distinction concerns the manner in which the trajectory plan is specified. either a sequence of a few points or the complete time history of the arm  that is  the path  can be planned. a r m motion in a constrained workspace involves path planning. 
       deterministic path planning can be performed in joint-variable space or in 1-space. in the former case  the time history of each joint is planned; it is the combination of the time histories of the joint variables that describes the motion of the arm. in the latter case  it is the motion of a particular point on the manipulator  commonly  a point on the hand  that is planned; the required joint variable time histories are derived from the plan. the advantage of planning in joint-variable space is that the plan is formulated more directly in terms of the variables to be controlled during motion. the associated disadvantage is the difficulty in determining where the various links will be during motion  a task required to guarantee avoidance of collisions with the other parts of the robot  the natural environment  or even with the arm itself. 
       constraining the fingertips to describe an elliptical arc is an example of planning in 1-space. in addition to the difficulties in finding the path described by other points on other links of the arm  there is also the problem of determining the kinematic sequence of joint variable values required to implement the plan. 
       in the stanford hand-eye project  refs. 1 and 1   the focus to date has been on deterministic path planning in joint-variable space  with some conditional planning. specifically  the time histories of the joint variables have been specified in terms of sequences of polynomials with continuity of joint variable value and its first two derivatives guaranteed at the boundary points of polynomials in the polynomial sequence. the number of polynomial segments and specified motion contraints determine the total number of coefficients required for a complete quantitative specification of joint trajectory. the jpl robot research program uses a modified version of the stanford planning algorithm. 
       fig  1a shows the time history of a joint variable described by a cubic  a quintic  and another cubic. it has been found that trajectories using polynomials of degree five or higher typically wander  as shown. this behavior appears in observation as gross extraneous motion of the arm. 
       use of a quartic-cubic-quartic trajectory reveals a somewhat different problem. as shown in fig. 1b  the desire to assure an appropriate direction of departure and approach of the terminal effector can be thwarted by the tendency of the quarticcubic-quartic trajectory to overshoot or undershoot its endpoint values. the stanford hand-eye project used both of these polynomial sequences  eliminating overshoot by special code. 
       a third polynomial sequence  five cubics  is being implemented for the jpl arm. this trajectory appears to minimize the  wander  and  overshoot  problems. typically  as in fig. 1c  there is no overshoot; wander  when it occurs  is small. 
       obstacle avoidance has been implemented for the jpl arm in two ways. 	the first method consists of the specification of an additional safe intermediate position for the joint s  most critically affecting arm motion in the sensitive direction. 	an additional 

1 

1 

1 

cubic is required for each additional intermediate 
position specified. the effect of implementing this type of obstacle avoidance is shown in the trajectory illustrated in figs. 1 and 1. fig. 1 describes joint variable motion and fig. 1 illustrates the projection of the same planned trajectories in the base coordinate system  as well as the associated total velocities. 
       as seen in fig. 1a  the task is to lift an object from the ground  from xq = 1   yo= 1   zq - -1  in the base reference frame  and deposit it on the vehicle platform at xq = 1   yo = -1   zo - 1 . the hand orientation is also specified at both end points of the trajectory. further  to aid the determination of the lift-off and terminal approach phases of the joint trajectories  two intermittent hand positions are also specified. as seen in fig- 1  joint trajectories #1 and #1 contain  respectively  1 and 1 segments due to obstacle avoidance. 
       a second method of obstacle avoidance is called the  freeway method.   precomputed safe trajectories  called  freeways   relating commonly accessed 
points are utilized in conjunction with entrance and exit  ramps  relating planned arm configurations to existing freeways. 	this freeway method is potentially useful in avoiding obstacles permanently affixed to the vehicle  such as the tv/laser head and support  the wheels and wheel motors  and the vehicle platform. 	presently  there are 1 such permanent obstacles on the jpl robot. 	the freeway method can be used more frequently if the vehicle is positioned in a predetermined standard manner with respect to objects of intended manipulation. 
       obstacle detection is performed by the relatively cumbersome method of checking for collision with all possible objects at various points along the trajectory. of course  for many obstacles  the safety of several links mast be examined. in the case of permanent obstacles  however  the invariant property of the relationship has been exploited to produce a series of increasingly complex tests. thus  in many cases  simple checks of joint variable values can assure safe motion  
1. 1 manipulator dynamics and control 
       execution planning deals with the specification of control laws and the design of control schemes whose implementation will assure that the physical motion of the arm will follow the desired motion. 
       a r m motion between distant points without prescribed continuous trajectories between the points can simply be controlled by driving each motor at some preset rate and terminating the motor drive at each joint when an appropriate signal  potentiometer or some external sensor  indicated that the joint position had reached the preset or desired terminal value  a r m trajectories planned in terms of continuous space-time coordination of joint motions  however  require that the joints be driven to comply strictly with the planned time histories of joint positions. 
       several techniques are available to build a suitable position servo for each joint drive.  see ref. 1.  an appealing computer-oriented servo technique  used in the stanford hand-eye project  is to compute the required torque or force as a function of time for each joint drive  accounting also for gear ratio  efficiency  and possible nonlinearities  and construct the joint position servo loops around 

     the dynamics of motion at the six joints of the arm is described by a coupled set of six second order nonlinear differential equations with time-varying  in fact  with state-varying  coefficients. there is no simple proportionality between torque {or force  acting at one joint and the acceleration of the same jyint when several joints are in motion simultaneously. even if only one joint moves at a given time  the proportionality between torque and acceleration is a complex function of the actual configuration of all links ahead of the moving joint and any load in the hand. the total variations in link inertias as seen at the joint drives due to changes in arm link configuration or load in the hand have been calculated for the jpl arm  ref.   1  and are shown in fig. 1. 

       in the case of simultaneous motion of several a r m joints  the effective torque  or force  acting at each joint is the sum of a number of dynamic com-
ponents: inertial acceleration of the joint; reaction torques or forces due to acceleration and velocity at other joints; gravity terms. the relative importance of the various dynamic components related to the planned motion displayed in'figs. 1 and 1 and computed for the actual kinematic and inertial parameters of the jpl robot research a r m is illustrated 
in fig- 1. to simplify the displayed variations  only motions and inertias of the first three joints are accounted for in the diagrams of fig. 1. if the speed of motion  or rather  the total lime of motion  is changed by a factor n  then the acce leration and velocity dependent torque and force-components of fig. 1 can simply be scaled by a factor n1. 
       two questions are currently investigated  ref. 1 : to what extent should the reaction components be accounted for  and in what form should the statevarying dynamic coefficients be specified to ease control scheme implementation. 
1. 1 summary 
       the integration of several robot subsystems into a functioning autonomous adaptive machine requires significant planning considerations on all system levels. the jpl robot research program is currently focused on subsystem planning and design and is in the process of implementing results in hardware and software. the manipulator itself has been manufactured and is undergoing final testing. vehicle modifications are partly completed. construction of the tv and laser systems are in progress. selection of complementary sensors and other hardware and acquisition of a realtime controller  the local computer  are underway. the design and building of the a / d and d/a interface units are also underway. development of the executive and subsystem software and the master control program have begun. the future concerns are mainly related to the implementation of subsystem execution programs  planning for subsystem interaction  and the integration of subsystems into a unified robot breadboard. 
       the outlined considerations and results related to the design of a self-contained planning algorithm for manipulator control  when the manipulator is part of a total robot system  suggest conducting further work in two directions: direct path planning in the object space; and truly adaptive manipulator control through unification of deterministic and conditional elements in the planning algorithm. 
acknowledgment 
       the preparation of the first part of the paper benefited from discussions with several members of the jpl ai working group. 
