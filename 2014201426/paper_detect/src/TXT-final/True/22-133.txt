 
incremental conceptual clustering is an important area of machine learning. it is concerned with summarizing data in a form of concept hierarchies  which will eventually ease the problem of knowledge acquisition for knowledge-based systems. in this paper we have described inc  a program that generates a hierarchy of concept descriptions incrementally. inc searches a space of classification hierarchies in both top-down and bottom-up fashion. the system was evaluated along four dimensions and tested in two domains: universities and countries. 
1. introduction 
a system described in this paper  inc  incremental 
conceptual clustering system   learns from observation by recognizing regularities among events  objects  instances  examples  etc.  and organizing them into a hierarchy of concepts. lebowitz  described learning from observation as a task that is important in domains where events arc not pre-classified  but where one still wishes to detect general rules and intelligently organize events. michalski and stepp  defined conceptual clustering as an important form of learning from observation  in which a configuration of events forms a class only if it is describable by a concept from a predefined concept class. a performance element then uses such concept descriptions to make inferences about new events based on partial information. 
hadzikadic and yun 	1      inc classifies events in the order of their appearance  thus building its knowledge base incrementally. it handles events in large numbers. in fact  the larger the number of events the better the hierarchy of concepts. in addition  inc's generalizations are pragmatic - they do not perfectly describe all the instances they cover. the concept representation mechanism implemented in inc is based on research done by rosch and mervis   who have hypothesized that the members of categories  classes  which are considered most prototypical are those with the most attributes in common with other members of the category and the least attributes in common with other categories. 
     this work was mainly influenced by work of michalski and stepp  1  1  and fisher and langley  in conceptual clustering  similar incremental conceptual clustering systems cobweb  fisher  1   unimem  lebowitz  1   and cyrus  kolodner  1   and the system developed by hadzikadic and yun  1 . 
1. system description 
     input to inc is a series of events  given to the system one at a time. the system's task is to recognize patterns of similarity among events  if they exist  and represent their generalizations in a hierarchy of non-disjoint concept descriptions  although each event is stored under one subclass only . 
1. knowledge representation 
     the evidence that prototypes play a critical role in human categorization is compelling. rosch and mervis  have demonstrated the existence of prototypes for both natural categories  like colors and animals  and artificial categories  like dot patterns and schematic drawings . inc uses a schema formalism to implement prototypical representation of events and concepts. a schema is a declarative structure that organizes pieces of knowledge  related to the same entity  into a unitary whole. a template of the schema structure is given in table 1. 
     the rel  relevance  parameter represents the frequency of attribute-value pairs found in members' descriptions. at this point  the system supports both nominal and structured attributes. the strength parameter reflects how closely an event/class resembles its superordinate class  i.e.  to what degree the event/class matches a prototypical representation of the concept. 
1.1. computing the relevance parameter 
     all attribute-value pairs from an event description participate in the concept description  once the class membership is determined. the more attribute-value pairs in the class description  the more general the description  for an event has more attribute-value combinations to 


 choose  from  match  to score above the predefined threshold and claim membership. however  the relevance of attribute-value pairs in class descriptions is generally lower than the corresponding relevance in event descriptions. thus  fewer attribute-value pairs will score above the threshold and be included in calculating the strength parameter. the relevance  rel  of an attribute-value pair  att.val  in a description of a class  c  is computed as the sum of relevances of the corresponding attribute-value pairs in member descriptions  ei    divided by the total number of members  n   i.e.  equation 1 : 

where m   n stands for the number of events ei e c with the property  att.val . 
     to improve the efficiency of the process  attributevalue pairs with a relevance below the threshold are temporarily dropped from a concept description  as long as their relevances remain low   since they do not contribute significantly to the prototypicality effect. attribute-value pairs with a relevance of 1 are true of all members of the class  thus effectively implementing the inheritance property. 
1.1. computing the strength parameter 
     once a class description has been generated and corresponding relevances calculated  the system can proceed to receive another event in order to decide whether to create a new class or place the event under one of the existing generalizations  inc computes the degree of class membership  similarity  with all top-level classes. the system first sums up the minimum of relevances for the attributes having the same value in descriptions of both the class  c  and the event  e . the resulting sum is then divided by the number of attribute-value pairs in the class description  n . this process is summarized in the following equation  1 : 

the class c and the event e  and rel x  atti val  represents the relevance of the  attival  pair in x. 
     to determine which  if any  of the existing top-level prototypical class descriptions d fa  the new event e resembles the most  the system will compute link ci  e  for i =1         n  where n stands for the number of classes under consideration. the event then belongs to the class which both maximizes the value of link and is greater than the prespecified threshold  1 in our case . the corresponding class description is subsequently updated according to equation 1. this process is then repeated for the children of a chosen class etc.  until the process reaches the leaves of the tree. 
1. operators 
     similarly to cobweb  fisher  1   there are four operators used by inc to generate a hierarchy of concepts: 
  place - place the event into an existing class. first determine the best host and then calculate the new relevances of the attribute-value pairs in the class description according to equation 1. 
  create - create a new class. a description of the new class is exactly the same as a description of the event 
  merge - merge two or more classes into one. this operator is applied when there is more than one 'best' host for the event a new class is introduced which replaces all of the best hosts. the participating classes  best hosts  are stored as subclasses of the newly created class. 
  split - split the class into two or more classes. where there is no good host for a given event  inc does not create a new class automatically. it first takes the best out of no-good hosts and evaluates its subclasses. if it finds a good host s  among them  it replaces the best of no-good hosts with its subclasses  and the process continues. 
1. algorithm 
     a control strategy implemented in inc is summarized in the following procedure. 
procedure inc event  root  
1. update a description of root with a description of event 1. compute the similarity between event and root's children. 
1. if a single best host is found  
then update its description and call inc event  besthost . 
else 

1 	machine learning 

if more than one best host is found  then 
 a  merge the best hosts and event   b  update the description of the root of the newly generated subtree  and 
 c  compute the strength of the hierarchical links. 

else 
if a good host is not found  then 
 a  evaluate  compute the similarity with  children of the best of no-good nodes  and  b  find the best host s . 
if found  then 
 a  split the best of no-good nodes into 1 classes:  1  one that contains event and the best of nogood nodes' children similar to event  and  1  a class that contains all other children of the best of no-good nodes; 
 b  update the class descriptions  and 
 c  compute the strength of hierarchical links. 
else 
 a  create a new singleton class for event  and 
 b  compute the strength of the hierarchical link. 
　　　given an event and a  root of  hierarchy that summarizes previously seen events  inc first updates a description of the root with a description of the event  and then computes the similarity  according to equation 1  between the event and all the children  subclasses  of the root. if there is only one class  best host  similar to the event  scoring above the s threshold - set to 1   then inc updates the best host's description and invokes the same procedure recursively  with the root being replaced by the best host. in general  the system will try to  push  an event down the tree as far as possible in order to place it in the most specific subclass. 
　　　if there is more than one best host for the event  inc replaces them  along with the event  with a new generalized class  generates its description  creates the links  pointers  from the best hosts as well as the event to the newly generated class and computes their strengths  thus effectively merging them into the same class. when discovering best hosts  the system requires that only the most similar class  scores  above the s threshold. all other best hosts need to be within e %  e is another threshold in the system  of the most similar class  with respect to its degree of similarity to the event. we have been experimenting with several values for the e threshold in 1 range. the optimal value depends on the values assigned to other thresholds in the system. the value we used most often for the e threshold was 1  actually implemented as 1 . 
　　　however  if a good host is not found  then the system computes the similarity between the event and the children of the best of  no-good  nodes and tries again to establish the best host s . if the effort is successful  then the best of no-good nodes is split into two classes. first class will contain the event and the best of no-good nodes' children similar  enough  to the event second class will be comprised of the rest of the children of the best of no-good nodes. the class descriptions are then updated and the strength of the hierarchical links computed. 
　　　finally  if a best host was still not found  then inc creates a new singleton class  for the event  and computes the strength of the link to the superordinate class. 
　　　in general  inc carries out a hill-climbing search through a space of hierarchical classification schemes. the system uses operators that let it search in both directions  place and create vs. merge and split . the merge and split operators provide the system with a form of backtracking to help it  correct  some of the earlier mistakes. the events are stored under generalizations that describe them best although an event can be stored under only one generalization  it may match descriptions of two or more concepts  thus introducing a possibility for multiple membership. the resulting concept hierarchy is used by the performance system to make inferences about new  previously unseen events. 
1. experiments 
　　　inc was implemented in common lisp and evaluated on sun workstations. it has been tested in two domains: countries and universities. the domain of universities will be described in this paper in greater detail. the following attributes were used in descriptions of 1 universities1: state  location  control  no-of-students-thous  male/female  student/faculty  sat-verbal  sat-math  expenses-thous  percent-financial-aid  no-applicant-thous  percent-admittance  percent-enrolled  academics-env  social-env  quality-of-life  and academic-emphasis. not all attributes had to be defined in an event description. the relevance of an attribute-value pair in the event description was presumed to be 1  which was consistent with our assumption that an event represents a singleton class. 
1. evaluating the system 
　　　we have used four dimensions to evaluate a performance of the system. the first dimension covers the effect of varying the values of the three thresholds defined in the system: $  e and d thresholds. different distributions of threshold values yields  somewhat  different concept hierarchies. 
　　　the second dimension is defined as the time needed to insert a new event into an existing hierarchy. it is evaluated with respect to the number of instances presented to the system prior to the current event. 
　　　the third dimension used to evaluate the system's performance is defined as the time needed to retrieve a  correct  concept for a given event  as well as the percentage of correct retrievals with respect to the number of total attempts. 
　　　finally  the forth dimension is defined as the percentage of correct classifications of  unseen  events given an existing hierarchy of concepts  thus effectively implement-

ing a performance component of the system. 
1. varying the threshold values 
     initially  we adopted the following values for the three thresholds defined in the system: s =1  e =1  d =1. it meant that: 
 a  in order to be similar to a concept  an event had to match at least half of the attribute-value pairs used in the concept description  or any combination of them resulting in a cumulative score of at least 1  1 being a maximum  =  s threshold. 
 b  an event was declared similar to more than one concept if the degrees of similarity between those concepts and the event did not differ from the highest degree of similarity  max   achieved between the event and one of the concepts under consideration  for more than 1% of max =  e threshold. 
 c  attribute-value pairs with a relevance below 1 in a concept description were not taken into consideration when computing the degree of similarity between an event and the concept =  d threshold. however  these attribute-value pairs were considered during the process of updating the concept description. 
     in order to evaluate the effect of varying threshold values on the resulting classification  we fixed the value for s threshold and vary the s and d thresholds in 1.1 range. two interesting conclusions were drawn from this experiment* 
 1  distributions {s =1  e =1  d =1} and {s =1  e =1  d =1 have produced identical hierarchies  although they have differed in the amount of time needed to complete the classification process. it seems that changes in the value of e threshold can compensate for some changes in d threshold values. at the same time  those hierarchies were the simplest ones of all - they contained fewest number of classes. 
 1  for some values of e threshold  e.g.  1   varying d threshold values did not make any difference. an explanation may be that if the value of e threshold is conservative  then infrequent attribute-value pairs do not contribute significantly to a resulting hierarchy. the situation  however  changed after we relaxed the value of e threshold to 1 or 1. 
1. efficiency considerations 
     a representative of the hierarchies containing the fewest number of classes  1  was then evaluated in terms of its computational efficiency. the results are summarized in column 1 of table 1. column e defines a position of an event in a sequence of events. the headings of other columns in the table include information about the values for the s  e  and d thresholds  respectively. the values pro-

     the values given in column 1 are obtained as a result of considering all attribute-value pairs of all concepts on the path to the most specific subclass similar to an event pairs with a relevance lower than d threshold are evaluated but not taken into consideration when computing the degree of similarity. to determine the rate of speed-up achieved by completely removing attribute-value pairs with a relevance below d threshold from a concept description  we have modified the system accordingly and tested it for the same threshold values. the results of the testing are provided in column 1 of table 1. it is obvious that the gain in efficiency is significant however  the modified system will not perform well in situations where the external world is characterized by constant changes and transitions. a more adaptive system may be warranted in such circumstances. 
column 1 represents an example of a hierarchy with 
1 classes. that example proved to be the most efficient classification tree. in general  a larger number of classes means both fewer merge operations and shorter paths  which improves the efficiency of the classification hierarchy. consequently  there is a trade-off between two contradictory requirements: a smaller number of classes vs. reduced processing time. 
1. concept retrieval 
     the third and fourth dimensions are introduced to evaluate both the quality and the efficiency of generated concept descriptions. this section is concerned with evaluating the quality of concept descriptions through the number of correct retrievals  and evaluating the efficiency of a concept hierarchy through the time needed to retrieve given events/concepts. 
     the two best hierarchies from the previous section were taken as a basis for this phase of the evaluation process  and consequently compared according to the obtained results. we used all the events that participated in generating the two hierarchies to retrieve the most similar 

1 	machine learning 

concept/event stored in the hierarchy. ideally  we would like to see an event retrieve  itself. however  since the basis of our approach is a prototypical representation of concepts  other members of the class may change the concept description significantly  thus causing the event under consideration to appear not so  prototypical  of the concept under which it is stored. that will prevent the system to retrieve the correct event/concept in certain situations. also  it is possible that the system retrieves the correct concept  but decides not to consider its instances if the degree of similarity between the event and the concept is below the threshold  1 . the results of this phase of the evaluation process arc summarized in table 1. 

     it is obvious that the {s=1  e=1  d=1} hierarchy consists of higher quality concept descriptions that summarize given events better than the other classification being evaluated. the 1% retrieval accuracy  vs. 1% for the other case  or 1% -- both correct instance and correct concept retrievals included  more than compensates for the 1% increase in retrieval time  1 vs. 1 milliseconds . 
     at this point  it is safe to conclude that our original evaluation criterion  which favors hierarchies with fewer classes  contradicts the criterion that favors concepts of higher quality. this introduces another trade-off which needs to be taken into consideration when implementing the system in a particular domain. 
1. classifying unseen events 
     classifying unseen events is an inherently subjective procedure since the proper classification depends on the perception  goals  and relevant knowledge of the observer. to reduce this subjectiveness as much as possible  we have decided to introduce the following scenario:  a  take the best hierarchy generated so far as a referent hierarchy;  b  take at least half of the events that have participated in generating the referent classification and run the system again with those events as the input;  c  use the rest of the events  nonclassified ones  to retrieve the most similar instances/concepts; and  d  compare retrieved instances/concepts with the events' intended concepts  as defined by the referent hierarchy. 
     the scenario outlined above was implemented in the following way: the {s =1  e=1  d=1} hierarchy was accepted as a referent classification  1 events were used to generate a new hierarchy  and the other 1 events were used as unseen instances. we have again distinguished between two cases: retrieving a concept and retrieving an instance of a concept. ideally  the system will retrieve a concept  given an event that is an instance of the concept. however  sometimes a concept has not been created  and the system will retrieve another event  a singleton class  most similar to the input event these cases arc potentially correct classifications since the retrieved event either belongs to the same concept as the input event  in the referent hierarchy  or it would have belonged to the same concept had there not been other events to alter the prototypical description of the concept before the retrieved event was presented to the system. 
     as a result  the system correctly classified 1% of the input events  1% correct and 1% potentially correct classifications   while misclassifying only 1% of them. 
1. related work 
     three incremental concept formation systems cobweb  fisher  1   unimem  lebowitz  1   and 
cyrus  kolodner  1  - have influenced our approach to conceptual clustering. cobweb  fisher  1  constructs a concept hierarchy from the top down to summarize instances described as sets of features. the system modifies its concept descriptions and hierarchy as it classifies each instance. cobweb employs probabilistic representations and an explicit evaluation function  category utility  to determine optimal clusterings. unimem  lebowitz  1  is also an incremental conceptual clustering system. its search through a space of hierarchies can be described as hill climbing. the system does not build its hierarchies in an entirely top-down or bottom-up fashion - it has operators for merging and deleting nodes and associated subtrees. the cyrus system  kolodner  1  makes use of domain knowledge to determine which elements of instances can best serve as discriminants among concepts  thus avoiding combinatorial explosions in retrieval and concept formation. 
     inc differs from the three systems mentioned above in several aspects: knowledge representation formalism  type of attributes supported  definition of operators used by the search procedure  clustering evaluation mechanism  and similarity function. the naturalness  flexibility  and simplicity of both the knowledge representation formalism and similarity function provide inc with a powerful mechanism for dealing with incomplete and inconsistent event descriptions: attributes and their values are not predefined  multiple values are allowed  some attributes may be missing  some incorrect values may be specified  etc. the relevance mechanism  similarity function  and control knowledge will eventually cause noisy attribute-value pairs to disappear from a concept description  as well as the  correct  pattern to emerge in the form of a cluster and its description. at the same time  the simplicity of computing the similarity function greatly improves the efficiency of the system. the efficiency can be increased even more by raising the value of d threshold. on the other hand  the greater the value of d 
	hadzikadic and yun 	1 

threshold  the lower the quality of the concept description. consequently  there is a limit to the degree of improvement that can be achieved by manipulating the value of the threshold. 
     however  inc pays the price for this simplicity of the similarity function: descriptions of a class and its subclasses significantly overlap  thus wasting a potentially significant amount of memory. this is especially true in the case of inherited properties  the ones with the relevance of 
1 . 
1. research issues 
     there are several important directions in which this work can be extended. currently  we are working on incorporating a gdn-like structure  goal dependency network  stepp and michalski  1   into the system. also  we are adding information about the context of the problemsolving task as well. the information about a goal and a context of classification will help the system determine relevant attributes for discriminating among candidate concepts  both in retrieval and clustering processes. the final result will be of higher quality and more useful to the performance element. in addition  the goal and context information may help the system determine the value of e threshold. when crisp and well-specified classes are sought  the threshold value should be low and  vice versa  a high value of e threshold will encourage largely overlapping classes. 
     a well-defined similarity function is a key to a successful classification. the similarity function defined in this paper is a simple one  and certainly can be improved. future research will pay considerable attention to that problem. 
     people often generate non-disjoint concepts. although somewhat imprecise  those concepts offer flexibility in dealing with a complex external world. inc creates non-disjoint concept descriptions  an event description can match several concept descriptions   but it stores an event under only one concept. however  inc can easily be updated to store multiple copies of an event when appropriate by modifying the merge procedure. we are planning to explore and carefully evaluate this possibility as well. 
1. conclusion 
     incremental  concept formation is an important area of machine learning. it is concerned with summarizing realworld information in a form of concept hierarchies  which will eventually ease the problem of knowledge acquisition for knowledge-based systems. in this paper we have described inc  a program that generates a hierarchy of concept descriptions incrementally. the system searches a space of classification hierarchies in both top-down and bottom-up fashion. we have evaluated inc along four dimensions: the effect of varying threshold values  the cost of inserting a new event into an existing hierarchy  the accuracy and cost of concept retrieval  and the success rate 
	1 	machine learning 
in classifying unseen events. the system was tested in two domains: countries and universities. we feel that inc represents a promising step toward systems that will be capable of constructing  maintaining  and refining a knowledge base automatically. 
acknowledgments 
     we thank m. lebowitz for kindly supplying the experimental data used to evaluate the inc system. 
