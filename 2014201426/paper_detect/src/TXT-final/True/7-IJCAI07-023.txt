
the task of learning models for many real-world problems requires incorporating domain knowledge into learning algorithms  to enable accurate learning from a realistic volume of training data. domain knowledge can come in many forms. for example  expert knowledge about the relevance of variables relative to a certain problem can help perform better feature selection. domain knowledge about the conditional independence relationships among variables can help learning of the bayesian network structure.
this paper considers a different type of domain knowledge for constraining parameter estimates when learning bayesian networks. in particular  we consider domain knowledge that comes in the form of inequality constraints among subsets of parameters in a bayesian network with known structure. these parameter constraints are incorporated into learning proceduresfor bayesian networks  by formulating this task as a constrained optimization problem. the main contribution of this paper is the derivation of closed form maximum likelihood parameter estimators in the above setting.
1 introduction
probabilistic models have become increasingly popular in the last decade because of their ability to capture nondeterministic relationships among variables describing many real world domains. among these models  bayesian networks  heckerman  1  have received significant attention because of their ability to compactly encode conditional independence assumptions over random variables and because of the development of effective algorithms for inference and learning based on these representations. a bayesian network consists of two components: a structure  which encodes the assumption that a variable is conditionally independent of its non-descendantsin the network  given the value of its parents  and a set of parameters  which describe how each variable relates probabilistically to its parents. a bayesian network encodes a unique joint probability distribution  which can be easily computed using the chain rule.
모when learning bayesian networks  the correctness of the learned network of course depends on the amount of training data available. when training data is scarce  it is useful to employ various forms of prior knowledgeabout the domain to improve the accuracy of learned models. for example  a domain expert might provide prior knowledge specifying conditional independencies among variables  constraining or even fully specifying the network structure of the bayesian network. in addition to helping specify the network structure  the domain expert might also provide prior knowledge about the values of certain parameters in the conditional probability tables  cpts  of the network  or knowledge in the form of prior distributions over these parameters. while previous research has examined a number of approaches to representing and utilizing prior knowledge about bayesian network parameters  the type of prior knowledge that can be utilized by current learning methods remains limited  and is insufficient to capture many types of knowledge that may be readily available from experts.
모the main contribution of our paper consists of deriving closed form maximum likelihood estimators for the parameters in a bayesian network  in the setting that expert domain knowledgeis available in the form of parameterinequality constraints  which current methods can not accommodate. with our estimators comes a theorem that describes the performancein the case when the domain knowledgerepresented by the inequality constraints might not be entirely accurate.
모the next section of the paper describes related research on constraining parameter estimates for bayesian networks. section 1 presents the task of parameter estimation in the presence of general parameter constraints and formulates it as a constrained optimization problem. section 1 details the main contribution of this paper: closed form solutions for parameter estimates for several classes of parameter inequality constraints. some formal guarantees about our estimators are discussed in section 1. we conclude with a brief summary of this research along with several directions for future work.
1 related work
the main methods to represent relationships among parameters of a bayesian network fall into two main categories: dirichlet priors and their variants  including smoothing techniques  and parameter sharing of several kinds.
모in  geiger and heckerman  1   it is shown that dirichlet priors are the only possible priors for discrete bayesian networks  provided certain assumptions hold. one can think of a dirichlet prior as an expert's guess for the parameters in a discrete bayesian network  allowing room for some variance around the guess. one of the main problems with dirichlet priors and related models is that it is impossible to represent even simple equality constraints between parameters  for example the constraint: 붿1 = 붿1 where 붿ijk = p xi = xij|parents xi  = paik   without using priors on the hyperparameters of the dirichelet prior  in which case the marginal likelihood can no longer be computed in closed form  and expensiveapproximatemethods are required to perform parameter estimation. a second problem is that it is often beyond the expert's ability to specify a full dirichlet prior over the parameters of a bayesian network.
모a widely used form of parameter constraints employed by bayesian networks is parameter sharing. models using different types of parameter sharing include: dynamic bayesian networks  murphy  1  and their special case hidden markov models  rabiner  1   module networks  segal et al.  1   context specific independence models  boutilier et al.  1  such as bayesian multinetworks  recursive multinetworks and dynamic multinetworks  geiger and heckerman  1; pena et al.  1; bilmes  1   probabilistic relational models  friedman et al.  1   object oriented bayes nets  koller and pfeffer  1   kalman filters  welch and bishop  1  and bilinear models  tenenbaum and freeman  1 . parameter sharing methods constrain parameters to share the same value  but do not capture more complicated constraints among parameters such as inequality constraints or constraints on sums of parameter values. the above methods are restricted to sharing parameters at either the level of sharing a conditional probability table  cpt   module networks  hmms   at the level of sharing a conditional probability distribution within a single cpt  context specific independence   at the level of sharing a state-to-state transition matrix  kalman filters  or at the level of sharing a style matrix  bilinear models . none of the above models allow sharing at the level of granularity of individual parameters.  niculescu et al.  1  introduces a parameter equality constraint framework that describes many models that use parameter sharing: module networks  context specific independence models  hmms and dynamic bayesian networks. within this framework  it is showed how efficient parameter learning is performed from both a frequentist and bayesian point of view  from both observable and partially observable data.
모all the models described so far can only take advantage of certain types of parameter equality constraints. only recently   altendorf et al.  1; feelders and van der gaag  1  study the feasibility of incorporating simple inequality constraints in the learning of parameters of bayesian networks. the constraints analyzed in these papers are somehow restrictive  in the sense that each constraint must involve all parameters in a conditional probability table  whereas our framework allows for constraints at individual distribution level of granularity. additionally  in  altendorf et al.  1   the authors employ an approximation algorithm  whereas we derive exact estimators. further   altendorf et al.  1  assumes the values of the variables can be totally ordered and  feelders and van der gaag  1  assumes all variables are binary. our framework makes none of these assumptions. in the next section we will place parameter learning with inequality constraints in a general constrained optimization framework and we will show how closed form learning of the parameters of bayesian networks can be performedwhen expertknowledge is available in the form of either of two types of parameter inequality constraints.
1 problem definition and approach
here we define the problem and suggest a general optimization based approach to solve it. this approach has serious limitations when the constraints are arbitrary. however  it constitutes the basis for computing the maximum likelihood estimators for the classes of inequality constraints described in section 1. we begin by describing the problem along with several assumptions.
1 the problem
our task here is to perform parameter estimation in a bayesian network where the structure is known in advance. to accomplish this task  we assume a dataset of examples is available. in addition  a set of parameter equality and/or inequality constraints is provided by a domain expert. the equality constraints are of the form gi 붿  = 1 for 1 뫞 i 뫞 m and the inequality constraints are of the form hj 붿  뫞 1 for 1 뫞 j 뫞 k  where 붿 represents the set of parameters of the bayesian network.
모initially we will assume the domain knowledge provided by the expert is correct. later  we investigate what happens if this knowledge is not completely accurate. next we enumerate several assumptions that must be satisfied for our methods to work. these are similar to common assumptions made when learning parameters in standard bayesian networks.
모first  we assume that the examples in the training dataset are drawn independently from the underlying distribution. in other words  examples are conditionally independent given the parameters of the bayesian network. second  we assume that all the variables in the bayesian network can take on at least two different values. this is a safe assumption since there is no uncertainty in a random variable with only one possible value. any such variables in our bayesian network can be deleted  along with all arcs into and out of the nodes corresponding to those variables. third  when computing parameter estimators  we additionally assume that all observed counts corresponding to parameters in the bayesian network are strictly positive. we enforce this condition in order to avoid potential divisions by zero  which may impact inference negatively. in the real world it is expected there will be observed counts which are zero. this problem can be solved by using priors on parameters  that essentially have the effect of adding a positive quantity to the observed counts and essentially create strictly positive virtual counts.
모finally  the functions g1 ... gm and h1 ... hk must be twice differentiable  with continuoussecond derivatives. this assumption justifies the formulation of our problem as a constrained maximization problem that can be solved using standard optimization methods.
1 a general approach
in order to solve the problem described above  here we briefly suggest an approach based on already existing optimization techniques. the idea is to formulate our problem as a constrained maximization problem where the objective function is the data log-likelihood logp d|붿  and the constraints are given by gi 붿  = 1 for 1 뫞 i 뫞 m and hj 붿  뫞 1 for 1 뫞 j 뫞 k. it is easy to see that  applying the karushkuhn-tucker conditions theorem  kuhn and tucker  1   the maximum must satisfy a system with the same number of equations as variables. to solve this system  one can use any of several already existing methods  for example the newtonraphson method  press et al.  1  .
모it is well known that finding a solution for the system given by the kkt conditions is not enough to determine the optimum point  but fortunately the objective function is concave and most of the constraints we have encountered in real life are linear equalities or inequalities. therefore several well known sufficiency criteria can guarantee optimality.
모unfortunately  the above methods have serious shortcomings in the general case. with a large number of parameters in the bayesian network  they can be extremely expensive because they involve potentially multiple runs of the newtonraphson method and each such run requires several expensive matrix inversions. other methods for finding the solutions of a system of equations can be employed  but  as noted in  press et al.  1   all these methods have limitations in the case when the constraints are arbitrary  non-linear functions. the worst case happens when there exists a constraint that explicitly uses all parameters in the bayesian network.
모the above method should be regarded as a mere suggestion and  because of its shortcomings  we believe it is not computationally feasible with arbitrary constraints. we mentioned it here only to show how learning in the presence of parameter constraints can be formulated as a general constrained maximization problem. this general approach also provides the starting point for finding closed form maximum likelihood estimators given the particular classes of parameter inequality constraints presented in the next section.
1 learning with inequality constraints
in this section we derive closed form maximum likelihood estimators for the parameters in a discrete bayesian network with known structure when domain knowledge is provided as either of the two types of inequality constraints.
1 inequalities between sums of parameters
briefly  this type of parameter domain knowledge states that the sum of several parameters within one conditional probability distribution is bounded by the sum of other parameters in the same distribution of the bayesian network. intuitively  one can think of this constraint in terms of the parts of speech of a language. usually  an adverb comes along with a verb and therefore it is reasonable to assume that a language expert can specify that the aggregate probability mass of adverbs is no greater than the aggregate probability mass of the verbs in a given language. formally  in this type of domain knowledge  the parameters of a conditional probability distribution  denoted by 붿1 ... 붿n  can be partitioned into s	s
for all 1 뫞 k 뫞 s. let us denote by nak the sum of the observed counts corresponding to parameters in ak. similar definitions hold for nbk and nc. let n be the sum of all observed counts ni corresponding to parameters 붿.
모an expert can potentially specify different such constraints for several conditional probability distributions in the bayesian network. because of the decomposability of loglikelihood  the problem of computing the maximum likelihood parameter estimators can be decomposed in a set of independent optimization subproblems  one for each conditional probability distribution in the network. we have the following theorem:
theorem 1. if all ni are strictly positive  the maximum likelihood estimators of parameters 붿 are given by:
a 
b   and nak 뫟 nbk
c   and nak   nbk
d 
proof. finding maximum likelihood estimators is equivalent to maximizing subject to the domain knowledge constraints  including the constraint that
. since this problem contains in-
equality constraints  we can attempt to solve it using karushkuhn-tucker theorem. we introduce the lagrange multiplier 뷂 for g and 뷃k for inequality constraint
. the optimum붿 can then be found among the solutions of the system:

from the first equation we obtain:

therefore  and .
based on whether constraint k is tight or not we have:
  if hk 붿   = 1  then. this implies
 and therefore 
nak+nbk
모모뷂 . in this case  we also have 뷂몫 nak  nbk  = 뷃k 몫  nak + nbk . since 뷃k 뫟 1  we also must have nak 뫟 nbk in order for constraint k to be tight.
  if hk 붿     1  then 뷃k = 1 and therefore we again have
. in this case we also have  and since hk 붿     1  we must also
have nak   nbk.
모the above observations allow us to conclude that a constraint is tight if and only if nak 뫟 nbk. now  summing up over all parameters in the conditional probability distribution we get:

this gives us: 뷂 = n and therefore:

모assume now that nak 뫟 nbk. according to the observations above  it means constraint k is tight and we have:
. from this we immediately
derive:  if 붿i 뫍 ak and nak 뫟 nbk and.
모if nak   nbk  then  as discussed above  뷃k must be 1 and therefore and nak   nbk.
because the log-likelihood objective function is concave and because the constraints are linear inequalities  it follows that 붿  is the set of maximum likelihood estimators. this concludes the proof of our theorem.	
1 upper bounds on sums of parameters
here the domain expert provides upper bounds on the sum of several parameters within one conditional probability distribution in the bayesian network. consider the same language example described in the introduction of the previous subsection. here the expert may state that the aggregate probability of nouns is no greater than 1  the aggregate probability of verbs is no greater than 1 and the aggregate probability of adjectives is no greater than 1. even though the combined probability mass of all words equals one  the sum of the upper bounds provided by the expert can be greater than one. formally  in this type of domain knowledge  the parameters of a conditional probability distribution  denoted by 붿1 ... 붿n  can be partitioned insuch that for all 1 뫞 k 뫞 s  where 붸k is a given positive constant. again  denote by nak the sum of the observed counts corresponding to parameters in ak and by n be the sum of all observed counts ni corresponding to parameters 붿. if there are parameters not involved in any of these constraints  then we can consider they belong to their own set ak with 붸k = 1. in the previous subsection we found an easy way to decide whether a constraint is tight at the optimum point. for the type of constraints we deal with here  we are not able to derive such a simple criterion. however  we show a simple  linear algorithm that computes the set of tight constraints at the optimum point. this algorithm starts with an empty set and at each step adds one of the final tight constraints.
모again  an expert can specify different sets of such constraints for different conditional probability distributions in the network and  because of the decomposability of loglikelihood  we can decompose the task of finding the maximum likelihood estimators into a set of independent optimization subproblems:
theorem 1. assume all observed counts ni are strictly positive and also assume we know the set k = {k1 ... kl} of constraints that are tight at the point given by the maximum likelihood estimators 붿 . then  we have:
a  and k 뫍 k
 and
proof. we can approach the problem of finding the maximum likelihood estimators in a similar fashion as in theorem 1. the data log-likelihood is given by log붿i which we have to maximize with respect to the domain knowledge constraints  including the constraint that
. again  we use karush-kuhn-tucker
theorem. we introduce the lagrange multiplier 뷂 for g and 뷃k for inequality constraint .
the optimum 붿  can then be found among the solutions of the system:

from the first equation we obtain:

모therefore . based on whether constraint k is tight or not we have:
  if hk 붿   = 1 i.e. k 뫍 k  then. this implies
붿 i = 뷂+n뷃ik = 붸k 몫 nnaik .
  then 뷃k = 1 and therefore we have.
모summing up over all parameters not involved in the tight constraints  we get:

we obtain  and further: 붿 i =  1  
 and. because the log-likelihood objective function is concave and because the constraints are linear inequalities  it follows that 붿  is the set of maximum likelihood estimators. this concludes our derivation of the maximum likelihood estimators when we know in advance which constraints are satisfied by our estimators.	
모next we describe the algorithm that finds the set k of tight constraints:
algorithm 1.  finding the set of tight constraints if

step 1. start with k =   and at each step add a constraint to k.
step 1. if as in the above theorem.
step 1. if there existssuch that  let
k = k 뫋 {kl+1} and go to step 1. otherwise stop and declare k the set of tight constraints.
proof.  correctness of algorithm  we start by making the following observation  based on the proof of theorem 1:
  if hk tight  then. because 뷃k 뫟 1  we must have.
  if hk not tight  then 뷃k = 1 and therefore we have 1   and therefore we must have
뷂. it is obvious that 뷂 뫟 1 must hold  otherwise we would have negative parameters.
모we have just developed a criterion to test if a set k of constraints is the set of tight constraints:
lemma 1. given 뷂  which depends on k  computed as in
theorem 1  k is the set of tight constraints if and only if for all k 뫍 k and for all.
모before proving that our algorithm produces the set of tight constraints  let us prove another useful result:
lemma 1. if then n = 뷂1 뫟 뷂1 뫟 ...  and the quantity  is always strictly positive.
proof.  of lemma  since initially k =    it is obvious that
. it is also obvious 뷂1 = n. let us verify
the induction step.
from  and because  we get:
	 1 
모it follows  with equality if and only if we processed all constraints  in which case we have  and it is obvious that all constraints must be tight. however  since we assumed  we must have  and the first part of the induction step
is proved.
   if in both sides of inequality 1 we add the quantity  1     we obtain:

which  given that   is equivalent to 뷂l 뫟 뷂l+1. this concludes the proof of our lemma. 
applying lemma 1  it follows that  in the case when
  the algorithm 1 ends at a step l such that
 for all kj 뫍 k and  for all
. from lemma 1 it follows that k is the set of tight constraints in the case when and therefore algorithm 1 is correct. another case is when all constraints are processed and we are not left with a 뷂l to compare with. this situation can not happen  because  at the last step  we would have:

and therefore either. in the second case  the constraints are contradictory  which can not happen because we assume the domain expert provides accurate domain knowledge. if  case which is not covered by algorithm 1   it is obvious that the all constraints must be tight not only for the maximum likelihood estimators  but for every feasible value of 붿.	
1 formal guarantees
sometimes it may happen that the constraints provided by an expert are not completely accurate. in all our methods so far  we assumed that the constraints are correct and therefore errors in domain knowledge can prove detrimental to the performanceof our learned models. in this section we investigate the relationship between the true  underlying distribution of the observed data and the distribution estimated using our methods based on inequality constraints. because of space reasons  we omit the proofs for the theorem and the corollary presented in this section.
모suppose p is the true distribution from which data is sampled. let p  be the the closest distribution to p in terms of kl p 몫   that factorizes according to the given structure and obeys the expert's inequality constraints. we have:
theorem 1. with an infinite amount of data  the distribution p  given by the maximum likelihood estimators in theorem 1 converges to p  with probability 1.
corollary 1. if the true distribution p factorizes according to the given structure and if the parameter inequality constraints provided by the expert are completely accurate  then the distribution p  given by the estimators computed in theorem 1 converges to p with probability 1.
모similar results hold for the inequality constraints described in subsection 1.
1 conclusions and future work
building accurate models from limited training data is possible only by using some form of prior knowledge to augment the data. prior knowledge in the form of parameter equality constraints has been incorporated in learning of several bayesian network models  including module networks  hmms and context specific independence models.
모in this paper we have demonstrated that the standard methods for parameter estimation in bayesian networks can be naturally extended to accommodate parameter inequality constraints by formulating this as a constrained maximization problem and deriving closed form maximum likelihood parameter estimators. it is also important to note that one can combinethe two types of parameterinequality constraints presented in this paper as well as the parameter sharing constraints described in section 1 when learning the parameters of a bayesian network as long as the scopes of these constraints do not overlap.
모we have provedthat even when the asserted parameterconstraints turn out to be incorrect  given an infinite amount of training data  our maximum likelihood estimators converge to the best describable distribution; that is  the distribution closest in terms of kl distance from the true distribution  among all distributions that obey the parameter inequality constraints and factor according to the given structure.
모we see several useful directions for future work. first  we would like to prove that by incorporating the inequality constraints given by an expert we compute estimators with lower variance than the ones obtained by simply learning the bayesian network directly from the data. a second direction to explore is to approach learning from a bayesian  as opposed to a frequentist  point of view. this might be achieved by specifying constrained dirichlet priors which assign zero probability mass over the space where the constraints are not satisfied. however  it is a challenge to compute the normalization constant of such distributions in closed form.
acknowledgments
we would like to thank john lafferty  andrew moore  russ greiner and zoubin ghahramani for their useful comments and suggestions. as a student at carnegie mellon university  radu stefan niculescu was sponsored by the nsf grants ccr-1 and ccr-1  by the darpa pal program under contract nbcd1  and by a generous gift from siemens medical solutions.
