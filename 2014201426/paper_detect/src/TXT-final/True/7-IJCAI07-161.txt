
we present a proactive communication approach that allows cbr agents to gauge the strengths and weaknesses of other cbr agents. the communication protocol allows cbr agents to learn from communicating with other cbr agents in such a way that each agent is able to retain certain cases provided by other agents that are able to improve their individual performance  without need to disclose all the contents of each case base . the selection and retention of cases is modeled as a case bartering process  where each individual cbr agent autonomously decides which cases offers for bartering and which offered barters accepts. experimental evaluations show that the sum of all these individual decisions result in a clear improvement in individual cbr agent performance with only a moderate increase of individual case bases.
1 introduction
distributed case-based reasoning  cbr  aims at studying and applying cbr techniques for situations where distributed resources are present  plaza and mcginty  1 . current approaches range from one cbr agent using several case bases  leake and sooriamurthi  1   or several agents using one case base  to multiple agents having individual case bases  plaza and ontan on  1뫣    and applications span from classification  plaza and ontan on  1뫣   and planning  mcginty and smyth  1  to engineering applications  watson and gardingen  1 .
모our goal in this paper is studying learning opportunities derived from communication among different cbr agents possessing individual case bases. communication among agents offers the possibility of using the other agents as an additional source of information. typically  a cbr system learns by retaining the cases they solve during the retain stage  aamodt and plaza  1 . the presence of cases owned by other cbr agents presents the opportunity of acquiring some of those cases to improve an individual cbr agent performance.
모an alternative approach might be to centralize all data. however  there are several reasons for not following this path always  i.e. centralization is feasible and efficient on some situations but not on others . first  since we assume data distributed over several sites  each with a case base ci   centralization means basically sending all data to everyone's site. in this way  every cbr agent will have all known cases on its case base  c = c1뫋 ... 뫋 cn ; this scenario is simple but hardly efficient nor scalable  and may be unfeasible in situations where the different sites would agree to partially disclose some data but not all data all the time.
모however  simply having more cases does not assure better cbr performance  smyth and keane  1   and we need to use case base maintenance techniques or retain policies to select the subset of cases that improves cbr performance  lopez de m뫣 antaras뫣 et al.  1 . thus  when using the centralized approach  after receiving all cases from the other agents each agent will proceed to purge its individual case base to obtain an individual reduced case base cr   c. in fact  a cbr agent ai would have only needed to acquire the the cases in the set cr   ci to achieve this situation. therefore  all that is needed is for ai to acquire from the other agents a subset of cases  cr   ci or a similar one  such that allows a real improvement of ai's individual performance.
모therefore  a more intelligent strategy is to find a subset of cases to be acquired from the other agents that is equivalent  for the purposes of improving a cbr agent performance  to the cr   ci set. our proposal is developing a distributed and decentralized strategy that achieves exactly this effect: instead of a centralized process we propose a protocol of cooperation  that respects the agents autonomy of decision  based on communication and bartering. this approach is also feasible in situations where the different agents involved are willing to share only part of their data  a situation where the centralized approach is not feasible.
모communication may allow the agents to discover how they can help one another. however  we need to define which kind of communication protocol is needed to facilitate the agents discovering which part of their respective data should be exchanged and with whom - without recourse to simply disclosing and transferring all data to all agents. the next section  뫫1  presents our proposal for a communication process aimed at discovering the individual informational deficits and the possible sources to overcome them.
모case bartering provides an equitable and practical way to reach agreements on what they effectively share once the individual information deficits and the possible sources to overcome them have been identified. section 1 presents an interaction protocol for case bartering and an individual policy for the agents to decide on the contents of each barter exchange. an experimental evaluation is discussed in section 1  and the paper ends with a conclusions section.
1 learning from communication
centralized cbr only considers learning from the problems the cbr system solves  i.e. the retain stage only considers the cases  owned  by the system. in a distributed cbr scenario  however  a cbr agent may learn from the cases solved by another agent. for this purpose  it is necessary to define a way to determine which cases of other cbr agents are of interest for an individual cbr agent to retain in addition to those it has already in the case base. in this paper we consider that the cases of interest are those that if present in an individual case base would improve the individual performance of that cbr agent. in this section we will present the process of communication  for information exchange  and bartering  for case exchange  proposed for improving the individual performance of cbr agents.
모previously  ontan on and plaza뫣  used case bartering to improve performance in multiagent case-based reasoning. however  their goal is that of improving performance for situations where the individual case bases were biased  when the contents of an individual case base is not a good sample of all cases it is said to be biased . in this approach  the communication process was simple and efficient: the only exchanged information that were class-distribution statistic data that indicated which agents have more  or respectively less  cases of a particular class than the average  information that is then used to barter cases of a specific class from agents that have more than average to those that have less than average. therefore  ontan on and plaza뫣  did not address the issue of improving a cbr agent performance in general circumstances  since in the absence of bias no bartering would take place.
모in order to enrich the communication process we will use the notion of justified prediction  introduced at  ontan on and뫣 plaza  1  as a useful tool for multiagent learning. using justified predictions  an agent communicates to another agent not just the solution of a given problem  the prediction  but also a symbolic description of the aspects that were important in determining the solution for that problem. figure 1 shows a graphical representation of the justification given by a cbr agent in the domain of marine sponges identification  used later in 뫫1 . this justification means:  the problem p belongs to the class hadromerida because it has no gemmules  the spiculate skeleton does not have a uniform length and the megascleres  in the spiculate skeleton  have a tylostyle smooth form . this justification was obtained using the cbr technique lid  armengol and plaza  1   but eager learning methods can also produce symbolic justifications - e.g. a decision tree can produce as justification the collection of branch conditions satisfied by the problem at hand.

figure 1: example of symbolic justification returned by lid in the marine sponges identification task.
모the main goal of a proactive communication process is to establish an interaction among cbr agents that allows to determine which information deficits each individual agent has; once these deficits are determined the case bartering process can proceed with the involved cbr agents possessing the necessary knowledge to offer and accept profitable case exchanges  see the case selection policy explained in 뫫1 . however  determining those deficits is not obvious  since an agent cannot determine its individual deficits.
모our proposal is then that an agent determines the deficits of other agents. imagine  for instance  that an agent ai sends three cases from its case base  c1 c1 c1  and stripping them from their known solutions sends the three problems  c1.p c1.p c1.p  to an agent aj. agent aj solves the three problems and sends back to ai three justified predictions
 . then  ai compares the predictions with the known solutions and determines  for instance  that aj has solved correctly problems c1.p and c1.p but has given an incorrect solution to c1.p; thus  ai has discovered a deficit of aj  one of which aj is necessarily unaware of. moreover  ai is surely in a disposition to help aj to improve its performance by repairing this deficit. the direct solution would be to offer case c1 to agent aj in exchange of some other case of aj that would help ai  case bartering .
모in fact  since agents are exchanging justified predictions  ai can find several cases that would be interesting for aj to exchange with. ai can examine its individual case base for those cases that satisfy the symbolic description sent in the justified prediction and that have the same solution as c1 - since any of those cases are likely to help aj in avoiding similar errors in the future. therefore  we can design a proactive communication process with which cbr agents can find out which deficits the other agents have  and determine the cases they own that can be useful for other individual agents; engaging this process insures to each participating agent that the other agents will detect its own deficits and determine useful cases for him. the next sections formalize these ideas defining justified predictions  뫫1  and specifying a collaboration strategy for a system of cbr agents  뫫1 .
1 justified predictions
in this section we will formally define the concept of justified prediction and some related notions required to clearly present our case bartering interaction protocol. we will use the following notation for cases. a  is a tuple containing a case description p 뫍 p and a solution class s 뫍 s. we will use the dot notation to refer to elements inside a tuple. e.g.  to refer to the solution class of a case c  we will write c.s. specifically  we define a justified prediction as:
definition 1 a justified prediction is a tuple j =  where agent a considers s the correct solution for problem p  and that prediction is justified a symbolic description d such that.
모thus  a justified prediction provides a way in which an agent a can explain or justify  using a symbolic description j.d  the reason why a predicts solution j.s for problem
j.p. the symbolic description has to subsume the problem
  because j.d has to be a generalization of j.p such that includes only those aspects of the problem that have determined predicting j.s as the solution. for example  figure 1 shows a symbolic description that is a generalization of  subsumes  a problem description  generated by the lid cbr technique  armengol and plaza  1  on the sponges data set used in 뫫1 .
모moreover  when an agent ai receives an incorrect justified prediction jaj from another agent aj  ai can examine this justification  and determine whether it has some cases in its local case base ci that can contradict jaj  i.e. those cases that would be useful to aj to repair its knowledge deficit. these cases are counterexamples of the justified prediction jaj.
definition 1 a counterexample of a justified prediction j is a case c such that  i.e. a case c subsumed by the justification j.d that has a solution different from the predicted solution j.s.
모using these definitions  we can now proceed to present the case bartering interaction protocol.
1 the pccl collaboration strategy
we present now a collaboration strategy that supports a proactive communication process and a case bartering protocol.
definition 1 the proactive communication case-based
learning	 pccl 	collaboration	strategy	is	a	tuple
  where ipccl is the pccl interaction protocol  뫫1  and dcs is the case selection decision policy  뫫1  used to decide which cases to offer to a given agent in exchange of other cases.
모the pccl interaction protocol does not separate a proactive communication stage from a case bartering stage; instead  pccl interleaves proactive communication and case bartering into a single process.
1 case bartering interaction protocol
the main idea of the case bartering interaction protocol is that each time an agent a receives a new case c to be retained  a uses c to find deficits of other agents. specifically  a sends them the problem c.p and looks for counterexamples for any incorrect justified prediction received from them. these counterexamples form the refutation sets. a refutation set is a record that contains a set of coutnerexamples found for

figure 1: refutation set of an agent a1.
an incorrect justification received from some agent. agents keep collecting refutation sets and each time that two agents have counterexamples to send each other  i.e. that an agent ai has some refutation sets for another agent aj and at the same time aj has refutation sets for ai   they will exchange cases to improve their individual case bases. figure 1 shows how an agent a1 creates a refutation set r after receiving from another agent a1 an incorrect justified prediction j at a given time t. a1 checks in its casebase c1 fort those cases subsumed by the explanation j.d  grey area   finding cases c1 c1 and c1; the refutation set r incorporates those cases  c1 and c1  with correct solution s1.
모specifically  let a = {a1 ... an} be a multi-agent system where each agent ai keeps a collection ii = {r1 ... rn} of refutation sets. when an agent ai receives a case c to be retained  it proceeds as follows:
1. ai asks the rest of the agents to make a justified prediction for c.p.
1. every agent aj that has received c.p generates a justified prediction and sends it back to ai.
1. ai now looks for counterexamples to all the received justified predictions that are wrong  i.e. those which predict a solution different than c.s . for each wrong justified prediction  for which a non empty set of counterexamples c is found  add a refutation set r =  where t is the current time .
1. ai finally retains c into its case base ci.
1. for each agent aj for which ai has some non empty refutation sets in its collection ii of refutation sets:
 a  ai uses its dcs decision policy to construct the belying set bi뫸j  explained in 뫫1 .
 b  ai informs aj that ai offers a number # bi뫸j  of cases to barter with aj.
 c  then aj uses its dcs decision policy to construct the belying set bj뫸i.
 d  if bj뫸i =   then  aj has no cases to offer to ai  and thus aj sends a message to ai rejecting the

figure 1: a belying set bi뫸j by agent ai to agent aj.
bartering offer. otherwise     agent aj sends a message to ai accepting the bartering offer and informing that has a number # bj뫸i  of cases to barter with.
 e  when a bartering offer is accepted both agentsselect a subset of cases from their belying sets with exactly min # bj뫸i  # bi뫸j   cases. then those cases are actually bartered  i.e. a copy of each bartered case is sent in a message   and the bartered cases are removed from the stored refutation sets in ii and ij.
모the next section explains the decision policy used in the protocol at step 1.a to select the cases offered to barter with another specific cbr agent.
1 case selection decision policy
the case selection decision policy dcs is in charge of selecting a set of cases that would be offered to a given agent aj in exchange of other cases.
모intuitively  when an agent ai uses its dcs decision policy to select cases  the process is the following one: ai has collected counterexamples in the refutation sets ii = {r1 ... rm} during the past iterations of the pccl interaction protocol. moreover  since the stored counterexamples are cases that may help other agents to improve their predictions  since those cases bely some of the other agents' wrong predictions   they are the cases that ai will offer to other agents.
모specifically  given an agent ai that wants to offer cases to another agent aj  dcs works as follows:
1. bi뫸j :=  .
1. for each rk 뫍 ii such that rk.a = aj
 a  select a case ck 뫍 rk such that.
 b  if ck exists then bi뫸j := bi뫸j 뫋 ck.
1. bi뫸j is the set of cases to be offered to agent aj.
모we call bi뫸j the belying set because this is the set of cases that contradict the justifications received from aj that were found incorrect. figure 1 illustrates this process  and shows how an agent ai generates the belying set bi뫸j for another agent aj by selecting one case of each of the refutation sets it has collected for aj.

figure 1: individual average accuracy with only individual learning  il  and with learning from communication  lfc .
1 experimental evaluation
in this section we empirically evaluate our learning from communication framework. we have made experiments in three different data sets: sponges  soybean  and zoology. the sponges data set is a marine sponges identification task  contains 1 marine sponges  of class demospongiae  represented as a relational cases and they have to be identified as pertaining to one of three different orders  astrophorida  hadromerida or axinellida . soybean is a standard data set from the uci machine learning repository with has 1 examples pertaining to 1 solution classes  why the zoology data set is also from uci and has 1 examples pertaining to 1 solution classes.
모in order to evaluate pccl  we have used a 1 agent system. in an experimental run the data set is divided into training set  1% of the cases  and test set  1%   a 1% of the training cases are initially distributed among the 1 agents without replication  i.e. there is no case shared by two agents. the remaining training cases are sent to the agents one by one. when an agent receives a training case  the agent uses pccl to find opportunities of learning from communication with other agents. moreover  periodically  test cases are sent to the agents to evaluate their improvement in classification accuracy as they receive more training cases.
모figure 1 shows the learning curves for a 1 agents system in the sponges  soybean and zoology dataset. the vertical axis shows the individual classification accuracy of the 1 agents on average  and the accuracy values are evaluated  over the horizontal axis  with different percentage of training cases

figure 1: average number of cases retained with only individual learning  il  and with learning from communication  lfc .
learnt by an individual agent  from 1% to 1% . the il plot shows the average individual accuracy for learning only from the training set  while the lfc plot show the average individual accuracy for learning from the training set and also from communication  using the pccl collaboration strategy . we can see that the additional case learning obtained from case bartering clearly improves individual accuracy in the three data sets. moreover  this improvement is achieved with a relatively modest number of additional cases  compared to what a  large  number of cases would be sharing in a scenario where all cases are shared . finally  the difference in accuracy is statistically significant for the three data sets according to a t-test with p = 1.
모figure 1 shows the evolution of the average individual case base size of the cbr agents both for il and lfc: the horizontal axis represents percentage of training cases learnt and the vertical axis shows the number of cases retained in an individual case base on average. the three plots of figure 1 also show that the proactive communication process increases the speed at which an individual cbr agent achieves higher accuracy values. moreover  the accuracy with case bartering keeps getting higher as the training set increases  showing that the cases learnt from communication are useful for the individual cbr agent. thus it is clear that with more cases  acquired via proactive communication  the average individual accuracy improves.
모let us now compare the accuracy achieved using case bartering with that achieved by the  random  cases in the training set. for instance  in the zoology data set accuracy is 1 with 1 retained cases on average  at 1%  using case bartering  while without bartering accuracy is only 1 with 1 retained cases  at 1% ; that is to say  with a smaller number of cases the accuracy is higher - and this effect is due to the selection of cases realized in pccl. another example  in the sponges data set  is that accuracy with case bartering is 1 with 1 retained cases  at 1%  while accuracy without case bartering is 1 with 1 retained cases  at 1% ; i.e. the same effect is present. in the soybean data set this effect is not as apparent: the reason is that accuracy rapidly degrades when a cbr agents has few cases  and in this situation any new case improves accuracy. summing up  the results in the three experiments show that the cases acquired via case bartering are useful not just as being new cases  but they are useful specifically for the individual for which they have been selected in the pccl collaboration strategy. that is to say  the case bartering protocol  뫫1  together with the case selection decision policy  뫫1  achieve the selection and effective retention of a small and individualized set of cases that clearly improve the case base of each cbr agent.
모the effect of achieving more compact case bases  for a given level of accuracy  can only be explained as a result of three factors. firstly  a  good selection   in the sense of being individualized  of cases is obtained by the dcs decision policy; otherwise more compact case bases would not achieve higher accuracy levels. secondly  a  small enough  set of cases is selected by the dcs decision policy; otherwise the size of case bases could grow by means of bartering a much larger amount of cases. thirdly  the bartering protocol is effective in transforming individual goals  improving one's accuracy  into a mutually beneficial strategy.
모finally  let us focus on step 1.e of the interaction protocol  where the number of cases effectively bartered is determined. step 1.e takes the minimum cardinality of the two belying sets bj뫸i and bi뫸j assuring the barter exchanges cases on a 1 for 1 basis. at first sight  this may seem too restrictive  since if agent ai offers 1 cases to aj who offers back 1 case then only 1 case is bartered and the other 1  that might be useful for aj  are  lost.  in order to evaluate this assumption  we performed the same experiments changing the step 1.e of the interaction protocol in a way that as long as the two agent have some cases to barter they are exchanged regardless of their numbers -i.e. we allow n : m barters. in principle  this is not unreasonable: traditional barter does not formally enforce a 1 : 1 exchange of goods since the utility of goods for each barterer may be quite different. this may also be true for case bartering  e.g. for a 1 : 1 exchange the single case may be very useful for the recipient.
모the experiments showed that this looser n : m exchange policy is not better than the strict 1 : 1 exchange policy. specifically  the experiments showed in the three data sets that n : m bartering achieves roughly the same accuracy as 1 : 1 bartering but the average individual case base size appreciably increases. thus  each cbr agent retains more cases from the proactive communication process but they are redundant  since they are not increasing the average individual accuracy. this situation is an instance of the principle mentioned in the introduction section: simply retaining all cases is not always the best retain policy. if we examine more deeply the reason for this effect  we notice that the selection policy dcs only selects one case from each refutation set. the reason is that  in principle  one counterexample is enough to prevent an agent aj to make the same error again. sending more than one counterexample to an agent aj for the same justified prediction will not add extra value to aj  and will  unnecessarily  increase its case base. the experimental results confirm that one counterexample is enough since the accuracy improvement is roughly the same. we can then conclude that the pccl collaboration strategy  case bartering protocol plus case selection policy  exchange an adequate number of cases and not more than those necessary.
1 conclusion
the content of a case base in a cbr system is traditionally determined by applying retention policies and/or case base management techniques  lopez de m뫣 antaras뫣 et al.  1 . however  these traditional approaches assume that there is a single source of case acquisition  the problems solved by the cbr system   while we have presented a situation where communicating with other cbr agents is a second source for case acquisition. we have presented a proactive communication process  by which a cbr agent sends problems to other agents and acquires their justified answers; this process is proactive because it is engaged to acquire the information that will later be useful in case bartering.
모during the proactive communication process  cbr agents not only solve the received problems  they use justified predictions to express the aspects they took into account in making that prediction. the symbolic description that is contained in a justified prediction is what allows an agent to determine not only when another agent fails  but the particular deficit that caused that failure. comparing the symbolic justification with its own cases  a cbr agent can discover which cases  counterexamples  can be useful for another agent to avoid a similar failure in the future. notice that it is the existence of justified predictions  introduced at  ontan on and plaza  1뫣    that allows such a fine-grained analysis and thus supports later a more focused bartering of cases process resulting in an overall improvement with only a relatively small number of cases exchanged.
모previous work on case bartering  ontan on and plaza 뫣 1  used a much less informed decision policy  icb   and would not improve the performance of cbr agents in our experimental setting. icb is useful when cbr agents have biased case bases -i.e. less  resp. more  than average number of cases of a certain class. biased cbr agents have lower accuracy that unbiased ones and icb guides a process of bartering cases that allows the cbr agents to eliminate all or most of their bias  achieving the  nominal  accuracy . however  pccl has been experimented with in this paper with already unbiased cbr agents  and the improvement is therefore on top of the  nominal  accuracy. the use of justified predictions is precisely the tool that allows to detect the cases that need to be bartered.
acknowledgments this research has been partially supported by the mid-cbr  tin 1-c1  and promusic  ic1-c1  projects.
