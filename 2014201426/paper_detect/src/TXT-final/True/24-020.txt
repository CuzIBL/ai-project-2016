 
investigating the character of scientific discovery using computational models is a growing area in artificial intelligence and cognitive science. 
scientific discovery involves both theory and experiments  but existing discovery systems have mainly considered the formation and modification of theories. this paper focuses on the modelling of experiments. a general characterization of the nature of experiments is given and more specifically galileo's motion experiments are examined. the 
stern scientific discovery system has been used to model galileo's investigations of free fall  and is introduced here. the system has an extensive representation for experiments and uses experiments to:  i  confirm existing hypotheses;  ii  find new hypotheses;  ii  enhance its own performance; and   iv  make intractable hypotheses tractable. 
1 introduction 
as a way to investigate the nature of scientific thinking and discovery  modelling episodes of scientific discovery in computer programs is now well established in artificial intelligence and cognitive science. for example  the bacon program  langley et.al. 1  has shown how laws  such as galileo's law of free fall  can be discovered from empirical data. echo  thagard  1  has been used to assess the acceptability of competing mature scientific research programmes  such as the oxygen and phlogiston theories in the history of chemistry. 
   stern is a scientific discovery system that continues this line of research. the program is an instantiation of a framework that attempts to characterize the nature of scientific research programmes in a general way. stern has extensively modelled galileo's investigations of naturally accelerated motion. 
   the role of experiments in scientific discovery has not been the major concern in previous work in the area. typically  the principal manifestation of experiments in existing discovery systems is in the form of correct empirical data. just a few researchers have considered experiments in more depth  e.g. kulkarni & simon  1 . hence  i will concentrate on the experimental component of stern in this paper. first  the extent to which experiments have been considered in previous work will be discussed. second  we will consider the structure of experiments as posited by the framework and then look at some of the experiments galileo used in his investigations. third  the instantiation of the experimental component of the framework in stern is described. finally  four of stern's processes that involve experiments will be considered in detail. 
1 experiments in previous work 
there are now a great variety of scientific discovery programs. here  we will just consider the extent to which experiments have been modelled. 
   in most existing systems the only manifestation of experiments is in the form of  observations  or correct empirical data. there are many programs that have empirical data as input. for example  bacon  langley et.al.  1  is given sets of numerical values from which it finds laws. for instance  given data relating to the radius and period of revolution of the planets bacon finds kepler's third law. systems that have followed bacon have combined both quantitative and qualitative methods in the formation of laws from data  e.g. nordhausen & langley  1; falkenhainer & michalski  1 . empirical data may also be used in other tasks; such as the modification of existing models 
 e.g. buchanan & feigenbaum  1; kokar  1; rose  1   or for assessing the acceptability of competing hypotheses in mature research programmes  thagard  1 . although an important part of scientific discovery  the use of empirical data is only a one of many aspects of experimentation. 
   however  three systems have considered experiments in more detail. the first is rajamoney et.al.'s  1  program that considers processes involving liquids in containers. the system investigates an unknown processes by designing experiments to differentiate between different processes. for example  by maximizing a liquid's free surface area  whilst minimizing the contact area with the vessel  the system can distinguish between evaporation and absorption. the two other systems are hdd  reimann  1  and kekeda  kulkarni & simon  1 . both have representations of experiments that:  i  specify the independent and dependent experimental variables;  ii  give the values of these variables; and   iii  supply some details about the particular nature of a given experiment. however  hdd has no heuristics for instantiating its own experiments; all its experiments are given as user inputs. of kekeda's many heuristics  there are several that propose different experimental tests depending on the nature of the hypothesis being investigated. 
to summarize  the modelling of experiments has played 
	cheng 	1 
only a modest part in previous work. clearly  there is plenty of scope for further investigations. so  let us now consider the nature of experiments in more detail. 
1 experiments 
the framework for computational models of scientific discovery was introduced by cheng  1 . it proposes a minimum set of components as a guide to the construction of acceptable models of scientific discovery. the focal concept is the research programme; a body of research that investigates a delimited set of phenomena using a theoretical component and an experimental component. 
   here  our main concern is with the nature of the experiments  but for completeness the theoretical component will be briefly outlined. the framework views theory as the abstract formal characterization of the phenomena within a research programme. theoretical knowledge is in the form of state transformation functions that interrelated the states of the phenomenon - sets of values for characteristic attributes of the phenomenon. three types of theoretical knowledge are distinguished:  i  hypotheses that characterize the phenomenon in all its different manifestations;  ii  models to characterize the phenomenon in just one situation; and  iii  instances that are series of states. the theoretical component also identifies different classes of theoretical inferences and considers criteria for assessing acceptability of theories. 
we now consider the structure of experiments in detail. 
1 the structure of experiments 
the framework gives a general abstract conception in which experiments are mechanisms that treat phenomena as  black boxes . the scientist investigates a phenomenon via a set of specified inputs and outputs. the inputs attempt to control some aspect of the phenomenon and manipulate others  while the outputs reveal values that result from these particular inputs. in an experiment  a phenomenon is instantiated in a manner that allows input parameters  inputs-m  to be manipulated and output parameters  outputs  to be measured or observed. some input parameters are fixed  inputs-c   they are held constant to tightly control the experimental environment. the form of experiments can thus be represented by the equation: 
　　　　　e inputs-e inputs-c  = outputs . . .  1  where the phenomena in the black boxes determine the hidden functional relation  ♀  between the inputs-m/inputsc and outputs. in this scheme experimental apparatus is required to instantiate and manipulate the phenomena  and instruments are needed for measurement and observation. ideally  just one input-m should be manipulated at a time when performing an experiment to prevent ambiguity over the extent to which a parameter affects the phenomena. 
   more specifically this characterization of experiments is treated at three levels of generality in the framework: as experimental paradigms  experimental setups and experimental tests. 
   at the most general level  within most sciences there are distinguishable classes of experimental situations  which are quite different ways a phenomenon can be investigated within a research programme. these classes of experiments are called experimental paradigms. 
at a more specific level there are experimental setups. 
these are instantiated experimental paradigms; manufactured experimental apparatus and instruments for manipulating and measuring input and output parameters  respectively. different experimental setups provide variations on the way a phenomenon is instantiated  manipulated and observed a under a particular experimental paradigm. 
   finally  at the most detailed level one has specific experimental tests. an experimental test refers to a particular experimental trial in an experimental setup. in an experimental test particular variables are chosen to be the input-m  input-cs and output parameters. the experiment is then performed with a series of input-m values for which output values are recorded  with fixed input-cs values. 
   in addition to the structure of experiments  the framework also considers: the processes required for the performance of experiments; the genesis of experiments; and the assessment of the reliability of experimental results. to make the characterization of the structure of experiments more concrete let us consider the experiments used by galileo. 
1 	galileo's 	experiments 
galileo is often considered to be the first scientist in the modern sense of the term because he not only theorized about phenomena but also performed experimental investigations. in his studies of naturally accelerated motion  the most important experimental paradigms used by galileo include  galileo  1 :  i  swinging pendulums consisting of small weights attached to the end of long suspended cords  maclachlan  1 ; and  ii  inclined planes  or ramps  made from long straight wooden batons along which spherical metallic balls are rolled  settle  1 . figures la and lb show these two experiments schematically and indicate some of their parameters. an inclined plane  for example  provides an experimental setup in which several different types of experimental tests can be performed. for example  the setup may be used in different tests to investigate how the distance  input-m  down the plane varies with time  output   or how the height  input-m  affects the time  output  with the distance held constant  input-c . 
   pragmatic knowledge plays an important part in the use of all kinds of experiments. the relative ease of manufacture of experimental setups from particular paradigms plays a role in the selection of the setups. a pendulum is simpler to construct than an inclined plane. in an inclined plane experiment  distance can be determined from markings made on the side of the plane but time is measured with a water clock. obviously distance is simpler to manipulate and measure so it is chosen as the input-m parameter  forcing time to become the output parameter. 
   further  background knowledge also has an important role to play. when choosing which parameters in a given experimental setup to make the input-m and output it is essential to ensure that they are not trivially related  that is  tautologically or by definition. for example  when the inclination of an inclined plane is fixed  the distance  height and length will vary in proportion to each other just because of the physical geometry of the setup. however  simple geometrical knowledge can be used to infer that such combinations of parameters are completely independent of motion phenomena. 
galileo's skill as an experimental scientist is shown by 


figure 1 galileo's inclined plane and pendulum experiments  experimental parameter names in italics  
his invention of new experimental paradigms. the basic 1 representing experiments technique he employed was to combine known experiments 
stern considers all three levels of experiments posited in 
using the output of one to feed into another. for example  the framework  see ′1 . stern has schemas for 
figure 1 shows the combined projectile and inclined plane experimental paradigms  setups and tests; and also for 
experiment  drake & maclachlan  1; drake  1 . in experimental parameters. all are instantiated as frames. 
this experiment a ball descends an inclined plane  pq. it is 
experimental paradigm frames have slots for information 
launched into the air with an imposed initial horizontal associated with each paradigm. the information includes: the 
motion by the lip at q  and describes a free path as a name of the paradigms  e.g. 'incplane' for the inclined 
projectile until it lands at r. the first half  inclined plane  plane ; lists of the relevant experimental parameters; what 
of such combined experiments will be called the initial part experimental setups available under the paradigm; the ease of 
of the experiment  and the second half  projectile  called the setup manufacture  a number in the range  1  ; the 
terminal part. there are two ways  or modes  in which mappings between the parameters and the variables used to 
combined experimental setups can be used in tests. in the express background knowledge; and  details to distinguish 
initial mode the input-m is chosen from the initial part of the initial and terminal parts of combined experiments. the 
the experiment  and the output from the terminal part; for experimental setup frames have slots for: the name of setups 
example height as input-m in the inclined plane and 
 e.g. 'down incplane' ; the parameters specific to a setup; 
horizontal projectile length as the output. the terminal experimental tests; and  the name of the initial part of the 
mode focuses just on the terminal part  with both input-m setup in the case of combined experiments. the 
and output being parameters chosen from that part; for experimental test frames has slots for the input-m  output 
example  the projectile's height and length could be the and fixed input-c parameters and their values  and a slot to 
input-m and output  respectively. the initial part's output indicate the mode in which combined experiments are used. 
acts as a input-c parameter to the terminal part. galileo 
　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　the experimental parameters employed by experimental carried out investigations on combined experiments using paradigms and setups are themselves frames. some of the the initial and terminal modes. parameter's slots are particularly relevant to our present 
experiments are not simple a matter. different levels and concerns. there are slots that name the parameter and hold 
types of experiments have an important part to play in its current value when required. two slots indicate the 
making scientific discoveries. in the following two sections maximum and minimum permitted values; restrictions on 
we consider how stern models most of the aspects of the magnitudes of a parameter imposed by the physical 
experiments just described. 
dimensions of the experimental apparatus. finally  there is a slot containing a measure of how easy it is to manipulate 

figure 1 galileo's combined inclined plane and projectile experiment  experimental parameter names in italics  
	cheng 	1 

and observe the parameter. 
   thus  stern has four different frames that instantiate most of the aspects of experiments considered in the section 1. we will now see how these various experimental frames are used by stern. 
1 stern's experimental abilities 
   in general terms  stern has a production system architecture  but is not a typical example of a production system. a complex hierarchy of schemas is used for its memory. for example  on the experimental side of stern  lists of experimental tests are stored under experimental setups  and lists of setups under experimental paradigms. a total of 1 rules are employed to carry out stern's various processes. the rules are partitioned into a hierarchy of 1 groups that constitute tasks on various different levels. for example  a high level task is the confirmation of existing hypotheses  and a more specific task is the comparison of a single theoretical prediction and an experimental test result 
four main experimental abilities are present in stern: 
 i  using experiments to  dis confirm hypotheses;  ii  experiment-led generalization to hypotheses;  iii  controlling the availability of experiments as means to enhance performance efficiency; and  iv  constructing and using new experiments to overcome odierwise intractable hypotheses. 
1 experiments to disconfirming theories 
one of stern's high level tasks  or strategics  is the confirmation  or disconfirmation  of an existing hypothesis. basically  this involves making a prediction  obtaining an experimental test result  and comparing the two. however  to be able to make a valid comparison the prediction must be relevant to the experiment; specifically  the theoretical terms mentioned in the prediction must correspond to measurable experimental parameters in the active experiment. thus  stern closely integrates its experimental and theoretical processes during this task. 
   stern first selects an existing hypothesis that has not been previously tested. one such hypothesis is the aristotelian effective weight law - the speed of a body is proportional to its  effective weight   or density. leaving aside the proportionality constant  the hypotheses can be expressed thus  
	v = den  	. . .  1  
where v and den are the speed and density of the body  respectively. 
   stern then chooses an experimental paradigm that has not already been considered with the current hypothesis and that seems the most profitable to use. a record of the experimental paradigms used to test each hypothesis is kept by stern. of those not previously considered  stern favours paradigms that combine ease of manufacture with the most experimental setups. the pendulum paradigm is typically preferred  but let us consider the inclined plane for our on going example. 
   as the current aim is to test the hypothesis using the experimental paradigm  stern checks whether v and den correspond to experimental parameters that are directly measurable. however  in this case neither do  so stern tries to find expressions in other terms to substitute for v and den using one of two different methods. first  stern can replace a term by its own definition  when preconditions attached to the definition obtain. for v  the condition that v is constant is satisfied because the aristotelian instantaneous acceleration law is assumed to hold at the time. second  background knowledge can be used to replace a term  by searching through the various relations in each different set of background knowledge  for expressions equivalent to the term. this is the case with den. the equation that stern finally infers from equation 1 is  
　　　　　　　　d / t = w / v o l   . . . 1  where d and t correspond to the distance and time of travel  respectively  and w and vol to the weight and volume of the ball  respectively. 
   stern next selects a particular inclined plane experimental setup and then attempts to make specific predictions. stern considers pairs of terms from equation 1  in turn  as the basis for making predictions. for example  let us take d and t. by reference to the experimental setup  d is chosen as the independent term  because its corresponding distance experimental parameter is the most easily manipulated and measured. t becomes the dependent term. a series of values for t and d are calculated using equation 1. the range over which d is permitted to vary is found from the magnitude limits of its corresponding experimental parameter. w and vol are given values equal to the mid point in the range of their corresponding experimental parameters. thus a quantitative prediction has been fully specified. 
   the next stage is to design an experimental test that matches the prediction. stern chooses input-m and output parameters that correspond to d and t  respectively. 
the values of the input-m and input-cs are set equal to the values of d  and w and vol  respectively. a subprogram then simulates the performance of the experimental test. it returns output parameter values with a realistic amount of noise.  in other systems the user typically supplies the results of experimental tests.  
   thus  stern finally has a prediction and an experimental test result that can be validly compared with each other. a function combining two forms of correlation analysis is used to simultaneously measure how accurately the values of the output parameter and dependent term match and to assess the amount of noise in the output. this predictive accuracy value is in the range  1 . the whole processes is repeated with predictions based on other pairs of theoretical terms  each yielding an instance with a value of predictive accuracy. the acceptability of the model. equation 1  is given by the quotient of the sum of the instance accuracy values and the number of instances. the acceptability of this model  and any others derived from the original hypothesis  are in turn used to assess the hypothesis  equation 1. hypothesis acceptability is given by the quotient of the sum of the model acceptability values and the number of models considered. hence  the measure of acceptability of hypotheses is a function of the adequacy of its models  and instances  that also reflects any uncertainty due to the presence of noise in the experimental data. 
   the confirmation strategy is used many times throughout the modelling of galileo's discoveries. aristotelian laws like equation 1 are found to be unacceptable using it. we will now consider how experiments also have an important part 

to play in the generation of new hypotheses. 
1 experiment-led generation to hypotheses 
as we saw above  many previous scientific discovery systems have been successful in the generalization of empirical data into laws. stern also infers new theoretical knowledge by generalization  but does so starting with experimental paradigms. 
   stern first chooses an experimental paradigm  such as the pendulum paradigm. the pendulum's setups are considered in turn. for each  stern designs a series of experimental tests based on pairs of parameters  which are to be the input-m and output of different tests. initially  stern considers all combinations of parameter pairs and then eliminates those that are trivially related or that have no bearing on the phenomenon being investigated. consider for example  three pairs of pendulum parameters:  size time    angle weight  and  angle length   see figure lb . trivially  tautologically  related pairs of parameters are found using background knowledge. for example   angle length  is eliminated  because the angle of swing is related to the length merely by the physical geometry of pendulums. the pairs of parameters that are considered irrelevant are ones that have no bearing on motion phenomena: that is pairs that do not have a distance  time or speed parameter. the  angle weight  pair is eliminated for this reason. of the 1 pairs that stern originally considers for the pendulum setup  only 1 remain after the two methods are applied;  size time  is one of them. the space of experimental tests that stern must consider has been significantly reduced. 
   for each of the remaining pairs of parameters stern designs experimental tests. given the  size time  pair  stern makes size the input-m and time the output  because size is more easily manipulated. all other parameters are treated as input-cs. a series of input-m values are calculated using the maximum and minimum permitted magnitudes of the size parameter. the input-c parameters are set to their mid range values. the experimental test is then performed by the experiment simulator subprogram  which returns the values of time for each size value. 
   to allow the theoretical side of the process to generalize the results  stern translates the lest results into theoretical terms: that is  time becomes t and size becomes s. the task of generalizing data into models is analogous to what bacon does  langley et.al  1 . later  when further models have been found using other experimental paradigms  those that are sufficiently general become hypotheses. many qualitative hypotheses  and the several quantitative models  are found using this experimental-led generalization strategy. one such model is the law governing the relationship between the length  size  of a pendulum and its period of swing  time . 
1 controlling the 	availability of experiments 
we have seen how stern can use experiments to confirm hypotheses  and how new theoretical knowledge is gained in an experiment-led manner. here we consider a quite different feature in stern - controlling the availability of experiments to improve performance efficiency. 
stern is given six experimental paradigms as its initial experimental input and it is also able to construct new combined experiments  see below . whilst engaged in the two strategies considered in the previous subsections  the system could consider every experimental paradigm in turn  but this would be quite inefficient. what stern actually does is to limit the number of available experimental paradigms. for example  attempting to initially confirm a hypothesis using just two experimental paradigms saves considerable effort. unacceptable hypotheses can be been found using just two paradigms and thus eliminated from further investigation. any acceptable hypotheses can be further tested using other experimental paradigms  but redundant processing is avoided by not doing the same for hypotheses already shown to be unacceptable. 
   a mechanism in stern limits the number of experimental paradigms that are available. a pragmatic measure of how worthwhile a paradigm is likely to be is calculated from the ease of manufacture its experimental setups and the number of setups. hence  when controlling the number of available experimental paradigms  only those with a practicability above a certain limit are made active. initially  the limit is chosen  by the user  so that two experimental paradigms will be available. when the first two experimental paradigms have been exhausted  the mechanism makes new paradigms available by lowering the value of the pragmatic limit. 
   this is an example of how the inclusion of experiments in a scientific discovery system not only makes it a more complete model  but also allows new heuristics to be devised for improving program performance. 
1 constructing and using novel experiments 
during the modelling of the galilean episode  stern infers many new hypotheses from those already obtained using the generalization strategy. one such new hypothesis is the most general form of the law of free fall  
	v = h1   	. . .  1  
where h is the vertical distance. stern must test the hypothesis using experiments to see whether it is really acceptable  using the confirmation strategy  see ′1 . however  when attempting to check the new hypothesis  
stern finds that is it intractable because v cannot be eliminated from equation 1. whereas  previously v was substituted using its own definition  this can no longer be done as the condition that v be constant is no longer satisfied  earlier aristotle's instantaneous acceleration hypothesis fulfilled the condition  but by now it has been shown to be unacceptable . 
   stern decides to construct a new combined experiment as a means to overcome this problem  just as galileo did  see ′1 . for example  consider the combined inclined plane and projectile experiment  figure 1 . separate equations that include v can be found for each of the experiment's two parts. the speed down the inclined plane is given by equation 1. the horizontal speed of a projectile is constant  so an equation in terms of horizontal distance  speed and time can be used. now  as the lip at the end of the inclined plane sends the ball horizontally into the air  this means that the speed terms in both equations are equal  and can thus be eliminated by substituting one equation onto the other. hie rest of the confirmation strategy may then be 
	cheng 	1 

applied as usual. 
   to be able invent combined experiments it is necessary to use real world knowledge; for example  that a lip can be attached to the end of the inclined plane. such abilities are beyond the current version of stern  which is given as inputs the legal combinations of combined experiments. however  stern is able to construct new paradigms given this information. 
to manufacture a new combined experimental paradigm  
stern finds experimental paradigms that can act as the terminal part of combined experiments. a paradigm  say the projectile paradigm  is made active. for this terminal paradigm  the other paradigms with setups that can be initial parts are also made active. for example  the inclined plane paradigm is a suitable initial part for the projectile as the terminal part. the actual construction of the combined experimental paradigm involves instantiating a new experimental paradigm frame and filling its slots using the information available for the active initial and terminal paradigms. for example  the ease of manufacture of the new combined experimental paradigm is calculated thus: manufacture ease =   i . t  /  i + t   . . .  1  where i and t are the manufacturing ease of the chosen initial and terminal paradigms  respectively. equation 1 satisfies the conditions that the ease of manufacture is:  i  between 1 and 1; and  ii  less than the magnitude of either i or t alone. 
   stern uses the new combined inclined plane and projectile experimental in the confirmation strategy to assess the acceptability of the law of free fall. the combined experiment is used in both the terminal and the initial modes. in the terminal mode  which focused only on the projectile part of the experiment  stern discovers the correct equation describing the parabolic shape of the projectile path. all this models what galileo also did with this combined experiment 
   that ends our consideration of the experimental abilities in the stern discovery system.  stern also has a purely theoretical strategy for generating new quantitative hypotheses from existing acceptable and unacceptable qualitative and quantitative hypotheses; cheng  1 . 
1 conclusions 
we have seen how stern has modelled several aspects of the role of experiments in galileo's investigation of the naturally accelerated motion. the experimental procedures are closely integrated with stern's various theoretical inference processes and are crucial to the system's overall discovery abilities. this research has begun to examine the important part that experiments have in scientific discovery  and demonstrates that there is much interesting research yet to be done. the current work on stern is concerned with the modelling of other galilean research programmes  such as the strength of materials. future work on experiments may concentrate on methods for assessing the reliability of experimental results  or model the physical structure of experimental setups in sufficient detail to enable stern to invent experiments. both issues will involve the development of more sophisticated control strategies  that will take into account previous theories and experiments  and model the scientist's aims and expectations. 
acknowledgements 
this research was carried out under a studentship and a postdoctoral fellowship from the science and engineering research council. thanks should go to: mark keane  marc 
eisenstadt and everyone in hcrl at the open university for all their support during my phd research; and  herbert simon for his comments on this paper. 
