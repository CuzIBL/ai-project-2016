iterated theory base change: a computational model 
mary-anne williams 
i n f o r m a t i o n s y s t e m s g r o u p 
d e p a r t m e n t o f m a n a g e m e n t 
u n i v e r s i t y o f n e w c a s t l e   n s w 1 1 
a u s t r a l i a 

a b s t r a c t 
the a g m paradigm is a formal approach to ideal and rational information change from a practical perspective it suffers from two shortcomings  the first involves difficulties with respect to the finite representation of information  and the second 
involves the lack of support for the iteration of change operators in this paper we show that these practical problems can be solved in theoretically satisfying ways wholely within the a g m paradigm 
   we introduce a partial entrenchment ranking which serves as a canonical representation for a theory base and a well-ranked episterruc entrenchment  and we provide a computational model for adjusting partial entrenchment rankings when they receive new information using a procedure based on the principle of minimal change 
   the connectioni between the standard a g m theory change operators and the theory base change operators developed herein suggest that the proposed computational model for iterated theory base change exhibits desirable behaviour 
1 	introduction 
information systems can be used to represent a reasoning agent's view of the world unless the agent has perfect and complete information it will require a mechanism to support the modification of its view as more information about the world is acquired moreover  a computational model to support the acquisition of new information requires a finite representation of the information held by the agent this representation must capture the information content  the agent's committment to this information  and an encoding of how the information should change upon the intrusion of new information 
   the a g m paradigm was originally developed by alchourron  gardenfors and makinson  and has become one of the standard frameworks for information change it provides formal mechanisms for modeling the rational evolution of an ideal reasoner's view of the world in particular  it provides operators for modeling the revision and contraction of information within the a g m paradigm the family of revision operators  and the family of contraction operators are circumscribed by sets of by rationality postulates the logical properties of a body of information are not strong enough to uniquely determine a revision or contraction operator  therefore the principal constructions for these operators rely on some form of underlying preference relation  such as a family of selection functions  alchourron et at 1   a system of spheres  grove  1 a nice preorder on models  katsuno and mendelzon 1  peppas and williams  1   or an epistemic entrenchment ordering  gardenfors and makinson  1  
from a theoretical point of view the a g m paradigm provides a very elegant and simple mechanism for rational and ideal change however  from a practical perspective its operators are insufficient because they essentially take a preference relation together with a sentence and produce a theory in other words  the underlying preference relation is lost this property is attractive in a theoretical context because it allows the resultant theory to adopt any preference relation depending on the desired dynamic behaviour in practice  however  a policy for change will be necessary a straightforward method of specifying such a policy is to impose constraints on the underlying preference relation which will in turn determine the dynamic behaviour of the system as noted above the a g m postulates do not uniquely determine revision and contraction operators  however gardenfors and makinson  showed that an epistemic entrenchment ordering does according to rott  1a  what should be at focus is not theory revision but epistemic entrenchment revision 
   the underlying preference relation fully characterizes a information system's content  its committment to the information  and its desired dynamic properties we refer to the process of changing an information system's underlying preference relation as a transmutation 
   williams  1a  showed that allowing the principle of minimal change to command the policy for change results to two different forms of transmutations  conditionalization and adjustment conditionalization was introduced by spohn  and is based on a relative measure of minimal change  on the other hand adjustment described by williams  1a  is based on an absolute measure of minimal change adjustments are compared and contrasted with conditionalization in 
 williams 1a  
   in our current theory base context we represent the underlying preference relation for a theory base as a partial entrenchment ranking which serves as a canonical representation of a well-ranked epistemic entrenchment we show it can be used to support transmutations of a theory base  and thus iterated theory base change furthermore  we provide a computational model which modifies a partial entrenchment ranking using an absolute measure of minimal change any theorem prover can be used to realize this model consequently  we present a practical solution to the iterated theory base change problem  we note however that a full complexity analysis of our proposed procedure is yet to be conducted 
   we briefly outline some technical preliminaries and the a g m paradigm in section 1  this is a standard treatise where two extra postulates introduced in  williams 1a  are presented  the reader familiar with this work may skip to the next section in section 1  we describe the representation of theory bases using partial entrenchment rankings  and we demonstrate how 
	williams 	1 


	1 	non m1t1nic reasoning 


	wiiiiams 	1 


	1 	a c o m p u t a t i o n a l m o d e l 
in this section we describe a particular type of transmutation called an adjustment which uses a policy 
for change based on an absolute minima/ measure in particular  it involves the absolute minimal change of a partial entrenchment ranking that is required to incorporate the desired new information a semantic 
account of adjustments can be found in  williams  
1 a  
   we present a computational model for adjustments which can be used as the basis for a computer-based implementation any theorem prover can be used to realize it the model itself is stated in its most perspicuous form  and can be optimised in several obvious ways  see  williams  1  for details for the purpose of our model we focus on finite epistemic rankings  and the following theorem describes the degree 
of acceptance of sentences with respect to finite rankings theorem 1 let a be a nontaulologtcal sentence if b€b is finite  then degree b  a  
1 	n1n m1t1nic reasoning 

¡¡the following theorem illustrates the interrelationships between theory base revision and theory base contraction based on adjustments in particular  theorem 1 j  is analogous to the harper identity and it captures the dependence of theory base contraction on the information content of the theory base  that is  the explicit information set  exp b  similarly theorem 1  is analogous to the levi identity  and 1  says that a levi identity also exists at the deeper preference relation level in particular  precisely the same partial entrenchment ranking is obtained when a partial entrenchment ranking is adjusted to accept new information a with firmness 1   1   o  as when we adjust the partial entrenchment ranking to remove a  and then adjust the resultant partial entrenchment ranking to accept new intheorem 1  captures the dependence of a theory base contraction on the content of the theory base that is  exp b  in particular  a sentence is retained in the theory base contraction if and only if it is member of the theory base and it would be retained in the corresponding theory contraction theoren 1  establishes a similar result for revision this substantiates our claim that adjustments retain as 'much as possible' of the original theory base 
	willams 	1 

   consequently  a partial entrenchment ranking can be used to model belief change for a limited reasoner in particular  partial entrenchment rankings can be used to represent the reasoner's explicit information  its commitment to that information  and an encapsulation of the desired dynamic behaviour in fact  depending on the nature of the theorem prover adopted for an implementation some resource bounds could also be introduced  williams  1  theorems 1  and 1  clearly demonstrate that theory base adjustments contain as many of the explicit beliefs as would be retained in the corresponding theory change operations in particular  we have established that each explicit belief retained in a theory change is also retained via theory base adjustments 
   theorems 1  and 1 n  show that theory change operators can be formulated in terms of theory base change using adjustments  and they provide explicit constructions for the theorems 1 and 1  respectively 

   for revision the adjustments of equivalent partial entrenchment rankings result in equivalent implicit information sets furthermore  it turns out that the second parts of theorems 1 and 1 can be generalised to equivalent partial entrenchment rankings  however 
we provided the current readings to for the sake of simplicity 
1 	related work 
gardenfore and rott  provide a comprehensive analysis of various prominent approaches  hansson 1  fuhrmann 1  nebel  1  to theory base change  and the interested reader should consult their work 
   nayak  and boutilier  explore iterated theoty change  and their approaches are closely related to transmutations because they focus on changes at the preference relation level  and as a consequence if the underlying preference relation is well-ranked then both of their procedures can be expressed as transmutations boutiher's natural revision being a special case of adjustment  and nayak's method being a special case of conditionalization for example  if we use theorem 1 to capture the relationship between an epistemic entrenchment ordering and a partial entrenchment ranking  then boutilier's approach can be characterized as an  a  l -adjustrnent 
   boutilier's new information is always accepted minimally firmly  spohn 1  p 1   and nayak's new information is always accepted maximally firmly  spohn 1  pll1  in other words  they both suffer from problems described by spohn  since their representation is essentially a simple conditional function  and their information input a sentence alone spohn claims that both of these extreme schemes are undesirable because we don't always want to accept new information with the same degree of firmness 
   in defense of nayak and boutilier we should point out that the degree of firmness for new information may not always be available  in which case we could adopt default firmnesses for newly acquired information when 
1 	non monotonic reasoning 
the quality of the evidence is unknown 
   if the underlying preference relation is well-ranked then transmutation schema* can capture any conceivable change within the a g m paradigm for the purpose of an implementation we will almost certainly be dealing with a well-ranked  probably finite  preference relation 
   an alternative approach to the problem of iterated revision is adopted by darwiche and pearl   and freund and lehmann  in particular  they have studied the iterated revision problem at the axiomatic level  and they suggest new meta-postulates for iterated revision rather than constraints on the modification of preference relations 
   williams et al  1b  capture spohn's notion of reason for  using adjustments of entrenchment rankings  and the computational model provided in section 1 can be used to implement spohman reasons 
   finally  we highlight some connections with nonmonotonic reasoning gardenfors and makinson  use an comparative expectation ordering to construct a nonmonotonic inference relation williams  1a  defines a partial expectation ranking to be is a function b from a subset of sentences in c into o such that   p e r i   and  per1  are satisfied we also note that reseller's plausibility indexes  are essentially partial expectation rankings given a partial expectation ranking b  if we define a nonmonotonic inference relation h  as af-/1 if and only if exp b* ¦Á i    - ¦Â where 1   1  then  -v 
is consistency preserving and rational  and the associated model structure is nice  gardenfors and makinson  1  
   williams  1a  shows that adjustments can be applied to partial expectation rankings thus providing a mechanism for changing nonmonotonic inference relations in an absolute and minimal way 
boutiher   pearl   freund and lehmann 
 also address the idea of changing default information  arguing that default information is usually quite stable  for example although our information about the flight coefficient of a particular bird may change dramatically  the default that typically birds fly will invariably remain unchanged  therefore changes should maintain as much default information as possible an adjustment not only concords with this perspective  but it preserves the properties of consistency perservation and rationality of the inference relation 
1 	discussion 
we have shown that the a g m paradigm can be extended to solve two outstanding practical problems that arise in the development of a computational model for belief revision this extension focuses on a finite representation of an epistemic entrenchment ordering  and the determination of a policy for change based on the principle of minimal change 
   we established that partial entrenchment rankings can be used to construct theory base change operators  theory change operators  as well as nonmonotonic inference relations moreover  we provided representation results for the construction of well-behaved and very wellbehaved theory change operators based on partial entrenchment rankings 
   we used partial entrenchment rankings to represent a well-ranked epistemic entrenchment ordering  and we provided a computational model for modifying partial entrenchment rankings based on an absolute measure of minima/ change which dealt with the removal of old information and the acquiescence of new information 
we established that theory base revision and theory 

base contraction operators based on adjustments are related via levi and harper identities at both the information content and the preference relation levels finally  we demonstrated that theory base operators based on an adjustment maintain as much explicit information as is retained by the corresponding theory change operator 
a c k n o w l e d g e m e n t s 
the author gratefully acknowledges  peter garden fore for suggesting how spohn'b work might be used in the development of a computational model  david makinson for a myriad of insightful suggestions concerning theory base change many thanks are also due to craig boutilier  didier dubois  norman foo  georg gottlob  abhaya nayak  bernhard nebel  erik olsson  
maurice pagnucco  judea pearl  pavlos pep pas  wlodek rabinowicz and hans rott for their helpful comments 
