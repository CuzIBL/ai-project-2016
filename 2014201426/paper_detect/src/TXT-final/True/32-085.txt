 
progressive processing is a model of computation that allows a system to tradeoff computational resources against the quality of results. this paper generalizes the'existing model to maice it suitable for dynamic composition of information retrieval techniques. the new framework addresses effectively the uncertainty associated with the duration and output quality of each component. we show how to construct an optimal meta-level controller for a single task based on solving a corresponding markov decision problem  and how to extend the solution to the case of multiple and dynamic tasks using the notion of an opportunity cost. 
1 	introduction 
this paper is concerned with the design and implementation of an effective computational model for information retrieval search engines that can tradeoff computational resources against the quality of the result. our approach is based on run-time monitoring of the information retrieval process and on dynamic selection of information retrieval techniques so as to maximize the quality of the answer produced with limited computational resources. information retrieval from a large collection involves uncertainty regarding the duration of the process and the quality of the result. in addition  there may be large variability in the number of requests that require a response at any given time. by taking a context dependent  dynamic approach to the problem we can significantly improve the average quality of service provided by such systems. 
　a typical search engine is composed of several information retrieval modules that perform such tasks as query formation  query optimization  query evaluation  precision improvement  recall improvement  clustering  and results visualization. for each one of these phases  there are a wide variety of techniques that have been developed in recent years  jones and willett  1 . currently  search engines are built by choosing and integrating a fixed set of modules and techniques. the choices are made off-line by the designer of the system. this 

figure 1: illustration of a progressive processing task for an information retrieval search engine 
static approach excludes techniques that work well in special situations. in addition  current information retrieval systems are optimized for a particular load; they cannot respond dynamically to varying load  availability of computational resources  and to the specific characteristics of a given query. 
　the ability to dynamically adjust computational effort based on the availability of computational resources has been studied extensively by the ai community since the mid 1's. these efforts have led to the development of a variety of techniques such as anytime algorithms  dean and boddy  1; zilberstein and russell  1   design-to-time  gravey and lesser  1   flexible computation  horvitz  1   imprecise computation  liu et a/.  1   and progressive reasoning  mouaddib  1; mouaddib and zilberstein  1 . 
　we adopt the progressive processing framework to formalize and solve the meta-level control problem of a realtime information retrieval application. the technique maps each task to a progressive processing unit  pru . each pru is composed of a set of modules that can contribute to the quality of the result. this offers a natural framework to describe the set of information retrieval techniques available to the system. figure 1 shows a simple task structure whose input is a query composed of a list of keywords. the task structure has three processing levels. the first level includes three alternative techniques to improve the initial query:  a  scan the query 

1 	uncertainty and probabilistic reasoning 

using concept recognizers to identify company names  dates  locations  personal names  and soon;  b  examine the query for pairs of words that have high statistical likelihood of being related and enhance the query with that information;  c  perform part-of-speech analysis to identify noun phrases within the query. the second level includes two alternative techniques that can improve the query's recall ability by expanding it to include related words and phrases;  d  use of local context analysis  lca   a statistical method for expanding queries that relies upon in-context analysis of word co-occurrence;  e  use of infinder  an association thesaurus that is faster than lca and does not capture context as well. finally  the third level performs the actual query evaluation and returns the results. quality in this application is measured by the number of relevant documents within the top n documents retrieved  i.e.  precision in the retrieved set . 
　the information retrieval application and the resulting task structure raise several fundamental issues that have not been previously addressed. 
1. handling the duration uncertainty and quality uncertainty associated with each technique. 
1. handling the dependency of quality and duration on the quality of intermediate results. 
1. handling a rich task structure in which some levels include several alternatives or optional computational steps; optional steps can be skipped under time pressure  leading to direct evaluation of the input query. 
1. selecting the  best  set of retrieval techniques in a dynamic environment taking into account the entire set of queries waiting for execution. 
　the rest of this paper offers an efficient solution to the meta-levei control problem. section 1 gives a formal definition of the problem. we then solve the problem in two steps. in section 1  we develop an optimal solution for a single pru  ignoring the fact that additional tasks are waiting for processing. section 1 shows how to handle multiple prus using the approach developed in section 1 and summarizing the effect of the waiting requests using the notion of an opportunity cost. in section 1 we address the issue of reactive control in a highly dynamic environment by estimating the opportunity cost and pre-compiling the control policies. we conclude with a summary of the results and a brief description of related work. 
1 	the meta-level control problem 
this section describes more formally the problem of meta-level control of the  enhanced  progressive processing model. each information retrieval request is mapped to a task structure described below. 
definition 1 a progressive processing unit  pru  is composed of a sequence of processing levels   ji fa   '- *!   the first level receives the input query and the last one produces the result. 
definition 1 each processing level  li} is composed of a set of  alternative modules  
each module can perform the logical function of level u  but it has different computational characteristics defined below. 
definition 1 the module descriptor  of module  is the probability distribution of output quality and duration for a given input quality. 
note that q is a discrete variable representing quality and  is a discrete variable representing duration. the module descriptor specifies the probability that module takes  time units and returns a result of quality when the quality of the previously executed module 
is module descriptors are similar to conditional performance profiles of anytime algorithms  zilberstein and russell  1 . they are constructed empirically by collecting performance data for a sample set of inputs. 
　when the search engine responds to a particular request   it receives an immediate reward defined as follows. 
definition 1 a time-dependent utility function   measures the utility of a solution of quality q if it is returned t time units after the arrival time of the request. 
we assume that there is a given constant t such that 
 that is  responding to a 
request more than t time units after its arrival has no value. 
　suppose that a system maintains a set of information retrieval requests  w  with arrival times the set of requests is updated dynamically as new requests arrive. the system processes the requests in a first-in-first-out order using a progressive processing unit to handle each request. 
　given a set of requests  the module descriptors of all the components of the progressive processing unit  and a 
　time-dependent utility function  we define the following control problem. 
definition 1 the reactive control problem is the problem of selecting a set of alternative modules so as to maximize the expected utility over the set of information retrieval requests. 
the meta-level control is  reactive  in the sense that we assume that the module selection mechanism is very fast  largely based on off-line analysis of the problem. the rest of the paper provides a solution to this problem. 
1 	optimal control of a single pru 
we begin with the problem of meta-level control of a single progressive processing unit corresponding to a single task. this problem can be formulated as a simple markov decision process  mdp  with states representing the current state of the computation. the state includes the current level of the pru  the quality produced so far  and the elapsed time since the arrival of the request. the rewards are defined by the utility of the solution which 
	zilberstein and mouaddib 	1 

depends on both quality and time. the possible actions are to execute a module of the next processing level or to skip that processing level. the transition model is defined by the descriptor of the module selected for execution. the rest of this section gives a formal definition of the mdp and the reactive controller produced by solving it. 
1 	state representation 
the execution of a single progressive processing unit  can be seen as an mdp with a finite set of states 
where in-
dicates the last executed  or skipped  level  is the quality produced by the last executed module  and  is the elapsed time since the arrival time  au  
of the request. note that quality is discretized and normalized to be in the range  all the intermediate modules use a uniform representation of input and output  a  query  in our application . note also that t is the maximum delay after which we consider the response to be useless. when the system is in state  one module of the t-th level has been executed.  the first level is  is used to indicate the fact that no level has been executed.  the states  failure  t  represent termination at time without any useful result. we distinguish between different failure states because failure can occur before the deadline leaving some remaining time for the execution of other requests in the queue. 
1 	transition model 
the initial state of the mdp  where t is the elapsed time since the arrival of the request current time -  and qinit is the initial quality of the request  1 in our application . the initial state indicates that the system is ready to start executing a module of the first level of the pru. the terminal states are all the states of the form  or  fallure  t . the former set represents finishing execution of the last level and the latter set represents failure. other states such as  reaching maximal intermediate quality  or  reaching the deadline before the execution of the last level  are not considered terminal states. a terminal state can be readied from state  by executing a series of skip actions until a failure state is reached. similarly skip actions take the automaton from state  to the last level because no execute action can improve the intermediate quality. 
in every nonterminal state the possible actions are: 
 execute the  jnodule of the next level  and s  skip the next level . to complete the transition model  we need to specify the probabilistic outcome of these actions. equations 1 define the transition probabilities for a given nonterminal state 
　the s action is deterministic. it skips the next level without affecting the quality or elapsed time.  it can be implemented as an additional  dummy  module whose 
execution takes no time and has no effect on quality.  
1 uncertainty and probabilistic reasoning 
	a  
skipping the last level results in failure. 
 1  
　　the action is probabilistic. duration and quality uncertainties define the new state. equation 1 determines the transitions following successful execution and equation 1 determines the transition to the failure state when the deadline  t  is reached. 
 1  
 1  
1 	rewards and the value function 
rewards are determined by the given time-dependent utility function applied to the final result  produced by the last level of the pru . the utility depends on the quality of the result and the elapsed time. keep in mind that in our application the intermediate results are useless and therefore have no direct rewards associated with them. we now define a value function  expected rewardto-go  over all states. the value of terminal states is defined as follows. 
		 1  
		 1  
the value of nonterminal states of the mdp is defined as follows. 

the value function is defined as maximum over all actions with the top expression representing the value of a skip action for any level such that  the middle expression representing the value of a skip action for level  and the bottom expression representing the value of an execute action. 
　this concludes the definition of an mdp. this mdp is a finite-horizon mdp with no cycles. it can be solved easily using standard dynamic programming algorithms or using search algorithms such as ao*. 


figure 1: illustration of the execution paths with multiple prus 
theorem 1 given one progressive processing unit u and a time-dependent utility function  the optimal policy for the corresponding mdp is an optimal reactive control for 
proof: because there is a one-to-one correspondence between the reactive control problem and the mdp  including the fact that the pru transition model satisfies the markov assumption   and because of the optimally of the resulting policy  we conclude that it provides optimal reactive control for the progressive processing problem. 
　we note that the number of states of the mdp is bounded by the product of the number of levels l  the maximum number of alternative modules per level maxi pi  the number of discrete quality levels  and the maximum execution time. while the maximum execution time can be quite large  the time unit used for the purpose of meta-level control is an arbitrary system parameter. a small time unit leads to a more effective control at the expense of a larger state-space. the choice of a unit of quality has a similar effect. these units introduce a tradeoff between the size of the policy and its effectiveness. further empirical evaluation is needed to determine the best choice of time and quality units in practice. 
1 optimal control of multiple prus using opportunity cost 
suppose now that we need to schedule the execution of multiple prus. we assume that there are n-f 1 requests whose arrival times are  one ap-
proach to construct an optimal schedule is to generalize the solution presented in the previous section. we can construct a larger mdp for the combined sequential decision problem including the entire set of  prus  as illustrated in figure 1 . to do that  each state must also include  the request number  leading to a general state represented as  note that t is the elapsed time since the arrival of the first request. 
　this rather complex mdp is still a finite-horizon mdp with no loops. moreover  the only possible transitions between different prus are from a terminal state of one pru to an initial state of a succeeding pru. therefore  we can solve this mdp by computing an optimal policy for the last pru for my starting time between 1 and  then use the value of its initial states to compute an optimal policy for the previous pru and so on. 
theorem 1 given a set  w  of progressive processing units and a time-dependent utility function  the optimal policy for the corresponding mdp is an optimal reactive control for w. 
this is an obvious generalization of theorem 1. the complete proof  by induction on the number of prus  is omitted. 
　we now show how to reformulate the effect of the remaining  requests on the execution of the first task. this reformulation preserves the optimality of the solution  but it suggests a more efficient control structure developed in section 1. 
definition 1  denote the ex-
pected value of the optimal policy for the last prus. 
to compute the optimal policy for the i-th pru  we can simply use the following reward function. 
		 1  
in other words  the reward for responding to the t-th request is composed of the immediate reward  defined by the time-dependent utility function  and the rewardto-go  defined by the remaining prus . alternatively  the reward can be represented as follows. 
		1  
therefore  the best policy for the first pru can be calculated if we use the following reward function for final states: 
 1  
definition 1 be the opportunity cost at time t. 
the opportunity cost measures the loss of expected value due to delay in the starting point of executing the last n tasks  all the tasks except the first one . 
definition 1 let the oc-policy for the first pru be the policy computed with the following reward function: 

the oc-policy is the policy computed by deducting from the actual reward for the first task the opportunity cost of its execution time. 
theorem 1 controlling the first pru using the ocpolicy is optimal 
proof: fvom the definition of 	we get: 
 1  
to compute the optimal schedule we need to use the reward function defined in equation 1 that can be rewritten as follows. 
		 1  
	zilberstein and m1ua1dib 	1 

but this reward function is the same as the one used to construct the oc-policy  except for the added constant 
 because adding a constant to a reward function does not affect the policy  the conditions of theorem 1 are met and the resulting policy is optimal. 
　theorem 1 suggests an optimal approach to scheduling the entire  requests by first using an oc-policy for the first request that takes into account the opportunity cost of the remaining n requests. then the oc-policy for the second request is used taking into account the opportunity cost of the remaining  tasks and so on. lb be able to implement this approach we need to have the control policies readily available. this issue is addressed in the following section. 
1 reactive control based on estimated opportunity cost 
in the previous section  we presented an optimal solution to the control problem of multiple progressive processing units without accounting for its computational complexity. in particular  the opportunity cost must be computed and revised quickly each time a new request arrives. once the opportunity cost is revised  a new policy for the current pru must be constructed. finding the exact opportunity cost requires the construction of an optimal policy for the entire set of tasks. in practice  this may slow down the operation of the information retrieval search engine. 
　in order to provide an effective reactive controller for dynamic progressive processing  it is necessary to: 
1. use a fast approximation scheme to estimate the opportunity cost; and 
1. use pre-compiled policies for different opportunity cost functions. 
the rest of this section explains this method in more detail. 
1 	estimating the opportunity cost 
the opportunity cost is defined in terms of the function v*1 which represents the value of an optimal policy for the remaining tasks in the queue. thus  it can be estimated by approximating this function. one way to approximate the cumulative value of the remaining tasks is to add the value of each task without taking into account the opportunity cost. in this calculation  the start time of each task is the expected end time of the previous one. the following set of equations summarizes this approximation scheme. 

where is the value function defined in section 1 for a single pru  therefore  can be approximated as follows. 
 1  
duration of the optimal single-fru policy when starting at time  relative to the arrival time of the request . then  is computed using with the expected starting time of task i relative to ita arrival time. 
		 1  
the function r  expected duration  can be computed for any finite-horizon mdp once the optimal policy is available by simply using durations as rewards. the function can be computed once off-line  making it easy to revise the opportunity cost when a new request is added. 
　we are also examining an alternative learning technique to approximate the opportunity cost function based on such features as total queue size and total waiting time. standard function approximation techniques can be used resulting in a compact representation of the opportunity cost. it is not clear at this point which approximation technique works better in practice. this will be determined based on empirical evaluation. 
1 	pre-compiled control policies 
to make the meta-level control truly reactive for large task structures  one may want to avoid computing a new policy  for a single pru  each time the opportunity cost is revised. to avoid this  the space of opportunity cost can be divided into a small set of regions representing typical situations. for example  there could be just three regions that capture low  medium  and high loads. for each region  an optimal policy would be computed offline and stored in a library. at run-time  the system will first estimate the opportunity cost and then use the appropriate pre-compiled policy from the library. these policies remain valid as long as the overall task structure and the utility function are fixed. because the dependency of the control decisions on the opportunity cost is monotonic  higher costs imply less time for execution   we anticipate that a small set of classes that correspond to qualitatively different action selection will be sufficient. 
　another advantage of the use of pre-compiled policies is the ability to react quickly to dynamic changes. control policies can be switched during the execution of a single request if the opportunity cost changes. this is possible because the policies share the same state space. 
1 	conclusion 
we present an innovative approach to meta-level control of progressive processing based on reformulating it as a 

1 	uncertainty and probabilistic reasoning 

markov decision problem. it is shown that an optimal policy for a set of tasks can be constructed by controlling a single pru  taking into account the opportunity cost of the remaining tasks. to apply this model to control the operation of an information retrieval search engine  a 
fast approximation of the opportunity cost is developed. finally  a highly reactive controller is described that uses a library of precompiled control policies to operate in a dynamic environment. 
　a less complex model of progressive processing that relies on heuristic scheduling has been developed {mouaddib and zilberstein  1 . the task structure  however  is limited to a linear set of levels with one module per level and no quality uncertainty or quality dependency. the heuristic scheduler is fast  but it cannot solve the more complex task structure presented in this paper and it does not provide optimal control. heuristic scheduling of computational tasks has also been studied by garvey and lesser  for the design-to-time problem-solving framework. the latter framework represents explicitly non-local interactions between sub-tasks. 
　the progressive processing framework relates to a large body of work within the systems community on imprecise computation  liu et a/.  1 . each task in that model is decomposed into a mandatory subtask and an optional subtask. a variety of scheduling algorithms have been developed for imprecise computation under different assumptions about the optional part. our model allows for a richer representation of quality and duration uncertainty and quality dependency. unlike imprecise computation  the schedule constructed by the mdp scheduler is a conditional schedule; the selection of modules is conditioned on the actual execution time and outcome of previous modules. 
　the application of dynamic programming to solve meta-level control problems have been previously used by hansen and zilberstein  to control interruptible anytime algorithms. optimal monitoring of progressive processing tasks using a corresponding mdp has been studied by mouaddib and zilberstein  with respect to a simpler task structure and without the notion of quality uncertainty and quality dependency. 
　the notion of opportunity cost is borrowed from economics. it has been used previously in meta-level reasoning by russell and wefald . horvitz  uses a similar notion to develop a model of continual com-
putation in which idle time is used to solve anticipated future problems. 
　the use of pre-compiled control policies to construct a highly reactive real-time system has been studied by several researchers. for example  greenwald and dean  show how a real-time avionics control system can use a library of schedules that cover all possible situations. each schedule is conditioned on the state of the flight operation. 
　in collaboration with the information retrieval center at umass we are currently developing the stochastic module descriptors for the components of the search engine. by definition  ir tasks involve large collections and a substantial amount of test data allowing us to test the applicability and scalability of this resource-bounded reasoning technique. 
acknowledgments 
we thank james allan and victor lavrenko for their contribution to the problem formulation and to the construction of the information retrieval testbed. 
　this work was supported in part by the national science foundation under grants no. iri-1  iri1  and int-1  by the ganymedell project of plan etat/nord-pas-de-calais  and by iut de lens. 
