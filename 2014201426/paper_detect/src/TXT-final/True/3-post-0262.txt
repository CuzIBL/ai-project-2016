 
web search engines are a great help for accessing web sites but they present several problems regarding semantic ambiguity.  in order to solve them  we propose new methods for polysemy disambiguation of web resources and discovery of lexicalizations and synonyms of search queries.  
1 introduction 
search engines like google have become an indispensable tool. however  their ranking algorithms are based only on a keyword's presence and have some serious handicaps that are reflected on the final results. on the one hand  if several ways of expressing the same search query exist  e.g. synonyms  lexicalizations  or even morphological forms   a considerable amount of relevant resources will be omitted. on the other hand  if the user selects a polysemic word as a 
query  the set of returned results will contain sites that are using that concept in different contexts  e.g. virus . 
　in order to face these two problems  in this paper we present new  automatic and autonomous methodologies for semantic disambiguation and classification of web resources and for discovery of lexicalizations and synonyms for a specific domain. these techniques use a previously obtained taxonomy of terms and web resources through the method described in  sanchez and moreno  1  to perform the appropriate contextualization  see an example for the sensor domain in figure 1 .  
 
figure 1. example of an initial taxonomy of sensors. 
 
　　 the support of  departament d'universitats  recerca i societat de la informaci┏  of catalonia is acknowledged. 
1 discovery of lexicalizations and synonyms  
there are several methodologies that try to find lexicalizations for a keyword like latent semantic analysis  deerwester et al  1 . it considers that words that co-occur in the same documents are semantically related. however  it tends to return domain related words but  sometimes  not truly  equivalent  ones  bhat et al  1 . other techniques  valarakos et al  1  identify lexicalizations with the assumption that they use a common set of 'core' characters. they can detect alternative spellings  e.g. pentium iii  pent. 1   but not synonyms  e.g. sensor and transducer .  
　we have developed a novel methodology for discovering lexicalizations and synonyms using an initial taxonomy and a web search engine. our approach is based on considering the longest branches  e.g. subcutaneous amperometric glucose sensor  of the taxonomy as a contextualization constraint and using them as the search query ommiting the initial keyword  e.g.  subcutaneous amperometric glucose   for obtaining new webs. in some cases  those documents will contain equivalent words for the main one just behind the searched query that can be considered candidates for lexicalizations or synonyms  e.g. subcutaneous amperometric glucose transducer . for each candidate  see table 1 with candidates for the sensor domain   a relevance measure  1  is computed  obtaining a ranked candidate list. those that overpass a minimum threshold computed in function on the number of multiwords considered will be selected. relev=#dif  web  appear* 1  #multi words terms 1    1 
table 1. lexicalizations and synonyms candidates for the sensor domain  1 multiwords . elements in bold are selected results. 

concept and derivates hits webs multi relev. sensor  sensors 1 1 1 1 transducer  transducers 1 1 1 1 system 1 1 1 1 probe 1 1 1 1 transmitter 1 1 1 1 measurement 1 1 1 1 
1 polysemy detection and semantic clustering  
in this case our goal is to be able to group different concepts  and their associated web sites  of the taxonomy associated to a search query in sets according to the concrete sense in which they are used. so  the user will obtain disambiguated sets of relevant web sites for the desired domain. 
　for that purpose  many techniques  ide and v└ronis  1  use an external dictionary to select the most appropriate meaning in each case. however  performing this classification without previous semantic knowledge is not a trivial process  sanderson and croft  1 . in this sense  we can take profit from the context where each concept has been extracted  concretely  the web documents that contain it. we can assume that each website included in the taxonomy is using the initial keyword  e.g. virus  in a concrete sense  so concepts that are selected from the analysis of that single document  e.g. linux  email  belong to the domain associated to the same keyword's meaning. applying this idea over a significant amount of web sites we can find  as shown in figure 1 for the virus example  quite consistent semantic relations between concepts. 
　the algorithm performs a clusterization process with the list of terms of a specific level of the taxonomy. for each pair  a similitude measure  1  is computed based on the amount of coincidences between the concept's url sets. the resulting similarity matrix allows us to detect the most similar concepts and join them. a new matrix is computed for the resulting set of classes. this process is repeated until no more concepts can be joined  there are no coincidences between urls   building a dendogram  see figure 1 . 
sim a  b  = max     #coin url#url a  a url 	 b     #coin url#url a  b url 	 b      	 1 
　the result is a partition  with 1 elements for the virus domain as shown in figure 1  of classes that groups the concepts and web resources that belong to a specific meaning. the number of final classes is automatically discovered by the clustering algorithm thanks to the constrained joining criteria. note that this methodology can be applied to a set of terms at any level of the taxonomy. 
 
figure 1. dendogram representing semantic associations between the classes found for the keyword  virus . two final clusters are obtained: sense 1 groups the classes associated to  computer program  and sense 1 the ones related to  biological agent . 
1 conclusions  
taking into consideration the amount of resources available easily on the web  we believe that methodologies that ease the search of information should be developed. standard search engines are widely used for this task but they present serious limitations due to their pattern-search algorithms because they lack any kind of semantic content. 
 on the one hand  polysemy becomes a serious problem when the retrieved resources obtained from the search engine are only based on the keyword's presence; in this case  we propose an automatic approach for polysemy disambiguation of concepts and web resources. on the other hand  in order to extend the search widely and retrieve the largest amount of resources that are semantically relevant for the query specified  an algorithm for discovering alternative keywords  lexicalizations and synonyms  for the same domain is also proposed. this is very useful for domains with a little amount of available web resources.    
　moreover  it is important to note that the proposed methodologies perform in an automatic and autonomous way  allowing to maintain the results updated easily by performing executions as frequently as desired. this is a very useful feature when dealing with a highly changing environment like the web and distinguishes our approach from other similar ones in which user's interaction or a thesaurus like wordnet are required  lamparter et al  1 . 
