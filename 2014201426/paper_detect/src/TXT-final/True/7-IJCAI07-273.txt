
this paper focuses on the linguistic aspect of noun phrase coreference  investigating the knowledge sources that can potentially improve a learningbased coreference resolution system. unlike traditional  knowledge-lean coreference resolvers  which rely almost exclusively on morpho-syntactic cues  we show how to induce features that encode semantic knowledge from labeled and unlabeled corpora. experimentson the ace data sets indicate that the addition of these new semantic features to a coreference system employing a fairly standard feature set significantly improves its performance.
1 introduction
recent years have seen an intensifying interest in noun phrase  np  coreference - the problem of determining which nps refer to the same real-world entity in a document  owing in part to the automatic content extraction  ace  evaluations initiated by nist as well as the surge of interest in structured prediction in the machine learning community. as a result  various new models and approaches to np coreference are developed. for instance  coreference has been recast as the problem of finding the best path from the root to a leaf in a bell tree  luo et al.  1   and tackled both as a relational learning task  see mccallum and wellner   and as a supervised clustering task  see li and roth  .
　equally important to the development of new coreference models is the investigation of new linguistic features for the problem. however  until recently  research in anaphora and coreference resolution has largely adopted a knowledgelean approach  in which resolvers operate by relying on a set of morpho-syntactic cues. while these knowledge-lean approaches have been reasonably successful  see mitkov et al.    kehler et al.  speculate that deeper linguistic knowledge needs to be made available to resolution systems in order to reach the next level of performance. in fact  it should not be surprising that certain coreference relations cannot be identified by using string-matching facilities and syntactic knowledge alone. for instance  semantic knowledge is needed to determine the coreference relation between two lexically dissimilar common nouns  e.g.  talks and negotiations   and world knowledge might be required to resolve the president to george w. bush if such background information was not provided explicitly in the associated document.
　our goal in this paper is to improve the performance of a learning-based coreference system by introducing features that encode semantic knowledge as well as knowledge that is potentially useful for identifying non-anaphoric nps  i.e.  nps that do not have an antecedent and hence do not need to be resolved . to evaluate the utility of the new linguistic features  we augment a baseline feature set  which comprises knowledge sources commonly employed by existing coreference engines  with these new features. in an evaluation on the ace datasets  the coreference system using the augmented feature set yields a statistically significant improvement of 1-1% in f-measure over the baseline system.
　another contribution of our work lies in the use of corpusbased methods for inducing features for coreference resolution. although there have been a few attempts on inducing gender  ge et al.  1   path coreference  bergsma and lin  1   np anaphoricity  bean and riloff  1   and selectional preferences  dagan and itai  1; yang et al.  1  for coreference resolution  most of the existing coreference resolvers rely on heuristic methods for feature computation.
1 new features for coreference resolution
in this section we describe the new linguistic features for our learning-based coreference resolution system.
1 inducing a semantic agreement feature
a feature commonly employed by coreference resolvers for determining whether two nps are coreferent is the semantic class  sc  agreement feature  which has the value true if the scs of two nps match and false otherwise. the accuracy of the sc agreement feature  therefore  depends on whether the sc values of the two nps are computed correctly. for a named entity  ne   the sc is typically determined using an ne recognizer; on the other hand  determining the sc of a common noun proves more difficult  in part because many words are polysemous and it is non-trivial to determine which sense corresponds to the intended meaning of the noun.
　to determine the sc of a common noun  many existing coreference systems use wordnet  e.g.  soon et al.    simply assigning to the noun the first  i.e.  most frequent  wordnet sense as its sc. it is not easy to measure the accuracy of this heuristic  but the fact that the sc agreement
person  organization  time  day  money  percent 
measure  abstraction  psychological feature  phenomenon  state  group  object  unknown
table 1: list of the possible semantic class values of a common noun returned by the first-sense heuristic method.
feature was not used by soon et al.'s decision tree coreference classifier seems to suggest that the sc values of the nps were not computed accurately by this  first-sense  heuristic.
　motivated by related work on semantic lexicon construction  e.g.  hearst   phillips and riloff    we develop the following method for learning the sc of a common noun  with the goal of improving the accuracy of the sc agreement feature. given a large  unannotated corpus1  we use  1  an in-house ne recognizer  which achieves an fmeasure of 1% on the muc-1 test set  to label each ne with its semantic class  and  1  lin's  1b  minipar dependency parser to extract all the appositive relations. an example extraction would be  eastern airlines  the carrier   where the first entry is a proper noun labeled with either one of the seven muc-style ne types1 or others1 and the second entry is a common noun. if the proper noun is not labeled as others  we may infer the sc of the common noun from that of the propernoun. however since neither minipar nor the ne recognizer is perfect  we use a more robust method for inferring the sc of a common noun:  1  we compute the probability that the common noun co-occurs with each of the eight ne types1 based on the extracted appositive relations  and  1  if the most likely ne type has a co-occurrence probability above a certain threshold  we set the threshold to 1   we label the common noun with the most likely ne type.
　an examination of the induced sc values indicates that our method fixes some of the errors commonly made by the firstsense heuristic. for instance  common nouns such as carrier and manufacturer are typically used to refer to organizations in news articles  but were labeled as person by the heuristic.
　nevertheless  our method has a potential weakness: common nouns that do not belong to any of the seven ne semantic classes remain unlabeled. to address this problem  we will set the sc of an unlabeled common noun to be the value returned by the first-sense heuristic.  in our implementation of the first-sense heuristic  we determine which of the 1 scs listed in table 1 a common noun belongs to based on the first wordnet sense.  however  we expect that our method will be able to label most of the common nouns  because in ace we are primarily interested in nouns referring to a person  organization  or location  as we will see in the next subsection.
1 inducing an ace-specific semantic feature
the semclass feature described in the previous subsection was developed for use in a general-purpose coreference system. however  because of the way the ace coreference task

1
　　we used  1  the bllip corpus  1m words   which consists of wall street journal articles from 1 to 1  and  1  the reuters
corpus  1gb data   which has 1 reuters articles. 1
 person  organization  location  date  time  money  and percent. 1
this indicates the proper noun is not a muc ne.
1
for simplicity  others is viewed as an ne type here.
personhumanorganizationcorporation  agency  governmentfacilityman-made structure  e.g.  building gspgeo-political region  e.g.  country  city locationgeographical area and landmass  body of water  geological formationtable 1: ace semantic classes.
organizationsocial groupfacilityestablishment  construction  building  facility  workplacegspcountry  province  government  town  city  administration  society  island  communitylocationdry land  region  landmass  body of water  geographical area  geological formationtable 1: list of keywords used in wordnet search for determining the ace semantic class of a common noun.
is defined  we may be able to improve system performanceon the ace data if we develop another semantic class agreement feature with the ace guidelines in mind. specifically  the ace coreference task is concerned with resolving references to nps belonging to one of the five ace semantic classes  ascs   namely  person  organization  facility  gsp  a geographical-social-political region   and location  see table 1 for a brief description of the ascs . in particular  references to nps belonging to other scs are not to be marked up. hence  we desire an ace sem class feature that considers two nps semantically compatible if and only if the two nps have a common asc. the rest of this subsection describes how we determine the asc of an np. as we will see  we allow an np to possess more than one asc in some cases. our method for determining the asc of an np is based in part on its sc value as computed by the semclass feature. in particular  the method hinges on the observation that  1  semclass's organization class roughly corresponds to two ascs: facility and organization  and  1  semclass's location class roughly corresponds to two ascs: gsp and location. given this observation  we can determine the asc of an np as follows:
  if its semclass value is not person  organization  or location  its asc will be others.
  if its semclass is person  its asc will be person.
  if its semclass is location  we will have to determine whether its asc is location or gsp  accordingto our observation above. specifically  we first use wordnet to determine whether the head noun of the np is a hypernym of one of the gsp keywords listed in table 1we then repeat this wordnet lookup procedureusing the
location keywords. if both lookupsare successful  the asc of the np will be both gsp and location; other-
wise the asc will be one of these two classes.
  if its semclass is organization  we will have to determine whether its asc is organization or facility. we can similarly use the procedure outlined in the previous bullet to determine whether its asc is organization  facility  or both.
1 inducing a semantic similarity feature
many reference resolvers use wordnet to compute the semantic similarity between two common nouns  e.g.  poesio et al.  and daume＞ and marcu  . however  this approach to determining semantic similarity may not be robust  since its success depends to a large extent on the ability to determine the correct wordnet sense of the given nouns.
　motivated by research in lexical semantics  we instead adopt a distributional approach to computing the semantic similarity between two common nouns: we capture the semantics of a noun by counting how frequent it co-occurs with other words  determining a pair of common nouns to be semantically similar if their co-occurrence patterns are similar.
　instead of acquiring semantic similarity information from scratch  we use the semantic similarity values provided by lin's  1a  dependency-based thesaurus  which is constructed using a distributional approach combined with an information-theoretic definition of similarity. each word w in the thesaurus is associated with a list of words most similar to w together with the semantic similarity values.
　given the thesaurus  we can construct a semantic similarity feature  semsim  for coreferenceresolution  in which we use a binary value to denote whether two nps  npx and npy  are semantically similar. specifically  the feature has the value true if and only if npx is among the 1-nearest neighbors of npy according to the thesaurus or vice versa.
1 inducing a pattern-based feature
next  we induce a patternbased feature using information provided by an algorithm that learns patterns for extracting coreferentnp pairs  each of which involvesa pronounand its antecedent. bean and riloff  also learn extraction patterns for coreference resolution  but unlike our method  their method is unsupervised and domain-specific.
　before showing how to compute our patternbased feature  let us describe the pattern learner  which operates as follows:  1  patterns are acquired from a corpus annotated with coreference information  and  1  the accuracy of each learned pattern is estimated. below we elaborate these two steps.
acquiring the patterns. recall that a pattern is used to extract coreferent np pairs; hence a good pattern should capture features of the two nps involved as well as the context in which they occur. to illustrate how to induce a pattern  let us consider the following coreference segment  cs   which we define as a text segment that starts with an np  npx  and ends with a pronoun that co-refers with npx:  john is studying hard for the exam. he . from this cs  we can induce a pattern that simply comprises all the tokens in the segment. if we see this sequence of tokens in a test text  we can apply this pattern to determine that john and he are likely to co-refer.
　the above pattern  however  may not be useful because it is unlikely that we will see exactly the same text segment in an unseen text. hence  we desire a pattern learner that can generalize from a cs and yet retain sufficient information to extract coreferent np pairs. specifically  we design a pattern learner that induces from each cs in a given annotated corpus three extraction patterns  each of which represents a different degree of generalization from the cs. in this work  we only consider segments in which the antecedent and the anaphor are fewer than three sentences apart.
　table 1 shows the three patterns that the learner will induce for the example cs above. the first pattern  see row 1  is created by  1  representing the antecedent and the anaphor as a set of attribute values indicating its gender  number  semantic class  grammatical role  and np type1;  1  representing each of the remaining nps in the cs by the token np;  1  representing each non-verbal and non-adverbial token that is not enclosed by any np by its part-of-speech tag; and  1  representing each verbal token as it is. the reason for retaining the verbal tokens is motivated by the intuition that verbs can sometimes play an important role in identifying coreferent np pairs. on the other hand  adverbs are not represented because they generally do not contain useful information as far as identifying coreferent np pairs is concerned.
　the second pattern  shown in row 1 of table 1  is created via the same procedure as the first pattern  except that each verbal token is replaced by its part-of-speech tag. the third pattern  see row 1 of table 1  is created via the same procedure as the preceding two patterns  except that only the nps are retained. so  the three patterns represent three different
levels of generalizations from the cs  with the first one being the most specific and the third one being the most general.
　note that some of the induced patterns may extract both coreferent and non-coreferent np pairs  thus having a low extraction accuracy. the reason is that our pattern learner does not capture evidence outside a cs segment  which in some cases may be crucial for inducing high-precision rules. hence  we need to estimate the accuracy of each pattern  so that a coreference system can decide whether it should discard np pairs extracted by patterns with a low accuracy.
estimating pattern accuracy. after we acquire a list of extraction patterns l  with the redundant patterns removed   we can estimate the accuracy of each pattern on an annotated corpus simply by counting the number of coreferent np pairs it extracts divided by the total number of np pairs it extracts  as described below. first  we collect all the cs's and non-coreference segments  ncs's  from the same annotated corpus that we used to induce our patterns  where an ncs is defined as a text segment beginning with an np  npx  and ends with a pronoun  npy  such that npx is not coreferent with npy.  as before  we only consider cs's and ncs's where the two enclosing nps are separated by fewer than three sentences.  from each cs/ncs  we use our pattern learner to induce three patterns in the same way as before  but this time we additionally label each pattern with a '-' if it was induced from an ncs and a '+' otherwise. we then insert all these labeled patterns into a list s  with the redundant patterns retained. finally  we compute the accuracy of a pattern l （ l as the number of times l appears in s with the label '+' divided by the total number of times l appears in s.
1. { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pn } is studying in np . { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pro }1. { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pn } vbz vbg in np . { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pro }1. { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pn } np { gender:m  number:sing  semclass:person  gramrole:subj  nptype:pro }table 1: the three patterns induced for the coreference segment  john is studying hard for the exam. he .　using the list of extraction patterns l sorted in decreasing order of accuracy  we can create our patternbased feature as follows. given a pair of nps  we march down the pattern list l and check if any of the patterns can extract the two nps. if so  the feature value is the accuracy of the first pattern that extracts the two nps; otherwise the feature value is 1.
1 inducing an anaphoricity feature
anaphoricity determination refers to the problem of determining whether an np has an antecedent or not. knowledge of anaphoricity can potentially be used to identify and filter non-anaphoric nps prior to coreference resolution  thereby improving the precision of a coreference system. there have been attempts on identifying non-anaphoric phrases such as pleonastic it  e.g.  lappin and leass   and nonanaphoric definite descriptions  e.g.  bean and riloff  .
　unlike previous work  our goal here is not to build a fullfledged system for identifying and filtering non-anaphoric nps. rather  we want to examine whether shallow anaphoricity information  when encoded as a feature  could benefit a learning-basedcoreferencesystem. specifically  we employ a simple method for inducing anaphoricity information: given a corpus labeled with coreference information  we compute the anaphoricity value of an np  npx  as the probability that npx has an antecedent in the corpus. if npx never occurs in the annotated corpus  we assign to it the default anaphoricity value of -1. hence  unlike previous work  we represent anaphoricity as a real value rather than a binary value.
　now we can encode anaphoricity information as a feature for our learning-based coreference system as follows. given a coreference instance involving npx and npy  we create a feature whose value is simply npy's anaphoricity value.
conceivably  data sparseness may render our anaphoric-
ity feature less useful than we desire. however  a glimpse at the anaphoricity values computed by this feature shows that it can capture some potentially useful information. for instance  the feature encodes that it only has a moderate probability of being anaphoric  and the np the contrary taken from the phrase on the contrary is never anaphoric.
1 inducing a coreferentiality feature
we can adapt the above method for generating the anaphoricity feature to create a coreferentiality feature  which encodes the probability that two nps are coreferent. these coreferentiality probabilities can again be estimated from a corpus annotated with coreference information; in cases where one or both of the given nps do not appear in the corpus  we set the coreferentiality value of the np pair to -1.
　our method of inducing the coreferentiality feature may also suffer from data sparseness. however  whether this feature is useful at all for coreference resolution is an empirical question  and we will evaluate its utility in section 1.
1 the baseline feature set
the previous section introduced our new features for coreference resolution. as mentioned in the introduction  these features will be used in combination with a set of baseline features. this section describes our baseline feature set  which comprises 1 selected features employed by high-performing coreference systems such as soon et al.   ng and cardie   and ponzetto and strube .
lexical features. we use nine features to allow different types of string matching operations to be performed on the given pair of nps  npx and npy1  including  1  exact string match for pronouns  proper nouns  and non-pronominal nps  both beforeand after determinersare removed ; 1  substring match for proper nouns and non-pronominal nps; and  1  head noun match. in addition  a nationality matching feature is used to match  for instance  british with britain. furthermore  we have a feature that tests whether all the words that appear in one np also appear in the other np. grammatical features. 1 features test the grammatical properties of one or both of the nps. these include ten features that test whethereach of the two nps is a pronoun a definite np  an indefinite np  a nested np  and a clausal subject. a similar set of five features is used to test whether both nps are pronouns  definite nps  nested nps  proper nouns  and clausal subjects. in addition  five features determine whether the two nps are compatible with respect to gender  number  animacy  and grammatical role. furthermore  two features test whether the two nps are in apposition or participate in a predicate nominal construction  i.e.  the is-a relation . finally  motivated by soon et al.   we have a feature that determines whether npy is a demonstrative np.
semantic features. there are two semantic features  both of which are employed by soon et al.'s coreference system. the first feature tests whether the two nps have the same semantic class. here  the semantic class of a proper noun and a common noun is computed using an ne finder and wordnet  by choosing the first sense   respectively. the second feature tests whether one np is a name alias or acronym of the other. positional features. we have one positional feature that measures the distance between the two nps in sentences.
1 evaluation
in this section  we evaluate the effectivenessof our newly proposed features in improving the baseline coreference system.
1 experimental setup
we use the ace-1  version 1  coreference corpus for evaluation purposes. the corpus is composed of three data sets taken from three different news sources: broadcast news  br   newspaper  pa   and newswire  wi . each data set comprises a set of training texts for acquiring coreference classifiers and a set of test sets for evaluating the output of the coreference system. we report performance in terms of recall  precision  and f-measure using two different scoring programs: the commonly-used muc scorer  vilain et al.  1  and the recently-developed ceaf scorer  luo  1 . according to luo  ceaf is designed to address a potential problem with the muc scorer: partitions in which nps are over-clustered tend to be under-penalized. for all of the experiments conducted in this paper  we use nps automatically extracted by an in-house np chunker and an ne recognizer.
1 the baseline coreference system
our baseline system uses the c1 decision tree learning algorithm  quinlan  1  in conjunction with the 1 baseline features described in section 1 to acquire a coreference classifier on the training texts for determining whether two nps are coreferent. to create training instances  we pair each np in a training text with each of its preceding nps  labeling an instance as positive if the two nps are in the same coreference chain in the associated text and negative otherwise.
　after training  the decision tree classifier is used to select an antecedent for each np in a test text. following soon et al.   we select as the antecedent of each np  npj  the closest preceding np that is classified as coreferent with npj. if no such np exists  no antecedent is selected for npj.
　row 1 of table 1 and table 1 shows the results of the baseline system obtained via the muc scorer and the ceaf scorer  respectively. each row of the two tables corresponds to an experiment evaluated on four different test sets: the entire ace test set  comprising all the br  pa  and wi test texts  and each of the br  pa  and wi test sets. these four sets of results are obtained by applying the same coreference classifier that is trained on the entire ace training corpus  comprising all the training texts from pa  wi  and br . owing to space limitations  we will mainly discuss results obtained on the entire test set. as we can see  the baseline achieves an f-measure of 1  muc  and 1  ceaf .
　to get a better sense of how strong these baseline results are  we repeat the above experiment except that we replace the 1 features with the 1 features employed by soon et al.'s  coreference resolver. results of the soon et al. system  shown in row 1 of the two tables  indicates that our baseline features yield significantly better results than soon et al.'s1: f-measure increases by 1  muc  and 1  ceaf .
1 coreference using the expanded feature set
next  we train a coreference resolver using the baseline feature set augmented with the five new features described in sections 1-1  namely  acesemclass  semsim  patternbased  anaphoricity  and coreferentiality.
in addition  we replace the heuristic-based sc agreement feature in the baseline feature set with our semclass feature  see section 1 . we employ the same methods for training instance creation and antecedent selection as in the baseline.
recall that the patternbased  anaphoricity  and
coreferentiality features are all computed using a data set annotated with coreference information. hence  we need to reserve a portion of our training texts for the purpose of computing these features. specifically  we partition the available training texts into two sets of roughly the same size: the training subset and the developmentsubset. the development subset will be used for computing those features that require an annotated corpus  and the training subset will be used to train the coreference classifier using the expanded feature set.
　results using the expanded feature set are shown in row 1 of the two tables. in comparison to the baseline results in row 1  we see that f-measure increases from 1 to 1  muc  and 1 to 1  ceaf . although the gains may seem moderate  the performance difference as measured by both scorers is in fact highly statistically significant  with p=1 for
muc and p=1 for ceaf.
1 feature analysis
to better understand which features are important for coreference resolution  we examine the decision tree learned using the expanded feature set  not shown here due to space limitations . at the top of the tree are the two lexical features that test exact string match for proper nouns and for non-pronominal nps. this should not be surprising  since these string matching features are generally strong indicators of coreference. looking further down the tree  we see the semclass  anaphoricity  and coreferentiality features appearing in the third and fourth levels of the tree. this indicates that these three features play a significant role in determining whether two nps are coreferent.
　to further investigate the contribution of each of our new features to overall performance  we remove each new feature  one at a time  from the expanded feature set and re-train the coreference classifier using the remaining features. results are shown in rows 1 of tables 1 and 1  where an asterisk  *  is used to indicate that the corresponding f-measure is significantly different from that in row 1  at p=1 . from these results  we make two observations. first  removing anaphoricity  coreferentiality or ace sem class precipitates a significant drop in f-measure  whichever scoring program is used. interestingly  even though we are faced with data sparseness when computing anaphoricity and coreferentiality  both features turn out to be useful. second  although removing semclass does not result in a significant drop in performance  it does not imply that semclass is not useful. in fact  as mentioned at the beginning of this subsection  semclass appears near the top of the tree. an inspection of the relevant decision tree reveals that the learner substitutes ace sem class for semclass when the latter feature is absent. this explains in part why we do not see a large drop in f-measure. hence  we can only claim that semclass is not important in the presence of ace sem class  a feature with which it is correlated.
entire test setbroadcast news  br newspaper  pa newswire  wi experimentsrpfrpfrpfrpfusing the baseline features only111111111111using soon et al.'s features only111111111111using the expanded feature set111111111111without semclass111111111111without ace sem class111 111111111 without semsim111111111111without pattern based111111 111111without anaphoricity111 111 111111without coreferentiality111 1111111111
1
1
1
1
1
1
1
1
table 1: results obtained via the muc scorer by learning coreference classifiers from the entire ace training corpus.
entire test setbroadcast news  br newspaper  pa newswire  wi experimentsrpfrpfrpfrpfusing the baseline features only111111111111using soon et al.'s features only111111111111using the expanded feature set111111111111without semclass111111111111without ace sem class111 111111 111 without semsim111111111111without pattern based111111111111without anaphoricity111 111111111 without coreferentiality111 1111111111
1
1
1
1
1
1
1
1
table 1: results obtained via the ceaf scorer by learning coreference classifiers from the entire ace training corpus.1 conclusions
in this paper  we investigated the relative contribution of our proposed features for learning-based coreference resolution. while we obtained encouraging results on the ace data sets  we should note that performance gains are limited in part by the difficulty in accurately computing these features given current language technologies. we expect that these features can provide further improvements if we increase the training data and develop even better methods for computing them. as noted before  there have been very few attempts on using corpus-based methods for inducing features for coreference resolution  and we believe our work contributes to the corpusbased induction of semantic and other non-morpho-syntactic features for coreference resolution.
references
 bean and riloff  1  d. bean and e. riloff. corpus-based identification of non-anaphoric noun phrases. in proc. of the acl  pages 1.
 bean and riloff  1  d. bean and e. riloff. unsupervised learning of contextual role knowledge for coreference resolution. in naacl.
 bergsma and lin  1  s. bergsma and d. lin. bootstrapping path-based pronoun resolution. in proc. of coling/acl  pages 1.
 dagan and itai  1  i. dagan and a. itai. automatic processing of large corpora for the resolution of anaphora references. in proc. of coling.
 daume＞ and marcu  1  h. daume＞ iii and d. marcu. a large-scale exploration of effective global features for a joint entity detection and tracking model. in proc. of hlt/emnlp  pages 1.
 ge et al.  1  n. ge  j. hale  and e. charniak. a statistical approach to anaphora resolution. in proc. of wvlc  pages 1.
 hearst  1  m. a. hearst. automatic acquisition of hyponyms from large text corpora. in proc. of coling  pages 1.
 kehler et al.  1  a. kehler  d. appelt  l. taylor  and a. simma. the  non utility of predicate-argument frequencies for pronoun interpretation. in proc. of hlt/naacl  pages 1.
 lappin and leass  1  s. lappin and h. leass. an algorithm for pronominal anaphora resolution. computational linguistics  1 .
 li and roth  1  x. li and d. roth. discriminative training of clustering functions: theory and experiments with entity identification. in conll.
 lin  1a  d. lin. automatic retrieval and clustering of similar words. in proc. of coling/acl  pages 1.
 lin  1b  d. lin. dependency-based evaluation of minipar. in proc. of the lrec workshop on the evaluation of parsing systems.
 luo  1  x. luo. on coreference resolution performance metrics. in proc. of hlt/emnlp  pages 1.
 luo et al.  1  x. luo  a. ittycheriah  h. jing  n. kambhatla  and s. roukos. a mention-synchronous coreference resolution algorithm based on the bell tree. in proc. of the acl  pages 1.
 mccallum and wellner  1  a. mccallum and b. wellner. conditional models of identity uncertainty with application to noun coreference. in advances in nips.
 mitkov et al.  1  r. mitkov  b. boguraev  and s. lappin. introduction to the special issue on computational anaphora resolution. computational linguistics  1 :1.
 ng and cardie  1  v. ng and c. cardie. improving machine learning approaches to coreference resolution. in proc. of the acl.
 noreen  1  e. w. noreen. 1. computer intensive methods for testing hypothesis: an introduction. john wiley & sons.
 phillips and riloff  1  w. phillips and e. riloff. exploiting strong syntactic heuristics and co-training to learn semantic lexicons. in emnlp.
 poesio et al.  1  m. poesio  r. mehta  a. maroudas  and j. hitzeman. learning to resolve bridging 