
to facilitate interactive design  the solutions to configuration problems can be compiled into a decision diagram. we develop three heuristics for reducing the time and space required to do this. these heuristics are based on the distinctive clustered and hierarchical structure of the constraint graphs of configuration problems. the first heuristic attempts to limit the growth in the size of the decision diagram by providing an order in which constraints are added to the decision diagram. the second heuristic provides an initial order for the variables within the decision diagram. finally  the third heuristic groups variables together so that they can be reordered by a dynamic variable reordering procedure used during the construction of the decision diagram. these heuristics provide one to two orders magnitudeimprovementin the time to compile a wide range of configuration.
1	introduction
product configuration is often an interactive procedure. the customer chooses a value for a decision variable. they then receive feedback from the configurator about valid values for the remaining decision variables. this continues until a complete and valid configuration is found.such a scenario requires an efficient mechanism to ensure the current decisions can be consistently extended. hadzic et al. have proposed a two-phase approach for such interactive configuration  hadzic et al.  1 . in the first offline phase  a compact representation is constructed of all product configurations using a decision diagram. this representation is then used by the interactive configurator during the second stage.

	copyright	1  ijcai  www.ijcai.org . all rights reserved.　in this paper  we focus on optimising the first phase of this configuration process: the compilation of the set of valid product configurations into a decision diagram. this is a computationally hard task that can use a significant amount of cpu time and require large amounts of memory. although the first phase is performed offline and is not real-time like the second phase  performance is still important. for many large configuration problems  compilation may require more
tw cse.unsw.edu.au
space and time resources than are available. we propose three heuristic techniques for improving the time and space required to construct a decision diagram representing the set of valid solutions to a configuration problems. these heuristics exploit the distinctive clustered and hierarchical structure observed in the constraint graphs of configuration problems. the first heuristic provides an order in which constraints are added to the decision diagram. this limits the growth in the amount of memory used during construction of the diagram. the second heuristic provides an initial order for the variables within the decsion diagram. finally  the third heuristic groups variables together based on the clustering. these groups are used by a dynamic variable sifting  rudell  1  procedure that reorders variables during the construction of the decision diagram. the combined use of these techniques reduces by one or two orders of magnitude the time to construct decision diagrams for problems from the configuration benchmarks suites  subbarayan  1; sinz et al.  1 . interestingly  the same heuristics perform poorly on satisfiability benchmarks from satlib suggesting that they are highly tuned to the clustered and hierarchical structure of configuration problems.
1	compiling configuration problems
a binary decision diagram  bdd   bryant  1  can be viewed as an acyclic directed graph where edges are labeled by assignments  and a path from the root to the node marked true corresponds to a model. the set of all such paths thus gives the set of all possible models. efficient proceduresexist for constructing and manipulating bdds. to compile the solutions of a configuration problem into a bdd  we can represent every constraint as a separate bdd and conjoin together these bdds. as bdds are added  the size of the resulting bdd grows. for example  figure 1 shows the relationship between the number of constraints added and the number of nodes in the resulting bdd for the renault megane configuration benchmark  subbarayan  1 . the decision diagram grows almost monotonically in size  except at the end where the addition of some critical constraints causes a dramatic drop in size. we observe similar behavior with other configuration benchmarks.
　such growth is surprsing as quite different behavior is typically observed with combinatorial problems. for example  figure 1b shows the growth in the size of the bdd for lang-

 a 

 b 
figure 1: dynamics of bdd growth for  a  the renault megane configuration benchmark and  b  langford 1  problem
ford's numberproblem  gent and walsh  1 . the decision diagram can be orders of magnitude bigger at an intermediate point than at the end. the amount of memory required to represent the intermediate bdd may therefore be more than is available  even though the final bdd representing all problem solutions may be comparatively small. in addition  even if there is adequate memory to represent the intermediate bdd  the time to construct the final bdd is adversely affected since the time to add a new constraint to a bdd depends linearly on the size of the bdd.
　monotonic growth in the size of a decision diagram is highly desirable from the perspective of memory consumption and speed. we therefore tried to identify the structure of configuration problems monotonic behavior. our goal is to use these properties in a more directed manner when constructing a bdd. we begin our investigations with the weighted primal constraint graphs. a primal constraint graph of a problem is an undirected graph where nodes correspond to problem variables and edges describe constraints. two variables are connected by an edge iff they participate in at least one common constraint. the weight of the edge is equal to the number of common constraints involving these two variables. figure 1 shows the constraint graph of a typical configuration benchmark.1 the constraint graph has a distinct tree-like skeleton. it contains a tree of clusters  most of which have a star-like structure with a few central nodes connected to a large number of peripheral nodes. in contrast  the constraint graph of a combinatorial problem like langford's numbers problem is more clique-like.
　the tree-like structure of constraint graphs can help explain the monotonic behavior of bdd. consider an idealised

figure 1: constraint graph of a mercedes configuration benchmark  c1fs .the circles indicate major clusters identified by markov cluster algorithm mcl 
binary constraint problem whose constraint graph is a tree. by ordering the constraints from the root to the leaves of the tree  we can achieve a monotonic growth in the size of the bdd. however  adding constraints in a random order can lead to non-monotonic growth.
　configuration problems also often have strong custered structures. for example  the circles on figure 1 indicate major clusters identified by the markov cluster algorithm mcl   van dongen  1a  for the c1 fs benchmark. a cluster typically corresponds to a group of variables which are very tightly connected. for example  they might describe a single component of the product  e.g.  the engine of the car. adding to the decision diagram all the constraints within a cluster typically reduces the number of valid combinations of the clustered variables and thus the size of the bdd. our hypothesis thus is that configuration problems have a distinctive hierarchical and clustered structured which often permits monotonic growth in the size of the bdd.
1	constraint ordering heuristics
based on these observations  we propose a heuristic for adding constraints that attempts to ensure monotonic growth in the size of the bdd by keeping its size as small as possible on every step. the heuristic attempts:
to respect the tree-like structure of many configuration problems.in particular  we want the heuristic to guarantee monotonic growth in the extreme case when the constraint graph is a tree.
to respect the clustered structure of many configuration problems. in particular  we want the heuristic to add constraints from one cluster at a time.
to keep the number of variables small. typically  a bdd grows in size with the number of variables added.

figure 1: flowchart of algorithm 1
therefore  we want the heuristic to add as few new variables as possible at each step.
　among the many heuristic algorithms that we implemented and evaluated  the following algorithm  referred to as algorithm 1  produced the best results for the majority of the benchmarks. figure 1 shows a flowchart of the algorithm. the internal state of the algorithm consists of a list of constraints already added to the bdd  a list of remaining constraints  a list of variables already added to the bdd  a list of remaining variables and a stack of variables that have been used as central variables  the current central variable is located at the top of the stack . a central variable is one of the most constrained variables of the problem  usually the center of one of the clusters.
step 1. selection of the first central variable. among all problem variables  a variable whose adjacent edges have the largest total weight is selected to be the first central variable. this variable is stored at the top of the stack.
step 1. selection of the first constraint. among all constraints that include the central variable  a constraint with the biggest number of variables in its scope is selected.
step 1. selection of the next constraint. the next constraint to add to the bdd is selected from the set of remaining constraints.
1 all constraints that contain the current central variable are selected from among the remaining constraints. if no such constraints exist  then step 1 terminates without selecting a candidate constraint.
1 from the obtained set of constraints  all constraints that contain the smallest number of variables not yet added to the bdd are selected.
1 from the obtained set of constraints  constraints with the smallest number of variables are selected.
1 for each selected constraint  the sum of weights of adjacent edges of all its variables is computed and those constraints with the largest sum are selected.
the first such constraint becomes the next candidate for being added to the bdd.
step 1. selection of the next central variable.
1 the set of all neighboursof the current central variable is computed  the current central variable is the variable located at the top of the stack of central variables .
1 from the obtained set of variables  all variables that do not participate in scopes of any of the remaining constraints are eliminated.
1 if the obtained set of variables is empty  the current central variable is popped from the stack of central variables and the algorithm returns to step 1.
1 from the obtained set of variables  a variable whose adjacent edges have the largest total weight is selected to be the next central variable. this variable is stored at the top of the stack of central variables. if there are several such variables  the first in the used variable ordering is selected.
　this algorithm selects a central variable and adds all constraints involving this variable  trying to add as few new variables as possible on every step. among all constraints that pass 1 to 1  a constraint containing the most influential variables is selected  since such constraint is more likely to reduce bdd size. then the next central variable is selected from the neighbours of the current central variable. we select the heaviest variable hoping that it will be the center of the next cluster  which is usually the case .
　figure 1 shows the results of applying this algorithm to two configuration benchmarks. the graphs compare adding constraints in a random order  in the original order specified in the benchmark description  and in the order produced by algorithm 1. in both cases  the order produced by algorithm 1 results in almost monotonic growth of the bdd and kept the bdd size smaller than the other two orderings on all steps. as a result  this algorithm significantly reduced the time to construct the bdd. we obtained similar results for other problems from the configuration benchmarks suite  which we were able to solve without the dynamic variable reordering optimisation presented in the following section.
　another interesting feature of the graphs is that the original constraint ordering was much more efficient than the random ordering. we conjecture that the original ordering usually reflects the natural structure of the problem. for example  it typically groups together constraints describing a single component of the product. our constraint ordering heuristic was  however  able to make further improvements to this order.
1	variable ordering
in the previoussection  we showedthat in configurationproblems it is often possible to achieve monotonic growth in the size of the bdd using constraint ordering heuristics. for large configuration problems  this may still not be enough. in order to reduce the space and time requirements of these problems  we would like to find ways to reduce further the size of the bdd. by reordering variables  it is often possible to reduce dramatically the size of a bdd  bryant  1 .

 a 

 b 
figure 1: dynamics of bdd growth when adding constraints in a random order  the original order  and in the ordering produced by algorithm 1 for  a  the c1fs configuration benchmark and  b  the c1fvk configuration benchmark
unfortunately  determining the optimal variable ordering is np-hard  bollig and wegener  1 . heuristics are therefore used in practice. variable ordering techniques can be divided into two groups: static and dynamic variable ordering algorithms. static algorithms compute an ordering of variables before bdd construction. dynamic algorithms attempt to minimise bdd size by improving variable ordering after the bdd has been partially or completely constructed.
　the next sections describe static and dynamic variable ordering heuristics that we developed for configuration problems. these heuristics are based on the following simple observations. first  we observe that locating strongly dependent variables close to each other typically reduces the bdd size. second  if in a group of variables  one or several variables strongly influence the assignments of all other variables  then these variables should be placed higher in variable ordering.
1	static variable ordering heuristics
the proposed static variable ordering algorithm  referred to as algorithm 1  consists of three steps. step 1 finds and groups strongly dependent variables. step 1 orders variable within groups. step 1 orders groups relative to each other.
step 1. first  we identify and group together strongly dependent variables. we employ the fact that configuration problems have clustered structure and assume that variables within a cluster are strongly related to each other  while variables in different clusters are weakly related. we use the mcl algorithm to decompose problem constraint graphs into clusters and group variables belonging to a cluster together in the static variable ordering.
step 1. second  we try to order variables inside clusters so that variables that influence the assignments of other variables are placed higher in the ordering. most clusters found in configuration problems have a small number of central variables connected to a large number of peripheral nodes  see for example figure 1 . typically  the central variables determine the values of the peripheral variables. therefore  we put them first in the variable ordering and sort the rest of the variables by their proximity to the center. the specific algorithm for ordering variables within clusters is as follows:
1. for each variable in the cluster  compute the total weight of all its adjacent edges. we will refer to this value as the weight of the variable.
1. among all variables in the cluster  select a variable with the biggest weight. this variable is considered the center of the cluster and is placed in the beginning of the cluster in the variable ordering.
1. variables in the cluster are sorted by the weight of edges connecting them to the central variable  variables that are not directly connected to the center are pushed to the back of the cluster .
1. variables that are not sorted by the previous step are sorted by their weights  the heaviest variables are put first . variables with equal weights are sorted by the total weight of their neighbours.
step 1. we establish an ordering among clusters: we place clusters that are weakly connected to the rest of the constraint graph in front of other clusters. the assumption is that relatively independentclusters do not increase the size of the bdd greatly. in the extreme case  a completely isolated cluster can be placed in the variable orderingwithout increasingthe size of the rest of the bdd. the degree of isolation of a cluster is determined based on its projection. according to  van dongen  1a   the projection of a node in a cluster is  the total amount of edge weights for that node in that cluster  corresponding to neighbours of the node in the cluster  relative to the overall amount of edge weights for that node  corresponding to all its neighbours  . the projection of a cluster is  the average of all projection values taken over all nodes in the cluster . clusters are sorted in descending order of their projections.
1	dynamic variable grouping heuristics
dynamic variable ordering algorithms try to minimise the size of an existing bdd by reordering its variables. rudell  rudell  1  has proposed a sifting algorithm for dynamic variable reordering and demonstrated that it achieves significant reduction of bdd size for some types of constraint satisfaction problems. the idea of the sifting algorithm is to move each variable up and down in the order to find a position that provides a local minimum in the bdd size. this procedure is applied to every problem variable sequentially. we applied the sifting algorithm provided by the cudd package  glu  1  to configuration benchmarks. we used an adaptive threshold to trigger variable reordering. whenever the bdd size reached the threshold  we performed variable reordering and  if the reduced bdd was bigger than 1% of the current threshold  the threshold was increased by 1%. the initial threshold was equal to 1 bdd nodes. these parameter values were selected empirically.
　panda and somenzi  panda and somenzi  1  noticed that dependentvariables tend to attract each other duringvariable sifting  which results in groups of dependent variables being placed in suboptimal positions. to avoid this effect  dependent variables should be kept in contiguous groups that are moved as one during variable sifting. they developed the group sifting algorithm  which automatically finds and groups dependent variables. in our experiments  not cited here  this algorithm slightly improved performance of variable sifting; however much better performance gain can be obtained by taking into account problem structure. as described in section 1  in configuration problems  groups of dependent variables can be identified based on the cluster decomposition of the constraint graph. we modified the variable sifting algorithm to partition problem variables into contiguous groups corresponding to clusters identified by mcl. grouped variables are kept contiguous by the reordering procedure. in addition  we allow variables within the group to be reordered before performing the group sifting.
　when performing variable grouping  it is important to put only strongly connected variables in the same group and avoid grouping weakly connected variables. therefore  among the clusters found by the mcl algorithm  we only group clusters that have projections bigger than 1.
1	experimental results
we evaluated the three heuristics on problems from the configuration benchmarks suites  subbarayan  1  and  sinz et al.  1 . the algorithms were implemented in c++ using the cudd 1.1 bdd package from the glu 1 library  glu  1  and the implementation of the mcl algorithm obtained from  van dongen  1b . in all experiments  mcl was used with the inflation parameter set to 1. this parameter affects cluster granularity; we select it to be equal to 1 to get fine-grained clusterings. experiments were run on a 1ghz pentium 1 machine with 1gb of ram.
　in most cases  mcl produced a satisfactory clustering of the constraint graph. however  it failed on several large problems: c1 fa  c1 fvf  and c1 fw. in these problems  the majority of variables are grouped into a single cluster as there are several variables connected to virtually every problem variable. therefore whenever mcl encounters a cluster that contains more than half of problem variables  we removed its central variables  which are the heaviest variables in the cluster  and repeated the the clustering algorithm. the removed central variables are placed at the top of the initial variable ordering as they are likely to be influential.
　table 1 gives results of our experiments. as can be seen from these results  the constraint ordering heuristics in algorithm 1  column 1  reduce the time to construct bdds compared to random  column 1  and  in most cases  the original  column 1  constraint ordering. we note that the original constraint ordering typically produces quite good results too. as observed before  we conjecture that the original ordering follows the problem structure very closely. for example  all constraints describing a single component of the product are typically placed contiguously in the original ordering. on the other hand  algorithm 1 is able to find a good constraint ordering even if the constraints are randomly shuffled.
　column 1 shows the effect of the static variable ordering algorithm  algorithm 1  on bdd construction speed. it produced comparable results to the original variable ordering  column 1  and performed an order of magnitude better than the random variable ordering  not given here   which means that we correctly identified the structure of the problem.
　comparing columns 1 and 1  1 and 1 we can see that variable ordering heuristic based on grouping clustered variables reduces bdd construction time compared to pure variable sifting  rudell  1  for the majority of benchmarks.
　interestingly  we also tried these three heuristics on a wide range of satisfiability benchmarks from satlib. we observed uniformly poor performance. we conjecture therefore that configuration problems have an unusual hierarchical and clustered structure which we can exploit when compiling solutions into a decision diagram.
1	related work
hadzic et. al. proposed using bdds to represent the solutions of configuration problems  hadzic et al.  1 . however  they were mainly concerned with reducing the size of the final bdd in order to improve the responsiveness of the configuratorand not with the efficiencyof the bdd construction. in contrast we focus on reducing time and memory requirements for bdd construction. for example  our first heuristic attempts to optimize the order in which constraints are added to the bdd. this does not affect the size of the final bdd  just the size of intermediate bdds.
　sinz  sinz  1  has proposed an alternative approach to the precompilationof the solutions of configurationproblems based on construction of the optimal set of prime implicates.
　static variable ordering techniques have been extensively studied for verification problems. such problems can be described by a model connectivity graph  an analogue of the constraint graph. a number of variable ordering heuristics have been developed based on the topology of model connectivity graph. these heuristics follow the same guidelines as the ones we used in the algorithm 1. namely  they keep strongly connected variables close in variable ordering and put the most influential variables on top  chung et al.  1 . jain et. al.  jain et al.  1  proposed a different approach based on construction of variable orderings for a series of bdds that partially capture the functionality of the circuit. this approach was further developed in  lu et al.  1 . while these methods are specialized to verification  it would be interesting nevertheless to adapt them to configuration and compare with the heuristics described here.
1	conclusions
we have proposed three heuristics for reducing the time and space required to compile the solutions to a configuration problem into a decision diagram. we first showed that the growth in the size of the decision diagram depends strongly on the order in which constraints are added  and proposed a constraint ordering heuristic based on the hierarchical and
constraint orderingrandomoriginalalg 1alg 1alg 1alg 1alg 1alg 1variable orderingoriginaloriginaloriginaloriginal +
siftingoriginal + sifting	+ groupingalg 1alg	1
sifting+alg	1
sifting grouping+
+benchmark1#vars#cons11111renault11111c1 fv111111111d1 m11.1.1.1.1.1.1.1.1c1 fw111111111c1 fs1111.11c1 fvk1-1111c1 fkb1---1-1c1 fr1----1-1c1 fvf1----1--1c1 fa1---1-1c1 fw1---1-1c1 fka1---1-1table 1: comparison of different bdd construction algorithms. columns 1 to 1 show average cpu time spent on bdd construction in seconds across 1 runs. the run-time of mcl algorithm is included.  -  denotes that the given problem could not be solved by the corresponding algorithm either because the bdd size exceeded 1 1 nodes or because it was interrupted after 1 secs.clustered structure of the primal constraint graph of many configuration problems. we further exploited these properties of configuration problems to develop heuristics for static and dynamicvariable ordering. the net effect of the proposed heuristics is one to two orders of magnitude improvement in the time to compile the solutions of benchmark configuration problems. in addition  we were able to solve some problems that could not be solved on our hardware without the heuristics due to memory limitations.
