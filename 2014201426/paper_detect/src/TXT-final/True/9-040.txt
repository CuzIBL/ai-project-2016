 
　　　a programming language for natural language processing programs is described. 	examples of the output of programs written using it are given. 	the reasons for various design decisions are discussed. 	an actual session with the system is presented  in which a small 
fragment of an english-to-french translator is developed. some of the limitations of the system are discussed  along with plans for further development. 
	1. 	overview 
     this paper presents some aspects of work done at odd intervals over the past two years  f i r s t at stanford and then at mit  on a project to develop a pro-
gramming language suitable for writing natural language processing programs. the relevant acronym is lingol  for linguistics oriented language. similar projects such as comit1 and its successors meteor1 and snobol1 no longer reflect the state of the art of computational linguistics; indeed  they do not rise above the remark that computational linguistics is concerned with pro-
cessing text strings. 	the issue addressed in these pages is that of the programming technology appropriate to the syntax-semaotics interface  an artifice that 
arises in the phrase-structure paradigm for natural languages. a secondary issue  to be dealt with else-
where  concerns the relative merits of various parsing strategies for phrase-structure oriented grammars  and the development of a parsing algorithm superior to both the barley and cocke-kasami-younger procedures.  see aho and ullman1   p. 1 . 
　　　following winograd's 	lead  we begin by giving some examples of the output of programs written in lingol. 	the point of having a programming language is to make programming less painful for all concerned. 	the interesting property of these programs is that two of 
them were written in quite a short space of time by students with no experience in either lingol or l i n guistics. another program  the french translator  was designed  written and debugged from scratch for demonstration purposes by the author from 1 a.m. to 1 a.m. of the morning he was scheduled to give a talk on i t . 
　　　the f i r s t program was written in september 1  to test out the f i r s t version of lingol. 	it was a sort of  deep structure  analyzer which attempted to make syntactic remarks about sentences  figure 1 . 	the gram-
mar used in it served as the basis for the next two programs. 
　　　the system languished for six months until a graduate student  bill faught  took advantage of it for a project in an a . i . workshop. he took two weeks to write an english-to-german translator  figure 1 . 
　　　later  faught decided to do some serious work on questioning-answering systems  and soon produced a comprehension program  figure 1  that relied on a relational model of the world in which all related concepts 
were represented in a graph as vertices linked by twoway labeled edges. recently he has produced considerably more impressive results  but it is more appropriate that faught himself report on them. 
　　　the french translator  figure 1  was written by the author early in 1  for demonstration purposes. the program consisted of a page of grammar and semant i c s   a page of dictionary and a page of useful functions for conjugating verbs  arranging agreements of 
articles and adjectives  performing liason and so on  so 
it was not particularly large. 	the point of it was 
i  	it was easy to write; i i   	it was sufficiently succinct to be suitable for 
exhibition; and 
  i i i   it dealt competently with that part of english for which it was defined. 
　　　it is easy to claim that  since this is a toy translator  it says nothing about the real world. this is certainly true with respect to polysemy. however  it is false with respect to extensibility of grammaticla rules; we shall later demonstrate the striking effects obtained on adding very simple rules. more recently  another four hours of work gave a self-tutoring capacity to the program  figure 1 . notice how unknown words are correctly classified as to part of speech before the program requests information. 
　　　we have been basking in these examples somewhat vicariously. it is very much like explaining the advantages and disadvantages of fortran by exhibiting the output of some fortran programs. thus the reader should only infer from these examples the existence of lingol  and a lower bound on what can be achieved with i t ; he should infer its quality or lack of it not from here but from the following. 
	1. 	terminology and perspective 
　　　let us set the stage preparatory to giving some definitions  we need a paradigm for computational linguistics programs  and we choose the translation paradigm as best describing the lingol system. the tranlation paradigm characterizes natural language processing programs as translators from the natural source language to some natural or formal target language  whether french  lisp  structural descriptions  predicate calculus  conceptual dependency diagrams or what have you. no loss of generality is entailed here  for by simply making the target language a programming language  any other paradigm 
may be conveniently emulated. the obvious competitor is the stimulus-response paradigm  in which the input isseen as a stimulus that elicits an action. again 
no loss of generality can occur  since a possible action is to emit an utterance. the main advocate of this paradigm is narasimhan 1 although it appears to be the implicit paradigm in many extant programs. we prefer the former paradigm for no very good reason  although we''do find it easier conceptually to manipulate and characterize utterances rather than actions. in particular  in the programming methodology to be described  large items are gradually built up from smaller ones  and it is tricky to cast this in a stimulus-response format. 
　　　within the translation paradigm we shall identify two main phases  cognitive and generative. the cognitive phase is parsing  in which the input is preprocessed until it is in a form convenient for operation on by the generative phase  which then produces the translation as output. the paradigm itself does not require that one phase run to completion before the other can start. indeed  winograd's program 
makes effective use of feedback from the partial results of his generative routines in guiding the cog-
nitive routines  by attempting to build a semantic structure for  say  a noun group  before continuing with the parsing. 
　　　we are now prepared for the definitions. by syntax is meant all aspects of the source language involved in the cognitive phase  including such things 
as phrase structure rules and semantic markers. by semantics we refer to what is involved 1n going from 

1 

1 

1 

the source language  after the syntactic preprocessing  to the target language during the generative phase. by pragmatics we mean knowledge about the universe of discourse  and the local context  that may be consulted by both the cognitive and generative phases as they make decisions. 
     each of these three concepts has been used many times in the literature  with varying shades of meaning and precision  so we are not redefining previously well-defined terms. rather  we see three main aspects to the programs written in lingol  and found three reasonably uncommitted terms with which to label them.  the first two definitions coincide more or less with those of winograd1  so we are not too far afield.  
     {it may seem paradoxical to include semantic markers in syntax  but this is just the consequence of our usage of the word semantics as opposed to that of  say  katz and fodor1. 	with respect to.our usage  
semantic markers represent an attempt to encode a tiny fragment of pragmatics into syntax  or into linguistics  to use the katz and fodor terminology  and their equation semantics = linguistics - syntax . we do not want to make value judgment; about such an encoding; the example simple serves to illustrate the perspective induced by our definition.  
	1. 	design philosophy 
     there is not one philosophy in lingol  but three  each tuned to the requirements of the three concepts defined above. in the current version of lingol  the 
philosophies are roughly as follows. 
1 	syntax 
     although this paper 1s concerned mainly with the semantic component of lingol  it behoves us to consider syntax since the cognitive phase's output is the generative phase's input. the central decision to be made here is the choice of representation for this output. it seems to be necessary to discover the relations between the words of the sentence  or the 
phrases of the sentence  or the entities denoted by those words or phrases. corresponding to each of these possibilities are dependency structures1 phrase structures  almost everybody  and conceptual dependency networks.1 actually the first two are not mutually exclusive  since it is perfectly reasonable to construct structures which contain all the information of both techniques. we shall use the term syntactic structure to refer to such a coalition  to distinguish it from a concept structure. 
     lingol is meant to be a practical system suitable for export and immediate use by practising computational linguists. the technology for phrase structure is far advanced over any other technology  and every successful program for the past eight years or so has unashamedly used it. also  it is fairly easy to convert a phrase structure system to a syntactic structure system  by tagging each phrase with the 
corresponding governing word together with pointers to the dependent phrases  and hence words . 
     for these reasons  the decision was made to use phrase structure as the output of the cognitive phase  leaving the other representations as projects to be experimented with in the future. it is worth noting 
at this point that the idea of a concept structure is a very powerful one  especially in combination with fillmore's1 notion of case  as suggested by shank1. the notion of phrase concatenation is nowhere near as rich as that of case-based relations between concepts. on the other hand  this does not make phrase-structure a hopeless loser; 1n principle it is possible to construct these relations during the generative phase. however  shank's point 1s that the information so discovered 1s vital to the cognitive phase. more recent phrase-structure systems  including those of bobrow and frazer1  woods1   winograd1 and the system described here make provision for discovering this sort of information while building the phrase structure. this immediately raises the question  why not build the concept structure anyway  since this infor-
mation is being discovered  this point seems unanwerable  and is an excellent area for more research. in the case of lingol  we have a half-answer  in that we have developed what we feel is very nice programming methodology for dealing with phrase structures during the generative phrase. an avenue for research is to see if this methodology carries over to concept structures. 
     given that lingol is based on phrase structure  the next issue is that of the user's language for describing how that phrase-structure is to be.built. the two criteria here are expressive power and ease of use. for our first iteration of lingol  since we were more interested in rapidly developing the semantics tech-
nology  we opted to sacrifice expressive power for ease of use if necessary. this corresponds in a way 
1
to woods and charnlak* assuming the existence of some sort of parser and continuing from there. the differences are firstly that both addressed pragmatic issues while we address semantic  and secondly that whereas they made up their own parsed output  lingol is equipped with a parser  on the philosophy that it is easier to type unparsed than parsed sentences  and 
that no harm is done when the parser gangs agley  which in practice occurs satisfactorily infrequently anyway. 
     the user's language for the cognitive component was therefore chosen to be context-free rules  since these are very easy to write. 	they have exactly the same expressive capacity as wood's transition net-
works1. moreover  just as woods extended the capacity of these networks by allowing the user to specify operations on registers  so do we permit the user to supply code to give hints to the parser whenever it is about to apply a rule. this code has access to the part of the tree built so far by the parser and relevant to the rule in question  and also to the user's data base  or pragmatics  which seems to make semantic markers unnecessary as a special feature of lingol . the form of the hint is a grunt of approval or disapproval  at a 'volume appropriate for the particular hint  and in this respect is just like winograd's numerical treatment of ambiguity1. so far  however  none of the programs written in lingol have made more than trivial use of this feature  in sharp contrast to the use made of the features in the semantics stage. 
     with respect to the actual parser used  the syntax philosophy is that the parser should be transparent to the user  to within the representation of the parts of the tree to which the user's code has access during the cognitive phase. this philosophy has enabled us to run without alteration each of a number of different lingol programs in conjunction with various parsing algorithms. 	the details of these parsers and experiments are beyond the scope of this paper. 
1 semantics 
1      in programming his semantics  the user should be able to work without the distracting detail of parsing  tree representation  and ambiguity. the point of identifying the cognitive and generative phases is to isolate these issues logically in order to achieve this division of labor. whether writing an englishto-french translation program or a question-answering system  there are many details to worry about that have absolutely no relevance to the cognitive phase; the myriad idiosyncrasies of french grammar and style  the various searching algorithms and inference rules that are tightly coupled in a qa system to the surface structure information  and so on. without some method in this large-scale madness  progress is bound 
to be slow. 
     furthermore  we believe that a high level of performance will be forthcoming from the cognitive phase of  say  machine translation programs  long before a similarly impressive level is attained by the generative phase. this is partly because comparatively little work is being done on generative aspects of mt  but more because it is inherently harder to say something with good grammar and style than it is simply to understand what is being said  at least explicitly! . the cognitive phase can ignore most details of style  and many details of grammar. in every program written so far with lingol  the generative component has been about three times the size of the cognitive component  and our prediction is that this ratio will increase as each phase is improved. 
     in taking this point of view  we are following a different philosophy from that of winograd1  who makes use of strong interaction between the syntax and semantics components  which is one of the more notable features of his program. however  the result has been to produce a program whose details are lost in the richness of this interaction  and 1 have heard winograd mutter when looking at a part of the program for  be    i don't remember writing that . 
     for the moment we are willing to sacrifice whatever additional power this approach has to offer for the sake of being able to write clean  modular  transparent semantic code. however  we do not believe that in order to restore this power we need to restore this interaction. instead  we plan to rely eventually on strong interaction between syntax and pragmatics  leaving semantics as the cognition-independent arena. this is not just passing the buck; since we see semantics as being more complex than syntax  we are trying to divide the work-load more evenly to keep all modules reasonably small. how syntax is to consult pragmatics is material for future research. our point is that the bulk of semantics is irrelevant to syntax. 
     the issue now is simply  how does one write programs that operate on trees the output of lingol's cognitive phase   this issue has been addressed by computer scientists in connection with compiling for the past ten years  and the discipline of syntax directed translation has gradually emerged. an early syntax  directed translator is that of warshall and shapiro1. they used the tree-walk paradigm  in which the semantics consists of programs that tell a pointer to move up  down or across the tree and occasionally 
output information. floyd  conversation  has commented that the technique was much too clumsy for practical applications when compared with techniques that tied the semantics to the syntax rather than to tne output of the syntax. it is alarming to find winograd using this approach in his program  which we conjecture would be made more transparent by adopting a more ruleoriented and less tree-oriented approach. 
     some theoretical work has been done on syntaxdirected translation  notably by lewis and stearns1  
	1
knuth   and aho and ullman . knuth's paper is of interest in that it deals with the problem of passing information up and down a tree  using the notions of inherited  from above  and synthesized  from below  
attributes. all of these studies suffer  from the computational linguist's point of view  in that they deal with the microcosm of computer source and target languages  in which the former can be made a compro-
mise between the user's needs and the syntax-directed technology  and the latter is a relatively well-defined  reference-poor language when compared with  say  french. 
     knuth's inherited and synthesized attributes come closest to meeting our needs. the problem with these attributes lies with his mechanism for moving them around a tree. every node through which information is passed must make explicit provision for forwarding i t   even if it is irrelevant to that node. 
for example  consider: 
no mother of such twins has time to relax. 
the mother of no such twins has time to relax. 
the mother of such twins does not have time to relax. 
the mother of such twins has no time to relax. 
 the second sentence is inspired by a study of negation by klima1. it should be said in a tone of horror  with the emphasis on  no   before it sounds correct.  
     in each case  what is being negated is the whole sentence  yet the negation marker can be almost any-
where in the sentence. this implies that a large number of rules will have to make provision for passing a negation marker up the tree. 
     this problem can be circumvented by using global variables instead of knuth's attributes. now all that is needed is for the negation marker to set a negation variable  and for the semantics at the syntactic clause level to read it. 
however  consider the following: 
the mother who has no twins has time to relax. 
     this sentence makes a positive claim  as distinct from the negative one of the previous example  in that it says that there actually are people who do have time 
to relax  namely those mothers who have no twins   moreover  it.does not explicitly say what happens to mothers of twins.  this seems to be a situation where synthesized attributes outperform global variables  since the rule at the relative clause level can simply refuse to pass on the negation marker. 
     negation is not the only such troublemaker. arranging subject-verb  adjective-noun and determinernoun agreement also requires passing information around the tree  especially when translating into french  where word-for-word translation does not necessarily result in correct agreement. again  having more than one clause makes difficult the use of global variables  particularly when a plural relative clause is separating a singular subject from its verb. 
consider the five subject-verb agreements in: 
     as i walked into the saloon  the three men whom jim talked to after i left him yesterday grt up and slowly walked towards me. 
     all of these problems are  marker  type problems. even worse is passing stylistic information from a word at the bottom of a tree to a clause node higher up  where this information is to be used to alter the whole structure of the translated clause. again it is important that the appropriate clause get this information. 
1      the mechanism we want here is that of the local variable  whose scope is the clause with which it is associated. with many clauses we will associate many more local variables corresponding to the various markers and other messages that each clause may want. similarly  we will associate other local variables with noun phrases  to achieve adjective-noun and determinernoun agreement. in the case of the subject  some of these markers  person and number  but not gender  must be shared with the clause as well  to ensure subject-verb agreement  but we do not want the clause to share the object's variables. also  a relative clause such as  who sleeps  needs the same information from its govenor as does the principal clause. moreover  we will want to pass not only markers  but also word-specific programs written at the dictionary level .  winograd1makes use of this technique for puting the right programs in the right places.  the implementation of local variables must be able to handle these combinations. 
     the first version of lingol implemented all of this in an unimaginative and not very general way. eventually  we saw the light and came up with the program paradigm for syntax-directed translation. 
     the program paradigm says that the surface structure tree is a program. 	at each node of the tree there is a function  and the subtrees of that node are the arguments of that function. 	for example  if we have a tree labelled 

this corresponds to the program  print  a + b x  -c -d  . 
　　　since lisp has a mechanism for local variables  two  in fact - prog variables and lambda variables   by adopting the program paradigm we automatically get local variables. moreover  because we can write the code for each function separately  we attain a very high level of modularity  which we have found pays off handsomely when one tries to add new rules to an already operational lingol program. 
     the mechanism we use for running these programs differs slightly from lisp's usual eval operator. the 
main difference is that it evaluates the function at each node f i r s t   giving the function the responsibility for evaluating subtrees at its leisure  and controlling the scopes of variables for different subtrees. 
　　　to illustrate all of this  we shall develop a small french translator. 	imagine we are seated at a 
　　　computer console. 	the following session has all typing errors and stupid mistakes edited out  since they rapidly become boring and obscure the main issues. 	the user input is underlined. 
first we load the system. 

     the cognitive part is a lisp s-expression  or program  that should evaluate to a number to indicate to lingol our satisfaction or otherwise with this choice of interpretation for this word. it is relevant only when a given word has two dictionary entries corresponding to two parts of speech. under these circumstances  we might write a program for each entry to inspect the environment to see how reasonable the corresponding interpretation is. these programs 
would be executed if and when both interpretations were found to make sense given the context to the l e f t   e.g.  it would be executed in  the scout f l i e s . . .   but not in  the big f l i e s . . .     where  flies  is listed as both a noun and a verb. this component of the entry need not concern us further here; we will remain neutral by writing 1 everywhere  unless we happen to dislike the entry itself  in which case we will write - 1   or -1 if we are in a bad mood. 
　　　the generative part is a function destined to be tacked onto the surface structure. 	since words are at the leaves of the tree  they have no arguments. 	in the rase of  the   when the tree is evaluated  the corresponding leaf will return a l i s t of one element  le  as its value. 	the symbol ' is a quotation mark  and 
means   l i t e r a l l y     so as lingol will not think  le  is a program to be executed. the other entries are all similarly structured. the reason we use a l i s t of one 
word rather than the word itself is that we are going to append these lists together to form longer l i s t s . 
　　　now we want a grammar to make sense out of the words in combination. 

each rule is of the form  left right cog gen . the f i r s t two items should be interpreted as a contextfree rule left -  right  where right is either one category or a l i s t of them if more are needed. at present lingol only permits right to have at most two categories; to get more  one should use extra names and rules in the standard way. 
　　　the item cog is exactly as for the corresponding dictionary item  except that it may be invoked for more complex types of ambiguity  usually structural. as with the dictionary  we shall write no non-trivial programs here  although we may occasionally use a negative number when we write a rule which we do not expect to need very often. 
　　　the item gen is a more complex item than its dictionary counterpart  since it can take arguments  which are written !d  down  if right is a syntactic category  and !l  left  or ir  right  if right is a l i s t of two categories. these are not variables but programs which run the program for the corresponding subtree. 
     the f i r s t rule takes the translation of the np and the pred and appends them into a single l i s t . for example  if the np were  le chien  and the pred were 
 aihe le her   then  append !l ir  would produce  le chien aime le mer . the function  reply l t  is a lingol function which allows the generative phase to type out on the console the words in l  followed by the value of t. the variable char is a lingol variable which makes available to the generative phase the character used to terminate the input string.  in the near future we shall give this to the cognitive phase instead  where it belongs.  in this case  we simply echo char back to the console. 

1 

1 

1 


     also we need a new person and no for the object  although gender is all right because it is in the np rule. 

     the reason we keep finding errors is because we are writing the program as though we were beginners. with a little experience  the user can learn to anticipate most of'these problems at the start. 
     this scheme has the advantage that the user is not constrained to any one morphological system  but can write his own in the same language as he writes his semantics. it has another advantage in that 
morphological processing can be interleaved with semantic processing. for example  when lingol gives up on a word altogether  it assigns it the category unknown and supplies the word in the generative phase. if we want to implement thome's closed-class dictionary1  in which unknown words are parsed as nouns  verbs or adjectives depending on which interpretation makes the best syntactic sense  then we could write rules such as 

     notice how the issue of deciding what part of speech the word is dealt with independently of  e.g.  
making  cat  plural. also notice that the parser correctly guessed the parts of speech  and went on to con-
jugate  correctly  the unknown verb  however   cats  is a bit of an anglicism. our program is starting to look quite clever already without our having done very 
much to it yet. 	we have only seven grammar rules  one function  reg  and a few dictionary entries. 
     in the example of figure 1  section 1  the rules involving unknown have for their generative component 
a program that queries the user about the translation. 
     these examples could go on indefinitely. to see what can be achieved with a few more hours work  refer back to figure 1. that example still has very little grammar - approximately twenty rules. however  it has a page of lisp functions for doing liason  vari-
ous agreements  and handling tricky things like les versus des in the object position. 
     these examples bring this section to an end. there 1s no section 1 on pragmatics - this is entirely the user's problem. figure 1  section 1  gives examples from a lingol program in which the user successfully interfaced his semantics to quite non-trivial pragmatics. it is not yet clear whether lingol should ever address pragmatic issues. 
	1. 	conclusions 
     we have described a programming language for natural language processing programs. we discussed the reasons for each of the major design decisions. we presented a session with the system in which we developed a trivial fragment of an english-to-french translator. with adequate imagination  the reader should be able to project at least some of the potential of lingol. what may be more difficult to see are the present limitations of the system. 
     we have already suggested that our separation of semantics from the syntax does not present serious problems. whether this is true we leave to further experiments with lingol. it should be noted that lingol is still in its infancy; so far the author has invested approximately three months' work in i t   over the two and a half years of its existence. 
     at present  conjunction is not handled at all by lingol  except in so far as one may supply contextfree rules for each syntactic category to be conjoined  which is most . this is tedious at best  and is net even always possible. one wants to deal not only with  the chinese have short names and the japanese long  but with  he eloped with and married the farmer's daughter.  neither of these are at all well handled by context-free grammars  regardless of what we write in the cognitive component of our rules. winograd's system deals with these sorts of problems simply by being more procedure-oriented. this provides the necessary flexibility to deal with pathological cases. 
     another difficult area is that of adverbs  which may appear in many places in a sentence  but which always modify the verb of the clause they appear in  unless they modify an adjective . 	it should not be necessary to give rules for each of the places an adverb may appear. 	it suffices to rely mainly on semantic connections to establish the role of the ad-
verb  and this is one place where concept structures 
	 schank1  	are of value. 	it is perhaps significant 
1
that winograd makes no attempt to deal with adverbs. 
     both of these problems will be studied in the near future  to see how best to change lingol to deal with them without losing the attractive programming convenience afforded by context-free rules in conjunction with lisp semantics. 	in the meantime  the system as it stands at present is available from the author for experimental use. 	a lisp environment is required  with at least 1k words of memory. 	an obvious application for lingol is as a pedagogical tool in a computational linguistics course  for introducing students painlessly to one method of writing actu-
al programs that do something useful with english other than parsing it for the sake of the parse tree. we have used it for this purpose during the independent activities period at mit this january. one student wrote an english-to-unpointed-hebrew translator! we ask only that users keep us up-to-date with the uses to which they put lingol. 
1 

bibliography 
work reported herein was supported in part at stanford by the national science foundation under grant no. gj 1  and the office of naval research under grant number n-1-a-1 nr 1; by ibm under a post-doctoral fellowship at stanford; and at the artificial intelligence laboratory  a massachusetts institute of technology research program 
supported in part by the advanced research projects agency of the department of defense and monitored by the office of naval research under contract number n1-a-1. 
reproduction of this document in whole or in part is permitted for any purpose of the united states government . 
1 
