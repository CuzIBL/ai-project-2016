
work in partial satisfaction planning  psp  has hitherto assumed that goals are independent thus implying that they have additive utility values. in many real-world problems  we cannot make this assumption. in this paper  we motivate the need for handling various types of goal utility dependence in psp. we provide a framework for representing them using the general additive independence model and investigate two different approaches to handle this problem:  1  compiling psp with utility dependencies to integer programming;  1  extending forward heuristic search planning to handle psp goal dependencies. to guide the forward planning search  we introduce a novel heuristic framework that combines costpropagation and integer programming to select beneficial goals to find an informative heuristic estimate. the two implemented planners  ipudand spuds  using the approaches discussed above  are compared empirically on several benchmark domains. while ipud is more readily amendable to handle goal utility dependencies and can provide bounded optimality guarantees  spuds scales much better.
1 introduction
classical planning aims at finding a plan that achieves a set of conjunctive goals. partial satisfaction planning  psp  relaxes this all-or-nothing constraint  focusing on finding a plan that achieves the  best  subset of goals  i.e. the plan that gives the maximum trade-off between total achieved goal utilities and total incurred action cost . the process of finding goals on which to focus is complicated by the fact that they interact with one another. for instance  actions may share in their achievement of goals  positive interaction  or conflict  negative interaction . these types of interactions introduce cost dependencies between goals because the cost of achieving them separately may differ from the cost of achieving them together. in the existing frameworks  goals only interact through cost dependencies. in this paper we extend psp to handle utility dependency which allows users to specify changes in utility on sets of goals  thereby increasing its expressive power.
　two concrete examples of utility dependency are mutual dependency and conditional dependency. for mutual dependency  the utility of a set of goals is different from the sum of the utility of each individual goal. for example   1  while the utility of having either a left or right shoe alone is zero  utility of having both of them is much higher  i.e. the goals  complement  each other ;  1  utility of having two cars is smaller than the sum of the individual utilities of having each one of them  i.e. the goals  substitute  each other . conditional dependency is where the utility of a goal or set of goals depend on whether or not another goal or set of goals is already achieved. for example  the utility of having a hotel reservation in hawaii depends on whether or not we have already purchased a ticket to hawaii.
　the main technical challenges in handling utility dependencies are in finding  1  a model where different types of goal utility dependencies can be compactly expressed and  1  an approachthat effectively combines utility interactions with cost interactions to find a high quality plan. the primary contribution of our paper is a systematic approach for handling cost and utility dependenciestogether in psp. in particular we present:
  an approach for representing utility dependencies between planning goals using the generalized additive independence  gai  model  bacchus and grove  1   combining utility theory and deterministic planning.
  an extension of a state of the art integer programming  ip  planner  van den briel et al.  1  to solve this extended psp problem.
  a novel heuristic framework combining cost propagation and an ip encoding to capture mutual dependencies of goal achievement cost and goal utility. this leads to informative heuristics used for guiding a variation of a forward state space search planner.
the two approaches  ip encoding and forward heuristic search  are implemented  resulting in two plannersipudand spuds  and tested on several planning benchmark domains. while the ip approach is more readily amendable to handle goal utility dependencies and can provide bounded optimality guarantees  we shall see that the heuristic search method scale much better.
1 problem formulation
a classical planning problem is a 1-tuple where: fluents f are a set of predicate symbols; initial state i is completely defined by predicates in f; goal state g is partially defined by a set of predicates in f; a set of actions a with a （ a are defined by pre- and post-conditions pre a  add a  delete a    f. a plan p is a sequence of actions that when executed from i achieves all goals g （ g.
　in partial satisfaction planning  psp   smith  1; van den briel et al.  1   goals g （ g have utility values ug − 1  representing how much each goal is worth to the user; each action a （ a has an associated execution cost ca − 1  representing how costly it is to execute each action  e.g. amount of time or resources consumed . let gp   g be the set of goals achieved by a plan p. the objective is to find a plan p that maximizes the difference between total achieved utility u gp  and total cost of all actions a （ p
 i.e.  plan benefit :
		 1 
　work on psp has until now assumed that goals have no utility dependencies and thus their utilities are additive:
.	in order to represent the types of
goal utility dependencies discussed in the previous section  i.e.  complement  substitute  conditional   we adopt the generalized additive independence  gai  model  bacchus and grove  1 . we chose this model because it is expressive  general and we can compile to it from other commonly used models such as ucp-net  boutilier et al.  1 . we assume that the utility of the goal set g can be represented by k local utility functions fu gk  （ r over sets gk   g. for any subsetthe utility of g is:
		 1 
　this model allows users to specify changes in utility over sets of goals. for the rest of this paper  we name the new psp problem with utility dependencies represented by the gai model pspud . if there are |g| local functions fk gk  and each gk contains a single goal then pspud reduces to the original psp problem  no utility dependencies .
1 ip encoding for pspud
since classical planning can be solved by ip  and since ip provides a natural way to incorporate numeric constraints and objectivefunctions  it follows thatpspud planning problems can be solved by ip as well.
　we setup an ip formulation to handle pspud problems by extending the generalized single state change  g1sc  formulation  van den briel et al.  1 . currently  the g1sc formulation is the most effective ip formulation for solving classical planning problems  and it outperforms the previously developed ip formulation used to solve psp problems without utility dependencies  van den briel et al.  1 .
　the g1sc formulation represents the planning problem as a set of loosely coupled network flow problems  where each network corresponds to one of the state variables in the planning domain. the network nodes correspond to the state variable values and the network arcs correspond to the value transitions. the planning problem is to find a path  a sequence of actions  in each network such that  when merged  they constitute a feasible plan. in the networks  nodes and arcs appear in layers  where each layer represents a plan period. the layers are used to solve the planning problem incrementally. that is  we start by performing reachability analysis to find a lower bound on the number of layers necessary to solve the problem. if no plan is found  all the networks are extended by one extra layer and the planning problem is solved again. this process is repeated until a plan is found  see  van den briel et al.  1  for a complete description of the g1sc formulation .
　in order to deal with utility dependencies we incorporate the following extensions to the g1sc formulation:
  in pspud problems not all goals have to be achieved for a plan to be feasible. therefore  we remove those constraints from the g1sc formulation which state that goals must be achieved.
  for each goal utility dependency function gk we add a variable zgk （ {1}  where zgk = 1 if all goals in gk are achieved  and zgk = 1 otherwise.
  for each goal utility dependency function gk we add constraints to ensure that gk is satisfied if and only if all goals g （ gk are achieved  that is:
 1 
 1 
where dc is the domain of a state variable c  yc f g t （ {1} are variables of the ip problem that represent value changes in the state variables  and t is the plan horizon.
  we create an objective function to maximize the netbenefit  utility minus cost  of the plan.

where u gk  represents the utility of satisfying the goal utility dependency function gk  and ca represents the cost of executing action a （ a.
　the extended g1sc formulation is bounded length optimal  i.e.  it generates optimal plans for a plan horizon t . global optimality cannot be guaranteed as there could still be solutions with higher net benefit at longer plan horizons.
1 heuristics for maximizing plan benefit
while ip planners are optimal within a bounded horizon  prior work suggests that heuristic search planners are more efficient and are able to find better solutions in larger problems  van den briel et al.  1 . for pspud problems  the challenge in computing a heuristic for maximizing plan benefit is that we need to simultaneously  1  pick the best set of goals and  1  find the best plan for them. while the first challenge is complicated by the utility dependencies  the second is complicated by the cost dependencies.
　current heuristic approaches for solving psp problems involve planning graph based heuristics that handle cost dependencies by providing an estimate of the cost for achieving each goal. the heuristics then use the goals' defined utility values to select goal subsets that offer the best net benefit on the estimated cost. in this scenario goals have no dependencies on one another. inpspud we must deal with the fact that both cost dependenciesbetween actions and utility dependencies between goals exist.
　in this section we define our search algorithm along with three heuristics that combine planning graph methods with a declarative ip encoding. we generate an ip encoding over the relaxed plan heuristic rather than the entire problem as discussed in section 1. by solving the ip encoding  we select a goal set along with an estimated cost for achieving it. our main innovation is the combination of a relaxed plan that handles cost interactions between goals and a declarative ip encoding that captures both mutual goal achievement cost and goal utility dependencies.
best-first heuristicsearchforpspud : to handlepspud   we use the best-first anytime heuristic search framework in sapaps  van den briel et al.  1 . this forward metric temporal planner uses an anytime variation of the a  algorithm guided by a heuristic derived from the relaxed planning graph. like a   this algorithm starts with the initial state sinit and continues to dequeue from the open-list the most promising node s  i.e. highest f s  = g s  + h s  value . for each search node s  g s  represents the benefit achieved so far by visiting s from sinit and h s  represents the projected maximum additional benefit gained by expanding s  with plan benefit defined in section 1. though calculating g s  is trivial  having a good estimate of h s  is hard and key to the success of best-first search algorithms. during exploration of the search tree the algorithm  which is called a psp  keeps outputting better quality plans whenever a node s with the best-so-far g s  value is expanded. like a   the algorithm terminates when a node s with h s  = 1 is picked from the top of the open list.
　though a psp can keep all generated search nodes  in practice sapaps prunes the search space by removing nodes that that appear unpromising  i.e.  nodes where the estimated benefit is negative . though this improves efficiency  one potential drawback is that when the heuristic h s  underestimates the value of a search node s  then s will be discarded  when compared to the benefit of the best solution found so far g sb   even if it can be extended to reach a better solution. to mitigate this issue  we modified the sapaps search strategy to keep some search nodes that appear unpromising when first generated. during search we set a value  as half the distance between the best node found so far sb and the worst-valued unpromising node. for each unpromising search node s that is within a threshold  of the current best solution  we find ρ  the complement of the percentage distance between it and the benefit of sb  i.e. g sb  . we then keep s with probability ρ.
goal achievement cost propagation: in all of our heuristic methods we estimate the cost c g  to achieve each goal  do and kambhampati  1 . starting with c f  = 1 for facts f in the initial state i and c f  = c a  = ± for all other facts and all actions  the propagation rules to estimate costs to achieve facts p and to execute actions a are1:
  facts:
  either:
1. max-prop:  a （ a : c a  = max c f ; or
f（pre a 
1. sum-prop:  a （ a : c a  =	Σ	c f 
　　　　　　　　　　　　　　　　　　　　　　　f（pre a  the update rules are used while extending the  relaxed  planning graph structure  blum and furst  1 . after the propagation is done  i.e.  no costs change   c g  is an estimate on the cost to achieve g for each goal g （ g.
deriving heuristics from propagated costs: we will use the notation hxy to name our heuristics. here x is the method used to estimate the goal utilities and y is the method used to estimate the goal costs. if utilities and costs are independent  both x and y can be  sum . the dependencies between goal utilities can be estimated using the gai model while the dependencies between goal costs can be estimated using relaxed plans.1
　it is easy to observe that if we use max propagation  maxprop   then c g  will underestimate the cost to achieve g while there is no such guarantee for sum propagation  sumprop   bonet et al.  1 . using c g  calculated by the cost propagation process outlined in the previous section  we can estimate the achievable benefit value as below:
		 1 
　notice that  as part of our heuristic  we the calculate the local utility functions as defined in equation 1. as such  our heuristic directly applies the gai model. if we use max-prop  then equation 1 will give the  heuristic and if we use sum-prop  it will give a corresponding hgaisum heuristic. while hgaimax overestimates the real achievable benefit  there is no such guarantee for hgaisum. thus a psp using hgaimax is guaranteed to output an optimal solution given enough time.
relaxed plan based heuristic: because hgaimax can significantly over-estimate the real benefit of achieving a set of goals  it performs badly in some domains  as we shall see . the hgaisum heuristic  while more informative  relaxes the cost interaction and assumes that plans achieving different goals are independent and do not overlap. to improve on those two heuristics  we adapt the relaxedplan heuristic  first introduced in the ff planner  hoffmann and nebel  1   that solves the planning problem ignoring the delete list. this heuristic improves over hgaisum by taking into account actions contributing to the achievement of several goals. the challenge in extending it to pspud is how to efficiently find a high-benefit relaxed plan in the presence of both cost and utility dependencies.
　let gp+   g be the set of goals achieved by the relaxed plan p+. the relaxed plan heuristic for pspud is:
		 1 
　note that equation 1 looks like equation 1 except that the optimal plan p in equation 1 is replaced by the optimal relaxed plan p+  i.e. achieving maximum benefit  in equation 1. h  gairelax overestimates the real achievable benefit and can be used as an admissible heuristic in  to find the optimal solution for psp problems.
　while finding a satisfying relaxed plan p+ for any given goal set gp+   g is polynomial  extracting requires finding an optimal relaxed plan  highest benefit . this task is np-hard even when we already know the optimal goal set g p+ and actions have uniform cost  bylander  1 . to approximate h  gairelax for pspud we use the following three steps. the first step was introduced in sapaps while the second and third steps are novel:
1. greedily extract a low cost relaxed plan p+ that achieves the largest set of achievable goals.
1. capture the achievement cost dependencies betweenachievable goals using the causal structure of p+.
1. pose the problem of extracting the optimal subplanwithin p+ that takes both cost and benefit dependencies into account as an ip encoding. a solution hgairelax of this ip encoding is used to estimate.
　notice that if we compile the entire relaxed planning graph  rather than just the greedily extracted relaxed plan  we can post the problemof findingh  gairelax as an ip problem. despite its conceptual elegance  we chose not to follow this route as the cost of heuristic computation increases significantly  especially for our progression planner which extracts a relaxed plan at each node .
step 1: heuristically extract a low cost relaxed plan
letbe the set of all achievable goals  c g    ±   we use the planning graph and the propagated achievement costs in section 1 to heuristically extract a low-cost relaxed plan to support g as follows:
1. start with supported facts sf = i  subgoal set sg = and the relaxed plan p+ =  .
1. for each g （ sg select a supporting action a : g （ add a  with lowest execution cost c a  value. update: p+ ○ p+ “{a}  sg ○ sg“ pre a  sf  and sf ○ sf “ add a .
1. repeat until sg =  .
　this backtrack-free process is guaranteed to finish in time polynomial in the number of actions.
step 1: build cost dependencies within p+
because certain actions contribute to the achievement of multiple goals  there are dependencies between the costs to achieve them. those relations can be discovered by using the causal structure of the extracted relaxed plan p+.
　to capture the mutual dependencies between the goal achievement costs  we find the set of actions shared between different partial plans achieving different goals. this procedure utilizes the causal links in the relaxed plan p+.
1. initialize:	 a	（	p+	:	gs a 	=	 ;
;
1. backward sweep fromgoals achievedby p+ and update until fix-point:

　using the procedure above  for each action a  gs a  contains the set of goals g that a contributes to  where the goalsupporting sets gs a  represents the achievement cost dependencies between goals.
step 1: estimate the maximum achievable benefit in this step  we combine the goal supporting set gs a  found in the previous step with the goal utility dependencies fu to find the most beneficial relaxed plan p within p+. one simple approach to find this plan  is to iterate over 1|gp+| subsets  of goals  with gp+ is the set of goals achieved by p+  and compare the benefit of plans p achieving g. however  when |g| is large this approach becomes impractical.1 therefore  we use a declarative approach of setting up an ip encoding with solution representing the most beneficial relaxed plan . note that while ip is generally slow for solving a complete planning problem  the number of actions in the relaxed plan is much smaller  by several orders  than the number of actions in the  relaxed  planning graph. this allows us to find an optimal solution in reasonable time. this is critical because we will build an ip encoding for each search node generated during forward heuristic search. the ip formulation that we set up is very similar to the one described in section 1 but it only allows actions that are in the relaxed plan and it does not create constraints for negative interactions. moreover  additional constraints representing the goal supporting set gs a  found in the previous step are also included to enforce that if a given goal g is selected  then any action that contributes to the achievement of g should also be selected. specifically:
  binary variables:
- : create one binary integer variable xa  xg  xgk.
  constraints:
-  a （ p  g （ gs a  :  1   xg  + xa − 1
- 
-  g （ gk :  1   xgk  + xg − 1
  objective: max 
　solving this ip encodinggives the benefit value of the most beneficial relaxed plan p within p+. the benefit of this p plan can be used as a heuristic to guide
1 empirical results
we have implemented the heuristic framework on top of the
sapaps planner along with the extension to the g1sc encoding discussed in section 1. we call the new planners spuds and ipud and compare  1  ipud;  1  spuds with three heuristics    and hgaisum ; and  1  a version ofsapaps whose heuristic ignores the goal utility dependencies  but whose g-value does not 
　ipud runs with cplex 1  a commercial lp solver  while we use lpsolve version 1  a free solver with a java wrapper  to solve the ip encodings in spuds. we found that lpsolve  while less powerful than cplex  has a shorter setup time and is more suitable for spuds  which sets up an ip encoding at every search node. all tests use a p1.1ghz/1gb ram computer with a 1 second time limit. spudsand sapaps continuously find better solutions until a termination criterion is met.
test problems: we automatically generated the pspud problems from a subset of the propositional planning benchmarks used in ipc1 and ipc1: in zenotravel  airplanes move people between cities; in satellite  satellites turn to objects and take pictures; in rovers  sets of rovers navigate to take samples and images; and in tpp  trucks visit markets to buy products.
　for each domain  we implemented a java program that parses the original problem files and generates the pspud version with action cost and goal utilities randomly generated within appropriate upper and lower bounds. the set of goal dependenciesalong with their utility values are also randomly generated. thus  the number of dependencies  size of the dependencies  set of goals involved  utility values and action costs are all selected within varied lower and upper bounds for each domain. all goals are soft  and therefore planners can trivially solve each problem with the null plan.
　we varied our bounds on action cost and goal set utility values such that each domain focuses on different aspects of utility dependency. in zenotravel  ending a plan with people at various locations increases utility significantly. but flying a person from one location to another has a cost that is only slightly less than the individual utilities of achieving each goal. thus  it is vital to have sets of people at their desired location. in tpp  purchasing items has a cost about equivalent to the individual utility of having the item. however  having items together can change the utility of a plan considerably. the idea is to simulate the benefit of having several items together  e.g.  to build a crate you need wood  nails  a hammer and saw . the satellite domain removes the emphasis on cost. here actions have costs lower than the comparatively higher benefit of having several images together  e.g.  to produce a mosaic image . the domain also adds negative goal utility dependencies  i.e.  substitution  by including negative utility for having certain sets of images yet ending a plan by pointing to an inconvenient spot.1 the rovers domain focuses on substitution as having certain scientific data together gives redundant information and therefore removes a large portion of utility gained by having them separately.
analysis: the empirical evaluation is designed to:  1  compare the effectiveness of the ip-based and heuristic search approaches in solving pspud problems;  1  determine the characteristics ofpspud planning problems which cause our approaches to return plans of differing quality.
　our results in figure 1 show the plan quality achieved by each planning method and the time to reach that quality. on problems where only the null plan was found  we indicate the extensive search for a better plan by setting the time to 1 seconds. for every other instance  the time that the best plan was found is shown. as the figure shows  the tested approaches varied in their relative plan quality on each domain butspudsusing the hgairelax heuristic always performed among the best.
　first  we observe the planner behavior in zenotravel and tpp. both of these domains involve gathering objects  though zenotravel focuses on delivering these objects as well. utility dependencies play an important role in these domains  and we see that sapaps does poorly  while the spudsheuristics and ipud fared much better. since the sapaps heuristic is not informed about utility dependencies this comes as no surprise. in easier problems  the hgaisum heuristic tends to return plans of similar or equal quality as compared with the other techniques used. however  as problem size increases  hgaisum begins to return plans of better quality  but still does worse than hgairelax in terms of the overall numberof plans found with best quality. with ipud  as the size of the problem encoding increases it is unable to find a good feasible solution.
　for our version of the satellite domain  some goal combinations remove utility from the overall quality of plans. also  the plans of higher quality tend to require many actions. this can be seen in the quality of the plans that ipudreturns. its reachability analysis is unable to properly estimate the distance to goals and it therefore begins its solution searching at a small horizon. for the hgairelax heuristic  it turns out that action selection helps guide search toward the goals.
　for the rovers domain  ipud does well on several problems. however  like in the satellite domain  it turns out that better quality plans require a larger horizon on some of the problems than its initial horizon provides. this gives spuds with the hgairelax heuristic an edge over ipud in 1 of the 1 problems. the heuristics hgaisum and hgaimax have information regarding utility dependencies  though  often performs worse than hgairelax  solving 1 of 1 problems with better quality plans  and hgaimax is only able to find the null plan in every problem instance. neither of these heuristics can detect the individual dependencies between actions.

figure 1: the problem results. for each domain we show the results of the problems solved  with later problems within the domain having increasing difficulty . the top graph shows the quality of the solutions found and the bottom graph shows the　also of interest is the time it takes to solve each problem between the heuristic search methods and the ip encoding used in ipud. since thespudsheuristics solve an ip encoding at each search node  they take much longer to compute on larger problems than the procedural sapaps heuristic. unfortunately  sapaps lacks the heuristic guidance necessary to properly select goals with utility dependencies. thoughwe found that the per-node ip encoding of hgairelax increased the time taken to find the solutions for each of our approaches.
amount of time spent per search node by 1 to 1 times over that of sapaps  with the highest increases on larger problems   spudswith theheuristic does better overall.
　when reaching the time limit  1 seconds for our results   sapaps   spuds and ipud return their best solution. in
spudsand sapaps this behavior comes from the best first anytime search and with ipudthis behavior comes from the cplex solver  which can return the best feasible solution found within a given time limit. insights can be obtained by observing the amount of time it takes to find the solution that is eventually returned. we used the anytime behavior to illustrate the scalability of each approach. figure 1 shows  of problems 1 through 1 in each domain  i.e.  the most difficult   which each technique performs best in terms of quality throughouttheir search  e.g.  has the best quality for 1 of the problems at 1 seconds . of our approaches performs the best overall. in the 1 tested problems  it solves 1 instances at 1 seconds better than any other planner. also interesting is that in 1 instances it obtains the best plan of the approaches or one of similar quality  by  similar  we mean within 1% of the best solution . figure 1 shows an example of the anytime behavior in a typical problem  zenotravel problem 1 . we can see that all of the spudsheuristic approaches quickly find a high quality plan  ipudcontinues to improve its solution until the time limit  and sapaps is only able to find a poor quality plan.
1 related work
there has been work on psp problems using orienteering to select goal subsets by david smith  1 . also  van den briel et. al.  1  introduced several planners such as altaltps   sapaps   and optiplan that tackle psp by either greedily selecting goals up-front  heuristically searching for solutions  or compiling the problem into ip. none of those

figure 1: the number of highest quality solutions found during anytime search by each plannerfrom problems1 through 1 in the domains.
planners deal with the utility dependencieswe described. the most recent international planning competition  gerevini et al.  1  included problems with preferences that involved indicating costs on plans that failed to meet preferred constraints. also  prefplan  brafman and chernyavsky  1  can find optimal plans with preferences between goals.
　besides the gai model that we used to represent the utility dependencies  there are several other attractive models such as ucp-net  boutilier et al.  1  and the graphical model  bacchus and grove  1 . while both provide a graphical representation that can make it easier for users to understand the dependencies  the gai model is more general and these modelling methods can be compiled into gai. we also note that pddl1 can represent gai utility dependencies  albeit in an unnatural way.1
it is possible to solve psp problems by modelling them as
mdps  boutilier et al.  1  and extracting a solution from

figure 1: zenotravel  problem 1 anytime behavior for each of the planners.
an optimal policy. however  past experiments have shown this approach fails to scale well even when solving problems without utility dependencies on state-of-the-art mdp solvers  do and kambhampati  1 .
　while we are not aware of work on using an ip encoding in combination with a greedy search for a planning heuristic as in this paper  there has been work on using ip encoding to handle a subset of planning constraints involving continuous resource or temporalvariables wolfman and weld  1; long and fox  1b .
1 conclusion
in this paper  we showed how the gai framework can be used to represent utility dependencies in planning problems and introduced both a heuristic search framework and an ip encoding for solving partial satisfaction problems with utility dependencies  pspud  . though we saw variation in the performance of the planners  spuds using the hgairelax heuristic typically did better than the other methods shown. performance of the hgairelax heuristic indicates that high quality relaxed plan computation can involve significant computation effort  but the extra guidance received pays off more than when lower-quality methods are used. we also see that while ip approaches solve these types of problems  they may have difficulty scaling in problem size. they also typically find solutions at a slower rate than heuristic-based approaches as observed from ipud's performance over time.
　we plan to extend this work further to combine both the quantitative preferences of psp with qualitative models as handled in planners like  brafman and chernyavsky  1 . we are also considering extensions to our model that handle preferences like those seen in the most recent international planning competition  ipc1   gerevini et al.  1 . to improve the performance  we plan on investigating more effective admissible heuristics that more aggressively take into account negative interactions  such as residual cost as described in altwlt  nigenda and kambhampati  1  to improve the heuristic quality.
acknowledgement: we want to thank david smith  wheeler ruml  ronen brafman  william cushing  and the ijcai reviewers for helpful comments on this paper. kambhampati's research is supported in part by the nsf grant iis-1  the onr grant n1 and by a lockheed martin subcontract tt1 to asu as part of the darpa integrated learning program.
references
 bacchus and grove  1  f. bacchus and a. grove. graphical models for preference and utility. in proc. of uai-1  1.
 blum and furst  1  a. blum and m. furst. planning through planning graph analysis. artificial intelligence journal  1-1  1.
 bonet et al.  1  b. bonet  loerincs g.  and h. geffner. a robust and fast action selection mechanism for planning. in proceedings of aaai-1  1.
 boutilier et al.  1  c. boutilier  t. dean  and s. hanks. decision-theoretic planning: structural assumptions and computational leverage. journal of artificial intelligence research  jair   1-1  1.
 boutilier et al.  1  c. boutilier  r. brafman  h. hoos    and d. poole. reasoning with conditional ceteris paribus preference statements. in proc. of uai-1  1.
 brafman and chernyavsky  1  r.i. brafman and y. chernyavsky. planning with goal p