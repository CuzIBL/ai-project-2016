
this paper describes a simple complete search for cumulative scheduling based on the detection and resolution of minimal critical sets  mcs . the heuristic for selecting mcss relies on an estimation of the related reduction of the search space. an extension of the search procedure using selfadapting shaving is proposed. the approach was implemented on top of classical constraint propagation algorithms and tested on resource constrained project scheduling problems  rcpsp . we were able to close more than 1% of the previously open problems of the psplib  kolisch and sprecher  1  and improve more than 1% of the best known lower bounds on those heavily studied problems. other new results on open-shop and cumulative job-shop scheduling are reported.
1 introduction
the resource constrained project scheduling problem  rcpsp  is one of the most general scheduling problem that is extensively studied in the literature. it consists in scheduling a project  which is a set of activities linked with precedence constraints  by means of a set of limited resources while minimizing the total duration of the project. the decision variant of the rcpsp  i.e.  the problem of determining whether there exists a feasible project of makespan smaller than a given deadline  is np-hard in the strong sense. the rcpsp is a very popular and frequently studied np-hard optimization problem and the last 1 years have witnessed a tremendous improvement of both heuristic and exact solution procedures  cf. e.g. the recent surveys given in  demeulemeester and herroelen  1; hartmann and kolisch  1  . the currently best lower bounds on the makespan for the general rcpsp are based on solving linear programs using adequate cutting planes  brucker and knust  1; baptiste and demassey  1 . state-of-the-art techniques for upper-bounds rely on meta-heuristics such as genetic algorithms  ant colony optimization or large neighborhood search. many scheduling problems such as job shop  cumulative job shop and open-shop can be modeled as special cases of rcpsp.
¡¡in this article  we present a pure constraint programming approach based on the exploration of a complete search tree to prove that the project cannot be achieved within a given deadline or to exhibit a feasible project if one exists. the search procedure is based on the detection and resolution of minimal critical sets  mcs   laborie and ghallab  1  at each node of the search. mcss are carefully chosen using a heuristic that tries to minimize the size of the search space. during the search  strong constraint propagation is enforced using classical scheduling constraint propagation techniques such as time-tabling  edge-finding  precedence energy and balance constraints  laborie  1 .
¡¡next section recap the definition of the resource constrained project scheduling problem and introduces some notations. section 1 describes our basic search procedure as well as the heuristic to select mcss. section 1 extends the basic search procedure to perform self-adapting shaving. the last part of the paper consists of experimental results on classical benchmarks  general rcpsp  open-shop and cumulative jobshop problems . for general rcpsp  we show that our approach closes more than 1% of previously open instances and improves more than 1% of best known lower bounds of the famous psplib instances  kolisch and sprecher  1 . the same approach using exactely the same settings was used to close all the hard open-shop instances of  gueret and prins ¡ä 1  in less than 1s cpu time and to improve the best known lower bounds and close several instances of cumulative jobshop  nuijten  1 .
1 model and notations
the resource constrained project scheduling problem  rcpsp  can be formally stated as follows. a project is made of a set of activities a linked by precedence constraints. precedence constraints can be represented by a directed acyclic graph g =  a e  where each node in a represents an activity and each arc  a b  ¡Ê e represents a precedence constraint between a and b. let d a  denote the fixed duration of activity a ¡Ê a and s a   resp. e a   denote the decision variable representing the start  resp. end  time of activity a. a set of discrete capacity resources r is considered  each resource r ¡Ê r having a maximal available capacity q r  over the entire scheduling horizon. each activity a ¡Ê a requires a non-negative quantity q a r  of resource r. the problem is to find a feasible instantiation s of the activity start times such that precedence and resource constraints are satisfied and the schedule makespan is minimal. more formally:
minimize subject to :maxe a 
a¡Êa a ¡Ê a 1 ¡Ü s a  e a  = s a  + d a   a b  ¡Ê e e a  ¡Ü s b  r ¡Ê r  t ¡Ê z+ x
q a r  ¡Ü q r 
a¡Ês t where s t  is the set of activities executing at time t:
s t  = {a ¡Ê a s a  ¡Ü t   e a }
¡¡a resource requirement of activity a on resource r is a triple u =  a r q  where q = q a r    1. if u =
 a r q  is a resource requirement  we will denote a u  = a the activity of u  r u  = r the required resource  q u  = q the required quantity  s u   resp. e u   will denote the start  resp. end  time of the activity of u. we will also denote u r  = {u/r u  = r} the set of resource requirements on resource r. if     u r  is a subset of resource requirements on a resource r  we will denote q    = pu¡Ê  q u  the global resource consumption of r by activities in  .
1 search
1 branching scheme
our branching scheme assumes that a temporal network representing the relations between the time-points of all activities  start and end  using the point algebra of  vilain and kautz  1  is maintained during the search. in our implementation  this is ensured by the precedence graph constraint of ilog scheduler  ilog  1 . we denote  the set of qualitative relations be-
tween time points. if u and v represent two resource requirements  we will denoteif and only if.
¡¡the branching scheme relies on the notion of minimal critical sets  mcs  and their resolvers as introduced in  laborie and ghallab  1 . a mcs is a minimal set of resource requirements on the same resource r that could be executed simultaneously and would  in this case  over-consume resource r. mcss are a natural generalization to cumulative scheduling of the pairs of activities conflicting for the same unary resource in disjunctive scheduling.
definition 1  minimal critical set  a minimal critical set on a resource r is a subset ¦Õ   u r   such that:
1. q r    q ¦Õ 
1.      ¦Õ q    ¡Ü q r 
1. v u v ¡Ê¦Õ¡Á¦Õ s u    e v  is consistent with the current temporal network
¡¡informally  the different ways to resolve a minimal critical set consist in posting a precedence constraint between any two of its activities.
definition 1  resolvers of a minimal critical set  if ¦Õ   u r  is a mcs  we call resolvers of ¦Õ the set of temporal constraints.
¡¡as described in  laborie and ghallab  1   the set of resolvers res ¦Õ  of a mcs ¦Õ can be simplified so as to remove those resolvers ¦Ñ ¡Ê res ¦Õ  for which there exists another resolver ¦Ñ1 ¡Ê res ¦Õ  such that ¦Ñ   ¦Ñ1 given the current temporal network. indeed  in such case  the resolver ¦Ñ is redundant. such a simplification procedure can be achieved in o k1  if k is the size of the mcs using the naive algorithm 1. line 1 allows removing resolver if there exists w such that. in what follows  we assume that the set of resolvers of a mcs has been simplified.
algorithm 1 resolver simplification algorithm 1: procedure simplify resolvers ¦Õ 
1:res ¦Õ  ¡û  1:for all u in ¦Õ do1:for all v in ¦Õ   {u} do1:
1:	for all w in	u v do
1:	if then
1:	keep uv ¡û false
1:
1:	if
1:
1:	return res ¦Õ 

¡¡at each search node  our branching scheme consists in selecting a mcs ¦Õ and branching on its possible resolvers in the children nodes until there is no more mcs. this approach is clearly complete.
1 heuristics
 as all the resolvers consist of temporal constraints of the form where x and y are two time-points  start or end of an activity   we are interested in an estimation of the size of the search space after posting such a precedence constraint. the fraction of the search space that is preserved when adding a precedence constraint is estimated using the complementary of the commitment measure introduced in  laborie  1 .
   let x and y be two time-points with respective lower and upper bound for time value:  xmin xmax  and  ymin ymax . the size of the search space is estimated by the cartesian product of the domain of the two variables  that is  the area of the rectangle  xmin xmax   ymin ymax . the size of the search space that is preserved when adding the constraint is the part of that rectangle above the line x = y as illustrated in figure 1. the fraction of the search space that is preserved can thus be estimated as follows. let:
a =  ymax   ymin + 1  xmax   xmin + 1 
b =  ymax   xmin + 1  ymax   xmin + 1 
cmin = max 1  ymin   xmin  ymin   xmin + 1  
cmax = max 1  ymax   xmax  ymax   xmax + 1  
the fraction is then equal to:

figure 1: preserved search space when adding

in the example of figure 1  this gives a = 1  b = 1 
cmin = 1  cmax = 1  and.
¡¡if ¦Ø is the size of the search space below the current search node  the size of the search space after posting a temporal constraintcan be estimated by.
if ¦Õ is the mcs that is selected to be resolved at the current search node  the size of the search space to explore below the current node can thus be estimated as the sum of the sizes of the search space below each child node  that is: ¦Ø ¡¤ p¦Ñ¡Êres ¦Õ  preserved ¦Ñ . therefore  preserved ¦Õ  =
p¦Ñ¡Êres ¦Õ  preserved ¦Ñ  estimates the fraction of the search space that is preserved when choosing ¦Õ as the next mcs to solve1. our heuristic simply chooses to resolve next the mcs ¦Õ that minimizes preserved ¦Õ  that is  the one that minimizes our estimation of the size of the explored search space. next section provides more details about the mcs selection algorithm.
1 mcs selection algorithm
at each search node  the mcs selection procedure develops a tree of partial mcss where the current partial mcs ¦Õ is extended adding one resource requirement in each child node. by definition of preserved ¦Õ   it is clear that ¦Õ1   ¦Õ   preserved ¦Õ1  ¡Ü preserved ¦Õ . thus  if ¦Õ  is the best mcs found so far  once a partial mcs ¦Õ has been reached such that preserved ¦Õ   ¡Ü preserved ¦Õ   the sub-tree of the mcs selection tree rooted at ¦Õ can be abandoned.
¡¡the algorithm for selecting and branching on a mcs is more precisely described in algorithm 1 using the following notations: id u  is a unique index associated with resource requirement u used to break ties. unranked u  represents all the resource requirements v that can possibly overlap u given the current temporal constraints  and that are such that q v    q u  or q v  = q u  and id v    id u . ¦Õ is the  partial  mcs that is currently being extended. a  partial  mcs is represented by a list of resource requirements: ¦Õ =  u1 ... uk . we denote uk = last ¦Õ  and define the operator ¨ as follows: ¦Õ¨u =  u1 ... uk u ; q = q ¦Õ  is the consumption of the current  partial  mcs; p = preserved ¦Õ  is the preserved search space so far in the current  partial  mcs; ¦Õ  is the best mcs so far and p  = preserved ¦Õ   is the preserved search space of the best mcs so far. the procedure at line 1 calls the mcs rating and selection process on each resource. at line 1  to rate and select mcss for a given resource  the procedure first sorts the relevant sets of requirements v at lines 1 and 1 by decreasing order of q v   using id v  to break ties in order to ensure that each mcs is scanned only once  starting with the smallest mcss  that is  the ones containing the most greedy requirements. the procedure at line 1 returns true if and only if a given requirement u can possibly overlap all the requirements of a partial mcs given the current temporal network. the procedure at line 1 computes the incremental increase of preserved space due to the insertion of a new requirement u in the current mcs ¦Õ. the value of preserved has been described in section 1. the main recursive function for selecting mcss is described at line 1.
algorithm 1 mcs selection algorithm
1: procedure select mcs
1:	p  ¡û +¡Þ
1:	for r in r do
1:	select mcs r 
1:	return ¦Õ 
1: procedure select mcs r 
1:	sort u r  by decreasing q
1:	for all u in u r  do
1:	sort unranked u  by decreasing q
1:	for u in u r  do
1:	rselect mcs r  u  q u  1 
1: procedure rselect mcs r ¦Õ q p 
1:	if q   q r  then	. ¦Õ is a mcs
1:	if p   p  then	. ¦Õ is the best mcs so far
1:	p  ¡û p
1:	¦Õ  ¡û ¦Õ
1:	else	. ¦Õ needs to be extended
1:	u ¡û last ¦Õ 
1:	for all v in unranked u  do
1:	if is unranked v ¦Õ  then
1:	dp ¡û delta preserved v ¦Õ 
1:	rselect mcs r ¦Õ¨v q+q v  p+dp 
1: procedure is unranked u ¦Õ 
1:	for all v in ¦Õ do
1:	ifthen
1:	return false
1:	return true
1: procedure delta preserved u ¦Õ 
1:	dp ¡û 1
1:	for all v in ¦Õ do
1:	dp ¡û dp + preserved u v  + preserved v u 
1:	return dp

the best mcs ¦Õ  that has been scanned by the above procedure is selected as the one to be solved at the current search node. this mcs is simplified using algorithm 1 and the search explores all of its resolvers ¦Ñ ¡Ê res ¦Õ   in the child nodes by decreasing order of preserved ¦Ñ . this order has no effect when the schedule is not feasible as in this case the complete search tree needs to be explored but it helps finding a solution quicker when a solution exists.
1 self-adapting shaving
shaving techniques  torres and lopez  1  provide a good framework for strengthening constraint propagation and avoiding late failures to be discovered in the search tree. they are all based on the following principle: if adding a constraint c in the current node of the search leads to a failure of the propagation  then  constraint  c can be inferred. due to the cost of propagating a constraint c and the potential number of constraints c to try to shave on  shaving techniques are in general computationally expensive.
¡¡to improve the pruning of the search tree  we implemented the following shaving technique based on mcss. if a mcs ¦Õ with resolvers res ¦Õ  = {¦Ñ1 ... ¦Ñk ¦Ñk+1} is such that  i ¡Ê  1..k   adding ¦Ñi in the current schedule leads to a failure of the propagation  then ¦Ñk+1 can be inferred. the complexity for shaving a given mcs ¦Õ of size n is thus in o n1p  where p is the cost of full constraint propagation at the current node. potentially  there is of course an exponential number of mcss to shave on at each search node and we can expect that many of those mcs do not allow inferring any precedence constraint. an idea to speed-up the shaving process is thus to only try shaving on a subset of mcss for which the probability to infer a precedence constraint is greater than a given threshold ¦Á. parameter ¦Á is an input of the shaving algorithm. we can roughly estimate that the probability that adding a precedence constraint  in the current schedule will lead to a failure of the propagation is proportional. if ¦Ñm = argmax¦Ñ¡Êres ¦Õ preserved ¦Ñ  is the resolver of the mcs ¦Õ with maximal preserved search space  we are interested in the mcss that get a high probability that all their resolvers but ¦Ñm will fail  that is  if we assume all the probabilities are independent  the ones such that ¦°¦Ñ¡Êres ¦Õ  {¦Ñm} 1  preserved ¦Ñ   is greater than a given threshold. for those mcss  if the threshold is close enough to 1  we can assume that preserved ¦Ñ  is small enough so that the first order approximation ¦°¦Ñ¡Êres ¦Õ  {¦Ñm} 1   preserved ¦Ñ   ¡Ö
1   p¦Ñ¡Êres ¦Õ  {¦Ñm} preserved ¦Ñ  is reasonable. to summarize  we thus only consider for shaving those mcs scanned by the procedure described in algorithm 1 that are such that preserved ¦Õ    preserved ¦Ñm  ¡Ü ¦Â  ¦Â being a threshold. the computation of this criterion only adds a negligible overhead related with the maintenance of ¦Ñm for each mcs in the mcs selection procedure. due to the numerous approximations  ¦Â is not taken to be constant  theoretically equal to 1   ¦Á . the threshold ¦Â is computed by

1
note that this estimation is exact at the extreme points when
  propagation will fail for sure  and when
  propagation cannot fail becausehas
already been discovered given the current domains of x and y .
self-adaptation in such a way that on average  among the last h shaving attempts  ¦Áh lead to the inference of a new precedence. whenever the number of successful shaving s among the last h ones deviates from ¦Áh  the parameter ¦Â is adapted accordingly: if s   ¦Áh  ¦Â is decreased by ¦Â and if s   ¦Áh  ¦Â is increased by ¦Â. for all our experiments with shaving  we took and start with ¦Â = 1.
1 experimental evaluation
the approach has been implemented on top of ilog
scheduler 1 using the timetable  disjunctive  edgefinder  precedence energy and balance constraints  ilog  1 . all the experiments described in this section were run on a dell latitude d1 laptop  1 ghz. detailed results such as individual lower bounds for each problem instance and new optimal solutions are available at http://scheduler.ilog.fr/.
1 results on general rcpsp
we evaluated our approach on the instances of the psplib
 kolisch and sprecher  1  with 1  1 and 1 activities  resp. sets j1  j1  j1 . for each instance  we solve the feasibility problem of finding a schedule with a makespan lower than t  starting with a legal lower bound for t 1 and incrementing t until either the problem is shown to be feasible  in this case  t is the optimal makespan  or a given time limit for solving the problem with makespan t is exceeded  in this case  t is a legal lower-bound but the search stops without providing any legal upper-bound .
¡¡in a first series of experiments  we use the basic search described in section 1 without shaving with a time limit of 1s. the previous best lower and upper bounds we compare with are the ones reported in the psplib together with the recent improvements on the j1 instances reported in  baptiste and demassey  1 . the results are summarized on table 1 with the following columns:
#o	:number of instances previously open#i	:number of improved lower bounds  % of #o agr:average gap  distance from the lower to the upper bound  reduction when a bound is improved#c	:number of closed instances  % of #o 	inst.	#o	#i	 %i 	agr	#c	 %c 
j11 1% 1%1 1% j11 1% 1%1 1% j11 1% 1%1 1% all1 1% 1%1 1% table 1: results on rcpsp without self-adapting shaving with a time-limit of 1s
¡¡out of the 1 previously open instances  we are able to improve 1 lower-bounds with an average gap reduction of 1% and to close 1 instances.
¡¡to show the effect of self-adapting shaving  we run a version of our approach using self-adapting shaving with the
	inst.	#o	#i	 %i 	agr	#c	 %c 
j11 1% 1%1 1% j11 1% 1%1 1% j11 1% 1%1 1% all1 1% 1%1 1% table 1: results on rcpsp with a self-adapting shaving and a time-limit of 1s
same time-limit of 1s. the results are summarized on table 1. out of the 1 previously open instances  we are able to improve 1 lower-bounds with an average gap reduction of 1% and to close 1 instances. the main conclusion is that  within the same time-limit  the addition of self-adapting shaving slightly increases the performances. the two curves below respectively show  on a particular instance  j1   the number of search nodes with a given depth in the search tree and  for each node depth  the ratio between the number of selected mcss that effectively lead to the inference of a new precedence and the total number of mcss selected for shaving. one clearly see that in the region of the search space where most of the nodes are concentrated  between depths 1 and 1   this ratio is effectively close to the target ratio of 1. in this instance  1 nodes where explored  1 mcss where selected for shaving and among them  1 effectively lead to the inference of a new precedence.


search depth
¡¡given that self-adapting shaving slightly improves the performances within the same time limit of 1s  we used this configuration with an extended time-limit of 1s. the results are summarized on table 1. out of the 1 previously open instances  we improve 1 lower-bounds  that is more than 1% of the previously open instances  with an average gap reduction of 1% and close 1 instances  that is more than 1% of the previously open instances .
1 results on open-shop problems
open-shop problems can be represented as a special cases of rcpsp where all resources have a unit capacity and additional unary resources are used to model the fact that activities of the same job cannot not overlap. we tested our
	inst.	#o	#i	 %i 	agr	#c	 %c 
j11 1% 1%1 1% j11 1% 1%1 1% j11 1% 1%1 1% all1 1% 1%1 1% table 1: results on rcpsp with a self-adapting shaving and a time-limit of 1s
	instance	ub	optim.	instance	ub	optim.
gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*gp11*table 1: results on open-shop with a self-adapting shaving and a time-limit of 1s
approach  with the same settings as in previous section on the open-shop problems instances proposed in  gueret and¡ä prins  1 . those instances are considered to be very hard instances of open-shop problems and serve as classical benchmark in open-shop scheduling  see for instance recent work in  blum  1  . the benchmark consists of 1 instances ranging from 1 jobs ¡Á 1 machines problems until 1 jobs ¡Á 1 machines problems. out of these 1 problems  1 instances are still open. using our approach  we were able to close all those instances in less than 1s cpu time. the optimal makespan for the 1 previously open instances is summarized on table 1 where the column ub corresponds to the currently best known upper-bound for which no optimality proof did exist.
¡¡we also experimented with the open instances of the benchmark of  brucker et al.  1 . we closed 1 of these 1 open instances: namely j1-per1  optimal makespan: 1   j1-per1  optimal makespan 1  and j1-per1  optimal makespan 1 .
1 results on cumulative jobshop problems
we tested our approach  with the same settings  on the cumulative job-shop problem benchmark described in  nuijten  1 . these instances are derived from classical jobshop scheduling problems by multiplying the number of jobs  and thus the number of activities  and the capacity of the resources by a given factor  ¡Á1 or ¡Á1 . our results are summarized on table 1 where lb is the lower bound using the consistency checking described in  nuijten  1  and newlb the new lower bound of our approach. we were able to close the ft1¡Á1 and ft1¡Á1 instances as well as to improve 1 lower bounds out of these 1 open instances.
	instance	lb	new lb	instance	lb	new lb
ft1¡Á11*ft1¡Á11*ft1¡Á11ft1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11la1¡Á11table 1: results on cumulative job-shop with a self-adapting shaving and a time-limit of 1s
1 conclusions
we presented a simple complete search procedure implemented on top of classical constraint propagation algorithms and applied it to resource constrained project scheduling problems. in average  this approach outperforms the best algorithms for finding lower bounds on those scheduling problems  even with a time limit of 1s per optimization step1. using this approach in conjunction with a self-adapting shaving procedure  we were able to close more than 1% of the previously open problems of the psplib and improve more than 1% of the best known lower bounds. what is even more remarkable is that this very same approach allows closing all the hard open-shop instances of  gueret and prins  1¡ä   in less than 1s cpu time although the approach was not particularly designed to tackle disjunctive scheduling and does not exploit the open-shop nature of the problems.
¡¡the understanding of why our method works so well on the instances of the psplib and on many open-shop problems would deserve a deeper study. from one hand  if the problems are highly cumulative  our approach is clearly limited by the explosion of the number of mcss to consider. from the other hand  when problems are highly disjunctive  we could expect other approaches dedicated to disjunctive scheduling to work better. a first possible explanation could be a good fit between our approach and the  disjunctivity  degree of the hard instances of the psplib as suggested by some recent work  garaix et al.  1 . a result of this study could be some kind of hybridizing of mcs-based search with techniques more adapted to highly cumulative problems  mcsbased search being restricted to the resolution of mcss with small preserved search space  thus small mcss  at the top of the search tree. a second direction for future work is the generalization of the notion of self-adapting shaving introduced in this paper to other shaving techniques in scheduling.
