 
　pattern matching and variable binding are easily implemented in conventional computer architectures  but not necessarily in all architectures. in a distributed neural network architecture each symbol is represented by activity in many units and each unit contributes to the representation of many symbols. manipulating symbols using this type of distributed representation is not as easy as with a local representation whore each unit denotes one symbol  but there is evidence that the distributed approach is the one chosen by nature. we describe a working implementation of a production system interpreter in a neural network using distributed representations for both symbols and rules. the research provides a detailed account of two important symbolic reasoning operations  pattern matching and variable binding  as emergent properties of collections of neuron-like elements. the success of our production system implementation goes some way towards answering a common criticism of connectionist theories: that they aren't powerful enough to do symbolic reasoning. 
1. introduction 
　computer scientists and others have long been interested in neural network architectures as a means of exploring the question of intelligence. in the past these architectures have been successfully applied to relaxation problems such as those found in low level vision  marr and poggio  1; barrow and tenenbaum  1; ballard et a/.. 1 ; they have also served as the basis for various pattern recognition and associative memory schemes proposed throughout the years  minsky and papert  1; post  1; hinton and anderson  1 . recently  a movement within al and cognitive science called 
 connectionism  has arisen to investigate massively parallel representations built from simple homogeneous elements as models for higher level cognitive processes. examples include finding the correct reference frame for object recognition  hinton  1   a psychologically plausible theory of word recognition  mcclelland and rumelhart  1   and a mechanism for context-based word sense disambiguation 
 cottrell  1 . 
　to implement the highest level of cognitive functioning  the one responsible for general reasoning  requires some sort of symbolic inference architecture. on a conventional computer this might be provided by a lisp interpreter  a resolution theorem prover  or a production system interpreter  all three of which have certain operations in common  namely pattern matching and variable binding. on a connections architecture these operations can be difficult to implement  especially if distributed representations are used ballard and hayes  1  have suggested one way of performing unification in a connectionist network  but they use a local representation. 
　in a distributed representation each symbol is represented by activity in many units and each unit contributes to the representation of many symbols. manipulating symbols this way is not as easy as with a local representation where each unit denotes one symbol  but there is evidence that the distributed approach is the one chosen by nature. a key problem  then  is how pattern matching and variable binding can be achieved in systems that use distributed representations. in answer to this problem we present two simple production system interpreters implemented as neural networks  in which distributed representations are used for both the wot king memory elements and the production rules. the research provides a detailed account of pattern matching and variable binding operations as emergent properties of collections of neuron like elements.* 
1. two production systems 
　the type of production system we consider here consists of a working memory that contains triples of symbols and a set of production rules that reference this memory. each rule has a 
　left hand side that matches a pair of working memory triples and a right hand side that specifies any number of triples to be added to or deleted from working memory if the rule should fire. variables may appear on the left hand sides of rules  where they act as constraints on the match process  and on the right hand sides where their values are instantiated to define the actions the rules take during firing. our first production system interpreter did not permit variables in the rules; it was conceptually very close to a finite state machine. a sample production rule from this interpreter is shown below. the rule states that if the triples  f a a  and  f b b  are present in working memory  then we may replace them with the triple  g a 
b . 

　'the binary threshold computing elements featured in connectionist models are commonly refened to simply as  neurons.  but the use of this term by us and by most other connectionist researchers should be understood as metaphorical. connections' models are not intended to be physiologically correct in all their detail  they rarely are   rather  they should be computationally interesting and/or psychologically plausible. 

	d. touretzky and g. hinton 	1 
we implemented this interpreter as a neural network simulated 

on a symbolics 1 lisp machine with about 1 binary threshold units; the weights and thresholds were constrained to be small signed integers. the particular values used for weights and thresholds of the various cell types are all predefined program constants; knowledge about rules is stored in the connection patterns of the neurons rather than in the weights. the contents of working memory are encoded in the states  either on or off  of working memory cells. 
　our second production system interpreter is similarly specialized. it accepts rules where a variable appears in the first position of both triples on the left hand side of each rule  and optionally in the first position of right hand side triples. this system interprets rules such as the following: 

　here  the appearance of = x in both left hand side triples means the rule can match pairs such as  f a b  and  f c d   but not pairs such as  f a b  and  g c d . our second interpreter  written as an extension of the first  uses about 1 units and a completely different set of weights. 
1. architecture of the interpreters 
　figure 1 is a schematic diagram of our second production system interpreter  which is composed of five  spaces  of cells.  the first interpreter resembles the second except it is missing the bind cell space.  the central space  labelled wm  is the working memory; it provides inputs to two clause spaces labelled c1 and c1. the clause spaces both influence and are influenced by two other spaces; one of these represents the production rules  while the other implements variable binding and is independent of specific rules. the system in figure 1 is known as a  two stroke production system engine  because it alternately performs each half of the classic production system recognize-act cycle. during the recognize stroke  wm cells exert influence on c1 and c1 cells and a relaxation algorithm is applied to cells in the c1  c1  rule and bind spaces until they settle into a state indicating a match. then  during the act stroke  a set of gated connections from the rule and bind cells to the wm cels is opened  allowing the rule that fires to update the contents of working memory. 
1. working memory 
　working memory elements are triples of symbols. we have chosen an alphabet size of 1 symbols  giving 1 or 1 possible triples. of these  only about half a dozen will be present in working memory at any one time. the most straightforward representation for working memory would be a  local  one  where each possible triple is represented by a 
　specific neuron. then a neuron in the active state would indicate that the corresponding triple was present. we have rejected this idea in favor of a distributed representation known as coarse coding  hinton  1; hinton ef a/.  1  for two reasons. first  local representations require too many neurons and too many connections; they quickly succumb to combinatorial explosion as the alphabet size or the length of a sequence increases. neurons are not used efficiently this way; figu re 1: schematic diagram of our second production system interpreter. 
in the system we are describing  with six items in working memory  only about .1 percent of the working memory cells would be active using a local representation  while in the distributed representation about 1 percent are in use. our second reason for preferring a distributed representation is that a direct tie between individual neurons and symbolic structures is physiologically implausible; it is reminiscent of the yellow volkswagen cell idea. 
　using a distributed representation based on coarse coding we are able to cover the entire space of 1 triples with just 1 cells. each cell has a  receptive field  of 1 or 1 triples  defined by the cross product of six randomly chosen symbols in each of the three positions of a sequence. for example  the cell described in figure 1 has the triples  c b r  and  f a a  in its receptive field  along with 1 other triples. the 1 cells have slightly overlapping receptive fields: the average number of triples in the intersection of two cells' receptive fields is less than one. yet in another sense there is a large degree of overlap  because each of the 1 possible triples falls within the receptive field of  on average  1 different cells. 
1. storing triples in working memory 
　 storing  a triple in working memory using a coarse coded representation means turning on all the wm cells in whose receptive field it falls. on average this is about 1 cells; the number varies from one triple to another due to the random distribution of receptive fields. to test if a particular triple is present in working memory  we can check the fraction of active cells among those that can receive it. if this fraction is close to 1  we may assume the triple is present. for example  let us store the triple  f a a  in working memory. to do so we will turn on the neuron described in figure 1  since  f a a  falls within its receptive field; we will also turn on about 1 other neurons. 

1 	d. touretzky and g. hinton 
notice that  c b r  falls within the receptive field of the cell in figure 1. the total number of receptors common to two unrelated triples is small; the average number is slightly less than one. while 1 out of 1  f a a  cells are active  only 1 out of about 1  c b r  cells will be active. thus we can state with a high degree of confidence that  f a a  is present in working memory but  c b r  is not. 

flgu re 1: the receptive field table of a wm cell. 
1. properties of coarse coding 
　coarse coded memory representations have several interesting features. one is immunity to noise. if we store some triples in wm  then turn a few cells on or off at random  the perceived contents of wm will not change. this is very important because we have allowed some overlap in the representation of triples: as production rules add and delete certain triples from working memory  the overlap will gradually affect the representation of other triples stored there. but because the overlap is small  due to small receptive field size  and the system is immune to small amounts of noise  the contents of wm are reasonably persistent. 
　another interesting feature of the distributed representation is that it gives a gradual degradation of wm performance as the number of elements increases. each triple added to wm increases the number of active cells  and therefore increases the overlap with triples that have not been explicitly added. as wm fills up  the fraction of active cells for triples that are  close  to those that have been stored approaches 1  and the dividing line between present and absent triples blurs. if many closely related triples are stored  such as  f a a    f a b    f a c   etc.  then the system may exhibit local blurring  where it can't tell whether  f a x  is present or not  but it is certain that  g k q  is absent. 
1. clause cells 
　each production rule contains exactly two clauses on the left hand side  where a clause is a specification of a triple. since there are two clauses  each rule must match a pair of wm triples. working memory holds half a dozen triples on average. the clause cells in ci and c1 provide a way to pull out specific working memory triples so they can be matched against the clauses in the production rules. michael mozer of ucsd has independently invented a device similar to clause spaces  which he calls  pull out networks   to allow a perception system to attend to specific objects in a scene  mozer  1 . 
　there are 1 cells in c1 space in one-to-one correspondence with the wm cells; the same is true for c1 space. each wm cell has an excitatory connection to its corresponding c1 and c1 cells. thus  whenever a wm cell comes on  it tends to turn on the corresponding cells in the c1 and c1 spaces. however  clause cells have a mutually inhibitory influence within their own space which is designed to limit the number of active clause cells to about 1 per space  i.e. just enough to represent one triple. the number of active cells in wm space is not regulated. thus  while wm may hold a half dozen or more triples  when the network settles c1 and c1 spaces will ideally hold just one triple each that has been selected out of wm space. 
　it might appear possible for the c1 and c1 spaces to settle into states representing triples that bear no relation at all to the contents of working memory  but instead simply contain 1 active neurons. this is a highly unlikely occurrence because a randomly chosen activation pattern in clause cell space will receive very little support from the rule and bind cells. the system's thresholds and bias levels have been chosen so that a 
　clause cell cannot remain active unless it receives support from a reasonable number of- both rule and bind cells as well as its corresponding wm cell. 
1. representation of rules 
　each production rule is represented by a population of 1 rule cells. let us begin with our first production system interpreter  where the rules contain no variables  as in rule-1 above. the left hand side of this rule references the triples  f a a  and  f b b . each rule cell that contributes to the representation of rule-1 receives input from a random subset of the  f a a  cells in the c1 population  and an equal number of randomly chosen  f b b  cells in the c1 population. if a sufficiently large number of c1 and c1 cells are active  indicating that the triples  f a a  and  f b b  are present in working memory  the rule cell will also become active. 
the 1 cells representing one production rule form a clique. 
each cell in the clique provides a slight excitatory stimulus to the other cells in the clique  and a slight inhibitory stimulus to the rule cells in other cliques. thus  the rule space is organized as a  winner take all  network  feldman and ballard  1 ; when the network settles  all the cells in one clique will be active and all the remaining cells will be inactive. this is how the system decides which rule to fire. 
　one reason for implementing rules as collections of cells rather than as single rule cells is that it allows for a graded response. if  during the settling phase  there is a weak match between one rule and working memory  this will be indicated by only some of the the corresponding rule cells being active. if another rule matches more strongly  more of the cells in its clique will be active  and they will eventually inhibit the cells in the other cliques. 

　another reason for implementing rules with multiple cells is that it frees any one cell from having to represent the entire pattern associated with a production rule's left hand side. instead  each rule cell has just a small amount of information; only the clique as a group has the complete representation for the rule. this is a more plausible organization than one in which each rule is represented by a single cell  since it allows us to limit the number of connections each rule cell must make to other cells. 
1. settling 
　hopfield  1  has shown that the state of a neural network with symmetric connections between units can be usefully described using the following energy measure  where s denotes the state  1 or 1  of the ith neuron  denotes the threshold of the /th neuron  and w1 denotes the weight of the connection between the ith and /th neurons: 

　if neurons change state asynchronously and there is no transmission delay across connections  such networks are guaranteed to settle into a minimum energy state from any starting state. this analogy to physical systems is the basis of the boltzmann machine architecture  fahlman et a/.  1; ackley er a/.  1   but it is also important for non-boltzmann neuron simulators such as the one discussed here. by designing the weights in our production system interpreter so that a successful rule match corresponds to a low energy state  we can match production rules against working memory by starting the network in a high energy state and allowing it to settle into an energy minimum. this is not a foolproof match technique; some problems with it will be discussed later. 
1. rule firing 
　the right hand side of a rule consists of a set of triples to add to working memory and a set to delete from it. a rule can add triples by exciting the wm cells that receive those triples  and it can delete triples by inhibiting those same wm cells. thus  the right hand side of a rule specifies two populations of wm cells: those to be excited and those to be inhibited. the 1 rule cells that represent a rule each make connections  of the appropriate type  either excitatory or inhibitory  to a random subset of the total population of cells the rule is to affect. however  these connections are gated so that the rule cells can only influence the wm cells during rule firing  rather than all the time  and the wm cells cannot influence the rule cells through symmetric connections. although this would appear to violate hopfield's conditions  we can show that during each settling phase the network is equivalent to another network that does not violate these conditions  and thus its behavior during a settling can be understood in terms of energy minimization even though the whole sequence of settlings cannot. 
　once the network of c1  c1  and rule cells has settled into a stable state indicating a match  it is a simple matter to fire the 
	d. touretzky and g. hinton 	1 
right hand side of the rule that matched. this is the rule whose clique of rule cells is active. all we need do is open the gate on the connections between rule space and wm space. each active rule cell will supply a small amount of inhibition or excitation to certain wm cells. if a cell receives enough of these inputs  its state will be changed. once the gate is closed  wm cells retain their most recent state until the gate is opened again at the next rule firing. 
　consider the case where rufe-1 has matched successfully  and it is now time to fire its right hand side. each rule cell will supply excitatory inputs to some of the wm cells that receive the triple  g a b   and inhibitory inputs to some of the wm cells that receive  f a a  or  f b b . to guard against a stray rule cell upsetting the contents of working memory  the weights and thresholds are set so that the concerted action of several rule cells is required to change the state of a wm cell in either direction. in other words  wm cells exhibit hysteresis. 
　the distributed nature of the rule representation means no single rule cell contains a complete representation of a production rule; a rule's successful matching and firing does not critically depend on the behavior of any single cell or small group of cells; and during rule firing a few rule cells can be turned on or off at random without effecting the updating of working memory at all. 
1. variable binding 
　let us now consider rules where a variable appears on the left hand side. in the system as it is currently implemented  the variable must appear in the first position of each triple. rule-1   whose left hand side contains  = x a b  and   = x c d   is an example. this rule can match pairs of triples such as  f a b  and  f c d   but it cannot match the pair  f a b  and  g c d  because the symbol in the first position of each triple is different. 
　to represent the binding of the variable = x we use a device called bind cells. these are similar to the mapping units used for object recognition in  hinton  1 . since there are 1 separate symbols in our alphabet  the variable ＊ x can have 1 possible values. we represent each possible value by a population of 1 bind cells  so there are 1 cells for the symbol a  1 for the symbol b  and so on. bind cells receive input from cells in both c1 and c1 space  and also influence the cells in those spaces. for example  each f cell receives input from a random subset of the c1 and c1 cells that have an f in the first column of their receptive field tables. each group of 1 bind cells forms a clique; every cell in a clique excites its neighbors slightly  and also slightly inhibits the cells in the other cliques. thus  bind space is another winner-take-all network. 
　suppose that wm contained the triples  f a b    f c 1   and a 
　few other random triples such as  g 1 k . suppose rule-1 was present in the network's long term production memory  i.e. in the connections of the appropriate rule cells.  then as settling progressed c1 space would settle into the representation of  f a b  and c1 space would settle into the representation of  f c 1 . 
each f bind cell would be getting excitation from several cells in each of c1 and c1 space  so the f bind cells would become the active clique. also  as the f bind cells become active  they tend 

1 	d. touretzky and g. hinton 
to support c1 and c1 cells representing triples that begin with f  thereby strengthening the representation of  f a b  and  f c d  in their respective clause spaces. 
 one key difference between rules with variables and rules without is in the receptive field size of the rule cells. there are about   cells tnat can receive  fab   but about cells that can receive  = x a b  for any value of  x. so the rule cells must be given larger receptive fields and different connection strengths and thresholds in order to cover the larger number of clause cells matching a triple with a variable in it. a production system interpreter capable of accepting mixed rule types  i.e. some with variables  some without  would be a logical extension to our second system. 
　the settling process by which rule matching is accomplished with variable binding is similar to what was described earlier  except that now c1 and c1 cells are influenced by both rule cells and bind cells  acting independently. however  the two populations of cells tend to work together to force the c1 and c1 cells into representing triples that give a legal rule match. 
1. performance 
　both production systems have run successfully on small test cases  sets of about six rules operating on a working memory holding two to six elements at a time.  in one test  which involved a finite state machine cycling through a series of six distinctive wm configurations  the system ran  overnight  through more than a thousand rule firings with no evidence of memory deterioration or other difficulty. a similar test using rules that involve variable binding gave equally encouraging results. 
　however  we have also found situations that cause problems for the settling algorithm used in rule matching. a trivial case is one where no rule successfully matches working memory; the system will still settle into some sort of local energy minimum  since it must do so. however  it may be possible to detect this no-match condition if it turns out that all good matches have  deep  minima and unsuccessful matches have only shallow minima. in preliminary experiments using two sample production systems  this has in fact been the case. our interpreter was able to reject faulty matches by checking whether the final settling energy of the system exceeded a given threshold. in that case  rather than going on to the firing phase it throws away the match and runs a new settling phase. 
　if there is more than one possible successful match  the two possibilities may interfere with each other. since the rule cells and binding cells compete independently; the state the system finally settles into may have two active cliques in rule and/or bind space  or there might be no active cliques left in one of the spaces. we have chosen to make the simplifying assumption that exactly one rule  with one binding  will be firable during each recognizeact cycle. however  it turns out that this assumption does not eliminate the possibility of interference among rule or bind cells. 
　consider a simple system of five production rules with no variable binding. the first four rules all reference the triple  a a 
a  which is present in working memory  and some other triples which are not present. the fifth rule references the triples  b b 
b  and  c c c   both of which are present. working memory also contains some additional random triples. during settling  the c1 cells corresponding to the representation for  a a a  will get support from four cliques of rule cells  although the rule cells will themselves be only weakly supported because they can get support for their c1 clause but not their c1 clauses. on the other hand  the c1 cells corresponding to  b b b  will be supported only by one clique  since only one rule references that triple  and similarly for the c1 cells representing  c c c . in this case  although only one of the five rules can be fired correctly  the system may still settle on the wrong rule due to the combined influence of the unsuccessful rules  or it may settle into a minimum that does not not represent a successful match at all. 
　obviously  when variable binding is permitted in rules  the potential for unsuccessful settling is increased. one way around such problems might be to use simulated annealing  kirkpatrick  1  as the search technique rather than doing a straight gradient descent in energy space. simulated annealing is a way to avoid getting stuck in local minima  so if there is a good match to be found  we can usually find it. we would then be adopting the boltzmann approach  ackley et a/.  1   which is computationally more expensive to simulate than gradient descent  but a much more effective search technique. we are pursuing this idea in our next generation production system interpreter. 
1. conclusions 
　we have described an implementation of production systems on a neural network architecture in which two common symbolic reasoning operations  pattern matching and variable binding  were performed using distributed representations. the work demonstrates that connectionist architectures are not limited to solving low-level vision problems or implementing associative memory schemes; they can be programmable symbol processors. the success of our production system implementation goes some way towards answering a common criticism of connectionist theories: that they aren't powerful enough to do symbolic reasoning. 
　our results also serve as the beginnings of a theory of symbolic representation in the brain. while the details of our model are not physiologically correct  we have nonetheless made progress by showing how distributed symbolic representations  which are physiologically plausible  can be manipulated effectively. 
　the brain is built from painfully slow and unreliable components: neurons  which fire less than once per millisecond  are susceptible to fatigue  and die off regularly. the only way the brain can succeed as a symbol processor is by exploiting massive parallelism using organizational principles that remain unknown for the present. by exploring the problem of computing with distributed representations  computer scientists may eventually uncover some of these principles. 

acknowledgements 
this research was supported by a grant from the system 
development foundation. 	we thank scott fahlman  jay 
mcclelland  david rumelhart  and terry sejnowski for helpful discussions. 
