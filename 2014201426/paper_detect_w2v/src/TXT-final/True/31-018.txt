 
in many real-world tasks  the ability to focus attention on the important features of the input is crucial for good performance. in this paper a mechanism for achieving task-specific focus of attention is presented. a saliency map  which is based upon a computed expectation of the contents of the inputs at the next time step  indicates which regions of the input retina are important for performing the task. the saliency map can be used to accentuate the features which are important  and de-emphasize those which are not. the performance of this method is demonstrated on a real-world robotics task: autonomous road following. the applicability of this method is also demonstrated in a non-visual domain. architectural and algorithmic details are provided  as well as empirical results. 
1. introduction 
　many real world tasks have the property that only a small fraction of the available input is important at any particular time. on some tasks this extra input can easily be ignored. but often the similarity between the important input features and the irrelevant features is great enough to interfere with task performance. two examples of this phenomena are the famous  cocktail party effect   otherwise known as speech recognition in a noisy environment  and image processing of a cluttered scene. in both cases  the extraneous information in the input can be easily confused with the important features  making the task much more difficult. 
　in this paper  we will use the representation of a neural network's hidden layer  trained to perform a time sequential task  to make predictions of what the next inputs will be. these predictions can be used as a pre-processor for the next inputs; they can provide a mechanism to focus the network's attention on the important features. in the next section  focus of attention is described in greater detail  and the notion of a saliency map is introduced. the cognitive foundations of focus of attention are also briefly explored. in section 1  the task of interest  autonomous road following  is presented  as well as results of using selective attention to improve performance on this task. in section 1  a synthetic problem is described; it contains many of the same difficulties as the road following task  yet lends itself to easier interpretation and analysis. the problem also serves to exhibit the benefits of a saliency map in a non-vision oriented task. finally  in sections 1 & 1  conclusions and suggestions for future research are presented. 
　a previous paper  baluja & pomerleau  1  presented preliminary results of using a task-specific saliency map on two simulated vision-based tasks. the findings of that paper are summarized in section 1; the results of that paper are expanded upon in section 1  to make them applicable to realworld tasks. in this paper  a method used to create an adequate number of training examples for training the saliency map is presented. these issues were not present in the tasks explored in  baluja & pomerleau  1  as the examples were created artificially and were inexpensive to generate. 
1. focus of attention: background and 
implementation 
　focus of attention has been studied in a variety of contexts. one of the largest branches of study has examined attention in static images. for example   triesman & gelade  1   hulbert & poggio  1  describe a study in which a subject recognizes the letter  s  mixed in a field  x 's and  t 's of various colors. the  s  pops out to the subject  suggesting a preattentive and parallel processing of the image. if an object must be distinguished by  conjunctive  features such as color and shape  the search seems to be performed in a more serial fashion  hulbert & poggio  1 . the most commonly accepted analogy for this is termed the  spotlight  hypothesis. the spotlight moves from one location to another  the area in which it focuses are operatively defined to be the areas in which an improved performance is found in the tasks of stimulus detection  identification  localization  or simple and choice response times  umilta  1 . 
　computational models of the spotlight mechanism have been proposed in the context of artificial neural networks  mozer  1  koch & ullman  1 . mozer makes the distinction between  data-driven  and  conceptually-driven  guidance of the spotlight. a simple case of  data-driven  guidance is that the spotlight should be drawn to objects  but not to empty spaces in the visual field. a  conceptuallydriven  spotlight is controlled directly by a  higher level of cognition   goal driven . this is necessary when reading  in which text must be scanned from left to right. 
when longer time intervals are introduced  the process of 
1. it should be noted that a moving the  spotlight of attention  does not necessarily entail eye movements.  umilta  1  discusses the relationship between eye movements and focus of attention. 
　
focusing attention becomes more challenging; objects can move and change. nonetheless  people can routinely solve the problem of focusing  and maintaining  attention on moving and changing objects. this ability to do this with  oddman-out 1 features has been has been called indexing  ullman  1 . the ability to index is a prerequisite for visual motor coordination and object description  trick & pylyshyn  1  . nonetheless  not all items can be indexed in this way.  allport  1  suggests a more complicated procedure  termed  selection-for-action  which introduces the task-specific nature of focusing. information about irrelevant features or objects must be filter out  to avoid crosstalk and confusion with respect to the feature or objects of interest. this model relates to the model presented in this paper. 
　in our attempts to design a mechanism to focus attention  the goal was to create a conceptually driven expectation which can maintain attention on moving objects which may change shape  orientation and position. further  as different tasks will require analyzing different portions of the scene  the focus of attention must be task-specific  selection-foraction . the focus of attention must designate as important only the portions of the scene which are necessary for completing the task. the next section describes the mechanism to implement this type of attention focusing. 
1. creating a conceptually driven saliency map 
　saliency maps have been used in the field of computer vision to direct processing to only the relevant portions of the scene. however  in many studies  saliency maps have been constructed in a bottom-up manner  clark and ferrier  1 . a very cursory summary of the bottom-up approach is that multiple different feature detectors are placed around the input image. each type of feature detector may contain a weight associated with it  to signify the relative importance of the particular feature. the region of the image which contains the highest weighted sum of the detected features is the portion of the scene which is focused upon. the approach taken in this paper is very different. the features and their weightings are developed simultaneously with the saliency map to solve the particular task. in this proposed method  the expectation of where the features will be in the next frame plays a key role in determining which portions of the visual scene are going to be focused upon. this will be explained in this section. 
　the first step in creating a conceptually based saliency map is determining which portions of the image are important. the creation of a saliency map is based upon a very basic analysis of the neural network. the underlying premise is that if a strictly layered  connections are only between adjacent layers  feed-forward neural network can solve a given task  the activations of the hidden layer contain  in ability estimation in irre is made by reconstructing the input image by using linear transformations of the activations in the hidden layer  and comparing the resulting reconstruction with the actual image. the greater the similarity between the actual input image and the reconstructed input image  the more the internal representation has captured the important input features  and therefore the more reliable the network's response. figure 1 provides a schematic of irre. 
　this method is related to auto-encoding networks. in these networks  the output is trained to reproduce the input layer  cottrell & munro  1 . the hidden layer  which is usually used as a bottleneck  captures important features for reconstructing the input. the difference between these networks and the ones employed in this study is that the networks used here were not trained to reproduce the input layer accurately; they were trained to perform well on a specific task. all of the representational power in the hidden units is devoted to solving the task only. the portions of the input which can be reconstructed accurately are the portions of the input which the hidden unit activations have encoded to solve the task. if the requirement of task-specificity did not exist  auto-encoder networks  or methods such as principal components analysis could capture many features of the input. however  the features found by these methods are important for reconstructing the image  not for solving the particular task. as only a fraction of the features found may be important for the task  it is difficult to focus attention on task-specific features based upon these methods. 
　although irre provides a method to determine which portions of the input the network finds important  a notion of time is necessary to focus attention in future frames. instead of attempting to reconstruct the current input  the network is trained to predict the next input  in figure 1  this corresponds to changing the subscript t to t+l  in the reconstructed inputs . the next input is predicted based upon the important task-specific features in the current image. 
　the prediction can be trained in a supervised manner  by training the network to predict the next set of inputs in the time sequence. the training example  the next inputs  may contain noise or extraneous features. however  since the hidden units only encode information to solve the task  the network will be unable to construct the noise in its prediction. more details on this idea  and methods to use the expectation of the next inputs  are described in the next sections. 
1. differences in expectation and realization 
some form  the important information for this task from the input layer. one method of finding out what information is contained within the hidden layer is to attempt to reconstruct the original input image  based solely upon the representation developed in the hidden layer. this method of reconstruction is closely related to input reconstruction reliability estimation  irre   pomerleau  1 . the reli-
1. these are features which are distinguished by attributes such as color  or by motion in an otherwise stationary background. 
1 	action and perception 　to this point  a method to create an expectation of what the next inputs will be has been described. there are two fundamentally different ways in which to interpret the difference between the expected next input and the actual next input. the first interpretation is that the difference between the expected and the actual input is the point of interest because it is a region which was not expected. this has applications in anomaly detection  or in the analysis of visual scenes in which the object of interest is moving across a stationary background. 
　in the second interpretation  the difference between the expected and actual inputs is considered noise. this interpretation is used throughout the rest of the paper. processing should be de-emphasized from the regions in which the difference is large. this makes the assumption that there is enough information in the previous inputs to specify what the important portions of the next image will be. as will be shown in the tasks described in sections 1 and 1  this method has the ability to remove spurious features and noise. it is interesting to note that in this interpretation  it is important that the prediction of the future state not be too accurate. if the prediction matched the next image exactly  the noise in the next image would also be reconstructed. although the network is trained to predict future inputs with example training images which may contain noise  the network is not able to reproduce the noise due to the hidden layer's limited capacity  the task-specific hidden units  and the task-specific nature of training. the implementation of the saliency map is descnbed in the next section. 
1. using expectation to filter noise 
　in this study  the saliency map was used as follows: the difference between the expectation of input imaget+j  derived from input imaget  and the actual input imaget+1 was calculated. this difference image was scaled to the range of 1 to 1. the smaller the difference  the closer the value to 1. each pixel of the difference image was then passed through a sigmoid; alternatively  a hard-step function could have been used. this results in the saliency map. this map indicates the portions of the input to which the network should be paying attention. in order to emphasize these regions for the input  the saliency map is multiplied  pixel by pixel  with input imaget+ . the result after multiplication was used as the input into the network. this has the effect of lowering the activation of the portions of the input which do not match the expectation. the portions of the input which match the expectation are left unaltered. examples of this filtering  for the task of autonomous road following  are shown in section 1. 
　training the neural network with a saliency map may require more pattern presentations than training a network which does not employ one. with feedback to the inputs  the system becomes dynamic. as the training for the task improves  the saliency map becomes more refined  and more of the correct information is filtered out of the images. the images input to the network later in the training process possess different qualities than the those input earlier in training. because the network is trained to reduce the task error  the hidden representation changes to adapt to the new images. this causes changes in the prediction of the next inputs  and the cycle continues. the cycles ends when either the system reaches a stable state or training is stopped. in practice  the system can be trained by using the standard backpropagation algorithm  with small learning rates  albeit with longer training times. 
　one of the problems encountered in focusing attention using this method  is the necessity to determine the features which are important for solving the task before the task is solved. the difficulty is that since the important features are task-specific  and are developed from the network's hidden layer  the task must first be solved. this  chicken-and-egg  problem is avoided in many situations because some of the images used for training may not contain noise. therefore  a small amount of learning is able to proceed without explicit focus of attention. once a few of the important features are determined  the system can  in many cases  bootstrap itself. in the implementations described here  the system is trained to build the saliency map and solve the task simultaneously. 
1. relations to other recurrent neural networks 
　the use of the feedback connections proposed are related to other recurrent neural networks  jordan  1  stornetta  1 . at time t  the jordan network uses feedback from the output units of time t-l  combined with feedback from the context units at time t-l  to create new context units. these units are used as additional inputs in the current time-step. the stornetta architecture uses the context units as a preprocessor of the input units  hertz et. al  1 . the context units are arranged with one-to-one connections with the inputs  and have feedback connections from themselves  which carry activation from the previous time step. 
　there are several important distinctions between the jordan and stornetta architectures and the one used in this paper. the first is that the stornetta architecture uses context units which are able to form arbitrary representations. in the architecture presented here  the feedback is from units which have a very defined task. the feedback is the prediction of the next inputs. also  the feedback is multiplicative  and acts like a filter  unlike the architecture in the jordan networks. 
　another large difference in these networks is that the feedback units are explicitly trained in a supervised manner. in architectures like the stornetta  the context units are trained in a manner similar to the training of the hidden units. the representations which are formed are created to reduce the error in a subsequent output layer. 
　finally  the last difference is in the problems which these architectures are designed to address. although most of the recurrent networks which have been explored in the literature have attempted to address the problem of sequence recognition and reproduction  this architecture is not suited to these tasks as the feedback is restricted to be the prediction of the next inputs. 
1. image based autonomous road following 
　one of the principle motivations for creating an algorithm which can focus attention is to perform visual processing in cluttered scenes. a real-world application which requires such attention focusing is autonomous road following. 
　in the domain of autonomous road following  the goal is to control a robot vehicle by analyzing the scene of the road ahead  and choosing a direction to travel based on the location of important features like lane markings and road edges. this is a difficult task since the scene ahead is often cluttered with extraneous features such as other vehicle  pedestrians  trees  crosswalks  road signs and other objects that can appear on or around a roadway. for the general task of autonomous navigation  these extra features are extremely important; however  for the restricted task of road following  these features are distractions. while we have had significant success on the road following task using simple feed-forward neural networks to map images of the road into steering commands  pomerleau  1   these simple methods fail when presented with cluttered environments like those encountered when driving in heavy traffic  or on city streets. 
1. the alvinn road following system 
　alvinn is an artificial neural network based perception system which learns to control cmu's navlab vehicles by watching a person drive. alvinn's architecture consists of a single hidden layer backpropagation network. the input layer of the network is a 1 unit two dimensional  retina  which receives input from the vehicle's video camera. the correct steering direction is determined from the activation of 1 output units. the output units attempt to create a gaussian centered around the correct steering direction. if the gaussian is centered around unit 1  this indicates the vehicle should make a sharp left  if the center is around unit 1  the vehicle should make a sharp right  etc. to teach the network to steer  alvinn is shown video images from an onboard camera as a person drives. for each image  it is trained to output the steering direction in which the person is steering. 
recently  there has been an emphasis on using the 
alvinn system as a driver warning device. in one of the proposed uses of this system  the model will warn drivers if they begin to drift over lane markings  indicating that they may be entering a lane with on-coming traffic  or leaving the road  etc. . the system must be robust with respect to other road features  such as road and off-road boundaries  cars  or other lane markings. experiments for this task are described in the next section. 
1. eliminating noise using a saliency map 
　the purpose of using a saliency map within this domain is to eliminate features of the road which the neural network may mistake as lane markers  and therefore output an incorrect steering direction. training the network to solve the task by focusing on the important regions of the scene is described below. 
　approximately 1 images were gathered from a camera mounted on the left side of a car  pointed downwards and slightly ahead of the vehicle. the car was driven through city and residential neighborhoods around pittsburgh  pa. the images were subsampled to a 1 pixel representation. in each of these images  a single x location of the lane marker was hand marked around the 1th row.  the total interactive time was -1 minutes . the task is to produce a gaussian of activation in the outputs  centered around the x location of the lane marker in the 1th row of the image. sample images and target outputs are shown in figure 1. 
　in training the network  there are several problems which must be addressed. the first is that there is only a limited amount of training data. further  assuming that the driver has directed the car well  the center line has probably stayed within a small region of the input image. therefore  the network has not been trained to recognize lane-markers outside the middle regions of the image. additionally  because the 
1 	action and perception 
prediction task attempts to forecast future inputs  it is important not to bias the network to memorize the image transitions in the training set. for example  had the driver chosen a slightly different action  the location of the important features in the next set of inputs may have been different. 
　in order to alleviate these problems with the training set  the following modifications were made: in training  extra images were created by translating the original images to the left or right by up to 1 columns. the portions of the image which were not specified after the translation were filled in with the last previous real pixel value in the current row. the output was also translated either to the left or right by the same amount as the image. this translation yields usable images because the camera is pointed downwards. if the camera had been pointed more ahead of the vehicle  more sophisticated rotations would have been required to maintain the correct perspective  as were used in  pomerleau  1 . 
　the sequential nature of focusing attention dictated that these images could not simply be added to the training set. for example  an image at time r  which is translated 1 steps to the left  should not be followed by an image at time t+j which is translated 1 steps to the right. if it were  the important features would jump a large distance  and this is unlikely to happen in practice. to avoid this problem  the expanded training set is used in the following manner: the image at time step t+j is chosen at a random translation which differs by  at most  ＼1 from the image at time step t. this ensures that large jumps of the important features are not present between consecutive time steps. as the network is trained through many passes through the training set  images are seen with different translations. 
　in addition to using the translated images as described above  to ensure that the network learns many of the possible transitions from any image  the errors from predicting 1 potential next input images are used. these 1  next input  images are created as follows: the images at time steps t-1  t1  t  t+j & t+1  are translated by 1 & 1 columns to the left and right. the error between the predicted next state and these 1 images are used for the backpropagation algorithm. this training is done because any of the 1 images are reasonable expectations for the next input  based upon the current inputs. in many tasks  using previous time steps  or time steps beyond t+j may not work  see section 1 . nonetheless  for this domain  the important features  such as the lane markings  will remain relatively consistent for short periods of time  and can be used in training future predictions. 

figure 1: three sample input images and target outputs. image 1 shows the region from which the lane marker was hand selected. in image 1 there is an extra lane marking. in image 1 the lanemarker is not completely visible. 

　after training in the manner described above  the results of this experiment were very promising. the lane tracker was able to remove various types of distracting noise from the images  see figure 1 . the performance of the lane tracker with the saliency map revealed a 1% improvement over the lane-tracker without the saliency map. the improvement was not greater because many of the image in the test set do not contain noise; with these images  a standard ann can be used to accurately estimate the lanemarker position. nonetheless  in order to maintain a user's trust in a driver warning system  it is crucial that false alarms are minimized. further  since the system is designed to take control of the vehicle in hazardous situations  under no circumstances may the system be distracted by spurious lanemarking or similar appearing features. the saliency map has provided an effective mechanism to focus attention on the important portions of the scene. 
　this task is made easier because the relevant features are in approximately the same location in many images  and are very similar in shape. this is not  however  required for the algorithm to work well. example tasks in which this was not the case can be found in  baluja & pomerleau  1  and in the next section. 
1. determining markov transitions in noisy 
environments 
　in this section  we describe a synthetic problem which contains many of the difficulties of the road following task  yet lends itself to easier interpretation and analysis. this problem also serves to demonstrate the saliency map's ability to work in non-visual domains. 
　in this experiment  there are 1 inputs and 1 outputs. only 1 input is turned on  activation of+1  in each example. output 1  o1  should be turned on if the input which is turned on is an input between 1 and 1  i1-i1 ; output 1 should be turned off  activation of -1 . if the input which is on is i1 the role of the output units should be reversed. the inputs turn on in a random order  which is determined at the beginning of the run; the order remains the same throughout the run. these markov chains proceed 1 steps  in which each input is turned on exactly once. after the 1 steps  the cycle repeats. the transitions can span any size gap in the input layer. this is unlike the previous task  of road following  in which features did not make large spatial jumps between successive frames. also  the previous task was not strictly markovian  as many next images were equally possible from each image. 
　the task  as described above  can be solved easily by a standard neural network. in fact  the order of activation is irrelevant. the task becomes more difficult when random inputs can turn on in addition to the input which should be turned on. with the addition of noise  the order of activation becomes important. when there is more than one input turned on  o1 should only be turned on if the underlying markov process dictates that an input i1-i1 should be on. it should not turn on when the markov process dictates  for example  that i1 should currently be on  and random noise has turned on i1. in the cases in which noise exists in the input units  it is necessary to be able to determine what the underlying markov transitions are  in order to determine which activated input is noise  and which is not. it was found that using a network with two hidden layers yielded good performance on this task. as in the previous task  although the hidden layers are connected to the prediction layer  the errors on the prediction do not influence the training of connections from the hidden layer to the input layer. the outputs specifying the next set of inputs is directly analogous to the expectation outputs used in the previous application. 
　several forms of noise were tested in this experiment. the first introduced randomly occurring noise into the input layer. the state of a randomly chosen input is flipped  i.e. if it was activated to +1  it is changed to -1  and vice-versa . with large amounts of training  networks both with and without a saliency map are able learn the appropriate markov transition rules. in fact  a neural network is not necessary for learning the transition rules. a simple method to learn these rules is to count  for each activated input at time t  which inputs turn on in time step t+/. even with a large amount of noise  the transition rules can quickly be found. 
a much harder task is to use a second  independent  
markov process to turn on inputs in a different order. in this task  only one of the processes is of interest  and the other process is noise. for this problem  the simple counting method described above will not work. the motivation for using two processes  instead of simple randomly occurring noise  is that this method more closely relates to real-world tasks  in which distractions may be coherent  structured features or objects which persist through multiple time steps. examples of these include multiple voices or conversations in the context of speech recognition or multiple lane markers in the context of road following. 
1. experiments - results 
　the task described above with two markov processes was conducted as follows: in each input presentation  two inputs were turned on. one corresponded to the actual process of interest  the other to the noise process. approximately every 1 pattern presentations  each process was restarted randomly from a randomly chosen position in each sequence. 
　
see figure 1 for an example. 
　there are two measures of performance for the task described above  each are measured every 1 pattern presentations. the first is to measure how well the transition rules of the real process were discovered. this is determined as follows: each input is individually turned on in separate presentations  total of 1 . for each presentation  the unit with the highest activation in the expectation portion of the outputs is determined. if this corresponds to the next input which would be turned on if the sequence was being presented  the output is correct. 
　the second measure of performance is how well the networks perform on the main task  turning on either o1 or 1 . this is determined as follows: the error on 1 pattern presentations is measured. the inputs include noise from the distracting process. to ensure that the network has not memorized how to de-emphasize the noise process when started in a particular position with respect to the real process  the noise and real process are restarted 1 times in random locations. the sum square errors  over all presentations  on the two output units are summed. 
　there are three training methods examined in this paper  these correspond to training the hidden units using the training signal from either the main task  or the expectation outputs  or both. the training method which corresponds to the method used with the lane-marking task  described in the last section  is  main-task only . in the  prediction task only   only the errors from the expectation are used to train the hidden units. the features developed for solving the prediction task must be used to reduce the main task error. in the  both tasks  training procedure  errors from the expectation outputs and the main task outputs are used. 
　all three of these methods are attempted with and without the saliency map. a typical run is shown in figure 1. the large oscillations in performance are due to the significant noise in the training and testing. if the network recognizes the wrong features  and mistakes the noise process for the real process  errors increase dramatically. the results for all six of the training sessions are shown below  in tables i & ii. runs are continued for 1xl1 pattern presentations. in order to judge whether the differences in the average performances are relevant  the significance for the differences in sum squared error are measured here. each network was trained 1 times  with random initial starting weights. for these tests  a two sided mann-whitney test is used at the 1% significance level. this test is a non-parametric  the underlying distribution is not assumed to be normal  equivalent of the standard two-sample pooled /-test. the differences in the means  measured by both criteria  are significant between 
1 	action and perception 
　
by both error metrics  than when the main task is used. this indicates that in this task  the errors from the main task must be used to improve performance on the main task and on the prediction task. 
1. conclusions 
　in this paper  a method for focusing attention on the portions of the input which are important for completing a particular task was presented. this method of using attention has been demonstrated in both visual and non-visual domains with promising results. the artificial neural network used in this study was able to avoid distractions by focusing attention on only the relevant portions of a scene. the feedback mechanism which is presented in this algorithm is more restricted in comparison to other recurrent neural network architectures. nonetheless  it is enough to focus processing to relevant portions of the input. the resulting network can be trained by using the standard backpropagation learning algorithm. extensions to the presented architecture can use methods of encoding task context  such as  jordan  1   in addition to the attention mechanisms. 
　unlike many of the previous studies which use neural networks to predict future states  this work has presented an algorithm which relies on the limited accuracy of the neural network's future state prediction. the premise of this algorithm is that future event prediction cannot be perfect. in particular  the network cannot accurately predict the future states when the future states contain noise or spurious features. by analyzing the difference between what is expected in the next time step and what is actually present in the next time step  it is possible to determine which of the features in the input retina are noise  and which are important to completing the particular task. 
　in this paper  we have demonstrated the applicability of this algorithm on a real-world application  that of autonomous road following. the algorithm is able to avoid being misled by extra lane markings  and other features which have very similar appearances  which could cause the algorithm to steer the vehicle incorrectly. one of the future directions is to use this network in a driver run off-road warning and control system. other future directions for study are presented below. 
1. future directions 
　relations to kalman filtering and pca analysis are currently being analyzed. in addition  alternative implementations of the saliency map are also being investigated. these include alternative methods to apply the information in the saliency map  and the use of additional previous inputs for more time-context. 
　an open question is from which hidden layer s  should the expectation be constructed  different hidden layers will contain information at different levels of transformation from the original inputs. another direction for future research is using the saliency map as a tool for interacting with other knowledge-sources. the information in the saliency map can be useful for high-level attribute selection and weighting in other algorithms. another form of interaction between the saliency map and external knowledge sources is using the knowledge sources to create or augment the saliency map directly. this interaction can provide  suggestions  to where the network needs to devote attention. 
acknowledgments 
　thanks are extended to the anonymous referees for their very helpful and constructive comments. 
　shumeet baluja is supported by a national science foundation graduate fellowship. support has come from  perception for outdoor navigation   contract number daca1-c-1  monitored by the us army topographic engineering center  and 
 unmanned ground vehicle system   contract number daae1-c-r1  monitored by tacom . support has also come from the national highway traffic safety administration under contract number dtnh1-c-1. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing official policies  either expressed or implied  of the national science foundation  arpa  or the u.s. government. 
