
in this paper we address the problem of inferring the topology  or inter-node navigability  of a sensor network given non-discriminating observations of activity in the environment. by exploiting motion present in the environment  our approach is able to recover a probabilistic model of the sensor network connectivity graph and the underlying traffic trends. we employ a reasoning system made up of a stochastic expectation maximization algorithm and a higher level search strategy employing the principle of occam's razor to look for the simplest solution explaining the data. the technique is assessed through numerical simulations and experiments conducted on a real sensor network.
1 introduction
in this paper  we are interested in recovering a topological representation of a sensor network embedded region that identifies physical inter-sensor connectivity from the point of view of an agent navigating the environment figure 1 ; as opposed to a description of the network's wireless communication connectivity  the conventional use of the word topology in wireless networks .
　we assume that we have no prior knowledge of the relative locations of the sensors and that we have only unlabelled observations of activity in the environment  i.e. we make the pessimistic assumption that the objects being observed cannot be distinguished from one another . we must use observational data returned from our sensors to understand the motion of agents present in the environment. by inferring underlying patterns in their motions we can then recover the relationships between the sensors of our network.
　our approach employs a reasoning system that is built on a fundamental topology inference algorithm that takes the sensor observations and environmental assumptions as inputs and returns the network parameters. this algorithm is formulated using monte carlo expectation maximization  mcem   but it depends on fixed values for certain numerical parameters that represent a priori knowledge regarding traffic patterns in the environment. the reasoning system searches over the input parameter space of the fundamental algorithm

	 a 	 b 
figure 1: example of a sensor network layout  a  and corresponding topology  b .
to find a global solution that optimizes a more abstract objective function based on the principle of occam's razor. 1
　the final output of our approach is a probabilistic model of the sensor network connectivity graph and the underlying traffic trends. the simplest application of this work would allow a set of sensors to be  dropped  into an environment and to automatically learn the topology of their layout. this autonomous calibration ability can be considered a step towards the larger goal of self-configuring intelligent systems. the information could be used in the self-calibration of a monitoring application or for route-planning purposes in a hybrid system employing a mobile robot. additionally  applications that log data for offline analysis should be able to benefit from our technique. for example  a vehicle monitoring network distributed about a city could help make decisions about road improvements which might best alleviate congestion.
　the topology of a sensor network  as we define it  must take into account the spatial constraints of the environment as they determine the inter-node connectivity parameters. the topological mapping problem has been well explored in mobile robotics  shatkay and kaelbling  1   choset and nagatani  1   remolina and kuipers  1   ranganathan and dellaert  1 . most sensor network related investigations  however  have been more recent  makris et al.  1   marinakis and dudek  1 ; the outcome is generally a graph where vertices represent embedded sensors in the region and edges indicate navigability. by combining this topological description with any additional metric information obtainable from the surrounding environment  further information regarding obstructions and motion corridors could be inferred. for example  two spatially proximal nodes that were not topologically adjacent would suggest a barrier of some sort.
　while much of the research conducted on sensor networks is based on developing distributed and efficient algorithms appropriate for networks of low-powered sensor platforms  recently there has been a shift towards more complex approachesincorporatingadvancedprobabilistic techniquesand graphical models  ihler et al.  1   paskin et al.  1 . the traditional sensor network assumption of homogenous systems of impoverished nodes is making way for tiered architectures that incorporate network components of some computational sophistication  dantu and sukhatme  1 . note that a hierarchical arrangement based on computational power holds true for several real world sensor networks  especially in data collection systems  wang et al.  1 .
　one problem in sensor networks that occasionally requires above average computational effort is the processing of distributed and information-poor observations. for example  in  songhwai oh and sastry  1   event detections alone were used for the tracking of multiple targets using markov chain monte carlo  mcmc . similarily   pasula et al.  1  approached a traffic monitoring problem using limited sensor data observations through a stochastic sampling technique.
　a related problem domain that generally employs a complex probabilistic framework and computationally intensive techniques is the simultaneous localization and mapping  slam  problem in mobile robotics. recently hybrid robot / sensor network systems have been employed to address slam issues. examples include  rekleitis et al.  1  in their use of an extended kalman filter  and  djugash et al.  1  who incorporate inter-sensor range data from a deployed sensor network in their approach.
　in remainder of this paper we describe a computationally heavy but powerful approach for constructing a topological representation of a network embedded region based on distributed observations collected from passive  informationpoor sensors. our approach builds on some recent work  marinakis et al.  1   marinakis and dudek  1  that has shown the validity of an mcem-based algorithm for sensor network topology inference. this technique uses only detection events from the deployed sensors and is based on reconstructing plausible agents trajectories. however  the algorithm requires significant prior knowledge regarding local traffic patterns that limit its general applicability. in the approach presented here  we incorporate the fundamental algorithm developed in this previous work into a higher level reasoning system that is able to remove much of its reliance on prior assumptions.
1 problem description
we describe the problem of topology inference in terms of the inference of a weighted directed graph which captures the spatial relationships between the positions of the sensors' nodes. the motion of multiple agents moving asynchronously through a sensor network embedded region can be modeled as a semi-markov process. the network of sensors is described as a directed graph g =  v e   where the vertices v = vi represent the locations where sensors are deployed  and the edges e = ei j represent the connectivity between them; an edge ei j denotes a path from the position of sensor vi to the position of sensor vj. the motion of each of the n agents in this graph can be describedin terms of their transition probability across each of the edges an = {aij}  as well as a temporal distribution indicating the duration of each transition dn. the observations o = {ot} are a list of events detected at arbitrary times from the various vertices of the graph  which indicate the likely presence of one of the n agents at that position at that time. in other words  each observation is identifiably generated by one of the sensors.
　the goal of our work is to estimate the parameters describing this semi-markov process based on a number of assumptions. we assume that the behavior of the agents can be approximated as being homogeneous; i.e. the motion of all agents are described by the same a and d. in addition  we must make some assumptions about the distribution of the inter-vertex transition times. generally  we make the assumption that the delays are normally distributed and bounded within a fixed range. we will show later  however  that we relax this assumption in some situations.
　given the observations o and the vertices v   the problem is to estimate the network connectivity parameters a and d  subsequently referred to as θ.
1 fundamental topology inference algorithm
the fundamental topology inference algorithm used by our technique infers the connectivity of a sensor network given non-discriminating observations. it assumes knowledge of the number of agents in the environment and additionally  requires some prior information regarding motion patterns in the system. the inference algorithm is based on the statistical technique of expectation maximization  em . it constructs plausible trajectories of agent motions based on current estimates of connectivity parameters  e step   and then updates the parameters to maximum likelihood estimates based on the sampled trajectories  m step . in this section  we will briefly outline the methodology behind this technique; full details can be found in  marinakis and dudek  1 .
　the algorithm simultaneously converges toward both the correct observation data correspondences and the correct network parameters by iterating over the following two steps:
1. the e-step: whichcalculates the expectedlog likelihood of the complete data given the current parameter guess:

where o is the vector of binary observations collected by each sensor  and z represents a hidden variable that determines the data correspondence between the observations and agents moving throughout the system.
1. the m-step: which then updates our current parameter guess with a value that maximizes the expected log likelihood:
θ i  = argmax
θ
　the e-step is calculated by approximating with m samples of an ownership vector l m  = {lim} which uniquely assigns the agent i to the observation oi in sample m: where l m  is drawn using the previously estimated θ i 1  according to a mcmc sampling technique. at every iteration  the m samples of the ownership vector l are used to re-estimate the connectivity parameter θ  the m-step . the algorithm continues to iterate over the e-step and the m-step until subsequent iterations result in very small changes to θ.
　markovchain monte carlo sampling is used to assign each of the observations to one of the agents. given some guess of the connectivity parameter θ and the current state in the markov chain specified by the current observation assignment l  proposals are generated by reassigning a randomly selected observation to a new agent selected uniformly at random. this new data association l is then accepted or rejected based on an acceptance probability which is determined by the metropolis algorithm.
　the technique uses an inter-vertex delay model that allows for the possibility of agent transitions to and from sources and sinks in the environment. in addition to maintaining a vertex that represents each sensor in the network  the algorithm assumes an additional vertex that represents the greater environment outside the monitored region: a source/sink node. a mixture model is employed during the e-step of the iterative em process in which potential changes to agent trajectories are evaluated. an inter-vertex delay time is assumed to arise from either a gaussian distribution or from a uniform distribution of fixed likelihood.
　the data assigned to the gaussian distribution are assumed to be generatedby  through-traffic and are used to during the m-step to update our belief of the inter-node delay times and transition likelihoods. however  the data fit to the uniform distribution are used only for updating the belief of transitions to and from the source/sink node for the associated vertices.
　the portion of data fit to each component of the mixture model is controlled through a a tunable parameter  called source sink log likelihood  ssllh   that determines the threshold probability necessary for the delay data to be incorporated into parameter updates. the probability for an inter-vertex delay is first calculated given the current belief of the  gaussian  delay distribution. if this probability is lower than the ssllh then this motion is interpreted as a transition made via the source/sink node and the transition is not used to update the network parameters associated with the origin and destination vertices. the value assigned to the ssllh parameter determines how easily the algorithm discards outliers and  hence  provides a compromise between robustness to observational noise and a tendency to discard useful data.
1 automatic parameter selection
our reasoning system treats the fundamental topology inference algorithm described in the previous section as a 'black box' and attempts to search over its input parameter space to find reasonable solutions. we construct a heuristic evaluation function that quantitatively assesses a potential solution based on the principle of occam's razor. the topology inference algorithm takes the following inputs: the observations o; the assumed number of agents in the environment n; and the ssllh parameter. the outputs of the algorithm are the network parameters θ and the ratio of data rdata incorporated into the parameter updates:
 θ rdata  ○ alg o n ssllh 
different input values result in different environmental assumptions and  hence  produce different outputs.
　we have created a metric that attempts to assess the validity of a solution by making the assumption that a good solution both explains the majority of the data and is as simple as possible. this principle  known as occam's razor  states   if presented with a choice between indifferent alternatives  then one ought to select the simplest one.  the concept is a common theme in computer science and underlies a number of approaches in ai; e.g. hypothesis selection in decision trees and bayesian classifiers.
　our simplicity metric incorporates a measure of the simplicity of the transition matrix and the amount of data explained by the solution. we measure the simplicity of a transition matrix by rewarding it in inverse proportion to how close it is to a uniform belief of transition probabilities:

where β determines the degree of the reward. we measure the utility of a given data use ratio by constructing an adjusted data ratio that attempts to reflect our belief in the solution as a function of the data used. the adjusted data ratio should incorporate the fact that some small portion of discarded data is actually optimal  but that our belief tails off rapidly as the discarded portion grows:
　　　　|# explained observations| rdata = 
|# total observations|

where γ and τ describe the shape of the belief curve  figure 1 . the final simplicity metric incorporates a weighted combination of asimp and radj:
　　　　　　qsimp =  asimp κ    radj λ where κ and λ reflect the relative weights assigned to the two portions.
　with the construction of the simplicity metric qsimp  we have shifted our dependence from specific a priori assumptions that must be made on a case to case basis. instead  we depend on more general assumptions regarding the attributes of a believable solution for this problem domain.
1 simulation results
in this section  we attempt to validate our general approach for selecting nearly optimal input parameters for the fundamental topology inference algorithm by using attributes of

figure 1: example relationship between rdata and radj with γ = 1 and τ = 1.
βγτκλ1.1.11table 1: table of values used to shape the simplicity quotient qsimp.
the solution it produces. we select parameters defining the qsimp metric based both on domain knowledge and experimental methods  table 1 .
　in order to justify these parameter values and to assess the effectiveness of this approach  we conducted a number of simulations in which we varied the input parameters and looked for a correlation between the performance of the algorithm and the simplicity metric.
　experiments were conducted by simulating agent traffic through an environment represented as a planar graph. the simulation tool takes as input the number of agents in the system and a weighted graph where the edge weights are proportional to mean transit times between the nodes. the output is a list of observations generated by randomly walking the agents through the environment. two types of noise were modeled in order reflect observations collected from realistic traffic patterns. first  a 'white' noise was generated by removing a percentage of correct observations and replacing them with randomly generated spurious observations. second  a more systematic noise was generated by taking a percentage of inter-vertex transitions and increasing the gaussian distributed delay time between them by an additional delay value selected uniformly at random. the range of this additional delay time was selected to be from 1 to 1 times the average normal delay time.
　for each experiment  the results were obtained by calculating the squared error between the true a and inferred a transition matrix:

　input parameters that resulted in good algorithm performance also resulted in solutions that generated high qsimp quotient values  figure 1 . when the error in the inferred transition matrix was plotted against the value obtained for the simplicity quotient qsimp for a number of simulations  there was evidence of a definite correspondence  figure 1 . the effect appeared robust to moderate levels of observational noise and different sizes of graphs. this result gives support for our adoption of occam's razor as a mechanism for selecting input parameters.

 a 

 b 

 c 

 d 
figure 1: the effect of varying assumed input parameters on performance and the simplicity quotient. results are averaged over 1 graphs using 1 simulated agents on 1 node  1 edge graphs with 1 observations. simulations labeled 'moderate noise' had 1 per cent of both white noise and systematic noise added to the observations. for charts a  and b  ssllh was set to -1 while for charts c  and d  the assumed number of agents was set to 1.

figure 1: the mean error in the inferred transition matrix elements plotted against qsimp for data obtained from the simulator with 1 true agents from 1 random graphs of 1 nodes  1 edges and 1 observations. input parameters to the algorithm were varied: assumed number of agents from 1 to 1; and ssllh from -1 to -1. trials labeled 'moderate noise' contained 1 per cent of both white noise and systematic noise.
　the accuracy of the solution we obtain depends heavily on the assumed numberof agents in the environment. the lowest error was consistently observed when the assumed number of agents was set to the correct value  and generally  the closer to the correct value this parameter was set  the better the results. over-estimating the assumed number of agents had less impact on accuracy than under-estimation.
　a correctly tuned ssllh parameter was also important to the accuracy of the final solution. as the input value for this parameter was increased  there appeared to be a  phase transition  in the accuracy of the results. past a certain threshold  the error suddenly increased dramatically. interestingly  the best results for both the inferred mean delay times  not presented here  and transition likelihoods seems to be obtained just before this sudden degradation in performance.
　while  the shaping of the qsimp metric is ongoing work  the current parameter values are adequate to demonstrate the correlation between the correctness and simplicity of the inferred transition matrix. in our experimental work  described in the next section  we took advantage of this correlation to select appropriate input parameters since the 'correct' values were unknown.
1 experimental results
in order to test our technique under real-world conditions  we setup an experiment using a real sensor network of nine nodes and analyzed the results using our approach. the sensor nodes were built up of photocell-basedsensors runningon low-powered commercial devices and vision-based sensors running on single board computers. both types of sensors were programmed to act as simple motion detectors sending event messages to a central server  which logged the origin and time of the activity.
　the experimentwas conductedin the hallways of one wing of an office building  figure 1  and the data were collected during a six and a half hour period from 1am to 1 pm on a weekday. in total  approximately 1 time-stamped events were collected.
　to determine appropriate input parameters for our inference algorithm we conducted an exhaustive search over the range of n = 1 .. 1 and ssllh =  1 ..  1. we then chose the output values that maximized our qsimp metric.  we used the same shaping parameters for the qsimp metric that were verified through simulations.  the maximizing arguments were: n = 1 and ssllh =  1. therefore  we selected the solution generated by these parameter values as our inferred network.
　except for a few small differences  the network parameters inferred by our topology inference algorithm closely corresponded to the ground truth topology. figure 1 compares the analytically determined and inferred topological maps. disregarding reflexive links  the difference between the inferred and 'ground truth' results amounted to a hamming error of 1. the two significant errors are: an extra edge found between sensors a and b; and a missing one-way edge from sensor d to i. additionally  the connections to the inferred source/sink node occurprimarilyfor boundarynodes  figure 1 c    and are therefore consistent with an analytical assessment of the traffic patterns. since traffic commonly enters and exits the monitored region via one of the boundary nodes  the inference algorithm should commonly employ the source/sink node in order bring the agent back into the system.
1 conclusion
in this paper we presented a method for inferring the topology of a sensor network given non-discriminating observations of activity in the monitored region. our technique recovers the network connectivity information opportunistically through the exploitation of existing motion. our work improves considerably on earlier related efforts for topology inference which require prior knowledge regarding motion in the environment. it is worth noting that our final technique recovers a much more complete description of network connectivity than just a topological map of the environment. additionally  we learn information regarding inter-node delay distributions  inter-node transition likelihoods  and other statistics regarding motion patterns in the system.
