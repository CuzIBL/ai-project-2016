 
　　we approach concept learning as a heuristic search through a space of concepts for a concept that satisfies the learning task at hand the heuristics represent bias that the concept learning program employs when forming an inductive generalization. we present a model of bias adjustment and report our experience with an implementation of the model. 
	i 	role of bias 
　　a major objective in research on inductive concept learning is creation of a program that can accept training data  apply knowledge  and form inductive hypotheses of the concept  all without human intervention. the learning program searches a space of hypotheses for those that are consistent with the observed examples  and which classify the unobserved instances as indicated by heuristics. the heuristics  which we call bias  determine the inductive generalizations that the program will form  given some set of training examples. the initial bias may be appropriate for one learning task  yet inappropriate for another. in many concept learning programs to date  e.g.  michalski 1    mitchell 1   the search for appropriate bias is done by hand. we examine an approach to mechanizing that search. 
vere  vere 1  and lenat  lenat 1  have programs that adjust their bias. vere uses the set difference operator to construct a new description c = a-b when no other consistent description is available. lenat's eurisko learns heuristics that lead the program to discover interesting concepts. eurisko is an advance from lenat's am where the search for appropriate bias was done by hand. 
	ii 	an approach to adjusting bias 
　　we represent bias as a restricted search space of concepts that we call the concept description language. we use mitchell's candidate elimination algorithm  mitchell 1  to maintain a version space of all concept descriptions in the concept description language that are consistent with the training instances. when the trainer supplies a positive instance  all concept descriptions that exclude the instance are refuted and removed from the version space. similarly  when the trainer supplies a negative instance  all concept descriptions that include the instance are refuted and removed from the version space. as shown in figure 1  as the version space shrinks  the complementary set of refuted hypotheses grows. if the version space becomes empty  then all descriptions in the concept description language have been refuted. a refuted concept description language indicates a 
　　refuted bias  and is sufficient justification for adjusting bias. we 
* this work was supported by national science foundation grant gmcs1  rutgers university laboratory for 
computer science research  and siemens research and technology laboratories. 
** current address is siemens research and technology laboratories  1 college road east  princeton  new jersey 1. 
do not yet know stronger justifications the role of bias adjustment is to enlarge the concept description language so that the version space becomes nonempty and search can continue. it may be that certain concepts are not describable within a particular formalism. if so  shift to a more appropriate formalism may be necessary. 

figure 1 model of bias 
we approach bias adjustment as a three step process: 
1. determine a membership specification for the new concept. 
1. translate the membership specification into a 
description that uses the formalism of the concept description language. 
1. assimilate the new concept description into the hierarchy of the concept description language. 
a membership specification is itself a concept description  but is expressed in an unbiased language so that the heuristics for determining the specification are not compromised by what is expressible. because the membership specification may be expressed in an alternate formalism  we require the ability to translate the membership specification into a concept description in the formalism of the concept description language. the translation step may require creation of new descriptive terms that correspond to membership specifications that are not describable in the current concept description language. a new concept must then be assimilated into the concept description language by defining its location in the hierarchy of descriptions. 
ill 	an example 
　　we have implemented a program that models bias adjustment as part of the lex program  mitchell 1  lex is a concept learning program that learns heuristics that suggest whether a given operator should be applied to a given problem state. each operator heuristic is represented as the concept  set of states to which this operator should be applied.  
　　lex currently learns heuristics in the domain of integral calculus. the program is initially given a set of problem-solving operators. each operator has a domain of applicability  a rewrite rule  and a range of producible states. for each operator  the legal domain of applicability describes states to which the 
1 p. utgoff 
operator can be applied. for each operator  the heuristic domain of applicability describes states to which the operator should be applied. 
　　lex solves a problem by producing a state that contains no integral. the solution tree is then criticized each operator application along the minimum solution path is labelled as a positive instance showing a state to which the given operator should be applied. each operator application that leads away from the minimum solution path is labelled as a negative instance showing a state to which the given operator should not be applied. the training instances are then used to update the heuristics being learned for the operators for each operator  mitchell's candidate elimination algorithm is used to maintain a version space of all candidate versions of the heuristic that have not yet been refuted if a version space becomes empty  then the bias adjustment module is invoked 
a 	a heuristic for membership 
　　deciding the membership of a new concept is the essence of induction. which instances should be included  and which should be excluded  we employ a heuristic: 
the domain of an operator sequence that leads to a solution should be describable in the concept description language. 
we choose this heuristic because of our a priori knowledge that the operator heuristic we hope to learn will be the disjunction of all useful sequences that start with that operator to describe the disjunction  we can start by being able to describe the disjuncts to compute a specification of the domain of an operator sequence that produces a state in a given range  in this case the set of solved problems  we apply a deduction procedure that we call constraint back-propagation. 
　　constraint back-propagation is a procedure for deducing the domain of a macrooperator that produces some constrained range of states. consider an operator sequence of length 1 that uses operator op   as shown in figure 1. if we constrain.the range of the op  to some set of states rcrange op    and then apply the inverse operator op 1 ; to r  then we deduce a constrained set dc i omain op1   such that opi d  = r. for example  an operator r- lr-1  has the set of real numbers as its domain and also as its range. if the domain is constrained to the set of integers  then the range is constrained to the set of even integers. 

　　if we know that op1 can produce a state that is a solved problem  we can compute op i intersecusolvedproblems  range opj    to deduce a constrained set d. d is then the set of states to which application of op1 will produce a solved problem. for operator sequences of length greater than 1  the deduction step is simply applied sequentially to the result of the previous deduction. 
b. 	a translation method 
　　a nested expression of intersections and inverse-operator applications  as shown above  is a specification of concept membership  but is not useful as a concept description because operator applications are required to evaluate whether an instance matches the description. the nested expression must be translated from a membership specification into a structural concept description that uses the formalism of the concept description language. our translation method is to evaluate the membership specification to let this work  we have defined a description of the set of solved problems  an intersection function  and inverse operator definitions. new concepts are created and assimilated during evaluation of the membership specification . 
　　when an operator only restructures a state via a simple rewrite rule  e.g a-b- b-a  creation of new concepts is not required because the range of the operator is expressible by a 
　　description in the concept description language. when an operator requires a computation  e.g. multiplication by 1  the range may be describable in the operator language  but not the concept description language. for example  consider an operator r-  r-1 . the  r-1  indicates that the bound value of r should be multiplied by 1  and the result used in the rewritten state if an 
operator is to be applied to a set of states  as with constraint backpropagation  then correct specification of the operator's domain and range becomes very important. application of r- |r-1  to the set of integers k produces a description f k-1 j. this is a description in the operator language  not the concept description language! 
　　our method of translating a description implied by a computation y = f x  to a term in the concept description language is to first create a definition {yl a y  match f-' y  x  } and then search for a term with the same definition if a term with that definition is not found  then a new term is created and defined as per the constructed definition  for example  the definition that corresponds to |k-1  is {yl a y  match y/1 'k  }  which we could associate with a new term  even   
c 	an assimilation method 
　　assimilation is the process of inserting a new concept description into the hierarchy of description in the concept description language assimilation is necessary so that we can use the match predicate to evaluate whether one concept is more specific or equal to another. 
　　our present method is imprecise. in general  if we are to assimilate z = {yl a y  match f 1 y   x  }  then we make z a specialization of y. this method is correct only in the sense that no false match relation is asserted. for example  our method may assert that  even integers  is a specialization of  real numbers   but fail to assert that  even integers  is also a specialization of  integers . at the same time  the method does indicate y as a most general bound on where z should be assimilated. if the set of possible assimilations is small  we would expect that a mechanical procedure could prune these by empirical refutation  but we have not pursued this. below we show an example of deducing the correct assimilation 
d 	experiments 
　　we present three experiments with the implementation. several problems came to light. 
	1. 	experiment #1 
　　as in  utgoff 1   lex found a solution for jcos1 x  dx similar to that shown in figure 1. lex was then given jcos1 x dx  for which the same solution sequence  and /cos1 x dx for which the same solution sequence did not work because the polynomial in the integrand was not an integer. because the concept description language did not contain a description that included jcos1 x dx 
and jcos1 x dx and excluded jcos1 x -dx  the heuristic for op1 could not be described. bias adjustment was invoked  and constraint back-propagation was expected to proceed as shown in figure 1. the implementation was successful for the last three propagation steps through op 1  op-1  and op 1. backpropagation through op1 failed because our formalism  a modified context-free grammar  does not permit specifying that whatever matches f be the derivative of whatever matches f. this example shows that the formalism of the concept description language also implies bias. the ability to identify the kind of bias that is associated with a given formalism is an important open problem. 
　　back-propagation of the set of integers k through the exponent in op 1 caused a new description {xl a x  match xl1 'k  } to be constructed  the set of even integers. because the operator could divide any real exponent by 1  the constructed set description was assimilated as a specialization of the set of real numbers. it would have been better to assimilate the set of even 
figure 1 - evaluating product with op1 
　　nevertheless  the back-propagation failed because the deduced set r1 r1/r1  did not satisfy a safety check requiring that a deduced set  in this case r1- r1/r1   match the state that occurred in the original solution sequence  in this case 1. although r1 matched 1  r1/r1 did not match 1. the concept description language did not include knowledge that r1/r1 is equivalent to the set of rational numbers  and that 1 is an instance of a rational number. the inverse operator had inserted an implicit computation; division! 
	1. 	experiment #1 
　　a problem jx 1 dx was given to lex  and was solved by op1 as shown in figure 1. other instances were also provided that caused the bias adjustment module to be invoked. the program 
p. utgoff 1 
needed to back-propagate the set of real numbers  r  through the exponent in op1 l. the code created a description {xka x  match x+1 'r  |  and assimilated it us a specialization of r. this produced a description with infinite recursion of the form  x is a real number if x + 1 is a real number . if the program could have applied knowledge that the real numbers are closed under addition  in this case by 1  then it would have proven that adding 1 to an x will not alter whether that x is a real number. 
to 
 1 mitchell  t. m.   version spaces: a candidate elimination approach to rule learning   proceedings of the fifth 
international joint conference on artificial intelligence  cambridge  mass.  1  pp. 1. 
 mitchell  t. m.  utgoft  p. e.  and banerji  r. b.  learning by 
experimentation: acquiring and refining problem-solving 
heuristics   machine learning  michalski  carbonell  mitchell  eds   palo alto  tioga  1  pp. 1. 
 1 utgoft  p. e. and mitchell  t. m.   acquisition of appropriate bias for inductive concept learning   proceedings of the 
second national conference on artificial intelligence  pittsburgh  august 1  pp. 1. 
 1 vere  s. a.  multilevel counterfactuals for generalizations of relational concepts and productions   artificial intelligence  1  september 1  pp. 1. 
