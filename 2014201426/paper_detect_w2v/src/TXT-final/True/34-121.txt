 
     this paper presents a method of segmenting a scene into its basic objects on the basis of motion. the velocities of points are approximated by associating them to sets of reference edges in the scene. these measurements are then used to group the points  a basic tenant of this work is that all points of a single object have the same velocity values. accordingly  points with the same velocity measurements are grouped together. since the motion of an object is independent of its other visual characteristics  whole objects  not surfaces or edges  are initially included in one segment. the program successfully grouped points from internally generated scenes with 1% accuracy. points from real test scenes were grouped correctly 1% of the time on the average. the poorest result was 1% accuracy the best was 
1%. 
introduction 

     one of the most important steps in processing digitized scenes is the segmentation of the scene into its basic objects   basic objects  in the sense used here correspond roughly to the common nouns that refer to three dimensional objects which would normally be used in the description of a scene   guz.man  segmented line drawings into objects on the basis of vertex configurations  brice and fennema  segmented scenes directly into surfaces on the basis of the gray scale values of the picture elements. it is the author's belief that the motion of objects in a scene can be profitably used for segmenting a scene into its component objects. potter  proved the feasibility of such an approach. the process envisioned here is not intended to solve the problem of segmentation by itself  but instead provide a powerful method of dividing a scene into a set of fundamental divisions which correspond to the scene's basic objects  a basic consideration in the design of the system was that it should be compatible with other segmentation schemes. the author hopes to integrate this system with other systems so as to achieve more complete and accurate scene segmentation. 
　　　　the use of motion for scene segmentation results in two subproblemsi first  how to extract motion information: second  how to use motion information for segmemtation. this paper discusses a method of 
*the research reported in this paper was completed by the author while a student nt the university of wisconsin - madison  motion extraction more general than that presented by potter . and a simple but effective system of scene segmentation based on the motion information obtained. 
motion extraction 

     motion can be extracted from a scene by processing sequentially related pictures several articles dealing with cloud motion have been published  leese  novak ana taylor  presented a system of  binary matching   the gray scale values of satellite pictures of cloud cover were converted into binary to emphasize edges. the pictures were then divided into  sectors   sectors from the first picture served as templates to be  looked for  in the second picture. the sector from the second picture that most nearly matched the template was associated with i t . the displacements between the sectors of the second pictures and their associated templates were used to calculate the amount and direction of motion of the cloud banks  endlich  wolf  hall and brain  described a method of motion detection which used  centers of brightness.  the  centers of brightness  were determined by a clustering algorithm  a cross-correlation technique was used to match centers. the 
motion of the clouds was calculated in the same manner as by leese et al. smith and phillips  1   also used a cross-correlation analysis to track clouds and determine their motion. 
     the goal of these processes was the precise determination of wind velocity from apparent cloud motion. thus the procedures developed are specific to that purpose and must accommodate  unusual  conditions. for example  the pictures are normally taken hours apart. the recognition of  objects  is of no concern. finally  the scenes generally contained known  objects   i.e. land masses  which enabled precise picture alignment. 
　　　　potter  1 developed procedures which are more useful for motion extraction from general scenes. he assumed that pictures could be taken arbitrarily close in time  that the exact determination of velocity is not essential as long as all parts  or points  of an object have the same velocity value  and that since seg-
mentation is a preliminary step in object identification there is no advanced knowledge of scene content which can be used for comparing two pictures. 
1      potter's approach to motion extraction wap bps d on the measurement of +** mrwo  ment of  edges.  he assumed that since 
the pictures were taken only a few moments apart  the edges* could be correlated between the pictures by their spatial position alone. a motion measurement was obtained by determining the displacement of the edges between pictures from a given 
point on a superimposed absolute reference grid. 
　　　these same general assumptions and approaches are taken here  however instead of determining the x- and y-motion comonents seperately as was done in potter 
　1   a  cross-shaped template  i1 used to determine the actual velocity in one step. 
the  cross-shaped template  

　　　the basic concept of velocity extraction to be used here is to find a feature in one picture  find the corresponding feature in a second picture and use the observed displacement as a measure of motion. the major problem with feature 
matching is that a feature has to be initially found   and identified . one way of circumventing this problem is to extract templates from one picture and in this manner  generate features. this approach was first discussed by uhr and vossler . their templates were rectangular and of a fixed size. if such a template happens to be defined in an area of the picture that contains little information  then there is little significance in its matching or failing to match in a subsequent picture. 
　　　the  cross-shaped  template  hereafter referred to as simply the cross template  contains two advantages for motion extraction purposes over the uhr and vossler template generation scheme. first  the template is cross-shaped as opposed to rectangular. this results in a considerable reduction of points that need to be processed for matching. in figure 1  for example  a five-by-seven rectangular tern-

plate contains 1 points. but the fiveby-seven cross template contains only    points. second  the cross template is of variable size. the length of an arm of the cross is determined by the distance from the central reference point  or simply center of the template  to the nearest edge. the variable size of the template greatly increases the likelihood that it contains useful information. 
       the cross template is defined by taking the point at the intersection of the arms as the center point of the template and the distance from the center to the closest edge in four given directions as the length of the corresponding arms. that is  an association of distance and direction forms the basis for the cross template. the association operates on the assumption that every point of a superimposed absolute reference grid is surrounded by edges in the picture. in any one picture  a reference point of the grid 
may be surrounded by any number of edges. a unique association is established between a reference point and an edge by picking a direction and recording the distance from the point to the nearest edge. in figure 1  the point  x y  is surrounded by the edges a  b  c  d  e and f. by restricting the direction of association to the positive x-axis  the number of edges is reduced to three : edges b c and d. this number is reduced to one  and therefore a unique association  by choosing the closest edge. in figure 1  the point  x y  and edge b are associated uniquely by the positive x-axis direction and the distance between them  three units. 


 more accurately  discontinuities in gray scale values were used instead of edges. however  since  edge  is a more easily understood term  i t will be used in this paner. it should be kent in mind however  that wherever  edge  is used  discontinuity in gray scale value should be used. see potter  for a more complete discussion 
     a template must be sufficiently unique that  false matches  do not occur. an effective design for a unique template consists of four orthogonal arms. thus a  cross-shaped  template is defined by a set of four rays parallel to the positive x-  positive y-  negative x-  and negative yaxes. in figure 1a  the cross template is 
1 

defined by uniquely associating the point  x y  with the closest edge  edge a  in the positive x-axis direction by the distance value of 1 units  with the closest edge  edge b  in the positive y-axis direction by the distance value of 1 units  with the closest edge  edge c  in the negative x-axis direction by the distance value of 1 units  and with the closest edge  edge d  in the negative y-axis direction by the distance value of 1 units 

　　　in figure 1a  the cross template is defined by the edges of a rectangular object. figure 1b illustrates the fact that cross templates can be used with any arbitrarily shaped rigid figure. i t should be 
kept in mind that although most of the examples in this paper are rectangular and have straight edges  the only requirement for application of the cross template is that the object does not change shape between pictures. 
velocity determination 

　　　after the cross template has been defined in one picture  it is moved around the second picture until an exact match is found. the cross template is sought in a regular manner. each of the absolute reference points in the neighborhood of the reference point used as the center of the defining template is tested as the center point of a matching template. first the points along the positive x-axis are tested  then the points along the negative xaxis  then the points along the positive y-axis and finally along the negative yaxis. each axis is searched until a search length parameter is exceeded. this parameter is set by the user and reflects the maximun number of absolute reference units an object can move between pictures. 
　　the search along the axes is a heuristic approach to finding a matching template since the actual movement of the object may be oblique to both axes. the searching routine looks for a match of the total length of the perpendicular arms of the template  i.e  total y-arms length  i f searching along the x-axis . if a total length match is found  the true y-displacement can be easily calculated. the search along the perpendicular axis  yaxis in this case  is then started from this newly calculated reference point. when  or if  a total x-arm match is found  the x-displacement is calculated. the absolute reference point obtained by calculating the x- and y-displacements  is tested as the center of a matching template. if successful  the x- and y-displacement values are used as a measurement of the x- and y-axes component velocities. if the template does not match  the search continues. points for which no matching template can be found are assigned a  null   not to be confused with zero  velocity value. 
　　the velocity value obtained from this process is associated with the corresponding reference point in the last picture taken. the reason for associating the velocity with the reference point is that if the reference point corresponds to some physical point of the object  then that physical point does have a velocity. moreover  at an initial level of processing  there may not be any other entity  edge  corner or feature of any type  that the motion value can be meaningfully associated with. 
　　the main advantage of this approach to velocity extraction is that it is object independent. it can be used on any size or shape of object. the only requirement is that a number of spatial discontinuities in gray scale be associated with the object. every visible object meets this requirement. perhaps more important is the property that this procedure can be applied to any point of a scene without any prior knowledge of the nature of the object which is at that point. therefore  the information obtained by this procedure is available to be used at all levels of scene processing. 
　　unfortunately  this velocity extraction procedure does not always detect the correct velocity  under certain circumstances it can not detect motion parallel to an edge. the situation arises when the extracted template is not unique. figure 1a shows an example of such a situation. the condition illustrated in the figure is complicated. first  the object must have two parallel sides. second  the two sides must be long enough and of such an orientation that they constitute the defining discontinuities for all of the arms 

1 


　　　　　　　　figure k of the template. third  the motion of the object must be parallel to the two sides. all of these conditions are expressed in' the phrase  oblique motion parallel to two edges  or  oblique motion  for short. 
     the problem of oblique motion is more theoretical than practical. since it arises from the relationship between the orientation of the arms of the template and the two parallel sides of the object  whenever the situation is detected  a new template can be constructed which avoides the problem. the new template need only to be constructed with one set of arms parallel to the parallel sides. this newly definded template will extract the correct velocity. unfortunately  this is a somewhat ad hoc solution to the problem. 
     the theoretical problem of oblique motion can be eased slightly by the observation that a human can not directly detect motion under similar conditions either. instead  motion of the parallel sides seems to be inferred from the observed motion of the ends  or  remainder   of the object. therefore  a less ad hoc but perhaps more difficult solution is to rely on the knowledge of the real world and deductive capability of a monitor. for example  all of the points in the'shaded areas of the object in figure 1b will have accurate motion measurements  a  smart  monitor should be able to infer that points with zero motion values which lie between the shaded areas are the result of oblique motion and should be given the same motion values as the bracketing points 
scene segmentation 

　　the points of a scene are grouped into segments on the basis of the computed xand y-axis velocity components. the avowed purpose of this procedure is to obtain a crude first approximation of the basic object segments in a scene. accordingly it is not essential and in fact wasteful to process every absolute reference point. instead  every n-th point  a system parameter  is processed. the points are processed in serial. thus  after the velocity values of a point have been determined  they are compared with the velocity values of previously processed points which have been divided into groups on the basis of their velocity measurements. if an exact match of velocity magnitude and direction of both the x- and y-axis components exists between the point and a group  the point is added to the group. if there is no match  a new group is created with the present point as its first member. this process is repeated until all of the points selected 
have been processed. in this elementary algorithm  points with  null  velocity values are grouped with points which have zero velocity values  this group corresponds roughly to the background of a scene . 
results 

　　the velocity extraction and scene segmentation program vess  was implemented in fortran iv on a datacraft computer. the program required 1-k memory locations  l1 bit words . the pictures were taken by a kgm 1tm television camera connected via a zeltex analog-to-digital converter to a pdpll/1 computer. each 1 byte picture was transmitted from the pdp1 to the datacraft by an asychronous interface unit. 
　　the vess program was tested on various scenes. it was completely effective on internally generated scenes of rigid  nonoccluded objects. these scenes contained three or four rectangular and triangular objects with various types of motion. the upper limit of four is due to the convenience of displaying a scene if the gray scale levels are limited to a single digit. figure 1 is an example of an internally generated scene of three objects. 
　　starting from point  1  every 1th point was processed that is  the 1 
points -  1 .  1   ...  1    1   ...  1   1  - were put 
into segments on the basis of their motion. of the fifty points processed for the scene shown in figure 1  all were correctly grouped. four groups were formed  one for each object and one for the background. every point in every group was from the 

1 

same object  background being an  object  . 
       four different real scenes of one or two rigid  non-occluded objects were used for testing the basic segmentation program. the first scene is shown in figure 1  table 1 shows the results of four runs. three of the runs used the same 1 point sample used to test the generated scenes. two parameters were used to accommodate noisy data. they were varied from zero to two. one of the two para-
meters determined the discrepancy in gray scale value allowed before an edge was  detected.  the other parameter determined the tolerance in velocity values allowed in grouping points. as can be seen the best results were obtained when th e  deltas  we re set to 1. 
       the poor results for object 1 in scene 1 were due to the lack of contrast between the right hand surface  orange  and the background  yellow   a second scene was taken with the right side of object 1 black with an orange insert  a 
ninety point sample   1 .  1 .   .. 
 1 .  1 . ...  1 .  1   was used for this test. the change in color resulted in an improvement to 1% correctly classified as shown in the scene 1 column of table 1. 
       a third test scene was made with the entire right face of object 1 contrasting with the background. the results of th i s test run were appro ximately th e same as the previous one. apparently the shadowy area between the objects in the second scene caused a decrease in contrast  so a fourth test scene  not shown  was taken of a single multi-colored object. the results were considerably better as shown in the scene 1 column of table 1  the averages of all tests  with  deltas  set to 1  are given in the last column of table  . 
     a major problem in these tests with real data was the noise present in the pictures. the edge noise was such that  large  objects were required  large objects can only be moved slightly before 
being outside of the field of view of the tv camera. the scenes used constituted a compromise of these aspects and consisted of moderately sized objects  1 to 1 inches long  in a field of two feet by one and a half feet. these limitations prevented using scenes with more than two objects. 
     during these test runs  the segmentation program processed on the average one point every 1 seconds. the fastest processing was one point every 1 seconds on the generated scene data. the real scene data was processed at one point every 1 seconds. 
conslusion 

     this paper shows that the use of motion for scene segmentation can be applied to quite general scenes. the cross template can be used to extract the motion of any arbitrarily shaped  rigid  nonoccluded object. the motion values so obtained can be effectively used to segment a scene into its moving components and  background   although the scenes in this paper were restricted to non-occluded objects  the approach presented here seems applicable with slight modifications to scenes with occluded objects. this problem is currently under investigation and results should be forthcomming shortly. the primary drawback of the cross template is its failure to detect  oblique motion   however  on the whole  this process seems to be quite promising as a first step in the segmentation of complex scenes since the groupings are independent of the color  or gray scale value  of the objects in the scene. 


1 





acknowledgement 

     the author wishes to express his gratitude to dr. l  uhr  who provided many 
helpful suggestions and criticisms during the course of this research. this work was supported in part by a grant from the national science foundation  gj-1 . 
bibliography 

1. brice  c r and c. l. fennema   scene analysis using regions   artificial intelligence  1  1  1. 
1. endlich  r. m.  d. e. wolf. d. j  hall  and a. e  brain   use of a pattern recognition technique for determining cloud motions from sequences of satellite photographs   journal of applied meteorology  1  1. 1. 
1. guzman  a.   decomposition of a visual scene into three dimensional bodies   afips proceedings  fall joint computer conference. 1. 1  1f. 
1. leese  j. a.  c. s. novak and v. r. taylor   the determination of cloud pattern motions from geosynchronous satellite image data   pattern recognition  1  1. 
1. potter  j    motion as a cue to segmentation   ieee transactions smc  smc-1  pay  1  1  
1. smith  e. a. and d. r  phillips   automated cloud tracking using precisely aligned digital ats pictures   ieee transactions on computers 1  1  1. 
1. uhr  l. and c. vossler   a pattern recognition program that generates  evaluates and adjusts its own operators   l  uhr  ed.   pattern recognition  john wiley and sons  new york  1  1. 
1 
