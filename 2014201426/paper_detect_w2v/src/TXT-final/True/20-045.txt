: 
this paper describes a system in which twin hierarchies for navigation and perception are controlled by a knowledge based supervisor. at the top level  these hierarchies contain collections procedures which implement the  skills  of the system in locomotion and spatial reasoning. the structure of these hierarchies  and their integration is described. 
perception and navigation are controlled and monitored by a knowledge based  supervisor . the supervisor decomposes a 
mission plan into subgoals and then uses the perception and navigation procedures to accomplish these subgoals. the organization of the rule base for the supervisor is described  and a mission planning is illustrated with a simple example. 
1 introduction 
this paper describes a technique for coordinating action and perception within a mobile surveillance robot. the surveillance robot employs an architecture composed of twin hierarchies for navigation and perception controlled by a knowledge based supervisor. such an architecture has allowed us to explore he interface between heuristic and algorithmic programming techniques for perception and action. our results illustrate that that most of the so called low-level tasks in perception and navigation are algorithmic in nature. on the other hand  at the  highest levels   the decisions as to which actions to perform is based on knowledge relevant to each situation. such decisions are heuristic in nature  and the relevant knowledge is naturally encoded as production rules organized as contexts. 
1 the system architecture 
the control of navigation and perception in an unknown environment present difficult problems. earlier projects  crowley 1a  in which this top level was implemented as an algorithmic process led to systems with rigid behavior. a major theme of this research is that control at the top level requires the application of a body of poorly organized knowledge. thus we have developed a system architecture in which a production system controls the hierarchies of perception and navigation. 
1 system organization 
the system organization is illustrated in figure 1. the system is composed of twin hierarchies for navigation and for perception. these hierarchies are organized as a set of levels according to the abstraction of the information which is processed. 
motors and sensors: at the lowest level  each hierarchy asynchronously processes raw signals. in the navigation hierarchy  this processing involves closed loop control of the motors to maintain a specified velocity  as well as capture of proprioceptive sensor signals for estimating position and velocity. in the perception hierarchy  processing involves acquiring sensor signals and converting these to an initial symbolic representation in vehicle coordinates. 
1 scientific issue: coordinating action and perception 
the research reported in this paper is part of an effort to develop a family of intelligent mobile surveillance robots. such robots are a 
form of  intelligent agent   operating in and interacting with the real world. 
the development of intelligent agents poses important scientific questions for robotics and artificial intelligence. among these questions is the relation between heuristic knowledge and algorithmic  skills . in particular  where and how should the boundary occur between heuristic and algorithmic programming in an intelligent agent  a second problem concerns the relationship between planning and plan execution: how much of a plan can be developed in advance  how should the agent respond when the plan does not succeed  
to explore these issues we have posed these problems within a specific application domain: the planning and execution of surveillance missions for a military robot in an urban environment. systems for dynamic world modeling and for navigation and locomotion have been developed for a surveillance robot within our laboratory  crowley-coutaz 1 . knowledge based coordination of action and perception has been investigated using a simulated version of our surveillance robot and a data base of simulated urban environments. the simulation imitates the functional behavior of our surveillance equipped with a rich set of sensor in a rich and changing environment. 
1 solution: knowledge based coordination 
our investigation has led to an architecture in which a production system sits at the top of twin hierarchies for perception and navigation. the lower levels of these hierarchies assure integrated control at the level of the vehicle  and integration of signals from the environmental sensors into a composite model of the surfaces in the immediate environment. 
the composite model and the vehicle level controller are data driven processes at roughly the same level of abstraction within the two hierarchies. above this level are a number of perception and navigation abilities which we refer to as the  action level  in the hierarchies. these action-level abilities correspond roughly to  skills  in a human. attempts to implement these abilities as bodies of rules within the production system soon convinced us that such an approach was not appropriate. skills are fundamentally algorithmic in nature and are better suited for programming in a traditional programming language. 
the result is an architecture in which algorithmic procedures for navigation and perception tasks are  triggered  by rules within the production system. the navigation tasks at this level often require a considerable amount of information from the perception hierarchy. as a result a considerable amount of communication between navigation and perception occurs without the awareness of the production system. 
in the section below we describe the system architecture. we then describe the organization of knowledge for the planning and plan execution systems. 
	crowley 	1 


figure 1. the system architecture: parallel architecture for navigation and perception controlled by an intelligent supervisor. 
vehicle control and composite model: at an intermediate level both hierarchies represent their information at a level of abstraction based on the vehicle and its environment. at the center of the navigation hierarchy is a vehicle level controller. this controller accepts asynchronous commands to move and turn the vehicle. the vehicle level controller also maintains an estimate of the position and velocity of the robot and shares this with the perception hierarchy. the perception hierarchy projects the description of new sensor signals into a common coordinate system  and uses the projected information to update a  unified  composite model of the environment. as a side effect of the update process  errors in the estimated position are detected and relayed to the vehicle controller. 
action level: a collection of algorithmic processes operate on the information provided by the vehicle controller and the composite model the navigation hierarchy includes algorithmic processes for such tasks as following a road  following a wall  or traveling towards a distant beacon. these processes necessarily depend on asynchronous access to perceptual information  made available by a set of interface procedures for the composite model a significant amount of the coordination between action and perception occurs between algorithmic procedures at the level of actions. in human terms  these action level procedures correspond to learned  skills  such as driving a car  or understanding the environment in terms of rigid objects. 
supervisor level: controlling the twin hierarchies for navigation and perception involves selecting the appropriate perception and navigation actions in order to accomplish some set of high level goals. such an activity is not easily organized as an algorithm; each situation implies a body of appropriate knowledge. such knowledge is naturally expressed as rules  organized into  contexts'*. within each context  rules are triggered by internal facts which represent things such as goals  external events  or descriptions of the environment 
in the following sections we describe briefly the structure of each part of the system. 
1 the perception system 
the robot's sensors are divided into two broad classes: environmental sensors and surveillance sensors. environmental sensors provide information for describing the structure of the local environment  while surveillance sensors are used to detect the presence of intruders. surveillance sensors operate under direct control of the supervisor. environmental sensors operate autonomously and continuously. 
the data from the environmental sensors drives a process which constructs and maintains a composite model of the environment the composite model describes geometric  dynamic and surface features within the local environment. the composite model serves as an 
1 	perception 
interface between data driven and knowledge driven processes for perception. 
1 integrating sensor data: the composite model 
the heart of perception system is a dynamically maintained data structure called the the composite model  crowley 1  as well as with 1-d vision  crowley 1 . the composite model is a geometric description; it does not contain labels for  recognized  objects. interpretation of the structures within the composite model as known objects is accomplished by the supervisor using algorithmic procedures at the action level. 
parts of the matching and update processes for the composite model have complexities on the order of the square of the number of elements. to keep the cycle time fast  it is necessary to restrict the contents of the composite model to a few tens of primitives. elements are quickly removed from the composite model when their presence is not reinforced by either the sensor signals or the needs of the task level processes. this purging is mediated by a recency mechanism. older elements are purged from the composite model to restrict the number of elements to a fixed limit. 
1 action level interface to the composite model 
the contents of the composite model are never directly available to the other parts of the system. instead the contents are accessible through a set of five interface procedures. three of these processes are described in more detail in  crowley 1 . 
visible: given two points  a and b  return the identity of the surface patch closest to point a which intersects the line. a return value of nil indicates that the point b is visible from the point a. 
correspond: given a primitive element  p  with a particular position and orientation  as well as a tolerance for position and orientation  return the identity of the primitive element in the model which  best  corresponds to die primitive. a return value of nil indicates that no such primitive can be found in the model. 
freepath: given two positions a and b  as well as a tolerance  indicate whether the robot may safely travel from a to b without coming within the tolerance of an object. return either nil or the identity of the first object which the robot might strike. 
findprimitive: given a primitive element with a set of position independent attributes  and uncertainty tolerances for each attributes  
return a list of all occurrences of the the primitive in the composite model 
findobject: given a description of an object as a composition of primitives  return a list of all such objects in the composite model. 
1 surveillance sensors 
the system described below employs three steerable sensors for detecting intruders: an infrared sensor  a micro-wave radar and an ultra-sonic ranging device. operation of the surveillance sensors are implemented as action level procedures. the operation commands to the sensor includes a firing aiffcle. the result of sensor operation is immediately returned to the supervisor. the supervisor can complete the information with either the composite model or with other sensors. 
1 the navigation system 
the navigation hierarchy has an organization which is parallel to mat of the perception hierarchy. each level in this hierarchy involves an independent control loop. these loops can communicate asynchronously with the control variables for each loop specified by the next higher loop. 

1 motor control 
at the lowest level of the navigation hierarchy  motor control circuits control the state vectors of angular position and velocity for the motors. the controller also captures and integrates the encoder signals to make produce a cumulative encoder count. the motor controller provide asynchronous control  which makes it possible to maintain an estimate of the position of the robot as it moves  as well as to adjust the direction of travel independent of the speed. 
1 vehicle level control 
the vehicle level controller coordinates the motor controllers to achieve a desired vehicle behavior  expressed in world coordinates. navigation tasks which involve following linear structures such as roads or walls may be formulated as a process of independently controlling forward displacement and orientation and their derivatives  wallace et. al 1 . the vehicle level controller must also maintain and make available an estimate of the position and orientation of the vehicle. 
the command set at the level of the vehicle are: 
move 
turn stop 
gctestimatedposition  x  y  angle  
correctestimatedposition 
commands may be received at any time and are executed immediately  superceding previous versions of the same command. the commands move and turn are implemented independently. the parameters of move and turn refer to displacement  d  and its first and second derivatives  v and a . 
1j action level procedures for navigation 
control of local vehicle movements is inherently an algorithmic process. this level of control corresponds to the  local navigation  described in  crowley 1 . our system currently uses five such procedures. the first is based on the use of estimated position maintained by the vehicle level controller. the remaining three procedures are implemented using a form of direct pursuit these last three tasks differ primarily in the way they use perception to select the target point. 
straight-line travel: the procedure is given a point in its local environment expressed in an external coordinate system. after verifying that a free path exists to the point  the robot turns toward the point and then travels in a straight line. 
pursue: the robot chases after a possibly moving target specified by the supervisor  maintaining a specified distance behind the target. the procedure calls the perception system to determine the position and velocity of the target. this function can also be used to travel towards a distant landmark or beacon. 
wallfoilowing: the robot travels a specified tolerance to the right or left of a wall for a specified distance. the target point is determined by projecting a target point in front of the vehicle  and then measuring the perpendicular distance to the wall  as well as the orientation of the wall at that point. these values are used to compute the target point. the procedure also uses function freepath to assure that the path is not blocked by an obstacle. an early version of this procedure is described in  crowley-coutaz 1 . 
roadfollowing: based on the techniques described in  wallace et. al 1 . the robot detects the center line of the road at a distance r  and uses the follow function to dynamically adjust its orientation. road following is not currently implemented on our vehicle. 
the choice of the appropriate local navigation procedure depends on the the local environment. such choice is best stated as a set of heuristic rules  depending on knowledge about the environment and the mission of the robot. in our surveillance robot  each route in the cartographic knowledge base contains a suggested local navigation mode for traveling along the route. the supervisor reads the suggested navigation mode from the cartographic data base and calls the appropriate local navigation procedure. when a navigation procedure is unable to continue  the procedure halts and notifies the supervisor. 
1 the supervisor for a surveillance robot 
the behavior of the supervisor is  goal oriented ; the supervisor is given a mission as a sequence of high level tasks to accomplish. the mission is decomposed into a sequence of lower level tasks by a planning stage. during execution  the plan is adapted and modified as needed in order to accomplish the mission goal. 
the supervisor is implemented as a production system using the 
ops-1 language  brownston et. al. 1 . the supervisor's rule base is organized as contexts according to the tactical situation and the current task. the right hand side of ops-1 rules may include function calls in common lisp. this provides the interface to algorithmic tasks for navigation and perception as well as access to the cartographic and object data bases. 
a mission for the surveillance robot is specified as a set of abstract navigation and surveillance tasks. the supervisor decomposes the mission into a sequence of sub-tasks to verify that sufficient information is available to accomplished the mission  and to verify that the robot can satisfy the stated constraints on time and fuel consumption. if the robot is unable to perform the mission  the human operator is informed and requested to re-specify the mission. 
1 cartographic and object knowledge 
much of the knowledge which is needed to plan and execute navigation tasks is cartographic in nature. such knowledge is organized naturally as a network of places and routes. a cartographic data base  composed of places and routes is implemented as a network of lisp structures accessible from lisp functions. the supervisor can recall the contents of a place or route by calling the lisp functions getplace or getroute. the result is the creation of an 
ops-1 object containing the attributes of the route or place. we have recently begun experiments with automatic construction of rules which suggest sequences of routes between non-adjacent places. these rules  cache  the results of planning for frequently traveled routes. 
a place contains the following fields: 
name: an alpha-numeric name for the place. 
location: a cartesian location for the place. 
tactical zone: the tactical situation at the place. adjacent places: a list of pairs  place  route  for adjacent places 
a route is composed pf: 
name: a name for the route. 
navigationmode: a suggested navigation procedure for this route. 
length: the length of the route. 
maximum speed: hie maximum speed for the route. 
efficient speed: an efficient speed for the route. 
tactical zone: the current tactical zone. 
adjacent places: the pair of places connected by the route. 
each place and each route in the cartographic knowledge base are labeled with an attribute which identifies the tactical zone for that 
	crowley 	1 

place or route. the tactical zone  in turn  is an important factor in determining the robot's behavior. each zone contains a risk factor  which is multiplied by the time spent in the zone  and used as a constraint in mission planning. 
1 operational knowledge 
the supervisors behavior is organized as a set of modes. modes are specified to the robot during mission planning. the current set of modes include: 
efficient: the robot travels at a rate which optimizes the consumption of fuel. no surveillance activity occurs. the optimum speed for each route is available as an attribute of the route in the cartographic knowledge base. the robot will not enter dangerous tactical zones while traveling in efficiently mode. 
rapid: the robot travels as fast as possible. no surveillance activity occurs. the maximum speed is an attribute in the description of the route in the cartographic knowledge base. the robot will not enter dangerous tactical zones while traveling in rapid mode. 
discrete: the robot seeks to avoid detection. it will not enter dangerous or hostile zones. it travels slowly in unknown zones to minimize noise. it travels efficiently in friendly zones. in discrete mode the robot maintains a surveillance activity  paying particular attention to comers. if an intruder is detected  the robot will seek to move so that a barrier is between it and the intruder. it will notify base of the presence of the intruder  and then either monitors the intruder in one of the detection modes described below or plan a path to avoid the intruder depending on the mission instructions. 
reconnaissance: in friendly zones the robot travels efficiently with no surveillance. in unknown  forbidden  hostile  or dangerous zones  the robot travels at a speed which most efficient for surveillance. in the case of a detection the robot notifies the base and enters one of the detection modes described below. 
1 mission specification and planning 
a mission is specified to the robot as a set of pseudo-natural language sentences which describe tasks to be accomplished. the tasks are either navigation tasks  surveillance tasks  or combinations of both. the following is a sample mission definition. 
mission start: time = 1  fuel = 1  maximum risk =1  if detection of person use mode warn. 
1  if detection of car use mode monitor 
1  go to place a in mode discrete 1  go to place b in mode surveillance. 
1  remain at place b in mode surveillance. 
1  at time= 1 return to place base in mode surveillance. 
the mission is planned by assembling a sequence of actions for accomplishing each task. navigation tasks in a known environment are best planned using graph search over a network of decision points. surveillance tasks are easily inserted in such a framework. 
a backward chaining search procedure is used to develop a tree of alternative mission plans. this search procedure is based on a version of the graphsearch algorithm described in  nilsson 1 . the algorithm has been modified to use rule based knowledge at the two critical stages of generating the list of successive actions  and selecting the next potential action to investigate. a similar modification may be found in a paper by mostow  mostow 1 . 
each action carries a vector of constraint values representing elapsed fuel consumption  time  risk  and distance. the selection rules for considering an action are based on the sum of the current constraint vector plus the constraint vector that would be generated for straight line travel in efficient mode in f the current rule base tries first to minimize fuel consumption  and thus prefers efficient travel. by changing rules  paths which preferentially minimize time  risk  distance traveled or linear combinations of constraints can also be 
1 	perception 
constructed. 
a major use of the planning process is to signal impossible tasks. if a specified task can not be completed within the allowed constraints  the operator is notified. the problem can be remedied by increasing the value of the maximum constraint or by changing the mission definition. 
the first navigation task in the mission given above was:  go to place a . this task generates the set of sub-tasks: 
straightune to place 1 in mode efficient followroad to place 1 in mode efficient 
straightune to place 1 in mode efficient 
straightline to place 1 in mode efficient 
straightline to place a in mode surveillance 
although  the mission plan contained a navigation mode  the final choice of navigation modes is determined by the tactical situation. thus although navigation mode efficient was specified for travel to place a  mode surveillance is automatically chosen for travel between place 1 and place a because this is marked as forbidden. such a change in navigation mode may also occur if the tactical situation for the current route or place changes during mission execution. 
1 summary and conclusion 
this paper has described a system which coordinates action and perception in a mobile surveillance robot. an architecture was presented in which twin hierarchies for navigation and for perception are controlled by a production system. much of the functionality of the hierarchies is provided by action-level procedures at the highest levels of the hierarchies. the procedures for navigation  in particular  make heavy use of procedures within the perception hierarchy. an important source of coordination between action and perception is thus provided by these procedures. 
the task level control in the system is provided by a supervisor implemented as a production system. the supervisor determines the choice of navigation and perception procedures according to the mission plan and the local environment. the mission plan is developed by the supervisor in a planning stage before the mission begins. this planning stage serves both to decompose the mission into sub-goals which can be translated into procedure calls to the task level procedures and to verify that the mission can be accomplished within the stated constraints. 
bibliography 
 brownston1  brownston  l.  et. al.  programming expert systems in ops-1  addison wesley  reading mass.  1. 
 crowley 1  crowley  j. l.    navigation for an intelligent mobile robot   ieee journal of robotics and automation. vol 1  march 1. 
 crowley-coutaz 1  crowley  j. l. and j. coutaz   navigation et modelisation pour un robot mobile   technique et sciences en informatique  octobre/novembre 1.  in french  
 crowley 1  crowley  j. l.  using a composite surface model for perceptual tasks   1rh ieee conference  on robotics and automation  raleigh  n.c.  april  1. 
 nilsson 1  nilsson  n. j. principles of artificial intelligence  tioga press  1. 
 mostow 1  mostow  d. j.  machine translation of advice into heuristic search procedures   in machine learning: an a i approach  ed. r. michalski  et. al.  tioga press  1. 
 wallace et. al 1  wallace  r. w. et. al.   first results in road following   ijcai 1  los angeles  august 1. 
