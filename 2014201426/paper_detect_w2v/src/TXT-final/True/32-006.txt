 
information retrieval queries often result in a large number of documents found to be relevant. these documents are usually sorted by relevance  not by an analysis of what the user meant. if the document collection contains many documents on one of those meanings  it is hard to find other documents. 
we present a technique called conceptual grouping that automatically distinguishes between different meanings of a user query  given a document collection. by analysing a word cooccurrence network of a text database  we are able to form groups of words related to the query  grouped by semantic coherence. these groups are used to reorganise the results according to what the user has meant by his query. testing shows that this automated technique can improve precision  help users find what they need more easily and give them a semantic overview of the document collection. 
1 introduction 
1 	problem 
many information retrieval systems either find no documents or hundreds of thousands of documents to be relevant to a user query. in the first case  the user has to try to reformulate his query in less specific terms without including too much. 
in the second case  the documents retrieved usually are sorted by some relevance metric. the system tries to guess what the user meant by his query and will put documents that are more likely to be relevant  higher on the list. in this way  users should be able to find what they need by looking at the first page of the results. 
　　however  which documents are relevant is highly dependent of what the user meant by his query. if two users enter the query  jaguar  in a search engine  one may be interested in buying a new car  while the other is interested in finding a picture of the animal jaguar. 
1 	machine learning 
if the document collection contains more documents on cars than on animals  it is very hard for the second user to find what he needs. it is present in the retrieved document collection  but it is not on the top of the list. therefore he has to reformulate his query by adding new terms and try  jaguar animal  or  jaguar lion . or he has to be patient and examine many pages of search results. 
　　this is a problem that is typical of many largevolume information retrieval systems with non-expert users. they tend to enter short  on average 1 keywords  and vague queries. these yield large low-precision results that often frustrate users. 
1 	solution 
one way to overcome this problem is to make the system distinguish between the different meanings of the user query. if we could make the system ask   what did you mean by 'jaguar'  did you mean the car or the animal   we can help both users to find more easily what they need. 
　　we have found that an extensive statistic and semantic analysis of the documents can help the system to automatically distinguish between different meanings of a user query. 
　　this can help in two ways. first  users that are interested in something beside the main meaning of the query words can find relevant documents more easily. secondly  this analysis can give users a semantic overview of the document collection with regard to their query. 
1 	overview of this paper 
in this paper  we will explain how this technique of conceptual grouping works. we will start by discussing our way to build word co-occurrence networks since these are the basis of our semantic analysis. 
after that  we will elaborate on the algorithms used to analyse such a network to form the different concept groups of a user query. 
finally  we will show how the technique was used in several applications and discuss some testing results. 

1 co-occurrence networks 
the input for our conceptual grouping technique is a word co-occurrence  or word collocation  network. such a network consists of concepts that are linked if they often appear close to each other in the database. several algorithms have been developed to construct such networks. this paper is not about co-occurrence networks  so only a brief description will be given on how to build them. 
　much research has been done on building word cooccurrence networks  smadja and mckeown  1; pattel et al.  1; doyle  1; maron and kuhns  1 . many different measures for ranking co-occurrences are given  as well as different window sizes  shapes and distance metrics  patel et al.  1   however  most of these analyses use a small  about 1  subset of words from the database as a dimension for their co-occurrence vectors  mainly because of computational complexity. our approach uses all words from the database  yielding vectors of over 1 dimensions. this has the advantage that the selection of dimensions is based on the database and not on human judgement or simple word frequencies. 
　the text database that we used for this paper is the reuters-1 database1. it contains 1 short articles that appeared on the reuters news wire in 1. 
1 	co-occurrence computation 
we consider a textual database with a total of n* words. we filter out a number of stop-words and use a stemming algorithm to come up with a total of n different word stems in the database. 
we consider words i and j to be a co-occurrence in document d only if they both appear in d  no further than 1 words apart. the number of such co-occurrences of i and j in document d is represented by the total number of occurrences in document d by nd. the relevance of co-occurrence c  out of  of words i and j in document d is defined as 
with the word distance between the c-th cooccurrence of words i and j in document d  and pi the probability of word i in the database; 
to find the relevance of the co-occurrence of i and j in document d  we compute 
to summarise over all documents and find the associative strength between words i and j  we define a bounded-add operator that is defined by 
this operator behaves similarly 
to normal addition  but keeps within 1 and 1 if x and y do too. then  

where the summation uses the bounded-add operator instead of classical addition. 
after this computation  we have a matrix of n by n with relevances between 1 and 1. let  be the number of documents in which words i and j occur. we filter out all occurrences i and j for which because words that appear together only in one context may not be related after all  and words that appear together in very many contexts will not be very helpful in further computation. from this list  we return for every word i the 1 best words j that co-occur with i. 
1 	results 
by adding several optimisation techniques  we were able to produce a 1 concept co-occurrence network for-a database of 1 small documents containing around 1 different words in about 1 minutes. our analysis was performed on a simple desktop pc running at 1 mhz. we need about 1 mb of free disk space. the reuters database was analysed in 1 minutes  yielding a semantic network of 1 concepts with 1 links  thus having a branching factor of 1. 
the results of an analysis of the word 'bomb' in the reuters database are given in table 1. 

injured 1 blast 1 police 1 exploded 1 injuries 1 device 1 explosion 1 explosive 1 hospital 1 officers 1 soldiers 1 wounded 1 table 1 co-occurrences of the word 'bomb' 

1  reuters-1 collection  distribution 1  reuters ltd. 
and carnegie group ltd. see http://www.research.att.com/-lewis for more information. 

veling and van der weerd 	1 


figure 1 part of cooccurrences of 'bomb' 


figure 1 semantic network for 'bomb' 

1 	conceptual grouping 
even though co-occurrences are useful on their own  in this paper we will elaborate on a further analysis of these networks on the basis of a user query. the goal of this analysis is to identify different meanings of a user query. this will help an information retrieval system to give the user a better conceptual overview of the subject area he is interested in  and it may improve the precision of the returned documents  grefenstette 1 . many conceptual clustering methods use predetermined thesauri or word lists  and build a hierarchical order at index time  not at query time  michalski 1; fisher 1 . 
what we will do is try to find a number of groups of concepts  possibly overlapping   consisting of words that are co-occurrences of a user query. so  if a user enters a query ' water'  all words that are linked to it in the cooccurrence network are likely to be semantically related to water. these words should be grouped together in a 
way that concepts within the same group have a higher semantic coherence than words from different groups. 
　the idea behind the method of conceptual grouping is that words that are related in this way are more likely to be linked in the co-occurrence network as well  or to be closer to each other in the network. 
　some of the words that are linked to 'water' in the reuters co-occurrence network  are 'rain'  'crops'  'offshore' and 'drilling'. it is likely that there are more documents in which 'rain' and 'crops' appear close to each other than there are documents with 'crops' and 'offshore'. this is based on the assumption that words that have very different meanings will not appear together in many documents. 
1 machine learning 
　one way to quantify the ideas on conceptual grouping presented above is to build a custom semantic network for a user query. what we do is build a new small semantic network with all concepts that are linked to the user query  e.g. 'bomb'  see figure 1  which shows only some of the links around 'bomb' . these concepts will be linked in the new network  if they are directly linked in the original network  or if there exist more than one path in the original network with length 1 between the concepts. such a query based semantic network can be seen in figure 1 for the query 'bomb'. 
　the 1 words from the network  see table 1  form a new network. the fat lines represent first-order links  the thin lines represent second-order links. so the words 'explosive' and 'device' are co-occurrences of each other as well. the words 'injured' and 'wounded* are linked by a 
　second-order link because there are at least two concepts  'bomb* and 'killed'  see figure 1  that are linked to both concepts in the original network  even though 'injured' and 'wounded' are not directly linked. 
the two types of links will be treated the same in the following  but can be given a different link strength to distinguish between the two. 
1 	grouping algorithm 
we define a semantic network to be a tuple  v e  with v a set of vertices  that represent concepts  and e a set of edges {i j} between vertices i and j. 
we will build a set g* of groups gi that contain all concepts in the network. these groups may have some overlap  since it is likely that some words are related to more than one context of the query  c*  in this example 'bomb' . we will try to form g* different groups. the conceptual grouping algorithm consists of four subtasks. we will now explain what these four tasks do. 

compute base groups 
we start by analysing the semantic network  v e  to construct the smallest groups possible as a basis of further grouping. we will group concepts that are totally linked to each other. 
for all concepts c we construct a group gc that is defined as the largest set of concepts that contain c for which holds 

so we build groups of totally linked sub-graphs of the semantic network. some groups will only contain one concept  while others contain more concepts  such as the group {explosive  device  injured} in figure 1. the group {injured  explosion  blast  injuries} is totally linked as well. 
note that after this step 
optimise groups 
the base groups contain some redundancy because there are several small groups that are totally contained in other groups  and there are several groups that are exactly the same. 
in this step we eliminate these groups by removing all groups gi for which holds 

reduce groups 
a solo group is a group of only one concept that has no links to other concepts. in figure 1 the group {hospital} is such a group. in some contexts  there are a lot of such groups that often have little significance to the different meanings of c*  so we will try to group them together in a garbage group ggarbage. in this way the groups that are formed will be more coherent because there are less such solo groups that make up a part of the g* groups. 
	/ / 	garbage 	c o l l e c t i o n 
while 
find a solo group g if  number of solo groups  then 
merge g w i t h ggarbage 
we only put the solo groups in the garbage group if they take up more than a quarter of all groups because they only hinder the differentiation of meanings if there are many of them. 
if the first step still results in too many groups  we use another grouping method. there are groups that contain just one concept  even though they have links to other concepts. we identify these concepts and merge them into the group they best fit into. this group is simply the group to which the concept is linked most. 
merge linked unary groups 
	while 	do 
find the group g w i t h that has the smallest number of l i n k s find the best group h g can be linked to 
merge g i n t o h 
if we still have too many groups  we will merge groups that have concepts in common. we define the overlap between groups g and h as follows 

f i n d groups g and h w i t h the h i g h e s t o v e r l a p 
merge g and h 
a final method for grouping concepts is used if the first three methods still give too many groups. many groups contain concepts that are linked to each other. we define the interconnection between groups g and h  with 
to be 
that is  the number of links between the groups divided by the number of links the smallest group has. 
	merge 	i n t e r c o n n e c t i n g groups 
	while 	do 
f i n d groups g and h w i t h the h i g h e s t i n t e r c o n n e c t i o n 
merge g and h 
this step concludes the merging of groups. note that it is possible that we still have not reached the desired number of groups g*. many improvements can be made to these grouping steps  by adding new merging conditions  or by taking into account more information  such as the strength of the links between the concepts . however  we find that the algorithm presented here is accurate enough for our purposes. 
sort groups 
the final step of the conceptual grouping algorithm provides a way to internally sort the concepts in each group. we needed this step to be able to present the groups to the user. the meaning of a group is dependent on the whole of the group  so we needed to present all concepts in a group to the user to make him understand the identified sub-meaning of his query. some groups contain many concepts and we needed a method to limit the number of concepts shown to the user  in a way that these concepts still explain what the group is about 
　we found that sorting the concepts in each group by a centrality metric does just that. for the query 'water* one 
veling and van der weerd 1 

of the groups on offshore drillings contains 1 words among which 'field' and 'california*. these concepts are less clarifying to the meaning of the group than the words 'drilling' and 'offshore'. by sorting the group  the best three words in the group are 'feet'  'drilling' and 'offshore'. these words are presented to the user  even though all words in the group are used to search the database. 
the centrality measure used to sort the concepts in each group is 

that is  the number of links in g that stay within the group. concepts with the highest centrality appear before concepts that are more in the group's periphery. 
1 	grouping examples 
to give the reader an idea of what types of responses the system can give  we now present a number of examples of the conceptual grouping of several queries. the basis for these analysis was the reuters-1 database  and we grouped with g*=1. the grouping analysis took about 1 ms for each word  so it can easily be done real-time  when a user enters a query. we only present the best three or four words for each group. 
water 	rainfall  dry  rain 
feet  drilling  offshore 
         waste  environmental bomb injured  explosion  injuries 
soldiers  wounded  officers 
         hospital cola 	coca  coca-cola  bottling  coke 
　　　　　pep  pepsi  pepsi-cola  pepsico satellite 	programming  entertainment rocket  orbit  space  nasa 
table 1 grouping examples 
from table 1 it can be seen that the system is able to distinguish between several meanings of 'bomb'  that is the bombing by terrorists versus bombing during a war. and it can distinguish between two large cola producing companies  coca-cola and pepsi cola. in the last example  the difference between the tv meaning of 'satellite' and the space-related meaning is found. 
　these examples show that conceptual grouping is able to successfully identify clusters of meanings that are semantically coherent. these clusters make sense. for other words  the clusters are sometimes less intuitive  even though most of the words in them are related to the query. we found that these sub-meanings often rise from the documents in the database and that there are such clusters of documents. so even in cases where the clustering is not very clear  it may help users find these clusters more efficiently. 
1 	machine learning 
1 	application of conceptual grouping 
conceptual grouping can be applied in two ways. first  it can help give the user an overview of the subject area he is interested in. we can do this by presenting the first couple of words of each group for a user query. the user can click on these words and reformulate his query to examine documents from the context of his original query. several visualisation techniques are available to do this  among which the aqua browser  veling 1 . secondly  grouping can be used to enhance precision in 
information retrieval systems. by grouping the user query in the way presented in this paper  the system can present the user with a tailor-made overview of the document collection. this application is similar to the semi-automatic clustering of the northern light search engine1  or the human indexed livetopics from altavista1. however  our approach seems to give more intuitive clusters  and it is completely automatic. 
we have built several information retrieval systems that use conceptual grouping in this way. one of these has a web-based interface that can be used to query the reuters database. 
　after a user types in a query  all document titles  and summaries  of documents that contain the query words are returned. a page of document titles contains 1 titles  and the user can browse through these documents and view the original documents in another frame. the groups are presented on the top of the page that lists results as follows. 
1 documents about  water  found. 
did you mean feet  d r i l l i n g   r a i n f a l l   dry  r a i n waste  	environmental 
1. pakistan gets 1 mln dlr world bank 
loan mln-dlr  	1-year loan to assist paki-
stan in a project designed to improve 
power plant efficiency... 
1. election result may delay japan economic stimulus 
 the r u l i n g liberal democratic party's  ldp  setback in sunday's nationwide local elections may... 
the groups are hyperlinks to a new search result that uses the group's words  all words  not just the ones shown  to capture the meaning of 'water' the user selected. 
1  see the custom search folders at http://www.nlsearch.com/ 
1  see http://www.altavista.com/ 

the filtered search combines two searches. it uses the results from the original query and it sorts them by the results of the group query. so if the user is interested in the 'rainfall  dry  rain' meaning of 'water'  the database is searched for any words from the group. these results are then used to sort the results from the query 'water'. note that no extra documents are retrieved. the new result contains just as many documents as the 'water' query; they now are sorted by meaning  so documents about rain will appear in the top of the list. we use an orranks operator that combines ranking information like a classical or  but only includes documents from one of the two result sets. the use of this operator instead of classical or helps to overcome the noise problem  rousselot 1  of using groups to filter queries. 
　we have tried other visualisation techniques for the groups as well  among which a presentation of the semantic network in a pie chart  with the groups as pieces of the pie. this may give users a better insight in the directional aspect of the approach. 
　we have not yet performed large recall/precision tests for conceptual grouping  but the extra user feedback loop has helped users to find documents on non-mainstream meanings of their queries. so if the groups are both intuitive and related to a subset of the documents retrieved for the original query  as they seem to be   the precision of the system will certainly be improved. 
1 	conclusions 
even though more extensive testing is needed  we can safely conclude that conceptual grouping is a powerful technique for enhancing the precision of information retrieval systems. it is completely automated and can be computed on a desktop computer in a reasonable amount of time. all that is needed is a textual. 
　the results of conceptual grouping seem to be intuitive  and may help users to find documents more easily  as well as give them an overview of the context of their query and the database. the algorithms need more tweaking to improve performance. 
for some queries  conceptual grouping yields nonintuitive clusters. however  these clusters have meaning on closer examination for the specific document collection. 
　we conclude that conceptual grouping is a promising technique that can be applied in many different information retrieval systems. we will continue to improve its performance and application. 
1 	suggestions for future research 
many improvements can be made to both the cooccurrence generation process and the conceptual grouping algorithm. for example  the use of word categories  nouns  verbs  in filtering the words may be helpful to decrease the number of noise words  e.g. 'red'  'have' . 
　if we would combine conceptual grouping with a publicly available thesaurus  such as wordnet or wordweb   we could try to find the best category for each group. this could help users to understand the group better  by presenting 'car' versus 'animal' instead of 'mercedes  xjr' versus 'lion  africa' for the 'jaguar' example. 
　the visualisation of tailor-made query-based clusters of documents needs more research too. how can we best explain visually the difference between query expansion and conceptual clustering  
