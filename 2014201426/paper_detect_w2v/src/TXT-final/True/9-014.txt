 
¡¡¡¡¡¡this paper describes a theory formation system which can discover a partial axiomization of a data base represented as extensionally defined binary relations.- the system first discovers all possible intensional definitions of each binary relation in terms of the others. it then determines a minimal 
set of these relations from which the others can be defined. it then attempts to discover all the ways the relations of this minimal set can interact with 
each other  thus generating a set of inference rules. although the system was originally designed to explore automatic techniques for theory construction for 
question-answering systems  it is currently being expanded to function as a symbiotic system to help social scientists explore certain kinds of data bases. 
introduction 
¡¡¡¡¡¡for over a decade researchers in ai have been designing question-answering systems which are 
capable of deriving  implicit  facts from a sparse 
data base. whether these systems use an axiomatic theorem proving approach or a procedurally oriented approach  they all must eventually face the problem 
of characterizing the generic knowledge or structural redundancies of their particular domain of discourseeven the simplest of such domains contains countless subleties which somehow must be captured before a 
complete characterization can be achieved. 
¡¡¡¡¡¡in this paper we discuss the problem of automatically constructing such a characterization. 	our 
research has not been directed toward a theoretical 
investigation of this general problem as in plotkin 
but rather towards constructing and experiment-
ing with a prototype system which has been applied to large and structurally rich domains. we w i l l provide 
numerous examples to show what is involved in forming conjectures about  apparent  structural redundancies 
in a given data base  model  and how such conjectures can be heuristically validated. the search for 
structure is inherently combinatorial. 	we w i l l there-
fore discuss borne ways to control the combinatorial 
explosion involved in forming and validating structural conjectures. finally  we w i l l discuss ways in 
which such a system might be used to help a social 
scientist discover structural theories about a set of observations over some  world . indeed  our eventual aim is to expand this system into a tool for such uses . 
problem definition 
¡¡¡¡¡¡before describing our system  a definition of the vague term  structural redundancies  is in order. let us consider a data base consisting of the complete extensions of a collection of binary relations r - {r1......rn} . that i s   for each ri e r the data base contains all the triples  x ri y  for each 
 x y €r 1 . 	the structural redundancies of this data base f a l l into three basic categories. 	the f i r s t 
category occurs where one of the relations is 
1 

¡¡¡¡¡¡the second kind of structural redundancy occurs where the existence of a path in the graph forms a sufficient but not a necessary condition for some other arc to exist. tor example  suppose we augment our data base to include the extensions of the sibling and cousin relations over the sane domain p. we 
would then discover that for every path of the form  x sibling z  and  z cousin y  there was always an arc of the form  x cousin y . such a pattern would lead to the rule: 
sibling/cousin =  cousin 
     the third and simplest kind of structural redundancy occurs where the relation itself has cer-
tain logical properties such as: 
transitive 
symmetric 
reflexive 
irreflexive 
     the f i r s t two kinds of redundancies cover how a given relation interacts with other relations in r  
whereas the last kind covers only how a relation interacts with itself. 
     the structural patterns comprising a l l three categories form the basis of a logical theory  or axiomatic characterization  of the data base in the following way: 
¡¡¡¡¡¡i n i t i a l l y   the data base consists of the complete extensional definitions of all the given relations. after our system discovers a l l the intensional definitions of the relations  then some subset of these relatione can be selected  to be called the atomic relations  from which the extension of a l l the remaining relations can be derived. the extension of a non-atomic relation can be computed by knowing only its intensional definition in terms of the selected atomic relations. consequently  the extensional definitions of a l l non-atomic relations can be discarded with no loss of information. in addition  the extensions of the atomic relations can be pruned by using structural properties in the second and third categories. for example  if an atomic relation is symmetric  then half of its extension can be 
eliminated without loss of information. 	with respect 
to the two structural redundancies: 
parent = spouse/parent spouse symmetric 
half of the parent and spouse extensions can be likewise discarded. what remains after all the redundant extensions have been eliminated is a kernel bet of extensions. 
     the structural rules defined by the set of intensional definitions  the logical properties of the atomic relations and the implicational statements in conjunction with a kernel set of extensions suffice to determine the complete extensions of a l l the relations. these rules plus the kernel set of data form a logical theory of the original extensional relations. note that the complete extensional 
set of delations is necessarily a logical model of the resultant  theory . the fact that this model  or equlvalently - the extenaionally defined relations  is f i n i t e   as far as our system is concerned  
 techniques to select the atomic sets are not discussed here but arc discussed at length in brown1. presents the interesting situation that our 
system w i l l often produce numerous rules that hold for this finite collection of data but which appear to be idiosyncratic. that i s   if the collection of data is really a sample from some potentially infinite model  then of course numerous  rules  may be found that 
might prove to be false when the data base is enlarged. 
on discovering intensional definitions 
¡¡¡¡¡¡the basic idea underlying the discovery of i n tensional definitions is quite simple. suppose we are trying to discover all the possible definitions of ri e r. since ri exists in the data base  it has a set of 1-tuples which represent its extension. we commence our process by arbitrarily choosing one of these 1-tuples  *i yi  and then searching for all possible simple directed paths that start at xi and end at yi we then delete the intermediate nodes of each such path leaving only an ordered l i s t of the labels of the path which we w i l l call a labelled path sequence  lps . the end result of this process is a l i s t of distinct lps's  each stemming from at least one specific path from x¡À to y j .  several xi  yi paths can collapse onto one lps   
     depending on storage limitations etc.   we repeat this process several times  choosing a different 1-tuple from ri's extensions for each repetition. 
in this manner we construct a collection of lists l: 

 computing this intersection can be quite costly  so some care is required in choosing a good data structure for these l i s t s   . if this intersection is nonempty  then the lps's that lie in this intersection form the f i r s t set of conjectures and are therefore 
passed to the verifying procedures to determine if there are any counter-examples to these conjectures. if an lps survives this check then it represents an intensional definition for ri. for example  suppose r1 - r1 - r1 is an lps which is in common to a l l the lxy's. it is then conjectured that r1 = r1/r1/r1. the intermediate nodes that were removed from the various paths underlying this lps are possible bindings for the extensional variables z1.z1 in the expression: 

on the other hand  the verifier determines whether for every x  y  and z1 and z1 that satisfy the right-hand side of the above expression  the 1-tuple  x y  is necessarily contained in ri's extension- if this is not true then the conjectured definition is considered to be  over-general . 
     a more interesting case arises when the intersection of a l l the lxy's is empty. in such situations there is no simple compositional definition for ri. instead  its definition  if there is one  must involve a disjunct. an obvious strategy to pursue is to keep intersecting the lxy's until the intersect becomes empty. at that point  undo the last intersection  
leaving a non-empty intersect. then  starting with this removed l i s t   recommence forming the intersection with it and the next l i s t and so on. for example  suppose we have l1 l1 l1 l1 l1 l1 as six lists of lps's with the following properties: 

we are left with three sets of non-empty intersections  namely l1 l1 l1 the conjectured definitions for ri would then be of the form: 

thus an intensional definition of ri would be a disjunct of relational compositions. 
     a moment's reflection on the above intersection process reveals that the outcome of these intersections can be critically dependent on the order in 
which the lists are intersected. for example  the lists l1 l1 l1 might very well form a non-void intersection and likewise the lists l1 l1 l1. if this were the case  we would then have unfolded a simpler set of conjectured definitions of the form: 


1 ¡¡¡¡¡¡given a moderately large data base of several hundred 1-tuples over thirty kinship relations  we were trying to discover some definitions of  parent . the resultant intersections computed with the original ordering of the lps lists  using a considerably more sophisticated algorithm for choosing what l i s t to merge next  led to the disjunctive sets of conjectures found in table la. however  a further search revealed a s t i l l better ordering yielding the conjectures found in table lb. 

     having great faith in occam's razor  we only attempt to verify conjectures that emerge from the 
minimal number of disjunctive intersections. finding an optimal grouping of the l lists that lead to this 
minimal property ib combinatorlally equivalent to the classical covering problems   however  unlike 
many covering problems  a fairly simple heuristic turns out to be quite satisfactory  see brown1 for 
more details . 
     a grouping for these lists which leads to the minimal number of non-null intersections induces a clustering of ri's extension  i.e group together all the  x y 's that generated the lps's of each disjunct . often this clustering can indirectly induce a clustering or even a partition on either ri's domain or range. this clustering should reflect some  internal  structure of the objects themselves. considering the above parent example reveals that the clustering of 1-tuples induced by the definitions of table lb shared the property that the first component of each of them were female. likewise  the first component of the other 1-tuples were a l l male. but  as far as the system knew  no object in the domain 
had any distinguishing characteristics whatsoever. thus  in some sense  the system had unfolded the necessary information to conjecture two unary predicates theretofore completely unknown to i t . justification of these predicates often requires supporting evidence which may be forthcoming i f   in considering other relations  similar clusterings are induced. 
discovering rules of inference 
     we w i l l concern ourselves only with discovering inference rules of a very restricted form. these rules w i l l be either of the form: 
1  
¡¡¡¡¡¡¡¡¡¡ where r itbelf could be also on the left  or of the form: 

¡¡¡¡¡¡in the latter case  the relatione under the vertical bar denote a required context before this rule can be applied. 	the similarity of these rules to context free and context sensitive grammars is not accidental. 	in fact  these inference rules are directly 	usable bv the question-answering system detailed in brown. 
¡¡¡¡¡¡discovering the f i r s t type of inference rule would appear to be straight-forward. we need merely locate a sequence of relations whose compositional 
extension is contained within the extension of r. the problem  however  lies not in finding such sequences but in finding  useful  sequences. although 
we have no way of making this distinction precise  we realize that in creating an axiom system for a question-answerer we often want more than just a minimal independent set of axioms. we want axioms that enable us to answer  usual  questions without undue inferencing. believing that typical questions often relate to subparts of the intensional definitions we bought ways to use the structure of the relations themselves in isolating potentially  useful  rules. 
     one way to isolate these rules would be to use the intenaional definitions themselves. specifically  any  recursive definition is a particularly good candidate   such as: 

¡¡¡¡¡¡another way t  generate potentially useful rules would be to discover definitions for a particular relation which turn out not to cover r's extension when their defining subspace is enlarged. an example of such a definition might be: 

which could arise from a data base in which every family had two children. but again  the key problem is finding ways that the structure of a relation can  i t s e l f   delimit  interesting  subsets of its own extensions so that we don't have to rely on chance for' providing such subspaces. 
determining subspaces for the discovery of inference 
rules 
     one way in which the structure of a relation can induce a natural partition on its extension is by 
possessing a disjunctive definition. this  as mentioned above  splits the relation's extension into groups of 1-tuples covered by the particular disjunctive terms. for example  using the parent example  we are lead to form the t r i v i a l rules: 

however  the disjunctive definition underlying these rules has the property that the two disjuncts are disjoint. that i s   if  x y  is satisfied by one of the disjuncts  it necessarily is not contained in the other. by searching for disjunctive definitions whose disjuncts can overlap  and in which one of the disjuncts covers a maximal portion of the given relation's extension  we discover such rules as: 

¡¡¡¡¡¡another way to utilize the structure of a relation in isolating subspaces stems from the co-occurrence of compositional seouences in a given disjunct of its definition. for example  in considering a data base of over five hundred facts  we discovered the standard definition of brother-in-law: 

let us consider the last disjunct which asserts that: 

line 1 suggests that in the  context  of  husband  the relations  sister  and  sibling  function equivalentl y   or we could say that: 

when conditioned on the left with  husband . clearl y   the notion of  context  is quite important for  although the rule  sister =  sibling  could be inde-

1 

1s 
¡¡¡¡¡¡our heuristic procedure picks an object 	x 	in the domain of the relation r being defined and com-
putes both the sets ir x  and 	i def  x . 	it then 
checks to see if the set x def  x  is equivalent to the set ir x . 	if not  it rejects the  def ; other-
wise it chooses a new 	x 	from r's domain and repeats 
this procedure until the domain of r has been exhaust-
ed. 	a faster but less complete version of this 
heuristic doesn't bother to exhaust r'e domain but chooses only one element from each inverse image class. these checkb are only heuristic since they 
do not take into consideration the local connections of the relations within each inverse image class  but that is precisely why they are fast! have to be temporarily  blocked  and a new set of 
conjectures would have to be invented. these new conjectures would then have to be verified  and so on  
until all the conjectures passed the verification 
phase. 
     our experiments have revealed that  for most of our test data  this process of conjecturing  verifying and blocking is often repeated a dozen or so times before a set of conjectures are formed which cannot be disproved within the data i t s e l f . conse-
quently  our system must typically verify many more conjectures than appear in the final output.                                                              some experiences an example of the power and limitations of this heuristic may be seen from another date base  of over a hundred facta  analyzed by this system. 
two types of patterns could appear. 
definitions might emerge that reflected idiosyncracies 
of this particular data which would  disappear  if we 
considered more data. valid definitions might appear which were logically 
¡¡¡¡¡¡the need for developing heuristics for speeding up the verification of conjectured definitions is better appreciated whan we understand the complex interactions between the generation of conjectures and their subsequent verification. in fact  there is a constant switching of control between these two phases. for example  suppose the f i r s t set of definitions conjectured were subsequently disproved in the verification phase. then a l l the paths in the data graph that lead to these conjectures would equivalent to ones we already knew  but which might 
be  simpler  relative to some criterion. both types of unexpected patterns may be seen in the f i r s t set of definitions discovered for the uncle relation 
on this data base  see table a . clearly the f i r s t two of these definitions reflect the idiosyncracy 
that every uncle is married. 	the third definition 
which is complete yet involves no disjuncts and as such might be considered simpler than the standard two disjunct definition: 1 
uncle = brother/parent v husband/sibling/parent 
weaknesses 

it was not u n t i l these definitions were manually over-ridden and indeed a fair number more before our system came up with the  traditional  definition. 
¡¡¡¡¡¡appendices 1 and 1 give a feeling for the surprising multitude of structural definitions found on this data base. for example  appendix 1 contains some of the three hundred definitions of  uncle which 
were discovered just on the above data base. the second appendix reveals the first set of definitions discovered for some of the other kinship relations. note  for example  the seven universally valid definitions for  cousin . 
     not all our experimenting has been limited to kinship relations. 	another domain that has been analyzed was made up of the extensional definitions of the accessibility relations between squares on a chess board for the various chess pieces. 	more precisely  the data base consists of a universe of 1 
objects - representing the squares of a chess board - and a collection of extensionally defined relations. some of these relations are geometric  e.g. east  just-east  positive-diagonal  and the others are chess moves represented as binary relations. for example   x y € knight means that a knight can move in one step from x to y. the task was to discover the definitions of the legal moves of the various chess pieces in terms of the other chess pieces and/ or in terms of the geometric relations. although space precludes a thorough description of our findings  we indicate below some of the discovered definitions: 
*in this system  the user has the freedom to reject definitions even if they have been accepted by the verifier and thus search for additional definitions which involve more disjunctions than the current ones. 
1 
     there are several limitations to our system that deserve further attention. 	the f i r s t concerns the difficult area of characterizing when something cannot be true. 	all the definitions and axioms i n vented by our system express positive assertions. that i s   our system never discovers the crucial fact that siblings can't marry and hence a father cannot be an uncle to his own child. 	of course  
we can hedge this problem by including just the right additional relations which cover precisely 
what can't hold over the original set but this quickly gets us into a combinatorial explosion. 
for example  we could include the relation  nonuncle  whose extension is the complement of uncle and then perhaps we could uncover: 
father -  non-uncle. 
somehow such a solution seems unpleasing since once the positive assertions have been characterized one 
might hope that they could he combined with a few negative assertions to imply all the potential negative assertions. 
       the second major limitation is that nur system expects its sample data base to be complete  i.e. missing no data and containing no erroneous data. there are numerous wavs to circumvent this limitation  some of which have been implemented. for example  the verification phase not only checks a conjecture 
but isolates  for any rejection  the counter-examples. the user can then decide whether or not to over-rule the verifier by deleting from the data hase these  counter-examples.  however  a considerably more provocative approach to the problem should be possible. relying on occam's razor  we might consider the entire set of discovered definitions and see how a particular set of changes on the data base affects the complexity of not only the definitions of the relation under btudy  but also the collection of definitions for all the relations. since altering a given relation's extension affects not only its own definition but also the definitions of all the other relations definable in terms of this relation  we would expect a dramatic global simplification for 
the  correct  changes to the data. 
further plans 
¡¡¡¡¡¡in addition to exploring the above issues we plan to investigate how to achieve more of a synergistic effect between the user and the computer in seeking the underlying structure of his data. the system is being re-implemented in lisp on a pdp-1 in hopes of having a friendlier environment for exploring the symbiotic uses of this kind of a theory formation system. 
acknowledgement 
¡¡¡¡¡¡i am deeply indebted to dr-. robert k  lindsay for defining this research problem and for helping me understand some of its ramifications. 




1 
