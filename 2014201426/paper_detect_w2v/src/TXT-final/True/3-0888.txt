 
accurate recognition and tracking of human activities is an important goal of ubiquitous computing. recent advances in the development of multi-modal wearable sensors enable us to gather rich datasets of human activities. however  the problem of automatically identifying the most useful features for modeling such activities remains largely unsolved. in this paper we present a hybrid approach to recognizing activities  which combines boosting to discriminatively select useful features and learn an ensemble of static classifiers to recognize different activities  with hidden markov models  hmms  to capture the temporal regularities and smoothness of activities. we tested the activity recognition system using over 1 hours of wearable-sensor data collected by volunteers in natural unconstrained environments. the models succeeded in identifying a small set of maximally informative features  and were able identify ten different human activities with an accuracy of 1%.  
1 introduction 
the task of modeling human activities from body-worn sensors has received increasing attention in recent years  especially in the ubiquitous computing  ubicomp  field  bao and intille  1; lukowicz et al.  1; patterson et al.  1 . although originally most of the research in activity recognition was done using vision sensors  gavrila  1; pentland  1   it has increasingly become dominated by various types of wearable sensors  like accelerometers and audio. a fertile application domain for activity recognition is in the health care arena  especially in elder care support  long-term health-monitoring  and assisting those with cognitive disorders. in addition  activity recognition is an important component for modeling higher level human behavior  tracking routines  rituals  and social interactions.  
　the majority of research using wearable devices  has concentrated on using multiple sensors of a single modality  typically accelerometers on several locations on the body  bao and intille  1; kern et al.  1 . the placement of sensors in multiple pre-defined locations can be quite obtrusive and is one of the limitations of such an approach. while the ultimate goal is to embed these devices into clothing  this technology is far from being commercially available and widely accepted. as a result  a single sensing device that can be integrated into existing mobile platforms  such as a cell phone  will be more appealing to users and is likely to garner greater user acceptance. work by  bao and intille  1  has shown that an appropriate sensor subset  two locations   does not effect the recognition scores significantly  by less than 1%  compared to a system with five sensors; whereas the use of a single sensor reduced the average accuracy by 1%. our hypothesis is that incorporating multiple sensor modalities will offset the information lost by using a single sensing device. furthermore  multiple modalities will be better suited to record the rich perceptual cues that are present in the environment  cues that a single modality often fails to capture. multiple modalities have already shown promise in earlier activity recognition experiments  lukowicz et al.  1 .  
　to capture the diverse cues from movement  sound  light  etc.  about ongoing activities  we have built a very small sensing unit  1 sq. in.  that includes eight different sensors: accelerometer  audio  ir/visible light  highfrequency light  barometric pressure  humidity  temperature  and compass. using these sensors  we have collected a large annotated dataset of various human activities from two volunteers over a period of six weeks. we compute over six hundred different features from these eight sensor modalities  which attempt to capture various attributes of the raw signal. 
　often in activity recognition  the choice of sensors and the features derived from them are driven by human intuition and by what is easily available  rather than by performance or practicality. using the right features is crucial for recognition. we are working towards developing a framework that allows us to systematically identify modalities and features that are most useful for machine recognition and discrimination of natural human activities. 
in the end  we want models that accurately recognize and track a variety of activities and a system that is lightweight enough to run on devices like cell phones  which many people already carry. thus  minimizing the computation cost of our recognition system is also an important goal.  
　the two main approaches that are used for classification in machine learning are:  i  generative techniques that model the underlying distributions of the classes and  ii  discriminative techniques that only focus on learning the class boundaries  rubinstein and hastie  1 . both of these approaches have been used extensively in the vision and the wearable sensing communities for recognizing various human behavior and activities. the work presented in this paper is a hybrid approach that combines the two techniques. first  a modified version of adaboost proposed by  viola and jones  1   is used to automatically select the best features and to learn an ensemble of discriminative static classifiers for the activities we wish to recognize. second  the classification margins from the static classifiers are used to compute the posterior probabilities  which are then used as inputs into hmm models. the discriminative classifiers are tuned to make different activities more distinguishable from each other  while the hmm layer on top of the static classification stage ensures temporal smoothness and allows us to continuously track the activities. 
　the rest of the paper is organized as follows: section 1 provides an overview of the activity recognition system. section 1 presents the feature selection and discriminative classifier training method. section 1 describes how the results from the classifiers are combined with hmms. section 1 describes our experimental results and the performance of the system  and section 1 discusses our conclusions and possible future directions 
1 activity recognition system overview 
the first problem we address is the systematic identification of modalities and features that are well suited for accurate recognition of natural human activities. the second problem we tackle is how these features can be effectively used to develop models that accurately recognize and track various activities. below we give a brief overview of the different components in our activity recognition system. 
sensing and feature extraction 
using a shoulder mounted multi-sensor board  figure 1 a    we collect approximately 1 samples of data per second. to reduce the dimensionality and to bring out details in the data we compute a total of 1 features; which include linear and mel-scale fft frequency coefficients  cepstral coefficients  spectral entropy  band pass filter coefficients  integrals  mean and variances. we combine the features from various sensors to produce a 1 dimensional feature vector at 1hz. however  since we have sensors with different sampling rates  there can be multiple instances of a feature within the 1 second window; that operate on different portions of the data. furthermore  when calculating some features  e.g. the integral features  we incorporate a longer time window that varies from several seconds to as long as a minute. we restrict the time windows to only use data from the past  so that our system functions without any latency.  
feature selection and discriminative activity models earlier work has shown that discriminative methods often outperform generative models in classification tasks  ng and jordan  1 . additionally  techniques such as bagging and boosting that combine a set of weak classifiers can further improve accuracy  without over-fitting to the training data  schapire  1 .  viola and jones  1  have shown that boosting can be used not only as a method for combining classifiers but also as a method for selecting discriminative features. we use their proposed approach to select only a fraction of the total features  and to train very simple ensemble classifiers to recognize a broad set of activities. 
capturing temporal regularities 
the activities people perform have certain natural regularities and temporal smoothness  e.g. people do not abruptly switch back and forth between walking and driving a car; thus  the recent history can help in predicting the present. using a sequence of posterior probabilities computed from the instantaneous classifiers  we train hidden markov models  hmms  that significantly improve the performance and smoothness of our recognition system. by incorporating the static classification results we overcome the weakness of hmms as effective classifiers  jaakkola and haussler  1 .  
1 selecting the right features  
given a rich set of sensor data and features  our classifiers will work best if we select the right features that enable the classifiers to discriminate well between classes  and if we remove features that are not useful or which might even confuse the classifiers. although it might be possible to hand pick the optimal features for certain activities  this is not a viable solution when the number of activities become large or when the sensor signals are not intuitive. in such scenarios  automatic techniques for finding the right set of features become increasingly important. a practical activityrecognition system will use a minimal number of features and the simplest possible models needed for high accuracy.  
1 feature selection and activity classification using boosted decision stumps 
in this paper  we assume that people engage in n different type of activities. given the set of activities a ={a  ... a1 n}   we also assume that we have a set of training data for each of those activities. each sample in the training set consists of a feature vector f ={f  ... f1 k} extracted from the sensors. for each activity ai we are 

figure 1: flow diagram describing the classification system presented in this paper.  a  our sensor board records a sequence of raw sensor recordings  b  from which we compute our feature vector. we pick the top fifty features per class  from our feature vector  and  c  supply them as inputs to our ensemble of decision stumps classifier.  d  each decision stumps classifier outputs a margin at time t.  e  this sequence of margins can then be converted to probabilities by fitting them to a sigmoid.  f  the sequence of probabilities is then supplied to ten hmm classifiers  g  each of which outputs a likelihood.  h  the class with the highest likelihood is the classified class. interested in finding a ranking of the feature set ri ={r  ... r1i ki }based on their usefulness in recognizing activity ai . moreover  we want to find a cut-off point τi for the ranked feature set such that adding features beyond τi does not significantly improve the accuracy of the classifier 
ci   i.e.   error c  f  ... fi ri1 rin     error c  f  ... f    i r1i riτ ＋ε . the reason behind estimating τi is that  if τi  n then we can reduce the computational complexity of our classifiers by not extracting the less useful features. since our final goal is to have the classifiers run on devices that users carry or wear  the computational costs of the classifiers are critical.  
　for each activity ai   we iteratively train an ensemble of weak binary classifiers hi ={h  ... h1i in}  figure 1 c   and obtain a ranking ri ={r  ... r1i ki }for the features using the variation of the adaboost algorithm proposed by  viola and jones  1 . the weak classifiers are constrained to use only one feature  and at each iteration m of boosting we select the feature and the associated weak learner h  f  im m that minimizes the training error εim  fm   on the weighted data. the error εim  fm   is used to re-weight the data for the next iteration and to compute the weight αim for h  f  im m . at the end of this process  we have a ranking for the features based on how useful each feature is in discriminating ai from the other activities aj  j 』 i    and we also have a set of weak classifiers h  f  im m and weights for those classifiers αim . the final output is a weighted combination of the weak classifiers  and by estimating the error of ci as a function of the number of features used  we can also find τi forci . so  for a given data point  the prediction of ci is 
	h    i f	sign 	imh  f   im	m	 
　each classifier ci uses the top τi features  which is a fraction of the total number of features available  i.e. f i =  f  ... f1i τii   . 
　we tried two different weak classifiers in our system:  i  a discriminative decision-stump and  ii  a generative na ve bayes model  conditional probability distributions are modeled using histograms that have 1 bins/dimension  as our weak classifier. in our experiments  the decision stump consistently outperformed the na ve bayes classifier  so we only use results from the decision-stump based classifier in the later sections. the decision stump finds the optimal threshold θim for each feature fm that minimizes the weighted error such that h  f  im m =1 if fm  θim and h  f  im m = 1otherwise.  
　for the boosted static classifiers  the classification margin for a data point can reflect the confidence in that prediction  schapire et al.  1 .  the margin of an example is the weighted fraction of the weak classifiers votes assigned to the correct class.  
	‘τi αimh  f  im	mi
m  i f i   = m 1=
	i	 
m
h  i f i   = sign m  i f i   
　however  constructing classifiers to output a posterior probability is very useful  especially if we want to combine the results of the multiple classifiers later on. one method of computing posterior probability directly is to fit a sigmoid function to the output of the ensemble classifier  platt  1   figure 1 e  . in our case  the posterior probabilities are derived as follows - 
 m  i f i  
	p c |i f i   = e em  i fi   +1  where  is a constant 	 
　a static classifier predicts the label for each data point independently. most of the time this independence assumption is clearly invalid and the prediction of previous data points can help with the current classification. a temporal model that uses the confidence of the predictions of the classifiers csi instead of the raw features f i is likely to have a greater impact on the performance. the ability to recognize activities in continuous time chunks would also allow us to learn how people transition between activities and thereby allow us to learn more about people's behavior and activity patterns. in the next section  we describe how we combine the confidence values of the static classifiers to build time-series models of the activities. 
1 incorporating prediction history using hidden markov models 
hmms have been successfully used in modeling different types of time-series data  e.g. in speech recognition  gesture 

figure 1: testing error rates per class as a function of the number of features selected. after 1 features are selected most of the testing errors for the classes have leveled off. the data graphed here is averaged from several smaller feature selection runs. 
 
tracking etc. we use hmms to capture the temporal dynamics; but instead of directly using the raw features selected in the previous section  we trained our hmms using the posterior probabilities of the static classifiers. the advantage of using the posterior probabilities is that we can take advantage of the results from the discriminatively trained classifier  as well as reduce the complexity of the hmms. the earlier work of  jaakkola and haussler  1  has also shown the benefits of combining generative models into discriminative classifiers by deriving kernel functions from probability models.  clarkson and pentland  1; oliver et al.  1  have used the output of an hmm model as input to another hmm.  yin et al.  1  have used the output of static classifiers directly into hmms for speech reading application; however they do not compute the margin or class posterior probability of these classifiers  which can be more effective than the raw outputs  platt  1 .  
　for each activity  a new hmm model λi  figure 1 f   is learned using a sequence of examples rather than individual instances. we construct a new input feature space based on the posterior class probabilities  which is  
     p c |1 f 1    f =        
  p cn | f n    
 
　given a set of observations {f f 1  1  ... ft} for each activity  we learn the parameters of the hmm λi using the standard expectation-maximization  em  method. during testing  we have a continuous sequence s  which we use to compute the likelihood value lι t  for λi at time t using a sliding window of duration  t  figure 1 g   - 
	li  t  = p   f f t	t 1+  ... ft+ t | λi    s 
the final segmentation and classification is based on the 
hmm 	that 	has 	the 	highest 	likelihood 	value  
i.e.c  t  i = maxi li  t   figure 1 h  .  
accelerometer1%ambient light  ir-vis 1%audio1%barometric pressure1%digital compass1%hi-freq vis light1%ir light1%relative humidity1%temp. from barometer1%temp. from relative humidity1%visible light1%table 1: the percentage of features from the top 1 that originated from the different sensors  averaged across all activity classes. 
 
　alternatively  we could have trained the various states of a single hmm to recognize the different activity classes and to learn the transition characteristic between activities. we choose not to do that here as our activities are primitive and a single transition statistic is not very meaningful. however  we believe that the output of these hmms could be used to train a single dynamic model of more complex behavior where the transition statistics would also be more informative.  
1 experiments 
to validate our approach  we recorded 1 hours of data consisting of a large number of activities  such as sitting  walking  jogging  riding a bike  driving a car  etc.  using the wearable multi-sensor board.  the dataset was collected across multiple days  by two volunteers  who are not the researchers  in various indoor and outdoor locations.  the recordings were done in long stretches  one hour on average   where the duration of the activities themselves ranged from seconds  e.g. entering a building   to hours  e.g. driving a car . the volunteers were asked to go about performing a series of activities naturally without any specific constraints on the order  for example  go to building x and walk around inside . to capture day-to-day variations in the activities we collected multiple instances of the various activities over the course of six weeks. on average we have about an hour of data per activity and around 1 instances per activity.  
feature selection 
for the feature selection stage  we selected 1% of the total data available for each class for training. based on the training examples we derived a ranking ri for the features for each activity individually using the boosted decision stump procedure described in section 1. figure 1 shows the testing error as a function of the number of features used for classification. from the results we see that classification error tapers off at around τ =i 1 features for most classes. if we were to pick more features beyond the top 1 our performance only improves slightly with the testing error only improving  1% for 1 features. the practical advantage of features selection is that we can significantly reduce the computational burden on our resource constrained devices  without drastically affecting the 

figure 1: output of the static decision stumps classifiers  at 1hz   and the hmm classifiers  trained with output probabilities of the static classifiers  for a continuous 1 minute segment of the data. the results are overlaid on top of the ground truth which was obtained by annotating video recorded from a webcam worn by our volunteers. the video was only used for determining ground truth and not as an additional sensor input. 
 
performance. moreover  by performing boosting  reweighting the data and selecting discriminatory features successively based on the error   we perform much better than taking a non-boosted  no re-weighting  approach to selecting the best 1 features. the accuracy   true positive + true negative  /  total # of examples   for the boosted features selection was on average ~1% higher than the non-boosted method. table 1 lists the contribution of the different sensors to the final classifier. the majority of the top 1 features came from the accelerometer  audio and barometric pressure sensors. barometric pressure data was useful in distinguishing activities that involved floor transitions  e.g. walking up/down stairs  elevator up/down ; the sensor is sensitive enough to pick up pressure differences between a single floor. 
static classification results 
using the top 1 features we tested the performance of the ensemble classifier for two different weak classifiers -  i  decision stump  discriminative  and  ii  na ve bayes  generative . the total duration of our test dataset was five and a half hours. the decision stumps outperformed the na ve bayes classifiers by a large percentage. table 1 shows the precision  true positive/ true positive + false positive   and recall  true positive/ true positive + false negative   numbers for the 1 activities in the dataset using the ensemble of decision stumps. table 1 lists the average precision and recall numbers for the na ve bayes as well as decision stump classifiers.  
continuous classification results 
although the decision stumps results from table 1 are quite good on their own  figure 1 illustrates the classification errors encountered for a continuous trace. the majority of the trace tends to be correctly classified by the decision stumps; but  with some scattered misclassifications. the addition of the hmm layer on top of the static classifier helps to smooth these classification errors as shown by the line in figure 1.   
　the parameters of the hmms were trained using 1 example scenes  on average 1 minutes of scenes  for each class. each hmm had two hidden states and gaussian observation probabilities. classification was performed using a 1 second sliding window with 1 second overlap. table 1 shows the sliding window performance results for the hmm  using the posterior probabilities as inputs  tested with concatenated test scenes. the overall accuracy in this case was 1%. it is interesting to note that the points in figure 1 where the hmm and ground truth differ appear to be somewhat natural and realistic; for example  classifying a region without any ground truth between walking and sitting as standing. in fact  the hmm output reveals some deficiencies in the ground truth. for example  some segments whose ground truth was marked as walking are in fact standing  as determined by post-analysis of the video by the experimenters   and are correctly recognized as standing by the hmm. 
　to compare the performance to a more standard hmm approach  we trained a new set of hmms that used the top 1 raw features as inputs rather than the output of the static classifiers. the performance of these hmms was 

classified activity  by decision stumps sittingstandingwalkingjoggingwalking up stairswalking down 
stairsriding a bicycledriving carriding elevator 
downriding elevator upsitting1%1%1%1%1%1%1%1%1%1%standing1%1%1%1%1%1%1%1%1%walking1%1%1%1%1%1%1%1%1%1%jogging1%1%1%1%walking up stairs1%1%1%1%1%1%1%1%walking down stairs
riding a bicycle1%1%
1%1%
1%1%1%1%1%
1%1%driving car
riding elevator down1%
1%1%
1%1%1%
1%1%1%1% 1%1%
1%1% 1%riding elevator up1%1%1%1%1%1%1%sitting1%1%1%1%1%1%1%1%1%1%standing1%1%1% 1%1%1%1%1%1%walking1%1%1%1%1%1%1%1%1%1%jogging
walking up stairs1%
1% 
1%1%
1%1%
  
1%1% 1% 
1% 
1% 
  
1%walking down stairs 1%1%1%1%1%1% 1% riding a bicycle1%1%1%   1%   driving car1%1%1% 1% 1%1%1%1%riding elevator down1%1%  1%1% 1%1%1%	riding elevator up	1%	1%	1%	 	1%	 	 	1%	1%	1%
table 1: precision and recall numbers for the decision stumps classifier. a randomly selected 1% set of data was set aside and used for the test results here. overall accuracy is 1%. 


sitting1%1%1%   1%1%  standing1%1%1%       walking1%1%1% 1%1%    jogging   1%      walking up stairs    1%     walking down stairs  1%  1%    riding a bicycle 1%    1%   driving car
riding elevator down 
  
  
  
  
  
  
 1%
  
1% 
 riding elevator up         1%table 1: precision and recall numbers for the hmm classifier  using posterior probabilities as inputs. overall accuracy is 1%. 
na ve decisionhmm withhmm withbayesstumpsdecision stumpsraw featuresprecision1%1%1%1%recall1%1%1%1%table 1: overall precision and recall numbers for the various generative and discriminative classifiers  used in evaluating our system.   
significantly worse  even worse than the static classifier  demonstrating the importance of discriminative classifiers in distinguishing between activities  see table 1 for a comparison of the overall precision and recall numbers for the various classifiers used in our experiments . we recognize that the modeling of more complex activities may require a generative model of personal behavior. however  we believe that discriminative classifiers that map sensor data into primitive activity classes will reduce a large amount of the sensor noise and allow us to learn complex behaviors more effectively.  
1 conclusion 
the problem of recognizing human activities from sensor data presents diverse statistical challenges: different classes of actions need to be actively distinguished from each other; and a model needs to incorporate the fact that people's actions are extended over time. in the present study  we approached these problems by combining the discriminative power of an ensemble of decision stumps with the generative and temporal powers of hmms.  
　as our presented results have shown  the combination of discriminative and generative classifiers is more effective than either of the classifiers on their own. not only does the hmm on-top of the discriminative classifier perform better than the discriminative classifier on its own  but it also produces very smooth and accurate outputs as figure 1 shows.  
　feature selection plays an important role in our system not only in improving the performance of our classifier but also in creating a practical system. our selection of the best 1 features for our top classes leaves us with 1 features from our original 1. this reduces the number of features necessary by more than 1%  which is a significant computational saving. this savings could be further improved upon by optimizing the calculation of the features to take advantage of the new subset  for example there are efficient techniques to obtain fft coefficients only for required sub-bands  goertzel  1 . in addition  this subset could be further reduced by allowing the feature selection process to determine a more optimal stopping point. 
　thus  our work lays out several directions in which the automatic recognition of human actions can be pursued further. first  multi-modal wearable sensors provide a cheap  lightweight and unobtrusive means of obtaining richly detailed data in unconstrained environments  and over long periods of time. second  the very richness of such sensor readings  and the mass of data collected  demand that suitable preprocessing and data-reduction techniques be applied. we found that by selecting the most informative features  computational costs could be cut by more than 1%  although still greater savings are probably attainable. third  the multi-faceted nature of human activities presents opportunities for multiple machine-learning approaches to be combined  with the complementary strengths of different approaches  in this instance  boosted decision stumps and hmms  meeting different aspects of the computational challenge. our initial studies  presented here  have yielded high recognition rates  suggesting that this is a fruitful approach. our future work will focus on incorporating and building on the techniques presented here to recognize more complex behavior patterns  e.g. cooking  cleaning  etc.  further development of these ideas will  we hope  lead to activity recognition systems that can move from beyond the research lab out into the real world  offering applications in areas as diverse as smart rooms  ethnography  and health care for both the young and aging population. 
acknowledgments 
the authors would like to thank dieter fox for the helpful comments and discussions. we also thank the two undergraduate students who collected many hours of data that was used our experiments. 
