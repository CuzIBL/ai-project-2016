 
recently there has been much criticism in the ai community that knowledge based systems are not situated. we argue that trying to provide for situatedness in a conventional system will lead to the so called model explosion cycle and that for most application environments adaptivity is needed for situated behavior. cooperative systems are a solution to the model explosion cycle where adaptivity is delegated to the user. a hybrid symbolic/connectionist system offers self tuning capabilities  and therefore adaptivity  but can't cope with the model explosion cycle. integrating both approaches into a cooperative hybrid system leads to a much more situated behavior than conventional systems can achieve. our approach is illustrated using a real-life expert system in the domain of technical troubleshooting. ongoing practical tests indicate that a cooperative hybrid design presents an attractive architecture for knowledge based systems. 
1. introduction 
in the last few years the terms situated cognition and situatedness have been brought into the discussion about knowledge based systems  kbs . it is argued that conventional kbs are not situated in several ways. winograd and flores  state that these systems  in contrast to humans  lack the ability to cope with  breakdowns   that is situations where the usual  habitual  behavior is interrupted by an impasse. in these situations something which is otherwise  ready-to-hand  - unproblematic  transparent establishes itself as a problem which has to be dealt with in a novel way  for example the mechanical properties of a jammed screw . suchman  demonstrates how an expert system for a copier fails to support the users because it does not have access to all the situational factors  and because its models about user intentions and behavior are 
this research was sponsored by tecan ag  hombrechtikon  and by the swift ai chair of the free university of brussels. 
learning and knowledge acquisition 
much too limited. while access to situational factors might be improved by furnishing the system with more sensory data  the limitations of the kbs by its models are more principled: humans use models and plans just to orient themselves in a situation and explain their past behavior; at the most basic level  in its atomic actions  behavior is situational and not model or plan driven. models of human behavior therefore are always bound to be incomplete and error-prone. clancey  1a  argues that  the idea that humanlike intelligent behavior could be generated by interpreting stored programs that predescribe the world and ways of behaving must be abandoned  for this view confounds descriptions an observer might make with physical mechanisms inside the agent . he concludes that the designer of a kbs should move from engineering 
 knowledge structures  in an agent to designing a statesensory coupling of a system to its environment  clancey  1b . 
at first sight these issues may seem fairly theoretical. 
nevertheless we were forced to deal with each of them when building the ddt  device diagnostic tool  kbs for technical troubleshooting of a liquid handling robot1. a conventional approach doesn't work because it is based on the implicit assumption that the system can be designed and built by the knowledge engineer  who tries to anticipate all the potentially relevant situations. the main problem with this approach is that such anticipation is simply not possible. for example there are costs associated with tests or observations the user  technician  of the kbs has to make. looking whether the power cord is plugged in correctly is associated with much lower costs than testing the proper connections of an internal circuit board of the robot. but these costs can vary greatly from situation to situation. if the cover of the robot has already been removed by the technician in the process of trying to find the faulty component  the costs of the second test can be very low. 
this liquid handling robot is a complex  programmable and configurable device that is controlled by a pc. failures do not only include mechanical  electrical or electronic deficiencies  but as well failures that occur due to a false setup of programs  or use of false liquids or reagents. 
however  if the cover has to be removed first to make the observation  costs will be higher. furthermore the costs of the observation greatly depend on the skills of the user. therefore they cannot be assigned globally once and for all. in a traditional system this problem might be approached by developing a user model and a spatial model of the device. but even these detailed models do not allow the anticipation of situations like the following: the user does not have the appropriate tools available at the moment  e.g. he does not have a screw driver   he cannot remove a screw because it is jammed  and thus he cannot remove the cover   he cannot execute a basically easy test  e.g. the knowledge engineer has not anticipated that to test  if  contacts are ok   many factors may have to be considered  for example corrosions  oil on the contact points  the solder points of the contacts aren't ok  etc. . it is important to note that the additional non-anticipated complications caused by a specific situation are not irrelevant on the contrary  they can be crucial to the whole task. for example  if the user cannot determine whether the contacts are ok  an alternative and potentially much more costly solution path may have to be followed. generally speaking  however detailed the models  there will always be additional relevant factors which should be included: a phenomenon which we called the model explosion cycle. 
   moreover  there will always be a tradeoff between the benefits of a more detailed model and the computational and interactional costs of applying the model to a particular situation. in other words  even if the model is more detailed - it includes potentially very many situations - much effort will have to be expended in actually applying the model: the user will have to be asked many questions which might not make much sense to him in this situation  and there will be high computational costs associated with maintaining the model internally. sometimes things get even worse when the user requires additional expertise to answer these questions. in summary  every knowledge base in a sufficiently complex real world domain will always by necessity be incomplete. 
   but in most application environments it is not sufficient to escape the model explosion cycle in considering all the relevant factors because relevancy itself is changing due to changes in the environment. for example in the domain of technical troubleshooting the following changes may occur: the devices to be diagnosed and repaired are redesigned; there are different configurations of the devices; the operators of these devices show different behavior  e.g. some are more careful than others   which leads to different types of failures; the users of the expert system have different skills  etc. thus  these kbs have to be adapted continually to maintain a situated behavior. by adaptation we understand the proper coupling of a system to its environment including the user  this matches clancey's  1b  request . if a system is able to adapt itself  it is called adaptive  that is  it has an inherent adaptivity. 
   hence  situatedness of a kbs means  that it has access to all the relevant information of a situation and is able to react appropriately in novel situations due to experience with similar situations. learning and performance cannot be separated in a situated system. 
1. our own approach 
our approach to build a situated kbs resulted in a cooperative hybrid system. we will briefly introduce the notion of cooperative systems on the one hand and hybrid systems on the other and then motivate our approach. in cooperative systems several actors contribute to a problem solution. each of this actors is capable of sophisticated problem solving on its own  but the solution to the complete problem cannot be achieved without cooperation. all the tasks to be performed to solve a specific problem are allocated to the individual agents in a cooperative system. these agents are either computer systems or humans  that is users. in this paper the focus will be on joint humancomputer systems. 
   most cooperative systems will be hybrid in the sense that they contain components of different types. the term hybrid has been used for systems that include analog and digital components  for kbs that include rules  frames  and constraints  or for systems including a traditional kbs and a neural network part. we will focus on the last. more concretely  a system will be described in which the neural network learns some tasks from the user  which require situation specific knowledge. in other words  in this system the neural network picks up parts of the task that were originally entirely delegated to the user. in the past few years many hybrid systems have been proposed. a number of them are briefly reviewed in gutknecht and pfeifer . 
   in the introduction we mentioned that kbs  in order to be situated  should include all the relevant situational knowledge without running into the model explosion cycle and provide for adaptivity. to escape the model explosion cycle the system must be cooperative. only the user of the system has access to the relevant information since he is present in the real-world problem solving situation  winograd and flores  1; suchman  1 . to take our example of the jammed screw  it is unnecessary to have a complete model of the fact that potentially all screws might be jammed and what should be done if this is the case. this is only considered if it actually arises. for this purpose the user is needed. although much of the knowledge needed is related to common sense - which is assumed to be present in all users - specific skills are also required. if the user has dealt with jammed screws in other situations he will be better able to cope with it. so  there is a high dependence of the joint human-computer system on the level of experience of the user. less skilled users should be able to benefit from the expertise of more skilled ones  but as we showed  this cannot be achieved by standard knowledge acquisition techniques only . 
   now  how can we provide less skilled users with access to the expertise of more skilled ones without running into the model explosion cycle again  our solution is to have the system pick up the control strategies of experienced users  since control - choosing the optimal thing to do next - is at the very heart of every kind of expertise. to do this  a list of hypotheses to pursue and tests that might be performed are presented on the screen from which the - preferably experienced - user can choose. these selections arc recorded and used for training a neural network. this way the network eventually picks up the strategy of the user. we use neural 

networks for convenience  because of their power to build correlations. this inclusion of a neural network leads to a hybrid system. 
   another possibility would be to simply ask the user why he is preferring a particular alternative to another. this would represent an efficient knowledge acquisition procedure which is  in fact  applied in quite a number of projects that we are aware of. however  this approach can lead to the problem of the user getting annoyed by too many questions  and the difficulty of making implicit knowledge explicit. as is known from the knowledge acquisition literature  such explanations are prone to be  post hoc rationalizations   nisbett&wilson  1 . by simply learning the choice of the user both of these problems can be avoided. in our approach the recorded selections may show that the user chooses different alternatives in the same situation. in this case  we can look for the hidden piece of information the user is apparently implicitly using. the knowledge engineer may then decide whether the discriminating knowledge should be introduced in the knowledge base or not. this provides us with an incremental knowledge acquisition procedure: we are using information about cases which have actually occurred  but we are not misled by potentially irrelevant cases and by rationalizations. 
   in adapting to the  adaptive  behavior of skilled users the system also implicitely tunes itself to changes in the environment. if due to some consistent error   e.g. the cover screws being jammed frequently   there is a design change   e.g. a different way of fixing the cover   the errors due to jammed screws will no longer occur  the users will change their behavior and the system will adapt to the changed design without direct intervention of a knowledge engineer. 
1. system description 
an overview of the system architecture of ddt  device 
diagnostic tool  is shown in figure 1. we will describe it in two parts. in the first part each component of the architecture will be introduced and in the second part the tasks relating the components to each other will be explained. 
1 	components 
in figure 1 there are two types of components: humans  head-symbols  and artifacts  boxes . the human components of the system are the user  the expert and the knowledge engineer. the user is the person who selects the best failure hypothesis from the interface  chooses and executes tests that discriminate between competing  failure  hypotheses and updates the list of current findings  see below . 
he is also the component most sensitive to the environment. the expert is the person responsible for the adaptation of the knowledge base  i.e. maintenance and extension . he sometimes assumes the role of the user. in this role he  produces  high quality cases for the case base  see below  to teach the hybrid system. the knowledge engineer is the person who designs the system. this includes the assignment of tasks to humans and artifacts. the knowledge engineer is in fact both  part of the system itself  where maintenance is concerned   and outside of it  as its designer  clancey  1a&b . her responsibilities include the knowledge acquisition up to the point where the system is maintainable by the expert. 


figure 1: architecture and embedding of the cooperative hybrid system. boxes represent components  arrows tasks relating the components to each other.  see text for further details.  
learning and knowledge acquisition 

   the artifacts in the system are the knowledge base  the neural networks  the case bases  and the user interface. the knowledge base  kb  stores the knowledge in a structured form and makes it available to the inference mechanisms and - for maintenance purposes - to the expert and the knowledge engineer. the diagnostic knowledge is divided into failures  observations  and relations between them. the neural networks  nn  are three layer feedforward nets that learn the focusing interactions from skilled users and are able to give hints to less skilled ones due to this knowledge. there are two nns in the system. one nn is trained on the users' selection of hypotheses  given the set of current findings  the other is trained on the users' selections of tests  or new observations   given the set of hypotheses which are currently in his focus. these selections which reflect the users' focusing actions are recorded in the case bases. 
   the user interface is supporting the user in solving his tasks by displaying relevant information. this information is extracted from the kb and the nns. but the user interface is also responsible for recording the user interactions  selections of hypotheses/observations/tests and updates of findings  in the appropriate case base. the user interface consists of windows and buttons to manipulate the information shown in the windows. one window is the observation window  where general symptoms or tests relevant to the current situation are displayed. in another window  the hypothesis window  failure hypotheses are displayed. in front of each hypothesis there is an evaluation part with the kb rating for this hypothesis and the nn rating. 
1 tasks 
in figure 1 the basic tasks are shown as arrows. the system has to perform two main types of tasks  namely consultation and modification tasks. three task loops can be identified: a consultation loop and two modification loops. in the following  the loop of consultation tasks is described as it is performed after the addition of some new findings to the set of current findings. the loop starts  when the user enters a set of initial findings. first the find&rate-hy-
potheses task will be performed. the result of this task is a set of rated hypotheses related to the set of current findings. the task can be performed by two problem solving methods. 
either the relations between findings and hypotheses in the kb are evaluated  or the nn which maps findings to hypotheses is consulted. in both cases the result is a rated set of hypotheses.  in contrast to the suggestions of the nn  which depend on previous cases and are therefore not complete  the kb always finds all valid hypotheses due to its observation-failure-relations.  then the presenthypotheses task filters and groups the set of rated hypotheses before presenting them to the user  filtering means either showing the highest rated kb proposals or those nn suggestions  which are valid and have a high rating . knowledge about groups of hypotheses is used for this task. 
the select-best-hypotheses task is performed by the user. he selects on the display the hypotheses he wants to focus upon  or marks the irrelevant hypotheses. this may involve changes of the hypotheses display  e.g. switching between kb and nn hypotheses . after the user has chosen a set of interesting hypotheses  this set is used by the find&rate-tests task to find a set of rated tests. again  there are two problem solving methods for this task. either the relations between hypotheses and tests in the kb are evaluated  or the nn which maps hypotheses to tests is consulted  cf.find-andrate-hypotheses . as for the hypotheses  a present-tests task groups the set of rated tests  before they are presented to the user  cf. present-hypotheses . knowledge about groups of tests is used for this task. then the user performs the selectbest-actions task by selecting appropriate repairs or tests to discriminate between the interesting hypotheses. he executes the selected repairs or tests and evaluates the results  execute&evaluate-actions task . afterwards he updates the set of findings on the interface accordingly  update-current-
findings task . the consultation ends when all symptoms have been removed. 
   modification tasks are performed in two loops: an automatic loop which tunes the system to the user and the environment  and a manual one that is performed by the knowledge engineer and the expert who adapt the kb based on their evaluation of the system performance. in the automatic loop the record-case task of the interface keeps track of the user's selections of tests or hypotheses and records them in two case bases. during the modify-network task the case bases are used to train the appropriate nn with the backpropagation learning algorithm  rumelhart el al.  1 . because this task requires a lot of time and system resources  it will typically be performed overnight when the kbs is not being used. the manual loop starts with the evaluation of observations about unsuccessful consultations by the expert and the knowledge engineer  evaluate-systemperformance task . these observations can either be made directly by users of the system or indirectly by analyzing the cases recorded in the case bases. based on this analysis they modify the kb {modify-knowledge-base task . 
1 a sample session: adaptation and knowledge acquisition 
we will show how the self tuning mechanism of the system leads to an adaptive behavior  and we will point out how specific characteristics of the system performance can be evaluated and used for knowledge acquisition. 
   the case presented here is a reproduction of a session of one of our experts with the system. this session was recorded in the case bases together with about four others of the same day. the case base with the data from the hypotheses selection task has been used afterwards to train the nn  which learns to focus on hypotheses. after 1 training passes through this case base  we replayed one of the five sessions to assess the quality of the now self tuned system. the results of the first five steps of this session are shown in table 1. in the leftmost column the step number together with the newly added finding is shown. in the next three columns  the hypotheses focused on by the expert and the corresponding suggestions of the nn and the kb are shown. the nn and the kb proposals appear with their associated ratings. for the nn this figure is the scaled activation level of the output node representing this proposal. only proposals with a rating above 1 are shown. for the kb this rating is computed from the number of findings related to this hypothesis and an apriori assessment of its frequency which is also stored in the kb. only the proposals with the highest ratings are shown. 


table 1: the first five steps of a session after the nn has been trained on several sessions. the leftmost column shows the number of the step together with the new finding. the next columns show the hypotheses the expert is focusing on  the suggestions of the nn together with their rating  and the top rated suggestions of the kb with their rating. 

   in the first step the nn suggests a focus which is too broad. beside the two hypotheses the expert has focused on  the nn suggests seven more hypotheses. this can be either due to a poor generalization on the part of the nn or to inconsistencies in the case base stemming from inconsistent behavior on the part of the users. inconsistent behavior can have two reasons: either the users were selecting different hypotheses/tests in the same situation due to their individual preferences and experiences or some relevant piece of discriminating information about these situations is missing in the system. in the first case  the cause of the individual preferences and experiences of different users could be found in peculiarities of their local environment  e.g. in some countries failures of a device due to insufficient maintenance are more frequent than in others  which would suggest that alternatively tuned system components  kb and/or nn  should be used. the second case is interesting  because it points out deficiencies of the kb itself. the kb must be modified to include some new hypotheses or observations  incremental knowledge acquisition . in our case the expert made a trial session with the system where he used the same initial finding  but chose a very broad focus. this session had been recorded into the case base too and was the reason that the system had been trained with this broad focus. the kb proposes only one of the two hypotheses of the expert. 
the other got a lower rating than the proposed one and is therefore not shown. 
   in the second step the expert includes three more hypotheses into his focus. the nn suggests the same hy-
learning and knowledge acquisition 
potheses as the expert except one   dispense speed too fast   which in fact had been proposed  but with a rating below 1 . it is interesting to note that the expert's hypotheses had already been proposed by the nn in step 1 with a significantly higher activity level than the rest. this can be explained as follows: when a hypothesis is part of the focus over several selection steps  it will be trained several times together with the initial findings. this means that strong connections will be built up between this finding and the hypothesis  reflecting the high correlation between them . when this finding is present in a consultation using the trained nn  the strongly correlated hypotheses will get a lot of activation from it leading to a high rating. the top rated suggestion of the kb was also part of the expert's focus. 
   in the third step the expert made a test which discriminated between the hypotheses in his focus. the nn and the kb both make a correct suggestion. 
   in the fourth step the observation that the liquid had a high viscosity made the expert eliminate both hypotheses remaining in his focus and switch to a totally new hypothesis. this focusing switch had also been learnt correctly by the nn whereas the top rated suggestion of the kb was not useful in this case. 
   in the fifth step the expert again broadened his focus and even reconsidered a hypothesis he had focused on before. the nn suggested all three hypotheses correctly. as before  the highest rated nn suggestion was considered the most likely one by the expert. the kb suggestion was part of the expert's focus  too. 

1. discussion and further work 
initially we stated  that if we want to build a situated kbs  it should meet the following requirements: it should include relevant situational factors without running into the model explosion cycle  and it should be adaptive to its environment we argued  that traditional kbs technology cannot appropriately fulfill these requirements  while the proposed approach based on cooperativity and tunability can. 
   cooperativity: cooperativity was shown to be a way to cope with the problem of the model explosion cycle. in our system cooperativity has been realized through a task distribution  which was developed in close collaboration with a domain expert  who has worked with us on the development of the system for more than a year. the nn part was only introduced recently  see below . it seems that the experts feel comfortable with this cooperative approach. one of our experts is a strong supporter of this technology in the company and sees a great potential for further applications. a preliminary evaluation was so successful  that the system has been introduced this spring into a productive environment. but extensive and systematic evaluations of experiences in various productive environments will have to be conducted to make a final assessment. 
   tunability : the need for having an incrementally tunable system is given by a changing environment which includes the skill levels of different users. our incrementally trained nn's can track the changes in the environment and represent a means for making skills of experienced experts available to less skilled ones. they function as a kind of associative case-base of previous user-system interactions. this setting allows the system to adjust itself to a certain extent to its environment since this was the most recent addition  there are no extensive tests available yet however  preliminary evaluations by one of the experts have been very positive. he clearly stated that the selection tasks present real problems for less skilled users and that having useful hints on an appropriate subset of hypotheses or tests for focusing would be of great advantage. he was also enthusiastic about the idea of tuning systems to different countries  the company distributes these robots world-wide  and to different user groups  e.g. to sales personnel  technicians  or operators . of course one has to be careful to train the nn with experienced users only. 
   independent statistical tests  with simulated cases  were performed to assess the capabilities of the nn. they clearly show the nn's capabilities to generalize to cases they were not trained on: the nn which learns the hypotheses selection task had been trained overnight on a case base of 1 cases1. after 1 epochs of training with the standard backpropagation algorithm the nn could reproduce 1 
 1%  cases of the training set correctly. tested on a set of 1 new cases it was able to solve 1  1% . this is a good result  considering the fact that in our application the interface filters out all nn suggestions that are not part of 
the net was a three layer net with 1 input nodes  findings   1 hidden nodes and 1 output nodes  hypotheses . we used a learning rate of 1 and a momentum value of 1. the weights were changed after each pattern presentation. 
the kb suggestions  i.e. what is shown on the interface is the intersection of the nn suggestions with all kb suggestions . in other words: if the user is solving a problem that has occurred previously  he can focus properly with the help of the nn in 1% of the cases; if it is a new problem  he will be better off  compared to a system which doesn't tune itself  in 1% of all the cases. but even in the remaining 1% of the cases he won't pursue any wrong hypotheses  he will just focus on hypotheses which will lead to a less optimal solution  but nevertheless a correct one . 
   the initial experiments have been encouraging. thus  it seems sensible to do further work in this direction. one task will be to analyze  how the optimal balance between design knowledge  acquired via traditional knowledge acquisition methods  and situation specific knowledge  acquired via adaptive mechanisms  can be found. moreover  it has to be investigated what the impact of this point of view is on knowledge engineering. we suppose  for example  that it may not be desirable to develop enormous libraries of problem solving methods but that more time and effort should be spent on studying experts and users in how they interact with their social and physical environments  and how the introduction of knowledge systems changes their work. these insights will in turn  feed back  into the design of better knowledge systems as discussed in this paper. 
acknowledgements 
we would like to thank b. aiken  d. allemang  t. 
bratschi  and t. wehrle for their helpful comments. 
