 
we argue for  hyper -logicism  the view  hitherto unarticulated  that ai can succeed in creating a genuine robot agent by building a symbol system of the appropriate sort which has no sub-symbolic interaction whatsoever with the external world. 
1 introduction 
a rather unfriendly debate continues to rage in ai between the  logicists  and the  connectionists.   hereafter  the 'cl' debate.  many connectionists  e.g.   smolensky 1   
 churchland et al. 1    waltz 1    schwartz 1    kaplan weaver et al. 1   hold that their  brain-like  architectures ought to supplant or at least supplement the symbol-based ones of traditional logicist ai. on the other hand  many logicists  e.g.  fodor and pylyshyn 1   hold that any successful ai model of human cognition  and a fortiori any sentient artificial intelligence itself  must use classical  logic-driven architecture. 
　in this paper we argue for  hyper -logicism  the most extreme form of logicism - an approach to ai hitherto unarticulated  let alone defended. in a word  hyper-logicism is the view that ai can succeed in creating a genuine robot agent by building a symbol system of the appropriate sort which has no sub-symbolic interaction whatsoever with the  external  world. what is pictured here is thus apparently a 
　symbol system that has no need for processing and representation schemes near and dear to the heart of connectionists. 
　two assumptions underlie the coming argumentation  and are worth setting out before we embark. 
　we assume  first  that the sort of ai with which we are concerned  whether it be connectionist or logicist or hybrid in spirit  is  at bottom  aggressive. someone who views ai as nothing more than the attempt to do things like model computationally the olfactory component of rat brains will find the debate with which we are concerned to be otiose. on the other hand  if one has a sanguine  rounded view of ai  our treatment should be of interest. such a view of ai  from our perspective  is two-fold in nature  namely that ats engineering side is reflected by the aim of building a genuine artificial intelligence  = a mind  person  or agent - not necessarily of the human variety   
1 	philosophical foundations 
while it's scientific side is reflected by the fact that reaching the engineering objective requires a thorough understanding of mentality itself. 
　our second assumption is simply that readers of what is to come are to an appreciable degree familiar with the concepts central to the debate in question. we assume here  in particular  that readers have a background  on the connectionist side  largely derivable from volume i of pdp  rumelhart and mcclelland 1   that is that they have assimilated neural net concepts like input  output and hidden units  activation  values  weights  training with back propagation  and so-called recurrent nets. on the logicist side  we assume readers to be at least comfortable with n-order extensional logics  timid to full-blown intensional logics  and traditional symbolic projects in ai employing fragments of these symbolic schemes. furthermore we assume that the reader in in command of the basic concepts and proofs of elementary computability theory  e.g.  finite state automata  turing machines  k-tape turing machines  cellular automata  and simulation proofs 
 e.g.  of the fact that a k-tape turing machine is no more powerful than a standard one  that a cellular automaton can be viewed as just a k-tape turing machine  and that a neural net can be recast as  among other things  a probabilistic cellular automaton. we would  in addition  like to assume that readers are familiar with analog devices  but this is perhaps unreasonable  since not only are physical analog computers in short supply  but also there is no satisfactory logico-mathematical or philosophic definition of 'x is an analog computer.' 
　it would be nice if readers had a formal understanding of symbol systems  sufficient  say  to assimilate lindstroms first and second theorems - see chapter xii of 
 ebbinghaus  flum et al. 1    but command of an informal account of the sort given by  harnad 1  suffices. formally speaking  hamad's account of a symbol system is erected by simply building on  and then generalizing from  the basic machinery of first-order logic  which  as is well-known  has both a  derivation  side  and a  meaning  side. that is  a symbol system is simply a generalization from  and perhaps if need be a refinement of  a first-order understanding of the familiar v and 'k' one generalizes from a first-order scheme by allowing symbol strings to be arbitrarily coded - as marks on paper  micro-

events in a digital computer or brain  etc  and also by stipulating that derivations are based  to use  harnad 1 's term  merely on the shape of symbol strings. 
1 strong logicism and connectionism 
the classic account of strong logicism is given by  fodor and pylyshyn 1   who argue that connectionism may provide theories of the implementation of cognition  but not theories of psychology  i.e.  not theories of what is apparently  emphasis to preclude begging any questions  symbolic in nature - things for example like the ability of a human person to produce/understand a sentence s if there is another related sentence 1' which this person produces/understands.  e.g.  set s = 'john loves mary ' set s' = 'mary loves john.1  
　strong logicism apparently includes the view that symbol systems will meet connectionist processing when these systems are  hooked up  to the external world. the view here is that connectionist work can proceed on its own  separate from logicist research  and then down the road  when the logicist wants to have her robot agent interact with the physical world  the fruit of connectionist research can be applied. strong logicists  for example  fodor 1  1  have thus typically espoused such slogans as that 'their symbol system must be connected to the world in the right way/ they thus embrace a view of robot agents possessed of nonsymbolic  transducers  which would allow symbolic processing at the heart of the robot agent's psychological attitudes to affect the robot's outside  physical  nonsymbolic environment  and vice versa. it is only the hyper-logicist who jettisons such transducers - as we shall see below. 
　at any rate  the fodorian argument seems to us to be unsuccessful  for the simple reason that  pointed out to a large degree by  garson 1   recent advances on the connectionist front  c.f.  servan-schreiber  clceremans et al. 1    elman 1    kaplan  weaver el al. 1   have resulted in systems that model the abilities thought by fodor and company to be symbolic in nature. this development would seem to be thoroughly unsurprising  because it would seem to be just what the formal results ensure. if one puts no artificial limit on type or complexity of a neural net  then you quickly have the | i recursive functions available  and therefore you have turing computability. and the converse holds also: for every turing machine you can be sure there is a neural net that matches it the mathematics of the situation  specifically the ultimate equivalence of neural nets and turing machines  would seem to doom forever the fodorian tack. we should before long have connectionist systems on the scene that are very good at handling those aspects of human language fodorians hold to be the special province of logicist approaches. this is because  in a genuine sense  neural nets are just turing machines. 
　the point here is based on the locution 'automaton x is just automaton y ' which may be used to encapsulate such facts as that cellular automata arc just it-tape turing machines  or that register machines  for an intro sec  ebbinghaus  flum et al. 1   are equivalent to turing machines. the idea here is that  ultimately  from the mathematical point of view  x and y  in the locution being considered  are the same creature: you could in principle specify both by the exact same set theoretic definition  starting from and never leaving the machinery of  say  zfc. 
　this may look like an obvious point  but recent work on the c-l debate flies in its face  since even those who explicitly consider the point seem to go to considerable lengths to dodge it. here  for example  is what  harnad  1  has recently said on the matter: 
there is some misunderstanding of  the  fact  that neural nets fail to meet certain necessary conditions for a symbol system  because it is often conflated with a mere implementational issue: connectionist networks can be simulated using symbol systems  and symbol systems can be implemented using a connectionist architecture  but that is independent of the question of what each can do qua symbol system or connectionist network  respectively. by way of analogy  silicon can be used to build a computer  and a computer can simulate the properties of silicon  but the functional properties of silicon are not those of computation  and the functional properties of computation are not those of silicon. 
　a proper analysis of this rather cryptic quote would require clarification of nothing less than the notions of functional properties  analogical arguments  and simulations. such clarification is an impossibly tall order  certainly given our space limitations. and yet it is easy to motivate such clarification: what are the functional properties of pencils  of pencils if some race who shun writing find them and use them to spin frisbees upon  fortunately  such questions need not detain us. we think it can rather easily be seen that harnad cannot be construed as here threatening the locution under scrutiny: suppose that we have an operator  which when applied to a standard   user friendly  specification of an automaton or neural net  yields an account expressible exclusively in zfc. then we are relying on the proposition that 
for every neural net n  there is a turing machine m such that  
we take it  furthermore  that for every x and y  if x = y  then x and y have precisely the same functional properties. new york's tallest building has the same functional properties  no matter what such properties amount to  as the world trade center. this follows from leibniz' law. 
　so it looks like the fodorian case  indeed any case which involves a claim about the  qualitative  differences between neural nets and conventional automata  is misguided. but we can nonetheless get appreciably clearer about what strong logicism is. here  in fact  is a stab at doing so: strong logicism  minimally  seems to us to include the following two propositions: 
  p e r t u r 	persons are turing machines. 
bringsjord and zenzen 

 if a robotic person s is to be eventually produced by logicist alniks  then s must be such that some of the propositions  ... which are objects of s's occurrent deliberations  and hopes  fears  etc.  are represented by formulas   of some symbol system where they 
can be processed according to the reasoning mechanism that is part of  
　the identification of strong logicism with  minimally  these two theses is not something pulled out of thin air.  reflects not only the strong logicist's view that she is ultimately aiming at the creation of a true agent  but also the view that this agent would be  at bottom  a classical  or symbolic  automaton. one can say that a 
　classical automaton is a symbolic automata  because every classical automaton is identical to an axiom system within some symbol system. this fact is what allows the proof of the undecidability of first-order logic to capitalize on the halting problem.  on the other hand  reflects the logicist tenet  cf.  fodor 1  1    fodor & pylyshyn 1   that symbol strings of a symbol system  in this case the imaginary capture what mental phenomena such as thoughts and beliefs arc. the view here is that there is a level of thought  the  mental  level  with ruleful regularities that are independent of their specific physical realizations. 
　we see these propositions as necessary  not sufficient  for strong logicism. one of the missing propositions might be a general thesis stating what  theory of mind  is operative in strong logicism. one candidate found in the literature for a theory of mind closely allied with traditional logicist ai is called ai-functionalism' by  rey 1 . viewed in the  flow chart  terms of  dennett 1   aifunctionalism says  intuitively  that if you find a flow chart match between human brains and silicon-based martian brains  then you can be assured that the human person and the martian enjoy the same mentality. 
　our characterization of strong logicism provides a springboard for describing hyper-logicism  and to it we now turn. 
1 hyper-logicism 
what  given the foregoing  is hyper-logicism  since  as far as we know  no one has explicitly articulated or championed this view in the literature  this question cannot be answered by simply thumbing through the appropriate paper or book. we nonetheless think we have some ideas about what hyper-logicism is about. specifically  it is for us the view which embraces at least the following three propositions: 
	persons are turing machines. 
 al can produce a robotic person s such that all of the propositions  which are objects of s's deliberations  and hopes  fears  
1 	philosophical foundations 
etc.  are represented by formulas ... of some symbol system where they can be processed according to the reasoning mechanism of  
cno-sufi  ai can produce a robotic person none of whose 	mental 	processing 	involves subsymbolic encodings not representable in 

　in the following three sections  as promised  we will defend these theses. 
1 agents as classical automata 
to argue directly for  would mean  among other things  confronting head-on questions about the ability of human persons to exceed the algorithmic. indeed  a cogent case for  would of necessity be a long  sustained essay in the philosophy of mind. fortunately  we can dodge the burden: there is no reason why we must take on the onus of proving . this is so because one of the assumptions behind the c-l debate is that agents just are to be understood in computational terms. the issue  in the present context  is which terms. after all  the strong logicist is also saddled with having to defend and the strong conncctionist may face the challenge of having to show that persons are neural nets. 
　let us make an enabling assumption: that despite our above objections to the fodorian argument for strong logicism  there is a substantive difference between on the one hand a thesis claiming that persons arc turing machines  and on the other that they arc  say  neural nets. then we can ask a question which gives rise naturally to the onus we should be under in the present section: how might differences between turing machines and neural nets end up supporting conncctionists  well  perhaps the connectionist would try to capitalize on the fact that neural nets are analog devices. the conncctionist might say that though neural nets and cellular automata and k-tapc turing machines are one and the same when considered through the lens of operators like  when these automata arc genuine physical entities in the physical world they arc quite different; and their differences could be  from the standpoint of generating mentality  significant. 
　yet this is a remarkable position. in order to see this  consider the following situation. suppose that we have a physical neural net  call it that computes a set of functions  and suppose that has been built out of stuff available in the physical world to connectionists. suppose that this neural net is very complex  closer by far to real human brains than to standard textbook diagrams of multi-layer nets. and now suppose that  using as a 
　sort of blueprint  we build a turing machine that computes all of  if we had the time  we could specify how  is to be built from  for example  suppose  
is a 1 layer neural net  and that input  neurons  are 1 in number; then we might want to build  as a 1-tape machine  with 1 squares of the first tape used to hold the input that goes into n*. and so on. 
　now. here is the crucial question: is it plausible to hold that while the immaterial set-theoretic versions of n* and m* amount to the same thing  i.e. that   n*   =   m    the physical versions don't  that the net and the turing machine here don't give rise to the same mental states  if in fact there are any in the picture   it may seem at first glance that there is no rationale supporting an affirmative answer to these questions. but this would be to move too quickly; it would be to ignore the importance the connectionist is placing on the physical. for this view might very well include 
 ana.  a true analog  neural net can compute things which no turing machine can. 
and thereby imply a rejection  = the falsity  of 
 ctt*  whatever can be accomplished by a computing machine of any sort  can be accomplished by a suitably programmed turing machine. 
and rejecting  ctt*  allows one to hold that while our physical net n* from above computes r  there is no physical turing machine that can compute t; and if there can be no such turing machine  then our little thoughtexperiment involving n* and a/* is all for naught. so in this response the connectionist affirms ai-functionalism  but also embraces a positive thesis about what sort of physical stuff is of paramount importance - stuff that can't be matched  functionally speaking  by any turing machine. 
　have we arrived  then  at a solid rationale for refusing to accept  pertur   
　well  if nothing else  this version appears to reflect the current situation. as of 1  nearly all neural networks arc implemented on general purpose parallel computers - computers whose power is specified  mathematically  by cellular automata. cellular automata  as we have noted  when viewed from the perspective of the foundations of mathematics  are exactly equal in power to turing machines. hence as of 1 neural computers can be viewed as turing machines  and it follows that today whatever can be done by a neural net can be done by an ordinary turing machine. but in light of this result our connectionist calmly proclaims that hardware is allimportant in reaching ai's ultimate goals  not solely in the sense of moving toward  brainlike  architectures; but hardware is all-important for the simple reason that wc don't really have a neural net as long as we are forced to implement it on a programmable  general purpose machine. we will have a true neural net  the strong connectionist continues  when and only when we implement a neural net which is isomorphic to that underlying the human brain on a true analog machine. 
　what are we to make of the position that the connectionist is now occupying  we are inclined to view the situation here as calling for a big application of modus tollens. that is  since we affirm both  ctt*   and since the present version of connectionism entails the negation of this proposition  we think that this version of connectionism is simply false. 
　now we haven't the time to consider arguments for and against  ctt* . it is at the very least inductively confirmed by the fact that researchers have never found a computing machine  whether analog or not  that is qualitatively superior to a turing machine. and while in principle a counter-example to  ctt*  is possible  no one takes this prospect seriously. there is also the fact  only recently noted by  mendelson 1   that the churchturing thesis and its relatives may  in a sense in use in mathematics  be provable. 
　but might there be other formidable reasons for an ainik to resist  per t u r    perhaps. one might say that neural nets  while  qualitatively  equivalent to turing machines via '      ' are nonetheless superior to turing machines  quantitatively.  this amounts to saying that neural nets are  in terms of complexity  superior to turing machines  when the problems in question are those crucially involved in thought at the heart of  agenthood.  this is a vague stance  which nets are competing with which turing machines  ...   but one worth taking seriously in the present context. can it succeed against the hyper-logicist  we don't think so. here's why. 
　there now seems to be reason to think that conventional automata  suitably realized  could be phenomenally powerful complexity-wise. we are referring to aspects of what are being called  quantum computers   cf.  lockwood 1    penrose 1  . while the physics behind these devices involves the difficult and  to many  puzzling field of quantum mechanics  and while most of those who discuss quantum computers appear to affirm the highly speculative thesis that the brain is a quantum computer  it does seem that the purely mathematical specification of a quantum computer is unexceptionable. whatever else one might say about quantum mechanics  it is surely the case that the mathematical techniques employed within it arc above reproach. a quantum computer  in exclusively formal terms  severed from picturesque claims about how the brain might be one  does appear to be a genuine generalization of standard turing machines. it appears that  for certain problems pi that cannect be encoded as functions  turing machines cannot solve pi in polynomial time proper  whereas quantum computers can  cf.  lockwood 1  . the basic idea behind quantum computers - let us call them q-machincs - is that they are as individuals  groups  of conventional turing machines whose internal states and tape states can be superpositions of these turing machines. 
　wc are not claiming here that g-roachines can be built; nor are we claiming that the brain is a q-mahinc. our point is only that  for all we know at the present time about what robot agents must be like  it is permissible to interpret  per t u r   as referring not to turing machines  and not to q-midlines  but to what might be called 
 generic classical machines   where these automata could be 
turing machines  q-machines  or some other exotic 
bringsjord and zenzen 
variation on the classical theme. this moves seems to us to take the wind out of the connectionist's sails  since there would seem to be little a priori reason to be sanguine about neural nets over and above classical automata for reasons pertaining to complexity. 
　at any rate  what is distinctive about hyper-logicism are and  no-sub   to which we now turn. 
1 the lesson of the parallel postulate 
the central claim of this section is that consideration of the lesson physics has taught us by way of alternative geometries provides significant reason for embracing 
 perhaps the quickest way to sec this is to begin by considering arguments that would typically be brought against this thesis. such arguments  kaplan weaver et al. 1  almost invariably appeal to the claim  allegedly established by certain psychological experiments  cf.  nisbett and ross 1    kahneman & tversky 1   margolis 1    that human persons hardly ever use logic to reason  and that when they are given problems which require the use of logic  subjects use it egregiously. we have have doubts about the validity of these experiments as evidence against the thesis that human persons competently employ logic. nonetheless we are willing for the sake of argument to concede that these experiments have the implications many connectionists claim they have. what we would like to suggest  however  is that these connectionist claims reflect the same sort of parochial attitude that used to exist about non-euclidean geometries. let us explain. 
　we begin with a compressed timeline from euclidean geometry to physical geometry: there was uneasiness about the fifth  or parallel  postulate  pp  for at least 1 years  during which time there were sporadic attempts to deduce it from the other four postulates. in 1  saccheri constructs an indirect proof by denying pp  which yields two routes   no parallels   and  many parallels.  the first case is inconsistent with the other four postulates  but the second is not. saccheri discovers a non-euclidean geometry but convinces himself that such a thing is absurd and contradictory. around 1 gauss demonstrates to his own satisfaction the possibility of many-parallels non-euclidean geometry  but doesn't publish the result. in 1 bolyai and lobachevski independently publish a many-parallels geometry. in 1 riemann works out a no-parallels geometry  as well as a generalized geometry which has euclidean  one parallel   bolyai-labachevski  many parallels  and riemannian  no parallels  as special cases. in 1 einstein's special theory of relativity connects measurements of space  time  and motion with light signals and revolutionizes the concepts of space and time in physics. in 1 einstein's general theory of relativity gives a theory of gravitation which equates gravity with the structure of space-time. they theory makes use of generalized four-dimensional riemannian geometry and shows how the local euclidean character of space is a consequence of scale. the overall structure of the universe is non-euclidean  a finite but unbounded four-dimensional manifold. 
1 	philosophical foundations 
wc are claiming that there are lessons here which may 
 partially  anyway  adjudicate the c-l debate in favor of hyper-logicism. in order to see this  suppose first that  mindspace  is thought of in terms of physical space. ordinary interaction with physical space  given that this interaction is neither with the very small nor with the very large  suggests a classical newtonian conception - one that is useful for sending rockets to the moon  but one which is not universally true. perhaps what we see of mindspace is similarly restricted. perhaps there are ways of thinking that differ substantially from our ways. perhaps  though we can't handle 1 nested quantifiers  there are cognizcrs who can. and so on. 
　there seem to us to be four general lessons which can be drawn from the physics story: 
 l1  be cautious about extrapolations from local situations.  l1  what we can or cannot conceive  imagine  or visualize at any given time is not a reliable indication of what is possible or actual.  l1  an easy separation of  conceptual  and  empirical  can be misleading. what appears to be clearly a conceptual or logical issue might have hidden empirical aspects and what seems to be a straightforward empirical problem might have subtle conceptual connections.  l1  it takes time to work things out. 　how might these lessons be applied to the c-l debate in such a way that hyper-logicism gains credence  let's take the lessons in turn  starting with  li . 
　 li  is based on the fact that physics has shown us that we cannot move from our sense of local simultaneity to absolute simultaneity and the notion of a  universal now   nor can we extend a local euclidean framework to galactic distances. the moral for ai would seem to be that we should be wary about generalizing from our local conception of mentality to absolute mentality. to be more specific  we should leave open the possibility not only that there are alternative modes of cognition which not only make crucial use of symbol systems  but which use symbol systems exclusively when it comes to 
 propositional attitudes.  such a view does not allow one to generalize from the typical   local    pro-connectionist  psychological experiment  in which  say  humans  given tasks thought naturally to require the use of logic  dont use logic  to the proposition that all agents are similarly inept at using logic. 
　 l1 's import  in the present context  seems clear: while wc perhaps cannot conceive of what it would be like  when cognizing at the level of occurrent propositional attitudes  to exclusively employ a symbol system for such cognition  this fact  if it is a fact  should not be taken as a reliable indication that a being whose cognition is couched 
exclusively in some symbol system is impossible.1 
　 l1  has perhaps the most interesting and specific implications for hyper-logicism and the c-l debate. the point here would seem to be that just as non-standard positions on the parallel postulate  itself conceptual and formal in nature  yielded genuine empirical possibilities  non-standard positions on formal issues related to symbol systems may yield genuine possibilities for hyper-logicist cognition. when logicism is criticized  it is almost invariably true that what is being criticized is standard firstorder logic. this is like attacking physics by pointing out that the euclidean scheme cannot accommodate empircal puzzles now explained by relativity theory. it is now well-known that if first-order logic is abandoned  myriad alternative possibilities open up. the first batch of such possibilities derives from second order  indeed /i-order  extensional logics. even the simplest of second-order logics produce a significant increase in expressive power  the peano axiom system can be formalized in second-order logic . and there are other possibilities: first-order logic is monotonic; dropping this restriction appears to hold promise for modelling cognition thought by many to be beyond the reach of a symbol system  for a competent distillation sec  nilsson & genersereth 1  . as mentioned above  there is intensional logic. and then of course there is an infinite number of as-yet undiscovered possibilities for symbol systems. 
　the lesson of  l1  can perhaps be put most forcefully in the context of a concession sometimes made by 
1
 our point here can perhaps be bolstered by a distinction between :nternal  and  external  visualization  due to the 1th century philosopher-scientist h. von helmholz. we can only sketch the argument here: external visualization makes use of one dimension of space to visualize arrangements of other dimensions. thus  we have no difficulty in visualizing two-dimensional manifolds as embedded in a three-dimensional space and we suppose that there are no problems in visualizing a euclidean space of three dimensions. but surely there are different kinds of visualization; we cannot avail ourselves of a fourth dimension to visualize three-dimensional situations embedded in a four-dimensional manifold. and here is where internal visualization enters: to visualize space internally is to imagine the kinds of experience one would have if she were living in such a space. 
         thus  with respect to visualization  both euclidean and non-euclidean spaces require internal visualization. this seems easy for the euclidean case because we live in this space and the non-euclidean cases arc correspondingly difficult to visualize because of our lack of practice. but  in principle  we can visualize the kinds of experience we would have if we lived in such a space. and  in fact  modern cosmology is a sort of aid to the development of a non-euclidean imagination! the  privileged  epistemological status of euclidean geometry turns out upon analysis to depend on psychological habituation - we are more familiar with euclidean space and seem to slide easily from external to internal visualization when  in fact  there are different kinds of  visualization.  euclidean space has no privileged logical or epistemological status but simply the privilege of habit. with respect to the internal visualization of non-euclidean space  wc only lack practice. 
connectionists. the concession here  made e.g. by  hamad 1   is that some mental activity  say for example the conscious  sustained  in the head  manipulation of a symbol system and its components  something often done by logicians   is by its very nature symbolic. what we want to suppose  in keeping with  l1   is that there may be  for all we know as residents of local mindspace  agents that are not only inhumanly good at this kind of symbolic activity  but agents whose cognition is couched exclusively in such symbolic reasoning. 
　 l1   finally  has a very simple message. the timeline for physics suggests to us that dissatisfaction with the logicist approach to ai is remarkably impatient. logicians and mathematicians working in ai may need to toil for centuries before their work can be used to undergird implementation that leads to the creation of a genuine robotic agent. if anything  mindspace would seem to be a more difficult domain than physical space. it would thus come as no surprise if the timeline for logicist ai stretched on well into the future. 
　the physics story  then  appears to us to lend credence to  sym . what about the final member of the hyperlogicist triad  we turn to a defense of it now. 
1 brains-in-a-vat thought experiment 
the  no-sub  part of the hyper-logicist triad is the view that ai should proceed in the hope of building robot agents resembling those in  putnam 1 's brain-in-a-vat thought-experiment. these agents would have no sensors and no way of changing the external world  and would have no need  so the story would go  of subsymbolic processing so well-suited  as the connectionists have shown  to handling the relation between an agent and the world through which it navigates. on the other hand  hyperlogicism  if tenable  leaves room for cognition that  as putnam and others have shown  can be in many ways as rich as our own. 
　at the core of our defense of  no - sub   then  is a thought-experiment - which runs as follows. the year: 1. sue  at birth  is pared down to her nascent brain and then placed in a vat instead of her mother's arms. this vat  supervised by an ingenious neuro-ainik  is actually an extraordinary device capable of providing  via a massive webwork of electrodes  all the input that normally enters a brain through standard sensory pathways. sue   growing up   gets all the input we get by way of a rather sinister short-cut. but what she  sees  is as vivid as what we see  and what she  hears  is an clear as what we hear; and so on. 
　one might argue  as  putnam 1  does  that sue could not be a person in the full sense; that we could not be  as some philosophical skeptics have claimed  brains in vats. we are willing to agree that such an argument could be made out  and that it would be sound. our point  however  concerns  no-sub : wc are claiming that the thoughtexperiment shows that 
 1  o there exists a robotic agent none of whose mental processing involves subsymbolic 
bringsjord and zenzen 
encodings  traditionally required for agentenvironment interaction  not represcntable in  
this robot agent of  1  needn't be just like human agents. 
　many questions remain; we have space enough to briefly consider only two. the first is this: is it really true that 
 1   	
given that  says that logicist ai can actually produce the sort of robot agent in question  we think the answer to this question is  yes   because sue-like robot agents would seem not only logically possible  but physically possible  and not only physically possible  but buildable. let  t  be the proposition produced by modifying  1  in this way  changing  the latter 
'physically possibly' . it seems us  then  that 
 1'   	
and so if we are right that sue and her more robotic relatives confirm  1*   we will have the third and final member of the hyper-logicist triad by modus ponens. 
　here is the second question: what would be the point of trying to build a robot agent not connected to the external world  some philosophers may balk at this question  because philosophers seem to specialize in precisely the kind of thinking that has very little to do with well-defined neural structures  and everything to do with the kind of thing that one can do while in a sensory deprivation tank  or do limbless  paralyzed  and all alone. but there is a much less pedantic and sensible way to address the question: it seems plausible to think that there arc problems in the world which might be solvable by a robot agent engaged in symbolic thought in the absence of any  hook ups  to the external physical world  save for a 
　keyboard or some such device to bring symbol strings directly in and out . we have in mind complex  symbolic macroeconomic and microeconomic problems the solving of which would presumably have great utility for human life  but the reader can no doubt think of other examples. 
