 
     we describe the sheffield aivru 1d vision system for robotics. the system currently supports model based object recognition and location; its potential for robotics applications is demonstrated by its guidance of a umi robot arm in a pick and place task. the system comprises: 
1  the recovery of a sparse depth map using edge based passive stereo triangulation. 
1  the grouping  description and segmentation of edge segments to recover a 1d description of the scene geometry in terms of straight lines and circular arcs. 
1  the statistical combination of 1d descriptions for the purpose of object model creation from multiple stereo views  and the propagation of constraints for within view refinement. 
1  the matching of 1d wireframe models to 1d scene descriptions  to recover an initial estimate of their position and orientation. 

 this research was supported by serc project grant no. gr/d/1-ikbs/1 awarded under the alvey programme. stephen pollard is an serc it research fellow. 
1 	robotics 
introduction. 
the following is a brief description of the system. 
edge based binocular stereo is used to recover a depth map of the scene from which a geometrical description comprising straight lines and circular arcs is computed. scene to scene matching and statistical combination allows multiple stereo views to be combined into more complete scene descriptions with obvious application to autonomous navigation and path planning. here we show how a number of views of an object can be integrated to form a useful visual model  which may subsequently be used to identify the object in a cluttered scene. the resulting position and attitude information is used to guide the robot arm. figure 1 illustrates the system in operation. 
     the system is a continuing research project: the scene description is currently being augmented with surface geometry and topological information. we are also exploring the use of predictive feed forward to quicken the stereo algorithm. the remainder of the paper will 

figure 1. a visually guided robot arm. 
     figures  a    b  and  c  illustrate our visual system at work. a pair of panasonic wv-cd1 ccd cameras are mounted on an adjustable stereo rig. here they are positioned with optical centers approximately 1cm apart with asymmetric convergent gaze of approximately 1 degrees verged upon a robot workspace some 1cm distant the 1mm olympus lens  with effective focal length of approximately 1mm  subtends a visual angle of about 1 degrees. the system is able to identify and accurately locate a modelled object in the cluttered scene. this information is used to compute a grasp plan for the known object  which is precompiled with respect to one corner of the object which acts as its coordinate frame . the umi robot which is at a predetermined position with respect to the viewer centered coordinates of die visual system is able to pick up the object. 

describe the modules comprising the system in more detail. 
pmf: the recovery of a depth map. 
     the basis is a fairly complete implementation of a single scale canny edge operator  canny 1  incorporating sub pixel acuity  achieved through quadratic interpolation of the peak  and thresholding with hysteresis 

figure 1. stereo images. 
     the images are 1 with 1 bit grey level resolution. in the camera calibration stage  a planar tile containing 1 squares equally spaced in a square grid was accurately placed in the workspace at a position specified with respect to the robot coordinate system such that the orientation of the grid corresponded to the xy axes. the position of the corners on the calibration stimulus were measured to within 1 microns using a steko 1 stereo comparator. tsai's calibration method was used to calibrate each camera separately. we have found errors of the same order as tsai reported and sufficient for the purposes of stereo matching. the camera attitudes are used to transform the edge data into parallel camera geometry to facilitate the stereo matching process. to recover the world to camera transform the calibration images are themselves used as input to the system  eg are stereoscopically fused and the geometrical description of the edges and vertices of the squares statistically combined. the best fitting plane  the directions of the orientations of the lines of the grid corresponding to the xy axes  and the point of their intersection gives the direction cosines and position of the origin of the robot coordinate system in the camera coordinate system. the use of the geometrical descriptions recovered from stereo as feedback to iterate over the estimates of the camera parameters is a project for the future. 

figure 1. the edge maps. 
     a single scale canny operator with sigma 1 pixel is used. the non maxima suppression which employs quadratic interpolation gives a resolution of 1 of a pixel  though dependent to some extent upon the structure of the image . after thresholding with hysteresis  currently non adaptive   the edge segments are rectified so as to present parallel camera geometry to the stereo matching process. this also changes the location of the centre of the image appropriately  allows for the aspect ratio of the ccd array  fixing the vertical and stretching the horizontal  and adjusts the focal lengths to be consistent between views. 
	porrlll  pollard  prldmora  bowen  mayhew  and friaby 	1 applied to two images obtained from ccd cameras. the two edge maps are then transformed into a parallel camera geometry and stereoscopically combined  see figures 1  1 and 1 . the pmf stereo algorithm  described in more detail elsewhere  pollard et al 1; pollard 1   uses the disparity gradient constraint to solve the stereo correspondence problem. the parallel camera geometry allows potential matches to be restricted to corresponding rasters. initial matches are further restricted to edge seg-



figure 1. the depth map. 
     the output of the pmf stereo-algorithm displayed  with respect to the left image  with disparities coded by intensity  near-dark far-light . the total range of disparities in the scene was approximately 1 pixels from a search window of 1 pixels. pmf is a neighbourhood support algorithm and in this case the neighbourhood was 1 pixels radius. the disparity gradient parameter to pmf was 1. the iteration strategy used a conservative heuristic for the identification of correct matches  and their scores were frozen. this effectively removes them from succeeding iterations and reduces the computational cost of the algorithm as it converges to the solution. 1 iterations were sufficient. 
ments of the same contrast polarity and of roughly similar orientations  determined by the choice of a disparity gradient limit . matches for a neighbouring point may support a candidate match provided the disparity gradient between the two does not exceed a particular threshold. essentially  the strategy is for each point to choose from among its candidate matches the one best supported by its neighbours. 
     the disparity gradient limit provides a parameter for controlling the disambiguating power of the algorithm. the theoretical maximum disparity gradient is 1  along the cpipolars   but at such a value the disambiguating power of the constraint is negligible. false matches frequently receive as much support as their correct counterparts. however  as the limit is reduced the effectiveness of the algorithm increases and below 1  a value proposed as the psychophysical maximum disparity gradient by burt and julesz    we typically find that more than 1% of the matches are assigned correctly on a single pass of the algorithm. the reduction of the threshold to a value below the theoretical limit has little overhead in reduction of the complexity of the surfaces that can be fused until it is reduced close to the other end of the scale  a disparity gradient of 1 corresponds to fronto-parallel surfaces . in fact we find that a threshold disparity gradient of 1 is very powerful constraint for which less than 1% of surfaces  assuming uniform distribution over the gaussian sphere: following arnold and binford 
1 	robotics 
  project with a maximum disparity gradient greater than 1 when the viewing distance is four times the interocular distance. with greater viewing distances  the proportion is even lower. 
it has been shown  trivedi and lloyd 1; porrill 
1   that enforcing a disparity gradient ensures lipschitz continuity on the disparity map. such continuity is more general than and subsumes the more usual use of continuity assumptions in stereo. 
     the method used to calibrate the stereo cameras was based on that described by tsai   using a single plane calibration target  which recovers the six extrinsic parameters  1 translation and 1 rotation  and the focal length of each camera. this method has the advantage that all except the latter are measured in a fashion that is independent of any radial lens distortion that may be present the image origin  and aspect ratios of each camera had been recovered previously. the calibration target which was a tile of accurately measured black squares on a white background was positioned at a known location in the xy plane of the robot work space. after both cameras have been calibrated their relative geometry is calculated. 
     whilst camera calibration provides the transformation from the viewer/camera to the worldyrobot coordinate spaces we have found it more accurate to recover the position of the world coordinate frame directly. stereo matching of the calibration stimulus allows its position in space to be determined. a geometrical description of the position and orientation of the of the calibration target is obtained by statistically combining the stereo geometry of the edge descriptions and vertices. the process is described in pollard and porrill . 
gdb: the recovery of the geometric descriptive base. 
     in this section we briefly report the methods for segmenting and describing the edge based depth map to recover the 1d geometry of the scene in terms of straight lines and circular arcs. a complete description of the process can be found in pridmore et al  and porrill et al  1a . 
     the core process is an algorithm  gdf  which recursively attempts to describe  then smooth and segment  linked edge segments recovered from the stereo depth map. gdf is handed a list of edge elements by connect  pridmore et al 1 . orthogonal regression is used to classify the input string as a straight line  plane or space curve. if the edge list is not a statistically satisfactory straight line but docs form an acceptable plane curve  the algorithm attempts to fit a circle. if this fails  the curve is smoothed and segmented at the extrema of curvature and curvature difference. the algorithm is then applied recursively to the segmented parts of the curve. 
     some subtlety is required when computing geometrical descriptions of stereo acquired data. this arises in part from the transformation between the geometry in disparity coordinates and the camera/world coordinates. the former is in a basis defined by the x coordinates in the left and 

right images and the common vertical y coordinate  the latter  for practical considerations  eg mere is no corresponding average or cyclopean image   is with respect to the left imaging device  the optical centre of the camera being at  1 1  and the centre of the image is at  1 1 where f is the focal length of the camera. while the transformation between disparity space and the world is projective  and hence preserves lines and planes  circles in the world have a less simple description in disparity space. the strategy employed to deal with circles is basically as follows: given a string of edge segments in disparity space  our program will only attempt to fit a circle if it has already passed the test for planarity  and the string is then replaced by its projection into this plane. three well chosen points are projected into the world/camera coordinate frame and a circle hypothesised  which then predicts an ellipse lying in the plane in disparity space. the mean square errors of the points from this ellipse combined with those from the plane provide a measure of the goodness of fit. in practice  rather than change coordinates to work in the plane of the ellipse  we work entirely in the left eye's image  but change the metric so that it measures distances as they would be in the plane of the ellipse. 
     typically  stereo depth data are not complete; some sections of continuous edge segments in the left image may not be matched in the right due to image noise or partial occlusion. furthermore disparity values tend to be erroneous for extended horizontal or near horizontal segments of curves. it is well known that the stereo data associated with horizontal edge segments is very unreliable  though of course the image plane information is no less usable than for the other orientations. our solution to these problems is to use 1d descriptions to predict 1d data. residual components derived from reliable 1d data 

figure 1. the geometric description overlaid on the left edge map. 
     the thin lines depict connected edge segments to which either no description has been ascribed because they were too short  or because they are present only in the left eyes image and only a 1d description was possible. the thicker lines depict the connected edge segments for which a 1d geometrical description has been computed. before segmentation each edge list was smoothed by diffusion  see porrill   approximately equal to a gaussian of sigma 1. 
and the image projection of unreliable or unmatched  1d  edges are then statistically combined and tested for acceptance. by this method we obtain a more complete 1d and 1d geometrical description of the scene from the left eyes view than if we used only the stereo data. figure 1 illustrates the gdb description of our scene. 
     evaluation of the geometrical accuracy of the descriptions returned by the gdf has employed both natural and cad graphics generated images. the latter were subject to quantisation error and noise due to the illumination model but had near perfect camera geometry; they were thus used to provide the control condition  enabling us to decouple the errors due to the camera calibration stage of the process. a full description of the experiments are to be found in pridmore   suffice it to say that we find that typical errors for the orientation of lines is less than a degree  and for the normals of circular arcs subtending more than a radian  the errors are less than 1 degrees in the cad generated images and only about twice that for images acquired from natural scene. the positional accuracy of features and curvature segmentation points has also been evaluated  errors are typically of the order of a few millimetres which maybe argues well for the adequacy of tsai's camera calibration method more than anything else. 
smm: the scene and model matcher. 
     the matching algorithm  see pollard et al  for details   which can be used for scene to scene and model to scene matching  exploits ideas from several sources: the use of a pairwise geometrical relationships table as the object model from grimson and lozano-perez  1; 1   the least squares computation of transformations by exploiting the quaternion representation for rotations from faugeraus et al  1; 1   and the use of focus features from bolles et al . we like to think that the whole is greater than the sum of its parts! the matching strategy proceeds as follows: 
1  a focus feature is chosen from the model; 
1  the s closest salient features are identified  currently salient means lines with length greater than l ; 
1  potential matches for the focus feature are selected; 
1  consistent matches  in terms of a number of pairwise geometrical relationships  for each of the neighbouring features are located; 
1  the set of matches  including the set of focus features  is searched for maximally consistent cliques of cardinality at least c  each of these can be thought of as an implicit transformation. 
1  synonymous cliques  that represent the same implicit transformation  are merged and then each clique is extended by adding new matches for all other lines in the scene if they are consistent with each of the matches in the clique. rare inconsistency amongst an extended clique is dealt with by a final economical tree search. 
porrill  pollard  pridmore  bowen  mayhew  and frisby 	1 

1  extended cliques are ranked on the basis of the number and length of their members. 
1  the transformation implicitly defined by the clique is recovered using the method described by faugeras et al . 
     the use of the parameters s  the neighbours of the focus feature   and c  the minimum subset of s   are powerful search pruning heuristics that are obviously model dependent work is currently in hand to extend the matcher with a richer semantics of features and their pairwise geometrical relationships  and also to exploit negative or incompatible information in order to reduce the likelihood of false positive matches. 
tied: the integration of edge descriptions. 
     the geometrical information recovered from the stereo system described above is uncertain and error prone  however the errors are highly anisotropic  being much greater in depth than in the image plane. this anisotropy can be exploited if information from different but approximately known positions is available  as the statistical combination of the data from the two viewpoints provides improved location in depth. from a single stereo view the uncertainity can only be improved by exploiting geometrical constraints. a method for the optimal combination of geometry from multiple sensors based on the work of faugeras et al  and durrantwhyte  has been developed  for details see porrill et al.  1b    and extended to deal both with the specific geometrical primitives recovered by the gdf and the enforcing of constraints between them. the method is used in the application being described to integrate the edge geometry from multiple views to create the object model  see figure 1   and to obtain the statistically optimum estimate of the position and direction cosines of the target object coordinate frame after the matching stage has been completed. the latter is done by enforcing the constraints that the axes of the coordinate frame are parallel to all the lines they should be  that they are mutually perpendicular  and intersect at a single point the result of the application of this stage of the process is the position and attitude of the object in the world coordinates. figure 1 illustrates the smm matching the compiled visual model in the scene. the information provided by matching gives the rhs of the inverse kinematics equation which must be solved if our manipulator is to grasp the 
object  see figure 1 . 
rev: the regions  edges  vertices graph. 
     one may regard the system as generating a sequence of representations each spatially registered with respect to a coordinate system based on the left eye: image  edge map  depth map and geometrical description. in the initial stages of processing a pass oriented approach may be appropriate but we consider that it is desirable to provide easy and convenient access between the representations at a higher level of processing. the revgraph is an environment  built in franz lisp  in 


figure 1. the integration of linear edge geometry from multiple views. 
     figure  a  is a pair of stereo images produced by a version of the ibm winsom csg body modeler. it depicts the object to be modelled. to ensure a description of the model suitable for visual recognition and to allow greater generality  the same approach has been successfully applied to natural images of a real object  we combine geometrical data from multiple views of the object to produce a primitive visual model of it figure  b  illustrates the 1d data extracted from eight views of the object their combination is achieved by incrementally matching each view to the next between each view the model is updated  novel features added and statistical estimation theory used to enforce consistency amongst them  eg. making near parallel and near perpendicular lines truely so . finally only line features that have been identified in a more than a single view appear in the final visual model  see 
 c  . 

1 	robotics 


figure 1. object location: 
     the dark lines depict the projection of the object model into the scene geometry after being transformed by the rotation and translation produced by the matching process  smm  and the geometry integration process  tied . the recovery of the object to scene transformation has two stages  they are as follows: first the matcher smm locates the object model in the scene and recovers a sub-optimum estimate of the rotation and translation. the process is suboptimal because it does not take account of the anisotropics in the errors in the geometry of the matched edge features  and furthermore sequences the problem by first solving for the rotation and then using the rotation to calculate the translation. notwithstanding these weaknesses  it is an adequate starting point for the second process which is a linearised recursive solution to the optimal weighted least squares integration of the geometry  tied   which delivers the corrected transformation. to give some idea of the scale of the matching search problem  the object model contains 1 features and the scene contains 1. some 1 model focus features  chosen on the basis of length  resulted in the expansion of only 1 local cliques. the latter were required to be of magnitude at least c-1 from s-1 neighbouring features. the largest clique found by the matcher contained 1 matched lines. 
which the lower level representations are all indexed in the same co-ordinate system. on top of this a number of tools have been and are being written for use in the development of higher level processes which we envisage overlaying the geometrical frame with surface and topological information. such processes will employ both qualitative and quantitative geometrical reasoning heuristics. in order to aid debugging by keeping a history of reasoning  and increase search efficiency by avoiding backtracking  the revgraph contains a consistency maintenance system  cms   to which any processes may be easily interfaced. the cms is our implementation of most of the good ideas in doyle  and dekleer  augmented with some our own. the importance of truth maintenance in building geometrical models of objects was originally highlighted by hermann . details of the revgraph and cms implementation may be found in bowen . 
conclusions 
     we demonstrate the ability of our system to support visual guided pick and place in a visually cluttered but  in 

figure 1. closing the loop. 
     figures  a  and  b  show the arm grasping the object and the scene with the object removed. 
terms of trajectory planning  benign manipulator workspace. it is not appropriate at this time to ask how long the visual processing stages of the demonstration take  suffice it to say that they deliver geometrical information of sufficient quality  not only for the task in hand but to serve as a starting point for the development of other visual and geometrical reasoning competences. 
acknowledgements 
     we gratefully acknowledge dr chris brown for his valuable technical assistance. 
