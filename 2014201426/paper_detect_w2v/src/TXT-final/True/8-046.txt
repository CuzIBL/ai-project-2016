a mobius automaton: an application 
of artificial intelligence techniques 
by 
nils j. nilsson 
stanford research institute menlo park  california 

summary 
     a research project applying a r t i f i c i a l i n t e l ligence techniques to the development of inte-
grated robot systems is described. the experimental f a c i l i t y consists of an sds-1 computer and associated programs controlling a wheeled vehicle that carries a tv camera and other sensors. the primary emphasis is on the development of a system 
of programs for processing sensory data from the vehicle  for storing relevant information about the environment  and for planning the sequence of motor actions necessary to accomplish tasks in the environment. a typical task performed by our present system requires the robot vehicle to rearrange  by pushing  simple objects in its environment . 
     a novel feature of our approach is the use of a formal theorem-proving system to plan the execution 
of high-level functions as a sequence of other  perhaps lower-level  functions. 	the execution of these  in turn  requires additional planning at lower levels. 	the main theme of the research is the integration of the necessary planning systems  models of the world  and sensory processing systems into an efiicient whole capable of performing 
a wide range of tasks in a real environment. 
key words 
robot 
robot system 
visual processing problem-solving 
question-answering 
theorem-proving 
models of the world 
planning 
scene analysis 
mobile automaton 
acknowledgment 
　　　at least two dozen persons at the stanford research institute have made substantial contributions to the project that tne author has the good fortune to describe in this paper. 	a l l of us express our appreciation to the rome air development center and the advanced research projects agency  who supported this research under contract no. f 1-c-1. 
	i 	introduction 
　　　at the stanford research institute we are implementing a f a c i l i t y for the experimental study of robot systems. 	the f a c i l i t y consists of a timeshared sds-1 computer  several core-loads of programs  a robot vehicle  and special interface equipment. 
　　　several earlier reports'1  and papers1 describing the project have been written; in this paper we shall describe its status as of early 1 and discuss some of our future plans. 
     the robot vehicle itself is shown in fig. 1. it is propelled by two stepping motors independently driving a wheel on either side of the vehicle. it carries a vidicon television camera and optical range-finder in a movable  head.  control logic on board the vehicle routes commands from the computer to the appropriate action sites on the vehicle. in addition to the drive motors  there are motors to control the camera focus and i r i s settings and the t i l t angle of the head.  a motor to pan the head is not yet used by present programs.  other computer commands arm or disarm interrupt logic  control power switches  and request readings of the status of various registers on the vehicle. besides the television camera and range-finder sensors  several  cat-whisker  touch-sensors are attached to the vehicle's perimeter. these touch sensors enable the vehicle to know when it bumps into something. commands from the sds-1 computer to the vehicle and information from the vehicle to the computer are sent over two special radio links  one for narrow-band telemetering and one for transmission of the tv video from the vehicle to the computer. 
　　　the purpose of our robot research at sri is to study processes for the real-time control of a robot system that interacts with a complex environment. we want the vehicle to be able to perform various tasks that require it to move about in its environment or to rearrange objects. in order to accomplish a wide variety of tasks rather than a 
　　　few specific ones  a robot system must have very 
general methods. what is required is the integration in one system of many of the abilities that are usually found separately in individual a r t i f i cial intelligence programs. 
　　　we can group most of the needed abilities into three broad classes:  1  problem-solving   1  modelling  and  1  perception: 
 1  	problem-solving 
     a robot system accomplishes the tasks given it by performing a sequence of primitive actions  such as wheel motions and camera readings. for e f f i ciency  a task should f i r s t be analyzed into a sequence of primitive actions calculated to have the desired effect. this process of task analysis is often called planning  because it is accomplished before the robot begins to act. obviously  in order to plan  a robot system must  know  about the effects of its actions. 

-1-

 1  modelling 
       a body of knowledge about the e f f e c t s of act i o n s is a type of model of the w o r l d . a robot problem-solving system uses the i n f o r m a t i o n stored in the model to c a l c u l a t e what sequence of actions w i l l cause the world to be in a desired s t a t e . as the world changes  e i t h e r by the r o b o t ' s own act i o n s or f o r other reasons  the model must be up-
dated to record these changes. a l s o   new informat i o n learned about the world should be added to the model. 
 1  perception 
       sensors are necessary to give a robot system new i n f o r m a t i o n about the w o r l d . by f a r the most important sensory system i s v i s i o n   since i t a l lows d i r e c t perception of a good sized piece of the world beyond the range of touch. since we assume that a robot system w i l l not always have stored in i t s model every d e t a i l of the exact conf i g u r a t i o n of i t s world and thus cannot know p r e c i s e l y the e f f e c t s o f i t s every a c t i o n   i t also needs sensors w i t h which to check predicted consequences against r e a l i t y as it executes i t s plans. 
       the i n t e g r a t i o n of such a b i l i t i e s i n t o a smoothly-running  e f f i c i e n t system presents both important conceptual problems and serious p r a c t i c a l challenges. for example  it would be i n f e a s i b l e f o r a s i n g l e problem-solving system  using a s i n g l e 
       model  to attempt to c a l c u l a t e the long chains of p r i m i t i v e actions needed to perform lengthy tasks. a way around t h i s d i f f i c u l t y is to program a number of c o o r d i n a t i n g   a c t i o n - u n i t s     each w i t h i t s own problem-solving system and model  and each respons i b l e f o r planning and executing a s p e c i a l i z e d f u n c t i o n . in planning how to perform i t s p a r t i c u l a r f u n c t i o n   each a c t i o n - u n i t knows the e f f e c t s of executing f u n c t i o n s handled by various of the other a c t i o n - u n i t s . with t h i s knowledge it composes i t s plan as a sequence of other functions   w i t h the a p p r o p r i a t e arguments  and leaves the planning r e quired f o r each of these f u n c t i o n s up to the a c t i o n - u n i t s responsible for executing them at the time they are to be executed. 
       such a system of interdependent a c t i o n - u n i t s i m p l i e s c e r t a i n a d d i t i o n a l problems i n v o l v i n g com-
munication of i n f o r m a t i o n and t r a n s f e r of c o n t r o l between u n i t s . when such a system is implemented on a s e r i a l computer with l i m i t e d core memory  obvious p r a c t i c a l d i f f i c u l t i e s a r i s e connected with swapping program segments in and out of core and handling i n t e r r u p t s in r e a l time. the coordinated a c t i o n - u n i t scheme serves as a u s e f u l guide in exp l a i n i n g the o p e r a t i o n of our system  even though p r a c t i c a l n e c e s s i t i e s have d i c t a t e d occasional dev i a t i o n s from t h i s scheme in our implementation. in the next s e c t i o n we s h a l l discuss the problems o l v i n g processes and models associated w i t h some s p e c i f i c f u n c t i o n s of the present sri robot system. 
	ii 	some specific functions of the robot 
system and their associated problemsolving processes and models 
a. 	low level functions 
       the robot system is capable of executing a number of f u n c t i o n s that vary in complexity from the simple a b i l i t y to t u r n the d r i v e wheels a cert a i n number of steps to the a b i l i t y to c o l l e c t a 
       number of boxes by pushing them to a common area of the room. the o r g a n i z a t i o n of these f u n c t i o n a l a c t i o n - u n i t s i s not s t r i c t l y h i e r a r c h i c a l   a l though f o r d e s c r i p t i v e convenience we w i l l d i v i d e them i n t o two classes: low l e v e l and high l e v e l f u n c t i o n s . 
　　　of the f u n c t i o n s that we s h a l l mention here  the simplest are c e r t a i n p r i m i t i v e assembly l a n -
guage routines f o r moving the wheels  t i l t i n g the head  reading a tv p i c t u r e   and so on. two examples of these are move and turn; move causes the v e h i c l e to r o l l in a s t r a i g h t l i n e by t u r n i n g both d r i v e wheels in unison  and turn causes the vehicle to r o t a t e about i t s center by t u r n i n g the d r i v e 
wheels in opposite d i r e c t i o n s . the arguments of move and turn are the number of steps that the d r i v e wheels are to t u r n  each step r e s u l t i n g in a vehicle motion of 1 inch  and   s t a t u s   arguments that allow queries to be made about whether or not the f u n c t i o n has been completed.* 
       once begun  the execution of any f u n c t i o n proceeds e i t h e r u n t i l i t i s completed i n i t s normal manner or u n t i l it is halted by one of a number of  abnormal  circumstances  such as the v e h i c l e bumping i n t o unexpected o b j e c t s   overload c o n d i t i o n s   resource exhaustion  and so on. under ordinary o p e r a t i o n   if execution of move r e s u l t s in a bump  mollon is stopped a u t o m a t i c a l l y by a 
       s p e c i a l mechanism on the v e h i c l e . this mechanism can be overridden by a special i n s t r u c t i o n from the computer  however  to enable the robot to push ob jects. 
　　　the problem-solving systems for move and turn are t r i v i a l ; they need only to c a l c u l a t e what s i g nals s h a l l be sent to r e g i s t e r s associated with the motors in order to complete the desired number 
of 	steps. 
       at a l e v e l j u s t above move and turn is a funct i o n whose execution causes the v e h i c l e to t r a v e l d i r e c t l y to a point s p e c i f i e d by a p a i r of   x   y   coordinates. this f u n c t i o n is implemented in the fortran r o u t i n e leg. the model used by leg cont a i n s i n f o r m a t i o n about the r o b o t ' s present   x   y   l o c a t i o n and heading r e l a t i v e to a given coordinate system and i n f o r m a t i o n about how f a r the v e h i c l e t r a v e l s f o r each step applied to the stepping motors. this i n f o r m a t i o n is stored along with some other special constants in a s t r u c t u r e c a l l e d the parameter model. thus f o r a given   x   y   
-1-* our implementation allows a program c a l l i n g r o u t i n e s l i k e move or turn to run in p a r a l l e l w i t h the motor f u n c t i o n s they i n i t i a t e . 
destination as an argument of leg  leg's problemsolving system calculates appropriate arguments for a turn and move sequence and then executes this sequence. predicted changes in the robot's location and heading caused by execution of move and turn are used to update the parameter model. 
     ascending one more level in our system  we encounter a group of fortran  two-letter  routines whose execution can be initiated from the teletype. our action-unit system ceases to be s t r i c t ly hierarchical at this point  since some of the two-letter commands can cause others to be executed . 
     one of these two-letter commands  ex  takes as an argument a sequence of  x y  coordinate positions. execution of ex causes the robot to travel from its present position directly to the f i r s t point in the sequence  thence directly to the second  and so on until the robot reaches the last point in the sequence. the problem-solving system for ex simply needs to know the effect caused by execution of a leg program and composes a chain of leg routines  each with arguments provided by the successive points specified in the sequence of points. under ordinary operation  if one of these leg routines is halted due to a bump  ex backs the vehicle up slightly and then halts. a special feature of our implementation is the ability to arm and service interrupts  such as caused by bumps  at the fortran programming level. 
     another two-letter command  pi  causes a picture to be read after the tv camera has been aimed at a specified position on the floor. the problemsolving system for pi thus calculates the appropriate arguments for a turn routine and a headt i l t i n g routine; pi then causes these to be executed  reads in a picture from the tv camera  and performs processing necessary to extract information about empty areas on the floor.  details of the picture processing programs of the robot system are described in sec. i l l below.  
     the ability to travel by the shortest route to a specified goal position along a path calculated to avoid bumping into obstacles is provided by the two-letter command te. execution of te involves the calculation of an appropriate sequence of points for ex and the execution of ex. this appropriate sequence is calculated by a special problemsolving system embodied in the two-letter command 
pl. 
     the source of information about the world used by pl is a planar map of the room called the grid model. the grid model is a hierarchically organized system of four-by-four grid cells. i n i t i a l l y the  whole world  is represented by a four-by-four array of cells. a given cell can be either empty  of obstacles   f u l l   partially f u l l   or unknown. each partially f u l l cell is further subdivided into a four-by-four array of cells  and so on  until a l l partially f u l l cells represent areas of some suitably small size.  our present system splits cells down to a depth of three levels  representing a smallest area of about 1 inches.  
　　　special  model maintenance  programs insure that the grid model is automatically updated by information about empty and f u l l floor areas gained by either successful execution or interruption of move commands. 
　　　the pl program f i r s t uses the grid model to compute a network or graph of  nodes.  the nodes correspond to points in the room opposite corners of obstacles; the shortest path to a goal point w i l l then pass through a sequence of a subset of these nodes. in fig. 1 we show a complete grid model of a room containing three objects. the robot's position  marked  r   and the goal position  marked  g   together with the nodes a b c d  e f h i j and k are shown overlaid on the grid model. the program pl then determines that the shortest path is the sequence of points  r f i  and g by employing an optimal graph-searching algorithm developed by hart  et al.1 
　　　if the grid model map of the world contains unknown space  pl must decide whether or not to treat this unknown space as f u l l or empty. 	currently  pl multiplies the length of any segment of the route through unknown space by a parameter k. thus if k=l  unknown space is treated as empty; values of k greater than unity cause routes through known empty space to be preferred to possibly shorter routes through unknown space. 
　　　execution of te is accomplished by f i r s t reading and processing a picture  using pi with the camera aimed at the goal position  and taking a range-finder reading. the information about f u l l and empty floor areas thus gained is added to the grid model. a route based on the updated grid model is then planned using pl  and then ex is executed using the arguments calculated by pl. if the ex called by te is halted by a bump  a procedure attempts to manuever around the interfering obstacle  and then te is called to start over again. thus  vision is used only at the beginning of a journey and when unexpected bumps occur along the journey. 
　　　although our present robot system does not have manipulators with which to pick up objects  it can move objects by pushing them. the fundamental ability to push objects from one place to another is programmed into another two-letter fortran routine  called pu. execution of pu causes the robot to push an object from one named position along a straight line path to another named position. the program pu takes five arguments: the 
-1- x y  coordinates of the object to be pushed  the  size  or maximum extent of the object about i t s center of gravity  and the  x y  coordinates of the spot to which the object is to be pushed. the problem-solving system for pu assembles an ex  a turn  and two move commands into a sequence whose execution w i l l accomplish the desired push. first a location from which the robot must begin pushing the object is computed. then pl is used to plan a route to this goal location. the sequence of points along the route serves as the argument for ex that is then executed.  should ex be stopped by a bump  pu is started over again.  next  pu's problem-solving system  using the parameter model  calculates an argument for turn that w i l l point the robot in the direction that the object is to be pushed. a large argument is provided for the f i r s t move command so that when it is executed  it w i l l bump into the object to be pushed and automatically halt. after the bump and halt  the automatic stopping mechanism on the vehicle is overridden and the next move command is executed with an argument calculated to push the object the desired distance. 
b. 	higher level functions 
　　　as we ascend to higher level functions  the required problem-solving processes must be more powerful and general. we want our robot system to have the a b i l i t y to perform tasks possibly requiring quite complex logical deductions. what is needed for this type of problem-solving is a general language in which to state problems and a powerful search strategy with which to find solutions. we have chosen the language of first-order predicate calculus in which to state high level problems for the robot. these problems are then solved by an adaptation of a  question answering system  qa-1  based on  resolution  theorem-
proving methods.1 
　　　as an example of a high level problem for the robot  consider the task of moving  by pushing  three objects to a common place. this task is an example of one that has been executed by our present system. if the objects to be pushed are  say  obi  1  and 1  then the problem of moving them to a common place can be stated as a  conjecture  for qa-1: 
c1p s {position  1bl p s  
a position  ob1 p s  
a position  1 p s } 
　　　 that i s    there exists a situation s and a place p  such that obi  1  and 1 are a l l at place p in situation s.   the task for qa-1 is to  prove  that this conjecture follows from  axioms  that describe the present position of objects and the effects of certain actions. 
　　　our formulation of these problems for the theorem-prover involves specifying the effects of actions in terms of functions that map situations into new situations. for example  the function push  x p s  maps the situation s into the situation resulting by pushing object x into place p. thus two axioms needed by qa-1 to solve the pushing problem are: 
      vx p s {position  x p  push  x p s  } and 
 vx y p q s {position  x p s  a ~ same  x y  *=  position  x p push  y q s  } 	. 
　　　the f i r s t of these axioms states that if in an arbitrary situation s  an arbitrary object x is pushed to an arbitrary place p  then a new situation  push  x p b   w i l l result in which the object x w i l l be at position p. the second axiom btates that any object w i l l stay in i t s old place in the new situation resulting by pushing a different object. 
　　　in addition to the two axioms just mentioned  we would have others describing the present positions of objects. for example  if obi is at co-
ordinate position  1  in the present situation  we would have: 
	position  obi   1   present  	. 
 this information is provided automatically by routines that scan the grid model  giving names to clusters of f u l l cells and noting the locations of these clusters.  
　　　in proving the truth of the conjecture  the theorem-prover used by qa-1 also produces the place p and situation s that exist. that i s   qa-1 
determines that the desired situation s is: s = push  1   1   push  1   1   present  . 
a l l of the information about the world used by qa-1 
in solving this problem is stored in the form of axioms in a structure called the axiom model. in general  the axiom model w i l l contain a large number of facts  more than are necessary for any given deduction. 
　　　another lisp program examines the composition of functions calculated by qa-1 and determines those lower level fortran two-letter commands 
needed to accomplish each of them. in our present example  a sequence of pu commands would be assembled. in order to calculate the appropriate arguments for each pu  qa-1 is called again  this time to prove conjectures of the form: 
  p w {position  ob1 p present  a size  ob1 w   	. 
again the proof produces the p and w that exist  thus providing the necessary position and size arguments for pu.  size information is also automatically entered into the axiom model by routines 
that scan the grid model.  
　　　in transferring control between lisp and fortran  and also between separate large fortran segments   use is made of a special miniature monitor system called the valet. the valet handles the process of dismissing program segments and starting up new ones using auxiliary drum storage for transferring information between programs. 
　　　the qa-1 theorem-proving system allows us to pose quite general problems to the robot system  but further research is needed on adapting theoremproving techniques to robot problem-solving in order to increase efficiency.* the generality of 
-1-* we can easily propose less fortunate axlomatizatlons for the  collecting objects task  that would prevent qa-1 from being able to solve i t . theorem-proving techniques tempts us to use a single theorem-prover  and axiom set  as a problemsolver  and model  for a l l high level robot a b i l i t i e s . we might conclude  however  that efficient operation requires a number of coordinating actionunit structures  each having its own specialized theorem-prover and axiom set and each responsible for relatively narrow classes of functions. 
　　　another lisp program enables commands stated in simple english to be executed.1 *1 it also accepts simple english statements about the environment and translates them into predicate calculus statements to be stored as axioms. 	english commands are ordinarily translated into predicate calculus conjectures for qa-1 to solve by producing an appropriate sequence of subordinate functions. 	for some simple commands  the theoremprover is bypassed and lower level routines such as pu  te  etc.  are called directly. 
　　　the english program also accepts simple english questions that require no robot actions. for these  it uses qa-1 to discover the answer  and then it delivers this answer in english via the teletypewriter.  task execution can also be reported by an appropriate english output.  
	i l l 	visual perception 
　　　vision is potentially the most effective means for the robot system to obtain information about i t s world. the robot lives in a rather antiseptic but nevertheless real world of simple objects- boxes  wedges  walls  doorways  etc. its visual system extracts information about that world from a conventional tv picture. a complete scene analysis would produce a description of the visual scene  including the location and identification of a l l visible objects. currently  we have two separate operating vision programs. one of these produces line drawings  and has been used for some time to identify empty floor space  regions on the floor into which the robot is free to move. the other  which is more recent  locates and identifies the major  non-overlapping objects. in this section we shall give brief descriptions of how these programs operate. 
a. 	line drawing program 
　　　the line drawing program produces a line drawing representation of a scene by a series of essent i a l l y local operations on a tv picture.* fig. 1a shows a typical digitized picture  which is stored in the computer as a 1 x 1 array of 1-bit  1level  intensity values. the scene shown is f a i r l y typical  and includes some of the problems of mild shadows and reflections  some faint edges  and objects not completely in the field of view. 
* 	most of these operations were adaptations of earlier work by roberts.1 	details of our procedures  together with a description of special hardware for doing them efficiently  are given in refs. 1 and 1. 
　　　the f i r s t of the local operations is a digital differentiation used to find points where there are significant changes in light intensity. these changes usually occur at or near the boundaries of objects  as can be seen from fig. 1b. the next step is to determine the local direction of these boundaries. this is done by systematically placing small masks over the differentiated picture  and looking for places where the masks line up well with the gradient. fig. 1c shows the locations and orientations of masks that responded strongly. 
　　　the next step is to f i t these short line segments with longer straight lines. this is done by f i r s t grouping the short line segments  and then f i t t i n g a single straight line to a l l of the segments in a group. grouping is a systematic procedure in which short segments are linked if they are sufficiently close in location and orientation. fig. 1d shows the results of f i t t i n g longer lines to the segments in each group. the final step is to join the endpoints of these long lines to produce a connected line drawing. this is done by considering the endpoints one at a time and creating candidate connections-straight connections to neighboring endpoints  extrapolations to points of intersection  extrapolations to t-junctions  etc. the candidate that best f i t s the corresponding part of the derivative picture is the one selected. the final line drawing produced by this procedure is shown in fig. 1e. 
　　　while the line drawing preserves much of the information in the quantized picture in a compact form  it often contains flaws due to missing or 
extra line segments that complicate i t s analysis. currently  the only information we extract from the line drawing is a map of the open floor space. a program called floor boundary f i r s t finds a path along those line segments that bound the floor space in the picture. these lines are typically the places where the walls or objects meet the floor  or where sides of objects obscure our view of the floor. fig. 1f shows the floor boundary extracted from the line drawing. 
　　　now corresponding to any point in the picture is a ray going from the lens center of the camera through the picture point and out into space. 	this ray is the locus of a l l points that can produce the given picture point. 	if we follow the rays going through points on the floor boundary to the points at which they pierce the floor  we obtain an i r regular polygon on the floor that bounds space known to be empty. 	in this way the line drawing is used to identify empty floor space  and the 
vision system enters information about open area 
into the grid model. 
b. 	object identification program 
　　　were the line drawing program able to produce a perfect line drawing  the analysis needed to locate and identify objects in the scene would be relatively straightforward. however  the line 
-1-drawing often contains flaws that seriously complicate i t s analysis. some of these flaws could be corrected by more elaborate local processing. 
however  there is a limit to how well local processing can perform  and when significant edges cannot be told from insignificant edges on the basis of local c r i t e r i a   the goal of producing a perfect line drawing in this way must be abandoned. 
　　　the object identification program locates and identifies non-overlapping objects by gathering and interpreting evidence supplied by local operators. 	the program consists of two parts: 	a repertoire of local operators and an executive. 	the local operators process the gradient picture to 
perform tests such as deciding whether or not there is a line between two points  or finding a l l lines leaving a given point. each operator returns not 
a single answer  but a set of possible answers with associated confidences  ideally  probabilities  that each answer is in fact correct. the executive explores the scene by calling local operators and evaluating the results in the light of both prior test results and b u i l t - i n knowledge of the world. 
　　　the executive program is organized as a decision tree. 	each node in the tree specifies that a particular test is to be performed. 	the branches leaving a node correspond to the possible test out-
comes  and since each outcome has an associated confidence  these confidences are attached to the branches. 
　　　a given node in the tree can be thought of as representing a hypothesis about the contents of the scene. this hypothesis is simply that the scene is partially described by the test results specified by the path from the start node to the given node. the hypothesis is given a confidence by combining the confidences of these test results. the test called for at the given node is designed to provide an answer that w i l l tend to confirm or infirm the hypothesis. 
　　　an analysis of a scene proceeds as a search of the decision tree described. at any stage in the search we have a partially expanded tree corresponding to the tests already performed. the nodes at the tips of this partial tree  which we shall c a l l open nodes  present us with a choice of possible next tests  or  alternatively  hypotheses to be further investigated . the open node with highest associated confidence is selected for expansion  
i . e .   the test called for by that particular node is performed. 	the search proceeds u n t i l the open node with highest confidence is a terminal node of the tree. 	a terminal node typically represents a complete description of at least a portion of the scene  and hence constitutes at least a partial  answer   	 certain terminal nodes correspond to impossible physical situations; in this event  the search is resumed at the next most confident node.  after returning a partial answer the portion of the scene containing the object found is deleted and the analysis begins again. 	thus the tree search is iterated u n t i l the scene contains no further objects. 
　　　the decision tree i t s e l f embodies the strategy for searching the scene. 	the basic ideas behind this strategy are simple  and w i l l be illustrated by following the operation of the program on the scene of fig. 1a. 	the f i r s t operation called for is a search for vertical lines  since these are usually both reliably detectable and significant. 	fig. 1a shows that the appropriate operator found three vert i c a l lines  which happened to rank in confidence as numbered. 
　　　starting with the highest confidence line and checking to see that i t s lower endpoint was within the picture  the program next looked for other lines leaving that endpoint. 	a failure here would 
have led to the conclusion that something was strange  and therefore to a transfer to the next 
most confident node in the tree. however  a  spur  was detected  as shown in fig. 1b. hypotheses that the lower endpoint was connected to the lower endpoints of other verticals were rejected because the direction of the spur was not correct. thus  at this point attention was shifted to the top of the vertical. a spur was found there  as expected  and that spur was followed to i t s endpoint as shown in fig. 1c. the fact that its endpoint was on the picture  coupled with the fact that the program had failed in its attempt to connect the vertical to other verticals  provided strong evidence that a wedge had been found. a further check of the angle at the top of the vertical confirmed the wedge hypothesis  and the same calculations used in the floor boundary program were used to locate the lower vertices. 
　　　at this point one object had been found and identified  and a search for other objects began. on the second iteration  the remaining verticals were successfully joined at their lower endpoints  as shown in fig. 1d  and various spurs were found  as shown in fig. 1e. a similar attempt to spot a wedge failed to produce strong evidence  as shown in fig. 1f  and the f i n a l output indicated the existence and location of an object partly out of view without specifying what it was. at this point there were no more vertical lines  and the analysis was completed. 
　　　the object identification program is capable of locating and often identifying non-overlapping objects on the basis of partial information. there are a number of obvious ways in which it can be improved and extended  and further research w i l l be devoted to these tasks. however  even as it stands it can provide the robot with much valuable infor-
mation about the robot's world. 
	iv 	conclusions 
　　　there are several key questions that our work has helped to put into focus. given that a robot system w i l l involve the successful integration of problem-solving  modelling  and perceptual a b i l i t i e s   there are many research questions concerning each 
of these. 	let us discuss each in turn. 
a. 	problem-solving 
our somewhat hierarchical organization of problem-solvers and models seems a natural  even if 
ad hoc  solution to organizing complex behavior. are there alternatives  will the use of theoremproving techniques provide enough generality to 

-1-

permit a s i n g l e general-purpose problem-solver  or w i l l several   s p e c i a l i s t   theorem-provers be needed to gain the required e f f i c i e n c y   
       other questions concern the use of theoremproving methods f o r problem-solving. how do they compare w i t h the  production methods  as used by the general problem solver  gps  or with the p r o cedural language approach as developed by fikes  1 perhaps some combination of a l l of these w i l l prove superior to any of them; perhaps more experience w i l l show that they are only s u p e r f i c i a l l y d i f f e r e n t . 
　　　another question i s : to what l e v e l of d e t a i l should behavioral plans be made before part of the plan is executed and the r e s u l t s checked against perceptual information  although t h i s question w i l l not have a single answer  we need to know upon what f a c t o r s the answer depends. 
       our problem-solving research w i l l also be d i r e c t e d at methods f o r organizing even more complex robot behavior. we hope eventually to be able to design robot systems capable of performing complex assembly tasks r e q u i r i n g the i n t e l l i g e n t use of t o o l s and other m a t e r i a l s . 
b. modelling 
       several questions about models can be posed: even if we continue to use a number of problems o l v e r s   must each have i t s own model  to what extent can the same model serve several problemsolvers  when a perceptual system discovers new i n f o r m a t i o n about the w o r l d   should it be entered d i r e c t l y i n t o a l l models concerned  in what form should i n f o r m a t i o n be stored in the various models  should p r o v i s i o n s be made for f o r g e t t i n g old i n formation  can a robot system be given a simple 
model of i t b own problem-solving a b i l i t i e s   ensuing research and experience w i t h our present system should help us with these questions. 
c. v i s u a l 	perception 
       the immediate v i s i o n problems involve i n c l u d ing more t e s t s in the object i d e n t i f i c a t i o n program to complete unfinished a n a l y s i s   and removing the r e s t r i c t i o n to non-overlapping o b j e c t s . beyond these improvements there are s t i l l longer range problems to be s o l v e d . the scene analysis programs i m p l i c i t l y store i n f o r m a t i o n about the world in t h e i r s t r u c t u r e . changes in the r o b o t ' s world can r e q u i r e extensive changes to the whole program. what program o r g a n i z a t i o n would minimize these problems  how can the scene analysis program i n t e r r o g a t e and use f a c t s stored in the model to advantage  since   f a c t s   obtained from e i t h e r the model or the subroutines are subject to e r r o r   it is n a t u r a l to accompany them by a confidence measure. how should these confidences be computed and how should they be combined  since  loosely speaking  we operate under conditions of strong s t a t i s t i c a l dependence  how can we augment the current r e p e r t o i r e of subroutines w i t h others to make use of such p r o p e r t i e s as c o l o r   t e x t u r e and range  future v i s i o n research w i l l be devoted to answering questions such as these. 
       the main theme of the p r o j e c t has been  and w i l l continue to be  the problem of system i n t e g r a t i o n . in studying robot systems that i n t e r a c t with the r e a l w o r l d   it seems extremely important to b u i l d and program a r e a l system and to provide it w i t h a r e a l environment. whereas much can be learned by s i m u l a t i n g c e r t a i n of the necessary funct i o n s  we use t h i s s t r a t e g y r e g u l a r l y     many important issues are l i k e l y not to be a n t i c i p a t e d at a l l in s i m u l a t i o n s . thus questions r e g a r d i n g   say  the f e a s i b i l i t y of a system of i n t e r a c t i n g a c t i o n u n i t s f o r c o n t r o l l i n g a r e a l robot can only be confronted by a c t u a l l y attempting to c o n t r o l a r e a l robot with such a system. questions regarding the s u i t a b i l i t y of candidate v i s u a l processing schemes can most r e a l i s t i c a l l y be answered by experiments w i t h a system that needs to  see  the r e a l w o r l d . theorem-proving techniques seem adequate f o r s o l v ing many   t o y   problems; w i l l the f u l l g e n e r a l i t y of t h i s approach r e a l l y be e x p l o i t a b l e f o r d i r e c t ing the automatic c o n t r o l of mechanical equipment i n r e a l - t i m e   
　　　the questions that we have posed in t h i s sect i o n are among those that must be answered in order to develop u s e f u l and v e r s a t i l e robot systems. experimenting w i t h a f a c i l i t y such as we have described appears to be the best way to e l i c i t the proper questions and to work toward t h e i r answers. 
