
we show that the trace of an exhaustive dpll search can be viewed as a compilation of the propositional theory. with different constraints imposed or lifted on the dpll algorithm  this compilation will belong to the language of d-dnnf  fbdd  and obdd  respectively. these languages are decreasingly succinct  yet increasingly tractable  supporting such polynomial-time queries as model counting and equivalence testing. our contribution is thus twofold. first  we provide a uniform framework  supported by empirical evaluations  for compiling knowledge into various languages of interest. second  we show that given a particular variant of dpll  by identifying the language membership of its traces  one gains a fundamental understanding of the intrinsic complexity and computational power of the search algorithm itself. as interesting examples  we unveil the  hidden power  of several recent model counters  point to one of their potential limitations  and identify a key limitation of dpllbased procedures in general.
1 introduction
knowledge compilation has been a key direction of research in automated reasoning  selman and kautz  1; marquis  1; selman and kautz  1; cadoli and donini  1; darwiche and marquis  1 . when propositional theories are compiled into a suitable target language  some generally intractable queries may be answered in time polynomial in the size of the compilation. compiling combinational circuits into obdds  for example  allows functional equivalence to be tested in polynomial time  or constant time if the same variable order is used   bryant  1 . more recent applications of compilation can be found in the fields of diagnosis and planning  involving the use of the dnnf language  darwiche  1a; barrett  1; palacios et al.  1 .
¡¡propositional satisfiability  sat   on the other hand  has been an area of no less importance  or activity. aside from its theoretical significance as the prototypical npcomplete problem  sat finds practical applications in many areas of artificial intelligence and computer science at large. while sat algorithms have substantially improved over the decades  many of them continue to build on what is known as the dpll search  davis et al.  1   for examples  see complete sat solvers in the 1 sat competition: http://satlive.org/satcompetition/1/ .
¡¡this paper sets out to demonstrate a deep connection between sat solving and knowledge compilation. in the first direction  we show how advances in search-based sat algorithms will carry over  via an exhaustive version of dpll  to compiling propositional theories into one of several tractable languages. we start by pointing out that the trace of an exhaustive dpll search  recorded compactly as a dag  can be viewed as a compiled representation of the input theory. with different constraints imposed or lifted on the search process  we then show that the compilation will be in the language of d-dnnf  fbdd  and obdd  respectively. these languages are known to decrease in succinctness: a propositional theory may have a polynomial-size representation in d-dnnf  but not in fbdd; or in fbdd  but not in obdd  darwiche and marquis  1 .
¡¡in the second direction  we formulate two principles by which the intrinsic complexity and computational power of a dpll-based exhaustive search is related to the language membership of its traces. applying these principles  we point out that several recent model counters are doing enough work to actually compile theories into d-dnnf. we also discuss a potential limitation on the efficiency of these model counters  as well as knowledge compilers using similar algorithms  based on the fact that these algorithms only generate traces in a specific subset of d-dnnf. finally  we note that the efficiency of all dpll-based exhaustive search algorithms are inherently limited by their inability to produce traces beyond d-dnnf. this realization is significant because some important computational tasks  such as existential quantification of variables and computation of minimum-cardinality models  could be efficiently accomplished with a weaker representation known as dnnf  a strict superset of d-dnnf.
¡¡under our uniform dpll-based framework for knowledge compilation  the power of successful modern sat techniques is harnessed  including sophisticated conflict analysis  clause learning  faster detection of unit clauses  and new branching heuristics. we also discuss caching methods specific to the needs of compilation and tailored to the desired target compilation language  as well as structure-based complexity guarantees. we finally relate our experimental results on imple-
 a  nnf	or	 b  decision node
or
 x ¦Á x ¦Â
 c  alternatively 
	 a b  b a	c  d d  c	¦Á¦Â
figure 1: an nnf sentence and a decision node.
mentations of the three respective compilers to the theoretical succinctness relations of the corresponding languages.
¡¡the remainder of the paper is organized as follows. section 1 reviews a number of propositional languages concerned in this work and their theoretical roles and relations in knowledge compilation. in section 1  we describe a uniform framework for knowledge compilation  with regard to these languages  based on recording the trace of an exhaustive dpll search  and discuss its implications on our understanding of the complexity and computational power of various search algorithms. we report experimental results in section 1 and conclude in section 1.
1 target compilation languages
a logical form qualifies as a target compilation language if it supports some set of nontrivial queries  usually including clausal entailment  in polynomial time. we will review in this section several target compilation languages relevant to the present paper  and refer the reader to  darwiche and marquis  1  for a more comprehensive discussion.
¡¡the languages we shall describe are all subsets of the more general negation normal form  nnf . a sentence in nnf is a propositional formula where conjunction  and  ¡Ä   disjunction  or  ¡Å  and negation  not     are the only connectives and negation only appears next to a variable; sharing of subformulas is permitted by means of a rooted dag; see figure 1a.
¡¡we start with the dnnf language  which is the set of all nnf sentences that satisfy decomposability: conjuncts of any conjunction share no variable. our next language  ddnnf  satisfies both decomposability and determinism: disjuncts of any disjunction are pairwise logically inconsistent. the formula of figure 1a  for example  is in d-dnnf.
¡¡the fbdd language is the subset of d-dnnf where the root of every sentence is a decision node  which is defined recursively as either a constant  1 or 1  or a disjunction in the form of figure 1b where x is a propositional variable and ¦Á and ¦Â are decision nodes. note that an equivalent but more compact drawing of a decision node-shown in figure 1c-is widely used in the formal verification literature  where fbdds are equivalently known as binary decision diagrams  bdds  that satisfy the test-once property: each variable appears at most once on any root-to-sink path  gergov and meinel  1 . see figure 1c for an fbdd example using this more compact drawing.
table 1: polytime queries supported by a language.   means  not supported unless p=np  and   means  do not know. 
lang.co¡Ìvace¡Ìimeqsectme¡Ìdnnf d-dnnf fbdd
obdd
obdd ¡Ì
¡Ì
¡Ì
¡Ì¡Ì 
¡Ì
¡Ì
¡Ì¡Ì
¡Ì
¡Ì
¡Ì¡Ì 
¡Ì
¡Ì
¡Ì   
¡Ì 
¡Ì 
 
 
¡Ì ¡Ì 
¡Ì
¡Ì
¡Ì¡Ì
¡Ì
¡Ì
¡Ì¡¡the obdd language is the subset of fbdd where all sentences satisfy the ordering property: variables appear in the same order on all root-to-sink paths  bryant  1 . see figure 1d for an obdd example. for a particular variable order    we also write obdd  to denote the corresponding obdd subset where all sentences use order  .
¡¡having an option among target compilation languages is desirable  despite their succinctness relations which may be known. the reason is that the succinctness of a language often runs counter to its tractability-that is  the set of queries supported in polynomial time-and the best choice may depend on the task at hand. given this trade-off between the two criteria  the rule of thumb  according to  darwiche and marquis  1   is to choose the most succinct language that supports the desired set of queries in polynomial time  in some cases the support of transformations  such as boolean operations  is also a consideration .
¡¡table 1 lists a set of polynomial-time queries of interest supported by each of these languages; the twoletter abbreviations stand for the following eight queries  respectively: consistency  validity  clausal entailment  implicant  equivalence  sentential entailment  model counting  model enumeration  darwiche and marquis 
1 .
¡¡interestingly  this table offers one explanation for the popularity of obdds in formal verification where efficient equivalence testing  among other things  is often critical. although more succinct  d-dnnf and fbdd are not known to admit a polynomial-time equivalence test  a polynomial-time probabilistic equivalence test is possible  darwiche and huang  1; blum et al.  1  . note also that although there is no difference between d-dnnf and fbdd to the extent of this table  the question mark on the equivalence test  eq  could eventually be resolved differently for the two languages.
¡¡in the following section we will use the notion of recording the trace of a dpll search to establish an important link between sat and knowledge compilation  providing a uniform framework for compiling knowledge into some of these languages. from this point of view we will then discuss our new understanding of the complexity and computational power of algorithms based on exhaustive dpll.
1 dpll with a trace
we start with the basic dpll search as in  davis et al.  1 . to facilitate our subsequent discussion of variants of this algorithm  we will omit unit resolution from the pseudocode.  all our discussions  however  are valid in the presence of unit resolution; see also the following two footnotes. 
 a  cnf
x1 ¡Åx1 x1 ¡Å x1 ¡Åx1
 x1 ¡Åx1 ¡Åx1
figure 1: exhaustive dpll with a trace.
¡¡algorithm 1 is a summary of dpll for sat. it works by recursively doing a case analysis on the assignment to a selected variable  lines 1 : the theory is satisfiable if and only if either case results in a satisfiable subtheory.  |x=1   |x=1  denotes the cnf obtained by replacing all occurrences of x with 1  1  in   and simplifying the formula accordingly. in effect  this algorithm performs a search in the space of variable assignments until it finds one that satisfies the given cnf formula or realizes that no satisfying assignment exists.1
¡¡now consider extending algorithm 1 so that it will enumerate all satisfying assignments-by always exploring both branches of line 1-rather than terminate on finding the first one. figure 1b depicts the search tree of this exhaustive version of dpll on the cnf of figure 1a  under some particular variable ordering. we are using a dotted  solid  line to denote setting the variable to 1  1   and will refer to the corresponding branch of the search as the low  high  branch. note that each leaf of this tree gives a partial variable assignment that satisfies the theory regardless of the values of any unassigned variables  and the whole tree characterizes precisely the set of all satisfying assignments.

1
¡¡¡¡to incorporate unit resolution into this simplified picture where all assignments are by decision  one can assume that when a chosen decision variable  line 1 of algorithm 1  has been implied by unit resolution  the algorithm will simply proceed down the right branch according to the implied value of the variable  noting that the other branch leads to unsatisfiability. one may also assume that in choosing a decision variable  those already implied by unit resolution will be favored  although this would represent a restriction on the search traces  which we describe shortly  that can be possibly generated.
algorithm 1 dpll   : returns satisfiability of cnf  
1: if there is an empty clause in   then
1:	return 1
1: if there is no variable in   then
1:	return 1
1: select variable x of  
1: return dpll  |x=1  or dpll  |x=1 
¡¡as the title of this paper suggests  we like to think of this complete search tree  also known as a termination tree or decision tree  as the trace left by the exhaustive dpll search. such a trace corresponds to the portion of the search space actually explored by a particular execution of the algorithm. furthermore  the trace can be viewed as a compiled representation of the original cnf formula  because it uniquely identifies the propositional theory-by specifying its models.
¡¡from the viewpoint of knowledge compilation  however  a search trace recorded in its present form may not be immediately useful  because it will typically have a size proportional to the amount of work done to produce it. answering even a linear-time query on such a compilation  for example  would be as if one were running the whole search over again.
¡¡this problem can be remedied by reducing the trace from a tree to a dag  with repeated applications of the following two rules:  i  isomorphic nodes  i.e.  nodes that have the same label  same low child  and same high child  are merged;  ii  any node with identical children is deleted and pointers to it are redirected to either one of its children  bryant  1 .
¡¡if we apply these reduction rules to the tree of figure 1b  and rename  sat/unsat  to  1   we will get the dag of figure 1c  in this particular example the first rule only applies to the terminal nodes and the second rule does not apply . observe that this dag is none other than a propositional theory in the language of fbdd. and this is no accident!
1 compiling cnf into fbdd
we are in fact in possession of a cnf-to-fbdd compiler  described more formally in algorithm 1. the main difference from the original dpll is on line 1: we always explore both branches  and the newly introduced function  get-node  provides a means of recording the trace of the search in the form of a dag. specifically  get-node will return a decision node labeled with the first argument  having the second argument as the low child  and having the third argument as the high child. note that lines 1 have been modified to return the terminal decision nodes  instead of the boolean constants.
¡¡we point out that the amount of space required by algorithm 1 to store the fbdd is only proportional to the size of the final result. in other words  it will never create redundant nodes to be reduced later. this is because the two reduction rules are built-in by means of a unique nodes table  well-known in the bdd community  somenzi  release 1 . specifically  all nodes created by get-node are stored in a hash table and get-node will not create a new node if  i  the node to be created already exists in the table  that existing node is returned ; or  ii  the second and third arguments are the same  either argument is returned .
algorithm 1 dpllf   : compiles cnf   into fbdd  dpll is lowercased to distinguish it from algorithm 1  its full version 
1: if there is an empty clause in   then
1:	return 1-sink
1: if there is no variable in   then
1:	return 1-sink
1: select variable x of  
1: return get-node x  dpllf  |x=1   dpllf  |x=1  

¡¡
¡¡caching. despite the use of unique nodes which controls the space complexity  algorithm 1 still has a time complexity proportional to the size of the tree version of the search trace: portions of the dag can end up being explored multiple times. to alleviate this problem  one resorts to formula caching  majercik and littman  1 .
¡¡algorithm 1 describes the same cnf-to-fbdd compiler  but now with caching: the result of a recursive call dpllf    will be stored in a cache  line 1  before being returned  indexed by a key  computed on line 1  identifying  ; any subsequent call on some  1 will immediately return the existing compilation for   from the cache  line 1  if  1 is found to be equivalent to    by a key comparison on line 1 .
¡¡in practice  one normally focuses on efficiently recognizing formulas that are syntactically identical  i.e.  have the same set of clauses . various methods have been proposed for this purpose in recent years  starting with  majercik and littman  1  who used caching for probabilistic planning problems  followed by  darwiche  1  who proposed a concrete formula caching method in the context of knowledge compilation  then  bacchus et al.  1; sang et al.  1  in the context of model counting  and then  huang and darwiche  1; darwiche  1  who proposed further refinements on  darwiche  1 .
1 from fbdd to obdd
we now turn to obdd as our target compilation language. note that in algorithm 1  dpll is free to choose any variable on which to branch  line 1 . this corresponds to the use of a dynamic variable ordering heuristic in a typical sat solver  in keeping with the spirit of fbdd compilation.
¡¡not surprisingly  a cnf-to-obdd compiler can be obtained by switching from dynamic to static variable ordering: the new compiler will take a particular variable order ¦Ð as a second argument  and make sure that this order is enforced when constructing the dag. see line 1 of algorithm 1.
¡¡caching. naturally  any general formula caching method  such as the ones we described earlier  will be applicable to algorithm 1. for this more constrained compiler  however  a special method is available where shorter cache keys can be used to reduce the cost of their manipulation. the reader is referred to  huang and darwiche  1  for details of this method  which allows one to bound the number of distinct cache keys  therefore providing both a space and a time complexity bound. in particular  due to this specific caching scheme  the space and time complexity of compiling obdds
algorithm 1 dpllf   : compiles cnf   into fbdd
1: if there is an empty clause in   then
1:	return 1-sink
1: if there is no variable in   then
1:	return 1-sink
1: key = compute-key   
1: if  result = cache-lookup key   1= null then
1:	return result
1: select variable x of  
1: result = get-node x  dpllf  |x=1   dpllf  |x=1  
1: cache-insert key  result 
1: return result
was shown to be exponential only in the cutwidth of the given cnf. a variant caching scheme allows one to show a parallel complexity in terms of the pathwidth  cutwidth and pathwidth are not comparable .
¡¡classical obdd construction. we emphasize here that algorithm 1 represents a distinct way of obdd construction  in contrast to the standard method widely adopted in formal verification where one recursively builds obdds for components of the system  or propositional theory  to be compiled and combines them using the apply operator  bryant  1 . a well-known problem with this latter method is that the intermediate obdds that arise in the process can grow so large as to make further manipulation impossible  even when the final result would have a tractable size. considering that the final obdd is really all that one is after  algorithm 1 affords a solution to this problem by building exactly it  no more and no less  although it may do more work than is linear in the obdd size  both because inconsistent subproblems do not contribute to the obdd size  and because the caching is not complete . an empirical comparison of this compilation algorithm and the traditional obdd construction method can be found in  huang and darwiche  1 .
1 from fbdd to d-dnnf
although any fbdd is also a d-dnnf sentence by definition  it remains a reasonable option to compile propositional theories into d-dnnf only  given its greater succinctness. considering that d-dnnf is a relaxation of fbdd  we can obtain a d-dnnf compiler by relaxing a corresponding constraint on algorithm 1. specifically  immediately before line 1  we need not insist any more that a case analysis be performed on some variable x of the formula; instead  the following technique of decomposition can be utilized. see algorithm 1
¡¡as soon as variable instantiation finishes without contradiction  we will examine the remaining cnf formula  and partition it into subsets that do not share a variable  line 1 . these subsets can then be recursively compiled into d-dnnf  lines 1  and conjoined as an and-node  line 1 . note that decomposition takes precedence over case analysis: only when no decomposition is possible do we branch on a selected variable as in regular dpll  lines 1 .

1
¡¡¡¡when unit resolution and clause learning are both integrated into this algorithm  an issue arises regarding implications via learned clauses that span otherwise disjoint components. see  sang et al.  1  for more discussion on this issue.
algorithm 1 dpllo    ¦Ð : compiles cnf   into obdd¦Ð
1: if there is an empty clause in   then
1:	return 1-sink
1: if there is no variable in   then
1:	return 1-sink
1: key = compute-key   
1: if  result = cache-lookup key   1= null then
1:	return result
1: x = first variable of order ¦Ð that appears in  
1: result = get-node x  dpllo  |x=1  ¦Ð   dpllo  |x=1  ¦Ð  
1: cache-insert key  result 
1: return result

¡¡note that our relaxation of algorithm 1 has resulted in a new type of node  returned by get-and-node on line 1. the old get-node function  line 1  still returns decision nodes  in a relaxed sense  as their children now are not necessarily decision nodes  in the form of figure 1c. the unique nodes technique can also be extended in a straightforward way so that isomorphic and-nodes will not be created.
¡¡we point out here that algorithm 1 only produces sentences in a subset of d-dnnf  because it only produces a
¡¡special type of disjunction nodes-decision nodes  again in the relaxed sense . recall that d-dnnf allows any disjunction as long as the disjuncts are pairwise logically inconsistent. we will come back to this in the next subsection.
¡¡static vs. dynamic decomposition. algorithm 1 suggests a dynamic notion of decomposition  where disjoint components will be recognized after each variable split. this dynamic decomposition was initially proposed and utilized by  bayardo and pehoushek  1  for model counting and adopted by a more recent model counter  sang et al.  1 .  darwiche  1; 1  proposed another  static  method for performing the decomposition by preprocessing the cnf to generate a decomposition tree  dtree   which is a binary tree whose leaves correspond to the cnf clauses. each node in the dtree defines a set of variables  whose instantiation is guaranteed to decompose the cnf into disjoint components. the rationale is that the cost of dynamically computing a partition  line 1  many times during the search is now replaced with the lesser cost of computing a static and recursive partition once and for all. this method of decomposition allows one to provide structure-based computational guarantees as discussed later  and can be orders of magnitude more efficient on some benchmarks  including the iscas1 circuits.1

1
¡¡¡¡one may obtain results to this effect by running the model counter  sang et al.  1   version 1  available at http://www.cs.washington.edu/homes/kautz/cachet/  on benchmarks used in  darwiche  1 . it should be noted that the two programs differ in other aspects  but the decomposition method appears to be the major difference. note also that using dpll for compilation incurs higher overhead than for model counting due to the bookkeeping involved in storing the dpll trace.
algorithm 1 dplld   : compiles cnf   into d-dnnf
1: if there is an empty clause in   then
1:	return 1-sink
1: if there is no variable in   then
1:	return 1-sink
1: components = disjoint partitions of  
1: if |components|   1 then 1:	conjuncts = {}
1:	for all  c ¡Ê components do
1:	conjuncts = conjuncts ¡È {dplld  c }
1:	return get-and-node conjuncts  1: key = compute-key   
1: if  result = cache-lookup key   1= null then
1:	return result
1: select variable x of  
1: result = get-node x  dplld  |x=1   dplld  |x=1  
1: cache-insert key  result 
1: return result
¡¡caching. several caching methods have been proposed for d-dnnf compilation  the latest and most effective of which appeared in  darwiche  1 . however  we refer the reader to  darwiche  1b  for a caching scheme that is specific to the dtree-based decomposition method. this scheme is not competitive with the one in  darwiche  1  in that it may miss some equivalences that would be caught by the latter  yet it allows one to show that the space and time complexity of ddnnf compilation is exponential only in the treewidth of the cnf formula  as compared to the pathwidth and cutwidth in obdd compilation . interestingly  no similar structure-based measure of complexity appears to be known for fbdds.
¡¡relation to and/or search. recent work has explored the long established notion of and/or search to process queries on belief and constraint networks  dechter and mateescu  1b; 1a . an and/or search is characterized by a search graph with alternating layers of and-nodes and decision-nodes  the former representing decomposition and the latter branching. the dags produced by algorithm 1 are indeed and/or graphs and  conversely  the and/or search algorithms described in  dechter and mateescu  1b; 1a  can be used to compile networks into the multi-valued equivalent of d-dnnf. this implies that these and/or search algorithms are capable of many more tasks than what they were proposed for-model counting  or other equivalent tasks such as computing the probability of a random variable assignment satisfying the constraint query . we discuss this further in the following subsection.
1 understanding the power and limitations of dpll
the main proposal in this paper has been the view of exhaustive-dpll traces as sentences in some propositional language. this view provides a unified framework for knowledge compilation as we have shown earlier  but we now show another major benefit of this framework: by using known results about the succinctness and tractability of languages  one can understand better the intrinsic complexity and computational power of various exhaustive dpll procedures.
¡¡consider a particular variation of dpll  say dpllx  and suppose that its traces belong to language lx. we then have:
1. dpllx will not run in polynomial time on formulas for which no polynomial-size representation exists in lx.
1. if dpllx runs in polynomial time on a class of formulas  then dpllx  with some trivial modification  can answer in polynomial time any query on these formulas that is known to be tractable for language lx.
¡¡take for example the model counters recently proposed in  bayardo and pehoushek  1; sang et al.  1   which employ the techniques of decomposition and  the latter also  caching. a simple analysis of these model counters shows that their traces are in the d-dnnf language  for specific illustrations  see the ddp algorithm of  bayardo and pehoushek  1  and table 1 of  sang et al.  1  . therefore  neither of these model counters will have a polynomial time complexity on formulas for which no polynomial-size representations exist in d-dnnf.
¡¡in fact  one can take this analysis one step further as follows. these model counters  and the compiler of  darwiche  1   actually produce traces in a strict subset of d-dnnf  call it d-dnnf1  which employs a syntactic notion of determinism; that is  every disjunction in their trace has the form  x ¡Ä ¦Á  ¡Å   x ¡Ä ¦Â   where x is a splitting variable. the ddnnf language  however  does not insist on syntactic determinism: it allows disjunctions ¦Ç ¡Å¦× where ¦Ç ¡Ä¦× is logically inconsistent  yet ¦Ç and ¦× do not contradict each other on any particular variable x. if d-dnnf1 turns out to be not as succinct as d-dnnf  then one may find another generation of model counters and d-dnnf compilers that can be exponentially more efficient than the current ones.
¡¡as an example of the second principle above  consider the query of testing whether the minimization of a theory   implies a particular clause ¦Á  min    |= ¦Á  where min    is defined as a theory whose models are exactly the minimumcardinality models of  . this query is at the heart of diagnostic and nonmonotonic reasoning and is known to be tractable if   is in d-dnnf. therefore  this query can be answered in polynomial time for any class of formulas on which the model counters in  bayardo and pehoushek  1; sang et al.  1  have a polynomial time complexity. similarly  a probabilistic equivalence test can be performed in polynomial time for formulas on which these models counters run in polynomial time.
¡¡beyond dpll. dpll traces are inherently bound to be nnf sentences that are both deterministic and decomposable. decomposability alone  however  is sufficient for the tractability of such important tasks as clausal entailment testing  existential quantification of variables  and cardinalitybased minimization  darwiche and marquis  1 . dpll cannot generate traces in dnnf that are not in d-dnnf  since variable splitting  the heart of dpll  amounts to enforcing determinism. it is this property of determinism that provides the power needed to do model counting  #sat   which is essential for applications such as probabilistic reasoning. but if one does not need this power  then one should go beyond dpll-based procedures; otherwise one would be solving a harder computational problem than is necessary.
1 experimental results
by way of experimentation  we compiled a set of cnf formulas into obdd  fbdd and d-dnnf  both to show the practicality of the dpll-based compilation approach and to relate the results to the theoretical succinct relations of the three languages. the benchmarks we used include random 1-cnf and graph coloring problems from  hoos and stutzle  1¡§    and a set of iscas1 circuits.1 the compilation was done with the obdd compiler of  huang and darwiche  1   using the mince variable order  aloul et al.  1   an fbdd compiler we implemented according to subsection 1 using the vsids variable ordering heuristic  moskewicz et al.  1   and the d-dnnf compiler of  darwiche  1 .
table 1: compiling cnf into obdd  fbdd  and d-dnnf.
cnfnumber ofobddfbddd-dnnfnamemodelssizetimesize	timesize	timeuf1111.1	1uf1111.1	1uf1111.1	1uf1111.1	1uf1111.1	1uf1111.1	1uf1111.1	1uf11--1.1	1uf11--1.1 1flat1111.1	1flat1111.1	1flat1111.1	1flat1111.1	1flat1111.1	1flat1111.1	1flat11----1.1flat11--1.1	1flat11--1.1	1s11.111.1s11.111.1s11	1--1.1s11.1 11.1s11.1 11.1s11.1 11.1s1	-	-	-	-1.1s11.1	11.1s11.1	11.1¡¡the results of these experiments are shown in table 1  where the running times are given in seconds based on a 1ghz cpu. the size of the compilation reflects the number of edges in the nnf dag. a dash indicates that the compilation did not succeed given the available memory  1gb  and a 1-second time limit. it can be seen that for most of these propositional theories  the compilation was the smallest in d-dnnf  then fbdd  then obdd; a similar relation can be observed among the running times. also  the number of instances successfully compiled was the largest for d-dnnf  then fbdd  then obdd. this tracks well with the theoretical succinctness relations of the three languages.  however  note that fbdd and d-dnnf are not canonical representations and therefore compilations smaller than reported here are perfectly possible; smaller obdd compilations are  of course  also possible under different variable orderings. 
¡¡we close this section by noting that the implementations of these knowledge compilers bear witness to the advantage of the dpll-based framework we have described. the first compiler is based on an existing sat solver  moskewicz et al.  1   and the other two on our own implementation of dpll  all three benefiting from techniques that have found success in sat  including conflict analysis  clause learning  and data structures for efficient detection of unit clauses.
1 conclusion
we established an important relationship between sat and knowledge compilation  based on studying the trace of an ex-
¡¡
haustive dpll search. this relationship provides a uniform framework for compiling propositional theories into various languages of interest  and throws light on the intrinsic complexity and computational power of various dpll-based algorithms. as interesting examples  we unveiled the  hidden power  of several recent model counters and discussed one of their potential limitations. we also pointed out the inability of exhaustive dpll to produce traces in strict dnnf  which limits its power from a knowledge compilation point of view.
acknowledgments
we thank the reviewers for commenting on an earlier version of this paper. this work has been partially supported by nsf grant iis-1 and muri grant n1-1.
