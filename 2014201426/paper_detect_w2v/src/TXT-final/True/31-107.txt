 
knowledge compilation is the process by which an initial theory  with respect to which inference is intractable is transformed into one or more  approximate  or equivalent theories with respect to which inference can be performed efficiently. selman and kautz introduced horn lowest upper bound  lub  approximations in  sk1   and generalized them in  ks1; sk1  to a number of target languages other than horn. in this paper  we analyze the problem of knowledge compilation for arbitrary clausal target languages  generalizing in several ways previous results. we provide general characterizations of the lub that are independent of the target language; analyze the properties of the generate-lub algorithm of selman and kautz  proving its correctness for any target language closed under subsumption  including a wide family of languages which guarantee polynomial size approximations ; and generalize the procedure to arbitrary target languages. we also examine some computational aspects of these procedures and the quality of horn approximations. 
1 	introduction 
knowledge compilation is the process by which an initial theory ♀ with respect to which inference is intractable is transformed into one or more  approximate  or equivalent theories with respect to which inference can be performed efficiently. the notion of horn approximations  more specifically of horn lowest upper bound  lub  and horn greatest upper bound s   glb   was introduced by selman and kautz in  sk1 . the idea is to map   compile   a clausal propositional theory into two horn theories   is a weakest horn theory that entails and is the strongest horn theory entailed by these  approximate theories  can be used to efficiently answer queries about the consequences of  as reviewed below. the key observation is 
   *much of this work was performed while the author was a post-doc at stanford university's computer science department. alternative email address: delval c1.stanford.edu. 
1 	knowledge representation 
that queries with respect to  can be answered in polynomial time  since both theories are horn  rather than using an exponential algorithm to decide whether 
 though the cost of obtaining  and eglb can and usually will be very high  which justifies thinking of it as a preprocessing or compilation step   this cost can be amortized over a sufficiently large set of queries about which can be answered more efficiently after compilation. 
　this framework was generalized by kautz and selman to approximations written in target languages other than horn  see  ks1; sk1   and section 1 below . a key aspect of the framework is given by two procedures that generate the lub and glb in the given target languages  respectively the generate-lub and generateglb algorithms. selman and kautz provide no proof of correctness for generate-lub either in its more restricted form  which generates horn lubs  or in the more general form in which it generates other kinds of lubs. in this paper  we establish general conditions for 
generate-lub to be correct; these conditions are strictly weaker than those cited by kautz and selman  as the target language needs to be closed under subsumption  but not under resolution. we thus improve and correct selman and kautz's analysis of their general framework for knowledge compilation  greatly expanding the set of target languages for which the generic generate-lub algorithm yields correct results. this set now includes  in particular  any subset of k-cnf closed under subsumption  for example the k-horn language  dp1 ; an important feature of such languages is that the lub has guaranteed polynomial size. in addition  a simple modification of the algorithm allows us to prove it correct with respect to arbitrary propositional clausal target languages. 
　the structure of this paper is as follows. in the next section  we review the main concepts of lub and glb knowledge compilation. section 1 offers two general characterizations of the lub for arbitrary target languages; in particular  completeness with respect to queries in the target language fully characterizes the lub. section 1 analyses the generate-lub algorithm  establishing general conditions for its correctness  and generalizing it to deal with arbitrary clausal target languages. in section 1 we consider some complexity issues  followed by an analysis of the quality of horn approxi-


	delval 	1 


1 	knowledge representation 
 the language of definite clauses  for example  cannot express unsatisfiable theories: the valuation which assigns true 
1
　　 except that in the  else  clause we should also delete to every symbol satisfies any set of definite clauses. on the from et any clause subsumed by c if we do not want to end other hand  any language closed under subsumption includes up with some subsumed clauses. the empty clause. 
	delval 	1 


   consider now any theory with an exponential number of prime implicates  examples can be found in  kt1; cm1  . by adding two new positive literals to every clause  any such theory will have an exponential number of non-horn prime implicates  since those two literals will occur in any clause entailed by the theory; in fact  all prime implicates will be non-horn. and since the language of horn clauses is closed under resolution  all these prime implicates will be computed and stored by generate-l t -lub  for lt - horn  despite the fact that the horn-lub of any such theory will be empty. similar or identical examples can be used to show that the same holds for many other target languages. these include  to begin with  subsets of the horn language  such as definite clauses  k-horn clauses  horn with at most k literals  for any fixed k   and unit clauses  at most one literal perclause ; but also languages such as reverse horn  clauses with at most one negative literal  and its subsets  binary clauses  clauses with at most two literals   or a language that allows only a subset of the symbols of the language. the following corollary summarizes this discussion. 
corollary 1 the generate-lt-lub algorithm requires exponential space  hence time   even in cases in which it outputs the empty theory as the ct-lub. 
　cases in which generate-l t -lub has exponential size output have already been described in  ks1a   corollary 1 is stronger in that the exponential space requirements are not justified by the size of the output  in other words  time and space are exponential in the combined size of input and output. notice furthermore that for all the above mentioned theories with empty lub  generate-lt-lub reduces to a brute force prime implicate algorithm  which is likely to be extremely inefficient. 
1 	the quality of approximations 
there are at least two important aspects in assessing the quality of an approximate theory: its size  and its  close-
1 	knowledge representation 
ness  to the original theory. in this section  we discuss the latter from a worst case perspective. for concreteness  we will focus on horn approximations. we show that the weakening of the original theory represented by the lub can result in failing to answer an exponential number of queries  and in adding an exponential number of models to those of the original theory. we leave the reader the task of identifying further target languages for which the conclusions of this section apply. 
example 1 the examples used to establish corollary 1 have an exponential number of prime implicates which do not follow from the horn lub. there is therefore an exponential number of queries entailed by the original theory that the lub will fail to answer. 

 in the last example  it is possible to work around the problem by observing that can be brought to horn form by an uniform renaming of all symbols  i.e. is in the class  renamable horn  and is therefore tractable. the next example does not have this property. 
lub has 1 - 1 models  or 1 - 1 more models than the original theory. any model containing at least one negative literal will satisfy the lub  rather than only those models with an even number of positive literals. 
example 1 	there is also at least one fairly natural class of theories that yield inadequate approximations. 


pendently of quantitative measures  moreover  we would argue that there is a qualitative sense in which these approximations are inadequate - for example  if xj denotes the position of an object  the compiled theory may be consistent with the object mysteriously vanishing  i.e. with xj having no value   so a robot may have no reason to look for it. note incidentally that combining the lub with a glb would be of little help for such problems  as any glb of must entail a complete assignment of values to every variable  because all horn strengthenings of the various clauses xj are positive unit clauses.  
in conclusion  it is easy to find examples which defeat 
horn approximations  even in theories  such as csps  with a very small proportion of non-horn clauses. while this is an important fact  we emphasize that it in no way precludes a profitable use of horn approximations for large classes of theories which do not include the ones discussed here. 
1 	discussion 
tn this paper  we have provided an analysis of approximate knowledge compilation on the basis of the approach introduced by selman and kautz in  sk1; ks1; sk1 . highlights of the analysis  which generalize the results of selman and kautz in a number of ways  are: 
  the characterization of the l t -lub for arbitrary clausal languages used as target of the compilation  both in terms of completeness with respect to ltqueries and of prime lt-implicates; 
  an analysis and proof of correctness of the generic procedure generate-l t -lub  as introduced in  ks1   showing that it can be used without modification for any target language closed under subsumption; 
  for languages not closed under subsumption  we have shown that the main computational attractive of the procedure  namely the avoidance of resolutions among clauses of the target language  can be preserved  providing a new generic algorithm that computes the l t - l u b for arbitrary propositional clausal languages. 
　as already mentioned  there is an important class of languages  closed under subsumption but not under resolution  for which  contrary to what was previously thought  generatelt-lub gives correct results. this class of languages includes any subset of k-cnf closed under subsumption; the lub with any such subset as target language has polynomial size. of special interest among them is the language k-horn  which is tractable  and which has been explored in detail as an approximation tool in  dp1; ks1b . 
　we have also analyzed some points which are crucial to the evaluation of the concepts and procedures discussed. first  either computation of the lt-lub  or inference in lt is likely to be intractable. second  for many target languages generate-l t -lub has exponential space and time requirements even in cases where the l t - l u b is the empty theory. finally  we have analyzed the quality of horn approximations in terms of closeness to the initial theory. 
　in the category of related work  the great debt of this paper to the work of selman and kautz should be obvious to any reader; credit for specific results or proofs due to them has been explicitly indicated where appropriate. we should also mention that our results may have consequences for other approaches to knowledge compilation  specifically for the work of del val in  dv1 . del val presents procedures to compile propositional theories into equivalent  not just approximate  theories for which unit resolution is complete. one of these procedures uses the skeleton of the generate-l t -lub algorithm as instantiated for the horn target language  and the question arises whether the cited procedure can be generalized to take advantage of the results of this paper. 
　finally  let us mention the work of inoue  lno1  on linear resolution procedures for finding the  characteristic clauses   prime lt-implicates  of a  production field   target language lt - just like us  inoue considers the problem for arbitrary target languages  providing procedures that compute the characteristic clauses of a theory for any target language closed under subsumption  what he calls an  stable  production field . interestingly  he discusses multiple applications of the notion of characteristic clauses  which suggest a somewhat different perspective on the goals of compilation. for example  in abduction we are interested in certain kinds of entailments of the database  namely the implicates that involve only literals describing allowable hypothesis  abducibles  and some literal to be explained in terms of those hypothesis. similarly  in determining the circumscriptive consequences of a propositional theory we are interested in particular in clauses that involve only positive literals whose symbol is being  minimized  or literals made from the set of  fixed   non-variable symbols. in diagnosis  we are interested in the  minimal conflicts   that is  the prime implicates that contain only ab-literals. in either case  the desired class of implicates can be designated as target language lt; the generate-l t -lub procedure can then be used to ensure completeness for queries expressed in lt- one can also think of less sophisticated 
	delval 	1 
but equally useful task specific reasons for choosing the target language. for example  we may want to compile the input-output behavior of a device assembled by means of some other more elementary components described propositionally. one possibility is to compute the prime implicates of the theory resulting from combining the theories corresponding to the device's components  throwing out all those which involve  internal  variables which do not refer to the initial input or final output of the assembled device. the other possibility  which may require much less space  is to designate the clauses involving only input and output variables as target language  and compile using the standard generatel t -lub. 
   in summary  achieving completeness with respect to a given target or query language is a worthwhile goal for lub compilation. even if the query language is not tractable  one can benefit from ignoring irrelevant parts of the initial theory  and there is always the possibility of further compiling the lub into a tractable form in a second pass  possibly using some other method. there is in fact an interesting alternative when the query language  is not tractable but its complement is closed under resolution. in this case  we can choose the complement as target language lt for generate-l t -lub  and obtain in  the prime implicates of  which belong to lq  as implied by theorem 1   hence the cq-lub. this guarantees completeness and tractability  relative to the size of   with respect to lq  while avoiding all resolutions among clauses which do not belong to the query language. as an example  one can obtain the k-quasi-horn lub  in prime implicate form  by designating its complement as target language; no pairs of non k-quasi-horn clauses will ever be resolved together by generate-l t -lub in this case. 
   both inoue's linear resolution procedure and the procedures of this paper can be used to obtain completeness with respect to the selected query language  inoue's results are limited in this regard to languages closed under subsumption  though the results of the present paper can be easily used to lift this restriction . there are two main differences. first  the restrictions imposed by his version of linear resolution have no analogous in generate-ltlub; the latter is therefore much more likely to generate redundant resolution derivations. however  and this is the second crucial difference  his procedure does compute all prime lt-implicates  producing  compiled  theories which in general will require much more space than those generated by the lub algorithm; this fact limits the usefulness of the linear resolution procedures for compilation purposes. 
