 
this paper describes the application of explanationbased learning  a machine learning technique  to the sri core language engine  a large scale general purpose natural language analysis system. the idea is to bypass normal morphological  syntactic and  partly  semantic processing  for most input sentences  instead using a set of learned rules. explanation-based learning is used to extract the learned rules automatically from sample sentences submitted by a user and thus tune the system for that particular user. by indexing the learned rules efficiently  it is possible to achieve dramatic speedups. 
　　performance measurements were carried out using a training set of 1 sentences and a separate test set of 1 sentences  all from the atis corpus. a set of 1 learned rules was derived from the training set. these rules covered 1 percent of the test sentences and reduced the total processing time to a third. an overall speed-up of 1 percent was accomplished using a set of only 1 learned rules. 
1. introduction* 
 when interacting in natural language it is easy to fall into assuming that the range of sentences that can be appropriately processed will approximate what would 
be understood by a human being with a similar collection of data. since this is not true  the user ends up adapting to a collection of idioms - fixed patterns that experience has shown will work.   winograd & flores 1  p. 1 . 
many users of natural language systems tend to phrase themselves in the same way most of the time. the optimization technique described in this paper is based on this observation: if one can speed up the processing for this limited set of  typical phrases   one will save a lot of computing time. the idea is that one can bypass normal 
　this work was sponsored by sics  the swedish institute of computer science  and the greater part of it was carried out while the second author was resident there. 
processing for most input sentences  instead using a set of learned rules  and thus vastly speed up the processing. this will be done paying the price of a small overhead when no learned rule proves applicable. the set of learned rules is extracted automatically  using explanation-based learning  ebl   from training sentences given by a user. by learning the rules from real user interaction  the set of rules is tailored so as to capture the user's way of expressing himself. the hope is that a comparatively small set of language constructions will account for the majority of the sentences actually submitted to the system. once the rules have been learned  it is important to store them in a way that minimizes the search for applicable ones at run-time  that is to index the learned rules so that quick access is guaranteed 
in this paper we focus on the experiments carried out at 
sri menlo park on the atis corpus  a large size lest corpus extracted from real user interaction. we have tried to make the paper as self-contained as possible. due to space limitations  however  we can only sketch out the main principles  and must refer to previous articles for the details. this is especially the case in sections 1 and 1. in section 1  we offer a description of what explanation-based learning means in the context of natural language processing and in section 1 we address the important issue of how to assure quick access to the learned rules. the architecture of the ebl module is shown in section 1 and in section 1 we describe the set-up of the experiments and report the results. in section 1 we summarize our experiences and reflections on the subject of applying ebl to natural language processing and point to questions that deserve further attention. 
　　this is the third time we have applied explanation-based learning to a natural language processing system. the target system this time was the sri core language engine  cle   a large scale general purpose natural language analysis system developed by sri cambridge  alshawi et al.  1    alshawi  forthcoming . in previous works  we have applied the ebl technique to the syntactic analysis phase of another large-scale nl system   rayner & samuelsson  1   and to syntactic and semantic processing in the chat-1 system   rayner & samuelsson  1 . here  ebl was used to bypass morphological and syntactic analysis  and semantic analysis up to and including generation of quasi-logical forms  qlfs . 
samuelsson and rayner 
1. what ebl means in nl processing 
explanation-based learning is a machine-learning technique  closely connected to other techniques like macro-operator learning  chunking  and partial evaluation; a phrase we have found useful for describing the method to logic programmers is example-guided partial evaluation; a phrase that may appeal to a natural-language person is grammar rule chunking. explanation-based learning is well-described in a number of articles  mitchell et a/.  1    dejong & mooney  1  and  minton et a/.  1   to which we refer the reader who wants to understand the general principles; here  we will only summarize briefly what ebl means in the context of natural-language processing. in section 1  we offer an intuitive description of the explanation-based learning method used and in section 1 we give an illustrative example of it using a toy nl system. 
1 informal description of the ebl scheme 
   our implementation is based on the scheme that has now become the standard model for  ebl in prolog   as exemplified by the systems described in  hirsch  1    van harm1en & bundy  1  and  kedar-cabelli & mccarty  1 . 
　　we learn rules from training examples. in this domain  a training example is a string that can be derived from the grammar  together with a trace of the derivation: in terms more commonly used by natural-language experts  a sentence and its associated parse-tree. the basic idea is first to define a class of operational goals; by this  we mean the sub-goals which will be allowed to appear on the right-handside of learned rules. having done this  a successfully processed example is generalized by  notionally  constructing the derivation tree  and then chopping off all the branches rooted in operational goals   un-instantiating  variables bound by these goals; the leaves in the new   generalized  derivation will be the conditions in the learned rule  and thus by construction operational   and the new root will be a more general version of the goal corresponding to the root in the example. in the simplest  one-level  version of the method  operational goals will coincide with lexical ones as in the toy grammar example of section 1. 
   we have extended the model in three important ways. firstly  we allow for multiple levels of operationality: the goals that are operational at one level  and thus appear on the right-hand side of the learned rules  are target concepts at the next level down  and thus appear on the left-hand side here . in the implemented system  there are three levels of operationality  corresponding to the goals  prove string x is a sentence    prove string x is a noun phrase  np   and  prove string x is a word . thus rules at the top level define sentences as concatenations of words and np's  rules at the second level define np's as concatenations of words  and rules at the lowest level define words as lists of morphemes. the choice of levels was fairly arbitrary  and it is certainly conceivable  especially at the highest level  to consider other possible choices for operational goals. we have already experimented  for example  with defining relative clauses as operational  rayner and samuelsson  1 . secondly  we carry out generalization in two stages  first running the 
learning and knowledge acquisition 
problem in a  dirty  representation which has been optimized for efficiency  to get a trace  and then using the trace together with a  clean  version of the same domain theory  see section 1 . this method makes it much easier to produce generalizations from complex domain theories. thirdly  we demonstrate that the use of domain-specific indexing methods can provide a satisfactory solution to the  utility problem . this is explained in detail in section 1. 
1 example of a derivation 
   we turn now to an example of single-level explanationbased generalization. 
   we transform our grammar into a horn-clause theory by encoding it as a definite clause grammar  pereira & shieber 1 ; this involves adding two extra arguments to each non-terminal  which represents the input string before and after the non-terminal is parsed. diagram 1 shows a toy example of such a grammar  closely based on the talk program in the above-mentioned book. the a symbol represents lambda abstraction. 

diagram j  toy grammar and lexicon 
   this grammar can parse a few trivial sentences like john sleeps or john loves a cat  and associate with each a corresponding expression in first-order logic; we will now show what happens when the second sentence is generalized with respect to the lexicon. 
   we first construct the normal derivation tree for the original sentence  or to be more exact for the proposition 

    the first argument - the logical form - is to be read as  an a such that  cat a  is also such that  loves john a .   
   the derivation tree will be as shown in diagram 1  where each node has been marked with the number of the clause resolved on at that point. we then want to generalize away the lexical information present. to do this  we perform the same series of resolution steps  but this time omitting all resolutions with unit clauses of the type lex     . here the operational goals coincide with the calls to lexical predicates. this will yield us the conditional derivation tree in diagram 1  where the assumptions have been written in bold-face. 
   
　　　the suspended calls to operational goals are then collected to form the learned rule in diagram 1. since the new tree represents a valid derivation for any values of the  meta-  variables a  b  c  d and agr  it thus constitutes a proof of the learned rule. 
s quant c y  d y   bay    a b c d    :lex a.pn   lex b tv 1-s     lex c det agr    lex d n agr  . 
diagram 1  generalized derived rule 
   thus we are now in possession of a learned rule which can handle not only john loves a cat  but also many other sentences  for example mary hates the winter and charlie has a ferrari  or could handle  had there been entries for these words in the lexicon. 
1. indexing the learned rules 
once we have derived a large set of learned rules  it will be too time consuming to simply try one after the other until we stumble upon the proper one. all computing time gained from using learned rules  instead of normal processing  will be devoured by costly linear search among the learned rules. this is the utility problem  minton 1 . our solution is to use a domain-specific indexing method to ensure quick access to the learned rules. 
   the obvious way to filter out most learned rules as inapplicable  is to inspect the syntactic categories of the 
samuetsson and rayner 
   
input siring: all strings a particular learned rule can handle must match the sequence of lexical constraints in the rule. 
   in the following two sub-sections  we describe briefly two such indexing schemes. from timing studies we have concluded that the key indexing scheme is good for one-level rules and that the decision-tree indexing scheme is good for two-level rules. therefore  we used the decision-tree indexing scheme for the sentence and noun phrase rules and the key indexing scheme for the morphological rules. 
1 the decision-tree indexing method 
   the decision-tree indexing method stores the learned rules in a decision-tree  using a demand driven algorithm dispatching on lexical category to access them. below we sketch out how the algorithm for finding a learned rule works;  rayner & samuelsson  1  contains a more detailed  pseudo-code description of it. 
to find a learned rule at run-time we do the following: 
we start at the root node in the decision-tree  and inspect the lexical category of the first input constituent. if the start node has an arc labelled with this category  we follow it to the child node. if it doesn't we fail. ii we were successful  we then inspect the category of the next input word. if our current tree node has an arc labelled with this category  we follow it  and so we continue until all of the input words are consumed. for the last input word  we search for an arc to a leaf node. this node will be the reference to a learned rule. 
   it is important to realize that lexical ambiguity does not in general give rise to an exponentially growing search space; an incorrect guess of a word's lexical category will normally find no arc to dispatch on  and thus terminate immediately. 
   the rule derived from john loves a cat in section 1 will be indexed as rule1 in the diagram below. the other rules correspond to john sleeps  john loves mary and the cat sleeps respectively. 

modifications that these  pops'' and  pushes  introduce  the scheme will work as in the one-level case 
   in our implementation we used one tree for top-level rules and another one for noun phrase rules. to avoid repeating work  it proved useful to include a well-formed sub-string table for the derived noun phrases. 
1 the key indexing method 
   the key indexing scheme scheme first maps the lexical constraints of the learned rule to a sequence of key letters. these letters are chosen such that distinct lexical constraints are associated with distinct key letters. in our example  assume that pn goes to e  for eigen-name   tv goes to v for verb  det goes to d and n goes to n. then  the sequence of letters is collapsed into an atomic key  in our case evdn. the learned rules are stored in a table indexed by such keys  utilizing the  first functor  indexing mechanism of most prolog systems. a more thorough description and analysis of this indexing scheme can be found in  rayner & samuelsson  1 . 
1. design of the ebl module 
   we will now describe briefly how the ideas in the previous section were realized for the sri core language engine  cle . it was interesting to note that the cle supplied most of the primitives necessary for our purposes. 
1 overall architecture 
   the ebl module can naturally be divided into its compile-time and run-time parts. the learning component is the compile-time part. for convenience  we will sub-divide it into two smaller components. these are the generalizer  which performs the actual extraction of learned rules and the rule compiler  which indexes the learned rules to ensure quick access to them at run-time. 

   
diagram 1  one-level decision-tree indexing scheme 
   when using multiple rule-levels  we extend the scheme by including arcs labels with  pushes  to trees indexing the lower level rules. these lower level trees will have  pop  arcs back to the tree that called them. apart from the slight 
learning and knowledge acquisition 
diagram 1  the learning component. 
   the run-time component of the system is the pattern matcher  which processes input sentences using the set of learned rules or establishes that no applicable combination of learned rules exists. 
   

diagram 1  the run-time component. 
we now examine the components in turn. 
1 the generalizer 
   the generalizer is a simple prolog meta-interpreter and the generalization is from a computational perspective essentially the parsing of a sentence with a dcg. usually  this means that care has to be taken to ensure that parsing efficiency is acceptably high  and even more importantly that infinite recursions are not caused by left-recursive grammar rules. however  the generalization is not driven simply by the target goal and  by recursion in the generalization algorithm  successive sets of sub-goals; it is guided by the derivation trace of a training example. thus the parsing is actually deterministic. the sentence is first subjected to the normal analysis component to find a derivation trace  which is then used to guide the dcg parser used by the generalizer. the top-level is thus schematically: learn a-rule sentence rule.subrules  :-
normal processing sentence logicalform trace   generalize trace rule subrules   
the trace is a tree of rule-ids encoding the derivation of 
logicalform from sentence. each rule-id refers to the dcg rule used at that resolution step. the dcg rule will have a lhs and a rhs. the generalizer re-does the resolutions of the derivation tree. with each rule-id it does one of the following: if the corresponding lhs is a non-operational goal  it expands it according to the dcg rule and calls itself recursively for each rhs goal. if the rule is a production rule for np's  or if it is a morphological rule  it saves the lhs of the dcg rule to be added to the rhs of the main learned rule and returns to top-level to learn a sub-rule for the lhs goal of the dcg rule  guided by the remaining sub-tree rooted in this rule-id. if the dcg rule is a lexicon look-up  the lhs goal of the dcg rule is saved and added to the rhs of the learned rule. this is basically the same generalizer as the one presented in  van harmelen & bundy  1 . 
1 quick access to learned rules 
   if the pattern-matcher is to be able to use the learned rules efficiently  they must be indexed in order to ensure quick access to them. this is what the rule compiler does. in general  when adding a rule to the data base of learned rules  it first checks to see if the new rule is subsumed by any previously added rule  or if is identical to one  in both cases the new rule is not added. also  it determines if the new rule subsumes some old rule already present among the learned rules  in the latter case the old rule is removed and the new one takes its place. 
the pattern matching process is divided into two steps: 
   in the first step  words are built from word stems and affixes. the rules performing this task are accessed by key indexing  since a one-level rule consumes its entire input in one go. 
in the second step  phrases are constructed from words. 
the rules for doing this are accessed using the decision-tree indexing scheme  as described in section 1. 
1. performance studies 
the main results of this paper concern the relationship between the performance and the size of the set of learned rules  when both the rules and the test data are acquired from real user interaction. such experiments were carried out at sri menlo park using the atis corpus. 
1 set-up of the experiments 
   here we describe the set-up of the experiments carned out at sri menlo park. they were conducted to determine how the coverage  the rule access time and the overall performance gain depend of the number of learned rules. 
   the coverage is defined as the fraction of a test corpus successfully handled by the ebl module. the performance gain is simply the ratio of the total processing time for the test set using normal processing  divided by the total time using the learned rules. 
   in these experiments  we did not bypass morphological analysis. the main reason for this was that the morphology is multiplied out into the lexicon in the sri menlo park version of the cle. 
   we worked with the atis corpora  large sets of sentences extracted from user interaction using  wizard of oz  techniques. we from these collected a large set of sentences that the cle could attribute with a semantic interpretation. we then split the set into two sub-sets. the larger  consisting of 1 sentences  was used as a training set. the other  with a size of one hundred exactly  became the test set. the sets were split by randomly choosing 1 numbers. first we learned a set of rules from the training set the 1 sentences yielded 1 learned rules. we then applied the ebl run-time component  equipped with this set of learned rules  to the training set and ordered the rules according to their frequency of use  dividing them into groups of 1 rules each according to their usefulness. thus rules which could be applied to many sentences  and therefore  intuitively  represented constructs  typical  of the domain  were added first. 
samuelsson and rayner 
   
   when measuring the run-time performance  we started with no learned rules and added each group of rules in turn to the rule data base. before adding a new score of rules we determined the coverage and measured the success- and failure times of the ebl module  using the test set. we then continued to add learned rules and repeated the measurements until all learned rules had been added. for comparison  we performed timing studies on normal processing. we could then extract the desired results from the experimental data. training and performance measurements were carried out in 
 batch mode   i.e no learned rules were added during training  primarily to make it simpler to get the typicality figures. 
　　the timing studies were carried out using quintus 1 running on a sparc1+ workstation with a 1 mbyte local disc. the prolog work-space was set to the maximum of what the unix system could provide  in order not to have rule space expansions corrupt the timing results. garbage collect was enforced before  and disabled during  every measurement. predicate calls of short duration were re-run a multitude of times  the entire cpu time measured and divided with the number of runs. 
1 experimental results 
   it is interesting to note that  at compile-time  1 learned rules  which together amount to 1 kbyte  could account for 1 sentences. from the run-time part of the experiment we find that the coverage reaches 1 percent at 1 rules  as shown in diagram 1. 

diagram 1. the coverage as a function of the number of learned rules 
   the coverage swiftly rises to 1 percent for 1 learned rules and then seems to increase slowly  but steadily  with about 1 percent additional coverage for every ten rules. presumably  rules which were sufficiently atypical would not be worth adding. however  diagram 1 shows quite clearly that performance was still going up even when the last of the 1 rales were added. it is very probable that even better figures could have been achieved by training with a larger set of examples  extracting a correspondingly larger set of rules. 
   diagram 1 shows the look-up time normalized by the time for corresponding normal processing. white diamonds indicate successful look-up  black failure. with 1 rules  the median bypass time is 1 times less than that of normal processing and the median overhead is 1 percent. 

diagram 1. the ebl look-up times as a function of the number of learned rules 
   there is a close to linear increase in look-up time with the number of learned rules. the large apparent variation of the failure times after 1 rules is probably not statistically significant  since there are only a dozen or so outstanding sentences left in the test-set at this stage that are not already covered by learned rules. 
   the ebl look-up times are small compared to normal processing times - the median look-up times lie between 1 and 1 percent of normal processing time. this results in a substantial overall speed-up  as can be seen in diagram 1. 

diagram 1. the overall processing times as a function of the number of learned rules 
   the overall speed-up increases slightly sub-linearly in the number of learned rules. the system is twice as fast with 1 learned rules and with 1 rules the system runs three 
   
times faster. 
learning and knowledge acquisition 
   
1. 	summary  	conclusions 	and 	further directions 
on the basis of our experiences this far  we think there are good reasons to take ebl seriously as a practical and generally applicable way of optimizing natural language systems; the speed-ups achieved are considerable at a low overhead. even more importantly  it has been possible to apply the ebl method to all nl systems attempted this far  even though one had several characteristics undesirable from this point of view. 
   an important question  when dealing with some systems  is the extent to which it is possible to compress the generated rules; one idea is to keep only the derivation traces and redo the resolution steps at run-time  since generalization is deterministic and has been observed to be about as fast as pattern-matching. from this we conclude that most savings result from guiding the search. since one is essentially trading space for time  this may be an economical compromise. 
   another  rather obvious  thing to do is to use the learned rules  backwards   that is for paraphrasing  by constructing an indexing scheme for logical forms. 
   two interesting software engineering challenges are to integrate the ebl scheme more closely with the target system to allow the normal analysis component to use partial results from the ebl module and vice versa  and to allow incremental adaption of the system by letting the learning component run as a background process. one will then also have to deal with the problems connected with user interaction and utility analysis. 
   finally  we mention briefly a line of research that we have just begun to investigate  namely to incorporate the learned rules into a probabilistic language model of the kind used by speech recognition systems. although our work to date is still only at a preliminary stage  it appears that this idea may potentially be very promising. 
acknowledgements 
the performance measurements described in section 1 could not have been carried out without the help and support of many people at sri menlo park. we are most grateful for being given this opportunity. in particular  we would very much like to thank robert c. moore  douglas b. moran and john dowding for all their help and for all the time and effort they spent making these experiments possible. we would also like to thank hiyan alshawi of sri cambridge for valuable advice. 
