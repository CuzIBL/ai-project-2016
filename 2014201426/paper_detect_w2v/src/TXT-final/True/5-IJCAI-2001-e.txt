
recently tremendous advances have been made in the performance of ai planning systems. however increased performance is only one of the prerequisites for bringing planning into the realm of real applications; advances in the scope of problems that can be represented and solved must also be made. in this paper we address two important representational features  concurrently executable actions with varying durations  and metric quantities like resources  both essential for modeling real applications. we show how the forward chaining approach to planning can be extended to allow it to solve planning problems with these two features. forward chaining using heuristics or domain specific information to guide search has shown itself to be a very promising approach to planning  and it is sensible to try to build on this success. in our experiments we utilize the tlplan approach to planning  in which declaratively represented control knowledge is used to guide search. we show that this extra knowledge can be intuitive and easy to obtain  and that with it impressive planning performance can be achieved.
1	introduction
for a long time ai planning systems were either capable of solving only trivial problems  or required extensive engineered knowledge to solve problems that were still relatively simple. recently  however  tremendous performance gains have been made. these gains have come from the development of new approaches to planning  and most recently from the improvementof the old idea of forward chaining. as a result  the fastest planning system in the recent aips-1planningcompetition  aips  1 was a forward chaining planner that was able to generate plans containing 1 steps in less than 1 seconds. this level of performance was achieved on simple test domains. nevertheless  if performance within one or two orders of magnitude of this can

　　this research was supported by the canadian government through their nserc and nce-iris programs.
be achieved in real application domains  tremendous possibilities for the practical application of ai planning will be created.
　however  performance is not the only impediment to the practical application of ai planning systems. the scope of problems they can represent and solve is also a problem. the planners in the competition were restricted to problems in which actions could be modeled by a set of simultaneous updates to the predicates describing the world. this is the model of planning inherited from the strips action representation; it is also the model used by the adl  pednault  1  representation. adl simply provides more flexibility in specifying the set of predicate updates that an action generates  so that  e.g.  this set can be conditional on the current world.
　real world applications require modeling a number of more sophisticated features  including uncertainty  sensing  varying action durations  delayed action effects  concurrently executing actions  and metric quantities. in this paper we address the last four issues. in particular  we present an approach to modeling and solving planning problems containing metric quantities  actions of varying duration  actions with delayed effects  and concurrently executing actions. our approach is based on extending the forward chaining approach to planning. in our experiments we demonstrate that  in particular  the tlplan approach to planning  bacchus & kabanza  1  can be successfully extended to deal with such problems.
　metric quantities have never been a significant problem for forward chaining planners  and in fact the tlplan system has been able to deal with metric quantities since its original 1 implementation. hence  the ability to deal with metric quantities is not a contribution of this paper. however  the manner in which tlplan deals with metric quantities is unique and has many advantages that help support the other extensions that are new to this paper.
in the sequel we first review and motivate the manner in
tlplan extends the strips/adl representationto deal with metric quantities. then we develop our approach to modeling actions with delayed effects from which the ability to model concurrent actions follows naturally. the approach we present can be used in any forward chaining planner. we compare our approach to some of the other work in this area 
and then present some empirical results to demonstrate the potential of our approach and the capabilities of the planner

we have developed. unfortunately it proved to be impossible to run controlled experiments to compare our planner with other systems that have been developed. so we have instead made an effort to present a suite of experiments and provide all of the necessary data sets so that a reusable experimental basis can be established for future work.
1	functions
we take planning problems as including a fully specified initial state  a goal  and a set of actions for transforming states to new states. a solution to the problem is a sequence of actions that when applied to the initial state yields a sequence of states satisfying the goal. the goal might simply be a condition on the final state of the sequence  or it might place conditions on the entire sequence of states.1
　a forward chaining planner is one that searches in the space generated by applying to each state all actions whose preconditions are satisfied by   starting at the initial state . a forward chaining planner expands this space as it searches for a sequence of actions that transform to a state  or sequence of states  satisfying the goal. in other words  forward chaining planners treat the planning problem as a state-based search problem.
　the key difference between the planning problem and a generic search problem  however  is that planning assumes a particular representation of states and operators. in planning states are represented as databases of predicate instances  and operators are represented by specifying the set of updates they make to the database  state  to generate a new state  database . in other words  planning uses a factored representation of the state in which each transition updates only a few of the state's components. it is this factored representation that has allowed the development of planning specific notions such as goal-regression.
　in planning  the closed world assumption is standard: any predicate instance not in the database is assumed to be false. under this assumption the state databases become first-order models against which arbitrary first-order formulas can be efficiently evaluated  halpern & vardi  1 . given a firstorder formula containing some set of free variables   we can efficiently find all tuples of bindings for that make true in a state: this is the same problem as computing
the relation specified by an sql query in databases.
　a natural semantics for operators specified in the strips or adl notation is to view them as being update queries. each operator has a precondition that is a first-order formula containing the free variables . every binding for the variables such that is true in a state generates an action that can be applied to to yield a new state. the strips/adl action representations have the property that a set of fully instantiated predicates to add and delete from can be computed simply by evaluating formulas in . for example  if an adl operator  drive  t  l  l'   drive truck  t from location  l to  l'  contains the conditional update1
 forall   o   in  o  t   and  add  at  o  l'    del  at  o  l    
 i.e.  update the at property of all objects  o in  t   then given a binding for  t   l  and  l'  i.e.  a fixed action instance  by computing the set of bindings for  o that satisfy  in  o  t  in all instances of at that must be changed can be determined. notice that the specific predicate instances in the update are determined by replacing the terms  o   l  and  l' by their values. in this case these terms are variables and their values  interpretations  are determined by the current variable bindings.
　first-order languages typically include functions. terms can then be constructed by applying functions to other terms.
thus a natural extension to the strips/adl representation is to remove its function-free restriction. for every function f the state can include in its database a relation specifying the value of f on its various arguments. first-order formulas can be evaluated just as before: whenever we encounter a term like  f t1 ... tk  in a formula we replace it with its value by recursively evaluating each of the ti and then looking up the resulting tuple of values in the relation specifying f. we specify updates to these function values by asserting equalities that must hold in the next state. now  e.g.  instead of describing the location of objects  x with an  at  x  l  relation  we could describe their location with a  loc  x  function. then the operator  drive  t  l  l'  could contain the conditional update
 forall   o   in  o  t   add  =  loc  o   l   
we use the convention that the function that is the first argument of the equality  loc  is the function to be updated  its arguments  the variable  o  are evaluated in the current state to determine which arguments of loc are to be updated  and the second argument  the term  l  is evaluated in the current state to determine the new value.
　functions whose values are numbers  and numeric functions like can now be accommodated in the same way. furthermore  the standard numeric functions like can be computed using existing hardware or software: we do not need to have a table of its values as part of the state's database.
　for example  if  capacity  t  is the fuel capacity of truck  t   fuel  t  is its current level of fuel  and  fuelused  is a  1-ary  function whose value in any state is the total amount of fuel used  then we can write an operator like
 refuel  t  with the update
 and
 add  =  fuel-used 
 +  fuel-used 
 -  capacity  t   fuel  t     
 add  =  fuel  t   capacity  t    
in the new state truck  t will have a full tank and we would have accounted for the amount of fuel put into its tank.
　adding functions to the action representation in this way  motivated directly by viewing operators as database updates  provides all the flexibility needed to model complex resource usage. for example  the following operators model fifo access to a fixed resource and also track the number of times the resource is used.  qhead  and  qtail  are 1 in the initial state   queue i  is a function whose value is the i'th request in the queue  and  serve  x  is a predicate true of  x if  x is currently being served.  qtail  will always be the total number of times the resource is used  and
 qhead   qtail  is always the number of items currently in the queue.
 def-adl-operator  enqueue-access  x 
 and  add  =  queue  qtail    x  
 add  =  qtail   +  qtail  1     
 def-adl-operator  dequeue-and-serve 
 pre    1  -  qtail   qhead      and
 del  serve  queue  qhead    
 add  serve  queue  +  qhead  1    
 add  =  qhead   +  qhead 1      
　in the literature addressing metric quantities  specialized notation has been developed for expressing resources  e.g.   wolfman & weld  1; kvarnstro：m  doherty  & haslum  1  . our argument is that such notation is not required. the natural extension of making functions first-class citizens along with standard operator preconditions provides a better solution.1 what we have just described is the manner in which tlplan has implemented functions since its original 1 version. functions as first-class citizens were also present in the original adl formalism  pednault  1   and  geffner  1  provides some other arguments in support of using functions.
1	modeling concurrent actions
forward chaining has proved itself to be a very fruitful basis for implementing high-performance planners. for example  the two fastest planners in the recent aips-1 planning competition  talplanner  doherty & kvarnstro：m  1   a planner that uses the tlplan approach  and fastforward  hoffmann  1  a planner using domain independent heuristics to guide its search  were both forward chaining planners. however  there is at least one aspect of forward chaining planners that seems to be problematic: they explore totally ordered sequences of actions. this is where they get their power: such sequences provide complete information about the current state and that information can provide powerful guidance for search. but modeling concurrent actions with linear sequences seems to be problematic. however it turns out that there is a surprisingly simple way of modeling concurrency with linear actions sequences.
　we associate with every state a time stamp  starting with a fixed start time in the initial state. the time stamp denotes the actual time the state will occur during the execution of a plan.
in a linear sequence of states a number of successive states may have the same time stamp. intuitively this means that the transitions between these states occur instantaneously  so the intermediate states are never physically realized. their existence is simply a convenient computational fiction.
　additionally  each state has an event queue. the event queue contains a set of updates  events  each scheduled to occur at some time in the future  of the state's time stamp . along any fixed sequence of states generated by a sequence of actions  each state inherits the pending events of its parent state. it might also queue up some additional events to be passed to its children. thus if we arrive at the same state via two different actions sequences we could generate two different event queues. we regard two states as being equal only if they have both the same database and the same event queue. thus  when the planner backtracks it backtracks to a state with a prior event queue  in effect backtracking the state of the event queue.
　as before  an action can be executed in a state only if its preconditions are satisfied by . applying to generates a new successor state . standard actions do not advance the world clock  so will have the same time stamp as . typically  it will have a different event queue  i.e.  what will happen in the future has changed   and a different database  i.e.  what is true  now  has changed . updates to 's database are used to model 's instantaneous effects  and updates to the event queue are used to model 's delayed effects.
　for example  consider the action of driving a truck  t from  l to location  l':
 def-adl-operator  drive  t  l  l' 
 pre   t   truck  t 
  l   loc  l 
  l'   loc  l' 
 at  t  l  
 del  at  t  l  
 delayed-effect
 /  dist  l  l'   speed  t  
 arrived-driving  t  l  l' 
 add  at  t  l'    
we can execute this action in if  t is a truck  both  l and  l' are locations  and  t is at location  l in . the instantaneous effect of the action is to delete the current location of the truck  and the delayed effect is to add the new location of the truck. the delayed effect is realized by adding an item to the event queue. the first argument of the delayedeffect specification is the event's time delta  the number of time units from the current time the event is scheduled to occur. this time delta is a term that will be evaluated in the current state. in this case it is the distance between the two locations divided by the speed of the vehicle. the next argument is simply a label for the event  designed to make the final plan more readable . the delayed effects are the subsequent arguments. in this case it is the addition of the new location of the truck. in general  delayed effects can be any kind of effect allowed in a normal action  including  e.g.  conditional effects.
　in addition to the standard actions there is one special action that advances the world clock: the unqueue-event
plan  s q  goal 
if  s	goal and q =   return s  else
s := s
s .prev := s
q := q
choice a	act : s	pre act 
s .action := a if a != unqueue-event
s := applyinstantaneousupdates s a  q := adddelayedevents q s a 
else
newtime := eventtime front q   s .time := newtime while eventtime front q    == newtime
         e := removefront q   s := applyeffect s  e  plan s  q  
figure 1: forward chaining search
action.1 this action moves time forward to the next scheduled event  removes all events scheduled for that new time and uses them to update the state's database. this realizes various delayed effects of previous actions. for example  eventually the arrival of  t at  l' will reach the front of the queue and will be dequeued. this will cause a transition to a new state in which the fact  at  t  l'  is added and the time is updated. if a set of events have been scheduled for the same time  they will all be dequeued and applied sequentially in fifo order.
　figure 1 specifies more precisely forward chaining search in this enhanced search space. the non-deterministic choice operator is realized by search. adddelayedevents examines the action  and for each delayed-effect in a evaluates the term specifying the delay of that effect. adding the time of the current state  s.time  gives the absolute time of the effect  and the effect is mergedinto the queue so as to keep the queue in time sorted order. the current variable bindings for the free variables in the effect are also stored along with the effect. if the chosen action is unqueue-event time is moved forward  and all effects scheduled for that time are removedfrom the queue and applied sequentially to the state. a goal state is a state whose database satisfies the goal and that has an empty event queue; we can find the sequenceof actions leading to that state by following the state's prev pointers.
　search for a plan is started by calling plan on the initial state. note that the queue need not initially be empty. instead it could contain some set of events that are going to occur in the future. the planner will then have to find a plan that negotiates around these future events. this also facilitates replanning where some previous actions cannot be canceled. this feature is similar to the ability of temporal refinement planners like ixtet  ghallab & laruelle  1  and rax  jo＞nsson et al.  1  to flesh out an initial set of temporal constraints.
　the choice of which action to try next is where heuristic or domain specific control comes into play. in the tlplan approach we restrict the set of possible action choices by requiring that the next state s satisfy the temporal control formula  see  bacchus & kabanza  1  for details .
　with delayed effects  concurrent actions are automatic. when an action is executed it generates a successor state in which its immediate effects have been made. this state  marks  the start of the action  and since it has the same time stamp as the previous state the action can be viewed as starting at the current time. after some stream of delayed effects have been executed the final delayed effect generates a state that  marks  the end of the action. depending on how we interleave the unqueue-event action with the ordinary actions we can start a whole series of actions at the same time  these actions can execute concurrently and some can end before others. thus at any particular time any number of actions can be executingconcurrently. if we only choose unqueueevent when there is no other action available  we will maximize the number of concurrent actions at each stage: each ordinary action whose precondition is satisfied will be started before the world clock is advanced. or we can achieve finer control over the degree of concurrency by controlling  via 
e.g.  a temporal control formula  when unqueue-event is chosen.
　in our approach all concurrency control is handled by action preconditions. typically the instantaneous effects of an action are used to modify the state so as to achieve concurrency control  while the delayed effects of an action are used to model physical achievements in the world. this is a low level but very powerful approach to concurrency control. for example  in the previous drive operator  the current location of the truck is immediately deleted. since this is also a precondition of drive  any attempt to concurrently drive the same truck to another location is blocked. more sophisticated situations are also quite straightforward to model  in part because of our general approach to functions and numeric computations.
　for example  consider a gas station with 1 refueling bays and a limited amount of fuel shared among these bays. let
 station-fuel  be the current amount of fuel at the station   bays-free  the number of bays currently free   capacity  v  the fuel capacity of a vehicle  and  fuel  v  the fuel in the vehicle. then the following actions model resource bounded concurrent access to the gas station:
 def-adl-operator  refuel  v  amount 
 pre
	  v 	 vehicle  v 
  amount   =  amount  -  capacity  v 
 fuel  v   
 and    1  bays-free  
    station-fuel   amount   
 add  =  station-fuel 
 -  station-fuel   amount   
 add  =  bays-free   -  bays-free  1   
 delayed-effect 1
 fueled  v  amount 
 and  add  =  bays-free 
　　　　　 +  bays-free  1     add  =  fuel  v   capacity  v      
the operator also demonstrates our system's ability to use functions to bind operator arguments. in this case  amount is bound to a function value computed from the binding of
 v.
　suppose in a state there are 1 vehicles and that various sets of these vehicles require more fuel that the station has. from a number of different sequences of concurrent refuel actions can be initiated. but in each of these sequences no more than 1 vehicles will be concurrently fueled  due to the instantaneous update of the  bays-free  resource  and no set of vehicles needing more fuel than available will be concurrently fueled  due to the instantaneous update of the  station-fuel  resource. in fact  it can be that after the first batch of 1 vehicles is concurrently fueled an additional batch of vehicles enter the station after 1 units of time have elapsed and the bays have become free.1 exactly which sequence of concurrent refueling appears in the plan will be determined by what sequences allow the goal to be achieved and the search strategy.
　the final plan will be a linear sequence of actions grouped into subsequences of actions each with the same time stamp. however  the linear sequencing is not a limitation of our approach. for example  a simple post analysis of these subsequences can be used to determine if the actions have to be started in the supplied order or if some other ordering can be used. for example  if no action in the subsequence affects the preconditions of another then they can be started in any order  or simultaneously. however  if starting the actions is near instantaneous in practice then there will be little to gain from such a post analysis. for example  say that one subsequence of actions to be executed at the same time is  drive truck1 loca locb  followed  drive truck1
locc locd   start driving two trucks concurrently  then it typically will make very little difference if we tell truck1 to start driving before telling truck1-the command to start driving takes negligible time in comparison to the actual drive.
　often what is required in these kinds of planning problems are goals that specify conditions over time. that is  specifying conditions on the final state is not sufficient. temporal refinement planners like ixtet  ghallab & laruelle  1  allow one to  e.g.  enforce that a predicate holds without interruption over a particular interval of time. in our approach if one specifies only a condition on the final state  there is no way of stopping the planner from inserting actions produce undesired intermittent effects-there is no way of telling the planner that these intermittent effects are undesirable. although we have not implemented it  there is no conceptual difficulty with combining our approach with our previous work on specifying temporally-extended goals  bacchus & kabanza  1 . with such a combination  an extremely rich set of extended conditions can be enforced on the final plan  includingthe typical conditionssupportedby temporalrefinement planners.
1	empirical results
we have implemented the above event-queue mechanism as an extension of the tlplan system  and tested our implementation using different versions of the metric logistics domain developed by  wolfman & weld  1 .
　using this domain allows us to make some empirical comparisons with previous work. unfortunately  it proved to be impossible to run controlled experiments with other planning systems  the systems and problems sets were not readily available  or the systems were not easily ported to our machine . therefore  the results we report are simply to demonstrate that our approach can efficiently solve large planning problems containing the features we are concerned with. however  we are reporting a range of results  and making the test sets available  bacchus  1  so as to provide an experimental base for future work.
　in the logistic domain there are a collection of packages that need to be transported to their final destination  trucks for moving packages between points in a city  and planes for moving packages between airports located in different cities. packages can be loaded and unloaded from vehicles and the vehicles can be moved between compatible locations.
　 wolfman & weld  1  added a fuel capacity for each vehicle  and a refueling action that fills up a vehicle given that the vehicle is located at a depot. in addition  each drivetruck operator consumes a fixed amount of fuel  each flyairplane operator consumes an amount of fuel based on the  fixed  fuel efficiency of planes and the distance between the two airports  and one is not allowed to move a vehicle to a location unless it contains enough fuel to get there.
　we take the tlplan approach to planning in which domain specific information is declaratively encoded in a temporal logic. unlike standard heuristics which try to measure the worth of a state  tlplan typically uses negative information that tells it that certain kinds of action sequences are flawed  kibler & morris  1 . this information is checked against the sequences generated during forward chaining  and any sequence satisfying a bad property is pruned from the search space. this approach to planning has proved to be extremely successful: in yields a level of planning performance that is an order of magnitude better than any other approach  and the approach has been applied to a wide range of different domains. in  bacchus & kabanza  1  an extensive set of examples and empirical results are presented to demonstrate both the performance of this approach and the fact that the requisite knowledge for many different planning domains is easily obtained and represented in the formalism.
　in the standard logistic world the control information needed is very simple.
1. don't move a vehicle to a location unless it needs to gothere to pickup or drop off a package.
1. don't move a vehicle from a location while it still contains a package that needs to be dropped off at that location.
1. a package needs to be picked up by a truck if it needs tobe moved to another destination in the same city.
1. a package needs to be picked up by a plane if it needsto be moved to another city.
1. a package needs to be dropped off from a truck if thetruck is at its goal destination or if the truck is at an airport and its goal destination is in another city.
1. a package needs to be dropped off from a plane if theplane is in the package's destination city.
each of these assertions can be easily encoded as a temporal logic formula  bacchus & kabanza  1   and with this collection of assertions the planner finds plans very efficiently. furthermore  this control knowledge is of such a simple form that it becomes possible  by looking at each action's effects  to predict whether or not an action will extend the current plan in such a way as to violate one of these assertions. as a result one can systematically convert the control rules into extra action preconditions  bacchus & ady  1 . this has the effect of blocking an action first  rather than executing it  generating the plan extension  and then determining that the extension is invalid. due to the extremely high branching factor in larger logistic problems  over a 1 applicable actions in each state on the harder problems   this  compiled one-step  look ahead improves planning performance by a couple orders of magnitude. in our experiments  we used a precondition encoding of these control rules.
　we used two sets of test problems. a set of four small problems  loga  logb  logc  and logd  utilized by wolfman in testing his lpsat system  and a collection of 1 much larger problems used in the aips1 planning competition.1 all of the experiments were run on a 1mhz piii machine with 1mb of memory. all times are reported in cpu seconds.
　in table 1 the first set of columns gives the time it takes the current version of tlplan to solve the original version of these problems  and the number of steps in the resulting plan. we then encoded wolfman's metric version  with fuel consumption  and ran the problems again. we used wolfman's loga-logd problems directly  and for the aips1 suite we added distances between the locations  fuel consumption rates and fuel tank capacities for the planes and trucks. we found that tlplan could solve these metric logistics problems very efficiently with the same controlknowledgeas used in the standard logistics world  along with the extra information
1. allow a vehicle to move to a depot if it needs fuel.
1. don't refuel a vehicle unless it needs more fuel to makea pickup or drop off.
1. don't move a truck or plane to a location in order topickup an object if there is already exists a similar vehicle at that location with sufficient fuel capacity to take it to its destination.
the times required to solve the fuel version of the logistic problems are shown in the second set of columns of the table. the data shows that our approach finds the metric problems not that much more difficult than the standard problems.  wolfman & weld  1  present a sat encoding approach to solving these metric logistic problems. their planner utilizes a combinationof sat solving and linear programming: the sat solver finds the plan while the linear program solver ensures that the plan satisfies the  linear  metric constraints. the solution times they report are approximately 1 sec. for loga  1 sec. for logb  1 sec. for logc and 1 sec. for logd  they also point out that their approach was faster than previous approaches . these times indicate that their approach scales poorly. interestingly  in examining the plans their system generated1 it was found that these plans used much more fuel  e.g.  1 units for the loga solution  and also contained many unnecessary moves  e.g.  moving a truck back and forth without using it to transport any packages. their system does not use domain specific control knowledge but some of the knowledge used here might be useful in improving the performance of their system.
　then  we took the metric logistics domain and made it concurrent  so that the domain contained both metric quantities and concurrent actions. in the concurrent version loads and unloads take 1 unit of time to complete  and multiple concurrent loads/unloads into the same vehicle are allowed  the same object cannot be manipulated concurrently . refueling a truck takes 1 unit of time  and an airplane takes 1 units. finally  driving a truck takes 1 units of time  and flying an airplane takes time that is dependent on the distance between the two locations. to the above control knowledge we added the extra information
1. a vehicle can be moved to a location if there is an object en route to that location  in a different type of vehicle  that can be transported by the vehicle.
this allows the planner to get the vehicles movingso that they can make progress towards the pickup location concurrently with the object they are to pickup. for example  the planner can start flying a plane to an airport while a truck is transporting an object to the airport that needs to be transported to another city. this decreases the duration of the plan. the last set of columns shows our results for this domain. in this case we show the duration of the plan as well as the length of the plan  number of actions . since the actions take at least 1 unit of time  it can be seen that highly concurrent plans are being found. the time to find a solution has also climbed  but not by much  and so has fuel consumption. this makes sense  as the concurrentplan will try to utilize more vehicles in order to maximize concurrency  and more vehicles means more fuel.
　another planning system that is capable of dealing with concurrent actions of different durations is the tgp system  smith & weld  1  that is based on graphplan. however  its underlying algorithms are considerably more complex than the approach we suggest here  and it cannot deal with metric quantities. we were able to run the tgp system on some simpler logistic problems involving varying action durations but without fuel consumption. we found that tgp could not solve any of loga-logd problems  when we removed the fuel consumption component  even when given an hour of cpu time. these results and the performance of wolfman's lpsat system  demonstrate that adding domain
problemstandardmetric fuelfuel+concurrentcpulen.cpulen.fuelcpudur.len.fuelloga11.11.1.11logb11.11.1.11logc11.11.1.11logd11.11.1.11x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111x-1.111111table 1: test results on versions of logisticsspecific control knowledge and utilizing our forward chaining approach allows us to move to another level of planning performance.
　there are two other planning systems that are quite similar to ours   pirri & reiter  1  and  kvarnstro：m  doherty  & haslum  1 . both of these planner utilize the tlplan approach and display good performance. however  both of these systems utilize a rich logical representation for actions and states  whereas the approach we present here can be utilized by any forward chaining planner with the much simpler strips/adl action representation.
　finally  temporal refinement planners are an alternate approach to planning with concurrent actions. the ixtet planner is an impressive system capable of dealing with resources and concurrent actions  ghallab & laruelle  1 . nasa's remote agent project rax also utilized a refinement planner. temporalrefinement planners operate by taking an initial plan that typically specifies the initial state and various goal conditions  and refining that plan by adding additional actions to achieve open conditions or constraints to protect other conditions. a key component of these planners is the use of constraint propagation to maintain the temporal constraints imposed on the plan during the refinement process. thus these planner search in a space of partially specified plans using constraint propagation to detect deadends  rather than in a space of fully specified worlds as in our approach. the rax planner also utilized extensive search control knowledge in order to achieve its good level of performance. however  the control knowledge was at a much lower level and was more procedural in style than that utilized by our approach. many of the standard concurrency control paradigms are easier to specify with a temporal refinement planner than in our approach. however  it should be possible to develop macros for our approach to encapsulate many of these paradigms thus easing the specification problem.
1	conclusion
forward chaining's ability to deal with metric quantities was already documented  but in this paper we have demonstrated that there is also a simple way of extending forward chaining to deal with concurrent actions. these two features can then be combined with other ideas like search control knowledge to yield a powerful approach to planning in the presence of concurrent actions of differing durations and resources.
　our empirical results show that complex and lengthy plans can be generated with our approach  and serve to demonstrate the potential of our approach. further verifying that potential is the subject of future work.
　other items of future work include  a  higher level constructs for concurrency control implemented as macros that can are expanded to the very general lower level constructs already supported by our system  and  b  access by actions to the event queue. this last is worth further explanation. consider a situation where a truck is being driven from location a to location b. at the start of the drive its arrival at location b is entered into the event queue. now it could be that location b only has capacity for one truck  thus a subsequent action should not be scheduled that would cause another truck to arrive at location b at the same time. checking this  precondition  involves querying the event queue. a different example is when via some other action or event the truck gets a flat tire en route. this will delay its arrival time. thus the  flat-tire  event must not only change the current state of the world but it must also alter events in the event queue. simply put actions must be able to treat the event queue just like the state's database: they must be able to query and update it. with this ability it becomes easier to model on-goingprocesses that can be interrupted and restarted  something that is cumbersomein our current model.
acknowledgments the referees providedsome very useful suggestions that helped improve the paper.
references
 aips  1  aips 1. artificial intelligence planning & scheduling 1 planning competition. http://www.cs.toronto.edu/aips1/
 bacchus & ady  1  bacchus  f.  and ady  m. 1. precondition control. available at http://www.cs.toronto.edu/ fbacchus/on-line.html
 bacchus & kabanza  1  bacchus  f.  and kabanza  f. 1. planning for temporally extended goals. annuals of mathematics and artificial intelligence 1-1.
 bacchus & kabanza  1  bacchus  f.  and kabanza  f. 1. using temporal logics to express search control knowledge for planning. artificial intelligence 1- 1.
 bacchus  1  bacchus  f. 1. on line experimental data sets. http://www.cs.toronto.edu/ fbacchus/tlplan.html
 doherty & kvarnstro：m  1  doherty  p.  and kvarnstro：m  j. 1. talplanner: an empirical investigation of a temporal logic-based forward chaining planner. in proceedings of time '1  ieee computer society  1.
 geffner  1  geffner  h. 1. functional strips: a more flexible language for planning and problem solving. in minker  j.  ed.  logic-based artificial intelligence. kluwer. in press.
 ghallab & laruelle  1  ghallab  m.  and laruelle  h. 1. representation and control in ixtet  a temporal planner. in proceedings of the international conference on artificial intelligence planning  1. aaai press.
 halpern & vardi  1  halpern  j. y.  and vardi  m. y. 1. model checking vs. theorem proving: a manifesto. in allen  j. a.; fikes  r.; and sandewall  e.  eds.  proceedings of the international conference on principles of knowledge representation and reasoning. san mateo  ca: morgan kaufmann  san mateo  california. 1.
 hoffmann  1  hoffmann  j.	1.	fast-forward. http://www.informatik.uni-freiburg.de/ hoffmann/ff.html.
 jo＞nsson et al.  1  jo＞nsson  a. k.; morris  p. h.; muschettola  n.; and rajan  k. 1. planning in interplanetary space: theory and practice. in proceedings of the international conference on artificial intelligence planning  1. aaai press.
 kibler & morris  1  kibler  d.  and morris  p. 1. don't be stupid. in proceedings of the international joint conference on artifical intelligence  ijcai   1.
 kvarnstro：m  doherty  & haslum  1  kvarnstro：m  j.; doherty  p.; and haslum  p. 1. extending talplanner with concurrency and resources. in proceedings of the 1th european conference on artificial intelligence  ecai-1 .
 pednault  1  pednault  e. 1. adl: exploring the middle ground between strips and the situation calculus. in proceedings of the international conference on principles of knowledge representation and reasoning  1.
 pirri & reiter  1  pirri  f.  and reiter  r. 1. planning with natural actions in the situation calculus. in minker  j.  ed.  logic-based artificial intelligence. kluwer press. in press.
 smith & weld  1  smith  d. e.  and weld  d. s. 1.
temporal planning with mutual exclusion reasoning. in proceedings of the international joint conference on artificial intelligence  ijcai   1.
 wolfman & weld  1  wolfman  s. a.  and weld  d. s. 1. the lpsat engine and its applicationto resourceplanning. in proceedings of the international joint conference on artificial intelligence  ijcai   1.
total-order planning with partially ordered subtasks
	dana nau	h└ctor mu oz-avila
univ. of maryland  college park  md  usa	univ. of maryland  college park  md  usa
nau cs.umd.edumunoz  cs.umd.eduyue caoamnon lotemsteven mitchellsolers inc.estimotion  ltd.lockheed martinarlington  vaglil yam  israelmanassas  va  usajasonc homemail.comlotem cs.umd.edusteve.mitchell lmco.comabstract
one of the more controversial recent planning algorithms is the shop algorithm  an htn planning algorithm that plans for tasks in the same order that they are to be executed.  shop can use domaindependent knowledge to generate plans very quickly  but it can be difficult to write good knowledge bases for shop.
　our hypothesis is that this difficulty is because shop's total-ordering requirement for the subtasks of its methods is more restrictive than it needs to be. to examine this hypothesis  we have developed a new htn planning algorithm called shop1.  like shop  shop1 is sound and complete  and it constructs plans in the same order that they will later be executed.  but unlike shop  shop1 allows the subtasks of each method to be partially ordered.
　our experimental results suggest that in some problem domains  the difficulty of writing shop knowledge bases derives from shop's total-ordering requirement-and that in such cases  shop1 can plan as efficiently as shop using knowledge bases simpler than those needed by shop.
1	introduction
one of the more controversial recent planning systems is the shop system  nau et al.  1   an htn planning system that plans for tasks in the same order that they will later be executed.  like any htn planner  shop uses domain knowledge in order to plan more efficiently-but unlike other htn planners  shop always generates the steps of its plans in the same order that those steps will later be executed.
　　on one hand  the shop algorithm makes it possible to generate plans quite efficiently.  for example  in the experiments reported in  nau et al.  1  1   shop ran orders of magnitude faster than the blackbox  ipp  tlplan  and umcp planners. furthermore  the shop algorithm is suitable for use as an embedded planning sytem in complex applications  munoz et al.  1 .
on the other hand  creating a shop knowledge base
can require significantly more  programming effort  than is needed for action-based planners.  for example  in two of the planning domains in track 1 of the aips-1 planning competition  shop was disqualified because we did not finish debugging the knowledge bases in time.
　　we believe that although the total-order htndecomposition technique used in shop has some significant benefits  the shop planning algorithm provides too restrictive a way of achieving these benefits. in particular  shop requires the subtasks of each method to be totally ordered  which makes it impossible for shop to interleave subtasks of different tasks. in section 1 we describe how this can complicate the job of the knowledge-base author by requiring him/her to introduce  global planning  instructions into shop's knowledge bases that would not otherwise be needed.
　　in this paper we introduce the shop1 planning algorithm  which has the following properties:
  like shop  shop1 is a sound and complete htn planning algorithm that generates the steps of each plan in the same order that those steps will later be executed.  thus  like shop  shop1 knows the current state at each step of the planning process.
  unlike shop  shop1 allows each method to decompose into a partially ordered set of subtasks  and allows the creation of plans that interleave subtasks from different tasks.
  shop1 is upward-compatible with shop. our shop1 implementation can run shop knowledge bases with only minor syntactical changes  and in fact runs them more efficiently than shop does.
we have done experimental comparisons of shop and shop1 in problem domains exemplifying situations  1  where domain-specific global-reasoning knowledge seems necessary for efficient plan-generation regardless of shop's total-ordering requirement  and  1  where such knowledge is necessitated only by shop's partialordering requirement.  in the latter case  we could easily create a knowledge base much simpler than shop's  that enabled shop1 to create plans more efficiently than shop and with plan quality similar to shop's.
1

	 a 	 b 
figure 1.  first set of methods for moving packages.
go m  load a  go n  drop a  go m  load b  go n  drop b 
figure 1: the plan we have actually told shop to generate.

figure 1.  plan generated using the methods in figure 1.
1	motivation
　　as example of the kind of difficulty that can result from shop's requirement that all tasks be totally ordered  consider the task of moving a package from one location to another.  for shop to generate a plan for this task  it needs to have a method telling it how to move a package  such as the method shown in  figure 1 a .  this method says that one way to move a package is to go to the package  pick the package up  go to the destination  and drop the package off.
　　if all we want to do is to deliver one package  then the method in figure 1 a  will work fine.  however  suppose we want to move two packages at once. although the two methods shown in figure 1 might at first glance seem satisfactory for this task  they will not always do what we want.  if the two packages both have the same initial location and the same destination  then we probably would like to deliver both packages at once  as shown in figure 1-but the methods in figure 1 will tell shop to deliver the packages one at a time  as shown in figure 1.
　　in this simple example  it is not hard to write methods telling shop to generate a plan for delivering both packages at once. for example  the methods shown in figure 1 will tell shop to generate the plan shown in figure 1.  however  to do this we had to tell shop explicitly how to reason about both packages at once.
　　the need to give shop such  global planning  instructions can occur frequently.  each of the shop knowledge bases described in  nau et al.  1  contains instructions for reasoning globally about the planning problem-and the same is true in most of the knowledge bases that we created during the aips-1 planning competition.  to write and debug such instructions can require significant time and effort.
1	shop1
1	preliminaries
as with most ai planners  a logical atom in shop1 consists of a predicate name followed by a list of arguments  and a state of the world consists of a collection of ground logical atoms.
　　as with most htn planners  a task in shop1 consists of a task name followed by a list of arguments. although tasks are similar syntactically to logical atoms  they are different semantically since they denote activities that need to be performed rather than logical conditions  erol et al  1; barret  1 .
　　a shop1 knowledge base contains domain-specific knowledge that shop1 will need in order to do planning in some domain.  it consists of axioms  methods  and operators  as described below.1
axioms. shop1's horn-clause axioms are identical to those used in shop. as in shop  shop1 uses these axioms to infer whether a method's preconditions are satisfied in the current state of the world  using hornclause inference.
　　also like shop  shop1's methods and horn clauses can contain calls to the lisp evaluator.  this allows shop1 to evaluate preconditions that contain  for example  numeric computations or queries to external information sources.
methods. shop1's methods are similar to those of shop except that methods can produce partially ordered sets of subtasks.  as in shop  the basic form of a method is
1
 :method task-atom precondition-atoms decomposition 
　　the task-atom tells what kind of task the method can be used for. the method cannot be applied to some task t unless task-atom is unifiable with t .
　　the precondition-atoms tell what things must be true in the current state of the world in order for the method to be applicable to t. the previous paragraphs described how shop1 infers whether these preconditions are true in the current in the current state.
　　the decomposition tells what subtasks to decompose the task into. in shop this set of subtasks was totally ordered  but in shop1 it can be partially ordered.
　　as in shop  additional preconditions and decompositions can be appended to the method for shop1 to use in an  if-then-else  manner:
 :method task-atom precondition-atoms-1 decomposition-1
precondition-atoms-1
decomposition-1     ...      
the idea here is that if precondition-atoms-1 is true then the method will produce decomposition-1; otherwise if precondition-atoms-1 is true then the method will produce decomposition1  and so forth.
operators. since the subtasks of a method can be partially ordered  this means that subtasks of different methods can be interleaved in a plan.  thus in order to prevent deleted-condition interactions  we need a way to specify protected conditions.  however  since shop1 will plans for tasks in the order that they will later be executed  we can get by with a rather simple protection mechanism  rather than the more sophisticated mechanisms used in partial-order htn planners such as o-plan  currie and tate  1; tate  1   sipe  wilkins  1   and umcp  erol et al.  1 . to accomplish this  shop1's operator syntax is modified beyond that of shop  to include the following way to specify protected conditions.
　　like shop's operators  each shop1 operator includes a task atom  which must be unifiable with a task in order for the operator to be applicable to that task   a  delete list   which tells what atoms to delete from the current state   and an  add list   which tells what atoms to add to the current state .  however  shop1 operators can also include protection requests  to tell shop1 that certain conditions should not be deleted  and protection cancellations  to tell shop1 that it is now permissible to delete those conditions .
　　for example  suppose we want to tell shop1 to drive a truck from location p to location q  and prevent the truck from being moved away from q. then we would write an operator that deletes   at-truck p    adds   attruck q    and adds a protection request for   at-truck q  . once we are ready to move the truck  another operator can delete the protection request.
1	the shop1 algorithm
the shop1 planning algorithm is as follows  where s is the current state  m is a partially ordered set of tasks  and l is a list of protected conditions:
procedure shop1 s m l 
if m is empty then return nil endif nondeterministically choose a task t in m that has no predecessors  r r'  = reduction s t  if r = fail then return fail endif nondeterministically choose an operator instance o applicable to r in s
s' = the state produced from s by applying o to r
l' = the protection list produced from l by applying o to r
m' = the partially ordered set of tasks produced from m by replacing t with r' p = shop1 s' m' l'  return cons o p 
end shop1 procedure reduction s t 
if t is a primitive task then return  t nil  else if no method is applicable to t in s then
return  fail nil  endif
nondeterministically let m be any method applicable to t in s
r = the decomposition  partially ordered set of tasks  produced by m from t
r = any task in r that has no predecessors  r' r'  = reduction s r  if r' = fail then return  fail nil  endif
r'' = the partially ordered set of tasks produced from r by replacing r with r'
return  r' r'' 
end reduction
　　the proof that the shop1 algorithm is both sound and complete is too long to include in this paper. however  it is a relatively straightforward induction proof  proceeding from the usual kind of definition of what it means for something to be an htn plan.
　　probably the only complicating factor worth mentioning here is the reason why reduce calls itself recursively until it finds a primitive task. this is needed in order to ensure that for all of the methods used to produce that primitive task  the preconditions are evaluated in the correct state of the world.
1	implementation and experiments
we implemented the shop1 algorithm by modifying the common-lisp coding for the shop planning system.  as we did with shop  we intend to make shop1 available as freeware under the gnu public license.
　　for our experiments  we wanted to compare shop1 and shop on problem domains exemplifying two different cases for the role of domain-dependent  global reasoning  knowledge:
1
  cases where such knowledge is somehow an intrinsic requirement for generating plans efficiently.  we chose the blocks world  nilsson  1  as a problem domain where such cases might be likely to occur.
  cases where such knowledge is necessitated only by shop's total ordering requirement.  as a domain in which such cases would be likely  we chose the logistics domain  veloso  1 .
　　for our comparisons  we built knowledge bases for shop1 in the logistics and blocks-world domains  and compared them to the knowledge bases that come with the shop code.  for our tests we used a 1-mhz power macintosh g1 with 1 mb of ram  using macintosh common lisp 1.
　　in order to do these comparisons properly  one concern was that in modifying the shop code to create the shop1 code  we also made some significant optimizations. because of these optimizations  shop1 runs shop knowledge bases faster than shop does  so we felt that running the shop1 code against the shop code would be unfairly favorable to shop1.
　　to solve this problem  we utilized shop1's upwardcompatibility with shop.  with some minor syntactical changes  any shop knowledge base will run in shop1-and running such a knowledge base in shop1 is equivalent to running the shop planning algorithm. thus for our tests  we used shop1 to run both the shop knowledge base and the shop1 knowledge base.
1	logistics problems
the shop knowledge base contains a complicated set of instructions that tell shop how to reason globally about the logistics-planning domain.  we could not figure out a way to make any significant simplifications to this knowledge base and still have it run in shop  except by removing the domain knowledge and forcing shop to do a brute-force search. however  it was relatively easy for us to create a much simpler shop1 knowledge base  consisting of instructions for how to transport an individual package to its destination.  as can be seen from table 1  this resulted in a shop1 knowledge base whos size was only about 1% of the size of the shop knowledge base.
　　we compared the shop knowledge base with the shop1 knowledge base on 1 randomly generated logistics problems. the problems involved n packages to be delivered  for n = 1  1  ...  1.  there were 1 problems for each n  for a total of 1 problems.  in each problem  the number of cities was no larger than n/1. each city contained three locations  one truck  and n/1 or fewer airports.  for each package  the original location and the destination location were randomly chosen and were guaranteed to be different from each other.
　　as shown in figure 1  shop1 ran about 1 times as fast with the shop1 knowledge base as it did with the shop knowledge base.  as shown in figure 1  the two knowledge bases created plans of nearly the same size  but the ones generated by the shop knowledge base were slightly shorter.
table 1: sizes of the shop and shop1 knowledge bases for the logistics domain  counting each if-then decomposition of a method as a separate method .
shop
knowledge baseshop1
knowledge basemethods1operators1axioms1
figure 1. cpu times for shop1 using the shop knowledge base and the shop1 knowledge base  on 1 randomly generated logistics problems.  the x-axis gives the problem number  and the y-axis gives the cpu time.

figure 1. sizes of the plans of figure 1. the x-axis gives the problem  number  and the y-axis gives the number of actions.
table 1: sizes of the shop and shop1 knowledge bases for the blocks world  counting each if-then decomposition of a method as a separate method .
shop
knowledge baseshop1
knowledge basemethods1operators1axioms11

figure 1. cpu times for shop1 using the shop knowledge base and the shop1 knowledge base  on randomly generated blocks-world problems. the x-axis gives the problem number  and the y-axis gives the cpu time.

figure 1. sizes of the plans of figure 1. the x-axis gives the problem number  and the y-axis gives the number of actions.
1	blocks-world problems
　　just as before  the blocks-world knowledge base for shop contains instructions for how to reason globally about the planning process.  just as before  we could not think of any way to significantly reduce the size of this knowledge base and still have it run in shop  other than by removing the domain knowledge and forcing shop to do a brute-force search.
　　as before  our objective for shop1 was to simplify the knowledge base giving shop1 instructions for how to move individual blocks.  however  we could not figure out any way to do this without forcing shop1 to do a brute-force search.  in fact  we suspect that  global  domain-specific algorithms such as the ones discussed in  chenoweth  1; gupta and nau  1  may be the only way to achieve efficient planning in the blocks world.
　　we tried creating a shop1 knowledge base by removing some of the total-ordering constraints and bookkeeping operations from the shop knowledge base  but this required us to add additional coding such as protection requests and protection cancellations to handle interleaving correctly. as shown in table 1  the resulting knowledge base was about 1% larger than the original shop knowledge base.
　　we compared the performance of the two knowledge bases on randomly blocks-world problems consisting of n= 1 ... 1 blocks to be relocated. we generated five problems for each value of n  for a total of 1 problems. to build the initial and final states  we generated configurations of blocks as follows:
  first  put a block onto the table  thereby creating a new tower .
  for each block after the first one  if t is the number of existing towers  then there are t+1 possible locations for the new block: on top of any of the existing towers  or on the table  thereby creating a new tower .  choose one of those locations at random  with an equal probability for each choice.
　　as shown in figure 1  the time taken by shop1 using the shop1 knowledge base varied greatly from problem to problem.  on the average  shop1 needed about 1 times as much time to generate plans with this knowledge base as it did with the shop knowledge base. as shown in figure 1  the two knowledge bases created plans of nearly the same size  but the ones generated by the shop knowledge base were slightly shorter.
discussion and conclusions
we have described a new htn planning algorithm  the shop1 algorithm.  like the shop planning algorithm  the shop1 algorithm generates the steps of a plan in the same order in which those steps are to be executed-but unlike shop  shop1 allows the subtasks of each method to be partially ordered.
　　shop1 runs shop knowledge bases faster than shop does; and our test results show that in some cases one can create knowledge bases for shop1 that are much simpler than the ones needed by shop yet still allow shop1 to run more quickly than shop.
　　we believe that the primary impact of our results is to provide a way to obtain the same advantages ascribed to the shop planning algorithm  while alleviating one of shop's primary drawbacks.  below  we summarize what those advantages and drawbacks are:
1. planning for tasks in the order that those tasks will be performed makes it possible to know the current state of the world at each step in its planning process  which makes it possible to incorporate significant reasoning power into the planner's precondition-evaluation mechanism. rather than just unifying preconditions against current-state atoms  the shop1 system  like the shop system  can perform horn-clause inferences to evaluate preconditions that are not directly mentioned
1
in the current state  and its preconditions can incorporate calls to the lisp evaluator  e.g.  to do numeric computations or make queries to external sources of information .
1. the combination of htn decomposition  to focus the search on the goal  and reasoning power in the preconditions  to prune inapplicable methods and operators from the search space  makes it possible to write domain-dependent knowledge bases that provide very efficient planning performance.  as an illustration of what this means  when we tried to run blackbox and ipp on the suites of logistics problems and blocksworld problems described above  we could not get them to solve any of the problems in the test suites. in each case  either they ran out of memory or else we had to terminate them after they had run for more than 1 minutes of cpu time without finding solutions.
1. the primary drawback of any htn planning system is the effort needed to create a knowledge base of domaindependent information for the domain we want it to do planning in.  in shop  this drawback is sometimes worsened by shop's restriction that the subtasks of each method must be totally ordered  because this can require the knowledge-base author to introduce global reasoning into the planning domain that would not otherwise be needed.  our experimental results suggest that in these cases  shop1 can plan more efficiently than shop using knowledge bases much simpler than those needed by shop.  in cases where such knowledge bases cannot be created  shop1 can run shop knowledge bases quicker than shop.
　　some of our topics for future work include the following: investigating additional ways to make the shop1 algorithm more powerful and easier to use  releasing the coding for shop1 as open-source software  and using the shop1 algorithm as an embedded planning algorithm in a real-world application.
acknowledgements
this work was supported in part by the following grants  contracts  and awards: afrl f1 and f1-1  arl daal1  and u. of maryland general research board. opinions expressed here do not necessarily reflect those of the funders.
references
 barrett  1  a. barrett.  frugal hierarchical tasknetwork planning. computer science and engineering dept.  university of washington  1.
 bacchus and kabanza  1  f. bacchus and f. kabanza.  using temporal logics to express search control knowledge for planning .  artificial intelligence  1-1 :1  january  1.  chenoweth  1  s. v. chenoweth.  on the {np}hardness of blocks world. aaai-1  july 1  pages 1.
 currie and tate  1  k. currie and a. tate. o-plan: the open planning architecture. artificial intelligence  1 :1  1.
 erol et al.  1  k. erol  j. hendler and d. s. nau. umcp: a sound and complete procedure for
hierarchical task-network planning. in proc. second international conf. on ai planning systems  aips-1   june  1  pages 1.
 gupta and nau  1  n. gupta and d. s. nau. complexity results for blocks-world planning. aaai1  july 1  pages 1.
 kautz and selman  1  h. kautz and b. selman. unifying sat-based and graph-based planning. ijcai1  1  pages 1.
 koehler et al.  1  j. koehler  b. nebel  j. hoffman and y. dimopoulus. extending planning graphs to an adl subset. in proc. ecp-1  1. toulouse  france.
 munoz-avila et al.  1  h. munoz-avila  d. w. aha  l. a. breslow  d. s. nau and r. weber. integrating conversational case retrieval with generative planning. in ewcbr-1  1. trento  italy: springer-verlag.
 nau et al.  1  d. nau  y. cao  a. lotem  and h. mu oz-avila. shop: simple hierarchical ordered planner. in ijcai-1  1.
 nau et al.  1  d. s. nau  y. cao  a. lotem  and h. mu oz-avila. shop and m-shop: planning with ordered task decomposition. tech report tr 1  university of maryland  college park  md  june 1.
 nilsson  1  n. nilsson. principles of artificial intelligence. morgan kaufmann  1.
 tate  1  a. tate. mixed initiative planning in oplan1. in proceedings of the arpa/rome laboratory
knowledge-based planing and scheduling initiative  1  pages 1. tuscon  ar: morgan kaufmann.
 veloso  1 	m. veloso.  learning by analogical
reasoning in general problem solving.  tech. report
	cmu-cs-1  	school 	of 	computer 	science 
carnegie mellon university  pittsburgh  pa  1.
 wilkins  1  d. wilkins.  can ai planners solve practical problems   computational intelligence  1 :1  1.
1
conditional progressive planning under uncertainty
lars karlsson
center for applied autonomous sensor systems
orebro university  se-1：	orebro  sweden： http://www.aass.oru.se/ lars.karlsson tech.oru.seabstract
in this article  we describe a possibilistic/probabilistic conditional planner called ptlplan. being inspired by bacchus and kabanza's tlplan  ptlplan is a progressive planner that uses strategic knowledge encoded in a temporal logic to reduce its search space. actions effects and sensing can be context dependent and uncertain  and the information the planning agent has at each point in time is represented as a set of situations with associated possibilities or probabilities. besides presenting the planner itself - its representation of actions and plans  and its algorithm - we also provide some promising data from performance tests.
1	introduction
in this article  we describe a conditional planner called ptlplan. a conditional planner does not presuppose that there is complete information about the state of its environment at planning time  but that more information may be available later due to sensing  and that this new information can be used to make choices about how to proceed. hence  a conditional planner generates plans that may contain conditional branches. in addition  ptlplan can handle degrees of uncertainty  either in possibilistic or in probabilistic terms. the  p  in ptlplan stands for exactly that.
　ptlplan is a progressive  forward-chaining  planner; it starts from an initial situation and applies actions to that and subsequent resulting situations  until a situation where the goal is satisfied is reached. being progressive  ptlplan has the disadvantagethat the search space is potentially very large even for small problems the advantage is that ptlplan can reason from causes to effects  and always in the context of a completely specified situation. the latter makes it possible to apply a technique that can reduce the search space considerably: the use of strategic knowledge that helps pruning away unpromising plan prefixes.
　ptlplan builds on a conditional planner etlplan  karlsson  1   which in turn built on a sequential  nonconditional  planner called tlplan  bacchus and kabanza  1; 1    tl  stands for  temporal logic  . two of the features that makes tlplan interesting are its fairly expressive first-order representation and its good performance due to its use of strategic knowledge. the latter is indicated by its outperforming most other comparable planners in empirical tests  as has been documented in  bacchus and kabanza  1 . etlplan added two features to tlplan:
the representation of actions and situations used in etlplan permitted actions that have sensing effects  that is the agent may observe certain fluents  state variables .
based on these observations  the planning algorithm could generate conditional plans.
in addition to these features  ptlplan also incorporates:
assignments of degrees of uncertainty  either in possibilistic or probabilistic terms  to effects  observations and situations/states.
based on these degrees  measures of how likely a plan is to succeed or fail. in the absence of plans that are completely certain to succeed  ptlplan is still capable of finding plans that  although they may fail  are likely enough to succeed.
ptlplan is the first progressive planner utilizing strategic knowledge to incorporate the features mentioned above  and as indicated by tests  it does so successfully. in the rest of the article  we describe the plan representation of ptlplan  the use of strategic knowledge and the planning algorithm  and we also briefly provide some data from performance tests.
1	related work
planning in partially observable domains has been a hot topic since the mid 1's. there has been a good amount on work on pomdps  partially observable markov decision processes   see e.g.  kaebling et al.  1 . pomdps typically utilize explicit enumerations of states  but there are also results on the use of more compact propositional representations  boutilier and poole  1 . note that this work is on the more general problem of generating policies that maximize utilities  and not plans with sequences and branches that achieve goals.
　one of the earliest conditional probabilistic systems originating from classical planning was the partial-order planner c-buridan  draper et al.  1   which had a performance which made in impractical for all but the simplest problems. the partial-order planner mahinur  onder and pollack  1  improved considerably on c-buridan by handling contingencies selectively. mahinur focuses its efforts on those contingencies that are estimated to have the greatest impact on goal achievement. c-buridan and mahinur are regressive planners: they perform means-ends reasoning from effects to causes.
　weaver  blythe and veloso  1  is a system that iterates between a classical planner and a probabilistic evaluator. it can model stochastic exogenous events but not sensing.
　c-maxplan and zander  majercik and littman  1  are two conditional planners based on transforming propositional probabilistic planning problems to stochastic satisfiability problems  e-majsat and s-sat  respectively . the latter can be solved in a highly efficient manner  in particular when certain pruning techniques are used. but  as pointed out in  majercik and littman  1   the translation from planning problems to satisfiability problems can lead to blow-ups in size and obscures the problem structure.
　on the possibilistic side  there is gue＞r＞e's and alami's conditional planner  gue＞r＞e and alami  1   which also has been demonstrated to have a practical level of performance. their planner is based on graph plan  blum and furst  1 . it assumes that sensing actions are perfectly reliable and do not have preconditions. another graph plan derivative is sensing graph plan  sgp   weld et al.  1   which can deal with incomplete information but has no means for quantifying uncertainty.
1	representation
1	uncertainty
ptlplan can represent uncertainty either using possibility theory  dubois and prade  1 or probabilitytheory  simply by interpreting the connectives used as follows.1
connectivepossibilityprobabilitycommentmin and max or 　thus  ptlplan can be used both when one is only interested in the relative likelihood of different facts and outcomes  and when one has precise information about probabilities.
1	syntax: fluents
the state of the world is described in terms of fluents  state variables  and their values. a fluent-value formula has the form =   denoting that the fluent has the value ; if the value is omitted  it is implicitly assumed to be t  true . examples of fluent-value formulae are door d1  and robot-at table1 =f. a fluent formula is a logical combination of fluent-value-formulae using the standard connectives and quantifiers. a fluent-assignment formula has the form := denoting that is caused to have the value ; e.g. robot-at table1 :=f.
1	syntax: actions
an action schema consists of a tuple	where	is the action name 	is a precondition  a fluent formula  and	is a set of result descriptions. each result description	is a tuple	where
is a context condition  a fluent formula  that deter-
mines when  in what states  the result is applicable. is the possibility or probability of the result.
is a set of fluent assignment formulae   :=t or
:=f  which specifies the effects of the result. we let denote the fluents with positive assignments in
	and we let	be those with negative ones.
　is a set of fluents   denoting that the current value of is observed  and/or fluent-value-formulae = denoting that is  correctly or incorrectly  observed to have the value . these observations are assumed to be made by the agent executing the plan.
note that restrictions apply to the values; the sum of the in applicable results must always be 1 for the probabilistic case  and the maximum of the must always be 1 for the possibilistic case.
example 1 the following are action schemas for the tiger scenario  the scenariois due to  kaeblinget al.  1  . there are two doors  one to the left  ld  and one to the right  rd . behind one of them lurks a tiger  and behind the other there is a reward. the fluent tiger d  stands for that the tiger is behind door d. probabilities are used.
　the agent can listen at the doors  and this gives a indication of behind which door the tiger lurks. unfortunately  there is a 1% chance of error. this is an action that yields observations but no concrete effects.
act:listen   pre:true
	context	p	effectsobservationsres:  tiger ld   1   tiger ld =t    tiger ld   1   tiger rd =t    tiger rd   1   tiger rd =t    tiger rd   1   tiger ld =t  the agent can open one of the doors  which either leads to the reward  rew   or to tiger-induced death  dead .
act:open  d  pre:door  d 
	context	p	effects	observations
res:   tiger  d  1  rew:=t   rew=t   
 tiger  d   1  dead:=t   dead=t  
1	semantics: situations and epistemic situations
we use a model of knowledge and action which is based on the concepts of a situation and an epistemic situation. in short  a situation describes one possible state of the world at a given point in time  where time is defined in terms of what actions has occurred. an epistemic situation  or esituation for short  is essentially a set of situations with associated possibilities/probabilities that describes the agent's knowledge at a point in time. in this ptlplan is similar to e.g. c-buridan  draper et al.  1  which employs a probability distribution over states. a transition relation over situations provides the temporal dimension; the transitions are due to applications of actions. the global possibility/probabilityof a situation is denoted . thisrepresents the possibility/probability that some given choice of actions  plan  will lead to . the global possibility/probability of an e-situation is computed from those of its constituents:
　  . the local possibility/probability of a situation is obtained by normalizing relative to its containing e-situation :  . this represents the possibility/probability the agent assigns to inside .
	the state	of a situation	is a mappingfrom fluents
to values  i.e. a set of fluents   and the observation set is a set of fluent-value-pairs . we impose the constraint that all situations in an e-situation  should have the same observation set; we denote this set by  .
example 1 the initial e-situation for the tiger scenario has no observations  obs=    but contains two situations with associated probabilitiesand states. in one situation where   the tiger is behind the left door  and in the other  where   it is behind the right door.
obs=
	1:	tiger ld  door ld  door rd 
	1:	tiger rd  door ld  door rd 
1	semantics: results of actions
the results of an operator/action in a situation is defined as follows: for each result description   if context condition is true in then there is a situation resulting from  i.e.   where the effects in occur  i.e.
  and the observationsin
are made  if and has value in   or if =   then  . finally  . for an epistemic situation   the result of an action is determined by applying to the different situations  as above  and then partitioning the resulting situations into new e-situations according to their observation sets.
example 1 we attempt to apply some different actions to the initial e-situation. applying open ld  yields the following two new e-situations   ...  stands for  door ld  door rd   : obs= dead=t
	1:	tiger ld  dead ...
	obs=	rew=t
	1:	tiger rd  rew ...
applying listen   to the initial e-situation yields the following two new e-situations:
	obs=	tiger ld =t
	1:	tiger ld  ...
	1:	tiger rd  ...
	obs=	tiger rd =t
	1:	tiger rd  ...
	1:	tiger ld  ...
note how the resulting situations are partitioned into esituations based on their observations.
1	syntax: conditional plans
plans in ptlplan are conditional. this means that there can be points in the plans wherethe agent can choosebetween different ways to continue the plan depending on some explicit condition. therefore  in addition to the sequencing plan operator  ;   we introduce a conditional operator  cond . the
syntax of a conditional plan is as follows:
	plan ::= success	fail	action;plan
cond branch*
branch ::=  cond:plan  action ::= action-name args 
a condition cond is a conjunction of fluent-value formulae. the conditions for a branch should be exclusive and exhaustive relative to the potential e-situations at that point in the plan. success denotes predicted plan success  and fail denotes failure.
example 1 the following is a plan which is a solution to the tiger scenario  see example 1 for how it could be generated .
listen  ; cond tiger rd =t : open ld ; cond rew=t:success  dead=t:fail    tiger ld =t : open rd ; cond rew=t:success  dead=t:fail  
1	semantics: application of conditional plans
the application of a plan to an epistemic situation  results in a set of new e-situations. first  the application of an action to  is defined as in section 1. next  the application of a sequence ; is defined as applying the first action
to    and then the rest of the plan to each of the resulting e-situations. finally  the application of a conditional plan element cond   :     :   is defined as an application of the branch whose context condition matches with   there should only be one such branch .
　this concludes how actions and plans are represented in ptlplan. next  we proceed to investigate how strategic knowledge can be represented and used.
1	strategic knowledge
in order to eliminate unpromising plan prefixes and reduce the search space  ptlplan  and tlplan and etlplan before it  utilizes strategic knowledge. this strategic knowledge is encoded as expressions  search control formulae  in an extension of first-order linear temporal logic  ltl   emerson  1  and is used to determine when a plan prefix should not be explored further. one example could be the condition  never pick up an object and then immediately drop it again . if this condition is violated  that is evaluates to false in some e-situation  the plan prefix leading there is not explored further and all its potential continuations are cut away from the search tree. a great advantage of this approach is that one can write search control formulae without any detailed knowledge about how the planner itself works; it is sufficient to have a good understanding about the problem domain.
　ltl is based on a standard first-order language consisting of predicate symbols  constants and function symbols and the algorithm progress f   case:
true if where	false otherwise
	true if	
= false otherwise
	true if	for all
false otherwise









return
figure 1: the ptlplan progression algorithm.
usual connectives and quantifiers. in addition  there are four temporal modalities:  until    always    eventually   and  next . in ltl  these modalities are interpreted over
a sequence of situations  starting from the current situation. for the purpose of ptlplan  we can interpret them over a sequence/branch of epistemic situations  and a current epistemic situation  in that sequence. the expression means that holds in the current or some future e-situation  and in all e-situations inbetween holds; means that holds in this and all subsequent e-situations; means that holds in this or some subsequent e-situation;
and	means that	holds in the next e-situation 	.
　in addition to the temporal modal operators from ltl  ptlplan also uses a goal operator   which is useful for referring to the goal in search control formulae. we let denote that it is among the agent's goals to achieve the fluent formula . semantically  this modality will be interpreted relative to a set of goal states   i.e. the set of states that satisfy the goal. we also introduce two new modal operators:   knows   means that the necessity/probability that the fluent formula is true in the current e-situation exceeds some prespecified
threshold k  given the information the agent has; and = denotes that is observed to have the value in the current e-situation. we restrict fluent formulae to appear only inside the   and  for fluent-value formulae  operators.
　we can now define the semantics of these modal operators relative to a branch of epistemic situations  a current epistemic situation    a variable assignment   and a set of goal states   as follows.
 iff there exists a such that  and for all such that  
	. 	iff for all	 		.
algorithm ptlplan 
1. if 	then return success 	.
1. let progress  ; if false then return fail  .
1. for the actions whose preconditions are satisfied in all  do:
a. let	 .
b. for each    let ptlplan  .
c. if	then let	fail		.
d. if	  let	;	.
	otherwise let	where
; cond  : ...  :   
 
	and each	=		.
1.	return the	with the lowest
　　  provided   or otherwise return fail  .
figure 1: the ptlplan planning algorithm.
		iff there exists a	such that
	. 	iff		. 	iff for all	 	.
		iff k	where
		.
		= iff	 .
the interpretationof is motivated by the fact that in possibility theory  necessity is defined as   and in probability theory .
　in order to efficiently evaluate control formulas  ptlplan incorporates a progression algorithm  similar to the ones of tlplan and etlplan  that takes as input a formula and an e-situation and returns a formula that is  one step ahead   i.e. corresponds to what remains to evaluate of in subsequent e-situations. it is shown in figure 1.  the goal states in case 1 are fixed for a given planning problem and need not be passed along.  note that the algorithm assumes that all quantifiers range over a finite universe .
example 1 the following is a control formula stating that a robot should never pick an object up and then drop it immediately again  i.e. hold it only one moment.
robot-holds
robot-holds	 1  robot-holds
1	the planning algorithm
ptlplan is a progressive planner  which means that it starts from an initial e-situation and then tries to sequentially apply actions until an e-situation where the goal is satisfied is reached. the algorithm is shown in figure 1. it takes as input an e-situation   a search control formula   a goal formula  with a    a set of actions and a success threshold  the failure threshold is  . it returns a triple containing a conditional plan  a degree  possibility/probability  of success  and a degree of failure. it is initially called with the given initial e-situation and a search control formula.
　step 1 checks if the goal is satisfied in   if this is the case it returns the possibility/probability of . step 1 progresses the search control formula; if it evaluates to false  the plan prefix leading to this e-situation is considered unpromising and is not explored further. in step 1  we consider the different applicable actions. for each such action  we obtain a set of new e-situations  a . we then continue to plan from each new e-situation separately  b . for those subplans thus obtained  if the combined possibility/probabilityof failure is above the failure threshold  we simply return a fail plan  c . if there was a single new e-situation  we return a simple sequence starting with the chosen action  d . otherwise  we add to the chosen action a conditional plan segment where branches are constructed as follows. the conditions are derived from the different observations of the different esituations  and the sub-plans are those obtained in  b . the success and failure degrees of this new plan are computed by combiningthose of the individualsub-plans. in step 1  finally  we return the best of those plans  i.e. the one with the least failure degree  found in step 1  or a fail plan if the degree of failure is too high.
example 1 to give a feel for the operation of ptlplan  we go through the tiger scenario. the actions are defined as in example 1  and the initial e-situation is as in example 1. there is one search control formula:1
	dead	 1 
finally  the goal is:
	rew dead	 1 
this goal should be achieved with a probability of at least   giving a failure threshold of .
1. from the initial e-situation  the applicable actions areopen ld   open rd  and listen  .
1. we first apply open ld   resulting in the e-situations described in the first half of example 1.
 a  continuing planning from the first of these esituations  the condition dead after progression evaluates to false  so this branch yields fail  plan  success degree failure degree ; see
step 1 in the algorithm.
 b  in the second one  the goal is achieved  yieldingsuccess .
thus  the combined probability of failure is   which is above the failure threshold  step 1.c .
1. applying open rd  gives a similar outcome.
1. applying listen   to the initial e-situation yields the two e-situations from the second half of example 1.
 a  continuing from the first new e-situation  weeventually find that choosing open rd  leads
problemscno scother plannerstiger 1111zandertiger 1111d:otiger 1111d:ocoffee111mahinurask-coffee111zandercold-room111gue＞r＞e-alamifigure 1: some solution times for different scenarios  in cpu seconds. sc =  search control formulae were used .
to success with a degree of 1: open rd ; cond rew=t:success  dead=t:fail 
 b  continuing from the second one  we find that choosing open ld  leads to success with a probability of 1: open ld ;cond rew=t:success 
	 dead=t:fail 	.
combining the branches from  a  and  b  and appending them to listen    finally  yields the plan shown in example 1  with 1 and 1 as probabilities of success/failure.
1	implementation and experiments
ptlplan has been implemented in allegro commonlisp  and uses a breath first search method involving detection of previously visited situations. the performance of ptlplan has been tested on some scenarios encountered in the literature. all tests were performed on a 1 mhz pentium ii. table 1 presents the results of the experiments. note that the use of search control formulae has a considerable impact  in particular in the three last scenarios. we also include some results documented for some other planners  majercik and littman  1; onder and pollack  1; gue＞r＞e and alami  1  in order to give some rough indication about the relative merits of ptlplan.1
the tiger scenario was solved for success probabilities
　　　　　　　　　. only the marginally helpful control formula in example 1 was used. the coffee robot scenario  boutilier and poole  1; onder and pollack  1  involves a robot that is to go to a cafe in order to buy coffee with cream and sugar  and then bring the coffee back to the office. if it is raining  1% chance  the robot has to bring an umbrella along  otherwise not. a conjunction of 1 search control formulaewere used in this scenario. the solution plan had two branches; the longest one had 1 steps. in the asking coffee robot scenario  majercik and littman  1   the robot does not have to bother about cream and sugar  but has to ask the user whether he wants coffee  1% chance . the solution had 1 branches. the cold-room scenario is a more complex  possibilistic scenario from  gue＞r＞e and alami  1  involving a poorly illuminated table with two test tubes. a robot should move the red tube to a second table in a cold-room. a conjunction of 1 search control formulae were used in this scenario  and one of them is shown in example 1. the solution plan involved going to a third well-illuminated table to ensure that the correct test tube was picked up. it had two branches; the longest one had 1 steps.
1	conclusions and future work
in this paper  we have presented work on the planner ptlplan. it is a progressive planner which utilizes strategic knowledge to reduce its search space. we have described ptlplan's fairly rich representation: actions with contextdependent and uncertain effects and observations  and plans with conditional branches. the semantics of this representation is based on associating different possible situations with degrees of possibility or probability. we have also described the planning algorithm and how we utilize a temporal logic to encode search control knowledge that can be used to prune unpromising branches in the search tree. ptlplan is based on tlplan  bacchus and kabanza  1  and etlplan  karlsson  1 . the novel contribution of ptlplan is the introduction of uncertainty into the context of progressive planning with strategic knowledge.
　in this paper  we have also given some brief but quite promising performance data on ptlplan  indicating that it compares favorably to other probabilistic/possibilistic conditional planners. yet  more remains to be done  both in orderto improve the performance of ptlplan  and to evalute it more systematically  in particular on larger scenarios. finally  we are now working on integrating ptlplan with a robotic system capable of action and perception  coradeschi and saffiotti  1 .
acknowledgements
this work was funded by the swedish kk foundation. many thanks to silvia coradeschi and alessandro saffiotti for helpful suggestions  and to stephen majercik for answering questions about zander.
references
 aaai1  1  proceedings of the sixteenth national conference on artificial intelligence  orlando  florida  1. aaai press  menlo park  california.
 bacchus and kabanza  1  f. bacchus and f. kabanza. using temporal logic to control search in a forward chaining planner. in m. ghallab and a. milani  editors  new directions in planning  pages 1. ios press  amsterdam  1.
 bacchus and kabanza  1  f. bacchus and f. kabanza. using temporallogics to express search control knowledge for planning. artificial intelligence  1-1  1.
 blum and furst  1  a. blum and m.l. furst. fast planning through planning graph analysis. in proceedings of the fourteenth international joint conference on artificial intelligence  montreal  1. morgan kaufmann.
 blythe and veloso  1  j. blythe and m. veloso. analogical replay for efficient conditional planning. in proceedings of the fourteenth national conference on artificial intelligence  providence  rhode island  1. aaai press  menlo park  california.
 boutilier and poole  1  c. boutilier and d. poole. computing optimal policies for partially observable decision processes using compact representations. in proceedings of the thirteenth national conference on artificial intelligence  portland  oregon  1. aaai press  menlo park 
california.
 coradeschi and saffiotti  1  s. coradeschi and a. saffiotti. perceptual anchoring of symbols for action. in proceedings of the seventeenth international joint conference on artificial intelligence  seattle  1. morgan kaufmann.
 draper et al.  1  d. draper  s. hanks  and d. weld. probabilistic planningwith informationgatheringand contingent execution. in proceedings of the second international conference on artificial intelligence planning systems. aaai press  menlo park  calif.  1.
 dubois and prade  1  d. dubois and h. prade. possibility theory - an approach to computerized processing of uncertainty. plenum press  1.
 emerson  1  e.a. emerson. temporal and modal logic. in j. van leeuwen  editor  handbook of theoretical computer science  volume b  chapter 1  pages 1. mit press  1.
 gue＞r＞e and alami  1  e. gue＞r＞e and r. alami. a possibilistic planner that deals with nondeterminismand contingency. in proceedings of the sixteenth international joint conference on artificial intelligence  stockholm  1. morgan kaufmann.
 kaebling et al.  1  l.p. kaebling  m.l. littman  and a.r. cassandra. planning and acting in partially observable stochastic domains. artificial intelligence  1- 1 :1  1.
 karlsson  1  lars karlsson. conditional progressive planning: a preliminary report. in brian mayoh  john perram  and henrik hautop lund  editors  proceedings of the scandinavian conference on artificial intelligence 1  1. to appear.
 majercik and littman  1  stephen m. majercik and michael l. littman. contingent planning under uncertainty via stochastic satisfiability. in aaai1   pages 1.
 onder and pollack  1  n. onder and m.e. pollack. conditional  probabilistic planning: a unifying algorithm and effective search control mechanisms. in aaai1   pages 1.
 weld et al.  1  d.s. weld  c.r. anderson  and d.e. smith. extending graphplan to handle uncertainty and sensing actions. in proceedings of the fifteenth national conference on artificial intelligence  madison  wisconsin  1. aaai press  menlo park  california.

planning
domain analysis for planning

one action is enough to plan
emmanuel guer＞ e＞ and rachid alami
laas-cnrs
1  avenue du colonel roche
       1 toulouse cedex 1 - france e-mail : emmanuel.guere  rachid.alami  laas.fr

abstract
we describe a new practical domain independent task planner  called shaper  specially designed to deal efficiently with large problems.
shaper performs in two steps. in the first step  executed off-line for a given domain subclass1  shaper explores and builds a compact representation of the state space called the shape graph. the main contribution of shaper is its ability to  resist  to combinatorial explosion thanks to the manipulation of sets of similar state descriptions called shapes. the shape graph is then used by shaper to answer very efficiently to planning requests.
a first version of the planner has been implemented. it has been tested on several well known benchmark domains. the results are very promisingwhen compared withthe most efficient planners from aips-1 competition.
1	introduction
in the stream of research that aims to speed up practical task planners  we propose a new approach to efficiently deal with large problems. even though task planners have made very substantial progressover the last years  they are stilllimitedin their use. indeed  they are sometimes overwhelmed by very simple or even trivial problems. our motivation stems also from the fact that there are domains which heavily influence the  structure  of the task state space; learning such a  structure  will certainly help in building efficiently a solution for a problem of the domain . our aim is to develop a domain independent planner that will exhibit and learn the  structure  of a given domain subclass. the main difficulty  and the key contribution  in this framework is to face the combinatorial problem of the task space exploration.
　in order to solve larger problems  all planners in the literature try to prune the state space. to do this  there are several ways: a first solution consists in having a  good metrics  of the domain in order to guide the search  heuristics . the heuristics can be automatically computed  domain independent planning - e.g.  bonet and geffner  1; hoffmann  1   or given by the user  domain dependent planning - e.g.  doherty and kvarnstrom  1  .
　a second way consists in restricting the search to a superset of accessible states from the initial state; such restriction allows to reduce the search space during the backward planning process  e.g. the graph expansion of graphplan  blum and furst  1  .
　a thirdway involves the analysis of the domain  structure  like invariant  e.g.  gerevini and schubert  1    type detection  problem decomposition or problem symmetries  e.g.  fox and long  1; 1  .
　we would like is to develop a new  complete and domain independent method to efficiently solve large problems. to do so  we both restrict the search space througha set of accessible states and deal with a large class of domain symmetries  represented by states which have the same shape1 .
　for instance  the ferry problem overwhelms classical planners because of the very high number of possible applicable actions  which may create many redundant states  even though moving one car or another has the same result for the goal. however  it appears clearly that the state space is highly redundant: there is only distinguishable shapes for cars. dealing with such shapes will certainly increase the planner capabilities by reducing the search space in a drastic manner.
　shaper1 is a new planner which is able to detect all different shapes of the state space for a given domain subclass. this methodis composed of twosteps: first the plannerbuilds a shape graph of the domain subclass. this step is performed off-line and only once for a given domain subclass  e.g. shaper builds the shape graph for the subclass of ferry domain with 1 cars. then  shaper is able to solve on-line any planning problem in this class by connecting two shape graphs. as we will see  the connection makes use of only one action; this ensures the efficiency of the solution extraction step.
the next section explains how to build such shape graph.
section 1 presents an expansion algorithm that guarantee shaper completeness. we then describe the solution extraction process  section 1 . a first version of the planner has been implemented and has produced very promising results. all sections are illustrated by examples obtained by running such an implementation. the last section presents and discusses a number of tests which are compared with some of the best current planners  from aips-1 competition .
1	the shape graph:
a planning problem is usually expressed as a triple where corresponds to the set of instantiated actions  the initial state and the goal. in the strips  fikes and nilsson  1 formalism  an action is described by its preconditions   means that is applicable to the state
   its addlist	and its dellist	. applying the operator
from state results in the new state . a state is an instantiated predicate set according to the closedworld assumption.
　the purpose of this section is to present the shape graph construction process  only extract  relevant  states . this state space exploration is performed off-line and once only for each domain subclass from a valid state .
　indeed  if we restrict ourselves to the strips framework  there is a priori no mean to check if a state is valid or not  except by applying a valid sequence of action to a valid one   - user-defined .
　this is the reason why the shape graph is an accessibility graph . now  the main difficulty comes from the combinatorial explosion of states and applicable actions; this is why we build a graph that only contains  relevant  states.
1	relevant states
the relevance of a state is defined according to the state description of the current graph . a state is relevant  i.e. it
 augments 	withnew information  iffthere exists no
such that is a substitution of :  i.e. the state can be instantiated by a variable permutation  . consider
for instance the two blocks-world states	and	:
	state g: 	state s: 
with and
.
　the state where is substitutedto   to and to is equal to    . in this case  and are said to have the same shape1.
　when has the same shape as   we can conclude that all shapes accessible from are also accessible from : if is a sequence of action applicable to   then is applicable to and . developing the state is then not informative: does not lead to a new shape.
buildgraph 	 	 

	while		do

	for each	such thatdo	if	and	such thatthen	if	then
	add the edge	to
else
	mark	in	with	and
else
	add the vertex	and the edgeto	table 1: build the shape graph	.
1	building the shape graph
in order to reduce the graph size  we only develop relevant states. the algorithm  presented in table 1  is similar to a breadth-first search algorithm. relevant states are sequentially developed by applying all possible actions . the algorithm detects links to other substitutionsas well as cycles in a given substitution  when  ; in this case  a new edge is added.
　in the case of a non-identical substitution   we keep in thename of the correspondingshape in and . owingtothe relation   the accessibility from to can be  if necessary  quickly retrieved. indeed  several substitutions
may produce the same result because of the commutativityof the logical and  i.e. does not imply .
1	an example
the graph construction algorithm is illustrated by figure 1 with an example from the gripper domain. the goal is to move 1 balls from table to table . to do this  the robot is able to pick and place a ball and to move from a table to the other. the robot has two arms. the graph expansion begins with the valid state  all three balls are on and the robot is near  . four actions are applicable to :
　　　　　 	 	and	; as shown on figure 1	and
. we can note that
is not added to the graph  since there exists a substitution
1 such
that . similarly  there exists a substitution between and ; we note it on the figure by a dashed line to . then is developed in and and so on ...
　the graph	finally contains nine vertices which model all possible shapes accessible from the valid state	.

	figure 1: build the shape graph	.
1	and the state space
this method makes it possibleto drasticallyreduce the size of the state space when the domain contains many  functionally similar   objects   variables with possible substitutions . indeed  in the blocks-worldand in the gripper domain  the state space grows exponentially comparing to the shape graph size as shown table 1.
as mentioned previously  shaper needs a valid state 
       to build the graph . although contains all shapes accessible from   in the case of a disjoint state space  shaper is unable to construct graphs from the other connected components of state space  their states are not accessible . therefore  the user must give one state per connexity; otherwise  the shape of  the initial state of a planning problem  might not be present in   which will constraint the planner to generate a complementary shape graph from during the on-line process.
1	a first step through solution extraction
to perform efficient on-line solution extraction  shaper takes advantage of the shape graph built off-line. three steps are necessary to find a plan: first  generate the graph  resp.
problemstate space sizesizeblocks-world
1 blocks11 blocks11 blocks11 blocks11 blocks1gripper
1 balls11 balls11 balls11 balls1table 1: growth of the state space comparing to the	size.

figure 1: extract a solution by connecting	and	.
	  associated to the initial state	 resp.	 . then
shaper searches forone action that connects with via and     and  . finallyit is enough to find a path from to in and from to in .
　to better understand this intuitive algorithm  let us explain it through the 1-balls-gripper example. there are three balls  two tables and two grippers; initially balls and are on table and the ball is in the left gripper near table .
this state has the same shape as	of the figure 1 where
　　　　　　　　. the goal is to obtain the three balls on . to do so  we instantiate the shape graph with the initial state substitution  resp. goal  and obtain the graph  resp.  . then the algorithm looks for one action which connects a state of to a state of   as illustrated by figure 1 with the action .
1	and completeness
the method  for solution extraction  proposed in the previous section  is generally very efficient  however in specific case  it is not always possible to connect the two graphs with a single action. to obtain a solution  the planner may need to connect several substitutions of the graph ; but looking for such transitions may be as costly as planning  from scratch .
　fortunately  we can compute off-line a meta-graph which contains all necessary substitutions of to solve any instance of the problem  from the learned domain  in only one action  between and  .
1	: a meta-graph of
in order to ensure the completeness for our method  we propose an expansion algorithm of the graph	to	. the main idea is the following: if all substitutions accessible from are accessible from	too  then there exists an action which connects	to	.
　to perform such expansion  we begin with . must contain all graph that allow to connect graph such that is not directly connected to . for each  with and    generate the graph . for each
	 with	and	   check if
is directly accessible from ; if it is not the case  then add to . this algorithm stops when becomes invariant. in other words  corresponds to the  transitive closure  of in terms of substitutions.
	s1		
figure 1: the graph for 1-blocksworld domain restricted to 1 stacks.figure 1: expanding the graph ensure completenesstofigure 1: models the state space accessible with one action from1	an expansion example
to better understand this expansion  we illustrate it on the 1-blocks-world domain restricted to three stacks. figure 1 presents the shape graph and its substitutions  e.g. is a substitution of the state  . intuitively  to reverse blocks and in this domain  it is necessary to use two substitutions of ; so find a solution with only one action may be impossible only by using .
　to expand presented in figure 1  shaper must examine states         and  states which leave  . de-
veloping   the shape graph from   allows to generate via  see figure 1 . note that there does not exist any action to connect a state of to a state of ; this means that allows to access to new substitutions. consequently  it is added to . the graph presented in figure 1 corresponds to the invariant of after having examined all the other states.
　naturally  all the graphs included in differ only by a substitution. therefore  can be expressed by only using substitutions and   e.g. in figure 1  is described by two substitutionson .
1	solution extraction
　and being computed off-line  shaper performs on-line plan extraction for any possible problem from the learned domain by searching for one action.
extract solution 	   	 	 	 
	find	and	such that
 /* instantiate	with	*/ with
	while not examine all states of	do
	for each substitutions	of	do
	for each triple	of	do
	/*	a substitution */
	/*	and	*/
if
	then if	then
	return the plan: plan 	   o 
	plan 	 
return: no solutiontable 1: algorithm for solution extraction
1	an efficient algorithm
table 1 presents the three-steps algorithm used to extract a plan from an initial state to . as the graph is computed off-line  it is also possible to compute the best path for any couple of vertices in . let be the optimal plan from to in and the number of actions of this plan. considering the cost   it is possible to find the best solution using only two shape graphs and one action. indeed  the algorithm examines iteratively all possible connections  ordered by an increasing cost  the cost is defined by	 . such procedure makes it possible to obtain non-optimal  because of the graph learning  but good solutions. this is illustrated by the number of plan steps in the results presented in table 1.
　figure 1 shows an example of a solution extraction in 1blocks-world domain restricted to three stacks. first  shaper instantiates the graph with the initial state  
                       obtaining	  and	with the goal  	  obtaining	.
then  in order to find a connection between	and	  the algorithm examines  following an increasing cost  the states	...	and	...	 see figure 1  and finds as first connection.	then  to build a valid

figure 1: a solution extraction example in 1-blocks-world domain restricted to three stacks
plan  it is enough to find a plan in	and a plan in
　　. thus  the plan extracted by shaper is the following:  movetotable d b   move b a d   movetotable a c    move b d a    movefromtable c b  .
1	bounds for computation time and plan length
having the shape graph computed off-line leads to an interesting property: the solution extraction algorithm is time bounded and the plans have a known maximal length.
　indeed  the algorithm presented in table 1 examines iteratively a set of triples of . the test consists in checking equality between two states. as is computed off-line  we know in advance how many triples there are  e.g. for 1 blocks there are only 1 triples. consequently  we can compute an upper limit for the on-line solutionextraction computation time.
　in the same way  we can compute an upper limit for the longest path in . the lengthofthe longest plan maximum number of plan steps  will then be bounded by .
　the results  presented in table 1  include a max column for number-of-steps and computation time bounds.
1	completeness
this subsection present the main ideas to prove the completeness of shaper in informal way.
	for a substitution	 	and
　　　　　　　　　　. so we can demonstrate the following theorem: with being an action applicable to the state 1.
　the algorithm to build ensures that for any state in and any action such that   there exists a substitution of a state of with . then it is possible to
demonstrate that	contains all accessible shapes. given
　and . suppose that allows to access to the state which has a new shape. from definition 
	. the action	is applicable to
; if then such that and	so
has the same shape as .
　similarly  satisfies the following property: for any state in and g in   is connected to by one actionthrough the substitution    all accessible substitutions from are also accessible from . is the transitive closure of in terms of substitutions. it is also possible to recursively prove that shaper finds a plan if there exists one. given and
a plan	such that	. if then there exists	with	and	. given	and the state	and with	and	. so	 connected to	by the state	and a substitution :	 . owing to
　's property  there exists a state of and a substitution such that . that means shaper is able to find a plan between and  connect to with one action ; apply recursively this reasoning1 on   demonstrates the completeness.
1	results
in this section  we compare our planner with the most efficient planners from aips-1 competition. ff  hoffmann  1  and hsp  bonet and geffner  1  use heuristics based on a relaxed problem  plan without dellist . ipp  koehler et al.  1  and stan  fox and long  1  are derived from graphplan  blum and furst  1 . in addition  they use an on-line mechanism that allows to deal with some symmetries; that is reason why it is interesting to compare them with shaper which is able to deal with a larger class of symmetries.
　in this comparison  we do not mention talplan  doherty and kvarnstrom  1  because it is a domain dependent planner; the comparison can then be only made with shaper solution extraction step. in such a case  talplan exhibits clearly better results than shaper: the made-by-hand heuristics is still the best.
　all running time presented in table 1 are measured on a sparc ultra 1 with 1mb. '-' means that the planner does not find any solution in 1sec. and '*' means that the shape graph has already been computed for a previous problem  same domain subclass .
　the ferry and the gripper domains are interesting because they overwhelm the majority of the planners by the number of their applicable actions. despite their ability to treat state symmetries  ipp and stan can not solve large problems in both ferry and gripper domain. ferry and gripper domains are easy for shaper because of their low number of shapes  resp. for cars and for balls . thanks to their good heuristics  hsp and ff solve easily all these problems  however  note that hsp solves gripper problems with an inefficient number of steps .
　blocks-world domains give surprising results for hsp and ff. hsp solves '-1' and '-1' problems more easily than '-1' problems. for ff  the situated is opposite. problems labeled '-i' correspond to i-stacks problems: a goal for a '-1' problem is to put the first block under the stack  without changing the order of the other blocks ; for '-1' and '-1' problems  the goal is to build one  interleaved  stack composed of all the blocks from the initial stacks  e.g. move stacks and into	 .
　with several problems in the same domain subclass  e.g. all problems with 1 blocks  we better understand the importance of the off-line process  computed more efficiently than some hsp or ff solution : the graph building step is performed only once. the small number of shapes allows to have a very short computation time upper limit.
　in conclusion  shaper solves all problems in less than 1 second; in addition it builds the graph and solves all problems faster than ipp and stan  and often hsp  and extracts all problems faster than ff with a near-optimal number of plan steps.
1	conclusion
we have proposed an original approach to task planning that allows to deal efficiently with large problems. it has been

soning allows to prove that there exists a connection with one action between and .
ipp-v1stan-v1hsp-v1ff-v1shaperoff-lineon-linemaxproblemsteptimesteptimesteptimesteptimenodestime steptime steptimeferry1 cars1.111.111.111.1 cars----1.111.111.1 cars----1.111.111.1gripper1 balls1.1111.111.111 balls----1.111.111.1 balls----1.111.111.1blocks-world
1 blocks1.111.111.111.1-1 blocks1.111.11**1.1**1 blocks1.111.11**1.1**1 blocks----1.111.111.1-1 blocks----1.11**1.1**1 blocks----1.11**1.1**1 blocks----1.111.111.1-1 blocks----1.11**1.1**1 blocks----1.1--**1.1**1 blocks------1.111.111 blocks----1.11**1.1**1 blocks--------**1.1**table 1: running time and quality  in number of plan action  for some of the current best planners  see the aips-1 competition ; comparing to shaper including its off-line process.implemented in a domain independent task planner  called shaper. it performs in two steps. the first step is performed off-line and only once for a given domain subclass. it allows shaper to  capture the structure  of the state space and to store it in a data structure called the shape graph. the main contributionhere is the ability of shaper to build a very compact description when compared to the size of the complete state space. the shape graph is then used on-line by shaper to answer very efficiently to planning requests.
　shaper exhibits several interesting properties: 1  it is complete  1  it is possible to determine  after the shape graph construction  the upper limit for the on-line solution extraction computationtime as well as length of the longest plan  1  it produces  good   near-optimal  solutions.
　our future work will be devoted to a state decomposition method. indeed  we would like to decompose a state intoseveral disjoint parts in order to minimize interferences in action applicability. this should allow to generate sub-graphs and to deal with sub-shapes resulting in an even more compact state space description.
　this would help to re-use shape graph created for a given domain subclass  e.g. 1 blocks  in order to generate shapes for  bigger  subclasses  e.g. 1 blocks  besides  we hope to be able to exploit the structure of the shape graph for conformant and contingent planningas in  gue＞r＞e and alami  1 .
references
 blum and furst  1  a.l. blum and m.l. furst. fast planning through planning graph analysis. artificial intelligence  pages 1  1.
 bonet and geffner  1  b. bonet and h. geffner. planning as heuristic search: new results. 1th europeanconferenceon planning  ecp'1   1.
 doherty and kvarnstrom  1  p. doherty and j. kvarnstrom. talplanner: an empirical investigation of temporal logic-based forward chaining planner. in proc. 1th int. workshop on temporal representation and reasoning  1.
 fikes and nilsson  1  r.e. fikes and n.l. nilsson. strips: a new approach to the application of theorem proving to problem solving. artificial intelligence  1-1  1.
 fox and long  1  m. fox and d. long. the automatic inference of state invariants in tim. ai research  jair   1-1  1.
 fox and long  1  m. fox and d. long. the detection and exploration of symmetry in planning problems. proc. 1th inter. joint conf. on artificial intelligence  ijcai'1   1.
 gerevini and schubert  1  a. gerevini and l.k. schubert. inferring state constraints for domain-independent planning. in proc. 1th nat. conf. ai. aaai'1   1.
 gue＞r＞e and alami  1  e. gue＞r＞e and r. alami. a possibilistic planner that deals with non-determinism and contingency. proc.
1th inter. joint conf. on artificial intelligence ijcai'1   1.
 hoffmann  1  j hoffmann. a heuristic for domain independent planning and its use in an enforced hill-climbing algorithm. in proc. 1th int. symposium on methodologies for intelligent systems  1.
 koehler et al.  1  j. koehler  b. nebel  j. hoffmann  and y. dimopoulos. extending planning graphs to an adl subset. in 1th european conferenceon planning  ecp'1   1.
hybrid stan: identifying and managing combinatorial optimisation sub-problems in planning
maria fox and derek long
department of computer science 
university of durham  uk maria.fox dur.ac.uk d.p.long dur.ac.ukabstract
it is well-known that planning is hard but it is less well-known how to approach the hard parts of a problem instance effectively. using static domain analysis techniques we can identify and abstract certain combinatorial sub-problems from a planning instance  and deploy specialised technology to solve these sub-problems in a way that is integrated with the broader planning activities. we have developed a hybrid planning system  stan1  which brings together alternative planning strategies and specialised algorithms and selects between them according to the structure of the planning domain. stan1 participated successfully in the aips-1 planning competition. we describe how sub-problem abstraction is done  with particular reference to route-planning abstraction  and present some of the competition data to demonstrate the potential power of the hybrid approach.
1	introduction
the knowledge-sparse  or domain-independent  planning community is often criticised for its obsession with toy problems and the inability of its technology to scale to address realistic problems. planners using weak heuristics  which attempt to guide search using general principles and without recourse to domain knowledge  cannot compete  in a given domain  against a planner tailored to perform well in that domain.
　on the other hand  tailoring a planner to a particular domain requires considerable effort on the part of a domain expert. this effort is generally not reusable because a different domain requires a whole new body of expertise to be captured and it is not clear what  if any  general principles can be extracted from any single such effort to facilitate the next. the philosophy underlying our work on domain analysis is that knowledge-sparse planning can only be proposed as realistic general planning technology if it is supplemented by sophisticated domain analyses capable both of assisting a user in the development of correct domain descriptions and of identifying structure in a planning domain that can be effectively exploited to combat search.
　in this paper we describe a way of decomposing planning problems to identify instances of np-hard sub-problems  such as travelling salesman  that are most effectively solved by purpose-built technology. knowledge-sparse  general  planning is unintelligent because it uses the same methods to solve all problems  whether they genuinely require planning or are in fact instances of well-known problems that are themselves the topic of substantive research. a more powerful approach is to allow such sub-problems to be abstracted out of the planning problem and solved using specialised technology. the different problem-solving strategies must then be integrated so that they can cooperate in the solution of the original problem.
　we have been experimenting with using the automatic domain analysis techniques of tim  fox and long  1  to recognise and isolate certain combinatorial sub-problems and to propose a way in which their solution  by specialised algorithms  might be integrated with a knowledge-sparse planner.
　the work described in this paper has been successfully implemented in version 1 of the stan system  stan1  and has proved very promising. stan1 competed in the aips-1 planning competition where it excelled in problems involving route-planning sub-problems and certain resource allocation problems involving a restricted form of resource. the data sets from the competition are discussed in section 1. in stan1  tim selects between a forward and backward planning strategy depending on characteristic features of the domain. the forward planning component  forplan  is integrated with simplified specialist solvers for certain simple route-planning and resource allocation sub-problems. in section 1 we describe the components of the hybrid architecture of stan1 and explain the integration of these components.
1	recognising generic behaviours
tim can identify a collection of generic types within a domain. generic types  long and fox  1  are collections of types  characterised by specific kinds of behaviours  examples of which appear in many different planning domains. for example  domains often feature transportation behaviours since they often involve the movement of self-propelled objects between locations. tim can identify mobile objects  even when they occur implicitly  the operations by which they move and the maps of connected locations on which they move. the analysis automatically determines whether the maps are static  for example  road networks  or dynamic  for example  corridors with lockable doors . the recognition of transportation features within a domain suggests the likelihood of route-planning sub-problems arising in problem instances.
　tim also recognises certain kinds of resources which restrict the use of particular actions in a domain. finite renewable resources  which can be consumed and released in units  are encoded in strips using discrete state changes to model the stages of their consumption and release  for example  in the freecell domain . stan1 recognised and exploited this generic behaviour in the freecell domain in the aips-1 competition  see figure 1  but we are not  yet  exploiting such resources in a robust way.
　tim takes as input a standard  unannotated  strips or adl description of a domain and problem. integration of specialised technology with the search strategy of a planner is most straightforward to achieve in a heuristic forwardsearch-based planner  so we have implemented a forward planner  forplan  using a simple best-first search strategy. it uses a heuristic evaluation function  based on solving the relaxed planning problem  similar to the approach taken by hsp  bonet et al.  1  and hoffmann's ff  hoffmann  1 . like ff  forplan uses a relaxed version of graphplan to compute the relaxed plan estimate. the difference between forplan and ff is that the relaxed plan is constructed for the abstracted planning problem - that is  the part of the planning problem that remains when operators and preconditions relating to the identified sub-problem have been removed. this gives us only part of the heuristic estimate. the heuristic estimate is then improved by estimating the cost of solving the removed sub-problem. this two-part process can result in much better estimates than those produced by other forward-search-based planners. forplan does not  at present  exploit any general heuristics  such as hoffmann's helpful actions  to inform its distance estimates. since the repertoire of sub-problems that tim can recognize is currently very limited  forplan has only been integrated with sub-solvers for certain forms of route planning and discrete resource handling. without an appropriate sub-solver to exploit  forplan easily becomes lost in the search space and therefore is ineffective as a general planner at present.
1	the hybrid planner architecture
because forplan is not yet effective as a general planner we cannot rely on it for solving problems that do not have route planning or resource handling sub-problems. our intention  in the development of stan1  has been to demonstrate an effective means of abstracting sub-problems from planning instances and of integrating special-purpose sub-solvers within a general planning framework. in order to be able to report results for problems that do not have the sub-problems currently in tim's repertoire we retained stan version 1 as a default planning strategy to use in domains not featuring these sub-problems. the presence of stan1 means that tim fails safe when it fails to identify a key sub-problem. at the moment this happens quite often because we are working with some simplifying assumptions  described in section 1  but we

figure 1: the architecture of the stan1 hybrid system.
are gradually increasing the range of sub-problems that can be handled.
　tim operates as an interface to stan1  selecting between its components according to the structure of the domain. a high-level view of stan1 is presented in figure 1.
　in this paper we describe the processes by which routeplanning sub-problems  once identified by analysis of a domain description  are abstracted and their solution  by specialised algorithms  integrated with forplan. the processes by which resource-allocation sub-problems are handled are similar  but we do not describe them in detail here.
　tim first analyses the domain and problem instance to identify whether mobile objects are present in the domain  and if so whether a decomposable transportation sub-problem can be found. a transportation sub-problem is decomposable if the form of mobility present in the domain is constrained in certain predefined ways  discussed in section 1. tim identifies the mobile objects and the locatedness predicates  also referred to as the atrels  they use  for example: at  inroom  by  etc . the locatedness predicate is important for identifying actions that rely on  or bring about  changes in the locations of mobile objects. if an appropriate form of mobile is found tim invokes forplan together with the route-planning sub-solver.
　the data presented in section 1 shows the performance obtained in the aips-1 planning competition on domains involving route planning and resource handling sub-problems. these domains were: logistics and the strips version of the elevator domain  route-planning  and freecell  resourceallocation .
1	sub-problem recognition
having found that there are mobile objects in the domain tim determines whether the problem of planning their movement between locations can be safely delegated to a sub-system. if the shortest distance to be travelled by an object moving from one location to another can be ascertained by looking at the map that the object moves on  then path-planning for that object can be devolved to a shortest path algorithm. if not  if the object can temporarily vacate the map en-route between two points  then a shortest path algorithm cannot be guaranteed to find the best path. the ability to vacate the map suggests that the mobile object is able to use two or more maps  each

figure 1: the result of amalgamating two maps.
by exploiting a different  move  operator. by entering a second map and moving between its locations  the object may be able to reappear on its first map at a location different from the one it left  and this flying behaviour might give access to shorter paths than are visible on the first map alone. to enable the problem of movement planning to be delegated to a sub-solver it is necessary to equip the sub-solverwith the map that the mobile can traverse.
　in the case where several maps can be used it is necessary to amalgamate the maps and to label the edges with the movement actions that the mobile uses to traverse them  and the locatedness predicate that the mobile uses with each action. the bulldozer domain  this can be found in the pddl release  mcdermott  1   is an example of a domain in which an amalgamated map is required to enable route-planning to be delegated. the bulldozer uses two maps - the map of roads  which it traverses by driving  and the map of bridges  which it traverses by crossing. both maps give access to the same set of locations.
　a simple example arises when a mobile can both fly and drive between locations in the same collection. figure 1 shows a situation in which the shortest route between and  assuming that all edges have the same cost  is to fly from to and drive from to - a route that is available only in the amalgamated map. to complicate matters  if there are additional actions that must be performed to enable certain edges to be traversed  for example  in order to fly the wings must be bolted on  then the shortest path in the amalgamated map might be to drive from to   from to and then from to   despite the fact that this path contains more edges in
the amalgamated map.
　to perform the amalgamation of maps for   we construct a single graph structure
             . we label the edges in each with the  move  action that can be used to traverse it and the locatedness predicate relevant to that movement action. this allows route plans to be constructed  using the appropriate actions and predicates  by a dedicated sub-solver. the means by which route plans are constructed are described in section 1.
　if the object must always re-enter the first map at the same location as the one it left when it entered the second map  then the shortest path between two points is guaranteed to be visible on the first map. this restricted form of flying  which we call hovering  does not require the amalgamation of different maps. this case is not distinguished from the case in which a single map of locations is traversed using a single  move  operator.
　a problem arises when the map  or amalgamated map  that a mobile object traverses is dynamic - that is  able to be changed by the actions of the planning agent. the grid world presents such an example  because new routes become available as the robot obtains keys to open doors in the grid. the route planning sub-part of grid planning problems are closely integrated with the key-collecting goals of the robot  so not sufficiently decomposable to be delegated. stan1 does not attempt to abstract the route planning problem for this domain.
1	sub-problem abstraction
to achieve the abstraction of route-planning  once tim has identified an appropriate mobile type  stan1 associates with each mobile object a data structure which records the current location of the object. it also identifies each operator  other than the moveoperation of the mobile itself  the preconditions of which require a mobile of this type to be located at a particular location in order for the action to be executed. once found  these preconditions are removed from the operators in which they appear  but each operator is then equipped with an additional data value identifying where the mobile must be in order to satisfy the abstracted precondition. in other words  the precondition is transformed from a standard proposition into a specialised representation with equivalent meaning  but allowing specialised treatment. this specialised representation  which we call a mobile-tag  provides the means of communication between the planner and a specialised sub-solver. the way the tag is used is described in section 1. figure 1 shows the result of abstracting the from the operation in the logistics domain.
　all move operations for the mobiles are then eliminated from the domain altogether. this results in an abstracted version of the domain containing the components of the original planning problem that the planner will be required to solve.
the problem is solved by the planner in this abstracted form.
1	integration
integration between forplan and the route planning subsolver is required in three places: in determining a heuristic estimate of distance between the current state and the goal state; in constructing a route to be followed in moving a mobile between two locations in the plan; in generating a plan format for reporting the routes to be traversed by the mobiles in the plan. we explain each of these stages in turn.

figure 1: the sub-problem abstraction process　forplan solves the abstracted problem using a heuristic estimate of the value of a state based on the length of the relaxed plan between that state and the goal. the heuristic estimate is calculated by first constructing a relaxed plan with the abstracted operators  and calculating its length  and then adding to it an estimate for the lengths of the routes that would have to be traversed by any mobiles it uses. for the lengths of these routes to be estimated it is necessary for the abstracted relaxed plan to record the commitments it makes on mobile objects to visit locations at which abstracted actions will be performed. for example  in logistics  the abstracted plan consists just of load and unload actions  but their successful execution commits mobile objects  trucks and planes  to be in place. the abstracted plan therefore maintains an array of commitments of mobiles to visit certain locations  associated with the layers of the relaxed plan graph  and the sub-solver estimates the lengths of the routes that available mobiles must traverse in order to meet these commitments.
　the cost of traversing the routes that a plan entails is too expensive to compute with accuracy. the arrays of commitments show which locations each mobile is required to visit to satisfy the requirements of the plan  with some ordering constraints implied by the layering of the relaxed plan graph and indicating the dependencies between the activities the mobile will be involved in at each location  loading must be carried out before unloading and so on . to calculate a shortest path that visits all these locations and respects these orderings is a variation on a travelling salesman problem  with multiple travellers and additional constraints. this problem is hard and cannot be solved repeatedly as part of the heuristic evaluation of a state. instead  we produce an estimate of the cost by assuming that each mobile can visit each location in turn from the closest of the locations it has previously visited in the plan  respecting ordering constraints on the visits. although this is an unsophisticated approach to tackling the travelling salesman problem  its integration with the planning process is a proof of concept  demonstrating the possibility of integrating more specialised technology. despite its lack of sophistication it gives a better estimate of the cost of a state than a pure relaxed plan estimate  since relaxed plan estimates neglect the fact that a mobile cannot be in two places at the same time  the relaxed plan ignores delete conditions and it is these which express the fact that a mobile cannot be at two places at once .
　integration between the planner and the route-planner is required again when actions are selected for addition to the plan. once an action is selected it is checked to determine whether it contains an abstracted locatedness precondition. if so  a path is proposed to move the mobile from its current location to the required destination  recorded within the mobile tag associated with action . we use the shortest path between the current location of the mobile  which is always known in a forward search  and the required location recorded in the mobile tag. at present this path is precomputed by tim using floyd's shortest paths algorithm  floyd  1   on the  possibly amalgamated  map inferred from the initial state. this approach works well for static maps  where the shortest paths remain fixed  and in situations in which the movement consumes no additional resources. if the mobile does use resources during its movement  it might be that the shortest path is not the best  but instead a longer path which consumes fewer resources is to be preferred.
　finally  it is necessary to integrate the efforts of the planner and the route-planner to produce output in the form of a plan sequence. once a route has been planned between the appropriate locations  stan1 generates instantiations of the necessary move operators to produce a plan sequence corresponding to standard format for strips plans. below we present some of the preliminary results obtained using domains from the strips subset of the aips1 competition data set. in this collection of domains  logistics and the miconic-1 lift domain both contain a path-planning sub-problem which tim was able to identify and extract. even using just our simple path-planning strategy we were able to obtain a significant performance advantage from exploiting path-planning abstraction.
1	experimental results
the data sets presented here were compiled by fahiem bacchus during the aips-1 competition  held in breckenridge  colorado. in the graphs  the thick line plots the results of stan1. graphs showing time performance are log-scaled.
　the graphs show howstan1 performed on problems from the strips data set involving either route-planning or resource allocation. the planners used for comparison are ff  hoffmann  1   hsp-1  bonet and geffner  1   talplanner  doherty and kvarnstrom  1   shop  nau et al.  1  and  occasionally  grt  refanidis and vlahavas  1 . the problems used were logistics  freecell and the strips version of the miconic-1 elevator domain. only the logistics and freecell data is shown  because of space restrictions.
　the competition comprised a fully-automated track and a hand-coded track in which planners were allowed to use hand-tailored domain knowledge. in the results presented here  stan1  ff  grt and hsp-1 are all fully-automated  whilst talplanner and shop use hand-coded control knowledge.
　stan1 participated in the fully-automated track on the strips problems. all planners able to handle the strips version of pddl competed in the strips problems  including planners in the hand-coded track. however  despite the advantage of being supplied with hand-coded control knowledge  these planners did not consistently out-perform the fully automated planners. for example  stan1 and ff were both faster than talplanner and shop on the first logistics data set  not shown  and produced at least as high quality plans.
　from figure 1 it can be observed that stan1 took slightly longer than ff on the larger logistics problems  but produced slightly better quality plans than any other planner  including those in the hand-coded track. as was emphasised earlier  the improvementin plan quality overff derivesfrom the fact that stan1 uses a more informative heuristic than ff. stan1 is using route-abstraction in this domain and achieves a small but consistent improvement in plan quality as a result.
　the freecell domain  figure 1  was introduced specially for the competition and is a strips formalisation of a solitaire card game released under windows. freecell has a resource-allocation sub-problem  because the free cells are a restricted  renewable and critical resource. to estimate how far a state is from the goal it is necessary to take into account the cost of ensuring that sufficient free cells are made available to meet the requirements of the abstracted relaxed plan. our purpose-builttechnology for calculating this cost ensures that the consumption of resources does not exceed availability of those resources. if a plan entails over-consumption then the cost of sufficient release actions to redress the balance is added in to the estimate of its value. we have not yet succeeded in obtaining a robust way of accurately estimating these costs  and the performance of stan1 is somewhat inconsistent as can be seen from the graph. despite being fastest in all of the problems that it could solve  stan1 missed several problems and was unable to solve any of the larger instances. its plan quality was generally good  except for some anomalously long plans. more work is needed to adequately estimate the cost of distributing resources efficiently throughout a plan.
　the propositional elevator domain used in the competition reveals one of the weaknesses of the nearest neighbour heuristic  demonstating that it is not a good general purpose approach for route-planning. in this domain stan1 produces slightly poorer quality plans at the the top end  than either ff or grt  data not shown . this is because the nearest neighbour heuristic favours visiting all of the pick-up locations before any of the drop-off locations  the simplest way

figure 1: quality of plans for  and time consumed to solve  logistics problems 1

figure 1: quality of plans for  and time consumed to solve  freecell problems.
of respecting the ordering constraints in the plan . in fact  a subtler approach would be to allow the drop-off locations to be inter-mingled with the pick-up ones  provided that a dropoff location is only selected next when the necessary people are on board. the nearest-neighbour heuristic tends to work less well whenever there are many objects to be transported  and many locations to be visited   and few carriers  as well as additional constraints  derived from the need to collect objects before delivering them  as in the elevator domain. the heuristic results in greater accuracyin logistics because there are  typically  few packages to be transported by any one carrier. however  the nearest-neighbour heuristic was only ever intended to demonstrate that it is possible to integrate purpose-built machinery into the heuristic estimate  allowing the incurred cost of solving an abstracted problem to be taken into account in measuring the goodness of a state. we are currently investigating more sophisticated special-purpose algorithms.
　the data presented here shows that forplan can rival the best available planning technology in domains featuring the sub-problems that can be identified by tim. the fact that forplan has no general search control mechanisms  and obtains its performance in these domains entirely by exploitation of appropriate sub-solvers  gives a clear indication of the potential value of automatic sub-problem abstraction within a forward planning framework. although forplan is far from effective as a general planner  the exploitation of subproblem abstraction makes a range of hard problems manageable and the generated solutions efficient.
1	further work
although these foundations have produced promising results the framework we have used to achieve integration is somewhat unsophisticated and inflexible. tim currently only recognises certain specific forms of mobile and very restricted forms of resource. as tim fails safe when appropriate forms are not recognised this does not affect the completeness of stan1. it does mean that stan1 is often unable to exploit domain structure effectively and we are working on extending its repertoire.
　stan1 can only integrate with one specialised sub-solver  even when there are two or more combinatorial sub-problems in a domain. at present stan1 emphasises route-planning abstraction because we have made most progress in solving route-planning sub-problems effectively. an important development is to enable integration with more than one subsolver. this will involve finding a way to communicate constraints between multiple sub-solvers and the planner.
　our  specialised technology  is currently very simplistic. an important refinement is to enable proper integration between the planner and the best available technology for solving combinatorial sub-problems where these arise. our handling of resources in stan1 is very restricted. we are working on the recognition of makespan subproblems  which are instances of multi-processor scheduling  and their treatment using approximation algorithms for scheduling.
1	conclusions
we have experimented  using stan1  with the design of a hybrid planning system in which the choice of problemsolving strategy is made automatically following static analysis of the domain. our current goals are to improve the integration between forplan and the specialised solvers  allowing a more sophisticated profile of sub-problems to be managed  and to explore what advantages might be gained from integrating other planning strategies into the hybrid.
　the key idea underlying our hybrid approach is that planning is not appropriate technology for solving all problems  and that resorting to generic search  or switching between a number of timed strategies  is not an effective way to address such problems. instead we are interested in building up a collection of purpose-built strategies for combatting some of the most commonly occurring combinatorial sub-problems and making these available  together with techniques for recognising where these problems arise in planning domains. the decision about how to approach a given planning problem can then be made automatically  in a principled way  by deciding how to view the problem and deploying the most effective technology to solve it.
references
 bonet and geffner  1  b. bonet and h. geffner. planning as heuristic search: new results. in proc. ecp  1.
 bonet et al.  1  b. bonet  g. loerincs  and h. geffner. a robust and fast action selection mechanism for planning. in aaai  1.
 doherty and kvarnstrom  1  p. doherty and j. kvarnstrom. talplanner: an empirical inverstigation of a temporal logic-based forward chaining planner. in proceedings of 1th international workshop on temporal representation and reasoning  1.
 floyd  1  r. w. floyd. algorithm 1: shortest path. cacm  1   1.
 fox and long  1  m. fox and d. long. the automatic inference of state invariants in tim. jair  1  1.
 hoffmann  1  j. hoffmann. a heuristic for domainindependent planning and its use in an enforced hillclimbing algorithm. technical report  albert-ludwigs university  freiburg  germany  1.
 long and fox  1  d. long and m. fox. automatic synthesis and use of generic types in planning. in aips  1.
 mcdermott  1  d. mcdermott. pddl - the planning domain definition language. technical report  yale university  http://www.cs.yale.edu/users/mcdermott.html  1.
 nau et al.  1  d. nau  y. cao  a. lotem  and h. mun ozavila. shop: simple hierarchical orederd planner. in proc. ijcai  1.
 refanidis and vlahavas  1  i. refanidis and i. vlahavas. grt: a domain independent heuristic for strips worlds based on greedy regression tables. in proc. ecp  1.

planning
search heuristics in planning

local search topology in planning benchmarks: an empirical analysis
jorg hoffmann：
institute for computer science albert ludwigs university
georges-ko：hler-allee  geb. 1
1 freiburg  germany

abstract
many state-of-the-art heuristic planners derive their heuristic function by relaxing the planning task at hand  where the relaxation is to assume that all delete lists are empty. looking at a collection of planning benchmarks  we measure topological properties of state spaces with respect to that relaxation. the results suggest that  given the heuristic based on the relaxation  many planning benchmarks are simple in structure. this sheds light on the recent success of heuristic planners employing local search.
1	introduction
in the last two years  planning systems based on the idea of heuristic search have been very successful. at the aips-1 planning systems competition  hsp1 compared well with the other systems  mcdermott  1   and at the aips-1 competition  out of five awarded fully automatic planners  ff and hsp1 were based on heuristic search  while another two  mips and stan  were hybrids that incorporated  amongst other things  heuristic search  bacchus and nau  1 .
　interestingly  four of these five planners use the same base approach for deriving their heuristic functions: they relax the planning task description by ignoring all delete lists  and estimate  to each search state  the length of an optimal relaxed solution to that state. this general idea has first been proposed by bonet et al. . the length of an optimal relaxed solution would yield an admissible heuristic. however  as was proven by bylander   computing the optimal relaxed solution length is still np-hard. therefore  bonet et al. introduced a technique for approximating optimal relaxed solution length  which they use in both versions of hsp  bonet and geffner  1 . the heuristic engines in ff  hoffmann  1  and mips  edelkamp  1  use different approximation techniques.
　three of the above planners  hsp1  ff  and mips  use their heuristic estimates in variations of local search algorithms  where the search space to a task is the state space  i.e.  the space of all states that are reachable from the initial state. now  the behavior of local search depends crucially on the problem structure  i.e.  on the topology of the search space.
thus  the success of these heuristic planners on many planning tasks gives rise to the suspicion that those task's state spaces have a simple structure with respect to relaxed goal distances. in this paper  we shed light on that suspicion. following frank et al.   we define a number of structural phenomena in search spaces under heuristic evaluation  impacting the performance of local search algorithms. we compute the optimal relaxed solution length to reachable states in small planning tasks  and measure structural properties. our results suggest that  in fact  the tasks contained in many benchmark planning domains have a simple state space topology  at least when using the optimal relaxed heuristic. to give an example of how this observation carries over to the approximation techniques used by existing heuristic planners  we apply the same technique of data collection to the ff heuristic. as it turns out  the results are similar. specifically  it follows that ff's search algorithm is a polynomial solving mechanism in a number of planning benchmark domains  under the hypothesis that the larger instances behave similar to the smaller ones.
　section 1 introduces our general approach  section 1 gives the basic definitions. sections 1 and 1 define structural phenomena in search spaces under heuristic evaluation  and give empirical data. section 1 summarizes the results in a taxonomy for planning domains. section 1 applies the methodology to the ff heuristic. section 1 concludes and gives an outlook on further research.
1	general approach
in our experiments  we used solvable planning tasks only  as we are interested in finding out why local search can succeed so quickly on many benchmark tasks. we looked at instances from 1 different strips and adl benchmark domains. due to space restrictions  we only present the results for the domains used in the competitions here  as those domains are well known in the planning community.
　to obtain data on how planning tasks behave with respect to the relaxation  rather than with respect to any of the approximation techniques used by existing heuristic planners  we consider the optimal relaxed solution length as our heuristic. as determining that optimal length is np-hard  it can only be computed for small planning instances. we build an explicit state space representation to such instances  and look at the topology in detail. this yields a clear picture of the fundamental structural differences between instances from different planning domains. in that context  we state some hypotheses. a piece of future work is to verify those.
　in total  the competitions featured 1 strips and adl domains: assembly  blocksworld  freecell  grid  gripper  logistics  miconic-adl  miconic-simple  miconic-strips  movie  mprime  mystery  and schedule. in 1 of these domains  we used random task generation software to produce small instances  at least 1 per domain. in gripper  there is only one instance of each size: balls to be transported. in movie  every instance of the aips-1 suite was small enough to be looked at in detail.
　sometimes  we depict scaling behavior. as our instances are all quite small anyway  we need  for that purpose  a finer distinction between instances than obvious criteria like the number of objects. we define the difficulty of a task to be the length of an optimal solution plan  and order our instances within any domain by increasing difficulty. except in the movie domain  where all instances in the aips-1 suite have the same difficulty   larger instances are on average more difficult than smaller ones. the maximal difficulty of any instance we could look at is in the gripperdomain  in the assemblyand logisticsdomains  in grid  and
in the blocksworld. in movie  all instances have difficulty   and in the remaining domains our maximal difficulty ranges from to .
1	basic definitions
the	competition	domains	contain	tasks	specified	in	the
strips and adl languages. in both cases  a planning task is specified in terms of a set of objects   an initial state   a goal formula   and a set of operator schemata .     and are based on a collection of predicate symbols. planning tasks from the same domain share the same sets of predicate symbols and operator schemata. instantiating the operator schemata with all objects yields the actions to the task. states are sets of logical atoms  i.e.  instantiated predicates. any action has a precondition  which is a formula that must hold in a state for the action to be applicable. also  an action has an add- and a delete-list. these are sets of atoms  where each atom has a condition formula attached to it  in strips  these condition formulae are trivially true . if an action is applied  the atoms with satisfied condition in the add list are added to the state  and those with satisfied condition in the delete list are removed from the state. a plan is a sequence of actions that  when successively applied to the initial state  yields a state that satisfies the goal formula.
　ignoring the delete lists simplifies a task only if all formulae are negation free. in strips  this is the case by definition. in general  for a fixed domain  any task can be polynomially transformed to have that property: compute the negation normal form to all formulae  negations only in front of atoms   then introduce for each negated atom a new atom notand make sure it is true in a state iff is false  gazen and knoblock  1 . in the following  we assume formulae to be negation free. we will investigate properties of the optimal relaxed heuristic . for any state in a planning task with actions and goal condition   the relaxed task to is the task defined by the same goal condition   the initial state   and the action set   which is identical to except that all delete lists are empty. then  is the length of a shortest plan that solves the relaxed task to   or if there is no such plan.
　we will be looking at the topology of search spaces with heuristic evaluation. the structural properties we will introduce do not depend on the planning framework. we therefore define them in a general manner  embedding planning state spaces as a special case.
definition 1 a search space is a -tuple   where is the set of states  are the state transitions  are the goal states  and is the initial state.
　given a planning task  the search space we look at is what is usually referred to as the state space. there  is simply the initial state of the task. is the set of states that are reachable from the initial state by successively applying actions from   and contains all pairs where one action  executed in   yields the state . is the set of all states that satisfy the goal condition. looking only at solvable instances  there is at least one such state.
definition 1 given a search space	.	the goal distance of	is
　the distance between any two states is the length of a shortest path from to in the directed graph given by and   or if there is no such path.
heuristic functions approximate	.
definition 1 given a search space	. a heuristic
is a function	  such that
.
we require that a heuristic recognizes goal states  yielding if and only if   which is equivalent to
     . we allow heuristics to return   as search spaces can contain dead ends.
1	dead ends
because state transitions in a search space are  in general  directed  there can be states from which no goal state is reachable.
definition 1 given a search space	. a state
	is a dead end  if	.
　if a local search algorithm runs into a dead end  it is lost. a heuristic function can return to indicate that might be a dead end. desirably  it does so only on states that really are dead ends.
definition 1 given a search space	with a
heuristic	.	is completeness preserving  if
.
　with a completeness-preserving heuristic  we can safely prune states where . for planning tasks  if a task can not be solved even when ignoring the delete lists  then the task is unsolvable. therefore  the function is completeness preserving. for the rest of the paper  we only consider those states where the heuristic value is less than .
definition 1 given a search space with a completeness-preserving heuristic . the relevant part of the search space is	.
　any search space with heuristic evaluation falls into one of the following four classes  with respect to dead ends.
definition 1 given a search space	with a
completeness-preserving heuristic	. the search space is
1. undirected  if
1. harmless  if  and1. recognized  if  and1. unrecognized  if
　for each of our planning instances  we verified which of the above classes the state space belonged to. we say that a domain belongs to class if the state spaces of all our instances belong to a class   and at least one instance belongs to class . we found the following.
1. blocksworld  gripper  and logistics have undirected graphs.
1. grid  miconic-strips  miconic-simple  and movie are directed  but do not have dead ends.
1. in assemblyand schedule  all dead ends are recognized.
1. freecell  miconic-adl  mprime  and mystery contain unrecognized dead ends.
　in addition to our empirical analysis  the results from 1. and 1. can be shown analytically. for undirected graphs  such a method is described by koehler and hoffmann . for the domains in class four  it is also interesting to see how many unrecognized dead ends there are. we measure the percentage of such states in the relevant part of the state space  see figure 1.
domainfreecell11111miconic-adl11111mprime11111mystery11111figure 1: percentage of unrecognized dead ends in the relevant part of the state space. mean values for increasing task difficulty in different domains.
　for each single domain in figure 1  the sequence of columns gives a picture of how the values develop with increasing task difficulty. in each domain  the tasks are divided into five groups. the difficulty of a task in group lies within interval   where divide our range of difficulty in that domain into five parts of same size. note that the intervals are different for each domain  so the values within a column are not directly comparable.
　as figure 1 shows  the mprimeand mysterytasks can contain a lot of unrecognized dead ends  and have the tendency to contain more of such dead ends the more difficult they get. for freecell and miconic-adl  we can not conclude much more than that there can be unrecognized dead ends. it seems that the percentage grows with task difficulty  and that tasks with high percentage are out of the range of difficulty we could look at.
1	search space topology
for sat problems  the topology of search spaces with respect to the behavior of local search has been investigated by frank et al. . as the basis of their work  frank et al. formally define a partitioning of the search space into plateaus of different kinds. for our purposes  we extend their definitions to deal with our general notion of search spaces with heuristic evaluation  where edges can be directed.
definition 1 given a search space with a completeness-preserving heuristic . for   a plateau of level is a maximal subset of for which the induced subgraph in is strongly connected  and for each .
　plateaus are regions that are equivalent under reachability aspects  and look the same from the point of view of the heuristic function. obviously  each state lies on exactly one plateau.
definition 1 given a search space with a completeness-preserving heuristic   and a plateau . a state is an exit of   if there is a state such that and . is an improving exit  if  for at least one such   .
　exits are states from which one can leave a plateau without increasing the value of the heuristic function. in undirected graphs  like are considered by frank et al.   leaving a plateau implies changing the value of the heuristic function  so all exits are improving there. according to the proportion of exits on a plateau  frank et al. divide plateaus into four classes: local minima  benches  contours  and global minima. taking account of directed edges  we have two types of exits  and define the following six different classes.
definition 1 given a search space with a completeness-preserving heuristic .
1. a recognized dead end is a plateau	of level	.
1. a local minimum is a plateau of level that has no exits.
1. a plain is a plateau of level that has at least one exit  but no improving ones.
1. a bench is a plateau of level that has at least one improving exit  and at least one state that is not an improving exit.
1. a contour is a plateau of level that consists entirely of improving exits.
1. a global minimum is a plateau	of level	.
　each plateau belongs to exactly one of the above classes. in our solvable instances  global minima are exactly the plateaus of level . with a completeness-preserving heuristic  recognized dead ends are irrelevant  and can be ignored. from local minima  there is no direct way of getting closer to the goal.
from benches  there is. from contours  one can get closer immediately. plains behave as a kind of entrance to either local minima or benches.
definition 1 given a search space with a completeness-preserving heuristic . a flat path is a path where all states on the path have the same heuristic value. for a plateau   the flat region from is the set of all plateaus such that there is a flat path from some to some .
	for a plain	  if there is at least one bench or contour in
　　　  then behaves similar to a bench  with at least one improving exit being within reach. otherwise  starting in   without increasing the value of the heuristic function  one will inevitably end up in a local minimum.
definition 1 given a search space with a completeness-preserving heuristic . a plain leads to benches if contains some bench or contour. otherwise  leads to local minima.
　based on the above definitions  and using an explicit search space representation  one can measure all kinds of structural parameters. due to space restrictions  we only discuss some of the most interesting parameters here.
1	local minima
first  we are interested in the percentage of states that lie on local minima. before doing this  we need to take a closer look at the definition of local minima. these are flat regions where all neighbors have higher evaluation. stepping on to one of these neighbors does not necessarily improve the situation  though: it might be  for example  that the only exits on that neighbor lead back to the local minimum. in general  a local minimum is only the bottom of a valley  where what we really want to know about is the whole valley. valleys are characterized by the property that one can not reach a goal state without increasing the value of the heuristic function.
definition 1 given a search space with a completeness-preserving heuristic . a state has a full exit path  if there is a path from to a goal state such that the heuristic value of the states on the path decreases monotonically.
　one state on a plateau has a full exit path if and only if all states on that plateau do so. if a plateau has no full exit paths  then it is part of a valley.
definition 1 given a search space with a completeness-preserving heuristic . a valley is a maximal set of plateaus such that no has full exit paths  no is a recognized dead end  and for all   is strongly connected to .
　the existence of valleys is  in any search space  equivalent to the existence of local minima. it turns out that  in 1 of the 1 competition domains  the state spaces of all our instances do not contain any local minima at all.
hypothesis 1 let be a planning task from any of the assembly  grid  gripper  logistics  miconic-simple  miconic-strips  or movie domains. then  the state space of	does not contain any local minima under evaluation with
.
　in figure 1  we show the mean percentage of states on valleys for those domains where we found local minima.
domainblocksworld11111freecell11111miconic-adl11111mprime11111mystery11111schedule11111figure 1: percentage of states on valleys in the relevant part of the state space. mean values for increasing task difficulty in different domains.
　any unrecognized dead end state lies in a valley. therefore  the percentage of valleys is at least as high as the percentage of unrecognized dead ends for the domains shown in figure 1. in freecelland miconic-adl  the states on valleys are exactly the unrecognized dead ends in all our examples. in mprime and mystery  there can be more valley states. in
blocksworld and schedule  values seem to approach an upper limit on our most difficult tasks. computing maximum instead of the mean values shown in figure 1  we found that some of our scheduletasks contain up to valley states. in our blocksworld suite  however  the maximum valley percentage is constantly   irrespective of difficulty.
1	contours
we also measure the average percentage of states lying on contours that are not part of a valley-regions in the state space that are dominated by such contours are likely to be passed quickly by a local search algorithm. in movie  the percentage is constantly . in assembly  logistics 
miconic-simple  miconic-strips  and schedule  between and of the relevant state space lie on such contours in our examples  and there is no clear tendency that the values decrease with task difficulty. in the remaining 1 domains  there is such a tendency. values are particularly low in the blocksworld  going down to in our most difficult tasks.
1	benches
for benches  the percentage of states alone is not a very informative parameter  as any plateau is a bench given it has at least one improving exit. what really matters is  how difficult is it to find such an exit  possible criteria for this are the size of benches  or the proportion of improving exits. here  we define another criterion that is-as will be shown in the next section-especially relevant for ff's search algorithm. the criterion is named maximal exit distance. we measure that distance for what we call bench-related plateaus. these are benches  and plains leading to benches. recall definitions 1 and 1.
definition 1 given a search space with a completeness-preserving heuristic . for a state on a bench-related plateau  the exit distance is the length of a shortest flat path from	to some	such that there is some
with	. the maximal exit distance
of a bench-related plateau	is
.
　the maximal exit distance in a search space is the maximum over the maximal exit distances of all bench-related plateaus  or if there are no bench-related plateaus. it turns out that  in 1 of the competition domains  the maximal exit distance is constant across all our examples.
hypothesis 1 to any of the gripper  logistics  miconicsimple  miconic-strips  or movie domains  there is a constant   such that  for all tasks in that domain  the maximal exit distance in the state space of is at most under evaluation with .
　in the listed domains  all our examples have maximal exit distance   so the constant fulfills the hypothesized property there. the crucial point is that  in those 1 domains  there apparently is an upper limit to the maximal exit distance. in contrast to this  computing mean values  we found that the mean maximal exit distance grows with difficulty in our suites from 1 of the remaining 1 domains. in mprime  mean values show a lot of variance  making it hard to draw any conclusions. see figure 1.

assembly1.1.1.1.1blocksworld11111freecell111grid11111miconic-adl11.1.1mprime11111mystery11111schedule1111figure 1: maximal exit distance. mean values for increasing task difficulty in different domains.
1	a planning domain taxonomy
our approach divides planning domains into a taxonomy of different classes with respect to the heuristic  depending on which dead end class they belong to  whether there can be local minima  and whether there is an upper limit to the maximal exit distance. see a schematic overview of our results in figure 1.
　remember that the existence of unrecognized dead ends implies the existence of valleys  which implies the existence of local minima. the overview in figure 1 gives an appealing impression of the kind of domains that state-of-the-art heuristic planners work well on: the  simple  domains are in the left bottom corner  while the  demanding  ones are in the top right corner. in fact  in the aips-1 competition  the freecell and miconic-adl domains constituted much more of a problem to the heuristic planners than  for example  the logistics domain did.
　the majority of the competition domains lie on the  simple  left bottom side of our taxonomy. in fact  this phenomenon gets even stronger when looking at other commonly

figure 1: a taxonomy for planning domains  overviewing our results.
used planning benchmark domains: from our 1 domains  1 do not exhibit any local minima. in 1 of those 1 domains  the mean maximal exit distance does not grow with difficulty. in the briefcaseworld  for example  the distance is apparently bounded by	.
　for domains without local minima and with bounded maximal exit distance  we can be precise about simplicity. consider the following algorithm  working on a search space with a heuristic .
:=
while	do
	do breadth first search for	 
　　　:= endwhile
　this algorithm has been termed enforced hill-climbing by hoffmann   and is used in ff.
proposition 1 let be a set of search spaces with heuristics  such that no search space contains a local minimum  and is an upper limit to the maximal exit distance. say we have a search space   with heuristic .
let be the maximal number of outgoing edges of any state. then  started on   enforced hill-climbing will find a goal state after considering states.
　without local minima  each iteration of enforced hillclimbing crosses a bench-related region or a contour  so it finds a better state at maximal depth   considering states. each iteration improves the heuristic value by at least one  so after at most iterations  a goal state is reached.
　reconsider the terminology introduced at the beginning of section 1. say we have a planning domain with operator schemata . any task specifies  amongst other things  the set of objects   yielding the action set . an obvious upper limit to the number of outgoing edges in the task's state space is . furthermore  if the longest add list of any action has size   then  for non dead end states   .
this is because with empty delete lists  each atom needs to be added at most once. finally  and are polynomial in for fixed . thus  considering only the solvable tasks from a domain  applying proposition 1 gets us the following. if does not yield any local minima  and produces a constant maximal exit distance  then enforced hill-climbing  using   finds a goal state to each task by looking at a number of states polynomial in	.1
1	explaining ff's runtime behavior
to give an example of how our results under evaluation with carry over to existing approximation techniques  we ran the same experiments  using the ff heuristic. the results are summarized in figure 1.

figure 1: results overview for the ff heuristic.
　comparing figure 1 with figure 1  one sees that there are three domains where local minima arise  when using the ff heuristic instead of . however  the averaged valley percentage is below in grid  below in assembly  and below in miconic-simple. four of the domains that are simple with stay simple with the ff heuristic.
　as hoffmann  describes  the ff system uses the enforced hill-climbing algorithm as its search method. for strips planning tasks  it is easy to see that  like it is the case for the heuristic  ff's heuristic estimate to any state is bounded by the number of actions. thus  if hypotheses 1 and 1 are true for the strips domains gripper  logistics  miconic-strips  and movie  under evaluation with the ff heuristic  then enforced hill-climbing  using that heuristic  solves the tasks in each of these domains by evaluating polynomially many states.
1	conclusion and outlook
the intuition that many planning benchmarks are  simple  in some sense is not new to the planning community. what the author personally likes most about the presented work is that it provides a formal notion of what simplicity  in that context  might mean. we give empirical data supporting that many benchmarks are  in fact  simple in that formal sense. the work provides insights into fundamental structural differences between different planning domains  and offers explaining the success of ff-and possibly of other state-ofthe-art heuristic planners-as utilizing the simplicity of the benchmarks.
　the presented results are preliminary to the effect that observations are made on a collection of comparatively small planning tasks. the stated hypotheses must be verified. for the function  we are going to prove our hypotheses analytically. for the ff and hsp heuristic functions  we are going to take samples from the state spaces of larger tasks.
　practically  we see the benefits of our results in mainly three areas. firstly-which is a line of work that we are currently exploring-one can try to recognize simple planning tasks automatically  and thereby predict the runtime behavior of ff or other heuristic planners. secondly  knowing about the strengths and weaknesses of existing heuristic functions may help in designing better ones. finally  a better understanding of the structural differences between planning domains may help in designing more challenging benchmarks.
acknowledgments
the author thanks bernhard nebel for discussions on the presented work in all stages of its development. thanks also go to malte helmert for many useful comments on an early version of the paper.
references
 bacchus and nau  1  fahiem bacchus and dana nau. the 1 ai planning systems competition. the ai magazine  1. forthcoming.
 bonet and geffner  1  blai bonet and hector geffner.＞ planning as heuristic search. artificial intelligence  1. forthcoming.
 bonet et al.  1  blai bonet  gabor loerincs  and h＞ ector＞ geffner. a robust and fast action selection mechanism for planning. in proc. aaai-1  pages 1. mit press  july 1.
 bylander  1  tom bylander. the computational complexity of propositional strips planning. artificial intelligence  1-1 :1  1.
 edelkamp  1  s. edelkamp. heuristic search planning with bdds. in ecai-workshop: puk  1.
 frank et al.  1  jeremy frank  peter cheeseman  and john stutz. when gravity fails: local search topology. journal of artificial intelligence research  1- 1  1.
 gazen and knoblock  1  b. cenk gazen and craig knoblock. combining the expressiveness of ucpop with the efficiency of graphplan. in proc. ecp'1  pages 1- 1. springer-verlag  september 1.
 hoffmann  1  jorg hoffmann.： a heuristic for domain independent planning and its use in an enforced hillclimbing algorithm. in proc. ismis-1  pages 1. springer-verlag  october 1.
 koehler and hoffmann  1  jana koehler and jorg hoff-： mann. on reasonable and forced goal orderings and their use in an agenda-driven planning algorithm. journal of artificial intelligence research  1-1  1.
 mcdermott  1  drew mcdermott. the 1 ai planning systems competition. the ai magazine  1 :1  1.
reviving partial order planning
xuanlong nguyen & subbarao kambhampati
department of computer science and engineering
arizona state university  tempe az 1
	email:	xuanlong rao  asu.eduabstract
this paper challenges the prevailing pessimism about the scalability of partial order planning  pop  algorithms by presenting several novel heuristic control techniques that make them competitive with the state of the art plan synthesis algorithms. our key insight is that the techniques responsible for the efficiency of the currently successful planners-viz.  distance based heuristics  reachability analysis and disjunctive constraint handling-can also be adapted to dramatically improve the efficiency of the pop algorithm. we implement our ideas in a variant of ucpop called repop . our empirical results show that in addition to dominating ucpop  repop also convincingly outperforms graphplan in several  parallel  domains. the plans generated by repop also tend to be better than those generated by graphplan and state search planners in terms of execution flexibility.
1	introduction
most recent strides in scaling up planning have centered around two dominant themes - heuristic state space planners  exemplified by unpop  hsp-r  and csp-based planners  exemplified by graphplan and satplan  . this is in stark contrast to planning research up to five years ago  when most of the efforts were focused on scaling up partial order planners 1; 1; 1; 1; 1; 1 . despite such efforts  the partial order planners continue to be extremely slow and are not competitive with the fastest state search-based and cspbased planners. indeed  the recent advances in plan synthesis have generally been  mis interpreted as establishing the supremacy of state space and csp-based approaches over pop approaches.
　despite its current scale-up problems  partial order planning remains attractive over state space and csp-based planning for several reasons. the least commitmentinherentin partial order planning makes it one of the more open planning frameworks. this is evidenced by the fact that most existing architectures for integrating planning with execution  information gathering  and scheduling are based on partial order planners. in

　　this research is supported in part by the nsf grant iri-1  afosr grant f1-1 and the nasa grants nag1 and ncc-1. we thank david smith  malik ghallab  austin tate  dan weld  terry zimmerman  biplav srivastava  minh b. do  and the ijcai referees for critical comments on the previous drafts of this paper.
　　ucpop  unpop  repop. repop'ssource code is available from http://rakaposhi.eas.asu.edu/repop.html.
  smith argues that pop-based frameworks offer a more promising approach for handling domains with durative actions  and temporal and resource constraints as compared to other planning approaches. in fact  most of the known implementations of planning systems capable of handling temporal and durative constraints -including ixtet  as well as nasa's rax -are based on the pop algorithms. even for simpler planning domains  partial order planners search for and output partially ordered plans that offer a higher degree of executionflexibility. in contrast  none of the known state space planners can find parallel plans efficiently   and csp planners such as graphplan only generate a very restricted class of parallel plans  see section 1 .
　the foregoing motivates the need for improving the efficiency of pop algorithms. we show in this paper that the insights and techniques responsible for the advances in plan synthesis made in the recent years in the context of state-based and csp-based planners are largely adaptable to pop algorithms. in particular  we present novel methods for adapting distance based heuristics  reachability analysis and disjunctive constraint processing techniques to pop algorithms. distancebased heuristics are used as the basis for ranking partial plans and as flaw selection methods. the other two techniques are used for efficiently enforcing the consistency of the partial plans-by detecting implicit conflicts and resolving them.
　our methods help scale up pop algorithms dramatically- making them competitive with respect to state space planners  while preserving their flexibility. we present empirical studies showing that repop  a version of ucpop  enhanced by our ideas  can perform competitively with other existing approaches in many planning domains. in particular  repop appears to scale up much better than graphplan in the parallel domains we tried. more importantly  the solutions repop generates are generally shorter in length  and provide significantly more execution flexibility .
　the paper is organized as follows. in the next section we will briefly review the basics of the pop algorithm. section 1 describes how distance based heuristics can be adapted to rank partial plans. section 1 shows how unsafe links flaws can be generalized and resolved efficiently. section 1 reports empirical evaluations of the techniques that have been described. section 1 discusses related work  and section 1 summarizes the contributions of this work.
1	background on partial order planning
in this paper we consider the simple strips representation of classical planning problems  in which the initial world state   goal state and the set of deterministic actions are given. each action has a precondition list and an effect list  denoted respectively as . the planning problem involves finding a plan that when executed from the initial state will achieve the goal .
　a tutorial introduction to pop algorithms can be found in . we will provide a brief review here. most pop algorithms can be seen as searching in the space of partial plans. a partial plan is a five-tuple:   where is a set of  ground  actions  is a set of ordering constraints over   and is a set of causal links over . a causal link is of the form   and denotes a commitment by the planner that the precondition of action will be supported by an effect of action . is a set of open conditions  and is a set of unsafe links. an open condition is of the form   where and   and there is nocausal link . loosely speaking  the open conditions are preconditionsof actions in the partial plan which have not yet been achieved in the current partial plan. a causal link is called unsafe if there exists an action such that     and    is consistent. in such a case  is also said to threaten the causal link
　　　　. open conditions and unsafe links are also called flaws in the partial plan. therefore a solution plan can be seen as a partial plan with no flaws  i.e.  and  .
　the pop algorithm starts with a null partial plan and keeps refining it until a solution plan is found. the null partial plan contains two dummy actions where the preconditions of correspond to the top level goals of the problem  and the effects of correspond to the conditions in the initial state. the null plan has no causal links or unsafe link flaws  but has open condition flaws corresponding to the preconditions of  top level goals .
　a refinement step involves selecting a flaw in the partial plan   and resolvingit  resulting in a new partial plan. when the flaw chosen is an open condition   an action needs to be selected that achieves . can be a new action in   or an action that is already in . the sets     and also need to be updated with respect to . secondly  when the flaw chosen is an unsafe link that is threatened by action
　  it can be repaired by either promotion  i.e adding ordering constraint into   or demotion  i.e adding into .
　the efficiency of pop algorithms depends critically on the way partial plans are selected from the search queue  and the strategies used to select and resolve the flaws. in section 1 we present several distance-based heuristics for ranking partial plans in the search queue. section 1 introduces the disjunctive constraint representation for efficiently handling unsafe link flaws  and reachability analysis for generalizing the notion of unsafe links to include implicit conflicts in the plan.
1	heuristics for ranking partial plans
in choosing a plan from the search queue for further refinement  we are naturally interested in plans that are likely to lead to a solution with a minimum number of refinements

　　although partial order planners are capable of handling partially instantiated action instances  we restrict our attention to ground action instances.
　　strictly speaking should be seen as a set of  steps   where each step is mapped to an action instance .
 flaw resolutions . as we handle the unsafe links in a significantly different way than standard ucpop  see section 1   the only remaining category of flaws to be resolved are open condition flaws. consequently one way of ranking plans in the search queue is to estimate the minimum number of new actions needed to resolve all the open condition flaws.
definition 1  h*  given a partial plan   let denote the minimum number of new actions that need to be added to to make it a solution plan.
　　　can be seen as the number of actions that  when executed from the initial state in some order  will achieve the set of subgoals . in this sense  this is similar to estimating the number of actions needed to achieve a state from the given initial state in state search planners  1;
1   but for two significant differences:  i  the propositions in are not necessarily in the same world state and  ii  the set of actions that achieve cannot conflict with the set of actions and causal links already present in .
　a well-known heuristic for estimating involves simply countingthe numberof open conditionsin the partial plan . heuristic 1  open conditions heuristic 
　this estimate is neither admissible nor informed in many domains  because it treats every open condition equally. in particular  it is ineffective when some open conditions require more actions to achieve than others.
　we would like to have a closer estimate of function without insisting on admissibility. to do this  we need to take better account of subgoal interactions. accounting for the negative interactions in estimating can be very tricky  and is complicated by the fact that the subgoals in may not be in the same state. thus we will start by ignoring the negative interactions. this has three immediate consequences:  i  the set of unsafe links becomes empty.  ii  the actions needed in achieving a set of subgoals will have no conflicts with the set of actions and and the causal links already present in . and  iii  a subgoal once achieved from the initial state can never become untrue. given these consequences  it does not matter much that the subgoals in are not necessarily present in the same world state  since the minimum number of actions needed for achieving such a set of subgoals in any given temporal ordering is the same as the minimum cost of achieving a state comprising all those subgoals.
　the foregoing justifies the adaptation of many heuristic estimators for ranking the goodness of states in state search planners. most of the early heuristic estimators used in state search not only ignore negative interactions  but also make the stronger assumption of subgoal independence 1; 1 . a few of the recent ones   1; 1  however account for the positive interactions among subgoals  while still ignoring the negative interactions . it is this latter class of heuristics that we focus on for use in partial order planning. specifically  to account for the positive interactions  we exploit the ideas for estimating the cost of achieving a set of subgoals using a serial planning graph.
　specifically  we build a planning graph starting from the initial state . let be the index of the level in the planning graphthat a proposition first appears  and be the index
of the first level at which all propositions in appear. let be the proposition in such that .

　　we assume that the readers are familiar with the planning graph data structure  which is used in graphplan algorithm.
   will possibly be the last proposition in that is achieved during execution. let be an action in the planning graph that achieves in the level . we can achieve by adding to the plan. introduction of changes the set of goals to be achieved to	. we can express the cost of in terms of the cost of and :
 1 
where	if	and 1 otherwise.	since is strictly smaller than	  recursively applying equation 1 to its right hand side will eventually express in terms of	 which is zero   and the costs of actions	. the process is quite efficient as the number of applications is bounded by	.
heuristic 1  relax heuristic 	  where
	  and	is computed using the
recurrence relation 1.
　given such a heuristic estimate  plans in the search queue are ranked with the evaluation function:
　　. the parameter is used to increase the greediness of the heuristic search and is set to 1 by default.
1	enforcing consistency of partial plans
the consistency of a partial plan is ensured through the handling of its unsafe links. in this section we describe two ways of improving this phase. the first involves posting disjunctive constraints to resolve unsafe links. the second involvesdetecting implicit conflicts  unsafe links  using reachability analysis.
1	disjunctive representation of ordering constraints
normally  an unsafe link that is in conflict with action is resolved by either promotion or demotion  that is  splitting the current partial plan into two partial plans  one with the constraint   and the other with the constraint
       . a problem with this premature splitting is that a single failing plan gets unnecessarily multiplied into many descendant plans poisoning the search queue significantly. a much better idea  first proposed in   is to resolve the unsafe link by posting a disjunctive ordering constraint that captures both the promotionand demotion possibilities  and incrementally simplify these constraints by propagationtechniques. this way  we can detect many failing plans before they get selected for refinement.
　specifically  an unsafe causal link that is in conflict with action can be resolved by simply adding a disjunctive ordering constraint to the plan.
　we use the following procedure for simplifying the disjunctive orderings. whenever an open condition is selected and resolved by either adding a new action or reusing an action in the partial plan  we add a new ordering constraint
to   followed by repeated application of the constraint propagation rules below:
false
　the first two propagation rules are already done as part of pop algorithm to ensure the transitive consistency of ordering constraints. the third rule is a unit propagationrule over ordering constraints. this propagation both reduces the disjunction and detects infeasible plans ahead of time. when all the open conditions have already been established and there are still disjunctive constraints left in the plan  the remaining disjunctive constraints are then split into the search space .
1 detecting and resolving implicit conflicts through reachability analysis
although the unsafe link detection and resolution steps in the pop algorithm are meant to enforce consistency of the partial plan  often times they are too weak to detect implicit inconsistencies. in particular  the procedure assumes that a link is threatened by an action only if has an effect . often might have an effect  or precondition   such that no legal state can have and  or and   true together. detecting and resolving such implicit interactions can be quite helpful in weeding out inconsistent partial plans from the search space.
　in order to do implicit conflict detection as described above  we need to have  partial  information about the properties of reachable states. interestingly  such reachability information has played a significant role in the scale-up of state space planners  motivating the development of procedures for identifying mutex constraints  state invariants and memos etc.  1; 1; 1   we shall henceforth use the term mutex to denote all these types of reachability information . one simple way of producing reachabilityinformationis to expandgraphplan'splanning graph structure  armed with mutex propagation procedure . the mutexes present at the level where the graph levels off are state invariants .
　exploitingthe reachabilityinformationto check consistency of partial plans requires identifying the feasibility of the world states that any eventual execution of the partial plan must pass through. although partial order plans normally do not have explicit state information associated with them  it is nevertheless possible to provide partial characterization of the states their execution must pass through. specifically  we define the general notion of cutsets as follows:
definition 1  cutsets  pre-and post-cutsets  and of an action in a plan are defined as
       and	  where is the set of all conditions such that there exists a link where is necessarily before   and is necessarily after
　the pre- and post-cutsets of an action can be seen as partial description of world states that must hold before and after the action . if these partial descriptions violate the properties of the reachable states  then clearly the partial plan cannot be refined into an executable solution.
proposition 1 if there exists a cutset that contains a mutex  then the partial plan is provably invalid and can be pruned from the search queue.
　while this proposition allows us to detect and prune inconsistent plans  it is often inefficient to wait until the plan becomes inconsistent. detecting and resolving implicit conflicts is essentially a more active approach that prevents a partial plan from becoming inconsistent by this proposition. specifically  we generalize the notion of unsafe links as follows:
definition 1 an action is said to have a conflict with a causal link if     is consistent and    either or contains a mutex. a causal link is unsafe if it has a conflict with some action in the partial plan.
these notions of conflict and unsafe link subsume the original notions of threat and unsafelink introduced in section 1  because also implies that is a mutex. therefore the generalized notion of unsafe links result in detecting a larger number of  implicit  conflicts  unsafe links  present in a partial plan.
　once the implicit conflicts are detected  they are resolved by posting disjunctive orderings as described in the previous subsection. as we shall see later  the combination of disjunctive constraints and detection of implicit conflicts through reachability information leads to quite robust improvements in planning performance.
1	empirical evaluation
we have implemented the techniques introduced in this paper on top of ucpop  a popular partial order planning algorithm. we call the resulting planner repop. as mentioned in section 1  both ucpop and repop are given ground action instances  and thus neither of them have to deal with variable binding constraints. both ucpop and repop use the lifo as the order in which open condition flaws are selected for resolution. our empirical studies compare repop to ucpop as well as graphplan and altalt  which represent two currently popular approaches  csp search and state space search  in plan synthesis. all these planners are written in lisp. in the case of graphplan  we used the lisp implementation of the original algorithm  enhanced with ebl and ddb capabilities . altalt  is a state-of-the-art heuristic regression state search planner  that has been shown to be significantly faster than hsp-r . the empirical studies are conducted on a 1 mhz pentium-iii with 1mb ram  running linux. the test suite of problems were taken from several benchmarkplanning domains from the literature. some of these  including gripper  rocket world  blocks world and logistics are  parallel  domains which admit solutions with loosely orderedsteps  while others  such as grid world and travel world admit only serial solutions. efficiency of synthesis: in table 1  we report the total running times for the repop algorithm  including the preprocessing time for computing the mutex constraints  using bilevel planning graph structures  . table 1 shows that repop exhibits dramatic improvements from its base planner  ucpop  in gripper  logistics and rocket domains-all of which are  parallel domains.  for instance  repop is able to comfortably generate plans with up to 1 actions in logistics and gripper domains  a feat that has hither-to been significantly beyondthe reach of partial order planners. more interestingis the comparison between repop and the non-partial order planners. in the parallel domains  repop manages to outperform graphplan. although repop still trails state search planners such as altalt  these latter planners can only generate serial plans.
　despite the impressiveperformanceof the repop overparallel domains  it remains ineffective in  serial  domains including the grid  1-puzzle and travel world  which admit only totally ordered plan solutions. we suspect that part of the reason for this may be the inability of our heuristics to adequately account for negative interactions. indeed  we found that the normal open conditions heuristic is better than our relaxed heuristic on these problems. it may also be possible that the least commitment strategies employed by the pop algorithms become a burden in serial domains  since eventually all actions need to be ordered with respect to each other. one silverlining in this matter is that most of the domains where pop algorithms are supposed to offer advantages are likely to be parallel domains from the planner's perspective-either because the actions will have durations  making the serial/parallel distinction moot  or because we want solution output by the planner to offer some degree of scheduling flexibility. plan quality: we also evaluated the quality of plans generated by repop  since plan quality is seen as an important issue favoring pop algorithms. to quantify the quality of plans generated  we consider three metrics:  i  the cumulativecost of the actions included in the plan  ii  the minimum time needed for executing the plan and  iii  the scheduling  execution  flexibility of the plan.
　for actions with uniform cost  the action cost is equal to the number of actions in the plan. table 1 shows that repop produces plans with lower action cost compared to both graphplan and altalt in all but one problem  rocket-ext-b .
　we measure the minimum execution time in terms of the makespan of the plan  which is loosely defined as the minimum number of time steps needed to execute the plan  taking the possibility of concurrent execution into consideration . makespan for the plans produced by graphplan is just the number of steps in the plan  while the makespan for plans produced by altalt  and other state space planners  is equal to the number of actions in the plan. for a partially ordered plan generated by repop  the makespan is simply the length of the longest path between and . specifically 
	  where	is the earli-
est start time step for the  instantaneous  action	. to compute
     we can start by initializing to 1 for all . next  we repeatedly update them until fixpoint using the following rule:
for all	 	.
table 1 shows that the solution plans generated by repop are highly parallel  since the makespans of these plans are significantly smaller than the total number of actions. graphplan's solutions have smaller makespans in several problems  but at the expense of having substantially larger number of actions.

 a  a parallel plan gen-  b  a partially ordered erated by graphplan plan
figure 1: example illustrating the execution flexibility of partially ordered plans over  graphplan's  parallel plans.
　finally  we measure the execution flexibility of a plan in terms of the number of actions in the plan that do not have any precedence relations among them. the higher this measure  the higher the number of orders in which a plan can be executed   scheduled  . figure 1 illustrates a parallel plan and a partially ordered plan   which are generated by graphplan and repop  respectively. both plans have 1 actions and a makespan value of 1  but is noticeably more flexible than
problemucpop
 time repopgraphplanaltalttime#a/ #s#flextime#a/ #s#flextime#agripper-1-11/ 1.1.1/ 1.1.1gripper-1-11/ 1.1min1/ 1.1.1gripper-1-11/ 1.1---11gripper-1-11/ 1.1---11rocket-ext-a-11/ 1.1.1/ 1.1.1rocket-ext-b-11/ 1.1.1/ 1.1.1logistics.a-11/ 1.1.1/ 1.1.1logistics.b-11/ 1.1.1/ 1.1.1logistics.c-11/ 1.1---11logistics.d-11/ 1.1---11bw-large-a 1 1 1  - 1/ 1  - 1  -11111bw-large-b 1 - 1  - 1/ 1  - 1  -11/ 1.1.1bw-large-c 1 - 1  - 1/ 1  - 1  ----11travel1.1 1  - 1  - 1  -11/ 1.1.1simple-grid1.1 1  - 1/ 1  - 1  -11/ 1.1.1simple-grid1- 1  - 1/ 1  - 1  -11/ 1.1.1simple-grid1----11/ 1.1.1table 1:  time  shows total running times in cpu seconds  and includes the time for any required preprocessing. dashed entries denote problems for which no solution is found in 1 hours or 1mb. parenthesized entries  for blocks world  travel and grid domains  indicate the performance of repop when using heuristic. #a and #s are the action cost and time cost respectively of the solution plans.  flex  is theexecution flexibility measure of the plan  see below .
	  since	implies ordering constraints such as	and
         but does not. to capture this flexibility  we define  for each action   as the number of actions in the plan that donothave any  direct or indirect  ordering constraint with . is defined as the average value of
over all the actions in the plan. it is easy to see that for a serial plan   = 1  and consequently .
in our example in figure 1  for all in   and for all in . thus  and
　　　　　　. it is easy to see that can be executed in more ways than . table 1 reports the value for the solution plans. as can be seen  plans generated by repop have substantially larger average values of than graphplan in blocks world and logistics  and similar values in gripper. graphplanproduces a more flexible plan in only one problem in the rocket domain.
	problem	ucpop	+ce	+hp	+hp+ce
gripper-1*1/ 1*1/ 1gripper-1*1/ 1*1/ 1gripper-1*1/ 1*1/ 1gripper-1***1/ 1rocket-ext-a**1/ 1/ 1rocket-ext-b**1/ 1/ 1logistics.a**1/ 1/ 1logistics.b**1/ 1/ 1logistics.c**1/ 1/ 1logistics.d***1/ 1table 1: ablation studies to evaluate the individual effectiveness of the new techniques: heuristic for ranking partial plans  hp  and consistency enforcement  ce . each entry shows the number of partial plans generated and expanded. note that repop is essentially ucpop with hp and ce.  *  means no solution found after generating 1 nodes.
　before ending the discussion on plan quality  we should mention that it is possible to use post-processing techniques to improve the quality of plans produced by state-space and csp-based planners. however  such post-processing  in addition to being np-hard in general   does not provide a satisfactory solution for online integration of the planner with other modules such as schedulers and executors  1; 1 .
ablation studies: we now evaluate the individual effectiveness of each of the accelerationtechniques  viz.  heuristic functions for ranking partial plans  hp   and consistency enforcement  ce .table 1 shows the numberof partial plans generated and expanded in the search when each of these techniques is added into the original ucpop. we restrict our focus to the parallel domains where repop seems to offer significant advantages.
　in the logistics and rocket domains  the use of heuristic accounts for the largest fraction of the improvement from ucpop. interestingly  fails to help scale up ucpop even on very small problems in the gripper domain. we found that the search spends most of the time exploring inconsistent partial plans for failing to realize that a left or right gripper can carry at most one ball. this problem is alleviated by consistency enforcement ce  techniquesthroughdetection and resolution of implicit conflicts  e.g. the conflict between and  . as a result  re-
pop can comfortably solve large gripper problems  such as gripper-1.
　among the consistency enforcement techniques  both reachability analysis and disjunctive constraint representation appear to complement each other. for instance  in problem logistics.d  if only reachability analysis is used with the heuristic   a solution can be found after generating 1k nodes. when disjunctive representation is also used  the number of generated nodes is reduced by more than 1 times to 1k.
1	related work
several previous research efforts have been aimed at accelerating partial order planners  c.f.  1; 1; 1; 1; 1; 1; 1; 1  . while none of these techniques approach the current level of performanceoffered by repop  many important ideas separately introduced in these previous efforts are either related to or are complementary to our techniques. ixtet  uses distance based heuristic estimates to select among the possible resolutions of a given open condition flaw  although no evaluation of the technique is provided . it is interesting to note that ixtet's use of distance based heuristics precedes their independent re-discovery in the context of state-search planners by mcdermott  and bonet and geffner . in   bylander describes the use of a relaxation heuristic based on linear planning for pop; it however seems not to be very effective. the idea of postponing the resolution of unsafe links by posting disjunctive constraints has been pursued by smith and peot in  as well as by kambhampati and yang in . our work shows that the effectiveness of this idea is enhanced significantly by generalizing the notion of conflicts to include indirect conflicts. the notion of action-proposition mutexes defined in smith and weld's work on temporal graphplan  is related to our notion of indirect conflicts introduced in section 1. finally  there is a significant amount of work on flaw selection strategies  e.g.  the order in which open condition flaws are selected to be resolved   that may be fruitfully combined with repop. the techniques for recognizing and suspendingrecursion  looping  duringsearch mayalso make a useful addition to repop .
1	conclusion and future work
the successes in scaling up classical planning using csp and state space search approaches have generally been  mis interpreted as a side-swipe on the scalability of partial order planning. consequently  in the last five years  work on pop paradigm has dwindled down  despite its known flexibility advantages. in this paper we challenged this trend by demonstrating that the very techniques that are responsible for the effectiveness of state search and csp approaches can also be exploited to improve the efficiency of partial order planners dramatically. by applying the ideas of distance based heuristics  disjunctive representations for planning constraints and reachability analysis  we have achieved an impressive performance for a partial order planner  called repop  across a number of  parallel  planning domains. our empirical studies show that not only does repop convincingly outperform graphplan in parallel domains  the plans generated by repop have more executionflexibility. this is very interesting for two reasons. first of all  most of the real-world planning domains tend to have loose ordering among actions. secondly  the ability for generatingloosely orderedplans is veryimportantin hybrid methods that involve on-line integration of planning with scheduling.
　there are several avenues for extending this work. to begin with  our partial plan selection heuristics do not take negative interactions into account. this may be one reason for the unsatisfactory performance of repop in serial domains. one way to account for the negative interactions  that we are considering currently  involves using the partial state information provided by the pre- and post-cutsets of actions. our work on altalt  suggests that the cost of achieving these partial states can be quantified in terms of the level in the planning graph at which the propositions comprising these states are present without any mutex relations. another idea we are pursuing is to use n-ary state invariants  such as those detected in   to detect and resolve more indirect conflicts in the plan. finally  a more ambitious extension that we are pursuing involves considering more general versions of pop algorithms- including those that handle partially instantiated actions  as well as actions with conditional effects and durations.
references
 c. backstrom. computational aspects of reordering plans. jair. vol. 1. pp. 1.
 a. blum and m.l. furst. fast planning through planning graph analysis. artificial intelligence. 1-1 . 1.
 b. bonet and h. geffner. planning as heuristic search: new results. in proc. ecp-1  1.
 t. bylander. a linear programming heuristic for optimal planning. in proc. aaai-1  1.
 m. fox and d. long. automatic inference of state invariants in tim. jair. vol. 1. 1.
 m. ghallab and h. laruelle. representation and control in ixtet. in proc. aips-1  1.
 a. gerevini and l. schubert. inferring state constraints for domain-independent planning. in proc. aaai-1  1.
 p. haslum and h. geffner. admissible heuristics for optimal planning. in proc. aips-1  1.
 j. hoffman and b. nebel. the ff planning system: fast plan generation through heuristic search. submitted  1.
 a. johnson  p. morris  n. muscettola and k. rajan. planning in interplanetary space: theory and practice. in proc. aips-1.
 d. joslin and m. pollack. least-cost flaw repair: a plan refinement strategy for partial-order planning. in proc. aaai-1.
 d. joslin  m. pollack. passive and active decision postponement in plan generation. proc. 1rd european conf. on planning. 1.
 a. gerevini and l. schubert. accelerating partial-order planners: some techniques for effective search control and pruning. jair  1-1  1.
 h. kautz and b. selman. pushing the envelope: planning  propositional logic and stochastic search. in proc. aaai-1.
 s. kambhampati  c. knoblock and q. yang. planning as refinement search: a unified framework for evaluating design tradeoffs in partial-order planning. in artificial intelligence  1.
 s. kambhampati and x. yang. on the role of disjunctive representations and constraint propagation in refinement planning in proc. kr-1.
 s. kambhampati. planning graph as  dynamic  csp: exploiting ebl  ddb and other csp techniques in graphplan. jair. vol. 1. pp. 1. 1.
 d. long and m. fox. efficient implementation of the plan graph in stan. jair  1-1  1.
 d. mcallester and d. rosenblitt. systematic nonlinear planning. in proc. aaai-1.
 d. mcdermott. using regression graphs to control search in planning. artificial intelligence  1-1 :1  1.
 x. nguyen and s. kambhampati. extracting effective and admissible state space heuristics from the planning graph. in proc. aaai-1.
 x. nguyen  s. kambhampati and r. nigenda. planning graph as the basis for deriving heuristics for plan synthesis by state space and csp search. to appear in artificial intelligence.
 m. peot and d. smith. threat-removal strategies for partialorder planning. in proc. aaai-1.
 d. smith and m. peot. suspending recursion causal-link planning. in proc. aips-1.
 d. smith  j. frank and a. jonsson. bridging the gap between planning and scheduling. in knowledge engineering review  1 :1. 1.
 d. smith and d. weld. temporal planning with mutual exclusion reasoning. in proc. ijcai-1  1.
 d. weld. an introduction to least commitment planning. ai magazine  1.

planning
planning with incomplete information

heuristic search + symbolic model checking = efficient conformant planning
piergiorgio bertoli   alessandro cimatti   marco roveri
itc-irst  via sommarive 1  1 povo  trento  italy
bertoli cimatti roveri  irst.itc.it
dsi  university of milano  via comelico 1  1 milano  italy

abstract
planning in nondeterministic domains has gained more and more importance. conformant planning is the problem of finding a sequential plan that guarantees the achievement of a goal regardless of the initial uncertainty and of nondeterministic action effects. in this paper  we present a new and efficient approach to conformant planning. the search paradigm  called heuristic-symbolic search  relies on a tight integration of symbolic techniques  based on the use of binary decision diagrams  and heuristic search  driven by selection functions taking into account the degree of uncertainty. an extensive experimental evaluation of our planner hscp against the state of the art conformant planners shows that our approachis extremelyeffective. in terms of search time  hscp gains up to three orders of magnitude over the breadth-first  symbolic approach of cmbp  and up to five orders of magnitude over the heuristic search of gpt  requiring  at the same time  a much lower amount of memory.
1	introduction
planning in nondeterministic domains is being recognized as increasingly important  and much harder than classical planning. in order to find plans that guarantee the achievement of the goal  it is necessary to deal with uncertainty in the initial condition  and with nondeterministic action effects. several approaches to different planning problems in nondeterministic domains have been recently proposed. in  pryor and collins  1; kabanza et al.  1; weld et al.  1; cimatti et al.  1; rintanen  1  the problem of producing a conditional plan under the hypothesis of  total or partial  run-time observability has been considered. conformant planning  goldman and boddy  1  is the problem of finding a sequential plan that will achieve the goal assuming that no information will be available at run-time. conformant planning has also a close relation with the problem of finding synchronization sequences in hardware circuits  kohavi  1 .
　conformant planning has been recently tackled in different ways. the first efficient approach  based on graphplan  was presented in  smith and weld  1 . bonet and geffner  formulate conformant planning as a problem of search in the space of belief states. the approach  implemented within the gpt system  relies on the use of heuristics to drive an -style search algorithm. the state of the art in conformant planning is  cimatti and roveri  1 . this approach extends symbolic model checking techniques  to compactly represent and efficiently explore the search space. althoughthe approachinherits from symbolicmodel checkinga blind  breadth-first search style  the cmbp planner shows surprising efficiency  the reported results being superior to the heuristic search of gpt  sometimes by more than two orders of magnitude.
　in this paper  we present a new  heuristic-symbolic search paradigm  based on the combination of heuristic search with ideas taken from symbolic model checking. we modify and extend the data structures defined in  cimatti and roveri  1   implementing the new planner hscp  heuristicsymbolic conformant planner . heuristic-symbolic search overcomes the bottleneck of the breadth-first approach while retaining the advantages of symbolic techniques: by means of a simple  domain-independentheuristic  hscp outperforms cmbp  gaining up to three orders of magnitudein search time  with a much lower memory consumption.
　this paper is structured as follows. we first define the problem of conformant planning. then  we present the combined use of symbolic and heuristic mechanisms for the representation and exploration of the search space. we describe the planning algorithm  and present an experimental analysis comparing hscp with cmbp and gpt. finally  we discuss some other related work and draw the conclusions.
1	conformant planning
we consider nondeterministic planning domains  where actions can have preconditions  conditional and uncertain effects  and the initial state can be only partly specified.
definition 1  planning domain  a planningdomain is a 1tuple   where is the  finite  set of atomic propositions  is the set of states  is the  finite  set of actions  and is the transition relation.
　intuitively  a proposition is in a state if and only if it holds in that state. in the following we assume that a planning domain is given. we use   and to denote states of   and to denote actions. holds iff when executing the action in the state the state is a possible outcome. we say that an action is applicable in iff there is at least one state such that holds. we say that an action is deterministic in	iff there is a unique state	such that holds. an action	has an uncertain outcome in if there are at least two distinct states	and	such that and	hold.
　plans are sequences of actions  i.e. elements of . we use for the 1-length plan  and to denote plans  and for concatenation. conformant planning is the problem of finding a plan that  if executed in any initial state in   takes the domain into a set of states   regardless of nondeterministic action effects. following  bonet and geffner  1   we model this problem as search in the space of belief states. a belief state is a set of states  intuitively expressing a condition of uncertainty  by collecting together all the states that are equally possible. conformant planning amounts to searching pow     i.e. the powerset of the set of states of the domain. in order to tackle this problem  we need the ability to define the applicability and effect of actions in a belief state  under a condition of uncertainty.
definition 1 an action is applicable in a belief state iff is applicable in every state in . if
is applicable in bs  its execution exec is the set and . the execution of a plan in a belief state  written exec   is defined as follows.
exec
exec
exec	if	is not applicable in
exec	exec	exec	otherwise
　we say that a plan is applicable in a belief state when its execution is not empty. for a conformant planning problem  solutions are applicable plans  for which all the final states must be goal states.
definition 1 let and . the plan is a conformant solution to the problem iff
exec	.
1	heuristic-symbolic representation
1	representation of planning domains
we represent planning domains symbolically  by means of
bdds  binary decision diagrams   bryant  1   borrowing from the formal verification community the standard machinery used in symbolic model checking  mcmillan  1 . bdds are an efficient mechanism for the representation of propositional formulae. a bdd is a binary directed acyclic graph. the terminal nodes are either or . each non-terminal node is associated with a boolean variable  and two bdds  the left and right branches  corresponding to the assignment of the true and false values to the node variable. bdds enjoy a canonical form  resulting from the imposition of a total order over the variables associated to nonterminal nodes. this allows for equivalence checking in constant time  and for the efficient implementation of boolean transformation  e.g. conjunction  disjunction  negation  and qbf transformations  i.e. universal and existential quantification of boolean variables . efficient software libraries for the manipulation of bdds  called bdd packages  are available. for lack of space the reader is referred to  bryant  1  for a thorough description of bdds.
　the symbolic representation of the automaton for a given domain can be efficiently built starting from the domain description language  see for instance  cimatti et al.  1  . for a given planning domain  we use two vectors of bdd variables  called current and next state variables  written
and respectively  to represent atomic propositions of the domain. a state can be seen as an assignment to such variables. a set of states is associated with a unique corresponding bdd  the models of which are the assignments corresponding to the states in . we represent actions by means of a vector of action variables . we write for the bdd in the variables representing the action . we assume a mapping between the set-theoretic view of the planning domain and the corresponding bdd-based representation. when clear from the context  we confuse the set-theoretic and symbolic representations. for instance  we use equivalently the bdd and . we write
for the bdd representing the transition relation  to stress the dependency on bdd variables. the notions defined in previous section at the set-theoretic level have a direct counterpart in terms of bdd transformations. for instance  the applicability relation appl is computed symbolically by the projection operation   the result being a bdd in the current state variables and action variables  whose assignments are the state-action pairs such that is applicable in . in order to check whether an action is applicable in a belief state   it is possible to check whether	appl is not the bdd. the execution of in is computed as
  where
represents the parallel substitution of the next state variables with the current state variables.
1	representation of the search space
the search space for conformant planning is pow     outlined in figure 1  with belief states represented as circles . the search space can be constructed forward  starting from the initial set of states  or backward  from the goal. in the first case  the arrows outgoing from belief state 1 represent the fact that the labeling action a  b  c  respectively  is applicable to all the states in 1  and can result in any of the states in belief state 1  1  1  resp. . in the backward case  the situation is dual: for instance  belief state -1 is the maximal belief state where the labeling action b is applicable  and the result is contained in the belief state -1. for both search directions  a belief state is directly represented by the corresponding bdd . given the canonical form of bdds  a belief state is simply the pointer to the unique corresponding bdd. in figure 1  the lower box depicts a possible status of the
bdd package. the column on the left shows the variables in the bdd package. the horizontal dashed line separates state variables  below the line  from action variable. a belief state is a subgraph in the state variables. below the dashed line  a possible configuration for the forward search space of figure 1 is given. for each belief state  there is a corresponding bdd in the state variables. solid  dashed  respectively  arcs in a bdd represent the positive  negative  resp.  assignment to the variable in the originating node. for instance  the leftmost bdd bs1 encodes the formula .

figure 1: the search space
for the sake of simplicity  only the paths leading to are shown. the advantage over an enumerative representation of belief states  e.g. the list of the state vectors associated to each state contained in the bs  is twofold. in terms of memory  there is no direct connection between the cardinality of the belief state and the size of the corresponding bdd.  consider for instance that  with 1 boolean variables  the set of all the states  of cardinality 1  is represented by the bdd  requiring one node.  furthermore  bdd packages are designed to maximize the sharing between different bdds  and minimize memory occupation. in terms of efficiency  the set-theoretic operations for the transformation and combination of belief states  e.g. projection  equivalence  inclusion  can be efficiently performedas bdd transformations  with the primitives provided by the bdd package  which make aggressive use of memoizing of previously computed subproblems.
　one of the novelties of our approach is based on the integration of the symbolic representation described above with the standard data structures used in heuristic search. in order to allow for heuristic search  a hash table is used to store and retrieve the belief states visited during the search  upper box in figure 1 . each entry directly points to the bdd representing the belief state  and is annotated with the suitable information  e.g. the plan  the cost factors . for instance  for belief state 1 the stored plan is the sequence b;a  i.e. one of the sequences of actions needed to reach belief state 1 from the initial belief state 1. the hash table is accessed using as key the pointer to the bdds representing the belief state. the approach relies on the canonical form of bdds  thanks to which only one bdd representative for equivalent boolean functions is required. the hash table is accessed with a bs  and if a corresponding entry is present  then it is returned  otherwise a new entry is created. notice that the memory occupation of the belief state for each entry in the hash table is fixed to a single pointer: the bdd package is responsible to compress the information  as shown in figure 1. notice also that this approach allows to reuse a standard bdd package  without interfering with its internal mechanisms  e.g. hashing  memoizing  garbage collection .
　the construction of the search space is performed by expanding an individual belief state  resulting in a set of the form	. for instance  when expanding in forward the initial belief state 1 in figure 1  the resulting expansion is the set   meaning that   and are applicable in 1  and the corresponding execution results are the belief state 1  1 and 1. dually  when expanding -1 backward  the result is
                   meaning that b can be applied in -1 and results in -1. the ability to expand belief states sym-

figure 1: the combined use of the hash and the bdd
bolically is one of the keys to the efficient search. the backward step of expansion bwdexpandbs  applied to the bdd   constructs the bdd
　　　　　　　　appl . the result is a bdd in the current state variables and action variables   representing an association from actions to states  
               that can be interpreted as an association between actions and belief states  i.e.   .
the dual forward step fwdexpandbs expands by computing the executions in of every applicable ac-
tion  i.e.	appl
　　　　　　　　. the data structure resulting from the expansion is again a bdd in the and variables. in figure 1 the bdd resulting from the forward expansion of belief state 1 is shown: the paths at the levels of action variables represent the different actions   and   and the attached subgraphs represent the corresponding belief states 1  1 and 1. the link between the symbolic representation of the expansion and the hash-based representation of the search space is the special purpose primitive prunebsexpansion. for either search directions  every time a belief state is expanded  the resulting belief states have to be compared with the previously visited belief states. if not present  they must be inserted in the hash of the visited belief states  otherwise eliminated. this analysis is performed by prunebsexpansion  that operates directly on the bdd resulting from the expansion of the bs  and allows to combine the symbolic expansion of belief states with the hashing mechanism. pruneb-
sexpansion recursively descends the bdd in the action and state variables  and interprets as a belief state every bdd node having a state variable at its top. nodes corresponding to previously visited belief states are pruned  while the new ones are inserted in the hash. prunebsexpansion assumes that in the bdd package action variables precede state variables  as shown in figure 1. this does not appear to be a significant limitation in many practical cases. this approach takes care of a very significant source of redundancy: often a belief state can be associated with a large number of equivalent plans  in figure 1  and are two equivalent action plans associated with 1 . the pruning mechanism makes sure that  for each bs  only one plan is left.
1	the planning algorithm
in this section we describe the planning algorithm  based on the data structures and primitives described in previous section. figure 1 depicts the backward search algorithm  that takes in input the problem description in form of the bdds and   while the transition relation is assumed to be globally available. openbspool contains the  annotated  belief states which have been reached but still have to be explored  and is initialized to the first belief state of the search  i.e.   annotated with the empty plan . bsmarkvisited inserts into the hash table of visited belief states  also updating the cost information. the algorithm loops  lines 1  until a solution is found or all the search space has been exhausted. first  an annotated belief state is extracted from the open pool  line 1  by extract. the belief state is expanded by bwdexpandbs  computing the corresponding bdd in the and variables. the resulting bs expansion  stored in bsexp  is traversed by prunebsexpansion as explained in previous section: for each belief state in the expansion  the hash table of the visited belief states is accessed  and only the belief states that are not present are accumulated in the returned list.
　each of the resulting belief states is compared with the initial set of states . if   then the associated plan is a solution to the problem  the loop is exited and the plan is returned. otherwise  the annotated belief state is inserted in openbspool and the loop is resumed. if openbspool becomes empty and a solution has not been found  then a fix point has been reached  i.e. all the reachable space of belief states has been covered  and the algorithm terminates with failure. the dual algorithm for forward search  not reported here for lack of space  shares the structure of the backward planning algorithm described in figure 1  but applies the forward expansion steps defined in previous section. the termination of the algorithms is guaranteed by the fact that the set of explored belief sets  stored in the visited hash table  is monotonically increasing. since the set of accumulated belief states is contained in pow     which is finite  a fix point is eventually reached. furthermore  a solution plan is returned if and only if the problem admits a solution  otherwise a failure is returned.
　the length of the constructed plans depends on the effectiveness of the heuristic with respect to the problem being tackled  in particular on the primitives extract and insert. we use a very simple heuristic function. when proceeding backward  it selects the belief state with the highest cardinality. we consider as more promising a belief state with a low degree of knowledge: intuitively  the associated plan requires a low knowledge to lead to the goal. dually  in forward  we select the belief states with lowest cardinality  that is associated with a plan that yields a guarantee of high knowledge. our approach departs significantly from the heuristic function used in  bonet and geffner  1   that are a simple combination of heuristic functions over the states in the belief state. the behavior of gpt on the square and cube variations shows that this approachcan lead to dramatic failures  as discussed in  cimatti and roveri  1 . although our selection strategy is in general not admissible  in the sense of a*   it seems to be extremely effective  especially in the backward procedure heursymbwdconformant     
1 begin
1 openbspool :=	; bsmarkvisited   ;
1 solved :=	; solution := ;
1 while  openbspool	solved  do
1 := extract openbspool ;
1 bsexp := bwdexpandbs bs ;
1 bsplist := prunebsexpansion	;
1 for	in bsplist do
1 if	then
1 solved :=	; solution :=	break
1 else insert 	 openbspool  endif;
1 end while
1 if solved then return solution;
1 else return fail;
1 end
　figure 1: the backward conformant planning algorithm case.
1	experimental evaluation
we implemented the data structures and the algorithms described in this paper  in the following called hscp  heuristicsymbolic conformant planner   on top of cmbp  cimatti and
roveri  1   see http://sra.itc.it/tools/mbp/ . we carried out an extensive experimental evaluation of our approach  covering all the test cases presented so far in the literature to evaluate conformant planners.  for lack of space  we refer to  cimatti and roveri  1  for the description of the problems.  the most relevant systems for the comparison are gpt  for its heuristic search style  and cmbp  for its use of model checking techniques. we do not consider other conformant planners  such as cgp  smith and weld  1  and qbfplan  rintanen  1   that are outperformed by gpt and cmbp  as shown in  cimatti and roveri  1 . for cmbp and hscp  the backward search algorithms were run. all the experiments were run on an pentium ii 1mhz with 1mb of memory running linux  fixing a memory limit of 1mb and a cpu time limit of 1 hours. the results of the comparison are depicted in the following. each plot refers to a problem class. for each problem instance  we report  in seconds on a logarithmic scale  the search time  i.e. the cpu time required to find a solution for the given planning problem  or to discover that the problem admits no solution.  we do not consider the preprocessing time. in the case of gpt  this includes the generation of a c++ file  that is compiled and then linked to the solver program. in the case of cmbp and hscp  for all the reported experiments  the automaton construction  optimized with respect to the results reported in  cimatti and roveri  1   requires at most 1 secs  in the omelette 1  problem. 
　the experimental evaluation shows that the heuristicsymbolic search of hscp outperforms cmbp  that  in turn  outperforms gpt  cimatti and roveri  1  . on average  the improvement is of about two orders of magnitude  with a minimum of one order of magnitude in the case of square and omelette  and a maximum of about three orders of magnitude in the case of btuc and of bmtc n 1  with high uncertainty. in the ring 1  problem  gpt reaches the fixed

	bt n 	btc n 	btuc n 

1	1	1	1	1	1	1	1	1	1	1	1	1
	# of packages	# of packages	# of packages
	bmtc n 1  low uncertainty	bmtc n 1  low uncertainty	bmtc n 1  low uncertainty

1	1	1	1	1	1	1	1	1	1	1	1	1	1
	# of packages	# of packages	# of packages
	bmtc n 1  high uncertainty	bmtc n 1  high uncertainty	bmtc n 1  high uncertainty

1	1	1	1	1	1	1	1	1	1	1	1	1	1
	# of packages	# of packages	# of packages
	square  n  corner	square  n  face	square  n  center

1	1	1	1	1	1	1	1	1	1	1	1	1	1	1 side length	side length	side length
	cube  n  corner	cube  n  face	cube  n  center

1	1	1	1	1	1	1	1	1	1	1 side length	side length	side length
	ring r 	uring r 	omelette n 

1	1	1	1	1	1	1	1	1	1	1	1
	# of rooms	# of rooms	# of good eggs

time limit without finding a solution. the uring problems are not representable in gpt. it is interesting to notice that  while gpt reaches the memory limit in 1 sets of experiments  solid triangles in the plots   cmbp and hscp complete all the runs within the given limit. this appears to be due to the use of the bdd based representation. in terms of memory  on average  cmbp requires about twice more memory than hscp: the main reason for this seems to be that cmbp represents plans symbolically  and this requires the introduction of a new set of action variables for each layer of the search. although cmbp is guaranteed to return plans of minimal length  hscp returns plans that are surprisingly short. for all the experiments  hscp returns minimal length plans  with the exception of some of the bmtc problems. finally  the omelette problem  differently from all the others  admits no conformantsolution  and thereforeit requires the complete exploration of the state space. we expected cmbp to outperform hscp  because of its ability to expand a large number of states in one single operation. however  hscp outperforms cmbp  having to deal with more bdds  but of smaller size.
1	related work and conclusions
in this paper  we have presented a new  heuristic-symbolic search paradigm  resulting in an extremely effective approach to conformantplanning. bdd-based  symbolic techniques are combined with search algorithms that exploit heuristic selection functions taking into account the degree of uncertainty. our approach gains up to three order of magnitude in search time over the breadth-first symbolic approach of cmbp  and up to five over the heuristic search of gpt  with lower memory requirements.
　in the following we describe additional related works. in hardware design  synchronizationsequences are used for testing and equivalence checking. the problem of finding a synchronizationsequence can be seen as a particularform of conformant planning: a synchronization sequence is a sequence of inputs that takes a circuit from an unknown state into a completely defined one. in  cimatti et al.  1   we tackle this problem within the heuristic-symbolic paradigm. a comparison over the standard benchmarks shows that our approach is more than competitive with specialized bdd-based algorithms  pixley et al.  1; rho et al.  1 . the work in  finzi et al.  1  is limited to deterministic actions  and relies on user-defined heuristics to achieve an efficiency comparable with cmbp.  ferraris and giunchiglia  1  tackles conformant planning in nondeterministic domains described in language  that allows for parallel actions. although the problemstackled by cmbp and hscp are expressedin the language  that is limited to sequential actions  the planners are not subject to this restriction. for instance  in  cimatti et al.  1  hscp is used to analyze circuits with for parallel inputs  actions  expressed in the smv language  mcmillan  1 . the planner of  ferraris and giunchiglia  1  can not discover when a problem admits no conformant plan  and the reported results are comparable with cgp  smith and weld  1   see also  cimatti and roveri  1  for a detailed discussion . in  bertoli et al.  1   the approach presented in this paper is used as a basis for planning under partial observability. as a future work  we will investigate the use of more accurate heuristic functions  that combine a measure of the degree of uncertainty with domain knowledge in the style of gpt. furthermore  we will extend the approach presented in this paper with the techniques of  cimatti and roveri  1   that allow to expand symbolically several belief states at a time. we will also generalize our work to deal with extended goals expressed in different forms of temporal logic specifications.
references
 bertoli et al.  1  p. bertoli  a. cimatti  m. roveri  and p. traverso. planning in nondeterministic domains under partial observability via symbolic model checking. in proc. ijcai-1. aaai press  1.
 bonet and geffner  1  b. bonet and h. geffner. planning with incomplete information as heuristic search in belief space. in proc. aips-1  pages 1. aaai press  april 1.
 bryant  1  r. e. bryant. symbolic boolean manipulation with ordered binary-decision diagrams. acm computing surveys  1 :1- 1  september 1.
 cimatti and roveri  1  a. cimatti and m. roveri. conformant planning via symbolic model checking. journal of artificial intelligence research  1-1  1.
 cimatti et al.  1  a. cimatti 	e. giunchiglia 	f. giunchiglia 	and
p. traverso. planning via model checking: a decision procedure for
   . in proc. ecp-1  lncs 1  pages 1  toulouse  france  september 1. springer-verlag.
 cimatti et al.  1  a. cimatti  m. roveri  and p. traverso. strong planning in non-deterministic domains via model checking. in proc. aips1  pittsburgh  usa  june 1. aaai press.
 cimatti et al.  1  a. cimatti  m. roveri  and p. bertoli. searching powerset automata by combining explicit-state and symbolic model checking. in proc. tacas 1  pages 1. springer  april 1.
 ferraris and giunchiglia  1  p. ferraris and e. giunchiglia. planning as satisfiability in nondeterministic domains. in proc. aaai'1   austin  texas  july-august 1. aaai press.
 finzi et al.  1  a. finzi  f. pirri  and r. reiter. open world planning in the situation calculus. in proc. aaai'1   austin  texas  july-august 1. aaai press.
 goldman and boddy  1  r.p. goldman and m.s. boddy. expressive planning and explicit knowledge. in proc. aips-1  pages 1. aaai press  1.
 kabanza et al.  1  f. kabanza  m. barbeau  and r. st-denis. planning control rules for reactive agents. artificial intelligence  1 :1  1.
 kohavi  1  z. kohavi. switching and finite automata theory. mcgraw-hill book company  new york  1. isbn 1-1.
 mcmillan  1  k.l. mcmillan. symbolic model checking. kluwer academic publ.  1.
 pixley et al.  1  c. pixley  s.-w. jeong  and g. d. hachtel. exact calculation of synchronization sequences based on binary decision diagrams. in proc. of the 1th design automation conference  ieeecs press  1.
 pryor and collins  1  l. pryor and g. collins. planning for contingency: a decision based approach. j. of artificial intelligence research  1-1  1.
 rho et al.  1  j.-k. rho  f. somenzi  and c. pixley. minimum length synchronizing sequences of finite state machine. in proc. of the 1th acm/ieee design automation conference  pages 1  dallas  tx  june 1. acm press.
 rintanen  1  j. rintanen. constructing conditional plans by a theoremprover. journal of artificial intellegence research  1-1  1.
 smith and weld  1  d. e. smith and d. s. weld. conformant graphplan. in proc. aaai-1  pages 1  menlo park  july 1 1. aaai press.
 weld et al.  1  d. s. weld  c. r. anderson  and d. e. smith. extending graphplan to handle uncertainty and sensing actions. in proc. aaai-1  pages 1  menlo park  july 1 1. aaai press.
planning in nondeterministic domains under partial observability via symbolic model checking
piergiorgio bertoli   alessandro cimatti   marco roveri	  paolo traverso
itc-irst  via sommarive 1  1 povo  trento  italy
bertoli cimatti roveri traverso  irst.itc.it
dsi  university of milano  via comelico 1  1 milano  italyabstract
planning under partial observability is one of the most significant and challenging planning problems. it has been shown to be hard  both theoretically and experimentally. in this paper  we present a novel approach to the problem of planning under partial observability in non-deterministic domains. we propose an algorithm that searches through a  possibly cyclic  and-or graph induced by the domain. the algorithm generates conditional plans that are guaranteed to achieve the goal despite of the uncertainty in the initial condition  the uncertain effects of actions  and the partial observability of the domain. we implement the algorithm by means of bdd-based  symbolic model checking techniques  in order to tackle in practice the exponential blow up of the search space. we show experimentally that our approach is practical by evaluating the planner with a set of problems taken from the literature and comparingit with other state of the art planners for partially observable domains.
1	introduction
research in planning is more and more focusing on the problem of planning in nondeterministicdomains and with incomplete information  see for instance  pryor and collins  1; kabanza et al.  1; weld et al.  1; cimatti et al.  1; rintanen  1a; bonet and geffner  1 . the search mechanismand the structure of the generatedplans dependon how information is assumed to be available at run-time. the approaches in  kabanza et al.  1; cimatti et al.  1   for instance  construct conditional plans under the assumption of full observability  i.e. the state of the world can be completely observed at run-time. at the other end of the spectrum  conformant planning  smith and weld  1; bonet and geffner  1; cimatti and roveri  1; bertoli et al.  1  constructs sequential plans that are guaranteed to solve the problem assuming that no information at all is available at run-time. in this paper we tackle the problem in the middle of the spectrum  i.e. planning under partial observability  the general case where only part of the domain information is available at run time. several approaches have been proposed in the past  pryor and collins  1; weld et al.  1; bonet and geffner  1 . this problem is however significantly more difficult than the two limit cases of fully observable and conformant planning  littman et al.  1 . compared to planning under full observability  planning under partial observability must deal with uncertainty about the state in which the actions will be executed. this makes the search space no longer the set of states of the domain  but its powerset  i.e. the space of  belief states   bonet and geffner  1 . compared to conformant planning  the structure of the plan is no longer sequential  but tree-shaped  in order to represent a conditional course of actions.
　in this paper  we propose a general and efficient approach to conditional planning under partial observability. we make the following contributions. first  we present a formal model of partially observable planning domains  that can represent both observations resulting from the execution of sensing actions  pryor and collins  1; weld et al.  1  and automatic sensing that depends on the current state of the world  toveyand koenig  1 . second  we propose a novel planning algorithm that searches through a  possibly cyclic  and-or graph induced by the domain. the algorithm generates conditional  acyclic plans that are guaranteed to achieve the goal despite of the uncertainty in the initial condition  and of the uncertain effects of actions. third  we implement our approach by means of bdd-based  symbolic model checking techniques  extending the planning via model checking paradigm and the related system mbp  cimatti et al.  1 .
　we experimentally evaluate our approach by analyzing some problems from the distributions of other available planners for partially observable domains and other problems  including the  maze  domains proposed by koenig  tovey and koenig  1 . mbp outperforms two state of the art planners for partially observable domains  sgp  weld et al.  1  and gpt  bonet and geffner  1 .
　the paper is organized as follows. we provide a formal definition of partially observable planning domains and of conditional planning. we then present the planning algorithm  and its implementation in the mbp planner. then  we report on the experimental evaluation  discuss further related work  and draw some conclusions.
1	partially observable domains
we consider nondeterministic domains under the hypothesis of partial observability  i.e. where a limited amount of information can be acquired at run time.

figure 1: a simple robot navigation domain
definition 1 a partially observable planning domain is a tuple	  where
is a finite set of propositions; is the set of states;
is a finite set of actions.
is the transition relation.
is a finite set of observation variables;
is the observation
relation.
intuitively  a state is a collection of the propositions holding in it. the transition relation describes the effects of action execution. an action is applicable in a state iff there exists at least one state such that . the set
contains observation variables  whose value can be observed at run-time  during execution. without loss of generality  we assume that observation variables are boolean. we use to denote observation variables. we call   written in the following  the observation relation of . given an action  that has been executed  and the resulting state  specifies what are the values that can be assumed at run-time by the observation variable . in a state after an action   an observation variable may convey no information: this is specified by stating that both and
hold  i.e. both the true and false values are possible. in this case  we say that is undefined in after . if holds and does not hold  then the value of in state after is true. the dual holds for the false value. in both cases  we say that is defined in after . an observation variable is always associated with a value  i.e. for each and for each   at least one of and holds.
　consider the example of a simple robot navigation domain in figure 1  containing a 1 room with an extra wall. the propositions of the domain are nw  ne  sw  and se  corresponding to the four positions in the room. exactly one of them holds in each of the four states in . the robot can move in the four directions  deterministic actions gonorth  gosouth  gowest and goeast   provided that there is not a wall in the direction of motion. the action is not applicable  otherwise. at each time tick  the information of walls proximity in each direction is available to the robot  observation variables walln  walls  wallw and walle . for instance  we have that for any action of the domain and . in this case  every observation variable is defined in every state and after the execution of any action of the domain. we call action-independent the observation variables that provide useful information automatically  independently of the previous execution of an action. we require an action-independent observation variable to satisfy  for any and any   the following condition:
in the following  we write when is actionindependent. in a different formulation of the domain  an action  e.g. obswalle  could be required in order to acquire the value of a corresponding variable  e.g. walle . in this case  walle would be defined in any state after the action obswalle  and undefinedotherwise. such observationvariables are modeled as action-dependent. action-independent observation variables model  automatic sensing   tovey and koenig  1   i.e. information that can always be acquired  as usual in embedded controllers  where a signal from the environment is sampled and acquired at a fixed rate  latched and internally available. action-dependent observations are used in most observation-basedapproachesto planning e.g.  weld et al.  1    where the value of a variable can be observed as the explicit effect of an action  like obswallw.
1	conditional plans
in partially observable domains  plans need to branch on conditions on the value of observable variables. a plan for a domain is either the empty plan   an action   the concatenation of two plans and   or the conditional plan  read  if then else     with
. for the example in figure 1  a plan that moves the robot from the uncertain initial condition nw or sw  to state
sw is goeast ;     ; gowest. figure 1 depicts the corresponding execution. the action goeast is executed first. notice indeed that in the initial condition all the observation variables would have the same value for both nw and sw: therefore the states are indistinguishable  and it is pointless to observe. after the robot moves east  it is guaranteed to be either in ne or se. the plan then branches on the value of walln. this allows the planner to distinguish between state ne and se: if the robot is in ne  then it moves south  otherwise it does nothing. at this point the robot is guaranteed to be in se  and can finally move west. this plan is guaranteed to reach sw from any of the initial states  either with three actions  if the initial state is nw   or with two actions  if the initial state is sw .
　we define	as the set of states in where is true  and as the set of states in where is false. if is undefined in a state after   then
　　　　　　　　　　. in the case of action-independent observations  we have	  and
	.	under partial observability 
plans have to work on sets of states whose elements cannot be distinguished  i.e.  on  belief states . we say that an action is applicable to a non empty belief state iff is applicable in all states of . we now define plan execution in the case of action-independent observations.
definition 1 let . the execution of a plan in a set of states is defined as follows:
1. exec	;
1. exec	with   if is applicable in ;
1. exec  ifis not applicable in;1. exec;1. exec
1. execexec	exec;execexec  if a  if  then exec b  if  then exec1. execotherwise.we say that a plan	is applicable in	iff
exec . if the plan is applicable  then its execution is the set of all states that can be reached after the execution of the plan. for conditional plans  we collapse into a single set the executionof the two branches  item 1 . the conditions  a  and  b  guarantee that both branches are executable. definition 1 can be extended to the case of action-dependent observations by replacing with and with
         where is the last action executed in the plan. notice that  at starting time  action-dependent observation variables must be undefined since no action has been previously executed. for lack of space  we omit the explicit formal definition. we formalize the notion of planning problem under partial observability as follows.
definition 1  planning problem and solution  a planning problem is defined as a 1-tuple	  where	is a planning domain 	is the set of initial states  and is the set of goal states. the plan	is a solution to the problem	iff	exec	.
1	the planning algorithm
when planning under partial observability  the search space can be seen as an and-or graph over belief states  recursively constructed from the initial belief state  expanding each encountered belief state by every possible combination of applicable actions and observations. consider the example in
figure 1  where is and is . for instance  belief state 1 expands in the or-node   1    representing the effect of action goeast. other actions are not applicable  and observation conveys no information. belief state 1 expands in the or-node   1   1    representing the effect of action gowest  resulting in belief state 1  and the effect of observing walln  resulting in the belief states 1 and 1. in order to find a solution for 1  it is either possible to find a solution for 1  or a solution for both 1 and 1. non-applicable actions are discarded.
　we plan under partial observability by exploring the andor search space described above. the algorithm is basically a postorder traversal of the search space  proceeding forward from the initial belief state  and ruling out cyclic plans. the state of the search is stored by associating a mark to each encountered belief state. possible marks are none  processing  solved and visited  associated to a belief state bs to procedure orsrch ornode 
1 res := failure	;
1 while ornode	nil	isfailure res  
1 res := mergeresults andsrch first ornode   res ;
1 ornode := rest ornode ; 1 return res;
procedure andsrch andnode 
1 res := success;
1 while andnode	nil	isfailure res  
1 res := bssrch first andnode  ;
1 andnode := rest andnode ; 1 return res;
procedure bssrch bs 
1 if  isbsprocessing bs  
1 return failure	;
1 else if  isbssolved bs  
1 return success;
1 else if isbsnone bs 	 
1 markbssolved bs ;
1 return success;
1 else
1 prevfailure := retrievefailure bs ;
1 if  isfailure prevfailure  
1 return prevfailure;
1 else
1 markbsprocessing bs ;
1 res := orsrch bsexpand bs  ;
1 if  isfailure res  
1 markbsvisited bs ;
1 memoizefailure bs removebs res bs  ;
1 return removebs res bs ;
1 else
1 markbssolved bs ;
1 return success;
figure 1: the planning algorithm
distinguish between the following situations. none: bs has not been previously encountered. solved: a plan has been already found for bs. processing: bs is being processed  i.e. it is currently on the stack . visited: bs has been previously processed  but the search has failed  and currently bs is not on the stack. if a belief state marked processing is found  then the search has bumped into a cycle  and shall therefore fail. a visited bs may deserve further expansion  and be therefore marked processing again . the primitives for recognizing and setting the mark of a belief state are
isbs mark and markbs mark .
　in order to avoid visiting over and over portions of the search space  we also store previous failures  associating with a belief state the set of belief states that were marked processing and blocked the search because of cycle detection. we store under which hypothesis did a search attempt fail  with the memoizefailure primitive. before retrying to process a visited belief state bs  the data base of failures is accessed with retrievefailure to check if any of the previous failures applies to the current situation  i.e. it is as-
proc.vis.failuressolvedplan1
1
1
1
1
11 11  1 11  1 11  1 111  1 1gow11  1 111 1gos11 1walln1 1goe1
1
1
1
1
1
1
1
1
1
1
1
1
1
figure 1: the algorithm solves the example
sociated to bs and all of the belief states contained in it are currently being processed. in this case  bs is not processed  and the retrieved failure is returned.
　the planning algorithm is presented in figure 1. the algorithm is built on 1 recursive subroutines  each returning either success  to signal that the search completed successfully  or a pair failure reason   to signal that the search has failed because the belief states in reason are on the stack.  for lack of space  the plan construction steps carried out in case of search success are not reported here but only outlined in the case of the example.  orsrch processes an or-node  i.e. a list of and-nodes. and-nodes are repeatedly extracted from the ornode and used as input to andsrch. the results are processed by mergeresults  that constructs the return value by accumulating the set of the failure reasons of the different and searches. if a success is found  then it becomes the return value. therefore  the search proceeds until a success is found  or the or-node is completely explored  in which case a failure is returned. andsrch processes an and-node  trying to find a solution for each of the contained belief states. it selects the most promising belief state in the and-node  and uses it as input to bssrch. as soon as a failed search is detected  a failure-reason pair is propagated. if a success is received for each belief state  then a success is returned. bssrch processes a single belief state. it first checks if bs is a loop back  in which case a failure  due to the bs itself  is constructed and returned. in lines 1  the case of success is handled. in lines 1  a node that is encountered for the first time is checked against the goal. then  lines 1   retrievefailure is called to check if bs can be pruned based on a previous failure. otherwise  bs is put on the stack  line 1  and expanded by bsexpand  that constructs the corresponding or-node. this is provided in input to orsrch. if the result is a failure  then bs is removed from the stack. the failure is stored disregarding bs itself  primitive removebs  since when the search started it was not on the stack. the planner is invoked as bssrch .
　figure 1 depicts the data structures built by the algorithm while solving the example problem of figure 1. for each step  we report the belief states marked processing and marked visited  the stored failures  the belief states marked solved and the associated plan. failure 1   introduced at step 1  means that the search started on belief state 1 failed because of a loop back on that was processing. the last column associates the plan to each belief state becoming solved. belief state 1 is a subset of and is thus associated with the empty plan. is the concatenation of the action gow  that leads from 1 to 1  with . the case for is similar. the conditional plan is constructed by andsrch: the observation variable walln associated with the and-node  1  being manipulated is the test of the plan  while the branches are the plans and associated to the successful belief states 1 and 1. notice that belief state 1 is processed again at step 1  after the failure due to the loopback on 1 at step 1. the storage of previous failures can speed up the search substantially  e.g.  if from nw it were possible to enter in a different  branch  of the navigation domain that cannot lead to the solution.
1	the planner
we integrated the algorithm described above in mbp  cimatti et al.  1   a planner for nondeterministic domains based on binary decision diagrams  bdd   bryant  1  and symbolic model checking techniques  mcmillan  1 . mbp allows for conditional planning under full observability  cimatti et al.  1   also considering temporally extended goals  pistore and traverso  1 . for this work  we extended mbp in two main directions. first  we developed a bdd-based implementation for the observation relation . second  we implemented the search algorithm described in previous section. we rely on the machinery of  bertoli et al.  1   where conformant planning is tackled as deterministic  rather than and-or  search in the space of belief states. each visited belief state is represented by a unique bdd  while a hashing structure is used to efficiently implement the marking mechanism described in previous section. the expansion of a belief state  primitive bsexpand  can be described in logical terms  and is implemented by means of bdd-based transformations. we first apply the symbolic expansion used in the case of conformant planning that computes the belief states corresponding to the execution from of all the possible actions. then  for each of the generated belief states   we take into account the effect of observations by generating  for each   the and-nodes of the form . however  in order to dominate the complexity of the application of the full combination of observations  we apply the following automatic  domainindependent simplifications. first  we analyze the domain to discover if it is possible to consider only one observation at a time without losing completeness. when this is not possible  we apply observations  set-wise  to   i.e. if we consider and   the corresponding splits are both applied  resulting in the and-node
.

table 1: experimental resultsin general  plans may be produced where the same observations are needlessly carried out on all branches  or useless actions precede observations. a special purpose procedure postprocesses the solution  getting rid of these sources of redundancy. finally  the and-or search is driven by a simple selection heuristic that orders the or-node by delaying the expansion of the belief states where no observation has effect. 1	experimental evaluation
we experimentallyevaluated our approach against sgp  weld et al.  1  and gpt  bonet and geffner  1 .  other similar systems  e.g. cassandra  pryor and collins  1   that are outperformedby sgp  as shown in  weld et al.  1   are not considered.  sgp is based on graphplan. it produces acyclic conditional plans  but it is unable to deal with nondeterministic action effects  i.e. uncertainty is limited to the initial condition. a planning graph is built for each initial state that can be distinguished by observation. gpt models planning domains as markov decision processes  and  based on the probability distributions  produces a policy associating actions to belief states. the search is based on the repeated generation of learning/control trials  starting from randomly selected states in the initial belief state. the policy tends to improve as the number of trials grows. gpt cannot guarantee that the returned policies are acyclic.
　we considered several test domains. the ones from the distributions of sgp turned out to be trivial  and therefore we report only the results for medical and bt  see  weld et al.  1  for a description . the maze domains  tovey and koenig  1  are similar to the explanatory example in figure 1  where a certain goal position has to be reached from a completely unknown initial position. the empty room problem is basically a maze without internal walls. the ring domain  cimatti and roveri  1  is a ring-shaped navigation domain  where each room has a window that the robot can observe and open/close. the goal is to have all windows closed  while the initial situation is unknown. we did not consider some of the domainsfrom the gpt distribution. someof these are meaningful only in a probabilistic setting  or admit only cyclic solutions  e.g. the omelette domain .
　the experiments were run on a pentium ii 1mhz with 1mb of memory running linux  fixing a memory limit of 1mb and timeout to 1 hour cpu  unless otherwise specified . the results of the comparison are depicted in table 1. each plot refers to a problem class. we report on a logarithmic scale the search time  in seconds . the performance of sgp tends to degrade quite rapidly. the instances of bt with
1 packages reached the time limit. in the case of empty room  sgp was unable to solve the 1 version of the problem in 1 hours of cpu time. for gpt we report the average performance  over 1 runs  on increasing numbers of trial runs. in order to ensure a fair comparison  we would have liked to report the performanceof gpt on the minimumnumber of trials needed for convergence. unfortunately  detecting whether gpt has converged to a solution is not evident from the output. a necessary condition for convergence appears to be the existence of a successful trial for each possible initial state: therefore  the cardinality of the initial state  called in the following  is a lower bound for convergence. the reported results correspond to increasing multiples of  the computation time grows accordingly . as one increases the number of trials  the probability of gpt converging to a solution increases. for simpler problems like medical and bt  gpt converges after a small number of trial runs. however  in the more complex problems  the number of initial states increases  as well as the required number of trials. this implies a growth of the computationalresources needed  as clear from the results. for the maze tests  the parser was unable to deal with problems larger than 1. for the ring 1  domain  gpt fails to compute the heuristic function within the time limit. we tried to run it without heuristics  but it exhaustedthe available memory after 1 hours of cpu time. a very important point is that the difficulty of the problem slows down convergence  due to increasing possibility of failed and/or repeated trials upon certain initial states. the thick line with bullets  crossing the results of gpt  indicates up to which problem size gpt reached convergence at least once. for instance  in the empty room domain  gpt did not find a solution with for room size larger than 1 in any of the attempted 1 runs.
similarly for the mazes with size larger that 1. mbp tackles the analyzed problems quite well. search in the belief space avoids the explosion following from the enumeration of initial states  while the use of symbolic data structures limits memory requirements. the produced plans are of reasonable length  with the exceptionis the ring domain  where the selection function is not effective: combined with the depth-first search of the algorithm  this results in extremely intricated plans. further research is needed to tackle this problem.
1	related work and conclusions
in this paper we have presented a novel approach to conditional planning under partial observability. the approach is based on a model of observation that encompasses automatic sensing  tovey and koenig  1  and action-based sensing  cassandra et al.  1; weld et al.  1; bonet and geffner  1 . see also  goldman and boddy  1  for a similar model of observation. the planning algorithm is based on the exploration of a  possibly cyclic  and-or graph induced by the domain. it is different from heuristic search algorithms like ao*  that are based on the assumption that and-or search graphs are acyclic. given the exhaustive style of the exploration  the algorithm can decide whether the problem admits an acyclic solution  i.e. a plan guaranteed to reach the goal in a finite number of steps. the algorithm is efficiently implemented in the mbp planner by means of bdd-based symbolic model checking techniques. we show that mbp outperforms the sgp and gpt planners. another interesting system is qbfplan  rintanen  1a   that extends the sat-based approachto planningto the case of nondeterministicdomains. the planning problem is reduced to a qbf satisfiability problem  that is then given in input to an efficient solver  rintanen  1b . qbfplan relies on a symbolic representation  but the approach seems to be limited to plans with a bounded execution length. the search space is significantly reduced by providing the branching structure of the plan as an input to the planner.
　the problem of planning under partial observability has been deeply investigated in the framework of partially observable mdp  see  e.g.   cassandra et al.  1; hansen and zilberstein  1; poupart and boutilier  1  . gpt follows this approach. methods that interleave planning and execution  koenig and simmons  1; genesereth and nourbakhsh  1  can be considered alternative  and orthogonal  approaches to the problem of planning off-line with large state spaces. however  these methods cannot guarantee to find a solution  unless assumptions are made about the domain. for instance   koenig and simmons  1  assumes  safely explorable domains  without cycles.  genesereth and nourbakhsh  1  describes an off-line planning algorithm based on a breadth-first search on an and-or graph. the paper shows that the version of the algorithm that interleaves planning and execution is more efficient than the off-line version  both theoretically and experimentally.
　future research objectives are the extension of the partially observable approach presented in this paper to strong cyclic solutions  cimatti et al.  1  and for temporally extended goals  kabanza et al.  1 . we will also investigate the use of heuristic search techniques  and the extension to the case of planning with non-deterministic/noisy sensing.
references
 bertoli et al.  1  p.g. bertoli  m. roveri  and a. cimatti. heuristic search + symbolic model checking = efficient conformant planning proc. of ijcai-1.
 bonet and geffner  1  b. bonet and h. geffner. planning with incomplete information as heuristic search in belief space. proc. of aips-1.
 bryant  1  r. e. bryant. symbolic boolean manipulation with ordered binary-decision diagrams. acm computing surveys  1 :1.
 cassandra et al.  1  a. cassandra  l. kaelbling  and m. littman. acting optimally in partially observable stochastic domains. proc. of aaai-1.
 cimatti and roveri  1  a. cimatti and m. roveri. conformant planning via symbolic model checking. jair  1-1  1.
 cimatti et al.  1  a. cimatti  m. roveri  and p. traverso. automatic obdd-based generation of universal plans in nondeterministic domains. proc. of aaai-1.
 genesereth and nourbakhsh  1  m. genesereth and i. nourbakhsh. time-saving tips for problem solving with incomplete information. proc. of aaai-1.
 goldman and boddy  1  r.p. goldman and m.s. boddy. expressive planning and explicit knowledge. proc. of aips-1.
 hansen and zilberstein  1  e. a. hansen and s. zilberstein. heuristic search in cyclic and-or graphs. proc. of aaai-1.
 kabanza et al.  1  f. kabanza  m. barbeau  and r. st-denis. planning control rules for reactive agents. artificial intelligence  1 :1  1.
 koenig and simmons  1  s. koenig and r. simmons. solving robot navigation problems with initial pose uncertainty using real-time heuristic search. proc. of aips-1.
 littman et al.  1  michael l. littman  judy goldsmith  and martin mundhenk. the computational complexity of probabilistic planning. jair  1-1.
 mcmillan  1  k.l. mcmillan. symbolic model checking. kluwer academic publ.  1.
 pistore and traverso  1  m. pistore and p. traverso. planning as model checking for extended goals in non-deterministic domains. proc. of ijcai-1.
 poupart and boutilier  1  p. poupart and c. boutilier. valuedirected belief state approximation for pomdps. proc. of the sixteenth conference on uncertainty in artificial intelligence  uai-1 .
 pryor and collins  1  l. pryor and g. collins. planning for contingency: a decision based approach. jair  1-1.
 rintanen  1a  j. rintanen. constructing conditional plans by a theorem-prover. jair  1-1.
 rintanen  1b  j. rintanen. improvements to the evaluation of quantified boolean formulae. proc. of ijcai-1.
 smith and weld  1  david e. smith and daniel s. weld. conformant graphplan. proc. of aaai-1.
 tovey and koenig  1  c. tovey and s. koenig. gridworlds as testbeds for planning with incomplete information. proc. of aaai-1.
 weld et al.  1  daniel s. weld  corin r. anderson  and david e. smith. extending graphplan to handle uncertainty and sensing actions. proc. of aaai-1.
planning as model checking for extended goals in non-deterministic domains
marco pistore and paolo traverso
itc-irst  via sommarive 1  1 povo  trento  italy pistore traverso  irst.itc.itabstract
recent research has addressed the problem of planning in non-deterministic domains. classical planning has also been extended to the case of goals that can express temporal properties. however  the combination of these two aspects is not trivial. in non-deterministic domains  goals should take into account the fact that a plan may result in many possible different executions and that some requirements can be enforced on all the possible executions  while others may be enforced only on some executions. in this paper we address this problem. we define a planning algorithm that generates automatically plans for extended goals in nondeterministic domains. we also provide preliminary experimental results based on an implementation of the planning algorithm that uses symbolic model checking techniques.
1	introduction
most real world planning domains are intrinsically  nondeterministic . this is the case  for instance  of several robotics  control  and space application domains. most often  applications in non-deterministic domains require planners to deal with goals that are more general than sets of final desired states. the planner needs to generate plans that satisfy conditions on their whole execution paths  i.e.  on the sequences of states resulting from execution. e.g.  in a robotic application  we may need to specify that a mobile robot should  move to a given room while avoiding certain areas all along the path .
　when dealing with non-deterministic domains  the task of extending the notion of goal leads to a main key issue  related to the fact that the execution of a given plan may nondeterministically result in more than one sequence of states. consider the previous example in the robotics context. on the one hand  we would like to require a plan that guarantees to reach the room and also guarantees that dangerous areas are avoided. on the other hand  in several realistic domains  no plan might satisfy this strong requirement. we might therefore accept plans that satisfy weaker requirements  e.g.  we might accept that the robot has a possibility of reaching the room without being guaranteed to do so  but it is however guaranteed to avoid dangerous areas. alternatively  we may require a plan that guarantees that the robot reaches the desired location  just trying  if possible  to avoid certain areas  e.g.  areas that are too crowded.
　in this paper  we define and implement a planning algorithm that generates automatically plans for extended goals in non-deterministic domains. extended goals are ctl formulas  emerson  1 . they can express temporal conditions that take into account the fact that an action may non-deterministically result in different outcomes. hence extended goals allow us to distinguish between temporal requirements on  all the possible executions  and on  some executions  of a plan.
　the plans built by the algorithm are strictly more expressive than plans that simply map states to actions to be executed  like universal plans  schoppers  1   memory-less policies  bonet and geffner  1   and state-action tables  cimatti et al.  1; daniele et al.  1 . beyond expressing conditional and iterative behaviors  the generated plans can execute different actions is a state  depending on the previous execution history. this expressiveness is required to deal with extended goals.
　we have implemented the planning algorithm inside mbp  cimatti et al.  1 . mbp uses symbolic techniques based on bdds  burch et al.  1  that provide the ability to represent compactly and explore efficiently large state spaces. in the paper we present preliminary experimental results that show that the proposed algorithm works in practice.
　this paper is structured as follows. we first define nondeterministic planning domains and extended goals. we then define the structure of plans that can achieve extended goals. finally  we describe the planning algorithm  describe its implementation  and show some experimental results.
1	planning domains
a  non-deterministic  planning domain can be described in terms of  basic  propositions  which may assume different values in different states  of actions and of a transition relation describing how an action leads from one state to possibly many different states.
definition 1 a planning domain is a tuple   where is the finite set of  basic  propositions  is the set of states  is the finite set of actions  and is the transition relation. we write for .
adjust
　 1
         load adjust unlock	load		lock
	1 	1 	1 	1
			
	lock	unload	unlock
figure 1: a simple non-deterministic domain
we requirethat the transition relation is total  i.e.  for every there is some and such that
　. we denote with the set of the actions that can be performed in state : . we denote
with the set of the states that can be reachedfrom performing action : .
　in figure 1 we depict a simple planning domain  where an item can be loaded/unloaded to/from a container which can be locked/unlocked. actions load and adjust are nondeterministic. load can either succeed  and lead to state 1 where the item is loaded correctly and the container can be locked  or it may fail  and lead to state 1  where the item needs to be adjusted to a correct position in order to lock the container. action adjust may in its turn fail  and leave the item positioned incorrectly. for all states in the domain  we assume to have an action wait  not represented in the figure  that leaves the state unchanged. the basic propositions are loaded  locked and misplaced. loaded holds in states 1 and 1  locked in states 1 and 1  misplaced in state 1.
　all the work presented in this paper is independent of the language for describing planning domains. however many of these languages  e.g.  adl-like languages as pddl  are not able to represent non-deterministic domains and should be extended allowing for disjunctive effects of the actions. for instance  the action load might be described with an extension of pddl as follows.
:action load
:precondition
 and  not loaded   not locked   not misplaced  
:effect  or  loaded   misplaced  
1	extended goals
extended goals are expressed with ctl formulas.
definition 1 let be the set of basic propositions of a domain and let . the syntax of an  extended  goal for is the following:
	u	u	w	w
 x    u   and  w  are the  next time     strong  until   and  weak until  temporal operators  respectively.  a  and  e  are the universal and existential path quantifiers  where a path is an infinite sequence of states. they allow us to specify requirements that take into account non-determinism. intuitively  the formula     means that holds in every  in some  immediate successor of the current state.
	u	 	u	  means that for every path  for some
path  there exists an initial prefix of the path such that holds at the last state of the prefix and holds at all the other states along the prefix. the formula w   w   is similar to u   u   but allows for paths where holds in all the states and never holds. formulas and  where the temporal operator  f  stands for
 future  or  eventually   are abbreviations of	u	and
	u	  respectively.	and	 where  g  stands
for  globally  or  always   are abbreviations of	w
and	w	  respectively. a remark is in order: even if
is allowed only in front of basic propositions  it is easy to define for a generic ctl formula   by  pushing down  the negations: for instance and w
	u	.
　goals as ctl formulas allow us to specify different interesting requirements on plans. let us consider first some examples of reachability goals.   reach    states that a condition should be guaranteed to be reached by the plan  in spite of non-determinism.   try to reach    states that a condition might possibly be reached  i.e.  there exists at least one execution that achieves the goal. as an example  in figure 1  the strong requirement locked loaded locked loaded cannot be satisfied  while the weaker requirement locked loaded locked loaded
can be satisfied by unlocking the container  loading the item and then  if possible  locking the container. a reasonable reachability requirement that is stronger than is
       w : it allows for those executionloops that have always a possibility of terminating  and when they do  the goal is guaranteedto be achieved. in figure 1  the goal locked loaded locked loaded w locked loaded
can be satisfied by a plan that unlocks  loads  and  if the outcome is state 1  locks again  while if the item is misplaced  state 1  repeatedly tries to adjust the position of the item until  hopefully  state 1 is reached  and finally locks the container.
　we can distinguish among different kinds of maintainability goals  e.g.    maintain       avoid       try to maintain     and   try to avoid   . for instance  a robot should never harm people and should always avoid dangerousareas. weaker requirementsmight be needed for less critical properties  like the fact that the robot should try to avoid to run out of battery.
we can compose reachability and maintainability goals.
　　　　states that a plan should guarantee that all executions reach eventually a set of states where can be maintained. for instance  an air-conditioner controller is required to reach eventually a state such that the temperature can then be maintained in a given range. alternatively  if you consider the case in which a pump might fail to turn on when it is selected  you might require that  there exists a possibility  to reach the condition to maintain the temperature in a desired range    . as a further example  the goal intuitively means  maintain the possibility of reaching  .
　reachability - preserving goals make use of the  until operators    u and u   to express reachability goals while some property must be preserved. for instance  an air-conditioner might be required to reach a desired temperature while leaving at least	of its	pumps off.
　as a last example in the domain of figure 1  consider the goal  from state 1  where the container is unlocked and empty  lock the container first  and then maintain the possibility of reaching a state where the item is loaded and the container is locked  state 1  . it can be formalized as locked loaded misplaced locked
       locked loaded . in the rest of the paper  we call this example of goal  lock-then-load goal .
　notice that in all examples above  the ability of composing formulas with universal and existential path quantifiers is essential. logics that do not provide this ability  like ltl  emerson  1   cannot express these kinds of goals1.
1	plans for extended goals
a plan describes the actions that have to be performed in a given state of the world. in order to satisfy extended goals  actions that have to be executed may also depend on the  internal state  of the executor which can take into account  e.g.  previous execution steps. consider again the  lock-then-load goal  for domain in figure 1. the plan  starting from state 1  has first to lead to state 1  and then to state 1. in state 1  the first time we have to execute action lock  while we have to load the item the second time. in general  a plan can be defined in terms of an action function that  given a state and an execution context encoding the internal state of the executor  specifies the action to be executed  and in terms of a context function that  depending on the action outcome  specifies the next execution context.
definition 1 a plan for a domain is a tuple act ctxt   where:
is a set of  execution  contexts  is the initial context 
act	is the action function  ctxt	is the context function.
if we are in state and in execution context   then act returns the action to be executed by the plan  while ctxt associates to each reached state the new execution context. functions act and ctxt may be partial  since some state-context pairs are never reached in the execution of the plan. an example of a plan that satisfies the lockthen-load goal is shown in figure 1. notice that the context changes from to when the execution reaches state 1.
this allows the plan to execute different actions in state 1.
　in the rest of the paper we consider only plans that are executable and complete. we say that plan is executable if  whenever act and ctxt   then .
we say that	is complete if  whenever act	and
　  then there is some context such that ctxt and act is defined. intuitively  a complete plan always specifies how to proceed for all the possible outcomes of any action in the plan.
act 1= lockctxt 1act 1= unlockctxt 1act 1= loadctxt 1ctxt 1act 1= adjustctxt 1ctxt 1act 1= lockctxt 1act 1= waitctxt 1figure 1: an example of plan
　　　　　　　 	  1		  1
				
		  1	 	  1	  1	  	 1
figure 1: an example of execution structure
　the execution of a plan results in a change in the current state and in the current context. it can therefore be described in terms of transitions between pairs state-context. formally  given a domain and a plan   a transition of plan in is a tuple such that   act   and ctxt . a run of plan from state is an infi-
nite sequence
where are transitions. given a plan  we may have an infinite number of runs due to the nondeterminism of the domain. this is the case of the plan in figure 1  since the execution can loop non-deterministically over the pair state-context 1 . we provide a finite presentation of the set of all possible runs of a plan with an execution structure  i.e  a kripke structure  emerson  1  whose set of states is the set of state-context pairs  and whose transition relation corresponds to the transitions of the runs.
definition 1 the execution structure of plan	in a domain
d from state	is the structure	  where:
	act	is defined  
	if	for some	 
as an example  the execution structure of the plan in figure 1 is depicted in figure 1.
　we define when a goal	is true in	  written by using the standard semantics for ctl formulas over the kripke structure	. the complete formal definition can be found in  e.g.   emerson  1 .	in order to make the paper self contained  we present here some cases. propositional formulas are treated in the usual way. iff for every path	  with	  we have	.
	u	iff for every path	  with
	  there exists	such that
and  for all   . the definition is similar in the case of existential path quantifiers. we can now define the notion of plan that satisfies a given goal.
definition 1 let be a planning domain and be a goal for . let be a plan for and be the corresponding execution structure. plan satisfies goal from initial state
　  written   if . plan satisfies goal from the set of initial states if for each
.
for instance  the plan in figure 1 satisfies the lock-then-load goal from state 1.
1	planning algorithm
the planning algorithm searches through the domain by trying to satisfy a goal in a state . goal defines conditions on the current state and on the next states to be reached. intuitively  if must hold in   then some conditions must be projected to the next states. the algorithm extracts the information on the conditions on the next states by  progressing  the goal . for instance  if is   then either holds in or must still hold in some next state  i.e. 
must hold in . one of the basic building blocks of the algorithm is the functionprogrthat rewrites a goal by progressing it to next states. progris defined by induction on the structure of goals.
progr	and progr	; progr	if	then	else	; progr	if	then	else	; progr	progr	progr	; progr	progr	progr	; progr	and progr	;
	progr	u	progr	u
	progr	and progr	u	progr
	u	progr	;
	progr	w	progr	w
progr and progr w progr w progr .
the formula progr can be written in a normal form. we write it as a disjunction of two kinds of conjuncts  those of the form and those of the form   since we need to distinguish between formulas that must hold in all the next states and those that must hold in some of the next states: progr
where     if     belongs to the -th disjunct of progr . we have different disjuncts that correspond to alternative evolutions of the domain  i.e.  to alternative plans we can search for. in the following  we represent progr as a set of pairs  each pair containing the and the parts of a disjunct:
           progr with progr	and progr	.
　given a disjunct of progr   we can define a function that assigns goals to be satisfied to the next states.
we denote with assign-progr the set of all the possible assignments such that each universally quantified goal is assigned to all the next states  i.e.  if then for all   and each existentially quantified goal is assigned to one of the next states  i.e.  if	and	then	for one particular
 . consider the following example in the domain of
figure 1. let be locked misplaced loaded and let the current state be 1. we have that locked misplaced loaded progr 1 . if we consider action load  the next states are 1 and 1. then locked must hold in 1 and in 1  while misplaced and loaded must hold in 1 or in 1. we have therefore four possible state-formulas assignments to be explored  in the following we write
	for	locked 	for misplaced  and	for loaded :
	1
	1
	1
	1
in this simple example  it is easy to see that the only assignment that may lead to a successful plan is .
　given the two basic building blocks progr and assign-progr  we can now describe the planning algorithm build-plan that  given a goal and an initial state   returns either a plan or a failure.1 the algorithm is reported in figure 1. it performs a depth-first forward search: starting from the initial state  it picks up an action  progresses the goal to successor states  and iterates until either the goal is satisfied or the search path leads to a failure. the algorithm uses as the  contexts  of the plan the list of the active goals that are considered at the different stages of the exploration.
more precisely  a context is a list   where the are the active goals  as computed by functions progr and assig-progr  and the order of the list represents the age of these goals: the goals that are active since more steps come first in the list.
　the main function of the algorithm is function build-plan-aux pl open   that builds the plan for context from state . if a plan is found  then it is returned by the function. otherwise  is returned. argument pl is the plan built so far by the algorithm. initially  the argument passed to build-plan-aux is pl act ctxt .
argument open is the list of the pairs state-context of the currently open problems: if open then we are currently trying to build a plan for context in state . whenever function build-plan-aux is called with a pair state-context already in open  then we have a loop of states in which the same sub-goal has to be enforced. in this case  function is-good-loop open is called that checks whether the loop is valid or not. if the loop is good  plan pl is returned  otherwise function build-plan-auxfails.
　function is-good-loop computes the set loop-goals of the goals that are active during the whole loop: iteratively  it considers all the pairs that appear in open up to the next occurrence of the current pair   and it intersects loop-goals with the set setof of the goals in list . then  function is-good-loop checks whether there is some strong until goal among the loop-goals. if this is a case  then the loop is bad: the semantics of ctl requires that all the strong until goals are eventually fulfilled  so these goals should not
function build-plan return build-plan-auxplanfunction build-plan-aux if open thenpl open planif is-good-loopopen then return plelse return
	if defined plact	then returnpl
foreach	do foreach progr do
foreach assign-progr pl pl
pl	pl pl act
open	conc	open foreach	do
order-goals
pl ctxtdo　　　　pl	build-plan-aux if pl	then next return pl returnplopenfunction is-good-loop open loop-goals setofbooleanwhile head open do head open
	loop-goals	loop-goals setof
	open	tail open
if	loop-goals	u	or	u	then return false
else return true
figure 1: the planning algorithm.
stay active during a whole loop. in fact  this is the difference between strong and weak until goals: executions where some weak until goal is continuously active and never fulfilled are acceptable  while the strong untils should be eventually fulfilled if they become active.
　if the pair is not in open but it is in the plan pl  i.e.  is in the range of function act and hence condition  definedplact   is true   then a plan for the pair has already been found in another branch of the search  and we return immediately with a success. if the pair state-context is neither in open nor in the plan  then the algorithm considers in turn all the executable actions from state   all the different possible progresses returned by functionprogr  and all the possible assignments of to .
function build-plan-aux is called recursively for each destination state in . the new context is computed by functionorder-goals : this function returns a list of the goals in that are ordered by their  age : namely those goals that are old  they appear in and also in   appear first  in the same order as in   and those that are new  they appear in but not in   appear at the end of the list  in any order. also  in the recursive call  argument pl is updated to take into account the fact that action has been selected from state in context . moreover  the new list of open problems is updated to conc open   namely the pair is added in front of argumentopen.
　any recursive call of build-plan-aux updates the current plan pl . if all these recursive calls are successful  then the final value of plan pl is returned. if any of the recursive calls returns   then the next combination of assign decomposition  progress component and action is tried. if all these combinations fail  then no plan is found and is returned.
　as an example  call build-plan 1 lock-then-load is successful and returns the plan in figure 1 where and
are goals	locked	locked	loaded	and locked	loaded   respectively.
　the algorithm always terminates  and it is correct and complete: given a state of a domain and a goal for   if build-plan then   and if build-plan
	then there is no plan	such that	.
1	symbolic implementation and experimental results
we have implemented the planning algorithm and have performed some experimental evaluations. though very preliminary  the experiments define some basic test cases for planning for ctl goals in non-deterministic domains  show that the approach is effective in practice with cases of significant complexity  and settle the basis for future comparisons.
　we have implemented the algorithm inside mbp   cimatti et al.  1  . mbp uses symbolic techniques based on bdds  burch et al.  1  to overcome the problems of the explicit-state planning algorithm due to the huge size of realistic domains  and in particular of non-deterministic domains.
　in order to provide a bdd-based implementation  the explicit algorithm presented in the previous section has to be revisited  taking into account the fact that bdds work effectively on sets of states rather than on single states. for lack of space  we can not describe the symbolic bdd-based algorithm in details: further information on this algorithm  as well as on the test cases  can be found at the mbp home page http://sra.itc.it/tools/mbp.
　one of the very few examples of planning for extended goals in non-deterministic domains that we have found in the literature is the  robot-moving-objects  search problem  presented in  kabanza et al.  1  to test the simplan planner for some ltl-like goals. the domain consists of a set of rooms connected by doors  of a set of objects in the rooms  and of a robot that can grasp the objects and carry them to different rooms. the non-determinism in the domain is due to the fact that  some of  the doors are defective and can close without an explicit action of the robot.
　we have performed experiments with different extended goals. for lack of space we report only the results for the goal of moving the objects into given rooms and keeping them there  experiment 1 in  kabanza et al.  1  . in our framework  this goal is of the form . the problem is parametrized in the number of the possible objects to be moved and in the number of defective doors. the time required to build the plan is reported in figure 1  all tests were

figure 1: experimental results
performed on a pentium ii 1 mhz with 1 mb ram of memory running linux . the time scale is logarithmic and shows that the required time grows exponentially in the number of objects  this corresponds to an exponential growth in the size of the domain . due to the usage of symbolic techniques  instead  the performance is not influenced by the nondeterminism. we remark that in the case of 1 objects the domain is quite complex: it has more than states.
　the results reported in  kabanza et al.  1  show a complementary behavior: simplan scales well with respect to the number of objects  but the explicit state search suffers significantly in the case of non-deterministic domains. we remark  however  that the efficient behavior of simplan in the case of deterministic domains depends on the enforced domain-dependent search control strategies  that are able to cut the largest part of the search graph. our experiments show that mbp outperforms simplan  if the latter is executed without control strategies. this result is not surprising: symbolic techniques have shown to be dramatically more efficient that explicit techniques in the case of huge search space.
1	conclusions and related work
in this paper we have presented an approach to automatic planning in non-deterministic domains where the goals are expressed as ctl formulas. we have implemented the algorithm by using symbolic model checking techniques  which open up the possibility to deal with large state space.
　some future objectives are the following. the symbolic implementation is still a rather naive transcription of the explicit algorithm presented in the paper: further work in needed to develop a symbolic algorithm that fully exploits the potentiality of bdds and of the symbolic exploration of huge state spaces. moreover  we plan to perform an extensive test with different kinds of extended goals on a set of realistic domains  to show that the approach is indeed practical. finally  in this paper we focus on the case of full observability. an extension of the work to the case of planning for extended goals under partial observability is one of the main objectives for future research.
　the problem of planning for ctl goals has never been solved before. the starting point of the work presented in this paper is the framework of  planning via symbolic model checking   see  e.g.   cimatti et al.  1; daniele et al.  1; bertoli et al.  1  . none of the previous works in this framework deals with temporally extended goals. the issue of  temporally extended goals  is certainly not new. however  most of the works in this direction restrict to deterministic domains  see for instance  de giacomo and vardi  1; bacchus and kabanza  1 . a work that considers extended goals in non-deterministic domains is described in  kabanza et al.  1 : see section 1 for a comparison.
　extended goals make the planning problem close to that of automatic synthesis of controllers  see  e.g.   asarin et al.  1; kupferman and vardi  1  . however  most of the work in this area focuses on the theoretical foundations  without providing practical implementations. moreover  it is based on ratherdifferenttechnical assumptionson actions and on the interaction with the environment.
references
 asarin et al.  1  e. asarin  o. maler  and a. pnueli. symbolic controller synthesis for discrete and timed systems. in hybrid system ii  lncs 1  1.
 bacchus and kabanza  1  f. bacchus and f. kabanza. planning for temporally extended goals. annals of mathematics and artificial intelligence  1-1  1.
 bertoli et al.  1  p. bertoli  a. cimatti  m. roveri  and p. traverso. planning in nondeterministic domains under partial observability via symbolic model checking. in proc. of ijcai'1  1.
 bonet and geffner  1  b. bonet and h. geffner. planning with incomplete information as heuristic search in belief space. in proc. of aips 1  1.
 burch et al.  1  j. r. burch  e. m. clarke  k. l. mcmillan  d. l. dill  and l. j. hwang. symbolic model checking: states and beyond. information and computation  1 :1  1.
 cimatti et al.  1  a. cimatti  m. roveri  and p. traverso. automatic obdd-based generation of universal plans in non-deterministic domains. in proc. of aaai'1  1.
 daniele et al.  1  m. daniele  p. traverso  and m. y. vardi. strong cyclic planning revisited. in proc. of ecp'1  1.
 de giacomo and vardi  1  g. de giacomo and m.y. vardi. automata-theoretic approach to planning with temporally extended goals. in proc. of ecp'1  1.
 emerson  1  e. a. emerson. temporal and modal logic. in j. van leeuwen  editor  handbook of theoretical computer science  volume b: formal models and semantics  chapter 1. elsevier  1.
 kabanza et al.  1  f. kabanza  m. barbeau  and r. stdenis. planning control rules for reactive agents. artificial intelligence  1 :1  1.
 kupferman and vardi  1  o.	kupferman	and	m.y.
vardi. synthesis with incomplete information. in proc. of 1nd international conference on temporal logic  1.
 schoppers  1  m. j. schoppers. universal plans for reactive robots in unpredictable environments. in proc. of ijcai'1  1.

planning
planning with temporal uncertainty

executing reactive  model-based programs through graph-based temporal planning

phil kim and brian c. williams
mit rm. 1
1 massachusetts ave.
 cambridge  ma 1 usa kim williams  mit.edu mark abramson
draper lab
1 technology square  ms1f cambridge  ma 1 usa mabramson draper.com

abstract
in the future  webs of unmanned air and space vehicles will act together to robustly perform elaborate missions in uncertain environments. we coordinate these systems by introducing a reactive model-based programming language  rmpl  that combines within a single unified representation the flexibility of embedded programming and reactive execution languages  and the deliberative reasoning power of temporal planners. the kirk planning system takes as input a problem expressed as a rmpl program  and compiles it into a temporal plan network  tpn   similar to those used by temporal planners  but extended for symbolic constraints and decisions. this intermediate representation clarifies the relation between temporal planning and causal-link planning  and permits a single task model to be used for planning and execution. such a unified model has been described as a holy grail for autonomous agents by the designers of the remote agent muscettola et al.  1b .
1	model-based programming
the recent spread of advanced processing to embedded systems has created vehicles that execute complex missions with increasing levels of autonomy  in space  on land and in the air. these vehicles must respond to uncertain and often unforgiving environments  both with a fast response time and with a high assurance of first time success. the future looks to the creation of cooperative robotic networks. for example  a heterogenous collection of vehicles  such as planes  helicopters and boats  might work in concert to perform a search and rescue during a hurricane or similar natural disaster. in addition  giant space telescopes are being deployed that are composed of satellites carrying the telescope's different optical components. these satellites act in concert to image planets around other stars  or unusual weather events on earth.
　the creation of robotic networks cannot be supported by the current programming practice alone. recent mission failures  such as the mars climate orbiter and polar landers  highlight the challenge of creating highly capable vehicles within realistic budget limits. due to cost constraints  spacecraft flight software teams often do not have time to think through all the plausible situations that might arise  encode the appropriate responses within their software and then validate that software with high assurance. to break through this barrier we need to invent a new programming paradigm.
　in this paper we advocate the creation of embedded  modelbased programming languages. first  programmers should retain control for the overall success of a mission  by programming game plans and contingencies that in the programmer's experience will ensure a high degree of success. the programmer should be able to program these game plans using features of the best embedded programming languages available. for example  reactive synchronous languages halbwachs  1   like esterel  lustre and signal  offer a rich set of constructs for interacting with sensors and actuators  for creating complex behaviors involving concurrency and preemption  and for modularizing these behaviors using all the standard encapsulation mechanisms. modelbased programming extends this style of reactive language with a minimal set of constructs neccessary to perform flexible mission coordination  while hiding its reasoning capabilities under the hood of the language's interpreter or compiler. second  we argue that model-based programming languages should focus on elevating the programmer's thinking  by automating the process of reasoning about low-level system interactions. many recent space mission failures  such as mars climate orbiter and mars polar lander  can be isolated to difficulties in reasoning through low-level system interactions. on the other hand  this limited form of reasoning and book keeping is the hallmark of computational methods. the interpreter or compiler of a model-based program reasons through these interactions using composable models of the system being controlled. we are developing a language  called the reactive model-based programming language  rmpl   that supports four types of reasoning about system interactions: reasoning about contingencies  scheduling  inferring a system's hidden state and controlling that state. this paper develops rmpl in the context of contingencies and scheduling  while  williams et al.  1   shows how rmpl is used to infer hidden state.
　rmpl offers a middle ground between execution languages  like raps  firby  1   and highly flexible  operator-based temporal planners like hsts  muscettola et al.  1a . raps offers the exception handling and concurrencymechanisms of embeddedlanguages  while adding goal monitoring  nondeterministic choice and metric constraints. however  raps makes its decisions reactively  without addressing concerns of schedulability and threat resolution  and hence can fall into a failure state. rmpl incorporates the forward looking planning and scheduling abilities of modern temporal planners  but can severely restrict the space of plans considered to possible threads of execution through the rmpl program. this speeds response and mitigates risk.
　the paper begins by introducing a subset of rmpl that includes constructs from traditional reactive programming plus constructs for specifying contingencies and scheduling constraints. second  we describe how kirk  an rmpl-based planner/executive  compiles rmpl programs into temporal plan networks  tpn   which compactly represent all possible threads of execution of an rmpl program  and all resource constraints and conflicts between concurrent activities. third  we present kirk's online planning algorithm for rmpl that  looks  by using network search algorithms to find threads of execution through the tpn that are temporally consistent. the result is a partially ordered temporal plan. kirk then  leaps  by executing the plan using plan execution methods tsamardinos et al.  1  developed for remote agent muscettola et al.  1b . finally  we discuss kirk's application to a simulated search and rescue mission.
1	example: cooperative search and rescue

as part of a search and rescue mission  consider an activity called enroute  in which a group of vehicles fly together from a rendezvous point to the target search area. in this activity  the group selects one of two paths for traveling to the target area  flies together along the path through a series of waypoints to the target position  and then transmits a message to the forward air controller to indicate their arrival  while waiting until the group receives authorization to engage the target search area.
　the two paths available for travel to the target area are each only available for a predetermined window of time  which is important to consider when selecting one of these paths. in addition  the timing of the enroute activity is bound by externally imposed requirements  for example  the search and rescue mission must complete in 1 minutes  with 1% to 1% of the time allotted to the enroute activity.
　codifying the enroute activity requires most standard features of embedded languages. there are both sequential and concurrent threads of activities  such as going to a series of way points  and sending a message to the forward air controller  fac   while concurrently awaiting authorization. there are maintenance conditions and synchronizations. for example  the air corridor needs to be maintained safe during flight  and synchronization occurs with the fac.
in addition to constructs found in traditional embedded languages  we need constructs for expressing timing requirements and alternative choices or contingencies  in this example to use one of two corridors. these constructs are common to robotic execution languages firby  1 . however  they are only used reactively. kirk must reason forward through the rmpl program's execution  identifying a course of action that is consistent.
1	rmpl constructs
to summarize  rmpl needs to include constructs for expressing concurrency  maintaining conditions  synchronization  metric constraints and contingencies. the relevant rmpl constructs are as follows. we use lower case letters  like   to denote activities or conditions  and upper case letters  like and   to denote well-formed rmpl expressions: . invokes primitive activity   starting at the current time. this is the basic construct for initiating activities.
   . asserts that condition is true at the current time  where is a literal. this is the basic construct for asserting conditions.
　if thennext . starts executing if condition is currently satisfied  where is a literal. this is the basic construct for expressing conditional branches and asserting preconditions.
do maintaining . executes   and ensures throughout that occurs. this is the basic construct for introducing
maintenance conditions and protections.
　　　. concurrently executes a and b. it is the basic construct for forking processes.
　　　. consecutively executes a and then b. it is the basic construct for sequential processes.
　　　. constrains the duration of program a to be at least and at most . this is the basic construct for expressing
timing requirements.
choose . reduces non-deterministicallyto program or . this is the basic construct for expressing multiple
strategies and contingencies.
　note that together  and if thennext provide the basic constructs for synchronization by specifying required and asserted conditions. and provide the neccessary constructs for building complex concurrent threads.
　the  do maintaining  construct offers a building block for creating complex preemption and exception handling mechanisms. note that to fully exploit these mechanisms kirk would need to perform conditional planning. the algorithms presented in this paper only address unconditional planning. with this restriction  do maintaining  acts as a maintenance condition that kirk must prove holds at planning time.
　using these constructs we express the enroute activity as follows:
group-enroute   l u  = { choose {
do {
group-fly-path path1 path1 
path1 tai pos  l*1% u*1% ;
} maintaining path1 ok  do {
group-fly-path path1 path1 
path1 tai pos  l*1% u*1% ;
} maintaining path1 ok
};
{
group-transmit fac arrived tai  1   do {
group-wait tai hold1 tai hold1 
 1 u*1% 
} watching proceed ok
}
}
　the choose expression models the two options for flight paths. 1% of the total time of the overall maneuver is allocated to this group flight. each flight has a maintenance condition that the flight path is okay. arrival is transmitted to the forward air controller  and receipt of a message to proceed is concurrently monitored.
1	temporal plan networks
executing an rmpl program involves choosing a set of threads of execution  plans   checking to ensure that the execution is consistent and schedulable  and then scheduling events on the fly. it is essential that we generate these plans quickly. this suggests compiling rmpl programs to a plan graph  along the lines of graphplan or satplan  weld  1   and then searching the precompiled graph. however  it is also important for the plan to have the temporal flexibility offered by a partially ordered  temporal plan. least committment leaves slack to adapt to execution uncertainties and to recover from faults. this partial committment is expressed in temporal planning through a simple temporal network  stn  dechter et al.  1 . hence  a key observation of our approach is that to build in temporal flexibility we should build our graph-based plan representation  called a temporal plan network  tpn   as a generalization of an stn.
　the tpn corresponding to the above enroute program is shown below. activity name labels are omitted to keep the figure clear  but the node pairs 1 and 1 represent the two group-fly-path activities  and node pairs 1 and 1 correspond to the group-wait and group-transmit activities  respectively. node 1 is a decision node that represents a choice between two methods for flying to the search area. the tpn represents the consequences of the constraint that the mission last between 1 and 1 minutes. it also models the decision between the two paths to the target area  and it models the restrictions that each of the paths can only be used if they are available.

　a tpn encodes all feasible executions of an activity. it does this by augmenting an stn with two types of constraints: temporal constraints restrict the behavior of an activity by bounding the duration of an activity  time between activities  or more generally the temporal distance between two events. symbolic constraints restrict the behavior of an activity by expressing the assertion or requirement of certain conditions by activities that all valid executions must satisfy.
　for example  consider some of the possible executions of the enroute activity. one possible execution is that the group flies along path one  pair 1  to the target area in 1 time units  seconds in this case   transmits an arrival message to the forward air controller  1  for one second  and concurrently waits  1  for another 1 seconds to receive authorization to proceed. another possible execution is that the group selects the second path  flies to the target area in 1 seconds  takes 1 seconds to transmit the arrival message  and is authorized to proceed immediately. if it were the case that path one was available from the time at which the enroute activity started to at least the time that the group arrived at the target area  then the first execution is valid. this is because it satisfies both the temporal constraints on the enroute activity  and the requirement that path one is available for the duration of the flight along it. the planning algorithm presented in the next section performs the identification of consistent activity executions.
　a temporal planning network is a simple temporal network  augmented with symbolic constraints and decision nodes. these additions are sufficent to capture all rmpl constructs given earlier. like a simple temporal network  the nodes of a tpn represent temporal events  and the arcs represent temporal relations that constrain the temporal distance between events. an arc of a tpn may be labeled with a symbolic constraint tell c  or ask c   as well as a duration. a tell c  label on an arc  i j  asserts that the condition represented by c is true over the interval between the temporal events modeled by the nodes i and j. similarly  an ask c  label on an arc  i j  requires that the condition represented by c is true over the interval represented by this arc. for example  in the enroute tpn  the ask path1=ok  label on the arc  1  represents the requirement for path one to be available for the interval of time corresponding to the interval of time between the temporal event modeled by node 1 and node 1. these ask-type symbolic constraints allow for the encoding of conditions in the network.
　decision nodes are used to explicitly introduce choices in activity execution that the planner must make. for example  in the enroute activity there are two choices of paths for the group to use for flying to the target area  path one and path two. the activity model captures the two choices as out-arcs of node 1 of the enroute tpn. this decision node is designated by a double outline and dashed out-arcs. all other nodes in the enroute tpn are non-decision nodes.
1	compiling rmpl to tpn
given a well formed rmpl expression  we compile it to a tpn by mapping each rmpl primitive to a tpn as defined below. rmpl sub-expressions  denoted by upper case letters  are recursively mapped to equivalent tpn:
	. invoke activity a between	and	time units.
	a.star t 	a.end 

	. assert that condition	is true now until	.

　if thennext . execute for   if condition is currently satisfied.
	a.st ar t 	a.end 

　do maintaining . execute for   and ensure throughout that occurs.
	a.star t 	a.end 

                 . concurrently execute a for and b for .

	.	execute a for	  then b for
.
	a.star t 	a.end 

	choose	.	reduces to	or
  non-deterministically.

1	planning using tpns
after compiling an rmpl program into a tpn  kirk's planner uses the tpn to search for an execution that is both complete and consistent. the execution corresponds to an unconditional  temporal plan. a plan is complete if choices have been made for each relevant decision point  it contains only primitive-level activities  and all activities labeled ask c  have been linked to a tell c . a plan is consistent if it does not violate any of its temporal constraints or symbolic constraints. the resulting plan is then executed using the plan runner described in  tsamardinos et al.  1 .
　the input to kirk's planner is a tpn describing an activity scenario. a scenario consists of the tpn for the top-level activity invoked and any constraints on its invocation. the following tpn invokes enroute  nodes 1 . in a parallel thread it constrains the time ranges over which path one is available  nodes 1  and over which the vehicles may perform search  nodes 1 .

　the output of the planner consists of a set of paths through the input network from the start-node to the end-node of the top-level activity. in the example the paths s-1-1-1-1-e and s-1-1-e define a consistent execution. the first path defines the execution of the group of vehicles  and the second path defines the  execution  of the rest of the world in terms of the assertion or requirementof relevant conditions over the duration of the scenario. the portion of the tpn not selected for execution is shown in gray.
　planning involves two interleaved phases. the first phase resembles a network search that discovers the sub-network  that constitute a feasible plan  while incrementally checking for temporal consistency. the second phase is analogous to the repair step of a causal link planner  in which threats are detected and resolved  and open conditions are closed weld  1 .
1	phase one: select plan execution
the first phase selects a set of paths from the start-node to the end-node of the top-level activity. the planner handles this execution selection problem as a variant of a network search ahuja et al.  1  rooted at the start-node of the tpn encoding of the top-level activity.
searching the network
recall that each node of a tpn is either a decision node or a non-decision node. if a plan includes a non-decision node with multiple out-arcs  then all of these arcs and their tail nodes must be included in the plan. if a plan includes a decision node with multiple out-arcs  then the arcs represent alternate choices  and the planning algorithm selects exactly one to be included in the plan.
　network search completes only when all paths reach the end-node of the top-level activity  and the subnetwork of the tpn  defined by these paths  is temporally consistent. this corresponds to testing consistency of an stn dechter et al.  1   as discussed in the next section.
　the first phase of planning is summarized by the modified network search algorithm  shown below. the set a  is the set of active nodes  which are those nodes whose paths have not yet been fully extended. the sets sn and sa are the sets of selected nodes and selected arcs  respectively:
1 modified-network-search  n  
1 a = { start-node of n };
1 sn = { start-node of n };
1 sa = { };
1 while   a is not empty  
1 node = select and remove a member of a;
1 if   node is a decision-node  
1 arc = select any unmarked out-arc of node and
1 mark arc and
1 add arc to sa;
1 if   tail of arc is not in sn  
1 add tail of arc to a and sn;
1 end-if
1 else
1 for each arc that is an out-arc of node
1 add arc to sa;
1 if   tail of arc is not in sn  
1 add tail of arc to a and sn;
1 end-if
1 end-for
1 end-if
1
1 if   cycle-induced sn  sa   
1 if   not temporally-consistent sn  sa    
1 backtrack sn  sa  a ;
1 end-if
1 end-if
1 end-while
1 end-function
　the algorithm extends an active node at each iteration. decision nodes are treated by extending the path along one out arc  lines 1   while non-decision nodes are treated by branching the path and extending along all out arcs  lines 1 . at the end of each iteration of the main while-loop  the modified network search tests for temporal consistency  lines 1 . if the test fails  then the search calls backtrack ..  in line 1  which reverts sn  sa  and a to their states before the most recent decision that has unmarked choices remaining  and selects a different out-arc. while for simplicity this explanation uses chronological backtracking  a wealth of more efficient search algorithms can be applied.
　note that it is not necessary to check temporal consistency after every iteration of the while-loop  since as long as no cycles are induced in the network  there is no way for a temporal inconsistency to be induced. determining whether a cycle has been created can be done for each arc that is selected by checking whether the arc's tail node has already been selected. since this can be done in constant time  it is significantly more efficient in practice than testing temporal consistency after every iteration  although it doesn't impact worst case complexity.
　also note that the algorithm stops extending a path when it encounters a node that is already in sn. the fact that this node is already in sn implies that two concurrent threads of execution have merged.
　finally  after the modified network search completes  the selected nodes and arcs define a set of paths from the startnode to the end-node of the top activity.
example:searching the enroute network
to illustrate the modified network search  we return to the enroute input network  where node 1 is the start-node and node 1 is the end-node:

　initially  node 1 is selected  which is indicated by its darker shade  and it is active. in the first iteration  kirk chooses node 1 from the set of active nodes  and since node 1 is not a decision node  it selects all out-arcs and adds their tails to the selected and active set. this continues until both node 1 and node 1 are selected:

　at this point  the modified network search chooses node 1 from the active set. since node 1 is a decision node  the algorithm must choose either arc  1  or arc  1 . it selects arc  1  and continues extending until it reaches the following:

　note that arc  1  is selected  forming the cycle  1-1-1-1-1-1 so the algorithm checks for temporal consistency. in this example  this selected sub-network is temporally inconsistent  so the algorithm backtracks to the most recent decision with open options  which is node 1. out-arc  1  has not yet been tried  so it is selected and the path extend to the end-node. finally a path through arc  1  is found to the end-node  resulting in the temporally consistent sub-network:

checking temporal consistency
to check temporal consistency we note that any subnet of a plan network  minus its symbolic constraint labels  forms a simple temporal network. hence temporal consistency can be checked using standard methods for simple temporal networks  dechter et al.  1 . recall that an stn is consistent if and only if its encodingas a distance graph contains no negative cycles  dechter et al.  1 . there exist several well knownalgorithms for detecting negativecycles in polynomial time. the bellman-ford algorithm  cormen et al.  1  can be used to check for negative cycle in time  where and are the number of arcs and nodes in the distance graph  respectively. this algorithm only needs to maintain one distance label at each node  which takes only space. a variant of this algorithm is used by hsts  muscettola et al.  1a  for fast inconsistency detection.
　the algorithm we use in the kirk planner is a variant of the generic label-correcting single-source shortest-path algorithm  ahuja et al.  1   which takes worst-case asymptotic running time  but performs faster in many situations. this algorithm also requires only space. space precludes a more detailed development.
1	phase two: threats and open conditions
symbolic constraints- ask c  and tell c  - are handled analogous to threats and open conditions in causal link planning weld  1 . two symbolic constraints conflict if one is either asserting  by using tell  or requesting  by using ask  that a condition is true  and the second is asserting or requesting that the same condition is false. for example  tell not c   and ask c  conflict. an open condition in a tpn appears as ask constraints  which represent the need for some condition to be true over the interval of time represented by the arc labeled with the ask constraint.
resolving threats
to detect threats the planner computes the feasible time bounds for each temporal event  node  in the network  and then uses these bounds to identify potentially overlapping intervals that are labeled with inconsistent constraints. these bounds can be computed by solving an all-pairs shortest-path problem over the distance graph of the partially completed plan. kirk uses the floyd-warshall algorithm for computing all-pairs shortest paths. we are currentlyevaluatingjohnson's
algorithmwhich runs in   or if	.
　once these feasible time ranges are determined  the planner detects which arcs may overlap in time. if there are two arcs that may overlap and that are labeled with conflicting symbolic constraints  then they are resolved by ordering the intervals  if possible.
　these interval pairs need to be identified efficiently. kirk maintains an interval set data structure for each proposition that keeps track of all intervals that assert or require or its negation. in order to identify threats  the planner need only check each interval set for threats. this takes asymptotic running time  where is the maximum cardinality over all interval sets  and performs much better in practice because the interval sets typically have few elements. more sophisticated indexing schemes may improve performance  such as interval tree structures  cormen et al.  1 .
　a threat is resolved by introducing temporal constraints. each threat consists of two arcs that represent intervals of time that may overlap. to resolve threats we introduce a constraint that forces an ordering between the two activites  similar to promotion and demotion in classical planning weld  1 :

closing open conditions
an open condition is represented by an arc labeled with an ask constraint  which represents the request for a condition to be satisfied over the interval of time represented by the arc. if this interval of time is contained by another interval over which the condition is asserted by a tell constraint  then the open condition is satisfied  i.e.  closed   and a causal link is drawn from the tell to the ask. open conditions are detected simply by scanning through all activites and checking any ask constraints. finding potentially overlapping intervals is performed using the same method described above for detecting threats. once a tell is found that can satisfy an open condition  temporal constraints are added so that the duration of the open condition is contained within the tell. this method of closing open asks is also closely related to the way that the hsts planner satisfies compatibilities  muscettola et al.  1a :

1	implementation and discussion
kirk's compiler generates tpn specification files  and is written in lisp. kirk's planner  written in c++  generates a plan from the tpn and checks consistency. kirk's executive  based on the remote agent plan runner  tsamardinos et al.  1   takes the resulting partially ordered temporal plan and executes it on the multi-air vehicle simulator. the following table summarizes kirk's performance on nominal plans for several activities within the search and rescue scenario. the fully expanded tpn generated from the group-search-andrescue activity included 1 nodes. the testing platform was an ibm aptiva e1u with an intel 1mhz pentium ii processor and 1mb of ram  running redhat linux version 1:

top activitynodesactivitiesplan timefollow .. 11 msgroup-rescue .. 11 msgroup-enroute  11 sgroup-sr-mission  11 s
　 top activity  refers to the top-level activity that was being planned.  nodes  is the size of the expanded tpn after planning. usually  about half of these were included in the final plan  with the rest corresponding to unselected executions.  activities  indicates the number of primitive activities included in the final plan. finally  the  plan time  gives the time that it took for kirk to generate a plan corresponding to each of these activities.
　kirk offers two sources for efficiency. first  typically an rmpl program significantly constrains the space of possible plans considered  in the spirit of hierarchical task network planners  erol et al.  1 . second  the use of tpns reduces online planning to graph search. in the example kirk does well with no search guidance up to about 1 nodes. at this point the time becomes dominated by the time required to compute feasible time bounds for events. this is due to the use of bellman-ford and chronological search. we are exploring a reimplementation based on johnson's algorithm and a more sophisticated search strategy.
　the primary contribution of this paper is the reactive model-based programming language and the temporal plan network representation. the algorithms presented here only begin to explore rmpl/tpn-based planning. the following are some example directions for further research.
　this paper focuses on the use of tpns as a synthesis of causal link planning weld  1   temporal planning  muscettola  1  and hierarchical task network planning erol et al.  1 . can methods from graph-based planning blum and furst  1; weld  1; smith and weld  1   particularly mutual exclusion relationships  be effectively employed within a tpn  an important element of practical temporal planners in the space domain  such as hsts muscettola  1  and ixtet laborie and ghallab 
1   is the ability to plan with depletable resources. can rmpl and tpns be similarly extended  how can rmpl and tpns be extended to support decision theoretic planning and agile maneuver planning  common to robotic vehicles 
　rmpl offers an expressive embedded programming language  by inheriting most of its primitive combinators from the timed concurrent constraint language  tcc   saraswat et al.  1 . for example  as with tcc  these primitives allow a rich set of operators to be derived for preemption and exception handling  similar to those found in embedded languages like esterel berry and gonthier  1 . however  the algorithm presented here performs unconditional planning  and hence only considers the case where exceptions can be prevented. rmpl's ability to express exception handling mechanisms can best be exploited through the development of conditional planning algorithms.
　finally  rmpl allows the programmer to constrain the family of possible behaviors that the planner considers when controlling an embedded system. it is important that this family of behaviors be safe. embedded languages like esterel berry and gonthier  1   lustre halbwachs et al.    and signal guernic et al.    offer a clean semantics  and offer support for direct machine verification of safety and liveness properties. the verification of rmpl programs would be similar  but requires methods  such as timed automata verification  that support metric constraints and non-determinism.
acknowledgments
we would like to thank michael hofbaur  tony abad and the anonymous reviewers for their invaluable insights. this research is supported in part by the office of naval research under contract n1-1 and by the darpa mobies program under contract f1-c-1.
references
 ahuja et al.  1  r. ahuja  t. magnanti  and j. orlin. network flows: theory  algorithms  and applications. prentice hall  1.
 berry and gonthier  1  g. berry and g. gonthier. the esterel programming language: design  semantics and implementation. science of computer programming  1 :1 - 1  november 1.
 blum and furst  1  a. blum and m. furst. fast planning through planning graph analysis. artificial intelligence  1-1 :1 1.
 cormen et al.  1  t. cormen  c leiserson  and r. rivest. introduction to algorithms. mit press  camb.  ma  1.
 dechter et al.  1  r. dechter  i. meiri  and j. pearl. temporal constraint networks. aij  1-1  1.
 erol et al.  1  k. erol  j. hendler  and d. nau. htn planning: complexity and expressivity. in proceedings of aaai-1  pages 1  1.
 firby  1  r. james firby. the rap language manual. technical report aap-1  univ. chicago  march 1.
 guernic et al.    p. le guernic  m. le borgne  t. gauthier  and c. le maire. programmingreal time applications with signal. pages 1.
 halbwachs et al.    n. halbwachs  p. caspi  and d. pilaud. the synchronous programming language lustre. pages 1.
 halbwachs  1  n. halbwachs. synchronous programming of reactive systems. kluwer academic  1.
 laborie and ghallab  1  p. laborie and m. ghallab. planning with sharable resource constraints. in proceedings of ijcai-1  1.
 muscettola et al.  1a  n. muscettola  p. morris  b. pell  and b. smith. issues in temporal reasoning for autonomous control systems. in autonomous agents  1.
 muscettola et al.  1b  n. muscettola  p. nayak  b. pell  and b. c. williams. the new millennium remote agent: to boldly go where no ai system has gone before. artificial intelligence  1-1 :1  1.
 muscettola  1  n. muscettola. hsts: integrating planning and scheduling. in mark fox and monte zweben  editors  intelligent scheduling. morgan kaufmann  1.
 saraswat et al.  1  v. saraswat  r. jagadeesan  and v. gupta. timed default concurrent constraint programming. j symb comp  1-1 :1  1.
 smith and weld  1  d. smith and d. weld. temporal planning with mutual exclusion reasoning. in proceedings of ijcai-1  1.
 tsamardinos et al.  1  i. tsamardinos  n. muscettola  and p. morris. fast transformation of temporal plans for efficient execution. in proceedings of aaai-1  1.
 weld  1  d. weld. an introduction to least commitment planning. in ai magazine  1.
 weld  1  d. weld. recent advances in ai planning. in ai magazine  1.
 williams et al.  1  b. c. williams  s. chung  and v. gupta. mode estimation of model-based programs: monitoring systems with complex behavior. in proceedings of ijcai-1  1.
dynamic control of plans with temporal uncertaintypaul morris nicola muscettola
nasa ames research center moffett field  ca 1  u.s.a.
{pmorris mus} ptolemy.arc.nasa.gov thierry vidal
lgp/enit
1  av d'azereix - bp 1
f-1 tarbes cedex - france thierry enit.fr

abstract
certain planningsystems that deal with quantitative time constraints have used an underlying simple temporal problem solver to ensure temporal consistency of plans. however  many applications involve processes of uncertain duration whose timing cannot be controlled by the execution agent. these cases require more complex notions of temporal feasibility. in previous work  various  controllability  properties such as weak  strong  and dynamic controllability have been defined. the most interesting and useful controllability property  the dynamic one  has ironically proved to be the most difficult to analyze. in this paper  we resolve the complexity issue for dynamic controllability. unexpectedly  the problem turns out to be tractable. we also show how to efficiently execute networks whose status has been verified.
1	introduction
simple temporal networks  dechter et al.  1  have proved useful in planning and scheduling applications that involve quantitative time constraints  e.g.  laborie and ghallab  1; muscettola et al.  1b   because they allow fast checking of temporal consistency. however this formalism does not adequately address an important aspect of real execution domains: the time of occurrence of some events may not be under the complete control of the execution agent. for example  when a spacecraft commands an instrument or interrogates a sensor  a varying amount of time may intervene before the operation is completed. in cases like this  the execution agent does not have freedom to select the precise time delay between events in accord with the timing of previously executed events. instead  the value is selected by nature independently of the agent's choices. this can lead to constraint violations during execution even if the simple temporal network appeared consistent at plan generation time.
　the problem of constraint satisfaction for temporal networks with uncertainty was first addressed formally in  vidal and ghallab  1; vidal and fargier  1 . in this setting  the question of temporal feasibility goes beyond mere consistency to encompass issues of  controllability.  essentially  a network is controllable if there is a strategy for executing the timepoints under the agent's control that satisfies all requirements  in all situations involving the uncontrolled timepoints. the previous work has identified three primary levels of controllability. in strong controllability  there is a static control strategy that is guaranteed to work in all cases. in weak controllability  for all situations there is a  clairvoyant  strategy that works if all uncertain durations are known when the network is executed. the most interesting controllability property from a practical point of view is dynamic controllability  where it is assumed that each uncertain duration becomes known  is observed  after it has finished  and the property requires a successful strategy that depends only on the past outcomes.
　in previous work  algorithms have been presented for checking strong and weak controllability  and strong controllability has been shown to be tractable  while weak controllability is co-np-complete  vidal and fargier  1; morris and muscettola  1 . however  dynamic controllability has proved difficult to analyze  primarily because of a time asymmetry where a control decision may depend on the past but not on the future. in this paper we present efficient constraint propagation methods for checking dynamic controllability. these explicitly add constraints that are implicit in the dynamic controllability property. with these additional constraints  dynamic controllability checking reduces to a form of consistency checking that turns out to be polynomial. the derived constraints are also used to guide an effective execution strategy.
1	background
we review the definitions of simple temporal network  dechter et al.  1   and simple temporal network with uncertainty  vidal and fargier  1 .
　a simple temporal network  stn  is a graph in which the edges are labelled with upper and lower numerical bounds. the nodes in the graph represent temporal events or timepoints  while the edges correspond to constraints on the durations between the events. formally  an stn may be described as a 1-tuple   n e l u   where n is a set of nodes  e is a set of edges  and l : e ★ ir “{ ±} and u : e ★ ir “{+±} are functions mapping the edges into extended real numbers  that are the lower and upper bounds of the interval of possible durations. each stn is associated with a distance graph  dechter et al.  1  derived from the upper and lower bound constraints. an stn is consistent if and only if the distance graph does not contain a negative cycle  and this can be determined by a single-source shortest path propagationsuch as in the bellman-fordalgorithm  cormen et al.  1 . to avoid confusion with edges in the distance graph  we will refer to edges in the stn as links.
　a simple temporal network with uncertainty  stnu  is similar to an stn except the links are divided into two classes  contingent links and requirement links. contingent links may be thought of as representing causal processes of uncertain duration; their finish timepoints  called contingent timepoints  are controlled by nature  subject to the limits imposed by the bounds on the contingent links. all other timepoints  called executable timepoints  are controlled by the agent  whose goal is to satisfy the bounds on the requirement links. we assume the durations of contingent links vary independently  so a control procedure must consider every combination of such durations.
　thus  an stnu is a 1-tuple   n e l u c    where n e l u are as in a stn  and c is a subset of the edges: the contingent links  the others being requirement links. we assume 1   l e    u e    ± for each contingent link e.1
　an stnu may be regarded as an stn by ignoring the distinction between contingent links and requirement links. this allows us to apply stn terminology and concepts  such as allpairs shortest-path calculations  to stnus.
　in addition  choosing one of the allowed durations for each contingentlink may be thoughtof as reducingthe stnu to an ordinary stn. thus  an stnu determines a family of stns  as in the following definition.
　suppose Γ =   n e l u c   is an stnu. a projection  vidal and ghallab  1  of Γ is a simple temporal network derived from Γ where each requirement link is replaced by an identical stn link  and each contingent link e is replaced by an stn link with equal upper and lower bounds  b b  for some b such that l e  ＋ b ＋ u e .
　given a fixed stnu   n e l u c    a schedule t is a mapping
t : n ★ ir
where t x   written tx here  is called the time of time-point x. a schedule is consistent if it satisfies all the link constraints. from a schedule  we can determine the durations of all contingent links that finish prior to a timepoint x.  this may be viewed as a partial mapping from c to ir.  we call this the prehistory of x with respect to t  denoted by t x. then an execution strategy s is a mapping
s : p ★t
where p is the set of projections and t is the set of schedules. an execution strategy s is viable if s p  is consistent  w.r.t. p  for each projection p.
　we are now ready to define the various types of controllability  essentially following  vidal  1 .
　an stnu is weakly controllable if there is a viable execution strategy. this is equivalentto sayingthat everyprojection is consistent.
  there is no uncertainty and we may as well replace e by a requirement link.
　an stnu is strongly controllable if there is a viable execution strategy s such that
　　　　　　　　 s p1  x =  s p1  x for each executable timepoint x and projections p1 and p1. thus  a strong execution strategy assigns a fixed time to each executable timepoint irrespective of the outcomes of the contingent links.
　an stnu is dynamically controllable if there is a viable execution strategy s such that
      s p1   x =  s p1   x    s p1  x =  s p1  x for each executable timepoint x and projections p1 and p1. thus  a dynamic execution strategy assigns a time to each executable timepoint that may depend on the outcomes of contingent links in the past  but not on those in the future  or present . this corresponds to requiring that only information available from observation may be used in determining the schedule. we will use dynamic strategy in the following for a  viable  dynamic execution strategy.
　networks where two contingent links have the same finishing point are clearly not dynamically controllable. because of this  and for certain technical reasons  following  morris and muscettola  1    we will exclude such networks in the remainder of this paper.
　it is easy to see from the definitions that strong controllability implies dynamic controllability  which in turn implies weak controllability. strong controllabilityis knownto be tractable and weak controllability is known to be co-npcomplete. in this paper  we investigate the status of dynamic controllability. note that a na： ve algorithm for checking this property is hyperexponential since it requires searching for an execution strategy that is both dynamic and viable  while a method described in  vidal  1  requires worst case exponential space.
　the following terminology will be useful in the subsequent discussion. a contingent link is squeezed if the other constraints  including the other contingent links  imply a strictly tighter lower bound or upper bound for the link. an stnu is pseudo-controllable if it is consistent and none of the contingent links are squeezed.
　if a network is pseudo-controllable then all the edges arising from contingent links are shortest paths. thus  the contingent links survive unchanged in the allpairs shortest-path graph  abbreviated as the allpairs graph . note that pseudocontrollability can be determined in polynomial time by computing the allpairs graph.
　it is easy to see that every weakly controllable network is pseudo-controllable since a squeezed contingent link would imply a projection that is not consistent. however  the converse is not true in general.
　even for a stnu that was originally pseudo-controllable  it is possible for a contingent link to be squeezed during execution  which may be viewed as augmenting the network with additional constraints . in this paper  we will make use of results from  morris and muscettola  1 . these guarantee that a contingent link cannot be squeezed during execution under certain circumstances. essentially  upper bounds can only be squeezed by propagations through links with non-negative upper bounds  and lower bounds can only be squeezed by propagations through links with positive lower bounds. even in these cases  squeezing cannot occur if the relevant bound is dominated by that of the contingent link  which essentially means the bound at issue is redundant. if the dominance relations are such that no contingent link can be squeezed  then the network is safe. a safe network can be executed like an ordinary stn  and thus is dynamically
controllable.
1	triangular reductions
a starting point for resolving the issue of dynamic controllability is to consider triangular stnu networks  i.e.  networks involving three timepoints and including a contingent link  as shown in figure 1. here ac is a contingent link with bounds  x y   while ab and bc are requirement links with bounds  p q  and  u v  respectively. this notation for contingent and requirement links will be used in subsequent diagrams. the contingent link ac is called the focus of the triangle. we will also assume that the triangular networks we consider are pseudo-controllable and have been placed in allpairs form  so every edge is a shortest path. it follows that  u v     x  q y   p   which implies  p q     y   v x   u .

figure 1: triangular network
　we will derive a number of results concerning additional tightenings or reductions of the bounds that must be obeyed by any schedule resulting from a dynamic strategy  i.e.  any s p  for any projection p  in the notation of the previous section . these will vary according to cases involving the signs of the  u v  bounds.
1. first suppose that v   1. we call this the follow case  since the lower bound of cb  i.e.  bc reversed  is  v and hence b follows c. then the network is dynamically controllable since c has already been observed at the time b is executed. in fact  it may be executed like an ordinary stn since any propagation will go from c to b and not vice versa. thus  the network is safe and no tightening is needed.
1. next consider the case where u − 1. we call this the precede case  since b occurs before or simultaneously with c. then no information about c is available to b. in this case  we claim that ab can be tightened to  y   v x   u . suppose there is a projection p that a dynamic strategy maps to a schedule t with tb   ta   y   v. since c is not in t b or t a  tb and ta cannot depend on ac. therefore ta and tb are unchanged if the projection is mutated to a projection p1 where ac equals y. but then we have bc = tc tb =  tc ta   tb ta    y  y v  = v  so the bc constraint will be violated. thus  tb ta− y v. a similar argument shows tb   ta ＋ x   u. after the tightening of ab to  y   v x   u   or equivalently ba to  u   x v   y    the bc bounds are dominated  redundant  since  u   x v   y  +  x y  =  u v . thus  the network is safe provided it is still pseudo-controllable.
1. the most interesting case occurs when u   1 and v − 1  which we call the unordered case  since b may or may not follow c. however  suppose b does not follow c and tb ta   y v. as in the previous case  there is then a projection where the bc constraint is violated. we conclude that  for a dynamic strategy  b cannot be executed at any time before y   v after a if c has not already occurred. this is a conditional constraint on ab  depending on the time of occurrence of c. it may also be viewed as a ternary constraint on a b  and c  which we call a wait since b must wait until either c occurs or the wait expires at y   v after a.
　first  there is one subcase for which the conditional constraint turns out to be unconditional which is when y v ＋ x. then c cannot occur before the wait expires  so we can simply raise the lower bound of ab to y   v. we will call this the unconditional unordered reduction.
　in the truly conditional subcase where x   y   v  an obvious idea is to branch on the conditional and consider separately two possibilities. first if it turns out that ac   y   v  in which case c occurs first and b follows   the network is safe if pseudo-controllableas in the follow case. otherwise if
ac − y  v then ab − y  v also  which gives ba an upper bound of v   y. thus  the bc upper bound of v is dominated  redundant . since the lower boundu is negative  the network is safe if pseudo-controllable  morris and muscettola  1 . observe that in either case b occurs later than x after a  so without branching we can raise the lower bound of ab to x. we will call this the general unordered reduction.
　we see above that assuming a dynamic strategy may lead to a tightening of the constraint bounds. if the tightening produces a violation of pseudo-controllability  then the original network was not dynamically controllable. on the other hand  if the network remains pseudo-controllable after the tightening  in the general unordered case we must verify this for both possibilities   then the triangular network is safe and thus dynamically controllable  morris and muscettola  1 . thus  the tightenings give a procedure for determining dynamic controllability of triangular networks.
1	local vs global dynamic controllability
to test a general stnu network for dynamic controllability  we can construct the allpairs graph  which may be regarded as a combination of triangular subnetworks. triangles that involve a contingent link may be viewed as instances of figure 1. if a triangle contains two contingent links 1 then we consider it twice  with each contingent link in turn playing the role of focus  and the other being treated as a requirement link. any tightening propagates to neighbour triangles until quiescence of the network is reached. the only problem arises with unordered cases: if we branch on the conditionals as discussed in the previous section  we end up with a combinatorial search  which we prefer to avoid. instead we use only the two non-branching unordered reductions discussed earlier  so the resultingiterative algorithmis deterministicand polynomial.  but the network is then not necessarily safe. 
　this propagation algorithm with no search may be viewed as a local dynamic controllabilitychecking procedure. since it applies to triangles  this is similar to a path-consistency algorithm in a classical constraint network such as a stn. hence  we call this local property 1-dynamic controllability and call the resulting algorithm 1dc. as with any local filtering algorithm  the process is sound: if it fails  then at least one triangle is not dynamically controllable and therefore the whole network is not.
　however  it is incomplete as shown by the example in figure 1. we invite the reader to verify that the triangles are all quiescent under the deterministic reductions considered above; therefore the network is stable under 1dc.

figure 1: quiescent non-dc network
　now consider the subnetwork acdb. it is not difficult to see that a dynamic strategy requires ad = 1. similarly  de must be 1. but that causes a violation of the ae link. hence the network is not dynamically controllable.1 this example also shows that 1dc does not compute the minimal network  i.e.  the network in which values not belonging to any dynamic strategy have been removed  for instance here ad would be tightened to  1  . a checking algorithm should ideally produce this minimality property  which is desirable for execution purposes. nevertheless  1dc is an efficient technique to rule out a wide variety of networks.
1	regression of waits
the incompleteness of 1dc might suggest we should reconsider a combinatorial search. however  we have not exhausted the possibilities of obtaining deterministic reductions from the unordered cases. if the ternary constraint corresponding to the unordered wait is used directly  then no branching is necessary. moreover  this ternary constraint can be treated somewhat like a binary constraint. suppose we have a wait condition that requires b to wait for c until time t after a. we will indicate that by placing a  c t  annotation on the ab link. note that if it is impossible for c to occur before t  for example if the lower bound of ac is greater than t   then the  c t  wait becomes a true lower bound of t on ab. this corresponds to the unconditional unordered reduction discussed earlier.
　now consider figure 1 again. the triangle abc is an unordered case  so ab receives a  c 1  wait. this is not unconditional since the lower bound of ac is 1. now consider triangle adb with this new label on ab. suppose c has not occurred yet and d is executed before 1 time unit after a. in the projection where db equals 1  b will then occur before 1 time units after a. if c still has not occurred by then  the wait on ab will be violated. in other words  the wait on ab can be regressed through db to obtain a derived wait on ad  still relative to c:  c 1  . this  happily  is an unconditional wait since c cannot occur before time 1  which produces a lower bound of 1 on ad and leads to a resolution of the example. one can notice as well that we achieve the hoped-for minimal network. that leads us to the following result.
lemma 1  regression  suppose a link ab has a wait  c t    where t is less than or equal to the upper bound of ac. then  in a schedule resulting from a dynamic strategy :
　 i  if there is any link db  including ab itself  with upperbound w  then we can deduce a wait  c t   w  on ad.
　 ii  if t − 1 and if there is a contingent link db with lower bound z  where b 1= c  then we can deduce a wait  c t   z  on ad.
proof: consider  i  first. suppose d occurs before t   w after a and c has not occurred yet. from the upper bound w on db  it follows that b must occur before w+t w = t. but this violates the wait on ab in the projection where c occurs at its upper bound  which is − t . we conclude that d cannot occur before t   w after a unless c has already occurred.
　now consider  ii . if t − 1  then b must be later than a. suppose d occurs before t z after a and c has not occurred yet. then neither a nor d can depend on the outcomes of ac or db. thus  we can consider a mutated projection where db finishes at z and ac finishes at its upper bound. this leads to a violation of the ab wait. 1
　note that  i  and  ii  are both applicable to contingent links but  ii  gives a more restrictive  longer  wait.

figure 1: regression example
　iterated regression amounts to a new type of propagation  where waits are spread to other links. the propagated waits can be examined for any unordered reductions  which place additional ordinary constraints throughout the network. for example  consider figure 1. intuitively  we can see this is not dynamically controllable because the waits in the worst case will cause an incursion on the ac lower bound  assuming the upper bounds of the ap dq br contingent links are all at least 1 . first we can regress the  r 1  wait through
procedure dynamicallycontrollable   network w 
1. compute the all-pairs graph for w.
if w is not pseudo-controllable then return false.
1. select any triangle such that v is non-negative.introduce any tightenings required by the precede case and any waits required by the unordered case.
1. do all possible regressions of waits  while convertingunconditional waits to lower bounds. also introduce lower bounds as provided by the general reduction.
1. if steps 1 and 1 do not produce any new  or tighter  constraints  then return true  otherwise go to 1.
figure 1: dc checking algorithm
ac  which gives a wait of  r  1  on ba. this gives rise to  unconditional case  a lower bound of  1 on ba  which is equivalent to an upper bound of +1 on ab. now we can regress the  q 1  wait on db through ab  which gives a  q  1  on da  giving rise to a +1 upper bound on ad. finally  we regress the  p 1  wait on ad through ad itself  which gives a  p 1  wait on aa. now the general reduction ensures a positive lower bound on aa  which is a direct inconsistency. thus  we have reduced the lack of dynamic controllability to a violation of consistency.
1	dynamic checking and execution
we are now ready to introduce the algorithm for determining dynamic controllability  summarized in figure 1. it is just an enhancement of 1dc with wait regressions and hence is still a local algorithm  but now we can show it is complete.
　we prove completeness by presenting a dynamic execution algorithm and showing that it is viable if the dc checking algorithm reports success. for simplicity  we will assume the execution takes place in the allpairs graph of the tightened network  although performance could be improved by transformingit to a minimum dispatchable graph as in  muscettola et al.  1a . the execution is essentially the same as for an ordinary stn except for adding a requirement to respect the waits. for this purpose  we only consider waits  c t  where t satisfies l c    t ＋ u c . note that waits with t ＋ l c  are converted to lower bounds  while waits with t   u c  are equivalent to those with t = u c .  since l c    1 by definition  the waits enforced by the algorithm are all positive. 
　the execution algorithm is shown in figure 1. we assume there is some start timepoint that is constrained to be before every other timepoint.  if necessary  one can be added.  in step 1  a timepoint is live if the current time is within the timepoint's bounds. it is enabled if all timepoints required to be executed before it  by links with positive lower bounds  have already been executed  muscettola et al.  1a .
　it is clear that this algorithm provides a strategy where the decisions depend only on the past. the issue is whether any constraints are violated. properties of stns guarantee that they can be executed incrementally  muscettola et al.  1a . therefore  only the special features introduced for stnus need be considered. the following are the possible ways in which the execution might fail.
  a deadlock might occur where a wait lasts forever.
  a wait might be forcibly aborted.
procedure execute  network w 
1. perform initial propagation from the start timepoint.
1. immediately execute any executable timepointsthat have reached their upper bounds.
1. arbitrarily pick an executable timepoint tp thatis live and enabled and not yet executed  and whose waits  if any  have all been satisfied.
1. execute tp. halt if network execution is complete.otherwise  propagate the effect of the execution.
1. advance current time  propagating the effect of anycontingent timepoints that occur  until an executable timepoint becomes eligible for execution under 1 or 1.
1. go to 1.
figure 1: dc network execution
  a propagation might squeeze a contingent link.
an example of a potential deadlock is when ac and db are contingent links with a  c t1  wait on ad and a  b t1  wait on da. more generally  a deadlock requires a cycle of links  each of which is labelled with a wait or a positive lower bound. however  the waits  c t  enforced by the execution algorithm satisfy l c    t ＋ u c   see above . these imply a positive lower bound of l c  by the general reduction. thus  we would have a cycle where each link has a positive lower bound. this corresponds to an inconsistency in the network that would be detected by step 1 of the dc checking algorithm. the other possibilities are considered in the following lemmas.
lemma 1 suppose a network has successfully passed the dc checking algorithm. then the first failure that occurs during the dc execution cannot be an aborted wait.
proof: suppose the first failure is an aborted wait  and the earliest time this occurs involves a wait  c t  on a link ab. as pointed out above  this wait must be positive  so the link ab will have a positive lower bound. first we note that b obviously cannot be the start timepoint.
　there are now two cases to consider. in the first case  the wait is aborted because step 1 required an immediate execution of b. consider the timepoint d  possibly the start  whose execution initiated the propagation that produced the upper bound of b. note the regression of  c t  through db produces a wait of  c t   u db   on ad. if t   u db  ＋ l ac   the checking algorithm places it as an unconditional lower bound on ad. otherwise   c t u db   is an earlier wait that is enforced by the execution algorithm. in either case  d does not occur until t u db  after a. suppose b and d are the upper bounds of b and d  respectively  and a is the time of execution of a. then  d   a  −  t   u db  . since b = d + u db   it follows that  b   a  − t. this contradicts the assumption that the wait was terminated.
　the second case involves the possibility that b is a contingent timepoint.  thus  the execution is not controlled by the agent . suppose eb is a contingent link with bounds  x y . again we can regress the wait througheb getting  c t x  on ae. since e is earlier than b  the latter wait must be satisfied. thus  the duration of ae is greater than t   x. since x is the minimum duration of eb  it follows that ab is greater than t   x + x = t  i.e.  the wait is satisfied after all. 1 lemma 1 suppose a network has successfully passed the dc checking algorithm. then the first failure that occurs during dc execution cannot be a squeezing of a contingent link.
proof: suppose the earliest failure is the squeezing of a contingent link ac that has bounds  x y . this must occur during a propagation that either raises the lower bound of ac or lowers the upper bound. however  the triangular reductions ensure that ac dominates adjacent links with finishing point c  except for the case of links bc with negative lower bound u and non-negativeupper-bound v such that y v   x  the conditional unordered case . this means the only possibility for a squeezing is an upper-bound propagation along some such bc. however  the existence of such a bc would cause the checking algorithm to place a  c y v  wait on ab. if c occurs before b then there is no propagation from b to c. otherwise  the enforcement of the wait by the execution algorithm ensures that b is not executed before y   v after a. thus  the upper bound propagated along bc will be tb +v −  ta+y v +v = ta+y  so ac is not squeezed. 1
theorem 1 dynamic controllability can be determined in deterministic polynomial time.
proof: lemmas 1 and 1 demonstrate that the execution algorithm successfully executes networks that are verified by the checking algorithm. thus  the dynamic controllability checking algorithm is complete. as noted earlier  the algorithm is also sound since the added constraints were derived from the assumption of dynamic controllability.
　the individual tighteningsare clearly polynomial and convergenceis assured because the domainsof the constraintsare strictly reducedby the tightenings. the only issue is how long the convergence takes. a crude upper bound can be obtained by assuming a fixed level of precisionδ and finite bounds  say between ＼β  on all links. if there are η links  then after at most 1ηβ/δ reductions  some domain would become empty. this bound grows polynomially with the size of the problem.
1
　it is worth pointing out that the execution algorithm presented here preserves maximum flexibility  since the additional tightenings and waits were all required by dynamic controllability.  in contrast to the approach  for example  of adding waypoints  morris and muscettola  1   which surrenders some flexibility.  another interesting point is that the execution algorithm allows the selection of any execution time within prescribed limits  without impairing the success of the dynamic strategy. therefore the incremental application of the dc propagation ensures that the values remaining in the domains are consistent with the dynamic strategy. in other words  the dc checking algorithm produces the minimal network in the sense described earlier.
1	conclusions
dynamic controllability is polynomial! that is certainly the main contribution of this paper  since this property  needed in many real-world applications such as planning and scheduling  was expected to be much harder.
　moreover  the proposed method is directly applicable to the stnu  as opposed to a previous technique that needed a translation into a finite-state automaton model  vidal  1    and is inspired by classical constraint satisfaction techniques. we have presented a local dynamic controllability algorithm based on triangle reductions  and have shown that non-binary constraints that were inherent in the problem give rise to binary constraints through a regression process. we have also proven this local controllability algorithm is complete with respect to dynamic controllability of the global network.
　we believe our contribution will be valuable in the design of new constraint programming packages that handle temporal uncertainty and will help pave the way to effective realtime execution systems that incorporate such uncertainties.
references
 cormen et al.  1  t.h. cormen  c.e. leiserson  and r.l. rivest. introduction to algorithms. mit press  cambridge  ma  1.
 dechter et al.  1  r. dechter  i. meiri  and j. pearl. temporal constraint networks. artificial intelligence  1- 1  may 1.
 laborie and ghallab  1  p. laborie and m. ghallab. planning with sharable constraints. in proceedings of the 1th international joint conference on a.i.  ijcai-1   montreal  canada   1.
 morris and muscettola  1  p. morris and n. muscettola. managing temporal uncertainty through waypoint controllability. in proc. of sixteenth int. joint conf. on artificial intelligence  ijcai-1   1.
 morris and muscettola  1  p. morris and n. muscettola. execution of temporal plans with uncertainty. in proc. of seventeenth nat. conf. on artificial intelligence  aaai1   1.
 muscettola et al.  1a  n. muscettola  p. morris  and i. tsamardinos. reformulating temporal plans for efficient execution. in proc. of sixth int. conf. on principles of knowledge representation and reasoning  kr'1   1.
 muscettola et al.  1b  n. muscettola  p.p. nayak  b. pell  and b.c. williams. remote agent: to boldly go where no ai system has gone before. artificial
intelligence  1-1 :1  august 1.
 vidal and fargier  1  t. vidal and h. fargier. handling contingency in temporal constraint networks: from consistency to controllabilities. journal of experimental & theoretical artificial intelligence  1-1  1.
 vidal and ghallab  1  t. vidal and m. ghallab. dealing with uncertain durations in temporal constraint networks dedicated to planning. in proc. of 1th european conference on artificial intelligence  ecai-1   pages 1  1.
 vidal  1  t. vidal. controllability characterization and checking in contingent temporal constraint networks. in proc. of seventh int. conf. on principles of knowledge representation and reasoning  kr'1   1.

planning
complexity of planning

complexity of probabilistic planning under average rewards
jussi rintanen
albert-ludwigs-universita：t freiburg  institut f：ur informatik
georges-ko：hler-allee  1 freiburg im breisgau
germany

abstract
a general and expressive model of sequential decision making under uncertainty is provided by the markov decision processes  mdps  framework. complex applications with very large state spaces are best modelled implicitly  instead of explicitly by enumerating the state space   for example as precondition-effect operators  the representation used in ai planning. this kind of representations are very powerful  and they make the construction of policies/plans computationally very complex. in many applications  average rewards over unit time is the relevant rationality criterion  as opposed to the more widely used discounted reward criterion  and for providing a solid basis for the development of efficient planning algorithms  the computational complexity of the decision problems related to average rewards has to be analyzed. we investigate the complexity of the policy/plan existence problem for mdps under the average reward criterion  with mdps represented in terms of conditional probabilistic precondition-effect operators. we consider policies with and without memory  and with different degrees of sensing/observability. the unrestricted policy existence problem for the partially observable cases was earlier known to be undecidable. the results place the remaining computational problems to the complexity classes exp and nexp  deterministic and nondeterministic exponential time. 
1	introduction
markov decision processes  mdps  formalize decision making in controlling a nondeterministic transition system so that given utility criteria are satisfied. an mdp consists of a set of states  a set of actions  transition probabilities between the states for every action  and rewards/costs associated with the states and actions. a policy determines for every state which action is to be taken. policies are valued according to the rewards obtained or costs incurred.
　applications for the kind of planning problems addressed by this work include agent-based systems  including internet agents and autonomous robots  that have to repeatedly perform actions over an extended period of time in the presence of uncertainty about the environment  and the actions have to - in order to produce the desired results - follow a high-level strategy  expressed as a plan.
　classical deterministic ai planning is the problem of finding a path between the initial state and a goal state. for explicit representations of state spaces as graphs this problem is solvable in polynomial time  and for implicit representations of state spaces in terms of state variables and precondition-effect operators  which sometimes allows an exponentially more concise representation of the problem instances  the path existence problem is pspace-complete  bylander  1 . this result is closely related to the pspace-completeness of the existence of paths in graphs represented as circuits  papadimitriou and yannakakis  1; lozano and balca＞zar  1 . similarly  the complexity of most other graph problems increases when a compact graph representation is used  galperin and widgerson  1; papadimitriou and yannakakis  1; lozano and balca＞zar  1; balca＞zar  1; feigenbaum et al.  1 .
　mdps and pomdps can be viewed as an extension of the graph-based deterministic planning framework with probabilities: an action determines a successor state only with a certain probability. the objective is to visit valuable states with a high probability. a policy  a plan  determines which actions are chosen given the current state  or a set of possible current states  possibly together with some information on the possible predecessor states.  for explicitly represented mdps  policy evaluation under average rewards reduces to the solution of sets of linear equations. sets of linear equations can be solved in polynomial time. similarly  policies for many types of explicitly represented mdps can be constructed in polynomial time by linear programming. papadimitriou and tsitsiklis  have shown that policy existence for explicitly represented mdps is p-complete. madani et al.  have shown the undecidability of policy existence for umdps and pomdps with all main rationality criteria.
　like in classical ai planning  mdps/pomdps can be concisely represented in terms of state variables and precondition-effect operators. the important question in this setting is  what is the impact of concise representations on the complexity of these problems. in related work  mundhenk et al.  1; littman  1; littman et al.  1   this question has been investigated in the context of finite horizons. not surprisingly  there is in general an exponential increase in problem complexity  for example from deterministic polynomial time to deterministic exponential time. the undecidability results for explicitly represented umdps and pomdps directly implies the undecidability of the respective decision problems with concise representations.
　in the present work we investigate the complexity of the policy existence problems for mdps and pomdps under expected average rewards over an infinite horizon. for many practically interesting problems from ai - for example autonomous robots  internet agents  and so on - the number of actions taken is high over a period time and lengths of sequences of actions are unbounded. therefore there is typically no reasonable interpretation for discounts nor reasonable upper bounds on the horizon length  and average reward is the most relevant criterion. a main reason for the restriction to bounded horizons and discounted rewards in earlier work is that the structure of the algorithms in these cases is considerably simpler  because considerations on mdp structural properties  like recurrence and periodicity  can be avoided. also  for many applications of mdps that represent phenomena over extended periods of times  years and decades   for example in economics  the discounts simply represent the unimportance of events in the distant future  for example transcending the lifetimes of the decision makers. boutilier and puterman  have advocated the use of average-reward criteria in ai.
　the structure of the paper is as follows. section 1 describes the planning problems addressed by the paper  and section 1 introduces the required complexity-theoretic concepts. in section 1 we present the results on the complexity of testing the existence of policies for mdps under average reward criteria  and section 1 concludes the paper.
1	probabilistic planning with average rewards
the computational problem we consider is the existence of policies for mdps  fully observable   umdps  unobservable  and pomdps  partially observable  generalizing both mdps and umdps  that are represented concisely; that is  states are represented as valuations on state variables and transition probabilities are given as operators that affect the state variables. the policies we consider may have an arbitrary size  but we also briefly discuss complexity reduction obtained by restricting to polynomial size policies.
　as pointed out in example 1  the average reward of a policy sometimes cannot unambiguously be stated as a single real number. the computational problem that we consider is the following. is the expected average reward greater than  or equal to  some constant . this amounts to identifying the recurrent classes determined by the policy  and then taking a weighted average of the rewards according to the probabilities with which the classes are reached.
1	definition of mdps
mdps can be represented explicitly as a set of states and a transition relation that assigns a probability to transitions be-

figure 1: a multichain mdp
tween states under all actions. we restrict to finite mdps and formally define them as follows.
definition 1 a  partially observable  markov decision pro-
cess is a tuple	where	is a set of states 
is a set of actions  gives the transition probability between states  the transition probabilities from a given state must sum to 1  for every action  is the initial state  associates a reward for applying an action in a given state  and is a partition of to classes of states that cannot be distinguished.
policies map the current and past observations to actions.
definition 1 a policy is a mapping from a sequence of observations to an action. a stationary policy is a mapping from the current observation to an action.
　for umdps the observation is always the same      for mdps the observations are singleton sets of states  they determine the current state uniquely   and for pomdps the observations are members of a partition of to sets of states that are indistinguishable from each other  the limiting cases are
and singletons for : pomdps are a generalization of both umdps and mdps. 
the expected average reward of a policy is the limit

where is the reward of taking action in state and is the probability of taking action at time point in state . there are policies for which the limit does not exist  puterman  1  example 1.1   but when the policy execution has only a finite number of internal states  like stationary policies have   the limit always exists.
　the recurrent classes of a pomdp under a given policy are sets of states that will always stay reachable from each other with probability 1.
example 1 consider a policy that induces the structure shown in figure 1 on a pomdp. the three recurrent classes each consist of two states. the initial state does not belong to any of the recurrent classes. the state reached by the first transition determines the average reward  which will be 1  1 or 1  depending on the recurrent class.
1	concise representation of mdps
an exponentially more concise representation of mdps is based on state variables. each state is an assignment of truthvalues to the state variables  and transitions between states are expressed as changes in the values of the state variables.
　in ai planning  problems are represented by so-called strips operators that are pairs of sets of literals  the precondition and the effects. for probabilistic planning  this can be extended to probabilistic strips operators  psos   see  boutilier et al.  1  for references and a discussion of psos and other concise representations of transition systems with probabilities.  in this paper  we further extend psos to what we call extended psos  epsos . an epso can represent an exponential number of psos  and we use them because they are closely related to operators with conditional effects commonly used in ai planning. apart from generating the state space of a pomdp  the operators can conveniently be taken to be the actions of the pomdp.
definition 1  extended probabilistic strips operators  an extended probabilistic strips operator is a pair   where is a boolean circuit and consists of pairs   where is a boolean circuit and is a set of pairs   where is a real number and is a set of literals such that for every the sum of the probabilities is 1.
　for all and   if contradicts for some and   then must contradict .
　this definition generalizes psos by not requiring that the s of members of are logically disjoint and their disjunction is a tautology. hence in epsos the effects may take place independently of each other. some of the hardness proofs given later would be more complicated - assuming that they are possible - if we had to restrict to psos. the application of an epso is defined iff the precondition is true in the current state. then the following takes place for every . if is true  one of the is chosen  each with probability   and literals are changed to true.
example 1 let
now is an epso but not a pso because the antecedents are not logically disjoint. a set of psos corresponding to has cardinality exponential on .
　rewards are associated with actions and states. when an action is taken in an appropriate state  a reward is obtained. for every action  the set of states that yields a given reward is represented by a boolean circuit.
definition 1  concise pomdp  a concise pomdp over a set of state variables is a tuple where is an initial state  assignment    is a set of epsos representing the actions  and associates a boolean circuit and a real-valued reward with every action  and is the set of observable state variables.
　having a set of variables observable - instead of arbitrary circuits/formulae - is not a restriction. assume that the values of a circuit are observable  but the individual input gates are not.  we could make every epso evaluate the value of this circuit and set the value of an observable variable accordingly.
definition 1  concise mdp  a concise mdp is a concise
pomdp with	.
definition 1  concise umdp  a concise umdp is a concise pomdp with .
1	concise representation of policies
we consider history/time-dependent and stationary policies  and do not make a distinction between history and timedependent ones. traditionally explicit  or flat  representations of policies have been considered in research on mdps/pomdps: each state or belief state is explicitly associated with an action. in our setting  in which the number of states can be very high  also policies have to be represented concisely. like with concise representations of pomdps  there is no direct connection between the size of a concisely represented policy and the number of states of the pomdp.
　a concise policy could  in the most general case  be a program in a turing-equivalent programming language. this would  however  make many questions concerning policies undecidable. therefore less powerful representations of policies have to be used. a concise policy determines the current action based on the current observation and the past history. we divide this to two subtasks: keeping track of the history  maintaining the internal state of the execution of the policy   and mapping the current observation and the internal state of the execution of the policy to an action. the computation needed in applying one operator is essentially a state transition of a concisely represented finite automaton.
　a sensible restriction would be that computation of the action to be taken and the new internal state of the policy execution is polynomial time. an obvious choice is the use of boolean circuits  because the circuit value problem is pcomplete  one of the hardest problems in p.  work on algorithms for concise pomdps and ai planning have not used this general a policy representation  but for our purposes this seems like a well-founded choice. related definitions of policies as finite-state controllers have been proposed earlier  hansen  1; meuleau et al.  1; lusena et al.  1 .
definition 1  concise policy  a concise policy for a concise
pomdp	is a tuple	where	is a
boolean circuit with input gates and output gates  is a boolean circuit with input gates and output gates  and is a mapping from to .
stationaryhistory-dependentumdppspace-hard  in exp  l1 undecidablemdpexp  t1 exp  c1 pomdpnexp  t1 undecidable　the rest of the paper formally states the results summarized in table 1 and gives their proof outlines.
lemma 1 existence of a policy with average reward　the circuit encodes the change in execution state in terms of the preceding state and the observable state variables table 1: complexity of policy existence  with references to the lemmata  theorems  and corollaries.
　. the circuit encodes the action to be taken  and gives the initial state of the execution. the integer is the number of bits for the representation of the internal state of the execution. when we have a stationary policy.
　the complexity results do not deeply rely on the exact formal definition of policies. an important property of the definition is that one step of policy execution can be performed in polynomial time.
1	complexity classes
the complexity class p consists of decision problems that are solvable in polynomial time by a deterministic turing machine. np is the class of decision problems that are solvable in polynomial time by a nondeterministic turing machine.
　　denotes the class of problems that is defined like the class except that turing machines with an oracle for a problem in are used instead of ordinary turing machines. turing machines with an oracle for a problem may perform tests for membership in for free. a problem is c-hard if all problems in the class c are polynomial time many-one reducible to it; that is  for all problems there is a function computable in polynomial time on the size of its input and if and only if . a problem is
c-complete if it belongs to the class c and is c-hard.
　pspace is the class of decision problems solvable in deterministic polynomial space. exp is the class of decision problems solvable in deterministic exponential time   where is a polynomial.  nexp is the class of decision problems solvable in nondeterministic exponential time. a more detailed description of the complexity classes can be found in standard textbooks on complexity theory  for example by balcaza＞r et al. .
1	complexity results
table 1 summarizes the complexity of determining the existence of stationary and history-dependent policies for umdps  mdps and pomdps. in the average rewards case the existence of history-dependent and stationary policies for mdps coincide. the undecidability of umdp and pomdp policy existence with history-dependent policies of unrestricted size was shown by madani et al. . the result is based on the emptiness problem of probabilistic finite automata  paz  1; condon and lipton  1  that is closely related to the unobservable plan existence problem.
　the results do not completely determine the complexity of the umdp stationary policy existence problem  but as the stationary umdp policies repeatedly apply one single operator  the problem does not seem to have the power of exp. it is also not trivial to show membership in pspace.
　for umdps  mdps and pomdps with only one action is pspace-hard.
proof: it is straightforward to reduce any decision problem in pspace to the problem. this is by constructing a concise umdp/mdp/pomdp with only one action that simulates a polynomial-space deterministic turing machine for the problem in question.
　there are state variables for representing the input  the working tape  and the state of the turing machine. the epso that represents the only action is constructed to follow the state transitions of the turing machine. the size of the epso is polynomial on the size of the input. when the machine accepts  it is restarted. a reward is obtained as long as the machine has not rejected. if the machine rejects  all future rewards will be 1. therefore  if the turing machine accepts the average reward is   and otherwise it is 1.
　there are two straightforward complexity upper bounds respectively for polynomial size and stationary policies. polynomial size policies can maintain at most an exponential number of different representations of the past history  and hence an explicit representation of the product of the pomdp and the possible histories has only exponential size  just like the pomdp state space alone. stationary policies  on the other hand  do not maintain a history at all  and they therefore encode at most an exponential number of different decision situations  one for each  observable  state of a  po mdp. for the unrestricted size partially observable non-stationary case there is no similar exponential upper bound  and the problem is not decidable.
lemma 1 let be a real number. testing the existence of a poly-size mdp/umdp/pomdp policy with average reward is in exp.
proof: this computation has complexity npexp exp  that corresponds to guessing a polynomial size policy  np  followed by the evaluation of the policy by an exp oracle. policy evaluation proceeds as follows. produce the explicit representation of the product of the pomdp and the state space of the policy. they respectively have sizes and
for some polynomials and . the product  which is a markov chain and represents the states the pomdp and the policy execution can be in  is of exponential size .
　from the explicit representation of the state space one can identify the recurrent classes in polynomial time  for example by tarjan's algorithm for strongly connected components. the probabilities of reaching the recurrent classes can be computed in polynomial time on the size of the explicit representation of the state space. the steady state probabilities associated with the states in the recurrent classes can be determined in polynomial time by solving a set of linear equations  nelson  1 . the average rewards can be obtained in polynomial time by summing the products of the probability and reward associated with each state. hence all the computation is polynomial time on the explicit representation of the problem  and therefore exponential time on the size of the concise pomdp representation  and the problem is in exp.
lemma 1 let be a real number. testing the existence of a stationary mdp/umdp/pomdp policy with average reward is in nexp. the policy evaluation problem in this case
is in exp.
proof: first a stationary policy  potentially of exponential size as every state may be assigned a different action  is guessed  which is nexp computation.
　the rest of the proof is like in lemma 1: the number of states that have to be considered is exponential  and evaluating the value of the policy is exp computation. hence the whole computation is in nexp.
theorem 1 let	be a real number. testing the existence of an arbitrary stationary policy with average reward	for a mdp is exp-complete.
proof: exp-hardness is by reduction from testing the existence of winning strategies of the perfect-information  fully observable  game  stockmeyer and chandra  1 . this game was used by littman  for showing that finitehorizon planning with sequential effect trees is exp-hard.
     is a game in which two players take turns in changing the truth-values of variables occurring in a dnf formula. each player can change his own variables only. who first makes the formula true has won. for variables the game is formalized by epsos  each of which reverses the truthvalue of one variable  if it is the turn of player 1  or reverses the truth-value of a randomly chosen variable  if it is the turn of player 1.  reward 1 is normally obtained  but if the dnf formula evaluates to true after player 1 has made his move  all subsequent rewards will be 1. this will eventually take place if the policy does not represent a winning strategy for player 1  and the average reward will hence be 1. therefore  the existence of a winning strategy for player 1 coincides with the existence of a policy with average reward 1.
　exp membership is by producing the explicit exponential size representation of the mdp  and then using standard solution techniques based on linear programming  puterman  1 . linear programming is polynomial time.
corollary 1 let be a real number. testing the existence of an arbitrary history-dependent policy with average reward for a mdp is exp-complete.
proof: for fully observable mdps and policies of unrestricted size  the existence of arbitrary policies with a certain value coincides with the existence of stationary policies with the same value.
theorem 1 let	be a real number. testing the existence of an arbitrary stationary policy with average reward	for a pomdp is nexp-complete.
proof: membership in nexp is by lemma 1. for nexphardness we reduce the nexp-complete succinct 1sat  papadimitriou and yannakakis  1  to concise pomdps. the reduction is similar to the reduction from the np-complete 1sat in  mundhenk et al.  1  theorem 1 . their theorem 1 claims a reduction of succinct 1sat to stationary policies of pomdps represented as circuits.
　the reduction works as follows. the pomdp randomly chooses one of the clauses and makes the proposition of its first literal observable  the state variables representing the proposition together with two auxiliary variables are the only observable state variables . the stationary policy observes the proposition and assigns it a truth-value. if the literal became true  evaluation proceeds with another clause  and otherwise with the next literal in the clause. because the policy is stationary  the same truth-value will be selected for the variable irrespective of the polarity of the literal and the clause. if none of the literals in the clause is true  the reward which had been 1 so far will on all subsequent time points be 1.
　the succinct 1sat problem is represented as circuits that map a clause number and a literal location  1  1  1  to the literal occurring in the clause in the given position. the pomdp uses the following epsos the application order of which has been forced to the given order by means of auxiliary state variables. the first epso selects a clause by assigning truth-values to state variables representing the clause number. the second epso copies the number of the proposition in the current literal  first  second or third literal of the clause  to observable variables  the third and fourth epso respectively select the truth-value true and false  this is the only place where the policy has a choice.  the fifth epso checks whether the truth-value matches  and if it does not and the literal was the last one  the reward is turned to 1. if it does  the execution continues from the first epso  and otherwise  the literal was not the last one and execution continues from the second epso and the next literal.
1	conclusions
we have analyzed the complexity of probabilistic planning with average rewards  and placed the most important decidable decision problems in the complexity classes exp and nexp. earlier it had been shown that without full observability the most general policy existence problems are not decidable. these results are not very surprising because the problems generalize computational problems that were already known to be very complex  pspace-hard   like plan existence in classical deterministic ai planning. also  these problems are closely related to several finite-horizon problems that were earlier shown exp-complete and nexp-complete  mundhenk et al.  1 . the results are helpful in devising algorithms for average-reward planning as well as in identifying further restrictions that allow more efficient planning. as shown by lemma 1  polynomial policy size brings the complexity down to exp  also in the otherwise undecidable cases. there are likely to be useful structural restrictions on pomdps that could bring down the complexity further. restricted but useful problems in pspace would be of high interest.
references
 balca＞zar et al.  1  j. l. balca＞zar  i. d＞az  and j. gabarr＞o. structural complexity i. springer-verlag  berlin  1.
 balca＞zar  1  jose＞ l. balc＞azar. the complexity of searching implicit graphs. artificial intelligence  1 :1  1.
 boutilier and puterman  1  craig boutilier and martin l. puterman. process-oriented planning and averagereward optimality. in c. s. mellish  editor  proceedings of the 1th international joint conference on artificial intelligence  pages 1. morgan kaufmann publishers  1.
 boutilier et al.  1  craig boutilier  thomas dean  and steve hanks. planning under uncertainty: structural assumptions and computational leverage. journal of artificial intelligence research  1-1  1.
 bylander  1  tom bylander. the computational complexity of propositional strips planning. artificial intelligence  1-1 :1  1.
 condon and lipton  1  anne condon and richard j. lipton. on the complexity of space bounded interactive proofs  extended abstract . in 1th annual symposium on foundations of computer science  pages 1  1.
 feigenbaum et al.  1  joan feigenbaum  sampath kannan  moshe y. vardi  and mahesh viswanathan. complexity of problems on graphs represented as obdds. chicago journal of theoretical computer science  1   1.
 galperin and widgerson  1  hana galperin and avi widgerson. succinct representations of graphs. information and control  1-1  1. see  lozano  1  for a correction.
 hansen  1  eric a. hansen. solving pomdps by searching in policy space. in gregory f. cooper and seraf＞n moral  editors  proceedings of the 1 conference on uncertainty in artificial intelligence  uai-1   pages 1. morgan kaufmann publishers  1.
 littman et al.  1  m. l. littman  j. goldsmith  and m. mundhenk. the computational complexity of probabilistic planning. journal of artificial intelligence research  1-1  1.
 littman  1  michael l. littman. probabilistic propositional planning: representations and complexity. in proceedings of the 1th national conference on artificial intelligence  aaai-1  and 1th innovative applications of artificial intelligence conference  iaai-1   pages 1- 1  menlo park  july 1. aaai press.
 lozano and balca＞zar  1  antonio lozano and jose＞ l. balca＞zar. the complexity of graph problems for succinctly represented graphs. in manfred nagl  editor  graphtheoretic concepts in computer science  1th international workshop  wg'1  number 1 in lecture notes in computer science  pages 1  castle rolduc  the netherlands  1. springer-verlag.
 lozano  1  antonio lozano. np-hardness of succinct representations of graphs. bulletin of the european association for theoretical computer science  1-1  june 1.
 lusena et al.  1  christopher lusena  tong li  shelia sittinger  chris wells  and judy goldsmith. my brain is full: when more memory helps. in kathryn b. laskey and henri prade  editors  uncertainty in artificial intelligence  proceedings of the fifteenth conference  uai-1   pages 1. morgan kaufmann publishers  1.
 madani et al.  1  omid madani  steve hanks  and anne condon. on the decidability of probabilistic planning and infinite-horizon partially observable markov decision problems. in proceedings of the sixteenth national conference on artificial intelligence  aaai-1  and the eleventh conference on innovative applications of artificial intelligence  iaai-1   pages 1. aaai press  1.
 meuleau et al.  1  nicolas meuleau  kee-eung kim  leslie pack kaelbling  and anthony r. cassandra. solving pomdps by searching the space of finite policies. in kathryn b. laskey and henri prade  editors  uncertainty in artificial intelligence  proceedings of the fifteenth conference  uai-1   pages 1. morgan kaufmann publishers  1.
 mundhenk et al.  1  martin mundhenk  judy goldsmith  christopher lusena  and eric allender. complexity of finite-horizon markov decision process problems. journal of the acm  1 :1  july 1.
 nelson  1  randolph nelson. probability  stochastic processes  and queueing theory: the mathematics of computer performance modeling. springer-verlag  1.
 papadimitriou and tsitsiklis  1  christos h. papadimitriou and john n. tsitsiklis. the complexity of markov decision processes. mathematics of operations research  1 :1  august 1.
 papadimitriou and yannakakis  1  christos h. papadimitriou and mihalis yannakakis. a note on succinct representations of graphs. information and control  1- 1  1.
 paz  1  azaria paz. introduction to probabilistic automata. academic press  1.
 puterman  1  m. l. puterman. markov decision processes: discrete stochastic dynamic programming. john wiley & sons  1.
 stockmeyer and chandra  1  larry j. stockmeyer and ashok k. chandra. provably difficult combinatorial games. siam journal on computing  1 :1  1.
computational complexity of planning with temporal goals
chitta baral
cs&e  arizona state university
tempe  az 1  usa chitta asu.eduvladik kreinovich
university of texas at el paso
el paso  tx 1  usa vladik cs.utep.eduraul＞ a. trejo
itesm campus edo. me＞xico
atizapan  me＞xico 1 rtrejo campus.cem.itesm.mxabstract
in the last decade  there has been several studies on the computational complexity of planning. these studies normally assume that the goal of planning is to make a certain fluent true after the sequence of actions. in many real-life planning problems  the goal is represented in a much more complicated temporal form: e.g.  in addition to having a desired fluent true at the end  we may want to keep certain fluents true at all times. in this paper  we study the complexity of planning for such temporal goals. we show that for goals expressible in linear temporal logic  planning has the same complexity as for non-temporal goals: it is np-complete; and for goals expressible in a more general branching temporal logic  planning is pspace-complete.
1	introduction
in the presence of complete information about the initial situation  a plan - in the sense of classical planning - is a sequence of actions that takes the agent from the initial situation to the state which satisfies a given goal. traditionally  a goal is described as a fluent which must be true after all the actions. for such goals  the computational complexity of finding a plan has been well-studied  bylander  1; erol et al.  1; liberatore  1; baral et al.  1 . in the most natural formulation  the problem of finding polynomial length plans is np-complete  for exact definitions of standard complexity terms such as np-completeness  see  e.g.   papadimitriou  1; baral et al.  1  .
　in many real-life planning problems  the goal is represented in a much more complicated temporal form: e.g.  in addition to having a desired fluent true at the end  we may want to keep certain fluents true at all times; for example  we may want to make sure that certain safety constraints are satisfied at all times. in this paper  we study the complexity of planningfor such temporal goals. there exist two formalisms for describing temporal goals: linear temporal logic  ltl   bacchus and kabanza  1  in which we are allowed to refer to the actual past and future events  and branching temporal logic ctl  niyogi and sarkar  1  in which we are also allowed to refer to events from the possible future. in this paper  we will describe the computational complexity of planning in both logics. to the best of our knowledge this has not been done before.
　our complexity analysis will be based on the action description language proposed in  gelfond and lifschitz  1 . the language and its variants have made it easier to understand the fundamentals  such as inertia  ramification  qualification  concurrency  sensing  etc.  involved in reasoning about actions and their effects on a world  and we would like to stick to that simplicity principle here. to stick to the main point we consider the simplest action description  and do not consider features such as executability conditions. we now start with a brief description of the language .
1	the language	: brief reminder
in the language   we start with a finite list of properties  fluents  which describe possible properties of a state.
a state is then defined as a finite set of fluents  e.g. 	or
       . we are assuming that we have complete knowledge about the initial state: e.g.  means that in the initial state  properties and are true  while all the other properties are false. the properties of the initial state are described by formulas of the type
where	is a fluent literal  i.e.  either a fluent	or its negation
.
　to describe possible changes of states  we need a finite set of actions. in the language	  the effect of each action	can be described by formulas of the type
where are fluent literals. a reasonably straightforward semantics describes how the state changes after an action:
if  before the execution of an action   fluent literals were true  and the domain description contains a rule      then this rule is activated  and after the execution of the action   becomes true.
if for some fluent   no activated rule enables us to conclude that is true or false  this means that the execution of action does not change the truth of this fluent; therefore  is true in the resulting state if and only if it was true in the old state.
formally  a domain description is a finite set of value propositions of the type      which describe the initial state   and a finite set of effect propositions of the type
 	   which describe results of actions .
the initial state consists of all the fluents for which the corresponding value proposition     is contained in the domain description.  here we are assuming that we have complete information about the initial situation.  we say that
a fluent	holds in	if	; otherwise  we say that
holds in	.	the transition function	which describes the effect of an action	on a state	is defined as follows:
	we	say	that	an	effect	proposition
 	  is activated in a state if all fluent literals hold in ;
	we define	as the set of all fluents	for which
	a rule  	  is activated in ;
	similarly  we define	as the set of all fluents
	for which a rule  	  is activated
in ;
	if	  we say that the result of the
action is undefined; if the result of the action is defined in a state  i.e. 
	if	   we define
.
a plan is defined as a sequence of actions . the result of applying a plan to the initial state is defined as
the planning problem is: given a domain and a desired property  find a plan for which the resulting trajectory  
                  	  etc.  satisfies the desired property. in particular  if the goal is to make a certain fluent true  then the planning problem consists of finding a plan which leads to the state in which is true.
　in addition to the planning problem  it is useful to consider the plan checking problem: given a domain  a desired property  and a candidate plan  check whether this action plan satisfies the desired property. it is known that in the presence of complete information about the initial situation  for fluent goals  plan checking is a tractable problem - i.e.  there exists a polynomial-time algorithm for checking whether a given plan satisfies the given fluent goal  bylander  1; erol et al.  1; liberatore  1; baral et al.  1 .
1	temporal extensions: motivations
let us give two examples of planning problems explaining why temporal extensions are desirable:
　1  if we are planning a flight of an automatic spy miniplane  then the goal is not onlyto reach the target point which can be described by the fluent    but also to avoid detection; more formally  a fluent   detected   must remain false all the time.
　1  when planning a movement of a robot  we may want to require that not only the robot achieve its goal but also that  whenever the robot strays from the desired trajectory  it should always be possible to bring the robot back to this trajectory  i.e.  make the fluent  true  by a single corrective action.
1	linear temporal logic: brief reminder
in linear temporal logic  ltl   in addition to the truth values of a fluent at the current moment of time  we can also refer to its truth values in the past and in the future. for this  ltl has several operators. different authors use different notations for these operators. since we will also analyze planning in branching time logic described in  niyogi and sarkar  1  as an extension of ltl  we will use notations from  niyogi and sarkar  1  for ltl operators. ltl has four basic future operators:
  next time in the future :	is true at a moment time if	is true at the moment	;
　 going to be always true : is true at the moment is is true at all moments of time .
 sometime in the future : is true at the moment if is true at some moment ;
　 until : is true at the moment if is true at this moment of time and at all the future moments of time until becomes true.
similarly  ltl has four basic past operators:
　 previously :	is true at a moment time	if	is true at the moment	;
　 has always been : is true at the moment if was true at all moments of time ;
　 once or sometime in the past :	is true at the moment	if	was true at some moment	;
　 since : is true at the moment if is true at this moment of time and at all the past moments of time since the last time when was true.
we can combine several such operators: e.g.  is true at a moment if is true at the moment .
　in general  an ltl-goal is a goal which is obtained from fluents by using ltl operators and propositional connectives   and      or    and   not  .
　for example  the objective from our first planning problem can be easily formulated as the following ltl-goal:
comment. some versions of ltl have additional operators  e.g.  we may have interval operators in which moments of time or are restricted to a given interval  bacchus and kabanza  1; niyogi and sarkar  1 .
1	branching temporal logic: brief reminder
in the branching temporal logic ctl  emerson  1; niyogi and sarkar  1   in addition to ltl operations  we have two additional operators and which describe possible futures:
    exists path  is true at the state at the time if there exists a possible evolution of this state for which is true at this same moment .
    all paths  is true at the state at the time if for all possible evolutions of this state  is true at this same moment .
for example  the requirement that  no matter what action we apply to the state   a fluent will always stay true  can be described as .
　similarly  we can describe in this language the fast maintainability requirement from our second planning problem: no matter what action we apply to the state   if a fluent stops being true after this action  we can always make the property true by applying appropriate correcting action.
　in ctl  this fast maintainability requirement can be formulated as follows:
once we have already reached the next state   the possibility to get back by applying a single correcting action means that either is already true  or there is a path in which will be true at the next moment of time     
	i.e.  that	.
so  the fast maintainability requirement means that every possible immediate future state satisfies the above property   i.e.  in ctl notations  that
comment. the description of more general temporal logics can be found in  gabbay et al.  1 .
1	results
1	what kind of planning problems we are interested in
informally speaking  we are interested in the following problem:
given a domain description  i.e.  the description of the initial state and of possible consequences of different actions  and a goal  i.e.  a fluent which we want to be true   determine whether it is possible to achieve this goal  i.e.  whether there exists a plan which achieves this goal .
we are interested in analyzing the computational complexity of the planning problem  i.e.  analyzing the computation time which is necessary to solve this problem.
　ideally  we want to find cases in which the planning problem can be solved by a tractable algorithm  i.e.  by an algorithm whose computational time on each input is bounded by a polynomial of the length of the input :  this length can be measured bit-wise or symbol-wise . problems which can be solved by such polynomial-time algorithms are called problems from the class p  where p stands for polynomial-time . if we cannot find a polynomial-time algorithm  then at least we would like to have an algorithm which is as close to the class of tractable algorithms as possible.
　since we are operating in a time-bounded environment  we should worry not only about the time for computing the plan  but we should also worry about the time that it takes to actually implement the plan. if a  sequential  action plan consists of a sequence of actions  then this plan is not tractable. it is therefore reasonable to restrict ourselves to tractable plans 
i.e.  to plans whose duration is bounded by a polynomial of the input .
　with this tractability in mind  we can now formulate the above planning problem in precise terms:
	given: a polynomial	  a domain description
 i.e.  the description of the initial state and of possible consequences of different actions  and a goal statement
　 i.e.  a statement which we want to be true   determine whether it is possible to tractably achieve this goal  i.e.  whether there exists a tractable-duration plan
	 with	  which achieves this goal.
we are interested in analyzing the computational complexity of this planning problem.
1 complexity of the planning problem with goals expressible in linear temporal logic
theorem 1. for goals expressible in linear temporal logic  ltl   the planning problem is np-complete.
comments.
since the planning problem is np-complete even for simple  non-temporal goals  bylander 1;erol et al.  1; liberatore  1; baral et al.  1   this result means that allowing temporal goals from ltl does not increase the computational complexity of planning.
this result is in good accordance with the fact that the decidability problem for linear temporal logic is also np-complete  emerson  1 .
for readers' convenience  all the proofs are placed in the special proofs section.
the proof of theorem 1 is based on the following result:
theorem 1. for goals expressible in linear temporal logic  ltl   the plan checking problem is tractable.
we give the proofs of theorems 1 and 1 for the version of linear temporal logic which only uses eight basic temporal operators. however  as one can easily see from the proofs  these result remains true if we allow more sophisticated temporal operators  e.g.  interval operators of the type meaning that the fluent is true in some future moment of time from the interval  bacchus and kabanza  1; niyogi and sarkar  1 .
1	complexity of the planning problem with goals expressible in branching temporal logic
theorem 1. for goals expressible in branching temporal logic ctl  the planning problem is pspace-complete.
comment. this result is in good accordance with the fact that the decidability problem for most branching temporal logics is also pspace-complete  gabbay et al.  1 .
for the branching temporal logic  not only planning  but even plan checking is difficult:
theorem 1. for goals expressible in branching temporal logic ctl  the plan checking problem is pspace-complete.
theorems 1 and 1 mean that allowing temporal goals from ctl can drastically increase the computational complexity of planning. these results  however  are not that negative because most safety and maintainability-type conditions can be expressed in a simple subclass of ctl. namely  in the maintainability conditions like the one above  we do not need to consider all possible trajectories  it is sufficient to consider trajectories which differ from the actual one by no more than one  or  in general  by no more than   states. in this case  the planning problem becomes much simpler:
definition 1. let beapositiveinteger. wesaythat anexpressionin ctl is -limited ifthisexpressionremains truewheninalloperators and  weonlyallowpossible trajectoriesdifferfromtheactualtrajectoryinnomorethan momentsoftime.
for example  the above maintainability statement  1  means that all possible 1-deviations from the actual trajectory are maintainable and therefore  this statement is 1-limited.
theorem 1. let be an integer. for -limited goals expressible in branching temporal logic ctl  the planning problem is np-complete.
theorem 1. let	be an integer. for	-limited goals expressible in branching temporal logic ctl  the plan checking problem is tractable.
1	conclusions
our first conclusion is that if  instead of traditional goals which only refer to the state of the system at the last moment of time  we allow goals which explicitly mention the actual past and actual future states  the planning problem does not become much more complex: it stays on the same level of complexity hierarchy.
　our second conclusion is that if we allow goals which refer to potential future  the planning problem can become drastically more complicated. thus  we should be very cautious about such more general goals.
1	proofs
proof of theorems 1 and 1. we already know that the planning problem is np-complete even for the simplest possible case of ltl-goals: namely  for goals which are represented simply by fluents  bylander  1; erol et al.  1; liberatore  1; baral et al.  1 . therefore  to prove that the general problem of planning under ltl-goals is npcomplete  it is sufficient to prove that this general problem belongs to the class np.
　indeed  it is known  papadimitriou  1  that a problem belongs to the class np if the corresponding formula can be represented as   where is a tractable property  and the quantifier runs over words of tractable length  i.e.  of length limited by some given polynomial of the length of the input .
　for a given planning situation   checking whether a successful plan exists or not means checking the validity of the
formula	  where	stands for  the plan
succeeds for the situation  . according to the above definition of the class np  to prove that the planning problem belongs to the class np  it is sufficient to prove the following two statements:
the quantifier runs only over words	of tractable length  and
the property	can be checked in polynomial time.
the first statement immediately follows from the fact that in this paper  we are considering only plans of polynomial
 tractable  duration  i.e.  sequential plans whose length is bounded by a polynomial of the length of the input :   where is a given polynomial. so  the quantifier runs over words of tractable length.
　let us now provethe second statement - that plan checking can be done in polynomial time.  this statement constitutes theorem 1.  once we have a plan of tractable length  we can check its successfulness in a situation as follows: we know the initial state ; take the first action from the action plan and apply it to the state ; as a result  we get the state ; take the second action from the action plan and apply it to the state ; as a result  we get the state ; etc.
at the end  we get the values of all the fluents at all moments of time. on each step of this construction  the application of an action to a state requires linear time; in total  there are polynomial number of steps in this construction. therefore  computing the values of all the fluents at all moments of time indeed requires polynomial time.
　let us now take the desired goal statement and parse it  i.e.  describe  step by step  how we get from fluents to this goal statement .
for example  for the above spy-plane goal statement
  parsing leads to the following se-
	quence of intermediate statements:	 
	 	  and finally 	.
the number of the resulting intermediate statements cannot exceed the length of the goal statement; thus  this number is bounded by the length of the goal statement.
　based on the values of all the fluents at all moments of time  we can now sequentially compute the values of all these intermediate statements at all moments of time:
when a new statement is obtained from one or two previous ones by a logical connective  e.g.  in the above example  as    then  to compute the value of the new statement at all moments of time  we need logical operations.
let us now consider the case when a new statement is obtained from one or two previously computed ones by using one temporal operations: e.g.  in the above example  as  . then  to compute the truth value of at each moment of time  we may need to go over all other moments of time. so  to compute for each moment of time   we need steps. hence  to compute the truth value of for all moments of time  we need steps.
in both cases  for each of intermediate statements  we need computations. thus  to compute the truth value of the desired goal statement  we need computational steps. since we look for plans for which for some polynomial   we thus need a polynomial number of steps to check whether the given plan satisfies the given goal.
　so  we can check the success of a plan in polynomial time  and thus  the planning problem indeed belongs to the class np. the theorems are proven.
proof of theorem 1. this proof follows the same logic as proofs of pspace-completeness of other planning problems; see  e.g.   littman  1  and  baral et al.  1 .
　by definition  the class pspace is formed by problems which can be solved by a polynomial-space algorithm. it is known  see  e.g.   papadimitriou  1   that this class can be equivalently reformulated as a class of problems for which the checked formula can be represented as
  where the number of quan-
tifiers is boundedby a polynomial of the length of the input  is a tractable property  and all quantifiers run over words of tractable length  i.e.  of length limited by some given polynomial of the length of the input . in view of this result  it is easy to see that for ctl-goals  the planning problem belongs to the class pspace. indeed  all the operators of ctl can be described by quantifiers over words of tractable length  namely  either over paths  for operators and   or over moments of time  for ltl operators . a plan is also a word of tractable length. thus  the existence of a plan which satisfies a given ctl-goal can be described by a tractable sequence of quantifiers running over words of tractable length. thus  for ctl-goals  the planning problem does belong to pspace.
　to prove that the planning problem is pspace-complete  we will show that we can reduce  to the planning problem  a problem known to be pspace-complete: namely  the problem of checking  for a given propositional formula with the variables   the validity of the formula of the type this reduction will be done as follows. consider the planning problem with two actions and   and fluents  
　　　　　. these actions and fluents have the following meaning: the meaning of is that we are at moment of time ;
the action  when applied at moment  makes -thvariabletrue;the action  when applied at moment  makes -thvariablefalse.the corresponding initial conditions are:
 for all  ;
	;	 for all	 .
the effect of actions if described by the following rules  effect propositions :
	for	  the rules
	describe how we assign values to the variables	;
	for	the rules
	describe the update of the time fluents	.
the corresponding goal is designed as follows:
first  we replace in the above quantified propositional formula   each existential quantifier by   each universal quantifier by ; let us denote the result of this replacement by ; then  we add to the resulting formula ;
	finally  we add	in front of the whole thing - creating
.
for example  for a formula   this construction leads to the following goal: this reduction leads to a linear increase in length  so this reduction is polynomial-time.
　to complete the proof  we must show that this is a  valid  reduction  i.e.  that the resulting planning problem is solvable if and only if the original quantified propositional formula is true.
　to prove this equivalence  let us first remark that  by definition of the operator   previous    the goal formula is true at a moment if and only if the formula
	holds at a moment	. since  due to our rules 
is only true at the starting moment of time   the goal can only be true if . thus  to check whether we can achieve the goal  it is sufficient to check whether we can achieve it at the moment   i.e.  after a sequence of actions. in this case  the validity of the goal is equivalent to validity of the formula at the initial moment .
　let us now show that the validity of the formula at the moment is indeed equivalent to the validity of the above quantified propositional formula. we will prove this equivalence by induction over the total number of variables .
induction base: for   we have no variables at all  so is either identically true or identically false. in this case 
simply coincides with	  so they are  of course  equivalent.
induction step: let us assume that we have proven the desired equivalence for all quantified propositional formulas with variables; let us prove it for quantified propositional formulas with variables.
　indeed  let a quantified propositional formula of the above type be given. there are two possibilities for the first variable of this formula:
it may be under the existential quantifier	; or it may be under the universal quantifier	.
　. in the first case  the formula has the form   where for each   is a quantified propositionalformula with
variables . according to our construction  the ctl formula has the form   where is the result of applying this same construction to the formula .
　to show that is indeed equivalent to   we will first show that implies   and then that implies .
	let us first show that	implies	.
indeed  by definition of the operator   if the formula holds at the moment this means that there exists
a path for which  at moment	  the formula	is true.
　by definition of the operator   next    the fact that the formula is true at the moment means that the formula is true at the next moment of time .
　by the time   we have applied exactly one action which made either true or false  after which the value of this variable does not change. let us select the value as  true  or  false  depending on which value was selected along this path.
　the moment can be viewed as a starting point for the planning problem corresponding to the remaining formula . by induction assumption  the validity of at this new starting moment is equivalent to the validity of the quantified propositional formula . thus  the formula is true for this particular   hence the original formula is also true. so  indeed implies .
	let us now show that	implies	.
　indeed  if is true  this means that there exists a value for which is true. by the induction assumption  this means that for this same   the goal formula is also true at the new starting moment . thus  for any path which starts with selecting this   the formula is true at the previous moment . since this formula is true for some path  by definition of the operator   it means that the formula is true at the moment   and this formula is exactly .
	thus 	does imply	  and hence	and	are equivalent.
the second case  when is under the universal quantifier   can be handled similarly.
the induction step is proven  and thus  by induction  the equivalence holds for all .
　thus  the reduction is valid  and the corresponding planning problem is indeed pspace-complete. q.e.d.
proof of theorem 1. similarly to the proof of theorem1  we can show that plan checking belongs to the class pspace  so all we need to prove is the desired reduction. from the proof of theorem 1  one can see that the exact same reduction will work here as well  because in this reduction  the equivalence between and did not depend on any action plan at all. the equivalence used in the proof of theorem 1 is based on the analysis of possible trajectories and does not use the actual trajectory at all.
　thus  we can pick any action plan  e.g.  a sequence consisting of actions    and the desired equivalence will still hold. q.e.d.
proof of theorems 1 and 1. for trajectories of duration   with possible actions at each moment of time  there are no more than possible trajectories differing in one state  no more than trajectories differing in two states  etc. in general  whatever number we fix  there is only a polynomial number    of possible trajectories which differ from the actual one in places.
　therefore  for fixed   we can explicitly describe the new operators and by enumerating all such possible trajectories. thus  similarly to the proof of theorems 1 and 1  we can conclude that for -planning  plan checking is tractable and the corresponding planning problem is np-complete.
acknowledgments
this work was supported by nasa  grant ncc1 and a research on intelligent systems grant   by the afosr grant f1-1  by the grant w-1 from the u.s.czech science and technology joint fund  and by the nsf grants iri 1  and 1mexico/conacyt. the authors are thankful to the anonymous referees for valuable comments.
references
 bacchus and kabanza  1  fahiem bacchus and froduald kabanza. planning for temporally extended goals. annals of mathematics and artificial intelligence  1-1  1.
 baral et al.  1  chitta baral  rau＞l trejo  and vladik kreinovich. computational complexity of planning and approximate planning in the presence of incompleteness. artificial intelligence  1-1  1.
 bylander  1  tom bylander. the computational complexity of propositional strips planning. artificial intelligence  1-1  1.
 emerson  1  e. allen emerson. temporal and modal logics. in: jan van leeuwen  editor. handbook of theoretical computer science  vol. b  pages 1  mit press  cambridge  massachusetts  1.
 erol et al.  1  kuthulan erol  dana s. nau  and v.s. subrahmanian. complexity  decidability and undecidability results for domain-independent planning. artificial intelligence  1-1 :1  1.
 gabbay et al.  1  dov m. gabbay  ian hodkinson  and mark reynolds. temporal logic: mathematical foundations and computational aspects. oxford university press  new york  1.
 gelfond and lifschitz  1  michael gelfond and vladimir lifschitz. representing actions and change by logic programs. journal of logic programming 
1 1 :1 1.
 liberatore  1  paolo liberatore. the complexity of the language . electronic transactions on artificial intelligence  1-1  http://www.ep.liu.se/ej/etai/1   1.
 littman  1  michael l. littman. probabilistic propositional planning: representations and complexity. in aaai 1  pages 1  1.
 niyogi and sarkar  1  rajdeep niyogi and sudeshna sarkar. logical specification of goals. in international conference on information technology icit'1  bhubaneswar  india  december 1  1. tata mcgraw-hill.
 papadimitriou  1  christos h. papadimitriou. computational complexity. addison-wesley  reading  massachusetts  1.
a simplifier for propositional formulas with many binary clauses
ronen i. brafman
department of computer science
ben-gurion university
beer-sheva  israel brafman cs.bgu.ac.ilabstract
deciding whether a propositional formula in conjunctive normal form is satisfiable  sat  is an npcomplete problem. the problem becomes linear when the formula contains binary clauses only. interestingly  the reduction to sat of a number of well-known and important problems - such as classical ai planning and automatic test pattern generation for circuits - yields formulas containing many binary clauses. in this paper we introduce and experiment with 1-simplify  a formula simplifier targeted at such problems. 1-simplify constructs the implication graph corresponding to the binary clauses in the formula and uses this graph to deduce new unit literals. the deduced literals are used to simplify the formula and update the graph  and so on  until stabilization. finally  we use the graph to construct an equivalent  simpler set of binary clauses. experimental evaluation of this simplifier on a number of bench-mark formulas produced by encoding ai planning problems prove 1-simplify to be fast and effective.
1	introduction
propositional satisfiability  sat  is the problem of deciding whether a propositional formula in conjunctive normal form  cnf  is satisfiable. sat was the first problem shown to be np-complete  cook  1  and has important practical applications. in the last decade we have witnessed great progress in sat solution methods  first with the introduction of efficient stochastic local search algorithms  selman et al.  1; 1   and more recently with a number of efficient systematic solvers  such as rel-sat  bayardo and schrag  1  and satz  li and anbulagan  1  and their randomized versions  gomes et al.  1 .
　among ai researchers  interest in sat solution algorithms has increased farther since kautz and selman showed that some classical planning problems can be solved more quickly when they are reduced to sat problems  kautz and selman  1 . kautz and selman's planning as satisfiability approach is based on generic sat technology  and  aside from the translation process itself  makes no use of properties specific to planning problems. however  sat-encoded planning problems have an important syntactic property: they contain a large fraction of binary clauses. interestingly  this property is found in another important domain - automatic test-pattern generation for circuits  larrabee  1 .
　unlike the general sat problem  1-sat  the problem of deciding whether a propositional formula containing binary clauses only has a satisfying assignment is  constructively  solvable in linear time. one would hope that this property would make it easier to solve sat instances containing a large fraction of binary clauses. in this article we describe the 1-simplify preprocessor  a simplifier that is geared to such formulas. like other simplifiers  e.g.  crawford's compact   this algorithm takes a propositional formula in cnf as input and outputs a new propositional formula. naturally  for this process to be worthwhile  the new formula should be easier to solve  and the overalltime requiredforsimplification and solution of the simplified formula should be less than the time required to solve the original sat instance. experiments on a number of bench-mark formulas derived from planning problems show that 1-simplify meets this criteria.
　1-simplify efficiently implements and combines wellknown 1-sat techniques  a limited form of hyper-resolution  and novel use of transitive reduction to reduce formula size. the basic idea is as follows: each clause of the form is equivalent to two implications: and . we use this property to construct a graph  known as the implication graph  aspvall et al.  1   from the set of binary clauses. this graph contains a node for each literal in the languageand a directed edge from a literal to another literal if the  disjunction equivalent to the  implication appears among the set of binary clauses. after constructing this graph  we compute its transitive closure and check each literal to see whether its negation appears among its descendants. if is a descendant of   we can immediately conclude that is a consequence of the original formula. once we know that holds  we can simplify the original formula. the simplified formula may contain new binary clauses  which are immediately added to the graph. 1-simplify utilizes these and other ideas to quickly derive unit literals from the original formula and produce the simplest equivalent formula as its output.
　in the next section we discuss the background of this work in more detail. in section 1 we present the simplification algorithm used by 1-simplify. in section 1 we present some experimental results  and we conclude in section 1.
1	background
we start with some sat background and then we briefly explain the planning as satisfiability approach  which motivated this work.
1	the sat problem
the sat problem is defined as follows: given a propositional formula in conjunctive normal form  cnf  output yes if the formula is satisfiable and no otherwise. in practice  a positive answer is accompanied by some satisfying assignment.
　there are two classes of sat algorithms: stochastic and systematic. stochastic methods  such as g-sat selman et al.  1  and walksat selman et al.  1   perform stochastic local search in the space of truth assignment. often  they can find solutions quickly  but they cannot identify an unsatisfiable instance. their performance is extremely sensitive to the choice of heuristic and various other parameters. systematic methods systematically search the space of truth assignments. thus  they can identify unsatisfiable instances. modern systematic algorithms are quite fast and stable thanks to improved branch choice heuristics and backtracking techniques. in addition  systematic solvers can be improved by introducing some randomization into their search procedure  e.g.  their choice of branch variable. see  gomes et al.  1  for more information on this topic.
　often  a formula simplifier is applied before the sat solver. simplifiers use specialized  efficient deductive methods to reduce the original formula into a simpler formula which is typically easier to solve. the best known simplification method is unit propagation. when one of the clauses in the formula contains a single literal  it must be assigned the value true in any satisfying assignment. for example  if a formula contains the clause then must be true in any satisfying assignment  i.e.  must be false. once we deduce this fact  we can use it to simplify other clauses: clauses that contain can be removed since their satisfaction is guaranteed when is false  and the literal can be removed from any clause containing it  e.g.  will be transformed into   because it is equivalent to false. as we just saw  the simplification process can yield additional unit clauses  which are used to produce additional simplifications. if during the simplification process an empty clause is discovered
 e.g.  if we assigned the value true and there is a unit clause   we can conclude that the formula is unsatisfiable.
　there are a number of additional simplification methods  such as failed unit clause and failed binary clause  where a unit or binary clause are added to the current formula and we attempt to show  e.g.  using unit propagation  that the resulting formula is inconsistent. in that case  the negation of the added clause is implied by the original formula  and we update the truth assignment accordingly. for example  if our original formula becomes inconsistent once we add the clause   we know that both and must be assigned false.
1	1-sat
1-sat is a subclass of sat in which clauses contain no more than two literals. while sat is np-complete  cook  1   1-sat can be solved in linear time. the key step in solving 1-sat problems is the construction of the implication
% binary clauseslog-dir.a1%log-dir.b1%log-dir.c1%log.d1%log-gp.a1%log-gp.b1%log-gp.c1%log-un.a1%log-un.b1%log-un.c1%bw-dir.a1%bw-dir.b1%bw-dir.c1%bw-dir.d1%figure 1: percentage of binary clauses in sat-encoded planning problems
graph  aspvall et al.  1  . the nodes of the implication graph correspond to the literals in the formula. the graph contains an edge between the literal and the literal if the clause appears in the formula. that is  edges in the graph correspond to implications  since is equivalent to  . since implication is transitive  we have that is implied by the formula whenever there is a path in the graph between node and node . in particular  if we have a path between and   we know that cannot hold. therefore  is implied by the formula. if  in addition  we have a path from to   then neither nor can hold  and so the formula is unsatisfiable. finally  we know that in every satisfying truth assignment  if is assigned true then any literal implied by   i.e.  any descendant of in the graph  must be assigned true as well.
1	planning as satisfiability
the planning problem is defined as follows: given a description of an initial state  a goal state  and a set of operators  =actions  for changing the state of the world  find a sequence of operators that  when applied in the initial state  yield the goal state. an important development in planning algorithms was kautz and selman's planning as satisfiability approach  kautz and selman  1 . kautz and selman showed that by reducing planning problems to satisfiability problems  we can often solve them more quickly than by using standard planning algorithms. planning problems can be encoded as satisfiability problems in a number of ways  e.g.  see  ernst et al.  1  for a description and analysis of some of these methods .
　as  brafman  1  points outs  encoded planning problems contain a large number of binary clauses. in figure 1 we show this for a number of instances of sat-encoded planning problems. this is no accidental phenomenon. close inspection of the types of constraints expressed within encoded planning problems makes it apparent that many classes of these constraints generate binary formulas. for example 

   available at ftp://ftp.research.att.com/dist/ai/logistics/tar.z and satplan.data.tar.z

figure 1: the implication graph
the constraint that if an action is executed at some time point then all its preconditions must hold prior  produces binary clauses. similarly  the constraint asserting that if an action is executed at some point then all its effects must hold after the execution yields binary clauses as well. in the encoding used by the blackbox planner  kautz and selman  1  mutual exclusion constraints  on actions and on state variables  play a prominent role. these constraints are expressed using binary clauses as well.
　interestingly  it turns out that the sat encodings of other important problems exhibit the same large percentage of binary clauses. these include test-pattern generation for circuits  larrabee  1  and bounded model checking  shtrichman  1 .
1	the 1-simplify preprocessor
we now explain the algorithm implemented by the 1simplify preprocessor using the following formula:
　 1  construct implication graph. a graph containing all literals in the language is constructed with directed edges from to if is a binary clause. figure 1 shows the implication graph for the formula above.
　 1  collapse strongly connected components. a subgraph in which there is a path between every pair of nodes is called a strongly connected component  scc . when a path from node to node exists  we know that is a consequence of our formula. therefore  all nodes within an scc imply each other  and they must all be assigned the same value.
　once we discover an scc we replace it by a single node. the children of this node are the children of the nodes in the scc  and the parents of this node are the parents of the nodes in this scc. in addition  all literals in the scc must be replaced by this new node within all non-binary clauses.
	in our example  the nodes	and	  and the nodes	and
　  form strongly connected components. we choose to represent the first scc and we choose to represent the second scc. the reduced graph is shown in figure 1.

figure 1: removing strongly connected components
　 1  generate transitive closure. we generate the transitive closure. now  we know that if is a child of then is implied by the original formula. we can deduce if either:
1. for some proposition   both	and	are children of	.
1. is a child of	.
　once we deduce   we can perform unit propagation: we know that all children of are true  and we can reduce the current formula by applying unit propagation. if the reduced formula contains new binary clauses  we add the appropriate edges to the graph and update the transitive closure.
　in figure 1 we can see the effect of this step. first  we compute the transitive closure of the current graph  shown in figure 1a. in this graph  we see that has as a descendant and that has as a descendant. therefore  we conclude that and must be assigned the value false. we can remove nodes that correspond to assigned propositions  i.e.  in our case . the resulting graph is shown in figure 1b. next  we perform unit propagation  and our initial ternary clauses: are reduced
to	the first clause was remove because it is satisfied  and a  false  literal was removed from the next two clauses. since we have new binary clauses  we can update the graph  as shown in figure 1c  making sure it is transitively closed. in the resulting graph  is a child of   and we can deduce that false. the reduced graph is shown in figure 1d.
　 1  derive shared implications. let be some non-binary clause in the formula. let be the set of literals implied by for . let . all literals in are consequences of our formula  and we can use them to perform unit propagation.
　consider the clause   the sets of literals implied by each of the literals in this clause are
	  respectively.	their intersection
contains	. hence  we can deduce that	is false.
　 1  compute transitive reduction. the transitive reduction of a graph is a graph with the same nodes as but with a minimal set of edges such that a path between and exists in iff a path between and exists in .

	 a 	 b 

	 d 	 c 
figure 1:  a  initial transitive closure.  b  removal of assigned nodes.  c  update with new binary clauses.  d  removal of assigned nodes.
　 1  output simplified formula. we outputa formulawhose clauses consist of the non-binary clauses remaining after all simplifications were performed and all binary clauses corresponding to edges in the transitive reduction of the graph. given the assignments deduced so far and the mappings between elements of strongly connected components  the simplified formula is equivalent to the original formula. for example  the output for our original formula will be: together with the partial assignment false	false	false	false.
　step  1  is a novel implementation of an old technique  hyper-resolution  robinson  1   and step  1  is new.
both have important impact on 1-simplify's performance.
the derive shared literals step enhances the ability of 1-
simplify to derive unit literals. in some cases  it can derive hundreds of new unit literals quickly. in fact  1-simplify uses a more sophisticated version of this procedure: if no shared unit literals exist  we attempt to derive new binary clauses by intersecting the implications of all literals but one. these binary clauses are then added to the implication graph. the compute transitive reduction step leads to a minimal sufficient set of binary clauses  leading to smaller and simpler formulas. we have found this reduction to have an important positive influence on systematic solvers.
1	experimental evaluation
we evaluated the 1-simplify preprocessoron a set of benchmark instances of encoded planning problems which were used to test the rel-sat solver. 1-simplify is written in c++ and all experiments described here were conducted on a dell latitude cp notebook with a pentium ii-1 pro-
instancesimp. timeassigned/totallog-dir.a11log-dir.b11log-dir.c11log.d11log-gp.a11log-gp.b11log-gp.c11log-un.a11log-un.b11log-un.c11bw-dir.a11bw-dir.b11bw-dir.c11bw-dir.d11figure 1: running time and deduction power of 1-simplify
instancesatz1-simplifysatz on 1stotallog-dir.a1111log-dir.b1111log-dir.c1111log.d1111log-gp.a1111log-gp.b1111log-gp.c1111log-un.a1111log-un.bua1uaualog-un.cua1uauabw-dir.a1111bw-dir.b1111bw-dir.c1111bw-dir.d1111figure 1: solution times for satz and 1-simplify+satz.
cessor with 1mb ram running linux. all time measurements refer to cpu time.
　first  we examined 1-simplify's ability to deduce unit literals. in figure 1 we show 1-simplify's running time on each of the instances and the number of variables it was able to assign. note that in addition to deducing unit literals  1simplify also supplies additional important information in the form of equivalent literals.
　to assess the utility of 1-simplify we generated simplified formulas for each of the instances and comparedthe solution time of the original formulas with the combined simplification and solution times for the simplified formulas. we performed this comparison using two systematic solvers: satz and rel-sat. the results for satz are shown in figure 1  where we show the simplification time again  in order to give a sense of its magnitude in comparison to solution time. we see that in all instances 1-simplify proves itself useful  reducing the overall solution time. 1-simplify is particularly useful on the instances on which satz takes longest.
　the results for rel-sat are shown in figure 1. we note that in many cases  rel-sat's performance on the simplified formulas can be improved by disabling its own preprocessor.
instancerel-sat1-simplify1s+rlog-dir.a111log-dir.b111log-dir.c111log.d111log-gp.a111log-gp.b111log-gp.c111log-un.a111log-un.b111log-un.b111log-un.b111log-un.c111bw-dir.a111bw-dir.b111bw-dir.c111bw-dir.d1.1.1figure 1: solution times for rel-sat  1-simplify  and 1simplify+rel-sat.
 we refer the reader to the full paper where these experiments appear.  we see that 1-simplify+rel-sat is always faster than rel-sat alone when we use rel-sat's preprocessor. the improvement is especially significant in the hardest instances. we note that the rel-sat figures represent average running times  because rel-sat has a stochastic element .
we run another sequence of experiments to compare 1-
simplify with crawford's compact simplifier. first  we examined the performance of various compact options on the test problems and found that the best performance is obtained almost always using either no flags or using the flags. to see whether 1-simplify improves on compact's performance we compare the sum of simplification time and solution time for combinationsof compact with and without 1-simplify and with either satz or rel-sat.
　in figure 1 we see the results for satz. the columns correspond to the combined running time of satz and the simplification algorithms on each of the instances. the first column is satz applied to compact simplified formulas  while the second is satz applied to 1-simplify+compact. the third and forth columns are similar  except that we used the options in compact. we see that 1-simplify leads to reduced running times in all cases except two  log-dir.a and log.d on compact with the options .
　in figure 1 we show the correspondingresults for rel-sat  with its preprocessor . here we see that 1-simplify improves the overall performance on all problems  and in some cases significantly so.
finally  we examined 1-simplify's influence on the per-

   in the case of bw-dir.d  rel-sat timed out on the original problem in some of the iterations and we provided a lower bound on its average running time.
   with no flags  compact does unit resolution  removes satisfied clauses  and renames variables to be contiguous. with   in addition to the above  compact eliminates pure literals  resolves away variables with a single occurrence  and for each literal checks whether its addition leads to contradiction.
c+s1s+c+spsl + spsl + 1s+ sbw-dir.a1111bw-dir.b1111bw-dir.c1111bw-dir.d1111log-dir.a1111log-dir.b1111log-dir.c1111log.d1111log-gp.a1111log-gp.b1111log-gp.c1111log-un.a1111log-un.b--11log-un.c--11figure 1: simplification with compact and 1-simplify  solution with satz.
c+r1s+c+rpsl + r1s+ psl + rbw-dir.a1111bw-dir.b1111bw-dir.c1111bw-dir.d-1-1log-dir.a1111log-dir.b1111log-dir.c1111log.d1111log-gp.a1111log-gp.b1111log-gp.c1111log-un.a1111log-un.b1111log-un.c1111figure 1: simplification with compact and 1-simplify  solution with rel-sat.
formance of walksat  a stochastic solver. as noted  stochastic solvers require tuning  and we tried to find the best parameters in each case. as figure 1 shows  the results are mixed. on the log instances  we get 1 fold improvement  except for the log.d. in this instance  the simplified formula is solved faster  but simplification time is larger than solution time. however  on the bw-dir instances we get significant reduction in performance. if 1-simplify ignores the transitivereduction step  i.e.  we maintain many binary clauses   we get somewhat different results  shown in the last column . these mixed result are not surprising as stochastic methods are know to be quite sensitive to the form of the formula.
1	conclusion and related work
sat instances with many binary clauses arise naturally in a number of important applications. the abundance of binary clauses in such problems can be exploited using 1-sat solution methods and other specialized inference algorithms. here  we presented 1-simplify  a principled and efficient simplification algorithm that uses the transitive closure of the
instancewalksat1s+walksat1s-tr+walksatbw-dir.a111bw-dir.b111bw-dir.c1-1bw-dir.d1-1log-dir.a111log-dir.b11.1.1log-dir.c111log.d111log-gp.a111log-gp.b111log-gp.c111figure 1: solution times using walksat.
implication graph together with a novel implementation of hyper-resolution i.e  the derive shared literals step  and transitive reduction to obtain a smaller equivalent formula. this leads to an approach that is faster  more powerful  and more efficient the ad-hoc resolution of binary clauses used in  brafman  1 . our experiments on a set of encoded planning problems show that 1-simplify is beneficial in conjunction with systematic solution algorithms: in virtually all tested experiments shorter solution times were obtained. in conjunction with a stochastic solver  the results were mixed  and the utility depends on the problem instance.
　we are not the first to utilize binary resolution in this area. larrabee used the implication graph to devise a sat algorithm in the context of test-pattern generation  larrabee  1 . larrabee systematically generates satisfying assignments consistent with the implication graph. any assignment that satisfies the non-binaryclauses is a satisfying assignment for the whole formula. this method exploits the binary portion of the formula  but it does not utilize the power of contemporary variable ordering and search techniques.
　1cl  van gelder and tsuji  1  is a solver based on the davis-putnam-logemann-loveland algorithm  davis et al.  1 . at each branch point  1cl constructs the transitiveclosure of the current implication graph and uses it to choose the next branching variable. thus  1cl is a dynamic extension of a key aspect of 1-simplify. we have yet to experiment with 1cl. however  our initial attempt to produce a dynamic version of 1-simplify along similar lines were not competitive with satz for two reasons: maintaining an updated transitive closure is costly in terms of time and memory  and satz seems to obtain better information through its use of unit propagation  and faster. at this point  it seems that the techniques that 1-simplify utilizes  i.e.  implication graph analysis  restricted hyper-resolution and transitive reduction  provide a basis for a good simplifier  but not necessarily a good systematic solver.
acknowledgments: i am gratefulto yefim dinitz for his help and advice on graph algorithms and for important comments on previous versions of this paper. this work was supported in part by the paul ivanier center for robotics and production management.
