 
the overhead incurred by reasoning in knowledgebased systems can be considerable when it is forced to rely on search. even problems that are known to have tractable solutions can expend large amounts of computation when the inference method is too general. as discussed in this paper  reflective architectures provide a well-motivated framework for integrating specialized control with general reasoning in knowledge-based systems. however  progress in developing reflective architectures for more expressive languages such as first-order logic has encountered several problems of its own. briefly  this paper considers a reflective architecture for general declarative languages  and describes how declarative and procedural requirements can be combined in a reflective system for first-order logic. as part of this example  two kinds of control  in the form control strategies and subsidiary deduction rules  are identified. 
i. introduction 
primarily  the interest in reflective architectures has focused on addressing the problem of search-intensive inference symptomatic of general knowledge-based systems. the basic approach has been to have the control component included alongside general inference:  i  generate secondary inferences to select among the best courses available to general inference  or  ii  apply subsidiary deduction rules to replace inferences that would otherwise have to be performed directly. the design is considered 'reflective'  or 'introspective'  since it provides for a limited form of self-directed reasoning. examples of systems proposed along these lines may be found in  bowen and kowalski 1    davis 1    gallaire and lasserre 1    genesereth and smith 1    kramer 1   and  weyhrauch 1 . 
　a clearer picture of the concept of reflection in knowledge-based systems can be obtained by considering how control information is to be expressed. the idea  as described in  smith 1   is to express 'properties of 
   financial assistance for this work was gratefully received from the school of graduate studies  and the department of computer science  university of toronto. 
control' in the same way as 'properties of a domain'  but to employ a separate knowledge-base  kb  for this purpose. one immediate advantage is that control information is not tied directly to any set of domain properties  and is therefore free to interact in solving different problems. a second advantage is that by representing control in terms of a knowledge-base  large-scale changes  such as those involved in re-programming an implementation  do not have to be made each time new control properties are introduced. 
　so far  combining reflection with pure declarative languages such as full first-order logic has run into several problems. the first is that  to be effective  secondary  or reflective  inference must be more constrained  less dependent on search  than the general inference processes over which it is to exercise control. however  it is not immediately apparent how to satisfy the demands of having a flexible control component  constraining reflective inference  and keeping the system deductively complete. the second problem centers on a pragmatic issue involving the relative ease with which control constructs can be expressed for a given representational language. in particular  an effective notion of control seems to depend heavily on the syntatic form of the sentences over which they operate. for example  consider the following definition of ancestor: 

to check if x is an ancestor z  a good strategy is to firstcheck if x is a parent of z  and if not  to find a y such that y is a parent of z.  informally  the corresponds to traversing up the family tree.  however  representing the same sentence as a set of clauses  

it is not longer straightforward how the same control strategy can be used. additionally  there is the problem of how to logically organize sets of clauses so that it is possible to recognize at what point particular strategies may be applied. 
　the object of this paper is to describe a reflective architecture for declarative languages  and show how it 


	lownie 	1 

c. t h e tower interface 
two operations are defined for each level of the tower. in this case  the focus is on a computational setting. the idea is to view each level of the tower as comprised of a set of knowledge-bases  kbs  which a user can interact with independently. 
　if the intention is to use the architecture to perform inference  the logics li  i n must be those where the rules of inference defining the consequence operations cni are recursively enumerable. this ensures that the theorems of any logic of the tower can be generated computationally. the two tower operations are analogues of those presented in  levesque 1 . specifically  they allow a user to tell a new statement to a knowledgebase  and to ask if a statement is a logical consequence of those contained in a knowledge-base. in the following  let k  n 
the operation meta-tell n  kbn k a  a  takes k b n   k 
 l n   i.e. the kth kb at the nth level of the tower  and returns k b n   k with a included as a premise. 
　the operation meta-ask n  kbn kjt  a  takes l n   i.e. the kth kb at the nth level of the tower  and returns yes or no  depending on whether a is provable or not provable from k b n   k in l n   respectively. 1 
i i i . the first-order example 
a. inference and procedural reflection 
the next problem to be discussed is where inference can be said to originate in the model  and how it is performed. by way of example  these issues are addressed for a tower based on first-order logic. as a starting guess  one can imagine taking a given tower and pairing each level with a 'black box'  which would carry out all of the reasoning required for that level. however  the original motivation in this area was that sentences expressed as part of a meta-theory should be able to guide inference with respect to a theory  but so far no procedural connection between levels has been made. 
　to establish this connection  an approach described by smith  is considered  called procedural reflection. 
the main ideas of this approach may be summarized as follows. in procedural reflection  a processor for a language is not regarded as a 'black box'  but is instead definable in terms of a program which describes it. all programs  therefore  are considered to be executed indirectly  by virtue of executing a program that represents the processor. a processor written in the same language 
1
　　only logics where the relation h is recursive are guaranteed to return an answers to arbitrary ask operations. where h is r.e.  but not recursive  answers are in general returned only in the case of a yes. 
it has been designed to implement is called meta-circular: 'meta'  because of the property that the processor operates on formal program fragments  and 'circular'  because an mcp does not  in itself  constitute a definition of the language. 
　the incentive for viewing computation in terms of a tower of mcps is that it allows reflective procedures  written in the same language as the original program  to be included as part of the environment which executes the program. hence  by changing the general description of the processor at level k + 1  for k   1  the underlying program situated at level k can give rise to different processes. for present concerns  the analogous idea is to axiomitize the proof procedure found in the 'black box' at level k  used to carry out inference at level k  as part of the axioms of provability a p k + 1 expressed by lk+1. in fact  the idea is to axiomitize the proof procedure in such a way that the axioms themselves can be interpreted procedurally. hence  inference performed on one level of the tower is viewed as being implemented by the level above. as with procedural reflection  where reflective procedures can be written to augment an mcp  this approach will allow sentences expressed in a metatheory to determine how inference proceeds with respect to a theory. 
   the ideas outlined above appear in various forms for several horn-clause systems   bowen and kowalski 1    gallaire and lasserre 1    davis 1    kramer 1  . the novelty of this approach is the step up to full first-order logic; of particular interest is the fact that negation can be explicitly represented. this is important for control  since negation allows testing for properties that do not hold. it therefore becomes possible to block unwanted properties from entering into a resolution process. also important is that resolution in the system presented is non-clausal. therefore  the sentences used to define the mcp  express control strategies  as well as express the original theories over which these operate  can maintain much of their original form usually lost when everything must be reduced into clausal form. 


tion of a proof procedure. the one adopted combines nc-resolution in a connection graph format. one of the attractive features of these graphs  from the point of view of obtaining an mcp  is that they provide a convenient way of organizing the sentences of a theory. informally  a set of well-formed formulas s can be represented as a connection graph   v  e    where each vertex vi  ε v denotes one of the formulas s  ε 1  and each edge ik ε e  
joining a pair of vertices in v  represents a potential resolvent. the connection graph refinement to robinson's resolution principle was introduced by kowalski . each vertex  therefore  denotes a formula in clausal form  and edges occur between those vertices containing unifiable  complimentary literals. the combination of ncand connection graph resolution is described in  stickel 1 . in this case  v denotes a set of quantifier-free formulas  and e is a set of edges joining vertices of v that contain unifiable atoms of opposite polarity. 
　a resolution step in   v  e   consists of selecting one of the edges ik e e  and forming the resolvent ncr associated with the ends of ik. a new graph   v'e'   is then constructed by adjoining ncr to v  and by including among e the set of edges which ncr is said to 'inherit' from its two parent vertices. 1 it should be noted that there is no a prion constraints on how edges should be selected to obtain a proof  only that they should be selected such that the completeness of the rule is preserved. 
　the previous discussion can be summarized in the form of two meta-language definitions  considered as a partial specification of the mcp: 1 
note that provable defines the overall proof procedure: by way of separate definitions  skolem and initialize-graph describe the addition of the skolemized form of - a to the graph   v  e   leading to the extended graph   v' er  . next  cg-resolve defines the steps involved in a deduction. the definition of select-edge represents the selection of an edge / from the set of edges e. with respect to nc-resolve  the term ncr denotes the nc-resolvent created by resolving on 
the atoms associated with the ends of /. the inclusion of ncr as a new vertex of the graph  mapping v to v  is represented by inherit-node  while the corresponding operation for new edges  mapping e to ef  is represented 
1
　　a property of edge inheritance is that the edge /* used to form the resolvent at each step is removed from the graph. however  since the interest in connection graphs is on the data structure they provide  rather than on defining a new rule of inference  this particular aspect is ignored. 
1 note that quantifiers have been included for readability. 
	lownie 	1 

the single remaining literal  

indicates the start of the deductive process on the graph 
 with respect to the mcp  this process is initiated by a resolution step between this literal and its definition in  ii . 
　the procedural interpretation placed on the mcp definitions corresponds to a form of depth-first search  so a question of completeness arises. in particular  it must be possible for the mcp to interact in a complete way with general object-language theories. search strategies expressed by the mcp are found as part of the definition of select-edge  a sub-definition of cg-resolve. note that e might be regarded in terms of an ordered list or schedule: selecting the first element of e  and inheriting new edges by mapping them onto the front of e  results in depth-first search  dfs . similarly  keeping inheritance the same  and selecting edges from the back of e  results in breath-first search  bfs . 
   in the full tower  each logic li+1  i   1  expresses the provability axioms ap i + 1 by a copy of the mcp. now  the kind of search strategy expressed by the mcp found at a particular level depends on whether resolution is associated with some general theory  or a theory representing another copy of the mcp. by default  all general theories are expressed by l o   and completeness is maintained for them by having the version of select-edge included in l1 satisfy the general strategy of bfs. for the rest of the tower lk  k   1  which by default operate on other copies of the mcp  select-edge in lk satisfies a special form of dfs  corresponding to the proof procedure . 
iv. advancing control 
in this final section  a cursory overview is presented on two extensions to first-order reflective tower outlined in ′1 to allow more specialized forms of control. for a more complete description  the reader is referred to  lownie 1 . 
a- c o n t r o l strategies 
edge schedules are often useful for implementing general domain-independent control strategies such as depthfirst and breadth-first search. however  trying to design more complicated domain-dependent strategies based exclusively on ordering edges in a schedule can be difficult. a more structured approach is to allow control strategies  expressed for a copy of the mcp as part of select-edge v e  /   to index the edges of a graph   v  e   through its set of vertices v. accordingly  the vertices v - ♀ v act in the role of 'goals' within a deduction  while the atoms a* ♀ vi  act in the role of 'sub-goals'. note that an edge / ε e can be described in terms of a 1-tuple: 

where a1 and a1 occur with opposite polarity in v1 and v} respectively  and mgu is a most general unifier that unifies them. a new selection policy  therefore  can be based on indexing through the components of an edge as follows: 
  select  in order  a combination of 

of course  other ways of indexing edges are possible  e.g. selecting two goals followed by two sub-goals. additionally  other structures can be used to extend this approach; for example   i  a 'mini-scheduler' i  to allow control information to be communicated between resolution steps  e.g. in the form of complete edges or various components of edges  and  ii  a 'history' h  providing a record of the resolution steps performed  and used  for example  to implement selective backtracking  or to pursue multiple lines of reasoning. 
b. subsidiary deduction rules 
a subsidiary deduction rule can be described as a property of the meta-theory in the role of an inference rule. for example   stickel 1  presents a general  sound  deductive principle called theory resolution which can be used to test for inconsistency among selected sets of clauses or literals. theory resolution allows specialized procedures to be included alongside general resolution to perform  for example  taxonomic reasoning or reasoning with partial-orders. 


　copies of map1+ are included into the tower by appending its definition as part of ap   for i   1. in terms of upward compatibility in the tower  it is possible to view mop1+ as a rule which can be selected and applied like any other. further consideration in this area involves:  i  a precise description how rules can be applied;  ii  'cross inheritance'  by which new edges for a rule are generated as a result of resolvents created by other rules; and  iii  an updated definition of provable which takes into account the the addition of copies of mcp1+. the details  while lengthy  are mostly straightforward   lownie 1  . 
v. summary 
this paper outlined a reflective architecture for declarative languages  which includes smith's procedural model    as a special case for first-order languages based on murray's nc-resolution rule   . its main contribution over existing approaches is how this leads to various forms of selective control for kb-systems based on  full  first-order logic. 
　several other topics warrant further consideration; for example  implementations which minimize computational overhead incurred by reflective inference by explicitly representing only those parts of the processor required for control. these are left to the later paper   lownie 1  . however  a good reference which can found in this area is  des rivieres and smith 1 . 
acknowledgments 
the author would like to thank  at the university of toronto  hector levesque  jim des rivieres  ray reiter  and john mylopoulos  and at queen's university  peter o'hearn  for their comments and suggestions regarding earlier drafts of this work. 
