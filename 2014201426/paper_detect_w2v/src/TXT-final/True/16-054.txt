 
   this paper describes the main aims of a new research project concerned with the implementation of automatic error recovery facilities in 
industrial robotics. an approach is discussed in which an existing manufacturing work cell is to 
be enhanced by the addition of a task event model contained in an error recovery knowledge base. this paper outlines the main design issues involved in this work. reasons why conventional fault tolerance techniques are inadequate are given and the industrial application is explained. a 
particular approach to sensory monitoring and error diagnosis is described. the proposed system has more similarities with sensory driven expert systems than with body modelling contingency planners. 
	i 	introduction 
a. 	background 
   this research concerns the problem of providing error recovery capabilities in 
industrial robot systems. the long term goal is to define software control mechanisms that will enable a robot to detect error conditions in its working environment and perform corrective actions in order to continue working unattended. the work is directed at industrial applications such as 
machine loading and simple assembly tasks. our interests do not cover hardware errors in the robot or computer systems nor software errors in the control programs. such topics are well covered in the literature on fault tolerance systems l . we assume that the hardware and software are relatively reliable  although we do provide some diagnostic facilities  and only deal with physical errors in the robots task environment. for example  defective components  alignment drift and jammed feeders are some of the common faults that can lead to damaged 
equipment  faulty products or significant plant down-time. 
b. conventional techniques 
the most widely used technique for hardware recovery is that known as backward error recovery 
where the system is restored to an earlier errorfree state by an inbuilt mechanism. such checkpoint and rollback schemes operate quite independently of the nature of the error and so can handle a range of error types. however  despite the attractive simplicity of these methods 
their fixed response often proves inappropriate in robotic applications. this is because backward recovery assumes  a  that processes are reversible and objects are recoverable  and  b  that the system has full control over a well 
defined  i.e. hardware or software  environment. these assumptions do not hold in robotics. 
c. 	the assembly world 
   in computer systems  errors can be defined as either component error or design errors  but in 
the robot assembly world there exists a third type: external errors. these include external 
interference with processes  or components  and 
unexpected events such as breakages and jammed parts. thus our systems must operate with incomplete control over the environment as well as incomplete information. when we list just a few error cases we see ample evidence of this: 
incorrect or defective parts  component errors  faulty feed process  missing part or orientation error  
faulty gripper action  pose error or dropped 
part   
incorrect target placement  collision or position error  
there has been very little previous work that has dealt with these issues  1 . we feel that progress lies in the application of knowledge engineering methods. only when the nature of an error is understood can it be successfully treated. 
d. 	knowledge based recovery 
   we propose a forward recovery approach where operators are applied to transform the error state into one of the error-free states further ahead on the task cycle. this amounts to a kind of corrective feedback. in this situation the recovery agent will need all available information including: 
    a  the actual state of the physical system   b  the desired or expected state   c  current sensory data   d  expected sensory data and  e  details of plausible recovery actions. 
we are building a software system that maintains a knowledge base containing information on the robots' task  the working environment  expected sensory bignals and plausible contingency procedures. 

	ii 	the laboratory test-bed 
   in order to remain faithfull to industrial practice a laboratory rig has been built which 
models an actual commercial application. this consists of a work cell with a unimation puma 1 and a visual inspection station. component recognition algorithms are processed by the autoview vision package  running on an lst 1. a conveyor delivers pipe sections to the work cell which fall onto a light table and are analysed  via a tv camera  by the autoview software. the puma then performs an appropriate action sequence for each pipe type  which normally involves transport to two machining station and 
ejection into an output bin. this is the normal  i.e. error free  task performance. 
   for error sensing  additional sensors have been added to the system. these include proximity and force feedback and special tactile sensing pads inside the gripper jaws. this distribution of 
multi-model sensors permits a range of errors to be deteeted: 
sensor 	errors detected 
proximity collisions  location errors  arm movement monitoring  
arm forces 	obstructions  jammed parts 
 insertion/assembly monitoring  
tactile gripper slip  orientation errors  lost part s 
 component movement monitoring  
vision 	part location  orientation  defects 
 inspection & verification  
   in the original application the puma is controlled by a task program  written in the 
manipulator control language val  which interacts with the visual inspection algorithms. however  in the laboratory the lsi 1 acts as overall supervisor and is able to down-load val programs or even single instructions for the puma to execute. in normal task operation the original val program is executed and so there is no effective difference between the two systems. however  when in recovery mode the supervisory software is able to generate and monitor additional val commands as determined by the prevailing sensory conditions and knowledge of the error event. 
itt error detection 
   obviously  for good quality error detection we will need many sensors. however  errors are rare occurrences and the benefits gained from extensive sensing must be balanced against the icrease in costs and computational overheads. we feel that an effective solution is to design systems with two levels of sensory activity. our system has a low level of sensory monitoring during normal operation but can perform much more extensive processing when required to respond to error situations. we define a sensory signature as a collection of parameters which specify the 
m. lee et al. 1 
limits of acceptability of a sensed signal during a task phase. these can be one dimensional  e.g. insertion force limits  or multi-dimensional  
e.g. visual silhouette measurement tolerances. in either case the signatures are continually tested at set points on the task cycle by a background monitoring process. normally the signatures will be accepted and the task continues. when a signature goes out of range  i.e. a 
 signature interrupt  occurs  the robot is halted and control handed over to the error diagnosis and recovery modules. notice that this recovery software can involve quite disproportionate sensory and computational overheads as the system is effectively in a  down-time  status. 
   although the sensory signatures are relatively simple measures  they will vary considerably  in range and relevance  with task parameters such as component type  movement speed  work space complexity  etc. we use the notion of relevancy by incorporating explicit control information in the task program so that only pertinent signatures 
are used at each stage of the task cycle. thus  the monitoring regime varies dramatically  in scope and quality  over the whole task. the design of signatures and the relevancy controls is very application dependent. for each task the val program is created first and then signatures can be selected  parameterised and entered into a signature data base. 
iv fault diagnosis 
   the second stage of recovery involves an assessment of the nature of the error and the extent of its influence. by systematic analysis of robot action sequences we can build a generic fault tree for use in diagnosis. there are essentially three basic actions which our robot can perform and these can be broken down in terms of their constituent components as follows: 
1. pick up component locate  find a component  
approach  fine movement towards target locat ion  
grasp  acquire component in the gripper  depart  fine movement away from target location  
1. 	transfer component 
 coarse  fast movement between locations  
1. place component approach  fine movement towards target location  
insert 	 fine movement while in physical contact  
ungrasp 	 release component  depart 	 fine movement away from target locat ion  
the  locate action  is not a robot function but refers to the action of either part feeders  implicit location data  or sensors  explicit location data . 

1 m. lee et al. 
   now by examining each of these atomic actions in turn we obtain a tree of error states and their 
relationships. 
pick up for example:-location error 
approach error 
grasp error 
depart error feeder empty or jammed part defective part orientation error collision with part 
missed part 
collision with workspace 
no part several parts orientation error part location error gripper slip 
obstruction part error grasp error workspace error this is only a sample of the full tree: there are further levels and more detailed expansion. by using the concept of an  atomic action  we have produced a detailed analysis for each 
manipulator movement axis . these trees illustrate the inherent structure in the error states and their causes. if we have knowledge of the current action and sensory data then  from the tree  we can infer plausible error causes. several iterations may be required  involving requests for selective sensory data. 
v knowledge base design 
   the ideal knowledge base for a robot would contain geometric data in a body modelling system 
which could represent the exact physical structure of the workspace and the objects. 	by using computational geometry and extensive high powered sensing the system would deal with contingencies by generating its own recovery plans . 	however  while research is active on these topics  such object level systems are not yet 
well developed and will be very complex and expensive. 
   our aim is more modest: to develop a knowledge base of actions and events in terms of the task descriptions used in existing manipulator languages. this is more a task event model than a body modelling system. the original task specification consists only of a sequence of val instructions  our final specification will have several parallel levels of ancillary knowledge cross-referenced into the val program. this 
multi-layered approach is a key feature of successful knowledge bases . our current levels are as follows: 
task level - val program  manipulation cycle of actions and tests . 
world level - knowledge of objects in environment. 
action level - preconditions  actions  effects and results. 
diagnostic level - sensory interrogation procedures. 
recovery level - parameterised recovery schemas. 
   other levels being examined include a user level  performance level and a meta strategy level. 
   our current activities are directed at-knowledge representation  frames and/or production rules   properties of objects and events  e.g. reversability   and the separation of generic diagnosis and fault data from application specific data. the next stage will be to implement and test our design in the application framework. 
acknowledgements 
we are grateful for the support of british robotic systems ltd. and the s.e.r.c. through grant gr/b/1. 
