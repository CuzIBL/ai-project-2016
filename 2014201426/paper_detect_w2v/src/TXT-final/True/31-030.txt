 
many real-world problems  such as air-traffic control and factory scheduling  require that a sequence of decisions be made in real time. the real-time constraint means that we typically do not have sufficient time to find a complete solution to the problem using traditional methods before we must commit to a decision. we propose an incremental search approach to making real-time  sequential decisions  and then present a new decision method called k-best  which is both an extension of an existing realtime decision method  minimin  and an approximation to a decision-theoretic approach to the real-time decision problem. we next provide an analytical bound on the worst-case expected error when k-best is used instead of the optimal decision method. the averagecase performance of k-best is then compared to minimin on a set of randomly generated problems. our results show that k-best is an improvement over minimin  although minimin performs quite well. given that minimin is very efficient and easy to implement  we conclude that it should be the algorithm of choice for many real-time decision problems. 
1 introduction 
one example of real-time decision making is factory scheduling when the objective is to keep a bottleneck resource busy. in this case  the amount of time available to decide which job should be processed next is limited by the time required for the bottleneck resource to process the current job. once a new job is scheduled  the time until the new job finishes processing can be used to decide on the next job. in general  this class of problems requires the problem solver to incrementally generate a sequence of time-limited decisions. this consists of three sub-parts: gathering information  e.g.  what jobs need to be processed   deciding when to stop gathering information  i.e.  what the decision deadline is   and making a decision based on the available information  e.g.  what job to process next . for this paper  we have focussed on the last question  namely how to make decisions based on a partially explored problem space. we first summarize the incremental search approach to real-time decision making based on searching a random decision tree with limited computation time. we next define the last incremental decision problem and develop the necessary steps for making an optimal incremental decision. we then argue that this approach is impractical due to the size and complexity of the equations needed to express the expected value. next  we present and analyze k-best  which is both an approximation to the optimal decision method and also an extension of minimin. we present experimental results that compare the performance of minimin and k-best on randomly generated problems. finally  we discuss related work and conclusions. 
1 a real-time decision problem 
real-time decision making can be modeled as searching a problem-space tree with a finite amount of computation. in this model  each node of the tree corresponds to a decision point  and the edges emanating from a node correspond to the choices  operators or actions  available for the decision at that node. each edge has a cost or penalty that the problem solver will incur if it chooses to execute the action associated with that edge. the node cost x  is the sum of the edge costs along the path from the root to node x. an example random tree is shown in figure 1. the objective is to reach a lowest-cost leaf node given the computational constraints. the more general problem of finding the minimum-cost leaf node in a random-tree has been studied in depth  see  zhang and korf  1  for a summary . in general  the task of finding a minimum-cost leaf node typically requires computation that is exponential in the tree depth. for real-time search  there is not sufficient time to find an optimal solution  so we must consider search methods that satisfy the real-time constraint. 
　we model the real-time constraint as a constant number of node generations allowed per decision. this is equivalent to having a deadline for each decision. we assume that the problem solver gathers information by expanding nodes  exploration  until the time available runs out  after which it chooses one of the children of the current root node as the new root node  decision making . this process is repeated  incrementally generating a complete solution. 
pemberton 
figure 1: example of a random tree problem. 
1 the incremental decision problem 
we begin by describing the last incremental decision problem  which is a simplified version of the general incremental decision problem. an example of a last incremental decision problem is shown in figure 1. in this figure  the black edge costs  are known  
and the grey edge costs  z1 ...  z1  are independently chosen at random from a known distribution. the decision task is to choose a child of the current root node so that the expected cost of a complete root-to-leaf path is minimized. after we choose a child of the current root node  then we can expand the frontier nodes below that child  and learn the remaining edge costs in the chosen subtree  before making the remaining decisions. the last incremental decision problem is basically a choice between a set of partially explored subtrees in which we will subsequently execute a sequence of optimal decisions. 
　the general incremental decision problem is just an extension of the last incremental decision problem to an arbitrary number of decisions. the main advantage of studying the last incremental decision problem over the general incremental decision problem is that we know that the remainder of the tree will be explored after the decision is made. this means that the distribution of minimum-cost paths that will be traversed below a given child of the root node is the same as the distribution of minimum-cost paths in the tree below that child  independent of the decision and exploration methods. this is why we have focussed our efforts on the last incremental decision problem. 
1 making a last incremental decision 
consider the last incremental decision problem shown in figure 1. the top two levels have been explored  and the bottom level of the tree  the gray edges and nodes  has not been explored. at this point  we must choose between nodes b1 and b1. we know that the remaining edge costs are chosen independently from a uniform distribution over  1   and that once we make a choice  we will be able to explore the remaining edge costs in the chosen subtree before making any additional decisions. the reader is encouraged to stop and answer the following question: should we move to node b1 or node b1  the obvious answer to this question is to move toward b  because it is the first step toward the lowest-cost 
frontier node  this de-
1 	automated reasoning 
figure 1: example of the last incremental decision problem. which node is a better decision  b1 or b1  
cision strategy  which is called minimin decision making in  korf  1   or simply minimin   has been employed by others for single-agent search  e.g.   russell and wefald  1l    and is also a special case of the two-player minimax decision rule  shannon  1 . 
　in fact  the optimal decision is to move to node b1 because it has a lower expected minimum root-to-leaf path cost. the expected minimum root-to-leaf path cost  or simply expected minimum path cost  through either b1 or b1 is the equal to the edge cost between the root and the child node plus the expected cost of the path that will be traversed after the remaining edge costs are learned. to make an optimal last incremental decision  and to show that b1 is the better decision in our example   we must calculate the expected minimum path cost through both children of the root node given the edge costs in the explored tree and the edge-cost distribution for the unexplored edges. 
　in order to calculate the expected minimum path cost for a child of the root node  we need to first calculate the distribution of minimum path costs for that child node. in general  the problem of calculating the distribution for a minimum-cost path from a child of the root node to a leaf node can be broken down into two steps. the first step is to determine the distribution for a minimum-cost path from a frontier node to a leaf in the tree. the second step is to combine the frontier node completion-cost distributions with the known edge costs in the explored search tree. 
　for node c  in figure 1  there is one unexplored level between the frontier node  c1  and the leaf nodes below it. the cumulative distribution can be calculated as follows is the edge-cost distribution . we assume that the edge-cost distributions are independent. 

　given the distribution for a minimum-cost path from a frontier node to a leaf node  the second step is to calculate the expected minimum path cost through a child 

of the root node. this involves constructing a piecewise combination of the frontier-node minimum-pathcost cumulative-distribution functions  cdf's . figure 
1 shows the cdf's for frontier nodes  as 
well as the combined cdf for node b  for two different relative values of y1 and 
	. 	. 	. 
　finally  the cumulative-distribution functions for the children of the root node  i.e.  b1 and b1  are differentiated to yield the probability density functions  pdf's  for minimum path cost through these nodes. these pdf's are then used to calculate the expected minimum path costs through each child of the root by integrating over the range of possible root-to-leaf path costs. the optimal last incremental decision is then to move to the child with the lowest expected minimum path cost. 
　we can now return to the example in figure 1. if we assume without loss of generality that then the equation for the expected cost of a complete path through node b1 is: 
an analogous equation applies for node b1. substituting the edge costs from figure 1 into equation 
1  we get e min.path.cost bi   - 1  whereas e min-path-cost b1   = 1. thus node b1 is the optimal decision for this example. intuitively  a move to node b1 relies on either having a low cost  whereas a move to b1 has four chances and z1  for a low final edge cost. thus  an optimal last incremental decision is a move toward the child node with the lowest expected root-to-leaf path cost that will be traversed after the incremental decision is made and the remaining edge costs are learned. 
　in general  finding an optimal last incremental decision is impractical for all but a few small search trees. the difficulty comes from the fact that the distribution of minimum path costs through a child of the root can have a distinct distribution function for each frontier node in the child node's subtree. for example  consider the graph and tree shown in figure 1. this tree has one more frontier node under b1 than our original example  figure 1 . the graph shows the cumulative distribution of minimum root-to-leaf path costs through nodes c1  c1  c1  and b1 versus the cost of a path to a leaf node. we observe that each of the three frontier nodes under b  is responsible for a change to the minimum-path-cost distribution for b1  fcc b1  - for example  the change in the distribution at  is due to the fact that at first every minimum-cost path through b1 must also pass through c1. once the minimum path cost is greater than or equal to then a minimum-cost path below b1 can be through either   this additional choice causes a sharp rise in the cumulative distribution function for  as shown in the graph. since the number of frontier nodes in each subtree is exponential in the search depth  in the worst case the number of different functions needed to describe the minimumpath-cost distribution is also exponential in the search depth. this is why calculating the expected minimum root-to-leaf path cost and consequently making an optimal last incremental decision is only possible for a set of small search trees. 
　thus far  we have presented two disparate incremental decision methods: minimin  which is easy to calculate but makes suboptimal decisions  and the optimal decision strategy  which only works on small search trees. in the next section  we present a new decision method that bridges the gap between minimin and the optimal decision method. 
pembert1n 

1 	k-best: 	a new incremental decision 
algorithm 
k-best is a new algorithm for making incremental decisions. it operates by maintaining a list of the k-best frontier nodes under each child of the root node as the subtrees are explored. these k-best frontier node costs are then used to calculate an approximation of the expected minimum root-to-leaf path cost for each child of the of node. the approximation is calculated by assuming that the child's subtree only contains the k-best frontier nodes. the k-best decision is simply to move to the child with the lowest k-best estimate of the expected minimum root-to-leaf path cost. 
　consider again the tree shown in figure 1b. first  we observe that the the lowest-cost leaf node  c1  under a given child of the root node has the greatest effect on the distribution of minimum-cost paths through that child because it determines the starting point of the minimum-path-cost distribution  i.e.  fcc b1  initially equals fcc c1  because c  is the lowest cost frontier node . the next largest effect is due to the location of the second-best frontier node  c1  in a child's subtree  and the size of the effect diminishes as we approach the highest-cost frontier node. for example  when the minimum root-to-leaf path cost through b  becomes greater than or equal to x1 + y1  then the distribution of minimum path costs for b1 shifts to a new function that combines the distributions of minimum path costs through c1 and c1. when the minimum path cost through b  is greater than or equal to x1 + y1  then the minimumpath-cost distribution for b1 shifts again to reflect the third frontier node  although the size of the second shift is much smaller than the first shift. in fact  it is often the case that the higher-cost frontier nodes under a given child node do not contribute at all to the distribution of minimum-cost path through that child because 
1 	automated reasoning 
their node cost exceeds the minimum frontier-node cost by more than the maximum possible edge cost. 
　k-best takes advantage of this observation by simply ignoring all but the k-best frontier node costs below each child of the root node. to make k-best tractable  we simply choose a value for k that is small enough so that we can calculate the expected minimum-path-cost equation. when k = 1  k-best and minimin will make the same decisions  up to tie-breaking . alternatively  when the number of frontier nodes in each subtree is less than or equal to k  then k-best makes optimal last incremental decisions. thus k-best defines a continuum of decision algorithms between minimin and the optimal decision method. 
　the obvious question at this point is what is the cost in terms of solution quality of this approximation  the worst-case expected error for a k-best decision occurs when k-best chooses a decision that only has k good frontier nodes  and all the frontier nodes below the decision that wasn't chosen by k-best are good  in the sense that their node costs are very close to  or perhaps equal to  the minimum frontier-node cost. this is the situation where the optimal incremental decision has greatest potential advantage over k-best. an example of this situation is shown in figure 1  where e is a small constant. 
　for this example  the k-leftmost frontier nodes all have cost x  which is the minimum frontier-node cost  and the other m - k frontier nodes below node b1 have node costs equal to x + 1  which is equal to the minimum frontier-node cost plus the maximum edge cost. this means that only these k minimum-cost frontier nodes can contribute to the expected minimum path cost below b1. we assume that there are m frontier nodes below b1  all of which have a node cost equal to x +e. we also assume that there is one remaining unexplored level of the tree and that the branching factor in this level is b. 
　the expected error of a k-best decision is simply the difference between the expected minimum path cost below the k-best decision  b1   and the expected minimum path cost below the optimal decision  b1 - for simplicity  we assume that the unexplored edge costs are independently chosen from a uniform distribution over the range  1  . since the k minimum-cost frontier nodes are the only frontier nodes that can appear on a minimum-cost path below b1 the expected minimum path cost below b1 is equal to x plus the expected cost of a minimum choice between kb random edge costs. for this edge-cost distribution  the expected cost of a minimum choice between kb random edge costs is l/ kb + 1 . 
　in order to calculate the expected minimum path cost below b1  we simply observe that the optimal decision after moving to b1 will be a choice between mb edge costs added to one of the m frontier nodes that have cost x + e. for this edge-cost distribution  the expected value of mb random choices is l/ mb-f 1 . thus the expected minimum path cost below b1 is x 1+ e +1 / mb +1 . 
　the worst-case expected error for a k-best decision  on this example problem  is simply the difference between these two expected minimum path costs. in the limit as m goes to infinity and e goes to zero  this difference approaches l/ kb- -1   which is the expected completion cost for the path below a set of k minimum-cost frontier node. this make sense  because as the number of frontier nodes below b1 increases  it becomes more likely that a zero-cost edge will be generated. 
　thus the worst-case expected error for k-best on a last incremental decision problem is bounded by the expected cost of a choice between kb unexplored edges. this expected-cost bound is a decreasing function of k. in addition  the amount of information that can be gained as k is increased is also a decreasing function of k. intuitively  it seems reasonable that the most important piece of information about a root-child decision subtree is the minimum frontier-node cost  and the second most important piece of information is the second smallest frontier-node cost  etc. 
figure 1: average minimin %error minus average 1best %error versus average node generations  b - 1 . 
1 experimental comparison of k-best and m i n i m i n 
in order to compare the average case performance of kbest and minimin  we performed a set of experiments on random trees with fixed branching factor  and with edge costs that are independently chosen from the set 
	a value of 1 was 
chosen for k to make the k-best equations manageable. for each trial  random values were assigned to each edge of the problem-space tree  and then both minimin and 1-best were allowed to explore the problem space using a depth-first branch-and-bound exploration up to one level above the bottom of the problem-space tree. this is a last incremental decision problem with one unexplored level. after the minimin and 1-best decisions were calculated  the remainder of the tree was explored in order to optimally complete both paths. in addition to the 1-best and minimin path costs  we also calculated the optimal path cost in the completely explored problemspace tree. we then recorded the percent solution-cost error  calculated as follows. 

we also compared the solution cost of the two algorithms  and recorded the number of times that each algorithm produced a lower-cost solution. 
　the graph in figure 1 shows the difference in average solution cost error for minimin and 1-best. the vertical axis is the difference between the average minimin percent solution-cost error and the average 1-best solution-cost error  whereas the horizontal axis is the average generations used per decision for search depths ranging from 1 to 1. each data point is an average of 1 trials  and the vertical line at each point indicates the 1% confidence interval. the results show 
pembert1n 

aged over 1 trials  and show that as the number of decisions increases  i.e.  the tree depth   the percentage of the trials that each algorithm wins initially grows. 

1 	making a series of decisions 
up to this point we have only considered the last incremental decision problem. we have also applied our k-best algorithm to the problem of making a series of incremental decisions. for a sequence of decisions  we can't guarantee that we will be able to see the bottom of the problem-space tree before the next decision  and thus the completion-cost distribution that we developed for the last incremental decision problem no longer accurately reflects the situation that will exist for the next decision. instead  the distribution of minimum-cost paths that might be traversed below a frontier node will depend on the decision-making algorithm  the exploration algorithm  as well as the factors that affect the last incremental decision. for these reasons  and the fact that an optimal solution to the general incremental decision problem will be at least as complicated as the optimal last incremental decision problem  we have assumed that it is reasonable to model the general incremental decision problem as if it were a last incremental decision problem with one additional level of unexplored problem-space tree below the bottom of the search tree. 
　to compare minimin and k-best on a series of decisions  we performed a new set of experiments where we fixed the search depth of the branch-and-bound exploration and increased the number of incremental decisions  i.e.  the depth of the tree . figure 1 shows the percent wins  minimin against 1-best  versus the log of the tree depth for a fixed search depth of 1 on a binary tree  with 1% confidence intervals . the results are aver-
1 	automated reasoning 
this makes sense because the number of opportunities for the algorithms to make a different choice increases with the number of decisions. what we didn't expect is that for more than about 1 decisions  the percentage of the trials in which k-best produces a lower-cost solution than minimin continues to grow  at the expense of the percentage of the trials in which minimin produces a lower-cost solution. this result clearly shows that k-best makes better quality decision on average than minimin. 
1 	related work 
the results presented here is an extension of our previous work reported in  pemberton and korf  1 . our initial work was motivated by mutchler's analysis of how to spend scarce search resources to find a complete solution path  mutchler  1 . our work is also related to russell and wefald's work on dta*  russell and wefald  1   although they have not directly addressed the last incremental decision problem. eric horvitz  horvitz  1  has also investigated the problem of reasoning under resource constraints  which he called flexible computation. the minimin decision method was initially employed by rta*  korf  1  and is a special case of the minimax decision rule that is widely used in game tree evaluation  shannon  1 . 
　the main difference between anytime algorithms  dean and boddy  1  and our real-time incremental search algorithms is that anytime algorithms address what we refer to as the complete solution problem  whereas we have focussed on the incremental decisionmaking problem. for example  in the random tree 

model  an anytime algorithm would generate a complete root-to-leaf path  whereas to-best focuses its attention on improving the quality of the next decision. thus  instead of generating a complete root-to-leaf path all at once  tobest generates the root-to-leaf path one step at a time  while interleaving computation and execution. 
　in some sense  we can view the computation for each incremental decision as an anytime decision problem. thus the difference between incremental search algorithms and anytime algorithms is in the way that the real-time search problem is formulated. anytime algorithms try to find the best complete solution under a time constraint  whereas real-time incremental search algorithms try to find the best next decision under a time constraint. 
1 	conclusions 
we have presented to-best  which is a new method for making incremental search decisions. we have shown that the expected error of to-best on the last incremental decision problem with one unexplored level remaining is at most equal to the expected cost of the minimum of kb random edge costs  where k is the number of frontier nodes considered  and 1 is the branching factor of the nodes in the unexplored level of the tree  tobest is both an approximation of the optimal decision method  and an extension of minimin. our experimental results show that to-best decisions are slightly better quality than minimin decisions on average  and that this improvement does add up over long sequences of decisions. since minimin is easy to implement  and is typically very efficient to execute  we recommend it as the first choice for real-time incremental decision problems. when the resource constraint is on the depth of the search rather than the time spent searching  e.g.  limited sensor range  unknown future job-scheduling requirements   then to-best provides a useful way to incorporate additional information about future decisions in order to improve the overall quality of the decision sequence. 
 horvitz  1  eric j. horvitz. computation and action under bounded resources. phd thesis  stanford university  december 1. 
 korf  1  richard e. korf. real-time heuristic search. artificial intelligence  1-1 :1  march 1. 
 mutchler  1  david mutchler. optimal allocation of very limited search resources. in proceedings  fifth national conference on artificial intelligence  aaai1   philadelphia  pa  pages 1  palo alto  ca  1. 
 pemberton and korf  1  joseph c. pemberton and richard e. korf. incremental search algorithms for real-time decision making. in proceedings  second international conference on artificial intelligence planning systems  aips-1   pages 1  1. 
 russell and wefald  1l  stuart russell and eric wefald. do the right thing. mit press  cambridge  ma  1. 
 shannon  1  c. e. shannon. programming a computer for playing chess. philosophical magazine  1 :1  1. 
 zhang and korf  1  weixiong zhang and richard e. korf. performance of linear-space search algorithms. to appear in artificial intelligence  1. 

acknowledgements 
this research was supported by nsf grant #iri-
1  the air force office of scientific research under contract 1  arpa/rome labs under contracts f1-c-1 and f1-c-1  a grant from 
rockwell international  and an equipment grant from hewlett-packard. we would like to acknowledge helpful discussions with rich korf  weixiong zhang  and the members of cirl. thanks to william cheng for tgif  david harrison for xgraph  and the free software foundation for gcc  gdb  and gnuemacs. 
