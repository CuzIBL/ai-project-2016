 
struct is a system that learns structural decision trees from positive and negative examples. the algorithm uses a modification of pagallo and haussler's fringe algorithm to construct new features in a first-order representation. experiments compare the effects of different hypothesis evaluation strategies  domain representation  and feature construction. struct is also compared with quinlan's foil on two domains. the results show that a modified fringe algorithm improves accuracy  but that it is sensitive to the distribution of the examples. 
1 	introduction 
structural learning  also known as relational learning  has a long if not prominent history in machine learning. like attribute-value concept learners  structural concept learners try to induce a description of a concept from positive and negative examples of the concept. structural concept learners differ in using a more expressive first-order predicate calculus representation for their hypotheses. 
   one of the reasons for the unpopularity of structural learning is the problems posed by learning in a firstorder representation. examples are described in terms of objects and the relationships among them; hypotheses may include existentially quantified variables. the ability to quantify over objects adds a great deal of expressive power to the representation. however  even matching a hypothesis to an example is an np-complete problem  haussler  1 . 
   recently  the advantages of a first-order representation have motivated further research into learning in this hypothesis language. foil  quinlan  1a  kate  manago  1   are some recent systems that can learn structural concepts. 
   this paper introduces a system  struct  that learns structural concepts from positive and negative examples. struct integrates and extends previous work 
   *this research was supported in part by nsf grant ir1. 
1 	learning and knowledge acquisition 
larry rendell 
beckman institute and 
dept. of computer science 
university of illinois urbana  il 1 
in structural and attribute-value machine learning research. from kate it borrows the use of decision trees to learn structural concepts. from foil it borrows the approach and several techniques. from fringe  pagallo and haussler  1  it borrows the iterative  adaptive feature construction algorithm to produce more concise  accurate  decision trees. from induce  dietterich and michalski  1  it borrows the representation of examples. 
   the main purpose of this paper is to explore how these different techniques can be integrated into a structural concept learning system. in addition  this paper describes the results of empirically evaluating several of these refinements. 
   the paper is organized as follows. first  we describe related research in section 1. the algorithm is described in section 1. next  we describe some experiments in structural domains and discuss the results of these experiments. section 1 presents the conclusions of this research. 
1 related work 
in this section  we review systems that use an information-theoretic approach to learning disjunctive structural descriptions. there are many systems that use other approaches  or address different problems in structural learning. some of these systems are described in  kodratoff and ganascia  1; iba et a/.  1; muggleton  1 . 
1 	separate-and-conquer 
separate-and-conquer algorithms for structural domains  also known as covering algorithms  try to find a dnf description of a concept by iteratively generating disjuncts that cover some of the positive examples while excluding the negative examples. 
   an early application of this algorithm to structural domains is induce  dietterich and michalski  1 . induce generates disjuncts by constructing a cover from from the literals of one positive example  called the seed. 
   quinlan's more recent foil  1; 1  differs from induce in a number of ways. first  it uses a tuplebased learning paradigm  as opposed to an examplebased learning paradigm. second  foil does not restrict the cover to use literals from a seed but searches 
the entire space of literals. we refer to this as full-width search  because all one-step specializations are considered as candidates. however  having evaluated the candidates  foil commits itself to one particular choice and discards the other candidates. in contrast  induce chooses a subset of the candidates for specialization. third  induce uses a general user definable evaluation function  whereas foil's information-theoretic evaluation function is an integral part of the system. 
¡¡another recent separate-and-conquer algorithm for learning structural descriptions is pazzani and kibler's  focl algorithm. focl uses a form of typed logic with sortal and semantic constraints to reduce the number of literals considered for inclusion in the cover. this improves efficiency and accuracy. focl can also use incomplete and incorrect background knowledge to aid induction  and an iterative-widening search to find a cover for the examples. 
1 	divide-and-conquer 
although divide-and-conquer algorithms  also known as decision tree inducers  have been widely used in attribute-value domains  until recently few systems have used this strategy in structural domains. bergadano and giordana's  ml-smart system uses a specialization tree approach that uses heuristics and domain knowledge to drive induction. manago's  kate is a decision-tree algorithm that uses an object-oriented frame language equivalent to first-order predicate calculus. kate makes extensive use of the structure provided by the object hierarchy and heuristics to control the generation of literals considered as branch tests. this system has a strong bias against introducing new existentially quantified variables into the description  unlike foil which favors introducing new variables. later  we discuss an experiment comparing the two strategies. man ago has also used induce's partial-star algorithm as a feature construction algorithm for kate. 
1 	adaptive feature construction 
like foil  pagallo and haussler's  fringe uses a tuple-based learning paradigm  but unlike the structureoriented systems  fringe uses the tuples simply as examples for atribute-based leaning. fringe also differs from induce  foil  focl  kate  and ml-smart in that fringe accepts only the training examples  no other knowledge. nevertheless  fringe and its successors symmetric fringe  pagallo  1  and dcfringe  yang et al.  1  have been shown to improve accuracy. these algorithms learn structure in the form of new features constructed as more and more complex conjunctions and disjunctions of the original attributes. the scheme is to perform iterative feature construction at the leaves of successive decision trees output by an id1like algorithm. extensions of the fringe method have been tested by matheus  which do not restrict constructions to the fringe nodes  also see yang et al.  1 . 
1 	struct 
our system learns structural decision trees from positive and negative examples. 
databases: 
db1 = 
father christopher  arthur   father christopher  victoria   mother penelope  arthur   mother penelope  victoria   brother arthur  victoria   sister victoria  arthur   son arthur  christopher   son arthur  penelope   daughter victoria  christopher   daughter victoria  penelope   husband  christopher  penelope   wife  penelope  christopher . 
train: 
father christophcr  arthur  :- dbl 
       -father victoria  arthur  :- dbl classes: 
father x  y  
figure 1: input for struct. 
1 	representation 
struct represents relations as horn clauses. a horn clause can be viewed as a logical implication  where the consequent consists of a single literal  called the head of the horn clause  and the antecedent consists of zero or more literals  called the body of the horn clause. this representation of examples is similar to the inductive assertions used in induce. in contrast  foil learns a relation from positive and negative tuples of a relation. the following shows the input for struct: the databases section defines zero or more dcitabases that can be referenced by examples. examples are horn clauses  whose antecedent may be an explicit list of literals or a reference to a database. the classes section defines the classes that are to be included in the decision tree. unifying the head of the training examples with the class literal yields the signed substitutions: 
	+ : 	{ christopher/x   arthur/y   
 - : {   v i c t o r i a / x       a r t h u r / y   } where the sign of the substitution indicates whether 
one of the literals was negated before unifying. in contrast  foil would be given the tuples 
	+ :  christopher  	arthur  
	-:  victoria  	arthur  
   which are isomorphic to the substitutions constructed by struct. the classes may be followed by a test section giving the test set. 
¡¡the ability of struct to store data in multiple databases rather than one global database can make induction more efficient. information that is not relevant to an example can be ignored when learning from that example. if this kind of relevance information is not available  all the data can still be stored in a single database. 
¡¡struct also represents knowledge in the form of horn clauses. this knowledge may be prior knowledge given to the system or a constructed feature. before constructing the decision tree  struct computes the 
watanabe and rendell 

create tree  class  examples  
- create a node root labelled by the literal class. 
- select the subset of examples whose head unifies with class or -*class 
- recursivesplit root  
recursivcsplit  node  
if all training examples at node are positive or negative examples  label node with pos or neg. 
else 
- select a test based on one literal 
- label node with the literal 
- create child nodes  left and right 
- place the examples that match node at left and the others at right 
- recursivc split left  
- recursivesplit  right  
figure 1: recursive splitting algorithm. 
deductive closure of the body of each example  and replaces the body with the closure. this form of logical constructive induction has previously been implemented in induce. 
1 structural decision trees 
in this section we describe the decision tree formed by struct and how it is used to classify examples. struct learns a boolean decision tree as shown in figure 1. the decision tree algorithm is modified to handle structural descriptions by associating a horn clause with each of the nodes of the tree  and sld-resolution is used as the match procedure. the clause associated with a node is defined by the following mapping. let nodeo  ... noden be the nodes along the path from the root to node nodcn. define li  to be the literal labeling node nodei if nodei is the left child of node.i-.1 otherwise its negation. then the clause  is associated with node noden. the node noden matches an example if the head of the example can be derived with sld-resolution from the above clause and the literals in the body of the example. 
1 generating literals for branch tests 
in this section  we first review foil's method for generating literals for branch tests  then compare its method to struct's method. 
¡¡foil generates the literals used as tests using the following procedure: if the clause associated with the current node is 	then a new literal of form 	or can be added to the clause  where xi's 
are existing variables  the vi's are existing or new variables  and q is some relation. the entire space of these literals is searched with the following exceptions: 
  literals may be pruned 
  the literal must contain at least one existing variable 
  the literal must satisfy some constraints designed to avoid problematic recursion. 
1 	learning and knowledge acquisition 
¡¡in contrast  struct generates the literals used as tests using the following procedure: if the current node is current  the parent of current is parent  the clause associated with parent is 
is a substitution that matches the current node to an example  	is a literal in the example  and then 	is a 
candidate literal for partitioning current. struct also considers all candidate literals of form  where xi's are variables in the clause associated with parent. 
the entire space of these literals is searched with the following exceptions: 
  the literal must contain at least one variable from parent 
  the literal must satisfy constraints to avoid prob-lematic recursion. 
¡¡pazzani and kibler  analyze the complexity of foil's approach  and describe how sortal and semantic constraints are incorporated into their system  focl. the complexity of foil's strategy  without pruning  is approximately  n + k - 1    where n is the number of old variables in the clause  and k is the arity of the predicate in the new literal. this must be repeated for each predicate and each generated literal must be matched against the examples  so the cost of generating and choosing a literal for a node is upper bounded by t ¡ö p -  n + k: - 1    where t is the number of tuples covered by the current clause  and p is the number of predicates. quinlan reports that pruning results in a dramatic improvement in the efficiency of the algorithm. 
struct's strategy is comparable in complexity to 
foil. the number of substitutions is the same as the number of tuples in quinlan's formalism. the cost of generating and choosing a literal is upper bounded by  where t is the number of matches of 
the parent node to the examples  / is the number of literals  and v is the maximum number of variables that are bound to the the same constant in any substitition. 
1 	evaluating literals 
struct uses the following evaluation function to evaluate candidate literals. let s be the set of examples at a node  x a literal  sx the subset of s that matches x  and sx  y the subset of sx that belongs to class y. then the evaluation function gives x the value: 

¡¡maximizing this evaluation function is equivalent maximizing information gain  quinlan  1 . foll's evaluation function sums over the tuples covered by the new clause  and is therefore asymmetric. the above evaluation function sums over both the matched and unmatched examples  not tuples . 
¡¡foil gives a small credit to a literal that introduces new variables. struct may give either a small reward or penalty  for each new variable in a literal. in our experimental section  we compare the effects of the reward and penalty strategies on the accuracy of the learned concepts. 

1. delete all instances of the relation to be learned from the database. 
1. as the decision tree is constructed  whenever a leaf node is created  add the literals in the heads of the examples at the leaf nodes to the database. 
figure 1: recursive learning strategy. 
1 	recursive definitions 
one issue that faces structural learners is the problem of recursive definitions. quinlan  proposes a partial ordering strategy that can eliminate some  but not all  of the problematic recursion. 
¡¡the problem arises because instances of the relation being learned are in the knowledge base. clearly  the relation itself is the best feature for splitting the positive and negative examples; i.e. 

¡¡perfectly splits the tree. but there is an implicit requirement on the learning system that it be able to classify future examples without knowing the same kind of information that is available to it during training  namely the classification of the example. 
¡¡one possible approach to this problem is to explicitly remove from the database information that the decision tree is supposed to learn  unless the decision tree has already learned it  see figure 1 . struct currently does not implement this procedure  but it avoids adding new literals with the same predicate and variables as the head of the clause. struct also has a non-recursive mode  where definitions are may not add literals with the same predicate as the one being learned. 
¡¡a second problem that can arise is an infinite regression during induction. for example  suppose the description associated with the current node is q  - p x  y  z  and the literal to be added is  the new definition matches exactly the same set of examples  and the system may continue to add another alphabetic variant of the literal indefinitely: 

¡¡to avoid this problem  struct forms co-designation constraints on the possible bindings of a literal. these arc created for every pair of literals li  and lj  where 
  lj is a new literal that has just been added to the definition 
  li is a literal with the same predicate as lj. 
  the j-th argument of lj is either a new variable  or is the same variable as the j-th argument of li . 
¡¡the constraint on unification of lj is defined as follows: let y1 ... yn be the new variables in lj  and x1 ... xn be the variables in li at the corresponding argument positions. then y1  x1 ... yn  xn are added as co-designation constraints on unification of lj. 
¡¡these co-designation constraints prevent the inductive recursion that sometimes occurred in earlier versions of struct. 
find-featurel {leaf  
let lp be the literal at the parent node of leaf 
let lg be the literal at the grandparent node of leaf if leaf is to the left of its parent else  

if leaf is to the left of its grandparent else  
¡¡¡¡return  where xi are the variables from the unnegated literals in lo  l  and p is a new predicate. fmd-feature1 /ea/  
let lr be the literal at the root of the tree 
let  be the feature returned by find-featurel  leaf . 
return  with guard lr 
figure 1: feature construction algorithm. 
1 	feature construction 
one problem with decision trees as a representation scheme is that dnf concepts cannot be represented concisely. representing a dnf concept as a decision tree may require replicating many parts of each disjunct in different branches of the tree. pagallo and haussler  call this the replication problem  and propose an adaptive  iterative feature construction algorthm  fringe  as a solution to this problem. 
   pagallo and haussler have conducted experiments with fringe in random and real-world domains. in the random domain experiments  fringe produced more concise and more accurate decision trees for small dnf. in the real-world domain experiments  fringe produced decision trees that were at least as accurate and more concise. in struct  we investigated a modification of the fringe algorithm for a structural decision tree. the algorithm is essentially the same as fringe  with a few changes to handle variables. the algorithm begins with the initial set of relations  and constructs a decision tree as described in the previous sections. next  a find-features procedure generates a new set of relation definitions by examining the fringe of the tree  by calling find-feature j for each leaf in the tree at depth  1  see figure 1 . 
¡¡we also implemented a variant of find-features  motivated by the following considerations. in the original 
find-features  the variables in literals at the fringe of the tree are usually bound by literals higher in the tree. however  the bindings are lost when the fringe literals are made into an independent feature. thus  the feature tends to be overly general if the literal is unnegated  or overly specific if the literal is negated. 
¡¡an additional source of potential problems is that the literal in the head of the example contains information that is ignored during feature construction. however  this literal cannot be added to the body of a feature 
watanabe and rendell 

definition because it matches literals in the head of an example  not the body. accordingly  we modified the rule representation and matching algorithm to handle guard literals. these literals must match the head of an example as a precondition of the rule. 
   the find-features procedure constructs new relation definitions. the new relation definitions are added to the knowledge base  in the form of horn clauses. old relation definitions are removed from the knowledge base if they define a relation that is not in the decision tree  and are not necessary for computing a relation that is in the decision tree. this method of feature pruning is pagallo's keep used last method. the examples are replaced by the deductive closure of the base level literals under the new knowledge base. then  the decision tree algorithm and find-features procedure is repeated. the process stops when the same decision tree is constructed as in the previous iteration  or when a fixed number of iterations  1  is exceeded. 
1 experiments 
we had several objectives in performing the experiments. 
first  we wanted to evaluate the overall performance of the system on some standard domains. second  we wanted to determine if quinlan's heuristic of assigning a small credit to new variables worked well in a decision tree system. third  we wanted to investigate the effectiveness of a modified fringe strategy for structural domains. 
1 kinship domain 
hinton  implemented a connectionist system for learning family relationships in two families. for a detailed description of the learning task  we refer the reader to quinlan's excellent  1  1  descriptions. 
1 m e t h o d 
in our experiments  we followed the procedure described in  quinlan  1b . the instances of each relation were partitioned into input-output vectors that have the same relation name and same second argument. only inputoutput vectors with at least one positive instance were used. there are 1 instances  equivalently  tuples or examples  in each of the total of 1 input-output vectors. the 1 input-output vectors were randomly partitioned into training and testing sets. the size of the training set was varied among the values 1  1  1  and 1. each of the test items was scored as correct only if all 1 examples within the vector were correctly classified. 
¡¡we extended quinlan's experiment by manipulating whether new variables were credited or penalized in the evaluation of literals. the same samples were used across conditions with the same sample size. each condition was run 1 times. these results are summarized in table 1. 
1 results and observations 
struct performed significantly better than foil on this domain for conditions with the same sample size. perhaps family relationships  being trees  are easily learned by a decision-tree algorithm. 
1 	learning and knowledge acquisition 
table 1: accuracy results on kinship domain. 

¡¡for struct  assigning a small credit to new variables resulted in decision trees of no better or worse accuracy. quinlan's rationale for the credit strategy is that adding new variables will allow new literals to be introduced that might have more information gain. this locally increases the size of the hypothesis space. however  the larger hypothesis may also result in overfitting. 
1 	chess endgame 
the chess endgame domain was used in a comparison of human and machine learning formalisms  muggleton et al.   1  muggleton et al. concluded that the ability to produce high-performance in this domain was almost entirely dependent on the ability to express first-order predicate relationships. thus  this domain seems to be a natural test-bed for structural learning. quinlan's  results for foil on this domain are included in table 1. 
¡¡the problem faced by the learner in the chess endgame domain is to learn the concept of an lilegal position involving three pieces a white rook  white king  and black king. a position is illegal if either king is in check or two pieces occupy the same square. 
1 	experiment 1 
in this experiment we compared three strategies against a default strategy for training sizes of 1 and 1. the control condition assigned a penalty for new variables in literal tests  and used a symmetric evaluation function. the other conditions differed from the control condition in one aspect of their strategy. the reward condition assigned a small reward for new variables. the asym condition used an symmetric evaluation function similar to the one used in foil  except that it evaluated information about examples rather than tuples. 
¡¡each condition was run with 1 testing examples and repeated for 1 trials. the same samples were used across conditions with the same sample size  and the two-tailed correlated t-test was used to test significance. 
1 	results and observations 
as shown in table 1  struct achieved comparable accuracy to foil for both sample sizes; their mean accuracies are within one standard deviation of each other's. however  foil finds descriptions of greater simplicity than struct. 
¡¡the evaluation function results in table 1 indicate that on the chess endgame domain  struct performs better with the symmetric evaluation function  the control condition  than with the asymmetric evaluation function. the sym condition produced more accu-

table 1: accuracy results on chess endgame domain. 
rate trees  particularly for larger sample sizes. perhaps the symmetric evaluation function is appropriate for the symmetric decision tree algorithm  and the asymmetric evaluation function is apppropriate for the asymmetric separate-and-conquer algorithm. 
¡¡on this domain  assigning a small credit to new variables was also significantly worse than assigning a small penalty to new variables. this result is not surprising as a complete and consistent description can be constructed without introducing any new variables. 
¡¡feature construction did not result in a significant t increase or decrease in accuracy in any condition  so these results are not included in table 1. for this data  feature construction's only advantage is the greater conciseness of the decision tree. our results are consistent with the results in  matheus  1; pagallo and haussler  1  which showed little or no improvement in accuracy for the datasets obtained from the uci repository of machine learning domains. matheus conjectures that the poor results are due to the high quality of the initial features. 
1 	experiment 1 
this experiment was motivated by the disparity in pagallo's  results for feature construction on synthetic domains and the uci domains. we conjectured that feature construction might be more effective if the distribution was biased to generate more of the difficult examples. 
¡¡accordingly  we created an example generator that produced relatively more examples of illegal positions where the black king was in check by the rook. we also biased the example generator to generate many nearmisses of this case - situations where the black king would be in check by the rook if the white king were not in the way. to improve the efficiency of the data generator  we did not check for repeated positions in either the training or testing set. each example was generated independently of every other example. the same distribution bias was used for the training and testing table 1: comparison of feature construction strategies. 
sets. 
¡¡we ran the experiment for each of the two find-features strategies  and a control condition with no feature construction. the ffl condition used find-feature j  and the ffs condition used find-feature1. each feature construction strategy was run with 1 and 1 training items  and 1 test items; the experiment was repeated 1 times. the same samples were used across conditions with the same sample size. in table 1  the correlated two-tailed t-test was used to find significance. in the first and last groups of three rows  each feature construction strategy is compared to the control; in the middle group of two rows  ff1 is compared with ffl. 
1 	results and observations 
for the biased distribution  there were significant differences for accuracy with and without feature construction. overall  ff1 performed best  followed by ffl. interestingly  the accuracy without feature construction is about the same as for the unbiased distribution. 
¡¡ffl learned with less accuracy than the control for 1 training items  but the difference is not significant. however  it did learn with significantly better accuracy for the larger sample size. ff1 learned with significantly better accuracy than the control for both sample sizes  and significantly better accuracy than ffl for the smaller sample size. 
¡¡these results suggest that feature construction is dependent on the example distribution. on the other hand  it may be quite easy to bias the distribution - one can use the decision tree as a test of whether or not an example is difficult. namely  examples that are incorrectly classified by a first-attempt decision tree might be used to construct a biased distribution for feature construction. 
¡¡the difference between the two feature construction results seems to indicate that the context of the literal is important for feature construction when learning from smaller sample sizes. 
1 	conclusions 
struct is a structural decision tree algorithm that provides good performance on the two test domains. on the kinship domain  it learns more accurate descriptions than foil. on the chess domain  it learns descriptions of comparable accuracy to foil. however  foil is considerably faster than struct. this can be important if there are many examples. in addition  foil generally finds simpler definitions than struct. 
watanabe and rendell 
   our experiments demonstrated that quinlan's heuristic of assigning a small credit to new variables does not work effectively in struct for these datasets. assigning a small debit to new variables produced more accurate decision trees. we conjecture that these results would be reversed for a separate-and-conquer strategy: quinlan's evaluation function would consistently outperform our evaluation function because of the asymmetry of the algorithm. 
¡¡the feature construction results indicate that the lack of effectiveness of feature construction on real-world domains may be due to the distribution of the examples. in order to use feature construction effectively  it may be necessary to bias the distribution. our results showed that a straightforward extension of fringe for structural decision trees produced significantly less accurate descriptions for smaller sample sizes than an alternate approach that compensated for loss of context information. 
acknowledgements 
discussions with pat langley  sudhakar yerramareddy  and members of the inductive learning group contributed to this paper. we would also like to thank ross quinlan for sending us foil.1. 
