 
　　this paper assesses several broad approaches to language analysis with respect to the problem of lexical ambiguity. the impact of the problem on both syntactic and semantic analysis is discussed  and several common methods for disambiguation  including the use of selectional restrictions and scriptal lexicons  are analyzed. their shortcomings illustrate the need for complex inference to resolve ambiguity  which forms one of the key functional arguments in favor of integrating language analysis with memory and inference. however  it has proven surprisingly difficult to realize such an integrated approach in practice: an assessment of lexical disambiguation within some recent models which attempt to do so reveals that they rely largely on the traditional techniques of selectional restrictions and scriptal lexicons  with all their drawbacks. the difficulty is shown to stem primarily from the theories of memory and inferential processing utilized. the implications for recent approaches to language analysis based on connectionist mechanisms are explored. finally  the requirements imposed by lexical disambiguation on theories of memory and inferential processing are discussed. 
introduction 
the problem of natural language analysis  or 
 parsing   has been approached in many different ways and from the perspective of many different theoretical traditions. because these theoretical traditions often differ quite radically in their basic assumptions about the goals of language analysis and the methods that ought to be employed  it can be quite difficult to compare the different approaches. but regardless of these differences  there are certain characteristics of the input that must be dealt with. natural language is elliptic  ambiguous  and vague  to name just three of these problematic features any language analyzer must contend with some or all of these problems. this suggests that one good way to try and make sense out of the variety of approaches is to examine their various strengths and weaknesses with regard to such characteristics. 
　　in this paper  i propose to evaluate several broad approaches to parsing with respect to one of the most basic of these problematic characteristics  lexical ambiguity. lexical ambiguity is one of the chief sources of ambiguity in language  so the problem is undeniably important. it is  further  widely recognized to be a far more pervasive phenomenon than it intuitively seems to be. because people are not consciously aware of most of the ambiguities in what they read or hear  the fact that most of what they read or hear is ambiguous is not immediately apparent. however  a glance at any ordinary dictionary should make it plain that lexical ambiguity is extremely common. 
　　lexical ambiguity is  finally  a problem the importance of which has long been appreciated. it was one of the rocks on which the early work in machine translation foundered. bar-hillel  1   in his critique of that work  showed that determining the correct sense of an ambiguous word depends  in general  on plausible inferences from extremely complex features of the context in conjunction with arbitrary facts about the world. he gave as an example the problem of choosing the correct meaning of the word  pen  in the sentence  the box is in the pen.  in this sentence  the pen in question is probably an enclosure  such as a play-pen  rather than a writing implement. bar-hillel argued that in order to determine this  a language analyzer would need access to knowledge of the functions and relative sizes of these two different kinds of objects  as well as some means of using that knowledge to determine the plausibility of the various possible interpretations of the sentence 
　　of course  lexical ambiguity is not just a problem for semantic analysis. it is also one of the chief causes of structural ambiguity  and it is  therefore  an issue with which syntactic analyzers must contend as well. this aspect of the problem has also long been appreciated. in the well-known example  time flies like an arrow    kuno  1   much of the structural ambiguity of the sentence stems from the part-of-speech ambiguity of the words  time    flies   and  like   which in turn reflects their semantic ambiguity. 
　　in sum  the problem of lexical ambiguity can indeed serve as a touchstone by which theories of language analysis can be assessed. the problem is basic and pervasive. the issues implicated in its solution  and the problems to which it gives rise  have long been appreciated. it arises regardless of whether one is trying to construct a syntax-based parser or a semantics-based one. despite its importance  however  surprisingly little progress has been made on the problem. in this paper  i will attempt to provide a critical survey of what has been accomplished. no new solutions will be presented. however  the critique will reveal some of the requirements 

for a solution  and some of the consequences for the understanding process as a whole will be explored 
lexical ambiguity and syntactic analysis 
　　in syntactic analysis  the problem of lexical ambiguity is not the problem of choosing the correct sense of a word  but simply the correct part of speech. however  as the last example demonstrated  these problems are not. unrelated. word-sense ambiguity very often entails part-of-speech ambiguity as well. thus  correctly disambiguating the part of speech of a word will in general depend on complex semantic and pragmatic processing syntactic analyzers cannot  therefore  be expected to solve by themselves the problem of lexical ambiguity  even just part-of-speech ambiguity. it is not unreasonable  however  to expect that they might contribute to its solution. 
　　the chief approach to resolving syntactic ambiguity  lexical or otherwise  is simply to try each alternative  while being prepared to back up in case it should prove mistaken. this is the approach taken in atn parsers and descendant models  see  e.g.  thome  bratlcy  and dewar 1. bobrow and fraser  1; woods  1  
fereira and warren  1  when such a parser encounters an ambiguous word  it simply tries each possible choice for that words part of speech which will enable a transition  and which therefore offers the possibility of successfully parsing the input sentence according to the grammar utilized. if the choice does not lead to a successful syntactic analysis  then it will be discarded when the parser backs up.  by performing an incremental semantic analysis on structures proposed by the syntactic analyzer  it is possible to rule out choices on semantic grounds as well; see. eg.  bobrow and webber  1.  this process will be repeated for a given word each time the parser encounters it when driving forward in the network all and only the choices that lead to successful analyses will be output with those analyses. further disambiguation is the responsibility of the semantic and pragmatic components of the understanding process 
　　more recently  however  marcus  1  has criticized this approach to resolving ambiguities  and has argued instead that syntactic analysis can normally be accomplished without resorting to unlimited back-up. in particular  he claims that syntactic structural ambiguities must and can be resolved with limited look-ahead and highly restricted use of semantic information. since much of the structural ambiguity in language arises as a result of lexical ambiguity  lexical ambiguity is clearly one of the crucial issues which must be faced in making such a claim nevertheless  marcus's theory barely addresses the problem: with only one or two exceptions  words are taken to be syntactically unambiguous in his work. at the very least  this failure to confront the issue makes it difficult to evaluate the status of the theory. 
　　in fact  the one or two cases of lexical ambiguity which marcus does attempt to resolve within the framework of his theory simply serve to show howprofound the impact of the problem actually is. for example  in order to disambiguate whether the word  have'' is used as an auxiliary or a main verb  marcus introduces a diagnostic rule which is arguably the most complex in his entire grammar. nevertheless  as marcus himself points out  the rule fails on many obvious examples. how well such rules would work in the context of many other ambiguous words is highly questionable. indeed  milne's  1  attempt to address lexical ambiguity within the framework of marcus's theory led to a substantially greater reliance on semantics. one need not agree with the details of his proposals to find this result suggestive. 
lexical ambiguity and semantic analysis 
　　we have seen that syntactic analyzers  alone  cannot be expected to do very much about lexical ambiguity it is  after all  primarily a question of word-sense ambiguity rather than just part-of-speech ambiguity  and so primarily a semantic problem rather than a syntactic one. quite naturally  therefore  it is an issue which has received far more attention in semantic analyzers than in syntactic ones. at first glance  there seem to be a variety of different semantic approaches to the problem. in fact  however  most approaches turn out to share only one or two fundamental mechanisms. 
　　the major semantic approach to the solution of lexical ambiguity involves the use of selectional restrictions  katz and fodor. 1  these are semantic requirements associated with the structures representing the meanings of words or phrases  which must be met by another semantic structure before the two can be combined. for example  an action like eating might require that its actor be animate in general  selectlonal restrictions are one-place predicates that test for the presence or absence of some semantic feature  or some boolean function of such predicates 
　　the use of selectional restrictions in disambiguation is  in principle at least  quite straight forward. one simply chooses the sense  or senses  of a word that select ional restrictions will allow to combine with other semantic structures in the sentence  either because it meets the requirements of those other structures  or because they meet its own requirements. to paraphrase a simple example from katz and fodor  1   consider the word  ball.  this can mean  among other things  either a fancy party with dancing  or a round object used as a toy. in the sentence  john hit the ball   the use of selectional restrictions would result in choosing the round object sense of  ball   since the action of hitting can be applied to a physical object but not to a social gathering. 
　　a variety of different methods have been developed for applying selectional restrictions in the resolution of lexical ambiguity; i will briefly mention just a few of them here. winograd  1  proposed that they be used by semantic interpretation specialists associated with functional syntactic constituents such as noun groups and clauses. riesbeck  1  proposed encoding selectional restrictions in the tests of the lexically indexed productions that represent  in his theory  the different meanings of a word. rieger and small's  1  theory of word experts and hirst and charniak's  1  theory of polaroid words are based on more sophisticated versions of this idea. wilks  1  has proposed that selectional restrictions should not be absolute requirements  but simply preferences. in his model  one picks the sense of each word that maximizes the total number of preferences satisfied in a given sentence. 
　　the other major approach to handling lexical ambiguity involves the use of a scriptal lexicon  schank and abelson  1  cullingford  1; riesbcck and schank  1  charniak 1  this idea is based on the observation that many words have special meanings in particular contexts. thus  in a sense  each script or frame used in understanding a text should have an associated lexicon in which words are assigned their frame-specific meaning. for example  the frame for a baseball game would have an associated lexicon in which the word  home  would be defined as the plate in the ground over which batters stand  and which a player must touch to score a run. by itself  this idea is not very useful for disambiguation  except insofar as it keeps frame-specific meanings out of consideration unless the relevant frame is ''active.  the crucial simplifying assumption which is usually made  therefore  is that if a 
　　given frame is  active   all words in its scriptal lexicon can be presumed to have their frame-specific meaning 
　　although both selectional restrictions and scriptal lexicons are very useful up to a point  especially in 
domain-limited applications  it should be clear that they have severe limitations. the simplifying assumption which underlies the scriptal lexicon approach  that words will not be used in other than their frame-specific sense  is clearly not true. for example  consider the following sentence in the context of a story about a baseball game:  the game was so lopsided that fred got bored and walked home after the seventh inning.  here  the home in question is probably freds residence  not home plate. 
　　the use of selectional restrictions has similar limitations. consider the following variant of bar-hillel's example: ''the pen is in the box along with assembly instructions.'' here  the pen in question is probably a play-pen  and almost certainly not a writing implement. determining this requires recognizing that the assembly instructions are probably for the assembly of the pen  and knowing that play-pens often require assembly by the consumer after purchase  whereas writing implements do not using this knowledge in turn requires inferring that since the pen is in a box with assembly instructions  it has probably just been purchased by the consumer. the point here is that these are simply not the kinds of rules that can be represented and employed as selectional restrictions  except at the risk of precluding the correct analysis of other examples. we cannot  for example  just invent a feature  objects that can be assembled  as a selectional restriction on the object of  assemble   and which would be a property of play-pens but not writing implements. writing pens certainly are assembled  in factories  and they may even be assembled by the consumer  as in  john assembled the pen after cleaning it and putting in a new cartridge   
lexical ambiguity and integrated analysis 
　　the above discussion makes it. clear that what must be brought to bear on the problem of lexical ambiguity are the general inference and memory processes used in understanding. thus  lexical ambiguity is one of the key problems which motivates an integrated approach to language analysis  one- in which inference and memory processing play an important role in the analysis process itself  schank  lebowitz  and birnbaum  1  schank and birnbaum  1 . although it plays a key role in motivating this approach  however  and would therefore seem crucial to theories of integrated analysis  
surprisingly little attention has been devoted to it 
　　for example  consider the approach taken in the model proposed by dyer  1   which explicitly aims to be a model in winch memory and inference are intimately entwined in the language analysis process despite this intent  the discussion of lexical disambiguation in the model is limited to the use of selectional restrictions and scriptal lexicons both are implemented as the tests of lexically indexed productions  in a manner similar to riesbcck  1  we can best see how this works by looking at a representative example for instance  here is the procedure which disambiguates the phrase  run into   slightly paraphrased for readability: 

lets analyze how this is intended to work the test for whether or not the actor is a vehicle is simply a selectional restriction. the test for whether  the scenario is transitional with a vehicle instrument  is perhaps more puzzling however  its purpose would seem to be to handle examples such as  while i was driving home  i ran into a parked car  1 in which the actor of  run into  is not a vehicle  but the proper interpretation is nevertheless vehicle accident. in effect  this is an implementation of the scriptal lexicon idea: if the vehicle travel frame is active  then  run into  means vehicle accident. both of these rules are subject to the limitations described in the last section. for example  this use of the scriptal lexicon approach would fail on the following text: 
while i was driving home  i remembered i needed some milk. i ran into a seven-eleven and picked up a half-gallon. 

　　finally  let's consider the test for a human who has some interpersonal relationship with the actor. here  the model begins to employ knowledge beyond simple seleetional restrictions  which are technically just oneplace predicates the problem is  it still employs thus knowledge exactly as if it were just a seleetional restriction although the presence of such a relationship  or  in fact  any semantic feature  is indeed the sort of knowledge that may be relevant in determining the correct meaning of a word  its use as a sufficient condition in a non-inferential  lexically-indexed rule of this variety is entirely misplaced. the point ls that such knowledge must be represented and indexed in a way that makes it available for use by the general inferential capabilities of the understander 
　　to be more specific about what is required  consider how the fact that two people have an interpersonal relationship might be relevant to determining the appropriate interpretation of ''run into.  if two people who knew each other happened to have a fortuitous encounter  then social rules such as politeness  and personal goals stemming perhaps from friendship  might cause them to pursue their interpersonal relationship at that juncture. they might  for example  engage in conversation  go to a bar  or arrange a subsequent meeting knowledge of this causal relationship would enable an understander to explain why people who knew each other would exhibit such behavior  and thus enable the understander to construct a causally coherent representation of a textual fragment describing such an episode. it is the attempt to construct such a causally coherent representation that determines the proper interpretation of  run into n a particular interpretation  such as ''social encounter '' is preferred to the extent that it promotes such coherence 
　　but the rule cited above does not explicitly represent such causal knowledge  nor does its choice of an interpretation for ''run into'' depend on the attempt to infer a causally coherent representation. instead  the inference process is  short circuited  by directly linking some  but not all  of the relevant features with some  but not all  of the possible interpretations such a rule simply cannot work in general. consider  for example  the following text: 
john was racing down the street trying to catch a bus all of a sudden  his neighbor fred stepped out of a doorway into his path. john ran into fred and knocked him down. 
fortunately  he wasn't hurt. 
　　what both this example and the previous one demonstrate  to repeat  is that the proper interpretation of ''run into  should be determined on the basis of the attempt by memory and inference to construct a causally coherent representation of the text as a whole - which is  after all  one of the chief functions of memory and inference in understanding. in a language analyzer which is truly integrated with memory and inference  it must be on the basis of these sorts of inferential considerations that language analysis problems  such as lexical ambiguity  are resolved instead  in dyers model we find that such inferential processing occurs after a word has already been disambiguated by means of seleetional restrictions and scriptal lexicons. 
the model of integrated partial parsing proposed by 
schank  lebowitz  and birnbaum  1g  and substantially extended by lebowitz  1  also depends  primarily  on the scriptal lexicon approach. in fact  most words are simply unambiguous as far as the model is concerned  since it presumes that input stories will involve only a single domain  terrorist incidents . to some extent  however  this model does make more serious use of memory and inference in disambiguation as well. in order to construct coherent representations of input stories  the model employs a version of script application  schank and abelson  1; cullingford  1   in which an action or state is interpreted by matching a scriptal expectation the model can then use these expectations to disambiguate a word by choosing the meaning that satisfies one of them  this method was originally proposed by riesbeck and schank  1  
this method is clearly a step in the right direction. 
 it is  however  subject to severe limitations  because it assumes  first  that if a script is active  then an ambiguous word must have the meaning that matches an expectation from that script  and second  that only one meaning will match an expectation but consider what would happen if more than one script were active  or if the scripts were larger and more detailed  or if expectations from sources other than scripts were utilized. u'nder these conditions  it seems quite likely that more than one meaning of an ambiguous word would match an expectation  or to put this another way  that more than one interpretation could be coherently interpreted within the context thus  this method for using scriptal expectations will not work in many situations; it will either fail to disambiguate  or else simply choose in a way which guarantees a high probability of error. the method can only be employed reliably when only one script is active  and when only one sense of the word matches an expectation from that script as a result  this use of scriptal expectations is virtually equivalent  in the power and scope of its disambiguation capabilities  to the use of a scriptal lexicon for all practical purposes  one might just as well stipulate that the given word will have a given meaning if the given script is active. 
conclusions 
　　how can the the use of scriptal expectations  or more generally of contextual expectations from varying sources  be extended to handle those cases in which more than one 
meaning of an ambiguous word might seem at first to fit the context  several factors must be taken into account beyond the mere occurrence of a match between a potential word meaning and an expectation. first  which expectations are more important  or more likely to be satisfied at this point in the text  to put this in more general terms  which of the explanations for the different possible interpretations is more plausible or more salient  second  does the text supply any additional clues  for example  a candidate semantic structure may be the right 

sort of action to satisfy an expectation  but may nevertheless be inappropriate because its potential actor  as specified in the text  does not match the binding already assigned to the actor in that expectation. the use of such information is essential to exploit the full potential of memory and inference in lexical disambiguation. 
　　in fact  this requirement poses the greatest challenge to recent models of language analysis employing connectlonist mechanisms  see  e.g.  small  cottrell  and shastri  1; cottrell  1; waltz and pollack  1 . 
the manipulation of variables and variable bindings is a difficult issue in the connectionist framework  j. feldman  personal communication   and as currently formulated these models do not seem capable of utilizing such information in disambiguation. thus  their use of contextual information in disambiguation seems subject to the limitations described at the end of the last section. whether the clever manipulation of parameters such as weights and activation levels can overcome these limitations remains to be seen. one possible solution is to use connect lonist methods simply to suggest potential inference chains  and employ more traditional inference mechanisms  capable of manipulating variable bindings  to check over the suggestions  charniak  1 . another possibility  requiring a more radical change in the connectionist framework  is to allow variable bindings to be passed between the units in a memory network  riesbeck and martin  1 . 
　　more broadly  however  the apparent difficulties in applying memory and inference to lexical disambiguation reflect not so much on the state of theories of language analysis as on theories of memory and inference. here  the lesson of lexical ambiguity is that the knowledge needed to draw inferential connections in understanding cannot be packaged in isolated rules that commit the understander to certain inferences irrespective of what other rules may propose it is true that one possible interpretation of someone ''running into  another person is as a fortuitous encounter leading to a social interaction. it is also true that one explanation for why two people would care to engage in such an interaction would be if they already knew each other. thus  the knowledge that two people knew each other would provide support for interpreting ''run into  as a social encounter  since such an interpretation would enable the understander to explain certain aspects of the situation. but  as we have seen  the decision that this is the correct interpretation cannot be made without considering the need to explain other aspects of the situation  aspects which may have nothing to do with social interactions and to which rules explaining such interactions cannot be expected to attend. 
　　this last point bears particular attention. no single explanatory inference rule can be expected to attend to all the aspects of a situation which might affect the truth or relevance of the explanation it offers  and hence the validity of the interpretation it prefers for some vague or ambiguous linguistic element. thus  determining which explanations to accept  and hence which interpretations to prefer  cannot be left to the inference rules themselves. 
l. bimbaum 1 
rather  there must be a more general inferential mechanism that determines which explanations to accept  taking into account the need to explain diverse aspects of a situation  and the evidence of diverse rules. 
　　probably the most ambitious attempt in this direction has been mcdermott's  1  model  which is capable of considering several potential explanations for a situation in parallel as it unfolds and choosing among them when evidence is available  as well as patching or replacing explanations that prove erroneous. granger  1  and ororke  1  propose models with this last capability as well  and granger  eiselt  and holbrook  1  have proposed a model of language understanding  including lexical disambiguation  which makes use of such techniques the most salient feature of these models is that they explicitly employ criteria  however crude  for deciding whether an explanation is adequate  when one explanation is preferable to another  and when an explanation has gone awry. for example  mcdermott's criteria are  basically  coherence - an explanation must fit the facts - and parsimony -- an explanation with fewer unjustified assumptions is preferred. the use of such criteria would seem to be a crucial aspect of any inferential mechanism capable of fulfilling the requirements set out above  and thus capable of resolving lexical ambiguity in a general manner. 
acknowledgments: i thank beth adelson  gregg collins  and alex kass for useful discussions and for comments on 
an earlier draft of this paper. this work was supported in part by the defense advanced research projects agency  monitored by the office of naval research under contract n1-k-1 
