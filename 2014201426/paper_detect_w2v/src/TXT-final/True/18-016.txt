 
　　we propose a new approach to parsing ambiguity in which a parser always moves forward with the common elements of competing syntactic analyses. the approach involves assertion sets constrained so that in formation is monotonically preserved throughout a parse asseriion sets have several advantages over trees as a parsing representation. they may also lead to better computational understanding of the attention-shifting mechan ism 
1 introduction 
　　recent linguistic theories divide linguistic constraints into subsystems each having its own character. the complex surface character of a language is ultimately generated by the interactions among a few fundamental processes and constraints. we are most interested in the gb-theory framework of chomsky  1   which identifies subtheones concerned with locality  government  assignment of semantic roles  pronoun binding  case  control  and x-constraints  but some developments in other frameworks also tend toward modularity. for instance  shieber  1ff  describes a version of the gpsg formalism that separates immediate-dominance rules  linear-order constraints  and metarules  while the tag formalism  kroch and joshi  1  factors recursion apart from co-occurrence restrictions. 
　　the surface complexity of parsing should be decomposed in the same way as the surface complexity of language. principles that are common to all languages should not have their effects repeatedly redescribed in the descriptions of particular languages  but should instead be exploited as part of parser design. similarly  a single underlying process within an individual language should not have its effects spelled out separately in each surface manifestation; ideally the process should be encoded just once  in such a way that  the parser can work out what surface appearances to look for beyond syntactic theory  parser design provides additional opportunities for such factoring  not only linguistic principles but also aspects of parser control structure may be factored out however  the general effect on the description of a language is the same less information is needed to describe a language  if redundancy can be factored out and if control-structure elements can be removed from the grammar and incorporated in basic parser design 
　　our goal is thus a dual one. we aim to build a parser that bases its operation on modular subcomponents instead of a welter of surface-oriented rules; in so doing  we will reduce the amount of language-particular syntactic information that must be supplied by the designer of a natural-language system.** as one component of this effort  we are considering possible ways to use a  stripped-down'' parsing representation that is based as much 
thin report describes research done at the artificial intelligence laboratory 
of the massachusetts institute of technology. support for the laboratory's artificial intelligence research has been provided in part by the advanced research projects agency of the department of defense under office of naval research contract n1-o-1. during a portion of this research ed 
barton'* graduate studies were supported by the fannie and john hertsr  foundation. 
see barton  1  for more information on this general research program. 
as possible on the predicates of linguistic theory. we hope to reduce the amount of grammatically extraneous information that the parser manipulates 
ii assertion sets 
   it is doubtful that traditional parse trees are ideal for representing syntactic structure  for in general the range of structural information that a tree makes explicit may not correspond to the information that is grammatically relevant. for example  x-theory suggests that the head-projection relationship may be more important grammatically than the immediate-domination relationship that a tree displays. in a different vein  it has been hypothesized  lasnik and kupin  1f  that linguistic theory is insensitive to characteristics of trees that cannot be recovered from information about the range of terminals spanned by each constituent. 
　　we are investigating the use of monotonically growing assertion sets as a parsing representation. a constituent is represented by a triple   where is a bundle of syntactic features  eg one that we might abbreviate with the usual label np  and i  j are the input positions defining the left and right edges of the constituent* for example  if we assume that adj  n forms a constituent that we will call nbar  the structure of the np the red block might be represented by the assertion set 
{ np 1   det 1 l   adj 1   n 1   nbar 1 }. 
with this representation  parsing is the construction of such an assertion set - closely akin to a  phrase-marker  in the sense of chomsky's  1  early work  in the early stages of parsing  the assertion should actually appear as  np 1 *  to indicate that the right edge of the constituent has not yet been encountered.  an assertion-set parser develops its analyses drterministically if changes in its  global  assertion set are always refinements in the information-theoretic sense that is  if information is monotonically preserved. under determinism  the only possible refinements are adding a new assertion  changing a * to a specific value  and adding features to an underspecified category. for example  operating under a rudimentary x-theory  it would be possible to change the features of a constituent from  +-nj to i+n  v +rnax   i.e. from an underspecified category to np  but impossible to change np to vp. monotonic.ity would also rule out the usual notion of nondeterministic chart parsing; the parser would be unable to remove initially plausible analyses that failed to pan out. 
   monotonically growing assertion sets are attractive in several ways for representing syntactic structure. for example  beyond the device of using initially underspecified feature bundles  there are some useful structural modifications that are informationpreserving when applied to assertion sets  but not when applied 
　this representation takes a cut  from lasnik and kupin as well as from the representations used in chart parsing. nirenburg and attiya  1  use a similar representation  but do not add the constraint of information monotonicity. although we use numeric input indices here for simplicity  a repre mentation based instead on the actual words of the terminal string is better in cases of movement and  under an new analysis by goodall  1   in cases of conjunction. 
1 g. barton  jr. and r. berwick 
to trees * changing the tree for / told john a ghost story into the tree for / told john a ghost story was th  lust thing 1 wanttd to hear requires  non-monotonically  breaking the link between vp and ;nr a ghost story j and replacing it with a link between 
vp and s. in the same way  a tree link is deleted when john is moved one level deeper in going from see john to sit john and bill in the assertion-set representation  each of these changes can be described as the addition of an assertion an s assertion is added in the first change  an np assertion in the second; in each case all previous structure assertions remain valid when the new assertion is added  if the change is made before the right edge of vp has been declared. assertion sets can thus allow a deterministic parser to be partially noncommittal about the exact attachment level of a constituent.** 
　　the ability of assertion sets to represent partial information can also be useful in handling pp-attachment ambiguity. if it is not clear whether to attach an adjunct pp under np or vp  for instance  the various structural possibilities will still agree on the existence and internal structure of pp. if np with ad-
junct pp is analyzed as  ni. np pp    they will also agree on the lower np.*** this example illustrates the fact that assertion sets support co-called chomsky-adjunction more naturally than sister-adjunction for example  on some analyses of the rightward movement called heavy np shift  np is chomsky-adjoined to the end of vp to produce the structure |vi vp np   with assertion sets  the representation of the lower vp is  monotonically  preserved when the assertion is added that describes the upper vp. some linguists have argued that the preservation of information about constituent structure makes this form of adjunction the appropriate one for describing the structural changes wrought by transformations.**** with trees  it is sister-adjunction that is information-preserving  as in a hypothetical replacement of |vr v t pp   with |vp v t pp np  . 
i l l the theory of 
attention-shifting 
   because of its atomistic character  the assertion-set representation may also pave the way to a better understanding of the attention-shifting mechanism of the deterministic marcus parser  marcus  1  the attention-shifting mechanism implements a  wait-and-see  strategy for dealing with some of the cases in which the parser cannot tell which possible step to take next. interpreted abstractly  the strategy allows the parser to move forward with those elements of the structural analysis that it can be sure of. when attention-shifting rules begin to build a constituent  it may be unclear how it will fit into the final parse tree. however  a deterministic parser cannot be justified in building the constituent unless all competing analyses agree on its existence and internal structure.***** 
   the possibility exists that a parser could deal with parsing ambiguity by explicity observing the operating principle: always go ahead with the common elements of competing syntactic analyses. under this principle  it would not be necessary to write attention shifts into the rule system explicitly; attention-shifting  when necessary  would be automatic. such a parser could explain 
* marcus et a/.  1  describe a parsing representation that also differs from trees in its possibilities for information-preserving structural modification. 
　this should be especially helpful in devising a data driven treatment of conjunction that does not predict conjoined nps except when prompted by specific cues. the close relation between some variant of assertion sets and the monostrings that lasnik and kupin have described also makes assertion sets promising for the implementation of goodall's new  1  monostringbased theory of conjunction. 
　　the assertion-set framework is compatible with having the assertion sets filtered by extrasyntactic information in order to ultimately resolve the attachment ambiguity. 
　　chomsky  1   among others  has tentatively argued this. however  ''chomsky-adjunction  as a name for this operation is historically accidental. 
     marcus's actual mechanism includes nothing to guarantee such agreement  with consequences that become more severe as lexical ambiguity increases. 
attention-shifting behavior by deriving it from a principled treatment of parsing ambiguity  could validate the informal characterization of attention-shifting as the implementation of a wait-andsee strategy  and would clarify the computational problem that is solved by the attention-shifting mechanism. in brief  it would contribute to the computational theory of the marcus parser in marrs  1  sense in addition to serving the goal of removing control-structure elements from language descriptions. 
assertion sets are superior to trees for use in such a parser 
it is unclear how to intersect trees in order to take the com mon elements of different analyses  while ordinary set intersec tion roughly suffices for assertion sets because of their atomistic character * it is also unclear how the tree representing common elements of analysis could be partially noncommittal about attachment point in the cases mentioned earlier. finally  in the presence of left-recursion as with possessive nps  there will be an infinite number of ways to extend a tree downward to encompass a new element; with at most bounded lookahead  it is impossible to say how many tree nodes lie between the new input and the point of attachment to the existing tree. it will thus be difficult to envision all possible syntactic analyses in a tree-based parser. left-recursion causes no more of a problem with assertion sets than it does with the related representation of a chart parser  since the  -notation collapses an infinite number of nodes into a single assertion. 
　　several issues must be addressed in the design of any parser that proceeds by moving ahead with those elements of the syntactic analysis that are known for certain. the parsing representation must be decomposable into smaller elements that have meaning when separated; assertion sets fit the bill here. different aspects of parsing rules and actions must also be separable in the sense that some parsing actions can still be licensed even when knowledge is insufficient to license all of them. it should sometimes be possible for parsing ambiguity to be eventually resolved when disambiguating evidence is encountered; elements of analysis that are correct but were initially discarded because of uncertainty should not remain forever absent. a decision must be made about the stringency of rule matching; it is customary to require the parsing representation to explicitly list the features mentioned in a rule  but because taking the common elements of competing analyses will result in feature underspecification  it may be better to require only feature compatibility between the rule pattern and the parsing representation. one must ensure that the implementation strategy does not allow combinatorial blowup to creep into the rule-matching process. finally  it will be necessary to impose some coherence requirement on the collection of analytic possibilities; if they diverge too widely  the parser cannot sensibly integrate their common elements. 
	iv 	shape compatibility 
　　the application of this parsing method is not completely worked out  either in the marcus framework or in a standard context-free parsing framework. however  some of the intent can be suggested by sketching out a simplified model based on cfgs. the basic parsing cycle is to involve three steps: matching rules against the parsing representation  running the matching rules to produce several possible extensions of the representation  and intersecting the possibilities to produce the next parsing representation. the fundamental problem is to intertwine analysis and control in such a way that the monotonically growing syntactic analysis is always sufficient to support rule matching  while the control component always runs a set of rules that will advance the analysis one step further in a coherent way - all the while operating under the strategy of taking the common elements of competing syntactic analyses. 
   as an initial approximation  suppose predictions define the unit of licensed parse continuation then if a is ambiguously either a1 or a1 and the rules s ~  a1 b x and s -  a1 b y are being considered while parsing a string that begins with a  it will 
some modification is necessary in order to accommodate analyses that 
disagree only on node features. 

initially be unclear whether to reduce a as a1 or a1 however  in 
either case it is predicted that a b will come next* in the input this common prediction can license the construction of a b and eventually allow the parser to see the disambiguating x at the end of the string. the same principle operates in a more complex way when parsing the vp know that big n d blocks . . given a determiner-noun agreement mechanism; if thai can be either comp or det. it is initially unclear which interpretation to take however  the competing syntactic analyses agre* that an nbak is possible after that. thus the construction of nbak is licensed  and the agreement mechanism can rule out the determiner interpretation once the nbak is built 
　　closer scrutiny reveals that intersection of predictions is not actually the appropriate operation here. suppose b above surfaces as k'b  another constituent c surfaces as a-'r  and the rule s -  a cz is possible. the construction of either b or c should be licensed after the initial a; in fact  b and c can always be distinguished by the time they have been completely scanned however  only b is licensed if we take the intersection of all predictions. in seeming contradiction to the principle of taking common elements of competing analyses  predictions should be subject to union rather than intersection. 
　　the contradiction is resolved by noticing that in any deterministic parser  it is necessary to say what counts as part of the syntactic analysis subject to determinism in marcus's parser  packet activations don't count; in contrast to features  they may be both added and removed. packet activation licenses the interpretation of certain elements in certain ways if they occur  but it does not commit the parser to expecting those elements  node creation and attachment  on the other hand  arc subject to determinism   predictions in the cfg framework license possible interpretations in the same way  hence they should not be sub-
ject to intersection; rather  the interpretations that are actually imposed should be intersected. 
   if some operations involve the union rather than the intersection of possibilities  an immediate question is why the parsing method does not degenerate to the full earley algorithm. in this sketch  that question is where the coherence requirement comes in. in the assertion-set framework  the simplest requirement to impose is one of shape compatibility. in the case of thatambiguity  even though we cannot initially decide whether that is a complementizer or a determiner  in either case it bears the same structural relationship to the next constituent  commanding the nbar of np  or commanding the s of sbar .* if different analyses must place constituent boundaries in the same place but may disagree about constituent identity  dotted-rule items will not re* quire a return address as they do in the full earley algorithm. in the above example  the possibilities  a1 1  and  a1 1  are shape-compatible and can intersect to the featureless lump  * 1 . when the end of a dotted rule is reached  such lumps can be back-traversed to find the left edge of the completed constituent thus the coherence requirement of shape compatibility allows the parser to use a finite  packet structure   as indeed it must if information monotonicity is not to be vacuous. 
　　preliminary investigation suggests that shape compatibility can help in many troublesome cases  e.g. t/iaf-ambiguity and /or-ambiguity. other cases such as pp-attachment ambiguity will require mechanisms to be extended. as one possibility  limited lookahead promotes coherence by filtering out shapeincompatible possibilities that would the soon anyway. extensions will also be required for full attention-shifting behavior. 
   ideally  cfgs and dotted rules should be dispensed with and the feature bundles of assertions should drive the entire analysis. by separability  this is feasible only if the feature system that is used can support a parsing interpretation for individual features. a feature system under development by reuland  1  is especially interesting in this regard  since each of his features describes a separate aspect of the combinatorial possiblities of a syntactic category. however  the standard x features  in ＼v| also are individually relevant to case-assignment rules and other 
* the possibilities share the same skeleton  in the sense of levy and joshi  1 . 
g. barton  jr. and r. berwick 1 
constraints that could be exploited in parsing in addition  some c ;im-: of parsing ambiguity that have been thought to require .mention-shifting might be analyzed in terms of other common elements between competing analyses besides those mentioned here. for example  a fact closely related to shape compatibility is that english that must begin some kind of x projection  whether it 1- the specifier  det  or the head  comp  of that projection. 
