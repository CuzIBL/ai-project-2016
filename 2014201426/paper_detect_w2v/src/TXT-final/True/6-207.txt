 
in this paper  we present an abstract framework for learning a finite domain constraint solver modeled by a set of operators enforcing a consistency. the behavior of the consistency to be learned is taken as the set of examples on which the learning process is applied. the best possible expression of this operator in a given language is then searched. we instantiate this framework to the learning of bound-consistency in the indexical language of gnu-prolog. 
1 introduction 
constraint satisfaction problems  or csps  have been widely recognized as a powerful tool to model  formulate and solve artificial intelligence problems as well as industrial ones. a common framework to address this task is the combination of search and filtering by a local consistency. enforcing a local consistency is usually done by the scheduling of monotonic and contracting operators up to reach their greatest common fix point. the consistency is obtained as the common closure of the set of operators. this closure is efficiently computed by a chaotic iteration of the operators  apt  1 . but usually  the task of finding efficient operators which actually define a consistency is considered as one of the smartest skills of the solver's implementor. the essence of the learning framework consists in considering the behavior of the operator enforcing the desired consistency as a set of examples in order to find an adequate representation of this operator in a given language. 
1 theoretical framework 

poster papers 
operators which satisfy the first three conditions are called pre-consistencies for c. as an example of consistency  if we suppose that each variable domain dx is ordered by a total ordering and for a dx  we denote by  a  the set {a  
then the bound-consistency 
is defined by 
with tx the projection of t on a  
　let csc be the consistency to be learned. our aim is to build a consistency / which behaves like csc as much as possible. thus / must be contracting  monotonic  correct w.r.t and singleton complete w.r.t 
for any singletonic search state s . how-
ever  singleton completeness is difficult to get and even not always possible to express in a given language. in order to transform a pre-consistency into a consistency  let us define a consistency idc such that is an empty state if s is a non-solution singletonic state  and = s otherwise. thus / and o / are consistencies for c if / is a pre-consistency for c. therefore by adding in the set of operators  processed by a chaotic iteration mechanism  apt  1  we only need to build pre-consistencies for c. on the other hand  the correctness condition must be ensured for every s  sw which is generally huge. we show that: 
proposition i if f is a monotonic and contracting operator such that f s  = sfor every singletonic state s which represents a solution of c  then f is a pre-consistency for c. 
therefore  by considering monotonic operators  we can reduce the search space to a sample set e which is a subset of sw and which contains all singletonic search states. let c be the language in which operators are expressed and / be an operator in this language. in order to find the best possible expression  we shall be able to compare two consistencies. this 
1 
is usually done with a distance. let d be such a distance between two consistencies. the learning problem is formulated as follows: 
where e contains all singletonic search states of sw and / is a monotonic operator. following the machine learning vocabulary   represents the example space and the hypothesis space. 
1 	learning indexicals 
to instantiate our theoretical framework  we have to define strong language biases in order to limit the combinatorial explosion. 
　the first question is the language in which operators are expressed. the language of indexicals  van hentenryck et al  1j is chosen  motivated by the ease of integration of the user-defined indexicals in gnu-prolog  diaz and codognet  1 . in this language  an operator is written x in r  where x represents the domain of the variable x and r is an expression representing a subset of dx. if we denote x the unary constraint representing a' s domain  then the indexical represents the operator  
　then comes the choice of consistency. we learn the boundconsistency  since it allows to limit the example space to intervals instead of arbitrary subsets. 
　for each variable we learn a reduction indexical and define an indexical for  the reduction indexical for x is of the form x in minx . . maxx where minx  maxx are in some fixed forms. in practice  we use linear  piecewise linear and rational forms. in order to the reduction indexical to be monotonic  the bound minx must be anti-monotonic and maxx monotonic. this can be ensured by syntactic conditions on the sign of the coefficients for each expression. 
　the indexicals for idc could be implemented in two ways: by using gnu-prolog indexicals for predefined constraints in which each instance of min and max is simply replaced by v a l   or by a direct code using v a l and c operators. 
　as distance between two consistencies  we use the global error on the example space e. by considering that / must be correct w.r.t csc  this distance is 
example for lack of space  we present here one example. an user defined global constraint is defined by the following conjunction: x - y   1  a - y   1* x - y   1 * y - x   1  x   1  y   1. when treated globally as a two dimensional polyhedra  these constraints yield less indexicals than the above decomposition. on the domain  1..1  x  1..1   our system generates the following operators: 

reparation operators are implemented from gnu-prolog indexicals. here is the one for x': 

when trying all reductions on boxes included in  1  x  1   the learned operators ran in 1 ms  while the nondecomposed constraints ran in 1 ms. all tests have been done on a pentium1ghz  1mb running linux. 
1 	conclusion 
related work solver learning has been first introduced by  apt and monfroy  1  in which they automatically generate a set of rules from the tuples defining a constraint. the complexity of the rules generation limits them to small finite domains such as boolean. 
the system propmlner  abdennadher and rigotti  1; 
1 j is devoted to the learning of constraint handling rules  fruwirth  1 . the produced solver is often very readable  especially when a small number of rules are produced. while being less general in theory since we only deal with finite domains  our method works on domains and constraint arities much larger. 
　in an earlier paper  dao et al.  1   we have presented an indexical learning process. we propose here two main improvements  besides a more general theoretical framework: the possibility of using only a sample of the example space while still ensuring the correctness of the learned solver and the reparation method. it follows that our system is able to handle larger constraint arity and larger domains and therefore yields a better solver. 
summary we have presented a general  languageindependent framework for finite domain constraint solver learning and an instantiation to the learning of boundconsistency with gnu-prolog indexicals. 
acknowledgment we gratefully thank michel bergere and the anonymous referees for their remarks on this paper. this work is supported by french cnrs grant 1je1. 
