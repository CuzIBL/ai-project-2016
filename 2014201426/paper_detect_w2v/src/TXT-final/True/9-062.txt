 
　　the problem of breaking an image into meaningful regions is considered. bayesian decision theory is seen to provide a mechanism for including problem 
dependent  semantic  information in a general system. some results are presented which make the computation feasible. a programming system based on these ideas 
and their application to road scenes is described. 
introduction 
　　the problem of segmentation  breaking a complex image into sections  is a central problem in machine perception. the analogous problem arises in the analysis of speech and  for that matter  in any problem of overwhelming size. we w i l l concentrate on the image segmentation problem  but most of the ideas 
are of wider applicability. the main idea is to apply  bayesian  decision theory techniques and the use of problem-dependent information  semantics  to attack the image segmentation problem. 
     the segmentation problem for t.v. images is as follows: given a picture of some scene  we have a rectangle composed of some  1 x 1 points and for each such point some information on the light intensity and perhaps color. for any further processing 1 points is far too many  so  depending on the perception task that we have in mind  the image should be segmented into regions. each of these regions should be meaningful in the problem domain and the relevant information needed for the specific task should be easily obtainable. 
     there has been a great deal of work on segmenting images and a certain limited success has been achieved. 1 some biological and meteorological images can be effectively segmented using known techniques. however  for images like those arising in road scenes or presented to assembly-line robots  the existing a l gorithms do not suffice. a major problem is that the existing algorithms use absolute criteria such as i n tensity difference  boundary strength  etc. to form regions 1 but the criteria for what is a  region  w i l l surely vary with context. certain shades of green  yellow and brown might be merged into a single region of grass in a scene  yet distinguishing the same set of colors might be crucial for region separation in another scene or even in another part of the same scene  assume for instance that a yellow 
car occludes part of the grass . another c r i t i c a l consideration is the goal of the perception. for borne problems separating the green grass from yellow grass w i l l be essential  in others completely confusing. 
　　the importance of goal direction and contextdependence for effective problem solving is now well understood in a r t i f i c i a l intelligence and scene analysis is just another example. one can certainly 
write a special purpose region analyzer for a fixed class of images and it w i l l work better than any general algorithm. 	this  in fact  has been done success-
fully by brice and fennema1 and harlow and eisenbeis1 
and is sometimes just the right thing to do. the obvious difficulty with this ad-hoc approach is that it requires a lot of work to build or modify each i n -
dividual program. 
     in this paper we present a theoretical framework for a general system incorporating context dependence in a region analyzer. the theory has been developed into a computer program for region analysis and a number of experiments on real pictures have been performed. there is an enormous amount of work remaining to be done  but we feel that a promising start has been made. 
before describing the system in more detail  we must make one additional point of clarification. it is a tenent of a r t i f i c i a l intelligence research that any information that can be brought to bear w i l l be helpful in a given task. this is especially true in 
machine perception  but our current efforts do not attempt to exploit it fully. region analysis is assumed to be a preliminary  relatively fast  partitioning of an image before further processing. for this reason  we have made no attempt to include semantic features like three-dimensional shape analysis in the region analyzer. we are s t i l l studying the cap-
abilities of our semantic structure. as more experience becomes available we w i l l be able to determine which information should be used in the segmentation process and which should be left for higher level processing. 
1. theory 
　the underlying theory of our system is bayesian decision theory. the ideas are quite beautiful and powerful  but have not received as much attention as they should from a r t i f i c i a l intelligence workers. even 
a brief description would be beyond the scope of this paper:  elementary decision theory  and  decision analysis - introductory lecures on choice under uncertainty  are good introductions and  optimal statistical decisions  and 'mathematical statistics a decision analysis approach  are advanced texts. 1 1 the two central ideas are the use of a u t i l i t y function to 
measure the value of various alternatives and an optimality theorem. 	this theorem shows that any adequate 
 admissible  strategy is equivalent to a strategy of maximizing expected utility for some choices of utility function and probabilities. the theory provides a com-
plete world view  like  e.g. logic  and has been applied to many management problems. the difficulty in practice is that it is d i f f i c u l t to select the u t i l i t y and probability functions and to actually carry out the computations. we describe below how we attack these problems. 
　　　for region analysis  we can define the u t i l i t y to be the probability that the analysis is correct  contingent upon two factors: the  a priori  context knowledge about the picture domain  and the values of 
1 measurements on this particular image  i.e. we are to maximize: 
p global-tnterpretatton | context.values of measurements  
     an interpretation will divide the image into regions and attach a type label  meaning  to each region. one choice of evaluating the overall interpretation would be obtained by considering each region independently. if for a given partition of the image into regions we have  r i  i = l  n l regions then the interpretation assigns label iht i  to region r i . the 
values of int i  will be sky  grass  road etc. depending on context and goals. then assuming independence 
we will want to maximize the expression: 
pfr i  is int i  | context values of measurements 
1
	 	on r i t 
over all partitions of the image into regions and 
assignments of labels to regions. this is quite conventional so far and is  in fact  too simple for our purposes. we want to account for two additional considerations. first we must use the model to get a good segmentation of the image into regions. for example  we might want to merge green  yellow and brown patches to create the whole area that we call grass. secondly  we want to use additional semantic constraints e.g. the grass is below the sky  to influence the total probability of an analysis of the scene. 
       in an attempt to enrich the semantic structure to support more of the problem knowledge and to provide for control mechanism on the region growing algorithm  the semantic structure was allowed to have also  first order structure . in addition to the properties of each individual region wc have  for each pair of adjacent regions of some interpretations  expected relative properties and some expected features of their common boundary line. for instance if we have two adjacent regions  one which is named  sky  and the other   h i l l   then we expect that the sky is above the h i l l   is a brighter blue than the hills  and that the boundary is usually a more or less horizontal smooth line. the relative properties are usually more significant than the absolute properties since they are less sensitive to variation between pictures. this semantic model is too limited to describe all that is known of a scene  but many classes of scenes can be segmented properly with first order methods. 
　　　recall that we want to get a partition of the input and interpretation for the segments  regions  and boundaries so as to maximize the likelihood of having the right interpretation. let r i  be the i-th region  b i j  the boundary between region r i  and r j   if it exists  and the label of r i  be int i . then with our first order assumption the expression that we want to maximize is: 
pfglobel interpretation | values of measurementil = 
 l p r i  is int i  j values of measurements on r i } x'fl pfb l.j  is between int i  and int j  | b i j 's measurements  
b i.j  	 
　　　the use of  represents more than just our belief that properties of individual regions and boundaries will suffice for our semantics. it also entails an assumption that the probability can be factored into the product above. this amounts to assuming that the probabilities of interpretations of each region  boundary  are dependent on the local properties of the individual region  boundary  and are independent of all other measurements. thus boundary b i j  which is the boundary between r i  and r j  is evaluated as boundary between int i  and ikt j   where r i  is labeled int i  and r j  is labeled int j . 
     for example  if int i  is  sky  and int j  is   h i l l     the evaluation will include factors involving the expected direction  smoothness  etc. of a boundary between sky and h i l l . thebe factors are assumed to be independent of the particular color etc. of the sky and h i l l . if the independence assumption seems to be unreasonable  consider the following argument: 
pfvalues of measurements  interpretation  context ! 
pfinterpretationl 	- 	. x pjinterpretatlon | context values of measurement  	rvalues of measurements   
	context  	context  	 
now 
pfvalues of measurements on r i  i r i  is int i   context! and 
pfvalues of measurements on b i j} | r i  is int i  and r j  is intfj .context  
are plausibly considered independent of each other. a similar argument can be used for the factorization of the other two terms in the expression on the right of   l   . putting these terms together give us back what we have in   1 . prom all picture models which were described in the literature the model described in reference ly is most similar to ours in the basic methodology aspects. 
　　　for a given utility function  like  1  there are standard techniques in decision theory for finding the 
maximum utility. unfortunately  the general techniques are too slow and much of our effort has gone into developing algorithms for efficiently computing an approximately optimal partition. the region growing algorithm starts with many small regions and on each iteration merges two adjacent regions  regions with a common boundary . the two basic decisions are which pair of regions to merge on each iteration and when to stop the algorithm. these two decisions can be controlled directly by the limited probabilistic semantic 
world model that we have-
　　　in general  on each iteration of region growing the pair of regions whose common boundary is the weakest in the current image partition will be merged. hence the control of the region growing algorithm is by evaluation of the boundary strength. 	we will show how our semantic representation can be used directly to compute the goundary strenth. 
　　　the second task of the semantics is to produce the stopping criterion for the region grower. in our case since we want to maximize 
pfinterpretation | measurements' values  context  
the optimal partition will be the one with that interpretation which maximizes this likelihood estimate over all partitions and all possible interpretations of partitions which do not allow false boundaries  boundaries between two regions which are interpreted as parts of the same final object . 
1 　　　in order to have an effective way to determine that probability we need a relatively fast way to obtain or approximate for a given partition the optimal interpretation and its value. 
　　　in the next section  we w i l l describe relatively fast methods for computing upper and lower bounds on the optimal value of the probability of a given partition. 
　　　the bounds on the value of the global interpretation w i l l be used as follows: the algorithm w i l l collapse regions  and generate a sequence of image partitions. for each partition generated  the bounds on the possible value of the best interpretation w i l l be evaluated. then when the collapsing has been carried too far  as observed by strong decline of the possible interpretation value  the system w i l l hack-up to the most promising partitions observed while growing the regions  as indicated by the lower and upper bounds estimates of the quality of the partition observed . next we w i l l search for the best interpretation for the partitions observed whose bounds were high enough to make it possible that they are the best partition observed. the current algorithm w i l l simply choose the best of these  but more sophisticated procedures can be used if necessary. 
　　　althernatively we can use the procedure which assigns meaning to a l l regions directly as the stopping criterion. 	that i s   if the best global assignment found for the given image partition does not 
interpret any boundary as an erroneous boundary  e.g. a boundary between regions of the same interpretation  we stop merging  see discussion below on lower bound estimates for the image partition for more details . 
1. program organization 
　　　the program has four basic sections: 1  the i n i t i a l i z a t i o n   1  i n i t i a l assignment and boundary strength evaluation  j  heuristics to evaluate a partition by approximating its optimal assignment  and 1  a limited interactive learning system. 
　　　the f i r s t step is to take a vector of values of measurements at a set of sample points  in our system usually 1 . the local measurements currently indicate only the dominant gray level around the sample point or if the image is observed through several color f i l t e r s the dominant gray level through each of the color f i l t e r s . 
　　　we employ a preliminary region-merging for i n i t ialization. 	the idea is to use a very crude algorithm on the reduced problem. 	the simple merging algorithms considered were: 
　　　1  take an image point and grow a region around it consisting of a l l image points which can be connected to the starting point by a path of points which satisfies the following conditions: a  each adjacent 
pair of points along the path are adjacent geometrically  b  the jump in the value of the measurements vector between two adjacent points along the path is less than some threshold. 1  note that some modifications are needed to treat gradual but strong changes. 
　　　1  this initialization is an extension of 1. 	it initializes as in 1 and then collapses  independent of order  a l l boundaries with strength less than some threshold. 	the advantage here over method 1 is the option to use more sophisticated boundary strength evaluation.1 
　　　our initialization method utilizes a sampling technique initialized as in 1  taking the connecting path to be a path of sample points  and then merges regions iteratively by eliminating the globally weakest boundary f i r s t . 	that i s   on each iteration the pair of regions whose common boundary is weakest in the current image partition is merged into one region. 
　　　the boundary strenth in this stage is evaluated directly from the differences across the boundary and its geometrical structure. 1 the stopping crietrion in this case can be a threshold on the weakest boundary  that is the merger is stopped when the weakest boundary is stronger than a given threshold. this threshold is chosen very conservatively so as to stop this simple 
minded region grower before it produces false merges. in our experiments it turned out that the simple i n i t ialization algorithm had to be stopped quite early so that the semantic control was called with about 1 regions present  see reference 1 for more details. 
　　　the main algorithm first computes additional properties  like shape  of the regions and boundaries resulting from the i n i t i a l i z a t i o n . it then assigns probabilities to the tentative interpretations of the regions   i.e. computes 
pfr i  is x 	values of measurement on r l    
　　　the boundary strength may be evaluated by two related methods: 1  the probability that the boundary is a real boundary  a boundary between different objects in our semantic world model  and 1  the change in the value of the interpretation as a result of eliminating the boundary. we w i l l describe here the f i r s t of these which is the one currently used. the second method has some advantages and w i l l be discussed below. 
     we approximate the probability of the boundary to be real as follows: 

　　　the next step is to search for a partition which yields a good value of   1   . this involves both forming partitions and computing the value attainable from 
a labelling of regions in each partition. 
     a lower bound on the value of an image partition is computed by actually finding a good global inter-
pretation using a simple fast algorithm. 	briefly what 
we are doing is to take the region of highest confidence interpretation and assign to it its most probable interpretation. this assignment allows the program to update the probabilities of adjacent regions of the newly interpreted region by considering the boundary features of the newly assigned region. then the region of highest confidence from a l l un-interpreted regions is assigned  etc. this is essentially starting a depth f i r s t search of the tree of interpretations and yields 
a value for the partition which is the desired lower bound. 	extending this search to f u l l tree search would yield the optimal interpretation. 	more details on the sequential assignment process are given below. 
1 　　　recall that we want to approximate the maximum possible value of the expression in  over a l l possible values of int i  for a given picture partition. 
     the assignment procedure we use to estimate the best possible assignement of int i  for a l l r i  for a given image partition is as follows: 
　　　1  compute for each region the ratio  based just on local measurements of the region  between the most likely interpretation and the next most likely interpretation. this ratio w i l l be called the confi reg . let xl be such that p r is x1 values of measurements on r  is maximized for r and let x1 be such that p{r i  is x1 values of measurements on r i l is the next highest. then 
	p r i  is xl 	measurements of r i  
conflfr i   - 
	p r i  is x1 	measurements of r i  
　　　1  sort the regions by their confidence ratio. 
　　　1  assign the region with highest confidence  the one with highest ratio  its most likely interpretation. 
　　　1  update probabilities of different assignment to regions that were not assigned already  assuming that the last assignment is true. let the region assigned most recently be r l  and its interpretation be int l . now if r i  has boundary b i i  with r l   then for any interpretation x of r i  in evaluating equation 1 above  there w i l l be a term of the form 
　p{r i  is x values of measurement on r i   from the first product and one of the form 
p b l i  is boundary between int l  and x b   l   i   ' s measurements' values  
from the second product. 	therefore a better approxi-
mation of the probability of r i  being x  assuming that r l  is int l   is 
	pold r i  is x  	x 	p b l i  is 
pnew r i  is x  = 	between int l  and x 	b   i   j   ' s features  
　　　thus we use the new information to find a more accurate probability for the different possible assignments for r i   by counting the newly interpreted region r l . 
     we do that updating to a l l possible interpretations for a l l adjacent regions of r l . 
　　　1  compute the new confidence ratio and rrsort the regions by the new confidence ratios. 
　　　1  if any region is s t i l l unassigned go to step 1 else exit. 
     this process of assigning interpretations iteratively provides a good guess on the possible best interpretation  but it does not guarantee the total 
maximization of our product. 	we can extend the current algorithm into a f u l l tree search  undoing some assign-
ments and trying alternative ones  to get the best interpretation. this w i l l be a depth first search in the tree of a l l possible assignments  where each node 
mill stand for the assignment of a meaning to a region. for efficiency purposes we can use various pruning techniques to reduce the search effort required to secure optimality  ＜ our current algorithm is the 
portion of the tree search up to the point where we get to the f i r s t terminal node   f i r s t global assignment . one should also note that the same sequential assignment and extension into tree search can be applied to an extended f i r s t order world model  where we allow relations between any two regions  not necessarily adjacent  if we continue to assume independence. the only difference is that we w i l l have to update the probabilities and confidence of a l l regions not just those regions adjacent to the newly interpreted region. 
     we have the option to use this assignment procedure as a region grower by taking a l l pairb of adjacent regions that were assigned the same meaning and 
merging them. to avoid false merging we consider a l l regions which were assigned meaning with a low confidence level not mergable into other regions. this 
approach may be extended by adding it to the meaning assignment algorithm as a new step 1. if any adjacent region of the newly interpreted region is a l ready assigned a meaning and it is identical with the 
meaning of the newly interpreted region  then merge the two together. 	from that point on the unified region 
w i l l be considered in updating probabilities of other  not yet interpreted regions. 
     we can use the two extensions  merging on the run  and full tree search  together. this w i l l generate a very reliable meaning assignment concurrent with a region growing procedure which has backup capabilities. it w i l l be however  relatively slow. 
upper sound 
     the upper bound is computed by relaxing the consistency constraint. this condition means that a boundary between two regions of known interpretation has to be counted in as a boundary between those two interpretations. we relax this condition by hreaking the product  l  into local sub-products and finding the best local interpretation for the terms involved in this subproduct. we take the best possible value for each sub-product separately  and  multiplying them  obtain in an upper bound on the value of the best global interpretation. one such relaxation is to consider a l l regions and boundaries independently and to 
assign for each the best possible interpretation considering only its own properties. the product of a l l these probabilities is an upper bound on the value of equation 1. it is this sort of estimate which would be used to approximate the single step improvement in the second method of boundary evaluation mentioned above. an exact computation of the change in interpretation value would be too time consuming. we do not yet know which boundary strength computation w i l l be better. 
     given the lower and upper bounds of the value of the best possible interpretation for a given picture partition  a variety of graph searching techniques can be applied to find a suitable interpretation and to pick out the best partitions observed for more detailed investigation using the f u l l semantic knowledge. 
	 . 	learning 
     one of the basic problems with any recognition system is the development of sharp classification cap-
abilities for objects  in our case interpreting regions and boundaries . our case is especially complicated since we need to recognize portions of objects  spurious boundaries and to overcome partial occlusions. to 
1 make the game of developing these capabilities easier we developed an interactive learning system. its main task is to carry out bookkeeping jobs  to estimate probabilities  and to point out pitfalls and options for improvement in the classification scheme. 
　　　the non-parametric approximation of the probabil i t y density function works as follows: given a set of measure functions on some class of objects  we break the space of a l l possible combinations of values of those measurements i n t o c e l l s  not necessarily c a r t e s i a n     t r y i n g to get an e f f e c t i v e c l a s s i f i c a t i o n . that i s   given that the values of the measurements of an object f a l l i n t o some c e l l   we want that often the p r o b a b i l i t y estimate of the real meaning of the object to be h i g h . given a fixed partition of the measurement 
vector space i n t o c e l l s we want to learn the p r o b a b i l i t i e s of d i f f e r e n t 	i n t e r p r e t a t i o n s 	of objects whose 
measurements' values f a l l i n t o a c e l l . this is done by keeping  for each c e l l and for each possible i n t e r p r e t a t i o n   the count of how many times in the past the value of the measurements of objects of that i n t e r p r e t a t i o n f e l l i n t o t h i s c e l l . the p r o b a b i l i t y of that i n t e r p r e t a t i o n is j u s t the number of times the 
measurements of an object of that i n t e r p r e t a t i o n f e l l i n t o the c e l l   divided by the t o t a l number of objects 
which 	f e l l 	i n t o that c e l l . 
　　　this brings us to the second learning system which would t r y to create a c e l l s t r u c t u r e w i t h as few c e l l s as possible while a t t a i n i n g a good c l a s s i f i c a t i o n among the possible i n t e r p r e t a t i o n s . for t h i s purpose we sould u t i l i z e an augmented c l a s s i f i c a t i o n tree whose leaves correspond to the c e l l s . the aug-
mented tree also allows representation of the fact that two measurements are independent. 
       currently t h i s tree is generated i n t e r a c t i v e l y . to generate a sub-optimal c l a s s i f i c a t i o n tree autom a t i c a l l y the system would keep a whole h i s t o r y l i s t containing objects observed in the past  t h e i r prope r t i e s and t h e i r real meaning. based on t h i s h i s t o r y the system could t r y to order the a p p l i c a t i o n of 
measurements so as to get good and cheap c l a s s i f i c a t i o n   creating as few as possible c e l l s   l e a v e s     
w h i l e s t i l l keeping the good c l a s s i f i c a t i o n p r o b a b i l i t y high. it also has the a b i l i t y to point out c e l l s that are not s u f f i c i e n t l y d i s c r i m i n a t i n g so that they 
may be worked on i n t e r a c t i v e l y or automatically   p r i m a r i l y by breaking each such c e l l i n t o f i n e r subc e l l s   so that for each eubcell the c l a s s i f i c a t i o n is more r e l i a b l e   . a detailed d e s c r i p t i o n of t h i s l e a r n ing and c l a s s i f i c a t i o n system is given in reference 1. techniques for organizing the c l a s s i f i c a t i o n tree so as to get near optimal sequential c l a s s i f i c a t i o n is described in slagle and lee  where game  a-b  type 
tree search is u t i l i z e d in creating the decision t r e e . 1 
　　　such learning techniques are common to many pattorn recognition and sequential decision problems. 	a 
vast amount of research  both t h e o r e t i c a l and e x p e r i mental  has been done in this area. reference 1 is a good d e s c r i p t i o n of the theory and reference 1 is a good i n t r o d u c t i o n to various applicable techniques. it is i n t e r e s t i n g to comment that a learning scheme s i m i l a r to the f i r s t  emphasizing c o r r e l a t i o n s   was 
developed by arthur samuel. 	attempts are now being made to apply t h i s learning scheme to speech seg-
mentation and r e c o g n i t i o n . 1 
　　　it 	is i n t e r e s t i n g to compare our technique w i t h the nearest neighbor c l a s s i f i c a t i o n which is i n v e s t i -
gated in various-papers. 	1 	this p r i n c i p l e is to take 
for a new unknown occurence of an object  the i n t e r -
p r e t a t i o n of the object observed in the past whose features of the new o b j e c t . there are two deficiencies in t h i s approach. f i r s t   only r a r e l y is there an ob-
vious metric on the space of values of measurements  and hence only rarely is it clear exactly how to measure distance in the features of two objects. secondl y   it is very hard to search for the nearest object observed in the past  unless we are in one dimension  since we have to compute the distance from many examples observed in the past to get the minimal d i s tance. an e f f e c t i v e way of reducing the search time 
w i l l c a l l for breaking the space i n t o c e l l s the way we do. that i s   l o c a t i n g f i r s t the c e l l i n t o which the measurements of the new object f a l l and then searching only among known objects whose measurements f a i l i n t o that c e l l for the nearest one  ignoring objects which f a l l i n t o other c e l l s . t h i r d l y   the answer returned is j u s t one possible i n t e r p r e t a t i o n and not a l i s t of d i f f e r e n t possible i n t e r p r e t a t i o n s w i t h various proba b i l i t i e s . extending the nearest neighbor p r i n c i p l e to find the n- nearest objects and computing the pro-
b a b i l i t i e s of d i f f e r e n t i n t e r p r e t a t i o n s based on them w i l l make the computation even less e f f i c i e n t because of search time and w i l l force even more reliance on space p a r t i t i o n i n g than the method we c u r r e n t l y use. 
	1. 	results and conclusions 
　　　as a f i r s t experiment  the program was applied to the problem of segmenting images which might be seen d r i v i n g on a road in the v i c i n i t y of the laboratory. the analysis was s i m p l i f i e d by assuming the camera was in an upright p o s i t i o n . there were s i x possible labels for a region: sky  road  roadside v eg et a t i o n  car  
shadow of car and t r e e . the non-terminal nodes in the c l a s s i f i c a t i o n tree are c a l l s on integer valued funct i o n s . some properties and the number of possible 
values for each a r e : l i g h t i n t e n s i t y  1  color hue 1 l color s a t u r a t i o n  1   size   1   l o g a r i t h m i c     v e r t i c a l p o s i t i o n  1   h o r i z o n t a l p o s i t i o n   1     p o s i t i o n on edge of image  1  and some crude shape d e s c r i p t o r s . 
　　　with s i x types of region  we get 1  1/   types of boundary. 	some boundary properties used  w i t h the 
number of values for each are: r e l a t i v e size  1 l o g a r i t h m i c     r e l a t i v e i n t e n s i t y   1   l o g a r i t h m i c     r e l a t i v e color  1 green r e l a t i o n x 1 red x 1 b l u e     boundary shape and o r i e n t a t i o n  1 classes   r e l a t i v e p o s i t i o n  1 r i g h t extremes x 1 l e f t extremes x 1 above extremes 1 'i below extremes   boundary length  1  and p o s i t i o n of boundary in frame  1 . the algorithms for computing the various properties and the d i s c r i m i n a t i o n in each were chosen i n t u i t i v e l y . 
　　　i n i t i a l values for the counts in c e l l s were also set i n t u i t i v e l y   and the learning routine was used i n t e r a c t i v e l y to r e f i n e them  approximating the prob a b i l i t i e s and breaking c e l l s t o finer c e l l s i f d e s i r ed for b e t t e r c l a s s i f i c a t i o n   . 
　　　the program was able to segment the scenes corr e c t l y using only region properties except that it had 
d i f f i c u l t y i s o l a t i n g the image on the car on the road. since a car can be of any c o l o r   the program either needs to make use of boundary r e l a t i o n s     e . g . the car is on the road  or perhaps shape d i s c r i m i n a t i o n should be made more s o p h i s t i c a t e d . 
　　　a region growing algorithm based on absolute properties would not work in these scenes mainly for the f o l l o w i n g reasons: 1  the trees and sky generated 
very many regions that were more varied in the values of t h e i r measurements than any other t h i n g in the p i c t u r e . 1  the sides of the road are patches of brown  green and y e l l o w . 1  strong shadows appear frequently on the road. 
1        the second domain to which the system was applied was l e f t v e n t r i c u l a r angiograms  x-ray images of the l e f t v e n t r i c u l a r made v i s i b l e by i n j e c t i o n of a r a d i o opaque dye . these angiograms are useful for various cardiologic applications since they allow observation 
of myocardial movement. the semantics used for this application described the heart interior  chest cavity background and the dark frame border. no color was available here  and as a result light intensity  position and shape was the major recognition tools. in addition the non-semantic region grower had to stop at a relatively early stage because of noise and lack of high contrast border. the number of regions on termination of the non-semantic region grower was two hundred. it is encouraging that the adjustment to the second domain was very easy. we hope that in the future a general and rich library of feature extracting routines with the capability of working on many models 
w i l l be achieved. 
　　　shown below are illustrations of the results of experiments. all pictures are taken from a graphics terminal with gray level capabilities. there are six 
bits available per image point. five are used for displaying the original picture  while the high order bit is used for the overlay of displaying the boundary lines. 
　　　this is a preliminary version of a general system for utilizing decision theory in scene analysis. there are a number of ideas from both areas that have yet t  be tried and many experiments yet to be run. however  there are already some additional considerations which should be mentioned. 
     the most restrictive assumption in the current program is assumption that the interpretation of a region depends only upon adjacent regions. there are 
ways of selectively relaxing this rule so that occluded objects can be understood without having each region depend on a l l others. in fact  the entire approach w i l l stand or f a l l on the question of whether there is sufficient independence to allow for good performance without prohibitive calculation cost. 
　　　the choice of local measurements around each point i s   of course  another crucial factor. the idea of relatively coarse sampling allow us to apply 
more operators  including ones like hueckel's  or 1  texture finders which inherently involve many paints. there is the additional important potential for variable density sampling  possibly using planning in the manner of kelly.1 
     a more d i f f i c u l t task would be to effectively i n corporate 1-d constraints  as done so successfully for blocks by  i.e.  falk and waltz  this would call for the addition of vertex properties .1 there are 
many possible refinements to the learning procedure  especially on the question of what measurements are important. 
bibliography 
1. barrow  h.g.  ambler  a.p. and burstal  r.m.  some techniques for recognition structures in pictures  department of machine intelligence and perception  university of edinburgh  1. 
1. barrow  h.g. and popplestone  r.j.  relational description in picture processing  machine .intelligence. 1  1  1. 
1- brice  c.r. and fennema  c.l.  scene analysis using regions  journal of a r t i f i c i a l intelligence  1  1  1. 
1. chernoff  h. and moses  l.  elementary decision theory  wiley publishing company  n.y.  1-
1. de-groot  m.h.  optimal statistical decisions  mcgraw-hill  n.y.  1. 
1. duda  r.d. and hart  p.e.  pattern classification and scene analysis  wiley  1-
1. falk  g.  computer interpretation of imperfect line data as a three dimensional scene  a r t i f i c i a l intelligence memo 1  stanford university  i1. 
1. ferguson  t.s. 'mathematical statistics  a decision analysis approach  academic press  1  
1. feldman  j.a.  a way of looking at things  dept. of computer science  hebrew university  jerusalem  january 1-
1. fu  k.s.  sequential methods in pattern recognition and machine learning  academic press  n.y.  1. 
1. griffith  a.k. 'mathematical models for automatic line detection  jacm. 1  1-
1. guzman  a.  computer recognition of visual object in a three-dimensional scene  m .i.t.  1-
1 harlow  c.a. and eisenbeis  s.e.  the analysis of radiographic images  technical report  dept. of electrical engineering  university of missouricolumbia. 
1. hueckel  m.h.  an operator which locate edges in digitize pictures  a r t i f i c i a l intelligence memo 1   stanford university  i1. 
is kelly  m.d.  visual identification of people by computer  a r t i f i c i a l intelligence memo 1. stanford university  i1. 
1. nilsson  n.j.  problem solving methods in a r t i f i c i a l intelligence . mcgraw-hill. 
1. freparata  franco p. and ray  s.r.  an approach to a r t i f i c i a l nonsymoblic cognition  information science  k  1  1. 
1. pingle  k.k. and tenenbaum  j m.  an accomodation edge follower   ijcai-1. 
1. quam  l.h.  computer comparison of pictures  stanford a r t i f i c i a l intelligence memo kh   stanford university  1. 
1. raiffa  h.  dicision analysis - introductory lectures on choice under uncertainty  addison wesley  july 1. 
1. rosenfeld  a.  picture processing by computer  academic press  n.y. i1. 
1. samuel  a.l.  some studies in machine learning using the game of checkers ii - recent progress  ibm journal of research and development  1  1  1. 
1. slagle  j.r. and lee  r.t.c.  application of game 
tree searching techniques to sequential pattern 
recognition  cacm  io1-iio  feb. 1-
1. thomas  a.  color perception  stanford university 
1-
experiments in speech recognition using signa-
1 1. thosar  r.b. and samuel  a.l.  some preliminary ture table learning  a r t i f i c i a l intelligence memo  stanford university   to appear   
1. vicens  p.  aspects of speech recognition by computer  a r t i f i c i a l intelligence memo 1  stanford university. 
1. waltz  d.l.  generating semantic description from drawing of scenes with shadows  m.i.t. tr-1i. 
1. yaklmovsky  y.  picture processing  use of probabilistic semantics for region growing and recognition  stanford university.  forthcoming dissertation . 
1. cover  t.m. and hart  p.e. 'fewest neighbor pattern 
classification  ieee trans. information theory  
vol. 1  1  1-


 a-1  the output of the region grower which melts weakest boundary f i r s t with non-semantics boundary strength evaluation. this is the result of stopping with the default stopping cri terion. 


 a-l  the output of the segmentation base on path connectivity when it is stopped by the default stopping criterion. the result ie image segmented into a few hundred regions. 

 a-1  result of merging regions down to 1 regions using weakest boundary f i r s t algorithm and non-semantics boundary strength evaluation. note that the top of the car ie melted into the roadside vegetation. 


 a-1  the effect of reducing the number of regions to 1 using path connectivity algorithm  using more liberal threshold than our current stopping threshold . 
1 
 a-1j result of attempt to reduce the number of regions to 1 without using semantics   melting weakest boundary f i r s t non-semantic boundary strength evaluation}. 
 a-g  output of region grower based on semantics.  melting weakest bounqary f irst where boundary strength is computed using the semantic world model . 

 a-1  f inal grouping of regions based on the interpretat ion assigned to them by the worid model. regions whose meaning was assigned with confidence less than 1 are not tnergable. they occur usually on the real boundary between two regions. 

 b-l  original picture. 

 b-1  output of the non-semantic weakest boundary meited f i r s t regi on grower. 

 b-1  output of the semantic based region grower 

 b-1  result of grouping regions by their assigned meaning. taking only 
regions which were assigned meaning w i th conf i dence over 1 to be niergable. 
1 
 b-1! grouping regions by their assigned meaning  ali regions considered mergable. 

 f-l  left ventricuiar ang iogram. output of the non-semantics weakest boundary f i r s t region grower. the stopping c r i t e r i o n is to stop when the merger gets down to two hundred regions. 


 f-1-1  iterations of semantic region grower. the region grower used i s grouping of all adjacent regions which are assigned the same meaning by the sequential assignment procedure  before the f i r s t 

1 

assignment with low confidence level occurs. on each iteration the confidence threshold is lowered. 

 f-s  final output . the heart interior is the dark center  around it is the chest cavity and on the two sides there is the dark frame border. 
