 

　　　this paper reports on the continuing design of and experimentation with jason  the berkeley robot. progress has been made in various aspects of the hardware  including the chassis  communications controller  and onboard microprocessor  and software  including problem-solving programs and world models . a particular experiment  analogous to the classical  monkey and bananas  problem  is described. a major feature of the reformulation of this problem is the use of decision analysis in coping wj th uncertainty. based on the accimula ted expected costs of executing the steps of various hypothetical plans  jason can evaluate the relative merits of direct act ion versus prior information-gathering using potentially unreliable sensors. 
introduction 

　　　as reported at the last ijcai conference 1 the objective of our current research at the uni-
versity of california at berkeley is the design and implementation of a relatively inexpensive  general-purpose  computer-control led  mobile robot. the berkeley robot  dubbed jason  was initially designed during the spring of 1 and tested off-line the following summer. hard-wire  blind-mode computer control was successfully accomplishcd during january 1. unreliable breadboard wiring as well as greater than expected demands for on-board power have led to a substant ial redesign effort; testing of a considerably improved version of jason is now underway. 
　　　our ultimate goal  as stated earlier  remains the investigation of the class of problems that a robot both encounters and creates while performing 

elementary tasks in a real-world envi ronment ineluding act ive human beings. the results of this research will hopefully enable us to construct better and safer robots at a modest price that are still capable of performing a variety of useful tasks such as factory or ware-house work or can function as a teaching aid for young children in the classroom. 
　　　this paper is divided into five sections. the first briefly reviews some of the recent improvements to jason hardware and software. the second section suggests some of the ways that robotics research differs from conventional al problem-solving research. the third section presents a decision analysis formulation of the classical  monkey and bananas  problem. the fourth section provides the results of the decision analysis. finally  the last section summarizes and proposes some improvements to jason hardware and software for the future. 
jason hardware/software improvements 

　　　figures i and 1a-f provide an overview of the current state of jason. 
a. hardware 
　　　first we discuss improvements to the key hardware subsystems: the chassi s  the sensors  and the communications controller. 
　　　1. robot chassis--the jason chassis consists of a half-inch thick aluminum base plate with an area of about two square feet with two additional aluminum shelves mounted above for electronic equipment- the three-ball configuration originally designed to support the front of jason  although conceptually good  did not perform well on rough surfaces 1 ike a parking lot  and consequently was replaced by a heavy-duty  1-inch diameter  swivel-castor wheel. to provide additional 
on-board power  the conventional  1-amp-hour  lead storage  auto battery was replaced by a 1-
amp-hour  1-pound  train battery. due to extensive two-handed coordination problems  the original plan for two simple hands has been reduced to one  and a prosthetic arm with jaw gripper has now been installed. a simple two-posi tion-sensor push bar has also been installed: one setting indicates slight pressure contact while the other indicates too much pressure  i.e.  jason is trying to push a nonpushable object. the motor-control unit was also rebuilt to make it more rugged. 
　　　1. sensors--an a-to-d converter to extract texture information as well as range data from the analog output of the ultrasonic torch has been dcsigned. an led proximity sensor has been mounted on the arm  and the proximity-sensor interface was completed. 
　　　1. communications controller--the preliminary jason 1-bit character asynchronous communications controller was successfully bench tested  re fabricated on circuit cards  and mounted in a new card rack and chassis by one of the authors  robb  previous problems of vibration should now be minimized  and circuit debugging should be greatly facilitated. because the controller has been designed to be teletype-compatible  jason could in principle be interfaced to any computer wi thout special-purpose hardware being installed at the computer side. for example  jason has already been connected to an hp-1  a cdc-1  and a pdp-1 computer system. furthermore  we have recently demonstrated jason over the arpa net. further details on the controller can be found in ref 1. our fcc radio-license was renewed  and two-way radio telemetry has been successfully bench tested  

1 



b. software 

　　　on the software side  the check out of realtime interactive routines was handicapped by the removal of the hp-1 computer from the lawrence hall of science. thus  a l l interactive work with 
jason during the last year was simulated on the cdc-1 available on the berkeley campus. we have recently transferred jason software to an interactive dec pdp-1 computer system and have successfully tested jason over the arpa net. 
　　　in the mean-time the jason simulator  which has produced output tapes capable of actually driving jason in blind mode  has grown extensively to include a much broader collection of intermediate level operators  ilo's  such as move  turn  face  goto  push  pushto  gotodoor  gothrudoor  etc.  capable of execution in an arbitrary collection of rooms connected by doorways and corridors  navigating optimally through an arbitrarily complex collection of boxes in any room. this work is documented in the jason reference manual 1 and although i t represents the work of many individuals  two of the authors  sinclair and sobek  are largely responsible. output from the simulator will be seen in section iv. 
real-world vs. toy problems 

　　　early research in a r t i f i c i a l intelligence tended to focus on a few well-known puzzles or 
 toy  problems  such as the monkey and bananas  missionaries and cannibals  or tower of hanoi problems  see ref. 1 for these and other examples . although toy problems demonstrate the i n t e l l e c t u a l competence of computers along one narrow dimension  research in robotics has broadened considerably the scope of the problem-solving enterprise. our experience with the jason project permits us to identify at least four general criteria which distinguish real-world robot problems from toy problems : problem-solving environment  problem formulation  data requirements  and solution require-
ments. 
a. problem-solving environment 

　　　a rough spectrum of problem-solving environments in terms of increasing complexity is indicated in the following table: 
in the language of table 1  almost a l l work 
in al was conducted in a s t e r i l e environment  el . subsequent early robotics research began with surgically-clean environments  e1  and was severely criticized for giving the appearance of e1 to uneducated observers  when in reality i t was not very much of an advance over el. as more advanced scene analysis and perceptual techniques became available  emphasis shifted to e1 and e1. with the appearance of more sophisticated hardware sensors initial forays are being made into benevolent environments  e1 . a l l work to date in natural or hostile environments  e1  has been done with teleoperators  where a human is an essential part of the loop. 
b. problem-formulation 
     because of the real-time execution and training aspect of robotics work  the problem for-
mulation must be accomplished in human terms rather than mathematically. thus  voice-input  restricted natural-language-problem statements are desired. other techniques to f a c i l i t a t e manmachine interaction such as  joy-sticks   cursor 
tracking balls  or light pens are also needed. 
c. data requirements 

　　　information to solve the problem may either be inadequate or embedded in a large quantity of seductive but mostly superfluous data  or some combination of these. insufficient information might occur for a variety of reasons:  1  it may not be knowable in principle    i i   it may not be known whether it is knowable in principle    i l l   the necessary information is knowable  but the cost of acquiring it may be prohibitive.  as a special case  the cost may be reasonable  but acquisition cannot be accomplished within s u f f i cient time to be useful   and  iv  it is not known whether the cost of information-gathering will prove to be prohibitive.  in this case decision analysis may be useful.  
　　　once obtained  data may s t i l l possess uncertainty or lack credibility for various reasons: 
 1  the data may be incorrect due to statistical u n r e l i a b i l i t y in the sensory path   ii  the source is known to be prejudiced    i i i   the source is 

known to be antagonistic and may deliberately provide false leads. finally    i v   the data may be inconclusive because of inherent ambiguities within the model upon which it is based and may not y i e l d a d e f i n i t i v e interpretation. medical or meteorological data f a l l in this category. 
d. 	solution requirements 

　　　as distinguished from conventional ai problem solving  a solution is not a solution for a robot until i t has been successfully implemented as action in the real world. there are many opportu-

n i t i e s for f a i l u r e along the path to a solution in this sense: planning failures  execution failures  
and decision failures  a failure of communication between the planner and the executor . 
　　　1. planner failures--within the planner various failure modes may occur: either a plan is found or it isn't. if no plan is found  it could either be due to the fact that none exists  i.e.  the task is t r u l y impossible  or the system lacked the intelligence to find one. if a plan is found  i t might s t i l l fail for a variety of reasons:   i   i t never could have worked  i.e.  i t fails in principle ;   i i   i t sometimes works  i.e.  i t fails in practice . a plan is said to be incomplete1  or 

soft  i f i t deliberately avoids dealing with a l l logically possible contingencies- although such fragmentary plans are generally undesirable  they are sometimes preferable to no plan at a l l . yet even a complete  or robust  plan will occasionally fail at some point in i t s capacity to sustain variation in environmental boundary conditions. if one were to plot the performance of a robot plan as a function of environmental complexity  el to e1 of table 1  then one could characterize the f a i l u r e mode as precipitous or capable of graceful degrada-

tion in proportion as whether the shape of perfor-

mance fell off sharply or smoothly with complexity;   i i i   even though questions of optimality are rarely stated e x p l i c i t l y in the problem formulation because it is normally unimportant whether the absolutely best way of doing something is proposed  plans should be penalized as failures if they are ludicrously i n e f f i c i e n t in accomplishing the job. 
a plan post-processor might be useful in overcoming this kind of f a i l u r e ;   i v   the use of nondetermini s t i c plans with parallel subsolution paths may make a plan more robust at the possible expense of introducing other failure modes. 
　　　1. execution failures--execution failures come in two broad categories: internal and external. internal failures sometimes called crashes  

can either be hard or soft. 	a hard crash is not 

immediately recoverable  and the plan must be reinitialized. i t may have been the result of either unreliable hardware or software. by comparison  a soft crash  usually due to a high-level monitor 

failure  w i l l allow the robot to resume the plan where i t left off  after a delay for reloading a fresh copy of the monitor. external failures are 

of three main types:   i   the robot failed  and knows that i t failed. this may be due to either systematic or random errors in i t s operators when executed in the real world  since a l l actions have inherent uncertainty in their outcomes.  better calibration should hopefully minimize systematic errors.  there may also be other legal error modes for operators  such as  timeouts  or resource-exceeded constraints;   i i   the robot failed  and didn't know that i t failed  sometimes called a mlssense error . this may be due to i n -

f i n i t e looping or other errors in the flow-ofcontrol or to self-deception through imperfect sensing of the true state of a f f a i r s ;   i i i   the 
robot succeeded  but thinks that it f a i l e d  sometimes called a nonesense error . i l l e g a l error 

messages or false alarms cause this kind of f a i l ure. 
　　　1. decision failures--decision failures are much more subtle. five general types w i l l be mentioned:   i   too l i t t l e or too much time devoted to planning compared with execution. this depends on the amount of time spent planning  the cost of thinking  the u t i l i t y of the goal  the penalty for incurring undesirable irreversible state changes in the real world  and so forth. note that human i n t u i t i o n may be very poor in this regard  since 
most human planning appears to take place at the 
subconscious level and therefore creates the il lusion of being cost-free. also  human planning and execution can frequently take place simultaneously  assuming that the execution process is not too intellectually-demanding. a robot may not always 
have this luxury;   i i   the f a i l u r e to capitalize on serendipity. tunnel vis ion during execution may cause the robot to push the solution out of the way in order to recreate the solution according to plan;   i i i   failure to adequately reparameterize plans based on past experience. this 
is sometimes referred to as structural as d i s t i n -
guished from s t a t i s t i c a l learning;   i v   f a i l u r e to reorder p r i o r i t i e s dynamically. mult iple  possibly conflicting goals must be continually monitored during execution. this may lead to seemingly anomolous behavior from the point of view of an outside observer  but be perfectly consistent with internal objectives;  v  failure to distinguish local from global failures  i.e.  calling upon the planner to replan from scratch  when salvaging the existing plan with a minor elaboration of an existing contingency branch of the current plan would be adequate  or conversely  trying al1 variations of a plan that was doomed to f a i l . in psychiatry this kind of pathology is referred to as functional f i x i t y . 
a new formulation of the  monkey and bananas  

the original formulation of the  monkey and 
bananas  problem1 can be stated b r i e f l y as follows: 
a monkey is in a room in which a bunch of bananas are hanging from the ceiling  just out of reach. the monkey's problem  obviously  is to get the bananas. in the corner of the room is a chair. the solution 

1 

efficient search strategy  we have independently reached the same conclusion regarding the positive value of joininr decision analysis with a symbolic robot problem solver to f a c i l i t a t e intelligent decision making under conditions of uncertainty.  see 