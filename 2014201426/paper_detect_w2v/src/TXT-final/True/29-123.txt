 level  numerica can be viewed as mapping continuous problems into discrete problems  which is exactly the opposite of traditional relaxation techniques  e.g.  in integer programming  garfinkel and nemhauser  1  . once nonlinear programming problems are viewed as discrete problems  it is natural to apply consistency techniques such as arc- and pathconsistency  e.g.   montanari  1; mackworth  1; mack worth and freuder  1   which have been successfully applied in many areas  van hentenryck and saraswat  1 . 
　numerica  and its constraint-solving algorithm  does not aim at replacing focal methods. local methods are extremely effective tools when they apply and are probably the only way to approach large-scale nonlin-

ear programming problems involving thousands of variables. however  there are many applications where the additional functionalities of numerica are needed  either because of the nature of the application  or because the problem is too hard for local methods  or simply because the robustness of the approach simplifies the task. this is especially true for small-scale highly nonlinear problems as those found in chemical and electrical engineering where traditional methods are likely to diverge  are unable to locate all solutions or to prove the absence of solutions  a requirement in these problems . reference  gehrke and marquardt  1  in fact indicates that progress in chemical engineering increases the need for these functionalities. 
　the rest of this extended abstract illustrates the advantages of numerica and contrasts it with traditional methods. more information about numerica can be found in  van hentenryck et a/.  1c; 1a; michel and van hentenryck  1; van hentenryck et a/.  1b . 
1 	what is possible and what is not  
today's computers can manipulate and store only a finite amount of information. since the solution of a nonlinear problem may be a real number that cannot be represented in finite space or displayed on a screen in finite time  the best we can hope for in general is a point close to a solution  preferably with some guarantee on its proximity to the solution  or an interval enclosing a solution. 
　computer methods for solving nonlinear problems typically use floating-point numbers to approximate real numbers. since there are only finitely many floatingpoint numbers  these methods are bound to make numerical errors. these errors  although probably small considered in isolation  may have fundamental implications on the results. consider  for instance  wilkinson's problem  which consists in finding all solutions to the equation 

in the interval  -1  -1 . when p - 1  the equation obviously has 1 solutions. when  it has no solution. wilkinson's problem clearly indicates that a small numerical error  e.g.  assume that p is the output of some numerical computation  can have fundamental implications for the results of an application. these numerical issues require users of numerical software to exercise great care when interpreting their results. with this in mind  consider the combustion problem  which consists in finding positive values for satisfying the equations 

using  1 ...  1  as starting point and the default setting of the system  a well-known commercial system produces a point  say a. in the same conditions but with the defaults set to obtain the highest numerical precision  the same commercial system produces another point  say 1  and prints a warning that the machine precision is not sufficient to achieve the desired accuracy. it is not obvious in this case how to interpret these results in a meaningful way. 
　it is also interesting to mention the common belief that proving the existence or uniqueness of solutions is outside the scope of computer algorithms. for instance  dennis and schnabel in their excellent text  dennis and schnabel  1  present the three functions 

and state 
it would be wonderful if we had a generalpurpose computer routine that would tell us: 

it is unlikely that there will ever be such a routine. in general  the questions of existence and uniqueness -does a problem have a solution and is it unique - are beyond the capabilities one can expect of algorithms that solve nonlinear problems. in fact  we must readily admit that for any computer algorithm there exist nonlinear functions  infinitely continuously differentiate  if you wish  perverse enough to defeat the algorithm. therefore  all a user can be guaranteed from any algorithm applied to a nonlinear problem is the answer   an approximate solution to the problem is ...  or  no approximate solution to the problem was found in the allocated time.  
this statement is not correct in general and applies mainly to local methods. such wonderful procedures in fact exist  within the limits imposed by the finite nature of computers  and one of them is used in numerica. 
　let us conclude this section by showing the behavior of numerica on the above examples. on wilkinson's 
	van hentenryck 	1 

problem  numerica returns -1  -1 ...  -1 as solutions and proves their existence when p = 1; it proves the absence of solutions when  on the combustion problem whose statement is depicted in figure 1  numerica returns the unique positive solution and proves its existence in about 1 second. solution 1 produced by the commercial system mentioned previously is close to being contained in this output box. on the functions 

the four ranges enclosing the solutions and proves the existence of a solution in each of them for f ; it returns two ranges and proves the existence of a solution in each of them for f1 it shows the absence of solutions for f1. the computation times for these examples are negligible. more precisely  the numeric a statement 

1 	local versus global optimum 
traditional globally convergent methods when applied to a minimization problem converge to a local optimum 
1 	invited speakers 

from almost all starting points. they are unable however to isolate all local optima and the global optima. this limitation is well illustrated by the minimization of the function 

and the maximization of the function 

as well as by the minimization of the function f{x  ...  xn  defined as 

these functions have many local minima. for instance  the last function has 1 local minima when n = 1 but only a single global minimum. it is unlikely that a local method will converge towards a global minimum without external knowledge about these problems.1 also  a local method will never be able to prove that the global minimum has been found. in contrast  numerica isolates all global optima to these functions without difficulty. figure 1 is the numerica statement for the last problem and it involves several of the features of the languages: input constant  minimization  function  and summation. in addition  it uses a trigonometric function sin and a predefined constant pi. numerica seems to be essentially quadratic in the number of variables on this problem  as shown in table 1. 
1 	convergence 
in addition to the above theoretical limitations  local methods also suffer from practical problems when implemented on a computer. one of the main problems is of course convergence. an interesting example in this context is the transistor modeling example of ebers and 


figure 1: the transistor model problem 


table 1: performance results on levy 1'. 
moll  ebers and moll  1 . the problem is to find a solution to the system of nonlinear equations depicted in figure 1 where the variables xi must take their values in 
 1  1  and the constants are given by 
1 1 1 1 1 1 1 1 
	1 	1 	1 	1 
	1 	1 	1 	1 
	1 	1 	1 	1 
　the article  ratschek and rokne  1  summarizes various attempts to find a solution to this problem using local methods and states 
in 1  cutteridge  cutteridge  1  combined local damped newton-raphson steps with the conjugate gradient method and a secondorder gradient-descent method with eigenvalue determination where the two latter methods were applied to the least squares problem  ...  cutteridge emphasized that only the sophisticated combination of the three methods had led to a positive result  i.e.  it did not suffice to only use the first two approaches mentioned above 
numerica finds the unique solution to the transistor modeling problem in the box  1 1 and proves its existence and the absence of other solutions in less than 1 minutes. the previous interval solution required more than 1 months on a network of workstations. 
　another important practical problem is convergence to an undesired solution  i.e.  a solution that fails to satisfy some external constraints not included in the problem statement. globally convergent algorithms are guaranteed to converge to some solution or some local minimum from almost any starting point  but they may fail to produce a given solution. for instance  a traditional quasi-newton method applied to the transistor modeling problem almost always converges to a solution in which some variables have negative values. solution a produced by the commercial system on the combustion 

table 1: performance results on broyden's function. 
problem has some negative components. morgan  morgan  1  also mentions that these undesired convergences are typical of chemical equilibrium systems: 
the other day an electrochemist friend came by my office with a problem. he was trying to work out part of a battery-plate manufacturing process. he had set up a math model to determine the amounts of various metal compounds that would be present in the plating bath at various times. he had ended up with a system of 1 polynomial equations in 1 unknowns. his problem was that newton's method kept converging to nonphysical solutions.  ...  this incident has been repeated in various guises many times. 
1 	practicality 
　the functionalities of numerica of course come at a price. the intractable nature of nonlinear programming precludes any guarantee on the computation times of interval methods. conventional wisdom claims that interval methods are too slow to be of practical use and that their guarantees and ease of use come at too high a price. the performance of numerica indicates that  for a rich collection of nonlinear problems  the price to pay is reasonable. moreover  even when the full functionality of global methods is not needed  numerica avoids the tedious work necessary to tune local methods and find suitable starting points. as a consequence  numerica's ease of use and robustness frequently compensate for a longer running time and may even reduce the actual time to obtain a solution. in this context  it may be useful to mention that numerica takes essentially linear time in the number of variables to isolate the zeros of the broyden banded function  a traditional benchmark from numerical analysis  even when the initial range of the variable is as large as or larger than  say   -1  1  . see figure 1 for a description of the 
	van hentenryck 	1 


figure 1: the broyden banded function. 

broyden banded function in numerica and table 1 for experimental results. 
　in addition  numerica compares well and frequently outperforms continuation methods on their benchmarks. this good performance comes from a novel combination of interval analysis methods  e.g.  hansen-sengupta's operator  and constraint satisfaction techniques. the combination of these orthogonal techniques gives surprisingly good results on many problems  although understanding its strengths and limitations more formally requires further research. 
　of course  there are also classes of problems for which interval methods are not appropriate at this point because interval evaluations may lose too much precision. for instance  nonlinear least-squares problems are not amenable to effective solution with the interval methods of which we are aware. interval methods converge  of course  on these applications but they do not compare well in efficiency with local methods. 
1 	challenges and opportunities 
there are many possible ways to improve global methods for nonlinear programming and we mention some of them without trying to be exhaustive. a particularly interesting research avenue  studied by f. benhamou and d. kapur for instance  is the combination of symbolic and numerical methods. new pruning techniques with a more global view of the problem is also of paramount importance to improve the pruning when far from a solution. similarly  it would be interesting to study ways of collecting global information beyond intervals. finally  constraint satisfaction techniques have been a driving force behind the development of numerica but only a tiny fraction of the existing research is exploited in numerica. it is an exciting field and it is likely to evolve substantially in the coming years. 
acknowledgment numeric a was developed jointly with laurent michel and yves deville. numerica is also based on previous work on newton with frederic 
benhamou  	deepak kapur  	and david mcallester. 
thanks to all of them for their invaluable contributions. 
1 	invited speakers 
part of this research was supported by the office of naval 
research under grant onr grant n1-l-1 and a nsf national young investigator award. 
