
local search algorithms for satisfiability testing are still the best methods for a large number of problems  despite tremendous progresses observed on complete search algorithms over the last few years. however  their intrinsic limit does not allow them to address unsat problems. ten years ago  this question challenged the community without any answer: was it possible to use local search algorithm for unsat formulae  we propose here a first approach addressing this issue  that can beat the best resolution-based complete methods. we define the landscape of the search by approximating the number of filtered clauses by resolution proof. furthermore  we add high-level reasoning mechanism  based on extended resolution and unit propagation look-ahead to make this new and challenging approach possible. our new algorithm also tends to be the first step on two other challenging problems: obtaining short proofs for unsat problems and build a real local-search algorithm for qbf.
1 introduction
over the last ten years  a lot of impressive progresses have been made in the practical solving of the satisfiability testing  sat . all the methods that address this typical np-complete problem may be divided in two categories: complete ones  usually based on the davis  logemann and loveland procedure  davis et al.  1; moskewicz et al.  1   can prove that a formula is satisfiable or not. incomplete solvers  also called one-sided solvers  only give an answer if the instance has a given property  generally if it is satisfiable . most of them  which are based on local search  perform a stochastic walk over the search space  selman et al.  1; hoos and stutzle  1 . those methods give very good results on certain classes of problems  like random 1sat problems  leberre and simon  1 .
¡¡in 1   selman et al.  1  challenged the local search communitywith a quest for an efficient local search algorithm for unsatisfiable formulae. we propose here the first successful approach  called gunsat  that pushes the local search formalism into resolution proofs search space. because stateof-the-art complete sat solvers are terribly efficient in practice  we only call efficient a solver  based on resolution  that can defeat state-of-the-artresolution-basedsolvers. for doing this  we propose to make a greedy walk among the resolution search space in which  at each step of the local search algorithm  we try to compute a  better  neighbour proof  i.e. a proof which differs from the previous ones by at most two clauses  one added by resolution  and one that may have been removed. to find such a neighbour we approximate the number of filtered models by the proof. this is achieved by a score given to all pairs of literals depending on their frequencies in the formula. as we will show it in our experimental investigation  the use of higher reasoning mechanism  based on extended resolution  robinson  1  and unit propagation look-ahead  leberre  1  is a key to make this new and challenging approach possible. because resolution-based methods seems to be an efficient way for solving quantified boolean formulae  qbf   we believe that our algorithm may be the first step on two other challenging problems: build a real local-search algorithm for qbf and obtain short proofs for unsat problems and qbf ones.
¡¡the paper is organised as follows. we start by introducing some definitions and notations  then  in section 1  we discuss previous works done on local search for unsat problems  and we present our new approach. before conclude  we provide some experiments.
1 preliminaries and definitions
let v = {x1 ... xn} be a set of boolean variables  a literal li is a variablexi or its negation xi. a clause is a disjunction of literals ci = l1 ¡Ål1...¡Ålni. a unit clause  or mono-literal  is a clause restricted to a single literal. a formula ¦² is in conjunctive normal form  cnf  if ¦² is a conjunction of clauses ¦² = c1 ¡Ä c1... ¡Ä cm. the sat decision problem is defined as follows: given a formula ¦² in cnf  is there an assignment of the variables v ¦² such that ¦² is satisfied  i.e. all the clauses of ¦² are satisfied 
1 local search for sat problems
local search algorithms for sat problems use a stochastic walk over total interpretations of ¦²  i.e. all variables are assigned . at each step  or flip   they try to reduce the number of unsatisfiable clauses  under certain conditions . the next algorithm 1: general scheme of a local search sat solver

	data	: ¦² a cnf formula
result : sat if a model is found  unknown otherwise
begin
for i=1 to maxtries do choose a random interpretation i; for j=1 to maxflips do if i is a model of ¦² then return sat ;
   i = neighbour i ; end
end return unknown ;
end

total interpretationis chosen among the neighboursof the current one  they differ only on one literal value . after a given number of steps  a restart is done to jump into an other part of the landscape  escape phase . we recall  algorithm 1  the general scheme of local search algorithms for sat.
¡¡a lot of improvementshave been proposed in the literature  like tabu search or the use of different heuristics to find the next interpretations. the interested reader may refer to  hoos and stutzle  1  for a detailed coverage of all methods.
1 resolution proofs
the resolution rule allows to deduce a new clause  called resolvent  with the help of two clauses. it plays a central role in many works based on clausal representations of boolean formulae  like preprocessing steps  ee¡än and biere  1 .
definition 1   robinson  1   let c1 =  x ¡Å a1 ¡Å a1 ¡Å ...an  and c1 =   x ¡Å b1 ¡Å b1 ¡Å ...bm  be two clauses. the clause c =  a1 ¡Å a1 ¡Å ...an ¡Å b1 ¡Å ...bm  is called the resolvent of the clauses c1 and c1 by performing a resolution on the variable x. we note c = c1   c1 this rule.
¡¡one may apply the resolution rule many times including on resolvent clauses to derive new clause. the obtained clause is proved by resolution:
definition 1  resolution proof  robinson  1   let ¦² be a cnf formula. a resolution proof of a clause c is a succession of clause p = c1 c1 ... ck such that c = ck and for all i ¡Ü k one of the following conditions holds :
  ci ¡Ê ¦²
   cm cn ¡Ê p  m   i and n   i  such that ci = cm  cn
¡¡if the empty clause  ¡Í  may be proved by resolution then the formula ¦² is unsatisfiable: the resolution proof system is completefor refutation. restrictions on generalresolutionexist and may still answer both sat and unsat questions  like ordered resolution . however  in practice  resolution-based solvers are more suitable to knowledge compilation problematics  preprocessing  prime implicates computation  ...  than to sat checking. directional resolution  dechter and rish  1  is one of the most famous restriction  based on the well known work of  davis and putnam  1 .  simon and del val  1  has shown how a simple generalisation of the resolution rule  called multi-resolution  allowed to scale-up most of the resolution based solvers  essentially for compilation purpose. this two resolution-based solvers will help us measure the performances of gunsat. we call efficient a solver  based on the resolution rule  that can beat both of them.
extended resolution
it is well known that the number of necessary clauses could be exponential to prove refutation by general resolution proof  even if no restrictions are imposed in the order of resolutions steps . this is the case for the well known pigeon hole problem  haken  1   the urquhart problems  urquhart  1  and even the random problems  chva¡ätal and szemere¡ädi  1 . we have here to notice that all those problems need large clauses  i.e. unbounded size  in the resolution proofbeforeproducing¡Í. on a lot of instances  allowing large clauses to be generated is essential.
¡¡however  it is striking to notice that as soon as one allows the introduction of new variables during the proof  like lemmas in theorem proving   then short proofs for the above problems exist.  tseitin  1  introduced this principle as the extended resolution rule. if ¦² is a formula  one application of this rule allows us to consider ¦²¡Ä e   l1¡Ål1  instead  where e is a fresh variable  not appearing in ¦²  and l1 and l1 are literals from ¦². even if this rule looks very simple  there is no proof system known to be stronger than extended resolution. despite its simplicity and its theoretical interests  no practical applications of extended resolution are used in modern sat solvers. some works implicitly use a restriction of it  like symmetry breaking algorithm based on the introduction of new variables. the work of  simon and del val  1  can also be viewed as a restriction of this rule  where nodes of the graph representation of the formula may be viewed as new propositional variables. however  at the end  the whole problem remains: even if this rule looks simple  how to choose the pair of literals to extend 
1 local search for unsat problems
after a discussion of previous works  we present gunsat  our new local search algorithm for unsat checking.
1 previous work
among the ten challenges proposed ten years ago  selman et al.  1   not so much work has been done to address the fifth challenge:  design a practical stochastic local search procedure for proving unsatisfiability .
hybrid solvers
almost all previous works on incomplete algorithms for unsatisfiability has been done on hybrid solvers only. some methods use a classical local search solver but record nogoods  based on resolvent. however  in the general case  those methods improve performance on satisfiable problems only  fang and ruml  1; shen and zhang  1 .
¡¡with the new interest in qbf solving and the relative failure of direct dpll extensions on them  some effort have been done on finding new methods  based on resolution or local search. the solver walkqsat  gent et al.  1  has two algorithm 1: gunsat

	data	: ¦² a cnf formula
result : unsat if a derivation of ¡Í is found  unknown otherwise begin
for i=1 to maxtries do
for j=1 to maxflips do if 1-saturation ¦²  returns unsat then
return unsat ;
if |¦²|   maxsize then
   remove-one-clause ¦²  add-one-clause ¦² ;
   add-extended-variables ¦² ; simplify-look-ahead ¦² ; end
   replace ¦² by all its vital clauses; end
return unknown;
end

distinct phases: the first one is a complete algorithm based on dpll for qbf; the second one use local search to quickly find models. this incomplete solver can prove either the validity and the invalidity of a qbf formula  but may never prove it.
ranger
ranger  prestwich and lynce  1  is also a local search algorithm for unsat problems that may looks very similar to gunsat. in this recent work  arbitrary resolution is performed in order to generate a large number of the shortest possible clauses  as fast as possible. to avoid combinatorial explosion  they may remove clauses. as we will see after  gunsat has a more powerful reasoning mechanism and a finest heuristic to guide moves whereas ranger is simpler but performs many more moves per second.
1 skeleton of our local search algorithm
the solver gunsat has  for a large part  the same skeleton than classical local search algorithms. intuitively  our algorithm will remove and add new clauses to the set of clauses ¦²  trying to derive ¡Í by the resolution rule. the whole problem is to ensure that our algorithm may be able to perform greedy moves in the search space. it is also fundamental to add a higher level reasoning mechanism to ensure good practical results. the gunsat algorithm  detailed in the later  is given in algorithm 1.
1 inside gunsat
estimation of the number of filtered clauses
given a set of clauses ¦² built on n variables  we want to approximate the total number of its potential models that are directly filtered out  over the 1n potential ones . the measure must be based on explicit information only  and the computational effort to obtain it must be polynomially bounded. otherwise  one may need to exactly count the number of its models  which is clearly harder than the conp-hard problem we are initially facing.
¡¡let ci = l1 ¡Å l1... ¡Å lni be a clause in the formula ¦². for any ci s.t. ni ¡Ý 1  it is clear that the clause filter out 1n ni of potential models.
¡¡our first measure  depth 1 of the approximation  estimates the number of filtered models considering clauses independently. each clause ci of length ni weights w1 ni  = 1n ni.
the whole weight of the proof may then be measured as
. it is however clear that filtered models are not independent and this measure gives a very inaccurate indication of the quality of the current proof. it remains at trying to produce as many short clauses as possible.
¡¡at depth 1 of the approximation  we fix the granularity to literals  by maintaining the estimation of the number of filtered models for each literal. for each literal l  we may sum its weight in all clauses where it occurs by considering that a clause ci of length ni ¡Ý 1 filter out 1n ni of the models that contain  l  over its 1n 1 potential models . if we suppose that all these filtered models are separately and equally distributed over all literals in the clause  which is a strong assumption on which our estimation is based  then the clause ci allows literal l to filter out of the models containing  l. even through this is a refinement of depth 1  it is clear that if l occurs in the two clauses l¡Äq and l¡Ä q then this scoring scheme is particularly inappropriate. in some way  it is important to take the locality of common variables into account.
   this is what approximation of depth 1 does. the granularity is here pairs of literals. for a clause ci of length ni  the 1n ni filtered models are supposed as equally distributed over the ni. ni   1 /1 pairs of literals occurring in ci. each pair  l1 l1  appearing in ci is credited a weight of . the score of a pair of literal  l1 l1  is defined as the sum of its weights in all clauses and noted s l1 l1 . the score s c  of a clause c is the sum of the scores of all the pairs of literals it contains. in the remaining sections  w and s may be used without indices for depth 1.
¡¡the deeper the approximation is  higher the cost to maintain it. we may refine our measurement by considering triplet of literals  but any explicit representation of all possible triplets of literals may be quickly unpracticable on realistic unsat benchmarks.
 remark 1  clauses scoring  if a given clause ci has a score  then ci is nearly the only one
that filter the models composed by the negation of its literals. even if such a clause is long  it should be kept in the proof.
at the opposite  if then there is a little hope that this clause is from great importance in the current proof.
what are greedy moves 
we now have a scoring scheme for pairs and clauses. if we try to improve the total sum of clauses scores over ¦²  then our algorithm will look for large clauses in which a lot of frequent pairs occur. this is the completely opposite goal.
¡¡instead of trying to improve a measurement over the whole proof  we'll focus on quadruplets of pairs only. in order to derive ¡Í  we need a step in our proof where l and  l are in
¦². because we perform 1-saturation with unit-clause propagation at each step of our moves  see in the later   such a case never occurs. so  we have to find two literals l1 and l1 such that clauses l1 ¡Å l1   l1 ¡Å l1  l1 ¡Å  l1 and  l1 ¡Å  l1 can be derived from ¦². in other words  we'll try to improve the scores of the four pairs built on the same variables  called quadruplets and noted  x1 x1 . because we want to localise quadruplets where all pairs have a high score  we define the score sq  x1 x1   over a quadruplet as the sum of the squares of the scores of its pairs sq  x1 x1   = s l1 l1 + s  l1 l1 + s l1  l1 + s  l1  l1. any move that enhance the score of one of the best scored quadruplets is thus a greedy move.
neighbourhood
adding any clause such that  may define the neighbourhood. however  the deduction mechanism must be restricted to a correct but polynomially bounded and uncomplete method. otherwise  one may reduce gunsat to a single call to any complete sat solver to check if and then add it to ¦².
¡¡we chose to use the 1-resolution mechanism  noted  1res  which is defined as  where c1 and c1 occur in ¦². even if this rule is very simple  we are already facing a huge neighbourhood. to illustrate this  let's take a random k-sat formula at a given ratio r  with n variables and r ¡Á n clauses. before the first move  each literal occurs on average k.r.n/1 times  and k1.r1.n1 clauses may be derived from 1-resolution on it  which give for the whole formula n1.k1.r1 potential clauses. for a 1 variables 1sat formula at threshold  r = 1   we already have over 1 potential moves to rank. random moves in this huge neighbourhood may only lead to blind search for unsatisfiability  without any hope to beat ordered resolution-based algorithms like  dechter and rish  1; simon and del val  1 .
finding the bests greedy moves
any explicit exploration of the neighbourhood is impossible in practice. however  if we know in advance that we have to increase the score of one of the bests quadruplets  we may try to increase the score of any of one of its pairs.
¡¡let  x1 x1  be the best scored quadruplet in ¦². increasing the score of any of its pairs  l1 l1  amounts to adding any new clause containing both l1 and l1. short clauses will grant  l1 l1  a higher score  and should be preferred. however  the score of the new clause itself has to be taken into account. if we add a short clause with a high score  then this clause will probably be considered as useless in the next iteration of the algorithm. thus  we are looking for a short clause with the lowest possible score to filter out new potential models.
¡¡when looking for this new clause with l1 and l1  we first try to localise the pivot variable on which we'll perform the resolution rule. if such a pivot p exists  then s l1 p    1 and s  p l1    1. we thus have to choose a clause cp containing l1 and p  and a clause c p containing  p and l1. to prevent the new clause from having a high score  we only try to generate the new clause c from the two clauses having the lowest scores. because of this restrictions  it is not always possible to produce a new clause c containing l1 and l1  for instance  c may be subsumed by some clause of ¦² or may simply be a tautology . if one pair score cannot be improved  then the other pairs of the same quadruplet are iteratively tried. if gunsat fails on all pairs of the best quadruplet  then the second quadruplet is tried and so on. this is what the call to add-one-clause does.
removing useless clauses
as we have seen  clause scoring will be preferred to a simple measurement of clause length to localise useless ones. this mechanism allows us to keep large clauses in ¦²  especially if it is the only one to filter out a large number of pairs. however  it is essential to keep vital clauses in ¦². they ensure that we are preserving its unsatisfiability. vital clauses are initial clauses  or any clause that previously subsumed another vital clauses. we also forced the algorithm to keep binary clauses. this step is performed by the call to remove-one-clause.
finding a random start
as described in gunsat skeleton  random start and general iteration of the algorithm only differ in the removing or not of clauses at each step. during the random start initialisation  no clauses are removed  except any subsumed clause  in order to fill the proof up to maxsize clauses.
1 other refinements
it has been essential to add three powerful mechanisms to
gunsat in order to make it competitive to other resolutionbased reasoning systems. the first but essential refinement concerns subsumptions. before adding a new clause  we perform forward/backward subsumption detection  zhang  1 .
binary clause saturation
the power of binary clause saturation has been exploited with success in  bacchus  1  for preprocessing purposes. at each step of the walk  binary clauses  related to our pairs of literals  have a special treatment in the call to 1-saturation. each time a new binary clause is found in ¦²  all resolutions between the set of binary clauses are performed to saturate ¦² with it. in order to exploit their full power  an equivalency literal search is performed: if clauses l1¡Å l1 and  l1¡Ål1 are found in ¦²  then all occurrences of l1 are replaced by l1 and l1 is tagged as a new potential extended variable to be used in the latter search.
¡¡while performing the binary clause saturation  the algorithm may find new unary clauses l1. the literal l1 is then propagated in the whole formula by unit propagation  all clauses containing l1 are deleted  all clauses containing  l1 are shortened . an inconsistency may be found at this step and then returned to the main algorithm.
extended resolution
when the algorithm has tried to increase the score of a given pair of literals too many-times without any success  we chose to adopt a tricky solution that really pays: use extended resolution  er  to artificially increase the score of this pair of literals.
¡¡the extended rule e   l1 ¡Å l1 is encoded by the three clauses   e¡Ål1¡Ål1    e¡Å l1  and  e¡Å l1 . if necessary  the add-extended-variable step may add a fresh variable by adding all those three clauses to ¦². of course  we ensured that a pair of literals can only appear in at most one extended rule. as we'll see section 1  this very simple rule gives very good results in practice.
look ahead techniques
the patented sta lmarck method  sta lmarck  1   which gives good results in practice on some structured benchmarks  uses a powerful look ahead technique to detect equivalencies between literals until an inconsistency is found. it uses a reformulation of the initial formula  based on a set of triplets
 p   q   r and p   q   r only . when formulae are initially written in cnf  the power of this method may be partially captured by unit-propogationlookahead  lh   leberre  1 .
¡¡to enhance the power of gunsat  we added lh techniques on pairs of literals. the four possible values of pairs are iteratively propagated in ¦²  searching for more  implied  unit propagations. if any literal l of ¦² is set to ¡Í in all the four tries  then lh proved that   and the unary clause  l is added to ¦².
restarting
when gunsat fails to derive ¡Í from ¦² after maxflips steps  a restart is performed. all clauses  except binary ones and the set of vital clauses  are removed. to ensure that gunsat will explore another part of the search space  we added random number to cut ties of quadruplets having the same scores up to a given . each restart is followed by a new random generation of quadruplets random numbers. all clauses containing at least one extended variables are deleted after each restart  including binary ones.
¡¡a particularity of our local search algorithm may be emphasised here: because of unit propagation  binary clause saturation and subsumption deletion  ¦² may evolve from starts to restarts. hopefully  ¦² will only evolve to a simpler and simpler formula.
1 experimental evaluation
our results were obtained with a xeon 1ghz with 1gb memory. gunsat is a prototype written in java and a lot of optimisations are still planned  java api linkedlist data structure are for instance used and may be greatly improved . in addition  our current implementation use an explicit representation of all pairs  which is a very costly operation. we are planning to manipulate only the top-m best pairs of literals in our next versions.
¡¡because of these two weak points  we selected instances with only a very restricted number of clauses and variables  aim  xor and jnh . furthermore  like other local search algorithms  gunsat has a lot of parameters to tune and some of them may be improved in the near future. we chose to perform 1 restarts and to fix the number of flips to 1 times the initial number of clauses.
¡¡as we have previously said  our purpose is not here to compare gunsat to state-of-the-art sat solvers. it is clear that conflict learning solvers like zchaff  moskewicz et al.  1  for structured instances and solvers like kcnfs
basiclherlh + er% st  f % st  f % st  f % st  f aim-1  1 1.111.11 1  1  1  1 aim-1  1 1.111.11 1  1  1  1 aim-1  1 1-1.111.1 1  1  1 jnh  1 1.111.11 1  1  1  1 xor  1 1--111.1 1  1 table 1: results on structured instances. %s gives the percentage of solved instances  1 launches per instance . t means time  in seconds  averaged of all successful runs   and f gives the averaged total number of flips.
lh + ervr% st  f 1.11  1 1.11  1 1.11  1 1.11  1 1.11  1 1.11  1 1.11  1 1.11  1 1.11  1 table 1: 1-sat random instances - each category contains 1 instances  each instance is solved 1 times
 dubois and dequen  1  for random instances outperform gunsat. we rather want to compare it with resolution-based solvers.
¡¡we compared 1 versions of our solver: the basic one  the one with lookahead  lh  only  with extended resolution only  er  and the one with both of them  lh+er .
1 structured instances
table 1 reports the results obtained by gunsat on structured problems. we do not report the original dr performances  dechter and rish  1 : over the 1 runs  only 1 finished without a memory allocation error and only 1 instances were solved  all aim-1 and 1 xor . zres  simon and del val  1  was able to solve all aim-1  half aim-1  but failed to solve aim-1 and jnh. it was able to solve all xor instances  because of its ability to handle large set of highly structured clauses.
¡¡it is clear that proposed refinements  lookahead and extended resolution  and especially their combination provide a realistic local search solver for unsat problems.
1 random instances
table 1 reports results on random instances with different number of variables  from 1 to 1  and different ratio  1  1 and 1 . we only report results for er+lh because all other versions of gunsat were only able to solve at most 1% of the instances. the solver dr cannot solve either these instances. zres solves only instances with 1 variables at the threshold in 1 seconds on average.  prestwich and lynce  1  also reports bad results on random instances with ranger.
¡¡even on hard examples for resolution based algorithms  gunsat lh+er showed promising results  in comparison with resolution based solvers and ranger  especially for large clause/variable ratios.
¡¡one may also notice the very low number of flips in all the cases  which mean that the obtained proof length is short  in comparison with zres experimentations on random instances.
1 conclusion and future work
we report the first good results on local search for unsatisfiability since  selman et al.  1  challenged the community. gunsat differs from classical local search algorithm in its high-cost flip mechanism. finding and adding good clauses  while maintaining the score of all pairs  is a costly - but necessary - task to prevent a blind local search. gunsat learns from start to restarts and may be able to prove unsatisfiability start after restarts  by suddenly finding a derived unit clause before starting again with this new high-valuable clause. we showed that lh techniques with er are two key points to allow local search on resolution proofs. with both mechanisms  made possible by our scoring based on pairs of literals  gunsat was able to defeat state-of-the-art resolution based solvers.
¡¡those good results should be relativized by the fact that gunsat cannot yet challenge state of the art dpll solvers. however  those solvers have two main drawbacks: they hardly exhibit a proof of unsatisfiability of the initial formula that can be checked by a third-party trusted algorithm and they seem to reach their limit when extended to qbf solving. resolution-based algorithms may be the next generation of efficient qbf solving  with a short proof checking made possible. in this new and still promising area  we believe that gunsat may take a good place.
