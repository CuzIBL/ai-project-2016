 
passing the turing test is not a sensible goal for 
artificial intelligence. adherence to turing's vision from 1 is now actively harmful to our field. we review problems with turing's idea  and suggest that  ironically  the very cognitive science that he tried to create must reject his research goal. 
1 	introduction 
alan turing was one of the greatest scientists of this century. his paper    computing machinery and intelligence  inspired the creation of our field  giving it a vision  a philosophical charter and its first great challenge  the turing test. 
　the turing test has been with ai since its inception  and has always partly defined the field. some ai pioneers seriously adopted it as a long-range goal  and some long-standing research programs are still guided by it; for others it has come to provide more of a vision to define and motivate the whole field. for example  in his recent text  ginsberg  defines ai as  the enterprise of constructing a physical symbol system that can reliably pass the turing test.  
　passing the turing test is now often understood to mean something like  making an artificial intelligence   without paying too much attention to the details. in this article  however  we will take turing seriously. we do not think he was being merely metaphorical or speaking in some loose  inspirational way. he seems to have been suggesting the imitation game as a definite goal for a program of research. it was supposed to be a concrete and relatively well-defined goal and hence to avoid the philosophical quagmire that turing  correctly  predicted would result from debates about whether a computer could properly be described as 
 intelligent.  
　but taken this seriously  we will argue  it is no longer a useful idea. the turing test had a historical role in getting ai started  but it is now a burden to the field  damaging its public reputation and its own intellectual coherence. we must explicitly reject the turing test in order to find a more mature description of our goals; it is time to move it from the textbooks to the history books. 
1 	head games 
as the reader probably knows  the turing test comprises an imitation game which involves a man  a woman  and a judge  
kenneth ford 
institute for human & machine cognition 
university of west florida 
pensacola  florida 1 u. s. a. 
all communicating  but unable to see one another  in a threeway conversation.  the sex of the judge is not specified  and we will use  he  for reasons purely of grammatical simplicity   the immediate task of the judge is to decide which of the other two is the woman  and the task of each of the players is to persuade the judge that he or she is the woman and that the other is the man. thus  the game is a test of the ability of a man to pretend to be a woman  and of a woman to resist being judged a man. to make the game more exact  turing proposes to use an average score over many conversations and to limit the length of each conversation to  say  1 minutes. turing then simply says that we should try to make a machine which could successfully  take the place of a man  in this game 1% of the time. 
　turing is usually understood to mean that the game should be played with the question of gender  e.g.  being female  replaced by the question of species  e.g.  being human   so that the judge is faced with the task of differentiating a human participant from a machine pretending to be human. we will call this the species test. 
　however  turing does not mention any change to the rules of the imitation game  and there is no need to interpret him as meaning to do so. if we take him at his word  the test is rather clever. it has a woman and a machine each trying to convince the judge that they are a woman  and the judge's task is still to decide which is the woman and which  therefore  is not. but this judge is not thinking about the differences between women and machines  but between women and men. the hypothesis that one of his subjects is not human is not even in his natural space of initial possibilities. this judge has exactly the same problem to solve as a judge in the original imitation game and could be expected to bring the same attitudes and skills to the problem. we will call this the gender test.1 
　there are some standard objections to turing tests in either version. for example  they seem likely to be extremely difficult: so difficult  indeed  that someone who declared one as his immediate research goal would now probably not be taken seriously. they ignore or sidestep many aspects of 
1  ruling out vision avoids such complexities as skill in crossdressing; but in any case turing thought that machine vision was likely to be very difficult and was irrelevant to the goal of his project. 
1
 judith genova  argues similarly. we use her 
'species/gender' terminology. 
current ai research  such as vision and robotics  and seem too closely bound up with natural language understanding to now be a beacon for the entire field. these are familiar objections  but there are deeper ones. the imitation game itself has some basic design flaws  which are inherited by any version of the turing test. later  we will argue that ai should not be defined as an imitation of human abilities in any case. 
1 	on not detecting anything 
one of the first lessons learned by a graduate student in psychology is never to design an experiment to detect nothing. this is such a fundamental error that it has been given a title: confirming the null hypothesis. it is impossible either to completely define the experimental conditions  how hard should one look for the thing that might not be there   or to come to a firm conclusion  what if one had looked harder  or differently  . the imitation game is precisely such a design  in which a difference between two behaviors is what isn't being detected. assume for a moment that one accepts the turing test as valid: if an artificial intelligence could reliably pass a given instantiation of the test  it would have demonstrated either that its intelligence was genuine or that the judge was not clever enough to ask sufficiently telling questions. but this raises the problem of what exactly are the telling questions  ironically then  the issue that the turing test was supposed to avoid remains in force: would it be an adequate criterion for intelligence  
　the imitation game conditions say nothing about the judge  but the success of the game depends crucially on how clever  knowledgeable  and insightful the judge is. a clever judge will be looking out for subtle signs of femininity. for example  sociolinguistic studies by robin lakoff have shown that adult american women tend to use a wider range of color words than men do. a woman will typically distinguish crimson and scarlet  where a man will usually describe them simply as red  a word which many adult women regard as ambiguous. a good imitation-game judge would know this and be alert for this sign of womanhood; and therefore  a successful player must also be expected to know it  and use it. and of course this applies to any other detectable sexual differences in word usage. but how many such differences are there  the question will always be a matter for research. the imitation game does not have a stable endpoint. 
　the zero-sum competitive design of turing's game has more odd consequences. it would not be enough simply to exhibit female use of color words  for example. if a female player notices her opponent  whom she knows to be male  using words like  puce  or  magenta   she might challenge him to engage in an explicit debate about color to test his knowledge and explicitly draw the judge's attention to such attempts to mislead  and a male player would need to able to deal with this. to be a successful player it would not be sufficient simply to have  and therefore exhibit the linguistic symptoms of  a feminine attitude to color; one would have to consciously know of those symptoms and use this knowledge in tactical planning. to be successful at the imitation game  one would have to be thinking all the time about techniques of female impersonation. 
note that such conscious strategic use of sociolinguistics 
is quite different from exhibiting a symptom of some underlying cognitive difference. some writers have objected to such things as an implemented model of female use of color vocabulary on the grounds that any such model involving  knowledge representation  can be only understood as modeling conscious thought. the difference between someone who  quite unwittingly  uses a rich color vocabulary and someone who consciously uses knowledge of sociolinguistics to improve his or her imitation game performance provides a vivid illustration of the necessary distinction. 
　another problem with null-effect experiments is that they cannot measure anything. the imitation game can test only for complete success. a man who failed to seem feminine in  say  1% of what he said would almost always fail the imitation game: to pass  one has to be totally convincing almost all the time. this is a criticism of these tests not only as a guide to research-they provide no way to measure partial progress toward the goal-but also of the goal itself. even in humans we recognize the possibility that an intellectual talent need not correlate with conversational skill or debating ability; but using any kind of imitation game as our research goal denies this simple insight and declares that we must strive to create a fully human-like collection of abilities  organized to succeed in winning an argument. 
1 	turing test problems 
all of these criticisms apply directly to the turing tests. 
this is what we would have to make our program able to do: not talk like a human because it thinks like a human  or even talk like a woman because it thinks like a woman  but rather to talk like a woman as a result of thinking about how best to talk like a woman. the gender test is not a test of making an artificial human  but of making a mechanical transvestite. 
　our point here  to emphasize  is not a moral one; rather it is concerned with what the program would have to be thinking about in order to be successful in these artificial games. human players would also be forced into these artificial frames of mind  which arise simply from the tactical pressures of the games themselves. for example  to succeed at the species test  a machine must not just pass as human  it must succeed in persuading the judge that its human opponent is a machine. to do this would require more than ordinary conversational abilities. the competitive nature of this test makes it essential that the machine give a human-like impression in every possible way and be alert for any way in which its opponent might seem mechanical. to pass this test  a machine would have to not just give a human-like impression  but also be an expert on making a good impression  be always aware of the impression it was giving  and be ready to defend itself against accusations of giving the wrong impression. it would have to take care not to exhibit any inhuman talents which it might have; it would have to always cleverly lie  cheat  and dissemble. the winner of the loebner competition  for example  sometimes deliberately  mistyped  a word  then backspaced to correct it at human typing speed. this strategy is clever  but surely such tricks should not be central to our subject. to pass the species test we must make not an artificial intelligence  but an artificial con artist. 
　the species test further reveals the poor experimental design of the imitation game in the difficulty of obtaining an unbiased 
judge. the general perception of what are essentially human talents keeps shifting. as ai progresses and more and more tasks previously considered to involve human abilities are performed by machines  a judge in the naive turing test will gain more and more subtle ways of detecting the behavior of nonhuman machines  just as a skilled doctor will become more adept at recognizing subtle symptoms. three hundred years ago  when pascal described his  calculator    a machine roughly similar to an automobile odometer   european academics were astonished that a machine could perform arithmetic  an intellectual ability that only few humans possessed. even as late as the second world war  when turing was working  the ability to perform complex mental calculations rapidly was considered evidence of intellectual talent  found useful throughout science and engineering  and given academic recognition. the ability to perform simultaneous translation may soon be reduced to the  merely mechanical.  
　when eliza first appeared  some people found its conversational abilities quite human-like. no machine until then could have reacted even in such a simple way to what had been said to it. but during the loebner competition  many programs were instantly revealed as nonhuman 
precisely by the first hint of resemblance of their behavior to that of eliza. amusingly  the boundary shifts in both directions. some judges in the loebner competition rated a human as a machine on the grounds that she produced extended  well-written paragraphs of informative text  which is now apparently considered to be an inhuman ability in parts of our culture. the loebner competition illustrates very clearly how the imitation game inevitably slides from a concern with cognitive status to being a test of the ability of the human species to discriminate its members from mechanical imposters. 
　turing tests suffer from another flaw: it is not clear what exactly they can be failing to detect. while turing was careful to not suggest the test as a definition of humanity or intelligence  the fact that it is often described that way is revealing. let us say that a turing test is a test of  human conversational competence.  but what is that  exactly  the only answer is the ability to pass the corresponding turing test. the tests are circular: they define the qualities they are claiming to be evidence for. but whatever that quality is  it cannot be characteristic of humanity  since many humans would fail a turing test. since one of the players must be judged to be a machine  half the human population would fail the species test. 
1 	inhuman intelligence 
these have all been criticisms of the design of turing's test considered as some kind of experiment. one might argue  however  that it should be regarded more as a spur to technological progress  much as the goal of getting a man on the moon was undertaken to spur the development of the us space program. however  we will argue that using this test to define our field  even loosely  now leads the field to disown and reject its own successes. 
notice first how parochial  one might even say arrogant  a perspective is assumed by the imitation game. why should we take it as our goal to build something which is just like us  a dog would never win any imitation game; but there seems to be no doubt that dogs exhibit cognition  and a machine with the cognitive and communicative abilities of a dog would be an interesting challenge for ai  and might usefully be incorporated  for example  into automobiles.  
　likewise  the species detection aspect of the turing test has served to focus much ai research on those facets of human behavior which are least susceptible to useful generalization precisely because they are not shared by other species  silicon-based or otherwise . as we develop a general science of cognition  it is the aspects of human thought which are not distinctively human that seem the most fundamental. as others have emphasized  cognitive science is a science of cognition  not particularly of human cognition; but we cannot expect to be able to understand human cognition without first having a firm grasp of the basic principles of cognition: 
　from a practical perspective  why would anyone want to build machines that could pass the turing test  as many have observed  there is no shortage of humans  and we already have well-proven ways of making more of them. human cognition  even high-quality human cognition  is not in short supply. what extra functionality would such a machine provide  even if we could build it  
　one answer is that if we could make a human intelligence then we could make a superhuman intelligence just by getting a better processor and extra memory. this vision-the hal vision of ai-is cited by several ai pioneers  e.g.  mccarthy  feigenbaum  minsky  and by many people who are worried about what these superintelligences might do. but if we abandon the turing test vision  the goal naturally shifts from making artificial supcrhumans which can replace us  to making superhumanly intelligent artifacts which we can use to amplify and support our own cognitive abilities  just as people use hydraulic power to amplify their muscular abilities. this is in fact occurring  of course  and has been clearly forseen and articulated by others; our point here is only to emphasize how different this goal is from the one that turing left us with. ai should play a central role in this exciting new technology  but to do so it must turn its back on turing's dream. 
　the area generally called  expert systems  has been hugely successful as a technology but is widely perceived  both in the academic community and in the commercial marketplace  as having somehow failed to achieve its goal. the systems produced are often described as  brittle   for example  which is a way of saying that they perform only in their intended domain. that it only performs its intended task would hardly be considered a criticism of most machines  however; and we suggest that it seems a valid criticism here solely because 
of the lingering influence of the turing test measure of ai success. specialized ai systems are sometimes criticized as being  idiot savants ; but if we abandon the goal of making artificial people  we can rejoice in making useful idiot savants. 
1  the worries seem to arise from the idea that the superhuman intelligence would not just be smart  but would also have superhuman political ambition and be vulnerable to human moral temptation. this might indeed be unwise  but not even the imitation game requires this. 
the authors look forward happily to having several such idiots for lawn mowing  tax preparation  etc... we are not here simply reiterating the widespread  hype  complaint that ai has promised too much and found itself unable to deliver. in this area  in fact  ai systems have delivered the goods very well  sometimes spectacularly well. but even this success is often somehow sicklied over with the pale cast of turing test insufficiency. 
　low fidelity simulations of human behavior are quite a different goal from systems which complement  surpass  and extend our cognitive attributes. the turing test does not admit of weaker  different  or even stronger forms of intelligence than those deemed human. this puts ai engineering in a rather ridiculous position. our most useful computer applications  including al programs  are often valuable exactly by virtue of their lack of humanity. a truly human-like program would be nearly useless. 
　one can detect a trend in the marketplace in which instead of selling  intelligence   even a limited version of it called  expertise   engineers are incorporating what might be called cognitive functionality into products whose overall behavior would often not be thought of as particularly intelligent. as ai progresses  we become able to make computers do more and more things  and some of these would be regarded as requiring intelligence-or at any rate cognitive ability of some kind-if a human did them. but this functionality is not made into a special category called  ai ability   or taken to the market as anything having to do with human beings. in fact  the ai is often quite invisible in the final product. there are cameras  copiers  televisions  automobiles  battery rechargers and laptop operating systems all with algorithms incorporated into them which use ai ideas and techniques  but they are not usually advertised as  intelligent  or  expert.  they certainly could not pass a turing test and there is no particular reason to suppose that they represent an application of a part or component of something that might one day pass a turing test. the designers of these systems construe ai as an enabling technology  and reject the turing test as a criterion for success. the influence of the turing test vision is so pervasive  however  that such work is often not called artificial intelligence just for this reason. this is a tragedy for al. our subject is fuelling technical revolutions and changing the world  but turing's ghost orders us to disinherit these successes. 
　one is not going to get something which can pass the turing test by eventually assembling a collection of these techniques. it would be both far too good and far too bad. it would be lightning-fast and superhumanly accomplished in some ways  curiously inept in others. we could find ways of disguising its inhuman talents  of course; turing considers this kind of problem explicitly  observing that a machine can always pretend to be worse at arithmetic than it really is. but if one's aim is to provide better machines for people to use  what a silly business to get involved in! it is like gluing a beak and feathers onto an airplane to make it look more like a bird. 
1 	on computational wings 
this flight metaphor is quite precise and worth pursuing in more detail. early attempts to make flying machines often did things like attaching a beak onto the front  or trying to make a wing which would flap like a bird's wing  this extraordinarily persistent idea is found in leonardo's notebooks and in a textbook on airplane design published in 1 . it is easy for us to smile at such naivete  but one should realize that it made good sense at the time. what birds did was incredible  and nobody really knew how they did it. it always seemed to involve feathers and flapping. maybe the beak was critical for stability. when one's ignorance was almost total  it made good sense to copy as much of the natural thing as one could  if only to find out what aspects were essential and which were not. a few hundred years ago the idea of artificial flight could have been defined-indeed  often was so characterized-as the idea of making a machine that could fly like a bird. birds were the only available exemplars for flight then  just as humans were the only exemplars for cognition when turing was writing. the turing test version of artificial flight is just that: make a machine which would be indistinguishable from a bird  if all you could see of it was how it flew. this bird making was the goal of artificial flight for centuries. most early attempts to make gliders copied aspects of bird structure. as late as 1  lielenthal's pioneering experiments with man-carrying gliders used wings and tails clearly based on bird anatomy  and a us patent was issued at the turn of the century for a  flying suit  with wing-linkages covered with feathers. 
　but progress was actually made when this aim of imitating nature was abandoned. the technology of flight advanced rapidly once workers gave themselves clearly-defined functional goals  separated from any notion of imitating biology  and strove to achieve these goals by any means available. the wright brothers clearly separated the problems of power-to-weight ratio  lift  lateral stability  pitch and yaw control and solved them one at a time  using such unnatural devices as box kites  launch catapults and vertical fin surfaces. the first successful flyers were very unlike birds  and did not fly like birds. likewise  the new science of aerodynamics made rapid progress only once it had artifacts with which to perform controlled experiments. the idea of the airfoil  which is crucial to the performance of all birds except the hummingbirds  was not discovered in nature. the shape of real bird wings is far too complex and flexible to suggest the idea of the airfoil; but once it had been discovered by experiments with artificial flyers  and its basic role understood from theory  a gull's wing can easily be recognized as one. birds are incredibly efficient and clever flyers  and aeronautical engineers still look to them for inspiration; but this productive interaction between technology and biology did not come about by the engineers taking as their goal the task of imitating nature. indeed  it happened as a direct result of abandoning that naive notion and seeking instead to identify general principles of stable flight and create machines based on them. similar things are happening now in cognitive science where computational ideas originating in ai are being successfully applied in cognitive psychology  linguistics  and neuroscience. 
　artificial flight both transcends and lags far behind natural flight  just as ai machines both surpass and lag behind human intelligence. airplanes fly at mach 1  miles above the clouds; but we doubt if an airplane will ever be able to land on the branch of a tree  or scoop a swimming fish from the ocean. machines can't lay eggs  of course  but even if we restrict ourselves to matters of flying  birds have talents that will probably always escape technology. no aircraft will pass the turing test for flight. 
　perhaps human conversation will always be beyond computer abilities in its complexity and subtlety. if so  we should not think that ai has failed  even if the aim of our science is to understand intelligence and of our technology to amplify and extend it. neither of them should be trying to reproduce it. that is unnecessary for the science and insufficient for the technology. 
　even if one's primary goal is essentially psychological  to understand human intelligence  attempting to build a replica of a human is not a sensible approach. but there is no reason why ai  or more generally cognitive science  should define itself in terms of human intelligence or cognition. while this was a natural way to begin  just as flight pioneers began by trying to imitate bird wings  the science itself provides explanations for cognition which deny the uniqueness of any biologically defined categories. its general insights and ideas apply equally well to electronic computers as to nervous systems  much as aerodynamics applies equally well to airflow over a metal wing as to one covered with feathers. this is not a new observation  but we have only recently begun to understand the extent to which it implies a rejection of imitation-game criteria for success in ai  and how pervasive the consequences of these criteria are. 
1 	turing's ghost 
two venerable intellectual threads weave through history and converge on alan turing. to his great credit he grasped them and started knitting what has become the rich tapestry of motivations and ideas that comprise ai. one thread is the idea that machines might somehow process meanings  which runs through hobbes  pascal  leibniz  boole  babbage  and many others. the other is the ancient ambition  which is probably older than civilization  to steal divine power by making something come alive. it is reflected  for example  in the greek myth of pygmalion  the golem legend  and the frankenstein story. turing was perhaps the first person to be in a position to see how these ancient themes might be brought together. whether or not he intended it  his insight that technology might  at long last  be able to reach a kind of divine power almost certainly played a key role in motivating early ai projects. viewed in this historical context  turing's suggestion of an imitation game seems more understandable; but the same historical view suggests strongly that we must now distinguish legend from science. ai is the proud heir of boole  babbage  and turing  but not of mary shelley. 
　we suspect that several subfields of ai have tended to reject their association with their parent precisely because they found it necessary to develop methodologies which are inconsistent with any kind of turing test. vision  for example  is a perfectly well defined area of scientific investigation or technological ambition within which one can work without feeling obliged to also thereby accept a larger goal of creating a complete intelligent machine. just as the turing tests allow for no degree of partial success  the research programs they define cannot be sensibly taken apart into subfields without an implicit agreement to conform to some kind of grand intellectual architecture  which is not a reasonable constraint to put on either a science or a technology. turing's legacy alienates maturing subfields with methodological inconsistencies. abandoning the turing test as an ultimate goal is almost a requirement for any rational research program which declares itself interested in any particular part of cognition or mental ability. let us emphasize again  we do not deny the need for this abandonment. the harm is done when this is perceived as abandoning ai. 
　allowing our field to be defined by a turing test also harms its reputation  in direct and subtle ways. perhaps not surprisingly  many lay critics of ai assume the field to be defined by turing's goal  and by this light it does not seem to be doing very well. for just one example  frederick allen  writing in the atlantic'   1 : 
today traditional artificial intelligence  or ai  is a backwater at best  and the confidence with which it was once pursued seems unimaginable. nobody has ever designed a program that can converse at all convincingly on a single subject  and the field has splintered into disparate parts the grand vision has nearly vanished. 
　such a pessimistic summary of a flourishing research area like ours may seem merely to reflect ignorance. but if one identifies ai with the goal of passing a turing test-the  grand vision  to which allen refers-then he is perfectly correct. the mistake lies in allowing that identification. 
　another much-cited attack on ai may arise in part from an insight into the turing test. as we have emphasized  in order to succeed at the imitation game even a human player would be obliged to think consciously  to an unnatural extent  about what effects his utterances might be having on a listener. it is quite natural to go from this insight to searle's idea that ai programs can be only a simulation of cognition  leading to his notorious distinction between strong and weak ai. the turing test indeed challenges a computer to simulate a woman  rather than be one. 
finally  perhaps the most subtle kind of damage which the 
turing test has done to ai is by limiting its sights. ironically  
turing's daring vision may in fact be too restrictive. all versions of the turing test are based on a massively anthropocentric view of the nature of intelligence. turing correctly insisted that his test was not meant to define intelligence. nevertheless  in giving us this touchstone of success  he chose human intelligence-in fact  even more peculiarly  the arguing skill of the educated english middle class in playing a kind of party game-as our goal. but the very science which turing directed us towards provides a perspective from which a much broader and more satisfying account of intelligence is emerging. the turing test focuses our attention on the most human details of behavior  rather than general computational principles of cognition. 
1 	what is ai  
ai has always wondered how to define itself  and has engaged in a long-running territorial battle with other parts of computer science. techniques are often developed in ai and later absorbed into mainstream computer science. unlike most subdisciplines of computer science  ai seems to be defined not by its methods but by the source of their inspiration.1 
　so  which parts of computer science are part of ai  we suggest a rather radical answer to this question: all of them. ai is not a part of computer science in the way that compiler design  object-oriented programming or genetic algorithms are. ai is the business of using computation to make machines act more intelligently  or to somehow amplify human intelligence. it is not a particular collection of methods  or a programming style. any technique can be used by a program to do something intelligent  or to display a cognitive ability. 
　until perhaps a decade ago many computational methods were pioneered in ai or in close association with it. one of the first compilers was reported at a meeting on intelligent machines. larry tesler has suggested that ai be defined to be the part of computer science where things don't work properly yet; the edge of the ice  as it were. but this may have been simply a historical consequence of the fact that many of the creative pioneers of computer science had accepted turing's dream  and were struggling to make computers act  intelligently.  it isn't true any longer  and many of the most exciting new ideas in computation are now being developed in other parts of computer science which have quite different aims. but it would be foolish to regard these methods as somehow excluded from ai. 
　for example  there has been a long-standing intellectual struggle in machine translation between methods based on explicit semantic representations and those which apply statistical techniques to large lexical corpora. this is often described as a battle between ai methods and other  non-ai  methods. while this may be an accurate account of the sociology of the two sides  it makes no scientific or technological sense. our aim might be to model the skill of human translators  or to make an effective mechanical translator: either way  we should not have any ad hoc constraints on what computational methods to use. if it works  or seems plausible  try it. ai has difficult enough problems already  without also having its technical hands tied. 
　consider again the analogy with flight. if cognitive psychology  psycholinguistics  etc. are like the study of natural flight in all its complexity  and ai is like aeronautical engineering  then computer science supplies the aerodynamic theory. the fundamental insight of cognitive science might be summarized by saying that computational science supplies  as it were  the dynamics of cognition. just as turing predicted almost half a century ago  the empirical sciences of natural cognition now share a computational vocabulary with the engineering discipline of ai. 
　this picture of our field defines it in a more useful and more mature way than turing could give us. ai is the engineering of cognition based on the computational vision which runs through and informs all of cognitive science. we expect ai to produce cognitive artifacts; things that think  see  communicate  plan  play and argue in some way. perhaps not in a human way  but somehow useful to humans. exactly what counts as  cognitive  will shift and change  and be altered by the science itself  just as the meaning of words 
1  attempts to define ai in terms of its computational methods never work properly. for example  if ai is the study of search then successful learning processes automatically remove themselves from the discipline. 
like  energy  has been changed by physics. but ultimately  this doesn't matter. turing's ultimate aim  which we can happily share  was not to describe the difference between thinking people and unthinking machines  but to remove it. 
1 	coda: the human condition 
colby  1  1  has argued that we should consider variations of the gender test  where the judge is asked to make different kinds of distinction. for example  the judge might be asked to decide which of the interrogants was really a child  or really an englishman; or  in a more familiar example  the judge might be a clinical psychologist trying to diagnose which of them is really paranoid. on this view  turing's choice of sex as the topic of conversation had no particular significance. it may have been chosen simply because it seems impossible to give any a priori bounds on the subject matter of the resulting conversation. 
　however  turing was a careful enough thinker that he would have suggested this diverse-topic interpretation of his game had this been what he had in mind  and we again propose to take him at face value. he seems to have chosen the topic of sexual identity deliberately. it is hard to avoid noticing that for turing  the problem of how to convincingly display a sexual identity was more than just deliberately vague. it was a real problem at the very core of his emotional and social life. turing was openly gay at a time when homosexuality was a crime in england and was widely regarded as unnatural and deviant. he was prosecuted for homosexuality  and avoided prison only by submitting to a six-month program of  rehabilitation  involving hormone injections which  among other things  caused his body to grow breasts. this bizarre and horrifying treatment is thought to have been part of the reason for his suicide in 1. 
　we suspect that turing chose this topic because he wanted the test to be about what it really means to be human. this is why he has set us up in this way. he tells us  quite clearly  to try to make a program which can do as well as a man at pretending to be a woman. if we really tried to do this  we might be forced into thinking very hard about what it really means to be not just a thinker  but a human being in a human society  with all its difficulties and complexities. if this was what turing meant  then we need not reject it as our ultimate goal. 
