
we are interested in the belief change that occurs due to a sequence of ontic actions and epistemic actions. in order to represent such problems  we extend an existing epistemic action language to allow erroneous initial beliefs. we define a nonmarkovian semantics for our action language that explicitly respects the interaction between ontic actions and epistemic actions. further  we illustrate how to solve epistemic projection problems in our new language by translating action descriptions into extended logic programs. we conclude with some remarks about a prototype implementation of our work.
1 introduction
reasoning about the effects of actions is an important problem in logical ai. action formalisms are often defined for reasoning about so-called ontic actions that change the state of the world. however  sensing actions have also been incorporated in the epistemic extensions of several notable formalisms  shapiro et al.  1; lobo et al.  1; son and baral  1; jin and thielscher  1 . in such extensions  the effects of sensing actions are defined in terms of belief revision. however  simply supplementing an action formalism with a revision operator is not sufficient; the iterated belief change caused by a sequence of ontic actions and sensing actions can not be determined iteratively  hunter and delgrande  1 . informally  the interpretation of a sensing result may be influenced by the preceding sequence of ontic actions. in this paper  we define an action formalism where the belief change caused by a sequence of actions respects the non-elementaryinteraction between ontic actions and sensing actions.
﹛in order to ground the discussion  we frame our results in an epistemic extension of the action languagea  gelfond and lifschitz  1 . we base the semantics of our action language on the belief evolution operators of  hunter and delgrande  1 ; our results can be seen as an application of the belief evolution methodology in an action formalism. the two main contributions of this paper are as follows. first  we introduce an action formalism that is suitable for reasoning about iterated belief change where the interpretation of sensing results depends on the preceding actions. in the process  we generalize an existing epistemic extension of a by allowing erroneous beliefs and non-markovian belief change. the second contribution of this paper is the introduction of a method for solving belief evolution problems through answer set planning. using this method  we can implement a solver for epistemic projection problems in our action language.
1 motivating example
we present a commonsense example involving iterated belief change due to action  and we will return to this example periodically throughout the paper. the example that we present is framed in the context of a zoo  where a certain crocodile must be fed every morning. the crocodile is fed from a bag of food that either contains whole chickens or whole ducks; the contents of the food bag varies throughout the year. the crocodile is never sick after eating chicken; even if it is initially sick we suppose that eating chicken makes it feel better. however  the crocodile will become sick if it eats two ducks in row. the crocodile will always eat the food it is given. the first zoo keeper to arrive in the morning typically feeds the crocodile by giving it one unit of food.
﹛suppose that bob the zoo keeper arrives in the morning for work. bob believes that the crocodile is unfed when he arrives  and he believes that the food bag contains chickens. suppose that bob feeds the crocodile  then observes that it becomes sick. we suggest that bob should conclude that his initial beliefs were incorrect; the sickness of the crocodile indicates that it has actually eaten two ducks. we are interested in using an action description language to formally model the belief change that occurs in problems of this form.
1 preliminaries
1 action language a
we briefly review the syntax and semantics of the action language a  as introduced in  gelfond and lifschitz  1 .
﹛an action signature is a pair where f denotes a fixed set of fluent symbols and a denotes a fixed set of action symbols. a state is a propositional interpretation over f  s denotes the set of all states  and |耳| denotes the set of states satisfying the formula 耳. a literal is either an element of f or an element of f prefixed with the negation symbol. let lits denote the set of all literals. we use the upper case letter a to range over actions  the lower case letters f g to range over literals  and the lower case letter s to range over states.
definition 1 an effect proposition of the language a is an expression of the form
             a causes f if g1 ＿ ﹞﹞﹞ ＿ gp where a ﹋ a  f ﹋ lits and each gi ﹋ lits.
a set of effect propositions is called an action description. every action description ad defines a transition relation on states as indicated in the following definition.
definition 1 let ad be an action description  let be states and let a be an action symbol. then  if

where e a s  is the set of literals such that f ﹋ e a s  if and only if  a causes f if g1 ＿ ﹞﹞﹞ ＿ gp  ﹋ ad and s |= g1 ＿ ﹞﹞﹞ ＿ gp.
intuitively  the transition relation maps a pair  s a  to a new interpretation s that is exactly like s except for the values of the fluents affected by a.
1 action language ak
our epistemic extension of a will be based on the language ak of  lobo et al.  1 . in this section  we briefly summarize the action description portion of ak. we remark that the complete specification of ak also includes queries  plans  and non-deterministic action effects. we restrict attention to the portion of the language that is defined in this section.
﹛a belief state is a set of states. the syntax of ak is obtained by extendinga with sensing actions  with effects given by propositions of the form
	a causes to know f ifg1 ＿ ﹞﹞﹞ ＿ gp.	 1 
the semantics of ak associates an epistemic transition relation 朴lad with every action description ad. an epistemic transition relation is a set of triples  where a is an action symbol and 百 百  are belief states. the relation 朴lad is defined as follows. if a is a non-sensing action  then  百 a 百   ﹋ 朴lad if and only if 百  is obtained by updating each world in 百 in accordance with the semantics of a. if a is a sensing action described by  1   then  百 a 百   ﹋ 朴lad just in case one of the following conditions holds.
1. 百  is the subset of 百 where g1 ＿ ﹞﹞﹞ ＿ gp and f hold
1. 百  is the subset of 百 where g1 ＿ ﹞﹞﹞ ＿ gp and  f hold
1. 百  is the subset of 百 where   g1 ＿ ﹞﹞﹞ ＿ gp  holds
informally   百 a 百   ﹋ 朴kad means that 百  is a possible belief state after executing the action a with belief state 百.
1 feeding the crocodile in ak
we illustrate how to represent the crocodile problem. the crocodile problem can be described in terms of the actions feed and lookatcroc  along with the fluents chicken fullchicken fullduck and sick. informally  chicken is true if the food bag contains chickens  whereas fullchickenand fullduck indicate what the crocodilehas eaten. action effects are described as follows.
feed causes fullchicken if chicken
feed causes  sick if chicken
feed causes fullduck if  chicken feed causes sick if fullduck ＿  chicken lookatcroc causes to know sick ifsick.
bob's initial belief state is 百 = | fullchicken ＿  fullduck ＿ chicken|. we are interested in bob's new beliefs after performing the actions feed and lookatcroc.
﹛after feeding the crocodile  bob's new belief state 百 is a subset of | sick|. as a result  after looking at the crocodile  the semantics of ak defines bob's final belief state to be  . hence  performing revision without considering the action history leads bob to hold a vacuous set of beliefs  despite the fact that there are plausible world histories that support bob's observation. this problem can be avoided by introducing an appropriate belief change operator.
1 belief evolution
one way to address erroneous beliefs in ak would be to introduce an agm revision operator    alchourro∩n et al.  1   and then define bob's new beliefs to be . however  under this approach  it is possible that bob's final belief state will contain states satisfying sick ＿ chicken. this is the case  for example  if   is the dalal operator  dalal  1 . we suggest that such states should not be possible  because bob is aware that sickness never follows eating chicken. informally  bob's observation after feeding should cause him to revise his initial belief state. belief evolution operators have been proposed to model this kind of reasoning  hunter and delgrande  1 . we briefly present a simplified version of belief evolution.
﹛let 朴 be a transition relation as in definition 1. we associate a belief projection operator   with 朴 as follows. for any belief state 百 and action a   for some s ﹋ 百}.
now suppose that   is an agm revision operator. we will actually let   take a set of states as an argument rather than a formula  but it is clear that agm revision can equivalently be formulated in this manner. we define the belief evolution operator   associated with presently. let a‘ denote a finite sequence of non-sensing actions  and let 耳 denote a propositional formula. define 耳 1 a‘  to be the set all states s such that a‘ gives a path from s to a state where 耳 is true. define   as follows:

hence  belief evolution operators essentially revise the initial belief state before applying the effects of non-sensing actions. in  hunter and delgrande  1   belief evolution operators are defined for arbitrary sequences of sensing and non-sensing actions. to simplify the discussion in the present paper  however  we restrict attention to sequences involving a single  terminal sensing action. it would be straightforward to extend our results to allow arbitrary action sequences by using the full definition of belief evolution.
1 an action language for belief change
1 syntax
our language is obtained by making a slight modification to
ak. let a = o ﹍ n where o ﹎ n =  . we refer to o as the set of sensing actions and we refer to n as the set of nonsensing actions. the symbol o ranges over sensing actions and the symbol a ranges over non-sensing actions. definition 1 propositions of ab have the following forms:
 1. a causes f if g1 ＿ ﹞﹞﹞ ＿ gp
 1. o causes to believe 耳 if g1 ＿ ﹞﹞﹞ ＿ gp where a ﹋ n  o ﹋ o  each gi ﹋ lits  and 耳 is a formula.
note that the effect of a sensing action is now a formularather than a fluent symbol.
1 semantics
the semantics of ab is defined with respect to pointed belief states and epistemic action sequences. a pointed belief state is a pair  where. the state s representsthe actual state of the world and 百 representsthe set of states believed to be possible. a pointed knowledge state is a pointed belief state. an epistemic action sequence is a sequence a1 ... an o where each ai ﹋ n and o ﹋ o. with each action description ad  we associate an epistemic transition relation 朴ad. for easy of readability  we write 朴ad as a function that takes a pointed belief state and an epistemic action sequence as arguments  and it returns a new pointed belief state.
﹛let o ﹋ o and let s ﹋ s. define eff o s  to be the conjunction of every formula 耳 that occurs in a proposition of the form
o causes to believe 耳 if g1 ＿ ﹞﹞﹞ ＿ gp
where s |= g1＿﹞﹞﹞＿gp. we are now in a position to define the semantics of ab. note that  for any action description ad  the non-sensing portion of ad describes a transition relation which in turn defines a projection operator  . we refer to   as the projection operator defined by ad  and we restrict attention to deterministic actions. the following definition assumes a fixed underlying revision operator  .
definition 1 let ad be an action description with corresponding projection operator be the belief evolution operator obtained from. for every pointed belief state
  define where
1.
1..
hence  the transition relation associated with ad returns a new pointed belief state. the new actual world is obtained by updating s by the non-sensing actions in a‘. the new belief state is obtained by belief evolution.
﹛the content of definition 1 for action sequences of length 1 is as follows.
1. for non-sensing.
1. for sensing
for longer action sequences  we use belief evolution to revise the initial belief state before determining the effects of a.
example  cont'd  the crocodile example can be represented in ab by taking the representation from ∫1 and replacing the causes-to-know proposition with the corresponding causes-to-believe proposition. note that sick 1 feed  is the set |fullduck ＿  chicken|. therefore  according to the semantics of ak  the final belief state should be

regardless of the operator    bob's new belief state will be non-empty and it will only include states where the food bag contains duck.
1 reliable action descriptions
note that the crocodile example only involves propositions of the form: o causes to believe 耳 if 耳. observations of this form can be understood to represent reliable observations. in general  we say that an action description ad is reliable if g1 ＿﹞﹞﹞＿gp |= 耳 for every sensing effect proposition in ad with the form
o causes to believe 耳 if g1 ＿ ﹞﹞﹞ ＿ gp.
by contrast  the action description would not be reliable if it contained the proposition
lookatcroc causes to believe sick.
in this case  looking at the crocodile causes the agent to believe it is sick  whether or not it is actually sick.
﹛reliable action descriptions describe infallible sensing actions. the following proposition formalizes the fact that  if an agent has correct knowledge of the world  then the conclusions drawn from reliable observations must also be correct.
proposition 1 let ad be a reliable action description and let be a pointed knowledge state. for any epistemic action sequencea‘  it follows that  is a pointed knowledge state.
1 representing ak
we can give a translation from ak action descriptions to reliable ab action descriptions.
definition 1 let ad be an action description in ak. the ab action description 而 ad  is obtained from ad by replacing every sensing proposition with sensing effect f and precondition 肉 by the following propositions:
o causes to believe f ＿ 肉 if f ＿ 肉
o causes to believe  f ＿ 肉 if  f ＿ 肉 o causes to believe  肉 if  肉.
﹛the following proposition illustrates the correspondence between the given epistemic action languages.
proposition 1 let ad be an ak action description  let o be a sensing action in ad and let 百 be a belief state. then if and only if there is some s ﹋ 百 such that
	 	 	.
proposition 1 illustrates that ak action descriptions are interpreted disjunctively  by determining all possible outcomes under the assumption that the actual world is in 百.
1 comparison with related formalisms
son and baral define an alternative extension of a  in which sensing effects are given by propositions of the form o determines f  son and baral  1 . we can define a translation 考 from as to ab by replacing each such proposition with two propositions: o causes to believe f if f and o causes to believe  f if  f.
proposition 1 let ad be a set of son-baral propositions. restricted to pointed knowledge states  the transition relation
朴考 ad  is equivalent to the corresponding son-baral transition relation.
hence  ab subsumes both of the epistemic extensions of a. moreover  ab is the only one of the three extensions that allows erroneous beliefs and respects the interaction between sensing actions and ontic actions.
﹛in the epistemic situation calculus  belief is defined through a ranking function on initial states that persists as ontic actions are executed  shapiro et al.  1 . for any situation s  the belief set bel s  is the set of minimally ranked situations consistent with all sensing actions executed. if we restrict attention to situation calculus theories where action effects are deterministic and the initial situations all correspond to distinct states  then we have the following result.
proposition 1 if a is an ontic action and o is a sensing action  then there is a belief evolution operator   such that
.
it follows that we can translate action theories in the epistemic situation calculus into equivalent action descriptions in ab. the same can not be said for the epistemic fluent calculus  where sensing results satisfy the agm postulates  jin and thielscher  1 . our work suggests that  in some action domains  simply revising the current belief state leads to unintuitive results. to represent such domains  we would need to define belief evolution operators directly in the fluent calculus. this would be straightforward to do.
1 implementation considerations
in this section  we illustrate how we can solve problems involving iterated belief change due to action through answer set planning. we proceed as follows. first  we define a revision operator based on path length. next  we introduce an informal procedure that can be used to solve belief evolution problems with respect to this operator. we then present a translation from ab to answer set programming to illustrate how the procedure can be automated.
1 topological revision operators
a transition relation on states can be used to define a natural agm revision operator. let 朴 be a transition relation  and let 百 汐 be sets of states. for technical reasons  we assume that every state in 汐 is reachable from 百 by a finite path in 朴. define 百   汐 to be the subset of elements of 汐 that can be reached by a minimum length 朴-path. under the assumption that every state in 汐 is reachable from 百  it follows that   defines an agm revision operator; we refer to this as the topological revision operator defined by t.
﹛we are interested in topological revision operators for two reasons. first  topological revision operators do not require any external notion of similarity: they depend only on the underlying transition system. second  topological revision operators are well-suited for the implementation that we propose in the next sections. we do not wish to imply  however  that topological revision is appropriate for all action domains; topologicalrevision is only appropriatefor domains where erroneous beliefs can be explained by action occurrences.
example  cont'd  we extend the crocodile example by introducing a new action called exchangefood which toggles the value of the fluent chicken. this new action allows an agent to change the food available to feed the crocodile. consider the crocodile example extended with this new action  and suppose that   denotes the topological revision operator. we saw earlier that bob needs to evaluate the expression 百   |fullduck ＿  chicken|.
by definition  we need to find the subset of |fullduck ＿  chicken| that can be reached by a minimal length path from 百. as such  the result of the revision is

therefore  bob's final belief state is

informally  bob explains the fact that the crocodile is sick by postulating that the chicken was replaced with duck  and the crocodile was already fed once. this is a plausible conclusion in this example. postulating actions to explain observations can also lead to non-trivialinferences in some action domains. for example  if we extend the examplefurtherto allow bob to keep an inventory of the number of ducks remaining  then topological revision would suggest that he should reduce the total by two ducks after he observes the crocodile's sickness.
﹛topological revision is essentially a form of abduction  in which an agent looks for the shortest sequence of actions that can explain an observation. to be clear  we are not suggesting that this is suitable for all action domains. however  it is appropriate for extended crocodile-type domains where there are plausible exogenous actions explaining an observation.
1 belief evolution under topological revision
in this section  we illustrate that belief evolution under topological revision can be reduced to finding shortest paths. we start by considering a single non-sensing action. let 百 denote a belief state  let a denote an action symbol  and let 耳 denote a formula. we are interested in determining

﹛figure 1 illustrates how this is calculated with the topological revision function. the figure shows a large box representing 耳 1 a ; these are the states that can reach |耳| by executing the action a. the circle inside 耳 1 a  represents 耳 1 a   百

		
a |耳|
figure 1: visualizing topological evolution
the subset that is minimally distant from 百  which in this context means the elements that can be reached from 百 by a minimal length path. in other words  the circle inside 耳 1 a  represents 百   耳 1 a . this gives a simple procedure for computing.
1. determine 耳 1 a .
1. let path denote the set of shortest paths from 百 to 耳 1 a .
1. let 百1 be the set of terminal nodes on paths in path.
1. let.
clearly. hence  this procedure allows us to compute the outcome of belief evolution for trajectories of length 1. note that steps 1 and 1 are straightforward; to implement a solver  we need some mechanism for determining the set of shortest paths from 百 to 耳 1 a .
1 translation to answer set programming
answer set planning refers to the approach to planning in which a problem is translated into an extended logic program where the answer sets correspond to plans  lifschitz  1 . many action languages have been translated into logic programming for answer set planning. we demonstrate how one existing translation can be modified for our purposes.
﹛we need a translation from a into logic programming. our translation is obtained by modifying a well known translation from c  lifschitz and turner  1 . let ad be an action description in the action language a. for any natural number n  we define an associated logic program 而n ad  with the property that answer sets for 而n ad  correspond to paths of length n in the transition relation described by ad. the language of 而n ad  consists of two disjoint classes of atoms  defined as follows. for each i ≒ n and each f ﹋ f  the language of 而n ad  contains an atom f i . for each i   n and each a ﹋ a  the language of 而n ad  contains an atom a i . the logic program 而n ad  consists of the following rules:
1. for every proposition in ad of the form a causes    f if g1 ＿ ﹞﹞﹞ ＿ gp
for each i   n  而n ad  contains the rules
   f i +1  ↘ a i  g1 i  ... gp i 
1. if b is either an action atom or b is f 1  for some f ﹋
f  then 而n ad  contains the rules
 b ↘ not b
b ↘ not  b
1. for every f ﹋ f and i   n  而n ad  contains f i +1  ↘ not  f i +1  f i   f i +1  ↘ not f i +1   f i 
1. for every i   n  and everypair of distinct action symbols
a1 a1  而n ad  contains the rules
 a1 i  ↘ a1 i .
the first two sets of rules are taken directly from lifschitz and turner's translation of c lifschitz and turner  1 . rule  1  states that all fluents are inertial  and  1  states that at most one action occurs at each point in time.
proposition 1 a complete set x is an answer set for 而n ad  if and only if it has the form

for some path in the transition relation described by ad.
hence every answer set for 而n ad  corresponds to a path in the transition relation.
﹛for the purpose of planning  it is useful to add a few rules to 而n ad  that restrict the admissible answer sets. let k be the conjunction of literals k1＿﹞﹞﹞＿kp. define 而n ad k  to be the logic program obtained by adding the following rules to 而n ad : k1  ... kp 1 . it is easy to see that the answer sets for 而n ad k  correspond to all paths of length n which start in a state where k is true. we are interested in using answer sets to solve   where   is given by the projection operator and the topological revision operator defined by ad.
﹛to simplify the discussion  we assume that  for each a  the action description ad contains at most one proposition in ad of the form
a causes f if g1 ＿ ﹞﹞﹞ ＿ gp.
if such a proposition exists for the action a  then define pre a f  = g1＿﹞﹞﹞＿gp. otherwise  define pre a f  = ﹠.
proposition 1 if s ﹋ s  f ﹋ lits  and a ﹋ a  then
 pre a f  ˍ  f ＿ pre a  f .
it follows that f 1 a  = |pre a f ˍ f ＿pre a  f  |. we are now in a position to give a basic procedure for the implementation of a belief evolution solver. given k a  and f  define evol k a f  to be the pair of belief states returned by the following procedure.
1. set n =1.
1. determine all answer sets for 而n ad k .
1. let path be the corresponding set of paths.
1. remove from path every path where the final state fails to satisfy pre a f  ˍ  f ＿ pre a  f .
 a  if path =    set n = n +1 and goto 1.  b  if  then continue.
1. let 百1 denote the set of final states in path.
1. let.
1. return.
proposition 1 if k is a conjunction of literals  a ﹋ a and f ﹋ lits  then evol.
following the given approach  there are two computational problems to be solved. first  we need to find all answer sets for a given logic program at step 1; this can be accomplished by using an existing answer set solver such as smodels or dlv. the second computational task involves checking if each final state entails f 1 a .
﹛solving  allows us to solve projection problems for a restricted class of action descriptions in ab. in particular  let ad be an action description where the precondition of every sensing proposition is empty and the effect is a literal f. in this case 
.
the actual state can be computed by the standard translation from a into logic programming  and the belief state can be computed as above.
﹛we have a prototype implementation of the solver outlined in this section. the present version of the solver implements our algorithm in a straightforward manner  using smodels to determine the answer sets at step 1. in fact  the solver is slightly more powerful than the approach that we have outlined  because it allows sensing effects to be represented by an arbitrary formula rather than a single literal. we have only restricted attention to literal sensing effects in the present paper to simplify the presentation. we are currently working on extending the solver to deal with multiple observations  which introduces new complications if the observations are inconsistent. when completed  our solver will join the flux solver for the fluent calculus on a short list of implemented tools for solving problems involving iterated belief change caused by actions.
1 discussion
reasoning about iterated belief change caused by action requires more than an action formalism supplemented with a revision operator. the interpretation of a sensing action may depend on the preceding ontic actions  so action formalisms incorporating sensing actions need to define belief change in a manner that considers the entire action history.
﹛we have considered an approach to the representation of iterated belief change in an action formalism by extending the action language a with sensing actions. our extension differs from existing extensions in that we allow agents to have erroneous beliefs. moreover  by defining the semantics in terms of belief evolution operators  we are able to respect the non-elementaryinteraction between ontic actions and sensing actions. to solve belief change problems in our action language  we presented a procedure for automating the solution of belief evolution problems through answer set planning.
﹛in future work  we would like to extend the language to permit a wider range of sensing effects. in particular  we would like to be able to reason about the beliefs of multiple agents performing actions that affect each agent's beliefs in a different manner. action domains of this form can be represented by allowing formulas of modal doxastic logic to be the effects of actions. the semantics of such formulas can be defined with respect to multi-agent belief structures  herzig et al.  1 . we are currently working on a multi-agent extension based on modal logic.
