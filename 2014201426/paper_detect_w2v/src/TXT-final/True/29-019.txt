 
topological maps provide a useful abstraction for robotic navigation and planning. although stochastic maps can theoretically be learned using the baum-welch algorithm  without strong prior constraint on the structure of the model it is slow to converge  requires a great deal of data  and is often stuck in local minima. in this paper  we consider a special case of hidden markov models for robot-navigation environments  in which states are associated with points in a metric configuration space. we assume that the robot has some odometric ability to measure relative transformations between its configurations. such odometry is typically not precise enough to suffice for building a global map  but it does give valuable local information about relations between adjacent states. we present an extension of the baum-welch algorithm that takes advantage of this local odometric information  yielding faster convergence to better solutions with less data. 
1 	introduction 
hidden markov models  hmms   as well as their extension to partially observable markov decision processes  pomdps  model a variety of nondeterministic dynamical systems as abstract probabilistic state-transition systems with discrete states  observations and possibly actions.1 such models have proven particularly useful as a basis for robot navigation in buildings  providing a sound method for localization and planning  simmons and koenig  1; nourbakhsh et a/.  1; cassandra et a/.  1 . much previous work has required that the model be specified manually; this is a tedious process and it is often difficult to obtain correct probabilities. 
　an ultimate goal is for an agent to be able to learn such models automatically  both for robustness and in 
1
 actions are modeled by pomdps but not by hmms. 
learning 
order to cope with new and changing environments. the baum-welch algorithm  rabiner  1  is frequently used to learn hmms. since pomdps are a simple extension of hmms  they can  theoretically  be learned with a simple extension to the baum-welch algorithm. however  without strong prior constraint on the structure of the model  the baum-welch algorithm does not perform very well: it is slow to converge  requires a great deal of data  and is often stuck in local minima. 
in this paper  we consider a special case of hmms 
 extendable to pomdps  for robot navigation  in which states are associated with points in a metric configuration space. we assume the robot has some odometric ability to measure relative transformations between its configurations. such odometry is typically not precise enough to suffice for building a global map  but it does give valuable local information about relations between adjacent states. this information is readily available in most robots and is often ignored during the process of learning topological maps. we present an extension of the baum-welch algorithm that takes advantage of this local odometric information  yielding faster convergence to better solutions with less data. 
1 	related work 
there has been a great deal of work on learning maps for mobile robotics and on learning stochastic models of dynamical systems in general. in this section  we focus on map learning for robots. 
　sometimes it is necessary for a robot to know its location accurately in terms of metric coordinates; in such cases  metric maps are clearly the best choice. in many other environments  such as office buildings with corridors and rooms  or networks of roads  maps that simply specify the topology of important locations and their connections suffice. such maps are typically less complex and support much more efficient planning than metric maps. topological maps are built on lower-level abstractions that allow the robot to move along arcs  perhaps by wall- or road-following  and to recognize properties of the locations; they are flexible in allowing a more general notion of state  possibly including information such as the robot's battery voltage or whether or not it is holding a bagel. 
　there are two typical strategies for deriving topological maps: one is to learn the topological map directly; the other is to first learn a geometric map  then to derive a topological map through some process of analysis. 
　a nice example of the second approach is provided by thrun and biicken  1b; 1a   who use occupancygrid techniques to build the initial map. this strategy is appropriate when the primary cues for decomposition and abstraction of the map are geometric. however  in many cases  the nodes of a topological map are defined in terms of other sensory data  e.g. labels on a door . learning a geometric map first also relies on the odometric abilities of a robot; if they are weak and the space large  it is very difficult to derive a consistent map. 
　we take the approach of learning the topological map directly  assuming that abstraction of the robot's perception and action abilities has already been done  we do it by hand  but see work of pierce and kuipers  for an automatic method . some approaches learn an underlying deterministic map of the world  independent of the noise in the robot's sensing and action processes. we prefer to learn a combined model of the world and the robot's interaction with the world; this allows robust planning that takes into account likelihood of error in sensing and action. 
   kuipers and byun  l1l  provide a strategy for learning deterministic topological maps. it works well in domains in which most of the noise in the robot's perception and action is abstracted away  learning from single visits to nodes and traversals of arcs. it is unable to handle situations in which long strings of actions and observations are necessary to disambiguate the robot's location. another set of learning algorithms  based on the theory of learning deterministic finite state automata  work in much noisier environments with much less global information. basye  dean  and kaelbling  provide algorithms for learning deterministic maps given fairly strong assumptions; these algorithms come with probabilistic correctness guarantees for learning in polynomial time with a polynomial amount of data. 
   engelson and mcdermott  learn  diktiometric  maps  topological maps with metric relations between nodes  from experience. the uncertainty model they use is interval based rather than probabilistic  and the learned representation is deterministic. ad hoc routines handle problems resulting from failures of the uncertainty representation. 
　the work most closely related to ours is by koenig and simmons  1b; 1a   who learn pomdp models  stochastic topological maps  of a robot hallway environment. they also recognize the impossibility of learning such a model without initial information; they solve the problem by using a human-provided topological map  together with further constraints on the shared structure of the model. a modified version of the baum-welch algorithm learns the parameters of the model. they also developed an incremental version of baum-welch that allows it to be used on-line in certain kinds of environments. their models contain very weak metric information  representing hallways as chains of one-meter segments and allowing the learning algorithm to select the most probable chain length. this method is effective  but results in large models with size proportional to the hallways length. 
　we show that  by using odometric information directly  we can avoid the use of a priori models and still learn stochastic maps efficiently and effectively. 
1 	models and assumptions 
in the following sections  we describe the model and algorithms used for learning an hmm  rather than a pomdp. extension to pomdps is technically straightforward but notationally more cumbersome. 
　the world is composed of a finite set of states. the states do not necessarily correspond directly to locations of the robot; they may include other state information  such as orientation or battery level. the dynamics of the world are described by state-transition distributions that specify the probability of making transitions from one state to the next. there is a finite set of observations that can be made in each state; the frequency of such ob-
servations is described by a probability distribution and depends only on the current state. in our model  observations are multi-dimensional  so an observation is a vector of values  each chosen from a finite domain. it is assumed that observation values are conditionally independent  given the state. each state is assumed to be associated with a point in some metric space. whenever a state transition is made  the robot records an odometry vector  which estimates the location of the current state relative to the previous state. it is assumed that the components of the odometry vector are corrupted with independent normal noise  extension to dependent noise is possible  and requires reestimation of the complete covariance matrix . 

	shatkay * kaelbling 	1 


learning 


	shatkay & kaelbling 	1 


figure 1: true map of the corridors ramona traversed. 

figure 1: learned map of the corridors ramona traversed. 
are longer ranged  and are used for obtaining  noisy  observations of the environment. the amount of data gathered by ramona is used here as a proof of concept but is not sufficient for statistical analysis. for the latter  we use data obtained from the simulated model. 
1 	robot domain 
the robot follows a prescribed path through the corridors in an office environment. low-level software provides a level of abstraction that allows the robot to move through hallways from intersection to intersection and to turn ninety degrees to the left or right. at each intersection  ultrasonic data interpretation allows the robot to perceive  in each of the four cardinal directions  whether there is an open space  a door  a wall  or something unknown. the robot also identifies doors and openings that it passes along the corridors. of course  both the action and perception routines are subject to error. finally  the robot has encoders on its wheels that allow it to estimate its pose  position and orientation  with respect to its pose at the previous intersection. the path ramona followed consists of 1 connected corridors in our building  which include 1 states  as shown in figure 1. 
　in our simulation  we manually generated an hmm representing a prescribed path of the robot through the complete office environment  consisting of 1 states  and the associated transition  observation  and odometric distributions. figure 1 shows the hmm corresponding to 
learning 

figure 1: true map of simulated hallway environment. 

figure 1: learned map of the simulated hallway environment. 
the simulated hallway environment1. further interpretation of the figures is provided in the following section. 
1 	evaluation method 
there are a number of different ways of evaluating the results of a model-learning algorithm. none is completely satisfactory  but they all give some insight into the utility of the results. 
　in this domain  there are transitions and observations that usually take place  and are therefore more likely than the others. furthermore  the relational information gives us a rough estimate of the metric locations of the states. to get a qualitative sense of the plausibility of a learned model  we can extract an essential map from the learned model  consisting of the states  the likely transitions and the metric measures associated with them  and ask whether this map corresponds to the essential map underlying the true world. 
　figures 1 and 1 are such essential versions of the true maps  while figures 1 and 1 are essential versions of representative learned maps. black dots represent the physical locations of states. multiple states  depicted as numbers in the plot  associated with a single location typically correspond to different orientations of the robot at that location. the larger black circle represents the initial state. arrows represent transitions that have probability 1 or higher. solid arrows represent the most 
1  observations and orientation are omitted for clarity. 

figure 1: a data sequence gathered by ramona. 
likely transitions between the states  and dashed arrows represent the less likely ones1. note that the length of the arrows is significant and represents the length of the corridors  drawn to scale. 
   more traditionally  in simulation experiments  the learned model is quantitatively compared to the actual model that generated the data. each of the models induces a probability distribution on strings of observations; the asymmetric kullback-leibler divergence  kullback and leibler  1  between the two distributions is a measure of how good the learned model is with respect to the true model. given a true probability distribution p = {p1 ... pn} and a learned one q = {q1  ... gn}  the kl divergence of q with respect to p is: 

we report our results in terms of a sampled version of the kl divergence  as described by rabiner . it is based on generating sequences of sufficient length  1 sequences of 1 observations in our case  according to the distribution induced by the true model  and comparing their likelihoods according to the learned model with the true model likelihoods. we ignore the odometry information when applying the kl measure  thus allowing comparison between models that are learned with and without odometry. 
1 	results 
we let ramona go around the path depicted in figure 1 and collect a sequence of about 1 observations. figure 1 plots the sequence of metric coordinates obtained by accumulating consecutive odometric readings  as described in section 1 . we applied the learning algorithm to the data 1 times. 1 of these runs were started from an informed  cluster based  initial model and 1 started from a random initial model.  note that there is non-determinism even when using informed initial models  since the clustering starts with random kmeans  thus multiple runs give multiple results . 
     1 bold dashed arrows represent transitions that are almost as likely as the most likely. 

figure 1: a data sequence generated by our simulator. 
　figure 1 shows an essential representation of a typical learned map starting from an informed model. the geometry of the learned map strongly corresponds to that of the true map  and most of the states positions were learned correctly. although the figure does not show it  the learned observation distributions at each state match well with the true observation distributions. when starting from an uninformed model  the results were not as satisfactory  which was predictable. 
　for obtaining statistically sufficient information  we generated 1 data sequences  each of length 1  using monte carlo sampling from the model shown in figure 1. 
one of these sequences is depicted in figure 1. the figure demonstrates that the noise model used in the simulation is indeed compatible with the noise pattern associated with real robot data. 
　we used three different settings of the learning algorithm: 
  starting from an informed  cluster based  initial model and using odometry information; 
  starting from a random initial model and using odometry information; 
  starting from a random initial model without using odometry information  standard baum-welch . 
for each sequence and each of the three algorithmic settings we ran the algorithm repeatedly 1 times. in all the experiments  tv was set to be 1  which is the  correct  number of states; for generalization  it will be necessary to use cross-validation or regularization methods to select model complexity. 
　figure 1 shows the essential version of one learned map  obtained from the sequence of figure 1  for a representative run. we note that some of the states whose locations overlap in the true model  e.g. 1  become separated in the learned model  e.g. 1 1   due to noise in the odometry readings and observations. however  there is an obvious correspondence between groups of states in the learned and true models  and most of the transitions  as well as the observations  which are not shown  were learned correctly. 
	shatkay & kaelbling 	1 
table 1: average results of three learning settings with five training sequences. 
　table 1 lists the kl divergence between the true and learned model  as well as the number of runs until convergence was reached  for each of the 1 sequences under each of the 1 learning settings  averaged over 1 runs per sequence. from the table it is clear that the kl divergence with respect to the true model for models learned using odometry  starting from either an informed or a random initial model  is about 1 times smaller than for models learned without odometry data. the standard deviation around the means was about 1 for all kl distances. to check the significance of our results we used the simple two-sample t-test. the models learned using odometric information have statistically significantly  p   1  lower average kl divergence than the others. 
　in addition  the number of iterations required for convergence when learning using odornetry information is roughly half that required when ignoring odornetry information. again  the t-test verifies the significance of this result. 
   the initial clustering strongly biases the outcome of learning; it is important to understand whether this bias is useful. when the entire model is initialized at random  the convergence time  measured in number of iterations  as well as the kl measure are somewhat higher on average  than when starting at an initial model based on clustering. the difference between the two starting points is not highly statistically significant since the clustering in many cases is not good. when the initial clustering is good  most of the work is already done and the em algorithm quickly fills in the details. however  if the initial clustering is bad  it is often close to a poor local minimum and the algorithm is unable to adjust it well. it will be important to try more sophisticated clustering algorithms. it may be best to run the algorithm multiple times  some with initial clustering and some without  taking the model with the highest likelihood as the final result. 
　to examine the influence of the amount of data on the quality of the learned models  we took one of the 
1 sequences  seq. #1  and used its prefixes of length 1 to 1  the complete sequence   in increments of 1  as individual sequences. we ran each of the three algorithmic settings over each of the 1 prefix sequences  1 times repeatedly. we then used the kl-divergence as described above to evaluate each of the resulting models 
learning 

table 1: average results of three learning settings with 1 incrementally longer sequences . 

figure 1: average kl-divergence as a function of the sequence length. 
with respect to the true model. for each prefix length we averaged the kl-divergence over the 1 runs. 
　table 1 summarizes the results of this experiment. it lists the mean kl-divergence over the 1 runs for each of the prefixes  as well as the standard deviation around this mean. entries with kl-divergence -   indicate that sequences generated by the true model were assigned negligible  -1  probability by the learned model  which corresponds to an infinite kl-divergence. the plot in figure 1 depicts the kl-divergence as a function of the sequence length for each of the three settings. both the table and the plot demonstrate that  in terms of the kl-divergence  our algorithm  which uses odometric information  is robust in the face of data reduction. in contrast  learning without the use of odornetry is much more sensitive to reduction in the amount of data. 
   again  we applied the two-sample t-test to verify the statistical significance of these results. for example  the kl-divergence being greater for sequences of length 1 than for sequences of length 1 when learning without the use of odornetry is highly statistically significant  p    1 . in contrast  the kl-divergence is not statistically significantly greater when the odornetry is used  for either informed or uninformed models. the informed model is even somewhat better   with moderate statistical significance  p   1   when using the sequence of length 1  due to better clustering when there is less accumulated noise on the odornetry data. 

   we note that the data sequence is twice as  wide  when odometry is used than when it is not  that is  there is more information in each element of the sequence when odometry data is recorded. however  the effort of recording this additional odometric information is negligible  and is well rewarded by the fact that fewer observations and less exploration are required for obtaining a data sequence sufficient for adequate learning. 
1 	conclusions 
odometric information  which is often readily available  makes it possible to learn hmms  or p o m d p models  for robot navigation efficiently and effectively. if we are interested in learning the geometric relationships between states  using the odometry readings is obviously very helpful. moreover  our experiments show that even when we are only interested in the underlying topological model  using odometry can both reduce the number of iterations required by the algorithm and improve the resulting model  while requiring shorter data sequences. 
   the work described in this paper is fairly preliminary. in the very near future  we will extend the example to learn the fully controllable pomdp rather than the hmm. the current implementation uses a very naive clustering algorithm; it will be useful to investigate more sophisticated clustering methods. the algorithm described in this paper is a batch algorithm. it would be useful to adapt it to be an incremental on-line algorithm. finally  we would like to find an improved m-step that would preserve the additivity constraint. 
acknowledgments 
we thank j i m kurien for providing and supporting the low level code for ramona  and william smart and jason lango for helping to keep her alive. we are also indebted to john hughes for the term  additivity  and sam trychin for letting us use his skateboard. 
this work was supported in part by the air force and 
a r p a under grant no. f1-1  by the nsf in conjunction with a r p a under grant no. iri-1  and by the nsf under grant no. iri-1. 
