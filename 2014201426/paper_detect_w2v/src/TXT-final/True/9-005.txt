 
     an approach for bringing semantic  as well as syntactic  information to bear on the problem of theorem-proving search for question-answering  qa  systems is descrilsed. 	the approach is embodied in a search algorithm  the 1* search algorithm  developed to 
control deductive searches in an experimental system. the q* algorithm is part of a system  termed the maryland refutation proof procedure system  mrpps   which incorporates both the q* algorithm  which performs the search required to answer a ouery  and an inferential 
component  which performs the logical manipulations necessary to deduce a clause from one or two other clauses. the inferential component includes many r e finements of resolution. 
     the q* algorithm generates nodes in the search space  applying semantic and syntactic information to 
direct the search. the use of semantics permits paths to be terminated and f r u i t f u l paths to be explored. the paper is restricted to a description of the use of syntactic and semantic information in the q* algorithm. 
keywords and phrases: deductive system  heuristics  problem-solving  proof procedure system  auestionanswering  resolution  search strategies  semantic heuristics  syntactic heuristics  theorem-proving. 
	1. 	introduction 
     the purpose of this paper is to describe an approach for bringing semantic  as well as syntactic  information to bear on the problem of theorem-proving search. the approach is embodied in a search algorithm  the q* search algorithm  developed to cont r o l the search in an experimental theorem-provingbased question-answering system. this system  termed the maryland refutation proof procedure system  mrpps   incorporates both the q* alqorithm which performs the search required to answer a ouery  and an inferential component which performs the logical manipulations necessary to deduce a clause from one or two other clauses. 
     the inferential component of mrpps provides a variety of resolution-based inference rules. for a given query  a user may select one  or a combination of the following inference systems: unrestricted binary resolution with factoring  set-of-support  input resolution  pl-deduction  a-ordering  paramodulation  linear and sl resolution. a mrpps user may also select certain search options that are available in the system. 
     the clauses from the negation of a given input query and those in the mrpps data base together with the selected inference system define a search space which is a directed graph whose nodes  states  are 
 labeled by  clauses. the i n i t i a l states are nodes labeled bv clauses from the negation of the query  and a goal state is a node labeled by the n u l l clause  ＆ . 
     the q* algorithm generates nodes in the search space  applying semantic and syntactic information to direct and l i m i t the search. this paper is restricted to a discussion of the q* algorithm. for a detailed description of the algorithm and of the entire mrpps system  see minker  et a l . .1 an overview of 
mrpps and of i t s inferential component may be found in 
	minker  et a l . 	. 1 
     the q* algorithm has been developed for eventual use in a question-answering system of practical scale. such a system would have a  large  number of axioms stored in i t s data base. a substantial majority of these axioms would be f u l l y instantiated unit clauses  termed  data axioms.  the remaining axioms  called  general axioms   define the predicates used and their interrelationships. one would want such a system to 
be very restrictive in permitting axioms to enter the search  in order to l i m i t the number of i/o accesses to the data base as well as to avoid clause interaction and memory clutter. in addition  one would want to be able to answer simple questions simply. an effective theorem-proving search algorithm for a guestion-answering system should generate the search space by:  1  selecting only those axioms from the 
data base that are relevant to the query  such that the  more premising  ones enter the search f i r s t ; and  1  deducing clauses from clauses already generated in as optimal an order as possible. 
     both of these problems are handled in the q* algorithm. 	the algorithm is subdivided into two d i s t i n c t but cooperating subalgprithms: 	the base clause selection algorithm which handles the f i r s t problem  
and the deduction algorithm which handles the second problem. the base clause algorithm uses primarily semantic information  while the deduction algorithm uses primarily syntactic information. 
     before discussing the algorithm  we review some of the background which precedes the present work and upon which t h i s work has been based. 
	1  	background 
     there has been a great deal of research in mechanical theorem-proving since the resolution principle was introduced by robinson . most of the r e search has been centered on developing refinements of resolution which reduce the size of the search space. however  relatively l i t t l e work has been reported in 
1 
developing improved search strategies or using semant i c s for theorem-proving systems.  we have recently learned that reiter 1 is attempting to incorporate semantics w i t h a theorem prover by the use of models.  resolution theorem-proving programs t y p i c a l l y use the unit preference search strategy  developed by vtos  et a l .   in which the merit of a clause in the search is based on i t s length. while t h i s is a useful strategy f o r proving simple theorems  it is not nearly 
powerful enough to successfully guide a search for even moderately deep mathematical proofs. furthermore  it is not adequate for use in question-answering 
applications which consist largely of u n i t clauses  since it gives preference to a i l u n i t clauses without regard to t h e i r relevance to the query. 
　　　green 1 in considering the application of theorem-proving in question-answering systems  p a r t i tioned clauses into two sets  active and passive. act i v e clauses are inferred clauses and axioms selected from the data base  whereas passive clauses are axioms which have not yet been selected. only active clauses may be used in inferences. a passive clause is made active only if it resolves with an existing active clause; preference is given to passive unit clauses. green incorporated t h i s search approach w i t h the u n i t preference strategy in the qa1 system which employs  essentially  set-of-support as i t s inference system. 
　　　kowalski  1a  1b 1 separates the notions of an inference system and a search strategy and describes t h e i r respective roles in the theorem-proving search problem. in addition  he defines a class of  upwards diagonal  search strategies which may be applied to a r b i t r a r y problem domains. these strategies simultaneously extend and refine the class of search s t r a tegies  which includes the a* algorithm described by hart  nilsson and raphael 1 kowalski also presents a particular upwards diagonal search algorithm  
which he c a l l s the j algorithm. in the j* algorithm  the passive/active clause concept is employed. in addition  the algorithm employs a clause merit evaluat i o n function in which both the length and level of a clause are considered. upwards diagonal search s t r a tegies could also be defined using heuristics other than length and level  see minker  et a l .  1 
	in the 1 	algorithm  the merit 	f c  	of clause 
c is a tuple    i   j     in which i = length c    and j = level c  . kowalski defines an ordering on t h i s 
merit function which he terms  upwards diagonal merit   denoted by the symbol u . given clauses c1 of merit   i     j 1   and c 1 of merit  i 1  j 1   tnen c 1 ♀ u c    i . e .   c  is of better or equal upwards diagonal merit than c 1   if 
	 i  	i1 	+ j1   i 1 + j 1   or 
	  i i   	i1 	+ j1 = i 1 + j 1 	and 	i1 	  i 1 . 
thus  if the length and level of two clauses sum to the same value  it is better to generate the shorter clause  since the goal of the search strategy is to generate a clause of length zero. 	it is thus advantageous to discriminate between clauses in t h i s manner rather than solely on the basis of the sum of the merit components  as is done in e a r l i e r search a l gorithms such as the a* algorithm  hart  et a l .  p. 
　　　based on t h i s merit function  kowalski p a r t i t i o n s the search space i n t o merit sets  called a-sets  into which clauses of equal merit are generated. the j* algorithm generates clauses i n t o these merit sets in increasing upwards diagonal order  it f i r s t t r i e s to generate a clause into a 1  which would be possible only if the n u l l clause were in the s t a r t i n g set of base clauses. 	it then successively attempts to generate  by selecting a clause from the base set  or by inference  clauses i n t o the sets 	a 1  	  a 1  	  a 1  	  a{1    a 1    a 1  	  etc. 	any time a clause is generated  an attempt is made to recursively generate a l l of i t s successors and successors of i t s successors which are of better merit than the current merit to which the algorithm has sequenced. 
r* 
     while the above description of the l algorithm is necessarily terse  the reader is referred to kowalski  1a  1b   1 ' 1 and to minker  et a l .  1  1  1 ' 1 for more detailed discussions. 
1. a view of resolution theorem-proving search as problem-reduction search 
　　　before describing the operation of the q* algorithm  it w i l l be useful to describe how resolution theorem-proving search may be interpreted as problemreduction search. in a problem-reduction search  an operator is applied to a problem p to reduce it to a set of subproblems such that solution of a l l the successor subproblems implies a solution to p . equivalently  the conjunction of these subproblems may be considered a new problem which must be solved for the given problem to be solved. this reduction process is recursively applied to each generated subproblem u n t i l the o r i q i n a l problem has been reduced to a set of p r i m i t i v e subproblems which are t r i v i a l to solve. 
     m o r e precisely  a problem-reduction consists of three sets: 
 1  a set of s t a r t i n g problems; 
 1  a set of operators that reduce a problem to a set of subproblems; and  
 1  a set of f i n a l problems which are  by d e f i n i t i o n   solved. 
　　　in the context of resolution theorem-proving  a clause corresponds to a problem and a l i t e r a l corresponds to a subproblem. thus  a clause is a conjunction of subproblems since all subproblems must be solved for the problem to be solved   i . e .   a l l l i t erals must be eliminated . 
     the startinq set of problems corresponds to a s t a r t i n g set of base clauses. the actual members of t h i s set w i l l depend upon the inference system being used. for instance  if the inference system is setof-support  o r i f i t includes set-of-support  the s t a r t i n g set of problems corresponds to the clauses in the negation of the cruery. for other inference systems  it consists of the entire set of base clauses  i . e .   a l l of the axioms together with the query clauses. 
1 　　　clauses may also be regarded as operators which are applied to problems by means of inference rules. however  the set of operators that may be applied w i l l vary depending on the inference rule used  e . g .   fact o r i n g   paramodulation  and various refinements of r e solution. for a resolution operation  two clauses are involved. in general  the choice of which clause is the problem and which is the operator is somewhat a r b i t r a r y . however  for certain inference systems  it seems natural to make a clearer d i s t i n c t i o n between the two. for instance  if input resolution is used  each clause of a linear chain may be regarded as a problem and a l l base clauses may be regarded as operators. for linear and sl resolution  ancestors of a problem may also be considered as operators  in addition to a l l the base clauses. 
     a clause may also be a final problem. in particular  the null clause is the only such clause when one is attempting to refute a conjecture. thus  when a null clause is generated  we know that a starting problem has been solved. determining when a subproblem is solved is more d i f f i c u l t . this may be seen by considering the process involved in solving a subproblem. a subproblem p  which corresponds to a l i t e r a l in a clause   may be solved in either of two wavs: 1  it may be solved in a single step bv applving an operator that refutes it  a unit clause ; 1  alternately  an operator may be applied to p that spawns a set of subproblems such that p is solved if and only if a l l of the subproblems are solved. in practice  the determination of when a given subproblem has been solved may be quite d i f f i c u l t . depending on the inference system used  subproblems are attacked in 
arbitrary order. consequently  the bookkeeping required to keep track of which literals of a given clause have been spawned by which subproblems may be quite involved. 
however  one inference system  sl resolution 
 {kowalski and kuehner } 1 stands out as being particularly well suited for this task. in the f i r s t place  sl resolution requires that only one subproblem be attempted at a given level. secondly  the required bookkeeping is built into the clause representation used in sl resolution. in this representation  a clause is referred to as a chain. in sl resolution  a subproblem to which a solution is sought is actually 
carried along  and duly tagged  in each of the successor chains. such l i t e r a l s are called  a literals  in the successor clauses. as new literals  called  b l i t erals   are introduced in the attempt to solve a subproblem  they are placed to the right of the a l i t e r a l . when a l l such b l i t e r a l s have been resolved awav  resolution is only performed on rightmost b literals  and 
an a l i t e r a l is exposed on the right  then that constitutes a solution to the subnroblem from which that a l i t e r a l descended. at this time  sl resolution requires that the exposed a l i t e r a l be removed from the clause - an operation which is called truncation. only at this time   and not before as with other refinements of resolution  may a new subproblem from the 
original problem be selected for solution. 
	1. 	the q* algorithm 
　　　the q* algorithm is based upon the i 	algorithm of kowalski together with the idea of green to allow only certain base clauses to enter the active clause space. 	both of these approaches have been extended in the current algorithm. 	the q* algorithm is subdivided into two major components: 
1  the deduction algorithm which uses primarily syntactic information; and  
1  the base clause selection algorithm which uses primarily semantic information. 
　　　the deduction algorithm generates new problems by the application of operators to problems already in the search space. any operator that is applied must i t s e l f have been previously generated either bv inference or by the selection of a base clause. 
     problems and operators are generated bv two major subalgorithms  fill and recurse  which are adaptations 
of analogous subalgorithms of the ♀ algorithm. as a clause is generated  it is placed into an a-set corresponding to i t s merit. the algorithm uses a generalized upwards diagonal merit function to calculate the merit of a clause  and generates clauses in approximately upwards diagonal order.  further details on this function as well as on the deduction algorithm are contained in minker  et a l . 	 1  1 1.  
　　　in using this merit function  it is hoped that clauses of better merit w i l l be more useful to answering the query than those of worse merit. however  in practice  it is extremely d i f f i c u l t to develop c o m nonents of the merit function that adequately reflect the relevance of clauses with respect to the query. most components used to date have been syntactic in nature  rather than semantic  and have led to very i n efficient search strategies.  see slagle and farrell 1 and minker  et a l . 1 for examples.  consequently  theorem-provers using such a search strategy are often deluged with irrelevant clauses and thus are inadequate for most applications. 
　　　there are two ways to alleviate this problem. first  after a problem is generated by an inference step  various deletion rules may be applied so that the problem may be eliminated in case it is redundant 
or semantically meaningless. thus  tautologies  alphabetic variants and subsumed clauses may be eliminated. furthermore  subproblems as well as problems mav be eliminated by predicate evaluation. this 
mav be done bv referencing stored semantic information about the problem domain. for instance  let c v f mary  x  be a generated problem  where c is the remainder of the clause. if it is known that the f i r s t argument of the father predicate must be male  and we know that mary is female  then the l i t e r a l f marv  x  w i l l never have a solution   i . e .   no unit clause/ f{mary  a    can be true  for any person a . we can thus evaluate the l i t e r a l f mary  x  as being true relative to the interpretation given to the problem domain and may eliminate the entire problem from 
the search space since it is unsolvable. with most inference systems completeness should not be violated 
bv deleting the clause. on the other hand  if a l i t eral of a clause is evaluated as false  that l i t e r a l alone  mav be removed  since it corresponds to a subproblem that is solved. 
     although predicate evaluation using semantic i n formation about the problem domain w i l l be useful in theorem-proving  it does not prevent irrelevant clauses from being generated and entered in the search snace. we thus feel that a more effective method by which to cut down the size of the search space is to avoid generating irrelevant clauses in the f i r s t place. in particular  this can be accomplished by carefully selecting those operators that are most relevant to the search in progress and by inhibiting those which are irrelevant. this is the function of the base clause selection algorithm. 
　　　depending on the inference system  the algorithm treats one or a l l of the l i t e r a l s of a generated clause as a specification with which to select axioms. thus  each l i t e r a l is termed a  spec l i t e r a l .    this mav be viewed as the selection of operators to apply to a subproblem.  in order to select axioms relevant to the querv  the q* algorithm i n i t i a l l y generates clauses from the negation of the query. each spec l i t e r a l is used to locate those axioms which either resolve with the generated clause on that l i t e r a l   or  in some cases  which possess a l i t e r a l which w i l l unify with the spec l i t e r a l . the axioms that have been located for a particular spec l i t e r a l may be reduced in number by filtering out those which are found to be semantically inappropriate  e.g.  because of i n compatible argument types . the remaining operators for a given subproblem then become candidates for generation and must be ordered so that  more promising  operators are tried f i r s t . the l i s t of candi-
dates for a spec l i t e r a l is placed on a l i s t called the speclist  which is i t s e l f ordered by using various 
heuristic c r i t e r i a . thus  the ordering of the speclist reflects the judgment of the base clause algorithm as to which subproblems from among a l l subproblems in a l l generated clauses should be attacked f i r s t . that i s   from among a l l l i t e r a l s in a l l generated clauses that are eligible for resolving  the base clause selection strategy picks the best one. 
     as a result of the control maintained over the base clauses by the base clause selection algorithm  the fill operation of the deduction algorithm w i l l not  in general  acquire a l l base clauses of a given fill 
merit. it obtains only those base clauses made a v a i l able to it by the base clause selection algorithm. as a result  the base clauses that are selected w i l l not necessarily be generated in merit order. consenuently  and in contrast to the j* algorithm  the q* algorithm is not admissible. however  as the exanples in section 1 demonstrate  the loss of admissibility may be of only theoretical importance since it would seem to be more important in practical qa amplications to find anv solution quickly rather than to find a simplest solution at great expense  at the risk of finding no solution at a l l because of space and time considerations. 
     the following sections describe the manner in which axioms are located  the way certain of these are f i l t e r e d out  and the way those that remain are ordered. section 1 presents a discussion of a olanned extension of the search strategy in which the base clause algorithm may prune the search space and delete 
certain candidates from the spbclist upon the recognition of certain events in the search process. 
1 	locating candidate axioms 
     as already indicated  the l i t e r a l s of generated clauses are used to locate axioms which may become candidates for generation. the inference system that is being used by the deduction algorithm w i l l deter-
mine which generated clauses should be used for this purpose  and what criterion should be applied to 
select the axioms. if the inference system in use is set-of-support  or if it incorporates set-of-support 
as does sl resolution  then only the l i t e r a l s of supported clauses w i l l be used. furthermore  the axioms which become candidates w i l l be those which could resolve with the generated clause. on the other hand  if the inference system does not include set-ofsupport then a l l genera-ted clauses  including generated axioms  w i l l be used to locate axioms. in addition  the resolution criterion must be weakened  so that an axiom w i l l potentially become a candidate if it contains a l i t e r a l which unifies with a l i t e r a l of a generated clause. the weakening of the resolution criterion is necessary in order to assure the refutation completeness of the algorithm  e.g.  in cases 
where the only refutations for a given ouery involves the use of a lemma  and the ouery is not used u n t i l the lemma has been established. 
     not only does the inference system dictate which clauses are to be used in locating axioms  it also dictates which l i t e r a l s should be used. thus  in  single l i t e r a l   inference systems such as sl resolution or a-ordering  only one designated l i t e r a l of each generated clause is used  while for other inference systems  a l l of the l i t e r a l s w i l l be used for this purpose. 
     the approach to locating axioms which may enter into the search  may  for a given query  preclude the generation of certain axioms. 	that i s   there may be axioms which are completely unrelated to the ouery in that they concern a different problem domain. 	but since these are completely irrelevant to the query  the search strategy w i l l not be hindered from finding a refutation if one is attainable. 
1 	semantic filtering of candidate axioms 
     once the potential candidates for a given spec l i t e r a l are found  these may be subjected to semantic f i l t e r i n g   and only those which are semantically consistent with the spec l i t e r a l and i t s host clause may become candidates. this f i l t e r i n g may be done on the basis of the class membership  or type  of a variable or constant in the spec l i t e r a l . for example  suppose the generated clause l i t e r a l is ~parent  dan  brett  and it is known that dan is a male  or the l i t e r a l is ~parent  x  brett  and  from context  it is known that x corresponds to a male. suppose further that the two potential base clause candidates: 
 1  ~father u v  v parent u v    and  1  ~mother  u v  v parent  u v  
were found in the data base. applying the f i l t e r   axiom  1  would be found semantically inconsistent with the spec l i t e r a l since the variable u in the parent l i t e r a l is found to be of type female from context    i . e .   from i t s use in mother l i t e r a l     and what is necessary is a parent l i t e r a l whose f i r s t argument is of type male. thus  only  1  would become a candidate. 
     a further type of f i l t e r i n g may also be performed. when a l l of the solutions to a subproblem are exp l i c i t in the data base  it becomes unnecessary to generate any general axioms which might be used to deduce a solution to the subproblem. for example  l e t ~mother x  emily  be a generated clause l i t e r a l . also assume that it is known that every individual has exactly one mother. if the axiom mother roz  emily  
were found in the data base  then  since this completely solves the subproblem at hand  it would become the only candidate. no other axioms that could resolve with ~mother{x  emily  would be entered to satisfy t h i s subproblem. 
     the f i l t e r i n g we have described can be seen to reduce the number of axioms which are generated into the search space. as a result  fewer clauses w i l l be available to interact logically and so the t o t a l number of clauses which may be generated is thereby r e duced  clearly  the clauses of the implicit search space which have become ungeneratable as a result of this f i l t e r i n g could not have contributed to a refutation so that although the search algorithm f a i l s to be complete  in the sense of exhaustive   it remains refutation complete. 
1 	ordering of candidate axioms and subproblems 
     once the candidate axioms have been located and subjected to semantic f i l t e r i n g   they must be ordered so that the  more promising  ones w i l l be generated f i r s t . as already noted  there is a two-level ordering that is performed: the candidates associated with a particular spec l i t e r a l must be ordered  this corresponds to the ordering of operators to be applied to a subproblem   and the l i s t s of candidates for the various spec l i t e r a l s are ordered with respect to one another  this corresponds to the ordering of subproblems . 
     in ordering the candidates for a particular spec l i t e r a l   two different approaches may be employed. in one approach  they may be ordered according to a teooimendation by the user. this is analogous to the recommendation l i s t s in planner  hewitt     1 . 
1 another approach is to order candidates according to 
the merit ordering  f   used by the deduction strategy  making sure that data axioms   i . e .   f u l l y instantiated 
unit clauses  precede any general axioms. 
　　　with respect to ordering the subproblems  a heuristic guideline is applied when one or more constants occur in l i t e r a l s of the query clauses. in this event  the candidates located by using constantcarrying l i t e r a l s of generated clauses w i l l precede in the ordering those candidate axioms located by the use 
of general l i t e r a l s . the reasoning behind this heurist i c is that  1  constant-carrying l i t e r a l s w i l l generally resolve  or unify  with fewer base clauses than w i l l general l i t e r a l s   and  1  if a query is about a particular individual  constant   then the search mechanism w i l l make more informed decisions about the relevance of candidate axioms if it concentrates on this individual  -and to others which are found to be related to i t   rather than going off blindly on the basis of some general l i t e r a l . in many cases  the general l i t e r a l may actually unify with a large subset of the axioms in the data base while only a few of these may be relevant. furthermore  by pursuing this policy  l i t e r a l s which are uninstantiated at one level of the search may become instantiated at a subsequent level. thus  in this approach  it w i l l often be the case that clues  in the form of constants  to direct the search w i l l be passed from one subproblem to another as the search progresses. 
　　　figure 1 illustrates a proof that was derived giving preference to those l i t e r a l s that contain constants. in figure 1  clause   l   y i e l d s two l i t e r a l s for the speclist. the l i t e r a l m y  sally  would be given preference on this l i s t since it contains a constant. the axioms that can interact with the l i t e r a l m y  sally  are entered into the search before other axioms that may apply to that clause. similarly  in clause  1   the constant in h v  rita  gives this l i t e r a l preference. although proofs can be found 
without using this heuristic  such proofs w i l l tend to generate many unneeded clauses. 
　　　it is reasonable to assume that in questionanswering applications a large percentage of the queries w i l l contain constants. even if constants appear in a given l i t e r a l   it may be reasonable to give preference to a l i t e r a l containing only variables based upon a lower estimate of potential candidates satisfying each of these l i t e r a l s . however  we would expect this to happen infrequently in questionanswering systems. 
　　　there may be several subproblems  spec literals  containing constants which must be ordered with respect to one another on the speclist. in this case  the ordering of candidate l i s t s by their spec literals is accomplished by using a prediction of the merit  f   of a resolvent between the spec l i t e r a l ' s host clause and the f i r s t axiom in the ordered l i s t of candidates from that l i t e r a l . one consequence of this ordering is that if a generated unit clause is contradicted by a unit axiom  then this axiom surely w i l l have become a candidate  and it w i l l be placed f i r s t in the ordering so that it w i l l be the very next axiom to be gen-
erated. each time an axiom is removed from the l i s t of candidates  the next candidate in the l i s t is used for a new prediction  and the corresponding spbclist entry is reinserted into an appropriate position of the l i s t - it may remain on top of the l i s t   or some other subproblem may emerge as  most promising.  
　　　in some data bases  there may be certain constants which occur in a large number of the data axioms. generally  these would be non-specific  class specifying types of constants such as male and single as used in the data axiom. 
person john  smith  id1  male  female  . 
since such constants do not designate particular i n dividuals  and since they do occur throughout the data base  thev w i l l be of l i t t l e value in directing the search. thus  for the purpose of ordering the speclist  spec l i t e r a l s containing these types of constants alone are treated as general l i t e r a l s . 
1 	semantic actions during the search 
　　　it was noted in section 1 that some subproblems may be comnletelv solved by data axioms stored in the data base  more generally  some subproblems have an exact number of solutions while others have an i n definite number of solutions. if the number of solutions to a given subproblem is known  then  during the course of the search  the progress of the search relative to finding these solutions can be monitored. when a l l of the solutions have been found  that portion of the search graph which has been unnecessarily generated in the attempt to find these solutions can be pruned. in addition  the candidate axioms located through the use of literals in the pruned clauses or in clauses along the solution path w i l l have their candidate status removed. the effect of this pruning is to reduce the number of irrelevant clauses in the search space. of even greater significance is that the potential successors of these clauses are effectively prevented from being generated. 
     the bookkeeping required to apply these semantic actions would be quite complex when arbitrary inference systems are employed  since  for a given clause  problem   attempts to solve a l l of the subproblons are carried out simultaneously. however  sl resolution is particularly well suited for this approach  since only one subproblem is attacked at a time and because the bookkeeping required to detect the solution of a subproblem is built into the sl clause representation  as noted in section 1. semant i c actions are taken when truncation occurs  since truncation only occurs when a subproblem has been solved. the semantic action taken is to increment a 
count and test it against the number of solutions sought. 	if this number is met  then pruning can be performed. 
     the above approach does not require that a l l solutions to a given subproblem be obtained before 
progressing to another subproblem. it would seem to be desirable  in some cases  to continue the search for additional solutions to the subproblem  while at the same time advancing to the next subproblem. 
	1. 	example runs with mrpps 
　　　the mrpps system incorporates a preliminary version of the q* algorithm plus an option for selecting the 	algorithm. 	the current implementation of q* does not yet include the semantic f i l t e r i n g of candidates  and no mechanism has been included to take semantic actions. 	the current version includes the 
deduction strategy as outlined  together with a base clause selection strategy which locates and orders axioms essentially as described. all details concerning the current implementation are described in minker  et a l .  l . the implementation of the ♀ algorithm uses the same deduction strategy as q*  but the base clause selection strategy merely locates axioms in merit order  that is to say  by length  without regard to other clauses generated by the search. 

     we present comparative s t a t i s t i c s for two d i f f e r ent queries  in which set-of-support and sl resolution 
were the chosen inference systems  and the merit components were clause length and l e v e l . clause length and level bounds were both set at eleven  and an f value bound  = length + level  was set at eleven. the data base used contains 1 data axioms which e x p l i c i t l y state the  1  mother   1  father   1  b i r t h date  and  1  birthplace of individuals in terms of t h e i r i d e n t i f i c a t i o n  i.d.  numbers  and  1  which relate the f i r s t and last name of each individual to t h e i r i d e n t i f i c a t i o n number. the data base also includes 1 general axioms which define the various predicates in terms of other predicates. 
question 1. 	 what is the name of brett fishman's moth-
　　　the significant aspects of t h i s simple question is that i t s negation in clause form is a u n i t clause containing constants. with the data base used  it r e quires four axioms and four levels of search to achieve a r e f u t a t i o n . 
v* 
　　　both the l and q* algorithms successfully completed the search  however as the s t a t i s t i c s in table 1 demonstrate  with considerably different levels of work and resources required. whereas the q* algorithm f o r t u i t o u s l y generated the minimal number of base clauses  the }* algorithm has to generate a l l axioms of length one   i . e .   a l l the data axioms   two  and three and some axioms of length four before the r e quired general axiom  of length four  was obtained. once t h i s general axiom was resolved against the query clause  the resolvent  having support  could be resolved against many of the axioms already in a-sets  and s i m i l a r l y for the resolvents obtained. as a consequence  many more resolvents were generated. furthermore  the presence of a large number of clauses in a-sets required the use of a considerable amount of free space to keep track of the clauses as well as a significant increase in the search time required. 
question 1.   i s there a person who is the grandfather on the father's side of individual 1 and the grandfather on the mother's side of individual 1   
the negation of the question in clause form i s : 
ff x  1  v fm x  1  
where 	ff 	is the predicate  grandfather on the 
father's side   and fm is the predicate  grandfather on the mother's side.  this question  which requires six levels of search requires the following six axioms from the set of 1 data axioms and 1 general axioms: 
f x  y  v m y  z  v fm x  z  f x  y  v f{y  z  v ff x  z  
	m 1  1   	f 1  1   	f 1  1   and f 1  1  . 
　　　proofs were found using set-of-support and sl resolution as the inference mechanism. the s t a t i s t i c s for set-of-support indicate that the q* algorithm was quite selective as compared to both with respect to the number of resolvents and axioms generated. however  1* did obtain considerably more general axioms than actually needed. 
     the same question was tested using sl resolution as the inference mechanism. the table shows s t a t i s t i c s for the q* algorithm as generated by the computer  it also shows s t a t i s t i c s   generated by hand  for the q* algorithm when the semantic r u l e of counting the number of possible solutions to a subproblem is used. the q* and 1 algorithms without the use of semantics generated the same number of inferences. however  ♀ brought in 1 axioms  only 1 of which were needed. q* when not using semantics brought in 1 axioms  only 
1 of which were actually needed. q* without semantics performed better when using sl resolution than when using set-of-support as the inference mechanism. the use of semantics for q* shows i t s general u t i l i t y . the number of axioms entered were 1  while only 1 were needed for the proof. although there is a significant decrease in the number of axioms generated using semantics  the one example should not be considered to be the type of improvement that one w i l l always achieve using semantic considerations to r e s t r i c t the search. however  it is indicative of the use of semantics. the trace of clauses generated by sl r e solution and the proof are shown in figure 1. 
	1. 	summary 
　　　we have described a search strategy for theoremorovinq which uses both svntactic and semantic i n f o r mation to d i r e c t the search in a question-answering system. most theorem-proving systems have used primarily syntactic information such as clause level and clause length to d i r e c t the search. others have attempted to use only refinements of resolution with a breadth-first search or an ad hoc use of heuristic rules. experience with such systems may have led some to speculate that means other than theorem-proving must be developed to perform deduction in questionanswering  or in other problems  e.g.  anderson and hayes  1 the reason for t h i s skepticism of theorem-proving may stem from the inadequacy of search strategies to l i m i t the search to a  reasonable  number of nodes in finding proofs. we agree that the use of only logical rules and syntactic heuristics w i l l not be s u f f i c i e n t for most systems. however  it is our hope that the introduction of semantic information to aid in directing the search w i l l be useful. 
　　　we have t r i e d to show where semantic information may be used in a theorem prover  and how it may coordinate w i t h the syntactic heuristics and logical deduction. there are several places where semantics enter i n t o the search process: 
 1  at the time a clause is generated  to determine whether it is semantically meaningful; 
 1  in selecting a l i t e r a l of a clause to expand; 
 1  in the f i l t e r i n g out of irrelevant operators; and 
 1  in taking actions when a l i t e r a l is solved. 
there i s   however  a tradeoff as to when semantics should be applied. it may r e s u l t that the attempt to determine whether or not a clause is solvable could take more time than the solving of the problem. hence  studies must be performed in t h i s area to determine the various costs involved. 
     with an a r b i t r a r y inference system it is not always easy to determine when a l i t e r a l from some clause has been solved. the bookkeeping that might be involved could become unmanageable. however  as described previously  sl resolution minimizes the bookkeeping problem. sl resolution has the additional advantage of providing the opportunity to select which subproblem to attack next. 
　　　some of the semantic information we use is gene r a l   e . g .   the count of the number of solutions to a subproblem; if such information is supplied by the 
user it could be used to advantage for any problem domain. 	a general framework for representing and applying semantic information is needed. 	in addition  our semantic considerations have been directed primarily at the meaning of constants  and not at the meaning of functions and skolem functions that may frequently occur in clauses. these must also be considered. 
     we have presented a f i r s t version of the q* a l gorithm that carbines syntactic and semantic considerations. improvements must be made in the algorithm to handle parallel searching such as in conniver  sussman and mcdermott 1 and to implement some of the features that were described  but not incorporated i n to the f i r s t version. however  based on limited ex-
perience with the current version of q*  it has been observed that the search does r e s t r i c t the generation of clauses. 
     the area of semantics and theorem-proving requires considerably more research and experimentation. this paper has described a f i r s t step in exploring this area. 
