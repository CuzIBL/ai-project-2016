 
　　　froblcm reduction is the name given to the problemsolving paradigm in which the problem solver manages a network of  tasks  representing its intentions  repeatedly reducing tasks to subtasks and coordinating their execution. this idea needs a lot of generalization for it to be able to handle a realistic range of problems. even after the model of time is made more realistic  to handle continuity and branching   issues remain regarding what it means to have a task or a subtask  how a task can succeed or fail  whether a 
　　　task is feasible. a profitable way to study these issues is to attempt to add axioms about tasks to a first-order temporal logic. the result sheds light on what sorts of generalizations of task networks are needed. 
1. introduction 
	problem 	solvers 	like 	noah  sacerdoti 	1   
nasl  mcdermott 1   and sipe  wilkins 1  do what is called problem reduction. they work on problems  or tasks  by retrieving plans from some kind of plan library. each task gives rise to a plan  which consists of one or more subtasks. the subtasks are actions  which  if done in the 
appropriate order  will solve the original problem. each subtask is either primitive  or becomes a new problem. the structure of partially ordered tasks is called a procedural network  or task network. see figure 1 

   this work was supported by the national science foundation under contract mcs-1 
　　　the subtasks interact in various ways  and may require reordering. for instance  if one task makes false a fact that another task requires to be true  it may be important to make sure that the falsifying task is ordered so that it occurs when the interaction no longer matters. 
　　　this framework is substantially that pioneered by sacerdoti and explored by others since. surprisingly little progress has been made in pushing it much further. one reason for this is that most problem solvers have had a 
　　　consistently impoverished vocabulary for expressing temporal concepts. for instance  it has usually been assumed that nothing happens unless the problem solver makes it happen  and that each action the problem solver performs can be expressed in terms of  addlists and delotelists   which specify a finite  often contextindependent  set of atomic facts that change in truth value instantaneously when the action is executed. these restrictions have historically been associated with applications of mccarthy's situation calculus  mccarthy .1   even though nothing in that calculus really requires them.  the use of  dynamic logic   as in  rosenschein 1   
freezes these faulty assumptions in an elegant crystalline form  but makes it harder to go beyond them than mccarthy's original formulation.  
　　　another reason for lack of progress is that the diagram of figure 1 is too seductive. it implies that any action can be reduced to a network of subactions and arrows. in fact  this vocabulary for describing plans is quite weak. of course  we can augment the vocabulary as much as we want; the trick is to retain the transparency that allowed sacerdoti's noah to reason about what it intended to do. 
　　　as an example of the sort of reasoning a problem solver should be able to do  suppose that it is set the task of managing a water supply. it can fill a main supply tank by opening an inlet  up to some level  and must be prepared to use water from the supply for various purposes. in particular  the water will be needed for a series of industrial tasks  cooling things  putting out fires  or whatever . we can model this as a sequence of two tasks: open the valve  and  for each event that requires water  draw down the required amount from the tank. 
　　　beyond this point  problem solvers have not been able to perform problem reduction. and yet  it seems a matter of simple temporal reasoning to foresee how much water will be available and roughly how much will be needed. if there is a discrepancy  it should be noticed  by a  critic    and task-network revision should ensue. 
　　　in  mcdcrmott 1   i tried to enlarge the vocabulary for talking about time and actions  to allow actions like   turn on the water    allow the tank to fill    avoid leaving the room   and  prevent the tub from overflowing.  none of these could be expressed in the older formalism. 
this was accomplished by enriching the ontology of the situation calculus. situations  now thought of as instantaneous states of the universe  were assumed to be packed into continuous sequences. the notion of a  next  state was abandoned. even while the problem solver does nothing  time continues to advance. this allows one to reason about processes and agents outside the problem solver  which i shall refer to as  the robot   since it reasons about taking actual actions in the real world . 
　　　another important augmentation was to stipulate that universe states are partially ordered. time branches into the future  so two states can both be in the future of  now''  and not be comparable; they represent alternative futures. in general  the outcome of an action is not a single state as has often been assumed. since lots of other things can be happening at the same time  and even simple actions have unpredictable effects  an action is thought of as happening over an interval. we write this  occ s1 s1  do robot a  : from state  sl to state s1  the robot does action a. the same action can be done in many different intervals  all starting in s1. stated otherwise  many different states of the world can result from doing a given action in a given state. 

　　　this is a promising start  but only attacks half the problem. we can talk about actions in a more sophisticated way  and reason  for instance  about tanks filling up  as in  mcdermott 1  . we must now develop ways of talking about problem-solver intentions as well. 
　　　it should be clear that in this paper i am exploring representational issues by the formal-logical methods pioneered by mccarthy  mccarthy 1  and hayes  hayes 1 . hard-nosed problem-solving researchers may be impatient with this. to many of them it must seem a waste of time to work on anemic logical studies when redblooded arms and motors await. eventually  however  the ad hoc nature of the problem solvers we build will catch up with us. we may as well act now to develop temporal calculi that can support the kinds of reasoning we will need to build into our autonomous robots. 
d. mcdermott 1 
1. tasks and subtasks 
　　　we must add to the temporal logic the ability to talk about tasks and plans as well as simple actions. the basic notion is  of course  the fact of having the intention to do an action. we write this as  t 1  task k a  .  t s p  means that fact p is true in state s; this is just a variant of the situation calculus   task k a  is a particular fact  true in some states and false in others. it is true if the robot has the intention of doing a whenever it can. k is a term denoting this intention. we have axioms like this: 


1 d. mcdermott 
of  get daddy warbucks's inheritance.  the subtask succeeds if warbucks is poisoned by annie; fails if she is thwarted; and evaporates if warbucks dies on his own. 
we formalize this as follows: 

this axiom is not a biconditonal  because a problem solver can have tasks with no supertasks  e.g.   stay alive  . 
　one possible definition of failure is that a task has failed when its action becomes impossible. rather than accept this definition  i opt for providing axioms explaining how every task of interest fails; more work is needed to see if the more general definition can be made to work. 
1. feasibility 
　　　in mccarthy's situation calculus  a typical deduction was of the form  find a sequence of actions that transform situation so into a situation in which fact p is true.  such deductions were done in an environment in which the only actions that were named were also feasible. that is  the axioms were set up so that only plans like  put a on b  then put c on a  could be generated. a plan like  play the horse that's going to win tomorrow  would never come up. 
　　a significant flaw in this axiom is that it neglects the possibility that a task goes away because it ceases to be the best way to carry out its supertasks. treating this case would require a substantial extension to the framework of this paper. 

　　　modern problem solvers generate abstract intentions before concrete plans to carry them out. as their possibilities widen  it will get increasingly difficult to ensure that simply finding an action sequence's name will guarantee that it is feasible. 
　　　the task-subtask calculus gives us some hints how to analyze this important problem. the major idea is to analyze feasibility thus: an action is feasible if trying it would cause it to happen. we analyze trying something as having a task to do it. 
　　　the definition of feasibility involves a counterfactual or subjunctive conditional.  as in  ''a was feasible  because if you had tried it  you would have succeeded.   fortunately  the branching time we assumed makes this a rather easy counterfactual to handle. we simply suppose that a branch of the universe is taken in which a  test task  is injected into the robot's intention structure. if the ''test task  would succeed  then the action is feasible. 
　　　one modification is needed here. suppose the robot has the task   stay in this room.  then the action  take this tool to the basement  is feasible  but only at the cost of upsetting the other task. so we introduce the notion of feasibility relative to a set of boundary tasks  none of which may be allowed to fail while the test task is performed. 
　　　we use the term  reltrytask state action boundary-task-set  to refer to the attempt to carry out action starting in state without upsetting any of the tasks in boundary-task-set. we suppose that the robot has  free will   and could essay a reltrytask on any action at any time. see figure 1. 
	d. mcdermott 	1 
therefore  we want to make the criterion be that an 
 isolated reltry  of an action would succeed. an isolated reltry is one that occurs without any other crazy tasks popping up  including especially other reltries. in the example of the previous paragraph  the proofs that al and a1 were feasible would depend on what happened when each was tried in isolation from the other. as desired  nothing could then be concluded about a situation in which both were tried at once. 
　　　we can't isolate a reltry too much  however  or the result will be useless; as soon as we put a complex task network around a task  the isolation condition will no longer hold  and feasibility will not allow us to conclude anything. 
　　　the following definition appears to do the job: an isolated reltrytask is one that takes place without any other new reltrytasks occurring  except subtasks and syntactic supertasks of the test task. for instance  in a proof that it is feasible to win the election of 1  we will posit a reltrytask to win it. we forbid weird new reltrytasks like  streak down pennsyvania avenue   but we allow subtasks like  file for candidate status by january  1.  
　　　with this definition of isolated task  see  mcdermott 1  for the details   we can define feasibility as follows: a is feasible in state s with respect to boundary tasks kk if an isolated reltrytask beginning in s would succeed or evaporate without any element of kk failing. 
　　　we can use this definition to prove these theorems  see  mcdermott 1  : 
1. if al is feasible in so  and a1 is feasible in 


　　　reltrytasks play a role like that of  test particles  in physics: hypothetical entities introduced into a situation that react to it without disturbing it. to determine if an action is feasible  we posit that it is tried  and see if we can 
deduce that it is successful. 
　　　we have to be quite careful about the way this is done  in order to avoid fallacies like this one: suppose that al and a1 are both feasible  because if either is tried  it succeeds. then suppose both are tried simultaneously. this event qualifies as a try of each separately  so we can conclude that both will happen  and hence that it is feasible that both can be done simultaneously. since al might be  leave the room   and a1 might be  stay in the room   you see the problem. 
every state resulting from doing al  then  prog  al a1   is feasible in so. 
1. if an event is certain to happen before any boundary task in a given set fails  then waiting for it is feasible with respect to those boundary tasks. 
　　　it is interesting that to prove these theorems  it is necessary to be explicit about how the tasks involved might 
fail. for instance  one must state explicitly that: 
a task to do  prog  a1 a1   is accomplished by a task to do al followed by a task to do a1  and it can f a i l only if the current task f a i l s . 
　　　separating tasks out from the actions they call for has the advantage that one can talk about jailing to accomplish something as well as accomplishing it. 
　　　another important axiom that must be added to the system is that if an action is feasible  and is a way of carrying out another action  then the second action is feasible: 

1 	d. mcdermott 

1. an example 
　　　in this section  i will sketch briefly an example showing the utility of these ideas. this is a chess problem i heard from john mccarthy. 
　　　i will call this state of affairs so  although you must remember that this constant refers to an arbitrary snapshot of a board position that actually lasts until white makes a move; an uncountable set of other states go by during this time  during which the chess position doesn't change  although other things in the world will . 
　　　white can win  by the following argument: k can get to a1  because if k leaves the rectangle with corners c1 and g1  an area 1 will call the  cage    then the pawn at e1 will 

queen. but then k can get to b1  because if k is anywhere but c1  white can move to b1 in one step  and if k is at c1  white can move to a1  then b1 by similar arguments  k can get to c1  and then to either d1 or d1; and then the pawn at e1 can queen. 
       i will discuss an approach to part of mccarthy's problem within the framework i have outlined. the part i will be concerned with is step one  showing that the white king can get to a1.  the remaining steps are more straightforward.  the interesting thing about this step is that the reasoning is  continuous : it talks about the white king moving toward a1 while the black king moves around in the  cage   completely neglecting the fact that these moves occur as interleaved jumps. 
　　　the following plan can be shown to be feasible and allow the robot  playing white  to get his king to a1  or queen the pawn at e1: 
 interrupt  move k a1  
 outside k cage  
 move p/e1 e1   
where the action  interrupt al p a1  is defined thus: definition 1:  interrupt al p as  is executed whenever one of the following happens: 
1. al is executed without p becoming true. 
1. p becomes true before al has been executed  and a1 is then executed 
　　　this is the sort of thing that the original task networks  see figure 1  cannot express  but that human problem solvers execute as plans all the time. 
　　　fortunately  we can analyze the  interrupt  plan as giving rise to subtasks. however  the subtasks are not always the same  or always foreseeable. if p never becomes true  then there will be just one subtask; if it does become true  there will be two. 
　　　the proof that  interrupt al p as  is feasible depends on the following lemma: 
l e m m a 1: in a state so  if al is feasible with respect to boundary tasks kk so long as p 
remains false  and if as is feasible in the first state in which p becomes true after so  if any   then  interrupt al p as  is feasible with respect to kk in so. 
　　　this statement can be proved using definition 1  but that is not sufficient. that definition adequately defined what it means to actually execute  interrupt ...   but did not specify what it meant to have an intention to execute it. since actions can be executed accidentally  the two are quite different. so we must provide an axiom like this: a x i o m 1: if  over an interval  a problem solver has a task k to perform  interrupt al p as   then either 
1. there is just one subtask kl to perform 
 until p al   and p stays false; or 
1. there are two subtasks  kl as described  which succeeds when p becomes true  and k1  a task that begins as soon as p becomes true. 
furthermore  at any moment while k is a task  it fails only if the current subtask fails. 


　　　in this axiom  i have had to introduce an intermediate task to perform the action  until p al . the reason is that the subtask k1  with action al  must evaporate if p becomes true  and therefore its su pert ask must end. since the interrupt task itself can't end  we insert the until task  which succeeds if p becomes true: 
definition 1:  until p a  is executed over any interval in which a is executed without p becoming true  before the last instant   or over any interval in which p becomes true without a being executed. 
　　　the until-task has its own subtask structure  see figure 1 : 
a x i o m 1: any task with action  until p a  has one subtask with action a. the su pert ask fails only if a fails before p becomes true. 
now we can prove the following theorem: 
t h e o r e m 1:  interrupt al p a1  is feasible whenever al is feasible provided p stays false  and a1 is feasible in the first state after p becomes true. 
　　　proof: assume that an isolated reltry of  interrupt al p a1  occurs. if p does not become true  then there is exactly one subtask kl with action  until p al   such that k fails only if kl fails. but  by axiom 1  there will be a unique subtask k1 with action al. because al is feasible  a1 will succeed  and hence  definition 1   kl will succeed  and hence k will succeed. the proof for the case where p does become true is similar. qed 
　　　several further steps are necessary to actually apply this theorem to the chess problem. recall that white's plan is 

the basic strategy is of course to show that if k never leaves the  cage   then  move k a1  is feasible  and that if it does  then  move p/e1 e1  is feasible. while these are in some sense obvious  there are some pitfalls in the formal proof. for instance  how can we be sure that the blocked pawns never move  or that white  that is  the robot itself  doesn't move his pawn at e1 prematurely  these are  chess lemmas  which it is not necessary to prove  or not our job  anyway   but some care is necessary in stating them. the second issue especially raises interesting issues about predicting one's own subtasks. in section   we had to restrict the  test task  for feasibility to be isolated; that is  no extraneous test tasks were allowed at the same time. we cannot rule out the robot's own genuine tasks so peremptorily; to prove feasibility  we must prove that no conflicting subtask will arrive. this is one reason proving feasibility is so difficult. 
d. mcdermott 1 
1 . c o n c l u s i o n s 
　　　this paper has sketched an approach to reasoning about intentions within the framework of the temporal logic developed in  mcdermott 1 . for a fuller treatment  see  mcdermott 1  
　　　sections and showed the power of this calculus to illuminate interrelationships among tasks  feasibility  and possibility. in addition  they showed its flexibility in allowing us to talk easily of actions beyond the reach of previous problem solvers. 

　　　this picture is not very different from the previous one. one difference is that the new picture has no successor links  replacing them with labels on the syntactic subtask relationships. the successor-link notation always 
tantalized us with its non-generalizable transparency. the new notation is much more generalizable; any action  like prog  that can be defined in terms of subactions  can be used in such a net. for instance  an  interrupt  might have subtasks labeled   m a i n   and   o o p s   . we call an action that is reduced syntactically a macro-action. a macro action with labeled subtasks replaces the successor link. 
　　　a second difference is that even the syntactic subtasks are not all foreseeable. this uncertainty is especially characteristic of macro-actions involving loops   repeat a until t  may have zero or more subtasks with action a  with path expressions   1       1     ... . the number of subtasks is indefinite  but a problem solver can estimate how many there are going to be  and apply noah-style methods to their analysis. the new wrinkle is that the estimates can turn out to be wrong  an inconceivable possibility for noah. it is as yet unknown how to revise them; the method of  doyle 1  may be useful. 
1 d. mcdermott 
　　　finally  a problem solver will want to keep track of different estimates  corresponding to different sets of interesting chronicles. for example  a task to do  interrupt at p a1  may have one or two subtasks  depending on whether p becomes true or not. if the system doesn't know whether p will happen or not  it may want to construct two different task networks  one for each eventuality. this operation may be desirable for almost any macro-action. 
　　　acknowledgments: the ideas in this paper were developed in conversations with robert moore  stan rosenschein  frnie davis  john mccarthy  stan letovsky  and several others. 
