
in this paper we present a system which learns to recognize objects through interaction by exploiting the principle of sensorimotor coordination. the system uses a learning architecture which is composed of reactive and deliberative layers. the reactive layer consists of a database of behaviors that are modulated to producea desired behavior. in this work we have implemented and installed in our architecture an object manipulation behavior inspired by the concept that infants learn about their environment through manipulation. while manipulating objects  both proprioceptive data and exteroceptive data are recorded. both of these types of data are combined and statistically analyzed in order to extract important parameters that distinctively describe the object being manipulated. this data is then clustered using the standard k-means algorithm and the resulting clusters are labeled. the labeling is used to train a radial basis function network for classifying the clusters. the performance of the system has been tested on a kinematically complex walking robot capable of manipulating objects with two legs used as arms  and it has been found that the trained neural network is able to classify objects even when only partial sensory data is available to the system. our preliminary results demonstrate that this method can be effectively used in a robotic system which learns from experience about its environment.
1 introduction
recently  the psychologicalpoint of view that grants the body a more significant role in cognition has also gained attention in spatial cognition theory. proponents of this approach claim that we have to deal with and understand a body that needs a mind to make it function instead of a mind that works on abstract problems  wilson  1 . these ideas differ quite radically from the traditional approach that describes a cognitive process as an abstract information processing task in which the real physical connections to the outside world are of only sub-critical importance  and are sometimes discarded as mere informational encapsulated plug-ins  fodor  1 . most theories in cognitive psychology take this traditional approach and have tried to describe the process of human thinking in terms of propositional knowledge. at the same time  artificial intelligence research has been dominated by methods of abstract symbolic processing  even when researchers have used robotic systems to implement them  nilsson  1 . ignoring sensorimotor influences on cognitive ability is in sharp contrast to the research of william james  james  1  and others  see  prinz  1  for a review  that describe theories of cognition based on motor acts  or a theory of cognitive function emerging from seminal research on sensorimotor abilities by jean piaget  wilson  1  and the theory of affordances by  gibson  1 . in the 1s the linguist lakoff and the philosopher johnson  lakoff and johnson  1  put forward the idea of abstract concepts based on metaphors for bodily  physical concepts; around the same time  brooks  brooks  1  made a major impact on artificial intelligence research by his concepts of behaviorbased robotics  and interaction with the environment without internal representation. this concept provides an alternative to the traditional sensereason-act cycle  and has gained wide attention ever since. as promising as these ideas seem to be at first glance  one has to carefully evaluate what exact claims can be made and how these can be evaluated. wilson identifies six viewpoints for the new so-called embodied cognition approach  wilson  1 :
1. cognition is situated: all cognitive activity takes part inthe context of a real world environment.
1. cognition is time pressured: how does cognition workunder the pressures of real time interaction with the environment
1. off-loading of cognitive work to the environment: limits of our information processing capabilities demand for off-loading.
1. the environmentis part of the cognitivesystem: becauseof dense and continuous information flow between the mind and the environment it is not meaningful to study just the mind.
1. cognition is for action: cognitive mechanisms  perception/memory  etc.  must be understood in their ultimate contribution to situation appropriate behavior.
1. off-line cognition is body-based: even when uncoupled from the environment  the activity of the mind is grounded in mechanisms that evolved for interaction with the environment.
　we have cited all six viewpoints here  as they represent an interesting perspective on the state of the art in embodied cognition. in this work we focus our attention on viewpoints 1 and 1  and we use them as a theoretical starting point for our work. to experiment with embodied cognition  we propose the use of a multifunctional four legged robot kinematically capable of walking and climbing on four legs as well as of grasping and manipulating objects with two legs used as arms. the role of manipulation acts in understanding spatial geometries and objects goes back to the idea that cognitive systems offload as much of the computational burden as possible onto the environment to understand spatial structures. instead of generating and transforming complex mathematical models of 1-d geometries  cognitive systems use motor acts to generate multi-modal perceptual inputs  which they use to test hypotheses about the nature of the geometric structure at hand.
　a prerequisite for developing higher levels of cognition is the process of sensorimotor coordination  in which the body of the system plays a central role in learning to recognize objects  nolfi and parisi  1; pfeifer and scheier  1 . many researchers  edelman  1; beer  1; nolfi  1; taka＞c  1  have shown that sensorimotor coordination can be exploited in solving categorization problems.
　one shortcoming of most existing methods is that they are able to recognize only a limited number of objects. additionally  most existing methods are difficult to extend. a typical application of such methods is to recognize hypothetical objects  and they are tested only in simulation or on simple robotic platforms. their ability to scale when used on complex robots is neither known nor proven. from our viewpoint  the reasons for the shortcomings of the existing methods are twofold: first  there is no presently firm theoretical framework for studying correlations within and between sensorimotor modalities for object recognition tasks. very few approaches apply statistical and information theoretic analyses to study the sensorimotor coordinationof data taken from real robots  lungarella et al.  1 . second  kinematically complex robots capable of increasing the role of the body in the process of learning and recognition are not commonly used. most of the time wheeled robots with few degrees of freedom or simulated robotic arms are used as test beds.
　after the introduction of brooks' behavior based robotics and interaction with environment  brooks  1   there appears to be a growing sense of commitment to the idea that cognitive ability in a system  be it natural or artificial  has to be studied in the context of its relation to a 'kinematically competent' physical body. therefore  in the last years we focused our research on complex legged robots which possess a rich repertoire of sensor and motor abilities  hilljegerdes et al.  1 .
　in this paper we present an extensible embodied object recognition system that can be used in complex real robots that learn through interaction with the environment. the system can be easily extended to use new object-features which distinctively describe the relevant characteristics of an object to be recognized.
　a work that is closely related to ours involves substrate classification on the basis of proprioceptive data  spenneberg and kirchner  1 . in this work  a legged robot named scorpion  kirchner et al.  1  interacts with various substrates to generate certain substrate specific sensory feedback. the results of this experiment show that this method of classifying based on proprioceptive data has a promising potential for use in terrain classification of unstructured environments. one of the important benefits of terrain classification is that it allows a terrain's traversability to be assessed given a specific robot body.
　this paper is organized as follows: first  we give a short overview of the learning architecture which we have used to implement object recognition through manipulation. we then explain the manipulation behavior and the recognition method used. next  we describe our experimental scenario and the results obtained. finally  we provide some conclusions and a future outlook.
1 learning architecture
the architecture we have adopted  shown in figure 1  is a hybrid architecture which integrates a reactive system with a higher-level deliberative system. it is suitable for controlling and integrating spatial learning and representation techniques in mobile robots  allowing them to explore and navigate in unknown environments.
1 reactive system
the reactive system includes the input  transfer  activation  and motor modules of figure 1. proprioceptive and exteroceptive data produced through interaction with the environment are processed in the input stage. this stage consists of three subsystems  see figure 1  which work together in order to learn  distinguish and identify the perceptual states the system is in. in the manipulation based object recognition experiment  an unsupervised classifier system is implemented that considers both proprioceptive and exteroceptive data  represented by the vectors  respectively. this classifier identifies and labels clusters of similar sensorimotor stimuli together. additionally  it generates a cluster probability. each element of this vector represents a probability estimate of the likelihood that a set of sensorimotor inputs belongs to a labeled cluster. the cluster probabilityis then used to train the two remaining classifiers which classify based only on the exteroceptive sensory data vector or on the proprioceptive data vector
. these classifiers also generate	estimates and
pc prop  which are are combined with pc sm to generate an overall cluster probability.

figure 1: overall learning architecture　this overall cluster probability is mapped in the transfer module to a set of motor-program activation levels. the activation levels serve to pre-activate a selected group of motor-programs. pre-activation consists of setting all the parameters  i.e. phase-shift  amplitude  frequency  etc.  of a motor-program  as well as a weight value which is used in a further stage to merge multiple motor-programs into a resulting behavior  kirchner et al.  1 . during the learning phase of the experiment presented here  a manipulation motor-program is made active.
　the activation stage generates a set of joint angles for each motor-program. at this point  it is possible for the output of the motor-programs to be modulated by other systems. an automatic reactive control system receives proprioceptive sensory feedback and modulates the motor-programoutput in order to realize local-reflex behaviors. additionally  a higherlevel deliberative system is able to influence a resulting action by modulating the motor-program output. finally  the output from the activation stage is fed into the motor stage  which implements a believed behavior  attempting to directly control the robot's actuators. we have used the term believed behavior to indicate that there is uncertainty as to whether an intended behavior has indeed been carried out. likelihood estimation of a successful behavior execution is made possible by comparing real perceptions with expected perceptions which come from hypotheses about how the robot's perceptions should change when a set of motor-programs has successfully been executed.
1 deliberative system
the deliberative system is responsible for high-level processing of cluster probabilities  and it is in this system that the world model and body model are generated through learning. positive and negative rewards combined with believed behavior information are used to learn the world model and body model of the robot itself. the deliberative system is also responsible for optimizing the existing motor-programs or adding new motor-programs whose resulting behavior cannot be obtained by combining the existing motor programs. additionally  the deliberative system pre-modulates the output of the transfer module to affect which motorprograms will be active  and post-modulates the output of the activation module  modifying the properties of the motor-programs that are currently active.
1 the recognition system

figure 1: sensory perception processorthe embodied recognition system functions by manipulating objects in order to determine their specific characteristics. a manipulation motor-program has been implemented  added to the activation module  and made active for the experiment. this motor-program uses a potential field method  khatib  1  to generate a trajectory for an end-effector to reach an object. the basic idea is to create a mathematical description of a virtual potential field acting within the workspace of the manipulator. regions in the workspace that are to be avoided are modelled by repulsive potentials  energy peaks  and the target region/point is modelled by an attractive potential  energy valley . the sum of repulsive and attractive potentials provides a representation of the workspace topology. by following the gradient  i.e. the minimum potential field at each step   a path towards the goal is generated. one fundamental difference between this method and classical path planning is that here  planning  is not done in the usual sense. rather  a path is incrementally computed that will end at the target position. this approach can be viewed as a reactive approach since there is no deliberation involved and it can be implementedon lower layers of control. furthermore  this reactiveness allows us to deal with obstacles on a real-time basis  the only limitation being the time needed to detect and identify objects as obstacles or goals.
　while manipulating objects  both proprioceptive data  pressure at fingertips  motor current consumption  motor angular position  and exteroceptive data  color of the object  number of corners detected on the object  number of line segments detected  and other distinctive features  are recorded.
both of these types of data are combined to form a vector
. the resulting vector is statistically analyzed in order to extract important parameters that distinctively describe the object being manipulated. for example  the average power consumption of the motors during the manipulation phase will differ depending on an object's weight. this data is then clustered using the standard k-means algorithm  macqueen  1  and the resulting clusters are labeled.
　prior to clustering  each element of a data vector is normalized using
		 1 
where i = 1 ，，， l and l is the length of a data vector x . the mean xi and variance σi1 are calculated with respect to the training data using
	 .	 1 
where n is the numberof data vectorsin the training set. this normalization process is necessary since the elements of a data vector typically have magnitudes that differ significantly.
　the labeled clusters are then used to train a radial basis function network  bishop  1   a subsystem of the input module  for classifying the clusters based on proprioceptive and exteroceptive data. rather than choosing a subset of data points of the clusters as the centers of basis functions  we use the k-means clustering algorithm  in which the number of centers must be decided in advance  to determine for each cluster a set of centers which more accurately reflects the distribution of the cluster's data points. the appropriate number of center points is determined by the performance of the resulting network on a validation set. in the implemented neural network  we used a gaussian function as a basis function. figure 1 shows the topology of the radial basis function network used for data classification.

figure 1: radial basis function network
1 experimental setup
the robot used for testing our system was developed in our group  and is based on the design of the aramies robot  hilljegerdes et al.  1 . our robot is a fully functional ambulating robot that is robust and kinematically flexible. it is equipped with various sensors that enable it to perceive both proprioceptive and exteroceptive signals. on each of the robot's legs  there are 1 d.c. motors  1 pressure sensors  and an infrared sensor. for our experiment  the camera of the robot was used as a source of exteroceptive data  and the average motor current consumption of each motor was used as a source of proprioceptive data.

figure 1: the robot manipulating an object
　in the experiment we performed  the robot's body is fixed and it uses its forelegs to manipulate the different objects shown in figure 1. the objects have differing weights and visual features. two of the objects have the same visual features  and cannot be distinguished from each other using only visual information; these objects are marked as  a  and  b  in figure 1. the faces on which the letters are written are placed away from the camera of the robot so that the two objects appear indistinguishable to the robot.

figure 1: objects used in the sensorimotor-coordination experiment
　in the training session  five manipulation acts were performed on each of the objects. for a single manipulation act  we took a series of images from which we calculated the average number of contours extracted and the average area of the extracted contours. furthermore  we calculated the total current consumption average for the motors on both of the robot's forelegs.
1 results
1 repeatability of features
table 1 shows  for each of the object  the average and standard deviation of the number of detected contours nc  the area  number of pixels  of the detected contours ac  and the total current consumption i  in ma  of both of the robot's forelegs over all training sessions. this data is an indirect


table 1: the average and standard deviation of features over the whole training set
measure of the repeatability of a particular feature's measurements. a measurement for a feature is repeatable if the variance of the measurement over a given sample of measurements is small enough that the overlap of measurements resulting from different objects is minimal. one can easily see that the number of contours detected is the most stable feature in this experiment. for getting the number of contours  we used a detector which is robust against noise and changes in lighting conditions. the average current consumption of both legs shows the highest variance in relation to the other features since the end effectors of the forelegs do not grab the object at the same point for each training session. this causes the object's center of gravity to shift with respect to the end effector  and thus a variation in the average current consumption is observed.
1 recognition rates
we tested the system's ability to recognize the objects it was trained for. the system was tested in three different scenarios. in the first scenario  the system was permitted to use both exteroceptiveand proprioceptivedata to recognize objects. in this case  the recognition rate was the highest  yielding only one misclassification in 1 trials. in the case where the system was allowed to use only exteroceptive data  there were 1 misclassifications in 1 trials. this poorer performance is explained by the fact that two of the objects have the same visual features. in contrast to these results  when only proprioceptive data was used  there were only 1 misclassifications in 1 trials because the weights of each object were unique. an interesting point is that the system was able to correctly classify objects  a  and  b  in this case  which would have caused problems when using only exteroceptive data.
1 conclusion and outlook
an embodied recognition system has been presented which learns to recognize objects by interacting with them. we have shown that a learning system trained based on multimodal sensory information can recognize objects by using only partially available  i.e. only exteroceptive  or only proprioceptive  sensory data. the direct byproduct of such systems is a robust system which continues to operate in the absence of either the proprioceptive or the exteroceptive data. our preliminary results demonstrate that this method can be effectively used in a robotic system which learns from experience about its environment.
　in the future  we plan to extend the system by increasing the number of proprioceptive and exteroceptive objectfeatures extracted from the environment  and improving their stability. for example  we may use local features such as sift  scale invariant feature transform  features  love  1  that describe objects distinctively and which are stable against translation  rotation  scaling and different lighting conditions. moreover  we want to extend the activation module of figure 1 using adaptive manipulation techniques that result in better manipulation skills  kamon et al.  1; coelho et al.  1; morales et al.  1 .
