
stochastic complexity of a data set is defined as the shortest possible code length for the data obtainable by using some fixed set of models. this measure is of great theoretical and practical importance as a tool for tasks such as model selection or data clustering. in the case of multinomial data  computing the modern version of stochastic complexity  defined as the normalized maximum likelihood  nml  criterion  requires computing a sum with an exponential number of terms. furthermore  in order to apply nml in practice  one often needs to compute a whole table of these exponential sums. in our previous work  we were able to compute this table by a recursive algorithm. the purpose of this paper is to significantly improve the time complexity of this algorithm. the techniques used here are based on the discrete fourier transform and the convolution theorem.
1 introduction
the minimum description length  mdl  principle developed by rissanen  rissanen  1; 1; 1  offers a wellfounded theoretical formalization of statistical modeling. the main idea of this principle is to represent a set of models  model class  by a single model imitating the behaviour of any model in the class. such representative models are called universal. the universal model itself does not have to belong to the model class as often is the case.
¡¡from a computer science viewpoint  the fundamental idea of the mdl principle is compression of data. that is  given some sample data  the task is to find a description or code of the data such that this description uses less symbols than it takes to describe the data literally. intuitively speaking  this approach can in principle be argued to produce the best possible model of the problem domain  since in order to be able to produce the most efficient coding of data  one must capture all the regularities present in the domain.
¡¡the mdl principle has gone through several evolutionary steps during the last two decades. for example  the early realization of the mdl principle  the two-part code mdl  rissanen  1   takes the same form as the bayesian bic criterion  schwarz  1   which has led some people to incorrectly believe that mdl and bic are equivalent. the latest instantiation of the mdl is not directly related to bic  but to the formalization described in  rissanen  1 . unlike bayesian and many other approaches  the modern mdl principle does not assume that the chosen model class is correct. it even says that there is no such thing as a true model or model class  as acknowledged by many practitioners. the model class is only used as a technical device for constructing an efficient code. for discussions on the theoretical motivations behind the modern definition of the mdl see  e.g.   rissanen  1; merhav and feder  1; barron et al.  1; grunwald  1; rissanen  1; xie and barron  1;¡§ rissanen  1 .
¡¡the most important notion of the mdl principle is the stochastic complexity  sc   which is defined as the shortest description length of a given data relative to a model class m. the modern definition of sc is based on the normalized maximum likelihood  nml  code  shtarkov  1 . unfortunately  with multinomial data this code involves a sum over all the possible data matrices of certain length. computing this sum  usually called the regret  is obviously exponential. therefore  practical applications of the nml have been quite
rare 
¡¡in our previous work  kontkanen et al.  1; 1   we presented a polynomial time  quadratic  method to compute the regret. in this paper we improve our previous results and show how mathematical techniques such as discrete fourier transform and convolution can be used in regret computation. the idea of applying these techniques for computing a single regret term was first suggested in  koivisto  1   but as discussed in  kontkanen et al.  1   in order to apply nml to practical tasks such as clustering  a whole table of regret terms is needed. we will present here an efficient algorithm for this specific task. for a more detailed discussion of this work  see  kontkanen and myllymaki  1¡§  .
1 nml for multinomial data
the most important notion of the mdl is the stochastic complexity  sc . intuitively  stochastic complexity is defined as the shortest description length of a given data relative to a model class. to formalize things  let us start with a definition of a model class. consider a set ¦¨ ¡Ê rd  where d is a positive integer. a class of parametric distributions indexed by the elements of ¦¨ is called a model class. that is  a model class m is defined as
m = {p ¡¤ | ¦È  : ¦È ¡Ê ¦¨}.	 1 
¡¡consider now a discrete data set  or matrix  xn =  x1 ... xn  of n outcomes  where each outcome xj is an element of the set x consisting of all the vectors of the form  a1 ... am   where each variable  or attribute  ai takes on values v ¡Ê {1 ... ni}. given a model class m  the normalized maximum likelihood  nml  distribution  shtarkov  1  is defined as
n p xn | ¦È  xn  m 
	pnml x | m  =	rnm	 	 1 
where ¦È  xn  denotes the maximum likelihood estimate of data xn  and rnm is given by
	rnm = xp xn | ¦È  xn  m  	 1 
xn
and the sum goes over all the possible data matrices of size n. the term rnm is called the regret. the definition  1  is intuitively very appealing: every data matrix is modeled using its own maximum likelihood  i.e.  best fit  model  and then a penalty for the complexity of the model class m is added to normalize the distribution.
¡¡the stochastic complexity of a data set xn with respect to a
¡¡model class m can now be defined as the negative logarithm of  1   i.e. 
	n	p xn | ¦È  xn  m 
sc x | m  =  log	rnm	 1 
=  logp xn | ¦È  xn  m  + logrnm.  1 
¡¡as in  kontkanen et al.  1   in the sequel we focus on a multi-dimensional model class suitable for cluster analysis. the selected model class has also been successfully applied to mixture modeling  kontkanen et al.  1   case-based reasoning  kontkanen et al.  1   naive bayes classification  grunwald¡§ et al.  1; kontkanen et al.  1b  and data visualization  kontkanen et al.  1a .
¡¡let us assume that we have m variables   a1 ... am   and we also assume the existence of a special variable c  which can be chosen to be one of the variables in our data or it can be latent . furthermore  given the value of c  the variables  a1 ... am  are assumed to be independent. the resulting model class is denoted by mt. suppose the special variable c has k values and each ai has ni values. the nml distribution for the model class mt is now
	k	hk m	k	ni	fikv
pnml xn | mt  ==1¦Ìhk   y=1y=1y=1¦Ìfikv  	# y n	hk
	ki	k	v
1
	¡¤ rnmt k  	 1 
where hk is the number of times c has value k in xn  fikv is the number of times ai has value v when c = k  and rnmt k is the regret term. in  kontkanen et al.  1  it was proven that an efficient way to compute the regret term is via the following recursive formula:
	n	r	n   r	n r
rnmt k =1 ¡ä ¦Ì	  n!	r
	r! n   r !	n	n
r=1
¡¡r	n r ¡¤ rmt k1 ¡¤ rmt k1 	 1  where k1 + k1 = k.
¡¡as discussed in  kontkanen et al.  1   in order to apply nml to the clustering problem  we need to compute a whole table of regret terms. this table consists of the terms rnmt k for n = 1 ... n and k = 1 ... k  where k is the maximum number of clusters.
¡¡the procedure of computing the regret table starts by filling the first column  i.e.  the case k = 1  which is trivial  see  kontkanen et al.  1  . to compute the column k  for k = 1 ... k  the recursive formula  1  can be used by choosing k1 = k  1  k1 = 1. the time complexity of filling tkanen et al.  1; kontkanen and myllym  1¡é aki  1¡§  .
the whole table is o k ¡¤ n	. for more details  see  kon-
¡¡in practice  the quadratic dependency on the size of data limits the applicability of nml to small or moderate size data sets. in the next section  we will present a novel  significantly more efficient method for computing the regret table.
1 the fast nml algorithm
in this section we will derive a very efficient algorithm for the regret table computation. the new method is based on the fast fourier transform algorithm. as mentioned in the previous section  the calculation of the first column of the regret table is trivial. therefore  we only need to consider the case of calculating the column k given the first k 1 columns. let us define two sequences a and b by
	nn	n	nn	n
an = rmt k 1  bn = rmt 1   1  n!	n!
for n = 1 ... n. evaluating the convolution of a and b
gives
a   b n = x=1n	h rmt k 1 n n  h hn ! h rmn th 1    1  h	h
  h! h
¡¡nn n n! h h n   h n h = x=1   ¦Ì   ¦Ì   n! h! n   h ! n n h
¡¡¡¤ rhmt k 1rmn th 1  1  nn n
= rmt k 	 1  n!
where the last equality follows from the recursion for-
mula  1 . this derivation shows that the column k can be computed by first evaluating the convolution  1   and then multiplying each term by n!/nn.
¡¡the standard convolution theorem states that convolutions can be evaluated via the  discrete  fourier transform  which in turn can be computed efficiently with the fast fourier transform algorithm  see  kontkanen and myllymaki  1¡§   for details . it follows that the time complexity of computing the whole regret table drops to o n logn ¡¤ k . this is a mamethod of section 1.   1 ¡é
jor improvement over o n ¡¤ k obtained by the recursion
1 conclusion and future work
the main result of this paper was a derivation of a novel algorithm for the regret table computation. the theoretical time complexity of this algorithm allows practical applications of nml in domains with very large datasets. with the earlier quadratic-time algorithms  this was not possible.
¡¡in the future  we plan to conduct an extensive set of empirical tests to see how well the theoretical advantage of the new algorithm transfers to practice. on the theoretical side  our goal is to extend the regret table computation to more complex cases like general graphical models. we will also research supervised versions of the stochastic complexity  designed for supervised prediction tasks such as classification.
acknowledgements
this work was supported in part by the academy of finland under the projects minos and civi and by the national technology agency under the pmma project. in addition  this work was supported in part by the ist programme of the european community  under the pascal network of excellence  ist-1. this publication only reflects the authors' views.
