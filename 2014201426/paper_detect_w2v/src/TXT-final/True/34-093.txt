 

　　　in order to cope with image signal variations in imaging devices  a direction coding method is proposed for stable scene analysis and object recognition. this 
method makes extensive use of macroscopic processing of direction-coded images to achieve noise-free analysis. examples showing recognition of obliquely-imaged box-like objects whose surfaces are rather complicated are included. additional efforts are made to recognize surface information of objects by spatially transforming the surface image as if it were viewed from a vertical direction. this method also involves positioninvariant and rotation-invariant image data transformation techniques  thus raising the possibility of more effective 
image analysis in actual application. 
1. introduction 

　　　scene analysis techniques in the artificial intelligence field intrinsically have the possibility of being applied to the automation of production lines and physical distribution systems. many studies have so far been devoted to thi s area  and have led to the development of prototype intelligent robot systems  1  1   1 . in the past  we at hitachi central research laboratory have also made efforts toward developing such robot systems  1   1  as well as toward realizing industrial eyes involving scene analysis capabilities  1   1 . a number of these have already found practical use in the automation of actual assembly and inspection processes which required unique application of visual technology. 
　　　from this experience  we have noted that the variation of image signals from imaging devices is usually the most significant problem to be overcome 
whenever we attempt to put scene analysis 
techniques into practical use. this variation is mainly caused by subtle changes in lighting conditions as well as by the intrinsic characteristics of the imaging device itself as affected by fluctuations in power source and temperature. this variation sometimes has ci highly significant influence upon the effectiveness of the scene analysis algorithms  by which objects in the image 
　　　this work is contracted with the agency of industrial science and technology  ministry of international 
trade and industry  as at part of the 
national research and development program  pattern information processing system . are ultimately recognized. 
　　　in this paper  to begin with an image processing method that can yield stable results all of the time by minimizing the effect of image variation is proposed. next  an attempt at object recognition by this method is described. the objects handled in this study are mainly parallelepipeds. however  unlike ordinary blocks with blank surfaces  boxes with rather complex pattern information on their surfaces were used. the method proposed here is concerned with how all geometric features  such as position and posture of the object  can be extracted by eliminating the surface information  and how this information on the objects surface can then be recognized. 
　　　this method attempted to make maximum use of macroscopic image processing  such as homogeneous processing  frequency distribution calculation  etc.  as opposed to microscopic processing such as edge following. since  it seems that 
macroscopic image processing is a prerequisite for high speed  stable recognition hardware to be developed in the future. 
1
　　　　　　 - direction coding method 1 basis of direction coding 
　　　it has been demonstrated that the image signal obtained from an imaging 
device is affected by a variety of factors. the form of the observable brightness signal g x y  is usually expressed as follows: 

where the parameters a and b denote the contrast and level change respectively. in other words  even if the same scene is observed  the same image value is not expected all the time. 
　　　another important characteristic of the image signal is that the value at each picture element in an image does not possess any specific meaning in the geometric sense. obviously  only the relation of the image values of a picture element and its neighbors can give geometric meaning. this implies that to extract geometric features from an image it is necessary to provide a means to execute comparison with surrounding picture elements. 
1 　　　the two above facts are drawbacks associated with usual image processing when a brightness image itself is used as an input image. they sometimes make the image processing very complicated. 
consequently  the input brightness image is f i r s t transformed into what we call a  direction-coded image  on which almost a l l subsequent processing is based. in t h i s image each picture element has a geometric meaning. 
　　　similar to the methods that are dealt with in previous papers  1  1   a 
　　　direction-coded image is one whose value at each picture element corresponds to the tangential direction of brightness change in the o r i g i n a l image. that i s   the direction-coded image a x y  is obtained by performing the following transformation on the o r i g i n a l brightness image g x y  : identical image a x y . 
1 	transforming into a direction-coded 

　　　in order to transform the brightness image g x y  into a direction-coded image by d i g i t a l computer  the following calculation is adopted for the d i g i t a l image. here  the d i f f e r e n t i a l values in eq.  1  are replaced by the differences using adjacent 1 picture elements as shown in fig. 1 a : 


in our computer simulation  a d i g i t a l image of 1 picture elements  each of which was of 1-bit brightness  1 levels    was used to y i e l d a direction-coded image whose picture elements consisted of 1-bit direction values 1 directions  as shown in fig. 1 b . in t h i s image  the numbers 1 through 1 are assigned for the 1 d i r e c t i o n s   and the number 1 is assigned for 
　　　if the threshold value  is too small  the direction-coded image a x y  is not unique as it is affected by the noise involved in the image. if  is too large  even the necessary information w i l l be eliminated. therefore  an adequate threshold value should be carefully chosen or automatically controlled by the image itself. in fig.1 the total number of picture elements whose values are not is plotted for an actual laboratory scene by changing the threshold value  as a parameter. a steep increase is seen in the curve where  is less than 1 . this is mainly due to the noise existing in the brightness image. from this figure  it can be said that the optimum threshold value i s   in general  somewhere between 1 and 1  although it of course depends on the imaged objects and the characteristics of the imaging device used. 
　　　special-purpose hardware for transforming a brightness image into a 
　　　direction-coded image can be constructed as shown in fig. 1. in t h i s construction  the threshold value is determined by the image value in the previous scanning frame of the tv camera by using a modified version of eq.  1 . this threshold value holds for the present frame period. thus  the direction-coded image can be obtained in a real time mode by synchronizing i t 
with o r i g i n a l input brightness image from a tv camera. 
1 

1. recognition algorithm of a parallelepiped 
1 principles of recognition 
     among actual three-dimensional objects  there are quite a number of boxlike objects  since factories make extensive use of boxes in packing finished products for shipment- therefore  from the viewpoint of the actual application of scene analysis techniques  especially to physical distribution systems  it is extremely important to refine the recognition algorithm of parallelepipeds. for simplicity  the recognition algorithm of a box-like object viewed from the top is first described. in the direction-coded image  each picture element represents the tangential direction of brightness change. therefore  quite a few picture elements with almost the same direction code are arranged on the linear edge line of an object  as long as a 
     brightness difference exists on the edge line- figure 1 a  shows a simple example of a rectangular shape  which corresponds to the top view of a box-like object. in this case  the frequency distribution of each direction code gives four peaks for 
used to f i l t e r out a l l other picture elements  thus enabling the edge lines to become more pronounced. after this f i l t e r i n g operation  the determination of the edge lines becomes much easier  and the ordinary method of l i n e determination can be easily applied. examples of these processes are shown in fig. 1. 
1 recognition of obliquely imaged parallelepipeds 
     when a parallelepiped placed on a table is viewed from above a t o b l i q u e angle  the p e r i o d i c i t y of the angle differences among the edge lines in the image disappears. however  by extending the above-mentioned algorithm under the following three premises  the recognition of a parallelepiped becomes possible: 
 1  the imaging device is placed far from the object compared to the size of the object so that the d i s t o r t i o n of the image caused by projection becomes negligible. 
 1  the object is placed on a horizontal plane. 
 1  the angle j between the v e r t i c a l line and the optical axis of the imaging device must be known. 

everyangle difference  as shown in fig. . therefore  when the four 
values at 	are added  the distribution curve gives a higher peak a t a s shown i n fig. 1 c . this 
ang rresponds to the principal 
direction of the rectangle  namely the posture of the box-like object-
　　　even when some other figures like triangles or circles also exist in the same image as a background  the position of the highest peak in the frequency distribution curve in fig. 1 c  is not usually affected  as the directions of the edge lines o f these figures do not possess a pitch of . the situation is quite the same when there are some characters or markings on the rectangular surface. therefore  it is possible to accurately detect the orientation of the rectangle from the peak point in the frequency distribution curve of the direction-coded image. 
　　　the next step is to eliminate a l l direction codes except the neighbors of 
thus  the edge 
lines of the rectangle are enhanced because a l l other background noise and figures are considerably reduced. this processing may be called  direction code filtering . further processing is done as shown in fig. 1 d . that is  the picture elements with direction codes of are projected on the line l whose angle is and are counted to yield a frequency curve q. then  the peaks in the frequency distribution are detected  and the stripe regions are generated so that each region contains an edge line. the regions for the remaining lirection codes are are also detected in 
the same manner. these regions are then 
1 

1 spatial transformation 

　　　to read and recognize surface information on an obliquely imaged parallelepiped  the image should f i r s t be converted to the normalized image having no relation to the position and orientation of the object. this can be effected by adequate expansion  contraction  s h i f t and rotation. 
　　　as shown in fig. 1   the lozengeshaped image portion corresponding to the upper surface of the object is transformed into a square image so that the edge points a  b  c and d correspond to the edge points a1  b'  c and d' respectively this is done by linear coordinate transformation by neglecting the projection d i s t o r t i o n of the imaging system. that i s   there exists the following relationship between the pre-transformed coordinates  x y  and the post-transformed coordinates  x y  ; 

where ax   ay  ...  dx $ dy denote the x and y coordinates of the edge points a  b  c  and d in the oblique image  and w corresponds to the length of the edge l i n e of the square in the transformed image. from t h i s equation  a picture point  x y  in the new image is obtained from the o r i g i n a l image by averaging the picture element data at  x y  or i t s v i c i n i t y   or by other interpolating methods. figure 1 shows an example of this spatial transformation  in which the image is transformed as if it were viewed from the top of the object. in this normalized square image  the number of picture elements is standardized at 1. as t h i s image is normalized according to i t s position and the size of i t s surface  a pattern matching method with standard patterns is applicable. this w i l l be further covered in the next section. 
　　　in the above example  a method of transforming an o r i g i n a l brightness image into a normalized brightness image of the surface is described. however  it is also easy to convert d i r e c t l y from the direction~coded oblique image into the direction-coded normalized square image of the surface. that i s   the direction code at  x y  is computed as follows: f i r s t   the coordinate  x y  is computed from eq. 1    and the direction code  at  x y  is determined from the direction-coded o r i g i n a l image by a suitable averaging or interpolating method. then  the d i r e c t i o n code  is converted into  using eq* 1  . 
finally  the principal d i r e c t i o n   see fig. 1 a  } is subtracted. 
1 	information compression and 

　　　the two-dimensional normalized image of the surface discussed in the above section i s s t i l l too redundant to directly perform pattern matching with standard patterns. also  in t h i s case  the large volume of image data would necessitate an enormous memory capacity f o r standard patterns. therefore  the following data compression is performed: 
 1  from the direction-coded  normalized square image of the surface  picture elements with a certain direction code are extracted and projected on the line l perpendicular to the d i r e c t i o n code to y i e l d the frequency d i s t r i b u t i o n curve q as shown in fig. 1 a  . 
 1  this frequency d i s t r i b u t i o n curve is transformed i n t o the fourier series and the magnitudes of the lower four harmonics  from 1st through 1th  are computed. 
 1  the above two processes are performed for a l l of the d i r e c t i o n codes  thus giving a data table with 1 directions times 1 harmonics as shown in fig. 1 b  . 
 1  the data table thus obtained shows how the four magnitudes of the lower harmonics change with the d i r e c t i o n change. therefore  by regarding the four rows of the table as four waveforms  these can be transformed into the fourier series. 
 1  the lower eight harmonics  from 1st through 1th  are chosen to compute each magnitude  thus giving a f i n a l table with 1 magnitude data as shown in fig. 1 c  . 
　　　by the above data compression  a normalized image is expressed as information with 1  =1  words. in other words  an image of the surface corresponds to a point in a 1-dimensional space. therefore  the distances in the 1dimensional space between the unknown image pattern and the pre-determined standard patterns are computed. the pattern with the minimum distance is determined as the best match. 
　　　the algorithm mentioned above has the following features; it is  1  invariant to the pattern rotation  and  1  invariant to the pattern shift. these features arise from the following facts: 
 1  the frequency d i s t r i b u t i o n of each d i r e c t i o n code is transformed i n t o the fourier series. 
 1  the magnitude change of each harmonic in r e l a t i o n to the d i r e c t i o n change is transformed into the fourier series. 
 1  only the magnitude data are used  and the phase data as well as d.c. 
component are neglected. 
therefore  even when the spatial transformation in fig. 1 gives an upsidedown image  the subsequent matching 

1 

process gives the correct answer. 	for 
example  the symbols  and 
as well as a with any a r b i t r a r y angle will lead to the same result  this characteristic is extremely useful when the posture of a pattern can not be specified beforehand. table 1 shows an example of some experimental data which represent the r e l a t i v e distances in 1dimensional space between some simple example patterns. it can be seen from the table that the same patterns give smaller distances regardless of the pattern inclinations. 
1. conclusion 

　　　the algorithm discussed in t h i s paper is summarized as follows. f i r s t   the edge lines of a parallelepiped are extracted based on the direction-coded 
image. next  the position of the object is determined irrespective of the existence of a noisy background or the existence of surface information of considerable complexity. then  by using the edge point data of the detected object  the surface image is projected as a normalized square image as if it were being viewed from a direction perpendicular to the surface. finally  the double fourier transformation is performed on the direction-coded image of the normalized square image. one of the fourier transformations is in conjunction with the axial direction in order to find the distribution of the direction code  and the other is with radial direction to determine magnitude variation. as a result  an image is largely reduced as to i t s quantity of information and is transformed into 
position-invariant and rotation-invariant data for easier pattern matching. 
　　　the main characteristics of t h i s method arise from the fact that the direction-coded image is p r e f e r e n t i a l l y used. it is possible to regard t h i s direction-coded image as the image in which the microscopic features in the o r i g i n a l brightness image are distributed. for these microscopic features of the o r i g i n a l image  macroscopic treatment such as frequency d i s t r i b u t i o n calculation and fourier transformation is performed. 
therefore  t h i s method is hardly effected by background noise or local noise which sometimes exists in the image. such 
macroscopic processing of microscopic features is one of the most effective 
methods of actually applying image processing to i n d u s t r i a l use. furthermore  this method seems to hold promise of effective application in more complicated scene analysis and pattern recognition problems. 
