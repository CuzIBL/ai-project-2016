 
in order to generate high quality explanations in technical or mathematical domains  the presentation must be adapted to the knowledge of the intended audience. current proof presentation systems only communicate proofs on a fixed degree of abstraction independently of the addressee's knowledge. 
in this paper we propose an architecture for an interactive proof explanation system  called prex. based on the theory of human cognition 
act-r.  its dialog planner exploits a cognitive model  in which both the user's knowledge and his cognitive processes are modeled. by this means  his cognitive states are traced during the explanation. the explicit representation of the user's cognitive states in act-r allows the dialog planner to choose a degree of abstraction tailored to the user for each proof step to be explained. moreover  the system can revise its assumptions about the user's knowledge and react to his interact ions. 
1 	introduction 
a person who explains to another person a technical device or a logical line of reasoning adapts his explanations to the addressee's knowledge. a computer program designed to take over the explaining part  should also adopt this principle. 
　assorted systems take into account the intended audience's knowledge in the generation of explanations  see e.g.  cawsey  1; paris  1; wahlster et a/.  1  . most of them adapt to the addressee by choosing between different discourse strategies. since proofs are inherently rich in inferences  the explanation of proofs must also consider which inferences the audience can make  horacek  1; zukerman and mcconachy  1 . however  because of the constraints of the human memory  inferences are not chainable without costs. explicit representation of the addressee's cognitive states proves to be useful in choosing the information to convey  walker and rainbow  1 . 
　while a mathematician communicates a proof on a level of abstraction that is tailored to the audience  stateof-the-art proof presentation systems such as proverb 
1 	cognitive modeling 
 huang and fiedler  1  verbalize proofs in a nearly textbook-like style on a fixed degree of abstraction given by the initial representation of the proof. nevertheless  proverb is not restricted to presentation on a certain level of abstraction. adaptation to the reader's knowledge may still take place by providing the appropriate level of abstraction in the initial representation of the proof. 
　drawing on results from cognitive science  we are currently developing an interactive proof explanation system  called prex  for proof explainer . in this paper  which extends the work reported in  fiedler  1   we propose an architecture for its dialog planner based on the theory of human cognition act-r  anderson and lebiere  1 . the latter explicitly represents the addressee's knowledge in a declarative memory and his cognitive skills in procedural production rules. this cognitive model enables the dialog planner to trace the addressee's cognitive states during the explanation. hence  for each proof step  it can choose as an appropriate explanation its most abstract justification that is known by the addressee. moreover  the system can revise its assumptions about the users knowledge and react to his interactions. 
　the architecture of p.rex  which is sketched in section 1  is designed to allow for multimodal generation. the dialog planner is described in detail in section 1. 
since it is necessary to know some of the concepts in 
act-r to understand the macroplanning process  the cognitive architecture is first introduced in the next section. 
1 	act-r: a cognitive architecture 
in cognitive science several approaches are used to describe the functionality of the cognitive apparatus  e.g. production systems  mental models or distributed neural representations. production systems that model human 
cognition are called cognitive architectures. in this section we describe the cognitive architecture act-r  anderson and lebiere  1   which is well suited for user adaptive explanation generation because of its conflict resolution mechanism. further examples for cognitive architectures are soar  newell  1  and epic  meyer and kieras  1 . 
　act-r. has two types of knowledge bases  or memories  to store permanent knowledge in: declarative and 

procedural representations of knowledge are explicitly separated into the declarative memory and the procedural production rule base  but are intimately connected. 
　procedural knowledge is represented in production rules  or simply: productions  whose conditions and actions are defined in terms of declarative structures. a production can only apply if its conditions are satisfied by the knowledge currently available in the declarative memory. an item in the declarative memory is annotated with an activation that influences its retrieval. the application of a production modifies the declarative memory  or it results in an observable event. the set of applicable productions is called the conflict set. a con-
flict resolution heuristic derived from a rational analysis of human cognition determines which production in the conflict set will eventually be applied. 
　in order to allow for a goal-oriented behavior of the system  act-r manages goals in a goal stack. the current  goal is that on the top of the stack. only productions that  match the current  goal are applicable. 
1 declarative knowledge 
declarative knowledge is represented in terms of chunks in the declarative memory. below is an example for a chunk encoding the fact that f c g  where subset-fact is a concept and f and g are contextual 
chunks associated to f actfsubsetg. 
fact fsubaetg isa subset-fact 
setl f set1 g 
　chunks are annotated with continuous activations that influence their retrieval. the activation .ai  of a chunk ci  consists of its base-level activation b  and the weighted activations of contextual chunks. in bi-  which is defined such that it decreases logarithmically when ci is not used  act-r models the forgetting of declarative knowledge. note that the definition of the activation establishes a spreading activation to adjacent chunks  but. not further; multi-link-spread is not supported. 
　the constraint on the capacity of the human working memory is approached by defining a retrieval threshold r  where only those chunks ci  can be matched whose activation at is higher than t. chunks with an activation less than r are considered as forgotten. 
　new declarative knowledge is acquired when a new chunk is stored in the declarative memory  as is always the case when a goal is popped from the goal stack. the application of a production may also cause a new chunk to be stored if required by the production's action part. 
1 	procedural knowledge 
the operational knowledge of act-r is formalized in terms of productions. productions generally consist of a condition part and an action part  and can be applied if the condition part is fulfilled. in act-r both parts are defined in terms of chunk patterns. the condition is fulfilled if its first chunk pattern matches the current goal and the remaining chunk patterns match chunks in the declarative memory. an example for a product ion is 
if the current goal is to show that x ♀ s1 and it is known that x e si and s  c s1 
then conclude that x 1 #1 by the definition of c 
　similar to the base-level activation of chunks  the strength of a production is defined such that it decreases logarithmically when the production is not used. the time spent to match a production with a chunk depends on the activation of the chunk.1 it is defined such that it  is negative exponential to the sum of the activation of the chunk and the strength of the production. hence  the higher the activation of the chunk and the strength of the production  the faster the production matches the chunk. since the activation must  be greater than the retrieval threshold r  r constrains the time maximally available to match a production with a chunk. 
　the conflict resolution heuristic starts from assumptions on the probability p that the application of the current production leads to the goal and on the costs c of achieving that goal by this means. moreover g is the time maximally available to fulfill the goal. the netutility e of the application of a production is defined as 
	 pg-g. 	 1  
we do not go into detail on how p  g and c are calculated. for the purposes of this paper  it is sufficient to note that g only depends on the goal  but not on the product ion. 
　to sum up  in act-r the choice of a production to apply is as follows: 
1. the conflict set is determined by testing the match of the productions with the current goal. 
1. the production p with the highest utility is chosen. 
1. the actual instantiation of p is determined via the activations of the corresponding chunks. if no instantiation is possible  because of r   p is removed from the conflict set and the algorithm resumes in step 1. otherwise the instantiation of p is applied. 
　act-r provides a learning mechanism  called production compilation  which allows for the learning of new productions. we are currently exploring this mechanism for its utility for the explanation of proofs. 
1 	the architecture of p. rex 
p. rex is planned as a generic explanation system that can be connected to different theorem provers. it  adopts the following features of the interactive proof development environment  mega  benzmuller et at.  1 : 
  mathematical theories are organized in a hierarchi-cal knowledge base. each theory in it may contain axioms  definitions  theorems along with proofs  as well as proof methods  and control rules how to ap-
ply proof methods. 
  a proof of a theorem is represented in a hierarchi-cal data structure. this representation makes explicit  the various levels of abstraction by providing 
several justifications for a single proof node  where each justification belongs to a different level of abstraction. the least abstract  level corresponds to a 
　　1  in this context ttime does not mean the cpu time needed to calculate the matcht but the time a human would need for the match according to the cognitive model. 
	fiedler 	1 

oroof in gentzen's natural deduction  nd  calculus gentzen  1 . candidates for higher levels are proof plans  where justifications are mainly given by more abstract proof methods that belong to the theorem's mathematical theory or to an ancestor theory thereof. 
an example for a proof is given below. each line consists of four elements  label  antecedent  succedent  and justification  and describes a node of the proof. the label is used as a reference for the node. the antecedent is a list of labels denoting the hypotheses under which the formula in the node  the succedent  holds.1 this relation between antecedent and succedent is denoted by k 
the fact in the node. the proof of the 
fact in the node is given by its justification. a justification consists of a rule and a list of labels  the premises of the node. jt denotes an unspecified justification. hyp and defu stand for a hypothesis and the definition of u  respectively. l1 has two justifications on different levels of abstraction: the least abstract justification with the nd-rule case  i.e. the rule for case analyses  and the more abstract justification with the rule u-lemma that stands for an already proven lemma about a property of u. by agreement  if a node has more than one justification  these are sorted from most  abstract to least abstract. 
　the proof is as follows: from  we can conclude that  by the u-lemma. if we do not know the u-lemma  we can come to the conclusion by considering the case analysis with the cases that 
v  respectively. in each ca.se  we can derive that by the definition of u. 
　a formal language for specifying proofs is the interface by which theorem provers can be connected to p. rex. an overview of the architecture of  is provided in figure 1. 
　the crucial component of the system is the dialog planner. it is implemented in act-r  i.e. its operators are defined in terms of productions and the discourse history is represented in the declarative memory by storing conveyed information as chunks  details are given in section 1 . moreover  presumed declarative and procedural knowledge of the user is encoded in the declarative memory and the production rule base  respectively. this establishes that the dialog planner is modeling the user. 
　in order to explain a particular proof  the dialog planner first assumes the user's supposed cognitive state by updating its declarative and procedural memories. this is done by looking up the user's presumed knowledge 
　as notation we use  and t for antecedents and  and  for succedents. 
1 	cognitive modeling 

in the user model  which was recorded during a previous session. an individual model for each user persists between the sessions. 
　the individual user models are stored in the database of user models. each user model contains assumptions on the knowledge of the user that are relevant to proof explanation. in particular  it makes assumptions on which mathematical theories the user knows  which definitions  proofs  proof methods and mathematical facts he knows  and which productions he has already learned. after updating the declarative and procedural memories  the dialog planner sets the global goal to show the conclusion of the proof's theorem. act-r tries to fulfill this goal by successively applying productions that decompose or fulfill goals. thereby  the dialog planner not only produces a multimodal dialog plan  see section 1   but also traces the user's cognitive states in the course of the explanation. this allows the system both to always choose an explanation adapted to the user  see section 1   and to react to the user's interactions in a flexible way: the dialog planner analyzes the interaction in terms of applications of productions. then it plans an appropriate response. 
　the dialog plan produced by the dialog planner is passed on to the presentation component. currently  we use proverbs microplanner  huang and fiedler  1  to plan the scope and internal structure of the sentences  which are then realized by the syntactic generator tag-gen  kilger and finkler  1 . 
　an analyzer receives the user's interactions and passes them on to the dialog planner. in the current 
experimental stage  we use a simplistic analyzer that understands a small set of predefined interactions. 
1 	the dialog planner 
in the community of nlg  there is a broad consensus that the generation of natural language should be done in three major steps  reiter  1 . first a macroplanner  text planner  determines what to say  i.e. content and order of the information to be conveyed. then a microplanner  sentence planner  determines how to say it  i.e. it plans the scope and the internal structure of the sentences. finally  a realizer  surface generator  produces the surface text. in this classification  the dialog 

planner is a rnacroplanner for managing dialogs. 
　as wahlster et al. argued  such a three-staged architecture is also appropriate for multimodal generation  wahlster et ai  1 . by defining the operators and the dialog plan such that they are independent of the communication mode  our dialog planner plans text  graphics and speech. 
　since the dialog planner in p. rex is based on act-r  the plan operators are defined as productions. a goal is the task to show the fact in a node n of the proof. a production fulfills the goal directly by communicating the derivation of the fact irl n from already known facts or splits the goal into new subgoals such as to show the facts in the premises of n. the derivation of a fact is conveyed by so-called mathematics communicating acts  mcas  and accompanied by storing the fact as a chunk in the declarative memory. hence the discourse history is represented in the declarative memory. act-r's conflict resolution mechanism and the activation of the chunks ensure an explanation tailored to the user. the produced dialog plan is represented in terms of mcas. 
1 	mathematics communicating acts 
mathematics communicating acts  mcas  are the primitive actions planned by the dialog planner. they are derived from proverbs proof communicative acts  huang  1 . mcas are viewed as speech acts that are independent of the modality to be chosen. each mca at least can be realized as a portion of text. moreover some mcas manifest themselves in the graphical arrangement of the text. 
in p. rex we distinguish between two types of mcas: 
  mcas of the first type  called derivational mcas  convey a step of the derivation. an example for a derivational mca with a possible verbalization is: 

 since a is an element of v and u is a subset of v'  a is an element of v by the definition of subset.  
  mcas of the second type  called structural mcas  communicate information about the structure of a 
proof. for example  case analyses are introduced by: 
 case-analysis 
 to prove   let us consider the two cases by assuming and 
1 	plan operators 
operational knowledge concerning the presentation is encoded as productions in act-r that are independent from the modality to be chosen. the proof explaining productions are derived from proverb's macroplanning operators  huang  1 . each of those corresponds to one or several productions in p. rex. 
　each production either fulfills the current goal directly or splits it into subgoals. let us assume that the following nodes are in the current proof: 


an example for a production is: 
 pi  if the current goal is to show and r is the most abstract known rule justifying the current goal 
and  are known 
then produce 	mca 	 derive :reasons i :conclusion 	:method 
and pop the current goal  thereby storing in the declarative memory  
by producing the mca the current goal is fulfilled and can be popped from the goal stack. an example for a production decomposing the current goal into several subgoals is: 
 p1  if the current goal is to show and r is the most abstract known rule justifying the current goal is unknown for 1 push the goal to show 
note that the conditions of  pi  and  p1  only differ in the knowledge of the premises  for rule r.  p1  introduces the subgoals to prove the unknown premises in . as soon as those are derived   pi  can apply and derive the conclusion. 
　now assume that the following nodes are in the current proof: 

　a specific production managing such a case analysis is the following: 
 p1  if the current goal is to show and case is the most abstract known rule justifying the current goal 
then 
this production introduces new subgoals and motivates them by producing the mca. 
　since more specific rules treat common communicative standards used in mathematical presentations  they are assigned lower costs  i.e.   ef. equation 1 . 
　moreover  it is supposed that each user knows all natural deduction  nd  rules. this is reasonable  since nd-rules are the least abstract possible logical rules in proofs. hence  for each production p that is defined such that its goal is justified by an nd-rule in the proof  the probability  that the application of p leads to the goal to explain that proof step equals one. therefore  since 
case is such an nd-rule  
	fiedler 	1 

　before examining more closely an example explanation of a proof  we look at. a production reacting to a user interaction. consider the case that the user informs the system that he did not understand a step of the derivation. the analyzer receives the user's message and pushes the goal to backtrack to the node n whose explanation was not understood. this goal can be fulfilled by the following production: 
 p1  	if 	the current goal is to backtrack to node n 
then push the subgoals to re-explain the fact in n and to revise the assumption  that the justification j used in its last explanation was known. 
   a further production  p1   which is omitted here due to space restrictions  performs the revision by decreasing the base-level activation of./. 
　in order to elucidate how a proof is explained by- let us consider the following situation: 

  the current goal is to show the fact in l1  
  the rules hyp  cask  -lemma are known  
  the fact in  is known  the facts in h1  l1  h1  and l1 are unknown. 
   the only applicable production is  pi . since ulemma is more abstract than case and both are known  it is chosen to instantiate  pi . hence  the dialog planner produces the mca 
	 derive 	:reasons 
:conclusion 
	:method 	u-lemma  
that can be verbalized a*s  since 
u u v by the u-lemma.  
   suppose now that the user interrupts the explanation throwing in that he did not understand this step. the analyzer translates the user's interaction into the new goal to backtrack to l1  which is pushed on the goal stack. this goal is processed by  p1  pushing the subgoals to re-explain the fact in l1 and to revise the assumption  that u-lemma is known. the latter is fulfilled by  p.r   by decreasing the base-level activation of u-lemma below the retrieval threshold. this leaves the goal to  re- cxplain the fact in  on the top of the goal stack. 
　　now  since case is the most abstract known rule justifying the current goal  both decomposing productions  p1  and  p1  are applicable. recall that the conflict resolution mechanism chooses the production with the highest utility e  cf. equation 1 . since and  for all productions /   
application of  p1  or  p1  would serve the same goal  
1 	cognitive modeling 

therefore  the dialog planner chooses  p1  for the explanation  thus producing the mca 
 case-analysis 
that can be realized as  to prove let us consider the cases that   and then explains both cases. the whole dialog takes place as follows: 

　this example shows how a production and an instantiation are chosen by . while the example elucidates the case that a more detailed explanation is desired  the system can similarly choose a more abstract explanation if needed. hence  modeling the addressee's knowledge in act-r allows p. rex to explain the proof adapted to the user's knowledge by switching between the its levels of abstraction as needed. 
   having in mind that the mcas and the explaining productions are derived from proverbs macroplanner  it is no surprise that prex's dialog planner produces text plan equivalent to proverb. but while the proof must be provided to proverb on an appropriate level of abstraction to satisfv the user  p. rex determines for each proof step which level of abstraction it considers as the most appropriate for the respective audience. moreover  p rex can react to interactions by the user and revise both its assumptions about the addressee and its planning decisions. 
1 	conclusion and future work 
in this paper  we proposed to combine the traditional design of a dialog planner with a cognitive architecture in order to strive for an optimal user adaptation. in the interactive proof explaining system prer  the dialog planner is based on the theory of cognition act-r. 
   starting from certain assumptions about the addressee's knowledge  e.g. which facts does he know  which definitions  lemmas  etc.  built up in the user model during previous sessions  the dialog planner decides on which level of abstraction to begin the explanation. since act-r traces the user's cognitive states during the explanation  the dialog planner can choose an appropriate degree of abstraction for each proof step to be explained. furthermore  it can react to user interactions and revise the user model. the rationale behind this architecture should prove-to be useful for explanation systems in general. 

   moreover  since this architecture can predict what is salient for the user and what he can infer  it could be used as a basis to decide whether or not to include optional information  walker and rainbow  1 . 
   p. rex is still in an experimental stage. it goes already beyond proverbs capabilities  since it can not only produce textbook style proofs but also plan explanations tailored to the respective user and react to interactions. we plan to extend the presentation component to multimodality supporting graphics  text  and speech. it should consist of the following subcomponents: 
   a multimodal microplanner plans the scope of the sentences and their internal structure  as well as their graphical arrangement. it also decides  whether a graphical or a textual realization is preferred. textual parts are passed on to a linguistic realizer that generates the surface sentences. then a layout component displays the text and graphics  while a speech system outputs the sentences in speech. hence  the system should provide the user with text and graphics  as well as a spoken output. the metaphor we have in mind is the teacher who explains what he is writing on the board. 
   currently  we are examining the knowledge compilation mechanism of act-r that could enable the system to model the user's acquisition of proving skills. this could pave the way towards a tutorial system that not only explains proofs  but also teaches concepts and proving methods and strategies. 
   moreover  we are planning experiments with users of different levels of expertise in mathematics to evaluate the system. 
acknowledgements 
many thanks go to jorg siekmann  frank pfenning  ken koedinger  and christian lebiere for their help in my research. frank pfenning  carsten sehurmann and chris scarpinatto read earlier drafts of this paper. i also want to thank the anonymous reviewers for their useful comments. 
