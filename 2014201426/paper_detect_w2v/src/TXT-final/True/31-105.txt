 
this paper explores the explanation of subsumption reasoning in description logics that are implemented using normalization methods  focusing on the perspective of knowledge engineers. the notion of explanation is specified using a proof-theoretic framework for presenting the inferences supported in these systems. the problem of overly long explanations is addressed by decomposing them into smaller  independent steps  using the notions of  atomic description  and  atomic justification . implementation aspects are explored by considering the design space and some desiderata for explanation modules. this approach has been implemented for the classic knowledge representation system. 
1 	introduction 
knowledge-based systems  like other software systems  need to be debugged while being developed. in addition  systems providing  expert advice  need to be able to justify their conclusions. traditionally  developers have been supported during debugging by tools which offer a trace of the inferences performed by the system  e.g.  a 
sequence of rule firings in a rule-based expert system   or  more generally by an explanation facility for the reasoner  e.g.   . description logics  dls  form the basis of several recent knowledge-based systems  but do not currently offer such facilities. this is especially troublesome since dl reasoners perform a considerable variety of inference types  some of whose results have repeatedly proven  in practice  to be unexpected by developers. 
　some dl-based knowledge base management systems  dl-kbms   such as kris  are implemented using theorem proving techniques such as refutation-style tableaux techniques with rewrite rules . many other systems  such as loom  back and classic  are implemented using a normalize-com pare approach  where implicit knowledge is first explicated into a normal form  after which subsumption can be checked quite quickly using simple so-called  structural  comparisons. this  supported in part by nsf grant iri-1. 
1 	knowledge representation 
alexander t. borgida* 
dept. of computer science rutgers university 
new brunswick  nj 1 u.s.a. 
borgidagcs.rutgers.edu 
paper addresses the problem of explanation for this second class of dl-kbms  which  although occasionally incomplete in terms of the inferences performed  tend to be more efficient for large and long-term kb maintenance. 
　an ad-hoc solution to the problem of explanation would be to take a particular implementation of a dl-kbms and intersperse at appropriate places printstatements or other  more sophisticated operations  whose result could be assembled into an explanation. this approach is not only unprincipled but also unworkable  as we illustrate in section 1   because the declarative knowledge is compiled into data structures and imperative code in order to achieve efficiency. our solution to this problem is to cast the various forms of dl reasoning into a single deductive framework based on rules of inference in the  natural deduction -style 1 and thence offer proofs as explanations of the system's conclusions. 
　however  even in simple cases  raw  proofs turn out to be too lengthy and non-modular. a second contribution of this work is a scheme for breaking up an explanation into steps  in a way which avoids superfluous details and which is incremental. this scheme is based on the idea of decomposing descriptions into  atomic  conjuncts  and providing  atomic justifications   which stand alone and may collapse several standard proof rules  or report only certain aspects of the proof rule application. 
　finally  we discuss some of the issues and choices that arise in implementing such an explanation system as part of an existing normalize-compare reasoner.  in fact  we have implemented such a component for the classic kr&r system .  a particularly subtle concept constructor  same-as  is used to show how it is possible to integrate the theorem-proving aspect of searching for a proof/explanation  with a performance reasoner already available for the language. 
1 	description logics 
description logics form a family of formalisms for representing and reasoning with knowledge  surveyed  among others  in  1; 1; 1 . the three fundamental notions of dls are individuals  representing objects in the domain  concepts  describing sets of individuals  and roles  binary 
　　1  the rules of inference constitute a proof-theoretic semantics for the dl. such semantics have been proposed for dls in  1; 1 . 


table 1: syntax and denotational semantics of description constructors  the symbols b 1 range over concepts  a ranges over atomic/primitive concept names  1r over roles  1 over individuals  and n over numbers.  
relations between individuals. composite descriptions are formed using constructors  using a syntax such as the one in table 1. in the following three examples: 
 and  prim wine   fills color red   
 and  prim wine   fills grape cabernet   fills color red   
 and  prim wine   at-least 1 grape  
 all grape wine-grape   
the concept red-wine is defined using the and constructor to conjoin the primitive concept wine with the description of individuals whose color role is filled by the individual red; cabernet further constrains wine by specifying values for its color and grape roles. 
　the main deduction in dls is subsumption: deciding whether one description  dl  is more general than another one  d1  i.e.  whether being a d1 logically implies being a dl . for example  cabernet is subsumed by red-wine and is not subsumed by blended-wine. most of the other kinds of inferences performed by dl-kbms  such as detecting incoherent or disjoint concepts  and even individual recognition  can be represented using subsumption. 
1 	explanation for description logics 
an explanation is a justification of the system's beliefs. in rule-based and prolog systems  an explanation facility is often based on a trace of rule firings since rule invocation mimics modus ponens  which is the fundamental logical inference rule of the system. in dl-kbms  an execution trace is inappropriate since the procedural implementation is too far removed from the underlying logic. for example  the implementation may traverse graph-like data structures to determine validity of coreference constraints  as illustrated in section 1. this is similar to the problems faced by deductive databases such as ldl  ll   where compilation for efficiency hides the original program's rule structure. as in ldl  explanation benefits from a declarative view of the reasoning  and we turn to the proof theory of description logics to obtain this. proofs are built from logical axioms or 

figure 1: subsumption and equivalence rules 
told assumptions using rules of inference. our rules are in the  natural semantics  style of   and show what new assertion can be considered  proven  on the basis of previously demonstrated ones. for example  modus ponens can be expressed a s i n d i c a t i n g that if the two antecedent assertions  and can be deduced  then the consequent is deducible in the next step of the proof. the subsumption rules of dls can also be expressed in this form  l   by considering the 
subsumption judgment  for example  the sub-
sumption relationship between all-restrictions  namely  that the value restriction of the subsumed all restriction needs to be more specific than the value restriction of the subsuming all restriction  is expressed by the rule 
  similar inference rules can 
be obtained from the proof-theory based on the sequent calculus for dls proposed in . 
1 	explanations as proofs 
since subsumption can be captured by inference rules  we can start by making the explanation of a subsumption relationship be its proof. 
　in order to provide an example  we will limit ourselves to a small dl  mini-classic  which has one built-in concept  thing  and concept constructors and  all  atleast  and prim. figure 1 provides the inference rules for determining subsumption.1 
consider a concept a  defined as 
1 symbols with a superscript tilde  indicate a set. 
	mcguinness and borgida 	1 


1 	knowledge representation 

en   we should eliminate redundant conjuncts  i.e.  ei should not subsume ej for i j.  an atomic justification has the form 
a  b because ruleld   argument list  . 
where b is an atomic description  ruleld is the name of an inference rule  and argument list is a set of bindings for variables in the inference rule. 
　the simplest atomic justification is told information: a relationship holds because it was explicitly asserted by the kb builder  usually as part of a definition: 
a   and  prim good wine   at-least 1 grape   because told-info 
we also report told-info as the reason why a is subsumed by each of the syntactically occurring conjuncts of its definition: 
　a   at-least 1 grape  because told-info. concept definitions are expanded by the  inheritance  inference: if a concept b is defined as  and a . . .     then one reason why bs have at least 1 grapes is because of transitive inheritance through a: 
　b   at-least 1 grape  because inheritance 
suppose we are given an additional concept c  having b as 
a conjunct; then c  a  so c would have  atleast 1 grape  by transitivity and inheritance through both b and a  whether or not b stated anything explicitly about the grape role. we may therefore limit inheritance to report only from the concept that contains the description as  told information : 
	c 	 at-least 1 grape  because inheritance 1=a . 
another atomic justification is based on the all rule: 
 all wines red-wine  because 
observe that this is not a complete explanation  since it leaves us with an intermediate explanandum: why was red-wine subsumed by wine  to answer this  the user may request a separate atomic justification or may enter another mode where the system will automatically ask all appropriate follow-up questions. prom the above example we can see that atomic justifications naturally chain backward  until one stops at  i  inference rules without antecedents  e.g.  told information    ii  rules whose antecedents are theorems of mathematics  e.g.  atlst    iii  user-specified rules that are deemed unnecessary or stopping points  e.g.  in classic explanation chains can be stopped when a user-defined rule fires . 
　there may be cases where there are multiple justifications  e.g.  inheritance from several ancestors . for this  one might allow multiple  disjunctively branching  explanation chains. of course  if an inference rule has multiple antecedents  the explanation  chain  needs to branch conjunctively. because it is possible for explanation chains to become long and branching  we provide user control of chaining. 
　to conclude  we review the example from section 1. explaining a   and  at-least 1 grape   prim wine   is now equivalent to explaining why a is subsumed by each of the two atomic descriptions of the subsumer: 

for readability  in applications such as  we associate templates with the various inference rules  so that the above justification is actually reported as 
　　 atleast-ordering  on role grape: 1 is greater than 1. our work on such such  surface  presentation is still preliminary. 
1 	developing an explanation system 
in order to build an explanation system based on the preceding theory  we need to accomplish the following tasks: 
e identify a  sub language of atomic descriptions. 
  present  atomization  rules for normalizing a de-scription into atomic conjuncts. 
  identify rules of inference for subsumption. 
  develop algorithms for  re- constructing subsump-tion proofs. 
1 	a t o m i c descriptions and a t o m i z a t i o n 
to define the grammar of atomic descriptions  one may begin with the grammar of the concept language  and eliminate those constructs that can be written as conjunctions of other  more general descriptions. such constructs might be signaled by the presence of inference rules involving and  or having the form 

　the following is a grammar of atomic descriptions for mini-classic: 
 atomic-descr  ::- thing | 
 at-least  integer   role-name    | 
 prim  identifier    | 
 all  role-name   atomic-descr    
one should verify that this grammar has the property that every description is equivalent to the conjunction of some set of atomic descriptions. if such a proof is constructive  it will usually identify a subset of inference rules that are needed for converting to normal form  see 
 . 
　for dl-kbms using a normalize-compare algorithm for subsumption  the normal form of a concept can be mapped onto a set of atomic descriptions relatively easily  and hence forms a good basis for the atomization process. for example  classic's normal form is not quite atomic because it contains nested conjunctions  as in  all r  and cd    and implicit conjunctions such as  fills r b1 b1 . however  a simple routine can be written to break apart such nested conjunctions to yield atomic descriptions. 
　the following is the grammar of additional atomic descriptions needed for full classic: 
i 
	mcguinness and borgida 	1 

1 finding subsumption rules and atomic justifications 
an explanation designer needs to identify the inference rules and the appropriate arguments that will be reported in explanations. it is wise to begin with a complete set of the inference rules required to derive all subsumptions. royer and quantz  describe an interesting systematic technique for obtaining inference rules for a dl from its translation to first order logic. one can also analyze the dl-kbms implementation  looking for all updates to data structures  and expressing these as inference rules. 
　in order to control the verbosity of explanations  the developer can choose to limit the set of inferences that will actually be reported in explanations. this may mean skipping certain inferences  or merging two or more inferences together for the purposes of reporting. in classic  for example  we reduced the set of inference rules from the 1 or so original ones  to about half that number used in  the default settings for  our explanations. we also gave the user the option to add or delete some inferences to the set that will be reported. 
　in reporting an atomic justification  the implementer may choose to eliminate arguments that appear obvious. in classic we generally do not report arguments that appear in the denominator of the inference rule. for example  the prim rule is reported only by name since all of its arguments appear in the denominator. also  we do not report arguments like at-least values that can only have one value  but we do report which of the many potential parent concepts from which something was inherited. more details on filtering given context appear in . 
1 	the explanation construction process 
typically  it requires too much space and effort to maintain enough information to allow a reconstruction of a formal subsumption proof for every deduction in a dlkbms. thus  we expect that any extensive explanation facility will need to reconstruct proofs on demand  by  replaying  the normalization and subsumption algorithms. to do this  we need to choose between augmenting the core system code or writing separate explanation modules. in a tradeoff between impact on the core system and extra code that must be maintained  we agree with  and choose to minimize dual algorithm development. thus  we have instrumented the main code to store more information when it is replayed in explanation mode. 
　our implementation tries to explain a deduction from the current state information. if that is impossible  the system destroys certain derived information  and reruns the deductive part of the core system. this deductive core has been modified to include a rerun mode that calls an explanation update function whenever the system applies an inference rule that should be reported. the explanation update functions build structures that record the proof structure  and it is from these structures that the final explanations are generated. the only modifications to the core system are an extra pointer in the main data structures  for the explanation structure  and the rerun mode calls to explanation functions. 
1 	knowledge representation 
1 	explaining co-reference constraints 
it will not always be possible to calculate explanations using the code implementing the dl reasoner. consider the class of persons who share their name with both their parents  which is defined using the same-as constructor: 
 and  same-as  mom name   name   
      same-as  dad name   name    this description is equivalent to: 
 and  same-as  dad name   mom name   
 same-as  dad name   name    
the canonical form for same-as involves a graph data structure   in which subsumption by a description of the form  same-as  pp   rr   is checked by tracing the paths pp and rr to verify that they end at the same node. unfortunately  the two concepts above may generate the same graph  in the same way that different regular expressions may generate the same finite automaton   though we would expect different explanations of why  same-as  mom name   dad name   subsumes them: in the second case it is told information  while in the first case there are inferences to be made. 
　it is possible to encode the subsumption inferences for same-as as a logic program for predicate eq r s   which  given certain  told equalities   finds all pairs of role paths r and s whose equality follows from them1. the rules include: 
told-eq  dad name    name  . base-eq x.y  :-told-eq x y . 
 q x x . 
eq x y  	:- base-eq x y . 
eq x y  	:- append xa xb x   	base-eq xa va   append va.xb v  eq v y . 
where a description such as  all p  same-as qr   is encoded as the term base-eq  p q     p r  . 
　readers familiar with prolog will realize that this program will easily enter an infinite loop. this can be avoided by forcing a breadth-first search of the goal tree  or equivalently  by putting a bound on the depth to be explored. this latter approach is feasible if we can bound a priori the number of inference rule applications. although this could be done on purely theoretical grounds  we can obtain a much more accurate bound by considering the implementation data structure: if  same-as  pp   qq   holds on some concept graph g  then only those equalities are potentially relevant which end up pointing to nodes on the paths traced from the root by following paths labeled by pp and qq. therefore  by counting the in-degree  minus 1  of every node in the set traversed when following paths pp and qq  the initial node is not counted  and the final  common  node is only counted once  an upper bound on the depth to which to search is obtained. in other words  the maximal depth to be given for any particular search can be computed from the existing implementation structure  and then passed to the explanation component; in turn  
　　1 because of the added overhead of adding this algorithm and prolog to our system  our current implementation offers a less detailed  and hence less accurate  explanation  which  in this case  produces the same result for both of the above examples. 

this does an  inefficient  but bounded  exhaustive search of all possible inferences until a proof is found. this illustrates our point that the implemented description reasoner can be used as a source of hints for reconstructing detailed formal proofs  which can then be presented as explanations. 
1 	conclusions 
dl-kbms require an explanation service in order to help knowledge engineers with debugging. in systems implemented using a normalize-compare algorithm  as opposed to a refutation technique   the task of providing such a service in a principled way is made difficult by the presence of procedural code manipulating data structures. 
　as a foundation for explanations of subsumption  we propose the use of a deductive framework based on proof rules in the  natural semantics  style. as part of this plan  we presented the rules of inference for a simple description logic  and showed how formal proofs of subsumptions are like explanations  albeit ones that are too onerous for users to read because of a surfeit of details. the advantage of the natural deduction style is that the resulting proofs have the familiar form of  backward chaining trees . 
　in order to simplify and break up explanations  we decompose concepts into atomic descriptions  for which subsumption is explained independently. furthermore  rather than presenting complete proof trees  we explain individual nodes in the proof tree through atomic justifications  which make symbolic references to the antecedents  thereby allowing the user to choose if and when proofs for these should be presented. 
　finally  we drew on our implementation and application experience to provide some general guidelines for developing explanation components for dls. in particular  rather than developing an entirely separate  theorem prover  for finding proofs  we suggest augmenting the dl implementation with facilities for reconstructing proofs  when these are needed. the synergism between these two components was illustrated using the same-as constructor of classic. 
　we have only reported on subsumption explanation in a limited dl. our full system explains every inference that classic makes  and also includes explanations of individual reasoning  errors detected  and why a concept does not subsume another object. we also provide extensive filtering methods based on meta-information for limiting presentations and explanations of objects. 
　acknowledgments: we are indebted to lori alperin resnick for her collaboration in implementing the explanation system for classic. we also gratefully acknowledge the enlightening comments on the work and its presentation offered by r. brachman  w. cohen  h. hirsh  s. hofmeister  h. kautz  c. kulikowski  p. patel-schneider  j. moore  w. swartout  r. thomason  e. weixelbaum  and j. wright. of course  all remaining errors are ours. 
