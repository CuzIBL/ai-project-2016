optimizing a video preprocessor for ocr 
m r 
ibm systems dev elopment division 
rochester  minnesota 

summary 
this paper describes how optimal video preprocessor performance can be achieved using a software recognition system and a set of controlled experiments. it basically involves optimizing on a constant threshold and then using recognition logic designed from that 
threshold to optimize an adaptive threshold function or threshold operator. by using this technique  the video preprocessor can be optimized early in the development of an ocr  optical character recognition  machine. the software recognition system is described and experimental data is presented to illustrate the procedures. 
introduction 
there are three basic stages in the data path of an optical character recognition  ocr  machine; scanning  video preprocessing  and recognition. 	the video preprocessor configuration could be one of many possible configurations  but  in general  its function is to improve the image quality prior to the actual recogni-
tion process. 	in the video threshold type of preproces-
sor discussed here  the analog video is compared to an automatic or adaptive threshold derived from intelligence in the video signal. 
since  for many ocr applications  a wide range of print quality distortions can be expected on the input documents  the circuitry deriving a threshold from video obtained from these documents becomes necessarily complex and difficult to optimize in terms of recognition performance. optimization techniques in the past have consisted of analysis of video output signals and of two-dimensional video bit patterns  and evaluation using the recognition circuitry of the machine for which the thresholding scheme is being designed. from either of these evaluation techniques one can determine the type of automatic threshold function needed  implement it in hardware  and then repeat the evaluation to determine if the output has improved. if readjustment to the first function is needed  the process must be repeated. this continues on a trial and error basis until the best results are achieved. use of the recognition circuitry as an evaluation tool has proven to be the most fruitful technique. 
this paper describes how optimal video preprocessor performance can be achieved using a software recognition system and a set of controlled experiments. even though a specific type of preprocessor is assumed here  the techniques can be applied to other preprocessors as well. it basically involves optimizing the recognition performance on a constant threshold and then using recognition logic designed from that threshold to optimize the adaptive threshold functions. recognition reject rates are used to measure improvement or deterioration in image quality at the preprocessor output. the recognition reject rate  therefore  provides the basis for determining when the preprocessor is optimal. 
general description of video preprocessor 
the relationship of a video preprocessor to the entire ocr system is shown in figure 1. an optical scanner provides an analog representation of the scanned image. circuitry  called threshold operators or adaptive threshold functions  measures certain distinguishing characteristics of the video  average contrast  peak control pulse width  etc.  and produces a threshold to which the analog video is compared using a voltage discriminator. the voltage discriminator output  or amplitude quantized video  is then time sampled and stored in a shift register for recognition. the thres-
hold operator may also use the information stored in the shift register. for a thresholder to perform 
optimally when the input consists of a wide range of print quality distortions at least one  and usually more  threshold operators are needed. 
the operator outputs t1 t1  t1  t1 in figure 1 are combined to form a final video threshold. to show how ti might be produced  consider an operator which measures average contrast v over previously scanned characters. the threshold t  could then be generated by making it a linear function of v  
		c1 	 1  
the threshold t1 would then respond to changes in v and this would be reflected in the final video threshold along with other similarly generated operator outputs. 
the basic hardware design of the threshold operators depends heavily on the type of optical scanner being used. generally  however  the operators will measure contrast  character line width  or any other conceivable video characteristic. another design parameter is the area of threshold influence. this may be a local area about a point or an area encompassing several characters. 
-1-video thresholding is used to reduce the variations in the thresholder output caused by print quality distor-
tions of the scanned image. once the threshold operators are designed  considerable effort still remains in optimizing parameters  such as k and c1 in equation 1  for each operator and for other parameters which are involved in mixing the operator outputs to form a final 
video threshold. 	difficulty arises when a subjective decision is made as to when a variation in thresholder output has been significantly reduced by a particular threshold operator. 	another difficulty is that a particular threshold operator may have bad as well as good effects on certain types of scanned images. 	in other words  the thresholder itself may introduce distortions into the video. 	here  again  some means of measuring 
the severity of the distortion is needed. 
a thresholder will be optimal when it has adapted to the widest print quality range possible. thus  the parameters in each operator must be adjusted for the particular type of distortion the operator was designed to improve. the outputs of each operator need to be mixed in such a way that the thresholder adapts to the different 
types of print quality distortions which occur in the 
input. 
thresholder optimization 
the basic tool used here for evaluating the thresholder type of video preprocessor is a software character recognition system. hardware or software recognition could be used  but there are certain advantages to the latter. with a software recognition system  it is not 
necessary to wait until hardware is designed and built before optimizing the preprocessor. preprocessor optimization can be completed prior to designing hardware and  therefore  the logic designers can converge more rapidly to an optimal hardware recognition logic design. 
for this application  an adaptive computer program was used to automatically design recognition logics. 	these logics were then used by the software recognition system. use of the adaptive program allowed the logics to be easily adapted to a large number of scanning devices and also to a wide range of print quality. 
optimization technique 
print quality distortions are introduced from four relatively independent sources in the document preparation process; the printer  the ribbon  the scanner itself  and the document handling process. for a conceptual understanding  some hypothetical quality function q can be defined as a measure of the image quality which finally reaches the recognition system. q could then be reprehandling and scanner  respectively. q would be maximum when each stage passed the image with minimum distortion. 
attempts have been made to define a unique measure of quality  such as q  which can be related to measurable characteristics of the image and ultimately predict the performance of an optical character reader. most of these attempts have been only mildly successful. for example  the average contrast or average stroke width of an image has been used as a measure of quality. these are only two of the many image characteristics which are altered by print quality distortion  and measuring these two alone cannot possibly provide a unique measure of print quality. the evaluation technique described here uses a character recognition system to provide a measure of image quality. 
it should be clear that a wide range of print quality will occur over the lifetime of a ribbon for any given printer the varying contrast levels which occur during this period of time constitute a print quality distortion  and  in addition  they modify the severity of distortions introduced by the printer itself. 	shaded printing  light 
tops with dark bottoms   for example  which normally is a distortion introduced by the printer may be a serious problem to a recognition system only with very old ribbons or when contrast levels are low. 	on the other hand  if the impression is set too high on a 
particular type slug  this may only cause recognition problems at high contrast levels where smudged images or even background noise would be expected. the first step in preprocessor evaluation then is to check its performance at different points during ribbon life. 
the number of lines printed is used as a measure of ribbon age. 	to evaluate the dependency of image quality on ribbon age  the number of characters rejected 
by a recognition system is calculated over thirty intervals of ribbon age.  will denote the interval and r n m will be defined as the number of rejects which 
occur between  and n. the three curves shown in figure 1 illustrate the dependency of r n m on a 
constant video threshold  a threshold which is independent of all contrast variations . 
sented as the product of four independent quality functions. 	low threshold  or late in ribbon life for a high threshold. 
 1  
it is possible to express the conditions for an optimum 
where p  r  h and s denote printer  ribbon  document 	constant threshold in mathematical terms. 	by 
-1-the shape of the function r n m is used to determine which of the three thresholds is best. since it is the goal of the preprocessor to produce an output which has the least amount of variation at different points in ribbon life  curve b would represent the best choice. it shows the least amount of deviation throughout ribbon life from the minimum reject rate. this choice becomes obvious after observing the extremes in image distortion which occur early in ribbon life for a 
differentiating curve b of figure 1  it is possible to determine two points of inflection  and   which can be used to define boundaries of three contrast ranges. is the first point at which for increasing values of is the first point at which dr n m for decreasing values of n. the three contrast ranges can then be defined as 

where m is a positive integer ranging from 1 to 1. the optimum constant threshold will occur when 
all discussion to this point have been concerned with a constant video threshold. while this is the most elementary  selecting the optimum constant threshold should be the first design step. when new threshold operators are designed  new values of rh  rm  and rl can be calculated and compared against the old to give a measure of success or failure. 
still another factor in favor of first optimizing on a constant threshold is that it gives a data set with a 
proportionate number of high and low contrast problem patterns on which a software recognition logic can be designed. this is an important consideration because the recognition logic will be used for additional preprocessor evaluation. the reliability of a recognition logic design on extremely distorted data such as that which produced curves a or c of figure 1 would be very questionable. 
video evaluation program 
even though the function r n  is very simple in concept  it is very time consuming to determine by manual calculation. for example  consider an optical character reader for which the average reject rate over ribbon life time is required to be 1%  1 reject per 1 characters . also assume that it is necessary to calculate the reject rate at thirty points throughout ribbon life to accurately determine r n m. it seems reasonable to require at least 1 rejects on the average for each point to minimize statistical fluctuations. this means that 1 x 1 characters need to be scanned  1 x 1 x 1  and 1 reject patterns have to be analyzed. thus  a computer program was written to calculate r n  . * m 
several other features were incorporated into the program to allow rapid determination of predominate pattern distortions. 	in addition to calculating r n m  a similar function was calculated for each character class. 	this allowed determination of which classes  if any  were significantly more troublesome than others. 	also the video patterns which were stored on the input tape were sorted according to class and then stored on the output tape. 	the output patterns can then be printed out in order of increasing values of n so that the type of distortion can be observed. 	this is necessary in order to determine what type of threshold operator needs to be designed. 
the program also calculated the number of high  medium  and low contrast substitutions. 	since the number of substitutions is normally small  it is not possible to determine a reliable relationship between substitution errors and ribbon age. 	the substitution 
patterns  however  were stored on the output tape so they could be printed for visual inspection. 
input documents 
input documents which are scanned for preprocessor optimization must be representative of those which the machine is finally expected to handle. if the machine is expected to operate in an uncontrolled print quality environment  documents printed with low quality ribbons  worn out ribbons  and poorly adjusted printers can be expected. for machines that are designed to perform in a so-called controlled environment  the print quality is considerably better but the machine must still be able to handle a large number of print quality distortions. 
documents can be printed for laboratory testing to simulate the range of print quality distortions a machine is expected to handle. for this evaluation technique  
the documents must be sampled from the printer output at equal intervals throughout the lifetime of a ribbon. ribbon lifetime is specified for an ocr ribbon as the number of lines that can be printed with a ribbon before print quality deteriorates to an unacceptable level for ocr. however  ribbons are often used beyond their specified lifetimes in customer applications  but this condition is easily simulated in the laboratory. scheduled maintenance is normally recommended for printers used in ocr applications and here again  if the maintenance is not done  print quality will deteriorate. to simulate this condition several batches of documents  one batch per ribbon  can be printed without adjusting the printer. 
these simulation techniques would apply for multifont applications as well as single font. in multifont applications  there are usually many more printing devices each introducing print quality distortions characteristic of a particular printing mechanism. a particular type style itself may be the source of a unique print quality distortion. to minimize the number of documents required for preprocessor optimization  a 

-1-

preliminary study should be made to determine which printers and fonts can be expected to occur most frequently. 
pattern collection 
a two-dimensional bit pattern of the scanned image is essential for the optimization technique. 	this  of course  implies that the document transport  scanner and cpu interface be made operational prior to pre-
processor optimization. 	a pattern collection program need also be written to store the two-dimensional bit patterns on magnetic tape. 	this program would be dependent on a particular machine configuration. 	all programs used in the optimization scheme beyond this point can be adopted to a variety of video patterns making them useful on any ocr machine. 
segmentation and registration program 
pattern segmentation  another type of video preprocessing must be completed before the recognition process. a computer program was written to perform segmentation as well as the pattern registration required by the adaptive program. a sampling feature was included in the program to reduce the amount of data which had to be analyzed by the recognition system. the input documents were divided into small groups with m documents in each group  m can be chosen by the designer . 
the segmentation algorithms were kept quite simple to keep computer time minimal. 	this simplicity caused segmentation errors  but these could be detected automatically by comparing the number of segmented characters per line to the number of characters printed on the document. 	error lines determined in this way were not used as input to recognition. 
segmentation errors which could not be detected in the above manner occur infrequently enough for single font applications so as not to significantly affect the final calculation of recognition error rates. this may not 
be true for multifont applications  but it would be possible to manually eliminate those recognition errors caused by improper segmentation from the final statis-
tics. another alternative for multifont machines is to design a sophisticated hardware segmentation system. 
optimization steps 
all of the optimization steps discussed are summarized in a flowchart shown in figures 1 and 1. the process 
consists of three phases. 	during phase i the optimum constant threshold is determined. 	this provides a recognition logic capable of handling a reasonable print quality range that can be used for additional optimiza-
tion in phase ii. one set of documents  about 1  1 lines  is required and the same document can be used during phase i and phase ii. 
the documents should be printed with that device which is expected to produce the largest percentage of input for the particular ocr application under consideration. the same is true of the font with which the printer is equipped in the case of multifont applications. 	the printing device should be properly adjusted so that its output is typical rather than worst case. 	this prevents designing threshold operators around distortions which are characteristic of a single printer. 	program running times are indicated in figure 1 and apply to an ibm system/1 model 1. 	the number of lines and characters required are also indicated and were arrived at from statistical considerations. 
during phase ii  figure 1   the threshold operators are designed  implemented and evaluated. 	the criterion for successfully completing phase ii is to make dr n m/dn = 1 for all values of n. 
a third phase is included to extend the evaluation to more printers of the same type used in phase i and ii and also to other printing devices. this will expose other print quality distortions and if they occur frequestly enough will require the design of additional 
threshold operators. 	new fonts can also be investigated 
in a multifont application. this would require first scanning the documents at the constant threshold derived in phase i so that a new logic can be designed which is capable of recognizing the character shapes presented by the new font. 
experimental results 
in order to check the computer programs and techniques described in figure 1  all of the steps of phase i were carried out. 
a sample of the printing which was scanned for the evaluation is shown in figure 1. an ibm 1 nl highspeed printer was used to print 1  1 lines  and a l/1-length ribbon was used to reduce the number of documents which had to be printed. this represents 1/1 times the number of documents recommended for customer applications.  1  1 lines is the recommended lifetime for a full length ribbon.  the impression setting of the printer was also set to its maximum value. only half of the printed lines were scanned and this number was again reduced by a factor of ten in the segmentation program prior to recognition  there is a sampling feature in the segmentation program . the recognition logics were designed on 1  1 patterns sampled uniformly throughout the total number of lines printed. 
print contrast levels were measured on the documents and the results are shown in figure 1. contrast is defined by the equation 

-1-

contrast levels take on a range of values over the document and even over the character. 	this is illustrated in the figure by upper and lower limits. 	notice that the lower limit approaches zero for large values of n. 	this may or may not be a problem depending on whether the contrast goes to zero in an area of the character that is critical to its identification. 
the electroptic device used to scan the documents had a square sampling aperature 1 x 1 in. wide. 	the video was time-sampled at a rate which was equivalent to 1 samples /inch on the document in both the horizontal and vertical dimensions. 	amplifiers and threshold circuits with appropriate gain and bandwidth were used. 	a constant threshold equivalent to 1% contrast was used. table 1 summarizes the parameters involved in this experiment. 
table 1 experiment parameters 
printer 
ribbon 
lines printed 
lines scanned 
lines passed through recognition 
character passed through recognition 
characters in design set 
constant threshold level 
figure 1 shows the relationship between the character reject rate and n. 

it is obvious from the shape of the curve that the 1% contrast threshold is too high and the documents should be rescanned at a lower threshold in order to produce a 
symmetrical curve similar to curve b in figure 1. figure 1 shows an example of some reject patterns which contributed to the high reject rate for large values of n. 
conclusion 
the techniques and computer programs described in this report provide a means of optimizing the video preprocessor early in a machine development program. recognition error rates need not be within final machine specification during the optimization process because they are used as a relative measure of image 
quality. once optimal performance is achieved in this manner a sophisticated recognition system can be designed which performs within machine specifications. 
acknowledgements 
the author would like to acknowledge messrs. c d 
tulledge and r baumgartner both of the ibm systems development divison laboratory  rochester  minnesota  for their programming assistance. 
