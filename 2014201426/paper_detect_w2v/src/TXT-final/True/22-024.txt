 
the ability to develop hypotheses to explain new  unexpected experiences is a hallmark of human intelligence. it is also a crucial concern within artificial intelligence  since intelligent computer systems need to construct explanations in order to guide learning  to recover from planning failures  and to make sense of the stories that they read. 
the principal issue in designing a computer program that builds explanations is how to bring the system's causal knowledge to bear on a problem so that it can efficiently infer an unseen cause of observed events. in this paper we discuss some drawbacks of previous approaches to this problem  and present an alternative. the alternative involves extending script/frame theory via a system that adapts its stored explanations to new situations. we discuss the types of explanation failures that occur  and how the system employs adaptation strategies to repair those failures. the execution of one of the strategies is demonstrated. 
1 	introduction 
the ability to develop hypotheses to explain new  unexpected experiences is a hallmark of human intelligence. it is also a crucial concern within artificial intelligence  since intelligent computer systems need to construct explanations in order to guide learning  as discussed in  dejong  1  and  mitchell et a/.  1    to recover from planning failures  as discussed in  hammond  1    and to make sense of the stories that they read. 
　the hard part of processing interesting stories is not understanding the language as such  but developing creative hypotheses about what might be going on in the story. for example  consider the following story:  swale was a star three-year-old racehorse. swale won the belmont stakes. a few days later  he died.  this story 
   *this work was supported in part by the defense advanced research projects agency  monitored by the office of naval research under contract n1-k-1 and by the air force office of scientific research  under contracts f1-c-1 and afosr-1. 
is an interesting one even though it is short and simple  because it gets a curious reader to start wondering what might have happened to swale. the goal of the adaptation-based explanation project  henceforth  abe1  is to build a system that can develop creative hypotheses about events  like the one described in the swale story  by adapting the explanations that it already has in memory to new situations. 
1 	inference is the issue 
the principal issue in designing a computer program that builds explanations is how to bring the system's causal knowledge to bear on a problem so that it can efficiently infer an unseen cause of observed events. 
　approaches to this inference problem have traditionally fallen into two principal categories. the first approach was to build systems that had a large base of inference rules and were able to build explanations by chaining these inference rules together on the fly  in response to each new problem. examples of this approach include rieger's  conceptual inferencer  mycin  shortliffe  1  and wilensky's  pam program. researchers who take this approach are led to concentrate on methods of controlling the combinatorial explosion inherent in the inference-chaining process. parallel methods of rule activation  bi-directional search  and application of either domain-dependent or abstract  thematic search-control knowledge are among the important elements in this camp's bag of tricks. 
　on the other hand  another school of research seeks to view the entire explanation process as an indexing problem. these researchers postulate the existence of ready-made knowledge schemas  such as scripts or frames   schank an d abelson  1    cullingford  1    minsky  1    charniak  1   that will provide all of the proper inferences if only the right structure can be found in memory. this is the  retrieve and apply  school of explanation construction. for script appliers  the inference problem is reduced to matching input from the story against a schema in memory this makes script appliers very efficient  provided that the stories they are faced with match their schemas. the concerns of the  retrieve and apply  school naturally revolve around 
1
　　abe is a descendant of swale  which was the joint work of the author  david leake  and chris owens. 
	kass 	1 
how these knowledge structures are represented and especially around how they are organized in memory so that the right one can be found at the right time. 
   both sides have strong arguments against the other  and both are right. the script-application approach originally arose out of the realization that the  chaining + control  method was ignoring issues of memory. the systems it produced treated each experience as completely novel  and this limitation doomed those systems to perform expensive analyses every time they recognized a new instance of a plan. on the other hand  the scriptapplication approach can only be employed when memory contains a script that precisely matches the episode being processed. in order for the matching process itself to be relatively inference-free  it is important that the expectations represented in a script be at a very specific level. but this means that a  retrieve and apply  system is stymied when confronted with situations that stray even slightly from its specific expectations. in short   chaining + control  is a weak approach because it knows nothing of stereotypes  and  retrieve and apply  is limited because it knows only its stereotypes. what's needed is a system that knows stereotypes  but also knows how to go beyond them when necessary. 
1 	adding adaptation to script/frame theory 
abe is an extension of script/frame theory for handling input that is less stereotypical. the key to building that more flexible understander is to relax the assumption  which script theory relied on  that schemas will be retrieved and applied in situations that precisely match the situations that those schemas were built to describe. instead one must assume that schemas will be retrieved in situations that are only sort of like those they were originally built to handle. 
   broadening the range of situations in which a schema will be applied introduces the need to evaluate the newlyproduced explanations for problems  and to do some creative adaptation to fix any problems that are found. in an adaptation-based theory of explanation much of the burden of producing an appropriate explanation is moved out of the schema-retrieval module into the adaptation module  which we call the tweaker . the emphasis is shifted from pulling a perfectly appropriate structure out of memory  to being able to work with whatever the best structure pulled out memory happens to be. since this adaptation process is more time-consuming than simply applying structures straight out of the schema library  it makes sense to add a storage module as well  allowing the system to save and re-use the new variations of its structures that the adaptation module produces. 
　in the augmented theory   retrieve and apply  evolves into  retrieve  apply  evaluate  adapt  and store .  actually  the application  evaluation and adaptation steps are contained in a loop; when a new variation is produced  that new variation is instantiated and evaluated again. if there are still problems with the explanation it can be further adapted.  this is essentially an application of the case-based methodology to the problem of constructing 
1 	tools 
explanations.  other cbr-related adaptation work that has influenced my thinking includes  hammond  1  and  kolodner et a/.  1 . some other work on adapting explanations includes  koton  1  and  simmons  1 .  
　because abe draws on schemas as a starting point  but can then make sensible changes to those schemas  it requires both a schema library and a knowledge base of facts and plausible inference rules to represent its domain knowledge. the schema library contains the variablized explanations  called explanation patterns  or xps  schank  1   that the system will adapt. the xps are inference networks  built out of the raw material from the knowledge base  that lead from the anomalies they explain back to possible causes. xps can be thought of as augmented scripts which represent not just the surface expectations to be matched  but also the causal relationships between the various expected events. this causal annotation aids in both the evaluation of instantiated explanations  and  as we shall see  in their adaptation. 
　the rest of this paper will concentrate on how the tweaker works. we will assume the existence of a retriever  evaluator  and storer  but won't describe how they operate. see  owens  1  and  leake  1  for some discussion of issues related to these tasks. well start by presenting some examples of the sorts of explanation failures that the tweaker can handle  next move to a discussion of some of the tweaking strategies used to fix those failures  and then move to more general discussion of the mechanics of tweaking. 
1 	explanation failure 
the tweaker is initially fed a  failed  explanation  i.e. one that the evaluator rejected as inappropriate in the current situation  along with a problem description  abbreviated hereafter as xp-fd  for xp-failure description   indicating why the evaluator decided that the xp needed tweaking. there are many different ways that explanations can fail  and there are several ways to fix most failures. a tweaking strategy is an algorithm for searching the knowledge base to find substitutions  generalizations  or specifications that are needed to fix a particular kind of failure. for example  if the problem with an explanation is that it involves some actor performing an action that he is incapable of performing  then the failure may be fixed by substituting in either a new action that the old actor could perform or a new actor who could perform the old action. furthermore  there are several ways to search for prospective substitutions. what follows are a few examples of the main categories of tweaks that system handles. 
1 	plausibility failures 
plausibility failures correspond to explanations that do not make sense because they contradict some aspects of the explainer's world-model  as represented in the knowledge base. consider the following examples of plausibility failures: 
  t h e bias story: college basketball star  len bias  died one day after being drafted by the boston celtics. he was the first pick in the nba draft. 
j i m fixx x p : someone who regularly engages in recreational jogging also has a hereditary heart defect. the stress on the heart from exertion caused by jogging combines with the defect to cause that person to have a heart attack and die. failure: len bias wasn't known as a recreational jogger.  an actor of some action in the explanation is not known to perform that action.  
fixing the failure: by substituting playing basketball for recreational jogging  the adapter can build an excellent explanation based on this xp. 
  t h e swale story: swale was a star three-yearold racehorse. the day after winning the belmont stakes  swale died. 
spouse insurance x p : someone who is greedy and doesn't really love his/her spouse kills the spouse in order to collect the life insurance money. 
failure: swale has no spouse and no life insurance.  a slot referenced in the xp does not actually exist . 
fixing the failure: by searching for other actors and similar motivations  the adapter can build from this explanation the reasonable hypothesis that swale's owner got greedy and killed him in order to collect the property insurance. 
　plausibility failures can arise from explanation that involve mismatched actor-action pairs  mismatched implement-action pairs  mismatched object-action pairs  reference by the explanation to missing slots  temporal sequence problems  and specific contradictions in between beliefs in xp and beliefs in the system's knowledge base. 
1 	vagueness failures 
vagueness failures correspond to explanations that are not detailed enough  not sufficiently convincing  or do not contain the kind of information that suits the explainer's needs. what counts as sufficiently convincing or sufficiently detailed is a function of what the explanation will be used for. for example: 
  t h e pan am story: pan am flight 1  en route from london to nyc  exploded in mid air  killing all aboard. 
terrorist b o m b i n g x p : someone who is engaged in intense political conflict with the people of a particular nation may kill citizens of that nation by planting bombs in crowded areas in that nation. 
failure: does not specify enough about who did the bombing. note that this might not be a problem if the understander were a pan am engineer who just wants to know whether it was a design flaw that caused the crash  but it would be a problem if the understander were the government agency responsible for retaliating against the perpetrators.  a slot-filler is insufficiently specified.  
fixing the failure: by searching for a more specific description of someone who might have had appropriate motivation to perform the action  the adapter can conjecture that perhaps an iranian terrorist planted the bomb on the american pan am jet in order to retaliate for america's destroying an iranian airliner. 
  a suicide bomber story: a teenage girl exploded a car bomb at a joint post of israeli troops and pro-israeli militiamen in southern lebanon  killing herself and a number of israeli soldiers. terrorist bombing x p : someone who is engaged in intense political conflict with the people of a particular nation may kill citizens of that nation by planting bombs in crowded areas in that nation. failure: this doesn't explain an important part of the anomaly - why someone would do something that resulted in her own death.  a decision that the explanation claims occurred is not sufficiently motivated by the xp.  
fixing the failure: one way to make an action in an xp seem more motivated is to add an explanation of why the negative side effects of the action would be less important than expected to the actor involved. by employing this strategy the adapter can hypothesize that in addition to having the above political conflict motivation  the bomber was terminally ill  and therefore did not value her own life as highly as most people would. 
　vagueness failures mainly arise when the xp contains insufficiently specified slot-fillers  or beliefs that  while not contradicted by anything in the knowledge base  require more causal support. 
1 	adaptation strategies 
in the previous section the idea was to describe the kinds of problems that the explanation tweaker is faced with  and to give a feel for the kinds of output that it produces. the heart of the adaptation process is a library of tweaking strategies  each of which is a program that is capable of fixing a class of explanation failures. for any given explanation failure that the tweaker can handle there will be a set of tweaking strategies that apply. the tweaker ranks this set according to how efficient the strategy has been in the past  how often it has worked in the past  and how closely tailored it is to the failure at hand. it then runs the strategies in best-first order until one of them produces an acceptable explanation. now let's examine some of the strategies. 
1 	substituters 
substituters attempt to fix plausibility problems by replacing a slot filler in one of the beliefs of a failed xp with a component that could have the same causal consequents. for example  one of the strategies available for fixing actor-action mismatches like the one that occurred with the bias story above is: 
t l : replace old action with an action stereotypically associated with the actor. 
   this is the rule invoked to change from recreational jogging to playing basketball in the bias example above. the idea is to climb the actor generalization hierarchy 
	kass 	1 

to find the categories that the actor is in  such as basketball player and college student for bias   and then to follow actor-theme links to find the actions associated with those categories   for example  college students attend classes; basketball players play basketball . these are the candidates for substitution. 
   next  the actions that are candidates must be examined to see if they link up with the original xp; are there inference rules that indicate that the new action could have caused the same things that the old action caused  playing basketball involves running  just as recreational jogging does  so it is a good substitution to actually try. attending classes doesn't involve running  or physical exertion  or anything in the original chain leading to death  and therefore is not a good substitution to try. the causal links within the original xp are crucial to making this distinction. 
   briefer descriptions of some other substitution tweaks follow: 
t1: replace old action with an action closely related to it in the action hierarchy. 
for example  recreational drugs is a kind of drug taking  and a kind of recreational activity. so  if recreational drugs shows up somewhere that it isn't appropriate  consider other kinds of drug taking  such as medicinal  or performance-enhancing  and other kinds of recreational activities. 
t1: replace old action with an action indexed as causing one of the events in the xp. 
for example  if recreational jogging couldn't have been involved in the heart attack  consider other stereotypical causes of heart attacks  such as a sudden scare  or a bad diet. 
t1: replace old actor with an actor known to have motivation mentioned in xp. 
for example  swale didn't have a spouse  but his owner might have stood to collect money upon his death. 
t1: replace old actor with an actor who old actor could have made perform old action. 
for example  if the explanation says that swale's owner killed him  but the owner was known to be somewhere else at the time  maybe it was one of the owner's employees. 
1 	generalizes 
generalizes fix plausibility failures and xp application failures by producing a version of an explanation that applies to a broader class of situations  at the cost of removing some of the detail from the hypothesis. there are two ways that this can be done: 
1.1 	component generalizes 
　component generalizes work by altering a particular slot filler in one of the beliefs of the xp. in this sense they are similar to substituters  except they try to generalize the invalid component rather than search for an alternative. examples: 
1 	tools 
t1: generalize old action to make it compatible with new actor. 
for example  go from recreational jogging to physical exercise. 
t1: generalize constraint on actor to make it compatible with current actor. 
for example  change an xp that calls for a moslem religious fanatic to simply call for any religious fanatic to handle an example where the actor was known to belong to another religion. 
1.1 	xp simplifies 
　xp simplifiers generalize the structure of the xp by make a more global change than those which simply alter one of the components. 
t1: delete problematic belief 
removes conflicting beliefs from the explanation. the resulting explanation thus contains less information  but may still be useful in many contexts. 
1 	specifiers 
specifiers fix vagueness problems by finding detail to add to an explanation  making it less general  but richer in information content. there are two sub-categories of specifiers  roughly analogous to the sub-categories of generalizes: 
1.1 	component specifiers 
　component specifiers add detail to the explanation by making the description of some slot-filler more specific. examples: 
t1: specify actor description by finding an actor which matches that description  and that is also mentioned elsewhere in the xp or elsewhere in the story being processed. 
for example  in applying the spouse insurance xp to len bias  the idea that the celtics killed bias for the insurance money represents an off-the-wall  but rather creative hypothesis that can be generated by this tweak. 
tio: specify actor description by finding an actor matching description that has motivation mentioned in the xp. 
for example  iran declared an intention to retaliate for the downing of one of its airliners  so it is known to be motivated to destroy american airliners  such as pan a m 1. 
1.1 	xp 	elaborators 
　xp elaborators add detail to an explanation by building more structure into it. these strategies do things like add causal links between beliefs in the explanation  or add additional explanation to support one of the beliefs  or splice two xps together to form a more complete explanation. elaborators can involve recursive calls to the explainer. examples: 
t1: add to the causal connections between two beliefs by splicing in another xp that explains how one would cause the other. 
t1: explain a decision made by one of the actors by splicing in an explanation of why the good effects of the decision would be more important to the actor than to most people. 
for example  killing the israeli soldiers might have become extremely important to the suicide bomber if they had killed someone in her family. 
t1: explain a decision made by one of the actors by splicing in an explanation of why the bad effects of the decision would be less important to the actor than to most people. 
for example  dying might be less important to the suicide bomber if she was convinced that she would be rewarded after death  or if she were terminally ill and knew she would die soon anyway. 
t1: explain a decision made by one of the actors by splicing in an explanation of why the actor might not have known about a bad effect of the decision. 
for example  perhaps the people who convinced her to do this had not told her that the car would explode while she was inside. 
1 	overview of the tweaking process 
tweaking an explanation involves two steps  selecting a tweaking strategy to try  and then executing that strategy. both of these tasks  tweak selection and tweak execution have a number of sub-steps. the overall idea is to retrieve a set of tweaking strategies suggested by the xp-failure description that was generated by the explanation evaluator  to make an estimate of which of the retrieved tweaking strategies is the most promising in the current situation  and then to figure out how to apply that most promising tweaking strategy to the xp in question  using the knowledge in memory to make the kind of changes to the xp that the strategy calls for. 
1 	tweak selection 
the first job a tweaker has when it is called upon to fix a failed explanation is to decide which xp tweaking strategy to apply. there are three sub-stages to the tweak selection problem: tweak retrieval  tweak filtering  and tweak ranking. 
　tweak retrieval: tweak retrieval involves pulling a first pass set of tweaking strategies out of the system's library of tweaking strategies. the tweak library of is organized in a straightforward fashion - each strategy is indexed under a variablized xp-fd pattern  abbreviated tip  for tweak index pattern  that corresponds to the type of failures that the strategy addresses. a tip is a 
　variablized structures that indexes a tweak in the tweak library. tips are constructed by the programmer and are static. an xp-fd is a structure that describes a specific explanation failure. xp-fds are created dynamically by the evaluator. each tip matches a class of xp-fds. the tweak retrieval step simply involves collecting all the strategies in the library whose tip matches the xpfd being addressed. this search process is currently implemented using a variablized discrimination net with the patterns serving as indices and the current failure as the key. 
　tweak filtering: not all the strategies that match a given xp-fd will be applicable to the xp at hand. for example  t1  described above   which involves substituting another actor mentioned in the xp could not be used to make the fixx xp applicable to bias  since the xp mentions no other actors. each tweak has a set of constraints associated with which get run on the current xp to determine if it makes any sense to try that tweak on that xp. if and of the checks fail  the tweak is filtered out from the list of candidates. 
　tweak ranking: not all the strategies which don't get filtered out are equally likely to produce desirable results. therefore  tweaks are tried in best-first order  with ranking based on the following three criteria: 
  m a t c h specificity is a measure of how closely tai-lored the tweak is to the xp failure at hand. for example  t1 can apply to just about any plausibility problem by removing the implausible belief altogether. this very general strategy often leaves the explanation much weaker  however  since it reduces the support for any conclusions that previously depended on the deleted belief. closelytailored strategies are preferred over more general ones. in the current implementation this calculation is done by a simple method - counting the number of constants that match between the xp-fd and the tweak's tip. a strategy with a more detailed tip will thus match in fewer situations but will be more highly ranked when it does match. 
  cost estimate is a measure of the amount of time that a tweak is likely to consume. for example  a tweak that simply deletes an offending belief is very fast  while a belief that searches memory for an appropriate generalization is medium expensive  and a tweak that builds an entire sub-explanation to support a premise in an xp can be very expensive. in the current implementation  the  cost  of a tweak is estimated based on a very simple-to-calculate number - the average number of inferences that this tweak has performed when run in the past. 
  h i t ratio is a measure of how often a given tweak has produced explanations that the evaluator has found usable in the past. when the tweak produces an explanation that the evaluator rejects its hit ratio goes down  when it produces an explanation the evaluator decides to use  the hit ratio goes up. 
　explanations are needed for different reasons at different times  and this affects which tweaking strategy is most appropriate in a particular situation. a system in which abe is embedded can control the tweaker's behavior by determining the weight that each of the above factors should be given relative to one another. for example  in situations where getting some hypothesis quickly is more important than necessarily getting the most detailed or most plausible explanation possible  the cost estimate could be weighted more highly than the other two factors. 
	kass 	1 

1 	tweak execution 
a crucial issue that a theory of adaptation must answer is what level of knowledge belongs in the adaptation strategies. one school of thought is to make the level of knowledge very general  sticking to rules like: when an explanation provides an inappropriate slot-filler  replace it with another slot-filler. this approach is elegant in that it produces a small number of domain-independent strategies  but it doesn't promise much in the way of efficiency because the strategies don't specify how to search for the appropriate replacement. on the other hand  one could adopt very domain-specific adaptation rules that say things like: when looking for someone who killed a racehorse  consider the horse's owner. such rules provide excellent guidance to the search process once selected  but there will be very many of them  and one is left without much of a general theory of tweaking. abe's adaptation rules fall somewhere in between. they are more problem-specific than the general rules described above  but they are still quite domain-independent. the knowledge that is coded into them is not domain knowledge - that is coded into the knowledge base. instead  what tweaking strategies know is how to search that knowledge base in order to make the necessary modifications. 
　a tweak is defined by three things: the part of the xp that it modifies  the method of searching for the domain knowledge necessary to do the modification  and a set of checks that have to be run on the modifications to see if they make any sense. for example  tl and t1 are candidates for fixing the same sets of explanation failures  and they both work by replacing the actor in one of the xp's beliefs. however  they differ in the way that they search for the replacement   t l uses the actor-generalization hierarchy and actor-theme links  while t1 uses the action-generalization hierarchy . since they use different algorithms to search for substitution candidates  the set of checks they must perform is also different. for example  t1 must check to see that any actions it considers are compatible with the original actor  while tl does not since that is guaranteed by its search algorithm. 
1 	a tweak in action 
several  though by no means all  of the tweaking strategies discussed above are implemented in the abe computer program. the program output that follows is intended to demonstrate how one of the system's tweaks actually operates. the transcript has been heavily edited to meet space requirements  and concentrates on showing the tweak execution phase. the system is attempting to fix a problem with the application of the fixx-xp to swale's death  swale was not a recreational jogger . it searches for actions stereotypically associated with swale. it finds three. one  competing in horse races  is the antecedent of an inference rule involving the running action mentioned in the original explanation. this rule forms the basis of a new explanation in which competing in races substitutes for recreational jogging. 
1 	tools 


1 	conclusion 
the goal of this paper has been to describe and to advocate an adaptation-based theory of explanation. i am attempting to extend script/frame theory by using adaptable explanation patterns as my knowledge schemas  and by providing my system with the means of adapting its stored schemas to new situations. i have developed a taxonomy of explanation failures and an arsenal of failure-specific  but domain-independent adaptation strategies. 
　abe learns new variations of its schemas as it processes new stories. it attains the efficiency advantages of a script-applier and the flexibility of a system that constructs explanations from scratch. 
acknowledgments 
i would like to thank chris owens  louise pryor  and the ijcai referees for their very helpful comments on drafts of this paper. 
