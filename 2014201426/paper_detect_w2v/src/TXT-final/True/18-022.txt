 
     in order for an expert system to provide the most effective explanations  it should be able to tailor its responses to the concerns of the user one way in which explanations may be tailored is by point of view a method is presented for representing the knowledge to support different points oi view in the current domain in addition  we present a method for determining the point of view to take by inferring the user's goal within a brief discourse segment the advising system's response to the derived goal depends on the strength of its belief in the inference for which a method of determination is also provided this information enables the system to decide what answer to give to a question  which kind of justification is relevant  and when to provide it some details of the current implementation are included 
1 introduction 
     while research on explanation for expert systems has addressed some important issues in identifying the kind of knowledge needed to provide acceptable explanations  eg  swartout 1  clancey 1   one main problem with existing systems is their inability to iailor an explanation adequately to the needs or perspective of a particular user in this paper  we show now information about the current user can and 
should influence the type of explanation provided 
     in past artificial intelligence research  there have been two main approaches to user modelling classifying users according to a priori types often by direct interrogation  e.g.  rich 1  swartout 1  wallis 1  or deriving information about the current state of the user's goals  beliefs and desires from the ongoing discourse itself  eg  allen and perrault 1  car berry 1  our work draws from the second of these two main approaches  but while previous research has emphasized the derivation of a user's goal in order to interpret an utterance correctly  we are interested in making use of derived goals to generate appropriate explanations this difference in emphasis has required the development of techniques for handling four specific tasks representing different points of view in a knowledge base to support different explanations  identifying which of several possible goals underlying the current discourse should be addressed  determining when the derived goal should be taken into account  and specifying how a generation system can relate the derived goal to different points of view to determine explanation content this extends allen and perrault's  1  approach by showing how a goal can be derived to represent a sequence of utterances as opposed to a single utterance  and goes beyond carberry's  1  approach by showing how a system can decide to respond to such goals 
   the work described in this paper was partially supported by onr grant nooo1-k-1 and by at&t bell laboratories. 
     this work is being done within the context of an ongoing project to develop a dialogue facility for computer-aided problem solving a student advising system is being developed which can provide information about courses and advice about whether a 
     student can or should take a particular course the system is currently structured as a question-answering system which invokes an underlying expert system on receiving  can  questions  e.g.   can i take natural language this semester    and  should  questions  e g    should i take data structures    this production system uses its rule base to determine the advice provided  i e   yes or no  and the trace of rule invocations is used to provide a supporting explanation of the advice 
the advisor system consists of an atn parser 
 woods 1   a kl-one knowledge base  brach man 1  with access functions  a goal lnferencer  an underlying production system  and a surface generator to produce responses and explanations in natural language  derr and mckeown 1  currently the system can produce responses to information questions by accessing the knowledge base and to  can  questions by invoking the underlying production system certain ' aspects of response generation and inferencing for should  questions have been implemented 
     in the following sections  we first show the different types of explanations required and then describe in some detail the techniques we have developed 
1 different explanations 
     in this paper  we focus on how the content of an explanation must vary according to the perspective or point of view taken on the underlying problem domain for example  in the student advisor domain there are a number of points of view the student can adopt for selecting courses it can be viewed  among 
others  as a process of meeting requirements  1 e    how do courses t:e in with requirement sequencing '   as a state model process  i e   what should be completed at each state in the process '   as a semester scheduling process  i e    how can courses fit into schedule slots  '   or as a process of maximizing personal interests  as in  how will courses help me learn more about ai  '  given these different points of view  alternative explanations of the same piece of advice  i e yes  can be generated in response to the question   should i take both discrete math and data structures this semester '' 
1 requirements yes  data structures is a requirement for all later computer science courses and discrete math is a corequisite for data structures 
1 state model: yes  you usually take them both first semester  sophomore year 1 semester scheduling: yes  they're offered next semester  but not in the spring 

and you need to get them out of the way as soon as possible 
1 personal interests  e.g.  al.  yes  if you take data structures this semester  you can take introduction to al next semester  and you must take discrete math at the same time as data structures 
     one of these explanations may be more appropriate than others depending upon the user's goal in pursuing the dialogue for example  we might supply explanation  1  above if the users goal were to complete requirements as soon as possible and explanation  1  if the user's goal were to keep apace with the normal rate of progress thus to address the problem of selecting a perspective to use in an explanation  we must develop techniques that allow a system to infer a user goal from a discourse segment as well as techniques that can indicate information that is relevant for any given perspective 
1 knowledge representation 
     in order to identify information that is relevant to a user's goal  we are using intersecting multiple hierarchies to represent different points of view in the underlying knowledge base the hierarchies are crosslinked by entities or processes  often courses in the student advisor domain  which can be viewed from different perspectives  and thus occur in more than one hierarchy  hence to construct the content for explanation  1  above the system would extract information about the relation between data structures and discrete math from the requirements hierarchy  and for explanation  1  extracts information from the state model hierarchy a diagram of a portion of these two hierarchies containing information for the two points of view is shown in figure 1 below. 

k. mckeownet al. 1 
     the partitioning of the knowledge base by intersecting hierarchies allows the generation system to distinguish between different types of information that support the same fact from this partitioning  the system ran select the portion that contains the information relevant to the current request and user goal 
1 deriving the user goal 
     the system must also be able to reason about the appropriateness of one perspective versus others since the perspective taken is related to the user's goal in pursuing the dialogue  the large body of work on goal inference techniques  allen and perrault 1  carberry 1  litman and allen 1  is applicable for deriving the user's goal we have drawn heavily from allen and perrault s  1  work  making use of their plausible inference rules  representation of domain plans  and representation of speech acts as plans while their work has been extremely useful  it falls short for our purposes in several ways for example  their inferenerng procedure derives a plausible  goal for a user based on a single utterance  while we are interested in deriving a goal based on the current sequence of utterances1 
     consider the discourse shown in  1  below assuming that a database of domain plans common to the student advising domain is maintained  allen and perrault's techniques could be used to derive the domain goal shown following each question but the explanation shown in  1c  addresses not the derived goal of  1c   nor any of the derived goals of the previous utterances but instead addresses the higher level goal indicated by the derived goals of  1a  and  1b  the problem for responding to such goals in an explanation  then  is to be able to derive a higher level goal relating the goals of individual utterances 
1a s i've read about the field of al and i'm interested in learning more about it eventually is natural language offered next semester  plausible
　　　　 goal = take natural language a yes. 
b s who is teaching artificial intelligence  plusible goal = take al 
   a lebowitz this semester e s i haven't taken data structures yet should 1 take it this semester  plausible goal = take data structures 
a yes  if you take data structures this semester  you can take al next semester which is necessary for all later ai courses 
     we use allen and perrault's rules to derive the domain goal of each individual utterance  which we term the current goal we also identify a goal representing the discourse sequence which we term the 
　 in this work  we restrict ourselves to a discourse segment that deals with a single or related set of goals. over a longer sequences of discourse  topics may shift and the user may reveal very different goals across such boundaries. detecting topic shifts and radical changes in goals is a difficult problem that we are not addressing. 

1 k. mckeown et al. 

     when the second utterance  who is teaching artificial intelligence   is entered  the current goal take ai is derived and all higher level goals derived  see figure 1  from that using the body-action rule the lowest level node where the two paths intersect becomes the relevant plan  concentrate-on-ai in this case . if the second utterance had been  when is operating systems offered    the higher level goal fulfill electives would have been inferred since this is the only relation between the goals take operating systems and take natural language 
     this method is essentially a search for the lowest common ancestor of the current goals of two providing this information 
1 when to respond 
     the goal inference techniques just described allow the system to infer what a user's goal might be  but this inference may be so tentative that explanations which always address such goals will be as undesirable as those that never take a goal into account allen and perrault themselves term their rules plausible inference rules since the goals they attribute to the user are only possibilities and not definite however  goals derived from some discourse sequences seem intuitively more definite than those derived from other sequences 
if the user directly asserts his/her goal fas in 1  

then it can be definitely inferred the plausible inference rules however  will infer the same goal for an utterance like that shown in  1  unless we have further indication that the user actually has the goal take natural language  then on receiving a follow-up question such as  1a   a neutral explanation as shown in  1b  is preferable to the tailored explanation in  1c  one problem for a system that generates tailored explanations  then  is being able to determine when to respond to a derived goal 
1 	s i'm planning on taking nip in the future what are the prerequisites  plausible goal = take natural language 
1. s is natural language offered this semester'' plausible goal = take natural language 
1 a s i'm thinking of taking computability this semester would that be a good idea  
plausible goal = take computability 
b a yes  it's your last requirement and it's a good idea to get it out of the way before going on 
to electives 
c a yes  computability is particularly important for nip since it covers grammars so it's a good idea to take it first 
     to handle this problem we use three levels of likelihood of derived user goals if we can distinguish between derived user goals that can definitely be attributed to the user  derived goals that are likely  and derived goals that are only plausible  then we have a basis for determining when to generate tailored explanations tailored explanations can be generated for definite and likely goals and a neutral explanation generated for plausible goals 
     a goal is definite if a user states that s/he has that goal  as in i want to concentrate in a l      i'd like to concentrate in al    or  i'm interested in taking as much al as possible   if not stated  it is difficult to infer without doubt that a user has a given goal  but there are cases where it is more likely than others space prohibits providing details  but we note that a goal is more likely if it has been repeatedly derived from consecutive utterances as well as in cases where it is one step in a plan that the user has partially completed the system is currently capable of deriving current and relevant goals for a discourse segment and classifying them as plausible or definite classification of coals as likely has been designed  but must still be implemented 
     we have ignored  in this paper  the possibility of responding in other ways than providing explanations in some cases  in fact  it may be preferable for the system to ask the user to clarify his/her goal or to 
k. mckeown et al. 1 
take the initiative in some other way determining when and how to take the initiative as an alternative to providing explanations is a topic addressed elsewnere  see matthews 1  
1 how to respond 
     finally  the system must be able to make use of the derived goal in constructing an explanation when a  should  question follows a dialogue sequence the underlying mini production system  consisting of working memory  rule base  and inference engine  is invoked in this process 
     to construct the explanation  the hierarchy representing the proper perspective is determined directly from the relevant goal  and information retrieved about the questioned object1 from that hierarchy is placed in working memory the production system uses this information to derive the response  that is whether the user should or should not pursue the queried action the trace of the reasoning is then available to provide the basis for the explanation  as is the case in traditional expert systems note that the information extracted from one hierarchy will allow a different set of rules to fire than will information extracted from another  thus producing different explanation content 
	as an example  	consider again 	the question 
 should i take both data structures and discrete this semester   assume that the system has determined that the user's goal is take required and that the goal should be taken into account in the explanation after deducing that the student can take these courses   the production system will attempt to prove that the queried action helps the user achieve his/her goals the information shown in figure 1  extracted from the requirements hierarchy  refer back to figure 1   enables rules 1 and 1 to fire with tx instantiated as data structures   y as discrete math  and  course as required the extracted fact that discrete math is a co-requisite for data structures enables rule 1 to fire its consequence and the extracted fact that data structures is a prerequisite to required enables rule 1 to fire  which concludes that required can be taken thus  the advice is yes since take required is the user's goal and these two instantiated rules can then be used as the basis for the hypothetical explanation given earlier and reproduced in figure 1 other rules in the rule base  such as  a course should be taken if the student is at the right year to take it   do not fire since information necessary to fire that rule does not exist in working memory this processing is partially implemented  but much work is needed before the full explanation can be produced 
   the questioned object is the course the user is inquiring about  e.g.  data structures in  should i take data structures   . 
   regardless of whether the user's queried action helps him/her achieve the relevant goal  if it is not permissible or will prevent the student from completing the major  the advice is always negative. rules encoding such absolute constraints include  a course cannot be taken before its prerequisite   or  a course should not be taken if it prevents the student from completing requirements by the time s/he is a senior . here  we assume  for convenience  that the student nas already taken the prerequisites to data structures and discrete math and is early enough in his/her program that s/he will be able to finish on time  and thus the absolute rules are satisfied. 

1 k. mckeown et al. 
acknowledgments 

information extracted 
 prerequisite required data-structures  
 co-requisite data-structure discrete-bath  
rule 1 
 takes  x  and  prerequisite  course  x   
-   can-take   course   
rule 1 
 co-requisite tx  y  and 
 taking  y  -   can-take tx  
     yes  data structures is a requirement for all later computer science courses and discrete math is a corequisite for data structures 
	figure 1: 	constructing explanation content 
1 future directions 
     more research is needed on explanation  plan recognition and user modelling for our approach to be effective for a broad range of human-computer dialogue as for explanation  in the current implementation the production system needs to be developed further and its reasoning trace interfaced to the operational surface generator for english output on the theoretical side  we are investigating the use of discourse strategies to control the organization of the explanation tne plans in the current implementation were selected by examining transcripts of actual student advising sessions  but it would be desirable to have a much larger set of plans knowledge about their base rates and importance  ana additional criteria for tracking their relevance and likelihood during the interaction it seems likely  also  that better explanations will require a more complete user model incorporating static  global characteristics of the user as well as those dynamic  local characteristics available from the ongoing dialogue itself additionally  while we have touched on one way of representing and using point of view  others will doubtless be necessary such a comprehensive attack on the topics of explanation  
p
lan recognition  and user modelling offers promise from both a theoretical and practical perspective 
1 conclusion 
     we have demonstrated the need for tailoring explanations to users in consultative or problem solving dialogues with a computer  and have addressed this problem with a new approach integrating research in plan recognition  user modelling  and explanation generation derivation of goals or plans is based on an extension of perrault and allen's  1  work which handles discourse segments rather tnan isolated utterances our model and implementation provide mechanisms for assessing which goal is relevant to the user at any moment during  the discourse  as well as when that point of view snould be addressed in an explanation it also makes progress toward the determination of how to tailor the explanation to the user's goal in addition to enhancing previous work on goal inferencing  this report shows now research in natural language processing on goal derivation can be applied to generate explanations sensitive to the user's current perspective in expert system interactions 
     we would like to thank michael lebowitz for his suggestions on an earlier draft of this paper 
