
this paper describes our research on automatic semantic argument classification  using the propbank data  kingsbury et al.  1 . previous research employed features that were based either on a full parse or shallow parse of a sentence. these features were mostly based on an individual semantic argument and the relation between the predicate and a semantic argument  but they did not capture the interdependence among all arguments of a predicate. in this paper  we propose the use of the neighboring semantic arguments of a predicate as additional features in determining the class of the current semantic argument. our experimental results show significant improvement in the accuracy of semantic argument classification after exploiting argument interdependence. argument classification accuracy on the standard section 1 test set improves to 1%  representing a relative error reduction of 1%.
1 introduction
deriving the semantic representation of a sentence is important in many natural language processing tasks  such as information extraction and question answering. the recent availability of semantically annotated corpora  such as framenet  baker et al.  1 and propbank  kingsbury et al.  1  prompted research in automatically producing the semantic representations of english sentences. for propbank  the semantic representation annotated is in the form of semantic roles  such as arg1  arg1  etc. of each predicate in a sentence  and the process of determining these semantic roles is known as semantic role labeling.
　most previous research treats the semantic role labeling task as a classification problem  and divides the task into two subtasks: semantic argument identification and semantic argument classification. semantic argument identification involves classifying each syntactic element in a sentence into either a semantic argument or a non-argument. a syntactic element can be a word in a sentence  a chunk in a shallow parse  or a constituent node in a full parse tree. semantic argument classification involves classifying each semantic argument identified into a specific semantic role  such as arg1  arg1  etc.
　various features based on either a shallow parse or full parse of a sentence have been proposed. these features are then used by some machine learning algorithmto build a classifier for semantic argument classification. while these features capture the syntactic environment of the semantic argument currently being classified  they overlook the semantic context of the argument.
　we propose a notion of semantic context  which consists of the already identified or role-classified semantic arguments in the context of an argument that is currently being classified. semantic context features are defined as features extracted from the neighboring semantic arguments  and used in classifying the current semantic argument. the use of these features explicitly captures the interdependence among the semantic arguments of a predicate.
　in this paper  we focus on the semantic argument classification task using propbank kingsbury et al.  1 . our semantic context features are derived from full parse trees. our experimental results show significant improvement in the accuracy of semantic argument classification after adding the semantic context features  when compared to using only features of the current semantic argument.
　the rest of this paper is organized as follows: section 1 explains in detail the application of semantic context features to semantic argument classification; section 1 gives a specific example to illustrate how semantic context features can improve semantic argument classification; section 1 presents our experimental results; section 1 reviews related work; and section 1 concludes the paper.
1 semantic argument classification with semantic context features
similar to  pradhan et al.  1   we divide the task of semantic role labeling into two sequential subtasks: semantic argument identification and semantic argument classification  and treat each subtask as a separate classification problem. our investigation focuses on semantic argument classification with the assumption that the semantic arguments have been correctly identified by the semantic argument identifica-
featuredescriptionsentence level featurespredicate  pr predicate lemma in the predicate-argument structurevoice  vo grammatical voice of the predicate  either active or passivesubcat  sc grammar rule that expands the predicate's parent node in the parse treeargument-specific featuresphrase type  pt syntactic category of the argument constituenthead word  hw head word of the argument constituentargument-predicate relational featurespath  pa syntactic path through the parse tree from the argument constituent to the predicate nodeposition  po relative position of the argument consitituent with respect to the predicate node  either left or right　　　　　　　table 1: baseline features tion module in the first step.
1 baseline features
by treating the semantic argument classification task as a classification problem using machine learning  one of the most important steps in building an accurate classifier is the choice of appropriate features. most features used in prior research  such as  gildea and jurafsky  1; pradhan et al.  1; bejan et al.  1   can be categorized into three types:
  sentence level features  such as predicate  voice  and predicate subcategorization.
  argument-specific features  such as phrase type  head word  content word  head word's part of speech  and named entity class of the argument.
  argument-predicate relational features  such as an argument's position with respect to the predicate  and its syntactic path to the predicate.
　the above features attempt to capture the syntactic environment of the semantic argument currently being classified. they are entirely determined by the underlying shallow parse or full parse of the sentence. they carry no information about the semantic arguments that have already been identified or classified. as such  the classification of each semantic argument is done independently from other semantic arguments. it assumes that the semantic arguments of the same predicate do not influence each other.
　we use the baseline features in  pradhan et al.  1  as our baseline. these features are explained in table 1.
1 semantic context features
for a semantic argument  its semantic context features are defined as the features of its neighboring semantic arguments. the combination of the features of the current semantic argument and its neighboring semantic arguments encodes the interdependence among the semantic arguments.
　to illustrate  the parse tree in figure 1 is annotated with the semantic argumentsof the predicate  added . these semantic arguments are arg1  arg1  arg1  and argm-adv .
s
hhhhhhhhhhhhhhhhh
	np	vp	.

	 arg1  index	p  ppppppppp	.
	ppppp	   

the nasdaq
	vbd	np	pp	pp
	 predicate 	 arg1   argpp1 p  argm-advppp 

	added	1	to 1	on ...shares
figure 1: semantically labeled parse tree  from dev set 1
pr	vo	scpt	hw	pa	poaradd active vp:vbd np pppp
np index np…s vp vbd	larg1add active vp:vbd np pp ppnp	1	np…vp vbdrarg1add active vp:vbd np pppppp	to	pp…vp vbdrarg1add active vp:vbd np pppppp rargm-advtable 1: semantic context features based on figure 1
each row of table 1 contains the baseline features  as defined in table 1  extracted for each semantic argument.
　in figure 1  suppose the semantic argument identification module has correctly identified the constituents  the nasdaq index    1    to 1   and  on ... shares  as semantic arguments of the predicate  added . assume further that the semantic argument the nasdaq index has been assigned the semantic role arg1. now consider the task of assigning a semantic role to the semantic argument 1 . without using semantic context features  the baseline features used for the semantic argument  1  appear in row 1 of table 1.
　if we augment with the semantic context features of all neighboring arguments  then the features pt  hw  pa  and po of the neighboring arguments arg1  arg1  and argm-adv are added as additional features. also  since  the nasdaq index  has been assigned a semantic role  its argument class arg1 is also used as an additional semantic context feature ar.
1 various ways of incorporating semantic context features
there are many possible subsets of the semantic context features in table 1 that one can choose to add to the baseline features of the current semantic argument being classified. in addition  since the semantic role labels of arguments that are already classified  like arg1 in the previous example  are available as additional context features  the order in which we process the semantic argumentsduringsemantic argument classification can affect the accuracy of the semantic role labels assigned. a good classifier should incorporate an informative set of semantic context features  as well as adopt an argument ordering that helps to give the best overall accuracy for semantic argument classification.
　we use context feature acronyms with subscripts to denote particular types of context features at specific locations relative to the current argument being classified. for example  hw1 refers to the head word feature of the argument imme-
featuredescriptionexamplesptithe syntactic category of the ith context semantic argumentpt 1=np ; pt1=pphwithe head word of the ith context semantic argumenthw 1=index	;
hw1=topaithe path of the ith context semantic argumentpa 1=np…s vp vbd ; pa1=pp…vp vbdpoithe position of the ith context semantic argumentpo 1=l ; po1=rarithe semantic role of the ith previous semantic argumentar 1=arg1table 1: examples of semantic context features. the current semantic argument being classified is  1  as shown in figure 1.
diately to the right of the current argument being classified. more examples are given in table 1. we also use set notation { i..i} to denote the set of context features with subscript index j （{ i ... i}. for example  hw{ 1..1} denotes the context features hw 1 and hw1.
adding all types of context features
we could choose to add all types of context features within a certain window size. to illustrate with the example in figure 1  suppose the current semantic argument being classified is  1 . if we add all types of context features from the set { 1..1}  i.e.  within a window size of one   then the additional context features added are those in table 1 that are darkly shaded. the baseline features for the current argument  1  is lightly shaded in table 1.
pr	vo	scpthw	pa	po	aradd active vp:vbd np pp ppnpindex np…s vp vbd	l	arg1add active vp:vbd np pp ppnp1	np…vp vbdr	*add active vp:vbd np pp ppppto	pp…vp vbdradd active vp:vbd np pp pppp	on	pp…vp vbd	r
table 1: adding all types of context features from the set
{ 1..1}
adding a single type of context features
alternatively  we could add only a specific type of context features within a certain window size  since it may be the case that certain types of context features are more effective than others. to illustrate again with the same example. if we add the head word features hw{ 1..1}  i.e.  within a window size of two   then the additional context features added are those in table 1 that are darkly shaded. the baseline features for the current argument  1  is lightly shaded in table 1.
different argument ordering
so far we have implicitly assumed that the semantic arguments are processed in a linear ordering  i.e.  according to the natural textual order in which the semantic arguments appear in a sentence. in propbank  the semantic arguments of a single predicate in a sentence do not overlap  so this ordering
pr	vo	scpthw	pa	po	aradd active vp:vbd np pp ppnpindexnp…s vp vbd	l	arg1add active vp:vbd np pp ppnp1np…vp vbdr	*add active vp:vbd np pp pppppp…vpvbdradd active vp:vbd np pp pppppp…vpvbdrtable 1: adding one type of context features hw{ 1..1}
is well-defined. using a linear ordering  the semantic arguments in figure 1 are processed in the order arg1  arg1  arg1  and argm-adv .
　experiments reported in  lim et al.  1  indicate that semantic arguments spanned by the parent of the predicate node  the immediate clause  can be more accurately classified. hence  if we process these semantic arguments first  their semantic role labels ari may be more accurately determined and so may help in the subsequent classification of the remaining semantic arguments. inspired by  lim et al.  1   we view a parse tree as containing subtrees of increasing size  with each subtree rooted at each successive ancestor node of the predicate node. in subtree ordering  the semantic arguments spanned by a smaller subtree are processed first before the arguments of the next larger subtree. using a subtree ordering  the semantic arguments in figure 1 are processed in the order arg1  arg1  argm-adv   and arg1.
1 an illustrating example of the utility of semantic context features
in this section  we shall motivate the utility of semantic context features by considering the example in figure 1. the predicate  add  has three rolesets defined in propbank  as shown in table 1. each roleset corresponds to a different argument structure. depending on the particular roleset that a specific instance of  add  belongs to  different argument classes are assigned to its semantic arguments.
rolesetargumentsadd.1arg1 speaker   arg1 utterance add.1arg1 adder   arg1 thing being added   arg1 thing being added to add.1arg1 logical subject  patient  thing rising / gaining / being added to   arg1 amount risen   arg1 end point  
argm-loc medium table 1: the rolesets of  add   as defined in propbank
　the roleset for  add  in our example is  add.1   where the first argument to the left of  added    the nasdaq index   is the  logical subject  patient  thing rising / gaining / being added to . this contrasts with the second roleset  add.1   such as  added  in the sentence  judge curry added an additional $1 million to the commission's calculations.   which is an illustrating example used in propbank's description of the roleset  add.1 .
　during classification of the semantic arguments  1  and  to 1  in this example  using only the baseline features of an individual semantic argument results in  1  being misclassified as arg1 and  to 1  being misclassified as arg1  when their correct semantic argument classes should be arg1 and arg1 respectively. since the two rolesets  add.1  and  add.1  have similar argument structures  add something to something   and since  add.1  occurs more frequently than  add.1   the semantic argument classification module has assigned the semantic argument classes of the roleset  add.1  to  1  and  to 1   which is incorrect.
　however  our experiments in section 1 show that a classifier augmented with the context features hw{ 1..1} assigns the correct semantic argument classes to  1  and  to 1 . this is because in the sentence  index added something to something   that  index  is the head word of the first argument gives a strong clue that the correct roleset is  add.1   since  index  cannot fill the adder  agent  role of  add.1 . in fact  occurrence counts from propbank section 1 indicate that of the three occurrences of  index  as the head word of the first argument of predicate  add   all three appear in the roleset  add.1 . this example illustrates the importance of neighboring semantic arguments in the context of the current semantic argument in determining its correct semantic argument class.
1 experimental results
our semantic argument classification module uses support vector learning and is implemented with yamcha1 and tinysvm1  kudo and matsumoto  1 . polynomial kernel with degree 1 is used in a one-vs-all classifier. the cost per unit violation of the margin c = 1  and the tolerance of the termination criterion e =1.
　the training  development  and test data sections follow the conventional split of section 1  1  and 1 of propbank release i respectively. in section 1 to section 1  we present the accuracy scores when evaluated on development section 1. in section 1  we present the accuracy scores on test section 1.
　the semantic argument classification accuracy when evaluated on section 1 using baseline features is 1%  assuming that semantic argument identification is done correctly  i.e.   gold argument identification  . in section 1 to section 1  accuracy scores that show a statistically significant improvement  χ1 test with p =1  over the baseline score of 1% are marked by  * . the highest score of each row in the score tables is boldfaced.
1 results of linear ordering
results using all types of context features
table 1 contains accuracy scores after augmenting baseline features with all types of semantic context features. ar feature is only present within context feature sets that contain neighboring arguments to the left of the current argument. we observe that the accuracy scores have a significant improvement from the baseline if context features on both sides of the current argument are used together. context features to the left of the current argument are not effective when used alone.
accuracy of increasing context window sizefeature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}all1*1*111feature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}all11111feature{1..1}{1..1}{1..1}{1..1}{1..1}all11111table 1: accuracy based on adding all types of semantic context features  with increasing window size  assuming correct argument identification and linear ordering of processing arguments
results using a single type of context features
accuracy scores of semantic argument classification after augmenting baseline features with a single type of context features are shown in table 1. the best improvement results from the use of head word features hw. the use of features ar reduces accuracy. this is likely due to semantic argument classes not being accurately determined  and errors committed in a position in linear ordering might affect classification accuracy at subsequent positions. however  a better argument ordering may improve the effectiveness of ar.
1 results of subtree ordering
we repeat the experiments of the last subsection  but this time with the use of subtree ordering. the accuracy scores are given in table 1 and table 1. the most prominent difference from the results of linear ordering is the better accuracy scores with the use of the ar features  as shown in table 1 compared with table 1. the improvementobserved is consistent with the findings of  lim et al.  1   that the argument class of the semantic arguments spanned by the parent of the predicate node can be more accurately determined.
1 more experiments with the ar feature
unlike other semantic contextfeaturesthat are completelydetermined once argument identification is completed  the ar feature is dynamically determined during argument classification. it may be possible to improve the overall accuracy of
accuracy of increasing context window sizefeature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}pt1*1*111hw1*1*1*1*1*pa1*1*111po11111feature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}ar11111table 1: accuracy based on adding a single type of semantic context features  with increasing window size  assuming cor-
rect argument identification and linear ordering of processing arguments
accuracy of increasing context window sizefeature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}all1*1*111feature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}all11111feature{1..1}{1..1}{1..1}{1..1}{1..1}all11111table 1: accuracy based on adding all types of semantic context features  with increasing window size  assuming correct argumentidentification and subtree orderingof processing arguments
accuracy of increasing context window sizefeature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}pt1*1*111hw1*1*1*1*1*pa1*1*1*11po11*111feature{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}ar11111table 1: accuracy based on adding a single type of semantic context features  with increasing window size  assuming correct argument identification and subtree ordering of processing arguments
assigning argument classes to all the semantic arguments of a predicate if we use a beam search algorithm to keep the best k combinations of argument classes assigned to all semantic arguments processed so far.
ar feature with gold semantic argument class
to determine the maximum accuracy improvement possible with the use of the ar feature  we assume that the argument classes of all previous semantic arguments have been accurately determined and used as semantic context features. the experimental results are presented in table 1  titled  linear gold  and  subtree gold  respectively for linear and subtree ordering.
ar feature with beam search
tinysvm's output scores are converted to confidence scores between 1 and 1  by applying the sigmoid function y =
. we implemented a beam search algorithm to find the overall best sequence of argument classes to be assigned to all semantic arguments. at each iteration  the beam search algorithm processes one semantic argument and determines the top 1 argument classes with the highest confidence scores for each semantic argument. it then finds and keeps the best k  k = 1 in our implementation  argument class sequences overall. each argument class sequence is assigned a confidence score  which is the product of the confidence scores of all arguments in the sequence. finally  the sequence of argument classes for all semantic argumentswith the highest score is chosen. experimental results are presented under  linear beam  and  subtree beam  in table 1  and show improvements after using beam search with ar feature for subtree ordering.
accuracy of increasing context window sizear with{ 1..1}{ 1..1}{ 1..1}{ 1..1}{ 1..1}linear11111linear beam11111linear gold1*1*1*1*1*subtree11111subtree beam1*1*1*1*1*subtree gold1*1*1*1*1*table 1: more experiments with the ar feature  using beam search and gold semantic argument class history
1 combining multiple semantic context features
the best accuracy score we have obtained so far is 1%  given by hw 1..1 in table 1. this score is a statistically significant improvement over the baseline score of 1% obtained with only baseline features. we want to further leverage on the other types of semantic context features. error analysis of experiments in table 1 and 1 on development section 1 shows that classifiers using different semantic context features make different classification mistakes. thus we would like to explore the combination of multiple semantic context features. this provides a basis for combining multiple semantic context features. here we more carefully select the context features than simply using all available features as in table 1 and 1.
a single classifier with multiple context features the best context features from each row of table 1  pt{ 1..1}  hw{ 1..1}  pa{ 1..1}  po{ 1..1}  and ar{ 1..1} are combined to form a new classifier based on linear ordering. similarly pt{ 1..1}  hw{ 1..1}  pa{ 1..1}  po{ 1..1}  and ar{ 1..1} from table 1 are combined to form a new classifier based on subtree ordering. evaluation on development section 1 gives accuracyscores of 1%and 1%  for linear and subtree ordering  respectively. the lack of accuracy improvement over that of hw 1..1 shows that such a simple combination might accumulate the errors introduced by each additional context feature.
voting with multiple classifiers
instead of building a new classifier with multiple semantic context features  one can combine the classification results of multiple classifiers and hope to achieve better accuracy through consensus and mutual error correction. the voting process combines k different classifiers each belonging to one row in table 1 or table 1. currently only classifiers based on the same ordering are combined. classifiers are chosen from different context feature types  but can be of the same context feature window size. for a particular semantic argument a  each candidate argument class will accumulate its confidence score assigned by all the voting classifiers. the candidate argument class with the highest aggregate score will be output as the argument class for a. exhaustive experiments are carried out with k = 1 1. on the developmentsection 1  the best voting classifier in linear ordering is {pt{ 1..1} hw{ 1..1} pa{ 1..1} ar{ 1..1}}  with accuracy 1%. the best for subtree ordering is
linear orderingsubtree orderingfeatureaccuracyfeatureaccuracypt{ 1..1}1*pt{ 1..1}1hw{ 1..1}1*hw{ 1..1}1*pa{ 1..1}1*pa{ 1..1}1*po{ 1..1}1po{ 1..1}1*ar{ 1..1}1ar{ 1..1}111*all{ 1..1}1*all{ 1..1}1*v otelinear1*v otesubtree1*table 1: semantic argument classification accuracy on test section 1. baseline accuracy is 1%.
{hw{ 1..1} pa{ 1..1} ar{ 1..1}} with accuracy 1%. we denote the two voting classifiers as v otelinear and
v otesubtree respectively.
note that the accuracy score of 1% achieved by
v otesubtree is a statistically significant improvement over the best score we have obtained without voting  1% of hw{ 1..1} in table 1.
1 testing on section 1
based on the experiments on development section 1  we choose the best classifiers and apply them for semantic argument classification on test section 1. the baseline classification accuracy for section 1 is 1%  with the use of only baseline features. subtree voting improves the accuracy to 1%  representing a relative error reduction of 1%. the detailed scores are in table 1.
1 related work
to overcome the inadequate assumption of semantic argument independence during classification   punyakanok et al.  1  employed integer programming to impose global constraints in semantic role labeling. these global constraints can be viewed as an introduction of semantic context knowledge  e.g.  no argument classes should be duplicated. however  these constraints are rule-based and may not always be applicable due to exceptions. our proposed approach can be viewed as inducing the constraints via statistical learning.
　the methods proposed in  hacioglu et al.  1; kouchnir  1; park et al.  1  used features such as the phrase type and head word of neighboring syntactic chunks. experiments in  pradhan et al.  1; fleischman et al.  1; kwon et al.  1  used the semantic role labels of previous semantic arguments as dynamic context features and showed improved accuracy. this demonstrates the utility of limited semantic context features. the semantic context features proposed in this paper capture more extensively the interdependence among arguments.
　our proposed subtree ordering can be viewed as a generalization of the two-level incremental approach of  lim et al.  1  in processing arguments  in which a sentence is divided into immediate clause and upper clauses.
1 conclusion
in this paper  we successfully used additional features of the neighboring semantic arguments in determining the class of the current semantic argument. our experimentalresults have shown significant improvement in the accuracy of semantic argument classification after exploiting argument interdependence. argument classification accuracy on the standard section 1 test set yields a relative error reduction of 1%.
acknowledgements
we thank taku kudo and sameer pradhan for their help in answering our questions related to the work in this paper.
