shape rfprfsfntatton in parallel systems 
	geoffrey f. 	hinton 
mfc applied psychology unit cambridge  fngland 

apstract 
　　there has been a recent revival of interest in parallel systems in which computation is performed by excitatory and i n h i b i t o r y interactions within a network of r e l a t i v e l y simple  neuronlike units  1 1   . at the early stages of visual processing  individual units can represent hypotheses about how small local fragments of the visual input should be i n t e r p r e t e d   and interactions between units can encode knowledge about the constraints between local i n t e r p r e t a t i o n s . higher up in the visual system  the representational issues are more complex. this paper considers the d i f f i c u l t i e s involved in representing shapes in p a r a l l e l systems  and suggests ways of overcoming them. in doing so  it provides a mechanism for shape perception and visual a t t e n t i o n which allows a novel i n t e r p r e t a t i o n of the gestalt slogan that the whole is more than the sum of i t s parts. 
	1 	introduction 
　　the most notorious f a i l u r e of the gestalt psychologists was t h e i r i n a b i l i t y to specify a plausible mechanism to explain the many important and i n s i g h t f u l perceptual phenomena that they discovered. cognitive science has rediscovered many of the phenomena. can it do any better with 
the mechanism1 we have the advantage of modern d i g i t a l computers which can simulate any mechanism we care to invent  but what kind of mechanism should we be looking for  is the d i g i t a l computer i t s e l f a good analogy  or should we be investigating the computational properties of processes occuring in p a r a l l e l systems of r i c h l y interconnected  neuronlike units  
the central idea of gestalt psychology is the 
gestalt i t s e l f - a coherent organisation of the parts of a figure into a perceptual whole which transcends the individual parts. the central idea of t h i s paper is that the mechanism underlying the formation of a gestalt is a set of competitive and cooperative interactions within a network of simple u n i t s . the interactions r e s u l t 
in a p a r t i c u l a r subset of the units becoming active and suppressing the rest. the active subset is the internal representation of the current gestalt. 
　　this is not a new idea and it has many problems. how does the gestalt represent shape independently of size  p o s i t i o n   and o r i e n t a t i o n 1 how are successive g e s t a l t s integrated in the temporal flow of perception 1 how is the gestalt for the whole related to the gestalts for i t s parts  how  exactly  are gestalts encoded as a c t i v i t y in the units of a parallel system1 before discussing these issues  t shall b r i e f l y describe the h i s t o r i c a l ups and downs of parallel models in computer v i s i o n   and also give a recent example of a parallel model that i l l u s t r a t e s many of the problems. 
1 parallel models in computer vision 
　　there is a long t r a d i t i o n of attempts to build neural models of visual perception. much of the early work was unconvincing because it was based on an inadequate analysis of what a visual system must do. it ignored the main problems l i k e segmentation or generating a 1-d representation from a  -p image. the inadequacies of the existing neural models led people in a r t i f i c i a l intelligence to abandon them and to concentrate on the problem of programming a visual system on a conventional d i g i t a l computer. 
　　work in computer vision has now given us a much better grasp of what the real problems are in getting from i n t e n s i t y arrays to the kind of 
articulated internal representations of 1-d scenes that are needed for object recognition and manipulation. we have l e a r n t   f o r example  that segmenting a real scene into objects is hard  and that it cannot be done properly by simply looking for edges or growing regions in the raw i n t e n s i t y array produced by a camera. 
　　for a time  it appeared that a major problem was to develop complex heterarchical control structures that would allow high-level knowledge about objects to aid the low-level i n t e r p r e t a t i o n of the i n t e n s i t y array  1   . this view has now been largely superceeded by two related developments. f i r s t   people in computer vision who studied real images rather than l i n e drawings rediscovered the gibsonian point that there is a geat deal of available information in the i n t e n s i t y array  especially if sources of information l i k e stereo and optical flow are considered. second  david marr   1   emphasised 

that low-level visual processing in the brain 
when a string of l e t t e r s is presented very 
involves an enormous amount of parallel b r i e f l y   	it is easier to recognise the l e t t e r s 
computation at or near the level of the i n t e n s i t y if they form a word than if if they form a 
array. so techniques designed to economise on the nonsense s t r i n g . rumelhart and mcclelland 
number of computational operations requiresd in a 
 henceforth ram  propose a model in which many 
sequential computer may be a poor guide to simple  neuronlike units interact to produce t h i s understanding how natural visual systems work. 
effect  1 . for s i m p l i c i t y   they r e s t r i c t themselves to a three-layered system  and they 
the problem of segmenting a scene into objects omit feedback from the middle layer to the 
is a testing ground for these new developments. bottom one  see fig. 1 . before segmentation occurs  it appears that a great deal of   l o w - l e v e l   visual processing must be done. the purpose of this processing is to i n t e r p r e t the i n t e n s i t i e s of each pixel in the image in terms of the local surface o r i e n t a t i o n   reflectance  and depth of the piece of 1-d surface thet is imaged in the p i x e l . these i n t r i n s i c properties of the surface are much more 
useful for segmentation than the raw intensity data  because they distinguish intensity changes caused by d i s c o n t i n u i t i e s in depth from similar i n t e n s i t y changes caused by surface markings or 
sharp changes in surface o r i e n t a t i o n . 
　　some of the algorithms that are used for recovering 	i n t r i n s i c properties of surfaces from local 	i n t e n s i t i e s   1   or from stereo pairs of images 	  	have a very interesting property. 
they involve local computations that can be figure 1 performed in networks of interconnected simple 
u n i t s . thus  f o r low-level processing  computer 	only a few of the units are shown for vision is moving back to models in which 	each of the three layers. 	i n h i b i t o r y 
processing occurs in pseudo-neural networks. the interactions are marked with a cross. current models d i f f e r from e a r l i e r neural-net a single l i n e is used to stand for conn-
models in several ways. they are rigorously ections in both d i r e c t i o n s . s p e c i f i e d   and the d e t a i l s of the computation are t y p i c a l l y determined by careful analyses of the 
the bottom layer contains  stroke  units that 
physics of the image formation process  and of detect local features l i k e the individual 
the general 	properties of the physical world that 	strokes of l e t t e r s in specific positions within 
determine how the properties of one piece of 	the word. a u n i t in this layer might  f o r surface constrain the probable properties of 	example  be activated if there is a v e r t i c a l 
neighbouring 	pieces 	. 	stroke that could be the r i g h t hand v e r t i c a l of 
                                                                     an h  m  or n in the second-letter position this paper discusses the problems involved in within the word. fach l e t t e r unit receives extending t h i s kind of parallel computation to excitatory input from a l l the stroke units that higher levels of visual perception l i k e shape f i t it and also i n h i b i t o r y input from stroke 
recognition which was the central preoccupation units in the same position that do not f i t i t . of the e a r l i e r generation of neural models l i k e perceptrons   1   . these problems are often units in the top layer correspond to specific ignored or brushed aside by parallel modelb of words. each word unit receives excitatory inputs 
shape recognition 1 ike recognition cones |1j or from a l l the l e t t e r units that f i t it and hierarchical relaxation . they must be i n h i b i t o r y inputs from the r e s t . word units also solved before t h i s kind of model can be accepted provide excitatory and i n h i b i t o r y feedback to as a plausible account of human shape perception. the l e t t e r u n i t s . in addition to these 
interactions between layers  there are i n h i b i t o r y interactions between a l l pairs of word units and between those pairs of l e t t e r units 
   iii an example of a parallfl system that correspond to a l t e r n a t i v e l e t t e r s at the same position within a word. to i l l u s t r a t e the kind of parallel system that 
1 w i l l be discussing  t have chosen a recent the a c t i v i t y level of a unit is a continuous model of word perception. the model is limited to variable constrained to l i e between two l i m i t s   the perception of b r i e f l y presented four l e t t e r and the precise rules for the excitatory and 
words  but it works  it f i t s the psychological i n h i b i t o r y interactions and for the thresholds data w e l l   and i t s l i m i t a t i o n s provide a good are quite complex. they are chosen so that when s t a r t i n g point for discussing the problems that the stroke units are activated as they would be 
more general systems of t h i s type w i l l have to 	by a v i s u a l l y presented word  the system s e t t l e s 
overcome. 	down into a stable state in which the appropriate 
word and l e t t e r units are highly a c t i v e   and the 
1 

inappropriate unite are suppressed. 
　　precise rules for the interactions can be chosen bo that the model is in good agreement with experimental data for a wide range of experiments. it can  f o r example predict the way in which the p r o b a b i l i t y of c o r r e c t l y reporting a p a r t i c u l a r l e t t e r depends on the onset and offset times of the other l e t t e r s . 
iv problems for parallel models of shape perception 
　　the r & m model has several interesting l i m i t a t i o n s which are characteristic of a whole class of models in which shape perception is performed by p a r a l l e l computation in a network of r e l a t i v e l y simple u n i t s : 
　　1. the model makes no provision for variations in the size  p o s i t i o n   or o r i e n t a t i o n of the word. it i m p l i c i t l y assumes that the input is somehow normalised so that the actual size  p o s i t i o n   and orientation of the word do not affect which of the stroke units are activated by the input. to put it another way  a c t i v a t i o n of a p a r t i c u l a r stroke unit represents the existence of a stroke of a p a r t i c u l a r type in a p a r t i c u l a r position r e l a t i v e to the whole word. at the lowest levels of the visual system  however  it is the p o s i t i o n   s i z e   and orientation of features r e l a t i v e to the retina that determines 
which units are activated. how to transform from features r e l a t i v e to the retina to features r e l a t i v e to the whole word is a major problem. 
　　1. the gestalt for a whole word is implemented as a pattern of a c t i v i t y in which the active stroke  l e t t e r   and word units a l l support one another and suppress the r e s t . to perceive another word  a d i f f e r e n t pattern of a c t i v i t y must emerge in the very same set of u n i t s   so the representation of the previous word must be wiped out. this makes it hard to see how successively perceived gestalts can be integrated into higher level wholes   1   . the only way to save the p r i n c i p l e that d i f f e r e n t gestalts are implemented as a l t e r n a t i v e patterns of a c t i v i t y in the very same set of u n i t s   is to introduce some kind of spatial working memory which keeps a compact record of recent gestalts separately from the apparatus that is used for forming gestalts. the contents of t h i s working memory presumably act as a context that influences the formation of new gestalts  and in extreme cases allows a new gestalt to be formed purely on the basis of the contents of working memory without any f u r t h e r perceptual input  as happens when people  see  a whole object a f t e r examining it by moving a small peephole over i t s various p a r t s   . a comprehensive p a r a l l e l model needs to specify how spatial working memory is implemented with neuronlike u n i t s   and how the contents of working memory influence the formation of new gestalts. 
　　j. the ram model requires a separate unit for each possible relationship of a stroke or l e t t e r to the whole word.  this duplication of feature units over a l l discriminable relationships requires a l o t of u n i t s . it is not too bad in the case of word perception where the number of possible positions of a l e t t e r within a word is small and the number of l e t t e r types is also small  but for other kinds of shape perception it could prove very expensive to use a d i f f e r e n t unit for each possible r e l a t i o n of a feature type to the whole object. the kind of model being proposed would be more plausible if there was some encoding scheme which achieved the effect of having separate units for each possible r e l a t i o n of a feature to the whole without requiring as many units as this seems to imply. 
　　in most simulations  the number of units is not a problem  because only a very small f r a c t i o n of the possible features are present at once  and 
they can be represented by data-structures containing numerical values that code the r e l a t i o n of the feature to the frame of reference. the interactions between feature representations can be implemented by using a general procedure which takes these numerical values into account. unfortunately  t h i s way of coping with the huge number of possible features r e l i e s on the a b i l i t y of the d i g i t a l computer to perform arithmetic  and it therefore hides a very real problem for t r u l y p a r a l l e l systems. 
　　in a network of neuronlike u n i t s   the interactions between features are achieved by d i r e c t connections  1 ' rather than by repeated application of a single parameterised procedure that determines the effect of one feature on another as a function of the numerical parameters of the two features. but it is the use of a single general procedure that enables a simulation program to avoid keeping datastructures for a l l the possible but currently absent features. if a l l the required interactions between features are coded by connection strengths between hardware u n i t s   rather than by a general procedures  it appears that a l l the units for a l l possible features must be present a l l the time. so how can we avoid having a very large number of units for each type of feature  
　　these three problems - normalisation  integration of successive gestalts  and e f f i c i e n t encoding of r e l a t i v e features are the topics of the rest of t h i s paper. 
v viewpoint and shape constancy 
　　we see an object from d i f f e r e n t viewpoints on d i f f e r e n t occasions. on each occasion it has a d i f f e r e n t r e t i n a l image  and yet we generally recognise it as having the same shape. to do t h i s   we have to cope with two quite d i f f e r e n t d i f f i c u l t i e s . f i r s t   parts of an object may be hidden or p a r t i a l l y hidden due to self-occlusion or occlusion by other objects. so we must be able to recognise the object from the subset of i t s parts that is v i s i b l e and their i n t e r r e l a t i o n s . second  the metrical properties of the parts and relationships that are v i s i b l e in the image depend on the viewpoint. the size  o r i e n t a t i o n   and position of an edge in the image depends as much on the viewpoint as on the properties of the corresponding edge in the external object. i shall focus on the second of these d i f f i c u l t i e s . 
　　a r t i f i c i a l intelligence has been dominated by a p a r t i c u l a r approach to these problems that can be traced back to roberts  and is probablymost widely known in the theory of shape representation proposed by minsky in his frames paper   l 1   . the v a r i a t i o n s in the metrical properties of the images of parts of an object are handled by using   t o p o l o g i c a l   categories. i f   for example  an object has a f u l l y v i s i b l e f l a t surface with three straight sides  then i t s image w i l l contain a triangular region. the shape of the triangle in the image depends on the precise viewpoint  but the fact that it is a triangle does not. so what is meant by  topological  in t h i s context is not the usual mathematical sense  invariant under any continuous transformation   but the somewhat stronger property of being invariant under p r o j e c t i o n   and hence not affected by viewpoint. relationships between the d i f f e r e n t parts of an image are likewise handled by using discrete category labels l i k e  connected t o     or  above  or  behind . again these categories are t y p i c a l l y unaffected by small changes in viewpoint. 
　　by using categorical labels for parts and their relationships  an image can be reduced to a relational network that is then matched against stored models. since r e l a t i o n a l labels l i k e  behind  are r e l a t i v e to the viewer  and since d i f f e r e n t topological features are v i s i b l e from d i f f e r e n t viewpoints  several d i f f e r e n t models are t y p i c a l l y needed for each object. the advantage of this approach is that the great wealth of metrical information in an image is reduced to a compact description which can be 
matched against s i m i l a r l y compact btored representations. i t s disadvantage is that this reduction of information faisb to u t i l i s e a powerful constraint on the interpretation of an image -- the single viewpoint constraint. 
　　the relationship between an object and the viewer determines how each part of the object appears in the image. conversely  when part of an image is interpreted as depicting part of an object  this puts constraints on the relationship between the object and the viewer. since every r e t i n a l or tv image is formed from exactly one viewpoint  the interpretations assigned to the various parts of an image must agree on what that viewpoint i s . 
　　some computer vision programs  make use of the single viewpoint constraint as a final check on the interpretation of an image. they f i r s t extract a relational network of topological features and use it to suggest a particular 1-d 
model. then they compute the relationship between 
the viewer and the object by using precise 
metrical information about a few points in the image and in the stored 1-d model. f i n a l l y   they use this computed relationship to project the 1-d model back onto the image. the f i t of the projected model with the o r i g i n a l image acts a check on the i n t e r p r e t a t i o n . this approach is rather sensitive to inaccuracies in the image  but it has been refined by  who describe a neat way of discovering the optimal viewpoint  i . e . the one which gives the best overall f i t between the original image and the image produced by projecting the stored 1-d model. 
　　using the single viewpoint constraint as a f i n a l check a f t e r a p a r t i c u l a r 1-d model has been hypothesised is better than not using it at a l l   but it would be more e f f i c i e n t to make use of the constraint to prevent inappropriate 1-d structures from being hypothesised in the f i r s t place. to show how t h i s can be done  i need to introduce the concept of an object-based feature. 
a. 	object-based features 
　　one way of ensuring that the underlying representation of the shape of an object is independent of viewpoint is to impose a canonical frame of reference on the object and to describe the sizes  positions  and orientations of the parts of the object in terms of this object-based frame. this technique allows an object to be described in terms of a constant set of objectbased features and hence to be recognised whatever i t s size  p o s i t i o n   and o r i e n t a t i o n . if a d i f f e r e n t object-based frame is imposed  a d i f f e r e n t set of object-based features w i l l be obtained. this explains why a single object can have several phenomenal shapes. an upright diamond  for example  may also be seen as a t i l t e d square. 
　　a considerable amount of early processing must occur before object-based features are extracted  because an object must be segmented out from the rest of the image before a frame of reference can be imposed on i t . in normal circumstances  the problem of getting from a 1-d image to a 1-d representation may be solved by this early processing before segmentation occurs and hence before object-based features are extracted. put simply getting 1-d features does not solve the problem of shape constancy. the 1-d features generated by early processing are r e t i n a based. in other words  t h e i r sizes  positions and orientations are defined r e l a t i v e to the frame of reference of the retina  or camera . if the viewpoint is changed  the 1-d retina-based features produced by an object also change  so they do not constitute a shape representation. 
　　the relationship between the imposed objectbased frame and the viewer determines the optical mapping from features of the object to features on the r e t i n a . hence an internal representation of this relationship can be used to govern the mapping from retina-based to object-based 
features  see fig. 1 . each possible viewpoint 

specifies a p a r t i c u l a r set of pairings between retina-based and object-based features. conversely  each consistent set of pairings specifies exactly one viewpoint  r e t a i l s of one possible scheme for implementing the structure shown in fig. 1 in a network of simple units are given in  

　　one interesting aspect of t h i s way of achieving shape constancy is that it requires an extension to the normal way of thinking about the global structuring of parallel systems. instead of allowing groups or layers of units to interact d i r e c t l y with other groups or layers  we have introduced a three-way i n t e r a c t i o n in which a c t i v i t y in one group controls the way in which two other groups i n t e r a c t . the idea of a 
variable mapping between feature sets recurs l a t e r . again  the feature sets involved are features r e l a t i v e to d i f f e r e n t frames of reference  and the mapping is controlled by a representation of the spatial relationship between the two reference frames. 
	vi hierarchical 	structural 	descriptions 
　　so far  i have been assuming that people only impose one object-based frame of reference at a time. this appears to c o n f l i c t with the widely 
held view tha.t people use hierarchical structural descriptions in which there is a node for each object that is linked to lower-level nodes for i t s parts. these lower-level nodes  in t u r n   are linked to nodes for their parts  and so on u n t i l a level of p r i m i t i v e e n t i t i e s l i k e edge segments is reached. each node in a structural description hab i t s own associated object-based frame of reference  and each l i n k between two nodes is labelled with the spatial relationship between their two object-based frames  1  . the great value of hierarchical structural descriptions as spatial representations is demonstrated by t h e i r use in computer programs for graphics  visual recognition  s p a t i a l manipulation  and spatial reasoning with innaccurate data . 
　　structural descriptions seem to explain many interesting effects in human perception and imagery . however  there is l i t t l e evidence that the whole of a complex structural description is a c t i v e l y represented at the same time. it may well be that our attention f l i t s between levels and that at each moment  we only focus on one node  i.e we impose the objectbased frame appropriate for this node and form a gestalt for i t . this sequential theory  raises several problems: how can there be a gestalt for the whole without gestal ts for the parts also being present  and how can successively perceived 
g e s t a l t s be integrated into a larger wholes1 
　　before answering these questions t need to correct the common misapprehension that a hierarchy of active object-based features is equivalent t o   or is an implementat ion of  a structural description. 
a structural rescriptions 	and 	feature 	hierarchies 
　　one important difference between a hierarchical structural description and a hierarchy of active object-based feature units is that each l i n k between nodes in the structural description is labelled with an e x p l i c i t spatial r e l a t i o n s h i p   whereas there are no e x p l i c i t representations of the spatial relationships between the various object-based features. an object-based feature unit is activated by the combination of a particular feature type with a p a r t i c u l a r relationship to the global objectbased frame of reference. the type of a feature and i t s relationship to the global reference frame are not separately encoded. this means that higher-level feature units can be activated d i r e c t l y by combinations of lower-level ones. they do not need to check the relationships between these lower-level features  because the relationships are i m p l i c i t l y encoded by which of the lower-level units are active. 
　　the absence of e x p l i c i t l y represented spatial relationships may seem like a rather minor point  but it allows hierarchies of object-based features to avoid the computational complexities of graph matching. the cost  of course  is that for each type of feature  there must be a separate unit for each discriminable relationship of a feature of this type to the global objectbased reference frame. the duplication of objectbased units of a given type for a l l different positions  o r i e n t a t i o n s   and sizes can be viewed as a way of using parallel hardware to avoid the graph-matching problem by avoiding representations of relationships that are 
separate from the things being related. 
	vit 	vholfs anp parts 
　　the gestalt psychologists were fond of saying that the whole is more than the sum of i t s parts. most information processing theories have 

interpreted t h i s slogan to mean that in a d d i t i o n to the representations of the p a r t s   there is a h i g h e r - l e v e l representation for the whole that is separate from  but connected t o   the representations f o r the parts  as in a h i e r a r c h i c a l s t r u c t u r a l d e s c r i p t i o n   . there i s   however  a far more radical i n t e r p r e t a t i o n of the gestalt siogan: when we attend to a whole we do not see i t s parts as wholes because the representation of the whole does not in any way involve or require the representations of the parts as wholes. when a part is seen as a constituent of a l a r g e r whole it is given a quite d i f f e r e n t i n t e r n a l representation from the one it has when it is seen as a whole in i t s own r i g h t . 
　　the view that there are two quite d i f f e r e n t ways of representing an o b j e c t   as a whole or as a constituent of a larger whole  is a s u r p r i s i n g reoult of considering a problem that is peculiar to p a r a l l e l systems: how is the representation of a shape related to the representations of the p a r t i c u l a r parameter values   e . g . i t s size and position  that d i s t i n g u i s h d i f f e r e n t instances of the same shape. in a conventional computer  t h i s is not a problem because a d a t a - s t r u c t u r e can be created for the instance containing separate f i e l d s for the shape and for each parameter value. the i n a p p l i c a b i l i t y of t h i s method to p a r a l l e l systems has already been discussed at the end of section iv. 
　　in a p a r a l l e l system l i k e the b r a i n   there appear to be two main ways of r e l a t i n g the representation of a shape to the representations of the parameter values that d i s t i n g u i s h d i f f e r e n t instances of the shape. if only one instance is represented at a time  the values of properties of the instance  l i k e i t s size and p o s i t i o n   can be associated with the shape of the instance by simply a c t i v a t i n g separate representations for the shape and for each of i t s s p e c i f i c property values a l l at the same time. the only thing that binds the separate representations together is t h e i r simultaneous a c t i v a t i o n . this method has the great advantage that if d i f f e r e n t instances of the same shape are presented on d i f f e r e n t occasions  the very same set of active u n i t s w i l l be used to encode the shape information. when an object is seen as a g e s t a l t   simultaneous a c t i v a t i o n can be used to bind a representation of i t s shape to separate representations of properties l i k e i t s size and posi t i o n . 
　　the method of simultaneity has the advantage that the very same representation of the shape is a c t i v e whatever the values of the other p r o p e r t i e s . so t h i s representation e x p l i c i t l y captures what it is that a l l instances of the same shape have in common  and it therefore explains how learnt associations l i k e the name of the shape can be generalised from one instance to other instances with d i f f e r e n t s i z e s   p o s i t i o n s   and o r i e n t a t i o n s . unfortunately  the method of s i m u l t a n e i t y has the disadvantage that it w i l l not work if more than one instance must be represented at a time  and that is a major motivation for the  one gestalt at a time  
p r i n c i p l e . i f   f o r example  the representations for   l a r g e       c i r c l e       s m a l l     and  square  are a l l active at once  mere s i m u l t a n e i t y cannot indicate which size goes with which shape. 
　　the second method of binding shapes to t h e i r property values involves using multi-dimensional u n i t s   each of which responds to a conjunction of a p a r t i c u l a r shape with a p a r t i c u l a r set of property values. this kind of representation is used in the ram model at the l e t t e r l e v e l . for each combination of a p a r t i c u l a r l e t t e r with a p a r t i c u l a r position w i t h i n the word  there is a p a r t i c u l a r dedicated u n i t . this method allows many instances to be represented at the same time  but it requires a large number of u n i t s   
and by coding d i f f e r e n t instances of the same shape as a c t i v i t y in d i f f e r e n t u n i t s   it f a i l s to capture what is common to e l l the instances of the shape. for example  in the ram model the l e t t e r h is encoded quite d i f f e r e n t l y in the two words fish and chip. this d i f f e r e n c e   however  is a p o s i t i v e advantage because it allows the two instances of the h to have quite d i f f e r e n t e f f e c t s at the word l e v e l . one supports the word fish and the other supports chip. thus m u l t i dimensional coding allows the e f f e c t s of d i f f e r e n t instances of the same shape to be t a i l o r e d to the p a r t i c u l a r property values of the instance   r e l a t i v e to the global object-based frame  . this is the primary motivation f o r thinking that when instances are perceived as constituents of a gestalt they are encoded by multi-dimensional u n i t s . 
　　to summarize  there are two quite d i f f e r e n t ways of binding together the shape and other properties of a p a r t i c u l a r instance in a network of neuronlike u n i t s . when an instance is perceived as a gestalt  the method of s i m u l t a n e i t y can be used. this allows the very same a c t i v e u n i t s to be used to represent the shape of an instance whatever i t s other p r o p e r t i e s . when an instance is seen as a constituent of a larger gestalt  however  the multi-dimensional method is used. this allows many constituents to be coded at once  and it allows the e f f e c t s of each constituent to depend on i t s p a r t i c u l a r parameter values r e l a t i v e to the whole. the representation of an instance when it is seen as a gestalt is therefore quite 
d i f f e r e n t from i t s representation when it is seen as a constituent of some l a r g e r whole. the gestalt f o r the whole does not in any way involve the gestalts for i t s p a r t s . 
	viii 	spatial working memory 
　　if we accept the p r i n c i p l e of one gestalt and one object-based frame at a time  there is a serious problem of piecing together successive g e s t a l t s . this problem is at i t s most severe when the parts of an object are observed sequentially through a peephole  and a new gestalt f o r the whole object is formed from these fragmentary glimpses. 
the r o l e of the hierarchy of object-based 

feature units is to allow a gestalt to be formed. once this has been done  a more compact record of the shape of the gestalt and of i t s else  position and orientation can be kept in the form of activity in a different set of hardware units which i shall call the  scene-buffer . a number of these records may be accumulated in the scenebuffer  and they can act as a context which influences the formation of new gestalts from the perceptual input. i f   for example  one part of an object has been seen as a gestalt in its own right  the corresponding record in the scene buffer will facilitate certain of the objectbased feature units when the gestalt for the whole object is formed. 
　　the position  orientation and size of a gestalt must be represented relative to some frame of reference. one possibility is the retinal frame of reference. the relation of the gestalt to the retinal frame is needed anyway to determine the mapping from retina-based to objectbased features. the retinal frame  however  is not very useful for the perceptual integration of gestalts formed at different times because the retina moves around in the world. what is needed is a stable contextual frame of reference defined by the scene  this argument is elaborated in 
. 
the combination of the shape of a gestalt and its relation to the scene can be represented by activating a particular  scene-based  feature unit. records of many different gestalts can be stored at the same time provided the units in the scene-buffer use the multi-dimensional method for binding the parameters of a gestalt to its shape. 
　　the mapping from the higher object-based features to the scene-based features can be handled by just the same kind of mapping apparatus as was used for relating retina-based and object-based features. 1y allowing the mapping to work in both directions  it is possible to implement the contextual effects of existing scene-based features on the creation of new gestalts. pig. 1 summarises the various sets of features that have been invoked and the interactions between them. 

	ix encoding 	multi-dimensional 	features 
　　if variations in size  position  and orientation are taken into account  the number of possible features is enormous. the relationship of a 1-d feature of a particular type to a frame of reference can vary along 1 dimensions  1 for position  1 for orientation  1 for size . so if there are  say  1 discriminable values along each dimension  there are 1 possible particular features. is there any way of achieving the same accuracy with less united 
　　in information theoretic terms  it is very inefficient to have a unit for each possible feature if only a very small fraction of the possible features are present at any one time. it would be much more efficient to use an encoding in which a much larger fraction of the units were active at any moment. this can be done if we abandon the naive idea that each specific feature is represented by activity in exactly one unit. instead each unit can be more coarsely tuned so that it is activated by a range of possible features  and the ranges of different unite can be made to overlap so that each feature activates many different units. the representation of a particular feature then becomes a pattern of activity in many units  and similar features are represented by similar patterns of activity. even though each unit is coarsely tuned and therefore rather imprecise about the exact parameters of the feature that activated i t   the whole set of 
units activated by a particular feature codes the parameters of the feature very accurately. to get an idea of the efficiency of this  coarse-coding  scheme as compared with the naive method in which each discriminable feature is coded by i t s own unit  we need to jump into hyperspace. 
　　for a given type of feature  the possible relations to a frame of reference form a sevendimensional space. fach particular feature corresponds to a point in this space. the naive encoding is equivalent to dividing the space into small  non-overlapping zones  and using one unit for each zone. the coarse-coding scheme divides the space into larger  overlapping zones. for simplicity  i shall assume that the zones are hyperspheres  that their centers have a uniform random distribution throughout the space  and that all the zones used by a given encoding scheme have the same radius. what we are interested in is how accurately a feature is represented as a function of the radius of the zones. is it better to have large zones with each feature point falling within many zones and hence being coded by activity in many units  or is it better to have the same number of smaller zones so that a feature is represented by activity in fewer but more finely tuned units  
   one way of expressing the accuracy with which the parameters of a particular feature are 
encoded is to ask what the probability is that two similar features  presented on different occasions  will receive different encodings. for 
1 

the encodings to be different  there must be at 	hard to turn this argument into a formal proof least one zone that contains one feature point 	because the extent by which r must exceed s to 
and not the other. if the zones have a radius of 	make the solid area in fig. 1 negligible depends 
r  then the centres of a l l the zones that contain 	on the dimensionality of the space . 
a given point fall within a hypersphere of 
radius r centered on that point. so for points p 	this unexpected result makes it much more 
and 1 in fig. 1 to receive different encodings  d i f f i c u l t to dismiss models because they require there must be at least one zone whose center too many units. by encoding features as patterns falls in one of the hypersheres around p and 1 of activty in many coarsely tuned units  it is 
but not in the other  i.e. there must be a zone 	possible to have many more discriminable 
with its center in one of the two shaded 	features than there are units. similarly  the 
 hypercrescents . 	representations of the mappings between 
reference frames can be economically encoded by 
using coarse-coding in the space of possible mappings. 
　　it is probably no accident that sensory neurons are typically much more broadly tuned 
than might be expected from the accuracy of an 
animal s perception. far from causing inaccuracy  this broad tuning is a way of increasing the 
accuracy of a representation given a fixed number of available units. 
   apart from boundary effects  there are two factors that set upper limits on the sizes of the zones. if many similar features occur at the same 
	figure 1 	time  their encodings may overlap. this is not 
fatal if the activity level of a unit reflects the number of features that fall within its zone  
   the probability of there being at least one but generally nearby features w i l l affect each zone center within the hypercrescents is others encodings. so zone sizes should be chosen completely determined by the expected number of so that not more than a few features f a l l within zone centers within the hypercrescents. this a zone at any one time. thus the value of the 
number is the product of the volume of the coarse-coding technique relies on the features hypercrescents and the density of zone centers being relatively sparse. 
throughout the space. as the volume of the 
hypercrescents is increased  the density of zone the other limit on zone sizes stems from the centers can be decreased proportionately without fact that the representation of a feature must be affecting the probability that the two features used to affect other representations. there is no receive different encodings. hence  the number  point using coarse-coding if the features have to n r   of zones of radius r that is required to be recoded as activity in finely tuned units achieve a given accuracy is inversely before they can have the appropriate effects on proportional to the volume of the hypercrescents. other representations. the details of this 
argument are complex  and there is not space for 
　　if the separation of the features under them here  but the conclusion is that coarseconsideration is small compared with the zone coding can be used provided the required effects radius  then the solid areas in fig. 1 are of a feature are approximately the average of the required effects of its neighbours. at a fine negligible and  in two-dimensional space  the enough scale this is nearly always true. the area of each crescent is approximately the same scale at which it breaks down determines an upper as for a rectangle of height 1r and width s  limit on allowable zone sizes. because the horizontal distance between the sides 
of a crescent is exactly s except at the very top 
and bottom. so in 1-d the area of a crescent is x conclusion proportional to r. in 1-d  the two surfaces bounding the 1-d  crescent  again have a this paper has explored the issues that arise separation of s in the direction of the line from the assumption that perceiving a shape as a joining the two feature points. so the 1-d whole involves a cooperative computation in which  crescent  can be divided into many narrow rods of a stable pattern of activity emerges in a network length s. these rods can be rearranged into a of units as a result of the external input and 
disk in same way as the horizontal strips are 	the interactions between the units. 
rearranged into a rectangle in the 1-d case. so 
the volume of each 1-d crescent is the same as shape representations that are independent of that of a disk of thickness s and radius r. this viewpoint can be achieved by using two different is proportional to r1 . in k dimensions  each sets of features  one relative to the retina and 
hypercrescent has a volume of s times the k-1 	the other relative to a frame of reference dimensional cross-section  which is the volume of 	imposed on the object. the interactions between a k-1 dimensional hypersphere. hence  in k 	features in the two sets are controlled by a dimensions nr.  * 	1/rk-1 	  provided s  r.   i t is 	representation of the relation between the fremes. 
1 

　　two ways of binding a shape to i t s parameter values   e . g . s i z e   p o s i t i o n   are described. one method can only be used f o r one shape at a time  and so it is s u i t a b l e f o r the g e s t a l t   but not f o r i t s many c o n e t i t u e n t s . 	this leads to the idea that when an object is seen as a constituent of a l a r g e r whole  	it receives a q u i t e d i f f e r e n t i n t e r n a l representation from the one it has when it is seen as a gestalt 	in i t s own r i g h t . 
　　the stable pattern that represents a gestalt can be recoded as a c t i v i t y in a d i f f e r e n t set of scene-based f e a t u r e s   	thus freeing the o b j e c t based 	features for the formation of a new g e s t a l t . this recoding again involves a f l e x i b l e mapping between sets of features r e l a t i v e to d i f f e r e n t frames of reference. 	the scene-based features act as a s p a t i a l working memory which influences the formation of new g e s t a l t s . 
　　f i n a l l y   a coding scheme is presented which allows e f f i c i e n t and accurate encoding of sparse  multi-dimeneional features by using patterns of a c t i v i t y i n coarsely-tuned u n i t s . 
ffffffncfs 
 minsky  m. k - l i n e s : a theory of memory. cognitive science  1  1  1 
 h i n t o n   g. f. a anderson j. a.  eds.  p a r a l l e l 	models of associative memory h i l l s d a l e   nj: fribaum   1. 
 marr p. a poggio t. cooperative computation of stereo d i s p a r i t y . science 1  1  1. 
 barrow  h. g. a tenenbaum  j. m. hecovering i n t r i n s i c scene c h a r a c t e r i s t i c s from images. in a. p. hanson a f. m. piseman  eds.  computer v i s i o n systems. new york: academic press  1. 
  1   s h i r a i   y. a context s e n s i t i v e l i n e f i n d e r f o r recognition of polyhed r a . a r t i f i c i a l i n t e l l i g e n c e   1   1  1. 
 freuder  f. c.  a computer system f o r v i s u a l recognition using a c t i v e knowledge.  ai-tf1  a . i . laboratory  mit  1. 
 marr  p. early processing of v i s u a l i n f o r m a t i o n . p h i l . trans. poy. soc. series b  1  1  1. 
 horn  b. k. p. understanding image i n t e n s i t e s . a r t i f i c i a l i n t e l l i g e n c e   1  1  1. 
 rosenblatt  f. p r i n c i p l e s of neurodynamics. washington p. c.: spartan  1 . 
 uhr  l.   f e c o g n i t i on cones   and some test r e s u l t s ; in a. p. hanson a f. m. piseman  eds.  
computer v i s i o n systems. new york: academic press  1 
  1 davis  l. s. a rosenfeld  a. hierarchical r e l a x a t i o n f o r waveform parsing. in a. f. hanson a f. m. piseman  eds.  computer 
	v i s i o n systems. new york: academic press  	1. 
  1     mcclelland  j. i . a rumelhari  p. f.  an i n t e r a c t i v e a c t i v a t i o n model of the e f f e c t of context in perception: part 1     technical report 1   center f o r human information processing  univ. c a l i f o r n i a   san pi ego  1. 
 fumelhart  p. f. a mcclelland  j. 1 .  an i n t e r a c t i v e a c t i v a t i o n model of the e f f e c t of context in perception: part 1     technical report 1 center f o r human information processing  univ. c a l i f o r n i a   san pi ego  1. 
 feldman  j. a. a connectionist model of visual memory. in  above. 
 hochberg  j. in the mind's eye. in p. n. haber  fd.  contemporary theory and research in visual perception. new york: h o l t   rinehart and winston  1. 
 roberts  l. g. machine perception of threedimensional s o l i d s . in j.t. tippett et . a l .  fds.    optical and e l e c t r o - o p t i c a l information processing. cambridge  ma: mit press   1. 
 minsky  m. a framework f o r representing knowledge. in p. h. winston   e d .     the psychology of computer v i s i o n . new york: mcgraw-hill  1. 
 barrow  h. c.   tenenbaum  j. m.   p o l i o s   p. 
c.   a wolf  h. c.  parametric correspondence and chamfer matching: two new techniques f o r image matching.  in proc. ijcai-1. cambridge  ma  august  1  1 . 
  1   h i n t o n   g. f.  a p a r a l l e l computation that assigns canonical  object-based frames of reference.  this proceedings. 
 	palmer  p. 	f. 	hierarchical s t r u c t u r e in perceptual 	r e p r e s e n t a t i o n . 	cognilive psychology  	1  	1  	1 
 1 j marr  p. a nishihara  h. k. representation and recognition of the s p a t i a l organisation of three-dimensional shapes. proc. roy* soc. series b  1  1  1. 
 newman  w. a sproul 1   p. p r i n c i p l e s of i n t e r a c t i v e computer graphics. new york: mcgraw-hill  1. 
  1   mcpermott  p. 	spatial inferences with ground  metric 	formulas on simple o b j e c t s     research report 1  	computer science pept. yale u n i v e r s i t y   new haven  ct  jan 1. 
 h i n t o n   g. f. some demonstrations of the e f f e c t s of s t r u c t u r a l d e s c r i p t i o n s in mental imagery. cognitive science  1  1  1. 
 h i n t o n   c. f. paper to appear in the proceedings of the 1rd annual conference of the cognitive science society  berkeley  1 

1 
1 

1 

1 







1 

1 

1 

1 

1 

1 

1 

1 

1 













