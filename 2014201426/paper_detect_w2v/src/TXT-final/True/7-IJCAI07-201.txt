
we investigate legal and philosophical notions of privacy in the context of artificial agents. our analysis utilizes a normative account of privacy that defends its value and the extent to which it should be protected: privacy is treated as an interest with moral value  to supplement the legal claim that privacy is a legal right worthy of protection by society and the law. we argue that the fact that the only entity to access my personal data  such as email  is an artificial agent is irrelevant to whether a breach of privacy has occurred. what is relevant are the capacities of the agent: what the agent is both able and empowered to do with that information. we show how concepts of legal agency and attribution of knowledge gained by agents to their principals are crucial to understanding whether a violation of privacy has occurred when artificial agents access users' personal data. as natural language processing and semantic extraction used in artificial agents become increasingly sophisticated  so the corporations that deploy those agents will be more likely to be attributed with knowledge of their users' personal information  thus triggering significant potential legal liabilities.
1	introduction
privacy's philosophical history dates back to aristotle's famous distinction between the public sphere of political activity and the private sphere of domestic life. philosophical debates since then have distinguished between descriptive  what is worthy of being kept private  and prescriptive  what is of normative value in privacy  accounts of privacy. of particular interest in this rich discussion  paul et. al 1; schoeman  1; agre & rotenberg  1  is the normative concept of informational privacy. this notion is increasingly threatened by the colossal amounts of personal information collected as individuals participate in online activities that identify them  and stored in commercial online databases whose access policies may not be sufficiently respectful of individual privacy  or in insecure databases maintained by federal  state  and local governments
 garfinkel  1 .
　concerns over the violation of privacy by technological advances are not new; the first expression of concern in this regard dates back to 1. there is a new wrinkle in the landscape however: the collection and use of information by programs such as google's adsense scanning technology  which when applied to google's gmail system leads to the generation of advertisements  ads  that are relevant to identified keywords in message bodies1. google conducts auctions of each keyword  so that the highest bidders have the right to have their ads linked to that keyword.
　google has sought to assuage concerns over this putative violation of privacy by pointing to the non-involvement of humans in the process. in the coming decades  we may expect increasing use of this technology and artificial agents  such as data-miners and bots  which scan online databases for profiling purposes. and we may see an increasing usage of the so-called google defense: if humans do not read your private communications  your privacy has not been violated. this raises a question for concerned citizens and designers of autonomous artificial agents: to what extent should these agents have access to personal information  does it matter that a human is not reading my email  should it concern us that information we would not entrust to a human willingly  citing privacy concerns  is collected  stored and analyzed by 'a mere program'  we will argue that it should; it is the technical capacities of this program that are relevant.
　the outline of this paper is as follows: in section 1  we argue for privacy as a moral value; in section 1 we introduce the general theory of artificial agents and attribution of knowledge to their principals; in section 1 we address whether google is 'reading my mail'  and in section 1 we inquire into the legal implications for google if that is the case. our conclusions are set out in section 1.
1	the value of privacy
in their seminal 1 paper  the right to privacy   samuel warren and louis brandeis argued that  political  social  and economic changes  and  the right to be let alone  entailed that the law offer privacy protection to individuals. responding to technological changes in the media  such as the advent of photography  warren and brandeis noted the invasion of privacy brought about by release of details pertaining to a person's private life. they argued that a general right to privacy would protect the extent to which one's innermost mental life could be shared with others  afford  peace of mind   and be grounded in a general right of immunity of the person   the right to one's personality   interpretable as protection of an individual's autonomy . while existent us law offered protection-via the fourth amendment-for homes and their interiors against searches  they argued that new  potentially intrusive  technology made it necessary to formalize this protection under the rubric of privacy.
　this formulation of the right to privacy is known as  control over information about oneself ; it says nothing about the identity of the agent gaining control over information. thus  photographs taken by an automated camera mounted outside someone's home entail a loss of privacy even if the photographs had not yet been viewed by humans: the person inside would have had no control over the release of this information. the 'information leakage' would be enough violation of privacy; the violation would take place at the moment the photograph was taken  not when they were viewed. for warren and brandeis  the right to privacy is a moral value worthy of protection under law  with no concessions made to contingent violations.
　to echo warren and brandeis' concerns  three landmark cases established that privacy needed protection from technological invasions. in the first electronic surveillance case  olmstead v. united states  1  the us supreme court ruled that warrants were not necessary in order for federal agents to carry out phone-taps. the court ruled that the fourth amendment only protected against  physical invasions  by law enforcement officers. dissenting from the majority  justice brandeis argued for a reconfigured notion of privacy to accommodate new technology. in 1  the supreme court overruled this decision in deciding katz v. united states1  judging that tapping phone conversations in a public phone booth was a violation of the fourth amendment. the court ruled that there is a  reasonable expectation of privacy  in public spaces:   t he fourth amendment protects people  not places.  what a person  seeks to preserve as private  even in an area accessible to the public  may be constitutionally protected.  finally  in 1  a us military court  citing the katz decision  ruled that an individual has a reasonable expectation of privacy in his private e-mail  even if stored and sent using an online service1. the right to informational privacy then  has been understood as protecting not just against surveillance  monitoring and warrantless searches  but also against appropriation and misuses of one's communications. again  these rulings did not make their judgments contingent upon the nature of the agent that violates a citizen's right to privacy.
　theorizing since then has reflected this concern with informational privacy1 and continues to link the notion of personal autonomy to it.  westin  1  describes privacy as the ability to determine for ourselves when  how  and to what extent information about us is communicated to others; while  parent  1  describes privacy as   the condition of not having undocumented personal information known or possessed by others . common to these analyses is the notion of the loss of autonomy when the agents' privacy is breached; each problematic appropriation of an agent's personal information takes place without his or her consent. westin's analysis raises the issue of autonomous determination of the release of information  while parent notes that information may only be released when the individual has itself documented it publicly. these analyses suggest a moral wrong occurs with the uncontrolled  non-autonomous release of information pertaining to an individual.
　more recently   lessig  1  argues that the right to privacy provides a measure of dignity  and tests our intuitions with a hypothetical situation. the us national security agency  nsa  releases a worm over the internet in an effort to try and find a file missing from their servers. this program enters every us resident's computer and scans its hard disk; if it finds the file  it sends a report to the nsa; if not  it moves on. the program is smart enough to only use idle cpu cycles on each machine. no intrusion then  that bothered me  took place; nothing was disturbed; the contents of my hard disk were not reported to the government  even my illegal collection of copyrighted music . an artificial  not human  agent went through my files  only their names  not their contents ; no human eyes have seen my data; yet our intuitions pertaining to our sense of dignity and personal autonomy are offended  for we were not asked for permission  our belongings were searched  and we were held potentially suspect until searched. privacy law finds its foundations in the intuition that we experience moral injury in situations like those in lessig's example.
　claims for full-blown rights to privacy then  regardless of the nature of the agent engaged in the violation  can be understood as carrying normative weight: dignity is a moral good  as is individual autonomy. understanding informational privacy as an expression of autonomy  michelfelder  1; scanlan  1; corlett  1   and dignity  in addition to viewing it as a constitutional limitation on governmental or corporate power  enables an understanding of it as a moral good  worthy of protection from the assaults of the legal and penal systems  and from changes in technological capacities that increase the potential for the invasive searches of  and the increasing access to  our personal information that artificial agents will come to have. as we will see  when an artificial agent and its principal can be said to 'know' something is crucial in determining whether a breach of privacy has occurred on its accessing our data.
1	attribution of knowledge held by agents
 chopra & white 1  1  argued for a development of legal doctrine  whereby artificial agents are assimilated to human agents for the purposes of entering into contracts and for the purposes of accumulating knowledge that could legally be attributed  or 'imputed'  to their principals  the legal persons  human or corporate  on whose behalf they act . artificial agents  on this analysis  would be akin to slaves under roman law  not legal persons in their own right  but with power to enter into binding arrangements  and receive information  on behalf of their owners  in circumstances where their owners would be bound by those arrangements or that knowledge.
　 chopra & white  1  showed that the law of imputed knowledge  whereby the knowledge of a  human or corporate  agent gained within the scope of the agent's employment is imputed to its principal  does not rest on a presumption that the agent has carried out its duty to inform its principal. rather  they postulate that it is the ability of the agent to convey the requisite information to the principal-that knowledge is ready to hand-that is crucial. they further argue that artificial agents  just like human ones  should be considered to be repositories of legally relevant knowledge on behalf of their principals  a compelling approach when most information held by corporations is in the form of electronic records. they suggest a distinction between electronic records  which are ready-to-hand and should be considered to be part of the knowledge of the corporation whether or not any human agent knows their contents  and paper records which the corporation controlling them cannot be presumed to know the contents of  in the absence of a human or artificial agent that does. attribution then  does not depend on a notional passing of knowledge up the management hierarchy; rather  attribution of knowledge held by an agent to the principal depends on the functions granted to the agent  i.e.  the existence and scope of the agency relationship.
　what of 'horizontal' information barriers  which prevent management from gaining access to the knowledge held by agents lower down the corporate hierarchy  these issues are important in medical situations  where patient confidentiality means that management and others not directly concerned with the patient's clinical care may have no right to particular patients' records. yet the law will attribute doctors' knowledge to an employing hospital or practice  for instance in the context of a medical negligence case. the fact that knowledge is not ready-to-hand to the management does not mean that it is not counted as the corporation's knowledge for legal purposes.
　furthermore  the corporation itself legally is attributed with that knowledge. if  for example  the employer made a misleading public statement about the number of patients it had treated who had had a certain medical condition  it could not plead in its defense its lack of knowledge of its patients' medical conditions. the proper response would be for the employer to establish a system whereby patient statistics-properly anonymized-would be collected and reported accurately. hence  knowledge can be attributed from an agent to a corporate principal even when the agent is under an obligation not to convey the knowledge to other agents of the corporate principal.1
1	is google reading my email 
the launch of gmail was attended by considerable disquiet among commentators to the effect that google's screening methodology amounted to a breach of the user's privacy. one response was that users are free to give up their own privacy  and are asked to do so on a regular basis  in exchange for receiving certain services. however  google's response was instructive: there was no issue of a breach of privacy because humans were not reading the users' mail:1
1. is google reading my email 
   no. google scans the text of gmail messages in order to filter spam and detect viruses  just as all major webmail services do. google...uses this scanning technology to deliver targeted text ads and other related information. this is completely automated and involves no humans.
however  thirty-one worldwide privacy bodies were quick
to point out:1
... a computer system  with its greater storage  memory  and associative ability than a human's  could be just as invasive as a human listening to the communications  if not more so.
we agree with the privacy bodies that the mere fact that humans are not involved is not relevant to either the legal or moral dimensions of google's behavior. however  the limited functionality of the software agents used to process the mail  and the limits on what is done with the information extracted  gives the user sufficient comfort that intimate details are not available for others to peruse. for many users  including these authors  the trade-offs are worthwhile.
　significantly  google does not itself place complete faith in the automated nature of the scanning process:1
all major email services...automatically scan email content for the benefit of users. when email messages are fully protected from unwanted disclosure  the automatic scanning of email does not amount to a violation of privacy.  emphasis added ...  d elivering information gathered through email scanning to a third party would be a violation of privacy. google does not do this. neither email content nor any personal information is ever shared with other parties...
google then  implicitly acknowledges that  however automated the process  if details were forwarded on to third parties  a violation of privacy would occur. thus  google recognizes that the automated nature of the process  while of comfort to users who are grateful their personal messages are not being read by human strangers  is not a defense to the charge of a violation of privacy. their defense is that no onward disclosure takes place. however  the fact that the software agents cannot do anything more with the information extracted than generate advertisements to place alongside those mails is not  by itself  sufficient to dispel the legal and ethical dilemmas at play.
　right now  google's system is able to identify users who have an interest-innocent or otherwise-in terrorism  nazism or child pornography. many people interested in these topics would have innocent motives  whether they are academics  law enforcement officials or curious citizens. but a small but relatively high percentage  compared with the total user group  would have a less innocent interest. information of this type is a valuable commodity in a world gripped by fears of terrorism and internet pedophilia. google was recently ordered by the us district court to hand over anonymized information about urls returned by user searches 1 and it and other online companies have been asked by the us justice department to retain records of
users' search queries for as long as two years.1
　if google were to find itself the subject of a valid subpoena relating to email content  and the court were to find the request not over-broad  it would be of no comfort to users that no human had read their mail. google notes that it is subject to authorized requests for information:1
many of the concerns around gmail have centered on the use of automatic scanning technology to deliver relevant ads and related information....these concerns are misdirected. automatic scanning technology alone does not make it any easier for a government to obtain or access your...private information. ...google does...comply with...search warrants  court orders  or subpoenas seeking account information. these same processes apply to all law-abiding companies.... t he primary protections you have against intrusions by the government are the laws that apply to where you live.  emphasis added 
google's assertion emphasized above is questionable. while the huge gmail databases could be queried under a subpoena using custom-built filters to track down 'bad guys'  gmail's development work is self-evidently eliminating the need to custom-build equivalent filters  and accelerating the development of more sophisticated filters that can build on their functionality.
　so  is google reading my mail  at present  we conclude not: adsense software does not currently appear to possess the semantic analysis capacity that we could call 'reading'. we would argue it knows what we are talking about and in some circumstances that may be compromising enough. but it does not  crucially  appear to know what we are saying and what emotions we are expressing about what we are talking about.
　google could however  continue to refine its software's sophistication  so that the semantic content of the mails being scanned becomes increasingly known to the software

1
 united states v google  inc.  1 f.r.d. 1.
1 http://tinyurl.com/f1q
1
 google inc.  'more on gmail and privacy'  note 1  op. cit.
deployed. its system might categorize mail according to what the mail was about  and which emotion concerning the subject matter of the email was being expressed. advertisers might find this useful. more invasively  google might want to build a profile of users' tastes  habits and characteristics  such as sex  race  religion  income ; advertisers would find that kind of information interesting too. when that technology eventuates  it would be natural to say that google is 'reading' my mail  just as we speak of computers 'knowing' that summer time has started. intentional attributions in the former case are even more plausible than the latter.
1	legal implications for google
even if google could then be said to be 'reading' its users' mail in a loose sense  it would not attain the level of semantic understanding of the mail that a human would. nevertheless  the fact that google has some  if not complete  knowledge of the contents of its users' emails has potential legal implications  which need to be kept in mind by designers of artificial agents.
　firstly  'reading' its users' mail could have legal implications for google under a us and a californian statute relating to wiretapping. the us wiretap act1 criminalizes a person who  intentionally intercepts  any  electronic communication   subject to certain exceptions1  and who subsequently uses or discloses the contents of the electronic communication  having reason to know that the information was obtained in violation of the provision1. it also provides for civil damages for a person whose electronic communication is intercepted  disclosed  or intentionally used in violation of the chapter.1
　it has been suggested  miller  1  that google's deployment of the adsense technology in its gmail service could violate the wiretap act as the scanning of each email on its first opening would constitute an 'interception' for the purposes of the act.1 it could also be argued that its use of the contents of an email by the adsense program would be a use by a person having reason to know that the information was obtained in violation of the provision  contrary to the statute.
　however  there is a specific exception in the wiretap act where  one of the parties to the communication has given prior consent to such interception .1 google could argue that it is protected by the consent that its users give to its terms of use. but  as  miller  1  points out  google's terms of use are made known after the user has signed up to the google account  and its privacy policies  which can be accessed before registration  are not specific on the issue. so  arguably  google is intercepting its users' emails without their consent. nevertheless  it seems that its users are

1
　　 1 usc chapter 1-wire and electronic communications interception and interception of oral communications
1
 1 usc ′ 1  a 
1
 1 usc ′ 1  c  and  d 
1
 1 usc ′ 1 a 
1
united states v councilman  1  1 f.1d 1.
1
 1 usc ′ 1  d 
content to trade-off the loss of privacy suffered for the convenience of a capacious  free online email storage system. implicit consent or consent by conduct might well be found by a court that had to decide the issue. were the issue to become a critical one google could review its registration process to ensure adequate consent was obtained.
　one privacy interest that is not protected by this conclusion  however  is that of the sender of email to a gmail account. unless it is assumed that all senders are aware of the details of google's adsense software  it seems there would be no protection for the sender of an email to a gmail account from having her mail 'read' by google.
　once opened  email retained on the gmail server may1be subject to a separate body of law relating to unauthorized access to stored electronic communications in the facilities of an electronic communications service provider.1  miller  1  argues that google would be in danger of violating this rule. however  even if this body of law is applicable  there are defenses that would be potentially applicable to google where the conduct complained of is authorized by:
  'the person or entity providing a n  ... electronic communications service'; or
  'a user of that service with respect to a communication of or intended for that user'1.
　while  miller  1  argues that the first of these exceptions is too broad  it would seem to be squarely applicable on the law as it stands. furthermore  google could argue that it has the authorization of its users to engage in scanning. on this point  the argument about consent set out above would be equally applicable.
　california penal code ′ 1 establishes expansive protections for  communications   which includes e-mail messages. this provision establishes a criminal offence where any person:
...willfully and without the consent of all parties to the communication  or in any unauthorized manner  reads  or attempts to read  or to learn the contents or meaning of any message  report  or communication while the same is in transit or passing over any wire  line  or cable  or is being sent from  or received at any place within this state; or who uses  or attempts to use  in any manner  or for any purpose  or to communicate in any way  any information so obtained  ...  emphasis added 
central to any argument that google is in violation of the provision is the proposition that google is 'reading or learning the contents or meaning of any message' within gmail.
　on 1rd may 1  the electronic privacy information centre  epic  wrote-on behalf of two other privacy organizations and itself-to california attorney general lokyer arguing that google was in breach of ′1 a .1 we agree with the epic that google should be treated as 'learning the contents' of the mails in the gmail system and therefore in prima facie violation of the statute. further  it appears to be using information so obtained  again in prima facie violation of the statute. if the adsense technology is developed further  google may violate the prohibition against 'reading' its users' mail. the provision raises a host of legal issues that would need to be demonstrated in practice in order to prove a violation on the part of google. for example  whether the email was in 'transit' for the purposes of the provision  and whether senders had consented to the application of adsense technology. in the event  the californian attorney-general failed to give any definitive response to
the allegations therein.1
　leaving aside questions of liability under these particular statutes  there is the issue of potential liability for knowledge that google might gain from users' mail. let us suppose that google's adsense semantic extraction technology continued to be developed. suppose the system becomes aware  not only of what my email is about  what emotion or attitude is being expressed  but starts to model in detail what is being said. such a system could become a kind of 'personal assistant'  managing my diary and automatically answering some emails. in such a situation we would find it completely natural to say the system was 'reading' my mail. but the knowledge gained by such a system might lead google to gain 'unwanted' knowledge.
　suppose  for example  that terrorists detonate a weapon of mass destruction in a major city causing great loss of life  that the terrorists used gmail to plot the attack  and the 'personal assistant' functionality was switched on. let us also suppose  contrary to current fact  that google was subject to a law which required all persons  including companies  to report knowledge of intended terrorism to the authorities.  in some jurisdictions  a person who merely knows of an intended act of treason is required to inform the authorities and commits a crime if she fails to do so; in the us  an ad-
ditional act of concealment is currently required.1 
　in this scenario  on the legal analysis above  google could be attributed with knowledge gained by its agent that a terrorist plot had been planned: a failure to warn the authorities of such a plot could  we maintain  be cause for prosecution of google itself. furthermore  if google failed to issue a warning about a planned terrorist attack  the firm might even be sued in a civil action by the families of the dead  by injured survivors and by owners of damaged property  for breach of its statutory duty to warn the authorities.
　thus  if firms such as google wish to 'read' users' mail  they would  absent shield laws such as are put in place for 'common carriers'  need to establish systems whereby suspicious mails are routinely alerted to the police and other authorities. as in the example of medically confidential information  the fact that the information should not ordinarily1 be shared with employees of google does not mean it can not be legally attributed to google. however  requiring google to have the capacity to warn of possible terrorist offences would require google to re-engineer its systems so as to better suit it to a quasi-law enforcement role.
　we acknowledge that resolution of the policy question whether this would be justified would depend not only on legal notions of attribution of knowledge  but as well on policy and cost-benefit grounds. it might be resolved in legislatures rather than in courts  given the stakes involved. such a fundamental policy question would need to be sensitive to issues such as the costs of building such an alert system  whether building such as system would be effectual  given the ability of terrorists to set up email accounts without such intrusive scanning and their access to strong encryption   and so on. one defensive strategy google might employ would be to design the system in such a way that the 'personal assistant' functionality was exclusively the agent of the user and not of google itself. the law of attribution in cases of dual agency is a very complex area and outside the scope of this paper. we hope to address it in a future work.
1	conclusion
we have a provided a legal and philosophical analysis of issues regarding access to our personal data by artificial agents and its implications for our privacy. after arguing for the moral value of privacy  we pointed out how the concepts of legal agency and attribution of knowledge gained by agents to their principals are crucial to understanding whether a violation of privacy has occurred. designers of artificial agents which access users' personal information or private communications need to be mindful of possible privacy implications: the more sophisticated their systems become  the more likely it is that corporations that deploy those agents will be attributed with knowledge of their users' personal information  possibly triggering significant legal liability. as natural language processing and semantic extraction used in artificial agents becomes increasingly sophisticated  it will be harder to use the google defense; that no humans are involved in 'reading' our email does not mean that our privacy has not been  and can not be  violated.
