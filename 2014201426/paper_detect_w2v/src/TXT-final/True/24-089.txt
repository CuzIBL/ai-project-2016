 
this paper describes an agent architecture and its implementation for situated robot control in field environments. the architecture draws from the ideas of universal plans and subsumption's layered control  producing reaction plans that exploit low-level competences as operators. the architecture has been implemented in an extended version of the gapps/rex situated automata programming language. this language produces synchronous virtual circuits which have been shown to have formal epistemic properties. the resulting architecture exhibits robust task execution  has high-level goal representations  and maintains consistent semantics between agent states and the environment. ongoing experiments using the architecture with two land mobile robots and one undersea mobile robot are described. the robots perform their tasks robustly during normal changes in the task environments. 
1 	i n t r o d u c t i o n 
we are interested in programming robots to carry out tasks robustly in field environments. field environments are those in which events for which the robot has a response can occur unpredictably  and wherein the locations of objects and other agents is usually not known with certainty until the robot is carrying out the required task. we expect the agent to be able to deal with its own mechanical and sensor limitations  e.g.  wheel slippage  limited sensor sampling rates   and with natural changes in the flow of events  e.g.  normally moving obstacles or other agents  transition from day to night . but when confronted with events for which it has no response  e.g.  a meteor shower or runaway train   we expect the agent only to safely cease operations. 
　as researchers began to realize that traditional ai planning techniques produced robot plans which failed in field environments  a number of new approaches to robot control emerged under the general heading of situated reasoning. these approaches stress a tight coupling of sensing and action to deal with changing situations and data uncertainty. two such approaches are reaction plans  schoppers  1  and subsumption  brooks  1 . 
essentially an enumeration of actions to take for all possible preconditions  reaction plans have a strong appeal for those interested in field robots. the ability to retry a subtask in the face of a changing situation  detected through continuous sampling of the environment  promises robust execution of tasks. additionally  such plans can be generated using formal techniques  providing a theoretical basis for plan analysis. yet  for any useful application  it has been shown  ginsberg  1  that such plans  if required to map raw sensor input into primitive actuator output  can quickly become exponentially large. 
　the subsumption approach also has a strong appeal. this is not only because it has been used successfully on actual robots  but also because as higher level competences are developed  the competences of the lower layers of the architecture are retained as default behaviors for unexpected or critical situations. yet the subsumption approach has generally not included room for goal representations to go beyond what is sometimes termed insect intelligence. 
　this paper describes an intelligent agent architecture wherein reaction plans use subsumption competences as operators. the key benefits are that the reaction plans need only map agent states into competences  thus reducing their size  and that the formal goal representation of the reaction plan can augment the insect intelligence of the subsumption competences. in our work we commit to layered control and to the combining of directives between layers. but we do not commit to the original subsumption language  
asynchrony of finite state machines  or the use of inhibition and suppression techniques. thus  the term layered competences is used rather than subsumption for the remainder of this paper. 
　in considering implementing the architecture  we wanted the resulting code to run synchronously. one of the thrusts of our work is to analyze agent operations for safety  bonasso et al.t 1 . if the executing software has guaranteed constant cycle times from sensor input to actuators commands  we can isolate the software operations from sensor and actuator physics for analyzing ranges of safe operations. constant time software requires synchronous operations. we also wanted to insure that the formal semantics of any abstract representations still held in the on-board software. synchronous operations allows for simpler semantics about the agent's most recent perception of the world and the formal rationale for carrying out the next action. 
　the desire for synchronous operations and consistent semantics led us to implement the architecture in the gapps/rex language  kaelbling  1 . the language brings to bear formal semantics about the relationship between an agent's internal states and those of the 

environment  rosenschein and kaelbling  1 . as well  the accompanying robot programming environment can build both the reaction plans and the layered competences of the architecture  while the resulting circuits guarantee constant cycle times. 
1 domains of interest 
we are initially interested in robots carrying out retrieval  delivery and reconnaissance tasks in field environments. these tasks consist of general navigation from the start point to the area of interest  grasping and ungrasping or directed sensing  and then general navigation back to the start point or subsequent sites. though not complex  these tasks are the basis for many jobs robots are expected to carry out in field environments. loading and unloading cargo  explosive ordinance disposal  planetary exploration  aerial tracking of ground phenomena  deep ocean mapping and exploration  all fundamentally consist of retrieval  delivery or reconnaissance tasks. 
　because the architecture does not yet address plan development at runtime  but see other related work   we further assume that the robot can be informed by other agents or humans as to changes in its mission. 
　we have begun experiments with several robots for such tasks as described above  and current results show that the architecture works well under these conditions. 
1 proposed architecture 
as stated above  the architecture consists of reaction plans which use competences for operators. figure 1 shows a sample reaction plan for a delivery task for a one-armed mobile robot in our indoor experiments. the preconditions of the plan are generated by hand for simple plans  or automatically via goal regression for more complex plans. on each pass of the control loop  these preconditions  shown here as a logic vector  are tested and the appropriate action is taken. 
　the numbers to the left show the linear order of subtasks to accomplish the delivery task. task activity commences when a widget appears  at which time the robot obtains the widget to be delivered and locates the receiver. the robot then moves to the receiver and places the widget on the receiver platform. finally  the robot backs away from the receiver and retracts the arm. since the preconditions are checked continuously  the reaction plan provides for robust operations. for example  if the receiver moves during the move-to operation  step 1   the receiver-located precondition will be false  causing the robot to re-acquire the receiver  step 1 . thus  the robot will track the receiver while moving toward it. likewise  if while the robot is raising its arm  step 1   the platform moves under the grasped widget  then the widget will be over the platform and the robot will skip step 1 and execute the place operation of step 1. 
　this plan is sufficient at the given level of detail for delivery tasks with actual robots in field environments only if the operators such as move-to  get-clear and grasp are competent. that is  the operators must be able to deal with variations in the environment as part of their 
1 	robotics 
design  thus unburdening the reaction plan of those considerations. this is the key contribution of this work to the growing body of situated reasoning research. figure 1 shows the concept for the layered competences in the architecture. the figure is notional. for instance  the lowest level perception results could be made available to the highest level reasoning. and there may be more than three layers of competence  though in practice  we have used the three layers shown. 
　there are three hallmarks of these layered competences. the first is the basic trait of the subsumption architecture: higher level competences subsume those of the lower levels. for example  once the robot has a competence to avoid obstacles on the fly  any high-level navigation vector which is generated by  say  a move-to reaction plan operator  will be adjusted to insure avoiding a previously unseen obstacle. this merging of directives  shown by the valve icon in figure 1  can take the form of simple constraints placed on the higher layers by the lower layers or can involve more sophisticated combination algorithms. in our work with an underwater robot  it was sufficient to average the 1d obstacle avoidance vector with the navigation mission vector. in our work with a ground mobile robot we use a combination algorithm based on a template of geometric constraints  slack  1  for robust outdoor navigation. 
　the second hallmark is that the lowest level dictates the smallest cycle time  and higher-level cycles are multiples of that time. our implementation generates synchronous circuits which  at each strobing or tick of the circuit  guarantees outputs for the lowest-level competence. subsequent ticks may produce additional outputs from higher levels in the architecture. this insures that the lower levels can be configured to effect emergency reactions tailored to the fastest problematic events in the environment  and yet those reactions will be blended with higher-level outputs as they become available. 
　the third hallmark is that levels of perception processing roughly match the levels of reactive competence  i.e.  that perception at each level is task-driven. thus  in the implementation  there may be global structures to allow for search efficiency  but task-related perception algorithms  if not individual representations  can exist at each level. for example  in one of our developments  the proposition  aware-p  class-of-things  is used as part of the locate competence  top layer . if the predicate is not true  then the robot's database of objects must be updated via a directed sensor search algorithm. at the lowest layer  for obstacles  the agent becomes aware simply by receiving raw data  such as the signal from a bumper contact switch. 
1 	implementation 
as mentioned before  we have chosen to use the 
gapps/rex robot programming environment for our implementation  since the resulting circuits are constant time and have formal semantics. the architecture dictates a programming methodology as follows. first write gapps goal reduction rules for the invocation of competences. with the rules in figure 1  for example  a hero robot will turn 

	preconditions 	actions 
wia era wig rcl dtr aip wop wip 
retire arm. set wia tof 
get-clear of receiver 
place widget 
get-near receiver 
raise arm 
move-to receiver 
locate receiver 
grasp widget 
position-for-grasp 
stay out of trouble 
t= true  f=false  * = don't care 
wia = widget is available  era = ebow room available 
wig = widget in grasp  rcl = receiver located dtr = distance to receiver   reach distance 
aip = arm in place position  wop = widget over platform 
wip = widget is placed 
comments 
task complete 
so arm can be retracted a simple release so widget win be over platform 
so arm is at platform level arm is oriented in front of robot 
via perception or being informed 
after getting some elbow room or accept from a donor 
default; no plan; survive  energy conservation.etc. 

figure 1. a reaction plan for widget delivery 

figure 1. layered competences 

from the nearest obstacle and move slowly away. figure 1 shows similar rules for a wander operation. 
　after writing these rules  the next step is to write the rex code for the functions that make up the competence execution  such as the  set-avoidance-turn  arg   function and the  moving-slowly  and  no-obstacles  predicates in the example. 
　finally  one builds the reaction plan using the goal expressions in the reduction rules. a simple plan can be built using a prioritization of goals. the gapps  prio-and gl ... gn  tries to satisfy n goals  but failing that tries to satisfy n-1 goals  etc. an example plan to have a hero robot wander safely around an area would be: 
 prio-and  maint not-crashed  ach wander   
 defgoalr  maint not-crashed  
	 if 	 no-obstacles  
 do anything  
 ach avoid nearest obstacle    
 defgoalr  ach avoid nearest obstacle  
	 if 	 notm  hero-at-avoidance-angle   
 ach turn to avoidance angle  
	 if 	 notm  moving-slowly   
 ach moving slowly  
 do anything     
 defgoalr  ach turn to avoidance angle  
 and  do update  !*turn-command*   do left-motor-dist 
 set-avoidance-turn !*left*   
 do left-motor-speed 
!*caution-drivc-speed*  
 do right-motor-dist 
 set-avoidance-turn !*right*   
 do right-motor-speed 
!* caution-drive-speed*    
 defgoalr  ach moving slowly  
	 and 	 do update  !*move-command*  
 do left-motor-dist !*max-move-dist*  
 do left-motor-speed !*caution-drive-speed*  
 do right-motor-dist !*max-move-dist*  
 do right-motor-speed !*caution-drive-speed*    
figure 1 . gapps reduction rules for obstacle avoidance. terms with asterisks are global parameters which are formed into a structured memory location by the ! symbol. ach and maint are abbreviations for achieve and maintain respectively. notm is a rex machine for the not function. the do command essentially sends the specified value to a vector of outputs. 
　an abstract of the resulting circuit is shown in figure 1  where it is compared to a wander circuit from the subsumption approach. the two circuits are surprisingly similar: they both have wander and runaway competences  make use of a sonar map  and receive feedback via optical encoders on the robot's wheels. moreover  the performance of the gapps wander circuit  implemented on our denning mobile robot  is the same as that of the robot using the subsumption architecture; i.e.  the robot can wander aimlessly about for hours without colliding with stationary objects or slow-moving humans. 
 defgoalr  ach wander  
	 if 	 notm  hero-at-wander-angle   
 ach turn to wander angle  
	 if 	 notm  moving-at-speed   
 ach moving-at-speed  
 do anything     
 defgoalr  ach turn to wander angle  
 and  do update  !* turn-command*  
 do left-motor-dist  set-wandcr-tum !*left*   
 do left-motor-speed !* normal-drive-speed*  
 do right-motor-dist 
 set-wandcr-turn !*right*   
 do right-motor-speed 
! *normal-drive-speed*    
figure 1. gapps rules for wandering. the function setwander-turn uses the sonar readings to find open spaces. 

figure 1. circuits for wander routines from  brooks  

1 	robotics 

1   above  and layered competences from gapps goals  below  

　there are important differences. the avoid block and the if block both serve to produce the correct heading under the right conditions  but the avoid block is part of the wander competence  whereas the if block specifically mediates between competence layers as a result of specifying a natural prioritization of high-level goals. also  the gapps circuit is a synchronous circuit. that is  it reads the sensors and computes outputs to the wheels in continuous cycles of a guaranteed constant time. the subsumption circuit functions as a network of asynchronous finite state machines whose timing is a function of the environmental conditions. finally  the gapps circuit allows for states  such as the robot's current heading angle  used in the  hero-atwander-angle  and  hero-at-avoidance-angle  predicates. because of the circuit synchrony  it can be shown that the robot knows in a formal sense its current angle with respect to its actual position in the environment  rosenschein and kaelbling  1 . 
　with the architecture described in this paper  we can make the high-level goal specification even more complex as in the hand-crafted reaction plan shown in figure 1. a recent extension to gapps described in  kaelbling  1  supports goal regression and allows the gapps compiler to generate these plans automatically. it is not clear that this can be done in the original subsumption architecture or programming language. 
　a further advantage to using gapps is that we can organize the merging of constraints and the combination of competences differently for different tasks at compilation time. for example  the gapps coding in figure 1 invokes an obstacle avoidance competence via the  maint notcrashed  goal during a navigation action. figure 1 shows how a simple change to the top-level goal makes the obstacle avoidance competence active during the entire mission. this kind of compile-time wiring can carry down 
 defgoalr  ach place object on platform  
 if  new-mission-in- inputs  
 if  andm  notm  object-placed    notm  have-object    
 ach get-object  
 if  andm  notm  object-placed   
 notm  arm-in-raised-position    
 ach arm-raised  
 if  andm  notm  object-placed   
 notm  near-enough-to-platform    
 ach get near to platform  
 if  notm  object-placed   
 ach place-object  
 if  andm  object-placed  
 notm 
 hero-clear-of-platform    
 ach hero clear of platform  
	 if 	 andm  object-placed  
 notm  hero-retired    
 achretire-hero  
 do anything        
 do anything    
　figure 1. a reaction plan for object delivery by a hero 1 to a mobile platform. 
;; this reduction rule says if there is no new-mission input by 
;; the user  then look for an object to be delivered. else place the ;; object on the receiver platform. 
 defgoalr  ach carry out any missions  
	 if 	 notm  new-rnission-in-inputs   
 ach look for new mission  
 ach object placed on receiver platform    
;; to  look  for a new mission  look for an object in the 
;; strongest light  robot has light and proximity sensors  no 
;; camera . else try to move to the strongest light while not 
;; bumping into anything. if there is an object in the light  the 
;; robot sets a possible-new-mission flag in the output which ;; will trigger an input routine to ask the user if there is indeed a ;; mission with the object in question. 
 defgoalr  ach look-for-new-mission  
	 if 	 some-object-exists-in-the-light  
	 and 	 ach turn to object in the light  
 do possible-new-mission  !yes   
 prio-and  maint not-crashed  
 ach move-toward-strongest-light     
figure 1. reduction rules for  ach carry out any missions  
 defgoalr  ach carry out any missions  
	 if 	 notm  new-mission-in-inputs   
 ach look for new mission  
 ach object placed on receiver platform    
;; to  look  for a new mission  look for an object in the ;; strongest light  robot has light and proximity sensors  no ;; camera . else try to move to the strongest light . 
 defgoalr  ach look-for-new-mission  
	 if 	 some-object-exists-in-the-light  
	 and 	 ach turn to object in the light  
 do possible-new-mission  !yes   
 ach move-toward-strongest-light    
figure 1. reduction rules for the goal 
 prio-and  maint not-crashed   ach carry out any missions   
through the competences via the rex functions  though the results are not as perspicuous in the rex code as in the gapps language. 
　the original gapps/rex environment generated a single circuit for each compilation. code could be arranged in groups of modules which represented the layers of competences  but all modules were constrained to execute to completion in one cycle  making the cycle time proportional to the size of the enure circuit if sufficient cpu speed or a parallel architecture is readily available  this is not a problem. however  most commercially available platforms have the equivalent of an m1 or less  so we needed to adhere to the architecture's proportional timing relationships among levels to insure that the most critical  reflex  actions could execute in a minimum time cycle. a recent change to the rex compiler allows us to code competences in accordance with the architecture's timing relationships  by specifying a maximum execution time of submodules of code. 
1 other related w o r k 
the work by chapman and agrc  can be grouped with subsumption as research in intelligence emerging strictly from activity. our layered competences generate behaviors exhibiting a certain amount of emergent intelligence. however  with reaction plans  we add goal representation and explicit ordering of behavior priorities. 
　a direct alternative to the reaction plan is firby's reaction action packages  raps  . the raps depend on an extant primitive execution layer  which could be the layered competences of the above architecture. the semantics of the raps are formally derived  but it is not clear how they extend to the machine level. 
　the research in subsumption  situated automata  and emergent intelligence  e.g.   chapman  1   all use circuit languages. another circuit language is gat's behavior description language  bdl  gat and miller  1 . this makes first class objects out of the channels that connect behaviors. like the original rex system  bdl results in a synchronous system where all behaviors execute on each cycle  and  like gapps  making the connections explicit allows the programmer to arrange the behaviors to suit the task  and/or hardware  available. no formal semantics of the behavior states have been worked out  but analysis might show them to be similar to those of rex. 
　recent work by maes  is similar to the work described here in that she uses competences for plan operators as we do in the reaction plans. it is dissimilar in that she uses explicit pre/post conditions for sequencing competing behaviors rather than subsumption. also her goal is run-time planning which the architecture in this paper does not yet address.  kaelbling  1  discusses how runtime planning might be done in gapps  and we are also looking at integrating deliberative and situated paradigms  see for instance  elsaesser and sanborn  1  . 
1 experiments 
in our current experiments  we are using two hero 1 mobile robots with 1-degrees of freedom arms  a denning mrv-iii mobile robot  and a remotely-piloted vehicle 
 rpv  for undersea operations at the woods hole oceanographic institute  whoi . as of this writing our results are qualitative  i.e.  the robots carry out their tasks as expected without getting into trouble in unknown or partially known environments. we are currently attempting to quantify the results with measures of effectiveness such as number of collisions or the task completion time as functions of the number and arrangement of environmental obstacles. 
　the architecture was originally developed in the context of a simulation of cooperating agents executing retrieval tasks  and was subsequently implemented in gapps/rex on a hero to execute the wander behavior. the hero uses ultrasonic sensors  optical encoders on its wheels  arm 
joints  and gripper  and a light intensity sensor. a code generator was developed to translate the rex circuits into 
1 	robotics 
the hero's native basic language for downloading and subsequent on-board execution. presently  the hero executes a delivery task in an indoor laboratory environment  see figures 1 and 1 . a mission is signaled to the robot by a human's proximity. the robot distinguishes the human from other objects by asking questions. then the robot accepts the object from the human and moves to a mobile platform where the object is deposited. a flashlight is used to identify the receiver platform  the room lights are dimmed during the runs . the hero avoids obstacles and slow-moving other agents  and deals robustly with the receiver platform being moved mischievously by humans under joystick control during the place operation. 
　we have implemented layered competences in gapps/rex on the denning mrv-iii mobile robot for navigation among indoor and outdoor obstacles. the denning has a ring of 1 acoustic sensors  an infra-red navigation beacon system  and an inclinometer. the denning hosts an m1 running the os1 real-time operating system. the gapps runtime environment for unix was adapted for os1  so that complete gapps circuits generated in c can be run autonomously on the denning. however  our circuits using more than simple vector techniques are too large to achieve useful responses onboard  so we typically use an rs1 tether to a faster computer. 
　the robot accurately achieves and maintains a 1 foot trajectory in the face of both natural and human-introduced obstacles in our autonomous systems laboratory environment and in one of our employee parking lots. the robot will halt and adjust its heading when a human passes by unexpectedly. currently  to avoid automobiles moving faster than its one foot per second speed  it relies on the human intelligence behind the wheel. the robot will soon be instrumented with a real-time stereo system  bonasso and nishihara  1  to conduct outdoor retrieval tasks. 
　the whoi rpv has a transponder-based navigation system for location updates  and an adaptive trajectory control algorithm which we use as our move and turn competences  see  bonasso  1  . the navigation computation and control algorithms execute on a transputer architecture. to improve the vehicle's awareness  a threedimensional proximity obstacle detection system  pods  using sonar altimeters was designed and integrated on board the vehicle. we then used the architecture to successfully develop a pilot support system wherein a human pilot steers the vehicle while the vehicle autonomously avoids obstacles and the walls of a test tank. thus  the architecture was able to integrate the natural intelligence of the pilot  the reaction planner   the heuristic obstacle avoidance behavior  and the analytical competence of the control-theory routines. follow-on experiments  based on these results  are being planned for a second vehicle with a manipulator  and for a deep ocean mapping task. 
　it has been our experience that once one is familiar with the gapps/rex system  useful working robot programs can be constructed literally overnight. we used the same basic programming methodology outlined in this paper for different tasks  with different robots  both for semiautonomous and autonomous operations. all of these codes were developed via the gapps language while adhering to die principles of the above described architecture essentially in a few days  resulting in the robots being endowed with task-achieving capability almost immediately. thus  there are indications that the architecture and its implementation promise to be generally useful for a variety of tasks on a variety of robots. however  the tasks in the above experiments have not required extensive sensor processing. the outdoor retrieval task with stereo vision  and the ocean mapping tasks use more sophisticated sensors and should do much to confirm or deny these preliminary indications. 
1 	conclusions 
we have developed an architecture for retrieval  delivery and reconnaissance tasks which integrates the intuitively attractive traits of reaction plans and subsumption for the control of robots in field environments. the approach adds to each what was lacking - robust operators for the reaction plans and a goal representation for subsumption. we attain desired synchronous operations and formal semantics by implementing the architecture in gapps/rex. this programming environment allows us to build flexible combinations of competing behaviors as appropriate for the task. 
　so far  experiments seem to qualitatively bear out the utility of our approach. the robots used perform their tasks robustly during normal changes in the task environment. in addition  analytical competences from other disciplines or natural intelligence have been easily integrated into this architecture with good effect. further experiments with additional sensors in more complex environments are underway. 
acknowledgements 
we wish to acknowledge the excellent efforts by leslie 
kaelbling and nathan wilson in making the necessary changes to gapps/rex which support the architecture described in this paper. thanks are due also to jim antonisse  lashon booker  leslie kaelbling  stan 
rosenschein  and marc slack for helpful comments on an earlier draft of the text. 
