 
         expert systems have been developed around one expert partly because the expert has been totally responsible for the soundness of the knowledge base. without strong aids to help ensure soundness in building expert systems  we must rely on the soundness of the mature cohesiveness of a human expert. as knowledge bases grow this mature expertise will not be adequate. we propose a new method  for expert systems  to aid the expert in knowledge evaluation within the rule-based system setting. we consider the problem of ambiguity within a classification system as an example of the proposed technique. 
introduction. 
         expert systems have depended upon the knowledge base of the collaborating expert for soundness and richness. however  as knowledge bases grow and try to remain current in a changing world  incremental knowledge needs to be added  and one does not have the filter of usage over time that makes an expert's knowledge so generally reliable. one is led to considering means of aiding the expert as he evaluates new information and attempts to update the knowledge base with this information. many different types of aids will be useful; we suggest a useful approach and give a specific example within this approach. 
         there has been some realization of the importance of aiding knowledge acquisition. teires1as  see  davis  1   not only provided convenience tools for rule input but helped with rule integrity by use of  rule models.  michalski and chilauski  michalski and chilauski  1  investigated inductive learning as a means of automating knowledge acquisition. recently. suwa  scott  and shortliffe  suwa  scott  and shortliffe  
1  have directly addressed the problems of verifying 
 completeness and consistency  in the context of the 1ncocin system. also see this last paper for a good iummary of the need for and present status of knowledge acquisition aids. 
         our general concern is also with the quality of the knowledge in a knowledge base. our immediate ooncern is to aid the expert with feedback regarding unintended interactions with other rules in a rulebased system when a new rule is added. in this paper we assume reasoning with certainty. extending the approach considered here to weighted evidence reasoning is an obvious next step. 
         this work is supported in part by the air force office of scientific research under grant afosr-1. 
         the approach we suggest is supplemental to those previously studied. we suggest discovering properties for significant classes of problems and then defining procedures for quickly detecting violations of the properties. this puts semantic information into the evaluation process directly. as was learned in automated theorem proving  if the problem class you model is broad or important enough  and your device sufficiently effort-saving  here over standard testing   then the device will be useful. in the example we give  the property is important to many expert systems existing today and the procedure we suggest saves much effort. 
         to illustrate the modeling of a property we choose the ambiguity property within classification systems. classification  or diagnostic  systems map certain inputs into their appropriate classes  such as certain symptom sets into the appropriate disease. let us define an atomic meaningful input vector  atomic vector  as a set of attribute-value pairs that elicits a single output  called a class. intuitively  these are usually the most important input vectors. if no inhibitor rules exist  then two or more atomic meaningful input vectors can combine to form a 
          general  meaningful input vector with output the union of the classes defined by the constituent atomic vectors. this superposition property is common: if one has ail the symptoms of a cold and a broken leg  one probably has a cold and a broken leg. we assume the property of superposition holds.  this can be softened.  
         when the expert adds a rule to a rule-based system  he would like to know what changes he has caused. however  in a large system  testing every possible input vector may be impossible. he might well settle for knowing what attribute-value pairs are elements of vectors of each specific class  and if any previously atomic meaningful input vector now is a member of two or more classes. the latter problem we call the ambiguity problem   we give an efficient means of testing which returns attribute-value pair associations and helps the expert with the ambiguity problem. 
         we note that we have selected a specific property  or problem  to check within systems where exhaustive testing is too time-consuming. for large domains  there is a tremendous number of possible attribute-value combinations  most of them meaningless. we focus on analyzing the meaningful vectors  here taken to be those that belong to at least one  output  class. we have chosen one  important  problem over that class to illustrate that effective testing procedures can exist. 
         along with natural devices we will exploit the following observation. by superposition  there will be 

many ambiguous meaningful input vectors  any union of meaningful vectors of different classes . if we could obtain the minimally ambiguous  min- ambiguous  vectors  we need only display these to the expert; a now-ambiguous ex-atomic meaningful vector will be caught. 
we model the inference system here by an 
 and-or  graph.  see figure 1.  an input node is a single attribute-value pair. an attribute may have several values. to represent this we partition the nodes into sections  each section denoting one attribute. therefore  an input vector can list only one node per section. a pseudovector is any collection of input nodes  perhaps several per attribute. we assume that we can process pseudovectors; the classification of a 
pseudovector is all classes inferred by activating all nodes of the pseudovector. a rule is depicted by a dark node with conjoined input  cut by a curved arc  and one or more outputs. output nodes are labelled c l   etc. 

finding unintended ambiguities. 
	our 	concern 	is 	to 	locate 	unintended 
classifications for meaningful input vectors. besides possibly using unusual input  vectors   pseudovectors  for input  we need only to augment our inference system to execute  backflooding  in order to use the 

d. loveland and m. valtorta 1 
procedure discussed here. by backflood from ci we mean to follow all backchaining paths and mark every ci-vector input node by   i   . this is amenable to parallel computation. 

we consider the interaction between classes 
cl and c1. one would check interactions between every pair of classes in turn. of course  the backflooding need be done only once per class rather than being repeated for every pair of classes. 
we proceed as follows: 
           step j. backflood from node cl. mark with a   1   all input nodes reached by backflooding. these are called cl-nodes. 
	step 1 	backflood from node c1. 	mark with a 
  1   all input nodes reached by backflooding. these are c1-nodes. the 1-nodes are now determined and printed for reviewing by the expert. it then may be clear by inspection that no meaningful input vector is a subset of the set v1 of 1-nodes; one could input v1 as a vector  or pseudovector  to doublecheck that no class is identified with this  pseudo vector.  see step 
1.  


1 d. loveland and m. valtorta 
	step 1 	suppose v1 is classified ci but not 
c1. v1 could contain a cl-vector which is part of a 
c1-vector not contained within v1; thus the minimal cl-vectors within v1 should be isolated so this can be checked. this can be done either by the critical set algorithm  see below  or by explicit testing. space limitation prevents further details. the symmetric case of v1 classified c1 but not ci is processed similarly. 
　　　　　step 1. since both classes cl and c1 are reached by v1  we need to check for meaningful ambiguous vectors within v l 1 . if v 1 is small then one reasonable way is to input directly the atomic meaningful vectors within v 1  checking that they each are uniquely classified. if some are not  one can directly print out the inference steps of the ambiguous rule or seek min-ambiguous subvectors. this can be 
done bottom-up from singleton nodes or top-down via the critical set algorithm  see below . the advantage of finding min-ambiguous subvectors is to ease the inspection of the inference steps since one knows the critical input nodes yielding the ambiguity. finally  if too many meaningful subvectors of v1 exist to process them directly the critical set algorithm may be used. 
this ends the procedure description. 
　　　　　we briefly outline the critical set algorithm purpose and form and then give a small example. 
space prohibits a full presentation of the 
critical set algorithm  which is presented in  loveland  
1 . the algorithm is -a divide-and-conquer algorithm to solve the following problem. we are given a universe u whose power set is the domain of a monotonic set function f  f binary valued  with f     = o  f u =l and sct 
=   f s   . f t . with f so defined  there exist critical sets b such that f b =l but for every proper subset s of b  f s =1. thus  b is a  minimal l-set  under f. in step 1 we use this algorithm where the universe u is the set of 1-nodes and f is defined as f s  = l if s as a pseudovector yields class cl  f s  = 1 if s yields no class at all. in step 1  the universe is the same and f s =l if s as a pseudovector yields classes cl and c1  f s =1 if s is not ambiguously classified. note that if there are no inhibitor rules then f is monotonic in both cases since the superposition property holds. 
　　　　　the algorithm finds some one critical set  element by element. to find an element it splits successive sets in two until a singleton set is reached  whereupon the isolated element is added to the critical set. to split a pseudovector  divide the values of one attribute in half  add a different half to each set s1 and s1 and add all other nodes  from other attributes  to both s1 and s1- to split a legal vector  one node per attribute  simply split the nodes evenly between s1 and 
s1-
　　　　　the algorithm is very efficient  in a suitable sense  in finding some critical set  but finding many critical 	sets 	can 	occasionally 	lead 	to 	high computational cost. for a full discussion see  loveland  1 . 
　　　　　we conclude with a very brief illustration regarding the process of finding unintended ambiguities. 
　　　　　suppose 	a b c d e 	are 	attribute-value 	pairs with  only  a and b representing different values for the same 	attribute. 	suppose 	vectors 	 a c d ecl   b c ec1  and  c d e ec1 are the only meaningful vectors. then v1 =  c.d}  learned from backflooding.  c d  is not of either class.  a c d e  is an ambiguous vector since it is in both classes  for good reason as it is a superset of two distinct and differently classed vectors. it is both meaningful and a min-ambiguous vector.  a b c d  is an ambiguous pseudovector  but not a vector since a and b have the same attribute. 
　　　　　suppose in addition that  b c d ecl is created in error by a new rule. then v1 =  b.c.d}  and  b c d  is min-ambiguous as can be found by the critical set algorithm applied at step 1. the algorithm gives a suggested sequence of input pseudovectors to be submitted by the expert  or perhaps automatically  to determine the min-ambiguous vector. the algorithm would have one evaluate input vectors  b c    d    b d  and  c d   and we know the  b c d  classification as step 1 was reached . here the expert on his own might have tried  b c  first  then  c d   and  b d   and  getting the expected results  realized the same conclusion slightly more efficiently. we stress that we do not want to oversell the critical set algorithm; it is the general approach we emphasize. most important  we stress the value of testing procedures to catch violations of key properties of dynamic inference systems. 
