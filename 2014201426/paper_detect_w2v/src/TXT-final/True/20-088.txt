ion and limited reasoning 
tomasz imielinski 
department of computer science 
rutgers university and 
polish academy of science 

i abstract 
　we are investigating the possibility of constructing meaningful and computationally efficient approximate reasoning methods for the first order logic. in particular  we study a situation when only certain aspects of the domain are of interest to the user. this is reflected by an equivalence relation defined on the domain of the knowledge base. the whole mechanism is called domain abstraction and is demonstrated to lead to significant computational advantages. the domain abstraction discussed in the paper is only a very special case of the more general notion of abstraction which is discussed shortly here and is a 
　subject of the currently ongoing research. 
ii introduction 
　in this paper we are interested in providing a basis for meaningful reasoning with low complexity. such reasoning will be called limited to indicate that it is weaker than the general first order logic proof methods. recently many authors have tried to develop different logic systems  which would have better complexity properties than the classical propositional or predicate logic  patel-schneider 1    lakemeyer 1    konolidge 1  and in a way  fagin 1 . here  we take a different approach by developing approximate methods of reasoning within the same logic. 
　approximate methods are widely accepted in numerical computations. unfortunately automated reasoning  which is computationally at least as expensive as numerical computing does not have a proper notion of approximation and has still to follow the ambitious  all or nothing  approach. the main problem is lack of the proper notion of error  without which it is difficult to provide any meaning to an 
approximation. 
　in this paper we demonstrate a notion of error which is sufficiently general to cover both automated reasoning and numerical computations. the following example illustrates the point: 
example 1 
　suppose we want to compute a volume of a certain cube a. assume that we round up the measurements of a  say to the closest integer in meters. if we 
research support*  by nsf grant dcr 1 calculate now  say  the volume of a our result will be biased with error  say 1 m1. 
　let us now take a look at this simple example from the more general point of view. let the measurements of a form a knowledge base and let volume a x   where a is our cube and x stands for volume be a query.  we could also have other queries asking for the diameter of a  total area of faces  etc.  the process of rounding up the measurements of a can be now viewed as replacement of the original knowledge base by a new one  less precise but presumably easier to deal with. the price of this simplification is paid in the loss of precision - we will not compute a  true  volume of the cube anymore but some other value. this new  approximate value will share certain properties with the real answer. indeed  let the answer to our query be represented in the form of atomic formula volume a  1 m1 . although this formula may not necessarly be true  the formula 
volume a x  will be true  since 
in other words  t  form a 
property of the real answer  which is preserved by the approximate answer. in fact all formulas of the form and 
b 1 will be preserved. on the other hand the preservation is not guranteed if 1 for instance the formula 
1   volume    will not necessarly be preserved  i.e it is true for our approximate answer  but could be false for the real answer . ＊ 
　our notion of error is motivated by this example - it will be the set of all formulas  notice that error is a 
　set  which are not preserved by the approximate answer. in our case  belongs to the error  while does not. 
　this notion of an error will be called local error since it is related to a particular query. we define also a global error resulting from the replacement of our knowledge base by the  rounded up  one. the global error will be simply a set of all queries  which are not quranteed to be answered correctly by the  rounded up  knowledge base. in the example 1 we could imagine the whole variety of queries  asking for a diameter  total area of faces  color of a cube etc  assuming the proper data is in the knowledge base  . some of these queries will be answered correctly  because the  round up  does not affect them. therefore  while the global error will divide queries 
	imlellnksi 	1 

into two categories  correctly answered  incorrectly answered   the local error will indicate  how far  each individual answer  for each individual query  is from the real answer. needless to say the local error will be empty for queries  which are answered correctly  that is which are not in the global error set. 
　this paper is intended to serve as a  case study  for the notions introduced above  for a very special type of approximate reasoning method  called domain abstraction. under domain abstraction only certain aspects of the domain will be of interest to the user. instead of domain constants  he will deal with equivalence classes of them. in consequence he will deal with  rounded up  knowledge base  similar to the numerical one just described. 
　important observations about the fundamental role of abstraction in approximate reasoning were made by hobbs in  hobbs 1 . the notion of abstraction is also studied in  imielinski 1 . here we concentrate on the domain abstraction  to be defined in the next section  by discussing it's computational benefits and  global  errors. 
　the paper is divided into two parts. in the first part of the paper  in section three  four and five we define formally the notion of abstraction and discuss the issues of query processing and the error of domain abstraction. finally  we briefly discuss applications of domain abstraction in the limited reasoning. 
i i i basic 	notions 
　by the knowledge base  denoted by kb  or db  we understand any finite collections of formulas of some first order language l. we also use the term database specially when the kb is a collection of atomic formulas corresponding to the relational database. 
　by the query we mean any open formula of l. and by the answer to a query the set of all substitutions 
of domain constants for variables such that the resulting closed formula is a logical consequence of kb. 
　by the domain of the knowledge base we mean the set of all objects occurring in the kb. 
　by the equivalence relation on the set d we mean a binary relation on d which is reflexive  symmetric and transitive. equivalence relation is selective on the subset d1 of d iff for any element  the equivalence class of 
i v d o m a i n 	a b s t r a c t i o n 
　let d be the domain of our knowledge base and let r be an equivalence relation on d. let l be the first order language of the knowledge base. we can extend r in the natural way to models of l. two models  m and m' will be r-equivalent iff for any atomic formula rar..ab which is true in m  m1  there is an atomic formula rbr..bn which is true in m'  m   such that ajrb  for 
　the equivalence relation r can be given one of the following interpretations: 
1. it may correspond to the relevant features of the external world which are of interest to the user 
1. it may be used by the system to hide certain features of the external world from the user 
1. it may correspond to the error with which data is entered into the database. as a consequence we do not entirely believe what is stated in the database  but take it with  the grain of salt   which is reflected by equivalence relation r. 
all these interpretations have similar consequences: 
i.e the user's view of external world is even more incomplete that the view of the knowledge base. the  noise  is introduced on the interface between the user and knowledge base. however  there is an important difference between these two approaches: in the first approach the choice of abstracted interpretation is made by user  while in the second interpretation the choice is made by administrator of a system. this distinction will have further consequences later in the paper. 
　let kb be a knowledge base and let r be the equivalence relation on the set of models of kb. the equivalence relation r determines a new  weaker  semantic consequence relation nr on l. 
 iff for any model m  is true 
not only in m but also in all models which are requivalent to r. 
　this definition corresponds to the truth definition for the necessity operator in the kripke model with r as its access relations. this is studied in more detail in the paper  imielinski 1 . intuitively  the external user whose information is filtered out by the relation r cannot distinguish between two models which are equivalent  therefore all models which are equivalent to models of kb are  for this user  as good  as models of kb. obviously some of the formulas of kb will be lost if they are not  filtered out  through r. 
　the above definition could be interpreted also in the different way  as abstraction of kb. indeed  our user no longer sees the knowledge base kb but rather some logically weaker set of formulas corresponding to his  less precise now  set of possible worlds namely: 
 there is m' such that m'rm and 
clearly any formula o is a semantic consequence of 
kb in the new sense iff it is true in each model from m kb r . 
　the equivalence relation r which is defined on the domain of knowledge base induces equivalence relation on the name constants of the knowledge base language l. the equivalence classes of this relation will be denoted by  a  where  a  is a name constant. 
 the key question  which we are going to investigate  is whether r is computationally more attractive than standard we are also interested in estimating the  error  if the reasoning is performed in the abstracted 

knowledge base instead of the original one. 
example 1 
　let our knowledge base have a form of a very long disjunction  say of the form: 

　let us assume that the user's equivalence relation r is defined in such a way on the domain of the knowledge base that all elements a ...an belong to the same equivalence class  say  a  and all elements b 1 ..b n belong to the other equivalence class  say  b . in such case the resulting knowledge base can be viewed simply as the atomic formula:  one can visualize very long disjunctions reducing its size to very short  if not atomic formulas  after applying this kind of abstraction. there are therefore obvious computational benefits of this technique here. ＊ 
　we use here two different languages: the abstracted language lft and the basic language l. the abstracted language is the first order language with name constants  the formulas of  are interpreted either as second order formulas  if we allow quantification on equivalence classes  or as first order formulas of some extension of l. 
second order interpretation of l. 
the second order interpretation of the formula o of 
la will be denoted by au  where  u  stands for   unaware   which will be clear later on . the satisfiability relation for this interpretation will be defined on the basis of the quotient models which is equal to the set of all equivalence classes  with respect to r  of models of kb. notice that quotient models are simply built as relations defined on equivalence classes  a  of domain constants aed. we will say the  tu is true in kb iff it is true in each quotient model of kb. 
　this interpretation corresponds to the situation when the external user is unaware of the fact that he is using any abstracted language. in fact he treats or equivalence constants as if they were names of singular objects. he is simply unaware of the fact that they are really unary predicates. 
first order interpretation of la 
　in this interpretation denoted by 1a the user is aware of   cheating  and he treats all the constants of the language as unary predicates. formally let l be the language l extended by unary predicates uiv.. un corresponding to the equivalence classes of r on the name constants of l. any formula of lt can be translated into the formula of l by replacing all constants  a  by existential quantifiers range restricted to the unary predicate  corresponding to  a . all quantifiers in la are treated as ranging over the objects of the domain d. 
example 1 
　the atomic formula will be translated to the formula: 
 are 
unary predicates corresponding to equivalence classes 	the 
equivalence class  a  . 
example 1 
　let kb be a knowledge base storing all direct flight connections in the united states. one natural abstraction which can be considered is provided by the equivalence relation putting all cities which are in the same state into the same equivalence class. the abstracted language la is going to use names of the states instead of using the names of the cities. in the second order interpretation the user will not be  aware  that states are really predicates. let us now consider the query a: give me all direct or indirect connections with one stop over from new york to seattle. according to the second order interpretation ou the user will get some erroneous connections. for example  if there is a flight from new york to la and the flight from san francisco to seattle then this will be printed as connection because la and san francisco are in the same state ! therefore  instead of the real answer to the query we will get some approximation of it which is complete but not sound  i.e we get more tuples than necessary . in the same time this approximation will give us a correct information about which connections are not possible. on the other hand take now the first order interpretation oa. this will be a very conservative interpretation  which in fact will lead to a subset of the real answer  i.e to the approximation which is sound but not complete. indeed  even if there is a flight from ny to seattle with one stopover in san francisco it will not be printed out  since there are other models in m kb r  in which the place of arrival of the flight from ny is different from the place of departure of the flight to seattle. in other words  even if the knowledge base contain formulas connected newyork state california  and 
connected california  washington  no matching between two occurrences of california will occur  since the user is aware that there may be many cities there. these two approximations differ in their treatment of equivalence classes  in the former approach equivalence classes are always unifiable with themselves  in the latter one they are never unifiable with themselves. 
i 
　let us now investigate the basic questions related to the very notion of abstraction: how good this approximation is  does it lead to computational benefits   . 
　we will approach these questions by investigating first the following problems: 
　　actually it it a possibility operator in the kripke model with access relation r defined as domain equivalence relation defined on models 
imielinksi 

1. given a theory kb how to construct theory 
 kbjr  called first order r-reconstruction in l* such that 
1. the same question but with regards to a theory    called second order 
r-reconstruction on la such that or that the set of models of  is equal to the set of quotient models of kb. 
1. what is the error between kb and  kb r  i.e. for which formulas kb and kbr give different answers  
　the first two questions will be investigated in the next two subsections. the last question is a subject of section 1. 
i v . l . first order r-reconstructions of the knowledge base kb 
　we will assume here that our knowledge base is a set of positive  no negation  formulas. later we discuss deductive  with implication  databases. 
　here we are interested in representing the set of all formulas of the language l* which are true in all models of m kb r . for a formula   we would like to establish a new formula  or shortly  if r is clear from the context  such that: 
　it easy to check that     behaves like a possibility operator'*. therefore: 
　therefore we cannot generate  t r on the formula by formula basis. instead we first transform t to the disjunctive normal form and treat each disjunct separately. for each individual disjunct u we form a set of formulas  u r by the following procedure: 
1. first rename all variables in u in such a way that no variable occur twice in u. we add proper equality conditions to reflect the fact that several different occurrences of the same variable were renamed differently. as the result we get the set of literals and the set of equalities. 
1. replace each individual constant  a  occurring in any of the literals by the variable with range restricted existential quantification over unary predicate  a  x   corresponding to the equivalence class generated by a.  u r will be formed by ignoring all equality conditions and making a conjunction of all literals possibly with such a range restricted existential quantification. 
therefore  in general only single literal formulas of d 

exactly two elements  and there are three occurrences of b in the database  therefore at least two of these occurrences have to be equal. 
　in general these kind of  combinatorial  inferences about equality are much harder to perform that even the standard first order derivations  i.e derivations when we assume that the equivalence relation is selective . we can conclude the above considerations in the following: 
	 ignorance  	principle 
　abstraction is computationally beneficial if we either don't know anything about the cardinality of equivalence classes or we know that there are singular 
 i.e contain one element  
iv.1. second order r-reconstruction 
　the second order reconstruction is much simpler than the one described above. we simply take each formula of the knowledge base kb and map all constants into their equivalence classes. some of the terms will collapse into one  for example in the case of disjunctions  and in the result we will always obtain a simpler theory. these is in fact a pure language abstraction. 
example 1 
　if we take the formula from the above example we will get the following second order reconstruction 
	constants 	for 
equivalence classes 
i 
　it is easy to see that both transformations lead to the proper r-reconstructions of the knowledge base both in the first order and in the second order case. 
v global error of the approximation 
　here we will evaluate the error which arises from assuming the r-reconstruction of the kb instead of kb itself. we want to characterize the set of formulas of l* which are preserved under domain abstraction. let  be the set of constants of the language l* and let ul be the set of unary predicates in l' corresponding to equivalence classes. without loss of generality we assume that all our predicates are untyped  i.e.  all database constants can occur on all positions of the predicates. we will construct a sublanguage l1 as follows: 
1. for any database predicate p and unary predicates u  ...u where each u is either a 
	r 	  
predicate corresponding to equivalence class or a universal domain predicate   the formulas of the form: 

d x  it true iff x belongs to the domain d of the knowldgebasr 

　given database kb and equivalence relation r by extended database we will mean the database kb extended by the unary predicates corresponding to the equivalence classes. 
lemma 1 
　the set of all formulas preserved by domain abstraction r is equal to the set of all formulas of which are consequences of the extended database. in other words the difference between the kb and its rreconstruction can only be detected by the formulas out of 
i 
　notice that the language  is in principle a propositional language generated by quantificational atomic formulas. disallowing arbitrary existential quantification is the consequence of the fact that there are no free variables in the formulas of 
 in a similar way we can obtain the estimation of error in terms of the abstracted language le. 
v . l . domain abstraction and approximations 
 the above considerations provided an error for the semantic consequence relation  for the queries belonging to the  error set  domain abstraction is not expected to give correct values: what will be the relation of the answers to queries computed according to the first order and second order interpretation  let be a query  r be an equivalence relation and let denote an answer to this query in the knowledge base kb  while  denote the r-answer returned to treated as first order interpretation and the r-answer returned due to the second order 
interpretation. we have the following lemma: 
lemma 1 
for any knowledge base kb  any abstraction r and 
that is is a sound but not always complete approximation  while   the second order interpretation  is complete but not always sound approximation  i.e. in general it will return more tuples then necessary. if  however belongs to l * then both answers will coincide with 
i 
　the analysis of local error would tell us  how close  are these approximations to the real a n s w e r w e will do it in the full version of the paper. 
　in the next section we will discuss the influence of domain abstraction on deduction process. 
imlellnksl 

vi 	r-resolution 
　here we would like to consider simple deductive database built from atomic facts and universally quantified horn formulas without function symbols. let db denote the set of atomic facts of this database and let  denote the set of horn rules. in database theory  given a query q we can either look at the database as a single theory t or modify the query q to the form in such a way that  can be directly evaluated on db forgetting about the formulas from  these two ways are equivalent  although the first one treats rules as a part of the database while the second one in treats them as a part of query. in abstracted database these two ways are no longer equivalent. the incorporation of rules into the query leads to a much less costly evaluation which we will call r-rtbolution. in r-resolution  r  from the equivalence relation r  all formulas before being transformed to clausal forms have all variables renamed  so no variable occurs twice  and proper equality conditions are added. then all formulas and negation of the query are transformed to the clausal form and standard resolution is performed with one slight modification of great computational consequences: all equality conditions imposed between two variables fail. this condition can be weaken again  if some additional conditions are imposed on equivalence relation r  selectivness of r on some subdomains  etc . in general  in this approach  the query q in the presence of deductive rules ~ is treated as  by the r-an$wer to q we will understand the answer to  computed from the rreconstruction of the db  the set of atomic facts . 
example 1 

　wqxyz-wxyz  where p  q and w1 are predicates whose extensions are stored in the database and w is a derived predicate. let our query have a form {xyzrwxyz}. in order to answer this query we can either treat the whole database  both facts and the above rules  as one theory  or modify a query q to the form  these two ways are equivalent  unless domain abstraction is applied. with domain abstraction and no knowledge about selectivness of r  the second disjunct of q  will fail  unification will fail . if we treat the database as a single theory  including rules  then the rreconstruction of it will lead to the different result and in fact will not be computationally attractive  effectively  it will require computing a fixpoint of the database before the r-reconstruction  which could be very expensive  i 
　the general failure of unification  in case we know nothing about r makes r-resolution very easy. even  if we have some partial knowledge about selectivity of r  r-resolution will still be easier than the standard resolution. a short analysis is provided in the next section: 
vi. 1. complexity of abstracted reasoning 
　there are two major computational advantages of abstraction: the r-reconstruction of the theory t is simpler than t itself and the reasoning is much less demanding because of the limited unification. in this way we obtain substantial computational improvements  which will be illustrated for two types of theories: horn theories without functions and horn theories with function symbols. 
horn theories without function symbols 
　for a knowledge base intensions in the form of sets of horn clauses without function symbols any query could be processed in time which is a polynomial function of the size of the database  vardi 1 . we will demonstrate here that under domain abstraction a very large class of queries can be processed in time which is a linear function of the database size. let us first define the notions of a proper query and of a 
　proper rule. 
definition 
　by the proper query q we mean a query such that in any conjunct of q with more then one database literal involved  i.e when the predicate is the database predicate  there is an equality literal   where x occurs in l1 and y occurs in l1.s 
by a proper rule we mean a universally quantified 
horn rule  which either has a single literal in it's body or  if it has more than one literal  for any literal i in the body there is some other literal y such that 1 and i  share the same variable. 
this definitions eliminates expensive and rather rare 
ii
cartesian 	product  	like 	conjunctions 	of 	the 	form 
 it still contains a very large family of practical queries and rules.. we have now the following easy fact: 
fact 1 
  be a knowledge base intension built from proper horn clauses without function symbols and let q be a proper query then the r-answer to a query q can be generated in time which is linear with respect to the database size. 
proof 
　as we have pointed out before  pure  equality conditions of the form  are always evaluated to * false  under abstraction. therefore  if such conditions occur in conjuncts the whole such conjuncts will be evaluated to false. hence  the only parts of the query which will  get through  will be single literals and disjunctions or existential quantifications of them. such queries however can be clearly processed in the linear time with respect to the size of the database. ＊ 
　more interesting situation occurs  when r is partially selective. we will discuss it in more detail in the full version of the paper. 
　we will now discuss a situation when the function symbols are present: 
function symbols and abstraction 
　it is well known that the problem of query processing is undecidable in the general case when function symbols are. present in the database. can domain abstraction help to make this problem more tractable  
　in the same way as before we will distinguish two different interpretations  first and second order. under the first order interpretation  when nothing is known about the equivalence relation  unification will still fail uniformly  as in the function-free case. in the same trivial way as before  we will always be able to compute an answer to a query  in most cases in time which is a linear function of the database size . a more interesting case occurs when the equivalence relation is partially selective. for instance  in case of natural numbers  the equivalence relation can be selective for all natural numbers up to n1 and map all larger numbers into one equivalence class called  large . such an abstraction will preserve all formulas which were proved  using small numbers  and will distort all formulas which  depend  on large numbers. this could be viewed as another interpretation of some  intuitionistic  principle that proofs using large nonconstructive numbers are invalid. 
　situation is different when one considers a second order interpretation. here  in order to have a well defined herbrand universe  we want r to be a congruence relation with respect to all functions  namely we want the following formula to be true: 

indeed  otherwise f  a   will even not be defined. if 
 *  is the case and r has a finite number of equivalence classes  then we can effectively compute answers to queries under second order interpretation  i.e. treating equivalence classes as constants . this is the case because a new herbrand universe  built from equivalence classes  is finite. 
v i i l i m i t e d inference 
 given a database kb in a predicate language l we can treat l as abstraction of some unknown  prelanguage   this will result in a very cautious treatment of object identity in the database  namely by treating all constants as equivalence classes of some unknown equivalence relation r. in more intuitive terms this treatment corresponds to somehow impersonal interpretation of names of objects: instead of saying  smith  we will say  some smith  and instead of saying  smith brings an apple  we will say  some smith brings some apple . the resulting reasoning will have low complexity characteristic to the  described before  abstracted reasoning. we could gradually introduce more information about r  selectivness etc  and get better and better approximations of the  real  answers to queries both in terms of already discussed upper - and lower -  approximations 
viii other types of abstraction 
　in  imielinski 1  the different types of abstractions were introduced. if we define abstraction equivalence relation by fixing some formula  and making two models: ml and m1 equivalent iff the diagram of  i.e. roughly speaking the set of all constants c such that q c  is true in the model  is identical in ml and m1 this formula  is called a view. it turns out that the r-reconstruction of any theory kb is equal to the set of all consequences of kb which can be constructed using formula q x  as the basic predicate and all logical connectives and quantifiers. this is discussed in detail in  imielinski 1 . 
dc conclusions 
　we introduced here new notions of errors in logic and studied one particular approximation  called domain abstraction  as an illustration of these formal notions. we argued that the notion of abstraction provides meaningful approximate method  which is computationally attractive with a clear notion of error. it can be used for a preliminary computation of the answer to a query  which can then be followed  if necessary  by some precise procedure. the notion of abstraction is much more general than the specific domain abstraction introduced in this paper. we indicated this in the last section of the paper. investigating different types of abstractions as approximation mechanisms in logical reasoning is a promising area for further research. 
