 
the hierarchical lexicon  in contrast to the traditional flat lexicon  enables a linguistic model to perform even in situations of incomplete knowledge: when a specific entry is missing  a more general entry can cover the gap. the question still remains regarding the construction of the lexicon itself. 
since the lexicon is organized as a hierarchy  and not as a flat structure  phrases cannot simply be placed in the lexicon: they must be interconnected with other phrases in the hierarchy at the appropriate level of generality. furthermore  since input examples arc always given in terms of specific phrases  phrases must be propagated up and down the hierarchy  starting at the bottom level. 
in this paper we describe a learning algorithm which is based on two existing machine-learning models: learning in a version space  mitchell1   and learning by accumulating specific episodes in a dynamic memory  kolodner1  schank1 . the input required by the algorithm is a sequence of specific episodes  or training examples  from which lexical entries at various levels in the hierarchy arc generalized and specialized. the algorithm is embodied by the program rina  zernik1b  which models learning english phrases by a second language speaker. 
1. introduction 
all language-related knowledge required by a linguistic model resides in its lexicon. traditionally  the lexicon has been viewed as a flat list of lexical entries  bresnan1 . recently  however  jacobs1  langacker1   hierarchy has emerged as a method for organizing lexical information. through the hierarchical representation  linguistic knowledge ranging form general grammar rules  to specific lexical entries can be covered uniformly. a significant advantage of this approach is the ability to cope with incom-
plete knowledge-* problem faced by any running linguistic model  as well as by humans. 
two aspects of this problem must be investigated: performance-parsing and generation-and acquisition. in another paper  zernik1b  we show how the hierarchical lexicon facilitates performance even in conditions of incomplete knowledge: through the hierarchy  general phrases can fill in for missing specific ones. however  how is the lexicon generated in the first place  in this paper we show how the hierarchy itself is constructed dynamically  as a by-product of parsing. the process is described in terms of the computer program rina which acquires phrases by receiving examples from a user  zernik1b  zernik1a  zernik1a . 
1 the linguistic phenomenon 
four scenarios are distinguished here  according to two parameters:  a  the contents of the program's lexicon  and  b  the clues given by the user's example. the entire sequence illustrates how the program upgrades its parsing ability as experiences are being accumulated. 
 1  neither the entry exists in the lexicon  nor is the context provided by the user: initially  the lexicon contains no entry to cope with the new phrase to push around. 
	user: 	throughout their childhood  
             frank used to push corinne around. rina: he moved her in circles  
although the words push and around exist in the lexicon  the entire phrase push somebody around is yet unknown. neither does the context  established by the text  throughout their childhood does not reveal the essence of the characters' relationship   provide any clue. therefore  the program cannot cope with the new phrase  and it uses the literal interpretation of the single words: he moved her in circles . 
 1  no entry exists  but an explanatory context is given: while no entry exists in the lexicon for push around  this time the context provided by the user is explanatory: 
	user: 	frank  corinne's elder brother  pushed her around. 
             he asked her to make his bed against her will. rina: frank made corinne carry out a job on his behalf. 
	zernick 	1 

here  due to the context provided by the user  rina forms an initial hypothesis. however  based on a single example  the hypothesis is not general enough  doing a job on behalf of a second person is not the essence of the meaning . 
 1  a similar entry exists  and a context is given: next  rina hears a similar phrase  to boss around. 
user: mary was hired on the same day as john  but she knew the manager. therefore  she used to boss around her colleague  john. rina: mary forced him to act. 
at this point  rina could identify the similarities between the two situations. basically  rina detected a common surface feature  the word around   and common semantic features  one person uses his power to impose his will on a second person . she constructs a generalization regarding the association between these features  and accordingly  she conveys a more general hypothesis to the user. this hypothesis may help the learner predict the behavior of other phrases involving the word around. however  since there are phrases involving around which do not have this meaning  e.g.  stick around  get around to it  etc.   the acquired generalized phrase must carry discriminating conditions. 
 1  no context is given  but a general entry exists: next  rina hears a third related phrase  to order around: 
user: 	doug  linda's younger brother  told her to stop ordering him around. 
	rina: 	doug asked linda to stop forcing him to act  
like the first scenario  neither:  a   the phrase order somebody around is encoded explicitly in the lexicon  nor  b   any explanatory context is provided by the user. however  in absence of specific knowledge for parsing the new phrase  rina applies here the general phrase acquired previously. 
rina's hypothesis is not guaranteed to be correct  yet it enables the formation of a hypothesis regarding the unknown phrase. 
notice how learning improved the performance of the program. 
  before learning  rina was not able to parse push around  without an explanatory context . 
  after learning  even in conditions of minimal context  rina could parse sentences which include  not only the phrase itself  but an entire set of similar phrases. 
1 the issues 
five issues must be addressed in acquiring such a hierarchical lexicon. 
determining scope and variability: the syntactic pattern of a new phrase is extracted initially from a single sentence. frank used to push corinne around. 
 from that sentence  the program must determine scope and the variability of the pattern. however  the unknown pat-
1 	cognitive modeling 
tern could take on many forms. 
frank pushed corinne 
x:person push:verb y:person 
x:person push:verb y:person around 
x:person use:verb to push.verb y:person around 
which one of the forms above is appropriate as the phrase pattern  
forming the meaning: the meaning of the phrase is extracted form the context. however  the context includes many concepts  some appropriate  and some inappropriate for meaning formation. thus  based on the given context of frank and corinne  what is the meaning of push around  
generalization: from the first example  rina extracted a narrow meaning: 
rina: frank made corinne carry out a job on his behalf. 
by hearing a second example  rina was able to generalize the meaning: 
	rina: 	mary forced john to act against his will. 
this meaning pertains to general interpersonal relationships 
 power  authority  and can cover more situations in which the phrase may appear.  1  how can a generalization be formed across two apparently distinct situations  family feud vs. problems at the working place    1  how far should generalization be pursued without causing overgeneralizing  e.g.  here is an overgeneralization: frank did something negative to corinne   
specialization: a new phrase order around is encountered without an explanatory context. yet  although a specific lexical entry for that phrase does not exist  the phrase can be analyzed by a generalized phrase. how is generalized knowledge applied in coping with gaps in specific knowledge  
phrase disambiguation: even when all the necessary information exists in the lexicon  parsing is not without problems. consider the following pair of texts: 
  mary and john were ice skating in circles. he was pushing her around. 
  john acted bossy with mary. he was always pushing her around. 
since two phrases exist for push around  the program must select the appropriate one in each case. individual lexical entries must provide the sufficient conditions for phrase discrimination. 
1 the approach 
the phrasal lexicon  becker1  wilensky1  fillmore1  contains not only single words  e.g.  around   rather it contains entire phrasal entries  e.g.  to get around to it  to suck around  around the clock  around 1pm . the phrasal approach has proved effective in parsing  wilks1  and in generation  jacobs1 . yet the basic dilemma regarding inclusion of 

phrases in the lexicon is unresolved. which linguistic elements belong in the phrasal lexicon  and which elements do not  on the one hand  productive phrases such as john gave mary the spoon  or mary went to school  should not reside in the lexicon  lest the lexicon will get oversized. on the other hand  non-productive phrases such as the big apple  or to throw the book at somebody must reside in the lexicon. their meanings cannot be derived from their constituents. however  there is a gray area which includes phrases such as stick around  hang around  and sit around  for whom the inclusion 
question is unclear. these phrases are non-productive  since their meanings cannot be simply derived from the single words. thus  they must be included. however  they all share semantic and syntactic features  thus they should not all be included as separate entries. therefore in our model  such groups of phrases are clustered into generalized phrases  which represent their shared features. such generalized phrases serve in predicting meanings of similar combinations even before they have been encountered. 
the hierarchical representation facilitates learning as a continuous process of knowledge refinement. two approaches have been integrated in our model. using mitchell's method  mitchell1  we view the lexicon as a version space of rules. since phrases are organized in a hierarchy by generalization  then both parsing and learning require determining location of phrases in that hierarchy. kolodner  kolodner1   on the other hand  has shown how learning is accomplished by organizing episodes in a dynamic memory. in our model  the lexical hierarchy itself is dynamic and nodes at all levels of generality are updated by receiving instance episodes at the bottom of the hierarchy. 
1. representing the context 
the context is represented as a goal-plan situation at two levels: specific planning  and abstract planning. 
specific planning knowledge: planning knowledge in each domain consists of goals-and acts which implement those goals. for example  consider the text: 
frank needed to clean up his room. corinne made his bed for him. 
the events underlying the sentence are given in the following plan box  schank1 . 

figure 1: the specific plan box 
making the bed  gl   wiping the floor  g1   clearing the desk  g1   are all subgoals for cleaning one's room  go . in this case  although go is a goal of frank  act al which im-
plements gl is executed by corinne. 
abstract planning knowledge: many specific plan boxes are required in covering planning situations across domains. in contrast  a relatively small set of abstract planning structures  wilensky1   e.g.  goal-conflict  goal-competition  goal-concordance  plan agency  etc.   and relations  authority  power  friendship  can cover situations across all domains. in our example  due to the power relationship between characters x and y  x causes y execute an act a on x's behalf. this is shown in figure 1 below. 

figure 1: an abstract goal situation 
corinne serves as a plan agent in executing a plan for frank. her motivation is neither  a  an authority relationship  frank is not an authority for corinne   nor  b  a friendship with frank  but  c  the power relationship  due to his frank's age . the abstract planning elements are used here to explain the planning situation. planning knowledge at these two levels provide the semantics for lexical representation. 
1. the lexicon 
the phrasal lexicon  zernik1a  is specified in two ways: by the contents of single lexical entries  and by the structure of the entire lexicon. 
single-phrase representation: a lexical entry  or a phrase  is a triple associating a linguistic pattern with its concept and a presupposition. for example compare the following sentences: 
 1  john sat three days working on his thesis   1  john sat around three days working on his thesis. 
what is the difference between their meanings  and what is the value added by the modifier around  the phrase to sit around is represented as a triple: 
	pattern: 	x:person sit around 
presupposition: x dedicates time to an act p concept: the execution of p is a waste of time 
sentence  1   then  is parsed in three steps using the lexical phrase: 
 1  the pattern is matched successfully against the text. consequently  x is bound to the person called john. 
	zernick 	1 

 1  the presupposition is unified with the current context. in this case the variable p is taken by the context as the ph.d work. 
 1  since both  1  and  1  are successful  then the pattern itself is instantiated  adding to the context: working on the phd wasted john's time  which disabled execution of other acts by john . 
generalized phrases: however  the representation given above for hang around is not satisfactory when considering two other similar phrases: 
john used to stick around for hours. 
john hung around  waiting for his girlfriend. 
the lexicon cannot simply enumerate all word combinations. there must be a more general entry to account for all the phrases of the from  verb around  which convey this particular sense. 
	pattern: 	x:person v:act around 
presupposition: v is an act of staying in location l for a period of time 
	concept: 	staying in l disables execution of other acts by x 
this entry captures an entire set of such phrases. the presupposition part is used to discriminate phrases such as hang around  and stick around from phrases such as push somebody around and boss somebody around  by detecting necessary conditions in the context. 
the global hierarchy: a hierarchy is defined  to accommodate for phrases at all levels of generality. 

figure 1: the hierarchy for verb-modifiers 
 the names of the nodes in this scheme are for reference only.  phrases in this hierarchy are all given uniformly as pattern-concept-presupposition triples. for example  pi1  sit  is the phrase for sit around  and p1   idle   is the phrase encompassing a set of v around phrases. specific phrases  traditionally called  lexical rules   reside near the bottom. general phrase  or  grammar rules   reside at the top. p1 
 around   for example  maintains general knowledge about the behavior of that modifier. 
1 the algorithm 
the learning algorithm accepts as input a sequence of episodes  from which it generates a subtree of phrases. the hierarchy before and after learning is given schematically below  where subtree t1 is the element added to the lexicon by learning. 

figure 1: the hierarchy before and after 
the process itself is shown schematically through a sequence of snapshots. 

figure 1: four snapshots in the sequence 
 1  initially  the subtree includes only a the general node p1  which stands for the modifier around . 
 1  node p1 is extracted from episode el. 
 1  node p1 is extracted from episode e1. howev-
er  p1 is generalized by detecting the similarities between el and e1  
 1  e1 is not informative enough for extraction of a node. however  node p1 can be specialized from the general node p1. 
thus  a subtree is added under p1. the specifications of the algorithm are given below. the given information is: 
 1  an initial hierarchy. this hierarchy is not sufficiently developed  so parsing of certain sentences might fail. 
 1  a sequence of episodes. an episode is a paragraph embedding a new phrase in an explanatory context. 
 1  the 	semantics 	of the 	context. 	semantic 

cognitive modeling 

knowledge is given in terms of planning knowledge. 

the objective is to refine the initial hierarchy. by adding on additional nodes  or by specializing and generalizing existing nodes  the new hierarchy should facilitate parsing of sentences on which the initial hierarchy has failed. the three basic steps of the algorithm are explained in regard to the sequence of scenarios in section 1. 
1 extracting a phrase from a single example 
two simultaneous actions are involved in acquiring an unknown phrase from a training example  frank pushed his younger sister around . 
 1  the pattern is extracted from the input sentence. 
 1  the meaning  both concept and presupposition  is extracted from the given context. 
 1  forming the pattern 
two problems arise in pattern formation: determining the scope and determining the variability of the new pattern. 
determining the scope: since the input sentence includes not only the bare phrase itself  but some additional elements  it is necessary to determine which elements in the sentence should be included in the pattern and which ones should be excluded. for example  the sentence under consideration contains two modifiers: 
throughout their childhood  frank used to push corinne around. 
while throughout their childhood is excluded  around is taken as a part of the new phrase. the reason is that throughout their childhood can be interpreted successfully by the parser in any context. it does not cause a parsing failure. however  around does cause a parsing failure:  frank moved corinne around something   thus  the pattern is scoped as follows: 
x:person push y:person around 
determining variability: in converting an instance sentence into a general pattern  each element in the new pattern either becomes a variable  or it remains as a literal. in the conversion above  both frank and corinne were taken as generalized references to persons  x and y. accordingly  it appears that the rule was: 
references to persons and to objects are converted into variables. 
however  this rule is refuted by examples such as: 
 1  admiral nellson went to davey jones' locker. 
 1  he kicked the bucket in trafalgar. 
in these idioms  the marked references are taken as literals and not as variables  in violation of the rule above. thus  the rule must be refined: 
references which can be resolved in the context are converted into variables. references which cannot be resolved in the context are kept as literals. 
further strategies for pattern formation are described elsewhere  zemik1b . 
 1  forming the meaning 
initially  the program focuses at the level of specific plans. 
g  cleaning the room  is goal of x  frank . 
p  making the bed  is a plan for g. p is carried out by y  corinne . 
the meaning captured at this level is: x carried out a job on y's behalf. consequently  the acquired phrase is: 
	pattern: 	x:person  push around  y'.person 
presupposition: p is a plan for g concept: 	y is a plan agent in executing plan p for x 
p1: the specific phrase for push around 
however  many situations in which push around may be applied  are not included in p1's definition. thus  p1 must be generalized. 
1 generalizing from two examples 
the second scenario  mary bossed her colleague around  does not share the specific features with the first example. syntactically: the verb is boss and not push. semantically: john did not carry out a job in mary's behalf. thus both the pattern and the meaning must be generalized. 
the pattern is generalized as the verb becomes a variable. 
the meaning is generalized when specific planning elements are replaced by abstract planning structures which are shared by both episodes: mary used her power  and not an authority   and frank used his power to make corinne act 
against her will. therefore  the resulting phrases is: 
pattern: x.person  v:act around  y:person presupposition: x presents a power for y concept: x causes y to act against x's will 
p1: the generalized phrase for  dominating  
notice that although the general phrase p1 was generated  the specific phrases p1 and p1 have not been eliminated. specific information is maintained even though it is sub* sumed by more general information. 
1 specializing a general phrase 
a specific phrase does not exist for order around in the fourth scenario. however  the sentence is parsed by using the generalized phrase p1. p1 is matched successfully in the episode e1  since: 
 1  the syntactic pattern of p1 matches the input sentence  the form is x verbed y around . 
 1  the semantic presupposition matches the input context  x presents a power to y . 
	zernick 	1 
the specific phrase p1  for order around  is added on to the lexicon  although it is subsumed by p1. for one thing  specific phrases enrich the program's vocabulary. in text generation they enable production of sentences which include specific variants of generalized phrases. 
1 previous work in language acquisition 
two previous models of language acquisition are related to our work. granger's program foul-up  grangcr1   which acquired word meanings  and pinker's model  pinker1  which acquired language syntax. 
foul-up was devised as a mechanism for extending sam's  cullingford1  lexicon while performing conceptual analysis. sam constructed meanings for english sentences by a two-step cycle:  a  select a script  and  b  instantiate the script. for example the following text: 
john's baby caught a cold. he called up his doctor  and made an appointment for the next morning. the nurse took his temperature  and it was 1 degrees. she realized immediately 
that he needed to be raggled. 
involves the sclinic script  which stands for a chain of events associated with a visit to the family doctor. thus  the combination of child-being-sick followed by call-up-adoctor causes the selection of sclinic. once this script is selected  references and events can be readily resolved. made an appointment for example is taken as a standard sclinic event. the nurse is bound to a designated role-holder in the script  and take his temperature also matches an anticipated action while in the clinic. the reference his  in his temperature  is bound to john's baby  and not to john  since the baby holds the role of the patient in sclinic. foul-up is activated by sam at the point that the word raggled is encountered  a word which does not appear in sam's lexicon. by knowing the rest of the possible events and the possible outcomes of sclinic  foul-up can predict that to be raggled means to taken to the hospital. foul-up learned lexical entries assuming that the new single word appeared in the context of a script  and that the meaning of the word could be drawn from that script. foul-up did not handle syntax acquisition  nor multi-word phrases. 
pinker  pinker1  modeled child language acquisition  covering phenomena ranging from basic phrase structure identification to mastering phrase interaction-the issue being addressed here* phrase interaction  or complementation  is restricted by two substantive constraints: 
 a  the argument which might be missing in the complement is always the subject  e.g.: in john persuaded mary to leave  the subject of the verb leave is not explicit in the text . 
 b  the missing argument is equated with either one of: 
 1  an object of the controlling verb  persuade in the example above   if an object exists  which is the case in the example   
cognitive modeling 
 1  the subject of the controlling verb if the object does not exist  as in john asked to go . 
this pattern of behavior holds for virtually all complementtaking english verbs. nonetheless there are some exceptions such as promise in john promised mary to go  or make in john made mary a fine husband such exceptions  although small in number  are significant since they could be used for testing the power of language-learning theories. if such exceptions did not exist  the learning of verb complementation would be trivial. indeed this behavior  of promise  accounts for errors in children's language  as recorded by carol chomsky  chomsky1   as in jenny's father promised her to go to disneyland meaning he promised her that she would go there . at this point  an example in context  in which it is clear that the father is supposed to go  can correct such a hypothesis. 
rina draws from both these approaches. rina's acquisition of lexical items concerns the mapping between syntactic patterns and their semantic concepts. however  granger's model was restricted to single words and simple script-like contexts. rina also addresses issues such as control and complementation. however  in our view  behavior of verbs reflects their semantics  and it is not just an arbitrary parameter which needs to be acquired to distinguish promise from persuade. concepts representing such verbs must account for two facts. the verb means that  1  one party conveyed fact to a second party  and  1  each individual verb denotes a different speech act performed by conveying that fact. thus learning the special syntax of promise is a by-product of understanding what promise means. 
pinker presupposes the existence of certain innate learning procedures. in his model  each language feature is accounted for by a custom-tailored procedure. for example  in learning the control aspect of complement-taking verbs  pinker assumes this preexisting rule  rule c1 : 
add to the lexical entry of the complement-taking predicate the equation x-comp's subj -  function  where  function  is the grammatical function annotated to the matrix argument that is coindexed with the missing complement subject in the contextually inferred semantic representation.    pink-
er1  pp. 1 . 
pinker has chosen lexical-functional grammar  lfg  
 bresnan1  as his linguistic framework. while lfg intends to denote a variety of linguistic phenomena  the rule c1 talks about lfg notation  but it certainly is not expounded in lfg terms. moreover  if a language-learning program requires such a specific procedural rule for each language feature  then the purpose of modeling learning in the first place is defeated. learning must be handled by a general declarative mechanism. in fact  the same unification mechanism which accounts for parsing and generation  should account also for learning. 
1 conclusions 
although the lexicon includes both specific and general phrases  the algorithm which constructs the hierarchy must require as input only specific episodes. this reflects human learning behavior. when communicating  people do not exchange syntax and semantics in form of rules  rather they communicate in terms of specific examples in context. 
accordingly we have shown a learning algorithm which augments a hierarchical lexicon as follows: 
