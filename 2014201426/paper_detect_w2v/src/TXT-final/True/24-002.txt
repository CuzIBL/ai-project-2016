 
in spite of the popularity of explanation-based 
learning  ebl   its theoretical basis is not well-understood. using a generalization of probably approximately correct  pac  learning to problem solving domains  this paper formalizes two forms of explanation-based learning of macro-operators and proves the sufficient conditions for their success. these two forms of ebl  called  macro caching  and  serial parsing   respectively exhibit two distinct sources of power or  bias : the sparseness of the solution space and the decomposability of the problem-space. the analysis shows that exponential speedup can be achieved when either of these biases is suitable for a domain. somewhat surprisingly  it also shows that computing the preconditions of the macro-operators is not necessary to obtain these speedups. the theoretical results are confirmed by experiments in the domain of eight puzzle. our work suggests that the best way to address the utility problem in ebl is to implement a bias which exploits the problem-space structure of the set of domains that one is interested in learning. 
1 	introduction 
explanation-based learning  ebl  treats learning as improving the efficiency of a problem solver  dejong and mooney  1  mitchell ei a/.  1 . the standard ebl systems start with complete and correct  if inefficient  problem solvers. learning involves taking a set of examples  i.e.  problem-solution pairs  as input and producing an efficient problem solver as output. the examples provide information about the problem distribution and eliminate the need to search for solutions. 
　while there are satisfactory formal models of empirical learning based on variants of probably approximately correct  pac  learning  valiant  1  haussler  1   ebl systems are not theoretically wellunderstood. there are some practical problems in ebl which can be directly attributed to the lack of adequate theoretical understanding. firstly  there is no clear definition of  success  for ebl systems. because of this reason there hasn't been a rational method to decide when to stop learning. any satisfactory formalization of ebl should specify what it means to succeed and should provide an effective method to recognize success. secondly  it is known that ebl systems do not always lead to performance improvement with learning. after learning a large number of rules  they might face what is called the  utility problem   i.e.  the problem of complexity of using the learned knowledge  minton  1 . since the utility problem can far outweigh the reduction in search due to learning  a successful formalization should take this into account and characterize the sufficient conditions for a guaranteed performance improvement. 
　this paper introduces a variation of the formal framework for performance improvement learning of  natarajan and tadepalli  1 . we call this framework probably approximately correct  pac  problem solving. using this framework  we analyze two forms of macrooperator learning  namely  macro caching and serial parsing. one of the main results of this paper is an explication of the biases exhibited by these two forms of ebl. in particular  macro caching and serial parsing implement two distinct biases:  a  the sparse solution space bias and  b  the macro table bias. the sparse solution space bias says that most problems in the domain can be solved by a small number of operator sequences. the macro table bias says that the solution to a problem can be constructed by serially composing a set of macro-operators that solve a series of subproblems. we show that when a domain and the hypothesis space of the learning system satisfy these biases  it leads to an exponential speedup in problem solving. somewhat surprisingly  the analysis also reveals that it is not necessary to compute the preconditions of macro-operators in order to obtain this speedup. the theoretical predictions of our analysis are confirmed by an implementation of serial parsing in the domain of eight puzzle. 
　the main contribution of this paper is a successful integration of ebl work with pac learning. it also extends korf's work on macro-operator learning  korf  1  to incremental learning by observation. our work also suggests that the utility problem in ebl can be solved by building learning programs that implement biases which exploit the domain structure. 
　the rest of the paper is organized as follows: section 1 introduces pac problem solving. sections 1 and 1 
　
describe macro caching and serial parsing  respectively. section 1 presents experimental results in the eight puzzle domain. section 1 discusses the related work  and the final section summarizes the contributions. 
1 probably approximately correct problem solving 
in order to formally analyze ebl  we need to precisely define what it means for ebl  or any other speedup learning method  to succeed. the problem definition in  mitchell et a/.  1  is not sufficient for our purposes  because it does not address the issue of learning from multiple examples. this section presents a definition which draws from the earlier formal frameworks presented in  natarajan and tadepalli  1 . 
　the key difference between purely empirical learning and ebl is that an ebl system is also provided with a  domain theory   which  we assume  is in the form of a set of goals and operators. however  this domain theory is too inefficient to use directly to solve problems. the operationality constraint of ebl  mitchell et a/.  1  may be viewed as defining a hypothesis space of potential efficient problem solvers  one of which is the target problem solver. in this paper  we view the problem of performance improvement as learning an efficient  approximate problem solver from the domain theory and the example solutions of some target problem solver in the hypothesis space. 
　define a problem domain d to be the tuple  s g 1   where 
this allows choosing the operator representation which is best suited to the domain rather than being constrained by the needs of the learning technique. 
　secondly  unlike the standard ebl approaches  our goals and operators are not parameterized. at first glance  this appears to seriously limit the power of ebl. somewhat surprisingly  this is not the case. this is because  for most domains  the maximum number of possible instantiations of any parameterized operator  or macro-operator  must be bounded by a polynomial factor so that the cost of instantiating it is not exorbitant. this means that every parameterized operator  or macro-operator  can be replaced with at most a polynomial  in the length of the state description  number of non-parameterized operators. to take a domain like chess as an example  every parameterized operator  e.g.  move pawn  can be replaced with n x n nonparameterized operators  e.g.  move pawn from e1 to e1   where n is the length of the state description  i.e.  the number of squares on the chess board. since  as our later definitions show  our formalization ignores all polynomial factors in sample size  learning time  and problem solving time  our results do not change whether the operators are parameterized or not. a parameterized model was considered and similar results were proved in  tadepalli  1 . for simplicity of exposition  this paper considers only non-parameterized operators. 
　a problem solver f for d is a deterministic program that takes as input a problem   s  g   and computes its solution sequence  if such exists. 
a hypothesis space h is a set of problem solvers. an example for a domain d is a pair   $  g    where is a solution sequence of  s  g .  
a meta-domain m is any set of domains. 
a learning algorithm for m is an algorithm that takes as input the specification of any domain d e m and some number of examples of problem solving with a target problem solver in h and computes as output an approximation for a problem solver for d. 
the learning protocol is as follows: first  the domain specification is given to the learner. the teacher then selects a problem distribution from a set of allowed distributions and a target problem solver from the hypothesis space. the learning algorithm has access to a routine called solved-problem. at each call  solved-problem randomly chooses a problem in the input domain  solves it using the target problem solver  and returns the example  the {problem solution  pair . the learning algorithm must output an approxi-
　
　notice that our domain specification is not as  explicit  as typical ebl programs require them to be. the operators need not be described in the strips formalism  and goals need not be logical formulae. in fact  they need not be declaratively represented at all  but may be described by procedures whose run time is reasonably bounded. thus  our learning framework requires the learning techniques to be more independent of the operator representation than the standard ebl techniques. 
1
　　this can be extended to partial functions by assuming that any operator  when applied to a state in which it is not applicable  will lead to a  dead state.  
mate problem solver with a high probability after seeing a reasonable number of examples. the problem solver need only be approximately correct in the sense that it may fail to produce correct solutions with a small probability. 
definition 1 formally  an algorithm a is a learning algorithm for a meta-domain m in a hypothesis space h with respect to a set of problem distributions t  if for any domain d m  any choice of a problem distribution p in t  and any target problem solver f  h  
1. a takes as input the specification of a domain d  
	tadepalli 	1 
m  an error parameter e  and a confidence parameter 1  
1. a may call solved-problem  which returns examples  x  f x   ford  where x is chosen with probability p x  from s xg. the number of oracle calls of a and its running time must be polynomial in the maximum problem s i z e a n d the length of its input.  
1. for all d m and distributions p t  with probability at least a outputs a program /' that approximates f in the sense that where fails on x while f succeeds}. 
1. there is a polynomial r such that  for a maximum problem size n    maximum length i and maximum step length r of any solution output by solved-problem  and an upper bound t on the running times of programs in d on inputs of size n  if a outputs f'  the run time of f1 is bounded by 

this framework is very similar to that introduced in 
 natarajan and tadepalli  1 . the main difference is the idea of the hypothesis space which is not present in  natarajan and tadepalli  1 . another difference is that it uses a less powerful solved-problem oracle than the useful oracle of  natarajan and tadepalli  1  which is capable of generating optimal solutions for any problem. we also insist that solved-problem must solve all problems using the same target problem solver chosen from the hypothesis space. 
　the first two conditions in definition 1 require that the learning algorithm must terminate and output the problem solver within reasonable computational time limits. the third condition requires that with probability at least 1 - 1  the learning algorithm should output an approximate problem solver for the domain. the problem solver is approximate in the sense that it is allowed to fail to find a solution with a probability less than e while the target problem solver succeeds when tested on problems chosen according to the same distribution that was used in training. note that the problem solver might find any correct solution and not necessarily the same solution that the target problem solver would have found. this is one reason why this framework is not subsumed by that of pac learning of functions described in  natara-
jan  1 . the final condition is to ensure that the problem solver output by the learning algorithm scales reasonably well. 
　we call this framework probably approximately correct  pac  problem solving. 
1 	macro caching 
in this section we describe macro caching and characterize the sufficient conditions for it to be a learning algorithm for a meta-domain. 
　we define a macro-operator  or a macro  to be any sequence of operators. macro caching consists of verifying that an operator sequence solves the problem by executing it  the  explanation  step of ebl  and storing the entire operator sequence from the start to the goal state in the example as a single macro. unlike the standard input domain specification d w  error parameter c  confidence parameter test-counter := 1 
1 := 1 
while test-counter    	do 
let solved-problem   return 
 problem  s y   solution b  
if  s  g  is solvable by the current problem solver 
then 
increment the test-counter by 1. 
else begin 
reset the test-counter to 1. 
update the problem solver by learning from 
i := i + 1 end; 
end while; 
output current problem solver; 
table 1: stochastic testing scheme. 
implementations of ebl  our algorithms do not rely on precondition computation. thus  a macro may only be viewed as a potential solution sequence  which must be tested at the problem solving time. the problem solver works by applying each macro to the current state and testing whether it succeeds. if some macro succeeds in achieving the goal  it returns the macro; otherwise it fails. 
　the idea is to pick enough examples so that after extracting the macros from these examples  one is reasonably certain that the learned problem solver is probably approximately correct. one difficulty remains  however. the number of examples necessary for successful learning depends on the the number of necessary macros  and we do not a priori know this number. hence  a different approach called  stochastic testing   used in  angluin  1   is adapted to our problem. the idea is to stochastically determine whether learning is complete by testing the program on randomly selected examples. in this  on-line  model  the program is tested as it is being trained  and the learning is terminated as soon as it succeeds on enough number of consecutive random examples. the testing scheme  described in table 1  has a slightly better bound on the number of test examples than that of  angluin  1 . 
definition 1 a problem solver f for a domain d and a problem distribution p satisfies a sparse solution space bias if there is a set of operator sequences mf such that  on any problem  
and is bounded by a polynomial q in the problem size n. 
　intuitively  the sparse solution space bias implies that there is a small number of operator sequences out of which solutions can be selected  so that the simple strategy of remembering all of them and trying them one by one would work well. the small number of operator sequences might be due to  a  the small number of problems that have a non-zero probability in the given problem-distribution  sparseness of problem distribution  or  b  the large number of states that satisfy the goal  high density of goal states   or a combination of both. to give an example of the second case  if a goal in the blocks world is to achieve a state in which there is a clear block on the table  it can be achieved by one of three macros: a null macro  a macro which puts the block being held in hand on table  and another macro which picks up a block on the top of a tower and places it on the table. this works for an exponential number of  in fact  all  initial states because an exponential number of states also satisfy the goal. 
theorem if h is defined by the set of problem solvers that satisfy the sparse solution space bias for all domains d in m and all distributions p in t  then stochastic testing with macro caching is a learning algorithm for m in h with respect to t. 
　proof  sketch : notice that  at any stage i  the learner has to succeed on  1 ln i -f 1  + in  randomly chosen test problems for the learner to terminate. at any stage i  the probability that the learner succeeds on all its tests when its macros are not  in fact  adequate to solve a randomly chosen problem with a probability greater than  i s less t h a n w h i c h turns out to be less t h a r . so  if the program terminates at some stage j  tne prodability that we have a problem solver whose probability of failure is greater than c is less than or equal to 
　by the sparse solution space bias  the number of macros necessary to solve the domain is bounded by a polynomial q{n t . since the lack of each such macro can cause at most one failure in our algorithm  the number of failures i satisfies . hence  the total number of iterations of the while loop  and the total number of examples needed is bounded by  which is a polynomial. it 
can be seen that the program runs in polynomial time.* macro caching's main limitation is due to its assumption that a small number of macros can solve most problems in the problem-space. for example  it does not work in domains like rubik's cube and eight puzzle  where each macro can solve at most one problem  and the problem distribution is not sparse. 
1 	serial parsing 
this section describes how ebl can succeed for arbitrary problem distributions by exploiting a problem-space structure called serial decomposability  korf  1 . 
　here we make the assumption that states are representable as vectors of discrete valued features   v1 ...  vn   where the maximum number of values a feature can take is bounded by a polynomial in n. 
　in rubik's cube  the variables are cubie names  and their values are cubie positions. in eight puzzle  the variables are tiles  and their values are tile positions. note that the above assumption makes it difficult to represent domains with relations  e.g.  the blocks world. 
　a domain is serially decomposable for a given total ordering on the set of features if the effect of any operator in the domain on a feature value is a function of the values of only that feature and all the features that precede it  korf  1 . 
　rubik's cube is serially decomposable for any ordering of features  also called  totally decomposable   . in eight puzzle  the effect of an operator on any tile depends only on the positions of that tile and the blank in the original state. hence eight puzzle is serially decomposable for any ordering that orders the blank as the first feature. 
　note that serial decomposability is a property of the domain as well as its representation. if eight puzzle is represented with positions as variables and tiles as their values  then it is not serially decomposable. 
　we assume that there is a single  fixed goal state described by  g 1  ... g n  . 1 
　korf defines a macro table as a set of macros mj i such that if mj i is used in a solvable state s where the features 1 thru i - 1 have their goal values  g1 .. . gi-1 and the feature i has a value j  then the resulting state is guaranteed to have goal values g1  ...  gi  for features 1 thru i. 
　korf showed that if a domain is serially decomposable and every state reachable from a solvable state is also solvable  then it has a macro table  korf  1 . if a domain is serially decomposable for the feature ordering 
 l ... n   then any move sequence that takes a state  can be 
used as a macro mj i-  since the values of features 1 thru i in the goal state only depend on their values in the  initial state  and not on the values of other features. 
　if a full macro table with appropriately ordered features is given  then it can be used to construct solutions from any initial state without any backtracking search  korf  1 . 
definition 1 a problem solver f satisfies a macro table bias for a domain d in m if there is a feature ordering o =  l ... n  such that   a  d is serially decomposable for o  and  b  f constructs all its solutions using a macro table m as follows: for each feature i from 1 to n  macros mj i are successively applied  where j is the value of feature i in the state before applying the macro. 
　since each application of macro mj i guarantees that the features 1 thru i will have their goal values  any solvable problem is solved in n macro applications by such problem solver. korfs learning program builds a macro table by exhaustively searching for a correct entry for each cell in the table  korf  1 . thus  korfs work might be characterized as  learning by doing.  our method  called serial parsing  extends his work to incremental learning of macro tables by observation. 
　instead of macro caching  the stochastic testing algorithm now calls serial parsing to extract the macros in a solution sequence. for a goal  g1 .. . gn   serial parsing proceeds from the beginning  varying i from 1 thru n  applying the operators in the solution to the current state   explanation  step of ebl   and collecting each operator subsequence that occurs between a state 
1 this can be generalized with parameterization. 
	tadepalli 	1 

and storing it 
as the macro mj i. if the domain is serially decomposable for the feature ordering 1 . . .n  this is guaranteed to yield correct macros. note that the structure of the macro table eliminates the need to compute the preconditions for macros. 
　for example  in eight puzzle  let r  /  u  and d represent the primitive operators of moving a tile right  left  up  and down respectively. macros are represented as strings made up of these letters. for notational ease  features  tiles  are labeled from 1 to 1  1 standing for the blank and i for tile i. a macro . represents the sequence of moves needed to get the tile to the goal position from its current position j  while preserving the positions of all previous tiles including the blank. the positions are numbered by the tile numbers in the goal state  which is assumed to be fixed. the goal state and an example start state along with a solution are shown in figure 1. 
　given the problem and the solution in figure 1  serial parser breaks down the solution as  amples the system constructs a table of macros. the problem solver works as described in definition 1. it fails if the macro table is missing some necessary macro at any point. 
　the result of this section can now be stated and proved. unlike theorem 1  the next theorem is distribution-independent. 
theorem 1 if  a  h is the set of all problem solvers defined by the macro table bias for domains in m  
1 1 1 1 1 1 1 	1 1 1 1 solution: drrdludruuldrdluuldrurdllurdurdl 
figure 1: a training example in eight puzzle 
 b  the number of distinct feature values in d is bounded by a polynomial function of maximum problem size  and  c  the feature ordering of the target problem solver is input to the learner  
then stochastic testing with serial parsing is a learning algorithm for m in h. 
　proof  sketch : we already saw that  if at some stage i  stochastic testing terminates  then  with a probability at least  it outputs a problem solver which has a probability of success of at least  we will now see that the number of examples and the running time of the algorithms are polynomially bounded. 
　conditions  a  and  b  imply the existence of a macro table  whose size  number of macros in the table  is bounded by a polynomial in the problem-size. conditions  a  and  c  guarantee that the serial parser would learn at least one missing macro from the example whenever the macro-based problem solver fails to solve a problem. hence  by arguments similar to those of theorem 
1  the examples are bounded by  which is a polynomial. it also follows that the learner runs in polynomial time. since the macro-based problem solver never needs to backtrack  it runs in time polynomial in all the relevant parameters.  
　the above theorem shows that serial parsing exploits serial decomposability  a problem-space structure which allows it to compress the potentially exponential number of solutions into a polynomial size macro table. 
　the macro table bias requires that the teacher's solutions  provided by the solved-problem  are composed from a macro table. this assumption is needed in the proof because serial parser can only learn a macro if the solution contains that macro. this assumption may not be true in general because  every problem might have several solutions  some of which may not be obtained by composing macros from a macro table. in fact  this assumption is most likely violated if the teacher gives only optimal solutions  because finding optimal solutions for the n x n generalization of eight puzzle is intractable  ratner and warmuth  1 . hence the macros learned from optimal solutions do not fit into macro tables. however  if the learner is allowed to ask queries  i.e.  ask the teacher to solve carefully designed problems  it is possible to learn macro tables in polynomial time irrespective of how the teacher solves the problems by designing a problem for each cell in the macro table and storing the solution as a macro. 
　

table 1: experimental results on eight puzzle. 
1 	experimental results 
serial parsing was implemented in the eight puzzle domain. the program sp  serial parser  was trained by randomly selecting a solvable problem  with uniform distribution   constructing a solution using a macro table  and giving them to the learner. sp was trained with stochastic testing for several values of and after each training session  it was also tested on 1 independent random test examples to estimate the error rate. the results are shown in table 1. each row represents the averages after training the system 1 times with the 
same values of 	and 	 
　the first column shows e which is set to be the same as 1. the second column shows the total number of examples used until after the last macro was learned. the third column shows the number of examples used for stochastic testing after the last macro was learned. the fourth column shows the total number of examples used. the fifth column shows the total number of macros learned. the sixth column shows the error rate after learning was complete  averaged over 1 independent test problems. the final column shows the cpu msecs for solving a single problem after learning was complete  averaged over 1 problems.  the measurements were 
taken on a sun sparcstation 1 with 1mb of real mem-
ory.  
　the full macro table contains 1 macros. in most cases all 1 macros were learned even when e and s were set to high values. the number of examples increased with decreasing e and 1  as can be expected. the most important thing to notice is that the system was able to learn the full macro table with approximately 1 training examples. with macro caching   1 macros and many more examples would have been required for perfect learning! 
　it is clear from the last column that our program did not suffer from the utility problem. the cpu time was fairly constant with decreasing and after learning was complete  sp was able to solve any randomly chosen solvable problem in less than 1 msecs of cpu time. the two main reasons for the speed of sp are :  a  the macro-based problem solving is linear in the length of the solution  and  b  the operators and goals are represented efficiently and avoid the overhead of the logical representations. 
1 	discussion and related work 
recently  there have been a few formal frameworks proposed to capture performance improvement learning. for example   cohen  1  analyzes a  solution path caching  mechanism and shows that organizing the solution sequences of the examples in a tree and restricting the search of the problem solver to this tree improves the performance of the problem solver with a high probability. solution path caching is similar to macro caching in that they both can be shown to be polynomial-time learning algorithms for domains defined by sparse solution space bias. by defining learning as producing a polynomial-time problem solver as opposed to simply running faster than the original problem solver  we have more stringent conditions on successful learning in our framework. hence  solution path caching  like macro caching but unlike serial parsing  fails to learn  by our definition  in domains like eight puzzle. 
　greiner and likuski formalize ebl as adding redundant learned rules to a horn-clause knowledge base to hasten query-processing  greiner and likuski  1 . this model is extended to recursive domain theories in 
 subramanian and feldman  1 . they conclude that learning macro-rules in ebl in such domains is not profitable in general unless strong assumptions are made about the problem distribution. while our result on macro caching is consistent with their conclusion  we also show that the structure of the problem-space can be exploited to make learning profitable in other domains. 
　serial decomposability is just one example of a problem-space structure.  etzioni  1  describes another kind of problem-space structure called  nonrecursive explanations  which explains the successful performance of prodigy in a number of domains. 
when this structure is present  the size of the explanation of a control heuristic is independent of the solution length. somewhat surprisingly  etzioni also found that examples were not the key reason for prodigy's successful performance  etzioni  1 . etzioni's program static matches prodigy's performance by statically analyzing the problem-space without using any examples. thus  even though  etzioni  1  explains why prodigy works  it fails to explain the role of examples in ebl-type systems in distribution-independent learning. this paper shows that ebl can gain from the problem-space structure as well as examples. the examples play two roles: first  they provide distribution information that determines which macros are worth learning  and second  they help the learner avoid expensive search for macros. 
　serial parsing is given the order in which subgoals are achieved. in systems like soar that successfully learn macros using ebl  the goal ordering is implicitly given by defining the subgoals such that they include one another  laird et a/.  1 . in  tadepalli  1   a method called batch parsing is described which learns the subgoal ordering along with macros for the subgoals. the basic idea here is to learn the macro table column by column  using multiple examples to disambiguate the feature that corresponds to a given column. ichalasani et a/.  1  describes algorithms that detect serial and to-
	tadepalli 	1 
　
tal decomposability by experimentation. 
　one consequence of our formalization is that it blurs the distinction between ebl and empirical learning. to the extent that the output of an ebl method depends on examples  ebl is also an empirical method. we showed that ebl systems also have syntactic biases in that their performance is based on some assumptions about the structure of the target problem solver. the main difference between the  empirical  and the  explanationbased  approaches seems to be that the ebl systems also have a  semantic bias  in that their hypothesis space is also constrained by consistency with their domain theory. 
1 	conclusions 
the main contribution of this paper is an integration of 
ebl with formal machine learning. the most important result of our analysis is an explication of the biases that allow ebl methods to guarantee performance improvement in the limit. conditions which were thought necessary for ebl to work  e.g.  declarative representation of operators  were found to be not so crucial from our analysis. on the other hand  the structure of the problemspace and the distribution of problems were found to be very important. our paper also integrated korf's work on macro-operator learning with the ebl work. 
　our work suggests that the best way to solve the utility problem is to implement a bias that exploits the domain structure. in the future  it is worthwhile to investigate the kinds of biases that occur in natural domains and implement them in new learning algorithms. as in empirical learning  this means that the program is then not suitable for domains which do not satisfy this bias. we think that the best way to address this generality issue is to build a variety of learning systems which are appropriate for domains with different problem-space structures. 
acknowledgments 
i am indebted to balas natarjan for his generous help and advice throughout this work. i thank prasad char lasani  tom dietterich  oren etzioni  nick flann  sridhar mahadevan  tom mitchell  balas natarajan  and armand prieditis for many fruitful discussions. i also thank them  barney pell  and the anonymous reviewers of this paper for their comments. i thank walter rudd for his generous support and encouragement. 
