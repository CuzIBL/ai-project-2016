 
       this paper describes a parsing system s p e c i f i c a l l y designed f o r spoken rather than w r i t t e n i n p u t . the parser is part of a p r o j e c t in progress at stanford research institute to develop a computer system for understanding speech. the approach described uses as much h e u r i s t i c knowledge as possible in order to m i n i mize the demands on acoustic analysis. 
parsing speech 
　　　parsing continuous spoken english is a s i g n i f i cantly d i f f e r e n t problem than parsing w r i t t e n english  there are at least two major differences between spoken and t e x t u a l input. 
　　　f i r s t   spoken input is not as easily decoded as text i n p u t . there are d i f f i c u l t i e s associated with 
e s t a b l i s h i n g the boundaries of the p a r t i c u l a r words in the acoustic stream  w i t h accounting f o r the v a r i a t i o n s of a word by d i f f e r e n t speakers  for d i f f e r e n t pronunc i a t i o n s of a word by the same speaker  and for d i f f e r ent pronunciations of the same word in d i f f e r e n t cont e x t s . recognition of spoken input words is much more complex and much leas r e l i a b l e than recognition of w r i t t e n input words. 
　　　second  speech provides information by prosodic features-intonation  stress  pause  juncture 1 for 
example  intonation contours  the variations in pitch and rhythm in an utterance  provide clues to the location of phrase boundaries and to syntactic relationships of the words.  work is now being done  particularly at the un1vac corporation1 and at the university of michigan *'1 on how to extract such information from the acoustic signal and how to incorporate it into a grammar for the computer.  
a strategy for parsing speech 
     in one approach to parsing text  the parser reads the input words  looks them up in the lexicon  and uses their syntactic features for guidance. 	this approach ie much less desirable for parsing speech because of the problem of reliably separating and identifying the input words using current acoustic techniques. 
　　　because of this limitation of acoustic recognition  we have chosen to restrict the detailed acoustic processing to testing words that have been hypothesised by the parser on the basis of a wide range of syntactic  semantic  and prosodic knowledge. we expect the shift to verification of parser-proposed words to lead to more reliable acoustic decisions since the verification algorithms can be tailormade for the individual words and can take context into consideration. moreover  by hypothesizing words in order of their likelihood in a particular context  we should be able to reduce the average number of incorrect words proposed and  hence  the potential for errors in acoustic recognition. 
     an early version of a system partially using this approach has been put together by making modifications to terry winograd's 	program.1 	our new system is not 
directly based on winograd's program  but it reflects his influence. it also has been influenced by the work of b i l l woods and ron kaplan on parsing systems. 1 ' 1 ' 1 
　　　while keeping the approach mentioned above  the new system differs from the old one in many ways. significantly  it uses a  best-first  parsing strategy in place of the more conventional  depth-first  strategy. both strategies are designed to deal with  choice points  in the grammar-places where there are several alternatives for continuing the parse but not enough information available to decide among them. with the depth-first strategy  choice points are handled by using  backtracking.   a single path from the choice point is pursued until an inconsistency with the input is found. at that time  the path is permanently abandoned. the parser is backed up to the most recently encountered choice point to try the next alternative.  
　　　there are several reasons why this depth-first method is unattractive for parsing speech. first  the uncertainty of acoustic recognition makes it d i f f i c u l t to decide conclusively whether a path should be abandoned. with speech  it makes more sense to deal with the likelihood of a path than with a categorical acceptance or rejection. a second objection is that the 
depth-first strategy makes it impossible to hypothesize words in order of their likelihood. before the other alternatives at a choice point can be considered  a l l possibilities for satisfying the f i r s t alternative must be explored. this forces the testing of all words corresponding to the f i r s t alternative regardless of their likelihoods. a final objection to the depth-first strategy is that it explores many more false paths than a strategy using heuristic knowledge to guide the parse. extra false paths are particularly bad for speech because of the high cost of the acoustic tests needed to determine that a path is a dead end and the danger 
of following false paths farther than necessary due to uncertain acoustic recognition. research in a r t i f i c i a l intelligence has shown that substantial increases in efficiency can result from the application of heuristic knowledge to guide searches. equivalent gains should be possible if knowledge is used to guide the search for successful parse. 
*see for instance nllsson's book and the work referenced there. 1 
　　　these considerations a l l support a b e s t - f i r s t parsing strategy. in this approach  each new path r e s u l t i n g from a choice point is assigned a p r i o r i t y according to i t s estimated l i k e l i h o o d of leading to a correct parse. the paths are then added to the set of a l l paths that have been generated but not yet extended 
during t h i s parse. the system follows the highest p r i o r i t y path from the comprehensive set u n t i l i t s p r i o r i t y drops or it reaches a choice p o i n t . at that time the cycle repeats. since the new path chosen need not be one of the successors of the previous path  the parser w i l l not necessarily continue along a single path u n t i l it reaches a dead end. instead  it w i l l suspend a path 
when there is an a l t e r n a t i v e available with a higher estimated l i k e l i h o o d . it w i l l resume the o r i g i n a l at a l a t e r time if it becomes most l i k e l y again. 
　　　the b e s t - f i r s t method avoids the objections made to the d e p t h - f i r s t strategy. f i r s t   it is not necessary to decide conclusively that a path is inapprop r i a t e   to force a  yes or n o .   the gradations of confidence in acoustic tests can be r e f l e c t e d in a range of p r i o r i t i e s . second  words can be hypothesized in order of t h e i r l i k e l i h o o d since there are no constraints imposed by the parsing strategy on the order in which paths are explored. and f i n a l l y   the number of false paths explored can p o t e n t i a l l y be reduced by using h e u r i s t i c knowledge to guide the parse. 
　　　of course  t h i s p o t e n t i a l f o r reducing false paths can be realized only if extensive knowledge is successf u l l y incorporated. winograd made a noteworthy step in t h i s d i r e c t i o n by using semantics to f i l t e r out unint e r p r e t a b l e phrases as soon as they were parsed. but more can be done; knowledge can be used to guide the parsing rather than to act simply as a passive f i l t e r   and a wider range of knowledge can be used . for instance  in addition to semantics  the parser could be guided by such things as prosodies  s t a t i s t i c s regarding vocabulary and syntactic constructs  models of the user and the d i a l o g . 
	control 	structures 
　　　the attempt to incorporate more knowledge may appear foolhardy in the l i g h t of the great complexity of e x i s t i n g systems. winograd himself has remarked that his program was nearing the l i m i t s of comprehens i b i l i t y ; our early system was c e r t a i n l y no b e t t e r . to combat t h i s problem  we have introduced control structures to encourage the c a r e f u l   systematic use of h e u r i s t i c knowledge and aid clarity of the parser. 
       the c o n t r o l structures d i f f e r e n t i a t e between the p r i o r i t y functions that embody the special knowledge and the other parser functions that embody the grammar. the grammar functions alone define the possible paths  while the h e u r i s t i c functions control the order in which the paths w i l l be explored. in this way the grammar is not obscured by the logic needed to assign p r i o r i t i e s . the d i v i s i o n is maintained by providing each a l t e r n a t i v e w i t h i t s own p r i o r i t y f u n c t i o n . this both f u r t h e r s the incorporation of knowledge and sim-
p l i f i e s the development of h e u r i s t i c s . we do not have to t r y to b u i l d an omniscient semantics module capable of evaluating any c o n f i g u r a t i o n ; our system w i l l use the p a r t i c u l a r semantic considerations in conjunction with other relevant information s p e c i f i c to a place in the grammar. 
　　　control structures also replace goto's with functions that give a clear and e x p l i c i t form to the stan-
dard parsing operations such as l i s t i n g alternatives and i d e n t i f y i n g optional elements. we agree with d i j k s t r a and others who find goto's p a r t i c u l a r l y harmf u l to program c l a r i t y . 1 - 1 many other parsing systems have treated the program as a c o l l e c t i o n of labeled blocks of instructions with control transferred a r b i t r a r i l y by explicit  reference to l a b e l s . this amounts to the unconstrained use of goto's whether the p a r t i c u l a r syntactic form is a m u l t i d i r e c t i o n branch statement  a state t r a n s i t i o n   or a production language formalism. the elimination of goto's is probably the most important way in which the control structures reduce the complexi t y of the parser. 
　　　f i n a l l y   there are advantages in developing the control structures as an extension to the lisp language. these include complete freedom in the use of procedures for s t r u c t u r i n g the system  a v a i l a b i l i t y of the control and data manipulation f a c i l i t i e s of lisp  and compatib i l i t y with standard debugging and program development aids . 
　　　before describing the control structures that have been added to lisp  it is useful to review the o v e r a l l parsing strategy and introduce some new t erminology. as the system attempts to understand an input  it uses the grammar to generate a sequence of paths. corresponding to each path is a  process.  the l i k e l i h o o d of a path is determined by p r i o r i t y functions and is reflected in the value of the p r i o r i t y for the process. p r i o r i t i e s are p o s i t i v e numbers whose values are i r r e l evant except to establish an order of a l l the processes. the highest p r i o r i t y process is run u n t i l c i t h e r i t s p r i o r i t y drops as a result of some test or it reaches a choice p o i n t . in e i t h e r case  control is transferred to the highest p r i o r i t y member of the l i s t of processes. parsing continues u n t i l an acceptable i n t e r p r e t a t i o n of the input is found or some resource bound is exceeded. 
1        with t h i s strategy in mind we can discuss the actual control functions. the most basic of these is alt  which is used to l i s t alternatives . its syntax is  alt a l t 1 . . . a l t n     where each a l t . is of the form {altname a l t p r i o r i t y e 1 . . . e n   . altname is a unique name f o r t h i s a l t e r n a t i v e . the use of the name is described in the section paths and maps. a l t p r i o r i t y is evaluated to determine the p r i o r i t y to be given the process corresponding to t h i s a l t e r n a t i v e . f i n a l l y   e 1 . . . e n specify the action for t h i s a l t e r n a t i v e . actions can include c a l l i n g other control functions or procedures that include control functions. in other words  there is complete freedom in dynamically nesting control s t r u c t u r e s . the effect of the alt is to replace one process by several new ones. each new process independently can continue the computation started by the o r i g i n a l process. when one has finished i t s action e. . . . e   it can immediately go on to the statement following the alt. 
     a second control function is option  which is used to identify optional components in the grammar. its form is  option optname optpriorities e1 ... e n    where optname is a unique name for this option  optprlorities evaluates to a pair of priorities  and e1 . . . en specify the optional action. the f i r s t of the priorities is assigned to a process that w i l l execute e1..............en  and the second to a process that will simply go directly to the successor of the option. 
     sequence is similar to option. on entry to sequence the process bplits into two-one which executes e1..............en  and one which does not. however  
unlike option  the f i r s t process reenters sequence after completing e n . this leads to computing another 
pair of priorities and spliting into one process 
which executes e1..............en a second time and one which does not. in this manner  the sequence statement can be reentered an arbitrary number of times to parse an arbitrarily long sequence of constituents satisfying e1..............en. . 
1 	n 
     the fourth control function is optionalif. its form is  optionalif condition name priorities 
e1...................en . if the condition is true then e1 . . . e 
1 	en 	i	n 
are optional; otherwise they are required. the name and priorities for optionalif are like those for option and are used only if the condition is true. 
　　　the final function is parse  used to call the program for a grammatical unit. its syntax is  parse unit arg1.......arg1   where unit is the name of the function to be called for a grammatical unit and arg1.......... argn are optional arguments for that function. the result of parse is a parse tree for the unit. parse also plays an important role in the implementation as discussed below. 
an example 
　　　having discussed the major elements of the parser  we w i l l now present a sample grammar for a noun phrase  figure 1 . unfortunately  an example small enough to present here cannot fully demonstrate the value of this approach in developing a large system. but this 
example can illustrate the format of a grammar. listings of a much more complete grammar are available from the authors. 
     the example grammar is a lisp program called noungroup. the f i r s t statement in it is an alt. in this example  the f i r s t alternative is 
 article  artpresent  
 wdtype article   
     altname is  article   altpriority is computed by the function artpresent  and the action for this alternative is the call to wdtype. the function wdtype finds in the input a word of the category specified by its argument. 
　　　in this example  alt 1 looks for an i n i t i a l article in the noun group  alt 1 through alt 1 look for a demonstrative adjective  quantifier  pronoun and thing pronoun respectively. the last alternative  alt 1 
 labeled null  allows the noun group to start directly with an adjective or noun. 	the statement following the alt controls the parsing of optional adjectives and the head noun. 	these are not allowed after a thingpron  are optional after either a demonstrativeadj or a quantifier  and are required in a l l other cases. this is represented in the program by an optionalif inside a cond. 	the final statement of noungroup looks for modifying relative clauses or prepositional phrases. 
this grammar will find constructions such as: 
the big green table  
 that part  
 some narrow pieces  
 something  
 everything green  
 he     i t   
     all of these except the pronouns can be followed by a sequence of modifying phrases. relative clauses such as  which you dropped  and  that was picked up  or prepositional phrases such as  on the floor  and  under the table  are modifying phrases. 
word verifier 
     another important part of the parsing system is the word verifier. 	this component testa acoustic data for the presence of words from such terminal categories as noun  verb  and adjective that are predicted by the 
parser according to some path through the grammar. the words in the terminal category can be thought of as alternatives  exactly like the higher syntactic alternatives in the grammar  that should be considered in order of their likelihood. the same structure of alternatives and priorities is here found on the level of word verification. estimated likelihoods can not only order the words in the terminal category  but also defer acoustic processing as long as higher priority alternatives remain to be explored. 
     the word verifier must f i r s t establish a priority for each candidate word and then  according to those 
priorities  schedule acoustic verification. corresponding to these two operations there is a priority function and a verification function associated with each word in the vocabulary. the tests made by the priority function are computationally simple  although broad in scope. the results of preliminary acoustic processing are consulted to ensure that the word is at least feasible. the frequency of occurrence of the word and the likelihood of co-occurrence of the word with recently 
used words are considered. finally  the semantic features of the word are compared to the semantic restrictions of the context. 
　　　in contrast to the quick tests made by the p r i ority function  the verification function may perform extensive acoustic analyses to determine how well the proposed word matches the next portion of input. 	the details of this processing are beyond the scope of this paper but have been sketched elsewhere.1 	since the verification function depends only on acoustic information  its results are saved so that  if another process looks for the same word in the same place  the prior results can be used. 	of course  the results of the priority functions cannot be reused in this manner since they are extremely dependent on context. 

1  

figure 1 

paths and maps 
　　　in the word verifier  we have seen how one process can use information gained by another; the results of a verification function can be used by a subsequent process looking for the game word. the next step is to share the syntactic structures that are found. but the processes may have had different contextual constraints and may need to make different tests  problems for direct sharing. we have added paths and maps to the parsing system to facilitate sharing and to allow for additional tests. 
this is closely related to the well formed substring f a c i l i t y described by woods.1 
     a path describes the flow of control through the grammar leading to the current state of a process. for example  at alt statements the name of the alternative taken is added to the path  and when a word is recognized in the input it also is added. the actual structure of the path is a list of names and words with the most recent history of the process at the front of the l i s t . a map is the part of the path that was followed by a process when it successfully parsed some 
1 grammatical unit. the function parse automatically records the map before it returns  and it checks for a map when it is called. 
　　　the control functions  alt  option  optionalif  and sequence  consult the map and raise the p r i o r i t y 
of the named a l t e r n a t i v e . the map thus helps to guide the process which is parsing a constituent by cont r i b u t i n g data on a l t e r n a t i v e s successful in p r i o r attempts. 
　　　nevertheless  it is s t i l l possible that the map w i l l f a i l due to differences in the context. when a process is forced o f f the path specified by a map  it simply reverts to the standard mode of parsing. this ensures that the use of maps w i l l not r e s u l t in the acceptance of a previously parsed constituent that f a l l s to meet the current c o n s t r a i n t s . the map merely serves as h e u r i s t i c knowledge to guide the reparse and can be overridden by other considerations. 
branch point are shared by more than one process. only the variables in terminal sections can be modified by the process without i n t e r f e r i n g w i t h other processes; the variables in nonterminal sections must not be changed. this presents a problem when the process 
wishes to r e t u r n from the f i r s t  nearest the root  function in the terminal section to the last function in the l a s t nonterminal s e c t i o n . the process cannot 
such a return by parse . 
the path from the root to the 
t i p contains a l l the variables for the process. branch points the paths f o r several processes j o i n . 
thus the variables in the path from the root to the 
1 use that section because it is shared. the s o l u t i o n is to make a copy of it that w i l l have the same r e l a t i o n to other sections of the path as the shared section but w i l l be for p r i v a t e use of the process. to ensure that t h i s copying is done properly  each stack section begins w i t h a c a l l of parse  and instead of returning in the normal manner  parse makes a copy of the next section of the tree and t r a n s f e r s c o n t r o l to i t . this provides a new terminal section for the process and returns cont r o l to the function that called parse o r i g i n a l l y . figure 1 shows the e f f e c t on the stack s t r u c t u r e of 

　　　there are two main r e s t r i c t i o n s on the parser caused by t h i s implementation. f i r s t   data structures which are not intended to be global to a l l processes cannot be changed except after copying. this is to avoid interference between processes which may be sharing the same s t r u c t u r e s . for example  if process p in figure 1a  has a variable x'whose value is a l i s t   then processes p 1 through pn in figure 1b w i l l a l l have variables pointing to the same l i s t   i n lisp terminology  the x's w i l l be eq . to change the value of x  process pi must store a new pointer in x rather than modify the o r i g i n a l structure pointed to by x. while t h i s r e s t r i c t i o n has affected the design of the parser  it has not been a serious problem. 
　　　the second main r e s t r i c t i o n on the parser  that only variables w i t h i n the terminal section of the stack can be changed  did present a problem. certain variables such as the current p o s i t i o n in the input are private to each process but global w i t h i n the 
process. the solution is to i d e n t i f y such variables to the system as  process g l o b a l s .   on entry to parse  the process globals are rebound to t h e i r old values. thus they are w i t h i n the terminal section and can be given new values. before parse e x i t s   it propagates the process globals back up the stack. for example  in going from figure 1a to figure 1b  the process globals for p are propagated from section b to section a   . by generalizing t h i s scheme  variables can appear to be bound at any l e v e l . thus we can eliminate the second r e s t r i c t i o n on the parser by i d e n t i f y i n g certain special variables to the system. 
　　　the implementation has the prime advantage of avoiding a special i n t e r p r e t e r for the parsing language  since the  language  consists of additional lisp funct i o n s   the e n t i r e parser can be compiled w i t h the standard lisp compiler and debugged with the standard lisp debugger. this means f a s t e r execution and easier debugging. of course  the biggest improvement in e f f i c i e n c y r e l i e s on knowledge to guide the parser  but compilation w i l l give a substantial speed up in a d d i t i o n . 
conclusion 
　　　the system described in t h i s paper is part of an. ongoing research project in speech understanding and is intended to provide a s o l i d basis f o r continuing 
work. there are many other aspects to speech understanding besides the development of a parser system. it has been to our benefit to be part of a speech proj e c t at sri that includes personnel interested in a v a r i e t y of tasks from acoustic signal processing through semantic representation to o v e r a l l system organization  
　　　a sizeable grammar for english has been w r i t t e n using t h i s parsing system. although it is d i f f i c u l t to characterize the scope of a grammar  it appears to 
be as extensive as others we are f a m i l i a r with   i n p a r t i c u l a r those of winograd 1 and woods  et a l . 1   . 
our current e f f o r t s center on acoustic processing 
these functions of course depend on the multiple environment control f a c i l i t y in bbn-lisp. routines for use in word v e r i f i c a t i o n   p r i o r i t y functions for grammatical alternatives  and semantic modeling of the domain of discourse. 
acknowledgements 
　　　we would l i k e to thank the people in the project f o r helping us to see some of the problems involved in speech understanding and to develop the approach to parsing speech described in t h i s paper. project leader don walker has been p a r t i c u l a r l y h e l p f u l in t h i s respect. we have also benefited from discussions with other participants in the advanced projects agency speech understanding program. 1 the research reported herein was supported at sri by the advanced research projects agency of the department of defense  monitored by the u.s. army research office-durham under contract dahc1 c 1. 
