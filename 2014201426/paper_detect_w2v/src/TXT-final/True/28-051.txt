 
we describe an approach to the problem of managing resources in routine decision-making tasks. the central feature of this approach is the use of reusable rap-like plans to generate decisions. this allows our system  apex  to take advantage of the flexibility in scheduling and method selection provided by execution mechanisms and thereby minimize or circumvent resource conflicts. we then discuss an application of apex for simulating a human air traffic controller in order to aid in the evaluation of radar display designs. 
1 introduction 
in this paper  we describe an approach to managing resources in routine decision tasks and apply this approach to a practical problem. routine decisions are choices that occur regularly in an agent's everyday tasks. for example  drivers are often faced with decisions such as whether to slow down for a yellow light and whether to turn at an oftenencountered intersection. making such decisions involves several resource-demanding activities including acquiring decision-relevant information  internally or from the task environment  and making inferences. in time-pressured conditions  or when multiple tasks compete for the same computational and perceptual resources  the ability to manage scarce resources becomes an important determiner of agent performance. 
researchers have taken a variety of approaches to managing resources  especially computational resources  when deciding action in realistically complex  dynamic task environments. one approach is to eliminate certain expensive computations. reactive planners  for example  use only current perceptions to conditionalize action choice  thus avoiding the expensive computations required to construct plans and retrieve items from memory. some systems avoid specific classes of inference such as the 
1 	cognitive modeling 
prediction of future states and deductive retrieval  firby1 . others allow expensive operations when they are most likely to prove essential but otherwise avoid them 
 chien1 ;hayes-roth1 . 
a second approach is to delay decisions until relevant information can be acquired cheaply  or at all   thus avoiding the computationally expensive process of conditionalizing decisions on a large number of possible future states. systems that employ this approach  firby1; gat1;simmons1;pell1  are referred to as execution systems since they interleave planning  deciding action  with plan execution. 
our system's plan execution component  like the rap system  firby1  on which it is based  combines these approaches but differs from previous systems in how it handles routine decisions. in particular  routine decision tasks are treated in a uniform manner with tasks of other kinds - i.e. they are carried out by general-purpose taskexecution mechanisms in accordance with task-specific  variablized plan structures called methods. methods consist of steps  each corresponding either to a primitive action or to some non-primitive that must be decomposed into substeps by selecting a more specific method. 
1 decision-methods 
the use of specialized decision-plans has a number of advantages. in particular  plan execution mechanisms can begin  abort  retry  interrupt  resume  specify and terminate decision tasks as needed to handle situational constraints and coordinate resource use with other tasks. consider  for example  the method below for deciding between alternative routes home from work. 
 method-1  decide-route-from-work-to-home  
 stepl  acquire-info:time-of-day =   time   priority +1   
 step1  acquire-info:day-of-week =   day   
 step1  infer rule-1  time  day =   best-route  
 wait-for stepl step1    
in this case  the decision is based solely on whether or not the agent is likely to face rush hour traffic  a function of the time of day and day of week. the two information acquisition steps are carried out in parallel  each by one of several methods. for instance  day of the week information is acquired either by checking a calendar or querying memory for the current day. when these steps complete  an inference rule is applied to decide the best route. information acquisition tasks can fail and thus fail to provide a value to a decision-relevant variable- e.g. when no calendar can be found and no information on the current day can be acquired from memory. similarly  execution may omit an information-acquisition task in response to timepressure or other factors. in these cases  the inference-rule will rely on a default value - e.g. that today is a weekday. 
this framework provides two means for managing resource use in routine decision tasks. first  execution mechanisms can control the timing of resource-demanding tasks by interruption  delaying task initiation  or delaying resumption. for example  if finding a calendar would take perceptual resources  gaze  away from a higher priority task  execution mechanisms can delay this action until the higher priority task completes. second  since different informationacquisition methods will generally differ in type and amount of required resources  methods can be selected in order to allocate resources them most effectively. for instance  if finding a calendar is prevented by a higher priority use of the gaze resource  execution could try retrieving the information from memory or using the null-method  i.e. omitting information acquisition and forcing reliance on a default  which requires minimal resources. 
method-selection in our system is handled by methodselection-rules  msrs  whose syntax mirrors that of the cond macro in lisp. msrs employ both transient and long-term knowledge. relevant long-term knowledge can include: the expected interval during which resources must be allocated to a method for it to complete; the usual level of competition for resources from other tasks present during execution of the decision-task  expected workload ; the usual amount of time available to complete the decision-task  expected urgency ; and the likelihood that the default value associated with an information-acquisition task will prove accurate. such factors determine the expected utility of alternative information acquisition methods and thus determine a stable preference between alternatives. taken together  the method preferences for all steps of a decisionmethod constitute a baseline decision strategy. 
transient information can be used to adapt a decision strategy to an agent's current situation. the current model supports adaptation from several kinds of information including especially: subjective workload and default counterevidence. subjective workload corresponds to an agent' s evaluation of its overall  busyness  compared to expected workload. during periods of unusually high workload for a given decision task  decision strategy is biased in favor of the least resource-demanding methods. in some cases  this will cause decisions to rely on defaults when more reliable information acquisition methods would normally be selected. 
default counterevidence is knowledge that the default value for some decision-relevant factor is likely to prove incorrect for some time into the future. for example  an agent may tend to assume that today is a weekday when deciding a route home from work. deciding to go into work on a 
weekend day invalidates this assumption and should  temporarily  reduce the system's tendency to rely on it - i.e. it should bias execution mechanisms to avoid using the default. this function is carried out by task-specific bias rules. since avoiding reliance on valid defaults wastes resources  bias rules must specify a duration  after which their effect expires. the length of this interval depends on the expected duration of the non-default condition and the expected interval between successive observations of the condition if it persists.1 the system will thus tend to rely on invalid defaults when the default condition lasts for an unusually long time or when an unusually long period has passed since the condition was last observed. 
1 application: user interface evaluation 
we have incorporated this approach to routine decision making into action selection mechanisms of our human operator model  apex.1 the model consists primarily of two components: action selection mechanisms based on the rap plan execution system  and a resource architecture which describes limitations on perceptual  cognitive  and motor resources and constrains action selection mechanisms to operate within those limits. 
1 to err is human  to prevent error is good design 
apex is intended to address a fundamental problem in the design of user interfaces. in particular  newly designed equipment and procedures often inadvertently facilitate human error. techniques for identifying error facilitations in design tend to be either ineffective or very expensive. for example  one of the most effective ways to test new designs is to hire human operators to carry out tasks using prototyped equipment  and then observe their performance in a wide range of operating conditions. in our domain  air 
 see  freed1  for information on how the bias duration parameter is set. 
1  architecture for procedure execution 
	freed & remington 	1 

traffic control  such tests typically require hiring highly paid expert controllers as subjects  often for extended periods. the limited amount of testing that results from high cost can stifle innovation and compromise safety. 
one way to get some of the benefits of a  human in the loop  study at much lower cost is to use a computer to simulate all elements of such a study including the equipment  human operators  and experimental observers. human simulation has been used successfully by others to guide design  e.g.  john1 corker1  . however  ours appears to be the first system to employ the powerful and versatile action selection mechanisms provided by ai plan execution systems  and thus the first able to function effectively in inherently complex  dynamic  and uncertain domains such as air traffic control. by employing action selection mechanisms designed for robot control  our model overstates human capabilities in some ways  but can operate in domains where predicting human error would be most useful. 
though not specifically designed to make errors of any kind  our approach to managing the resource cost of routine decision-making enables apex's plan execution component to help predict a type of error sometimes referred to as a  habit capture   reason1 . habit captures are defined by their apparent cognitive cause. in particular  people make such errors when  instead expending resources to acquire reliable information  they act in accordance with a false but usually reliable default assumption. habit captures are reported quite frequently in naturalistic studies of error  reason1 . for example: 
 i went to the bedroom to change in to something more comfortable for the evening  and the next thing i knew i was getting into my pyjama trousers  as if to go to bed. 
 i had decided to cut down my sugar consumption and wanted to have my cornflakes without it. but the next morning  however  i sprinkled sugar on my cereal just as i always do.  
in our view  much of people's tendency to rely on default assumptions can be explained as adaptations to regularities in the task environment. for instance  people will be more likely to rely on a default if  apriori  it is especially likely to be true or if the environment reliably provides default counterevidence when it is false. this view provides a basis for predicting when people will rely on false defaults and make habit capture errors as a result. 
1 	cognitive modeling 
1 an example 
at a tracon air traffic control facility  one controller will often be assigned to the task of guiding planes through a region of airspace called an arrivals sector. this task involves taking planes from various sector entry points and getting them lined up at a safe distance from one another on landing approach to a particular airport. some airports have two parallel runways. in such cases  the controller will form planes up into two lines. 
occasionally  a controller will be told that one of the two runways is closed and that all planes on approach to land must be directed to the remaining open runway. a controller's ability to direct planes exclusively to the open runway depends on remembering that the other runway is closed. how does the controller remember this important fact  normally  the diversion of all inbound planes to the open runway produces an easily perceived reminder. in particular  the controller will detect only a single line of planes on approach to the airport  even though two lines  one to each runway  would normally be expected. 
however  problems may arise in conditions of low workload. with few planes around  there is no visually distinct line of planes to either runway. thus  the usual situation in which both runways are available is perceptually indistinguishable from the case of a single closed runway. the lack of perceptual support would then force the controller to rely on memory alone  thus increasing the chance that the controller will accidentally direct a plane to the closed runway. 
1 simulation 
when the simulated controller hears that the left runway is closed  interpretation mechanisms cause a propositional representation of this fact to be encoded in memory. the encoding event generates bias  default counterevidence  according to the following rule: 
 bias-rule-1 
 if  closed  rwy  
 create-bias method-1 step1  1 minutes     
newly generated bias is represented explicitly in memory along with a notation indicating when the bias will expire if not renewed. in this case  bias lasting 1 minutes causes decision mechanisms to consider the possibility of runway closure  step1 below  in cases where the usual state - all runways open - might otherwise be assumed. 
when a plane approaches its airspace  the simulated controller initiates a routine plane-handling method involving accepting responsibility for the plane  determining where the plane is headed  and then guiding it to its destination. if the plane's destination is los angeles airport  lax   guiding it to its destination will involve selecting between the airport's two parallel runways. for highly routine decisions such as runway selection  human controllers can reasonably be expected to know which factors to consider in making the decision and how to appropriately weight each factor. this knowledge is incorporated into the following decision method: 
 method-1  select-runway  plane  
 stepl  id-rwy-with-fewer-planes =   fewer    step1  id-rwy-fastest-approach  plane =  
 fastest   
 step1  id-rwy-easiest-for-me =   easiest   
 step1  id-rwy-better-microclimate =  climate   
 step1  id-available-runways =   available   
 step1  id-safest-rwy  plane =   safest   
 step1  infer rule-1  fewer  fastest ...  
 wait-for stepl step1 ... step1    
in most cases  more than one method will be available for acquiring information about a factor. in this example  the controller could determine runway availability by retrieving information from memory  asking another controller  or by assuming the most likely condition - that the runway is open. since runways closures are rare and memory retrieval is expensive  carrier1;stein1   the decision strategy underlying this method  along with associated msrs  prescribes reliance on the default assumption unless transient bias  default counterevidence  promotes a more effortful alternative. 
in the described scenario  bias produced after learning of the runway closure causes the agent to temporarily avoid reliance on the default. instead  for some time thereafter  the runway's availability is verified by retrieving information from working memory whenever a runway selection task occurs. eventually  the initial bias expires. to select a runway for a newly arrived plane  the agent's decisions will once again conform to the default assumption. other factors will then determine which runway is selected. for example  the controller may choose to direct a heavy plane to the longer left runway which  in normal circumstances  would allow the plane an easier and safer landing. with the left runway closed  actions following from this decision result in error. 
avoiding error requires maintaining appropriate bias. in a variation of the described scenario in which no error occurs  visually perceived reminders of the runway closure cause bias to be periodically renewed. in particular  whenever visual attention mechanisms attend to plane icons on an approach path to the airport  interpretation mechanisms note the absence of a line of planes to the left runway and signal an expectation failure. 
 expectation-generation-rule-1 
	  i f 	 and 
	 not 	 visual-group plane-icons 
ift-rwy-path   
 visual-group plane-icons rt-rwy-path   
	 assert-anomaly 	 rwy-imbalance r i g h t         
in general  whenever an expectation failure occurs  a task to explain the observed anomaly is initiated. the first step in such a task is to try to match the anomaly to a known explanation-pattern  xp   schank1 . a match results in a task to verify the xp hypothesis. 
 explanation-pattern-1 
 :anomaly  rwy-imbalance  rwy    :candidate-explanation  closed  rwy    
in principle  verifying a hypothesis could involve mental and physical actions of any kind. in the current model however  the only way to verify a hypothesis is to check for a match in working memory. in this case  the contents of working memory are adequate; the anomalous absence of planes on approach to the left runway is explained as a result of the left runway's closure. 
bias renewal occurs whenever the working memory item that originally produced the bias is re-encoded or retrieved. thus  retrieving the proposition  closed runway left  triggers the bias generation rule just as if the proposition had been encoded for the first time. thus  the unusual arrangement of planes on the radar scope acts as a constant reminder  preventing the agent from reverting to the use of its default assumption and thereby preventing error. 1 aiding user interface design 
interface designers often overlook aspects of an interface that facilitate user errors  though in many instances  design problems are obvious once pointed out  norman1 . the problem of noticing these design problems becomes especially difficult in domains such as air traffic control where interfaces must mediate complex tasks carried out in diverse operating conditions. by employing a model of error-prone human behavior  we hope to partially automate the process of predicting design-facilitated errors. 
the basis for these predictions arises from an analysis of how agents generally  and humans in particular  can manage limited resources in decision-making. employing this analysis  it is possible not only to simulate the influence of interface attributes on human tendencies to err  but also to provide causal explanations for predicted errors that indicate ways to repair the design. for example  explaining the described error scenario to a designer as an indirect consequence of low workload indicates a clever fix: runway closures can be visually signaled  but only in 
	freed & remington 	1 
low workload conditions when the added screen clutter would cause little distraction. 
1 discussion 
the process of deciding action can make substantial demands on limited computational and physical resources. to cope with time-pressure and competing demands  our system decides action on the basis of flexible strategies incorporated into rap-like reusable plans and other structures. when carried out by the same task execution mechanisms used to carry out non-decision tasks  these decision plans provide two means for managing resources. 
first  execution mechanisms can delay or interrupt decision subtasks to give higher priority tasks preferential access to resources. second  execution can select between alternative methods for subtasks on the basis of duration or compatibility between their different resource requirements and demands from other tasks. selecting a method for its resource-demand characteristics will sometimes entail trading off against some other desirable attribute such as reliability. in particular  execution may rely on a default assumption in making a decision rather than engage in time- and resource-demanding efforts to acquire more reliable information. 
resource-management strategies that prescribe reliance on defaults make an agent vulnerable to habit-capture errors when assumptions underlying the strategy do not hold in its current environment. in the described example  the strategy of assuming runway availability in the absence of default counterevidence makes the simulated air traffic controller vulnerable in conditions of low workload when counterevidence is unavailable. 
the systematicity of such errors makes our approach useful for predicting circumstances in which aspects of an interface design might inadvertantly facilitate error. by alerting designers to the potential for such errors early in the design process  we hope to reduce the cost of evaluation and thereby speed the safe introduction of new technology. 
acknowledgements 
thanks to jim johnston  eric ruthruff  mark van selst  and mike shafto for many useful discussions. 
1 	cognitive modeling 
