 
first-order logic is the traditional basis for knowledge representation languages. however  its applicability to many real-world tasks is limited by its inability to represent uncertainty. bayesian belief networks  on the other hand  are inadequate for complex kr tasks due to the limited expressivity of the underlying  prepositional  language. the need to incorporate uncertainty into an expressive language has led to a resurgence of work on first-order probabilistic logic. this paper addresses one of the main objections to the incorporation of probabilities into the language:  where do the numbers come from   we present an approach that takes a knowledge base in an expressive rule-based first-order language  and leams the probabilistic parameters associated with those rules from data cases. our approach  which is based on algorithms for learning in traditional bayesian networks  can handle data cases where many of the relevant aspects of the situation are unobserved. it is also capable of utilizing a rich variety of data cases  including instances with varying causal structure  and even involving a varying number of individuals. these features allow the approach to be used for a wide range of tasks  such as learning genetic propagation models or learning first-order strips planning operators with uncertain effects. 
1 	introduction 
first-order logic has traditionally formed the basis for most large-scale knowledge representation systems. the advantages of first-order logic in this context are obvious: the notions of  individuals*'  their properties  and the relations between them provide an elegant and expressive framework for reasoning about many diverse domains. the use of quantification allows us to compactly represent general rules  that can be applied in many different situations. for example  when reasoning about genetic transmission of certain properties  e.g.  genetically transmitted diseases   we can write down general rules that hold for all people and many properties. 
　unfortunately  like all deterministic logics  first-order logic is highly limited in its ability to represent our uncertainty 
   *this work was supported in part through the generosity of the powell foundation  and by onr grant n1-1 -1. 
1 	probabilistic reasoning 
about the world. a fact is either known to be true  known to be false  or neither. one cannot say that a fact is probably true. real-world relationships  on the other hand  are noisy and nondeterministic  a fact which cannot be captured in the standard logical framework. this severely limits the applicability of this framework. for example  very few deterministic rules in the domain of genetically transmitted properties are actually  absolutely  true in real life. 
　this limitation  which is crucial in many domains  e.g.  medical diagnosis   has led over the last decade to the resurgence of probabilistic reasoning in ai. in particular  bayesian belief networks  pearl  1  have been shown to be a principled and useful framework for reasoning in an uncertain domain. however  belief networks do not  by themselves  provide a complete solution for very large-scale knowledge representation tasks. the primary reason is their attributebased  propositional  nature  which does not support a domain description in terms of general rules that apply to many qualitatively different situations. 
　the tension between these two complementary paradigms has been the primary motivation for some of the recent work on trying to combine the two  halpern  1; breese  1; poole  1; ngo et al  1 . knowledge-based model construction  kbmc  goes a considerable way towards bridging this gap by allowing a set of first-order probabilistic logic  fopl  rules  first-order rules with associated probabilistic uncertainty parameters  to be used as a basis for generating bayesian networks tailored to particular problem instances. 
　the idea of attaching probabilistic parameters to rules leaves unanswered one of the major objections that have been raised about probabilistic representations: the famous  where do the numbers come from  question. this issue has been addressed satisfactorily for traditional belief networks  lauritzen  1; heckerman  1 . in this paper  we show how similar techniques can be used to learn the probabilistic parameters of fopl rules from data. 
　the ability to learn the uncertainty parameters of a rich firstorder representation has the potential to be a powerful tool in many situations. we illustrate this using two very different examples: reasoning about genetically transmitted properties and planning for mobile robots. in both these examples  as in many others  the problem of learning these uncertainty parameters is an important one. the skeleton of the rules  the rules without the parameters  is often easier to acquire than the parameters themselves. in fact  an existing set of traditional first-order rules often provides us with an appropriate skeleton. in general  the rule structure directly reflects the underlying causal structure of the domain  a type of knowledge with which human experts are often fairly comfortable. by contrast  probabilistic parameters are notoriously difficult to elicit from people. 
　the propagation of genetically transmitted properties was a key example in some of the early research into belief networks  lauritzen and spiegelhalter  1 . given a particular family tree and set of properties being studied  one can construct a traditional propositional belief network in which the probability of each property being passed from each generation to the next is represented. however  a new network must be specially constructed for every family tree. currently  this is either done manually or using a special-purpose procedural program  szolovits and pauker  1 . 
　using a first order representation  one can capture the general mechanism of gene inheritance using a small number of rules. these can be used to automatically generate an appropriate belief network for any family tree and any set of properties. the generality of first-order languages is manifested here in three ways: the same mechanism is at work in different family trees  in different generations within the same family tree  and in the propagation of different genes from parent to child. our approach enables us to learn the propagation parameters for the different classes of properties. we will also be able to learn the strength of the correlations between propagations of the different properties  e.g.  that eye color is usually propagated together with diabetes  because of proximity on the chromosome strand . 
　the task of planning for an autonomous agent has traditionally been based on a logical representation of actions and their effects. in recent years  there has been a growing consensus that the underlying assumptions of this representation-deterministic actions  reliable sensors  and  often  complete observability-are rarely true in practice  particularly in robotics applications. as a consequence  probabilistic representations have recently started to play a role in planning  kushmerick et al.  1; dean and wellman  1 . these representations  however  are typically attribute-based  and are therefore limited in their ability to capture general patterns in action models. fopl would allow for an integration of these two formalisms. 
　certain important issues arise when we contemplate learning in domains such as these. first  as in most real-life applications  most of the relevant variables are not observed by the learning agent. in the domain of genetically transmitted properties  we may observe the phenotype of some of the people in the family. we will rarely  if ever  have complete information about the entire family. we will hardly ever have any information at all about the genotype of the different people involved. in the planning domain  we will typically have access only to the robot's sensors. the variables corresponding to the true state of the world are almost always unobservable. 
　a second common thread is that these domains all require the ability to learn from data cases that are qualitatively very different from each other. for example  in the genetic propagation example  we wish to learn from different family trees  over a varying number of individuals  and representing the inheritance of different properties. in our planning domain  we are faced with runs of different length  where the robot undertakes different actions. note that  in both of these applications  each of the  very different  data cases gives us information about many  or all  of the parameters of interest  so that we cannot simply separate them into distinct clusters and run a learning algorithm on each. 
　the approach we present in the paper is capable of dealing with both of these issues. we start out with a knowledge base consisting of partially specified fopl rules: the rule structure is determined  but the uncertainty parameters are left unspecified. we are also given a set of data cases  where each data case consists of a context  e.g.  the structure of the family tree  or the set of actions taken by the robot  and the observations made by the agent. we use a standard kbmc algorithm to generate the network structure for each of the data cases. the observations in each data case become evidence in the resulting network. the conditional probability tables in the resulting networks are related to the parameters corresponding to the rules in the knowledge base. we adaptively learn these parameters  using an extension to the standard em algorithm  lauritzen  1  for learning the parameters of a belief network with fixed structure and hidden variables. we extend it to deal with an ensemble of networks of varying structure  and in which the same parameter can appear several times. 
　the two major advantages of first order languages over propositional languages-generality and compactness-have particular ramifications in a learning context. the generality of first-order models allows the learned parameters to be reused again and again in many different contexts. the cost of learning is therefore amortized over a large number of instances in which the benefits are reaped. the compactness of such representations allows a probabilistic model to be represented using a small number of parameters  hopefully resulting in faster learning. 
1 	knowledge-based model construction 
since the idea of constructing belief networks from a firstorder probabilistic knowledge base was first proposed  breese  1   several approaches have been developed. most of these augment logic-programming style rules with uncertainty parameters. in this paper  we largely follow the framework of  ngo et aql.  1 . in this approach  a set of horn rules describes the ways in which first-order predicates influence each other. because the influence may be uncertain  each rule has a uncertainty parameter associated with it. intuitively  one can think of a rule as identifying a possible set of conditions under which the consquence becomes true  and giving the probability that the consequence actually becomes true as a result of the conditions. 
　for example  a very simple model for gene propagation can be expressed in the rules: 

the first rule says that a when a person's parent has a gene  the person will inherit it with probability 1. the second rule 
	roller & pfeffer 	1 
says that when a person has a gene  it will be observed in the person's phenotype with probability 1. 
　when only one instantiation of a rule can cause a predicate to be true  the associated uncertainty parameter is in fact the conditional probability that the head is true given that the body is true. sometimes  more than one set of conditions can cause a predicate to be true. for example  if both a person's parents have a gene  the first rule will fire twice  for the two different values of q. in such cases  we need a combination rule to indicate how the different possible causes interact. one very common combination rule is noisy-or  pearl  1   which describes a situation in which an effect happens whenever any of its potential causes succeeds in making it happen  and the different causal influences act independently. more precisely  the probability that the effect does not happen is the probability that all the potential causes independently fail to cause it. for example  if the combination rule for genotype is noisy-or  then a person both of whose parents have a gene will fail to inherit it with probability  1 1 = 1. 
　a more accurate model for genetic propagation may incorporate the number of chromosomes  1  1  or 1  on which the gene is found.  our language allows for multi-valued variables. rules for such variables have several parameters corresponding to each of the possible values.  a person with the gene on both chromosomes in a pair will always propagate a copy to his or her children  while a person with one copy will only propagate it with probability 1. the combination rule in this case will be a noisy addition rule in which the number of genes possessed by a person is the sum of the number of succesful propagations from his or her parents. the probability that a gene will be manifested in a person's phenotype will depend both on the number of copies possessed and on whether the gene is dominant or recessive. note that this can easily be expressed in our language as a property of g. an even richer model may consider the correlation between the propagation of different genes based on their proximity on the chromosome strand. 
　the rules in the knowledge base describe  in a general manner  the ways in which various predicates interact. they are used in a particular situation to build a bayesian network  via a process of knowledge-based model construction  kbmc . the resulting network defines a probability distribution over the variables that are relevant in the given situation. a situation is defined by a context  which determines the structural relationship between the objects in the situation. in the genetic domain  the parent predicate is part of the context  defining the family tree. in general  the body of a rule will consist of both context variables and random variables  which are treated differently by the model construction process. 
　the kbmc algorithm takes as input a knowledge base  a context  a query and evidence  and returns a bayesian network that can be used to compute the probability of the query given the evidence. the context  the query  and the evidence are all ground facts in the language. the algorithm proceeds by backward chaining through the horn rules  iteratively adding nodes representing different ground facts to the network. it starts by adding the query and the evidence. each time a 
　variable is added to the network  it is matched with the rule heads to determine what predicates can influence it. context 
1 	probabilistic reasoning 
predicates appearing in the rule body must be satisfied for the rule to apply; if it does  the other predicates in the body  appropriately instantiated  are added to the network as random variables. figure 1 shows a simple network constructed for the genetic domain to compute the probability of phenotype a  big ears  given phenotype b  big ears  and not phenotype c  big ears . the context consists of the ground facts parent a c   parent b.c   parent a d   and parent b d . 

figure 1: generated network for genetic domain. 
　in order to complete the specification of the probability distribution defined by the bayesian network  the kbmc algorithm must determine the conditional probability table  cpt  for each node. this table lists the conditional probability of the node given each possible value of its parents. the cpt entries are determined by the uncertainty parameters  using the combination rules. in principle  the combination rules could determine the entries to be any function of the parameters. however  learning is greatly simplified if each cpt entry is associated with at most one parameter which must be learned. thus  we restrict attention to decomposable combination rules  ones which can be expressed using a set of separate nodes corresponding to the different influences  which are then combined in another node. fortunately  all the commonly occuring combination rules  including noisyor and tree-structured iboutilier ef at.  1   generate cpts with this property. the kbmc algorithm automatically generates the decomposed representation for these combination rules  thereby facilitating learning. 
　this approach can be applied naturally to planning domains. for example  consider planning in a robotics domain where properties of objects and the effects of actions such as moving and grasping are uncertain. for any  possibly uncertain  initial condition and sequence of actions  kbmc is used to build a probabilistic model of the world after the actions have been taken. the context here consists of the set of objects in the world  some known properties of the objects  such as their type and shape  and the sequence of actions taken. the random variables include other properties of the objects  such as whether they are currently wet and therefore harder to grab   and the locations of objects at different times. the knowledge base consists of strips-like rules with uncertainty  as in  kushmerick et al  1    stipulating the probability that certain postconditions will hold given that the preconditions hold and an action is taken. our use of the closed world assumption on context predicates fits naturally with the strips 
　
assumptions. 
　a useful type of combination rule for planning domains is a selection rule. a selection rule behaves analogously to a multiplexer: a predicate may match several rules  and the value of a selection variable determines which of the rules is applicable. selection rules are useful in situations where a predicate is influenced by a single cause  but the identity of the cause is itself uncertain. this is typical of planning situations. for example  the effects of a move action may depend on the properties of the robot's current location. since the robot's location is itself a random variable  the properties of all locations could potentially influence the action's effects. the location is used as a selector to determine which properties are the relevant ones. computationally  selection rules require the bayesian network inference algorithm to take advantage of context-specific independence lboutilier et al.  1 . 
1 	learning 
our learning task is to take a set of data cases  c  and return a hypothesis h that  explains  the data c in the best possible way. the hope is that a hypothesis that provides a good explanation will also generalize well to unseen data cases  modulo concerns about overrating . here  each data case consists of a context and some evidence. since our goal is to learn the parameters for a set of fopl rules  we assume that our algorithm is provided with a skeleton rule base  and must only fill in the values of the uncertainty parameters. formally  our hypothesis space consists of the possible values for the rule parameters. we assume for convenience that the rule parameters have values between 1 and 1. thus  if there are m unspecified parameters  the hypothesis space is the set of m-vectors we consider a hypothesis as a good explanation for the data if it gives it high probability. thus  we seek to find the maximum likelihood hypothesis  that maximizes the probability of the data c. 
　our first task is to define this probability  for a single data case         we can use the techniques of section 1. a probabilistic model consisting of the rule skeletons and the parameters  defines a belief network for each data case. the probability of the data case given the hypothesis is thus defined as the probability that the evidence variables will take on their given values in the distribution defined by this belief network. more precisely  let c be a particular data case  dc the observed evidence in the data case  and  the belief network constructed for that data case from its context. the probability of c given the hypothesis  is defined as 

　at this point we would like to define the likelihood of the entire data set as the product of the likelihoods of the individual data cases  so that if c = {c1  . . . cn}. then 
 this definition embodies the as-
sumption that the different data cases are independent. this seemingly innocuous assumption  which is made almost universally in the context of machine learning  is not as obviously justified. our more expressive language gives us the ability to relate two individuals  having the properties of one affect the other. but now  we may be uncertain about whether individuals observed in the context of two different data cases are related to each other. in the gene inheritance domain  for example  two people appearing in different family trees may in fact have a common ancestor  thereby linking the two trees. in some sense  the 'ideal' model for a data set c is a single huge belief network incorporating all of our information. after all  our domain really does contain all of these elements. in this network  we can represent our uncertainty concerning the potential relationships between individuals in the different family trees. clearly  practical considerations prevent us from taking this course. this is the reason for making the independence assumption  which in the genetics example essentially asserts that different family trees are extremely unlikely to be closely related to each other  and that the influences between data cases are attenuated across many generations. however  it is important to keep in mind that this is purely an approximation  and that we need to check every time whether it is 
justified in our particular situation. 
1 	the learning algorithm 
in this section we describe our learning algorithm in detail. the algorithm takes as input a set of probabilistic rule skeletons with some of the rule parameters left unspecified  and a training set c consisting of contexts and evidence. it attempts to find the maximum likelihood vector of parameter values using a two-stage process. in the first stage  it constructs a belief network for each data case by mimicking the knowledge based model construction process. in the second stage  it attempts to find the maximum likelihood hypothesis using the em method  in a manner analogous to its use for learning bayesian networks  lauritzen  1 . 
　let c be a particular data case   the evidence in the data case  and. the the belief network constructed for that data case. the learning algorithm begins by building the network for each data case  via back-chaining from the evidence nodes. the second phase of the algorithm uses the em algorithm to search for the value of  that maximizes the likelihood of the evidence in the constructed belief networks. we briefly review the em algorithm and its application to our problem. to understand the intuition  consider the problem of maximum likelihood parameter learning in standard bayesian networks from fully observable data. there  the network structure is identical in all data cases  and the parameters are simply the cpt entries. let a  be some node in the network and u be its parents. the maximum likelihood estimate for the cpt entry  is simply the number of data cases where a  u take the values x  u respectively  divided by the number of data cases where u takes the value u. 
　if our data cases have missing values  we can no longer perform this counting process. the em algorithm essentially provides us with a way for probabilistically  filling in  the missing values. it starts out with some initial set of parameters  and uses them to compute a probability distribution over the various possible completions of each partial data case. each completion is then treated as a fully-observed data case  but one whose weight is its probability. a new set of parameters is then computed as described above  over the set 
	roller & pfeffer 	1 
　
of weighted data cases. the process is now repeated with the new set of parameters. standard results  see  mclachlan and krishnan  1   imply that this procedure converges to a set of parameters which is a local maximum in the likelihood space. in practice  of course  one cannot generate every fully observable completion for a partially observable data case c  since the number of such completions is exponential in the number of unobserved variables in c. luckily  the total weight of the completions for c which contribute to the weighted count of the event x = x  u = u is simply 

　in our context  the basic idea is the same. the two main differences are that the networks for the different data cases have different structures  so that a parameter may appear in a variety of contexts  and that the same parameter can appear more than once in the same network. to see that neither of these is a problem  consider some rule r in our knowledge base. by assumption  r is associated with some set of parameters  and these appear only in r. recall that our use of decomposable combination rules implies that each node in the generated network is associated with at most one rule.  some nodes simply compute deterministic functions such as or and summation.  thus  while the same rule can induce more than one node in the network for a data case  all of the nodes have an identical local structure: the cpts are the same and incorporate the parameters in the same way. thus  each of the nodes derived from r can be viewed as a separate  experiment  for the parameters associated with r. each should therefore make a separate contribution to the  count  for those parameters. this situation is now analogous to the one that arises in learning hidden markov models  rabiner and juang  1   where we also have data cases of varying structure and parameter sharing in each data case. 
formally  let r be some rule  and be one of its parameters. 
let xr  ur be the values for a node and its parents that are associated with in a node generated by rule r. for every data case c  let be the set of nodes in the network   which correspond to the rule r. in each iteration of the em algorithm  we begin with some set of parameters and adjust each of them according to the weighted counts  as follows: 

the values of prx can be computed using standard bayesian network calculations in the network   constructed using the current guess for 
　the fact that the we get the maximum likelihood estimate for our parameters in the fully observable case implies the desired convergence property  mclachlan and krishnan  1 : 
theorem 1: the iterative em procedure described above converges to a set of parameters which induces a local maximum in the likelihood 
it is instructive to compare the complexity of our learning algorithm to that of parameter estimation in standard  propositional  bayesian networks. our learning procedure involves a single initial phase of constructing the network structure for each data case. the cost of this phase is insignificant relative 
1 	probabilistic reasoning 
to the cost of the em iterations  each of which involves running bayesian network inference for each data case. this cost  per iteration  is the same as in the case of learning parameters for propositional bayesian networks. we do not have an analysis of the number of iterations required for convergence either for standard bayesian networks or for our rules. the first-order rules  however  support a significant reduction in the dimensionality of the parameter space via the parameter sharing encoded in the rules. in general  a reduction in the number of parameters tends to speed up convergence. for example  it has recently been shown  friedman and goldszmidt  1  that exploiting context-specific independence in traditional bayesian networks can speed up the learning process considerably. 
　the learning procedure presented here suffers from two potential problems: local maxima and overrating. since we are only attempting to learn numerical parameters  any overfitting would be numerical  i.e.  learning the parameter values to too great a degree of accuracy. techniques such as random restart may alleviate the problem of local maxima  but possibly at the cost of increasing the danger of overrating. future work should determine how serious these issues are for this procedure  and develop techniques to deal with them. 
1 experimental results 
we tested the learning algorithm on a simple gene propagation model with three parameters. we generated data cases from a given set of rules with associated parameters. we then gave our algorithm the  correct  rule structures and used it to learn the parameters from the data cases. in addition to the two rules shown in section 1  there was a rule for spontaneous acquisition of a gene  with uncertainty parameter 1. the experiments tested the ability of the algorithm to learn the correct values of the parameters from n data cases  for various values of n between 1 and 1. each data case described a family tree relating between 1 and 1 people  with the phenotype being observed for approximately one third of them. ten sets of experiments were run for every value of ny each with a different training set constructed from the same set of parameters. 
　the results are shown in figure 1. figure 1 a  shows the mean absolute error of the learned parameter values as compared to their true values. the graph shows the average  best and worst results for each value of n. figure 1 b  shows the relative error for the parameter values. figure 1 c  describes the performance of the learned parameters in predicting the probabilities of events in a test set. the test set consisted of 1 data cases  generated from the same model as the training data  but which were not shown to the learning algorithm. the figure shows the mean relative error of the predicted probabilities as compared to the true probabilities. notice that the relative error of the predictions is much smaller than the relative error of the parameter values.  note the scale of the two graphs.  it has often been observed that the predictive performance of a bayesian network is not sensitive to small error in the parameters. our results indicate that a similar phenomenon may hold for the parameters of noisy rules. this type of robustness to small errors greatly increases the appli-
　

figure 1:  a  mean absolute error of learned parameter values   b  mean relative error of learned parameter values   c  relative error on probability prediction for new cases. in each figure  the x-axis represents the number of data cases. 
　
cability of learning. 
1 	conclusion 
we have shown how techniques for learning in standard belief networks can be adapted to learning in first-order probabilistic models. this allows us to learn in domains where we encounter many qualitatively different circumstances that share an underlying causal structure and uncertainty parameters. clearly  more extensive experiments are required in order to test the usefulness of our approach in practice. 
　our presentation in this paper was based on a specific representation language for the first-order probabilistic rules. we are currently investigating the problem of defining expressive languages for modeling complex stochastic domains  including languages that support the representation of continuous variables and temporal processes  and reasoning at different levels of granularity. whatever the results of this research  we expect that a model in our language will continue to define a belief network for a given situation  and that the conditional probabilities will be functions of various parameters. therefore  the ideas in this paper should continue to be applicable. 
　finally  we have focused on learning the numeric uncertainty parameters of first-order probabilistic rules. we did not address the problem of learning the structure of the rules. in recent years  there has been significant work both on learning the structure of belief networks  see  heckerman  1  for a survey  and on inductive logic programming  muggleton  1 -learning deterministic first-order rules. it would be very interesting to see whether the techniques developed in these two areas of research can be integrated  allowing us to learn the causal/rule structure of complex uncertain domains. 
