 information is entirely replaced by concrete examples when the constraints regarding boredom and overload are less stringent  it is sufficient to remove the last sentence in the discourse on the top  in square brackets  this is because this sentence is generated to contradict a possible erroneous inference  which is of lower 
significance than the propositions in the input  table 1  
1 	i n p u t a n d o u t p u t o f t h e c o n t e n t 
p l a n n e r 
our system receives two types of input propositional and user model related the propositional input con tains  1  a set of propositions to be conveyed   1  the degree of belief the user is expected to achieve with respect to each proposition  and  1  the significance of each proposition  1 e   how important it is that the user believes it propositions are grouped into aspects such as operation  domain and structure based on their main predicate table 1 shows the input from which the texts 
1 


	1 	natural language 


1 


	1 	natural language 

　our algorithm computes sets of rds  step 1  expansion   rather than simply collating together the rds that convey individual propositions  because these rds typically interact with each other in two possible ways  1  an rd planned for one proposition may convey other propositions  thereby making their rds obsolete  and  1  an rd may yield erroneous inferences which require the generation of additional rds to correct them 
　the algorithm for computing minimally sufficient sets of rds may keep sets of rds that subsume each other  
so long as they are generated for different user models for example  this happens if {rd1 rd1} is minimally sufficient for model maverage but it is not sufficient for mweak  where {rd1  rd1 rd1} is required 
　if there are no minimally sufficient sets of rds that satisfy all the constraints  then it is impossible to generate a single piece of discourse that convey′ the intended information without incurring boredom and/or overload in this case  we consider two orthogonal approaches for generating discourse which satisfies the constraints  step 1  selection  these approaches relax the following requirements of the problem  1  the communicative goal  l e   less information is conveyed  section 1   or  1  the single-discourse requirement  i e   the material is broken up into smaller chunks to be presented sequentially in a session  section 1  the first approach yields new 
minimally sufficient sets of rds that satisfy all the constraints  thus step 1 of selection is performed successfully this time the second approach yields a  possibly partial  sequence of sets of rds  each of which is optimal for conveying a smaller chunk of propositions thereby satisfying all the constraints as well 
　once a set of rds has been selected for expansion  our algorithm determines prerequisite propositions and referring expressions required for understanding this set of rds  step 1  selection  this is performed as described in  zukerman and mcconachy  1  the expansion-
selection process is then repeated to compute minimally sufficient sets of rds that convey these prerequisite propositions 
　during the next iteration  the constraints are checked for the set of rds generated so far plus its referring expressions and the sets of rds which convey its prerequi-
site propositions this is necessary because it is possible that when a referring expression or a set of rds that 
conveys prerequisite propositions is added to a main set of rds  the overload and/or boredom constraints are violated  even though individually neither set of rds could violate these constraints  in this case  the 'convey less information' policy for dealing with constraint violation is applied with respect to the original intended 
propositions  rather than their prerequisite propositions this is because if we decide to satisfy a constraint by not conveying a particular prerequisite proposition  we affect the understanding of all the rds that rely on this propo-
sition  and hence  the understanding of possibly several intended propositions conveyed by these rds 
　to illustrate the optimization process  consider a situation where the intended propositions are as shown in table 1  and the probabilities that the student belongs to the different student models are as follows ex-
1 


	1 	natural language 

1  the atomic mass of a nucleus is the number of neutrons plus protons in it   
1 a nucleus with a low binding energy is unstable 
1  a nucleus with a huge atomic mass is also unstable  e g   u1   
1 an unstable nucleus is easily split an easily split nucleus is fissionable fuel  
1 which is used in fission reactors 
table 1 sample discourse for an average student with/without boredom due to length 
this inference is noted  so that the discourse relation between the rds that convey these propositions can be expressed in the discourse  and the two sets of rds can be ordered 
1 	r e s u l t s 
the system was run on several inputs with both policies for dealing with constraint violations it generates introductory discourse in technical areas such as nuclear fission  chemistry and biology the following observa tions were made based on the system's output for the 
'convey less information' relaxation policy 
　when the boredom constraints are turned off there is no penalty for excessive length or unnecessary rds  hence the generated texts contain several examples to ensure that the material is conveyed  top of table 1  overload affects the system's output only if a shift in belief that is too large for the more probable user models is required 
　when boredom due to length is activated  rds that convey propositions of lower significance tend to be omitted first for instance  in table 1  sentence 1 is removed since its significance is low  and sentence 1 is then removed since atomic mass is defined only because of its use in sentence 1 if a proposition with a higher significance requires many rds  then these rds become good candidates for omission 
　when both types of boredom constraints are activated  if the probabilities of the user models are evenly distributed around the target model  the only way to satisfy both sets of constraints is to convey very little information  yielding an objective function with a low value in this case  following accepted teaching practices  the system relaxes the unnecessary-rds constraints  giving a higher priority to the requirements of the weaker user models 
　when the 'break-up the material relaxation policy is used  the discourse becomes longer since some information is repeated in order to link the different sets of rds 
1 	conclusion 
we have offered a content planning system which takes into account a speaker's uncertainty regarding the user model to which an addressee belongs  and considers two possible outcomes of generating discourse aimed at a user model that does not fit the addressee boredom and overload our system applies a constraint-based optimization mechanism which uses a probabilistic function of a user's beliefs as its objective function  and a 
representation of boredom and overload as constraints that affect the possible values of this function further  we have discussed two orthogonal policies for relaxing the parameters of the communication process when constraints are violated  viz relaxing the communicative goal and relaxing the single-discourse requirement 
　since the purpose of this research is to investigate the effect of the above mentioned factors on discourse  op-
timal algorithms which perform exhaustive enumeration were devised using these algorithms  our system takes 1 seconds of cpu time on a sparcstation1 to generate english text with 1 rds since these times are not acceptable for an interactive system  next we intend to compare the performance of these algorithms with that of sub-optimal but more time-efficient algorithms 
