 
　the generalized delta rule  which is also known as error backpropagation  is a significant advance over previous procedures for network learning. in this paper  we compare network learning using the generalized delta rule to human learning on two concept identification tasks: 
  relative ease of concept identification 
  generalizing from incomplete data 
introduction 
　the generalized delta rule for network learning has received a great deal of attention recently. the generalized delta rule is a 
　learning procedure for associative networks which contain hidden units. it is a significant advance over previous network learning procedures which either  1  were limited to two-layer networks  which are incapable of solving a number of interesting problems   or  1  required stochastic units  and a large amount of computation for each learning cycle. 

	input 	hidden 	output 
figure 1: a multi-layer network which contains hidden units 
　figure 1 presents a simple network with two input units  three hidden units  and one output unit. for each unity in a network  the output o given an input pattern p is: 

where is the weight from unit i to j and  is a  threshold  for unit j-
　the generalized delta rule indicates how the weight on the connection from unit i to unit j should be changed after presentation of an input pattern p. where n is a parameter which controls the learning rate; is the target output for unit j with input pattern p; is the error propagated back to unit j from a unit k whose input is and wkj is the weight of the connection from unit j to unit k. the interested reader is referred to  for a derivation of the generalized delta rule. 
　the concept identification task  has been extensively studied in psychology. in this paper  we review a number of findings on concept identification in human subjects  and compare these findings to network learning with the generalized delta rule. in a typical concept identification experiment  a subject is shown a set of cards with different objects on them. the cards are presented to the subject one at a time in a random order and the subject is to determine whether the card belongs to the class to be learned. after each presentation  the subject is given feedback on the correctness of his response. typically  the subject is told which attributes of the objects on the card  e.g.  the number of objects  the shape of the objects  and the color of the objects  are potentially relevant. the trials continue until the subject makes no errors. 
the concept identification task seems ideal for network learning. 
the attributes on the card are treated as input to the network. in most of the experiments  the attributes are two valued  so a binary encoding of the input is possible  e.g.  for shape 1 = square and 1 = circle . the output of the network is 1 if the card is an instance of the concept and 1 otherwise. after the network classifies an input pattern  it is given feedback on the correctness of its output so that the weights on connections between units can be modified. 
　for all of the simulations  the network learning algorithm is simulated on a symbolics 1. to ensure that the algorithm has been correctly implemented  we have run it on many of the examples in  and obtained similar results. 
　the issue addressed in this paper is an evaluation of what might be called the strong pdp hypothesis: that all cognitive processes are realized directly in a homogeneous network of connected units. this hypothesis has been entertained by churchland . at the other extreme is the physical symbol system hypothesis : that all cognitive processes are symbolic manipulations of the sort in logic and lisp. 
 the most fundamental contribution so far of artificial intelligence and computer science to this joint enterprise has been the notion of a physical symbol system. this concept of a broad class of systems that is capable of having and manipulating symbols  yet is also realizable within our physical 
	pazzani and dyer 	1 
universe  has emerged from our growing experience and analysis of the computer and how to program it to perform intellectual and perceptual tasks. the notion of symbol that it defines is internal to this concept of a system. thus  it is a hypothesis that these symbols are in fact the same symbols that we humans have and use everyday of our lives. stated another way  the hypothesis is that humans are instances of physical symbol systems.  
　in between these two extremes  there are a number of possible hypotheses. after presenting the results of our simulations  we shall comment on other alternative hypotheses. 
relative ease of concept identification 
　there have been a large number of experiments investigating the ease of learning combination of attributes. for example  bower and trabasso  have reported that concept identification by a 
　single affirmative attribute  e.g.  blue  is easier than concept identification on a conjunction of cues  e.g.  blue and square . others  have found that conjunctive concepts are easier than disjunctive concepts  e.g.  blue or square  and that disjunctive concepts are easier than exclusive disjunctive concepts  e.g.  blue or square but not blue and square  . finally  polymorphous concepts  also called m-out-of-n   e.g.  at least two of square  blue and symmetric  have been found to be more difficult than disjunctive concepts . to our knowledge  there has been no comparison of polymorphous and exclusive disjunctive concepts; both are more difficult than disjunctive. figure 1 summarizes the relative ease of acquiring concepts. 
1. affirmation 
1. conjunction 
1. disjunction 
1. exclusive disjunction polymorphous 
figure 1: relative ease of concept identification  as determined by the number off trials required to learn the concept 
　we tested the generalized delta rule in a large number of different networks and conditions. in all of the tests  there were three input units  one output unit  and a number of hidden units connected to the output unit. the following parameters were varied in the trials: 
  number of hidden units: two  eight  and twenty-four. 
  connections between units: for all of the tests each input unit was connected to every hidden unit. in addition  mi the case of the twenty-four hidden unit test  random connections between the input and hidden units were tested. 
  the value of n. varied from .1 to .1 in increments of .1. 
the weights w:jk were set to random numbers between -1 and 
1. the threshold 1  of the hidden units were also set to random values between -1 and 1 subject to the constraint that the output was never more than than .1 or less than .1 for any input combination 1 an output value of greater than .1 was considered to be 1  and less than .1 was considered to be 1. for each condition  five concepts corresponding to one of the classes of concepts were learned from 1 random initial conditions and the number of presentations of each input pattern was recorded. 
　in the conditions tested  the number of hidden units and the value of r  did not affect the relative ordering of the ease of concept identification considerably. results from several simulations are shown in figure 1. for all of the simulations  if the network failed to learn after 1 presentations of each input pattern  the simulation was terminated. 
　1 the rationale for constraining the threshold value was to increase the rate of learning. from the generalized delta rule  it it easy to see that learning is slowest when the output approaches 1 or 1. 
1 	cognitive modeling 
hidden units: 
affirmation 
conjunction 
disjunction 
polymorphous 1 
1 
1 
1 
1 
1 1 
1 
1 
1 
1 
1 1 
1 
1 
1 
1 1 
1 
1 
1 
1 exclusive disjunction 1 1 1 1 figure 1: mean number of presentations of each input pattern before correctly identifying the concept. 
　there are several conclusions which can be drawn from this simulation. 
  affirmation is always easier than other classes of concepts  p   .1 . this result is identical to the result with human subjects. 
  usually  there is no significant difference between conjunctive disjunctive  and polymorphous concepts.1 this result differs from the findings on human subjects . a bit of analysis indicates why conjunction and disjunction are equally difficult  since by interchanging vs and 1's the disjunction becomes conjunction  i.e.  in digital circuits  an or-gate in positive logic is an and-gate in negative logic . bruner has argued that disjunction is more difficult for human subjects because they find it more difficult to work with negative instances. the generalized delta rule does not share this difficulty. 
  exclusive disjunctions were always significantly  p   .1  more difficult than disjunctions. this result is identical to the result with human subjects. 
  the average number of presentations required for learning in all conditions is much greater than that required by human subjects. for example  in   with three two-valued attributes the mean number of cards presented was nine for conjunctive  twenty-eight for disjunctive  and forty for polymorphous concepts. note that in figure 1  the results are reported in decks of cards  i.e.  presentations of all eight input patterns . the results in figure 1 must be multiplied by eight before being compared to human performance on this task. 
redundant relevant cues 
　bower and trabasso have extensively investigated concept identification when there are redundant attributes . for example  if two attributes always vary together   i.e. squares are always blue  and blue things are always squares   then human subjects fall into three classes: those that use one of the relevant attributes  e.g.. blue   those that use the other relevant attribute  e.g.. square  and those that use both . since bower and trabasso were primarily concerned with determining whether or not subjects attended to both attributes  they group together those subjects who conjunctively and disjunctively combined the redundant attributes. 
　encouraged by the results in the earlier simulation where the value of r  did not alter the result  in these simulations we did not vary the value of r   .1 . we simulated networks with 1 and 1 
1
hidden unit s  . in this simulation there were three input attributes  
　1 although with twenty-four hidden units and n=.1. conjunction was significantly  p  1  more difficult than disjunction and poiymorphy. 1 the networks generalize better with fewer hidden units. if there a large number of hidden units  there can be one hidden unit unit which  looks for each possible input combination. 
xty and x.1 the value of z was always the same as the value of x. presentation of the four input patterns were repeated until the network would respond with 1 when x  and  therefore  t  was 1 and with 1 otherwise. after the network had learned this concept  it was presented with all eight possible input patterns. the output value of the network determined what function it had learned. for example  if the network reported 1 only when x was 1  then it had learned that x was the relevant attribute. 
　in this simulation  for some input patterns which were never seen the output value might not be greater than .1  which we consider 1  or less than .1 which we consider 1. in their simulations on generalization  rumelhart  hinton  and williams  accept a value of greater than or equal to .1 for 1  and less then .1 for 1. we also adopted this strategy. the results of these simulations are in figure 1. 

figure 1: distribution of concepts learned when there are redundant relevant cues. 
　there are sixteen possible boolean functions consistent with the four input patterns which were presented. of these  human subjects only report the first four z  x  xz and xvi in figure 1. in human subjects  the attribute which is not at all correlated with the output     is not considered relevant. the exact distribution among the four functions depends on a number factors such as the saliency of the cues. in the trabasso and bower experiment  1% classified on one attribute  1% classified on another  and 1% classified on both attributes. in network learning with eight hidden units  the rule learned to classify the concept contains the irrelevant attribute     slightly more than 1% of the time. with just one hidden unit  the irrelevant attribute was included more than 1% of the time. 
　the results of this simulation question the ability of the generalized delta rule to arrive at a reasonable generalization when some input configurations have not presented. the concept descriptions of human subjects in the redundant relevant cue experiments are simpler than those which are learned by the generalized delta rule. occam's razor favors a simpler hypothesis over a more complex hypothesis when both are consistent with the data. note that  simpler is defined symbolically. a distributed network which computes x is just a complex as one that computes 

discussion 
　in the psychology literature  the models of the concept identification task  e.g.   1   are consistent with the physical symbol system hypothesis. these models postulate that subjects generate a potential concept description in an a!l-or-none fashion and then confirm  or reject  the potential concept description with future examples. when learning simple affirmative concepts  in which only one attribute is relevant  i.e.  discrimination learning  the pattern of performance remains at chance for a period of time and then suddenly jumps to perfect . these results are in contrast with the strong pdp hypothesis. 
　some have criticized the concept identification task because the categories learned are artificial . many natural categories such as  games  do not appear to have a set of necessary and sufficient features. instead  it is argued  that many concepts are polymorphous. one encouraging result of our simulation is that the polymorphous concepts are no harder for the generalized delta rule to learn than conjunctive or disjunctive concepts.1 however  a full model of concept identification should be able to account for the acquisition of simple concepts like  square  which have necessary and sufficient features. 
　others have criticized the concept identification task because the learning takes place in an artificial environment without regard to the learner's goals or prior knowledge  1 . for example  consider the following more realistic redundant relevant cue experiment. someone familiar with many sports but who has never seen a game of basketball notices that there are five players with green shirts  blond hair  and various color sneakers. when one of these players has the ball  all the players run to one end of the court. five other players have yellow shirts  black hair  and various color sneakers. when one of these players has the ball  everyone runs to the other end of the court.1 two opposing players collide  and are injured. two replacements come in  one with a green shirt and black hair  the other with a yellow shirt and blond hair. the new player with the green shirt and black hair gets the ball. to which end will everyone run  an intelligent person would use his prior knowledge of sports  i.e.  players on the same team wear the same color uniform  to determine that shirt color is relevant and hair color is not relevant and make the correct prediction. this is in sharp contrast to an artificial situation in which a learner must decide whether the color or the size of a rectangle is relevant. however  the nature of the concept identification task makes no difference to the networks we have been simulating. one way to bias the saliency of attributes in network learning is to set the initial weights differently  e.g.  shirt color is initially stronger than hair color . however  a simple bias would not suffice for all problems. to see this  consider the following different task: one of the players with the green shirt and blond hair also endorses hair products. he is arrested on drug charges and the company decides to find another basketball player to represent their products. in this situation  hair color may be more important than uniform color. instead of always favoring one attribute over another  a more complex process is required which takes into account the goals of the learner. 
　in our simulations  network learning with the generalized delta rule failed to exhibit a number of similarities with human learning on a number of concept identification tasks. this is in contrast with the results of network learning on other tasks  such as classical 
　1 however  it should be noted that the results on the relative ease of oonotpt identification assume that the learner has no prior knowledge. a theory which explains a particular combination of features facilitates teaming for example  when causal explanations are present  linearly separable categories are easier to learn than nonnneariy separable categories. the reverse is tiue when there is no explanation  1 . it is not dear how these results could be modeled olreotiy in network approaches to ooncept learning  since the generalized delta rule is not affected by the ability to oonstruct a causal explanation. 

1 ln an experiment with human subjactt  x might represent shape with 1 - square 
and 1 - circle  y might represent color with 1 - red and 1 = blue  and x might 	 some may recognize this as a lakers-celtics game. represent size with 1 - big and 1 - small 
	pazzani and dyer 	1 

conditioning in animals  and human skill learning . models such as these seem to weaken support for the strongest version of the physical symbol system hypothesis. 
conclusion 
　human learning is a very complex process and it is not clear that any single rule or strategy can account for all human learning . tulving  has distinguished three types of human memory  each with its own type of learning  following rumelhart and norman   and retrieval: 
  in procedural memory  which retains connections between stimuli and responses  the learning mechanism is tuning. retrieval from procedural memory is by performing  i.e.  acting or perceiving . 
  in semantic memory  which represents knowledge of the world  the learning mechanism is called restructuring. retrieval from semantic memory is called knowing. 
  in episodic memory  which represents knowledge about personally experienced events  the learning mechanism is termed accretion. retrieval from episodic memory is called remembering. 
　the generalized delta rule seems to correspond most directly with tuning. indeed  it has been most successful at simulating the learning of those activities of humans and animals which improve gradually over time. 
　we conclude that although  1  manipulating symbolic representation is not a necessary condition for intelligent behavior   and  1  the symbolic level is not the best level of description for some intelligent behaviors  the symbolic level is the appropriate level of description of other human behaviors. for example  in the redundant relevant cue experiment  human subjects consistently generate concept definitions which are simpler symbolically. there are two possible ways of unifying these different levels of description within the parallel distributed processing framework: 
1. look for network architectures which implement  virtual machines  which manipulate symbols  1 . this approach ackowledges that humans have  connectionist  hardware  but admits that  at least by adulthood  humans have built up some capabilities which are better characterized at the symbolic level. 
1. look for network architectures and learning rules which explain intelligent behaviors without reference to symbols . for example  it is possible that such an architecture can follow 
occam's razor without explicitly representing hypotheses as symbols and occam's razor as a rule. 
