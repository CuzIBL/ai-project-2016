session 1 	natural language: systems 
	margie memory  analysis  response generation  and 	inference on english 
roger c. schank 
ntit goldman 
charles j. riager i i i chris rissbeck 
stanford university 
	stanford   california 	usa 


	conceptual 	dependency 	uses only fourteen possible 
actions  these actions are primitive building blocks from which verbs describing complex chains of these actions can be b u i l t . these actions ares 
propel grasp hove ingest expel smell speak listen-to look-at mtrans atrans ptrans conc mbuild these actions are described in detail elsewhere . the most important are mtrans  transfer of mental information ! ptrans  change of i ocation  t and atrans t transfer of possession . 
　　　　　uhat is important about the system described here it that for the examples it does  it functions the way we 
would claim an ideal language understanding system must. namely  the analysis of the input is done to a deep conceptual level using conceptual information rather then by doing a syntactic analysis f i r s t . then it is operated upon using the language-free nature of this depth  and then repacked into english. 
1. the analuzer 
　　　　　the natural language analyzer attempts to extract the conceptua i dependency representation under iying a sentence. there are several things that distinguish the approach to parsing described here from others. the f i r s t matter is the use of a predetermined 
representation of the meaning of sentences  i.e. conceptual dependency. the determination of the syntactic structure of a sentence is an instrument in the primary task of figuring out what that sentence means. in fact syntax has been denigrated to the status of something to use when all else f a i l s . 
　　　　　our analyzer also differs from traditional parsers in having been written with an emphasis on uhat individual words can and do communicate  not on uhat 
possible syntactic structures there are and what they mean. thus the analyzer does not look for the presence or absence of a particular structure by template matching nor by feature recognition. rather those words that might appear as features for the structure have attached to them programs that perform the task which would be considered as the meaning df the structure. for example  the analyzer does not look for an active or a passive construction. attached to the various forms of the verb  be  is an instruction that says that the following words w i l l be t e l l i n g some fact about the subject and further if the verb form following is a past p a r t i c i p l e   i . e . a verb form with indications of tense  then something is being told about what happened to the subject. implicit then in the instructions attached to  be  is the active /passive distinction but it not looked for in those terms but rather is part of a general semantic function of  be  just like  john is dead.  
　　　　　the following description of the analysis of a sentence may help to clarify the processes involved. the sentence is  john told nary that b i l l wants a book.  the f i r s t word of the sentence   john  t e l l s the analyzer 
nothing about what is going to happen. but only gives a subject for some verb or predication to follow. subject is a syntactic relationship that has semantic importance only in that it is a place to save something while the conceptualization involving that something is yet unknown. there are other place-holders aval labia  like object and recipient which are useful to distinguish 
words from each other without making a commitment about any particular conceptual role they w i l l play. thus in 
 john gave mary a beating   the word  give  assigns a syntactic role of recipient to  mary  but eventually the conceptual role for  mary  will be as the conceptual 
object of  beat . syntactic roles thus serve a purely u t i l i t a r i a n function  highly specific to the needs of the verb involved. no semantic reality is attached to them and thus one verb's use of what the analyzing program labels an object w i l l have no necessary relationship to 
uhat some other verb does with uhat it calls an object. a verb needs only enough places to save those things for which it hasn't determined conceptual roles. 
　　　　　returning to the sample sentence  following  john  we have the verb   t o l d   . now this word t e l l s us many things. it t e l l s us that there is a communicative act invoived  which is cailed mtrans in conceptuai dependency . by its morphology it t e l l s us the act took place before the time of speaking. it tell us that the subject of the verb is the actor of the action and also that the information was originally in the active part of his mind  called the conscious processor  cp . it t e l l s us that if s human follows then that person's cp is the conceptual recipient of the communication. it t e l l s us that there will be a another conceptualization i ike  bill wants a book   or at least a word signifying a set of conceptualizations  liks a   l i e   or a  story   which will follow soon. 
	the 	next 	word 	  mary   	satisfies 	the 
expectation of a recipient for the action. like  john  the major action on the part of  mary  is to say it is a human. out of context it doesn't add any new expectations to the handling of the sentence. 
　　　　　the next word   that   is one that does have functional effect on the analysis of the sentence. it says that if it is followed by a simple noun it is 
being used to say that the object following  e.g.  that joke   is one the hearer should know about  either from 
past knowledge or from information that is about to come. if  that  is followed by anything else it says that the conceptualization expected by the previous verb is being started and the analyzer should be prepared for 
a new set of syntactic and conceptual roles and role f i i l e r s . 
　　　　　the next word  bill   is not a simple noun and so the analyzer  obeying uhat  that  told i t   assumes that   b i l l   is a new subject  just like  john  was. other than that and information about the start ing point for tense determination the analyzer knows nothing  out of 
context. 
　　　　　the next word   wants   says quite a b i t . as should be obvious the verbs and acts and function words . l i k e  that  and prepositions .are the driving fore behind the analyzer. they setup conditions that t e l l where what has come and uhat is predicted to cone should f i t and the nouns and adjectives and previous context 
serve as the data base for these instructions to operate upon.  wants  gives us the conceptual information that the topic of the sentence is something that   b i l l   believes w i l l cause him pleasure. in conceptual dependency a person's belief of some conceptualization is rspresented as the presence of that conceptualization in the passive part of his mind  called the long term memory  ltfl .  ijante  t e l l s us that if a verb form  to x  follows then that is the action bi1 would iike and further either he is the actor or  if the  to  was preceded by another person  then that person is the actor of the action specified by the verb. if the only thing that follows  wants  is a noun phrase then the action that would give b i l l pleasure must be assumed from the nature of the object and the context. there ars othsr options following  wants  of course but the above includes the relevant one. 
　　　　　the next word is  a  which causes a syntactic holding to occur in the analysis. that is  a  t e l l s the analyzer to collect from the sentence f i r s t a complete phrase  ending with a noun  attach the preceding ad j ectivs and nouns to th i s f i na i noun w 1 th the appropriate conceptual relationships and then pass this r e s u l t back to the l i s t of expectations set up by the previous function words df the sentsnce. the finding of a phrase boundary is not independent of the context of the sentence  nor is it a clear cut process  as can be seen from 	the two sentences   the city people like is new york  
and  the c i t y people like new york.  but then very l.ittle in the comprehension of sentences  e clear cut. 
　　　　　the next uiord   book   is absorbed into the phrase being b u i l t   but we don't know yet if the phrase is ended or if  end  or  marker  or something will follow. 
	the next thing to come is the end of 	the sentence. 
this has a major effect on many analyses. the various function words have provisions for what kind of assumptions to make if the sentence ends before they get a l l the information they need. the f i r s t use of the sentence end is by the instructions attached to  a . the a r t i c l e recognizes that the end of a sentence ends a phrase and so the concept of a  book   noted as being indefinitely referenced  is passed back to the instructions attached to  wants . these instruct ions  seeing that the sentence is f ini shed and seeing that no action has yet been specified involving the book   make an assumption that bill wants to have the book. this is a general assumption made with all inanimate physical objects. another assumption that might have been made if the object were a person is that b i l l wanted that pernon to come to him. uhen  wants  has taken care of all the business that it needs to  the was involved makes the analyzer look for another conceptualization  not the particular syntax of   t e l l   . 
　　　　　this approach has not solved immediately any of the classic problems of ambiguity and contextual relevance  
uhat it does do is provide a format where the solutions to such problems can be formulated in terms that match commonsense descriptions of how people figure out meanings. 
         the sentence whose analysis was followed above will be discussed further with respect to reasonable inferences that can be made upon i t . the section on generation usee d i f f e r e n t examples which give a better indication of the paraphrase capability of the generator. these other examples can also be successfully analyzed by the program and the analyses d i f f e r in no fundamental way from what has just been described. an example is  john advised mary to drink the wine.   john    nary   and  wine  are like the nouns in  john told mary that b i l l wants a book.   advised  is the communicative act htrans as is   t o l d     wi th the added expectation that the word  to  will probably introduce an action for the recipient to perform  and further if the recipient performs this action the recipient w i l l be better for i t . hence the analyzer's output for  john advised mary to drink the wine  is ; 

wanting a 

#john in memory  this #john ie used in the internal form. uhen no #john satisfies the descriptive set  or when severe i do  a  possibiy temporary  token i  created  storing the facts in the descriptive set as its occurence set  and noting this event on the hat iunknounref. 
　　　　　 1  to 	extract 	subpropositions 	from 	the 
conceptualization at points before and 	during infereneing* those extracted before usually 	cone from rel link 	  -   as in 	 the red 	dog   	 dog  -  	 actor  dog  	 ＊  	 color val  red     	  	embeddings  	and  	together 	ui th 	the 	main propoeition  	comprise 	the 	i n i t i a l 	l i s t 	of propositions submitted to the breadth-firtt inferences 
　　　　　 1  to generate inferences of five basic types from each subproposition. these five types are   x -* y  means  y ie inferred from x   h 
 a  normative. uhat is the normal stats of affairs in the world  example!  mhere is john at 1am tuesday   
 probably at work.  
 b  peripheral. uhat  surrounds  a sltuationt uhat do people automatically assume uhen hearing something  example!  john told mary that b i l l saw rita.  -  john knows that b i l i saw rita.  
 c  causative. 	uhat uere probable causes of some 	state or action. examplet 	 john hit mary.  	*  john ua  *ad at mary.  
 dt resolutive. uhat are the probable results of some state or action  example:  john b i t b i l l   - .   b i l l is 
h u r t .   
 a  predictive. uhat might an actor do  given his current state  example:  john wants an icecream cone.  -   john might go to the store.  
a very important goal for making inferences ie to analyze an input on both the actual level  uhat the conceptual dependency diagram conveys l i t e r a l l y   and the level of intention of the actors  why did they do what they did.  for a l l inferences  particular attention is accorded to maintaining a record of uhat generated what. this means that for any proposition in memory  there is a l i s t of other propositions which participated in its generation  and a l i s t of propositions in whose generation it has p a r t i c i p a t e d . also  for resultative and causative inferences  in addition to the new inference  a  cause x y  r e l a t i o n s h i p is generated between the old and new information. 
　　　　 s  to make use of resultative and causative inferences to f i l l in missing causal chains. for example  the analysis of  mary kissed b i l l because he h i t john.  wou id reeu1 in a causa i wh i eh s tood for severe i intervening unspecified causa 1st  a  b i l l ' * h i t t i n g john caused john to be hurt   b  john's being hurt pleased mary  a peripheral inference is that mary feels a negative emotion toward b i l l      c  mary's pleasure was caused by john's action   d  mary therefore feels a positive emotion toward john  ie  this causes her to kiss john. this is a very common and important memory function  and is called causal chain expansion. 
　　　　 1  to detect when the same inferred information astsee from two distinct sources  for example  uhen a predictive inference mads from one line of a etory is confirmed by some later story i ins . this is cal led knitting  see m   end generally indicates that memory has  by inference*  been able to show how information in a story ie connected. a vary simple example of this ie the f o l l o u l n g t 
 mary wae h i t by a car.  
 sha want to the hospital.  
or 
 john wanted a wrench.  
 ha went to the hardware store.  
uhere  inferring that mary was badly hurt  memory predicts that she w i l l go to the hospital.'and this is immediately confirmed by the next line  notice that this prediction would help understand  the nurses usre very kind.  if this sentence were the second line of this story . 
　　　　 1  to detect and try to f i l l in missing or unspecified concepts  tokens  or events during inferancing. th i s i nciudes suppiy i ng i nformat i on to the ana iyzer i n cases such as  john h i t mary   where  in the abaence of other information  the object of the propel act involved in the h i t ie inferred  by a normative inference  to be  hand part  john  . in the sequence  john picked up a rock.   he h i t mary.   memory would apply the knowledge that people h i t other people with whatever they are currently holding  and would in this case return  rock *-   actor  rock       *l1c* val  hand part  john       in the example which w i l l be described shortly. memory will detect a missing concept during inferencing  and w i l l dsk a qusstion about i t . 
　　　　memory r e l i e s on two main data types for the storage of conceptual information and concepts and their tokens: concepts and bows- a bond is a   1 t of concepts which is stored with property bondvalue under a system-generated atom  called a superatqm. a concept  or a token of a concept is simply a lisp-generatsd atom. if it has a name  the name ie stored in the same way all other conceptual information about the concept is stored. both bonds and 
concepts have an occurence set  whose value is a l i s t of euperatoms under which are stored bonds in which x occurs. memory is therefore a fully inverted structure. conceptually  the occurence set of a bond or concept is a catalog of a l l conceptual knowledge about that bond or concept. this form of data base facilitates rapid lookup and s i m p l i f i e s simulation of parallel associative searches. 
　　　　in addition to its occurence set  each bond  x  has associated with it two very important propertiee: its reason set and offspring set. the reason set is the l i s t of other proposi tions in memory which contributed to the generation of x  and the offspring set is a l i s t of propositions in whose generation x has participated. thus memory is preserves lines of reasoning as well as the facts lying along those lines. other properties of bonds and 
concepts are: truth  is this fact currently believed or n o t     recency  when was this bond or concept last accessed   and strength  if believed  with uhat strength . strengths are propagated and can be dynamically updated when the strength of propositions on some bond's reason set changes. 
　　　　the flow of information in memory in response to conceptual input ie as follows. the graph is transformed s y n t a c t i c a l l y into internal positional notation. during t h i s process  subpropos i t ions communicated by rel  *＊＊*  links and main-conceptualization modifiers  like tine and location  are noted as potential subpropositions. also during this phase  direct references to predicates and concepts are immediately linked into the correct occurence sets. this includes the creation of new time tokens. next  as many references to tokens are established from descriptive eets as are possible. potential rel subproposi tions used in this step are processed no further. possibly temporary tokens are created for ail unidentified referents  using the available descriptive sets   and bonde are created for the structure's propositions and stored. at t h i s point  there is the main conceptualization  a l i s t of subproposi tions  and a l i s t of unidentified references. 
　　　　the main conceptualization and subpropositions are eubmitted in parallel to the inference mechanism. thie is a simple breadth-first monitor which looks at the predicate of the proposition for which inferences are desired  and locates the lnfe r♀ncji molecule for that predicate. no pattern matching is done in the monitor  only in inference mo i ecu i es. the mon i tor a i so co 1 ec ts as much time information a* can be found about the bond into a condensed form and makes it available to the inference molecule. all inference molecules are time and context sensitive. the molecules are highly structured lisp progs which the moni tor executes. 
e 
       the reeult of executing an inference molecule is a l i s t of inferences  which are pointers to newly created 
bonds in memory   organized by inference type and a simple interest measure. inferences are reordered  cut off below c e r t a i n interest and strength levels  and stored on the master l i s t . after inferencing has ceased  the monitor rescans the master . l i s t to detect actions  asserts the v o l i t i o n of actors by assuming the actor wanted the results of hie action  and submits these new want propositions to the inferencer again. 
       as each 'inference is generated  an  evaluation function  is applied to it to detect one of three 
s i t u a t i o n s ; confirmation  contradiction or augmentation. these are the heart of the causal chain expansion and k n i t t i n g mechanisms described above  but are beyond the scope of this paper  see 1   also during the inferencing  the l i s t of  unident fled concepts mag be augmented by some new inference requiring knowledge which memory cannot guess 
 the example w i l l enow such a case . these go on 'unk'nounref. there is a similar l i s t   called  unknouncon on which missing actions or states  which memory cannot predict  are noted. 
　　　　after all inferencing ceases  the referencer is reentered in the hope that the inferencer has generated new information about unidentified references at the beginning. if any more can be solved at this time  the inference mechanism is re-app 1 i ed  not duplicating previoue work since inference molecules remember which inferences were successful on the f i r s t pass. this second pass is done in case the now-accessibi e occurence sets of the newl y i d e n t i f i e d concepts w i l l open new inference paths. 
　　　　after these processes  potential responses come from the following sources: interesting inferences  iunknqwnref and iunknoutc1n. at present there are no heuristics for deciding what to say  so memory merely dumps everything on the generator for expression. for each conceptualization to be expressed  this involves conversion from internal to external format. part of this is just syntactic  but part is deciding what information to include about each bond and concept since there are generally many members of each concept's and each bond's occurence set. this is a theoretical issue which has not been addressed by this research. hence  memory uses some f a i r l y simple heuristics for deciding what to include in the expression of each bond 
and concept. examples of what to include are: for all concepts  a name if possible; for bodyparts  who is it part ofj for a state  its begin and end times  or just a time ; for an action  time  mode  location  and so on. 
　　　　the proper handling of time relatione has been a central issue in this project. in memory  this means that  as well as time-sensitive inference molecules  there must exist proof procedures for determining before  and otherl relationships. also this means that outdated propositions can be kept around by proper maintenance of their time dependencies. the implications of this approach from the standpoint of the frame problem are discussed in w. 
       a summary of what happens to the parser output from the sentence  john told mary that b i l l wants a book.  w i l l 
now be given. we w i l l not pursue the problems of reference establishment  but assume a perfect internal form can be created immediately. only the inferences which go to the generator w i l l be shown. 

the resulting set of inferences generated  their content  i s; 
 p: peripheral  r: resultative  c: causative  
pr: predictive  n: normative  mios missing informal ion question  
 p  john believes that b i l l wants a dook.  people generally believe what they communicate to others.  
 r  	mary  now knows that 	bill 	wants a book.. 
 people normally believe factual information they are told.  
 p  b i i i wants a book. 
　　　　 memory believes what it hears too.   p r  bill wants to come to possess a book.  people want actions because of the predictable results of those actions. one certain result of an atrans is that the recipient acquires possession of the object.  
 p.r  b i l l possibly wants someone else to cease to have a book  
　　　　 another result of the atrans is that the donor ceases to have the object  this has a much lower strength than the previous one.   n  b i l l wants to read a book. 
 people usually want to have objects to use them in their normal function.  
 p;r  b i l l wants to know the concepts contained in a book. 
　　　　 this would be a result of reading a book.   miq  a book about what  
 the concepts predicted by the last inference are not known. other useful inferences could be generated if memory knew what the book is about.  
 pr  b i l l might get himself a book. 
 knowing someone's state  he may be predicted to do certain things.   pr  john might give b i l l a book. 
 knowing someone's wants  another person might attempt to satisfy them.   pr  mary 	might give b i l l a book. 
 etc.   c  john may want mary to give b i l l a book. 
 a person's motivation for communicating a want might be to have that want satisfied.         memory passes each of these in turn to the conceptual generator. 

1 

1 

meaning class  so control passes to node 1. at this node a cho i ce based on the i dent i ty of the  potentially benefitted  individual is made. since in our example this is the recipient of the mtrans  mary1   the branch leading 
to a1vise1 	and rchn1 	 a sense 	of  recommend   	is taken. eventually terminal node 1 uith the word sense 	aovisel is reached. 
　　　　　'advise1' has associated uith it a lexicon entry  advise  and a framework - a l i s t of syntax relations with a s p e c i f i c a t i o n of a substructure of the conceptualization where the value for each can be found. for 'aovisel* the 
framework contains the pairs: relation conceptual location actsbj actor 1bj1 recipient infinitive object each of these substructures is then used as an argument to the generator program  resulting in the construction of syntax net  b . further processes add such information as tense  voice  and determiners to the syntax net. 
　　　　　th i e exatnpl e has shown how the generator may reconstruct a syntactic case representation of an english input d i r e c t l y from its conceptual representation. it is not necessarily the case  however  that the syntax net derived w i l l correspond directly to the original input. there are two independent sources of the paraphrase c a p a b i l i t i e s of the generator. the f i r s t is implicit in the theory on which this form of generation depends. since the conceptual networks from which the generator works are 
 1  language-free  and 
 1  unique representations of meaning  the generator is not tied to the same vocabulary as the 
parser  nor even to a synonymous one. in generating  b  from  a   there is no clue that the word 'advise' was used in the original statement. 
　　　　　there is also an explicit paraphrase capability in the generator. terminal nodes may contain  in addition to word-sense tokens  pointers back into the discrimination net.  these pointers are written as it node-index  in figure 1. in fact  some terminals contain only such pointers.  in paraphrase mode  the control algorithm may ignore a word-sense token at a terminal and resume the f i l t e r i n g operation at the node indicated by the pointer  thus finding a different 'word-sense' for the conceptual  sub-  structure. this sense may have a very different lexical uni t and syntax framework associated wi th i t   
r e s u l t i n g in a syntax net differing in many aspects from that previously obtained. if 'aovisel'were ignored in the preceding example  f i l t e r i n g would resume at node 1 of the discrimination net  and the head 'rctlnd'  among others  would be found. the following paraphrases are among those obtained for conceptualization  a ; 
john recommended to mary she drink the wine. 
john suggested mary would like to drink the wine. john told mary she would enjoy drinking the wine. 
　　　　　no further description of the surface generation phase w i l l be given here. it bhould be emphasized  however  that the relations we are dealing with in the syntax nets have only syntactic significance to the process  and no semantic properties are ascribed to them. a l l 'meaning' is treated at the conceptual level; thus the notion of a semantic net as proposed by simmons has no place in margie's generation system. in addition to obvious theoretical implications of this difference  there is the practical consequence that we can  in general  expect a simpler netuork grammar to handle a given subset of a language. consider  for example  
 a  john broke the window. 
 b  john remembered to go home. 
the 'eemantic' deep case interpretation may involve marking john as an agent  instigator of an action  in  a   but ae a dative or experiencer  one affected by an action  in  b . we can mark 'john' as actsbj in both caees  since the only property of the relation in which we are interested it that it becomes the subject np in active sentences. 
1. conclusion 
　　　　　margie it intended primarily to be the beglnninge of a larger more complex system for language understanding. 
many effective natural 	language understanding programs. work 
in severely restricted domains. thus  many of the techniques that work  for example  in woods* soon rock* system  1j or winograd'e  blocks world are not necessarily expandable to a larger domain. ue have f e l t that a consistent conceptual representation is very important before attempting computer understanding. our 
analyzer u t i l i z e s the properties of this system to aid its analysis of input sentences. the memory  which certainly owes much of its design to notions brought forward by quii man  1 and becker   operates on these conceptual representations  thus simplifying the problem of handling identical information by allowing only one possible deep format for a given meaning. inference is thus more straightforward because of thb very few primitive actione that exist in the system  see  and . by using a deep conceptual system of the type we propose  the englibh-like quality of the input is lost. untie this f a c i l i t a t e s understanding it also creates the problem of 
recoding information back into english. urn have found simmons' program to be helpful in this regard  but most of the problem was left unsolved by hie program eince his 
representations are considerably less deep than ours. 
　　　　　ue 	have 	found 	margie encouraging uith reapsct to the prospects of a larger system and thus 	we 	stress 	that while 	our 	computer 	results 	are 	interesting  	it is the theoretical design of the 	system 	that 	is 	important 	for future 	e f f o r t s . 
1. 