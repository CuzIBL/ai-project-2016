 
knowledge base  kb  refinement is a suitable technique to support expert system  es  validation. when used for validation  kb refinement should be guided not only by the number of errors to solve but also by the importance of those errors. most serious errors should be solved first  even causing other errors of lower importance but assuring a neat validity gain. these are the bases for improver  a kb refinement tool designed to support es validation. improver refines es for medical diagnosis with this classification of error importance: false negative   false positive   ordering mismatch. improver is being used to validate a real es and some empirical results are given. 
1 introduction 
software validation aims at assuring the compliance of a program with its requirements  which capture the needs of the final user. this concept remains fully applicable when the target software is an expert system  es   although es peculiarities demand specific validation methods. a main difficulty in e s validation is the lack of detailed and testable requirements  rushby 1 . aldiough some work has been developed in tins sense  it becomes increasingly apparent that achieving a complete set of testable requirements for some es tasks  i.e.  medical diagnosis  is currently unfeasible  krause et al  1 . an important part of the validation process relies on manual testing using known cases and matching es outputs against experts' opinions. when discrepancies exist  the es is updated until a satisfactory performance is achieved. 
   theory refinement considers the improvement of an approximate domain theory from a set of cases widi known solution. a refinement problem exists when some of these cases are treated incorrectly in the theory. using machine learning techniques  the theory can be modified to achieve a correct treatment on all cases. it is assumed that the theory is close to a satisfactory state. the set of cases should be a 
   representative sample of the problem domain. 
+ current address: departament de llenguatges i sistemes 
informatics  universitat politecnica de catalunya  pau gargallo 
1  1 barcelona  spain. 
   the manual testing-update cycle in es validation can be automated using theory refinement techniques. the theory is the knowledge base  kb  and the process is known as kb refinement. this approach has been considered by several authors  which have developed automatic kb refinement tools. these works have been mainly focused on developing learning strategies to improve the kb  but the validity of the refined es has not been considered in detail. 
   in this paper  we propose kb refinement as a suitable technique to support es validation. this work shares concepts with previous refinement approaches  although the emphasis is put on the validity of the final es instead on the learning capabilities of the refinement process. since the main concern is to improve es validity  performance errors are no longer considered of equal importance but they are weighted by their relative impact on the es task. this impact depends on the type of error and on the elements involved in this error  aspects that are application-dependent. based on these ideas we have developed improver  a kb refinement tool for es validation  that is guided by error importance. when solving an error  improver may generate new errors of lower importance  but always assuring a neat validity gain. we have used improver to refine es for medical diagnosis  where the solution for a case is a ranked list of elements. this has caused to consider a new type of refinement error  ordering mismatches. 
   this paper is organized as follows. section 1 summarizes previous work. section 1 analyzes kb refinement in es validation. section 1 details the es model  and the refinement criteria and operators. section 1 describes how improver works  while section 1 contains empirical results. finally  section 1 encloses some conclusions. 
1 related work 
verification is the most developed subfield in es validation. 
available verifiers give response to many structural problems  inconsistency  redundancy  circularity  unreachable goals  unfireable rules  etc. . however  the absence of structural problems is a necessary but not sufficient condition to get a valid system. traditionally  validity has been assessed by testing  see mycin  buchanan & shortliffe 1 and rl  mcdermont 1  . manual testing against human experts is very expensive  resulting in a short number of test cases  1 in mycin  1 in rl . nevertheless  the problem is not the number of test cases but their 
	meseguer 	1 

coverage  o'keefe et al  1 . 
   kb refinement systems by empirical learning over a library of known cases follow a common pattern composed of four phases: identification  localization  generation and selection. at the identification phase errors are detected by matching  for each case ci  the set of hypothesis hi  that the es assigns to ci against the correct set of hypothesis an hypothesis h is classified in:  i  true positive  

positives and false negatives are the errors to solve by kb refinement. a false positive indicates that the kb is too general and it should be specialized. conversely  a false negative indicates that the kb is too specific and it should be generalized. the localization phase identifies the kb part responsible for these errors. the generation phase builds several refinements on this kb part. the selection phase determines those refinements to be implemented. 
early refinement systems like seek  politakis & weiss 
1  and seek1  ginsberg et al  1  refine propositional rule bases with a restricted form of uncertainty. rule usage statistics are used in the localization phase. refinements arc generated using heuristics. the antidote algorithm  wilkins & buchanan 1   solves misdiagnoses on rule bases under  probability based  uncertainty. rules are ranked by responsibility on the identified errors. the only refinement operator is rule deletion. the krust system  craw & sleeman  1  refines rule bases considering rule priority. all possible refinements are generated and filtered by heuristics. refined kb are ranked using seek-like statistics. the rtls system  ginsberg 1  refines an operationalized propositional rule base by modifying label hypotheses. refinements consist on label generalization/specialization. 
either  ourston & mooney  1  and ductor  cain 1  refine propositional theories. the localization phase is based on explanation analysis and the generation phase uses inductive learning techniques. selection is made by testing theory performance. these refinement systems consider a simple knowledge representation  namely rules in propositional logic with some kind of uncertainty and  only krust  analyzes the role of control. the es output consists on a single element  which can cause a false positive or a 
false negative. false positives and false negatives are considered equally important. 
1 validation and refinement 
in machine learning the goal of kb refinement is to improve 
es performance by empirical learning. es performance is measured as the number of errors detected executing the es on the case library. when kb refinement is used for validation purposes  the goal is to improve es validity  that is to say  the es should be more valid after implementing each single refinement in the kb. this goal slightly differs from former one  since more valid is not equivalent to performing a lower number of errors. different errors can have a different impact on the overall es validity  so decreasing the number of errors does not always mean producing a better es. to increase es validity  kb refinement should be guided by error importance with respect to the es task. most serious errors should be solved first  
1 	knowledge base technology 
even causing some errors of lower importance  but always assuring a neat validity gain. a classification of error importance with respect to the es task is needed. this classification is application-dependent and may be based on the error type and on the elements involved in an error. 
   for instance  in the medical diagnosis domain a false negative  a diagnosis that does not appear in the es output but it should  is a more serious error than a false positive  a diagnosis that appears in the es output but it should not . a false negative may cause the actual origin of an illness to be ignored. a false positive introduces an extra diagnosis  what can be seen as noise in the es output  but does not cause missing the right one. difference in error importance comes from the impact of each error on the es task. 
   the usage of kb refinement for validation also differs from kb refinement in machine learning. every suggested modification by automatic refinement should be evaluated by the human expert responsible for the es prior any update. detailed justification of the proposed modifications should be provided  detailing the solved errors as well as the potential new errors introduced. after expert's evaluation  the modification can be accepted  rejected or modified. refinement failures should also be reported to the expert  since they leave unsolved errors that will be treated by hand. 
   a kb refinement system and its two main functions  the automatic testing facility and the learning capability  can be of great help in the validation process during the es lifecycle. at the development stage  the automatic testing facility can evaluate the achieved performance as the subset of cases correctly solved in the case library  while the learning capability can improve the current prototype. at the maintenance stage  automatic testing can evaluate the impact of kb updates on the es performance  activating the learning capability if needed. when new cases are added to the library  these processes can be easily repeated. in this way  an accurate measure of the es performance is always available. obviously  a kb refinement system does not release human developers from their responsibilities. they should control all the steps in the refinement process and they should solve the remaining unsolved issues. a kb refinement system automatizes a set of activities that would require lots of effort if they were performed manually  providing modifications that objectively improve the es validity according with the classification of error importance considered for the specific es task. 
1 refinement on an es m o d e l 
in order to carry out these ideas in practice  we selected for refinement the medical application pneumon-ia  verdaguer 1   developed on the shell milord  sierra 1 . this choice fixed the kind of es model to be refined  that is to say  the specific task and the knowledge representation. this has influenced clearly the criteria and operators used in the refinement process  although the basic ideas remain fully applicable for any es. the es task is pneumoniae diagnosis  so this work may be applicable to other es for medical diagnosis. the knowledge representation used is based on rules  including metarules and uncertainty management. in the following  we detail this es model and the refinement criteria and operators we apply on it. 
1 the es model 
   the es model is based on rules  underlying propositional logic  with uncertainty management  including implicit and explicit control  and monotonia 
kb structure. the kb is denoted by a 
mr  where f is a set of facts  r is a set of rules  m is a set of modules and mr is a set of metarules. 
represents an attribute in the problem domain and has both a value and a certainty value  cv  associated. special facts called goals drive the deduction process. two kind of rules exist  concluding rules and up-down rules  forming the disjoint sets and r u d   such that concluding rule is formed by a conjunction of conditions on facts in its left-hand side  ihs   an assertion about the value of one fact in its right-hand side  rhs  and a cv. when r is fired  the concluding fact is asserted with a cv computed from the cvs of and r. an up-down rule rerud is formed by a conjunction of conditions on facts in lhs r  and an action to increase or decrease the cv of a fact/ in rhs r . up-down rules on / are always fired after concluding rules on/. rules are fired backwards. a module contains a collection of rules and one or several goals. each rule belongs to one module. a metarule  is formed by a conjunction of conditions on facts in ihs mr   and an action in  there are two types of actions: on modules and on the es. metarules acting on modules have a 
cv associated  as a measure of their strength. metarules are fired forward as soon as their conditions are fulfilled. 
   concerning uncertainty management  a cv is assigned to each fact representing positive evidence. uncertainty is propagated through rule firing  using the functions cvconjunction and cv-modus-ponens. the function cvdisjunction computes the cv of a fact independently deduced by different rules. the certainty threshold x cuts all deductions with a cv less than x. 
   control is divided in implicit and explicit. implicit control is coded as the conflict-set resolution criteria. three criteria of decreasing importance have been considered:  i  select the most specific rule   ii  select the rule with highest cv  and  iii  select the first rule. these criteria establish a total order in r. explicit control is coded in metarules acting on modules or on the whole es. metarules on modules can perform two actions  add m or remove m  meaning that module m will be activated or inhibited for deduction. a module can be activated several times  but once it has been inhibited it cannot be activated again. active modules are kept in the active module list  acl . modules in the acl are ordered by the cv of their adding metarule. on the whole es only the stop action can be performed. 
es function. the es model works as follows: when it starts  a metarule builds up an initial acl. then the following cycle starts. the first module in the acl is selected as the current module. its goals are pursued using the rules contained in it. as soon as new facts are deduced  metarules are tested for firing  and the acl is eventually updated. when every goal in the current module has been tried  a new current module is selected and the cycle restarts. the es stops when no more modules are available in the acl or a metarule stopping the es is fired. after termination  the es output is the set of deduced goals ordered by their cv. to test performance  the es output in a case c   the ordered set hi  is matched against the correct ordered set obtaining the following errors:  i  false negative  
and  iii  ordering mismatch  	position 
position ordering mismatch is a new type of error caused by the structure of es output. 
es task. the es task is medical diagnosis  specifically diagnosis of extrahospitalary pneumoniae in adults in the first days of infection  verdaguer 1 . the es goal is to obtain  from the patient's data  the subset of microorganisms that are more likely to cause the infection. in very few cases this subset is formed by a single element  because usual symptoms do not discriminate enough to isolate a single cause. the classification of error importance is as follows: false negative   false positive   ordering mismatch. clearly a false negative is a more important error than a false positive in medical diagnosis  at least for pneumoniae diagnosis   and both are more important than ordering mismatch  which simply indicates discrepancy in diagnostic ranking. 
1 refinement criteria and operators 
   first of all  kb refinement in es validation should be guided by error importance with respect to the es task  solving most important errors first. according to the classification of error importance for pneumoniae diagnosis  refinement should try to solve false negatives first  followed by false positives and finally ordering mismatches. the classification of error importance is application-dependent  so this one is only valid for the considered es. 
   second  every type of knowledge in the kb is subject to potential refinement. this applies to domain and control knowledge  since both types of knowledge may be responsible for false negatives and false positives  while domain knowledge is the only responsible for ordering mismatches. refinement of certainty degrees of rules and metarules is obviously included. 
   third  the number of generated refinements must be controlled. this is needed to prevent combinatorial explosion  since the set of modifications that can potentially solve an error is very large. if every potential refinement was tried  the process would be computationally intractable. for this reason  all the implemented systems include some heuristics to control refinement generation. they are based on the following assumption: the kb state is close to a correct state. based on this assumption  we made two choices:  i  minimal changes are preferred  and  ii  refinements cannot delete kb objects. this second choice supposes that every kb object has some prior justification  what is quite reasonable for es built with the support of knowledge engineers and following some development methodology. in other words  we assume that single erroneous rules as totally wrong associations of conditions and conclusion do not exist1. errors are caused by kb incompleteness or by small rule defects  that can affect both control and domain knowledge. the kb is assumed consistent  since consistency and other structural properties can be achieved using verifiers  see  meseguer 1  and  meseguer 1  for an incremental verifier on this es model . based on these assumptions  the legal refinements operators are the following: 
op1. generalize/specialize conditions in the left-hand side of rules/metarules. 
op1. modify the certainty degree of rules/metarules. op1. modify the certainty degree in conclusions of up-down rules. 
op1. modify the right-hand side of a metarule. 
ops. add conditions to the left-hand side of rules/metarules. op1. add new rules/metarules to the kb. 
   proposed modifications may cause new errors. the following criteria establish when a modification is acceptable to guarantee a neat validity gain: 
ac1. a modification solving n false negatives but causing p false positives is acceptable when 
ac1. a modification solving p false positives but causing n false negatives is acceptable when  we have determined empirically for pneumon-1 a. 
ac1. a modification solving o ordering mismatches is acceptable when  i  it does not generates any new false negative nor positive  and  ii  when it causes o' new ordering mismatches  
1 improver: a tool for kb refinement 
improver is a kb refinement tool to enhance es validity. it is composed of three stages: solving-false-negatives. solving-false-posiiives and solving-ordering-mismatches. each stage tries to solve an specific type of error. stages are invoked in this order  because solving an error may generate other errors of lower importance. stage ordering can be altered  to adapt improver to other classifications of error importance. improver has limited the generated refinements to one elementary change on a single kb object. this choice has been quite effective  preventing an exaggerated use of computational resources. in the following  we explain how improver works in every stage and in every refinement phase. the error identification phase is common to all the stages and is explained separately. 
1 error identification 
   the first issue in error identification is the definition of the right solution for a case  the gold standard.  gasching et al  1  provides two definitions of gold standard for a case:  i  the objective correct answer  or  ii  what a human expert considers as the correct answer  using the same information that is available to the es. they take the second definition because the first one is often inapplicable. this is also our approach  since in medical diagnosis the exact illness cause is often unknown  and in occasions can only be obtained by aggressive tests or by autopsy. 
   to compute a gold standard the opinion of a group of independent experts is required for each case. experts usually disagree  so a consensus function is needed. experts' opinions are ranked lists of diagnoses  and the consensus 
1 	knowledge base technology 
function generates another ranked list in the following form. each diagnosis is assigned to the position obtained by computing the position mean value of the diagnosis in the experts opinions. diagnoses with very close positions are grouped into a class  assigned to the mean value of their corresponding positions. the last class in the consensus is eliminated  because it corresponds to diagnoses only mentioned by one expert in a low position. 
   errors are identified by matching the es output against the gold standard for every case. improver obtains the es output simulating es execution. thus  data coming from es execution simulation and from kb refinement are treated homogeneously. improver performs independent analyses of domain and control knowledge  detecting defects that would be occluded by odier defects in actual es execution. specifically  domain knowledge is represented by an and/or tree  where and nodes represent rules and or nodes represent facts in rule conclusions. rule priority is also recorded. control knowledge is represented in a separated and/or tree  where and nodes represent metarules and or nodes represent modules. domain and control knowledge can be refined independently. deduction details for all die deduced facts in all cases are recorded in a table indexed by cases/diagnoses. it allows refinement to focus on specific kb parts  always considering the whole case library. 
1 solving false negatives 
localization when a false negative diagnosis d is detected  both control and domain knowledge are analyzed. control knowledge is responsible for the false negative when the module m containing d has not been visited when it should. this can happen by one of the following causes: 
fn 1. no metarule adding m has been fired. 
fn1. a metarule removing m has been fired. en1. a metarule adding m has been fired but execution has terminated before m has been visited. 
   domain knowledge is responsible for the false negative when  assuming that m has been visited  d has not been deduced. this can happen by one of the following causes: 
fn1. a rule required to deduce d has not been satisfied. fn1. threshold t has cut the deduction for d. 
fn1. an up-down rule has decreased d certainty below t. 
   causes related to control or domain knowledge can coexist. for causes requiring generalization  fn1 and fn1  the partial proof trees for the unsatisfied rules/metarules are computed and passed to the next phases. for the rest of cause types  the responsible rules/metarules are located and passed to the next phases. 
generation/selection. each cause type is treated as follows. selected modifications satisfy ac1. 
fn1. unsatisfied conditions in the partial proof trees are tentatively generalized  op1 . one or several metarules adding m are inductively learned  op1   taking as positive examples the set of false negatives that is being solved and as negative examples the set of false positives caused by the previous unsuccessful generalization. 
fn1. condidons in metarule mr removing m are specialized 
 op1 . conditions are added to mr  ops   taking as positive examples the true negatives in which mr has been fired  and 

as negative examples the false negatives that are being solved. 
fn1. the certainty degree of a metarule adding m is increased  op1 . module m it is located at the beginning of the add part of the fired metarule  op1 . fn1. analogous to fn1 substituting metarules by rules. fn1. the certainty value of the fact / responsible for threshold action is increased. this can be made by cither increasing the cv of rules concluding / op1  or increasing the cv of facts supporting /  op1 or op1 . fact / is identified as the deducible fact with lowest cv in lhs r   being r the rule where the deduction has been cut. 
fn1. the up-down rule r is smoothed making smaller the certainty subtraction  op1 . the cv of d before r is applied is increased  following the fn1 procedure. rule r is specialized following the fn1 procedure. 
1 solving false 	positives 
localization. when a false positive diagnosis d is detected  both control and domain knowledge are analyzed. contrary to the false negative case  there arc not definite but tentative causes since there is no evidence of what rule/metarule should not been fired. control knowledge is responsible for the false positive when the module m containing d has been visited but it should not. this can happen by the following causes: 
fp1. a metarule adding m has been fired but it should not. fp1. a metarule removing m has not been fired but it should. 
fp1. execution has terminated after visiting m but it should terminate before. 
   domain knowledge is responsible for the false positive when  assuming that m hits been correctly visited  d should not been deduced. this can happen by the following causes: 
fp1. rules required to deduce d have been fired. 
fp1. certainty of rules used to deduce d is too high to be cut by x. 
fp1. an up-down rule has increased d certainty. 
ciiven that no definite evidence of the actual cause exists 
 except for fp1   all the possible causes for a false positive are considered. for the cause ip1 requiring generalization  the partial proof trees requiring a minimum number of assumptions are computed and passed to next phases. for the rest of causes  responsible rules are located and passed to the next phases. 
generation/selection. each cause type is treated as follows. selected modifications satisfy ac1. 
fp1. conditions in metarules mr adding m are specialized 
 op1 . each metarule mr is specialized  op1   taking as positive examples the true positives in which mr has been fired  and as negative examples the false positives that are being solved. 
fp1. unsatisfied conditions in the partial proof trees are tentatively generalized  opi . one or several metarules removing m are inductively learned  op1   taking as positive examples the set of false positives that is being solved and as negative examples the set of true positives caused by the previous unsuccessful generalization. fp1. the certainty degree of metarules adding m is decreased  op1 . module m is located at the end of the add part of the fired metarule  op1 . 
fp1. analogous to fp1 substituting metarules by rules. 
fp1. certainty degree of rules involved in the deduction is decreased  op1 . 
fp1. when an up-down rule r has increased the cv of a false positive it is specialized following the fp1 procedure. 
1 solving ordering mismatches 
localization. when an ordering mismatch is detected only domain knowledge is analyzed because control knowledge has no effect in cvs of diagnoses. it can happen by one of the following causes: 
oml. certainty degree of rules used to deduce d is too high/too low. 
om1. an up-down rule has incorrectly increased/decreased d ceruiinty. 
generation/selection. each cause type is treated as follows. selected modifications satisfy ac1. 
oml. certainty degree of rules involved in the deduction of d is decreased/increased  op1 . 
om1. the up-down rule r is smoothed making smaller the certainty addition/subtraction  op1 . the cv of d before r is applied is decreased/increased  following the oml procedure 
1 empirical results 
we have used improver to validate pneumon-ia  an es composed of 1 facts  1 rules  1 metarules and 1 modules. the case library is composed of 1 cases. we have the recommendations of five independent experts for every case in the library. using the consensus function  section 1   we have obtained the gold standard for every case  that has been used by improver to refine pneumon-ia. 
   to evaluate the performance level of pneumon-ia before and after the refinement process  we compare it against human expert competence. thus  we have matched the recommendations of the five independent experts against the gold standard for every case  obtaining the number of false negatives  false positives and ordering mismatches that each expert has performed with respect to the gold standard. we remind that the gold standard was computed as a consensus among the opinions of these experts. we also matched the recommendations of pneumon-ia  before and alter the use of improver  against the gold standard. the results of these comparisons  summarized for all the cases  are recorded in table 1. 
   regarding false negatives  pneumon-ia  before  surpasses in performance to a human expert only  expert 1   while the other four experts exhibit a better performance. however  pneumon-ia  after  surpasses in performance to all the human experts in the most important error type. this result shows clearly the usefulness and power of improver  as well as the quality of the knowledge contained in pneumon-ia. regarding false positives  all the experts surpass in performance to both pneumon-ia  before  and pneumon-ia  after   which decreases 1 false positives. 
experts perform a low number of false positives at the expenses of a high number of false negatives  for example  see expert 1 . on the contrary  p n e u m o n - i a 
	meseguer 	1 

table 1. comparison among five human experts  e1-e1  and 
pneumon-ia  pn  before and after refinement. #fn  
#fp #om and #diag stand for the number of false negatives  false positives  ordering mismatches and total number of diagnoses  considering the whole case library. 
follows the classification of error importance. regarding ordering mismatches  both pneumon-ia  before  and pneumon-ia  after  surpass in performance to all experts except for expert 1. the number of ordering mismatches increases in 1 during the refinement process as a consequence of solving more important errors  specifically false negatives. this is a good example of how the number of errors of a given type may increase at the expenses of solving other errors  resulting in a better es. in summary  pneumon-ia after refinement is clearly more valid than before  what evidences that kb refinement is a very valuable technique for es validation. 
   considering computational complexity  it has been proved  valtorta 1  that rule base refinement is exponential in the worst case. empirical results indicate that  under some assumptions  this problem is tractable for medium-size kb. improver has required 1  1 and 1 cpu hours on a slin1  for solving false negatives  false positives  and ordering mismatches respectively. 
1 	conclusions 
from this work we extract the following conclusions. first  
kb refinement techniques can be effectively used to support 
es validation. second  when used for validation purposes  
kb refinement should be guided by error importance with respect to the es task  in order to assure a neat validity gain. in addition to satisfy acceptance criteria  final acceptance of refinements depends on the expert responsible for es development. third  when solving an error  kb refinement must consider every kind of knowledge that could be responsible for it. and four  using some heuristic assumptions to limit the number of modifications  refinement is computationally feasible for medium-size kb. 
acknowledgements 
i thank ram1n l1pez de mantaras and enric plaza for reading a previous version of this paper and providing many useful comments. i specially thank dr. albert verdaguer for his support on evaluating refinements  and romero donlo for her collaboration on writing this paper. 
