 
in this paper  we examine methods for comparing human and agent behavior. the results of such a comparison can be used to validate a computer model of human behavior  score a turning test  or guide an intelligent tutoring system. we introduce behavior bounding  an automated model-based approach for behavior comparison. we identify how this approach can be used with both human and agent behavior. we demonstrate that it requires minimal human effort to use  and that it is efficient when working with complex agents. finally  we show empirical results indicating that this approach is effective at identifying behavioral problems in certain types of agents and that it has superior performance when compared against two benchmarks. 
1 introduction 
over the past twenty years  ai research has successfully demonstrated a number of techniques for constructing agents that exhibit intelligent behavior. many applications have the additional requirement that the agent's behavior be consistent with that of a human expert. this is especially true for tasks in which the agent must simulate a human such as in training situations or in virtual social experiences such as on-line gaming. 
　for these tasks  the standard approach to developing expert level agents begins with knowledge acquisition. unfortunately  knowledge acquisition is usually imperfect. as a result  significant resources must be spent on validation  which often requires both a knowledge engineer and domain expert to monitor the agent's behavior in a large number of test scenarios. in this paper  we present a method for automatically comparing two actors' behavior that could be used to overcome this validation bottleneck. 
　the potential uses of automated behavior comparison extend well beyond knowledge-base validation. for example  a generalized approach for comparing two actors' behavior can be used to objectively score a turing test. a perfect result would be indicated if no detectable differences between the 
   *this work was supported by the office of naval research  contract n1-c-o1 
human and its computer counterpart were identified. in addition  automated behavior comparison can serve as the core of an intelligent tutoring system  where the roles are reversed. a novice human's behavior is compared to a computer agent's behavior which serves as a gold standard and information about the student's errors is used to guide the lesson. in all of these applications  the basic process for comparing behavior is identical. the differences only stem from the source of behavior  e.g. human or machine  expert or novice  and how the results of the comparison are used  to identify programming errors  to score a test or to guide a lesson . for simplicity and cohesiveness  this paper will focus on using behavior comparisons to aid the knowledge-base validation problem  but the discussion and results can also be applied to the other tasks as well. 
1 interactive human-level agents 
the need for behavior comparisons is particularly pronounced when the agent must masquerade as its human counterpart  the expert . these agents  which we term interactive human-level agents  are distinguished by two properties. first  the agent's performance is judged based on its ability to behave as the human expert would behave. secondly  like humans themselves  interactive human-level agents must interact with an external environment in order to perform many of their tasks. 
　a good example of an interactive human-level agent is tacair-soar  jones et al  1 . tacair-soar flics virtual military planes as part of a simulated training exercise. teammates may be other tacair-soar agents or human counterparts. because the agents are intended to model expert level behavior  it is not acceptable just to achieve the final states  e.g. shooting down the enemy planes . instead  the agent must generate the same behavior as the expert. meeting this requirement is challenging because the expert may perform the task differently on different occasions. 
　in the remainder of this paper  we first begin by examining a simple method of comparing a computer agent's behavior to a human expert's behavior. deficiencies with this method lead us to examine more sophisticated model-based approaches. in section 1 we summarize desirable features of such an approach. then  beginning in section 1  we present our method of model-based behavior comparison. 

1 toward automated behavior comparison 
before two actors' behavior can be compared  the behavior must be represented in a form that can be processed by the comparison algorithm. we can do this most easily by storing individual instances of behavior  or behavior traces. a behavior trace is a sequence of tuples b - in which each tuple 
indicates the environmental state  s   the goals be-
ing pursued by the actor  g   and the action being performed  a . the state and action portion of the behavior trace can be captured by observing the actor perform the specified task. the actor's goals are necessary to disambiguate instances when different actions are performed in equivalent environmental states. depending on whether the actor is human or computer agent  the actor may need to record how their goals change during the task. 
　a simple approach to comparing the actor's behavior can be performed with the following steps: 
acquire a set of behavior traces from the human expert and the agent for the specified task. these sets  h and a  represent the human expert's and agent's behavior respectively over a number of different trials. 
extract relevant features from the behavior traces. some information gathered through observation may not be useful to detect errors. in this step  the salient features from 
the sets h and a are used to create two new sets of se-
	quences 	and 	 
compare each sequence 	to the contents of  
compute the minimal number of edit operations  insert  delete  modify  that would be required to transform a into /i  where h is the sequence in  that is most similar to a. each edit operation indicates a potential error. 
report all deviations  after removing any redundancies  between the human's and agent's behavior. this report summarizes all potential errors. 
　this simple approach performs a more detailed analysis of behavior than simply checking that the agent and the expert reach the same final  goal  state. in this way  the agent's externally observable behavior as well as some aspects of its internal reasoning process can be inspected to ensure that it is consistent with the human expert's. in addition  this methodology has the ability to identify a large number of possible errors because it has access to all the salient properties of the behavior trace. 
　however  this simple approach also suffers from a number of potentially serious flaws. first  the representation of the actors' behavior is a set of sequences extracted from the behavior traces. these sets grow as more observations are considered. because interactive human-level agents can typically solve problems in a number of different ways  and because the environments they operate within are complex  it is likely that a very large number of observations will be required to adequately cover the actor's behavior. this problem is exacerbated by the fact that the sequential representation makes no assumption about how the actor's behavior might be constrained. although this makes it possible to use this simple approach with any variety of behavior  it also makes 
1 
it impossible to leverage regularities that might exist in large classes of goal directed tasks. 
1 model based approaches 
to improve upon the simple approach for automated error detection described in section 1  we propose a model-based approach to comparing actors' behavior. central to any such approach are the properties of the behavioral model. our choice is guided by the following requirements: 
low complexity unless the new model is significantly less complex than the agent's knowledge base  understanding the model and the behavior it represents is no easier than examining the knowledge base directly. for the model to be an asset  it must provide an adequately accurate representation of behavior while remaining easy to understand. 
low effort we have argued that one of the main uses of the behavior comparison is to reduce the cost of validating a human-level agent. in order to accomplish this goal  the human effort required to build the behavioral models must remain low. 
compatibility behavior comparison has a number of potential applications  but most rely on being able to examine both human and software agent behavior. thus the representation must be limited to data that can be collected from either of these types of participants. 
efficiency human-level agents operate in complex environments and may perform their tasks in a variety of different ways. to address this problem  a model may be built using observations of expert behavior. in this case  it must be possible to generate the model efficiently  even if many observations are required. 
efficacy meeting the preceding requirements will come at a cost. most likely this will be a decreased ability to distinguish between some types of behavioral deviations  potential errors . a good representation will nonetheless be able to identify a wide range of behavioral deviations that are likely to occur within the target environments and overlook meaningless differences. 
　prior work in model-based diagnosis  e.g.  lucas  1   has examined how to detect errors given a model of correct behavior. in general  however  the models in these systems are relatively complicated and intended to identify problems with mechanical or solid state devices as opposed to software agents. however  one system  clips-r  murphy and pazzani  1  was designed expressly for validating software agents. 
　in clips-r  the behavior model consists of environmental constraints that must be met initially  as well as during and after task execution. in addition  the model can include a finite state machine which identifies acceptable sequences of actions pursued by the agent. superficially  the requirements for the clips-r approach seem relatively simple to meet. however  specifying this additional knowledge is a manual process that can significantly increase human effort and ironically can introduce a recursive validation problem for the constraints. 
multiagent systems 
1 behavior bounding 
as an improvement to clips-r and to the simple method presented in section 1  our approach to behavior comparison  called behavior bounding  automatically and efficiently builds concise models of both the human's and agent's behavior by examining behavior traces. the model of the expert's behavior is used to identify boundaries on acceptable behavior  and potential errors are reported by comparing the model of agent behavior to these boundaries. 
1 	a hierarchical model 
the advantages of behavior bounding all stem from its representation of behavior. behavior bounding is inspired by the hierarchical representations used in and/or trees  htn planning  erol et al.  1  and goms modeling  john and kieras  1  to encode the variety of ways in which particular tasks can be accomplished. 
　the hierarchical behavior representation  hbr  used in our approach is illustrated in figure 1a. the hierarchy is an and/or tree with binary temporal constraints representing the relationships between the actor's goals and actions. in this representation  internal nodes correspond to goals and leaves correspond to primitive actions. a node's children indicates the set of sub-goals or primitive actions that are relevant to accomplishing the specified goal. for example  in figure 1a  the sub-goals destroy-lead and destroy-wingman are relevant for completing their parent goal  engage - enemy. the manner in which sub-goals should be used to achieve their parent goal is encoded by the parent's node-type constraint   a n d vs or  and the ordering constraints between sub-goals. in figure 1a  a n d and or nodes are represented with ovals and rectangles respectively. binary temporal constraints are represented with arrows between siblings. thus  the hierarchy specifies that engage enemy may be correctly accomplished by first accomplishing destroy-lead and then accomplishing destroywingman. 
　this model of behavior is clearly less complex than the agent's underlying knowledge base  indeed  it is likely to be less complex than the model used by clips-r. behavior bounding abstracts away internal data-structures the agent may use in problem solving that cannot be represented by the constraints in the hierarchy. this means  that the hbr alone could not be used to perform some basic tasks such as depth first search. this begs the question  if the agent's behavior can be represented using such a simple structure  why was it not programmed in this representation to begin with  the hypothesis here is not that this representation is sufficient to completely capture the agent's behavior. most human-level agents do rely on intermediate data-structures that are not available through the environment or through the structure of the goal hierarchy. however  our hypothesis is that the representation provided by behavior bounding is sufficient to identify a large class of possible errors in agent behavior without sacrificing efficiency. moreover  we believe that behavior bounding can also help identify potential problem spots in the agent's knowledge  e.g. a specific goal  even if an exact error cannot be identified. 

figure 1: hierarchical behavior representation & goal stack 
　in contrast to the behavior representations used for the simple comparison described in section 1  the hbr makes two strong assumptions about the organization of the actors' knowledge and the effects this will have on their behavior. these assumptions increase the efficiency and efficacy of error detection for certain types of human-level agents. 
　the first assumption used by the behavior bounding approach is that the actor's goals are organized hierarchically  with more abstract goals placed toward the top of the tree. we also assume that at any point in the problem solving process the actor pursues a set of goals belonging to different levels in the hierarchy. this set  referred to as the goal stack  corresponds to a path in the hierarchy beginning at the top node and descending to the most concrete sub-goal that is currently being pursued by the actor. figure ib illustrates a possible goal stack maintained by the actor whose behavior is represented in figure 1 a. 
　the second assumption leveraged by behavior bounding relates to the independence of goals. temporal constraints can only be formed between sibling nodes  and and/or classification determines which of a node's children must be performed for a particular task. this makes it is easy to constrain the way a particular goal is achieved  but difficult to represent constraints between arbitrary parts of the hierarchy. although this may cause problems with some agent implementations  this property has significant benefits. most importantly  it decreases the number of observations that are required. consider a task that requires completing two goals  each of which could be fulfilled in four distinct ways. a sequential representation that makes no assumptions about goal independence  such as the one described in section 1  would require sixteen distinct observations to cover the acceptable behavior space where as behavior bounding would only require four observations. this significant impact on efficiency is the direct result of leveraging the assumption about how goals are likely to add regular structure to an actor's behavior. 
1 	identifying errors 
in general  we can view a behavior comparison method as an algorithm which divides the space of possible behaviors into two regions: behaviors that are likely to be consistent with the expert  and behaviors that are likely to be inconsistent with the expert. the simple comparison method described in section 1 does this by enumerating consistent behaviors. 

figure 1: imposing order on the behavior space 
in behavior bounding  however  the constrained hierarchical representation allows us to break the space of possible behaviors into more refined regions. 
　we begin by noting that the constrained hierarchical representation allows us impose order on the space of possible behaviors. in particular  we can define an ordering from specific to general over the behavior hierarchies  by starting with a maximally constrained hierarchy  at the top  and iteratively removing constraints until none remain. constructing a representation of an expert's behavior  section 1  performs this same generalization  but most often stops before all constraints have been removed. figure 1  in which each node represents a behavior hierarchy  illustrates this ordering. once we have created a representation for the expert's behavior  we can identify the node it occupies in this ordered space  call this node a in figure 1 . this node  the upper boundary node  allows us to easily determine if the agent's behavior is likely to be correct. because correct behavior must be consistent with expert behavior  an agent whose behavior representation is a specialization of the expert's  i.e. lies above a in the generalization lattice  exhibits behavior that is is likely to be correct. 
　the node that represents the completely unconstrained goal hierarchy is at the bottom of figure 1  labeled b  and provides a lower boundary. it contains the most basic specification for what may constitute acceptable agent behavior and as a result could be used to identify behavior representations that are known to be incorrect. such representations would have a goal decomposition structure that was inconsistent with  i.e. contained different parent/child relationships than  this lower boundary  nodes in the right side of figure 1 . 
　using the upper and lower boundaries described above we can classify any representation of agent behavior as: likelycorrect  a specialization of the expert's behavior representation ; likely-incorrect  a specialization of the expert's goal decomposition structure ; and known-incorrect  inconsistent with the expert's goal decomposition structure . 
　clearly  the hierarchical representation used by our approach describes behavior at a much higher level of abstraction than a typical knowledge base and in so doing  it presents a much more concise illustration of potential behavior than  for example  a set of individual rules. as a result  it meets our first requirement  low complexity . in addition  this representation can be generated automatically by examining behavior 
1 
traces of an actor's performance on a task thus meeting the second requirement  low human effort . and because the behavior traces can be captured from either human or agent behavior with only minor support from the human participant  this model meets the third requirement. in the following sections  we will examine the remaining requirements in detail. 
1 learnability 
in this section  we examine two aspects of behavior bounding's hierarchical representation: the effort required to create and maintain it  and its ability to represent behavior efficiently. both of these requirements are addressed by the overall learnability of the representation. that is  if the representation can be learned from observations  as we have suggested   then it requires human effort only to initiate the learning process. if the learning procedure is efficient  and the data structure's growth is limited  we can further say that the hierarchy represents behavior efficiently. 
　the learning procedure for constructing the hbr extracts goal stacks and actions from a behavior trace  forming a hierarchical structure such as the one illustrated in the previous section. after processing the first behavior trace  the hierarchy contains the maximum number of constraints  i.e. and/or constraints on the goals and binary temporal constraints between siblings  that are consistent with the behavior in the trace. so  if each goal in the hierarchy is pursued only once while performing the task  all internal node-types are a n d  maximally constrained  and all sibling internal nodes are totally ordered  again  maximally constrained .  upon examining subsequent behavior traces  the hierarchy is generalized in such a way that it remains maximally constrained with respect to all of the behavior traces it has processed. 
　due to page limitations  we cannot present the learning algorithm in detail  however it should be clear that the hierarchy can be built as described above with complexity where is the size of the goal hierarchy and l is the length of the behavior trace. in most cases  it is reasonable to assume that one property of expert quality behavior is completion of the task within a number of steps proportional to when this assumption holds  we can say that this algorithm is bounded by   in time and space  with respect to the size of the input  i.e. the length of the behavior trace . because this complexity is a low order polynomial of  the hierarchy is efficient when encoding an instance of behavior. 
　we can also classify the sample complexity of our hierarchical representation. we can think of our representation as an ordered tuple p =  where each pi is itself a tuple containing the type of the node z  either 
a n d or or   as well as a list l = such that iff is ordered before note that since ordering constraints only occur between siblings  the length of the list 
l would only need to be length  in the degenerate case. 
the size of this hypothesis space is bounded by  
using haussler's equation  haussler  1   the number of 
   'the leaves  representing primitive actions  will only be totally ordered if each action was used only a single time to achieve its parent goal. 
multiagent systems 

training examples m required to learn the appropriate behavior representation is bounded by: 

　this indicates that the required sample size is polynomial with respect to the number of goals in the hierarchy   n  . this  together with the fact that the time required to incorporate a new behavior trace into the learned hbr is also polynomial in lnl  shows that our representation is pac-learnable. this means that the hbr efficiently represents aggregate behavior as well an individual instance of behavior  thus meeting our fourth requirement. 
1 efficacy 
the efficacy of behavior bounding is addressed by two components. first  how good is the unconstrained hierarchical representation  the lower boundary  at identifying behavior that is known to be incorrect. second  how well does the expert's representation  the upper boundary  serve to distinguish between potentially correct and incorrect behavior. 
　at first glance  it is not obvious how much behavior can be filtered by the lower boundary. however  its effectiveness as a filter is quite surprising. consider an unconstrained behavior representation with branching factor b and depth d. without loss of generality  assume that the nodes are uniquely labeled. for simplicity  also assume that at any level in this hierarchy  the actor completes its current goal before starting the next goal. then  we could define an actor's behavior as a sequence of symbols chosen from the lowest level of the unconstrained hierarchy. for behavior sequences of length bd  in which no symbol is repeated  there are 
possible sequences that are consistent with the goal decomposition of the unconstrained hierarchy. in contrast  there are bd  sequences in which the symbols may be placed without necessarily conforming to the unconstrained hierarchy. for a hierarchical structure of depth 1 and branching factor 1  only 1 in approximately 1   1 of the possible sequences of length 1 are consistent with the goal decomposition specified by the unconstrained hierarchy. this illustrates the potential power of the lower behavior boundary to discriminate between behavior that is potentially correct and the large collection of behavior that is inconsistent with the expert's goal decomposition structure  and thus known to be incorrect. 
　to examine how well the expert's representation distinguishes between correct and incorrect behavior we would ideally examine a large set of hand-programmed agents before they have been validated. unfortunately  this is not feasible. instead  we make random modifications to an agent's knowledge base. these modifications introduce unbiased behavioral flaws in the agent program  and experiments are performed to determine how well each type of error is identified. because the modifications are made randomly  the errors that are examined will not be biased by our expectations about how easily they will be to identified. 
　our experiments are performed on a series of agents within a simulated object-retrieval environment. the object-retrieval task requires both planning and reactive reasoning. initially  when given the task  the agent must plan a route through known territory to a building thought to contain the desired artifact. because the agent has no prior knowledge of the building's layout  it must explore the facility until the object is found  and then find its way back out. the task is complete once the agent leaves the building with the object. a behavior comparison metric's performance is judged based its ability to correctly identify errors in agent behavior  to identify all errors that have occurred  and to produce minimal amounts of spurious information in the report. 
1 methodology 
we implemented the algorithm described in section 1  along with two version of the simple approach described in section 1 to serve as benchmarks. the first benchmark  the action sequence  extracts the sequence from the behavior trace 
b - while the second benchmark extracts the sequence of goals g =  go  g i   . . .   from b. remember that the benchmarks are not particularly efficient representations; they can grow exponentially and have an exponential sample complexity. however  they do make interesting benchmarks of efficacy. 
　we initially constructed an agent that solves the problem in a very rigid manner. that is  across different attempts  the agent will complete the task using identical behavior so long as it is provided identical initial states and so long as the environment responds identically to its behavior. given this agent  we performed modifications on its knowledge-base by randomly removing rules that determine preferences between competing goals and actions. the results of these modifications are agents that complete the task successfully in the traditional sense  i.e. they reach the same end state   but have increased flexibility in terms of the sequence of goals and actions they use to achieve that final state. in addition  the behavior exhibited by these modified agent's cannot be classified as incorrect by the lower behavior boundary node. as a result  these tests directly examine the abilities of the upper boundary node to distinguish between correct and incorrect behavior. 
　each family of experiments begins by selecting two agents  e and n  such that n is a modified  more flexible  version of e. we designate e as the expert  and n as the novice. because n is more flexible than e  it will behave in certain ways that are not consistent with expert behavior-these are errors. 
　after the expert and novice have been selected  they are individually incorporated into a simulation so their behavior can be observed. we then gather between 1 and 1 behavior traces of the actors performing their task  ensuring that no two behavior traces are identical. these traces form the sets and  for the expert and novice respectively. finally  each behavior trace in  is examined manually to determine what errors it contains. 
the captured behavior traces are then split into a number 
of subsets: 	and 	a single experi-
ment consists of examining each comparison method's performance on a pair of these subsets and   a family of experiments contains the experiments that compare all to all  for a particular novice/expert pair. thus comparing 


　　　experiment family figure 1: report density 
four expert/novice pairs results in four experiment families although the total number of individual experiments may be much larger. by constructing experiment families in the way  we are able to examine the impact of different observational data more easily. 
1 	results 
for each experiment  we begin with a record  summarized by our manual examination of the agent's behavior traces  of what behavior errors were committed by the agent; these are true errors. this record identifies both low-level true errors such as omissions  commissions  and intrusions  as well as higher-level true errors such as misplacement  or repetition which are the result of multiple low-level errors. we then collect a summary from each comparison method about how the agent's behavior differed from the expert's behavior. based on this  we record the number of true errors that occurred but were not identified by the summary  false negatives . then  for each behavioral deviation in the summary we manually determine whether it indicates a new true error in the agent's behavior. if so  this deviation is meaningful and thus a useful part of the report  otherwise it is spurious. 
　to judge the performance of a comparison method  we first determine how many errors it fails to identity  false negatives . from this standpoint  all comparison methods performed relatively similarly. across all experiment families the range on false negatives is between zero and 1 for all comparison metrics. however  in each experiment family behavior bounding does perform slightly better than the rest  maintaining the lowest average score  and achieving zero false negatives in five experiment families. 
　the other performance criteria we are interested in is how much of the comparison method's summary is useful. because the summary is likely to be analyzed by a human  spurious errors are undesirable because they require human effort to examine and follow-up before they can be dismissed. if a summary is largely spurious errors  it is unlikely that anyone would actually care to read it. on the other hand  if the summary provides a large amount of good information  an occasional spurious error is likely to be acceptable. 
this can be expressed as a ratio of how many true errors 
1 
can be identified by the deviations listed in the summary to the total number of deviations listed in the summary. we call this value the report density of the summary. thus  a comparison method that reports no meaningful deviations  and only spurious information will have a report density of zero. note that it is possible for the report density to be higher than one. when a deviation in the summary correctly identifies a highlevel error  such as the agent performing action a before b in contrast to the expert who performs b before a  we consider the summary as also identifying all the low-level errors that form this high-level error  e.g. two commissions in which a replaces b and vice-versa . this means that from the point of view of report density  it is better to identify high-level errors than low level errors. because we should favor concise summaries  this is exactly what we want. figure 1 illustrates the average report density of each comparison method's summary over all experiment families. overall  behavior bounding outperforms the other metrics by achieving an report density of one or higher in six of the seven experiment families. 
1 	conclusions 
our behavior bounding method uses an abstract model of behavior to identify potentially problematic differences between two actors. this in turn leads to a semi-automated method that can be used to validate complex  human-level behavior. moreover  behavior bounding offers significant advantages over prior validation approaches and traditional manual techniques: it can be easily be used to validate an agent when human performance is the specification for acceptability; it requires only minimal human effort to initiate and perform the behavior comparisons  and behavior bounding is effective at identifying errors  even when compared to methods that are not constrained by efficiency requirements. 
