 
motivated by the need to reason about utilities  and inspired by the success of bayesian networks in representing and reasoning about probabilities  we introduce the notion of utility distributions  in which utilities have the structure of probabilities. we furthermore define the notion of a bi-distribution  a structure that includes in a symmetric fashion both a probability distribution and a utility distribution. we give several examples of bi-distributions. we also show that every state space with standard probability distribution and utility function can be embedded in a bi-distribution  and provide bounds on the size requirements of this bi-distribution. finally  we suggest a reinterpretation of the von-neumann and morgenstern theorem in light of this new model. 
1 	introduction 
ai enjoys a rich arsenal of tools with which to represent shades of certainty. one can formally represent varieties of certainty using logics of knowledge  nonmonotonic logics  and  importantly  probability theory. one reason the latter is particularly significant is that one has tools for efficiently representing and reasoning about probabilities  notably in the form of bayesian networks. 
　of course  ai is interested in uncertainty in general  and in probability in particular  only to the extent that it provides help with decision making. while wildly successful  bayesian networks constitute a mechanism to reason purely about probabilities. in contrast  ai has been fairly impoverished when it comes to mechanisms for reasoning about the motivational components of decision making  such as preferences  goals  and  importantly  utilities. 
   *this work was supported in part by nsf grant iri1. 
1 	probabilistic reasoning 
　i don't mean that ai hasn't designed computational mechanisms to deal with some of these notions; obviously  the notions of goals and plans lie at the heart of ai planning research. what i mean is that there is not the analog of bayesian networks  that is  a simple and clear computational mechanism to effectively reason about preferences or utilities that rests on crisp  wellunderstood mathematical foundations. 
　influence diagrams  and the related dynamic bayesian networks  are the closest we get to mechanisms for reasoning about utilities. however  while these mechanisms are undisputedly important and do contain a utility component  they provide very little power to reason about the utility component. i will discuss this further in the comparison section. 
　why might we want to reason purely about utilities  the answer might be self evident  but here are a few examples: 
 personalization  a recipe-generation program can use information about the user's gastronomical preferences to devise tailored recipes. 
 software agency  a software agent needs to know its owner's preferences so as to act in the owner's best interests. 
 electronic commerce  a software agent engaged in a strategic interaction with another  human or computer  agent can exploit an understanding of the other agent's preferences to maximize its gain. for example  a software agent negotiating over access fees to a database might benefit from knowing that the database owner pays royalties to a third party on certain items and not on others. 
　it would be quite convenient if we had a mechanism analogous to bayesian networks to reason purely about utilities  and this paper makes a contribution in that direction. at the heart of bayesian networks lie three concepts: probability distribution  conditional probability  and probability independence. if we manage to mirror those notions in the case of utilities  we will have 
　
availed ourselves of a ready-made mechanism for reasoning about utilities. this paper is devoted to the first task  namely  defining a notion of distribution for utilities. a companion paper  sho1  completes the story by discussing conditional utility and utility independence. 
　perhaps the best starting point for explaining the approach advocated here is to note the striking asymmetry between probabilities and utilities in the traditional view  e.g.   kre1; sav1; fis1  . a probability distribution has a rich structure  which allows you among other things to compute the probability of an event  that is  a set of states  and to meaningfully add the probabilities of disjoint events  whereas a utility function allows neither. the crux of my argument will be that this is an arbitrary choice  and that in fact one can define a coherent notion of utility distributions in which  for example  in makes perfect sense to add the utilities of disjoint events. in fact  the same argument will suggest that in a symmetric fashion the notion of probability can be coherently weakened to a notion of graded certainty that has only the properties of traditional utilities. 
the structure of the rest of the paper is as follows. 
  in section 1 i review some of the importance man-ifestations of the asymmetry between probabilities and utilities. here i discuss only the more familiar quantitative case; in the long version of this paper i discuss also the  arguably more fundamental  qualitative case. 
  in section 1 i give an overview of an alternative  more symmetric model by way of a simple example  and accompanying intuition. 
  in section 1 i provide the mathematical definition of this alternative model  and explore some of its rudimentary properties. 
  in section 1 i discuss the possible impact on the foundations of decision theory; specifically  1 speculate on how one might re-interpet von neumann and morgenstern's seminal representation theorem. 
  finally  in section 1 i discuss related work. 
1 asymmetries in quantitative probabilities and utilities 
here are some obvious asymmetries between the quantitative models of probabilities and utilities  in the traditional view. 
　1. probability of each state lies in  1   and the probability of all states sum to 1. utilities of states  or outcomes  or prizes  do not have these constraints. this on the surface is no big deal; certainly in the finite case one can normalize the utilities to comply with these constraints. 
　1. under some conditions we can meaningfully add or subtract probabilities of different states; there appears to be no sense in performing similar arithmetic on utilities of states. this is perhaps the most telling asymmetry between current quantitative theories of probability and utility. 
　1. the fundamental notion in the case of probability is a probability distribution  or lottery   a function applied to sets  specifically  a function defined over a algebra   whose values on different sets are constrained by the settheoretic relationships between these sets. in the case of utility  the fundamental construct is a function applied to a single state  and  as it happens  yielding a real value . there is no principled way to lift this function to sets of states without appealing to the added notion of probability  i.e.  via the notion of expected utility  but see section 1 for discussion on some proposals to lift an ordering on points to an ordering on sets of points . 
　in short  there are fairly interesting things we can do with probabilities alone  and almost nothing we can do with utilities alone. 
1 	two examples 
in this section i will explain all the important ingredients of the construction through two examples and informal discussion; the formal definitions and results will be given in the next section. 
　consider the possibility of owning any of three cars: a rolls royce  r   a maserati  m   and a ford  f . this gives rise to eight different events  corresponding to whether each of these cars is owned. suppose furthermore that we define a probability distribution over these events  and also attach utilities to each of the states  as follows: 
state   r m f rm rf fm rfm prob. 1 1 1 1 1 1 1 1 util. 1 1 1 1 1 1 1 1  the uniform distribution is chosen here for concreteness; any other would do as well.  we can sum any of these probabilities and get something meaningful; for example  we can compute the probability of owning a ford by summing the probabilities of the four states that include a ford  getting the value 1. we cannot meaningfully sum any utilities we wish. however  it is easy to see that the utility function in this example has a special structure. specifically  it can be interpreted as arising from assigning the three cars the values 1  1  and 1  respectively  and defining the utility of any subset of the three cars as the sum of the individual utilities of the cars in the subset.1 
   *the reader familiar with multi-attribute utility theory will recognize that this is a special case of maut; more on 
　
　given this observation  let us construct another space as follows: 

　the first two rows of this structure form an instance of what i will call a utility distribution. the states in this distributions will be called factors.  from now on i'll reserve the term 'states' to denote elements on which a probability distribution is defined  and 'factors' to denote elements on which a utility distribution is defined.  factors are informally thought of as the various independent contributions to one's sense of satisfaction or well being. the utilities associated with each factor determine how much of one's sense of well being is supplied by that factor. a factor set is simply a set of factors  for example {r f}  and it plays a role analogous to an event in a probability distribution; its contribution to one's satisfaction is simply the sum of the contributions of its members. one can additionally attach to factors  probabilities  and on the basis of those compute expected utilities  but these are mere numbers that cannot be meaningfully added up. in other words  this structure is the exact dual of the structure we started out with. 
　finally  note that these two structures are intimately connected  in the sense that certain factors  co-occur  with certain states. specifically  r co-occurs with all the states that contain r  and ditto for m and f. so in fact  one need not explicitly list the utilities in the first structure  nor the  probabilities  in the second structure. these can be inferred: the utility of a state is the sum of the  utilities  of all factors that co-occur with it  and the  probability  of a factor is the sum of the probabilities of all states that co-occur with it. 
　this is a convenient situation; not only have we managed to separate the representation of probabilities from that of utilities  but the representation of utilities is identical to that of probabilities  providing hope that we can use  e.g.  the mechanism of bayesian networks to reason about utilities. 
　on the face of it  our example was contrived so as to make this separation possible. can we view any given utility function as having this particular form  we will see in the next section that the answer is 'yes ' but that the set of factors might not be as small as this particular example suggests. the next example illustrates this point  and also the fact that the notion of 'factor' is quite broad. 
　suppose we have seven envelopes; one contains one $1 bill  another contains two $1 bills  and so on up to seven $1 bills. a subject receives one of these envelopes drawn from a given distribution. for concretethis in the comparison section. 
1 	probabilistic reasoning 
ness  consider uniform distribution  and a sigmoid-like utility function; the smallest-valued envelopes have little value since there's little you can buy with them  then they start to pick up steam  and at some point their value starts to level off because there's just that many things you can buy. this is captured in the following table: 
state | $1 $1 $1 $1 $1 $1 $1 prob. | 1 1 1 1 1 1 1 util. .1 .1 .1 .1 .1 .1 1 　as usual  it would make no intuitive sense to ask what the numerical utility was of the set consisting of the second and fifth envelopes  without appealing to probabilities. however  let us now construct the dual space where we can ask these sorts of questions. this time the factors will consist of the seven pairs  k  k- i  for 1   k   1; the informal interpretation of the pair will be the ar-th  order statistic   that is  the k'th $ bill. the utility of the k-th $ bill will be defined as the difference between the utilities  in the first   state  space  of the $k-envelope and the $ k - l -envelope  that is  the marginal utility of the k-th $1 bill  we take the utility of a $1-envelope to be 1  to cover the case of k = 1 . in our concrete example  these marginal utilities form a bell-shaped curve; the marginal utility drops the closer k is to either 1 or 1. this is captured in the following table: 
factor   1st 1nd 1rd 1th 1th 1th 1th util. .1 .1 .1 .1 .1 .1 .1 prob. | 	1 1 1 1 1 1 1 　in this factor space it makes perfect sense to add the different contributions to joy: the second $1 bill adds an independent value from that of the fifth $1 bill. 
　here's an important point. you might worry that  it doesn't make sense to add up the utilities of only the second and fifth $1 bills  since we can't get the two bills without also getting all first five.  but that's confusing states with factors; the fact that one cannot experience a particular combination of factors doesn't mean that this combination has no meaning or value. 
　of course  we would like to capture the fact that only certain factor combinations are possible  and here is where the co-occurrence relation between states and factors comes in. in the first example  for each combination of factors there was a state whose co-occurring factors were exactly that combination. this is not the case in this second example. here  the k -th-$ factor co-occurs with the $/-envelope iff k   i. 
　a final word about the numerical range of probabilities and utilities  before we move on to the formal treatment. why do we insist that utilities sum to 1  in fact we don't have to  but nor do we in the case of probabilities. the question is whether we wish to model relative notions of  chunk of reality  or  chunk of satisfaction   or absolute 
　
　the previous definition intentionally avoids a particular interpretation of the notions  so that they can be applied to both probabilities and utilities. the following definitions could also be presented in neutral terms  but that generality is not needed in this paper. 
definition 1 a bi-distribution  also called a pudistribution  is a triple  such that 
-  sp  p  is a distribution called the probability distribution  
 su   u  is a distribution called the utility distribution  
- sp and su are disjoint  and 
l is a nonempty subset of sp x su. 
　next  we use the structure to compute expected utilities: 

proposition 1 	given a bi-distribution as above  

　the next proposition delivers on the promise that one need not get lucky to enjoy the bi-distribution representation: it states that given any probability distribution with an associated utility function on its states  we can embed the probability distribution in a bi-distribution that induces back the original utilities on the components of the probability distribution. 
　this above construction appears to be wasteful in the number of factors created in order to represent a given utility function. we might ask how small that set of factors might be. 
proposition 1 
 lower bound  given any set s of n distinct natural  real  numbers  there does not exist a set t of less than log1 n natural  real  numbers such that each number in s is the sum of some numbers in t. 
 upper bound  there exist infinitely many sets s of n distinct natural  real  numbers  including infinitely many in the interval  1 i    for which there does not exist a set t of less than n natural  real  numbers such that each number in s is the sum of some numbers in t. 
　proof:  lower bound  k numbers yield at most 1k distinct sums   upper bound  take s to be any finite set of distinct powers of 1  for example {1 1}  or any set of distinct negative powers of 1  for example {1/1/1/1}. 
　these facts still leave open several important questions. perhaps the most important mathematical question is what is the minimal set of factors required for a given set of utilities. and most importantly  these mathematical constructions do not address the question of how natural the factors are. 
　finally  a short and somewhat whimsical comment on expected utilities. so far  we've discussed probability and utility as rich notions  but expected utility as little more than the result of numerical calculations on given probabilities and utilities. it's possible to invert the picture  and view the links of a bi-distribution as the basic elements of our world model. the link  s t  will be assigned the weight p s u t   and the weight of sets of links will be simply the sum of their weights. what do those links represent  well  if the state s describes a piece of reality  and the factor t describes a piece of joy  then surely the pair  s t  describe a piece of real ized  joy. while it's hard to object to a theory of real joy  this line of reasoning does not play a role in the paper and is not developed further. 
1 	the scriptures revisited 
the primary motivation for this paper has been the search for a mechanism for reasoning about utilities. in service of this goal  the particular focus of this paper has been to level the playing field between probabilities and utilities. however  the notion of utility distributions calls into question foundational assumptions in choice theory regarding the asymmetric roles and structure of probabilities and utilities. indeed  it suggests a reinterpretation of some of the most influential developments in choice theory. here we will discuss one of them the representation theorem of von neumann and morgenstern.1 
　in the foundations of decision theory  mental notions such as utilities are usually presented as convenient auxiliary constructs  to be justified based on other  observable phenomena such as choices made. the representation theorem of von neumann and morgenstern  and especially that of savage  the  crowning achievement of decision theory   to quote one mathematical economist   are among the deepest embodiments of this  revealed preference  doctrine. some economists have argued to me in private that the fact that the traditional properties of probabilities and utilities enable these deep theorems is in itself justification for accepting these properties. 
　recall von neumann and morgenstern's theorem  here presented in its finite version . the setting is a finite set of prizes  or outcomes  z  the set p of all  !  probability distributions over z  and a binary relation   on p. the intended interpretation of p   q is  p is preferred to q.  vnm introduce the following three postulates: 


 with the usual overloading of the   symbol . furthermore  u is unique up to positive affine transformation. 
i will now present a new representation theorem  which i'll call the vmn theorem. the setting for the vmn theorem consists of a set of factors z  the set p of all utility distributions over z  and an ordering   on p. the intended interpretation of p   q is  p is preferred to q. 1 
　we are now ready to present the vmn theorem  but we need not; it is identical to the  theorem. 
　this is of course tongue-in-cheek; i've presented no new mathematics  and have merely re-interpreted the vnm theorem. however  i have hopefully made the point that the conceptual foundations of the vnm theorem are open to debate. while the theorem was presented with a certain interpretation in mind  it admits at least one other interpretation as well  in which the roles of probabilities and utilities are reversed. specifically  the original interpretation suggests a picture of a selfish person attempting to select among lotteries presented to him so as to maximize his own expected payoff. the new interpretation suggests a picture of a benevolent person attempting to select among multiple other people with varying tastes  in order to maximize the payoff to the selected person.  note that the properties represented by the three postulates seem to make as much sense under the reverse interpretation as under the intended one . 
　note  by the way  that this re-interpretation of the vnm theorem flies in the face of its reputation as the most extreme embodiment of objectivist view on probabilities. in the re-interpretation  the utilities are exogenous  or objective  and the  probabilities   quoted here since they no longer have the rich structure of a distribution  are imputed  or subjective. 
　i believe similar discussion is possible in the context of the more complex representation theorem of savage  but that is beyond the scope of this paper. 
　
1 	probabilistic reasoning 
　
1 	related work 
the advertized motivation for the work described here is a dearth of mechanisms to reason about utilities. we should mention one weak exception to this dearth  namely influence diagrams  sha1 . these have  in addition to chance and decision nodes  a special node called a value node. this node  which can have no successors and cannot be part of the evidence set  is merely used to compute a given expected utility function as a result of evidence propagation. the usual way this utility is used is to search the space of values for decision nodes so as to maximize this utility. thus  while technically speaking 
　　1  yet a different version would substitute here  p is mroe likely than g   but we do not pursue this further here. 
　
influence diagrams reason with utilities  in fact all their smarts is in how they represent probabilities. 
　one minor modification of the basic influence diagram is to introduce several value nodes  and to sum the utilities of all the value nodes. this is based on assumption that the utility function is decomposable in such as way. the theory governing such decomposable utility functions is multi-attribute utility theory  maut   kr1 . maut has attracted some attention in ai in recent years  since it seems to offer a handle on complexity. indeed  utility distributions are closely related to mau functions. it is beyond the scope of this paper to discuss this connection in detail; this is precisely the topic of the companion paper  sho1 . here i will only remark that from the mathematical point of view utility distributions can be seen as a special case of additive multi-attribute utility functions  but that the difference is also conceptual in nature  and hinges on novels senses of conditional utility and utility independence. 
　the main  complaint  in the paper about the standard notion of utility function has been that it applies to states but not to events  or sets of states. there have been several proposals in ai to lift an ordering defined on points  whether the ordering reflects a degree of certainty or a preference  to an ordering on sets  for example by doyle and wellman  dw1  and halpern  hal1 . all these proposals are qualitative in nature; they usually boil down to quantifying over points in various sets  which reduces to using the min and max operations in some combination. none of these proposals have the quantitative flavor afforded by  probability or utility  distributions. 
1 	summary and what's next 
there is growing interest in ai in representing and reasoning about utilities. we have suggested that endowing utilities with the properties of utilities will get us closer to the goal of applying bayesian-network-like mechanisms to utilities. the primary contribution of this paper has been to introduce the notion of utility distribution  and the related notion of bi-distribution. a side effect of this development has been to call into question conventional wisdom from mathematical decision theory. 
　this is clearly only the beginning of the story. now that we have a sense for utility distributions  we can revisit the familiar notions of conditional utility and utility independence. as was mentioned  this is the topic of  sho1   where we show new senses of these notions that are isomorphic to their probabilistic counterparts. this means that  at least in principle  we can use the mechanism of bayesian networks  that would more aptly be called utility networks in this context  to reason about utilities. however  whether this promise can be realized  depends on whether one can take these formal ideas and apply them in practice. can one identify natural factors in realistically large and natural domains  can we in fact elicit preferences using the new model  it must be admitted that at this time factors seem more mysterious than states. it is not clear to me if this is a reflection of their novelty  the inherent elusiveness of mental state  or the fact that factors are not in general a natural category. while i'd like to believe that the framework described here  and further developed in  sho1   is more than an idle exercise  only time will tell. 
acknowledgements. i have discussed the ideas described here informally with many people  who have made very useful suggestions and other comments. among the ai/cs people are xavier boyen  urszula 
chajewska  denise draper  moises goldszmidt  daphne 
roller  christos papadimitriou  stuart russell  and mike wellman. among the economists are ken arrow  
paul milgrom  and especially tzachi gilboa. in addition the referees made useful comments on an earlier draft of the paper. this  however  does not imply that any of the above necessarily agree with the ideas expressed here. 
references 
 dw1  j. doyle and m. p. wellman. defining preferences as ceteris paribus comparatives. in proc. aaai spring symp. on qualitative decision making  pages 1  1. 
 fis1  p. c. fishburn. utility theory for decision making. john wiley &; sons  inc.  1. 
 hal1  j. y. halpern. defining relative likelihood in partially-ordered structures. in proc. twelveth conference on uncertainty in artificial intelligence  pages 1  1. 
 kr1  r. h. keeney and h. raiffa. decision with multiple objectives: p