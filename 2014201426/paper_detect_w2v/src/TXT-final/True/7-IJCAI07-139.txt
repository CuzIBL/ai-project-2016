
planning in partially-observable dynamical systems  such as pomdps and psrs  is a computationally challenging task. popular approximation techniques that have proven successful are point-based planning methods including pointbased value iteration  pbvi   which works by approximating the solution at a finite set of points. these point-based methods typically are anytime algorithms  whereby an initial solution is obtained using a small set of points  and the solution may be incrementally improved by including additional points. we introduce a family of anytime pbvi algorithms that use the information present in the current solution for identifying and adding new points that have the potential to best improve the next solution. we motivate and present two different methods for choosing points and evaluate their performance empirically  demonstrating that high-quality solutions can be obtained with significantly fewer points than previous pbvi approaches.
1 introduction
point-based planning algorithms  pineau et al.  1; spaan and vlassis  1  for partially-observable dynamical systems have become popular due to their relatively good performance and because they can be implemented as anytime algorithms. it has been suggested  e.g.  in  pineau et al.  1    that anytime point-based planning algorithms could benefit significantly from the principled selection of points to add.
¡¡we provide several methods for using information collected during value iteration  specifically  characteristics of the value function  to choose new additional points. we show that properties of the value function allow the computation of an upper bound on the potential improvement  gain  resulting from the addition of a single point. we argue that the addition of points with maximal gain produces good approximations of the value function  and this argument is empirically verified. further  we define an optimization problem that finds the point with the maximal gain for a given region.
¡¡these new approaches are empirically compared to traditional anytime point-based planning. the results show that our algorithms choose additional points that significantly improve the resulting approximation of the value function. such improvement is potentially beneficial in two ways. first  computation time can be reduced because there are many fewer points for which computation must be performed. however  this benefit is sometimes  but not always  offset by the additional time required to select new points. another potential benefit is reduced memory storage for smaller sets of points. currently  the solution of most systems do not require large numbers of points  but a storage benefit may become more important as the size of problems increases such that more points are required.
1 background
the planning methods developed here are for partiallyobservable  discrete-time  finite-space dynamical systems in which actions are chosen from a set a  observations from a set o  and rewards from a set r. there is exactly one action  one observation  and one reward per time-step-planning algorithms attempt to find a policy that maximizes the longterm discounted reward with discount factor ¦Ã ¡Ê  1 .
¡¡these point-based planning methods are suitable for at least two classes of models that can represent such dynamical systems  the well-known partially observable markov decision processes  pomdp   and the newer predictive state representation  psr   singh et al.  1 . for the sake of familiarity  we use pomdps here  but it should be noted that the methods presented here  as well as other planning methods for such dynamical systems  can just as easily be applied to psrs  see  james et al.  1  for details .
1 pomdps
pomdps are models of dynamical systems based on underlying latent variables called nominal states s ¡Ê s. at any time step  the agent is in one nominal state s. upon taking an action a ¡Ê a the agent receives a reward r s a  that is a function of the state and action  transitions to a new state s according to a stochastic transition model  and receives an observation o ¡Ê o according to a stochastic observation model pr o|s a . for compactness  we define the vector ra as ra s  = r s a . 1
¡¡the agent does not directly observe the nominal state s  and so  must maintain some sort of memory to fully characterize its current state. in pomdps  this is typically done using the belief state: a probability distribution over nominal states. the belief state b summarizes the entire history by computing the probability of being in each nominal state b s . this computation of the new belief state reached after taking action a and getting observation o from belief state b is given in the following update:
.
this equation is used as the agent interacts with the dynamical system to maintain the agent's current belief state.
1 point-based value iteration algorithms
point-based planning algorithms  such as pbvi and perseus  for partially observable dynamical systems perform planning by constructing an approximation of the value function. by updating the value function for one point  the value-function approximation for nearby points is also improved. the basic idea is to calculate the value function  and its gradient  only at a small number of points  and the value function for the other points will be  carried along . this point-based approach uses only a fraction of the computational resources to construct the approximate value function  as compared to exact methods.
¡¡there are two main sets of vectors used: the set p of points  each of which is a belief state vector; and the set sn which represents the approximate value function vn at step n. the value function is a piecewise linear convex function over belief states  defined as the upper surface of the vectors ¦Á ¡Ê sn. the value for belief state b is

¡¡the bellman equation is used to define the update for the next value function:

where
	 	 1 
for ¦Ái ¡Ê sn. these g vectors are defined as such because they lead to computational savings. the computation of ¦Á vectors for vn+1 b  uses the so-called backup operator.
	backup b  = argmaxbtgab 	 1 

whereargmax{gaoi }i btgaoi . in pbvi  the backup is applied to each point in p  as follows.

function onesteppbvibackup p  sold 
1. snew =  
1. for each b ¡Ê p compute ¦Á = backup b  and set snew = snew ¡È ¦Á
1. return snew

¡¡for perseus  in each iteration the current set of ¦Á vectors is transformed to a new set of ¦Á vectors by randomly choosing points from the current set p and applying the backup operator to them. this process is:
function onestepperseusbackup p  sold 
1. snew =    p = p  where p lists the non-improved points

1. sample b uniformly at random from p  compute ¦Á = backup b 
1. if bt¦Á ¡Ý vn b  then add ¦Á to snew  else add = argmax
1. compute
1. if p is empty return snew  otherwise go to step 1
¡¡given this  the basic  non-anytime  algorithms are  for * ¡Ê  pbvi  perseus :

function basic*  
1. p = pickinitialpoints    s1 = minimalalpha    n = 1
1. sn+1 = onestep*backup p  sn 
1. increment n  goto 1

where pickinitialpoints   typically uses a random walk with distance-based metrics to choose an initial set of points  and the function minimalalpha   returns the ¦Á vector with all entries equal to minr¡Êr r/ 1   ¦Ã . the algorithm will stop on either a condition on the value function or on the number of iterations. this algorithm is easily expanded to be an anytime algorithm by modifying pickinitialpoints   to start with a small set of initial points and including a step that iteratively expands the set of current points p. typically  having a current set with more points will result in a better approximation of the value function  but will require more computation to update. the anytime versions of the algorithms are:

function anytime*  
1. p = pickinitialpoints    s1 = minimalalpha    n = 1
1. if readytoaddpoints    then p = p ¡È bestpointstoadd findcandidatepoints   
1. sn+1 = onestep*backup p  sn 
1. increment n  goto 1

¡¡there are three new functions introduced in this anytime algorithm: readytoaddpoints   which determines when the algorithm adds new points to s; findcandidatepoints   which is the first step in determining the points to add; and bestpointstoadd   which takes the set of candidate points and determines a set of points to add. in section 1  we present variations of these functions  including our main contributions  methods for determining the best points to add based on examination of the value function.
1 incremental pbvi and perseus
in this section we present methods for finding the best points to add  given a set of candidate points. in some cases  the best points will be a subset of the candidates  and in other cases new points that are outside the set of original candidates will be identified as best. in all cases  we will make use of a scalar measure called the gain of a point  which is a way to evaluate how useful that point will be. we show how the current  approximate  value function can be used to compute useful measures of gain that can then be used in informed methods of point selection.
¡¡for a point b in the belief space  the gain g b  estimates how much the value function will improve. the problem  then  is to construct a measure of gain that identifies the points that will most improve the approximation of the value function. this is a complex problem  primarily because changing the value function at one point can affect the value of many  or all  other points  as can be seen by examining the backup operator  equation 1 . changes may also propagate over an arbitrary number of time steps  as the changes to other points propagate to yet other points. therefore  exactly identifying the points with best gain is much too computationally expensive  and other measures of gain must be used.
¡¡here  we present two different measures of gain: one based on examining the backup operator  written gb  and the other is derived from finding an upper bound on the amount of gain that a point may have. we use linear programming to compute this gain  written glp.
¡¡given these definitions of gain  we present two different methods for identifying points to add. the simplest method  detailed in section 1  takes the candidate points  orders them according to their gains  and then selects the top few. a more sophisticated method leverages some information present when computing glp to identify points that have even higher gain than the candidate points  and so returns different points than the original candidates. we describe how these selection methods can be implemented in section 1  following a detailed discussion  sections 1 and 1  of the two measures of gain.
1 gain based on one-step backup
the gain gb measures the difference between the current value of point b and its value according to an ¦Á vector computed by a one-step backup of b via equation 1. this measure does not have strong theoretical support  but intuitively  if the one-step difference for a point is large  then it will also improve the approximations of nearby points significantly. these improvements will then have positive effects on points that lead to these points  although the effect will be discounted   improving many parts of the value function. this gain is defined as:

where ¦Á = backup  b . note that this measure includes the immediate expected reward at b  a quantity that was not previously included in the computation of any ¦Á vector. this measure can make use of cached ga vectors  equation 1   and so it is inexpensive from the computational standpoint. in the following section  we describe a different measure of gain that has a stronger theoretical justification  but also comes at the expensive of higher computational cost.
1 gain based on value-function bounds
this second measure of gain that we introduce uses the following insight  which we first illustrate on a system with two nominal states  then extend the intuition to a three-state system  and then describe the general calculation for any number of states. the value function is a piecewise linear convex function consisting of  for two nominal states  the upper surface of a set of lines defined by ¦Á vectors  see figure 1a for a running example . the vectors which define these lines correspond to points interior to the regions where the corresponding lines are maximal  points a  b  and c . intuitively  the value function is most relevant at these points  and becomes less relevant with increasing distance from the point. here  we assume that the value given by the ¦Á vector is correct at the corresponding point. now consider the inclusion of a new ¦Á vector for a new point  point x in figure 1a . if the value function for point a is correct  then the new ¦Á vector cannot change the value of a to be greater than its current value; the same holds for b. therefore  the new ¦Á vector for point x is upper-bounded by the line between the value for a and the value for b. thus  the gain for x is the difference between this upper bound and the current value of x.
lp
	 a 	 b 	 c 
figure 1:  a : value function for a dynamical system with two nominal states  note that p s1  = 1 p s1   so an axis for p s1  is unnecessary . the value function is defined by the ¦Á vectors corresponding to points a  b  and c. the gain glp x  for point x is the difference between the upper bound defined by the lineand the current value of x.  b c : value function for a system with three nominal states. the value function is defined by the ¦Á vectors corresponding to points a  b  c  and d  and the gain glp x  for point x is the difference between the tightest upper bound  defined by plane and the current value for x. that tightest upper-bound plane is produced by the first lp  findgainandregionforpoint . the best point produced by the second lp  findbestpointforregion  for the bounding region {a b c}.¡¡for the case with three nominal states  the analogous planar solution to the upper bound is not as simple to compute  see figure 1b and 1c . to visualize the problem  consider a mobile plane being pushed upward from point x  which is constrained only to not move above any of the existing points that define the value-function surface  a b c  and d in figure 1b . in the example depicted in figure 1b  this plane will come to rest on the points defined by the locations of a  b  c in the belief space and their values. the value of that plane at x then gives the tightest upper bound for its value if we were to add a new ¦Á vector at x. the gain is then computed in the same manner as in the two state case above  but finding the above-described plane is not straightforward  and becomes even more difficult in higherdimensional spaces . the difficulty is that in higher dimensional spaces - in contrast to the two state case where the minimal upper bound is always defined by the points immediately to the left and right of the new point - selecting the points that define that minimal upper-bounding surface is a non-trivial task. however  this problem can be formulated as a linear program  lp . we describe this lp in table 1 and refer to it as findgainandregionforpoint b1 .
¡¡given a candidate belief point b1 its current scalar value v1  the current points {b1...bm}  the current scalar values v1...vm of these points  and the value vectors ¦Á1...¦Án  this minimization lp finds the tightest upper bound   which can then be used to compute the gain glp b1  = vu b1    v  b1 . in words  this minimization lp works by finding a set of points  these are the set of points with nonzero weights wi  such that: i  b1 can be expressed a convex linear combination of these points  and ii  the value function defined by the plane that rests on their value-function points is the minimal surface above v1. we call the set of such points with non-zero weights the bounding region ¦£ b1  = {bi|wi   1} for point b1; it has the property that the point b1 must be interior to it  and these bounding regions will play an important role in the next section.
¡¡there is one subtle issue regarding the above lp  which is that not all points of potential interest are interior to the set of current points for which ¦Á vectors are defined  in fact early in the process when there are few points  most of the useful points will be outside the convex hull of current points . this is problematic because we want to consider these points  they often correspond to relatively poorly approximated areas of the value function   but they are never interior to any subset of the current points.
¡¡to resolve this issue  we introduce the set u of unit basis points: the points with all components but one equal to 1  and the remaining entry equal to 1  the standard orthonormal basis in the belief space . we then augment the set of current belief points in our lp to include the unit basis points: {b1...bm} = {p ¡È u}. the values vj of the points in u   p are computed as vj = backup  bj   bj ¡Ê u   p  since these points were not updated in onestep*backup   as were the points in p.
as before  the variables in this augmented lp are the scalar weights w1...wm that define which points from {p ¡Èu} form the bounding region ¦£ b1 
1 finding the best point in a bounding region
given the gains glp for the candidate points  it is possible to choose points to add based on this criteria  but one drawback to this is that we might add multiple points from the same bounding region ¦£  and thus waste resources by approximating the value function for multiple points when just one would work almost as well. further  it may be that none of these points is the point in the region with the highest gain. to address these issues  we introduce another lp called findbestpointforregion ¦£   table 1  that takes a bounding region and finds the point interior to that region with maximal glp. note that this region may contain unit basis points  allowing the new point to be exterior to the current set of points. this lp takes as input a bounding region ¦£ b1  =
{b1...bl}  scalar values v1...vl of these points  and the value vectors ¦Á1...¦Án. the optimization variables are: scalar weights w1...wl  vector bnew   which is the point to be found  and the scalar value vnew  which is the value of bnew. the process of finding the best points to add will call this lp on all unique regions found by running the first lp  findgainandregionforpoint  on all candidate points.
1 using gains in pbvi and perseus
we now define two incremental algorithms  pbvi-i and perseus-i  using the gains gb and glp  and the linear programs above. referencing the anytime*   algorithm  we explored various possibilities for readytoaddpoints    bestpointstoadd c   and findcandidatepoints  . while many variations exist  this paper presents only a few that seem most promising.
table 1: the linear programs used to i  compute the gain and region ¦£ b1  for point b1 given a value function  and ii  find the best point within a given region ¦£ given the value function.

findgainandregionforpoint b1 :	findbestpointforregion ¦£ ¡¡two computationally cheap possibilities for readytoaddpoints   are to add points: i  after a fixed number of iterations  and ii  when the update process has approximately converged  i.e.  the maximal one-step difference in value over all points is below some threshold   . we have also explored two methods for findcandidatepoints  . the first is to keep a list of points that are one-step successors to the points in p  the set {boa|b ¡Ê p}. the second method is to do a random walk and use a distance threshold to choose points  just as in pickinitialpoints  .
¡¡the gains discussed in the previous section can then be used for bestpointstoadd c . gain gb orders the candidate points c and the top k are chosen. for gain glp  the candidate points define a set of unique bounding regions {¦£ b |b ¡Ê c}. for each region  the lp findbestpointforregion   returns the best candidate point b. these candidate points are ordered by and the top k are chosen. to compare our methods against a baseline anytime algorithm  we used the standard random walk method  choosing the first k points that exceeded a distance threshold.
1 experiments
to evaluate our principled point selection algorithms  we conducted testing on a set of standard pomdp domains. three of the problems are small-to-mid sized  and the fourth  hallway  is larger. domain definitions may be obtained at  cassandra  1 . we tested three algorithms: i  a baseline  anytime perseus using the distance-based metric; ii  one-step backup perseus-i using gb; and iii  lp-based perseus-i using glp and the two lps for finding the best points.
¡¡all three algorithms used the convergence condition with for readytoaddpoints  . the algorithms for network  shuttle  and 1 added up to 1 points at a time  while hallway added up to 1 points at a time. however  choosing points using lps often did not add all 1 because fewer unique regions were found. in the one-step backup perseusi  we used the successor metric for findcandidatepoints   as it was easily integrated with little overhead  while in the lpbased perseus-i we used a random walk with a distance metric as it introduced the least overhead in this case. the results were averaged over 1 runs  and the performance metric is the average discounted reward  for a given initial belief state. the results are presented in the graphs in figure 1  which are of three types. the first type  performance vs. number of points  is a measure of the effectiveness of point selection. the second type  performance vs. number iterations  and the third type  performance vs. cpu time  both measure how well the use of principled point selection affects the overall performance  but the third type shows the impact of additional time incurred by the point-selection process. these graphs show performance on the x-axis  and the amount of resource  points  iterations  or time  used to achieve that performance on the y-axis. when comparing two algorithms with respect to a given resource  the better algorithm will be lower.
¡¡examination of the first-type graphs shows that the lpbased perseus-i did a good job of identifying the best points to add. the resulting policies produced better performance with fewer points than either of the other two methods. furthermore  on three of the problems  the one-step backup perseusi also did significantly better than the baseline for choosing points. thus  for this metric  our goal of finding useful points has been achieved. most promisingly  on the largest problem  hallway  our algorithms used significantly fewer points to achieve good performance. however  the other graphs show that choosing good points does not always translate into a faster algorithm. on one problem  network  both versions of perseus-i were faster than the baseline  but on the other problems  the performance was either closely competitive or slightly worse due to the overhead incurred by identifying good points. while this result was not optimal  the fact that there were significant speedups on one problem combined with the point selection results leads us to draw the conclusion that this method is promising and needs further investigation and development.
