 
recursive conditioning  rc  is an any-space algorithm lor exact inference in bayesian networks  which can trade space for time in increments of the size of a floating point number. this smooth tradeoff' is possible by varying the algorithm's cache size. when rc is run with a constrained cache size  an important problem arises: which specific results should be cached in order to minimize the running time of the algorithm  rc is driven by a structure known as a dtree  and many such dtrees exist for a given bayesian network. in this paper  we examine the problem of searching for an optimal caching scheme for a given dtree  and present some optimal time-space tradeoff curves for given dtrees of several published bayesian networks. we also compare these curves to the memory requirements of state-of-the-art algorithms based on jointrees. our results show that the memory requirements of these networks can be significantly reduced with only a minimal cost in time  allowing for exact inference in situations previously impractical. they also show that probabilistic reasoning systems can be efficiently designed to run under varying amounts of memory. 
1 introduction 
recursive conditioning  rc  was recently proposed as an any-space algorithm for exact inference in bayesian networks  darwiche  1 . the algorithm works by using conditioning to decompose a network into smaller subnetworks that are then solved independently and recursively using rc. it turns out that many of the subnetworks generated by this decomposition process need to be solved multiple times redundantly  allowing the results to be stored in a cache after the first computation and then subsequently fetched during further computations. this gives the algorithm its any-space behavior since any number of results may be cached. this also leads to an important question  which is the subject of this paper:  given a limited amount of memory  which results should be cached in order to minimize the running time of the recursive conditioning algorithm   

figure 1: an example dtree. 
　we approach this problem by formulating it as a systematic search problem. we then use the developed method to construct time-space tradeoff curves for some real-world bayesian networks  and put these curves in perspective by comparing them to the memory requirements of state-ofthe-art methods based on jointrees  jensen et a/.  1; shafer and shenoy  1 . the curves produced illustrate that a significant amount of memory can be reduced with only a minimal cost in time. in fact  for much of their domains  the time-space curves we produce appear close to linear  with exponential behavior appearing only near the extreme case of no caching. this dramatic space reduction  without a significant time penalty  allows one to practically reason with bayesian networks that would otherwise be impractical to handle. 
　this paper is structured as follows. we start in section 1 by providing some background on recursive conditioning and the cache allocation problem. we then formulate this problem in section 1 as a systematic search problem. time-space tradeoff curves for several published bayesian networks are then presented in section 1. finally  in section 1  we provide some concluding remarks and discuss some future work. 
1 any-space inference 
the rc algorithm for exact inference in bayesian networks works by using conditioning and case analysis to decompose a network into smaller subnetworks that are solved independently and recursively. the algorithm is driven by a structure 

known as a decomposition tree  dtree   which controls the decomposition process at each level of the recursion. we will first review the dtree structure and then discuss rc. 
1 	dtrees 
definition 1  darwiche  1  a dtree for a bayesian network is a full binary tree  the leaves of which correspond to the network conditional probability tables  cpts . if a leaf node t corresponds to a cpt then vars t  is defined as the variables appearing in cpt 
　figure 1 depicts a simple dtree. the root node t of the dtree represents the entire network. to decompose this network  the dtree instructs us to condition on variable b  called the cutset of root node t. conditioning on a set of variables leads to removing edges outgoing from these variables  which for a cutset is guaranteed to disconnect the network into two subnetworks  one corresponding to the left child of node and another corresponding to the right child of node see figure 1. this decomposition process continues until a boundary condition is reached  which is a subnetwork that has a single variable. 
　we will now present some notation needed to define additional concepts with regard to a dtree. the notation and  will be used for the left child and right child of node and the function vars will be extended to internal nodes 
vars t  vars each node in a dtree has three more sets of variables associated with it. the first two of these sets are used by the rc algorithm  while the third set is used to analyze the complexity of the algorithm. 

the width of a dtree is the size of its maximal cluster -1. 
　the cutset of a dtree node t is used to decompose the network associated with node /  into the smaller networks associated with the children of t. that is  by conditioning on variables in cutset f   one is guaranteed to disconnect the network associated with node t. the context of dtree node t is used to cache results: any two computations on the network associated with node t will yield the same result if these computations occur under the same instantiation of variables in context f . hence  a cache is associated with each dtree node t  which stores the results of such computations  probabilities  indexed by instantiations of context f . this means that the size of a cache associated with dtree node t can grow as large as the number of instantiations of context t . 
　for a given bayesian network  many different dtrees exist and the quality of the dtree significantly affects the resource requirements of rc. the width is one important measure of this  as rcs time complexity is exponential in this value. the construction of dtrees is beyond the scope of this paper  but in  danviche  1; danviche and hopkins  1  it was shown how to create them from elimination orders  jointrees  or directly by using the hmetis  karypis and kumar  1  hypergraph partitioning program. 
1 recursive conditioning 
　given a bayesian network and a corresponding dtree with root t  the rc algorithm given in algorithms 1 and 1 can be used to compute the probability of evidence c by first  recording  the instantiation e and then calling rc /   which returns the probability of e. 
　our main concern here is with line 1 and line 1 of the algorithm. on line 1  the algorithm checks whether it has performed and cached this computation with respect to the subnetwork associated with node / . a computation is characterized by the instantiation of vs context  which also serves as an index into the cache attached to node /. if the computation has been performed and cached before  its result is simply fetched. otherwise  the computation is performed and its result is possibly cached on line 1. 
　when every computation is cached  rc uses 1 n exp w   space and 1 n exp iu   time  where n is the number of nodes in the network and w is the width of the dtree. this corresponds to the complexity of jointree algorithm  assuming that the dtree is generated from a jointree  danviche  1 . when no computations are cached  the memory requirement of rc is reduced to 1{n   in which case the time requirement increases to 1 nexp w logn  . any amount of memory between these two extremes can also be used in increments of the size of a floating point number  a cache value. 
　suppose now that the available memory is limited and we can only cache a subset of the computations performed by rc. the specific subset that we cache can have a dramatic effect on the algorithm's running time. a key question is then to choose that subset which minimizes the running time  which 

1 	probabilistic inference 


figure 1: an example dgraph. 
is the main objective of this paper. we refer to this as the secondary optimization problem  with the first optimization problem being that of constructing an optimal dtree. 
most of our results in this paper are based on a version of 
rc which not only computes the probability of evidence e  but also posterior marginals over families and  hence  posterior marginals over individual variables. this version of rc uses a decomposition graph  dgraph   which is basically a set of dtrees that share structure. 
　an example dgraph for a network with four variables can be seen in figure 1. it should be noted that each of the four root nodes corresponds to a valid dtree  so this dgraph actually contains four dtrees which share a significant portion of their structure. creation of dgraphs is discussed in ldarwiche  1 . 
　the code in algorithms 1 and 1 is also used in this version of rc  where rc r  is called once on each root f of the dgraph  the posterior marginal of each family is computed as a side effect of each of these calls . this version of rc uses more memory as it maintains more caches. but it is more meaningful when it comes to comparing our time -space tradeoff curves with the memory requirements of jointree algorithms  as this version of rc is equally powerful to these algorithms. 
1 the cache allocation problem 
the total number of computations that a dgraph  or dtree  node t needs to cache equals the number of instantiations of context t . given a memory constraint  however  one may not be able to cache all these computations  and we need a way to specify which results in particular to cache. a cache factor cf for a dgraph is a function which maps each internal node t in the dgraph into a number cf  t  between 1 and 1. hence  if cf t  = .1  then node t can only cache 1% of these total computations. a discrete cache factor is one which maps every internal dgraph node into either 1 or 1: all of the node's computations are cached  or none are cached. the rc code in algorithms 1 and 1 assumes a discrete cache factor  which is captured by the flag cache  ♀   indicating whether caching will take place at dgraph node t. 

figure 1: search tree for a dgraph with 1 internal nodes. 
　one can count the number of recursive calls made by rc  and  hence  compute its running time  given any discrete cache factor. specifically  if  denotes a parent of node f in a dgraph  and denotes the number of instantiations of variables s  the number of recursive calls made to node t is ldarwiche  1; 1 : 

if the cache factor is not discrete  the above formula gives the average number of recursive calls  since the actual number of calls will depend on the specific computations cached. this equation is significant as it can be used to predict the expected time requirement of rc under a given caching scheme. 
　we focus in this paper on searching for an optimal discrete cache factor  given a limited amount of memory  where optimality is with respect to minimizing the number of recursive calls. to this end  we will first define a search problem for finding an optimal discrete cache factor and then develop a depth-first branch-and-bound search algorithm. we will also use the developed algorithm to construct the time-space tradeoff curves for some published bayesian networks from various domains  and compare these curves to the memory demands and running times of jointree algorithms. 
1 cache allocation as a search problem the cache allocation problem can be phrased as a search problem in which states in the search space correspond to partial cache factors that do not violate the given memory constraint  and where an operator extends a partial cache factor by making a caching decision on one more dgraph node. the initial state in this problem is the empty cache factor  in which no caching decisions have been made for any nodes in the dgraph. the goal states correspond to complete cache factors  where a caching decision has been made for every dgraph node  without violating the given memory constraint. suppose for example that we have a dgraph with three internal nodes this will then lead to the search tree in figure 1. in this figure  each node n in the search tree represents a partial cache factor for example  the node in bold 

corresponds to the partial cache factor 
and moreover  if node 	is labeled with a dgraph 
node i;  then the children of represent two possible extensions of the cache factor one in which dgraph node will cache all computations  1-child   and another in which dgraph node will cache no computations  1-child . 
　according to the search tree in figure 1  one always makes a decision on dgraph node  followed by a decision on dgraph node to  and then node ♀1. a fixed ordering of dgraph nodes is not necessary  however  as long as the following condition is met: a decision should be made on a dgraph node only after decisions have been made on all its ancestors in the dgraph. we will explain the reason for this constraint later on when we discuss cost functions. 
　in the search tree depicted in figure 1  the leftmost leaf represents no caching  while the rightmost leaf represents full caching. the search trees for this problem have a maximum depth of c/  where d is the number of internal nodes in the dgraph. given this property  depth-first branch-and-bound search is a good choice given its optimality and linear space complexity  papadimitriou and steiglitz 1 . it is also an anytime algorithm  meaning that it can always return its best result so far if interrupted  and if run to completion will return the optimal solution. hence  we will focus on developing a depth-first branch-and-bound search algorithm. 
1 	cost functions 
the depth-first branch-and-bound  dfbnb  algorithm requires a cost function / which assigns a cost to every node  in the search tree. the function estimates the cost of an optimal solution that passes through n. the key here is that must not overestimate that cost; otherwise  one loses the optimality guarantee offered by the search algorithm. we will now develop such a cost function based on the following observations. since each node represents a partial cache factor function must estimate the number of recursive calls made to rc based on an optimal completion of cache factor  consider now the completion of in which we decide to cache at each dgraph node that did not make a decision on. this cache factor is the best completion of  from the viewpoint of running time  but it may violate the constraint given on total memory. yet  we will use it to compute as it guarantees that   will never overestimate the cost of an optimal completion of 
　one important observation in this regard is that once the caching decision is made on the ancestors of dgraph node we can compute exactly the number of recursive calls that will be made to dgraph node  see equation 1 . therefore  when extending a partial cache factor  we will always insist on making a decision regarding a dgraph node t for which decisions have been made on all its ancestors. this improves the quality of the estimate as gets deeper in the tree. it also allows us to incrementally compute this estimate based on the estimate of 's parent in the search tree. 
1 	pruning 
as depicted by the search tree in figure 1  there is potentially an exponential number of goal nodes in the search tree and the combinatorial explosion of exhaustive search can become unmanageable very quickly. hence the search algorithm must eliminate portions of the search space while still being able to guarantee an optimal result. one of the key methods of doing this is by pruning parts of the search tree which are known to contain non-optimal results. the dfbnb algorithm does this by pruning search tree nodes when the cost function is larger than or equal to the current best solution. hence  more accurate cost functions will allow more pruning. another ma-
jor source of pruning is the given constraint on total memory. this is accomplished by pruning a search tree node and all its descendants once it attempts to assign more memory to caches than is permitted by the memory constraint. 
1 search decisions 
now that we have chosen a cost function  we are still left with two important choices in our search algorithm:  1  which child of a search tree node to expanded first  and  1  in what order to visit dgraph nodes during search. expanding the 1child first is a greedy approach  as it attempts to fully cache at a dgraph node whenever possible. results on many different networks have shown that in many cases  expanding the 1-child before the 1-child appears to be equal to or better than the opposite  and it is this choice that we adopt in our experiments. the specific order in which we visit dgraph nodes in the search tree turns out to have an even more dramatic effect on the efficiency of search. even though wc make caching decisions on parent dgraph nodes before their children  there is still a lot of flexibility. our experimentation on many networks has shown that choosing the dgraph node t with the largest context t  is orders of magnitude more efficient than some other basic ordering heuristics  allen and darwiche  1 . this choice corresponds to choosing the dgraph node with the largest cache  and it is the one we use in our search algorithm. 
1 time-space tradeoff 
the main goal of this section is to present time-space tradeoff curves for a number of benchmark bayesian networks  some of which are obtained from  bayesian network repository  url  and others are included in the distributions of  hugin 
expert  url; genle  url . the main points to observe with respect to each curve is the slope of the curve  which provides information on the time penalty one pays when reducing space in probabilistic inference. the second main point is to compare the produced curves with the time and space requirement of jointree methods  as the version of rc we are using provides the same functionality as these algorithms  that is  probability of evidence and posterior marginals over families and variables . this baseline comparison is important as it places our results in the context of state-of-the-art inference systems. 
　time-space tradeoff curves. figures 1  1  and 1 depict optimal discrete time-space tradeoff curves for three networks. these curves were generated as follows. a jointree was first generated for the network using hugin.1 the 
   'we used hugin's default setting: the minimum fill-in weight heuristic in conjunction with prime component analysis. 

1 	probabilistic inference 

figure 1: time-space tradeoff on b. 
jointree was then converted into a dtree as described in  darwiche  1 . the dtree was finally converted into a dgraph as described in the full paper. two sets of results were then generated: 
we computed the space requirements for jointree algorithms  using both the hugin  jensen et al.  1  and shenoy-shafer ishaferand shenoy  1  architectures. 
for the first architecture  we assumed one table for each clique and one table for each separator. for the second  we assumed two tables for each separator  no tables for cliques . we also performed propagation on the jointree using netica  norsys software corp.  url  and recorded the running time. 
  we then ran our search algorithm to find an optimal cache factor under different memory constraints  where we generated 1 data points for each curve. for each caching factor that we identified  we computed the number of recursive calls that will be made by rc under that factor and converted the calls to seconds.1 
a number of observations are in order here. first  these timespace tradeoff curves show that the amount of memory used by rc under full caching is very close to that required by the shenoy-shafer architecture  the hugin architecture takes much more space . second  the curves show that a significant amount of memory can sometimes be reduced from full caching with only a limited increase in the time required; in fact  the exponential growth appears to be occurring only near the lower extreme of no caching. the space requirement for water  figure 1   for example  can be reduced to 1% while only increasing the running time by a factor of 1. moreover  the space requirements for b  figure 1  can be reduced to about 1%; while increasing the running time by a factor of 1. finally  we note that each optimal search for the water and b networks took less than two seconds  and each optimal search for alarm took less than two minutes. we stress though that such searches need to be done only once for a network  and their results can then be used for many further queries. 
　non-optimal tradeoffs. on some networks  the search space is too large to solve optimally using our search algorithm  but the anytime nature of the algorithm allows us to interrupt the search at any point and ask for the best result obtained thus far. figures 1 and 1 were generated by allowing the search to run for an hour. even though these curves are not optimal  they are useful practically. for example  according to these curves  the memory requirement of barley can be reduced from about 1 mb to about 1 mb while only increasing the running time from about 1 to 1 minutes. moreover  the space requirement of munin 1 can be reduced from about 1 mb to 1 mb  while increasing the running time from about 1 minutes to about 1 hours. encouraged by such results  we are planning to investigate other  nonoptimal  search methods  such as local search. 
　dtrees vs dgraphs. running rc on a dtree takes less space than running it on a dgraph  but produces much less 
computer with 1 mb of ram  makes an average number of three million recursive calls per second. 


　　　　　　　　　　　　　　　　　　　　　　figure 1: time-space tradeoff on water for computing probfigure 1: time-space tradeoff on barley. ability of evidence. 


figure 1: time-space tradeoff on muninl. 
information  probability of evidence instead of posterior marginals . to illustrate this difference concretely  we present in figure 1 two tradeoff curves for the water network  assuming a dtree version of rc  which require much less memory compared to the curves in figure 1. suppose now that we only have 1 mb of memory  instead of the 1 mb or 1 mb required by jointree algorithms  and we want to compute the posterior marginals for all variables. according to figure 1  we can do this in 1 seconds using the dgraph version of rc. the dtree version takes 1 seconds to compute the probability of evidence under this amount of memory  and we would have to run it 1 times to produce all posterior marginals for the water network  given variable cardinalities in water . 
　effect of dtree/dgraph on tradeoff. our notion of optimally for tradeoff is based on a given dtree/dgraph; hence  generating different dtrees/dgraphs could possibly lead to better time-space tradeoff curves. to illustrate this point  we generated tradeoff curves for the water network based on figure 1: time-space tradeoff on random for computing probability of evidence. 
multiple dtrees/graphs  as shown in figures 1 and 1. one observation that we came across is that dtrees/graphs that are based on jointrees tend to require less memory under full caching  but are not necessarily best for tradeoff towards the no caching region; see figures 1 for an example. yet  we used such dtrees/graphs in this paper in an effort to provide a clear baseline for comparison with jointree methods. if we relax this constraint  however  we can obtain better tradeoff curves than is generally reported here  as illustrated by figures 1 and 1. the specific way in which properties of a dtree/dgraph influence the quality of corresponding timespace tradeoff curves is not very well understood  however  and we hope to shed more light on this in future work. 
　size of search space. it should be noted that the difficulty of obtaining an optimal time-space tradeoff curve on some networks is not due to a large space requirement  but is due mostly to the number of nodes in the bayesian network as that is what decides the size of search space. to further illustrate 

1 	probabilistic inference 

this point  we generated a network randomly with 1 nodes  many of them non-binary   1 edges  and a width of 1. this network requires extensive memory but has a relatively small number of variables. in fact  both netica and hugin were unable to compile the network requiring about 1 gb and 1 gb respectively. we were able  however  to produce an optimal time-space tradeoff curve for this network. the curve for the dtree version of rc is shown in figure 1. according to this curve  we can compute the probability of any evidence on this network in about 1 hours using only about 1 mb. 
　related work. we close this section by a note on related work for time-space tradeoff in probabilistic reasoning  which takes a different approach  dechter and fattah  1 . in this work  large separators in a jointree are removed by combining their adjacent clusters  which has the effect of reducing the space requirements of the shenoy-shafer architecture  as we now have fewer separators   but also increasing its running time  as we now have larger clusters . the tradeoffs permitted by this approach  however  are coarser than those permitted by rc as discussed in  darwiche  1 . furthermore  the secondary optimization problem of which separators to remove in order to minimize running time is not addressed in  dechter and fattah  1  for the proposed approach  as we do in this paper for the rc approach. 
1 conclusions and future work 
the main contribution of this paper is a formal framework  and a corresponding working system  for trading space for time when designing probabilistic reasoning systems based on bayesian networks. the proposal is based on the algorithm of recursive conditioning  and is accompanied with a set of experimental results showing that a significant amount of memory can sometimes be reduced while only incurring a reasonable penalty in running time. the proposed framework is then beneficial for designing reasoning systems with limited memory  as in embedded systems  and for reasoning with challenging networks on which jointree algorithms can exhaust the system memory. 
　recursive conditioning and the described time-space tradeoff system have been implemented in java in the sam 1am tool  which is available publically  ucla automated reasoning group  url . 
acknowledgments 
this work has been partially supported by nsf grant iis1 and muri grant n1-1. 
