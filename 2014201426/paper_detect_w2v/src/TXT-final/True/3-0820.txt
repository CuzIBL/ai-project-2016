
arc consistency algorithms are widely used to prune the search space of constraint satisfaction problems  csps . coarse-grained arc consistency algorithms like ac-1  ac-1d and ac-1 are efficient when it comes to transforming a csp to its arc-consistent equivalent. these algorithms repeatedly carry out revisions. revisions require support checks for identifying and deleting all unsupported values from the domain of a variable. in revisions for difficult problems most values have some support. indeed  most revisions are ineffective  i.e. they cannot delete any value and consume a lot of checks and time. we propose two solutions to overcome these problems. first we introduce the notion of a support condition  sc  which guarantees that a value has some support. scs reduce support checks while maintaining arc consistency during search. second we introduce the notion of a revision condition  rc  which guarantees that all values have support. a rc avoids a candidate revision and queue maintenance overhead. for random problems  scs reduce the checks required by mac-1  mac-1  up to 1%  1% . rcs avoid at least 1% of the total revisions. combining the two results in reducing 1% of the solution time.
1 introduction
arc consistency  ac  algorithms are widely used to prune the search space of binary constraint satisfaction problems  csps . mac  sabin and freuder  1  is a backtrack algorithm that maintains arc consistency during search. it reduces the thrashing behaviour of a backtrack algorithm  which usually fails many times as a result of the same local inconsistencies. mac-x uses ac-x for maintaining arc consistency during search.
　many arc consistency algorithms have been proposed. on the one hand there are algorithms such as ac-1  mackworth 

 
　　this work has received some support from science foundation ireland under grant no. 1/pi.1/c1.
 
　　the first author is supported by boole centre for research in informatics.1  and ac-1d  van dongen  1 . these algorithms have a low o e + nd  space complexity but they repeat their support checks and have a non optimal bound of o ed1  for their worst-case time complexity. here e is the number of constraints  n the number of variables and d the maximum domain size of the variables. on the other hand there are algorithms such as ac-1  mohr and henderson  1   ac-1  bessie`re and cordier  1   and ac-1  bessie`re and re＞gin  1  that use auxiliary data structures to avoid repeating their support checks and have an optimal worst-case time complexity of o ed1 .
　since the introduction of ac-1  mohr and henderson  1  much work has been done to avoid repeating support checks by using auxiliary data structures. depending upon the algorithm  these auxiliary data structures store one or more supports for each value involved in each constraint. the belief is that reducing checks helps in solving problems more quickly. however  allowing algorithms to repeat  not too many  checks  relieves them from the burden of a large additional bookkeeping and this may save time  especially if checks are cheap. in this paper  we introduce the notion of a support condition  sc  which guarantees that a value has some support. scs help avoiding many  but not all  sequences of support checks eventually leading to a support without storing and maintaining support values.
　coarse-grained arc consistency algorithms repeatedly carry out revisions to remove all unsupported values from the domain of a variable. many revisions are ineffective  i.e. they cannot remove any value. for example  when rlfap #1 is solved using mac-1 or mac-1  1% of the total revisions are ineffective. we introduce the notion of a revision condition  rc  which guarantees that all values have some support. rcs help avoiding many  but not all  ineffective revisions and much queue maintenance  which is also a great source of time consumption  van dongen and mehta  1 . furthermore  we show that reverse variable based heuristics  mehta and van dongen  1  result in fewer revisions.
　the remainder of this paper is as follows. section 1 is a brief introduction to constraints. section 1 discusses revision
ordering heuristics and the coarse-grained algorithm ac-1. sections 1 and 1 introduce the notions of a support condition and a revision condition. section 1 presents experimental results. conclusions are presented in section 1.
1 constraint satisfaction
a constraint satisfaction problem is defined as a set v of n variables  a non-empty domain d x  for each variable x （ v and a set of e constraints among subsets of variables of v. a
binary constraint cxy between variables x and y is a subset of the cartesian product of d x  and d y  that specifies the allowed pairs of values for x and y. we only consider csps whose constraints are binary.
　a value b （ d y  is called a support for a （ d x  if  a b  （ cxy. similarly a （ d x  is called a support for b （ d y  if  a b  （ cxy. a support check  consistency check  is a test to find if two values support each other. a value a （ d x  is called viable if for every variable y constraining x the value a is supported by some value in d y . a csp is called arc-consistent if for every variable x （ v  each value a （ d x  is viable.
　the density p1 of a csp is defined as 1e/ n1   n . the tightness p1 of the constraint cxy between the variables x and y is defined as 1   |cxy |/|d x  〜 d y |. the degree of a variable is the number of constraints involving that variable. before starting search mac transforms the input csp to its arc-consistent equivalent. we call the domain of a variable in this arc-consistent equivalent as the arc-consistent domain of that variable. for the remainder of this paper for any variable x  we use dac x  for the arc-consistent domain of x  and d x  for the current domain of x. the directed constraint graph of a given csp is a directed graph having an arc  x y  for each combination of two mutually constraining variables x and y. we will use g to denote the directed constraint graph of the input csp.
1 revision ordering heuristics
coarse-grained arc consistency algorithms use revision ordering heuristics to select an arc from a data structure called a queue  set really . when an arc   x y   is selected from the queue  d x  is revised against d y . here to revise d x  against d y  means removing all values from d x  that are not supported by any value of d y . revision ordering heuristics can influence the efficiency of arc consistency algorithms  wallace and freuder  1 . they can be classified into three categories: arc based  variable based  mcgregor  1   and reverse variable based  mehta and van dongen  1  heuristics. the differences between them are as follows.
　arc based revision ordering heuristics are the most commonly presented. given some criterion they select an arc  x y  for the next revision. selecting the best arc can be expensive  van dongen and mehta  1 . each selected arc correspondsto exactly one revision. since there may be many revisions there may be many selections and this may result in a significant overhead. when arc based heuristics are used  the queue needs to be updated after every effective revision unless the domain of a variable becomes empty. many updates can be an overhead too.
　variable based heuristics  mcgregor  1  first select a variable x and then repeatedly select arcs of the form  y x  for the next revision until no more such arcs exist or some d y  becomes empty. they may be regarded as propaga-
function ac-1: boolean; begin
q := g
while q not empty do begin select any x from {x :  x y  （ q} effective revisions := 1 for each y such that  x y  （ q do
remove  x y  from q revise x y changex  if d x  =   then return false
else if changex then
effective revisions := effective revisions + 1 y1 := y;
if effective revisions = 1 then
   q := q “ { y1 x |y1 is a neighbour of x … y1 =1 y1} else if effective revisions   1 then
q := q “ { y1 x |y1 is a neighbour of x}
return true;
end;
figure 1: ac-1.
tion based heuristics because the consequences of removing one or more values from d x  are propagated in all of its neighbours. if a variable x is selected then the domain of all its neighbours in the constraint graph will be revised against d x . in this setting there are usually fewer selections from the queue at the cost of performing more checks. if checks are cheap then time can be saved because the queue needs fewer selections. here too every effective revision results in updating the queue.
　reverse variable based heuristics  mehta and van dongen  1  first select a variable x and then repeatedly select arcs of the form  x y  for the next revision until there are no more such arcs or d x  becomes empty. they may be regarded as support based heuristics because for one variable x at a time  each value in d x  seeks support with respect to all of its neighbours for which it is currently unknown whether such support exists. when a variable x is selected a number of revisions is performed which is between 1 and the number of arcs of the form  x y  currently present in the queue. therefore  the number of selections  of x   and the overhead of queue management  is usually less.
　selecting a variable x and revising it against all its neighbours y such that  x y  is currently present in the queue we call a complete relaxation of x. another advantage of using reverse variable based heuristics is that the queue only needs to be updated after every effective complete relaxation and not after every effective revision  which reduces the number of times the arcs are added to the queue. overall fewer revisions are performed which results in saving support checks. pseudo-code for ac-1 equipped with reverse variable based revision ordering heuristic is depicted in figure 1. the revise function upon which ac-1 depends is depicted in figure 1.
　in figure 1  if d x  was changed after a complete relaxation and if this was the result of only one effective revision  effective revisions = 1   which happened to be against d y1   then all arcs of the form  y1 x  where y1 is a neighbour of x and y1 =1 y1 are added to the queue. however  if d x  was changed as the result of more than one effective revision  effective revisions   1  then all arcs of the form  y1 x  where y1 is a neighbour of x are added to the queue. modulo constraint propagation effects this avoids queue maintenance overhead.
1 a support condition
arc consistency algorithms are based on the notion of support. most arc consistency algorithms proposed so far put a lot of effort in identifying a support to confirm the existence of a support. identifying the support is more than is needed to guarantee that a value is supportable: knowing that a support exists is enough. optimal algorithms like ac-1 and ac-1 always keep track of the last known support for each value. when this support is lost they try to identify the next support. ac-1 is the only algorithm that confirms the existence of a support by not identifying it during the course of search but its inefficiency lies in its space complexity o ed1  and the necessity of maintaining huge data structures during search.
　we propose the notion of a support condition  sc   which guarantees that a value has some support. the key point is that it guarantees the existence of a support without identifying it and without storing and maintaining support values. let cxy be the constraint between x and y  let a （ d x   also denoted as  x a   and let scount x y a  be the number of supports of  x a  in dac y . a value a （ d x  is supported by y if it has at least one support in d y . furthermore if r y  = dac y    d y  are the removed values from the arc-consistent domain of y then |r y | is an upper bound on the number of lost supports of  x a  in y. therefore  if the following condition is true then  x a  is supported by y:
	scount x y a    |r y |	 1 
in order to use the equation  1  in any coarse-grained mac algorithm  for each arc-value pair involving the arc  x y  and the value a on x  scount x y a  must be assigned the number of supports of  x a  in dac y . once these support counters are initialised they remain static during search. hence  there is no overhead of maintaining them. the pseudo-code for computing the support count for each arc-value pair is depicted in figure 1. in the algorithm  last x y a  stores ac-1's last known support for  x a  in y. note that the algorithm does not repeat checks and uses the bidirectional property of constraints. for easy problems initialising support counters can be an overhead in terms of support checks. however  it can save time and checks for hard problems.
　next we generalise the idea presented in the equation  1 . here we associate a weight  non-negative integer  w x y a  with each arc-value pair. if the following condition is true
function initialisesupportcounters     call ac-1 if the problem is arc-consistent then for each  x y  （ g do
for each a （ dac x  do
scount x y a  := 1
for each  x y  （ g such that x   y do
for each a （ dac x  do
for each b （ dac y  such that b   last x y a  do if b supports a then begin
scount x y a  := scount x y a  + 1 scount y x b  := scount y x b  + 1
end
figure 1: initialisation of support counters.
	w y x b 	w y x b 

	x	y	x	y
	case 1	case 1
figure 1: support inference using different weights
then  x a  is supported by y:
	x w y x b    x w y x b1  .	 1 
	 a b  （ cxy	b1 （ r y 
we call the left hand side of equation  1  the cumulative weight of  x a  with respect to y: it is equal to the sum of the weights of the supports of  x a  in dac y . we call the right hand side of equation  1  the removed weight from dac y  with respect to x: it is equal to the sum of the weights of the values removed from dac y  with respect to x. note that if the weight associated with each arc-value pair is 1 then equation  1  is a special case of the condition in equation  1 . in that case the cumulative weight of  x a  with respect to y is equal to the number of supports of  x a  in dac y  and the removed weight from dac y  is equal to the number of values removed from dac y . we call the condition in equation  1  a support condition  sc . a sc guarantees the existence of a support and may allow to save many checks.
　we illustrate the use of sc to infer the existence of a support by using the example as shown in figure 1. in figure 1  case 1   the weight associated with each value is 1. the cumulative weight of a1 with respect to y is 1: it is equal to the number of the supports of a1 in dac y . now assume that b1 is deleted from dac y  then the removedweight from dac y  with respect to x is 1: it equals |r y |. it can be inferred that a1 still has a support in d y  since the cumulative weight of a1 is greater than the removed weight from dac y . similarly  a support for any value in d x  can be inferred if any single value is removed from dac y . if any two values are removed from dac y  then the removed weight from dac y  is 1. here a support cannot be inferred for any value of d x  because the cumulative weight of each value in d x  is 1  which is not greater than the removed weight.
　if other weights are used and if sc holds for any value a （ d x  then a support is still guaranteed to exist in d y . let us examine case 1 of figure 1 where the weight assigned to each value in dac y  is its own support count with respect to x. now the cumulative weight of a1 is 1 since the weights of the supports of b1 and b1 are 1 and 1 respectively. like case 1  if any single value is removed from dac y   a support can be inferred for all values in d x . if the two values b1 and b1 are removed then the removed weight from dac y  is 1. unlike case 1 a support can be inferred for all the values of x. in another situation if b1 and b1 are removed then also the existence of support can be inferred for at least a1 and a1 since their cumulative weights are 1 and the removed weight from dac y  is 1. we will see further on that using support
function revise x y var changex 
begin
changex := false for each a （ d x  do
if p a b  （ cxy w y x b    pb1 （ r y  w y x b1   then skip /* a is supported */
else if  b （ d y  such that b supports a then begin
d x  := d x    {a} changex := true
end
end;
figure 1: algorithm revise of ac-1.
counts as weights lets scs save more checks.
　the revise function for ac-1 is depicted in figure 1. this function is slightly different from its original version because it uses sc to avoid a series of checks for which it can be known in advance that it will eventually lead to a support. the use of sc is not restricted to ac-1. it can be integrated in any coarse-grained algorithm.
1 a revision condition
the support check is the core operation carried out by arc consistency algorithms. to reduce the number of checks  algorithms proposed so far  1  perform viability checks like in ac-1   1  check the status of counters like in ac-1   1  make some inference based on the supports stored in auxiliary data structures like in ac-1  or  1  carry out scs as mentioned in section 1. we call all these tests auxiliary support checks  ascs . when support checks are not too expensive then ascs can be an overhead and reducing the checks alone does not always help in reducing the solution time.
　all the improvements proposed so far to reduce support checks are done at fine level of granularity. we propose a coarser check at arc level. the idea is that we will use this coarser check to avoid a complete revision. this will not only save support checks but will also avoid auxiliary support checks. for a given arc  x y   if the least cumulative weight  lcw  of the values of d x  with respect to y is greater than the removed weight from dac y  then all the values of d x  are supported by y. this can be expressed as follows:
.
　　　　　　　　　　　　　　　　　　　　　　　 1  we call this condition a revision condition  rc . the rc can be used by all coarse-grained arc consistency algorithms to reduce unnecessary revisions while maintaining full arc consistency during search.
　if a rc holds then it can be exploited after selecting the arc  x y  or when arcs are added to the queue. in the former case the corresponding revision is not carried out and in the latter case the arc  x y  is not added to the queue. we will use the revision condition by tightening the condition for adding the arcs to the queue: arcs should only be added if rc does not hold. this is depicted in figure 1. with this implementation the advantages of using the rc are threefold:  a  it will reduce the number of arcs that have to be added to the queue   b  it will reduce the number of arcs that have to be selected from the queue  and  c  it will reduce the total number of revisions.
ifeffective revisions = 1 then
q := q “ {  y1 x |y1 is a neighbour of x … y1= y1…
{p	1 } p	}
else if effective revisions   1 then
q := q “ {  y1 x |y1 is a neighbour of x… min{p a b  （ cy1x w x y1 b  : a （ d y1 } ＋ pb1 （ r y1  w x y1 b1 } figure 1: enforcing rc while adding the arcs to the queue.
　note that both sc and rc are presented in such a way that the idea is made as clear as possible. this should not be taken as the real implementation. we compute the cumulative weight for each arc-value pair before the search starts. whenever a value is deleted from the domain of a variable x  we update the removed weight for all the arcs of the form  ， x . if there is a change in the domain size of a variable x after a complete relaxation  we update the lcw for all the arcs of the form  x ， . the space complexity of storing the cumulative weights is o ed . the space complexity of storing the removed weights and the lcws for all the arcs is o e  but it may increases to o en  during search. the overall space complexity of using sc in conjunction with rc is o ed + en  = o emax d n  .
　updating the least cumulative weight for all the arcs of the form  x ，   if there is a change in the domain of x after every complete relaxation can be an overhead. the other option is to update the lcw of only one arc  x y  while revising d x  against d y  instead of all the arcs of the form  x ，  after a complete relaxation. this can be done cheaply and may avoid the addition of the arc  x y  to the queue in future. this can be considered as a weak version of a revision condition  wrc  because the lcw is not maintainedfor all the arcs. the disadvantage here is that not all possible ineffective revisions will be saved then can be saved by rc.
　independent work by  boussemart et al.  1  uses min{p a b （cxy 1 : a （ dac x }   pb1 （r y  1  which is a special case of equation  1 . note that in their setting w x y a  is 1 for each arc-value pair and the above condition is exploited after determining the arc for the revision. for a given arc  x y   this condition examines the least cumulative weight  the least support count  of the values of dac x  and not of d x  with respect to y as is done in equation  1 . we call this condition a static version of a revision condition because the least cumulative weight is not updated for any arc during the course of search. it remains static for all the arcs. this may not allow to avoid as many ineffective revisions as can be avoided by rc.
1 experimental results
1 introduction
in this section  we shall present some results to prove the practical efficiency of sc  rc and wrc. we implemented them in mac-1 and mac-1 equipped with comp  van dongen  1  as a revision ordering heuristic. we denote the arc based  reverse variable based  and the variable based heuristic comp as arc:comp  rev:comp  and var:comp respectively. the details about these heuristics can be found in
mac-1mac-1heuristicconditionweightcheckstimerevisionscheckstime--1 1.1 11 1.1arc:compsc1 111 1 11wrc1 111 1 11sc + wrc1 111 1 11--1 1.1 11 1.1sc1 111 1 11scscount1 1.1 11 1.1wrc1 111 1 11wrcscount1 1.1 11 1.1rev:compsc + wrc1 111 1 11sc + wrcscount1 1.1 11 1.1rc1 111 1 11rcscount1 1.1 11 1.1sc + rc1 111 1 11sc + rcscount1 1.1 11 1.1table 1: results for the random problems.
mac-1mac-1heuristicconditionscheckstimerevisionscheckstime-1 1.1 11 1.1arc:compsc1 1.1 11 1.1wrc1 1.1 1 11sc + wrc1 1.1 1 11-1 1.1 11 1.1sc1 1.1 11 1.1rev:compwrc1 1.1 1 11sc + wrc1 1.1 1 11rc1 1.1 1 11sc + rc1 1.1 1 11table 1: results for rlfap#1. mehta and van dongen  1 . during search all macs visited the same nodes in the search tree. they were equipped with a dom/deg variable ordering heuristic with a lexicographical tie breaker  where dom is the domain size and deg is the original degree of a variable. all algorithms were written in c. the experiments were carried out on linux on a pc pentium iii  1 ghz processor and 1 mb ram . performance is measured in terms of the number of support checks  the cpu time in seconds  and the number of revisions.
　we experimented with random problems which were generated by frost et al.'s model b generator  gent et al.  1   http://www.lirmm.fr/ bessiere/ generator.html . in this model a random csp instance is characterised by hn d p1 p1 i where n is the number of variables  d the uniform domain size  p1 the average density  and p1 the uniform tightness. for each combination of hn d p1 p1i  1 random problems were generated. table 1 shows the mean results for h1 1 1iwhich is located at the phase transition. in table 1  under the column labelled as weight  1 denotes that the weight associated with each arcvalue pair is 1  also the default value  while scount denotes that the weight associated with each arc-value pair is its own support count. table 1 corresponds to the real world instance rlfap #1 which came from the celar suite. table 1 corresponds to a quasigroup with holes problem  achlioptas et al.  1  of order 1 and 1 holes.
1 discussion
one can immediately notice that sc reduces the number of checks required by mac-1 and mac-1. for instance for the random problem  checks required by mac-1 and mac-1 are reduced by 1% and 1% respectively  when the weight associated with each arc-value pair is its own support count. we observed that for the random problems sc and rc are especially effective for difficult problems that take a lot of time. the original version of mac-1 requires 1 times more checks than the original version of mac-1 but it reduces to 1 after using sc. it is interesting to note that for the random problem and the quasigroup problem mac-1 with sc requires fewer checks than the original version of mac-1. remember that mac-1 uses a nonoptimal algorithm ac-1 while mac-1 uses an optimal algorithm ac-1 but that they usually repeat checks in different branches of the search. in case of rlfap #1 when sc is used in mac-1 there is an improvement in the number of checks required during the course of search but not in the total number of checks. this is caused by the initialisation of the cummulative weights.
　mac-1 always spends fewer checks than mac-1 but requires more time. this corresponds to the results presented in  van dongen  1 . using sc in mac-1 and mac-1 reduces the number of checks but this is not reflected in the solution time. in fact there is only a marginal saving and in some cases it may consume more time. this shows that when checks are cheap carrying out ascs to reduce the checks is not really a great help in reducing the overall solution time.
　both rc and wrc avoid at least 1% of the total revisions. rcs are able to save more ineffective revisions than wrcs. satisfying a rc or a wrc avoids a complete revision that not only reduces checks but also acss and the overhead of queue management. when rev:comp and wrc are used together in mac-1 or in mac-1 there is on average 1% reduction in the solution time compared to the original algorithms equipped with arc:comp  which is significant. results for arc:comp with rc are not presented due to the space restriction. the overhead to maintain lcws is less with rev:comp because they need to be updated after every effective complete relaxation but in case of arc:comp and var:comp after
mac-1mac-1heuristicconditionscheckstimerevisionscheckstime-1 111 1 11arc:compsc1 1.1 11 1.1wrc1 1.1 11 1.1sc + wrc1 1.1 11 1.1-1 111 1 11sc1 1.1 11 1.1rev:compwrc1 1.1 11 1.1sc + wrc1 1.1 11 1.1rc1 1.1 11 1.1sc + rc1 1.1 11 1.1table 1: results for quasigroup problems of order 1 with 1 holes.every effective revision. results shown in all the tables confirm that rev:comp is good in saving revisions  support checks and the cpu time for both mac-1 and mac-1 when compared to arc:comp.
　finally  we compared rc with the static version of rc. for the random problems when solved with mac-1  the static version of rc with var:comp as implemented in  boussemart et al.  1  spends on average 1 1 revisions  1 1 checks and 1 seconds while rc with rev:comp spends on average spends 1 revisions  1 1 checks and 1 seconds. the static version of rc spends about twice as many revisions and checks as rc but saves time. the reason for this is that checks are very cheap for random problems and that the static version uses a variable based queue  which has low maintenance overhead.
1 conclusions
in this paper first we present a support condition. satisfying
sc guarantees the existence of a support for a value. scs avoid many positive and negative support checks during the course of the search. we showed that when checks are cheap reducing them by using ascs do not payoff a lot in terms of the cpu time. instead of carrying out ascs for each value we tried to reduce the number of ineffective revisions through revision condition and a weak version of revision condition. both of them reduce the number of arcs that have to be added to the queue. having fewer arcs in the queue improves the selection of the best arc from the queue. furthermore fewer revisions are performed. overall  scs reduce the positive and negative support checks required by mac-1 and mac-1. rcs avoid at least 1% of the total revisions. combining the two results in reducing the solution time by 1%.
acknowledgements
thanks to barbara smith  mark hennessy  richard wallace and the other members of the cork constraint computation centre for helpful comments.
