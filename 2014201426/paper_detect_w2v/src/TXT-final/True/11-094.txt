epistemological problems of artificial intelligence 
john mccarthy 
computer science department 
stanford university 
stanford  california 1 

introduction 
     in  mccarthy and hayes 1   we proposed dividing the artificial intelligence problem into two parts - an epistemological part and a heuristic part. this lecture further explains this division  explains some of the epistemological problems  and presents some new results and approaches. 
     the epistemological part of ai studies what kinds of facts about the world are available to an observer with given opportunities to observe  how these facts can be represented in the memory of a computer  and what rules permit legitimate conclusions to be drawn from these facts. it leaves aside the heuristic problems of how to search spaces of possibilities and how to match patterns. 
     considering epistemological problems separately has the following advantages: 
     1. the same problems of what information is available to an observer and what conclusions can be drawn from information arise in connection with a variety of problem solving tasks. 
     1. a single solution of the epistemological problems can support a wide variety of heuristic approaches to a problem. 
     1. ai is a very difficult scientific problem  so there are great advantages in finding parts of the problem that can be separated out and separately attacked. 
     1. as the reader will see from the examples in the next section  it is quite difficult to formalize the facts of common knowledge. existing programs that manipulate facts in some of the domains are confined to special cases and don't face the difficulties that must be overcome to achieve very intelligent behavior. 
     we have found first order logic to provide suitable languages for expressing facts about the world for epistemological research. recently we have found that introducing concepts as individuals makes possible a first order logic expression of facts usually expressed in modal logic but with important advantages over modal logic - and so far no disadvantages. 
     in ai literature  the term predicate calculus is usually extended to cover the whole of first order logic. while predicate calculus includes just formulas built up from variables using predicate symbols  logical connectives  and quantifiers  first order logic also allows the use of function symbols to form terms and in its semantics interprets the equality symbol as standing for identity. our first order systems further use conditional expressions  non-recursive  to form terms and -expressions with individuaal variables to form new function symbols. all 
these extensions are logically inessential  because every formula that includes them can be replaced by a formula of pure predicate calculus whose validity is equivalent to it. the extensions are heuristically non-trivial  because the equivalent predicate calculus may be much longer and is usually much more difficult to understand - for man or machine. 
     the use of first order logic in epistemological research is a separate issue from whether first order sentences are appropriate data structures for representing information within a program. as to the latter  sentences in logic are at one end of a spectrum of representations; they are easy to communicate  have logical consequences and can be logical consequences  and they can be meaningful in a wide context. taking action on the basis of information stored as sentences  is slow and they are not the most compact representation of information. the opposite extreme is to build the information into hardware  next comes building it into machine language program  then a language like lisp  and then a language like microplanner  and then perhaps productions. compiling or hardware building or  automatic programming  or just planning takes information from a more context independent form to a faster but more context dependent form. a clear expression of this is the transition from first order logic to microplanner  where much information is represented similarly but with a specification of how the information is to be used. a large ai system should represent some information as first order logic sentences and other information should be compiled. in fact  it will often be necessary to represent the same information in several ways. thus a ball player habit of keeping his eye on the ball is built into his  program   but it is also explicitly represented as a sentence so that the advice can be communicated. 
     whether first order logic makes a good programming language is yet another issue. so far it seems to have the qualities samuel johnson ascribed to a woman preaching or a dog walking on its hind legs - one is sufficiently impressed by seeing it done at all that one doesn't demand it be done well. 
     suppose we have a theory of a certain class of phenomena axiomatized in  say  first order logic. we regard the theory as adequate for describing the epistemological aspects of a goal seeking process involving these phenomena provided the following criterion is satisfied: 

1      imagine a robot such that its inputs become sentences of the theory stored in the robot's data-base  and such that whenever a sentence of the form  / should emit output x now  appears in its data base  the robot emits output x. suppose that new sentences appear in its data base only as logical consequences of sentences already in the data base. the deduction of these sentences also use general sentences stored in the data base at the beginning constituting the theory being tested. usually a data-base of sentences permits many different deductions to be made so that a deduction program would have to choose which deduction to make. if there was no program that could achieve the goal by making deductions allowed by the theory no matter how fast the program ran  we would have to say that the theory was epistemologically inadequate. a theory 
that was epistemologically adequate would be considered heuristically inadequate if no program running at a reasonable speed with any representation of the facts expressed by the data could do the job. we believe that most present ai formalisms are epistemologically inadequate for general intelligence; i.e. they wouldn't achieve enough goals requiring general intelligence no matter how fast they were allowed to run. this is because the epistemological problems discussed in the following sections haven't even been attacked yet. 
　　　the word  epistemology  is used in this paper substantially as many philosophers use it  but the problems considered have a different emphasis. philosophers emphasize what is potentially knowable with maximal opportunities to observe and compute  whereas ai must take into account what is knowable with available observational and computational facilities. even so  many of the same formalizations have both philosophical and al interest. 
　　　the subsequent sections of this paper list some epistemological problems  discuss some first order formalizations  introduce concepts as objects and use them to express facts about knowledge  describe a new mode of reasoning called circumscription  and place the ai problem in a philosphical setting. 
epistemological problems 
　　　we will discuss what facts a person or robot must take into account in order to achieve a goal by some strategy of action. we will ignore the question of how these facts are represented  e.g.  whether they are represented by sentences from which deductions are made or whether they are built into the program. we start with great generality  so there many difficulties. we obtain successively easier problems by assuming that the difficulties we have recognized don't occur until we get to a class of problems we think we can solve. 
　　　i. we begin by asking whether solving the problem requires the co-operation of other people or overcoming their opposition. if either is true  there are two subcases. in the first subcase  the other people's desires and goals must be taken into account  and the actions they will take in given circumstances predicted on the hypothesis that they will try to achieve their goals  which may have to be discovered. the problem is even more difficult if bargaining is involved  because then the problems and indeterminacies of game theory are relevant. even if bargaining is not involved  the robot still must  put himself in the place of the other people with whom he interacts . facts like a person wanting a thing or a person disliking another must be described. 
　　　the second subcase makes the assumption that the other people can be regarded as machines with known input-output behavior. this is often a good assumption  e.g.  one assumes that a clerk in a store will sell the goods in exchange for their price and that a professor will assign a grade in accordance with the quality of the work done. neither the goals of the clerk or the professor need be taken into account; either might well regard an attempt to use them to optimize the interaction as an invasion of privacy. in such circumstances  man usually prefers to be regarded as a machine. 
　　　let us now suppose that either other people are not involved in the problem or that the information available about their actions takes the form of input-output relations and does not involve understanding their goals. 
　　　1. the second question is whether the strategy involves the acquisition of knowledge. even if we can treat other people as machines  we still may have to reason about what they know. thus an airline clerk knows what airplanes fly from here to there and when  although he will tell you when asked without your having to motivate him. one must also consider information in books and in tables. the latter information is described by other information. 
　　　the second subcase of knowledge is according to whether the information obtained can be simply plugged into a program or whether it enters in a more complex way. thus if the robot must telephone someone  its program can simply dial the number obtained  but it might have to ask a question   how can i get in touch with mike   and reason about how to use the resulting information in conjunction with other information. the general distinction may be according to whether new sentences are generated or whether values are just assigned to variables. 
　　　an example worth considering is that a sophisticated air traveler rarely asks how he will get from the arriving flight to the departing flight at an airport where he must change planes. he is confident that the information will be available in a form he can understand at the time he will need it. 
　　　if the strategy is embodied in a program that branches on an environmental condition or reads a numerical parameter from the environment  we can regard it as obtaining knowledge  but this is obviously an easier case than those we have discussed. 
　　　1. a problem is more difficult if it involves concurrent events and actions. to me this seems to be the most difficult unsolved epistemological problem for ai - how to express rules that give the effects of actions and events when they occur concurrently. we may contrast this with the sequential case treated in  mccarthy and hayes 1 . in the sequential case we can write 
1  	s' - result e s  
where s' is the situation that results when event e occurs in situation s. the effects of e can be described by sentences relating s'  e and s. one can attempt a similar formalism giving a partial situation that results from an event in another partial situation  but it is difficult to see how to apply this to cases in which other events may affect with the occurrence. 
　　　when events are concurrent  it is usually necessary to regard time as continuous. we have events like raining until the reservoir overflows and questions like where was his train when we wanted to call him . 
　　　computer science has recently begun to formalize parallel processes so that it is sometimes possible to prove that a system of parallel processes will meet its specifications. however  the knowledge available to a robot of the other processes going on in the world will rarely take the form of a petri net or any of the other formalisms used in engineering or computer science. in fact  anyone who wishes to prove correct an airline reservation system or an air traffic control system must use information about the behavior of the external world that is less specific than a program. nevertheless  the formalisms for expressing facts about parallel and indeterminate programs provide a start for axiomatizing concurrent action. 
i n v i t e d 	papers-1: 	mccarthy 1 　　　1. a robot must be able to express knowledge about space  and the locations  shapes and layouts of objects in space. present 
programs treat only very special cases. usually locations are discrete - block a may be on block b but the formalisms do not allow anything to be said about where on block b it is  and what shape space is left on block b for placing other blocks or whether block a could be moved to project out a bit in order to place another block. a few are more sophisticated  but the objects must have simple geometric shapes. a formalism capable of representing the geometric information people get from seeing and handling objects has not  to my knowledge  been approached. 
       the difficulty in expressing such facts is indicated by the limitations of english in expressing human visual knowledge. we can describe regular geometric shapes precisely in english 
 fortified by mathematics   but the information we use for recognizing another person's face cannot ordinarily be transmitted in words. we can answer many more questions in the presence of a scene than we can from memory. 
       1. the relation between three dimensional objects and their two dimensional retinal or camera images is mostly untreated. contrary to some philosophical positions  the three dimensional object is treated by our minds as distinct from its appearances. people blind from birth can still communicate in the same language as sighted people about three dimensional objects. we need a formalism that treats three dimensional objects as instances of patterns and their two dimensional appearances as projections of these patterns modified by lighting and occlusion. 
       1. objects can be made by shaping materials and by combining other objects. they can also be taken apart  cut apart or destroyed in various ways. what people know about the relations between materials and objects remains to be described. 
       1. modal concepts like event e  caused event e1 and person e can do action a are needed.  mccarthy and hayes 1  regards ability as a function of a person's position in a causal system and not at all as a function of his internal structure. this still seems correct  but that treatment is only metaphysically adequate  because it doesn't provide for expressing the information about ability that people actually have. 
       1. suppose now that the problem can be formalized in terms of a single state that is changed by events. in interesting cases  the set of components of the state depends on the problem  but common general knowledge is usually expressed in terms of the effect of an action on one or a few components of the state. however  it cannot always be assumed that the other components are unchanged  especially because the state can be described in a variety of co-ordinate systems and the meaning of changing a single co-ordinate depends on the co-ordinate system. the problem of expressing information about what remains unchanged by an event was called the frame problem in  mccarthy and hayes 1 . minsky subsequently confused matters by using the word  frame  for patterns into which situations may fit.  his hypothesis seems to have been that almost all situations encountered in human problem solving fit into a small number of previously known patterns of situation and goal. i regard this as unlikely in difficult problems . 
       1. the frame problem may be a subcase of what we call the quqlification problem  and a good solution of the qualification problem may solve the frame problem also. in the missionaries and cannibals problem  a boat holding two people is stated to be available. in the statement of the problem  nothing is said about how boats are used to cross rivers  so obviously this information must come from common knowledge  and a computer program capable of solving the problem from an english description or from a translation of this description into logic must have the requisite common knowledge. the simplest statement about the use of boats says something like   // a boat is at one point on the shore of a body of water  and a set of things enter the boat  and the boat is propelled to the another point on the shore  and the things exit the boat  then they will be at the second point on the shore . however  this statement is too rigid to be true  because anyone will admit that if the boat is a rowboat and has a leak or no oars  the action may not achieve its intended result. one might try amending the common knowledge statement about boats  but this encounters difficulties when a critic demands a qualification that the vertical exhaust stack of a diesel boat must not be struck square by a cow turd dropped by a passing hawk or some other event that no-one has previously thought of. we need to be able to say that the boat can be used as a vehicle for crossing a body of water unless something prevents it. however  since we are not willing to delimit in advance possible circumstances that may prevent the use of the boat  there is still a problem of proving or at least conjecturing that nothing prevents the use of the boat. a method of reasoning called circumscription  described in a subsequent section of this paper  is a candidate for solving the qualification problem. the reduction of the frame problem to the qualification problem has not been fully carried out  however. 
circumscription - a way of jumping to conclusions 
       there is an intuition that not all human reasoning can be translated into deduction in some formal system of mathematical logic  and therefore mathematical logic should be rejected as a formalism for expressing what a robot should know about the world the intuition in itself doesn't carry a convincing idea of what is lacking and how it might be supplied. 
       we can confirm part of the intuition by describing a previously unformalized mode of reasoning called circumscription  which we can show does not correspond to deduction in a mathematical system. the conclusions it yields are just conjectures and sometimes even introduce inconsistency. we will argue that humans often use circumscription  and robots must too. the second part of the intuition - the rejection of mathematical logic - is not confirmed; the new mode of reasoning is best understood and used within a mathematical logical framework and co-ordinates well with mathematical logical deduction. we think circumscription accounts for some of the successes and some of the errors of human reasoning. 
       the intuitive idea of circumscription is as follows: we know some objects in a given class and we have some ways of generating more. we jump to the conclusion that this gives all the objects in the class. thus we circumscribe the class to the objects we know how to generate. 
       for example  suppose that objects a  b and c satisfy the predicate p and that the functions fix  and g x y  take arguments satisfying p into values also satisfying p. the first order logic expression of these facts is 

invited papers-1: mccarthy 1 the conjecture that everything satisfying p is generated from a  b and c by repeated application of the functions / and g is expressed by the sentence schema 

where   is a free predicate variable for which any predicate may be substituted. 
it is only a conjecture  because there might be an object d such that p d  which is not generated in this way.  1  is one way of writing the circumscription of  1 . the heuristics of circumscription - when one can plausibly conjecture that the objects generated in known ways are all there are - are completely unstudied. 
       circumscription is not deduction in disguise  because every form of deduction has two properties that circumscription lacks transitivity and what we may call monotonicity. transitivity says that if p + r and r + s  then p + s. monotonicity says that if a + p  where a is a set of sentences  and a c b  then b + p for deduction. intuitively  circumscription should not be monotonic since it is the conjecture that the ways we know of generating p's are all there are. an enlarged set b of sentences may contain a new way of generating p's. 
       if we use second order logic or the language of set theory  then circumscription can be expressed as a sentence rather than as a schema. in set theory it becomes. 
sentence p by circumscription is true in all minimal models of p  where a deduction from p is true in all models of p. minimality is defined with respect to a containment relation s. we write that m1   m1 if every element of the domain of mi is a member of the domain of m1 and on the common members all predicates have the same truth value. it is not always true that a sentence true in all minimal models can be proved by circumscription. indeed the minimal model of peanos axioms is the standard model of arithmetic  and codel's theorem is the assertion that not all true sentences are theorems. minimal models don't always exist  and when they exist  they aren't always unique. 
 mccarthy 1a  treats circumscription in more detail. 
concepts as objects 
we shall begin by discussing how to express such facts as 
 pat knows the combination of the safe   although the idea of treating a concept as an object has application beyond the discussion of knowledge. 
       we shall use the symbol safe  for the safe  and combination s  is our notation for the combination of an arbitrary safe s. we aren't much interested in the domain of 


　　there is a way of applying circumscription to an arbitrary sentence of predicate calculus. let p be such a sentence and let   be a predicate symbol. the relativization of p with respect to    written p   is defined  as in some logic texts  as the sentence that results from replacing every quantification that occurs in p by and every quantification that occurs in p by the circumscription of p is then the 
sentence 

this form is correct only if neither constants nor function symbols occur in p. if they do  it is necessary to conjoin   c  for each constant c and  for each single argument function symbol / to the premiss of  1 . corresponding sentences must be conjoined if there are function symbols of two or more arguments. the intuitive meaning of  1  is that the only objects satisfying p that exist are those that the sentence p forces to exist. 
       applying the circumscription schema requires in venting a suitable predicate to substitute for the symbol    inventing a suitable set in the set-theoretic formulation . in this it resembles mathematical induction; in order to get the conclusion  we must invent a predicate for which the premiss is true. 
       there is also a semantic way of looking at applying circumscription. namely  a sentence that can be proved from a 
       combinations  and we shall take them to be strings of digits with dashes in the right place  and  since a combination is a string  we will write it in quotes. thus we can write 1  combination safe   =  1-1  
as a formalization of the english  the combination of the safe is 1-1 . let us suppose that the combination of safe1 is  coincidentally  also 1-1  so we can also write 
1  	combination safe1  =  1-1 . 
       now we want to translate  pat knows the combination of the safe . if we were to express it as 1  *knows pat  combination safe i    
the inference rule that allows replacing a term by an equal term in first order logic would let us conclude 1  *knows{pat  combination safe1    which mightn't be true. 
       this problem was already recognized in 1 by frege  the founder of modern predicate logic  who distinguished between direct and indirect occurrences of expressions and would consider the occurrence of combination safe   in  1  to be indirect and not subject to replacement of equals by equals. the modern way of stating the problem is to call pat knows a referentially opaque operator. 
i n v i t e d 	p a p e r s - 1 : 	m c c a r t h y 
1        the way out of this difficulty currently most popular is to treat pat knows as a modal operator. this involves changing the logic so that replacement of an expression by an equal expression is not allowed in opaque contexts knowledge is not the only operator that admits modal treatment. there is also belief  wanting  and logical or physical necessity. for ai purposes  we would need all the above modal operators and many more in the same system. this would make the semantic discussion of the resulting modal logic extremely complex. for this reason  and because we want functions from material objects to concepts of them  we have followed a different path introducing concepts as individual objects. this has not been popular in philosophy  although i suppose no-one would doubt that it could be done. 
       our approach is to introduce the symbol safel as a name for the concept of safel and the function combination which takes a concept of a safe into a concept of its combination. the second operand of the function knows is now required to be a concept  and we can write 
1  	
to assert that pat knows the combination of safel. the previous trouble is avoided so long as we can assert 
1  	
which is quite reasonable  since we do not consider the concept of the combination of safe  to be the same as the concept of the combination of safe1  even if the combinations themselves are the same. 
       we write 1  	
and say that safel is the denotation of safel. we can say that 
pegasus doesn't exist by writing 
1  	
still admitting pegasus as a perfectly good concept. if we only admit concepts with denotations  or admit partial functions into our system   we can regard denotation as a function from concepts to objects - including other concepts. we can then write 
1  	
       the functions combination and combination are related in a way that we may call extensional  namely 
1  	
and we can also write this relation in terms of combination alone as 

or  in terms of the denotation predicate  

it is precisely this property of extensionality that the abovementioned knows predicate lacks in its second argument; it is extensional in its first argument. 
       suppose we now want to say  pat knows that mike knows the combination of safe  . we cannot use 
knows mike  combination safe    as an operand of another knows function for two reasons. first  the value of knows person  concept  is a truth value  and there are only two truth values  so we would either have pat knowing all true statements or none. second  english treats knowledge of propositions differently from the way it treats knowledge of the value of a term. to know a proposition is to know that it is true  whereas the analog of knowing a combination would be knowing whether the proposition is true. 
       we solve the first problem by introducing a new knowledge function knows personconcept  concept . knows mike  combination safel   is not a truth value but a proposition  and there can be distinct true propositions. we now need a predicate true proposition   so we can assert 
1  	
which is equivalent to our old-style assertion 
1  	
we now write 
1  	
to assert that pat knows whether mike knows the combination of safel. we define 

which forms the proposition that a person knows a proposition from the truth of the proposition and that he knows whether the proposition holds. note that it is necessary to have new connectives to combine propositions and that an equality sign rather than an equivalence sign is used. as far as our first order logic is concerned   1  is an assertion of the equality of two terms. these matters are discussed thoroughly in  mccarthy 1b . 
       while a concept denotes at most one object  the same object can be denoted by many concepts. nevertheless  there are often useful functions from objects to concepts that denote them. numbers may conveniently be regarded has having standard concepts  and an object may have a distinguished concept relative to a particular person.  mccarthy 1b  illustrates the use of functions from objects to concepts in formalizing such chestnuts as russell's  / thought your yacht was longer than it is . 
       the most immediate ai problem that requires concepts for its successful formalism may be the relation between knowledge and ability. we would like to connect mike's ability to open safel with his knowledge of the combination. the proper formalization of the notion of can that involves knowledge rather than just physical possibility hasn't been done yet. moore  1  discusses the relation between knowledge and action from a similar point of view  and the final version of  mccarthy 1b  will contain some ideas about this. 
       there are obviously some esthetic disadvantages to a theory that has both mike and mike. moreover  natural language doesn't make such distinctions in its vocabulary  but in rather roundabout ways when necessary. perhaps we could manage with just mike  the concept   since the denotation function will be available for referring to mike  the person himself . it makes some sentences longer  and we have to use and equivalence relation which we may call eqdenot and say  mike eqdenot brother{maryy rather than write 
 mike = brother mary    reserving the equality sign for equal concepts. since many ai programs don't make much use of replacement of equals by equals  their notation may admit either interpretation  i.e.  the formulas may stand for either objects or 

invited papers-1: mccarthy 1 1 

concepts. the biggest objection is that the semantics of reasoning about objects is more complicated if one refers to them only via concepts. 
       i believe that circumscription will turn out to be the key to inferring non-knowledge. unfortunately  an adequate formalism has not yet been developed  so we can only give some ideas of why establishing non-knowledge is important for ai and how circumscription can contribute to it 
       if the robot can reason that it cannot open safe i  because it doesn't know the combination  it can decide that its next task is to find the combination. however  if it has merely failed to determine the combination by reasoning  more thinking might solve the problem. if it can safely conclude that the combination cannot be determined by reasoning  it can look for the information externally. 
       as another example  suppose someone asks you whether the president is standing  sitting or lying down at the moment you read the paper. normally you will answer that you don't know and will not respond to a suggestion that you think harder. you conclude that no matter how hard you think  the information isn't to be found. if you really want to know  you must look for an external source of information. how do you know you can't solve the problem  the intuitive answer is that any answer is consistent with your other knowledge. however  you certainly don't construct a model of all your beliefs to establish this. since you undoubtedly have some contradictory beliefs somewhere  you can't construct the required models anyway. 
       the process has two steps. the first is deciding what knowledge is relevant. this is a conjectural process  so its outcome is not guaranteed to be correct. it might be carried out by some kind of keyword retrieval from property lists  but there should be a less arbitrary method. 
       the second process uses the set of  relevant  sentences found by the first process and constructs models or circumscription predicates that allow for both outcomes if what is to be shown unknown is a proposition. if what is to be shown unknown has many possible values like a safe combination  then something more sophisticated is necessary. a parameter called the value of the combination is introduced  and a  model  or circumscription predicate is found in which this parameter occurs free. we used quotes  because a one parameter family of models is found rather than a single model. 
       we conclude with just one example of a circumscription schema dealing with knowledge. it is formalization of the assertion that all mike knows is a consequence of propositions p and q. 

philosophical notes 
       philosophy has a more direct relation to artificial intelligence than it has to other sciences. both subjects require the formalization of common sense knowledge and repair of its deficiencies. since a robot with general intelligence requires some general view of the world  deficiencies in the programmers' introspection of their own world-views can result in operational weaknesses in the program. thus many programs  including winograd's shrdlu  regard the history of their world as a sequence of situations each of which is produced by an event occuring in a previous situation of the sequence. to handle concurrent events  such programs must be rebuilt and not just provided with more facts. 
       this section is organized as a collection of disconnected remarks some of which have a direct technical character  while others concern the general structure of knowledge of the world. some of them simply  give sophisticated justifications for some things that programmers are inclined to do anyway  so some people may regard them as superfluous. 
       1. building a view of the world into the structure of a program does not in itself give the program the ability to state the view explicitly. thus  none of the programs that presuppose history as a sequence of situations can make the assertion  history is a sequence of situations . indeed  for a human to make his presuppositions explicit is often beyond his individual capabilities  and the sciences of psychology and philosophy still have unsolved problems in doing so. 
       1. common sense requires scientific formulation. both al and philosophy require it  and philosophy might even be regarded as an attempt to make common sense into a science. 
       1. al and philosophy both suffer from the following dilemma. both need precise formalizations  but the fundamental structure of the world has not yet been discovered  so imprecise and even inconsistent formulations need to be used. if the imprecision merely concerned the values to be given to numerical constants  there wouldn't be great difficulty  but there is a need to use theories which are grossly wrong in general within domains where they are valid. the above-mentioned historyas-a-sequcnce-of-situations is such a theory. the sense in which this theory is an approximation to a more sophisticated theory hasn't been examined. 
          mccarthy 1c  discusses the need to use concepts that are meaningful only in an approximate theory. relative to a cartesian product co-ordinatization of situations  counterfactual sentences of the form  // co-ordinate x had the value c and the other co-ordinates retained their values  then p would be true  can be meaningful. thus  within a suitable theory  the assertion  the skier wouldn't have fallen if he had put his weight on his downhill ski  is meaningful and perhaps true  but it is hard to give it meaning as a statement about the world of atoms and wave functions  because it is not clear what different wave functions are specified by  if he had put his weight on his downhill ski . we need an al formalism that can use such statements but can go beyond them to the next level of approximation when possible and necessary. 1 now think that circumscription is a tool that will allow drawing conclusions from a given approximate theory for use in given circumstances without a total commitment to the theory. 
       1. one can imagine constructing programs either as empiricists or as realists. an empiricist program would build only theories connecting its sense data with its actions. a realist program would try to find facts about a world that existed independently of the program and would not suppose that the only reality is what might somehow interact with the program. 
       i favor building realist programs with the following example in mind. it has been shown that the life two dimensional cellular automaton is universal as a computer and as a constructor. therefore  there could be configurations of life cells acting as self-reproducing computers with sensory and 

i n v i t e d 	p a p e r s - 1 : 	m c c a r t h y 
1 

motor capabilities with respect to the rest of the life plane. the program in such a computer could study the physics of its world by making theories and experiments to test them and might eventually come up with the theory that its fundamental physics is that of the life cellular automaton. 
       we can test our theories of epistemology and common sense reasoning by asking if they would permit the life-world computer to conclude  on the basis of experiments  that its physics was that of life. if our epistemology isn't adequate for such a simple universe  it surely isn't good enough for our much more complicated universe this example is one of the reasons for preferring to build realist rather than empiricist programs. the empiricist program  if it was smart enough  would only end up with a statement that  my experiences are best organized as if there were a life cellular automaton and events isomorphic to my thoughts occurred in a certain subconfiguration of it . thus it would get a result equivalent to that of the realist program but more complicated and with less certainty. 
       more generally  we can imagine a metaphilosophy that has the same relation to philosophy that metamathematics has to mathematics. metaphilosophy would study mathematical systems consisting of an  epistemologist  seeking knowledge in accordance with the epistemology to be tested and interacting with a  world . it would study what information about the world a given philosophy would obtain. this would depend also on the structure of the world and the  epistemologist s opportunities to interact. 
       ai could benefit from building some very simple systems of this kind  and so might philosophy. 
