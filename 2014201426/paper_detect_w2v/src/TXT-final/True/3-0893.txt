
we consider the problem of attribution of knowledge to artificial agents and their legal principals. when can we say that an artificial agent x knows p and that its principal can be attributed the knowledge of p  we offer a pragmatic analysis of knowledge attribution and apply it to the legal theory of artificial agents and their principals.
1 introduction
an agent's principal is its employer  or any other legal person engaging the agent to carry on transactions on its behalf. a problem commonly faced by courts is deciding when to attribute the knowledge in possession of an agent to its principal. if the agent in question is an artificial one  how should the courts decide that a  the agent knows the proposition in question and b  that this knowledge can be attributed to the agents' principal  we need a philosophical account of knowledge attribution that does justice to the first question  and thereby aids in the resolution of the second - legal -  problem. conversely  legal resolutions of these issues will aid us in a solution of the philosophical problem - just as legal findings on personhood can clarify philosophical debates over the nature of personal identity. as the delegation of tasks to artificial agents increases  so will cases that encounter the need for decisions hinging on these debates  thus rendering more urgent the need for a solution. 
the plan of this paper is as follows. in section 1  we present our analysis of knowledge attribution. in section 1   within limitations of space  we illustrate its plausibility by examples and arguments. in section 1 we describe the legal problem of attributing knowledge held by agents to their principals  while critically examining current legal doctrine in this area  and show how our analysis is of help. while we concentrate on british commonwealth and us law  this paper does not purport to be a complete survey of the relevant law in the jurisdictions dealt with. when citing nonacademic sources such as case reports  we use the legal mode of citation.
1 agents' knowledge: a pragmatic analysis
consider the following knowledge claim: x knows p. philosophers have long considered the conditions under which such a claim could be made going back to plato's theatetus  which analyzed knowledge as justified true belief: i.e.  x knows p iff:
1. x believes p
1. p is true
1. x is justified in believing p
 gettier  1  has shown by a series of counterexamples that this analysis is flawed. despite considerable effort  no satisfactory analysis of knowledge has emerged that does justice to these or newer counterexamples  largely due to difficulties in defining a satisfactory notion of justification . knowledge attribution has long been recognized as ripe for a treatment grounded in a more pragmatic understanding.
in our analysis of knowledge attribution  x knows p iff:
1. x has ready access to p
1. p is true
1. x can make use of the informational content of p  equivalently  x can exercise certain capacities dependent on its knowing p 
we retain the truth condition of the original analysis and introduce two new conditions. condition 1 uses the notion of access to  or easy availability of  the proposition p. condition 1 - which replaces the notion of justification - implies counterfactuals such as  if x did not know p  then y  - where y is a statement like  x is not able to exercise capacity c . since x is able to exercise capacity c  it knows p.  see dispositional  levi and morgenbesser  1  or functionalist accounts  armstrong  1  for similar notions. 
1 the case for the pragmatic analysis
the following examples illustrate the intuitions underlying our analysis:
1. as i walk down the street  i am asked by a passerby   excuse me  do you know the time   i answer  yes  as i reach for my cellphone to check and inform him what time it is. this example  due to andy clark   shows that we take ourselves to know those items of information that are easily accessible1 and can be easily used. clark's example is part of an extended argument for distributed cognition through external tools and memory stores not confined to the inside of our craniums. for our analysis we note that information at hand can be described as information that we 'know'  i could not claim to know my friends' telephone numbers if  on being asked  i were to reply   i can't remember  .
1. a friend wants to buy me a book as a gift. he asks me for my shipping address so that he can send me the book. i direct him to my wish-list at amazon.com saying   amazon knows my shipping address . indeed  the shopping cart software on that site does. when my friend has decided which books he wants to buy  he pays and picks the shipping option. amazon generates a shipping invoice complete with shipping address. the shopping cart software is able to discharge its functions using that piece of information. i had stored the shipping address on amazon precisely for such future use. i could store an alternate shipping address and forget its details  since amazon 'knows' it and will ship to it if anyone decides to send me a book at that address. note that parts of my address could be obtained from amazon's database  by amazon.com programmers  by writing specific queries  e.g.   what street does customer x live on   . in a weaker sense  then  amazon then also knows which of its customers lives in postal code 1.
1. i have to attend a meeting at the university campus branch located in the city center. with directions for the meeting written down on a piece of paper that i keep in my pocket  i head out the office door. as i do so  my office-mate asks me  do you know where the meeting will be held   i answer   yes 
as i hurry towards the next train. here  gricean semantics  grice  1  is at play: if i said i did not know the meeting's location  i would be misleading my questioner. this example is crucial in showing that knowledge claims are connected to the pragmatics of speech. to deny a valid knowledge attribution in this case would be to say something misleading or something whose semantic value is considerably less than the knowledge claim.
in the amazon example the agent is able to use my address to fulfill its functions. an alternative locution would be to say   amazon has my address   but what purpose would be served other than an avoidance of intentional vocabulary  if it did not ship to the correct address  amazon could not use as a defense the claim that it did not know  or 'have access to'  my address. it was stored in their database and had been used successfully in the past.  amazon is capable of informing a potential customer that it is unable to ship goods since it does not 'know' the recipient's address  or credit card number . if amazon has access to my address but it has changed in the meantime  then it is natural to say that amazon does not know my address since it would not be able to perform the function of shipping books to me.
when we say   amazon.com knows my shipping address   our analysis implies that:
1. amazon has ready access to my shipping address in its databases.
1. the shipping address is correct.
1. amazon is able to perform capacities dependent upon its knowing my address  it is able to make use of the informational content of the address .
furthermore  the relevant counterfactuals are true: if it did not know my address  amazon's core functionality with respect to its interactions with me would not be achievable; if amazon did not know my shipping address  it would not be able to send books to me; if amazon did not know my address  it would not be able to send me a bill; but it is able to do so; hence it knows my address. this kind of analysis is readily extended to other kinds of agents that take actions based on information at their disposal. an artificial agent's actions could be described in much the same way as a human agent's -  the pricebot sent me a quote because it knew my preferences .
 	our analysis may be fruitfully contrasted with conventional formal analysis  in which an agent's belief corpus is taken to be the set of propositions that the agent is committed to  the agent answers  yes  when asked  do you believe  p   . formally  p is derivable using the inference machinery built into that agent's architecture. thus i could say of an artificial agent that it knows or believes p if p is derivable from its knowledge base. but to limit knowledge attribution to those agents that are capable of deriving the proposition p using a formally specifiable inference mechanism would be to put the proverbial cart before the horse. we feel comfortable making the claim that the cat knows a mouse is behind the door though we do not have the foggiest idea of what kind of inferential mechanism is at hand. the cat reveals its knowledge through its actions. whatever kind of retrieval or inference mechanism is at work  it enables the cat to go about its tasks. similarly for an artificial agent -  it reveals its knowledge of p through the ready availability of the proposition in facilitating the agent's functionality. we do not discount a hybrid architecture that employs a deductive database that can infer further information applying rules to a set of stored facts. in that case we would say that the agent in question knows all the facts derivable from its database as well - subject to tractability conditions as in  parikh  1 .
where does an agent's epistemology come into the picture  if an agent elicits information from humans then the responsibility of ensuring the accuracy of the information is the user's. if the user inputs incorrectly  the agent is in possession of false information and we do not make the knowledge attribution. thus  the software artifact inherits its epistemology from the humans that supply it information and carry out data entry. this should not lead us to think that artificial agents do not have an independent epistemology. pricebots that read price information on remote web pages acquire knowledge autonomously  by using their file-reading mechanisms  presumably equipped with error checking and validation routines that guarantee it will not read in garbage  the software equivalent of a reliable sensor . the accuracy with which these agents acquire information is a function of their design and the code that runs on them - very similar to human agents  the accuracy of whose beliefs is a function of how well their senses work in conjunction with background knowledge and their reasoning powers.
we would not want to say that an artificial agent knows a proposition if the proposition is simply stored in the agent's knowledge base but is not accessible for use by the agent. in that case  we would say that the information in question is stored in the agent but the agent does not know it  since it is unable to access or use it. note that when files are deleted from a computer the information ordinarily does not vanish  it simply becomes a target for over-writing. the information is not accessible any more without elaborate recovery methods  and hence the computer's operating system is reasonably enough said not to have access to it any more.
in the case of amazon  it is possible that not a single human being employed by amazon knows my address. it is conceivable that when the shipping invoice is printed out by the software  a human clerk will pick it up and attach it to the box of books in question without bothering to check any further whether the address is correct or not. the software has been treated as a reliable source of information with regards to the address - and thus humans might accurately claim that they learned a proposition from a software agent. when a book is purchased  my address has been used by amazon.com without any human knowing it. what sense would it make to say that amazon did not know the address  alternative locutions for describing this functionality of amazon's would be artificial. what could we say - that amazon has access to this true information  and can use it  the parallels with knowledge attributions to human agents should be clear. for human agents  on our analysis  are said to know a proposition p when we can make such a claim. if i know that 1 times 1 is 1 but cannot open a safe with this combination  then i do not know the combination to the safe since i cannot open it but i do know the product of 1 and 1.
in making knowledge attributions  there is a parallel between humans and artificial agents. the ease with which we slip into the intentional attribution when it comes to amazon.com is an indication of this similarity. the intentional stance is used when it is possible to give the best explanations of behavior using it. what kind of behavior would we able to predict  we could predict amazon's responses to certain queries. for instance  we could say that amazon knows the isbn number for how green was my valley since it would be able to produce that number on request. but as we have argued  we could also predict amazon's success in certain tasks - amazon could demonstrate its knowledge of the isbn number of how green was my valley by shipping me that book and none other.
condition 1 of our analysis is crucial  as in most analyses of knowledge  since if the shipping address in question were incorrect we would not say that amazon knows the shipping address.  the locution we would employ if amazon were to use the incorrect shipping address would be  amazon shipped my books to what it thought  or believed  was my correct address . we would not make the claim that amazon knows my address if in fact  the address is false  since it is possible to have a false belief .
one way to deny that artificial agents can know propositions would be to ask   who does the knowing in the case of the artificial agent   our response would be that the same could be asked of humans  and in the absence of any philosophically satisfactory analysis of personal identity there is no reason to believe that a stronger condition should be placed on artificial agents.  below  we suggest that the correct legal treatment of artificial agents is to assimilate them to human agents  but without the personhood possessed by human agents. if the same view is adopted on the philosophical perspective  it becomes otiose to ask who does the knowing in the case of an artificial agent - other than the agent itself  of course.
1 the legal doctrine of attributed knowledge
this inclusion of the ready-to-hand in the knowledge of an agent has close and instructive parallels in the legal doctrine of attributed knowledge. under this doctrine  the law may impute to a principal knowledge - relating to the subject matter of the agency - which the agent acquires while acting on behalf of its principal within the scope of its authority. the scope of the agent's authority refers to those transactions that the principal has authorized the agent to conduct. in some circumstances  knowledge gained by the agent outside the scope of the agency can also be attributed to the agent's principal. 
once knowledge is attributed to the principal  it is deemed to be known by the principal and it is no defense for the principal to claim that he did not know the information in question  for example  because the agent failed in its duty to convey the information to the principal.
the doctrine of attributed knowledge has many applications  and is used generally in civil law contexts in cases where the knowledge of the principal is relevant. for instance  legal consequences attach to principals knowingly receiving trust funds  or having notice of claims of third parties to property received  or knowingly making false statements.
the doctrine has close parallels with our analysis above  which extends the concept of knowledge to include the information that we retain in storage devices - including written documents - that are ready-to-hand. from this perspective  a human agent is akin to a knowledge storage device under the control of a principal. below  we suggest that artificial agents can be thought of similarly. but first  we explore the basis of the doctrine and its application to the modern company.
1 a duty to communicate 
while the doctrine of attributed knowledge is pervasive in the legal systems under discussion  its precise doctrinal basis is still a matter of some dispute  demott  1 .
one explanation of the doctrine relies on the supposed identity of principal and agent  whereby the law sees them as one person for some purposes. however  this theory lacks explanatory power  and does not explain the public policy justification for the rule.
another explanation put forward for attributed knowledge is that the law presumes that agents will carry out their duties to communicate information to their principals. for example  in the standard practitioner's text halsbury's laws of england  the scope of an agent's duty to communicate determines the existence and the timing of any attributed knowledge of the agent.1 under this approach  the doctrine operates on a pre-existing duty to convey information to deem that the duty has been discharged.
in the us  the common law of agency does not require as a precondition an existing duty to communicate the information to the principal  demott  1 . as langevoort  points out  the courts' description of attribution as the presumption that the agent has fulfilled its duty of candor in conveying information is not correct  since attribution applies even where interaction between principal and agent creates enough scope of discretion that no transmission of information is expected  or occurs .
in england the  duty to communicate  has been abandoned as the explanatory basis of attribution of knowledge.1 similarly  australian courts have inferred attribution of knowledge in the absence of a duty to communicate information in cases where the task assigned to the agent included making appropriate disclosures. 1
we believe the rejection of the duty to communicate is correct on policy grounds to require such a duty in order to attribute knowledge held by agents to their principals would encourage principals to ask agents to shield them from inconvenient information  and would put principals acting through agents in a better position than principals acting directly. such an approach is also incompatible with modern information management practices within companies  and we discuss why below.
however  the fact that agents are capable of communication is important to the attribution of knowledge. in terms of our analysis of knowledge  a lack of capacity to communicate information would render the first and/or third conditions unfulfilled - i.e.  that the principal has ready access to the knowledge held by the agent  or that the principal can make use of its informational content. the capacity to communicate therefore plays an explanatory role when thinking about how artificial agents fit within this legal schema.
1 attribution of knowledge to companies
a company is a special kind of organization that  in modern legal systems  is recognized as a legal person in its own right. how  then  does a company gain knowledge in the eyes of the law  apart  possibly  from knowledge gained  directly  by the board or general meeting of a company  only through the attribution to it of knowledge gained by its agents  i.e.  its directors  employees or contractors . by the doctrine of attribution  the company is deemed to gain the knowledge that is gained by the natural persons  i.e.  humans  engaged by it. 1
the large modern company illustrates why the  duty to communicate  cannot found the attribution of knowledge. given the company is an abstract entity  the only way to make sense of such a duty would be in terms of communication to other agents  such as immediate superiors   who are required to communicate it  directly  to the company as embodied by the board of directors  or general meeting . since in modern corporations authority to enter and administer contracts is usually delegated to relatively junior staff members  it would be absurd if all the knowledge that had legal consequences for a company had to be communicated upwards in this way. instead  most information within the modern corporation remains with lower-level officers  and is only passed upwards in summary terms - or when there is some exceptional reason to do so  such as a dispute with outside parties. abandoning the  duty to communicate  allows the legal system to acknowledge information managed in accordance with modern decentralized practices.
today the most common way for information to be stored and controlled by low-level officers is by inputting it into the company's information systems. some of these systems can be queried by senior managers - but it has never  to our knowledge  been suggested that this is essential to the attribution. to what extent could information systems - artificial agents - themselves be treated by the legal system as agents for the purposes of attribution of knowledge 
1 artificial agents as agents for knowledge imputation purposes
in  chopra and white  1   following  kerr  1   it was argued that the legal system should and could extend the legal treatment of human agents to artificial agents  with appropriate modifications. artificial agents  on this approach  would have a legal status akin to slaves in roman law - that is  with capacity to enter contracts on behalf of their principals  but without contracting capacity or legal personhood in their own right.
we believe a similar move can and should be made with respect to the imputation of knowledge. on this approach  knowledge gained by artificial agents employed by corporations could be attributed to the corporations themselves  where that knowledge would be attributed to the corporation in the case of a human agent.
our analysis could be utilized in a legal context for the task of determining what is known by the artificial agent in question.1
the scope of the agency would be those transactions that the artificial agent has been deployed to conduct. not all the agent's knowledge would necessarily be attributed to the principal. for example  an agent could conceivably act for two principals and in accordance with the law of agency  knowledge gained in the course of one agency is not always attributed to the other principal.1 a natural person could deploy an artificial agent  and in that instance the agent's knowledge would be attributed to the principal in the same circumstances.
surprisingly  there is a paucity of judicial pronouncements on the possibility of attribution of knowledge held by artificial agents. some tangential judicial support for such a treatment of artificial agents was given recently  but it was made clear that it did not  yet  represent the law.  in the australian case commercial union v beard & ors1  the issue arose whether a fact contained in a news clipping  filed in a company paper file  was  known  to an insurer for the purposes of the relevant statute. if it was known to the insurer  the party taking out insurance was relieved of the obligation of making disclosure of the fact to the insurer.
the majority found that a matter could be  known  by the insurer company if it were contained in the  current formal records  of the company. this term appeared to include the minutes of the company's board meetings. however  the majority held that the extract of the news clipping in question was  not a record of  the insurer  and it was not contained in any file to which officers of  the insurer  were expected to have recourse for the purposes of the subject insurance. 1 as a result  they found that the contents were not  known  to the company for the purposes of the statute.
the minority judge  however  seemed to discount that anything could be  known  to the company merely by being contained in a record  while acknowledging that such a view had its attractions  emphasis added :
we were not referred to any authority for the proposition that  in the absence of actual knowledge on the part of relevant officers of a company  the company may  nevertheless   know  a matter  where the relevant information is contained in a company file. i find the proposition an attractive one. in circumstances  which are undoubtedly common today  where important information relating to the conduct of a company's business is stored in the company's computer system  from which it may be readily obtained  the suggestion that such material is part of the company's knowledge is certainly appealing. however...the present state of authority does not permit a finding that the information so stored becomes  known  to the company until it is transferred into the mind of an officer  who is relevantly engaged in the transaction in question1.
the emphasis on being readily obtainable echoes condition 1 of our analysis of knowledge. indeed  we suggest that  had the contents of the news clipping been stored in an information system  rather than a paper file  so as to be readily available to the human officers conducting the insurance transaction  the result should have been different in the commercial union case. the prohibitive cost of insisting on cross-checks being made of all paper files before proceeding with any transaction without fear of legal consequences is obviously significantly reduced if those files are held electronically and therefore ready-to-hand to employees of the company generally.
the example suggests that information systems that are mere accumulations of records may not qualify as agents for attribution purposes. we suggest that the knowledge held by artificial agents will only be attributed to a corporation to the extent that the agent permits ready access by other  human or artificial  agents to its contents. in this way  while the duty to communicate is not necessary for the imputation of knowledge  the ability to communicate so as to make information readily accessible to others - and not just to passively store information - might well be.
considering the company as a knowing agent in its own right for a moment  paper files  to which officers are not expected to have recourse in conducting particular transactions  could be equated with the 'dead' information contained within  but not accessible to  an artificial agent - such as information written on a hard disk  but not readily accessible to the user through the operating system without deploying specialized software.
1 conclusion
we have presented a philosophical and legal analysis of knowledge attribution and suggested that the courts could make use of the analysis when deciding whether to attribute knowledge to artificial agents and principals  such as corporations  employing those artificial agents to conduct transactions on their behalf. in our discussion of amazon  we did not bother to distinguish between the corporation  a legal entity  and the software agents operated by the corporation. we think that for the reasons mentioned in our analysis above  it can make sense to attribute knowledge to both the artificial agents operated by a corporation and the corpora-
                                                 
1 per foster aja at paragraph 1
tion itself. we also pointed out close and instructive parallels between the philosophical analysis and the legal doctrine. we look forward to the first cases where legally salient information known only to artificial agents is nevertheless attributed to the corporations operating those agents on the basis of the above-outlined principles.
