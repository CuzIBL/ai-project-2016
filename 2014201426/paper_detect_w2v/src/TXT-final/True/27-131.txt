what has ai in common with philosophy  
	j o h n 	m c c a r t h y 
computer science department 
stanford university 
stanford  ca 1  u.s.a. 
jmc cs.stanford.edu  http://www-formal.stanford.edu/jmc/ 

a b s t r a c t 
ai needs many ideas that have hitherto been studied only by philosophers. this is because a robot  if it is to have human level intelligence and ability to learn from its experience  needs a general world view in which to organize facts. it turns out that many philosophical problems take new forms when thought about in terms of how to design a robot. some approaches to philosophy are helpful and others are not. 
1 introduction 
artificial intelligence and philosophy have more in common than a science usually has with the philosophy of that science. this is because human level artificial intelligence requires equipping a computer program with a philosophy. the program must have built into it a concept of what knowledge is and how it is obtained. if the program is to reason about what it can and cannot do  its designers will need an attitude to free will. if the program is to be protected from performing unethical actions  its designers will have to build in an attitude about that. 
   unfortunately  in none of these areas is there any philosophical attitude or system sufficiently well defined to provide the basis of a usable computer program. 
   most ai work today does not require any philosophy  because the system being developed doesn't have to operate independently in the world and have a view of the world. the designer of the program does the philosophy in advance and builds a restricted representation into the program. building a chess program requires no philosophy  and mycin got by without even having a notion of processes taking place in time. designing robots that do what they think their owners want will involve their reasoning about wants. 
   not all philosophical positions are compatible with what has to be built into intelligent programs. here are some of the philosophical attitudes that seem to me to be required. 
1. science and common sense knowledge of the world must both be accepted. there are atoms  and there are chairs. we can learn features of the world at the intermediate size level on which humans operate without having to understand fundamental physics. causal relations must also be used for a robot to reason about the consequences of its possible actions. 
1. mind has to be understood a feature at a time. there are systems with only a few beliefs and no belief that they have beliefs. other systems will do extensive introspection. contrast this with the attitude that unless a system has a whole raft of features it isn't a mind and therefore it can't have beliefs. 
1. beliefs and intentions are objects that can be formally described. 
1. it is legitimate to use approximate concepts not capable of iff definition. common language does and robots will have to. 
1 the philosophy of artificial intelligence 
one can expect there to be an academic subject called the philosophy of artificial intelligence analogous to the existing fields of philosophy of physics and philosophy of biology. by analogy it will be a philosophical study of the research methods of ai and will propose to clarify philosophical problems raised. 1 suppose it will take up the methodological issues raised by hubert dreyfus and john searle  even the idea that intelligence requires that the system be made of meat. 
　presumably some philosophers of ai will do battle with the idea that ai is impossible  dreyfus   that it is immoral  weizenbaum  and that the very concept is incoherent  searle . 
　it is unlikely to have any more effect on the practice of ai research than philosophy of science generally has on the practice of science. 
1 epistemological adequacy 
formalisms lor representing facts about the world have to be adequate for representing the information actually available. a formalism that represented the state of the world by the positions and velocities of molecules is inadequate if the system can't observe positions and velocities  although it may be the best for deriving thermodynamic laws. 
	mccarthy 	1 

   the common sense world needs a language to describe objects  their relations and their changes quite different from that used in physics and engineering. the key difference is that the information is less complete. it needs to express what is actually known that can permit a robot to determine the expected consequences of the actions it contemplates. 
1 free will 
an attitude toward the free will problem needs to be built into robots in which the robot can regard itself as having choices to make  i.e. as having free will. 
1 natural kinds 
natural kinds are described rather than defined. we have learned about lemons and experienced them as small  yellow fruit. however  this knowledge does not permit an iff definition. lemons differ from other fruit in ways we don't yet know about. there is no continuous gradation from lemons to oranges. on the other hand  geneticists could manage to breed large blue lemons by tinkering with the genes. 
1 four stances 
daniel dennett named three stances one can take towards an object or system. the first is the physical stance in which the physical structure of the system is treated. the second is the intentional stance in which the system is understood in terms of its beliefs  goals and intentions. the third is the design stance in which the system is understood in terms of its composition out of parts. one more stance we'll call the functional stance. we take the functional stance toward an object when we ask what it does without regard to its physics or composition. the example i like to give is a motel alarm clock. the user may not notice whether it is mechanical  an electric motor timed by the power line or electronic timed by a quartz crystal.1 each stance is appropriate in certain conditions. 
1 ontology and reification 
quine wrote that one's ontology coincides with the ranges of the variables in one's formalism. this usage is entirely appropriate for ai. present philosophers  quine sometimes included  are often too stingy in the reifications they permit. it is sometimes necessary to quantify 
over beliefs  hopes and goals. 
   when programs interact with people or other programs they often perform speech acts in the sense studied by austin and searle. quantification over promises  obligations  questions  answers to questions  offers  acceptances and declinations are required. 
1
　　1 had called this the design stance  and i thank aaron sloman for pointing out my mistake and suggesting functional stance. 
1 	panels 
1 counterfactuals 
an intelligent program will have to use counterfactual conditional sentences  but ai needs to concentrate on useful counterfactuals. an example is  if another car had come over the hill when you passed just now  there would have been a head-on collision.  believing this counterfactual might change one's driving habits  whereas the corresponding material conditional  obviously true in view of the false antecedent  could have no such effect. counterfactuals permit systems to learn from experiences they don't actually have. 
　unfortunately  the stalnaker-lewis closest possible world model of counterfactuals doesn't seem helpful in building programs that can formulate and use them. 
1 philosophical pitfalls 
there is one philosophical view that is attractive to people doing ai but which limits what can be accomplished. this is logical positivism which tempts ai people to make systems that describe the world in terms of relations between the program's motor actions and its subsequent observations. particular situations are sometimes simple enough to admit such relations  but a system that only uses them will not even be able to represent facts about simple physical objects. it cannot have the capability of a two week old baby. 
1 	philosophers! help! 
philosophers could help artificial intelligence more than they have done if they would put some attention to some more detailed conceptual problems such as the following: 
how what is the relation between naming an occurrence and its suboccurences  he went to boston. how  
     he drove to the airport  parked and took ua 1responsiveness when is the answer to a question responsive  thus  vladimir's wife's husband's telephone number  is a true but not responsive answer to a request for vladimir's telephone number. 
useful counterfactuals what counterfactuals are useful and why   // another car had come over the hill when you passed  there would have iteen a head-on 
collision.  
