 
this paper introduces gsss  genetic state-space 
search . the integration of two general search paradigms - genetic search and state-space-search provides a general framework which can be applied to a large variety of search problems. here  we show how gsss solves constrained optimization problems  cops . basically  it searches for  promising search states  from which good solutions can be easily found. domain knowledge in the form of constraints is used to limit the space to be searched. interestingly  our approach allows the handling of constraints within genetic search at a general domain independent level. 
     first  we introduce a genetic representation of search states. next  we provide empirical results which compare the relative merit of the introduction of constraints during the generation of the initial population  during the fitness calculation  and during the application of genetic operators. finally  we describe some extensions to our method which came about when applying it to factory floor scheduling problems. 
1. introduction 
a large number of problems originating from different fields of study  e.g. economics  engineering  belong to the class of cops. as a result  research into efficient solution methods for cops has become a field of study in its own right. 
     constrained optimization problems typically consist of a set of n variables xi  i   n  which have an associated domain di of possible values. there is also a set c of constraints which describe relations between the values of the xi.  e.g. the value of x1 should be different from the value of x1 . finally  an objective function f is given. an optimal solution consists of an assignment of values to the xi such that: 1  all constraints in c are satisfied  i.e. the solution is valid  and 1  the assignment yields an optimal value for the objective function  f. 
     cops typically exhibit a high degree of epistasis: the choices made during the search are closely coupled. in general  highly epistatic problems are characterised by the fact that no decomposition in independent subproblems is possible. in that case  it is difficult to combine subparts of two valid solutions into another valid solution. that is why the efficiency of genetic algorithms  gas  - which typically search by combining features of different  solutions  - decreases significantly for higher degrees of epistasis. 
     the last couple of years a number of methods for constraint handling have been proposed within the ga community. the first one - genetic repair 
 miihlenbein  1  - removes constraint violations in invalid solutions generated by the genetic operators  such as mutation and crossover. the second one uses decoders such that all possible representations give rise to a valid solution  davis  1 . a third one uses penalty functions  see for example  richardson et al.  1 . this approach defines the fitness function as the objective function one tries to optimize minus the penalty function which represents the  degree of invalidity  of a solution. all three approaches are however problem specific: for every cop one has to determine a good decoder  a good genetic repair method or a penalty function which balances between convergence towards suboptimal valid solutions  when the penalty function is too harsh  or towards invalid solutions  when too tolerant a penalty function is used . 
     a subclass of cops  those involving only numerical linear  in equalities  can be elegantly solved with gas. in this case  the space of valid solutions is known to be convex. michalewicz and janikow  used this property to define genetic operators which always generate valid solutions. 
     we tackle here the general class of cops. the problem description of a cop typically contains constraints which implicitly describe which portions of the search space contain valid solutions. here  we discuss how these constraints  which come with the problem specification anyway  can be used to improve the search efficiency of a ga by limiting the search space 
	paredis 	1 
it has to explore. hence  the constraints provide cheap domain specific knowledge which can be used to augment domain independent search methods such as gas. gsss gets its generality from its embedding in the standard state-space search paradigm. 
     we first describe the general framework for the integration of constraint programming in gas. next  we discuss empirical results on a simple cop. finally  we describe some extensions of our approach in the context of factory scheduling. 
1. constraint programming for cops. 
constraint programming has established itself as a good technique for solving cops. the effective use of constraints during the search for solutions made it possible to solve  real-world  cops  even when these exhibit a combinatorial nature. 
     a typical constraint program proceeds as follows. first  a constraint network is generated. this involves the creation of the variables xi  their domains di  and the constraints between the variables. next  the constraint based search algorithm repeats the following selection-assignment-propagation cycle: select a variable whose domain contains more than one element  select a value from the domain of that variable  assign the chosen value to the chosen variable  i.e. the variable's domain becomes a singleton containing this value 1  finally propagation is performed. this propagation process executes all constraints defined on the reduced domain. this might further reduce the domain of other variables. for every domain which becomes reduced to a singleton the propagation process is recursively applied. the propagation algorithm above is known under the name forward checking. 
     the search algorithm described above can easily be described as a standard state-space search. with each search state a set of potential solutions can be associated. this set is simply the product of all domains  i.e. dlxd1x... x dn. at each choice point  assignment   the domain of a variable is reduced to a singleton  followed by constraint propagation. this reduces the set of solutions associated with a state because the domains get smaller. whenever a domain becomes empty no solution exists for the given choices. or  in other words  the current state is a dead end. when finally all domains are reduced to a singleton a solution has been found. 
     the use of constraints allows for early detection of dead ends. hence  the search procedure can skip branches of the search tree which do not lead to a valid solution. this may considerably reduce the amount of back-tracking. another advantage of con-
1  here we use pure random variable and value selection. the use of more intelligent selection heuristics would obviously further improve the results presented in this paper. 
machine learning 
straint programming is that one can state the constraints of the problem domain in a natural way. a good introduction to constraint programming can be found in  van hentenrijck  1 . 
1. a genetic representation for search states 
gsss operates on search states instead of on complete solutions. or  in other words  it operates on partial solutions instead of on complete solutions. for highly epistatic problems this is particularly advantageous because it is much easier to generate valid partial solutions than valid complete solutions to these problems. the same is true for the genetic operators: combining two valid complete solutions into another valid complete solution often turns out to be difficult. as we will see below  search states leave more flexibility for combining them in a  more complete  search state. we will also discuss how the quality  i.e. fitness  of a search state can be defined in terms of the quality of the potential solutions associated with the search state. 
the representation of the search states on which 
gsss operates is straightforward. it heavily relies on the fact that a search state is uniquely determined by the choices  i.e. value assignments  made to reach it from the initial search state. in the standard selectionassignment-propagation algorithm the number of choices is at most equal to the number of variables xi. hence  a string of length n  the number of xi  is used. 
if at the search state to be represented the variable xi is not yet assigned a value  i.e. its domain is not a singleton  then the i-th element of the string consists of a  . if  on the other hand  the search state contains the assignment  choice  xi=v then the i-th element is filled in with v. consider  for example  the string  1   1 . it represents a search state in which x1  x1  and x1 are assigned the values 1  1  and 1  respectively. the representation used here was originally introduced by hinton and nowlan  to study how individual learning can guide evolution. we use the term pigrepresentation when referring to this partially instantiated genotype representation. 
1. the algorithm 
our algorithm is based on genitor  whitley  1   a well known genetic algorithm. after the generation of an initial population  genitor repeats the following steps: 1  select two parents from the population. this selection is biased towards individuals with a high rank in the population which is sorted on fitness; 1  a new individual is generated from these parents through the application of genetic operators  see below ; 1  its fitness is calculated; 1  if this fitness is higher than the worst individual in the population then the child is inserted in the sorted population. at the same time  the worst individual in the population is removed. 
     new  however  is the use of constraints in three components of the ga: during the creation of the initial population  during the fitness calculation  and during the application of the genetic operators. in these three modules gsss uses both representations discussed above: the pig-representation of a search state  and its corresponding constraint network. the individuals in the population are pig-strings. the constraint network is used during the generation of the strings  during the application of genetic operators  and during the fitness calculation. below  we describe how this is done. 
1. the creation of the initial population 
gsss starts from the two representations of the initial search state: 1  the pig-string containing only  s  and 1  a constraint network containing the variables  with their initial domains and the given constraints. next  the selection-assignment-propagation cycle  see section 1  is executed an a priori determined number of times. each cycle replaces a randomly chosen   of the pigstring with a value randomly chosen from the domain of the corresponding variable. next  gsss updates the constraint network: it reduces the domain of the chosen variable to the singleton containing the chosen value. propagation ensures that the domains - from which the values are chosen - are consistent with the assignments made so far. 
     interestingly  this generation of individuals is a constraint satisfaction problem itself. it is however simpler than the original problem because only a portion of the total number of choices need be made: the  s represent choices which are left open. because of this we are often able to insist on validity of the states in the initial population  with respect to the given constraints . hence  no domain becomes empty as a result of the choices present in the individual. in our experiments  only a small amount of back-tracking was the price to be paid. 
1. fitness calculation 
we define the fitness of a search state as the value of the objective function for the best solution which can be reached from it through further assignments. obviously  an exhaustive search through the set of potential solutions will often be far too expensive. hence  we explore only an h priori determined number of  randomly chosen search paths . the constraint network corresponding with the search state to be evaluated is used as a starting point for each search path. each path consists of a number of selection-assignment-propagation cycles. the random selection mechanism accounts for the random nature of the search process whereas the propagation enforces consistency between the choices. search along a path stops when a  all domains are reduced to a singleton  i.e. a solution has been found  or b  propagation results in an empty domain  i.e. no valid solution exists for the choices made so far. we can effectively say that the searches explore the regions around a given search state. we define the fitness of a search state as the value of the objective function of the best solution found. obviously  there is no guarantee that a valid solution will be found during the random searches starting at a given state. it is useful to give such states a  low  fitness. this fitness value should reflect the usefulness of the individual choices made to reach this state so that recombination can make use of valuable genetic material. we will see examples of this later. 
     the fewer  s in a search state description the higher the probability that the searches find the same solutions. in the limit  every search starting from a fully instantiated search state - containing no  s - always returns the same solution: itself. in order to provide selective pressure towards states containing fewer  s  a secondary criterion is used to order states for which the best search yields the same quality. in that case  the state from which this solution quality is found most often is considered the fittest. hence  this state is inserted before the other one in the sorted population. 
     notice that the fitness value is a lower bound for the best solution which can be reached from the search state. it is important to stress here the usefulness of the propagation. it considerably limits the chances of ending up in a dead end. hence  the chances of finding valid solutions are much higher than when no propagation were used. this way the promise of the state is estimated more reliably. the empirical comparisons later in this paper demonstrate this. 
1. the genetic operators 
let us now look how crossover can be augmented through the use of constraints. as discussed above  there is no guarantee that combining choices of two  good  search states yields a search state from which a solution can be reached. gsss uses constraint checking to remove inconsistencies introduced by crossover. figure 1 illustrates this mechanism on a problem where the constraints require that all  eight  variables get a different value. in a first step  a  one-point  crossover operator generates the pig-string   1   1. in this case  the randomly chosen crossover point is located after the fourth element. obviously  the search state represented by this string cannot be expanded into a valid solution because of the two 1s. that is why a second step - constraint checking - is added. starting from the initial constraint network the following process is repeated. first  one of the assignments in the pig-string is randomly chosen. this assignment 
	paredis 	1 

is then done  i.e. the corresponding domain is reduced to a singleton. next  propagation is activated. this process is repeated for all assignments in the string in random order. each time a domain becomes empty the last assignment is discarded  i.e. the constraint network is restored to its state before that assignment. furthermore  that last assignment is also deleted from the search state description. as a result  only a set of assignments mutually consistent with the constraints is retained. that is why  in our example  constraint checking only retains one 1  see figure 1 . notice the generality of this approach: it is independent of the particular crossover used. as a matter of fact  it consists of a general genetic repair method for search states. 
the first line above prohibits two queens to be placed in the same row. the second ensures that no two queens are on a same diagonal. note that the column constraint  only one queen is allowed per column  is implicit in the representation. 
     in order to turn the n-queens problem into an optimization problem we randomly assign a real number between 1 and 1 to each of the locations on the board. the cop-variant of the n-queens problem can now be described as follows: find a solution to the n-queens problem such that the sum of the values associated with the n locations where the queens are positioned is maximized. 


     finally  mutation is applied to the result of crossover. the probability of mutating a pig-string element is proportional to  n - difo/n1. where n is the length of the string  i.e. the number of variables   and diff is the number of locations on the pig-string which are different for both parents. mutation changes a   in an element randomly chosen from the domain of the corresponding variable. values  on the other hand  are replaced by another randomly selected value from the domain or by a  . 
1. an empirical study 
in this section  we introduce the bench-mark problem - an optimization variant of the well known n-queens problem - that allows us to illustrate our approach and to test it empirically. the n-queens problem consists of placing n queens on a nxn chess board so that no two queens attack each other  i.e. they are not in the same row  column  or diagonal . a typical constraint programming representation of this problem uses n variables xi. each variable represents one column on the chess board. the assignment x1 indicates that a queen is positioned in the third row of the second column. initially  the domains associated with the xi are instantiated to {1  ... n . the constraints for this problem are simple: 

machine learning 
     we concentrate here on 1-queens cops. the members of the initial population contain 1 assignments  and hence also 1  s. furthermore  1 searches are done to evaluate a state. the objective function for a valid solution is the sum of the values associated with the 1 locations where the queens are positioned. for invalid solutions this sum is divided by two. in the latter case  only the assigned variables contribute to the fitness. this way  the fitness value also yields information on sets of good locations even when none of the 1 searches find a valid solution. 
     in order to allow for empirical comparison we construct a  constraint-free  algorithm for the three components described above. for the generation of the initial population and the calculation of the fitness we simply drop the propagation from the selection-assignment-propagation cycle. this way the value-assignments in the initial individuals are randomly drawn from the initial domains  i.e. no consistency is enforced between the choices. obviously  this algorithm often generates invalid search states which cannot be completed into valid solutions. 
     the constraint-free version of fitness calculation starts with the constraint network corresponding with the search state to be evaluated. the domains in this network reflect the assignments of the search state and the reductions resulting from propagation. during the 1 searches no further propagation is done  i.e. the domains are not changed anymore. or  in other words  the domains - from which the values are chosen - do not reflect the choices made during the search. 
     the last constraint-free component involves the genetic operators. we used the same mutation operator as described above  only crossover is changed. it uses a conventional operator  here one-point  without constraint checking. 
     up to now we introduced six algorithms. let us call these i+  f+  o+  i-  f-  o-. the letters i  f  and o refer to the component  i.e. the creation of the initial population  the calculation of the fitness  and the application of the genetic operators. a minus refers to the variant 

which uses no constraints  whereas a plus refers to the algorithm which does use constraints. a triplet consisting of one i  one f and one o algorithm represents a ga. we use i-f-o-   the constraint-free ga   as a baseline for comparison. 
     figure 1 depicts the results of our tests. the xaxis of this graph represents the number of offspring generated. the y-axis represents the average best-sofar fitness value  i.e. the fitness value of the best search state found so far averaged over 1 runs. all test runs use a population size of 1 and generate 1 offspring. performance data is collected every time fifty children have been generated. 

     a couple of interesting observations can be made from figure 1. the performance of i+f+o+ and i-f+o+ is virtually the same. although the difference in the average value of the best element of the initial population is quite large  1 for i+f+o+  only 1 for if+o+  this difference has virtually disappeared after the creation of 1 children  1 versus 1 . this because i- is unlikely to generate valid search states. hence the low fitness value of the individuals in the initial population. the crossover of i-f+o+  however  ensures validity of the offspring with respect to the constraints. hence  the performance of both algorithms quickly becomes similar. from this one can conclude that it is not worthwhile to insist on validity of the members in the initial population. these initial individuals only seem to act as a source of genetic diversity. 
     the performance of two other gas  i+f-o+ and i+f+o-  demonstrate the pay-off of using constraints during the calculation of the fitness and the genetic operators  respectively. the average best-so-far of i+fo+ after the creation of 1 children is considerably lower than that of the initial population of i+f+o- and i+f+o+  see figure 1 . this because the random searches of f- are unlikely to find a valid - let alone an optimal - solution. hence  i+f-o+ often considerably underestimates the fitness value of a search state. as a result many individuals from which good solutions can be reached may not get the chance to reproduce at all. or  in other words  their genes might be lost. this lack of focus during the genetic search not only causes a low average quality of solution. it is also responsible for the large variation between the best solution quality found in different runs. the standard deviation of the best-so-far at the end of each of the 1 runs is 1 and 1 for i+f+o+ and i+f-o+  respectively  see table 1 . this while their average best-so-far equals to 1 and 1  respectively! some of the runs of i+f-o+ did not even find any valid solution during the generation of 1 offspring. table 1 also shows an average increase in solution quality of 1% when constraint checking is used during crossover  the average best so far of i+f+o+ and i+f+o- is 1 and 1  respectively. 

1. job shop scheduling 
the general framework described in this paper grew out of earlier work on the use of constraint programming for scheduling  paredis and van rij 1 . paredis  describes an interesting modification to the general approach described here. it takes into ac-
count the volatile environment in which scheduling takes place: orders may be cancelled  machine breakdowns may occur etc. in such a volatile environment one should be able to reactively revise schedules in response to unexpected events. instead of putting a large effort in finding one optimal schedule  we aim at finding states from which a number of different good schedules can be reached. whenever one cannot stick to a given good schedule  then one can - to some extent at least - search locally around these states for another feasible schedule. in order to achieve this the fitness calculation takes into account not only the best solution found during the random searches but also the number of different solutions and the average quality of the solutions. by changing the relative importance of these features the search process explores other regions of the search space trading off the density and variation of solutions  the quality of the best solution  and the average quality of the solutions. 
	paredis 	1 

1. discussion 
in the previous sections we saw that the combination of constraint programming and gas considerably enhances the solution quality. here  we investigate the differences between our approach and standard gas. 
     holland showed that for problems with a moderate degree of epistasis  operators that splice together parts of two different individuals might yield good solutions. for such problems  sets of functionally dependent genes are relatively small. in that case  it becomes possible to use a string representation in which  correlated  genes are placed close to each other. once the ga finds good values for these genes  they are unlikely to be split apart during sexual reproduction. analogously  independent genes should be located far apart from each other on the string. otherwise there will be too little exploration: suboptimal values for these genes are unlikely to become disrupted. this typically results in premature convergence. in general  a linear string might not be sufficient to place interacting bits close to each other  and to place non-interacting bits far apart. this is particularly the case when addressing problems with a high degree of epistasis. 
     our approach is aimed at a large class of combinatorial problems which can be stated in terms of constraints. no search control knowledge is needed. the knowledge present in the problem specification is fully exploited through the constraints. we still use the standard linear representation. but now dependence need not necessarily be translated into physical proximity. the use of constraint propagation allows the ga to take into account long-distance interactions. the constraints represent the epistatic linkages. 
     there is an additional remark to be made here: the degree of interaction between a group of  genes  is not necessarily constant over the entire search space. our algorithm operates on search states with different levels of instantiation. hence  it searches at different hierarchical levels. at different levels  different dependencies may dominate. the opposite goes as well: the tightness of a dependency often depends on the assignments in the search state. the standard static linear representation is unlikely to be able to cater for these changing dependencies in an adequate way. here again  the constraints explicitly enforce the relevant dependencies even when they span a wide distance in the genetic representation. 
1. conclusion. 
gsss combines the advantages of both: gas and constraint programming. gas have proven to be good search algorithms for large  moderately epistatic  problems. hence  we use genetic search to explore the large search spaces of cops. a more thorough explo-
machine learning 
ration of the region around a search state is done through constraint-based search. furthermore  domain knowledge in the form of constraints allows the ga to deal with higher degrees of epistasis. 
     we presented a genetic representation for search states of cops which allows for the combination of both paradigms: genetic search and constraint programming. next  we discussed the incorporation of constraints in three components of a ga. our empirical study clearly shows the advantage of the use of constraints during the fitness calculation and during reproduction. especially  the former plays a crucial role in obtaining an efficient hierarchical search. 
