 
the aim of this paper is to provide a sound framework for addressing a difficult problem: the automatic construction of an autonomous agent's modular architecture. we briefly present two apparently uncorrelated frameworks: autonomous planning through markov decision processes and kernel clustering. our fundamental idea is that the former addresses autonomy whereas the latter allows to tackle self-organizing issues. relying on both frameworks  we show that modular selforganization can be formalized as a clustering problem in the space of mdps. we derive a modular self-organizing algorithm in which an autonomous agent learns to efficiently spread n planning problems over m initially blank modules with rn   n. 
introduction 
this paper addresses the problem of building a long-living autonomous agent; by long-living  we mean that this agent has a large number of relatively complex and varying tasks to perform. biology suggests some ideas about the way animals deal with a variety of tasks: brains are made of specialized and complementary areas/modules; skills arc spread over modules. on the one hand  distributing functions and representations has immediate advantages: parallel processing implies reaction speed-up; a relative independence between modules gives more robustness. both properties might clearly increase the agent's efficiency. on the other hand  the fact of distributing a system raises a fundamental issue: how does the organization process of the modules happen during the life-time   
　there has been much research about the design of modular intelligent architectures  e.g.  theocharous et al  1j  hauskrechtef a/.  1   kaelbling  1  . it is nevertheless very often the  human  designer who decides the way modules are connected to each other and how they behave with respect to the others. few works study the construction of these modules. to our knowledge  there are no effective works about modular self-organisation except for reactive tasks  stimulus-response associations   e.g.  jacobs et al.  1   digney  1  . 
　this paper proposes an algorithm by which the organization of an agent in functional modules is automatically computed. the most significant aspect of our work is that the number m of modules is fewer than the number n of tasks to be performed. therefore  the approach we propose involves a high-level clustering process  in which the n tasks need to be  properly  spread over the m modules. 
　section 1 introduces what we consider as the theoretical foundation for modelling a mono-task autonomous agent: markov decision processes. section 1 presents the kernel clustering approach: we consider this approach as a theoretical basis for addressing self-organization. finally  section 1 combines both domains in order to propose a modular selforganizing algorithm. 
1 	modelling a mono-task autonomous agent 
markov decision processes  puterman  1  provide the theoretical foundations of challenging problems such as planning under uncertainty and reinforcement learning  sutton and barto  1 . they stand for a fundamental model for sequential decision making and they have been applied to many real worls problems  sutton  1 . this section describes this formalism and presents a general scheme for approaching difficult problems  that is problems in large domains . 
　a markov decision process  mdp  is a controlled stochastic process satisfying the markov property with rewards  numerical values  assigned to state-control pairs. formally  an mdp is a four-tuple  s  a  t  r  where s is the state space  a is the action space  t is the transition function and r. is the reward function. t is the state-transition probability distribution conditioned by the control: 
 1 
　the usual mdp problem consists in finding an optimal policy  that is a mapping : s a from states to actions  that maximises the following performance criterion  also called value function of policy tt: 
1 	poster papers 		 1  
it is shown that there exists a unique optimal value function v*; once v* is computed  an optimal policy can immediately be derived  e.g. see  puterman  1  . 
　in brief  solving an mdp problem amounts to computing the optimal value function. well-known algorithms for doing so are value iteration and policy iteration  see  puterman  1  . their temporal complexity dramatically grows with the number of states  littman et al  1   so they can only be applied in small domains. 
　in large domains  it is impossible to solve an mdp exactly  so one usually adresses a complexity/quality compromis through an approximation scheme. ideally  an approximation scheme for mdps should consist of a set of tractable algorithms for 
  computing an approximate optimal value function 
  evaluating  an upper bound of  the approximation error 
  improving the quality of approximation  by reducing the approximation error  while constraining the complexity. 
the first two points are the fundamental theoretical bases for sound approximation. the third one is often interpreted as a learning process and corresponds to what most machine learning researchers study. for convenience  we respectively call these three procedures appproximate    error    and learn  . then  the practical use of an approximate scheme can be sketched by algorithm 1. one successively applies the 
lcarn   procedure in order to minimize the approximation error; when this is done  one can compute a good approximate optimal value function. 
1 	kernel clustering 
before addressing the problem of modular self-organization  we need to present the kernel clustering paradigm. in  diday  1   the author introduces the kernel clustering approach as an abstract generalization of vector quantization. indeed  the author argues that  in general  a clustering problem is based on three elements: 
  a set of data points taken from a data space a  
  a set of kernels taken from a kernel space 
  a distance measure between any data point and any kernel. the smaller the distance d x  l   the more l is representative of the point x. 
given a set of kernels  a data point x is naturally associated to its most representative kernel l{x   i.e. the one that is the closest according to distance d: 
conversely  a set of kernels partition of the data set each class corresponding to a kernel: 
		 1  
　given a data space  a data set  a kernel space and a distance d    the goal of the kernel clustering problem is to find the that minimizes the distortion d 
 1  
a general procedure for suboptimally solving this problem is known as the dynamic cluster algorithm  diday  1  which we present in an online version in algorithm 1. it is a very intuitive process: for each piece of data x  one finds its most representative kernel l  and one updates l so that it gets even more representative of x. little by little  one might expect that such a procedure will minimize the global distortion and eventually give a good clustering. 
1 	modular self-organization 
this final section shows how the kernel clustering paradigm can be used to formalize a modular self-organization problem in the mdp framework  the algorithmic solution of which will be given by the on-line dynamic cluster procedure  algorithm 1 . 
　if one carefully compares the general learning scheme we have described in order to address a large state space mdp  algorithm 1  and the on-line dynamic cluster procedure  algorithm 1   one can see that the former is a specific case of the latter. more precisely  algorithm 1 solves a simple kernel clustering problem where 
poster papers 	1   the data space is the space of all possible mdps and the data set is a unique task corresponding to an mdp m 
  the kernel space is the space of all possible approxima-tions and there is one and only one kernel:  
  the distance d is the error   function. 
　it is then straightforward to extend this simple clustering problem to a more general one  with n tasks/data points and m approximate models/kernels . given a set of m approximate models }  an mdp is naturally associated to the approximate model that makes the smallest error: 
 1  
as before  a set of approximate models 	nat-
urally induces a partition of any set of n mdps 
into m classes each class corresponding to an approximate model: 
  1  
　the transpositon of the on-line dynamic cluster algorithm into the mdp framework  algorithm 1  therefore allows to find a set of m approximate models that globally minimize the approximation error for n mdps: 


order to efficiently solve n tasks  or  as we might say  it selforganizes the m modules in order to improve the resolution of the n tasks. 
conclusion 
in this paper  we have described a general scheme for addressing large state space markov decision processes. we have then showed how such an approach could be extended to an interesting problem: modular self-organization. indeed  we have formalized modular self-organization as a clustering problem in the space of mdps. a natural algorithmic solution to this clustering problem  algorithm 1  uses an on-line version of the dynamic cluster algorithm  algorithm 1 . due to lack of space  we could not show any experimental evaluation; interested readers will find some in  scherrer  1bl and  scherrer  1a . 
