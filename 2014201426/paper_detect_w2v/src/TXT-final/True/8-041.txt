computer simulation of articulatory activity in 
speech production 
	p. 	m e r m e l s t e i n 
	b e l l 	telephone 	l a b o r a t o r i e s   	i n c o r p o r a t e d 
	murray h i l l   	new jersey 

       a computer f a c i l i t y f o r m o d e l i n g 
       sound p r o d u c t i o n r e s u l t i n g from e x c i t i n g a 
moving a r t i c u l a t o r y system i s d e s c r i b e d . the v o c a l t r a c t is t r e a t e d as an a c o u s t i c t r a n s m i s s i o n l i n e w i t h v a r i a b l e c r o s s s e c t i o n a l a r e a . the system a l l o w s o n - l i n e 
s p e c i f i c a t i o n o f the h i s t o r y o f a r t l c u l a t o r y s t a t e s   v o c a l - t r a c t shapes  and e x c i t a t i o n p a r a m e t e r s   and g e n e r a t e s the r e s u l t a n t a c o u s t i c s i g n a l f o r immediate e v a l u a t i o n by the e x p e r i m e n t e r . novel f e a t u r e s i n c l u d e g r a p h i c a l as w e l l as n u m e r i c a l c o n t r o l o f a r t i c u l a t o r y c o n f i g u r a t i o n s   t i m e - m o t i o n d i s p l a y o f a r t i c u l a t o r y d a t a and r e s o n a n t - f r e q u e n c y versus time d i s p l a y s f o r the r e s u l t i n g a c o u s t i c s i g n a l . the f a c i l i t y i s used f o r the s t u d y o f the dynamics o f a r t i c u l a t o r y movement and f o r speech s y n t h e s i s . 
i n t r o d u c t i o n 
       in m o d e l i n g the process of human speech p r o d u c t i o n we r e c o g n i z e f i v e d i s t i n c t s t a g e s . f i r s t   the message i s o r g a n i z e d on the l i n g u i s t i c l e v e l and s t r u c t u r e d g r a m m a t i c a l l y . second  the 
message i s expressed p h o n o l o g i c a l l y i n terms of a sequence of d i s c r e t e u n i t s   l a b e l l e d phonemes. s t r e s s and i n t o n a t i o n marks can be c o n s i d e r e d s p e c i a l phonemes and assigned s p e c i a l codes. t h i r d   the s t r i n g of phonemes is c o n v e r t e d to a set o f c o n t i n u o u s s i g n a l s c o n t r o l l i n g the m u s c u l a t u r e o f the v a r i o u s a r t i c u l a t o r s . t h i s r e s u l t s i n a h i g h l y complex i n t e g r a t e d movement sequence in which genera l l y a l l the a r t i c u l a t o r s   the l i p s   the tongue  the m a n d i b l e   e t c .   p a r t i c i p a t e . f i n a l l y   the p h y s i c a l i n t e r a c t i o n o f the v i b r a t i n g v o c a l cords and the moving a r t i c u l a t o r y s t r u c t u r e produces a c o n t i n u o u s a c o u s t i c s i g n a l p e r c e i v e d as speech. 
       we are p a r t i c u l a r l y i n t e r e s t e d in m o d e l i n g the f o u r t h o r the a r t i c u l a t o r y movement stage of the speech e v e n t . we c o n s i d e r the speech event as composed of a sequence o f p h o n e t i c segments s p e c i f i e d i n terms of one or more v o c a l - t r a c t shapes and the c o r r e s p o n d i n g e x c i t a t i o n p a r a -
m e t e r s . the a c o u s t i c s i g n a l i s generated by s i m u l a t i n g the e x c i t a t i o n mechanism as w e l l a s the a r t i c u l a t o r y t r a j e c t o r y . i n c o n t r a s t   most p r e v i o u s speech p r o d u c t i o n systems c o n s i d e r g e n e r a t i o n of the speech s i g n a l from t h e a c o u s t i c p o i n t o f view and are c o n t r o l l e d b y s p e c i f y i n g the v a r i a t i o n s o f 	v o c a l - t r a c t 	resonant 	f r e q u e n c i e s 
  formant f r e q u e n c i e s   w i t h time.1 m o d e l i n g the process a t the a r t i c u l a t o r y l e v e l can be expected to be s i m p l e r because the a r t i c u l a t o r s respond to muscular f o r c e s w i t h p r e d i c t a b l e changes 
i n t h e i r p o s i t i o n and r a t e s o f movement. on the o t h e r hand  simple r u l e s f o r resonant f r e q u e n c y changes are not necess a r i l y r e a l i z a b l e by the anatomy of the v o c a l t r a c t . i n f a c t   simple a r t i c u l a t o r y changes can have complex a c o u s t i c e f f e c t s . t h i s r e p o r t i s p r i m a r i l y concerned w i t h g e n e r a t i n g the a c o u s t i c s i g n a l c o r r e s p o n d i n g t o g i v e n changes i n the shape of the v o c a l t r a c t . accomplishment of t h a t t a s k is a p r e r e q u i s i t e to s t u d y i n g the movements a c t u a l l y executed by the a r t i c u l a t o r y system when p r o d u c i n g 
a p a r t i c u l a r u t t e r a n c e . 
       recent s t u d i e s show t h a t no phoneme  n o t even the v o w e l s   e x h i b i t s a unique set o f resonant f r e q u e n c i e s i n a l l i t s occurrences in connected speech.1 theref o r e   i t i s unreasonable t o expect t h a t a unique v o c a l - t r a c t shape can be a s s o c i ated w i t h a l l p r o d u c t i o n s o f t h a t phoneme. c e r t a i n a t t r i b u t e s o r d i s t i n c t i v e f e a t u r e s of the e x c i t a t i o n mechanism and of the a r t i c u l a t o r y s t a t e s e r v e   however  t o d i f f e r e n t i a t e among the phonemes. such f e a t u r e s may i n c l u d e presence or absence o f l a b i a l c l o s u r e   o f p e r i o d i c o r t u r b u l e n t e x c i t a t i o n   c o u p l i n g o f the nasal passage t o the main v o c a l t r a c t   e t c . while i n c o r p o r a t i o n o f these f e a t u r e s i n the a r t i c u l a t o r y d e s c r i p t i o n i s necessary t o o b t a i n a n i n t e l l i g i b l e r e s u l t   i t i s n o t s u f f i c i e n t . the human speech p e r c e p t i o n apparatus i s e a s i l y confused b y f a l s e cues t h a t a r i s e from u n n a t u r a l a r t i c u l a t i o n s . t h e r e f o r e   those p a r a meters u n s p e c i f i e d b y the d i s t i n c t i v e f e a t u r e s of the phoneme must be s p e c i f i e d w i t h r e f e r e n c e t o the moving a r t i c u l a t o r y s t r u c t u r e s o t h a t the r e s u l t w i l l correspond t o the n a t u r a l e x e c u t i o n o f the a r t i c u l a t i o n . c o n t e x t u a l e f f e c t s such a s a n t i c i p a t i o n o r i n e r t i a c o n t r o l these o p t i o n a l f e a t u r e s   and one is i n t e r e s t e d i n s p e c i f y i n g i n d e t a i l the n a t u r e o f 
       t h a t c o n t r o l mechanism. 
-1-       i f the e f f e c t s o f c o n t e x t are expressed i n r u l e s f o r a r t i c u l a t o r y movement  o n l y the e s s e n t i a l f e a t u r e s o f the phonemes need be s p e c i f i e d e x p l i c i t l y   
and the optional parameters w i l l be deter-
mined automatically. the simulation system is intended to aid the postulation of such rules by serving as a convenient tool for the evaluation of their articulatory and acoustic effects. this report describes a f a c i l i t y for specifying a discrete sequence of excitation and articulatory states of the vocal tract  and the system simulates the articulatory movement between these states  thus producing a continuous acoustic signal. the segment corresponding to a particular phoneme is represented as a sequence of one or more such states  where the numerical description of the states may be functions of the adjacent phonemes. for example  sustained tongue tip closure in the absence of voicing is a feature of the consonant / t /   but the shape of the tongue hump for that production is controlled by the adjacent vowels. aspiration  another contextdependent feature of the / t /   is achieved by optionally introducing states specifying the onset and termination of turbulent excitation. for the moment  a l l parameters of the excitation and vocal-tract shape must be specified explicitly  or they are assigned fixed default values. 
　　　the timing of articulatory movement can be controlled in open-loop or closedloop modes. the closed-loop mode would require continuous position or velocity feedback; however  the rapidity of the articulatory movement does not allow for this. hence we assume a ballistic-type movement based on the present and the target articulatory positions. the time interval for the movement is explicitly specified  and it is assumed that the forces generated by the musculature are adjusted accordingly. the time durations are in practice functions of the adjacent articulatory states and future models can be expected to compute them from the a r t i culatory specifications. where timing differences arise from causes other than the articulatory context  such as the duration difference in english vowels before voiced and unvoiced consonants  these cannot be handled at the articulatory level and would have to be introduced explicitly even where articulatory movement proceeds completely by rule. 
　　　the speech production apparatus is modeled as consisting of a periodic source of variable frequency and amplitude  the vocal cords  and/or a noise source  exciting a nonuniform acoustic transmission line continuously changing in shape. the shape  of course  controls the characteristic impedance at any point  and thereby the transfer function of the line. a r t i culatory states are represented in terms of sampled values of the vocal-tract cross-sectional area at points along the tract. 
　　　henke has postulated a set of rules governing tongue  l i p and mandible movements based on analyzing frames from highspeed x-ray motion pictures of the moving vocal tract. however  he did not evaluate the resulting speech signal aurally. our data are derived from acoustic measurement of the vocal-tract cross-sectional area1 and admit the postulation of similar rulea this report is primarily concerned with the implementation of a f a c i l i t y for immediate aural evaluation of utterances generated with the aid of postulated rules. comparison of the computed trajectories of the vocal-tract resonant frequencies as functions of time with those measured from natural articulatory events yields a quantitative difference measure that can be used to complement the subjective evaluation of the audio signal. in addition  the specified movements are displayed for evaluation as sagittal projections convenient for comparison with x-ray pictures. 
　　　static electric analogs of the vocal tract1 1 have been used for an extensive period as tools in the study of how deformations in the vocal tract control the characteristics of the speech signal. dynamic electric analogs1 have been used for the synthesis of a restricted number of syllables  but they suffered from an inability to control the transmission-line elements over wide ranges at high speeds. kadokawa and nakatall have simulated the dynamic behavior of the vocal tract by computing a time-dependent transfer function and thus determining the variations with time of the vocal-tract resonant frequencies. coker1 uses a timevarying parametric representation of the vocal tract to compute the changing resonant frequencies and thus control a formant synthesizer. the primary obstacle to the development of a general synthesis f a c i l i t y has been the unavailability of a suitably flexible control system that allows quick and convenient specification or change of the parameters controlling the tract configuration. the computersimulated system not only eliminates limitations to rapid configuration changes over a wide range of cross-sectional area values  but also permits experiments designed to search for convenient control strategies. 
-1-　　　the presence of the human listener in the sound generation - evaluation modification - sound generation feedback loop is necessary because at present we are unable to assign effective objective criteria to the significant attributes of 
the acoustic r e s u l t . naturalness is a subjective c r i t e r i o n   and therefore the presence of the l i s t e n e r is essentia . the experimenter also acts as a visual observer  evaluating shape and resonantfrequency variations with time. we endeavor to f a c i l i t a t e the experimenter's task so that in the l i g h t of his evaluat i o n he can change the data variables quickly and conveniently. this is accomplished by allowing the experimenter to control the simulation using measures f a m i l i a r to him  for example  l i p opening or e x c i t a t i o n frequency. he may b u i l d up the data for an utterance item by item  evaluating the result each time. alternately  he may modify data previously entered and hear the modified audio signal in less than a minute. 
the simulation method 
　　　the simulation principles are based on those used by kelly and lochbaum1 with considerable extensions and modifications. the vocal t r a c t is represented 'as a nonuniform transmission l i n e supporting l o n g i t u d i n a l propagation only. i t s chara c t e r i s t i c impedance at a l l points is inversely proportional to the crosssectional area in a plane perpendicular to the flow l i n e . the tract is assumed hard-
walled ; the compliance of the soft tissues of the t r a c t wall is ignored. the sampling frequency for the simulation  1 khz  is determined by the spacing of area samples  1 cm  that is necessary to simulate the continuous t r a c t up to a signal frequency of 1 khz. since the length of each section is considerably smaller than the wavelength even at t h i s frequency  the effect of the d i s t r i b u t e d 
r e f l e c t i o n of a section traversed by the 
wavefront in one sampling period can be represented by a lumped r e f l e c t i o n c o e f f i cient centered on the section. 
　　　figure 1 shows a block diagram of the v o c a l - t r a c t model. pressure samples propagate back and f o r t h along the transmission l i n e and suffer multiple i n t e r n a l r e f l e c t i o n s . excitation may be periodic  simulating vocal-cord v i b r a t i o n   or t u r bulent corresponding to f r i c a t i o n . for periodic e x c i t a t i o n the samples of the e x c i t a t i o n function are added to the samples of the reflected signal a r r i v i n g at the g l o t t i s . turbulent e x c i t a t i o n may take place at the vocal cords or at any i n t e r i o r section. it is implemented by 
means of a white-noise generator and associated source impedance placed in series with the l i n e . for computational s i m p l i c i t y   the t r a c t is assumed lossless 
w i t h i n i t s i n t e r i o r . simple d i g i t a l f i l t e r s act at the t r a c t boundaries  the vocal cords and the l i p s   to approximate the frequency-dependent losses so that actually measured resonant-frequency bandwidths are properly matched. the g l o t t a l r e f l e c t i o n and the labial radiation functions act essentially as high-pass f i l t e r s ; the l a b i a l r e f l e c t i o n appears as a lowpass f i l t e r . the nasal passage is represented by an additional transmission l i n e of fixed but nonuniform shape coupled to the main tract with the aid of a variable coupling parameter. it serves in the production of nasalized vowels and consonants. the system output is obtained by summing the outputs of d i g i t a l f i l t e r s approximating the free-space radiation characteri s t i c s at the l i p s and n o s t r i l s . radiat i o n through the l i p s i s   of course  cont r o l l e d by the variable l i p area. if the opening is reduced  more of the energy a r r i v i n g at the l i p s is reflected within the t r a c t and less is radiated to the outside. radiation through the tract wall is not e x p l i c i t l y included. 
　　　a r t i c u l a t o r y movement is simulated by defining a sequence of a r t i c u l a t o r y states or targets and i n t e r p o l a t i n g the p o s i t i o n dependent r e f l e c t i o n c o e f f i c i e n t values and oral-nasal coupling between them. thus targets are not necessarily phonemic in nature but may be specified as frequently as desired in order to approximate natural a r t i c u l a t o r y movement as closely as possible. when the a r t i c u l a t o r positions are derived from a model of a r t i c u l a t o r y a c t i v i t y   the vocal-tract shapes computed therefrom are expected to act as the target states of the simulation program. stress and intonation informat i o n are assumed embedded in the excitat i o n frequency and amplitude parameters and w i l l not be discussed here in d e t a i l . 
　　　linear i n t e r p o l a t i o n of the r e f l e c t i o n - c o e f f i c i e n t values implies that near sharp constrictions the area varies l i n e a r l y with time  but where the area changes s l i g h t l y or the reflections are small  the areas vary exponentially with time. the resonant-frequency curves 
r e s u l t i n g from t h i s procedure resemble those observed in spectrograms more closely than the s t r a i g h t - l i n e segments used in most formant synthesizers. 
implementation 
　　　the system is operational on a ddp-1 computer. a l l of the routines are w r i t t e n in fortran  except for the most frequently executed loop of the wave propagation computations which was rewritten in assembly language. among the note-
-1-worthy hardware features u t i l i z e d is the use of input/output channels to feed the loudspeakers through the d i g i t a l - t o - a n a l o g 
converter from one memory module  while simultaneously reading the next record from tape or disk into a second module. 
cathode-ray tube display proceeds simultaneously with processor operations on an interrupt basis. 
　　　the execution time of the simulation is approximately 1 times real time. the sample propagation computations along the transmission line  although basically very simple  are the most time consuming. a special slave processor has been designed to carry out these operations under control of the general purpose computer. if implemented  it would cut the simulation time to four times real time. immediate application to real-time speech synthesis is therefore limited and the system is considered primarily a research tool. 
　　　the excitation period serves as a time clock for the synthesis routine  and within each period parameters or parameter increments remain constant. therefore an excitation period is specified even when the tract is excited by noise or not excited at all as in pauses within the utterance. this alllows a relatively rapid  free-running simulation for 
hundreds of sampling periods before a check is made for new parameter values. 
　　　once the control data have been specified the simulation runs without interaction  and writes the speech output on disk or tape. thus the time duration of speech material generated in any run is limited only by the control table storage limitations and the patience of the experimenter. because the pressure distribution along the vocal tract at any time within the utterance cannot be simply recreated  a change in any one target parameter requires the regeneration of the complete utterance. 
control and use of the simulation facility 
　　　the control parameters for a particular synthesis task are specified in terms of two parameter l i s t s . the f i r s t is a l i s t of articulatory states defined in terms of sets of 1 area values. the second l i s t is a time sequence of targets  nasal coupling values  target interval durations  excitation frequency values  excitation amplitude values  whether periodic or random excitation and if the latter  the place of excitation. targets are specified by using character-string labels as pointers to entries in the table of articulatory states. excitation para-
meters are conveniently separated from specification of the articulatory configurations and each is easily varied inde-
pendently of the other. the same articulatory configuration may be repeatedly called by its label in the second l i s t without having to specify it again in numerical terms. the program supplies default values for most parameters  generally unchanged from the previous specification so that only changing parameters 
need be explicitly specified. targets may be appended  inserted or deleted from the l i s t conveniently and quickly. a typical sentence  the example discussed later  which consists of 1 phonemes required a sequence of 1 articulatory targets for acceptable synthesis. 
　　　the basic mode of data entry is through the on-line typewriter. once a parameter l i s t satisfactory to the experimenter has been entered  the program generates the output signal and records it digitally on tape or disk. because the simulation runs slower than real time  the output signal is converted to analog form and played back only after its generation 
has been completed. 
　　　the above method of operation  though perfectly feasible  is not terribly convenient from the point of view of an experimenter not used to numerical specification of articulatory data. to visualize the articulatory configurations and movements between them  a time-motion display of the articulatory trajectory is projected at a rate proportional to the real-time movement rates specified. any particular configuration may be selected for static display  graphically modified with the aid of a visible pointer  and returned to its slot in the target history of the utterance. 
　　　another display that has found wide application to evaluate the course of articulatory events is one where the sequence of vocal-tract resonant frequencies are displayed on a time base. to ease the computational load  the resonances are computed from the stored shapes!1 rather than the generated signal. this display resembles a conventional spectrogram in appearance. based on his 
wide experience with spectrograms  an experienced speech scientist can rapidly pin-point situations where the acoustic effects of the specified articulatory trajectories deviate appreciably from normal 
patterns. the visual information he obtains thus complements his aural evaluation of the generated utterance. 
-1-　　　let us now consider in detail simulation of the production of the sentence   this is a story about a man.  this sentence was generated through t r i a l and error procedures by modifying shapes derived from x-ray pictures and referring to the natural utterance for timing values. it demonstrates the quality of output available through careful work with the system. no explicit articulatory rules were used in this example. instead the 
experimenter's accumulated knowledge of a r t i c u l a t o r y dynamics and the acoustics of speech production were u t i l i z e d . the automation of t h i s process so that one w i l l not have to resort to t r i a l and error f o r every d i f f e r e n t sentence generated is the next task at hand. 
　　　in figure 1 the spectrograms of the synthetic and natural utterances are com-
pared. we transcribe that sentence in terms of phonemic symbols ais lz a ' s t o r l ''baut   'main/. the apostrophes indicate stress marks which are considered in specifying the excitat i o n frequency and target interval durat i o n data. the e x c i t a t i o n frequency funct i o n for the sentence is obtained by modifying the function determined from the intonation pattern. the e x c i t a t i o n frequency is increased p r i o r to and decreased r e l a t i v e l y more rapidly after stress marks. for the voiced f r i c a t i v e s / $ /  th  and / z / we supply  in addition to periodic e x c i t a t i o n   turbulent e x c i t a t i o n at points 1 cm and 1 cm respectively behind the front end of the t r a c t . in each case the vocal-tract shape is r e l a t i v e l y constricted at that point. the unvoiced f r i c a t i v e / s / is excited by noise only at the same point and using the same v o c a l - t r a c t shape as / z / . the vowels /*/  /   /   / o / and / a t / are p e r i o d i c a l l y excited and have t h e i r a r t i c u l a t o r y configurations shaped by modifying the configuration appropriate for the isolated vowel in accordance with the a r t i c u l a t o r y i n f l u ences of the neighboring consonants. tn t u r n   the vowels are used to control the variable a r t i c u l a t o r y characteristics of the consonants. for example  the a r t i c u l a t i o n of the i n i t i a l / s / is the same as that of the /%/ except where the tongue t i p is raised to produce the c o n s t r i c t i o n . the glide / r / is vowel-like in e x c i t a t i o n and r e t r o f l e x i o n of the tongue is not applied. the diphthong /a c / is generated by l i n e a r r e f l e c t i o n - c o e f f i c i e n t i n t e r polation between bounding target values that are somewhat modified versions of the isolated independent vowels / a / and / u / . the unvoiced stop / t / has a t r a n s i t i o n part to an a r t i c u l a t i o n e x h i b i t i n g almost complete c o n s t r i c t i o n at a point 1 cm from the f r o n t . this constricted a r t i c u l a t o r y state is sustained f o r a 1 msec i n t e r v a l before release. on release a short burst of noise is introduced to simulate a f f r i cation or turbulence; thereafter the amplitude of the periodic e x c i t a t i o n is l i n e a r l y increased from a zero value. the voiced stop / b / has the a r t i c u l a t i o n changing from that of the previous vowel / * / to that of the i n i t i a l part of the f o l l o w i n g diphthong /aur/ while the l i p s are kept almost completely constricted. a very small but f i n i t e l i p opening is helpf u l in simulating the acoustic effects of energy radiated through the walls of the mouth. the nasal consonants /m/ and / n / are produced with the oral t r a c t comp l e t e l y constricted at the l i p s and 1 cm behind them  respectively  but with a high value of nasal coupling. the coupling is reduced but not eliminated for the i n t e r -
vening 	ea/ 	vowel which is thus made nasa1ized. 
　　　one interesting result observed through t r i a l and error experiments is that naturalness is enhanced by avoiding sustained a r t i c u l a t i o n s - those where two adjacement a r t i c u l a t o r y states are specified as i d e n t i c a l . except for the vowels in the stressed syllables and the f r i c a tives  the a r t i c u l a t i o n s are continuously changing. this further invalidates the idea that speech can be produced by concatenating d i f f e r e n t stationary signals. 
conclusions 
　　　the simulation program produces i n t e l l i g i b l e speech if care 	if taken to 
modify a r t i c u l a t o r y shapes  time durations  and excitat ion frequency values to f i t the contextual environment on a level at least as large as the sentence. data appropriate for the production of an isolated word but not for the sentence in which it is embedded may make not only that word  but the complete sentence u n i n t e l l i g i b l e . the q u a l i t y of the mater i a l generated so far can be used as a goal for the quality to be achieved by implementing rules governing the movements of the individual a r t i c u l a t o r s . 
　　　the program uses an e x c i t a t i o n funct i o n that is stored and independent of the vocal-tract shape. the a r t i c u l a t i o n   however  is known to affect both the waveshape and the e x c i t a t i o n frequency.1 the fixed wave-shape independent of frequency is but a rough approximation to the real s i t u a t i o n . detailed simulation of vocalcord movement would  however  increase the execution time of the program by at least a factor of two. because these factors are not central to the aspects of speech generation under consideration at the moment  they have not been included in the present program. 
-1-　　　the vocal t r a c t is assumed lossless in i t s i n t e r i o r   therefore  the resulting resonance bandwidths are fixed functions of frequency and independent of the a r t i c u l a t i o n . the losses in general do depend on the surface area of the t r a c t wall and are thus affected by the shape of the t r a c t in the plane perpendicular to the flow d i r e c t i o n s . the contribution of t h i s factor to lack of naturalness has not been precisely evaluated. 
　　　articulations of / l / and / r /   in particular  often exhibit sidebranches formed by the tongue and the hard palate that cannot be modeled precisely when one treats the vocal tract as one continuous tube. our approximations are therefore expected to lead to differences in the acoustic result and must be recognized as limitations of the model. 
　　　a program that requires explicit specification of a l l articulatory and excitation parameters suited to the particular context cannot be said to exhibit 
extensive a r t i f i c i a l intelligence. instead  the simulation program must be viewed as a framework within which statements regarding articulatory movements can be expressed and evaluated. the framework reported is based on the consideration that utterances are organized on the a r t i culatory level  and that organization can be studied most effectively at the same level. 
　　　our results up to this time concern organization at the lowest level. here articulatory parameters are treated as independent  and interactions between them  except as reflected on the acoustics level  are ignored. for example  the nasal coupling parameter is used to cont r o l nasalization of vowels adjacent to a nasal consonant at the same time as the tongue shape is changing as required for the production of those vowels. thus the adjacent vowels are perceived as nasalized. the production of the same effect on the acoustic level is much more complex. this example substantiates the basic motivation for speech generation through articulatory control  that this direction of attack can unravel the complex organization of the individual phonemes into the integrated utterance. 
