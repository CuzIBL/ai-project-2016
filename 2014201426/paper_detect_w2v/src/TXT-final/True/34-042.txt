 
　　　adaptive production systems are defined and used to illustrate adaptive techniques in production system construction. a learning paradigm is described within the framework of adaptive production systems  and is applied to a simple rote learning task  a nonsense syllable association and discrimination task  and a serial pattern acquisition task. it is shown that with the appropriate production building mechanism  a l l three tasks can be solved using similar adaptive production system 
learning techniques. 
	i. 	introduction 
　　　this paper presents results in the design and use of adaptive production systems  ps's . a ps  newell & simon  1; newell  1  is a collection of production rules  pr's   that i s   conditionaction pairs  c =  a  where the left side is a set of conditions relevant to a data base or working memory  wm  and the right side is a l i s t of actions which can modify wm. the ps's to be discussed are written in pas-ii  waterman & newell  1; waterman  1  and each is a set of ordered pr's. the control cycle consists of selecting one pr from the set and executing its actions. the f i r s t rule  in the ordered set  whose conditions match wm is the one selected. after the actions of the selected rule are executed the cycle repeats. this process continues until no conditions match. 
　　　an adaptive ps is one which can modify its own pr's. there are three ways this can take place: by adding new rules  deleting old rules  and changing existing rules; however  the ps's described here use only addition of new rules. 
　　　we now postulate a common machinery for learning:  1  a ps interpreter for ordered ps's   1  a ps representation for learning programs   1  pr actions for building rules and adding them to the system  and  1  the learning technique of adding new pr's above error-causing rules to correct the errors. three learning tasks are investigated: arithmetic  verbal association  and series completion. 
　　　the programs for the tasks are written as short ps's which access a single wm composed of an ordered set of memory elements  me's . when pr's   f i r e     
i . e .   their actions are executed  they modify wm by adding  deleting  or rearranging me's. such changes may cause different rules to fire on the next cycle and new memory modifications to be made. thus the system uses wm as a buffer for holding i n i t i a l data and intermediate results. most actions modify wm. some modify the ps by assembling wm elements into a pr and adding it to the ps. these actions give the ps i t s self-modification capability. 
　　　the arithmetic task consists of learning to add two integers given only an ordering over the set of integers. from this ordering  pr's which define the successor function are created and then used to calculate the desired sum. the verbal association task is a ps implementation of epam  feigenbaum  1 . instead of growing an epam discrimination net  the system creates a set of pr's equivalent to such a net. the series completion task consists of predicting the next symbols in a sequence  such as aabbaabb.. here pr's are created which represent hypotheses about which symbol contexts lead to which new symbols  i . e .    two a's a l ways lead to a b.  these rules constitute the concept of the series and are used to predict new symbols. 
	i i . 	pas-ii production system 
　　　the pas-ii ps interpreter is modeled after psc  newell  1  1 . pr's in pas consist of condition-action pairs  where the condition side is a set of conditions with implicit member and and functions and the action side is an ordered l i s t of independent actions. a rule to deposit  c  and  d  into wm if it already contains  a  and  b  i s :  a   b  =   dep  c    dep  !     where the action dep deposits its argument into wm. the control cycle of the ps interpreter consists of two mechanisms: recognize and act. a cycle is defined to be a single recognize-act sequence  and is repeated un~ t i l either no rules match wm or a ps halting action is executed. 
　　　recognize. recognize selects a rule to be executed. when many rules match wm a conflict occurs  as recognize must produce one rule for act to work on. conflict resolution consists of applying a scheme to select one rule from those that match wm. the only conflict resolution used here is p r i o r i t y ordering. thus the rule recognized is the highest p r i o r i t y rule whose conditions match wm. 
　　　the match mechanism assumes implicit member and and notation and scans condition elements  ce's  in order from l e f t to right to see if each element is in wm. when a l l the ce's in a rule match corresponding me's  the me's are brought to the front of memory  just before actions are executed  in the order specified in the rule. a me can match only one ce in any rule and the order of the me's does not have to correspond to the order of the ce's. for example  the conditions  a   b  
 a  w i l l match wm;  b   a   a   but not wm:  a   b . a ce w i l l match a me if the me contains a l l items the ce contains  in the same order  starting from the beginning of the me. thus ce  a t  w i l l match me's  a t   and  a t e  but not  a    t a   or   t a t   . the match routine searches for the absence of a me if the ce is preceeded by a minus sign  - . thus  a  -  b  w i l l match wm if it contains  a  but does not contain  b . free variables can be used in the ce's and are denoted x1  x1 ...xn. when a match occurs each item in the me which corresponds to a variable is bound to that variable. for example  
with wm;  a   b l   and pr:  xl   b x1  -   dep x1   xl is bound to a  and x1 to  l . the action taken w i l l be to deposit  l  into wm. 

1 

　　　act. act takes the rule specified by recognize and executes a l l i t s actions  one at a time  in order from l e f t to right. actions in a ps are c r i t i cal since they determine the grain of the system. if the grain is too coarse a single action may embody a l l interesting activity  obscuring it from view. the criterion in defining actions is to make them primitive enough so the ps trace w i l l exhibit the activity deemed interesting. 

　　　the three types of pas actions are: basic  modification  and special  as shown in table 1. they assume wm is an ordered l i s t of me's going from l e f t to right. thus dep places me's into wm at the l e f t   and rep counts me's starting from the l e f t . the modification actions w i l l now be illustrated. 

count and nn are local variables i n i t i a l i z e d to zero and n respectively. count and nn are continuously incremented by one  using the successor function  u n t i l count equals m. at this point the answer is nn. 

1 

　　　ado performs these steps with some differences. first  it has no successor function  so it creates a pr representation of that function. second  once a sum is calculated it adds a rule that produces the answer directly the next time. thus it builds the addition table for integers. 
learns to predict the correct response when giver a stimulus syllable by growing a discrimination net composed of nodes which are tests on the values of certain attributes of the letters in the syllable. responses are stored at the terminal nodes  and are retrieved by sorting the stimuli down the net. a paired associate training sequence for this 

learning task is shown in figure 1. 
1 


i n i t i a l l y wm  here called stm  contains  ready . 
rule 1 fires and the system asks for the stimulus. 
then 1 fires  adding stimulus components to memory. next 1 fires and prints a question mark as the system's reply to the stimulus  adds this reply to memory  and asks for the correct response. 
1 true in ps 
stm:  wrong     resp con   1 p     1 x     1 a    
 stim pax  
1 true in ps 
now inserting 
 i p    -   used   dep  reply con    say con  on line 1 
stm:  1 p     resp con   wrong t   1 x     1 a t  
 stim pax  
　　　since the reply     does not match the response  con   1 fires and changes the label reply to wrong. 
now 1 fires creating rule 1. 

　　　before the second pair of syllables is presented  memory is i n i t i a l i z e d back to  ready   and the system is restarted. again 1 and 1 are fired to obtain and perceive the stimulus. but now 1 matches wm and causes  1 p    to be marked used  and the system to reply con and add the reply to memory. this is an example of stimulus generalization: the system confused pum with pax since it was only noticing f i r s t letters. 

　　　now memory contains a reply but no response  so 1 fires and e l i c i t s the correct response  jes  from the user. 	rule 1 f i r e s   since the reply differs from the response  marking the reply wrong. next 1 fires  changing the used label to cond. finally 1 fires and creates a new rule with two condition elements  one from the cond already in memory and one from the cond inserted by rule 1  the two rules just added are: 

pax w i l l now e l i c i t the response con  and pum the response jes  as desired. 
　　　epam1. figure 1 shows epam1. this complete version of epam grows a ps in which response cues rather than complete responses are stored in some terminal nodes. these cues   i . e .   c n  are retrieved by dropping the stimulus through the net  
and are then themselves dropped through the net to retrieve the responses stored in other terminal nodes. 


1 


　　　epam1 was given the stimulus-response pairs of figure 1 and produced the output shown in 
figure 1. there were two instances of stimulus generalization  two of response generalization  one of both stimulus and response generalization  and two of stimulus-response confusion. 

　　　the pr's learned by epam1 and the corresponding discrimination net are shown in shorthand notation* in figure 1. note that the condition elements are analogous to intermediate nodes and the response elements to the terminal nodes in the net  and the path through the net from the top to a terminal node corresponds to the sequence of conditions tested in the ps to obtain a response 
*conditions  l i k e  1 p   are elements denoting a l e t t e r and i t s location in the s y l l a b l e   and are 
ordered   f i r s t   t h i r d   second  according to s y l lable l o c a t i o n . actions are response words l i k e con  or p a r t i a l response cues l i k e  1 m . 
1 

	v. 	production system for series completion 
computer models of series completion  simon 1 
kotovsky  1; klahr & wallace  1; williams  
1  have been complex programs with structures quite dissimilar from those of more basic learning models. here we provide a common structure for these learning tasks. the essence of their commona l i t y is  1  an ordered ps representation of what is learned  and  1   the technique of adding new pr's above the error-causing rules to correct errors a ps w i l l now be described which can solve complex letter series completion tasks which require the use of same  successor  or predecessor operations on the alphabet. 
learning technique 
　　　pr's are created which represent hypotheses about what symbols come next given a current context of symbols. these hypotheses are tested by checking the given series to see if the current set of pr's  the learned ps  correctly predicts each symbol in the series given the partial series up to that symbol. when every symbol is correctly predicted  the system uses the learned ps and the entire problem series to predict the next symbol in the series. 
　　　for the series cabcab the rule c a -   b would be learned. this means   i f the last two letters of the partial series are ca  the next is b.  before being added to the system  rules are generalized to take into account the relevant letter relationships. the problem is that rules can be generalized many ways  each being a hypothesis about which letter relationships are relevant for the series. the variations on c a -  b are shown 
below. 

　　　the f i r s t rule above means  any letter followed by a leads to b   the second is  c followed by any letter leads to b   and the third  any letter followed by a leads to the predecessor of that l e t t e r .   
　　　if for every new rule the system a r b i t r a r i l y picked a generalization  intending to backtrack to try the others when an error occurred  a huge tree of possibilities would be generated  making the problem unsolvable. the solution is to use tree-pruning heuristics to l i m i t the number of generalizations at each step. the ps to be described uses one powerful heuristic  the template heuristic. 


1 

     the template heuristic consists of hypothesizing period size  and recognizing only relations between letters which occupy the same relative position within the period  while generalizing on all letters. for example  if given the series acaba with period 1  then the relations looked for are shown by the arrows below. 

     learning proceeds as follows: period size is hypothesized and the series goes through a partition-prediction cycle. generalized rules are added  and the cycle is performed once for each period hypothesis. a period hypothesis is false if: 
 1  no relation is found between letters occupying the same relative position within the period 
or  1  the number of inter-period rules added exceeds the period size hypothesis. 
　　　when the period hypothesis is false  it is increased by 1  and the cycle starts over. table 1 shows this procedure for the series abhbcicd. in line 1 we see the default rule x1 -  x1  always considered to generate an error  and the partitioned series. everything to the left of the slash  /  is the current context. context a is dropped through the rules and a is predicted. this is not valid  -   as the actual next letter is b. now the system takes context a and next letter b to form a -. b  generalizes it to get 
x1 -  x1'  and places it above the error-causing  default  rule as shown. in line 1 the number of rules added  1  exceeds the period size hypothesis 
 1  so a new size hypothesis  1  is made in line 1 in line 1 the rule cannot be generalized since no relation can be found between a and h*  thus size 1 is hypothesized in line 1. line 1 completes the learning cycle and line 1 illustrates the ps 
making i t s f i r s t actual extension to the series. the concept of the series is now embodied in the numbered rules  the inter-period rules . thus we say that xl x1 x1 -  x1' is the concept learned by the system  and the series predicted by this concept is abhbcicdjdek... . 
production system 
　　　figure 1 shows the ps for letter series completion. rules 1 and 1 provide i n i t i a l i z a t i o n   rule 1 acts as the default rule  and rule 1 adds productions to the system. figure 1 shows concepts learned using the 1 series from simon and kotovsky  1 . the correct predictions are made in a l l cases. for more on serial pattern acquisition see waterman  1 . 
 the system does not search for relations higher than triple predecessor or successor. 
1 

v i . 	conclusion 	acknowledgments 

　　　the pas-ii system has been described and used to i l l u s t r a t e adaptive techniques in production system construction. the focus has been on the machinery needed to implement s e l f - m o d i f i c a t i o n w i t h i n a ps framework. it has been demonstrated that using a simple production b u i l d i n g action in an ordered ps leads to r e l a t i v e l y short  s t r a i g h t forward programs. 
　　　moreover  it has been shown that one can create a learning paradigm which applies to  1  simple rote learning tasks such as learning the addition t a b l e    1  more involved learning tasks l i k e nonsense s y l lable association and d i s c r i m i n a t i o n   and  1  com-
plex induction tasks such as inducing the concept of a s e r i a l p a t t e r n . in a l l three cases the paradigm consisted of creating an ordered ps represent a t i o n of the concept learned by adding new pr's  or hypotheses  above the error-causing r u l e s . 
　　　adaptive ps's are q u i t e parsimonious; that i s   the system which learns the concept is represented in the same way as the concept being learned. both are represented as pr's in a single ps. this e l i m inates the need f o r two types of control in the system; one f o r a c t i v a t i n g the learning mechanism and another f o r accessing the concept learned. the concepts learned are not passive  s t a t i c structures 
which must be given a special i n t e r p r e t a t i o n   but rather are self-contained programs which are executed automatically in the course of executing the learning mechanism. 
　　　the add ps is somewhat d i f f e r e n t from the ps's f o r verbal learning or sequence p r e d i c t i o n . this is because add is self-modifying but not r e a l l y adaptive in the s t r i c t sense of the word. it creates new r u l e s   not on the basis of external feedback  but rather on the basis of i n t e r n a l information  i . e .   the ordering on the set of integers. furthermore  rules are added only when needed to solve the problem at hand. this is a good example of an e x p l i c i t view of predetermined developmental p o t e n t i a l . the system has the capa c i t y to develop the addition table or the successor function on integers but does so only when the environment demands i t . 
     the epam and series completion ps's are extremely compact pieces of code which perform sizable amounts of information processing. their power comes from the strong pattern matching capa b i l i t i e s inherent in the ps i n t e r p r e t e r and from the p r i m i t i v e but highly useful memory modification and system b u i l d i n g actions employed. the compactness is due  in p a r t   to the use of ordered pr's  since much information concerning r u l e applicab i l i t y i s i m p l i c i t i n the location o f the r u l e s . with ordered rules the system can use the simple h e u r i s t i c  add a new rule immediately above the one that made the e r r o r   to great advantage. 
     f i n a l l y   the analogy between an ordered ps and a d i s c r i m i n a t i o n net has been made clear  i . e .   that the condition elements are non-terminal nodes in the net  the action elements are terminal nodes  and the searches through the conditions in the ps are analogous to the paths from the top element to the terminal elements in the net. 
　　　the author thanks david klahr  dick hayes  herbert simon  and allen newell for t h e i r suggestions concerning t h i s paper. this work was supported by nih mh-1  and by arpa  1-1 . 
