
multi-context systems  mcs  represent contextual information flow. we show that the semantics of an mcs is completely determined by the information that is obtained when simulating the mcs  in such a way that a minimal amount of information is deduced at each step of the simulation.
in mcs  the acquisition of new information is based on the presence of other information only. we give a generalized account to model situations in which information can be obtained as a result of the absence of other information as well.
1 introduction
based on motivational papers by mccarthy  and giunchiglia  several formalizations of contextual information and inter-contextual information flow have been proposed. most notable are the propositional logic of context developed by mccarthy  buvac and mason¡¦  1; 1   and the multi-context systems devised by giunchiglia and serafini   which later have been associated with the local model semantics introduced by giunchiglia and ghidini . serafini and bouquet  have argued from a technical point of view that multi-context systems constitute the most general formal framework. this conclusion is supported by a more conceptual argument of benerecetti et.al. .
¡¡a multi-context system describes the information available in a number of contexts  i.e.  to a number of people / agents / databases  etc.  and specifies the information flow between those contexts. the local model semantics defines a system to entail a piece of information  if and only if that piece of information is acquired  independently of how the information flow described by the system is accomplished.
¡¡our first contribution is based on the observation that the local model semantics of a multi-context system is completely determined by the information that is obtained when simulating the information flow specified by the system  in such a way that a minimal amount of information is deduced at each step of the simulation. we define an operator which suitably implements such a simulation  and thus determines the information entailed by the system. this operator constitutes a first constructive account of the local model semantics.
¡¡our second contribution is based on the observation that in multi-context systems  new information is derived based on the presence of other information only. however  in many natural situations  concrete examples will be given below   new information is obtained due to a lack of other information. we propose a generalized framework so as to account for such situations. non-monotonic reasoning techniques are applied to formulate a suitable semantics for this framework.
¡¡we proceed  in section 1  with a brief review of multicontext system syntax and local model semantics. minimality is discussed in section 1  and the generalized framework is presented in section 1. we conclude  in section 1  with a concise recapitulation of our main observations and results.1
1 preliminaries
mr.1mr. 1
figure 1: a magic box.
¡¡a simple illustration of the main intuitions underlying the multi-context system framework is provided by the situation depicted in figure 1. two agents  mr.1 and mr.1  are looking at a box from different angles. the box is called magic  because neither mr.1 nor mr.1 can make out its depth. as some sections of the box are out of sight  both agents have partial information about the box. to express this information  mr.1 only uses proposition letters l  there is a ball on the left  and r  there is a ball on the right   while mr.1 also uses a third proposition letter c  there is a ball in the center .
¡¡in general  we consider a set of contexts i  and a language li for each context i ¡Ê i. we assume i and {li}i¡Êi to be fixed  unless specified otherwise. moreover  for the purpose of this paper we assume each li to be built over a finite set of proposition letters  using standard propositional connectives.
¡¡to state that the information expressed by a formula   ¡Ê li is established in context i we use so-called labeled formulas of the form i :    if no ambiguity arises  we simply refer to labeled formulas as formulas  and we even use capital letters f  g  and h to denote labeled formulas  if the context label is irrelevant . a rule r is an expression of the form:
	f ¡û g1 ¡Ä ... ¡Ä gn	 1 
where f and all g's are labeled formulas; f is called the consequence of r and is denoted by cons r ; all g's are called premises of r and together make up the set prem r . rules without premises are called facts. rules with at least one premiss are called bridge rules. a multi-context system  system hereafter  is a finite set of rules. a fact describes information that is established in a certain context  independently of which information is obtained in other contexts. a bridge rule specifies which information is obtained in one context  if other pieces of information are acquired in different contexts. thus a system can be thought of as a specification of contextual information and an inter-contextual information flow.
example 1 the situation in figure 1 can be modeled by the following system:
1 :  r	¡û
1 : l	¡û
1 : l ¡Å r	¡û	1 : l ¡Å c ¡Å r
1 : l ¡Å c ¡Å r	¡û	1 : l ¡Å r
mr.1 knows that there is no ball on the right  mr.1 knows that there is a ball on the left  and if any agent gets to know that there is a ball in the box  then he will inform the other agent.
a classical interpretation m of language li is called a local model of context i. a set of local models is called a local information state. intuitively  every local model in a local information state represents a  possible state of affairs . if a local information state contains exactly one local model  then it represents complete information. if it contains more than one local model  then it represents partial information: more than one state of affairs is considered possible. a distributed information state is a set of local information states  one for each context. in conformity with the literature  we will refer to distributed information states as chains.
example 1 the situation in figure 1  in which mr.1 knows that there is no ball on the right but does not know whether there is a ball on the left  is represented by a chain whose first component   {l  r} { l  r}   contains two local models. as such  the chain reflects mr.1's uncertainty about the left section of the box.
¡¡a chain c satisfies a labeled formula i :    denoted c |= i :    iff all local models in its ith component classically satisfy  . a rule r is applicable with respect to a chain c iff c satisfies every premiss of r. notice that facts are applicable with respect to any chain. a chain c complies with a rule r  iff  whenever r is applicable with respect to c  then c satisfies r's consequence. we call c a solution chain of a system s iff it complies with every rule in s. a formula f is true in s  denoted s |= f  iff every solution chain of s satisfies f.
¡¡let c denote the set of all chains. notice that  as each li is assumed to be built over a finite set of proposition letters  c is assumed to be finite. let c¡Í denote the chain containing every local model of every context  notice that c¡Í does not satisfy any non-tautological expression ; let c  denote the chain containing no local models at all  notice that c  satisfies any expression . if c is a set of chains  then the component-wise union of c is the chain  whose ith component consists of all local models that are in the ith component of some chain in c. if c and c1 are chains  then c   c1 denotes the chain  whose ith component consists of all local models that are in ci but not in. finally  we sometimes say that a local model m is  not  in c  when we actually mean that m is  not  in some  any  component ci of c.
1 minimality
we order chains according to the amount of information they convey. intuitively  the more local models a chain component contains  the more possibilities it permits  so the less informative it is. formally  we say that c is less informative than
   if for every i we have ci   c1i. if  moreover  for at least one i we have  then we say that c is strictly less informative than c1  c   c1 .
lemma 1 let c and c1 be two chains  such that. then any formula that is satisfied by c is also satisfied by c1.
¡¡we call c minimal among a set of chains c  iff c is in c and no other chain c1 in c is strictly less informative than c. in particular  we call c a minimal solution chain of a system s  if it is minimal among the set of all solution chains of s.
theorem 1 every system s has a unique minimal solution chain cs.
proof. let cs be the set of all solution chains of s. cs 1=   as c  ¡Ê cs for any s. let cs be the component-wise union of all chains in cs. then cs ¡Ê cs and  for any c ¡Ê cs. so cs is the unique minimal solution chain of s. 
theorem 1 the semantics of a system s is completely determined by its unique minimal solution chain cs:
	s |= f	 	cs |= f
proof. f is true in s iff f is satisfied by all solution chains of s iff f is satisfied by the component-wise union cs of all
solution chains of s.	
¡¡theorem  1  and  1  are extremely useful  because they establish that  to answer queries about a system s  it is no longer necessary to compute all solution chains of s; we only need to consider the system's minimal solution chain cs.
1 computing the minimal solution chain
the minimal solution chain of s can be characterized as the -least fixpoint of an operator ts  which  intuitively  simulates the information flow specified by s. let s  c  denote the set of rules in s  which are applicable w.r.t. c. then we define:
	ts c  = c   {m |  r ¡Ê s  c  : m 1 cons r }	 1 
¡¡for every rule r in s that is applicable w.r.t. c  ts removes from c all local models that do not satisfy cons r .
intuitively  this corresponds to augmenting c with the information expressed by cons r . in this sense  ts simulates the information flow described by s. as ts c  is obtained from c only by removing local models from it  ts c  is always more informative than c.
¡¡as  forms a complete lattice  and ts is monotone and continuous w.r.t.    tarski  1  yields:
theorem 1 ts has a -least fixpoint  which is obtained after a finite number of consecutive applications of ts to c¡Í.
lemma 1 let c be a chain and let s be a system. then c is a fixpoint of ts if and only if c is a solution chain of s.
theorem 1 let s be a system. then the minimal solution chain cs of s coincides with the -least fixpoint of ts.
¡¡from theorems 1 and 1 we conclude that the minimal solution chain cs of a system s is obtained after a finite number of applications of ts to the least informative chain c¡Í. but we can even prove a slightly stronger result:
theorem 1 let s be a system and let |s| denote the number of bridge rules in s. then the minimal solution chain cs of s is obtained after at most |s| + 1 applications of ts to c¡Í.
¡¡in fact  a slightly more involved  but essentially equivalent procedure was introduced for rather different reasons by roelofsen et.al. . this procedure was shown to have worst-case time complexity o |s|1 ¡Á 1m   where m is the maximum number of propositional variables in either one of the contexts involved in s.
example 1 consider the system from example 1. applying ts to c¡Í establishes the facts given by the first two rules of the system. but then mr.1 knows that there is a ball in the box  so the next application of ts simulates the information flow specified by the third rule of the system: mr.1 informs mr.1 of the presence of the ball. the resulting chain is left unaltered by any further application of ts  and therefore constitutes the minimal solution chain of s. the fact that this chain satisfies the formula 1 : l reflects  as desired  that mr.1 has come to know that there is a ball in the left section of the box.
1 absent information
rules of the form  1  only allow us to model a rather restricted kind of information flow  namely one in which new information is established based on the presence of other information only. there are many natural situations in which information is obtained as a result of the absence of other information. such situations cannot be modeled by the present formalism.
example 1  coordination  let d1 d1 be two meteorological databases that collect their respective data from sensors located in different parts of the country. at the end of the day each database produces a weather forecast based on its own data but also on the information obtained by the other database. for example  d1 predicts rain  if that follows from its own data and if  moreover  d1 does not maintain that it won't rain:
1 : r ¡û 1 : r ¡Ä not 1 :  r
example 1  integration  let d1 and d1 be as in example 1 and let d1 be a third database  which integrates the information obtained in d1 and d1  respectively. any piece of information that is established by d1 and not refuted by d1  or vice
versa  is included in d1:	1 :  	¡û1 :   ¡Ä not 1 :   	1 :  	¡û1 :   ¡Ä not 1 :   example 1  trust  let d1  d1  and d1 be as in example 1. it would be natural for d1 to regard d1 as more trustworthy than d1  or vice versa . in this case any piece of information that is established in d1 is automatically included in d1  but information obtained in d1 is only included in d1 if it is not refuted by d1:
	1 :  	¡û	1 :  
	1 :  	¡û	1 :   ¡Ä not 1 :   
to model these situations we need rules r of the form:
	f ¡û g1 ¡Ä ... ¡Ä gm ¡Ä not h1 ¡Ä ... ¡Ä not hn	 1 
where f  all g's  and all h's are labeled formulas. as before  f is called the consequence of r  cons r  . g1 ... gm are called positive premises of r and together constitute the set prem+ r . h1 ... hn are called negative premises of r and make up the set prem  r . a rule does not necessarily have any premises  m n ¡Ý 1 . in analogy with commonplace terminology in deductive database and logic programming theory  we call such rules normal rules  and finite sets of them normal multi-context systems  normal systems for short . if a rule only has positive premises  we call it a positive rule. note that a system  which consists of positive rules only conforms with the original definition of multi-context systems. from now on we call such systems positive systems.
¡¡our aim is to generalize the result obtained section 1  i.e. to define the semantics of a normal system s in terms of a single canonical chain cs of s  such that  whenever s is a positive system  cs coincides with the minimal solution chain of s.
¡¡a first naive attempt would be to say that a chain c complies with a normal rule r iff it satisfies r's consequence  whenever it satisfies every positive premise of r and does not satisfy any negative premise of r. the  minimal  solution chains of a normal system can then be defined as for positive systems. however  as the following example shows  a normal system does not generally have a unique minimal solution chain  and worse  its minimal solution chains do not generally correspond with its intended meaning.
example 1 let a system s be given by the following rule:
	1 : p	¡û	not 1 : q
then s has two minimal solution chains:

intuitively  s provides no ground for deriving q in context 1. thus  p should be derived in context 1  and every  proper  canonical chain of s should satisfy 1 : p. as cq fails to do so  it should be rejected as such. but how  then  should the canonical chain of a normal system be characterized 
¡¡extensive research efforts have been involved with an analogous question in the setting of logic programming  when  in the late 1's / early 1's  a proper semantics for normal logic programs was sought. in motivating our characterization of canonical chains for normal multi-context systems  we will recall some important intuitions and adapt some crucial definitions that have resulted from these efforts.
¡¡a first desired property of canonical chains  introduced in the setting of logic programming by apt et.al.  and bidoit and froidevaux   is termed supportedness. intuitively  a chain c is a supported solution chain of a normal system s iff  whenever c satisfies a formula f  then s provides an explanation for why this is so.
definition 1 we call a chain c a supported solution chain of a normal system s iff  whenever c satisfies a formula f  then s contains a set r of rules  such that:

example 1 in example 1  as desired  cp is a supported solution chain of s  while cq is not. but both cp and cq are supported solution chains of the following extension s1 of s:
1 : p	¡û	not 1 : q
1 : q	¡û	1 : q
intuitively  cp should be accepted as a canonical chain of s1  but cq should be rejected as such  because the explanation provided by s1 for the fact that cq satisfies 1 : q is circular  i.e.  it relies on the very fact that cq satisfies 1 : q. so  in general  the concept of supportedness does not satisfactorily characterize the canonical chain of a normal system.
¡¡the notion of well-supportedness  first introduced for logic programs by fages   refines the notion of supportedness to avoid the counter-intuitive result obtained in example 1. intuitively  a chain c is a well-supported solution chain of a normal system s iff  whenever c satisfies a formula f  then s provides a non-circular explanation for why this is so.
¡¡fages also proved this notion to be equivalent to the notion of stability  which had been defined somewhat earlier by gelfond and lifschitz . the results obtained in section 1 pave the way for a straightforward adaptation of the notion of stability to our present setting.
definition 1 let c be a chain and s a normal system. define:
	s1 c 	=	{r ¡Ê s |  h ¡Ê prem  r  : c 1 h}
	s1 c 	=	pos s1 c  
where pos s1 c   is obtained from s1 c  by removing all negative premises from its rules. then  c is a stable solution chain of s  iff it is the unique minimal solution chain of s1 c .
¡¡intuitively  a solution chain c of a system s is stable iff  whenever the information represented by c is assumed  then the information flow specified by s reproduces exactly c. namely  if c is assumed to contain valid information  then any rule in s  one of whose negative premises is satisfied by c  is certainly not applicable w.r.t. c. negative premises which are not satisfied by c can be removed from the remaining rules  because they do certainly not inhibit those rules from being applicable w.r.t. c. thus  c is stable iff it corresponds exactly to the meaning of s1 c   i.e.  by theorem 1  to its minimal solution chain.
example 1 in example 1  as desired  cp is a stable solution chain of s1  while cq is not.
¡¡for many systems  stability suitably characterizes a unique canonical chain. there are still some special cases  however  in which it fails to do so. we give some typical examples.
example 1 both cp and cq from example 1 are stable solution chains of the system given by the following rules:
1 : p	¡û	not 1 : q
1 : q	¡û	not 1 : p
example 1 the following system does not have any stable solution chains.
	1 : p	¡û	not 1 : p
in both cases we think it is most reasonable to conclude that no information is derived at all  i.e. to regard c¡Í as the proper canonical chain.
example 1 the following system does not have any stable solution chains either.
1 : p¡ûnot 1 : p1 : t¡ûnot 1 : q1 : r¡û1 : texample 1 illustrates that  even if the rest of the system is unproblematic  one single rule  in this case the first one  can cause the system not to have any stable solution chain at all.
in this case  t and r should be derived in context 1 and 1  resp.
¡¡the well-founded semantics  first proposed for logic programs by van gelder et.al.  avoids the problems encountered in the above examples. the well-founded model of a program is defined as the least fixpoint of an operator  which  given an interpretation  determines the atoms that are necessarily true and those that are necessarily not true with respect to the program and the interpretation. it assigns true to the former set of atoms  and false to the latter. as a result  more atoms may become necessarily true or necessarily not true. corresponding truth values are assigned until a fixpoint is reached. all atoms that have not been assigned a definite truth value  are interpreted as unknown.
¡¡our approach shares an important intuition with the wellfounded semantics for logic programs  namely  that while constructing the canonical chain of a system  it is not only important to accumulate the information that can certainly be derived from the system  but also to keep track of information that can certainly not be derived from the system.
¡¡but the two approaches are also fundamentally different. the well-founded semantics constructs a 1-valued interpretation i  which is minimal with respect to a truth order v  i.e. i v i1 iff i makes less atoms true and more atoms false than i1   whereas we seek a chain which is minimal with respect to an information order  makes less expressions either true or false than c1 . this particularly results in a different treatment of expressions that are found not to be true. to regard these expressions as false  as the wellfounded semantics does  would be to introduce redundant information. instead  in our setting  such expressions should simply be recorded as not being derivable.
1 constructing the canonical chain
the canonical chain of a normal system s  henceforward denoted by cs  is constructed by an iterative transformation of a datastructure hc ai  where:
  c is the  canonical chain under construction . initially  c = c¡Í. every transformation of c removes from it those local models that are found not to be in cs. so at any phase of the construction of cs  c contains those local models that are possibly in cs  and as such represents the information that is necessarily conveyed by cs.
  a is the  anti-chain . initially  c = c . every transformation of a adds to it those local models that are found to be in cs. so at any phase of the construction of cs  a contains those local models that are necessarily in cs  and as such represents the information that is possibly conveyed by cs.
observation 1 by construction  we have .
therefore  by lemma 1  for any formula f:
	c |= f	 	cs |= f
	a 1 f	 	cs 1 f

¡¡we call a chain-anti-chain pair hc ai less evolved than another such pair hc1 a1i  denoted as hc ai ¡Ü hc1 a1i  iff c is less informative than c1 and a is more informative than a1. if  moreover  c is strictly less informative than c1 or a is strictly more informative than a1  then we say that hc ai is strictly less evolved than hc1 a1i. we call hc ai minimal among a set ca of chain-anti-chain pairs  iff hc ai ¡Ê ca and no other chain-anti-chain pair hc1 a1i in ca is strictly less evolved than hc ai. notice that  if hc ai is minimal among ca  then c is minimal among {c | hc ai ¡Ê ca}.
¡¡given a certain chain-anti-chain pair hc ai  the intended transformation ¦·s first determines which rules in s will  not  be applicable w.r.t. cs  and then refines hc ai accordingly. the canonical chain cs of s will be characterized as the first component of the ¡Ü-least fixpoint of ¦·s.
¡¡we first specify how ¦·s determines which rules will  not  be applicable w.r.t. cs. let hc ai and a rule r in s be given. if r has a positive premise g  which is satisfied by c  then g will also be satisfied by cs. on the other hand  if r has a negative premiss h  which is not satisfied by a  then h will not be satisfied by cs either. so if all positive premises of r are satisfied by c and all negative premises of r are not satisfied by a  then r will be applicable with respect to cs:
 + r  : c |= g  
 g ¡Ê prem
	s+ c a 	=  r ¡Ê sand	 
  h ¡Ê prem  r  : a 1 h  
if r has a positive premise g  which is not satisfied by a  then g will not be satisfied by cs either. if r has a negative premise h  which is satisfied by c  then h will be satisfied by cs as well. in both cases r will certainly not be applicable with respect to cs:
 g ¡Ê prem
	s  c a 	=   r ¡Ê sor+ r  : a 1 g   
  h ¡Ê prem  r  : c |= h  
for convenience  we write:
s¡« c a  = s   s  c a 
think of s¡« c a  as the set of rules that are possibly applicable with respect to cs  and notice that s+ c a    s¡« c a   whenever  and that s+ c a  = s¡« c a   if c = a.
lemma 1 if s is a normal system and hc ai and hc1 a1i are two chain-anti-chain pairs s.t. hc ai ¡Ü hc1 a1i  then we have:
1. s+ c a    s+ c1 a1 
1. s  c a    s  c1 a1 
1. s¡« c a    s¡« c1 a1 
proof.	suppose that hc ai ¡Ü hc1 a1i. then  by definition 
. let r be a rule in s. for the first statement  suppose that r ¡Ê s+ c a . then c satisfies all of r's positive premises  and a does not satisfy any of r's negative premises. by lemma 1  the same goes for c1 and a1  respectively  which implies that r ¡Ê s+ c1 a1 . the second statement is proven analogously; the third follows directly from the second. 
¡¡next  we specify how ¦·s refines hc ai  based on s+ c a  and s¡« c a . every local model m ¡Ê ci that does not satisfy the consequence of a rule in s+ c a  should certainly not be in cs and is therefore removed from c. on the other hand  every local model m ¡Ê ci that satisfies the consequences of every rule in s¡« c a  should certainly be in cs  s provides no ground for removing it  and is therefore added to a.
       ¦·s hc ai  = h¦·cs hc ai  ¦·as hc ai i where:

¡¡as  c ¡Á c ¡Ü  forms a complete lattice  and ¦·s is monotone and continuous w.r.t. ¡Ü   tarski  1  yields:
theorem 1 ¦·s has a ¡Ü-least fixpoint  which is obtained after finitely many iterations of ¦·s  starting with hc¡Í c i.
definition 1 let s be a normal system  and let hcs asi be the ¡Ü-least fixpoint of ¦·s. we define cs to be the canonical chain of s  and we define the semantics of s to be completely determined by cs. that is  for every formula f:
s |= f	¡Ô	cs |= f 
¡¡a bound on the number of iterations needed by ¦·s to reach its ¡Ü-least fixpoint can be formulated in terms of the number of bridge rules in s.
theorem 1 let |s| denote the number of bridge rules of a normal system s. then  starting with hc¡Í c i  ¦·s will reach its ¡Ü-least fixpoint after at most |s| + 1 iterations.
¡¡the semantics for normal systems defined above properly generalizes the local model semantics for positive systems.
theorem 1 the canonical chain of a positive system s coincides with its minimal solution chain.
proof. if s is positive  then for every pair hc ai  s+ hc ai  and s  c  coincide  so ¦·cs hc ai  does not depend on a. as a consequence  cs is the -least fixpoint of ts iff  for some anti-chain as  hcs asi is the ¡Ü-least fixpoint of ¦·s. 
¡¡the canonical chain of a system s  and other fixpoints of ¦·s  are intimately related to the stable solution chains of s.
theorem 1 let s be a normal system  let hcs asi be the
¡Ü-least fixpoint of ¦·s  and let cstable be any stable solution chain of s. then.
theorem 1 let s be a normal system and let hcs asi be the ¡Ü-least fixpoint of ¦·s. if cs and as coincide  then cs is the unique stable solution chain of s.
¡¡finally  we remark that  in our view  all the examples presented above are suitably dealt with by the present analysis. we treat one of them explicitly.
example 1 let s be the system from example 1. then:

as desired  no information is derived about p and q  while t and r are indeed established in context 1 and 1  respectively.
1 conclusions
we showed that the semantics of a multi-context system is completely determined by its least informative solution chain. we provided a way to compute this chain  and thus gave a first constructive account of the local model semantics.
¡¡we presented a generalized framework in which new information can be derived based on the absence of other information. we applied non-monotonic reasoning techniques to establish a suitable semantics for this framework.
