 
the system presented here shows how soar  an architecture for general problem solving and learning  can acquire general search-control knowledge from outside guidance. the guidance can be either direct advice about what the system should do  or a problem that illustrates a relevant idea. the system makes use of the guidance by first formulating an appropriate goal for itself. in the process of achieving this goal  it learns general search-control chunks. in the case of learning from direct advice  the goal is to verify that the advice is correct. the verification allows the system to obtain general conditions of applicability of the advice  and to protect itself from erroneous advice. the system learns from illustrative problems by setting the goal of solving the problem provided. it can then transfer the lessons it learns along the way to its original problem. this transfer constitutes a rudimentary form of analogy. 
	i. 	introduction 
chunking in soar has been proposed as a general learning mechanism  laird et a/.  1 . in previous work  it has been shown to learn search control  operator implementations  macro-operators  and other kinds of knowledge  in tasks ranging from search-based puzzles to expert systems. up to now  though  chunking has not been shown to acquire knowledge from the outside world. the only time soar learns anything from outside is when the user first defines a task; but this is currently done by typing in a set of productions  not by chunking. the objective of the research reported here is to show that chunking can in fact learn from interactions with the outside world that take place during problem solving. 
　　two particular styles of interaction are investigated in the present work. both come into play when soar has to choose among several courses of action. in the first  the advisor tells soar directly which alternative to select. in 
   *this research was sponsored by the defense advanced research projects agency  dod  under contract n1-c-1  by the sloan foundation  and by a bell laboratories graduate fellowship to andrew golding. computer facilities were partially provided by nih grant rr-1 to sumex-aim. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the defense advanced research projects agency  the us government  the sloan foundation  bell laboratories  or the national institute of health. the authors are grateful to allen newell and haym hirsh for comments on earlier drafts of this paper. 
1 	knowledge acquisition the second  the advisor supplies a problem within soar's grasp that illustrates what to do. both styles of interaction teach soar search-control knowledge. 
     in the next section  the basics of the soar architecture are laid out. a soar system that implements the two styles of interaction mentioned above is then described. following that is a discussion of related work and directions for future research. the final section summarizes the contributions of this work. 
	i i . 	the soar architecture 
soar  laird et al.  1  is an architecture for general cognition. in soar  all goal-oriented behavior is cast as search in a problem space. search normally proceeds by selecting an operator from the problem space and applying it to the current state to produce a new state. the search terminates if a state is reached that satisfies the goal test. all elements of the search task - operators  problem spaces  goal tests  etc. - are implemented by productions. 
     various difficulties can arise in the course of problem solving. an operator-tie impasse results when soar is unable to decide which operator to apply to the current state. an operator no-change impasse occurs when soar has selected an operator  but does not know how to apply it to the state. when soar encounters any kind of impasse  a subgoal is generated automatically to resolve it. this subgoal  like the original goal  is solved by search in a problem space - thus soar can bring its full problem-solving capabilities to bear on the task of resolving the impasse. 
     chunking is the learning mechanism of soar. it summarizes the processing of a subgoal in a chunk. the chunk is a production whose conditions are the inputs of the subgoal  and whose actions are the final results of the subgoal. intuitively  the inputs of a subgoal are those features of the pre-subgoal situation upon which the results depend. because certain features are omitted from the chunk namely those that the results do not depend on - the chunk attains an appropriate degree of generality. 
     once a chunk is learned for a subgoal  soar can apply it in relevant situations in the future. this saves the effort of going into another subgoal to rederive the result. 
	i i i . 	design of the system 
in this section  a soar system that learns search control from outside guidance is presented. the performance task of the system is described first  and then the strategy for learning from interactions with the outside world. 

a. 	t h e performance task 
the system works in the domain of algebraic equations containing a single occurrence of an unknown  such as 
	 a + x / b + c  = d + e. 	 1  
the unknown here is x  and the solution is 
	x =  d + e - b + c -a. 	 1  
　　to derive this solution  the system goes into its equations problem space and applies an appropriate sequence of transformations to the equation. transformations are effected by isolate and commute operators. together  these two types form a minimal sufficient set for solving any problem in the task domain of the system. 
　　isolate operators transfer top-level terms from one side of the equation to the other. to illustrate  two isolate operators are applicable to equation 1. one multiplies the equation by the term  b + c   yielding 
	a + x =   f + e - b + c ; 	 1  
the other subtracts e from both sides and produces 
	 a+x / b +c  - e = 	d. 	 1  
the reason the latter subtracts e from both sides  and not d  is that isolate operators always transfer right-hand arguments. isolate operators can thus be characterized by two parameters: the operation they perform  and the side of the equation the transferred term starts out on. there are five possible operations: add  subtract  multiply  divide  and unary-minus; the side of the equation is either left or right. the operators above are isolate multiply  left  and isolate subtract  right   respectively. 
　　there are just two commute operators  one for each side of the equation. they swap the arguments of the top-level operation on their side  provided the operation is abelian. commute  right  applies to equation 1  giving 
	 a + x / b + c  = e + d. 	 1  
b. 	t h e learning strategy 
the system's strategy for learning is to ask for guidance when needed  and to translate that guidance into a form that can be used directly in solving equations. the general procedure for doing this is to formulate an appropriate goal and then achieve it  thereby learning chunks that influence performance on the original equations task. the instantiation of the general procedure depends on the form of guidance provided. the most direct form is where the advisor tells the system which of its operators to apply. alternatively  the advisor could suggest an easier problem whose solution illustrates what to do in the original problem. less direct still  the advisor could refer the system to a textbook  or offer other equally hostile assistance. 
　　the current system accepts both of the simpler forms of help mentioned above - direct advice and illustrative problems. in the following sections  the general procedure is instantiated and illustrated for these forms of help. 
1. learning from direct advice 
in the course of solving its equations  the system is likely to run into situations where it does not know which operator to apply next. this condition is signalled in soar as an operator-tie impasse in the equations space. soar's default behavior is to go into a selection problem space and proceed to evaluate each operator involved in the tie in an arbitrary order  until a correct operator is found. 
　　at this point  there is an opportunity for the system to benefit from outside guidance. rather than evaluate operators randomly  the system enters an advise problem space  where it displays all of the operators  and asks the advisor to pick one. the advisor's choice is evaluated first  in the hopes that it will be correct  allowing the evaluation process to be cut short. normally  the system will be unable to evaluate the advisor's choice by inspection; thus it sets up a subgoal to do the evaluation. in the subgoal  it goes into another equations space and applies the advisor's choice to the current equation. if this leads to a solution  the operator is accepted as correct. 
　　phrased in terms of the general procedure given above  the goal that the system sets for itself is to evaluate the correctness of the advisor's guidance - in this case  the system resembles a traditional learning apprentice; this point is taken up in section iv.a. a more trusting system would simply have applied the suggested operator to its equation. however  by verifying that the recommended operator leads to a solution  the system paves the way for the learning of general conditions of applicability of the operator. this is done by the chunking mechanism  which retains those features of the original equation that were needed in the verification  and discards the rest. moreover  if the system is given a wrong** operator  its verification will fail  and thus it will gracefully request an alternative suggestion. it even picks up valuable information from the failed verification by analyzing what went wrong; the chunks learned from this analysis give general conditions for when not to apply the operator. 
1. example of direct advice 
following is a description of how the system solves 
	ab= -c- x. 	 1  
together with direct advice from outside. a graphic depiction of the problem solving appears in figure 1. 
　　since the system has no prior search-control knowledge  it cannot decide which operator to apply to the initial equation. it asks for a recommendation  and the advisor gives it isolate add  right . the system sets up a subgoal to evaluate the correctness of this operator. in the subgoal  it tries out the operator on its equation  yielding 
	a.b + x = -c. 	 1  
　　here the evaluation runs into a snag  as the system again cannot decide on an operator. it asks for help  and is told to apply commute left . accordingly  it sets a subgoal within its current evaluation subgoal to verify this advice. 
the first equation generated in the new subgoal is 
	x + a   b = -c. 	 1  
 **it turns out that in the current domain  the only wrong operators are those that are inapplicable to the equation. 
	golding  rosenbloom  and laird 	1 

　　the final bit of guidance the system needs is that it should apply the isolate subtract  left  operator. it goes down into a third nested subgoal to verify this  and obtains x = -c-ab. 	 1  
　　having reached a solution  the system is satisfied that isolate subtract  left  is correct  and soar learns a chunk that summarizes the result. the chunk states that if the left-hand side of the equation is a binary operation with the unknown as its left argument  then the best operator to apply is the one that undoes that binary operation. 
　　the verification of the preceding operator  commute left   now goes through as well. the chunk for this subgoal pertains to equations with an abelian binary operation on the left-hand side  whose right argument is the unknown. it says to apply the commute left  operator. 
　　finally  the first evaluation subgoal terminates  and a chunk is learned for it. this chunk requires that the equation have on its right-hand side a binary operation whose inverse is commutative  and whose right argument is the unknown. it asserts that the best operator to apply is the one that undoes the binary operation. 
　　having done the necessary evaluations  the system can go ahead and solve the equation. it no longer has to ask for advice  because its chunks tell it which operators to apply. these chunks may also prove useful in other problems  as demonstrated in the next two sections. 
1. 	learning from illustrative problems 
learning from an illustrative problem takes place in the same context as learning from direct advice - namely  when soar is about to evaluate the operators involved in a tie. but now  instead of going into an advise problem space  the system enters another equations space. this instance of the space is for solving the illustrative problem. 
　　the initial state of this space does not contain an equation. the system detects this  and goes into a parse problem space  where it asks the advisor for an illustrative equation. it parses the equation into its tree-structured internal representation  and attaches it to the initial state; now it is ready to attempt a solution. 
　　to instantiate the general procedure presented earlier  the goal the system sets for itself this time is to solve the illustrative example. there are several ways for it to do so - the current system can either follow direct advice  as described above  or do an exhaustive search. 
　　in the process of solving the illustrative problem  chunks will be learned that summarize each subgoal. then  if the subgoals of the illustrative problem are sufficiently similar to those of the original problem  the chunks should apply directly  resolving the original operator-tie impasse. the learning strategy is thus to apply the lessons of one problem to another. this can be viewed as a rudimentary kind of analogical transfer  as discussed in section ivb. 
1. 	example of an illustrative problem 
in this run  the system is again asked to solve 
	a-b = 	-c-x. 	 1  
figure 1 gives a pictorial representation of the run. 
　　as before  the system hits an operator-tie impasse at the first step  but this time the advisor helps by supplying r = 	s/y 	 ii  
as an illustrative problem. this problem is simpler than the original one  as it has no extraneous operations  such as a multiplication or unary minus  to distract the system. an exhaustive breadth-first search would expand 1 nodes in solving the original equation  but only 1 nodes here. 

figure 1: subgoal structure for learning from direct advice. the levels of the diagram correspond to subgoals. non-horizontal arrows mark the entry and exit from subgoals. within a subgoal  a box represents a state  and a horizontal arrow stands for the application of an operator. ovals denote operator-tie impasses. operator no-change impasses appear as two circles separated by a gap. a wavy line symbolizes arbitrary processing. 
1 	knowledge acquisition 　　the system proceeds to solve equation 1 by bruteforce search. the details are suppressed here  but the outcome is that it finds the sequence of operators isolate  multiply  right   commute  left   and isolate divide  left . chunks are learned for each step of this solution. these chunks are in fact identical to the chunks learned in section iii.b.1; this is because equations 1 and 1 are identical in all relevant aspects. it follows that the chunks can be applied directly to solve the original problem. 

	i v . 	discussion 
the system described here represents a first step toward the construction of an agent that is able to improve its behavior merely by taking in advice from the outside. soar appears ideally suited as a research vehicle to this end  as it provides general capabilities for problem solving and learning that were not available in previous research efforts  mccarthy  1  rychener  1 . the relatively straightforward implementation of direct advice and illustrative problems shows that the advice-taking paradigm fits naturally into soar. below  these methods of taking advice are compared with related work  and extensions to the straightforward implementations are proposed. 
a . 	direct a d v i c e 
the system is similar to a learning apprentice  mitchell et a/.  1  in its treatment of direct advice; instead of 
accepting it blindly  it first explains to itself why it is correct. nevertheless  the system cannot accurately be called a learning apprentice  as it actively seeks advice  as opposed to passively monitoring the user's behavior. in fact  the learning-apprentice style of interaction could be considered a special case of advice-taking in which the guidance consists of a protocol of the user's problem-solving. 
　　the limitation of direct advice is that it forces the advisor to name a particular operator; it would be desirable to allow higher-level specifications of what to do. to take the canonical example of the game of hearts  the advisor might want to tell the system to play a card that avoids taking points  instead of spelling out exactly which card to play. to accept such indirect advice  the system would have to reduce it to a directly usable form  mostow  1 . 
b. 	illustrative problems 
the system processes an illustrative problem by applying the chunks it learns from that problem to the original one. since it is solving the two problems in serial order  it may seem that this approach amounts to just working through a graded sequence of exercises. there are two reasons that it does not  however. first  the teacher can observe how the student fails  and take this into account in choosing a suitable illustrative problem. second  the system is solving the illustrative problem in service of the original one; thus it can abandon the illustrative problem as soon as it learns enough to resolve the original impasse. 
　　a more apt way to view the system's processing of illustrative problems is as a type of analogical transfer from the illustrative to the original problem. the trouble with this type of analogy  though  is that the generalizations are based solely on the source problem  without regard for how they will apply to the target. a more effective approach would be to establish a mapping between the two problems explicitly. this forces the system to attend to commonalities between the problems  which would then be captured in its generalizations. this is in fact just the way generalizations are constructed in grapes  anderson  1 . 
	v . 	conclusion 
the system presented here shows how soar can acquire general search-control knowledge from outside guidance. the guidance can be either direct advice about what the system should do  or a problem that illustrates a relevant idea. the system's strategy of verifying direct advice before accepting it illustrates how soar can extract general lessons  while protecting itself from erroneous advice. this strategy could be extended by permitting the advice to be indirect; the. system would then have to operationalize it. in applying the lessons learned from solving an illustrative problem to its original task  the system demonstrates an elementary form of analogical reasoning. this reasoning capability could be greatly improved  however  if the system were to take into consideration the target problem of the analogy as well as the source problem. 
