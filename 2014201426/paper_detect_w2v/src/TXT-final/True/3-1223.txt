 
in game-playing programs relying on the minimax principle  deeper searches generally produce better evaluations. theoretical analyses  however  suggest that in many cases minimaxing amplifies the noise introduced by the heuristic function used to evaluate the leaves of the game tree  leading to what is known as pathological behavior  where deeper searches produce worse evaluations. in most of the previous research  positions were evaluated as losses or wins. dependence between the values of positions close to each other was identified as the property of realistic game trees that eliminates the pathology and explains why minimax is successful in practice. in this paper we present an alternative explanation that does not rely on value dependence. we show that if real numbers are used for position values  position values tend to be further apart at lower levels of the game tree  which leads to a larger proportion of more extreme positions  where error is less probable. decreased probability of error in searches to greater depths is sufficient to eliminate the pathology and no additional properties of game trees are required. 
1 	introduction 
most game-playing programs are based on the minimax principle. such programs choose the best move by searching the game tree to a chosen depth  heuristically evaluating the leaves and then propagating their values to the root using the minimax principle. it is generally agreed that deeper searches produce better evaluations at the root. however  first attempts to explain this mathematically yielded the paradoxical result that minimaxing amplifies the error of the heuristic evaluations and that consequently deeper searches produce worse evaluations  nau  1; beal  1 . this phenomenon is called the minimax pathology  nau  1 .  
　it was evident that the setting of these mathematical analyses omitted some property of real games that eliminates the pathology. several explanation were proposed  but eventually most researchers came to the conclusion that the property they were looking for is the similarity of positions close to each other  bratko and gams  1; beal  1; nau  1; scheucher and kaindl  1; lu trek  1 . 
　in most research on the minimax pathology  true position values were losses or wins. this seems reasonable  since in games like chess  positions can indeed only be lost or won  or drawn . in practice  however  a game playing program needs an evaluation function that makes it possible to maintain a direction of play  gradually moving toward a win  not just maintaining a won position without achieving the final goal. this requires a multivalued or even realvalued evaluation function. 
　we introduce a minimax model using real-valued evaluation function and a way to interpret real values as losses and wins. this leads to a new  simpler explanation of the pathology. namely  node values at lower levels of the game tree are more dispersed. if the error of the evaluation function  represented by normally distributed noise  is independent of the depth of search  it turns out that the error in terms of loss/win evaluations decreases with the depth of search  because larger dispersion means a larger proportion of more extreme positions where error is less likely. this is different from what the previous analyses assumed and is sufficient to eliminate the pathology. 
　the paper is organized as follows. section 1 presents the minimax pathology and gives an overview of the attempts to explain it. section 1 introduces a minimax model based on real-number position values. section 1 shows why the model from section 1 is not pathological  while seemingly similar models used in previous research were. section 1 explains whether minimax in general can be expected to behave non-pathologically. section 1 concludes the paper and points out where further research is needed. 
	1 	the pathology and related work 
the minimax pathology was discovered independently by nau  and beal . beal's basic minimax model made several assumptions: 1. game tree has a uniform branching factor; 
1. nodes of the tree can have two values: loss and win; 
1. node values are distributed so that at each level of the tree the proportion of losses for the side to move is the same; 
1. node values within each level of the tree are independent of each other; 
1. the error of heuristic evaluation at a node at the lowest level of search  being the probability of mistaking a loss for a win or vice versa  is independent of the depth of search and the true value of the node. 
　we proceed to present beal's basic model  although our analysis is mostly based on later work. negamax representation is used in this section  i.e. node values are viewed as lost or won from the perspective of the side to move. let b be the branching factor of the tree  d the depth of search and ki the probability of a node at i-th level being lost. levels are numbered downwards: from 1 for root to d for the lowest level of search. 
　a node can only be lost if all of its descendants are won  for the opponent   so the relation between the values of k at consecutive levels is governed by equation  1 . 
	ki =  1 - ki+1 b	 1  
　assumption 1 requires ki = ki+1  which results in ki = cb for all i; for example  c1 = 1. 
　two types of evaluation error are possible: a loss can be mistaken for a win  false win  or a win for a loss  false loss . let pi and qi be the probabilities of the respective types of error at i-th level. they are calculated according to equations  1  and  1 . 
	1	b	b	b 
	pi =  1  ki+1   1  1  qi+1    =1  1  qi+1 	 1  
qi =‘b    bj    kij+1 ki+1 b  j pij+1 qi+1 b  j  1  1 ki j=1 
　it turns out that if the same pd = qd are used in searches to all depths  the error in the root  defined as p1 k1 + q1  1 - k1   increases with d.  this result is disappointing   concluded beal  since it was exactly the opposite of what he set out to show. his model must have been flawed in some way. 
　in the years following the discovery of the pathology  several researchers attempted to find the flaw in beal's basic model by attacking its assumptions  1. through 1. at the beginning of this section . 
1. michon  observed that the pathology depends on the probability distribution of branching factor: game trees with uniform branching factor tend to be pathological  while game trees with  for example  geometrically distributed branching factor do not. it is not known whether real games have any of the nonpathological distributions  though. 
1. bratko and gams  were the first to experiment with multivalued evaluations. they assigned no particular meaning to different values  which resulted in behavior similar to the one with two values  i.e. pathological. pearl's results were similar . scheucher and kaindl  and lu trek  also used multiple and even real values  but only to establish realistic relations among node values and the magnitude of error  so even though their models were not pathological  they did not attribute the absence of pathology to real values. sadikov et al.  used multiple values in their analysis of king and rook versus king chess endgame. they explained the pathology  but their explanation involves multiple values only indirectly and it is not known whether it applies to cases other than the endgame they studied. 
1. having node values distributed so that ki = cb for all i not only simplifies calculations  it is generally agreed to be necessary  bratko and gams  1; beal  1; nau  1 . if k1 』 cb is chosen  ki starts to oscillate between values close to 1 and 1 for relatively small i  meaning that we are dealing with games that are almost certainly won for one side and as such not interesting. 
1. most researchers  bratko and gams  1; beal  1; nau  1; scheucher and kaindl  1; lu trek  1  agreed that similarity of positions close to each other eliminates the pathology  although they arrived at this conclusion in different ways. pearl  claimed that early terminations are the culprit  but these can also be interpreted as a form of node-value dependence. 
1. pearl  showed that in order to overcome the pathology  the error of the evaluation function must decrease exponentially with the depth of search. it is generally believed that the quality of the evaluation cannot vary enough to account for the absence of pathology. scheucher and kaindl  did use depthdependent error. and although such error made increased depth of search more beneficial  node-value dependence was required to altogether eliminate the pathology. 
　the conclusion one can make based on the existing literature on the minimax pathology is that the pathology is usually not observed in real games because their position values are not independent of each other. this conclusion is reinforced by the fact that multiple authors have arrived at it in different ways. 
1 	a minimax model based on real values 
even though all the explanations for the absence of pathology in minimax provided in the previous section are valid  at least under the assumptions their authors made  are these assumptions really necessary and realistic  we argue that real numbers should be used for position values  in which case another  more basic explanation is sufficient. 
　both game-playing programs and humans use multivalued position evaluations. there is little doubt this is necessary in games where the final outcome is multivalued  othello  tarok etc. . in games where the outcome can only be a loss  a win and perhaps a draw  chess  checkers etc.   multiple values might seem to be useful only as a way to express the uncertainty of a program or human. however  even given unlimited resources to determine the value of a position  in a losing position  the best one can do against a fallible and not fully known opponent is evaluate the position in terms of the probability of loss. in a winning position  even a perfect two-valued evaluation function could maintain a won position indefinitely without actually winning  or until termination due to 1-move rule in chess . in essence  multivalued evaluation function is necessary to differentiate between multiple winning  or losing  if only such are available  moves. scheucher and kaindl  demonstrated on chess that a two-valued evaluation function performs poorly compared to a multivalued one. 
　we propose a minimax model similar to beal's basic model  except that it uses real numbers for position values: 
1. game tree has a uniform branching factor; 
1. nodes of the tree have real values; 
1. if the real node values are converted to losses and wins  they are distributed so that at each level of the tree the proportion of losses for the side to move is the same; 
1. node values within each level of the tree are independent of each other; 
1. the error of heuristic evaluation at a node at the lowest level of search  being normally distributed noise  is independent of the depth of search and the true value of the node. 
game trees built according to our model are assigned 
　
 
figure 1: equivalence of real- and two-value minimaxing.
　
independent uniformly distributed values from  1  1  interval to the leaves at level dmax. these are true values; true values of internal nodes are obtained by backing up the true leaf values using the minimax rule. when searching to depth d  heuristic values at level d are generated by corrupting the true values with normally distributed noise representing the error of the heuristic evaluation function; heuristic values of nodes at levels   d are obtained by backing up the corrupted values at level d using the minimax rule. 
　two types of error can be observed at the root of a game tree: position error  which is the absolute difference between the true and the heuristic value of the root  and move error  which is the probability of choosing a wrong move because of position error at the root's descendants. however  neither type of error corresponds directly to the error in two-value models used in most of the previous research: two-value error is defined as the probability of mistaking a loss at the root for a win or vice versa. 
　in order to measure two-value error  real values must be converted to losses and wins. this can be accomplished by establishing a threshold t: the values below it are considered losses and the values above it wins. according to beal's assumption 1  if negamax representation is used  ki = cb for all i. we do not use negamax representation in our model  so ki alternates between cb and 1 - cb. since true values of the leaves are distributed uniformly in  1  1  interval  kd = cb is achieved by setting t = cb. even though real-value minimaxing is used  ki behaves as desired for i   1. this happens for two reasons. first  leaf values in our real-value model  converted to two values  correspond exactly to leaf values in beal's basic model. the probability of a loss at a leaf with value x is p  x   t   which for uniform distribution in  1  1  interval and t = cb equals cb. in beal's basic model  the probability of a loss at each leaf is kd  which also equals cb. second  real- and two-value minimaxing are equivalent in the sense that performing minimax on losses and wins from level i to j   i gives the same results at level j as performing minimax on the underlying real values from level i to j and converting them to losses and wins at level j. this is illustrated in figure 1; losses are marked with  -  and wins with  + . 
　we conducted monte carlo experiments with game trees generated according to our model. only the results for b = 1 and dmax = 1 are presented in this paper; the results for larger branching factors and depths are similar. the results are averaged over 1 game trees. for each tree  there were 1 repetitions with randomly generated noisy values for each d. figure 1 shows position  move and two-value error at the root of the game tree with respect to the depth of search; standard deviation of noise is 1. 

figure 1: error at the root with respect to the depth of search.
　as can be seen in figure 1  all three types of error decrease with the depth of search  with the exception of even/odd level fluctuations of two-value error . note that these observed behaviors are different from beal's original results   which were pathological. 
　even though our primary concern is comparison with beal's basic model  we checked whether the absence of pathology occurs only under the described settings or is it more general. we tried uniform distribution of error and normal distribution of node values as well as different forms of dependence among node values. none of the experiments yielded pathology except for some rare cases where slightly pathological behavior was caused by very large static error. there was no pathology in terms of position error  but move and two-value error did in some cases behave pathologically when their static values were close to 1. however  since 1 is the point where evaluations become completely random  this seems to be of little practical importance. 
1 	why is our model not pathological  
　considering that our model is very similar to beal's  why is it not pathological  to answer this question  we must 
examine two-value error at the lowest level of search. beal's assumption 1 states that it should be constant with search depth  but in our model  real-value position error is set to be constant instead  which is achieved by using normally distributed noise with the same standard deviation at all levels . two-value error at the lowest level of search is shown in figure 1; standard deviation of noise is 1. 
figure 1: two-value error at the root with respect to the depth of search when two-value error at the lowest level of search is always 1. 
　as can be seen in figure 1  the results for binarized realvalue model and the results for beal's basic model match 
figure 1: two-value error at the lowest level of search with respect to the depth of search. 
　as can be seen in figure 1  two-value error at the lowest level of search decreases with the depth of search. this is different from beal's assumption 1. however  to eliminate the pathology  pearl  observed that if the error is small  it should decrease by a factor of 1 every two levels  i.e. exponentially with the depth of search  while in figure 1  it decreases roughly linearly. for pearl's observation to be true  the error should be quite small  though. for example  if the error at depth 1 is 1  the value chosen by bratko and gams  and close to the quite well. the matching is not perfect because in the realvalue model  the probability of a false win at the lowest level of search is higher than the probability of a false loss. this happens because false wins occur in  1  t  interval  while false losses occur in  t  1  interval. since t = c1  the former is smaller  therefore node values are on average closer to the threshold  and hence two-value error is more likely. the ratio of probability of a false win : probability of a false loss is  1 - t  : t. if the overall probability of twovalue error is to remain 1  the appropriate settings in beal's model are pd = 1 / t and qd = 1 /  1- t . under these settings  the models match perfectly. values we experimented with   pearl's approximation gives two-value error 1 at depth 1  while the exact error is 1. we chose not to work with smaller errors in this paper because move and two-value error are probabilities computed from frequencies and when they are very small  very large samples are required to obtain meaningful results. 1 	minimax pathology in general 
　what remains to be considered is whether constant position error or constant two-value error at the lowest level of search is more realistic. there is no pathology in the former case  while the latter case corresponds to beal's 　figure 1 shows two-value error at the root when twovalue error at the lowest level is always 1; results for beal's basic model are shown for comparison. 

　
　if noise introduced at the lowest level of search is adjusted so that two-value error at the lowest level of search is always 1  position error at the lowest level of search increases with the depth of search as shown in figure 1. 

figure 1: position error at the lowest level of search with respect to the depth of search when two-value error at the lowest level of search is always 1. 
basic model and is pathological. game-playing programs use real  or at least multiple  values in their evaluation functions. position error is the most direct representation of the fallibility of these functions and there is no reason to believe that it should increase with the depth of search as shown in figure 1. but can we expect two-value error to behave as shown in figure 1  we will show here that the answer is  yes . game-playing programs are generally not concerned with two-value error; if they were  one can easily imagine that it would be large in uncertain positions whose values are close to the threshold and small in clearly lost or won positions far from the threshold. if both sides are to have comparable chances to win at the root  the value at the root should be close to the threshold. each level downwards from the root is one move away from the root position. position values usually change gradually  so with each move  position values can be more different from the root value. therefore the average distance of a position value from the threshold at lower levels can indeed be expected to 
be larger than at higher levels  as was also stated by scheucher and kaindl . this is illustrated in figure 1; darker area represents higher probability of two-value error. 
 
figure 1: distance of nodes values from the threshold and its relation to two-value error. 
　in game trees with independent node values  the effect of position error on two-value error can be analyzed mathematically. for simplicity  we will only consider b = 1 and limit node values to  1  1  interval. 
　due to space limitation  we will only examine false losses. consider the probability of a false loss at a node with true value x and heuristic value x - e  where e is the node's position error. false loss means that x   t and the heuristic value is on the other side of the threshold  i.e. x - e   t. the probability for such a mistake to happen at a node whose true real value is distributed according to distribution function f  x  is calculated according to equation  1 . 
p x   t … x  e   t  = p t   x   t + e  = f t + e   f t   1  
　consider now the probability of a false loss at different levels in a game tree. let fi  x  be the distribution function of node values at i-th level of the game tree. if i - 1 is a max level  fi-1  x  is calculated from fi-1  x  according to equation  1 . 
	fi 1 x  = p x i 1   x  = p x i 1   x 1 = fi 1 x 1 	 1  
　if i - 1 is a min level  fi-1  x  is calculated from fi  x  according to equation  1 . 
fi 1 x  = p x i 1   x  =1  p x i 1   x  =	 	 1  
	1
=1  p x i   x  =1  1  p x i   x   =1  1  fi  x  
　in order to calculate fi-1  x  from fi  x  in one step   1  and  1  are joined into equation  1 . 
	fi 1 x  = fi 1 x 1 =  1  1  fi  x  1 = 	 1  
	1	1
= 1fi  x   1fi  x  + fi  x 
　we will show that the probability of a static false-loss error at higher levels is usually greater than at lower levels  which is expressed by inequality  1 . 
p  false loss at level i - 1    p  false loss at level i  
 1  fi-1  t + e  - fi-1  t    fi  t + e  - fi  t  
　inequality  1  means that the difference between the values of distribution function at points t + e and t is greater at higher levels - in other words  that the distribution function is steeper at higher levels. let us take as an example our model from section 1: dmax = 1 and leaf values are distributed uniformly  therefore f1  x  = x. equation  1  can be used to calculate f1  x  = 1 x1 - 1 x1 + x1. figure 1 shows f1  x  and f1  x  in our model.  
 
figure 1: distribution functions of node values at levels 1 and 1 in our model from section 1. 
　as can be seen in figure 1  f1  x  is steeper that f1  x  between x = a and x = b. to determine where fi-1  x  is steeper than fi  x  independently of fi  x   inequality  1  must be solved; note that fi  x  is written as fi. 
dfi 1   dfi 
	dfi	dfi	 1  
1 fi - 1 fi1 + 1 fi1   1 
　the expression dfi-1 / dfi as a function of fi is shown in figure 1. 
 
figure 1: dfi-1 / dfi as a function of fi.
　with the help of figure 1 we can solve inequality  1 : 1   fi   1. values a and b in figure 1 are therefore a = f1  1  and b = f1  1 ; since f1  x  = x  this means a = 1 and b = 1. so whenever the values of fi  t + e  and fi  t  are in the interval between 1 and 1  false-loss error at level i - 1 is greater than false-loss error at level i for any distribution function fi  x . since fi  t  = ki  if ki is to be the same for all i  most reasonable distribution functions should satisfy the condition 1   fi  t    1. 
　we now see that two-value error at higher levels is smaller than at lower levels. but is it smaller enough  if pi and qi when searching to depth dmax were computed for all i  these values could be used for pd and qd when searching to depths d   dmax. under these conditions  two-value error at the root would be the same for searches to all depths - minimax would be neither pathological nor beneficial. if we can prove that given position error e causes greater twovalue error at level i - 1 if it is introduced at level i - 1  denoted p1  than if it is introduced at level i and then backed-up to level i - 1  denoted p1   we will also have proven that two-value error as a result of depth-independent position error decreases from the leaves towards the root sufficiently to make minimax non-pathological. p1 and p1 are calculated using equations  1  and  1  in different order  resulting in equations  1  and  1 . 
p1 = fi 1 t + e   fi 1 t  =
	= 1fi  t + e 1  1fi  t + e 1 + fi  t + e 1  	 1  
	  1fi  t 1  1fi  t 1 + fi  t 1 	 
p1 = 1 fi  t + e   fi  t  1  1 fi  t + e   fi  t  1 +
 1  
1
	+ fi  t + e   fi  t  	 
　we solved inequality p1   p1 on  1  1  interval using mathematica software  resulting in  1 . 
fi  t ＋ fi  t +e ＋ 1+ fi  t   1fi  t  1fi  t 1 	 1  1
　the upper limit for fi  t + e  from inequality  1  is shown in figure 1. 
 
figure 1: f  t + e  as a function of f  t .
　as can be seen in figure 1  minimax will behave pathologically only when f  t + e  is close to 1  shaded area . since f  t  is generally not expected to be close to 1  this means a large position error. this is consistent with our observations from section 1 where there was no pathology except in some cases when static error was very large. 
1 	conclusion 
to analyze the pathology  we designed a minimax model with real-number position values. the model did not behave pathologically under a wide range of settings  as long as normally  or uniformly  distributed noise used to model the error of heuristic evaluations was independent of the depth of search. however  under these settings  two-value error was not independent of the depth of search  which is contrary to what was assumed in most of the previous research. due to minimax relations among the true values  both types of error cannot be independent of the depth of search simultaneously  because at greater depths  position values are on average farther away from the threshold separating losses from wins; therefore at greater depths  the same position error causes smaller two-value error. in real games  this is caused by position values starting close to the threshold at the root and dispersing gradually as we advance downwards through the game tree. we showed mathematically that in game trees with independent node values  two-value error at higher levels is also smaller than at lower levels. furthermore  we showed that the reduction of the error is in most cases sufficient to eliminate the pathology. the pathology sometimes persists  particularly when the error is very large  but such cases are probably rare. establishing which cases exactly are these is left for further work. 
　in summary  the explanation for the minimax pathology  or the absence of it  presented in this paper  is a necessary consequence of a real-value minimax model  and does not require any other assumption. even if one were to claim that in a purely theoretical sense  real values are inappropriate  they are certainly necessary in practice. and the minimax pathology is considered pathological because it is at odds with what is observed in practice. 
