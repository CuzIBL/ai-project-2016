node aggregation for distributed inference in bayesian networks 
k u o - c h u chang and robert fung 
advanced decision systmes 
1 plymouth street 
	mountain view  california 	1 

a b s t r a c t 
this study describes a general framework and several algorithms for reducing bayesian networks with loops  i.e.  undirected cycles  into equivalent networks which are singly connected. the purpose of this conversion is to take advantage of a distributed inference algorithm |1|. the framework and algorithms center around one basic operation  node aggregation. in this operation  a cluster of nodes in a network is replaced with a single node without changing the underlying joint distribution of the network. the framework for us 
ing this operation includes a node aggregation theorem which describes whether a cluster of nodes can be combined  and a complexity analysis which estimates the computational require ments for the resulting networks. the algorithms described include a heuristic search algorithm which finds the set of node aggregations that makes a network singly connected and allows inference to execute in minimum time  and a  graph-directed  algorithm which is guaranteed to find a feasible but not necessary optimal solution and with less computation than the search algorithm. 
1 	i n t r o d u c t i o n 
this study describes a general framework and several algorithms which use that framework for converting bayesian networks with loops  i.e.  undirected cycles  into equivalent singly-connected networks. the purpose of this conversion is to take advantage of a distributed inference algorithm . the framework and algorithms center around one basic operation  node aggregation. in this operation  a cluster of nodes in a network is replaced with a single node without changing the underlying joint distribution of the network. 
   like its predecessor technology  decision/risk tree technology  bayesian networks  a.k.a. influence diagrams    is a technology for representing and making inferences about beliefs and decisions. a probabilistic bayesian network is a directed  acyclic graph  dag  in which the nodes represent random variables  and the arcs between the nodes represent possible probabilistic dependence between the variables. a network as a whole represents the joint probability distribution between the random variables. the representation has proved to be an improvement over the older tree technologies for several reasons including increased functionality  compactness  and intuitiveness to users. 
　while a fast distributed inference algorithm exists for singly-connected networks  it has been proved  l  that no algorithm can be efficient on all bayesian networks with loops. however  there appears to be much room for expanding the set of graph topologies which can be addressed in a computationally efficient manner. other than the node aggregation approach presented in this study  several other approaches have been proposed to address the inference problem for arbitrarily-connected networks. these approaches include: conditioning |1|  cliques   using the influence diagram operations such as link reversal and node removal   and stochastic sim ulation . 
　in this paper  we have chosen the node aggregation method to handle the inference problem in an arbitrary network. for all node aggregation methods  the first and defining step is to reduce the graph using node aggregation into a singly connected graph. this step needs only occur once. in the second step  the distributed infer ence algorithm is applied to the reduced graph to calculate the posterior distributions of each node. since the aggregated nodes in the reduced graph may consist of more than one original node  the third step calculates the posteriors of the original nodes by marginalizing the posterior probabilities of the aggregated nodes. 
　the paper is organized as follows. section 1 describes the definitions and theorems which make up the framework. of principal interest is a node combinability theorem which determines if a set of nodes can be aggregated. the effects of a node aggregation on a graph are then described. a computational complexity measure is also presented in section 1. given a graph's topology and the state space size for each node in the graph  this measure calculates the approximate computation time required for each update in inference. in section 1  an a* search algorithm to find the optimal node aggregation partition is developed based on the performance criterion obtained in section 1. this algorithm utilizes pruning techniques that can substantially reduce the search space and the optimal solution is guaranteed to be retained. a much 
	chang and fung 	1 


simpler heuristic approach  graph-directed decomposition  for finding a suitable partition is also presented in section 1. finally  some conclusions and directions for future research are discussed in section 1. 
1 	framework 
in this section we define the basic definitions and present theorems which make up the framework. as directed acyclic graphs  there are two major topological classes of bayesian networks  graphs which are singly-connected and graphs which contain undirected cycles  i.e.  loops . for graphs with loops  the distributed inference algorithm |1j does not apply since the loops cause the local propagation schemes to circulate messages indefinitely around these loops. in order to keep the advantages of the distributed inference scheme  several methods have been proposed to deal with this problem. these include aggregation  conditioning   and stochastic simulation. in this study  we focus on the aggregation method. 
　in order to aggregate nodes in a loop  first we need to be able to identify all nodes involved in loops for a given acyclic graph. this can be done by using well-known graph-theoretic algorithms. there may be more than one loop in a graph. in that case  we need to identify all the loops and group them into independent loop set  where two loops are independent if they don't share any node. for each independent loop set  the nodes involved in the loops are partitioned into clusters which are then aggregated into macro nodes. note that not all sets of nodes can be aggregated. in particular a set of nodes cannot be aggregated if it creates a cycle in the network. in this section  we will describe the basic node aggregation theorem and illustrate the results of aggregation with several simple examples. 
1 	node aggregation theorem 
first a path is defined for a directed graph in the usual way. for example  in figure 1   acd  is a path between a and d  but  acfd  is not a path. second  a pair of nodes is called combinable if there is no path between the two nodes which contains a third node. similarly  a group of nodes is called combinable if for every pair of nodes in the group there exists no path between such pair which contains a node outside the group. 
search 
　with the above definitions  we have the following lemma. 
　lemma 1 : a pair of nodes in an acyclic graph can be combined into a macro node so that the resulting graph remains acyclic if and only if the node pair is combinable. proof : the proof is given in appendix a. 
　with the above theorem  we also have the following node combiliability theorem. 
　theorem 1 : a group of nodes in an acyclic graph can be combined into a macro node so that the resulting graph remains acyclic if and only if the group is combinable. 
　proof : the proof of this theorem is similar to the proof of the above lemma. 
1 	the results of combining 
when a macro node is created  the predecessors and successors of the node as well as its conditional probability requires definition. a macro node's predecessors are the union of its component nodes' predecessors  and its successors are the union of its component nodes' successors. for the conditional probability distribution of macro nodes  we have the following lemmas. 
　lemma 1 : the conditional probability of the macro node given its predecessors is equal to the product of all component node's conditional probabilities. for the example in figure 1  if  b c d  are combined into a macro node m  then the conditional probability of m given the predecessor a is equal to: 

　lemma 1 : the conditional probability of a macro node's successor is equal to the conditional probability of the successor given all the component nodes in the macro node  except for those component nodes which are not linked directly to the successor  in which case  they are irrelevant and will not affect the conditional probability other than increasing the dimension of the conditional probability matrix. for the same example as above  where  b c d  are combined into a macro node m  then the conditional probability of e given m is equal to: 
		 1  
since c is not linked directly to e  the conditional probability only depends on b and d  namely  p e b  d   which is already available. therefore  one only needs to fill up the matrix with appropriate entries  i.e.  

　proof : the proofs of lemmas 1 and 1 are straightforward and will not be carried out here. 
　according to the above theorem and lemmas  for a graph which is not singly connected  one may partition each independent loop set in the graph into several clusters and aggregate the nodes in each cluster into a 
　macro node so that the graph can be reduced to a singlyconnected graph and the distributed inference algorithm  can be applied in processing. for the example given in figure 1  there are several ways of aggregating nodes and reducing the original graph into a singly-connected graph. each one of these is called a feasible partition. 

some of the examples with feasible partition or infeasible partition  with loops  are given in figure 1. obviously  certain partitions are better than others in computation requirements in the resulting networks. in order to distinguish them  a criterion of performance needs to be defined. in the next subsection  we develop the computational requirements for each macro node and define it as the performance measure to be considered. 
1 	computational complexity 
in order to determine the computational efficiency for different network structures  we first need to be able to quantify the computational requirements for various configurations. due the characteristics of the distributed algorithm   the computational requirements for each node depend not only on the size of state space of the node itself  but also on the number of its predecessors and successors as well as their state space sizes. for each node in a singly connected network  there are four modules in the algorithm  two of them for upward propagation and two of them for downward propagation. in a distributed processing environment  each processing node may propagate the data upward and downward simultaneously  however  due to the interaction between the four processing modules  calculating the exact processing time needed for each node is not trivial. we may approximate the computation requirements by considering the number of multiplications that have to be performed in all four modules for each update. 
　as carried out in appendix b  for a node x with m predecessors and tv successors  the total number of mulwhere n and npi are the state space sizes of node x and its i:-th predecessor xpi respectively. in a tree structure  each node can have at most one predecessor  i.e.  m - 1  therefore the number of multiplications reduced to 1n + nn | 1n 1   where npi is assumed to be equal to n. this coincides with the calculations given in  1j. 
　in the above calculations  it was assumed that the enlarged conditional probability matrices as obtained in equations  1  and  1  are stored in their corresponding macro node at the time the graph was reduced and  initialized . therefore  in normal processing when new evidence is added  only the computational requirements involved in standard propagation as described above need be considered. alternatively the conditional probabilities can also be calculated from the component nodes whenever needed instead of storing the matrix at the macro nodes. this alternative is preferable when the matrix is very large and a large amount of memory is re-
quired. nevertheless  more computational resources are necessary in this approach since the conditional probabilities need to be re-calculated each time they are needed. this kind of trade-off should be considered in choosing aggregation partition for various network configurations. in the next section  several heuristic algorithms are proposed for finding suitable partitions. 
1 	aggregation algorithms 
all aggregation algorithms face the basic fact that the number of possible partitions of a graph with n nodes is b n   where b n  is given by the recursive formula: 

　this sequence of numbers is called the bell sequence   and grows exponentially. the first few elements of this series are: 1  1  1  1  1  1  1  1  1  
1. thus for a graph with 1 nodes there are about 1 thousands possible partitions. 
   however  many of these partitions  i.e.  reduced graphs  are not feasible since they have undirected or directed cycles. although it is possible for certain specialized structures to find the optimal partition through direct inspection of the graph  we have as yet found no such general algorithm for the general case. instead the algorithms proposed in this paper  either by searching through the space of partitions or by inspection of the graph  find a feasible but not necessary optimal partition. in this paper  we have identified several methods to use the special  i.e.  directed  acyclic  structure of bayesian networks in order to cut down the number of 
	chang and fung 	1 
partitions examined in the search for the optimal partition. in this section  we will use the example graph shown in figure j to illustrate each concept presented. 
1 	heuristic search 
in this subsection  an aggregation algorithm is proposed which formulates the aggregation problem as a search problem and guarantees the identification of the optimal partition. in this algorithm  the nodes in each dependent loop set are first ordered  and then partial partitions are generated recursively  with pruning of in feasible partitions occurring at each level. 
　it is well known that acyclic graphs can be numbered such that every node has a larger number than all of its predecessors  and a smaller number than any of its successors. the numbers shown in figure 1 are obtained by this scheme. it should be noted that some of the decisions are arbitrary   e.g.  b could switch order with 
　given the node ordering scheme above  the full set oi partitions for a dependent loop set can be identified by the following recursive algorithm: 
1. initialize the old-partition-list to 1. 
1. for node i from 1 to n 
1a. start a new-partition-list 
1b. for each partition in old-partition-list 
1bl. for each cluster in partition 
1. make a new partition by adding node i to that cluster 
1. add that new partition to new-partitionlist 
end for  1  
end for  1b  
1. set the old-partition-list to the new-partition-list 
end for  1  
　an illustration of this expansion algorithm for the example graph is shown in figure 1 up to the fourth node  i.e.d . 
　without pruning  this expansion algorithm for an independent loo   set with n nodes will produce b n  number of complete partitions. two pruning operations have been identified to manage the search space without removing any feasible partitions. the first pruning operation removes any partition which has a node cluster which is not combinable. the partial partition  ad    bo   see figure 1  is one such partition since the nodes ad are not combinable. the second pruning operation removes any partition which contains a loop. the partial partition  a b c d  is one such partition since the nodes abcd form a loop. the claim that these pruning operations do not remove any feasible partitions from consideration is proven below. 
　theorem 1 : with pruning of infeasible partial partitions which contain at least one loop  or at least one node cluster which is not combinable  all feasible complete partitions are still reachable. 
　proof : because of the ordering scheme  if a node cluster in a partial partition is not combinable  the addition of any new node cannot make that node cluster combinable. also if a partial partition contains a loop  the addition of any new node will not remove the loop 
search 
from that partition. thus any successor partition of any infeasible partial partition will be infeasible. thus pruning an infeasible partial partition does not prune any feasible complete partition. 
　in order to use heuristic search techniques  an evaluation function must be defined. in particular for the a* algorithm  the cost functions g p  and h p  must be defined where p is a partial partition. the function g p  is an estimate of the cost from the start node to the the partial partition. this can be calculated using the computational complexity results derived in sec 1. the function h p  is an estimate of the additional cost of getting to the final complete partition and must be less than or equal to the  actual  cost of reaching the final partition. for h p  we compute the additional cost of completing the partition by assuming the rest of the nodes are added singly since this is the minimum cost solution. the cost functions g p  and h p  are combined into the evaluation function f p  where: 
	f p  	- g p  	+ 	h p  	 1  
while we have chosen to discuss the a* algorithm  here  other heuristic search techniques could be applied as well. 
　an additional technique for reducing search is to devise an algorithm for initializing f p  before any search starts. such algorithms find a  good  feasible complete solution directly. such an algorithm is discussed in the next subsection. 
　in summary  the heuristic search algorithm can be described as follows: 
1. order the nodes in the dependent loop set. 
1. initialize the old-partition-list to be 1. 
1. initialize the minimum cost by an initialization algorithm  e.g.  sec. 1  
1. choose the partial partition pi with minimum / pi   to expand. 
1a. make new partitions by adding the i + 1 node to the partial partition pi 
1b. prune all partitions containing a ''non-combin able'1 node cluster. 
1c. prune all partitions containing a loop. 
	1d. evaluate 	j{pi+1  	for each new partial partition. 
1e. if there is a partial partition to expand  go to 1  else done. 
1 	graph-directed algorithm 
another heuristic method developed based on the node aggregation theorem is the so called  graph-directed algorithm . this algorithm is  graph-directed  since the aggregation process follows the direction of the graph  i.e.  from a graph's roots to its leaves . this algorithm consists of the following steps : 
1. for each independent loop set  find the root nodes. 
1. identify all root nodes1 successors which are within the loop set. 
1. group these successors into clusters such that any two nodes of different clusters do not share any predecessor. 
1. if the nodes in a cluster are combinable  combine 


them into a macro node. 
1. if the nodes in a cluster are not combinable  collect these nodes together with their direct successors within the loop set and go to step 1. 
1. when all nodes involved in the loop set have been considered  done. 
this algorithm reduces a graph with loops into a singlyconnected one. it is not optimal but is simple and requires small amounts of computational resources. it can serve as a mechanism for initializing the search algorithm described in the previous subsection or can be used as a stand-alone algorithm for finding a partition for node aggregation. to illustrate the algorithm  figure 1 shows several example graphs together with their resulting partitions obtained based on this algorithm. 
1 	conclusions and discussion 
in this paper  we have presented a general framework and several algorithms for converting baycsian networks with loops into equivalent singly-connected networks. the purpose of such conversions is to take advantage of the distributed algorithm  for inferencing in a singlyconnected network. the framework and algorithms center around one basic operation  node aggregation. in this operation  a cluster of nodes in a network is replaced with a single node without changing the underlying joint distribution of the network. the framework consists of a node combinability theorem which determines if a set of nodes can be aggregated  a description of the results of node aggregation and a computational complexity measure associated with the aggregation. 
   a search algorithm to find an optimal node aggregation partition as well as a simpler heuristic approach for finding a suitable partition are then presented. while the algorithms described in this paper may not in the end prove to be the most efficient ones  all of the ba-

sic concepts in the framework and those used in the algorithms  e.g.  node combinability  computational requirements measure  node ordering  pruning operations  are fundamental and useful to all node aggregation algorithms. 
　there are at least two primary directions of research to pursue  algorithm development within the node aggregation framework and the comparison and integration of other methods for dealing with graphs with loops  e.g.  conditioning  stochastic simulation . 
　with respect to algorithm development  the most promising avenue of research seems to be algorithms like the  graph-directed  algorithm which would utilize graph features such as connectivity and state space size  to directly identify a near optimal if not the optimal so lution. search approaches seem less promising since even heavy pruning of in feasible and high cost alternatives can still be computationally costly for some graphs. hybrid approaches which combine search and algorithms which generate an initial feasible solution may also be worth looking into. 
   for the integration of algorithms  it seems clear that with each method which has been suggested  there are certain graph topologies where that method provides the best solution. however  the same method may perform very poorly for other topologies. this suggests a direction of research in which the algorithms are compared and integrated based on their individual strength in dealing with various graph topologies. 
a 	proof of combinability theorem 
the proof of the lemma follows  proof : 
　 -   if a cycle is created in the new graph due to the combination of the node pair  then there must exist at least one path between the two nodes which contains a third node. this violates the combinable node pair definition. therefore  if a node pair is combinable  then the resulting graph  with the node pair combined into a macro node  remains acyclic. 
     -  if a node pair is not combinable  then there exist at least one path between the two nodes which contains a third node. now if the pair is combined into a macro node  that directed path will create a cycle and make the resulting graph cyclic. therefore  in order to maintain the resulting graph acyclic  the node pair to be combined has to be combinable. 
b 	computational complexity 
for the four modules in the algorithm   the respective number of multiplications needed are  
　module i : calculate . according to the updating formula  there are two parts  first calculate the transition matrix  then multiply the matrix by the vector 
 since wc have m predecessors  the total number of multiplications needed is: 


