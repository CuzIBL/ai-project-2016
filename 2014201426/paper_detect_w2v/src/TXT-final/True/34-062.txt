 
　　　this paper describes torus  a natural language understanding system which serves as a f r o n t end to a data base management system in order to f a c i l i t a t e communication with a casual user. the system uses a semantic network for  understanding  each input statement and for deciding what i n f o r mation to output in response. the semantic network stores general knowledge about the problem domain  in this case  student f i l e s   and the educational process at the university of toronto  along with s p e c i f i c information obtained during the dialogue with the user. a number of associated functions make it possible to integrate the meaning of an input statement to the semantic network  and to select a p o r t i o n of the semantic network which stores information that must be output. a f i r s t version of torus has been implemented and is currently being tested. 
	1. 	introduction 
　　　this paper describes the scope and current status of the torus  toronto understanding system  p r o j e c t . 
　　　the main goal of the project is to develop a methodology f o r designing and implementing  understanding  data base management systems 
 udbmss   i . e .   systems which have available 
 a  a data base stored in and maintained by a 
data base management system  dbms   
 b  a natural language understanding system  nlus   serving as a f r o n t end to the dbms  which is given knowledge about the data  can understand and respond to simple english sentences and can engage the user in a dialogue. 
　　　such systems can obviously play a very important role in the future in making data bases available to casual users who have neither the time nor the patience to learn a programming or query language so that they can communicate with the computer. 
　　　as a f i r s t step towards achieving the basic goal of torus  we have designed and implemented a prototype udbms  using a data base of graduate student f i l e s . two of the most important methodol o g i c a l decisions we made are given below: 
 a  we have fixed the type of dbms available to the udbms to be a r e l a t i o n a l system along the lines proposed by codd   1   . this decision enables us to be more e x p l i c i t about the nlus-dbms interface and also makes our work easier since r e l a t i o n a l dbmss o f f e r a more powerful set of  higher l e v e l   commands than other types of dbmss. 
 b  we have decided to base the  understanding  c a p a b i l i t i e s of the nlus on semantic nets  i . e .   directed labelled graphs whose nodes represent conceptual objects and whose edges represent semantic r e l a t i o n s . more s p e c i f i c a l l y   we have based our semantic net representation of knowledge on a case structured representation and the use of a form of the subset and isa r e l a t i o n found in several other representations  1  1   . more information about the torus representation is given elsewhere  s . 
　　　our emphasis has been on modelling an i n s t i t u t i o n a l world rather than a physical world. this fact has influenced much of the design of torus. 
　　　there already e x i s t today several questionanswering systems   e . g .   converse   1     rel   1     lunar  e t c .     whose main difference from torus is that they lack f a c i l i t i e s for  understanding  the on-going dialogue 	 such as a semantic net or pianner-like theorems e t c .   . 	there also e x i s t a few nluss   e . g .   shrdlu   1     elinor   1     margie  etc.  w i t h which we share our methodology to varying degrees. 	it is our b e l i e f   however  t h a t none of these systems  including ours  has succeeded yet in formulating an integrated methodology for constructing nluss and that more of them w i l l have to be b u i l t to t e s t new proposals and to integrate solutions to s p e c i f i c problems in natural language understanding. 
　　　it is assumed that the reader is f a m i l i a r w i t h basic r e l a t i o n a l calculus   l     and with casegrammar terminology   1   . 
　　　throughout the paper we w i l l be using as examples the queries 
    what is john smith's address   and 
 how many recommendation l e t t e r s did we receive for him   
1. the representation 
　　　information is divided i n t o two general categories and is accordingly stored in a dbms available to torus or on the semantic net. 
1 	information t h a t is p a r t of a student's f i l e 
　　　such information is stored in a r e l a t i o n a l dbms in terms of n-tuples that are elements of r e l a t i o n s . 	for example  one of the r e l a t i o n s used for the representation of information regarding student f i l e s is the biodata r e l a t i o n : 
biodata name  address  telephone-*  status-in-
　　　canada  field-of-study  full-or-part-time  underlined a t t r i b u t e s indicate the keys of the r e l a t i o n . one instance of thi& r e l a t i o n   regarding 
　　　
1 
　　　

another r e l a t i o n is 
recommendation-letter  name   date-received  
　　　recommending-person  address  letter  and some instances of i t   regarding  john smith   are 
recommendation-letterc john smith'   1  ' j i m brown'  1 willowdale ave.  toronto  canada'  
a  
recommendation-letter 'john s m i t h '   1  'joe d o e '   '1 charles s t .   toronto  canada 1   b  
where 1 and 1 specify dates 	{year-monthday  and a and b stand f o r the contents of the two 
l e t t e r s . 
　　　we w i l l often r e f e r to the c o l l e c t i o n of student f i l e s stored in the dbms as the data base. 1 information about student f i l e s 
　　　the system also stores  in semantic net form  general knowledge about students  the educational process  and student f i l e s   along with the system's understanding of the on-going dialogue it may be having with a user. it should be noted t h a t sometimes a p a r t i c u l a r item of knowledge w i l l be stored on the semantic net and the data base at the same time  j u s t as it may be remembered  temporarily  by a secretary and also appear in some student's f i l e . 
　　　the semantic net representation is s i m i l a r in several ways to those proposed and used by rumelhart et a l .  and martin   l l     and is described in more d e t a i l elsewhere   1   . our goal here is to give enough information about it so that the reader w i l l understand the examples to be given in the following sections. 
　　　nodes on the semantic net can be concepts  events and c h a r a c t e r i s t i c s . 	thus the generic ideas persok  university  as w e l l as i n s t a n t i a t i o n s  john smith  and  university of toronto  are a l l concepts. 	s i m i l a r l y   the generic idea of receive  such that every p a r t i c u l a r  receiving  	action is i t s i n s t a n t i a t i o n     as w e l l as s p e c i f i c i n s t a n t i a tions of the idea  are a l l events. 	f i n a l l y   	ideas which express states or properties of objects  actions or other properties are c h a r a c t e r i s t i c s . for example  student-number characterizes students and can have as values 1 - d i g i t integers. 
　　　as noted above  an important c l a s s i f i c a t i o n of nodes is whether they represent generic ideas or i n s t a n t i a t i o n s of them. generic nodes are placed   u p s t a i r s   and are denoted by names in c a p i t a l l e t t e r s   while s p e c i f i c instances are put  downstairs  in small l e t t e r s . 
　　　objects on the semantic net are organized in a superset-subset hierarchy  defined in terms of sub set -labelled edges and e xample-of -labelled edges. thus student is a subconcept of person while  john smith  is an example   i n s t a n t i a t i o n   of person and w i l l therefore be represented on the semantic net as shown in fig. 1 a . 
　　　sub-labelled edges can only l i n k objects located u p s t a i r s   while e-labelled edges always 

l i n k a node located upstairs to one located downs t a i r s . 	the properties of any object on the hierarchy are i n h e r i t e d by a l l objects below i t   unless otherwise s p e c i f i e d for any of these 
objects. 
　　　another important r e l a t i o n we w i l l allow  usually between concepts  is the part r e l a t i o n . thus finger is a part of arm which in turn is part of body. note t h a t   in general  properties of objects are not i n h e r i t e d along part-labelled edges. 
　　　an important class of edges are the cases used to specify semantic relations between an event and other objects of the semantic net. the cases we w i l l use are agent  a   objective  1   affected  aff   topic  t   instrument   i     result  r   source  s   destination  d  and neutral  n . the semantics of most of these cases are implied by t h e i r name. 
　　　characteristics have t h e i r own edges l a b e l l e d characteristic {ch  and value  v  which specify respectively the object being characterized and the value of the c h a r a c t e r i s t i c . fig. 1 b  shows two examples. 
　　　note that c h a r a c t e r i s t i c s are meant to define basic properties of objects  such as the mass  charge and v e l o c i t y of an elementary p a r t i c l e   the colour of an object or the s o c i a l insurance number of a person. in many s i t u a t i o n s   however  we w i l l use them to specify that a semantic r e l a t i o n e x i s t s 
　　　
1 
　　　
between two objects when we do not want to e x p l i cate that r e l a t i o n . for example  address w i l l be treated as a c h a r a c t e r i s t i c of person  although a deeper representation would have made e x p l i c i t the semantic r e l a t i o n between a person and what we c a l l his address  fig. 1 . 1   c     . 
　　　sometimes we w i l l want to attach a t h i r d edge l a b e l l e d wrt  with-respect-to  a c h a r a c t e r i s t i c . for example  the c h a r a c t e r i s t i c grade needs a wrtl a b e l l e d edge to specify the course with respect to 
which a student is characterized by a p a r t i c u l a r grade  fig. 1 . 1   d     . 
　　　location  absolute and relative time and duration w i l l a l l be represented in terms of c h a r a c t e r i s t i c s . 
　　　apart from the above-mentioned edges  the representation allows connectives of various kinds 
such as 
before  after  while  temporal  prerequisite  effect  causal  e t c . 
　　　figures 1 and 1 show portions of the semantic net which w i l l be used in the examples that follow. 

for convenience we have omitted sub-labelled edges which l i n k event  characteristic or concept  which are generic objects on the semantic net  to other events  characteristics and concepts. the types of the nodes can be determined by examining the edges that leave them. 
	the important things to note in fig. 	1 are 
- an address can be associated to any person or i n s t i t u t i o n  the union of these generic concepts we have named legal-person  
- current-address is a sub-characteristic of the c h a r a c t e r i s t i c address and i t s d i s t i n g u i s h i n g feature is the fact t h a t when characterized by relative-time  the value of the l a t t e r is always  present . 
　　　in fig. 1 we have defined the scenario of writing-a-recommendation-letter-to-dcs. 
1 relating the a t t r i b u t e s of data base r e l a t i o n s to objects on the semantic net 
　　　most data base a t t r i b u t e s have nodes of the semantic net associated to them. these nodes define the semantics of the corresponding a t t r i butes and they can therefore be used in questionanswering and in determining whether a given r e l a t i o n a l operation on one or more a t t r i b u t e s makes sense. 
　　　for example  to the node of fig. 	1 named current-address we w i l l associate the a t t r i b u t e 
named address of the biodata r e l a t i o n . this means t h a t 
- if someone asks a question involving the value of a person's current address  the system could r e t r i e v e the entry of the address a t t r i b u t e for a biodata r e l a t i o n instance whose name a t t r i b u t e 
has the person's name as value. 
- the semantics of the a t t r i b u t e address are defined by the semantic r e l a t i o n s associated w i t h the node current-address. 
　　　s i m i l a r l y   we can associate the data base a t t r i b u t e s name  recommending-person  date-received and letter to the nodes named person  recommendingperson  date and recommendation-letter of fig. 1 respectively. 
	1. 	understanding input sentences 
　　　in t h i s section we describe the analysis c a r r i e d out by torus when a sentence is presented to it by the user. 
　　　for convenience  the analysis w i l l be p a r t i tioned i n t o a syntactic and semantic component. the syntactic analysis is responsible for producing a parse tree  modified deep structure  of the input sentence  while the semantic analysis is responsible for constructing a semantic graph and f o r i n t e g r a t i n g it to the semantic net. it must be stressed at t h i s point t h a t the modularization and l i n e a r i z a t i o n of the understanding process was adopted only in order to by-pass the main memory constraints of present-day computers and to enable us to see more c l e a r l y the various problems involved. the sole purpose of the syntactic analysis is to i d e n t i f y the syntactic constituents corresponding to most of the semantic units making up the representation of the sentence's meaning. 
1 	syntactic analysis 
　　　the f i r s t step consists of a complete wordby-word morphological analysis of the input sentence during which we deal with problems of word r e c o g n i t i o n   i n f l e c t i o n a l and d e r i v a t i o n a l a f f i x analysis and contractions. this section of 
　　　
1 
　　　
the system is also responsible f o r recognizing contiguous sets of words such as idioms and compound words  and for replacing them with other words or symbols which the rest of the system can understand  e.g.    department of computer science  
w i l l be replaced by   d c s     . 
　　　the output of t h i s section of the algorithm is a table of d i c t i o n a r y e n t r i e s   including multiple entries for ambiguous words  corresponding to the words in the o r i g i n a l sentence. 
　　　the table is passed to an augmented t r a n s i t i o n network  hereafter atn  grammar for syntactic analysis. the analysis is non-deterministic and several parses are possible for the same sentence. however  only one parse is produced at any one time. an i n t e r e s t i n g feature of the parser is the way in which it handles adverbials. usually  adverbials can modify one of several predicates or noun phrases of the input and the modification which is a c t u a l l y correct can only be determined on semantic grounds. the parsing strategy we have adopted ensures that we can r e t r i e v e from the parse tree a l l and only the possible constituents which the adverbial can modify. 
1 	constructing a semantic graph from a parse tree 
　　　by a semantic graph we mean here a graph which involves concepts  c h a r a c t e r i s t i c s and events connected through semantic r e l a t i o n s  cases  connectives e t c .     but not yet integrated to the semantic net. 
　　　the preliminary processing of the parse tree finds possible referents for noun phrases  nps  in the input. each np may be r e f e r r i n g to an already e x i s t i n g object on the semantic net or a new one. 
　　　in the former case  e i t h e r the referent is uniquely i d e n t i f i e d or a bvar  bound variable  node is created  with referent candidates connected to it by cand edges. question words replacing noun groups are represented by nodes labelled       . see fig. 1 a    b  for examples. 
　　　once a head node has been constructed for every np  the system retrieves case frames stored with the predicate of each sentence and attempts to f i n d the appropriate case f i l l e r s . 
　　　the case f i t t i n g algorithm for the second example w i l l construct the   p a r t i a l   semantic graph of fig. 1 a  by using the case frame for receive. 
　　　the verbs be and have are handled in a special way by using functions rather than case frames  since they have many meanings and uses. thus for the f i r s t example  the be function notes that the parse tree f i t s the characteristic-value configuration and checks the s e l e c t i o n a l r e s t r i c tions specified by the address node. the result is the semantic structure shown in fig. 1 b . 
　　　the next step to be carried out is the const r u c t i o n of a graph for each pp or np. each pp or np consists of a head noun and zero or more modifiers. so far we have constructed a node for the head noun and we must now look at the modifiers modifiers can be possessives  r e l a t i v e clauses. 

p a r t i c i p l e s   adjectives or unused pps dominated by the current pp on the parse t r e e . 
　　　for example  possessive modifiers are handled by using a nine-point check l i s t for the various possible semantic r e l a t i o n s between two words involved in a construction of the form  p's n . 
among them are: 
 a  n is a c h a r a c t e r i s t i c of p 	  john's height  
 b  p possesses or owns n 	  jim's b a l l     
 c  n is part of p 	  jim's leg   
 d  p plays a role   f i l l s a case  in some event associated with n   mary's telegram  means  mary sent/received a telegram  . 
　　　note that these cases  and especially  a  and  d   may not be mutually exclusive. thus  as pointed out in section 1   john's address  may be represented e i t h e r in terms of a c h a r a c t e r i s t i c or an implied event  or both. 
　　　the other types of modifiers are also handled through h e u r i s t i c r u l e s   which w i l l not be d i s cussed here. 
　　　once the construction of graphs for the pps and nps of the parse tree is complete  we attempt to determine the system commands to be used for t h i s input sentence  if any. for example  one simple h e u r i s t i c used to determine a command i s : if the determiner is  how-many   then the command is count  returning a number . 
1 　　　not a l l verbs in the dictionary appear as events on the semantic net. for example  the graph for a sentence l i k e 
　 john smith took csc 1 from jim brown  which is shown in fig. 1 c   w i l l have to be mapped into the  deeper  semantic structure shown in fig. 1 d  before it can be integrated with the semantic net. the task of mapping more surface semantic structures to deeper ones is carried out by mapping functions associated with some events or characteristics. 
　　　the final result of this part of the algorithm for our sample sentences is shown in fig. 1. note that each node of the semantic graph constructed is associated with a node of the semantic net shown in figs 1 and 1. more details about this part of the system can be found in . 
this w i l l be done by using syntactic c r i t e r i a and h e u r i s t i c s . 	these c r i t e r i a and h e u r i s t i c s could have been expressed in terms of semantic r e l a t i o n s   but we feel t h a t in every universe of discourse there w i l l be peripheral knowledge  such as recognizing addresses  which w i l l best be integrated i n t o the system through recognition functions rather than an expanded semantic net-
work. 
　　　the i n t e g r a t i o n of the semantic graph to the semantic net is carried out by moving the associations constructed during the previous step  shown in fig. 1 as broken l i n e s   as far  down  along sub- and e-labelled edges as possible. 
　　　

1 	integrating a semantic graph to the semantic net 
　　　due to the properties of the superset-subset hierarchy  there is a unique p o s i t i o n on the semantic net for each semantic graph we wish to integrate. in t h i s section we sketch b r i e f l y t h i s i n t e g r a t i o n process. 
 many generic objects on the semantic net have recognition functions associated to them  which recognize i n s t a n t i a t i o n s of these generic objects. 
　　　consider  for example  the generic concept address-value and i t s associated recognition funct i o n is-address. when the semantic graph f o r   say   john smith's address is 1 st. george s t .   toronto  is being integrated  is-address w i l l be asked to determine whether  1 s t . george s t .   toronto  is an i n s t a n t i a t i o n of address-value. 
　　　portions of the r e s u l t i n g semantic net are shown in fig. 	1 f o r the two sample sentences. 

　　　one of the interesting features of the integrating procedure is that in certain situations it w i l l attempt to create missing cases  which are marked as obligatory  by calling the find-instances function or by using default values represented e x p l i c i t l y on the semantic net. 
thus in integrating the semantic graph for 
 what is his grade   
find-instance w i l l be called to find the relevant course associated with  his grade . to the question  however  
　 what is. his status   the system w i l l take  status  to mean  academicstatus  and w i l l also assume that it is to be considered wrt  dcs   the default value in this case . 
　　　another important feature of the integrating procedure is that it attempts to perform referent determination at a deeper semantic level than that tried earlier. for example  in determining a referent for  his  in 
　 what is his grade   one may consider f i r s t as candidate any male person. during the integration process  however  and as the semantic graph is moved down  it may be determined that the candidates should be 
　　　
1 
　　　
r e s t r i c t e d to students  or graduate-students  or graduate-student-in-dcs . the i n t e g r a t i o n process notes such r e s t r i c t i o n s and eliminates candidates which do not s a t i s f y them. 
	1. 	using the dbms during a dialogue 
　　　once torus has found the  meaning  of an input sentence by constructing a semantic graph and i n t e g r a t i n g it to the semantic net  	it must execute the generated system commands  	if any. this section describes the execution of these commands and the i n t e r p r e t a t i o n of t h e i r outcome. 
　　　the section is divided i n t o three subsections which deal with the commands increasingly closer to the dbms: 
 a  the semantic l e v e l : commands here operate on the data base a t t r i b u t e s with no knowledge about how a t t r i b u t e s are divided i n t o r e l a t i o n s . 
 b  the interface l e v e l : commands here operate on one or more data base r e l a t i o n s . 
 c  the dbms l e v e l : 	commands operate on i n d i v i d u a l data base r e l a t i o n s . 
1 	the semantic level 
　　　the input to t h i s level is a command-list  along with a l i s t of pointers to objects on the semantic net on which these commands w i l l operate. this l e v e l constructs a request for information from the interface l e v e l and sends t h i s request to the i n t e r f a c e . when t h i s information is returned  the semantic net is updated accordingly. 
for the f i r s t example  	the result of t h i s computation is the replacement of the 	'   ' - l a b e l l e d 

node   f i g . 1 . 1   a     b y j o h n s m i t h ' s a d d r e s s   p r o v i d e d t h i s c a n b e f o u n d i n t h e d a t a b a s e . 
　　　　f o r t h e s e c o n d e x a m p l e t w o l e t t e r s o f r e c o m m e n d a t i o n a r e r e t r i e v e d f r o m t h e d a t a b a s e and t h e r e s u l t i n g s e m a n t i c n e t i s shown i n f i g . 1 . 1 . n o t e 
　　　　t h a t t h e receive e v e n t o f t h e i n p u t s e n t e n c e has b e e n i n s t a n t i a t e d t w i c e t o a c c o u n t f o r t h e t w o i n s t a n t i a t i o n s o f receive t h a t w e r e j u s t r e t r i e v e d f r o m t h e d a t a b a s e . 
1 	the 	i n t e r f a c e 	l e v e l 
　　　the interface level decides which relations should be accessed for the commands passed to it by the semantic level and what data base commands should be used. security checking and cost estimation is also carried out at t h i s l e v e l . 
1 	the dbms level 
　　　this l e v e l offers p r i m i t i v e s for maintaining and manipulating a r e l a t i o n a l data base through a system called miniz. details about the system and a larger dbms project called zeta can be found elsewhere  1  1 . 
	1. 	generating english sentences 
　　　the problem of generating a response w i l l be broken down i n t o two parts:  a  selecting the information to be output 
 b  generating a sentence  given the information selected in  a . 
1 	the selector 
　　　the s e l e c t o r ' s main job is to construct a 
　　　graph which contains information relevant to the input statement. in constructing t h i s graph the selector must: 
 a  recover information stored i m p l i c i t l y on the semantic net. for example  it must i n f e r the destination case of the receive event of the second sentence by taking i n t o account the   t r a n s i t i v i t y   property of the supersetsubset hierarchy. 
 b  consider s t y l i s t i c problems such as pronomin a l i z a t i o n   nominalization  modalities  r e l a t i v e clauses and amount of d e t a i l t h a t w i l l be provided in the system's response. 
 c  decide whether it w i l l output a sentence or a np. 
　　　the input to the selector is a l i s t of pointers to objects on the semantic net that const i t u t e the main event or c h a r a c t e r i s t i c of the input sentence   address  and receive respectively for our two examples  or stored information relevant to the input sentence   e . g .   the addressvalue found for the f i r s t example  and the recommending persons along with the dates when the recommendation l e t t e r s were sent for the second example . 
　　　the selector f i r s t copies the p o r t i o n of the semantic net which is to be output  figs. 1 a  and 1 b  respectively for the two examples . it then uses inverse mapping functions to produce a more surface  but s t i l l case-grammar-based  representation of the information to be output. while t h i s mapping is being carried out  nps are constructed f o r the concepts of the answer graph 
　　　
1 
　　　
modality l i s t s are constructed next and a surface ordering rule  sor  is chosen for each verb of the resulting structure. sors  as used here and elsewhere   1  1   basically specify the order in which the system should output the syntactic cases associated to a particular verb. 
1 	the generator 
　　　once constructed  the answer graph is passed to the generator which must construct a sentence from i t . 	this is accomplished by using a version of the simmons-slocum algorithm . 	some of the 
extensions we have incorporated i n t o our generation algorithm are: 
 a  the grammar we use  defined in terms of an 
atn  is more complete than that described in  and allows complementation  r e f l e x i v i z a t i o n and complex nps. 
 b  morphological functions are used to f i n d regular i n f l e c t i o n s of verbs and nouns. 
 c  question-generat ion has been generalized to allow multiple queries. 
　　　more detaiis about the selector and the generator can be found in 	. 
the f i n a l output for the two examples is 
 his address is 1 st. george s t .   toronto  
　　canada  and 
 we have received two l e t t e r s of recommendation from jim brown and joe doe on may 1 and june 
1 . 
	1. 	implementation 
　　　a f i r s t version of torus has been implemented on an ibm 1 ii under os/mvt and is c u r r e n t l y being tested. the languages used for the implementation are spitbol  and l.pak  an extension of spitbol o f f e r i n g graphs and graph patterns . since mini   has been implemented in p l / i   one part of the interface level was w r i t t e n in that language. the input d i c t i o n a r y contains at t h i s time approximately 1 words  the semantic net only 1 nodes and we have w r i t t e n very few mapping  recognition and inverse mapping functions. 
	1. 	concluding remarks 
　　　the system we implemented is in many ways incomplete. apart from expanding the vocabulary  the semantic net and the various tables used  and t e s t i n g the system to determine i t s l i m i t a t i o n s   there are several important features which we are currently researching and propose to add to torus in the near f u t u r e . among them we note 
 a  an i n f e r e n t i a l c a p a b i l i t y based on the semantics of connectives and cases. 
 b  a question-generation f a c i l i t y which w i l l enable the system to resolve d i f f i c u l t i e s it is encountering by asking questions to be answered e i t h e r by the user  the semantic net or the dbms. 
 c  a more general referent determination r o u t i n e based on inference and contextual expectations . 
 d  more general mechanisms for handling conjunct i o n   d i s j u n c t i o n and q u a n t i f i c a t i o n than those currently available in the system. 
　　　we believe at t h i s time that these features can be added without having to modify or even extend the methodology we have been using. we currently are engaged in research on man-machine conversations and expect t h i s research to have a major influence on future versions of torus. 
　　　we believe that torus has made important contributions in two areas of a i : 
	 a  	language understanding 
　　　the main c o n t r i b u t i o n here is in the emphasis we have placed on the design and implementation of 
an integrated language system for a p a r t i c u l a r 
1 
　　　
problem domain  i n t h i s case s t u d e n t f i l e s and t h e e d u c a t i o n a l p r o c e s s . d e s i g n i n g a system w i t h such goals i s and w i l l remain a d i f f i c u l t problem t h a t w i l l r e q u i r e e x p e r t i s e i n combining and p o s s i b l y m o d i f y i n g s o l u t i o n s t h a t have been proposed t o s p e c i f i c language problems   i n p u t   o u t p u t   r e p r e s e n t a t i o n   r e f e r e n t d e t e r m i n a t i o n e t c .   . moreover  a methodology must be developed f o r c o n s i d e r i n g a problem domain and r e p r e s e n t i n g the r e l e v a n t knowledge. we know of o n l y two o t h e r works 
  winograd 	  1     	scragg 	  	which have t a c k l e d t h i s problem. 	the s t u d e n t 	f i l e s w o r l d i s d i f f e r e n t 
from winograd's blocks w o r l d and scragg's k i t c h e n w o r l d p r i m a r i l y 	i n 	t h a t 	the 	r e l e v a n t knowledge 	i s 
m o s t l y i n s t i t u t i o n a l r a t h e r t h a n p h y s i c a l i n n a t u r e and t h i s has n a t u r a l l y l e d us i n t o a d i f f e r e n t s e t o f r e p r e s e n t a t i o n a l p r i m i t i v e s . 
 b  	a p p l i c a t i o n s of ai 
       as we have a l r e a d y mentioned in t h e i n t r o d u c t i o n   	t h e use o f language u n d e r s t a n d i n g systems 	i n data management 	i s 	v e r y d e s i r a b l e and w i l l 	soon become q u i t e necessary 	in o r d e r to make data bases a v a i l a b l e 	t o t h e c a s u a l 	user 	  date bases 	t o t h e people  	i s our s l o g a n   . 	i n o r d e r t o achieve t h i s w e w i l l have t o study 	the problem o f i n t e r f a c i n g 
nluss w i t h dbmss  a problem t h a t is as much w i t h i n ai as those of i n t e r f a c i n g an u n d e r s t a n d i n g system to an ear  speech u n d e r s t a n d i n g     an eye   v i s u a l u n d e r s t a n d i n g   or a body   r o b o t i c s   . r e l a t e d to the i n t e r f a c e p r o b l e m   are the dbmss' problems of s e l e c t i n g a r e l a t i o n a l schema  g i v e n a semantic network d e s c r i p t i o n of a d a t a base  m a i n t a i n i n g the c o n s i s t e n c y of a   r e l a t i o n a l   data base by u s i n g t h e a s s o c i a t e d semantic n e t w o r k   and d e c i d i n g on issues of c o s t and s e c u r i t y r e g a r d i n g the d a t a base b y   a g a i n   u s i n g the a s s o c i a t e d semantic network. we t a c k l e d some of these p r o blems and t h e r e are a l r e a d y more r e c e n t r e s u l t s 
  schmid and swenson 	  1     	roussopoulos 	  	t h a t have been i n f l u e n c e d by torus. 
       t r a d i t i o n a l approaches 	to data base management emphasize t h e s y n t a x of data using such phrases as 	  r e p e a t i n g group  	e t c . 	the r e l a t i o n a l 
approach  though s t i l l s y n t a c t i c   i s moving away from s y n t a x     r e l a t i o n s       f u n c t i o n a l dependenc i e s     e t c .   . however  problems s t i l l e x i s t due to the l a c k of semantics of t h e r e a l w o r l d . torus 
is 	i n t e n d e d to be a b r i d g e to t h i s 	realm. 
acknowledgements 
       we would l i k e to acknowledge the c o n t r i b u t i o n s of w a l t e r b e r n d l   lindsay watt and hector levesque 
in t h e d e s i g n and i m p l e m e n t a t i o n of the torus 
system. moreover  we are t h a n k f u l to stewart s c h u s t e r   denis t s i c h r i t z i s and the d a t a management group a t t h e u n i v e r s i t y o f toronto f o r t h e i r c o o p e r a t i o n on t h e j o i n t torus/zeta p r o j e c t . 
f i n a l l y   we are g r a t e f u l to angie b l o n s k i and v i c k y shum f o r t h e i r h e l p i n t y p i n g and p r e p a r i n g t h e f i g u r e s f o r t h i s paper. 
t h i s r e s e a r c h was s u p p o r t e d in p a r t by t h e 
department of communications of canada and t h e n a t i o n a l 	research c o u n c i l o f canada. 
