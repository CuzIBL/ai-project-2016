 
   a heuristic is good on a search space to the extent that it allows the prediction of which states are near to the goal. in this paper heuristics are investigated on several different search spaces. a measure is proposed for assessing the predictive accuracy of a given heuristic on a given search space. the measure sheds light on characteristics of the traveling salesman problem that make it computationally more difficult to solve than the minimum spanning-tree problem. 
introduction 
   a search space 1 is a quadruple  1  o  /  g   where 1 is a set of states  o is a set of operators for moving from state to state  / is a set of initial states  and g is a set of goal states  see handbook ai '1 and banerji  '1 . the problem is to find the sequence of operators that connects some initial state to a 
   goal state. to avoid exhaustive search  the search algorithm employs  as a guide  a heuristic evaluation function / nilsson  '1 . 
   to characterize the utility of / on 1 a measure n1v is created. the author hypothesizes that difficult problems can be distinguished from easy problems with niv. difficulty is traditionally related to computational complexity  but niv directly characterizes relationships within the search space. 
formalization 
   niv on  1  f  tells the degree to which similar states have similar f values. two states are similar  if they are connected by an operator. to handle  similar  for / values the following terms are introduced: equivalence classes of states  heuristic-predictions  and inversions. the equivalence class 1 i is defined to be { s | s e 1 and s can be reached from / by a sequence of i operations } the heuristic-prediction function h 
on s e 1 is h s  = max {f w    w e s1 +  and 1 move connects s to w }. the ordering imposed by h on s1 is compared to the 
this work was supported in part by a wayne state university faculty development grant. 

results 
mst and ts 
two important graph problems are the minimum-cost 
spanning tree problem  mst  and the traveling salesman problem  ts . both involve weighted graphs and the search for a subgraph with certain properties. in the mst a subgraph is desired that spans the graph and has minimal cost. in the ts a cycle is desired that crosses every vertex and has minimal cost. for a graph with e edges  the solution to the mst requires o eloge  time steps. the only known algorithms to solve the ts require more than a polynomial amount of time  garey and johnson  '1  why are these two problems of such different time complexity  
   for many combinatorial problems s is part of a power set p on some primitives. consider  for example  the complete 1-node graph with edges a  b  . . .  f and weights w a   . . .  w f . s msl = {s st p { a w a    . . .   f w f  }  and  s    1 }. in order that smst = sts  a modified ts is henceforth considered in this paper  where the goal on an n-node graph has n-l edges. this modified ts is also np-compiete  garey and johnson  '1 . a reasonable /for ts follows: 
/ts { x1w x       xj w xj  }  
 w x   + ¡ö     w x    1 if x   .... x  contains no cycles or 
figure 1. nivj 1x  for j from 1 to 1 and x e {tsaincq  ts  mst}. 
for 1 the relationship between niv j s1 fts  and nivj s1/mst  is similar to that for s1. this evidence supports the hypothesis that more difficult problems have more niv. however  at any given position j there exists a graph such that niv  sifts    nivj sif mst   where i e {1}. just the average over the 1 graphs is 
r. rada 1 
consistently  significantly higher for ts than for mst. 
   graphs were also studied whose edge weights satisfy the triangle inequality  a ineq . approximation algorithms for ts aineq can propose a solution whose length is guaranteed to not be greater than 1 times the length of an optimal tour  reingold  et al  '1 . no such algorithms exist for the unconstrained ts. thus one suspects that by some standard of search space  difficulty  d that d mst    d tsaineq    d ts . this author hypothesized that n1v would order these 1 problems as d did. to investigate this hypothesis the computer program was amended to generate 1 graphs whose edge weights satisfied the a ineq. for each graph the program chose 1 nodes whose coordinates were randomly chosen from the set {1  . . .  1}. the edge weights thus ranged from 1 to 1. 
rule-based planning systems  like strips and dcomp 
 nilsson  '1   fit the framework of this paper. for a simple example  denote the registers of a computer by r  and the contents of r; by cj. the s of ss is { r1 c     r1 c1    r1 c1    r1 c1 
 }  where c1 e {1  a  b}. the initial state is { r 1 a    r1 b    r1    r1 }. one exchange problem e 1  has the goal of { r   1    r1    r1 a    r1 b }. another exchange problem e1 has the goal of { r1 
 b    r1 a    r1    r1 }. the operator is the assignment rule in nilsson  '1 : 
rule: assign  rj a rj b  precondition:  rha    rjb  delete:  rj a  assert:  rj b  
1 r. rada 
the heuristic f s  tells the number of registers in s whose contents are the same as the corresponding registers in the goal. both e  and e1 can be solved in 1 steps. e1 seems harder  since for it a step from s  to si+1 must be made such that h s     h si+1 . application of niv to e  and e1 reveals that niv is much higher for e1 than e . this supports the hypothesis that niv distinguishes problems by their difficulty. 
extensions: backward-chaining and search algorithms 
¡¡¡¡the definition of heuristic-prediction h involves looking from 1  to 1i+1 and thus is related to forward-chaining. a small amendment to h requires the new function bh to look backward from 1  to s . . for s e s  bh s  = max{ f w    we si-1 and s and w are connected by o}. for all of the previously mentioned 
experiments  bh  as well as h  was used. when h is replaced by bh in the definition of niv  a new function  called bniv  is produced. for the function optimization and rule-based problems bniv showed the same tendencies as niv did-namely  the values of bniv on the harder problems were larger than on the easier problems. bniv for ts is not everywhere bigger than bniv for mst. if step 1 in the definition of bniv  and niv  is amended so that f s  =/ .sj +1  - bh sj+1   bh si+1    then bniv  and niv  of ts is everywhere greater than bniv  and niv  of mst. 
another direction in which to extend the applicability of 
niv is that of relating the performance of search algorithms to the niv of search spaces. consider a class of search algorithms a = {a   a1  . . .}. each a  proceeds through an  ssf  for which the state space s has been divided into equivalence classes sj  as defined earlier. furthermore  a  goes from s  to s: to     
  sk by emphasizing the states in each equivalence class whose / value places those states in the top i positions. one can show that over all possible ss and/those on which a   performs well have  on the average  smaller niv values than those on which a l+1 performs well. details of this argument can be found in  rada  '1 . 
discussion 
   an efficient search algorithm examines only a relatively small number of the states in a search space before finding a solution. heuristics permit a search to explore efficiently  but a 
   given heuristic is good for some problems and not for others. how can one characterize a heuristic's power vis-a-vis a particular class of search spaces  a heuristic must  in some sense  predict which states in the search space are close to the goals. often  easily-solved problems are those for which a heuristic / exists such that similar states have similar / values  see the continuity argument of lenat  '1 . this  similar-state --  similar-value  notion has been formalized in this paper by the introduction of predictions and a measure niv  where niv quantifies the accuracy of the predictions. 
   the hypothesis of this paper is that niv can distinguish problems by their difficulty. theoretical considerations reveal that for a search space and heuristic on which depth-first  best-first search finds the solution  niv 1 sif  = 1  for all j. an easy problem  like mst  has the property that niv 1 stf  = 1  for all j. to further test the validity of the hypothesis that niv varies in proportion to problem difficulty  a large number of experiments have been performed. three famous combinatorial graph problems  mst  tsaineq and ts  were analyzed on the computer. the computational complexity of mst is less than that of ts  and niv for mst proves experimentally to be less  on the average  than niv for ts. the experiments also demonstrate several phenomena which require more study before they can be considered evidence for or against the hypothesis. to demonstrate the applicability of this paper's methodology on other than graph problems  function optimization and rule-based planning have been tested; the results support the hypothesis. 
   characterizing the utility of heuristics is an important step in the development of a theory of heuristics. constraints in a search space must be advantageously utilized by good search algorithms  pearl  '1 . by noting what a heuristic says about the search spaces on which it is useful  as niv docs   one may begin to understand how a heuristic benefits from constraints. one next step towards a theory of heuristics and search spaces is to characterize hard and easy problems by their niv values. 
acknowledgements: thanks to the referees and graduate student ching-chio sheu. 
