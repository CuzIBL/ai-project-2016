 
in   montemerlo et al. proposed an algorithm called fastslam as an efficient and robust solution to the simultaneous localization and mapping problem. this paper describes a modified version of fastslam that overcomes important deficiencies of the original algorithm. we prove convergence of this new algorithm for linear slam problems and provide real-world experimental results that illustrate an order of magnitude improvement in accuracy over the original fastslam algorithm. 
1 	introduction 
simultaneous localization and mapping  slam  is a highly active research area in robotics and ai. the slam problem arises when a moving vehicle  e.g. a mobile robot  submarine  or drone  simultaneously estimates a map of its environment and its pose relative to that map. in the absence of global position information  the vehicle's pose estimate will become increasingly inaccurate  as will its map. since maps may contain thousands of entities  acquiring large  accurate maps is a challenging statistical estimation problem  especially when performed in real-time. 
　most present-day research on slam originates from a seminal paper by smith and cheeseman   which proposed the use of the extended kalman filter  ekf  for solving slam. this paper is based on the insights that errors in the map and pose errors are naturally correlated  and that the covariance matrix maintained by the ekf expresses such correlations. newmann  recently proved that the ekf converges for linear slam problems  where the motion model and observation model are linear functions with gaussian noise  see below . 
　unfortunately  ekf covariance matrices are quadratic in the size of the map  and updating them requires time quadratic in the number of landmarks n. this quadratic complexity has long been recognized to be a major obstacle in scaling slam algorithms to maps with more than a few hundred features. it also limits the applicability of slam algorithms to problems with ambiguous landmarks  which induces a data association 
problem  1; 1 . today's most robust algorithms for slam with unknown data association maintain multiple hypotheses  tracks   which increase their computational complexity. 
　consequently  there has been a flurry on research on more efficient slam techniques  see e.g.   . one group of researchers has developed techniques that recursively divide maps into submaps  thereby confining most computation to small regions. some of these approaches still maintain global correlations among those submaps  hence are quadratic but with a much reduced constant factor  1; 1; 1; 1 . others restrict the update exclusively to local maps   hence operate in constant time  assuming known data association . 
　a second group of researchers has developed techniques that represent maps through potential functions between adjacent landmarks  similar to markov random fields. the resulting representations require memory linear in the number of landmarks  1; 1 . under appropriate approximations  such techniques have been shown to provide constant time updating  again for known data association . unfortunately  no convergence proof exists for any of these extensions of the ekf  even for the generic case of linear slam. furthermore  if landmarks are ambiguous  all of these approaches have to perform search to find appropriate data association hypotheses  adding a logarithmic factor to their update complexity. 
　the fastslam algorithm  proposed in  as an efficient approach to slam based on particle filtering   does not fall into either of the categories above. fastslam takes advantage of an important characteristic of the slam problem  with known data association : landmark estimates are conditionally independent given the robot's path . fastslam uses a particle filter to sample over robot paths. each particle possesses n low-dimensional ekfs  one for each of the n landmarks. 
this representation requires o nm  memory  where m is the number of particles in the particle filter. updating this filter requires 1 m log n  time  with or without knowledge of the data associations. however  the number of particles m needed for convergence is unknown and has been suspected to be ex-
ponential in the size of the map  in the worst-case. 
　this paper proposes an improved version of the fastslam algorithm. the modification is conceptually simple: when proposing a new robot pose-an essential step in fastslam*s particle filter-our proposal distribution relies not only on the motion estimate  as is the case in fastslam   but also on the most recent sensor measurement. such an approach is less wasteful with its samples than the original fastslam algorithm  especially in situations where the noise in motion is high relative to the measurement noise. 
　to obtain a suitable proposal distribution  our algorithm linearizes the motion and the measurement model in the same manner as the ekf. as a result  the proposal distribution can be calculated in closed form. this extension parallels prior work by doucet and colleagues  who proposed a similar modification for general particle filters  and markov chain monte carlo techniques for neural networks . it is similar to the arc reversal technique proposed for particle filters applied to 

robotics 	1 

bayes networks   and it is similar to recent work by van der merwe   who uses an unscented filtering step  for generating proposal distributions that accommodate the measurement. 
　while this modification is conceptually simple  it has important ramifications. a key contribution of this paper is a convergence proof for linear slam problems using a single particle. the resulting algorithm requires constant updating time. to our knowledge  the best previous slam algorithm for which convergence was shown requires quadratic update time. furthermore  we observe experimentally that our new fastslam algorithm  even with a single particle  yields significantly more accurate results on a challenging real-world benchmark  than the previous version of the algorithm. these findings are of significance  as many mobile robot systems are plagued by control noise  but possess relatively accurate sensors. moreover  they contradict a common belief that maintaining the entire covariance matrix is required for convergence . 
1 	simultaneous localization and mapping 
slam addresses the problem of simultaneously recovering a map and a vehicle pose from sensor data. the map contains 
n features  landmarks  and shall be denoted 
the path of the vehicle will be denoted  is a time index and st is the pose of the vehicle at time t. 
 most state-of-the-art slam algorithms calculate  or approximate  variants of the following posterior distribution: 
 1  
where . 	is a sequence of measurements  e.g.  
range and bearing to nearby landmarks   and is a sequence of robot controls  e.g.  velocities for robot wheels .  as usual  we assume without loss of generality that only a single landmark is observed at each time the variables are data association variables - each specifies the identity of the landmark observed at time initially  we assume is known; we relax this assumption below. 
　to calculate the posterior  1   the vehicle is given a probabilistic motion model  in the form of the conditional probability distribution this distribution describes how a control asserted in the time interval affects the 
resulting pose. additionally  the vehicle is given a probabilistic measurement model  denoted describing how measurements evolve from state. in accordance to the rich slam literature  we will model both models by nonlinear functions with independent gaussian noise: 
 1   1  
here g and //. are nonlinear functions  and 	and 1t are gaussian noise variables with covariance 	  and 	  respectively. 
1 	fastslam 
fastslam  is based on the important observation  that the posterior can be factored 
	 1  
this factorization is exact and universal in slam problems. it states that if one  hypothetically  knew the path of the vehicle  the landmark positions could be estimated independently of each other  hence the product over n . in practice  of course  one does not know the vehicle's path. nevertheless  the independence makes it possible to factor the posterior into a term that estimates the probability of each path  and tv terms that estimate the position of the landmarks  conditioned on each  hypothetical  path. 
　fastslam samples the path using a particle filter. each particle has attached its own map  consisting of n extended kalman filters. formally  the th particle contains a path along with n gaussian landmark estimates  described by the mean and covariance 
 1  
　we briefly review the key equations of the regular fastslam algorithm  and refer the reader to . each update in fastslam begins with sampling new poses based on the most recent motion command 
 1  
note that this proposal distribution only uses the motion command ut  but ignores the measurement 
　next  fastslam updates the estimate of the observed landmark    according to the following posterior. this posterior takes the measurement into consideration: 
here is a constant. this posterior is the normalized product of two gaussians as indicated. however  if is non-linear  the product will not be gaussian in general. to make the result gaussian  fastslam employs the standard ekf  trick  : g is approximated by a linear function  see below . under this approximation   1  is equivalent to the measurement update equation familiar from the ekf literature . 
　in a final step  fastslam corrects for the fact that the pose sample has been generated without consideration of the most recent measurement. it does so by resampling the particles . the probability for the th particle to be sampled 
 with replacement  is given by the following variable commonly referred to as importance factor: 

as shown in   the resampling operation can be implemented in 1 m log n  time using trees  where m is the number of samples and n the number of landmarks in the map. however  the number of particles m needed for convergence remains an open question. 
　fastslam has been extended to slam with unknown data associations . if the data association is unknown  each particle in fastslam makes its own local data association decision by maximizing the measurement likelihood. the formula tor finding the most likely data association maximizes the resulting importance weight: 
1 	robotics 		 1  
here makes the dependence of the factor on the variable explicit. a key characteristic of fastslam is that each particle makes its own local data association. in contrast  ekf techniques must commit to a single data association hypothesis for the entire filter. results in  show empirically that this difference renders fastslam significantly more robust to noise than ekf-style algorithms. 
1 fastslam 1 
our new fastslam algorithm is based on an obvious inefficiency arising from the proposal distribution of regular fastslam. in regular fastslam  the pose is sampled in accordance to the prediction arising from the motion command as specified in  1 . it does not consider the measurement 
acquired at time instead  the measurement is incorporated 
through resampling. this approach is particularly troublesome if the noise in the vehicle motion is large relative to the measurement noise. in such situations  sampled poses will mostly fall into areas of low measurement likelihood  and will subsequently be terminated in the resampling phase with high probability. unfortunately  many real-world robot systems are characterized by relatively high motion noise. as illustrated in the experimental results section of this paper  the waste incurred by this inefficient sampling scheme can be significant. 
1 sampling the pose 
fastslam 1 implements a single new idea: poses are sampled under consideration of both the motion and the measurement this is formally denoted by the following sampling distribution  which now takes the measurement into consideration: 
 1  
in comparison to  1   incorporating the measurement only makes sense if we incorporate our current estimate of the observed landmark-obtained from the variables 
 which are included of the condi-
tioning variables above . so in essence  the difference to fastslam is that the measurement this change has important ramifications. 
　the proposal distribution  1  can be reformulated as follows: the probability of the measurement calculating the latter involves an integration over possible landmark locations 
　unfortunately  sampling directly from this distribution is impossible in the general case; it does not even possess a closed form. luckily  a closed form solution can be attained if g is approximated by a linear function  h may remain non-linear! : 

denotes the predicted measure-
                   the predicted robot pose  and the predicted landmark location. the matrices and the jacobians  first derivatives  of with respect to and s  respectively: 
 1   1  
under this ekf-style approximation  the proposal distribution  1  is gaussian with the following parameters: 
 1  
 1  
 1  
1 	updating the observed landmark estimate 
the updating step remains the same as in fastslam  see  1  . as stated in the previous section   is linearized to retain gaussianity of the posterior. this leads to the following update equations  whose derivation is equivalent to that of the standard ekf measurement update : 

1 	the importance weights 
resampling is necessary even in our new version of fast-
slam  since the particles generated do not yet match the desired posterior. the culprit is the normalizer  in  1   which may be different for different particles m. this normalizer is the inverse of the probability of the measurement under the th particle: 	to 
account for this mismatch  our algorithm resamples in proportion to the following importance factor: 
unknown data associations 
the approach for handling data association is similar to the one in regular fastslam: again  we select the data association that maximizes the probability of the measurement for the m-th particle: 


robotics 	1 

at first glance  one may be tempted to substitute wt m  for the probability on the right-hand side  as in regular fast-
slam. however  does not consider the sampled pose whereas the expression here does. this leads to a slightly 
different probability  which is calculated as follows. 

linearization of g leads to a gaussian over zt with mean and covariance both are functions of 
the data association variable 
1 	feature management 
finally  in cases with unknown data associations  features have to be created dynamically. as is common for slam algorithms   our approach creates new features when the measurement probability in  1  is below a threshold. however  real-world data with frequent outliers will generate spurious landmarks using this rule. following   our approach removes such spurious landmarks by keeping track of their posterior probability of existence. our mechanism analyzes measurement to the presence and absence of features. observing a landmark provides positive evidence for its existence  whereas not observing it when  falls within the robot's perceptual range provides negative evidence. the posterior probability of landmark existence is accumulated by the following bayes filter  whose log-odds form is familiar from the literature on occupancy grid maps : 
 1  
here 
mark 	s the probabilistic evidence provided by a measurement. under appropriate definition of the latter  this rule provides for a simple evidence counting rule. if the log odds drops below a predefined threshold  the corresponding landmark is removed from the map. this mechanism enables particles to free themselves of spurious features. 
1 	convergence 
a key result in this paper is the fact that our new version of 
fastslam converges tor m=1 particle  for a restricted class of linear gaussian problems  the same for which kfs converge  1; 1  . specifically  our result applies to slam problems characterized by the following linear form: 
 1  
 1  
linear slam can be thought of as a robot operating in a cartesian space equipped with a noise-free compass  and sensors that measure distances to features along the coordinate axes. the following theorem  whose proof can be found in the appendix  states the convergence of our new fastslam variant: 
　theorem. for linear slam  fastslam with a/=l particles converges in expectation to the correct map if all features are observed infi nitely often  and if the location of one feature is known in advance. 
　this theorem parallels a similar result previously published for the kalman filter  1; 1 . however  this result applies to the kalman filter  whose update requires time quadratic in the number of landmarks n. with a/=l  the resampling step becomes obsolete and each update takes constant time. to our knowledge  our result is the first convergence result for a constant-time slam algorithm. it even holds if all features are arranged in a large loop  a situation often thought of as the worst case for slam problems . 
1 	experimental results 
systematic experiments showed that fastslam 1 provides excellent results with surprisingly few particles  including m= 1. most of our experiments were carried out using a benchmark data set collected with an outdoor vehicle in victoria park  sydney . the vehicle path is 1km long  and the map is 1 meters wide. the vehicle is equipped with differential gps that is used for evaluation only. fig. la shows the map of the terrain  along with the path obtained by raw odometry  which is very poor  the average rms error is 1 meters . this data set is presently the most popular benchmark in the slam research community . 
figs  lb&c show the result of applying fastslam with 
1 	robotics m = l particle to the data set  without  fig. lb  and with  fig. lc  the feature management approach described in section 1. in both cases  the estimated vehicle path is shown 

figure 1: rms map error for regular fastslam  dashed line  versus fastslam 1  solid line  on  a  the victoria park data  b  simulated data. fastslam 1's results even with a single particle are excellent. as a solid line  and the gps information is shown as a dashed line. results of the same accuracy were previously achieved only with 1{n1  ekf-style methods  and with fastslam using a/=1 j particles. the feature management rule reduces the number of landmarks in the map from 1  fig. lb  to 1  fig. lc . 
   fig. 1 plots the rms error of the vehicle position estimate as function of the number of particles for the victoria data set  panel a  and for synthetic simulation data  panel b  taken from . while our new algorithm does approximately equally well for any number of particles  regular fastslam performs poorly for very small particle sets. we suspect that the poor performance of regular fastslam is due to the fact that the vehicle possesses relatively inaccurate odometry  see fig. la   yet uses a low-noise range finder for landmark detection  a common configuration in outdoor robotics   leading to the generation of many particles of low likelihood. 
   the small number of examples needed to obtain state-ofthe-art estimation translates to unprecedented efficiency of the new filter. the following table shows the results required to process the victoria park data set on a 1ghz pentium pc: 
 ~ekf 	i 1 sec i regular fastslam  m=1 particles 1 sec 
	i fastslam 1  m=1 particle | 	1 sec | 
in comparison  the data acquisition required 1 seconds. thus  while ekfs cannot be run in real-time  our new algorithm requires less than 1% of the vehicle's trajectory time. 
1 	discussion 
this paper describes a modified fastslam algorithm that is uniformly superior to the fastslam algorithms proposed in . the new fastslam algorithm utilizes a different proposal distribution which incorporates the most recent measurement in the pose prediction process. in doing so  it makes more efficient use of the particles  particularly in situations in which the motion noise is high in relation to the measurement noise. 
　a main contribution of this paper is a convergence proof for fastslam with a single particle. this proof is an improvement over previous formal results  which applied to algorithms much less efficient than the current one. in fact  this result is a first convergence result for a constant time slam algorithm. 
　the theoretical finding is complemented by experimental results using a standard benchmark data set. the new algorithm is found to outperform the previous fastslam algorithm and the ekf approach to slam by a large margin. in fact  a single particle suffices to generate an accurate map of a challenging benchmark data set. despite this surprising result  the use of multiple particles is clearly warranted in situations with ambiguous data association. we believe that our results illustrate that slam can be solved robustly by algorithms that are significantly more efficient than ekf-based algorithms. 
1 	acknowledgments 
this work was supported by darpa's mars and mars1 program. daphne koller was supported by the office of naval 
research  young investigator  pecase  grant n1-1. we thank the hertz foundation for their support of michael montemerlo's graduate research. 
