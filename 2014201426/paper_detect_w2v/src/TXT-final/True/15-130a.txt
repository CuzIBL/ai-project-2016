 
learning theory is the study of systems that implement functions from evidential states to theories. the theoretical framework developed in the theory makes possible the comparison of classes of algorithms which embody d i s t i n c t learning strategies along a variety of dimensions. such comparisons yield valuable information to those concerned with inference problems in cognitive 
science 	and 	a r t i f i c i a l 	intelligence. 
the present paper employs the framework of learning theory to study the design specifications of inductive systems which are of interest in the domain of 
language acquisition. 
section 1: 	introduction 
¡¡¡¡¡¡learning theory is tho investigation of systems that implement functions from evidential states to theories. of central concern is the characterization of conditions under which such functions stabilize to accurate theories of a given environment. within the theory  the informal notions of  evidence   
 theory     s t a b i l i z a t i o n      accuracy   and  environment  are replaced by precise d e f i n i t i o n s . alternative formulations of these concepts y i e l d alternative models within the theory. the vigorous development of learning 
theory began with a celebrated paper by 
gold  1 . angluin & smith  1  provide a valuable review of formal results. 
¡¡¡¡¡¡learning theory is motivated by both s c i e n t i f i c and technological concerns. s c i e n t i f i c a l l y   the theory 
has proved useful in the analysis of human learning  p a r t i c u l a r l y   language acquisition  see osherson  stob & weinstein  forthcoming  for a review of issues . technologically  the theory helps specify what is learnable 1n p r i n c i p l e   and may thus guide the construction of practical systems of inductive inference. 
¡¡¡¡¡¡learning theory yields potentially valuable insights about problems of inductive inference in the context of 
cognitive science and a r t i f i c i a l intelligence. the theory provides the framework for systematic comparison of various learning algorithms. such comparisons are particularly useful in determining the relative strength of classes of algorithms which embody d i s t i n c t abstract learning strategies  in assessing their resource requirements  and in predicting their 
behavior in various environments. w h e n combined with empirical studies of language acquisition  learning theory may provide constraints on the character of the learning strategies implemented by children  and reflect in turn on the character of the class of languages which m a y be a c q u i r e d . such studies in c o g n i t i v e science m a y be of importance to system builders in a r t i f i c i a l intelligence. they suggest that the search for ideal learning strategies' is not well motivated. rather  by focussing on learners who embody different  styles  of learning  and by investigating their properties  the theory allows a comparison of the optimality of d i s t i n c t approaches to learning along a multitude of dimensions. in addition  through the analysis of classes of algorithms that embody d i s t i n c t learning strategies  t h i s t h e o r e t i c a l framework m a y provide a 
useful complement to studies of ad hoc systems b u i l t to perform inductive inference in problem domains of limited 
scope. 
¡¡¡¡¡¡the present paper reviews some of our recent work on practical inference and relates it to problems in language acquisition. we consider design specifications for inductive systems relevant to  a  the speed of inference  
 b  the simplicity of inferred theories   c  the likelihood of i n f e r e n t i a l success  and  d  the resilience of such systems in environments subject to informational imperfection. attention 

is r e s t r i c t e d to l e a r n i n g paradigms in which only   p o s i t i v e i n f o r m a t i o n   is a v a i l a b l e about the language or d a t a - s e t to be i n f e r r e d ; d i r e c t i n f o r m a t i o n about nonmembership is not o f f o r e d to the l e a r n e r ; angluin & smith  1  survey r e s u l t s relevant to l e a r n i n g paradigms in which both p o s i t i v e and negative i n f o r m a t i o n is assumed a v a i l a b l e . 
       our e x p o s i t i o n is organized as f o l l o w s . the next s e c t i o n provides d e f i n i t i o n s and c o n s t r u a l s at the heart of contemporary l e a r n i n g t h e o r y . section 1 e x h i b i t s theorems proper to the t o p i c s  a  -  d  l i s t e d above. proofs of these theorems can be found in 
osherson  	stob 	& 	weinstein 	 1  
1d . in section 1 we consider the r e l a t i o n between r e s u l t s reviewed here and language a c q u i s i t i o n by c h i l d r e n . 
	d. osherson et al. 	1 
	1 	learning 	functions 
       let g be a f i x e d   computable i s o m o r p h i s m between seq and n. a learning function is any f u n c t i o n from n i n t o m; such a f u n c t i o n w i l l be thought of as o p e r a t i n g on members of seq   v i a g   y i e l d i n g indices for r e c u r s i v e l y enumerable s e t s . learning f u n c t i o n s may be t o t a l or p a r t i a l   r e c u r s i v e or n o n r e c u r s i v e . the   p a r t i a l   r e c u r s i v e learning f u n c t i o n s are just ¦µ  ¦µ 1   . . .   ¦µ the class of a l l l e a r n i n g f u n c t i o n s is denoted: f. the class of a l l recursive l e a r n i n g f u n c t i o n s 
  p a r t i a l 	or 	t o t a l   	is 	d e n o t e d : 	f r e c . 
1 convergence  identification 

section 1: the gold modol 
1 sequences  languages  texts 
n is the set of natural numbers. 
we take the notions finite sequence  in n  and infinite sequence  in n  to be basic. the set of all finite sequences is denoted: seq  for n ¡ê n  and infinite sequence  t: rng t  is the set of numbers appearing in t; tn is the nth member of t; and t n is the finite sequence of length n in t. 
     let p1. p1 pi ... be a fixed list of all partial recursive functions of one variable  and assume the 1 ist to be acceptable in the sense of rogers  1  ch. 1 . for i ¡ê n  let w1 domain pi  the recursively enumerable subset of n with index i  languages are 
identified with nonempty members of {w1 € n . the collection of all languages is denoted: . for l ¡ê   1 c n  1f l = wi then 1s said to be for l. 
section 	1: 	practical 	learning 
	1 	e f f i c i e n t 	inference 

     a text for l ¡ê &1  is any infinite sequence such that rng t  = l  the class of all texts for l is denoted: tl. given a collection  l  of languages. 
 t  denotes ul € l   the class of all texts for languages 1n l. 
       useful l e a r n i n g must not take too much t i m e . this vague admonition can be resolved i n t o two demands:   i   the l e a r n e r must not examine too many inputs 
before s e t t l i n g for good on a correct h y p o t h e s i s   and  1  the learner must not spend too long examining each i n p u t . learners s a t i s f y i n g   i   w i l l be called   t e x t - e f f i c i e n t ;   learners satisfying 

 1t  will be called  time-efficient;  learners satisfying both  i  and { i i   
will be called  efficient.  	in this section 	these 	requirements 	are formulated precisely and examined for their impact on identifiablllty. 
1.1 	text-efficiency 1.1 time efficiency ¡¡¡¡¡¡proposition 1 shows that text efficiency is not a restrictive design feature relative to the class of all learning functions. in contrast  the next proposition shows that text 
efficiency is restrictive relative to the class of recursive learning functions.      indeed  any h such that h x    x almost everywhere can be chosen in proposition 1. 
	1.1 	efficiency 
¡¡¡¡¡¡let i c re 1  and let h be a total recursive function. ¦µi is said to identify l h-efficientlyy just in case  i  ¦µi identifies l text e f f i c i e n t l y with respect to f r e c  in particular  ¦µi identifies l   and  ii  ¦µj is h-time efficient for l. h-efficiency  that is. combines the virtues of text efficiency  with respect to f r e c   and h-time efficiency. the next proposition shows that  for any h  h-efficiency is more restrictive than text efficiency as a design feature of recursive learning 
¡¡¡¡¡¡functions. 
¡¡¡¡¡¡proposition 1: for every total recursive function  h  there is a collection  l  of languages such that 
 i  some f € frec identifies l text efficiently  but  ii  no ¦µ € frec identifies l h-efficiently. 
¡¡¡¡¡¡proposition 1: for some total recursive function  h  there is l c re such that  i  some f € frec identifies l text efficiently   ii  some ¦µi identifies l h-time e f f i c i e n t l y   but   i i i   no ¦µj identifies l h-efficiently. 
1 simple conjectures 
¡¡¡¡¡¡to be useful  a learner should not only converge rapidly to a correct theory of its environment  it should also converge to a relatively simple theory: excessively complex theories  even if true  are of l i t t l e practical use. to study the impact of such simplicity constraints on learnability  a total recursive size measure  s:n -  n  is now imposed on our acceptable ordering of partial recursive functions. i n t u i t i v e l y   s may be conceived as mapping indices to sizes  s i  being the length of the program for ¦µ1 corresponding to index i. the measure is governed by the following two axioms  
due to blum  1b . 
¡¡¡¡¡¡axiom 1: for all i € n  there are only finitely many j € n such that s j    i. 
	axiom 	1: 	the 	predicate 	 j 	€ 
s l 1    for ifj € n  	is decidable. 
d. osherson et al. 1 
define the f u n c t i o n ms:¡ãre -  n as 
follows. 	for 	l 	€ 	re  	re l  
uj  1k  wk = l & s k  = j   . thus  ms l  is the size of the smallest program that accepts l. concern about simple conjectures may take the f o l l o w i n g form. let g be a total recursive function  let f € f  and let l c re. f is said to identify l g-s1mply just in case f i d e n t i f i e s l  and for a l l t € tl  f converges on t to an index  j  such that s j    g ms rng t  . to exemplify  let g be  x.1x. then f i d e n t i f i e s l g-simply just in case f identifies l  and for a l l l € l and t € t l   f converges on t to an index of size no greater than twice ms l   the size of the smallest program that accepts l * rng t  . 
	text 	efficiency 	and 	g-simplicity 
are more r e s t r i c t i v e design features of recursive learning functions than either is alone. this is the content of the next proposition. 
¡¡¡¡¡¡proposition 	1: 	there 	is 	l 	c re such that   i   some f € frec i d e n t i f i e s l text 	e f f i c i e n t l y   	  i i   	for 	any 	total recursive function  g  such that g x    x f o r a l l x € n  some f € f r e c i d e n t i f i e s 	l 	g-simply  	but 	  i i i   	for every 	f 	€ 	frec   	and 	every 	t o t a l 
recursive function  h  	if f i d e n t i f i e s l text 	e f f i c i e n t l y 	with 	respect 	to 	frec   then f does not identify l h-simply. 
1 learning in l i k e l y environments'1 
¡¡¡¡¡¡in some environments each p o t e n t i a l element of a language is associated with a 	fixed 	probability 	of 	occurrence  invariant 	through 	time. 	such environments 	m 	a 	y 	be 	thought 	of 	as i n f i n i t e 	sequences 	of 	stochastically independent events  the p r o b a b i l i t y of a 
given element  e  appearing in the n+lst position 	being 	independent 	of 	the contents of positions 1 through n. 
¡¡¡¡¡¡to study such environments  each l € re is associated with a probability measure* m  on n such that for a l l x € n  x € l if and only 1f ml {x}    1. 
 recall that every l € re 1s nonempty; see section 1.  next  we impose on 
tre
    its baire topology  re; that 1s  for each a € seq  we take bg   {t € 
t	a
 1bsl is in t to basic open set of f re. for each l € r¡ê  we define the 

 unique  complete probability measure  by stipulating that for all a 
we 
now assume the existence of a fixed collection  of measures on 
correponding members of 
 intuitively. for measurable 	tl is the probabi1ity that an arbitrarily selected text for l is drawn from s. 
     the following facts are easy to establish. for at 1 


     in the stochastic context just discussed  the gold definition of language tdentificat ion seems needlessly restrictive. rather than requiring identification of every text for a given language  l  it seems enough to require identification of any subset of  of sufficient probability. we are thus led to the following definition. let f is said to measure-one 
iflentiry l just in case 
identifies t l   = 1  f measure-one identifies just in case f measure-one identifies every in this case  is said to be measure-one identifiable. the definition of measure-one identifiability is inspired by waxier & culicover  1  ch. 1 . 
     measure-one identification of a language differs from ordinary identification only by a set of measure zero. the next proposition reveals the significance of this small difference. 
	proposition 	1	: i s measure-one 
identifiable. 
let  be an indexed 
collection of languages  and let 
 n} be the corresponding measures on then.  is said to be uniformly measured just 1n case the predicates  x  are decidable 
line decidability of the latter predicate actually implies that of the former . minor modifications in the proof of proposition 1 yield the following. 
¡¡¡¡¡¡proposition 1; let l be a uniformly measured collection of languages. then  some f g r e c measure-one identifies l. 
     thus  in contrast to gold's theorem  section 1  above   any uniformly measured col lection of languages consisting of all finite sets and any infinite set is measure-one identif iable. 
1 imperfect environments 
1.1 noisy texts 
     a noisy text for a language  l  is any text for a language of the form where d is a .finite set. thus  a noisy text for a language  l  can be pictured as a text for l into which any number of intrusions from a finite set have been inserted. since the empty set is finite  texts for l count as noisy texts for l. we say that a learning function  
f. identifies a language  l. on noisy text just in case f converges to an index for l on every noisy text for l. a learning function  f  identifies a collection  l  of languages on noisy text just in case f identifies every language in l on noisy text. 
     it is clear that noisy text renders impossible the identification of the collection of ell finite languages. the following proposition provides a less obvious example of the disruptive effects of such envi ronments for recursive learning functions. 
     proposition 1: there is a collection  l. of languages such that  a  every language in l is infinite and disjoint from every other language 1n l   b  some recursive learning function identifies l  and  c  no recursive learning function identifies l on noisy text. 
	1.1 	incomplete texts 
an incomplete text for a language  
l. is defined to be a text for l-1  where d is any finite set. an incomplete text for a language  l  can be pictured as a text for l from which all occurrences of a given finite set of 
sentences have been removed. texts for l count as incomplete texts for l. we say that a learning function  f. identifies a language  l  on incomplete text j u s t in case f converges to an index for l on every incomplete text for 
l. i d e n t i f i a b i l i t y of collections of languages on incomplete text is defined straightforwardly. 
¡¡¡¡¡¡proposition 1: there is a c o l l e c t i o n   l  of languages such that  a  every language in l is i n f i n i t e and d i s j o i n t from every other language in l   b  some recursive learning f u n c t i o n i d e n t i f i e s 1  and  c  no recursive learning function i d e n t i f i e s l on incomplete text. 

¡¡¡¡¡¡given the margin of error tolerated in finite-difference identification  one might doubt that imperfection r e s t r i c t s t h i s kind of l e a r n i n g . it is thus natural to conjecture: 
l is finite-difference identifiable  by recursive learning function  if and only if 1 is finite-difference identifiable on noisy text  by recursive learning f u n c t i o n   ; and 
	d. osherson et al. 	1 
l is finite-difference identifiable  by recursive learning function  if and only if l is finite-difference identifiable on incomplete text  by recursive learning f u n c t i o n   . 
the next two propositions show that both versions of both conjectures are false. 
¡¡¡¡¡¡proposition 1: there is a c o l l e c t i o n   l  of languages such that some recursive learning function i d e n t i f i e s l  but no learning function  recursive or not  f i n i t e - d i f f e r e n c e i d e n t i f i e s l on noisy t e x t . 
¡¡¡¡¡¡proposition 1: there 1s a c o l l e c t i o n   jl  of languages such t h a t some recursive learning function i d e n t i f i e s l  but no learning function  recursive or not  f i n i t e - d i f f e r e n c e i d e n t i f i e s l on incomplete t e x t . 
section 1: language acquisition and formal models of inference 
¡¡¡¡¡¡the circumstances of normal language acquisition by children appear to share a fundamental feature with the inference paradigms discussed above. infants apparently have no direct access to the nonsentences  so labeled  of the target language. this assertion rests on evidence that children are seldom corrected for ungrammatical utterances per se  nor do they communicate more successfully with grammatical than with ungrammatical sentences  brown & hanlon  1 . in short  children learn t h e i r language on texts. 
¡¡¡¡¡¡as a consequence of this shared environmental feature  the propositions adduced above are relevant to the study of language a c q u i s i t i o n . thus:  a  propositions 1 - 1 reveal some of the consequences of e f f i c i e n t learning by children; if language acquisition proceeds e f f i c i e n t l y in the senses e a r l i e r defined  the class of learnable languages is narrower on this account   b  if the class of natural languages is i n f i n i t e   then a corollary of results in section 1 shows that i n f i n i t e l y many grammars conjectured by children are w i l d l y oversized  by any reasonable measure of s i z e      c  if each sentence in the target language can be associated with a lower bound on the p r o b a b i l i t y of its occurrence in the c h i l d ' s l i n g u i s t i c environment  then proposition 1 shows 

that the set of languages that can be learned with certainty is very large. and  d  propositions 1 and 1 reveal the surprising consequences for language acquisition of even mild imperfections in children's l i n g u i s t i c environments. 
these kinds of connections between formal learning theory and language acquisition by children have become increasingly central to l i n g u i s t i c theory and developmental psycholinguistics  see wexler & 
culicover  	1; 	osherson  	stob 	& 
weinstein 1a . 
¡¡¡¡¡¡the results reviewed in this paper represent only one of several perspectives on language acquisition offered by formal learning theory. 
thus  in addition to e f f i c i e n c y   soveral other learning strategies plausibly attributed to children have been investigated from the learning theoretic point of view  osherson  stob & weinstein 1b . these include such response tendencies as  a  r e s t r i c t i o n to hypotheses compatible with available data   b  gradual s h i f t s in hypotheses rather than large leaps   c  perseveration on conjectures that predict the available l i n g u i s t i c data   d  r e s t r i c t i o n to grammars with n o n t r i v i a l  recursive  rules  and  e  exclusion of long-past data in hypothesis selection. a d d i t i o n a l l y   c r i t e r i a of successful acquisition less stringent than i d e n t i f i c a t i o n have been formulated and studied in the context of contemporary l i n g u i s t i c theory and language a c q u i s i t i o n . these issues are discussed in osherson & weinstein 
 1c . 
