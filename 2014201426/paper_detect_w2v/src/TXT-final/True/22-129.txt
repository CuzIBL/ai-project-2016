 
each concept description language and search strategy has an inherent inductive bias  a preference for some hypotheses over others. no single inductive bias performs optimally on all problems. this paper describes a system that couples induction with optimization to carry out an efficient search of large regions of inductive bias space. experimental results are reported demonstrating the system's capacity to choose optimal biases even for complex and noisy problems. 
1 	introduction 
research on methods for learning concepts from examples occupies a central position in the discipline of machine learning  michalski  carbonell  & mitchell  1 . among those who study the problem of learning from examples  it is now widely recognized that each concept description language and search strategy has an inherent inductive bias. mitchell  1  defined inductive bias as  any basis for choosing one generalization over another  other than strict consistency with the observed training instances.  in our research  we give the term inductive bias a functional definition. given a set of examples  an inductive bias is a function that produces a hypothesis  mapping points from a space of input representations to points in a space of output representations. in this paper we focus on inductive systems that produce functions that map a set of input values to a single output function value. a partial list of inductive systems conforming to this restriction includes: neural nets  rumelhart & mcclelland  1   regresssion  box  hunter  & hunter  1   decision-trees  rendell 1; quinlan 1; breiman  friedman  olshen  & stone  1   logic-based approaches  michalski  1   and exemplar-based approaches  smith & medin  1 . 
1 	machine learning 　the best inductive bias for a given problem depends heavily on the user's objectives  i.e.  hypothesis credibility metric . for instance  if the predominant objective is to produce a hypothesis that is easy to comprehend  a good in-
   * this research was sponsored in part by the national science foundation  dmc-1  and by the applied intelligent systems group of digital equipment corporation. 
ductive bias might represent hypotheses as english sentences or graphic representations. in other cases  when predictive accuracy is the primary concern  neural nets  decision trees  and mathematical equations may be preferable. given the diversity of user objectives  it is clear that no single inductive bias can be optimal for all situations. 
　to address this problem  our research seeks to produce a robust inductive system in accordance with the methodology first described in rendell  seshu  and tcheng's  1  discussion of the variable-bias management system  vbms . the original vbms paper laid out three methods for developing robust learning systems: integration  optimization  and meta-learning. integration involves the representation of unique inductive biases as points in a multi-dimensional space  inductive bias space . optimization is a method for searching inductive bias space. meta-learning is a method for selecting an appropriate bias optimization strategy based on characteristics of the current problem. 
　in this paper we present the results of tangible progress towards integration and optimization. to integrate existing inductive biases  we developed the competitive relation learner  crl   a system that manages a set of diverse inductive biases to produce hybrid concept representations. to optimize inductive bias  we developed an optimization algorithm called the induce and select optimizer  iso  and applied it to the problem of optimizing crl's inductive bias. 
　in what follows  we first suggest that well known decision-tree building algorithms such as id1  quinlan  1   plsi  rendell  1   and cart  breiman et al.  1   as well as recently developed hybrids like utgoff s perception trees  1   can all be viewed as partial instantiations of an abstract class of algorithms we call recursive splitting algorithms. second  we describe crl  a generalized recursive splitting algorithm  tcheng  lambert  & lu  1  that provides a framework for integrating multiple methods for function approximation  learning strategies   multiple methods for breaking problems into subproblems  decomposition strategies   and multiple methods for selecting the best set of subproblems to solve  decomposition evaluation functions . next we argue that optimization is the appropriate methodology for searching crl's bias space. after a general discussion of optimization  we describe the details of iso. finally  we present experimental results that illustrate the capabilities of both crl and iso. in concluding  we outline plans for applying the combined system to a large database of real-world learning problems and for learning meta-level 

rules for selecting inductive bias optimization strategies. 
1 the crl system 
the principal factor motivating the design of crl was the observation that the behavior of a recursive splitting algorithm depends on three factors:  1  how predictions are made within regions of input space;  1  how candidate decompositions are generated; and  1  how candidate decompositions are evaluated  see also breiman et al..  1 . analysis of traditional recursive splitting algorithms reveals that each method possesses only one learning strategy  i.e.  a method for making predictions in each subregion   one decomposition strategy  and one decomposition evaluation function. for example  id1  quinlan  1  creates n-way splits on nominal feature dimensions  selects the split that minimizes its entropy function  and assigns the most frequently occurring class label to each subregion  i.e.  leaf node . pls1 creates binary splits perpendicular to scalar feature dimensions  chooses the decomposition that maximizes the difference in the output functions  and attaches the mean output value to each subregion. utgoff s  1  novel contribution lay in realizing that performance could be improved by putting more powerful predictors at the leaf nodes. his perceptron-tree algorithm first attempts to classify all instances with a perceptron  i.e.  a network of threshold logic units . failing that  it imposes n-way splits along nominal attribute dimensions  selects the split that minimizes its entropy function  and inserts perceptrons at the leaf nodes. figure 1 summarizes how these algorithms and crl instantiate the three crucial component processes: prediction  decomposition  and evaluation. 

figure 1. characteristic components of four recursive splitting algorithms. 
　any fixed combination of prediction  decomposition  and evaluation strategies may be ideal for a particular class of problems  but will fail to provide optimal performance on others. the crl system was designed to perform well across a wide range of problems. this robust performance is made possible by crl's ability to manage multiple  competing component strategics. such competition often results in the formation of hybrid concepts that simultaneously capitalize on the strengths and minimize the weaknesses of two or more distinct inductive biases  schlimmer  1; utgoff  1 . the current implementation of crl contains multiple learning strategies  multiple decomposition strategies  and multiple decomposition evaluation functions. the design is modular  and new strategies can be added incrementally as long as they adhere to crl's standard input-output specifications. below are relevant details of crl's component strategies. 
1 	learning strategies 
in traditional recursive splitting algorithms  predictions are made by traversing the decision tree with a given input example and then simply returning the mean or mode of the output points in the specified subregion. hypotheses generated by such algorithms take the form of discontinuous stepfunctions. in contrast  were regression or a neural network used at the leaf nodes  at least two advantages would be reaped. the resulting hypothesis would provide a closer fit to continuous functions and fewer decompositions would be necessary. expanding on this idea  crl competitively applies a variety of learning strategies  i.e.  inductive biases  at the leaf nodes to produce a hypothesis for each subregion. in addition to averaging  crl can be made to fit subregions with several different models  i.e.  statistical regression  neural nets  averaging  and exemplar based strategies . competition provides the basis for choosing the learning strategy for each region that will be used to form the final hypothesis. the availability of several learning strategies allows crl to solve complex problems involving multiple models  and it is one of the novel aspects of the crl system. below are the learning strategies currently implemented in crl. 
1.1 mean and mode 
these strategies take either the mean or mode of all observed output vectors and return a constant hypothesis. due to their limitations  the mean and mode learning strategies are almost always combined with one or more decomposition strategies. 
1.1 	exemplar 
the exemplar learning strategy is based on a psychological model of human concept acquisition  smith & medin  1 . in the learning phase  the exemplar strategy randomly selects and remembers a specified number of examples from the training set. in the performance phase  predictions are made by looking through all of the memorized examples and finding the set of n-examples closest to the new example in input space  based on normalized euclidean distance . the average of the n closest output points is returned as the predicted output value. 
1.1 	regression models 
these learning strategies are based on the classical statistical regression model  box  hunter  & hunter  1 . crl currently contains the linear  quadratic  logarithmic  and exponential regression models. 
	tcheng  lambert  lu and rendell 	1 

1.1 	neural net models 
the last of crl's component learning strategies is a neural network. neural networks are highly interconnected assemblies of simple computing elements which  when properly trained  can learn arbitrary input-output mappings. the particular system in crl is a flexible model designed to let the user explore a wide range of architectures  connectivity patterns  and settings of other parameters. the network learns by the back-propagation of error signals  rumelhart & mcclelland  1 . 
1 	decomposition strategies 
the general idea of problem decomposition is of fundamental importance in problem solving  newell & simon  1 . equipped with a representation of the problem space and operators for moving around in that space  the problem solver's objective is to break down the given problem into subproblems whose solutions can be achieved by applying the available operators. in crl  the operators are learning strategies and the difference to be reduced is the error of the overall hypothesis. 
　mathematically  a decomposition is a function that maps every point in the parent region of input space to one subregion indexed by a subproblem number. for example  if ii and 1 are input features  equation  1  represents a simple binary decomposition function of the sort generated by pls1. 

in general  a decomposition function may be defined over any or all of the input feature dimensions and may map examples to two or more subregions. in traditional recursive splitting algorithms  only one algorithm for generating decomposition functions  i.e.  a decomposition strategy  is available. because many decomposition strategies exist  crl allows the user to specify a set of them to use in parallel. below are the decomposition strategies currently defined in crl. 
1.1 	distance decomposition strategy 
this decomposition strategy is a slight variation on that used by pls1. first  the minimal hyper-rectangle that contains all the points in input space is calculated. then a set of candidate decompositions is generated by splitting each input feature dimension at n evenly spaced points. 
1.1 	population decomposition strategy 
the major disadvantage of the distance decomposition strategy is that it is insensitive to the actual distribution of examples in input space. in the worst case  many of the decompositions generated will divide input space into two regions  one containing all but one of the examples and the other containing a single example. to avoid this problem  we have developed a method for generating decompositions which partitions input space into regions based on population density. the result is that more densely populated regions of input space undergo proportionately more decomposition  kadie  1 . 
1 	machine learning 
1.1 	hyperplane decomposition strategy 
all of the previously mentioned decomposition strategies insert region boundaries perpendicular to attribute dimensions. instead of a single attribute test  this strategy generates arbitrarily placed hyperplane decomposition functions  see breiman et a/..  1 . the position of the hyperplane is controlled by a parameter which determines how many randomly selected input points will be used to compute the location of an origin. if this parameter is set to ±  all hyper-planes pass through the centroid of the input space vectors and the population tends to be divided equally. if this parameter is set to 1  the hyperplanes pass through a single  randomly selected point  not necessarily the center   yielding a greater variety of decompositions. once the origin has been chosen  the orientation of the hyperplane is randomly determined. 
1 	decomposition evaulation functions 
recursive splitting algorithms  such as id1  typically rely on mathematical measures of a subregion's entropy to evaluate decompositions. decomposition evaluation functions of this sort favor splits that partition the input space into minimally entropic regions. the logic behind such a strategy  based on information theory  predicts that regions of low entropy will be easier to learn. as such  entropy measures are indirect measures of the overall hypothesis error reduction that a given decomposition will bring about. in contrast to the entropy-based heuristic  the crl approach to decomposition evaluation is to measure directly the overall error reduction of a candidate decomposition by actually evaluating competing learning strategies in the newly created subregions  see fig. 1 . crl's decomposition evaluation functions consist of two components  a hypothesis error metric and a error validation strategy. 
1.1 	hypothesis error metrics 
　a crl hypothesis error metric is a function taking the actual example and predicted output vector as input and returns a value indicating the error of the prediction. general purpose hypothesis error metrics include average deviation  standard error  entropy  and vector difference. the user can also define domain-specific error metrics. for example  when crl is used to create diagnostic rules  the relative cost of false positives and false negatives can be built into the error metric and thus used to bias decomposition accordingly. this advantage is unavailable to systems that use only general error metrics because such metrics are insensitive to the type of misclassifications that may result from a given split. 
1.1 	error validation strategies 
　whereas an error metric measures the error of a prediction based on a single example  a validation strategy uses the error metric to estimate the average hypothesis error across across an entire example set. crl currently possesses three error validation strategies  resubstitution  test-sample  and vfold cross validation  breiman et al.  1 . resubstitution tests a hypothesis on the same examples that were used to create the hypothesis. test-sample requires the user to divide the available examples into training and testing sets. training examples are used to form the hypothesis  and testing 

examples are used to estimate the error of the hypothesis. v-fold cross validation is a method for estimating the error of a hypothesis  where the number of folds is the number of groups to partition the examples into. for example  if the number of folds is 1  then the examples are randomly partitioned into 1 equal-sized groups. next  the examples from all but 1 of the subgroups are used to create a hypothesis with the given learning strategy. the accuracy of the hypothesis is then estimated using the unseen group of examples as test cases. this process is repeated for each group of examples  and the average hypothesis error is calculated. when more than one learning strategy is competing  v-fold cross validation prevents learning strategies with a high degree of freedom from unjustly dominating  e.g.  by memorizing all the examples . 
1 	the crl algorithm 
figure 1 shows how crl takes a given set of active learning and decomposition strategies and decides which will be used to form the final hypothesis. this method is a straightforward generalization of the simple recursive splitting algorithm - the difference being that crl uses a 
best-first search  without backtracking  strategy to evaluate multiple learning and decomposition strategy combinations in parallel. crl begins with a single input space region containing every example and estimates the error in the region. the error of a region is determined by applying each active learning strategy to the examples and recording the error of the most accurate hypothesis. 
   next  the algorithm determines whether further decomposition will reduce the overall hypothesis error. to do this  crl applies all active decomposition strategies and evaluates the resulting candidate decompositions by computing the error of the resulting regions in the manner described above. the most valuable decomposition  the one that brings about the greatest overall error reduction  is used to create new subregions. this process is recursively applied to each subregion until one of the following three stopping criteria is met:  1  the error of the overall hypothesis ceases to decrease more than a specified threshold;  1  the number of examples in a candidate subregion falls below a specified threshold; or  1  the time consumed exceeds a specified threshold. 

　from the user's perspective  the main advantage of crl is that it creates an environment in which one can easily experiment with a diverse set of learning strategies without having to recode data or jump from system to system. unfortunately  the diversity of choices has a cost. with so many alternative inductive biases to choose from  finding the best bias for a problem is difficult one way around the problem of bias selection is to activate a large  representative set of crl's learning and decomposition strategies and to let them compete. this approach can be immensely expensive - especially if the user wants to ensure that all significantly different biases are tried. we do not advocate such a brute force solution. instead  an independent optimization system can be used to search for the inductive bias that is optimal with respect to a given set of user objectives. 
   to say that optimization should be used to search inductive bias space is insufficient because as many optimization biases as inductive biases exist. therefore  to complete the definition of our methodology  we must decide on a framework for optimization. in the following section  we describe both weak optimization methods  such as random search  and strong methods  which themselves employ inductive biases to guide the search for the optimum. rather than choosing between weak and strong methods  we eventually propose a methodology that allows us access to both. 
1. relating optimization and induction 
1 	what is optimization  
from the perspective of decision making  optimization is the process of finding the best decision among a range of untested alternatives  buchanan  1 . optimization problems are defined in terms of a decision space and a means for evaluating candidate decisions  the evaluator  see fig. 1 . 


figure 1. pseudo code for the crl algorithm. 

figure 1. simple view of optimization. 
   for example  if the goal is to design an aircraft wing that produces maximal lift  the dimensions of the decision space are attributes of the wing design  e.g.  material type  wing curvature  wing length  etc. . in this case  candidate decisions can be evaluated either by building and testing the wing or by estimating the wing performance through computer simulation. the goal of the optimization process is to find the best point in decision space using the least effort. 
   an optimizer takes as input a set of examples and employs some heuristic to generate new candidate decisions. a continuum of optimization biases ranges from the weak to the strong. random selection of candidate decisions is a weak heuristic which can be quite effective when the cost of 
	tcheng  lambert  lu and rendell 	1 

evaluating decision points is negligible. if the cost of evaluation is high  stronger  and less efficient  selection heuristics are justified. strong selection heuristics employ some inductive bias to create a hypothesis that describes the objective surface over decision space  see fig. 1 . this hypothesis is used to guide further selection. 
　response surface fitting  box et al  1  is an example of a strong optimization strategy which uses an inductive bias to aid in the selection of new candidate decisions. response surface fitting typically uses polynomial regression to estimate the relationship between decision variables and objective score. to generate new candidate decisions  the selector component of a response surface fitting algorithm first calculates the decision point maximizing its polynomial hypothesis and then selects that point as the next decision to evaluate. for each selected point  an ob-
jective score is calculated by the evaluation function and associated with the decision space point to form an example for the next iteration of polynomial regression. the process continues until some stopping criterion is met  e.g.  the objective score ceases to increase or resources are exhausted . 
1 	the induce and select optimizer 
recognizing that a versatile optimization system ought to posess both the strong and weak methods described above  we designed the induce and select optimizer  iso . the iso framework is schematically represented in figure 1. 

figure 1. component view of optimization. 
　as its name suggests  iso includes two main components: an inducer and a selector. the role of the inducer is to describe  for the selector's benefit  the objective surface over decision space  see fig. 1 . optimization strategies such as response surface fitting use induction  but they are equipped with only one inductive bias  e.g.  quadratic regression . this is fine if the objective surface over decision space happens to be similar to a quadratic function. if it is not  however  using the induced quadratic hypothesis to guide the selection of new decisions adds little benefit  and may actually impede progress toward the optimum. iso escapes this limitation because its inducer manages a collection of competing inductive biases. with many inductive biases to choose from  the inducer within iso has a much higher probability of accurately describing the objective surface over decision space. iso is  therefore  much more likely to find a strong optimization method. 
　the second component of iso is its selector. selection is the process of using both the examples and the induced 
1 	machine learning 
hypothesis to guide the selection of new candidate decisions. in iso  selection is based on two control parameters called novelty and performance. a high novelty setting causes iso to prefer points in decision space that are maximally distant from those already attempted. if novelty were the only consideration  iso would ignore the induced hypothesis describing the objective surface over decision space  and instead perform random  non redundant search. if performance were the only consideration  iso would attend only to the induced hypothesis  choosing new candidate decisions that maximize that hypothesis. in this way  the novelty and performance parameters allow iso to exhibit both strong and weak optimization biases. 

1 optimizing inductive bias with iso 
the availability in crl of multiple decomposition strategies  learning strategies  and decomposition evaluation functions increases the size of the inductive bias space through which iso may search. here we encounter a classic tradeoff. larger search-spaces are more likely to contain better solutions  but they are also more difficult to search. in this section we describe how iso optimizes hypothesis credibility over crl's inductive bias space. 
   conceptually  crl's bias space is a feature space defined by a set of variables that jointly specify which learning and decomposition strategies to use  their control parameters  the hypothesis error metric  how the hypothesis error is to be measured  and the minimum error reduction needed to justify a decomposition. simply put  a point in bias space completely determines crl's hypothesis formation behavior. 
   by selecting which component processes are eligible to be considered  the experimenter defines the region of crl's inductive bias space in which iso can seek an optimum. in the first stage of optimization  iso probes randomly in bias space. each probe  x  is evaluated by forming a hypothesis with the prescibed inductive bias. the bias point  x  is associated with the achieved hypothesis credibility  o  to form an example. these examples are fed to the induction component of iso. the inducer within the optimizer outputs a hypothesis  o x   that describes the credibility surface over bias space. the selector component of the optimizer uses o x  and the existing examples to select the next point in bias space to evaluate. this process is the same as that described in figures 1 and 1  but the decision space is crl's inductive bias space  and the objective surface is defined in terms of hypothesis credibility  e.g.  accuracy  evalution cost  formation cost  comprehensibility  etc. . 
1 experimental results 
crl's task in this example is to predict the surface roughness of a machined part based on the control parameters of the cutting tool and on the dimensions of the work piece. examples were generated by a mechanistic simulator for the turning process  boothroyd  1 . the simulator mapped four input variables - feed rate  f   depth of cut  d   nose radius  n   and work piece diameter  w  to one output variable - surface roughness  s . noise was added to the examples so they would more closely approximate real world observations. 
　　for this problem  the user's objective was defined in terms of two factors: hypothesis accuracy  in terms of the variance between predicted and actual outputs  and hypothesis formation time. accuracy was measured by training iso on 1 examples and testing on 1 different examples. for each trial  both training and testing examples were randomly selected. hypothesis formation time was controlled by an iso control parameter that placed an upper limit on the amount of cpu time that could be used to form any single hypothesis. for the results reported below  the time limit was 1 cpu seconds  on a sun/1 with 1 meg . 
   figure 1 shows the two best crl hypotheses produced during the optimization process. figure 1 shows crl's performance improvement over time with a 1% confidence interval for the mean hypothesis error superimposed. the minimum possible error was 1 because of the amount of noise added to the examples. the actual function used by the turning simulator to predict surface roughness is given in equation  1 . 


figure 1. comparision of accuracy of hypotheses produced by crl and traditional inductive biases. 
1 conclusions and future research 
the work presented here reflects initial progress toward our ultimate goal: an inductive system which takes as input a problem description  consisting of examples and the user's objectives   returns the hypothesis which is optimal with respect to those objectives  and improves its performance over time by learning from problem solving experience. there is more work to be done before such a system is a reality. 
　obvious extensions to the existing implementation include the addition of more component strategies. we plan to add logic-based learning strategies such as aq  michalski  1   more sophisticated decomposition strategies  that go beyond binary splits   improved selection strategies for iso  e.g.  genetic optimizers  holland  1  and simple hill climbing   and facilities for feature selection and construction. 
   beyond adding component strategies to the existing framework  the framework itself needs to be expanded before the system will learn from its own experience. for example  we have shown how an optimizer can be used to find a good inductive bias for a particular problem. however  optimizers themselves have biases such as the method for generating an initial candidate decision to evaluate. iso begins the optimization process by generating a candidate decision randomly. the system would be more efficient  however  if it possessed meta-level knowledge relating problem characteristics  e.g.  number of examples  number of features  type of features  problem domain  maximum hypothesis formation time  etc.  to good points in inductive bias space at which to begin optimization. 
   to gain this added efficiency  we are currently in the process of implementing the third component of the vbms framework: meta-learning. meta-knowledge takes the form 
of hypotheses that relate problem characteristics to optimal points in inductive bias space  or at least good points at 
	tcheng  lambert  lu and rendell 	1 

which to begin further optimization . there are at least two approaches to learning this relationship:  1  the system could take problem-description/optimal-bias pairs  saved from past experience  as examples and do induction as usual to learn best-bias problem . to select a bias point for a particular problem  the system just evaluates this function with the current problem description as its argument; or  1  the system could take problem/bias/ objective-score triples  saved from optimization experience  and induce the function describing the objective surface over problem/bias space  i.e.  objective problem  bias  . to use this function to select the best starting point in inductive bias space  one replaces the problem argument with the current problem description and optimizes objective bias  in the usual manner. eventually  we plan to test these meta-learning strategies on a large database of realworld machine learning problems  aha  1 . 
　in closing  it is important to emphasize that this particular implementation is just the beginning of a much larger project. it reflects  for the most part  the work of a small group of researchers working primarily on engineering problems. achieving the three design goals of vbms  integration  optimization  and meta-learning  rendell et al  1   was relatively easy in such a small  focused group. the challenge over the long term  however  is to achieve these design goals at the level of entire scientific communities. in this paper  we have taken some small steps toward that end. 
acknowledgements 
special thanks to dr. guangming zhang for help in running the turning simulator. thanks also to david lambert and dr. barbara o'keefc for helpful comments on an earlier draft. funding for this research was provided in part by the applied intelligent systems group of digital equipment 
corporation  by the national science foundation  dmc1 . 
