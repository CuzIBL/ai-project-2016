 
previous work in pruning algorithms for max  multi-player game trees has produced shallow pruning and alpha-beta branch-and-bound pruning. the effectiveness of these algorithms is dependant as much on the range of terminal values found in the game tree as on the ordering of nodes. we introduce last-branch and speculative pruning techniques which can prune any constantsum multi-player game tree. their effectiveness depends only on node-ordering within the game tree. as b grows large  these algorithms will  in the best case  reduce the branching factor of a //player game from b to /; n-  /n. in chinese checkers these methods reduce average expansions at depth 1 from 1 million to 1k nodes  and in hearts and spades they increase the average search depth by 1 ply. 
1 introduction 
while the minimax algorithm with alpha-beta pruning  knuth and moore  1 has dominated the study of 1player games  a clearly dominant algorithm has not emerged in the study of h-player games. 
　　the standard algorithm for /i-playcr games is ma n  luckhardt and irani  1|. only some max  game trees can be pruned using established techniques such as shallow pruning |korf  i1| and alpha-beta branch-and-bound pruning  sturtevant and korf  1|. this is because the amount of pruning possible under these algorithms is dependant on both the node ordering and the range of terminal values found in the game. common heuristics for games such as hearts and chinese checkers do not have appropriate terminal values for pruning. in two-player games  however  pruning is only dependant on the node ordering in the tree. 
　　we present here last-branch and speculative pruning techniques which can be used to prune any rt-player constantsum max  game tree. the effectiveness of these algorithms depends only on node ordering within the game tree. ixistbranch pruning is similar to a directional algorithm |pearl  
multiagent systems 
1  as it examines the successors of each node left-toright without returning to previously searched nodes. it does require that you know when you are searching the last branch of a node. speculative pruning  however  is not a directional algorithm as it may re-search some branches of the tree. lastbranch pruning is a special case of speculative pruning. 
　　the remainder of the paper is as follows. in section 1 we present a brief overview of sample multi-player domains. in section 1 we cover previous techniques for pruning max  trees. section 1 covers our new techniques  with results from various domains in section 1. 
1 multi-player domains 
a multi-player game is one in which there are 1 or more players or teams competing against each other. many 1-player games are designed for 1 teams  making them two-player games from a theoretical standpoint. we highlight a few of the many interesting multi-player games here. 
1 chinese checkers 
one of the best known multi-player board games is chinese 
checkers. this game is played on a board in the shape of a 1-pointed star  with players' pieces starting on opposite sides of the board. the goal is to move your pieces across the board faster than your opponent s  can. chinese checkers can be played with 1 players  and is not played in teams. 
1 card games 
we use two games here as examples. spades and hearts. spades is usually played with 1 players  but has a 1-player variant. the goal of spades is to maximize your score. hearts is usually played with 1 players  but can be played with 1 or more. the goal of hearts is to minimize your score. 
　　many card games  including these  arc trick-based. because a trick cannot be given up after being taken  the tricks taken during the game provide a monotonically increasing lower-bound on the final score of the game. in the case of spades  players get i point per trick taken  while in hearts each player gets 1 point for every heart in the tricks they take  as well as 1 points for the queen of spades. a complete game is made up of multiple hands  where the goal is to minimize or maximize your points over all the hands. 
both spades and hearts are imperfect-information 


games  while the descriptions and trees in this paper assume games have perfect information. in card games  however  we often use perfect-information methods to search imperfectinformation games through monte-carlo simulation. this involves generating sets of hands that are similar to the hands we expect our opponents to have. we then use traditional perfect-information methods to search these hands  combining and analyzing the results to make the next play. these methods have been successfully used in the bridge program gib.  ginsberg  1 
1 pruning algorithms for max  
the max  algorithm can be used to play games with any number of players. for two-player games  max  reduces to minimax. in a max  tree with n players  the leaves of the tree arc h-tuples  where the ith element in the tuple is the /th player's score. at the interior nodes in the game tree  the max  value of a node where player / is to move is the child of that node for which the /th component is maximum. this can be seen in figure 1. 
　　in this tree fragment there are three players. the player to move is labeled inside each node. at node  a   player 1 is to move. player 1 can get a score of 1 by moving to the left or right and a score of 1 by moving to the middle node. we break ties to the left  so player 1 will choose the left branch  and the max  value of node  a  is  1  1  1 . player 1 acts similarly at the root selecting the left branch  because the first component of the max  value there  1  is greater his score from the middle branch  1  and his score at the right branch  1. 
1 	shallow pruning 
　　shallow pruning refers to cases where a bound on a node is used to prune branches from the child of that node. the minimum requirements for pruning a max  tree with shallow pruning are a lower bound on each players' score and an upper bound  maxsum  on the sum of all players' scores. we demonstrate this in figure 1. in this figure  all scores have a lower bound of 1  and maxsum is 1. 
　　player 1 searches the left branch of the root in a depthfirst manner  getting the max  value  1  1 . thus  we know that player 1 will get at least 1 points at the root. since there are only 1 points available  we know the other players will get less than 1 points at this node. 
at node  a   player 1 searches the left branch to get a maxsum = 1 

 1 1  
　　　　figure 1. shallow pruning in a 1-player max  tree. score of 1. because maxsum is 1 we know that player ts score will never exceed 1 at node  a   so player 1 will never choose to move towards  a  at the root  and the remaining children of  a  can be pruned. 
　　for shallow pruning to actually occur in a maximization game  each player must have a score that ranges between 1 and maxsum.  sturtevant and korf  1  there are similar bounds for minimization games. in the average case  no asymptotic gain can be expected from shallow pruning.  korf  1 the basic problem with shallow pruning is that it works by comparing the scores of only 1 out of n players in the game  and it is unlikely that 1 players will have their scores sum to maxsum. this contrasts with the large gains available from using alpha-beta pruning with 1-playcr minimax. 
1 branch and bound pruning 
if a monotonic heuristic is present in a game  it can also be used to prune a max  tree. the full details of how this occurs is contained in  sturtevant and korf  1|. an example of a monotonic heuristic is the number of tricks taken in spades. once a trick has been taken  it cannot be lost. this guarantee can provide a lower bound on a player's score  and an upper bound on one's opponents scores  which can be used in branch-and-bound pruning to prune the game tree. alphabeta branch-and-bound pruning combines the actual scores of the 1 players compared in shallow pruning with the heuristic information from the other n-1 players to prune the tree. 
1 pruning in practice 
these algorithms have mixed performances in practice. there are no obviously useful monotonic heuristics for chinese checkers  and most useful cutoff evaluation functions for the game do not meet the requirements for shallow pruning. thus  in practice it is not possible to use any of these techniques to prune a chinese checkers game tree. 
　　if we use the number of points taken in the game tree so far as the evaluation function  we will be able to use shallow pruning in spades and branch-and-bound pruning in both spades and hearts. this is fine if you can search the entire game tree  but we are currently unable to do that. if we add a predictive component to the evaluation function  these pruning techniques are much less effective. thus a trade-off has to be made between the quality of the cutoff evaluation function 

maxsum = 1 	 1  1  1  or  1  1  

figure 1: the failure of deep pruning. 
and the potential amount of pruning in the game tree. 
1 deep pruning 
deep pruning refers to when the bound at a node is used to prune a grandchild or lower descendant of that node. |korf  1 shows that  in the general case  deep pruning can incorrectly affect the max  value of the game tree. we demonstrate this in figure 1. after searching the left branch of node  b . player 1 is guaranteed 1 points  and player 1 is guaranteed to get no more than 1 points at node  b . so  we can conclude that the max  value of node  b  will never be the max  value of the game tree  because player 1 is already guaranteed a score of 1 at the root  and he can do no better than that at node  b . it is still possible  however  that the max  value at  b  can affect the final max  value of the tree. 
for instance  if the actual maxn value of  b  is  1  1  1   
player 1 will prefer the move  1  1  1  at node  a   and this will be the max  value of the game tree. but  if the max  value of  b  is  1 1   player 1 will prefer this value  and so player 1 will choose  1  1  to be the max  value of the game tree. thus  in general deep pruning is not valid. 
1 new pruning techniques 
we now present our new algorithms. they have the same minimum requirements to prune as shallow pruning  namely a lower bound on each player's score and a upper bound on the sum of scores. this is slightly weaker than requiring a game to be constant-sum  meaning that the sum of all scores at every node is constant  but in either case we can usually make adjustments to the evaluation function in a game to be able to prune effectively. 
1 	requirements for pruning 
last-branch and speculative pruning both examine portions of max  game trees to find nodes whose max  value can never be the max  value of the tree. they take different approaches  however  when they prune these nodes. 
　　returning to figure 1  we know that player 1 will never get a better value than 1 at node  b . but  to prune at  b  correctly  we must show that player 1 cannot get a better max  value at the root from either node  b  or node  a   as the maxsum = 1 	 1  1  

 1 1  
figure 1. combining max  scores to limit value propagation. 
values at  a  may interact with unseen values at  b  to affect player 1's  and thus player 1 's move. in this case  deep pruning failed because the value at the right child of  a  was better for player 1 than a previous child of  a . if the children of  a  were ordered optimally for player 1  or if there was no right child at  a   the deep prune could not have affected the max  value of the tree. 
　　while shallow pruning only considers 1 players' bounds when pruning  we can actually use n players' bounds in a nplayer game. since each player has already searched one or more branches when we reach node  b  in figure 1  we have a lower bound on each player's score. in this case  player 1 has a lower bound of 1 from the left branch of the root  player 1 has a bound of 1 from the left branch of  a   and player 1 has a bound of 1 from the left branch of  b . the sum of these bounds is 1  which is greater than or equal to maxsum. we can thus show that any unseen value at  b  cannot be the max  value of the tree. 
lemma 1: if  in a max  game tree  the sum of lower bounds for a consecutive sequence of unique players meets or exceeds maxsum  the max  value of any child of the last player in the sequence cannot be the max  value of the game tree. proof: we provide a proof by contradiction. figure 1 shows a 

figure 1. combining scores to limit value propagation in general. 


generic 1-player game tree. in this figure player 1 has a lower bound of jc at the root  player 1 has a lower bound of y at  a   and player 1 has a lower bound of z at  b . given that these values sum to maxsum  assume there is a value v at the right child of  b  which will be the max  value of the game tree. 
　　let v =  for v to become the max  value of the tree  each player must prefer this move to their current move. 
since ties are broken to the left  z  must be strictly better than must be strictly better than y  and xl must be strictly bet-
ter than x. thus  	and 	 
maxsum  and maxsum. but  by the definition of maxsum  this is impossible. so  no value at the right child of  b  can be the max  value of the game tree. while this is the 1-player case  it clearly generalizes for n players.  
　　while we have shown that we can combine n players' scores to prove a max  value will not propagate up a max  tree  we must also show that a prune in this case will not affect the max  value of the entire game tree. last-branch and speculative pruning address this problem in similar ways. neither algorithm  however  will prune more than n levels away from where the first bound originates. 
1 	last-branch pruning 
when a sequence of players have bounds appropriate for pruning under lemma 1  last-branch pruning guarantees that the prune will be correct by only pruning when the intermediate players in the sequence arc searching their last branch. 
　　we can see this in figure 1. to prune correctly  we observe that after searching the left children of node  a  player 1 has only two choices: the best max  value from a previous branch of  a   or the max  value from  b . if player 1 chooses the max  value from the previous branch of  a    1  1  1   player 1 will get a lower score at  a  than his current bound at the root. umma 1 shows that the max  value at  b  can be better than the current bound for player 1 or for player 1  but not for both players. so  if player 1 chooses a value from  b   it must also have a lower max  value for player 1 than his bound at the root. thus  player 1 will not get a better score at  a   and we can prune the children of node  b . 
　　for last-branch pruning to be correct  in addition to the conditions from lemma 1  player 1 must be on his last branch  and the partial max  value from player 1's previously specmaxn node  parentscore  grandparentscore  
{ 
best = nil; specprunedq = nil; if terminal node  return static eval node ; 
for each child node  if  best previous player   parentscore ! 
result = specmaxn next child node   best current player   parentscore ; 
else result = specmaxn next child node   best current player   1 ; 
if  best == nil  best = result; 
else if  result == nil  add child to specprunedq; 
else if  best current player  result current player   best = result; 
if  best previous player   parentscore  re-add specprunedq to child list; 
if  grandparentscore+parentscore+ 
best current player  maxsum  
return nil; 
return best; 
} 
figure 1: speculative max  pseudo-code for a 1-player game. 
searched children must not be better for player 1 than his current bound at the root. in the //-player case  all intermediate players between the first and last player must be searching their last branches  while players 1 and n can be on any branch after their first one. 
ixist branch pruning has the potential to be very effective. 
instead of only considering 1 players' scores  it compares n players' scores. in fact  when all nodes in the tree have the exact same evaluation  last-branch pruning will always be able to prune  while shallow pruning will never be able to. 
　　the only drawback to last-branch pruning is that it only prunes when intermediate players between the first and last player are all on the last branch of their search. for a game with branching factor 1 this is already the case  but otherwise we use speculative pruning to address this issue. 
1 	speculative max  pruning 
speculative pruning is identical to last-branch pruning  except that it doesn't wait until intermediate players arc on their last branch. instead  it prunes speculatively  re-searching if needed. 
　　we demonstrate this in figure 1. at the root of the tree  player 1 is guaranteed 1 points. at node  a   player 1 is guaranteed 1  and at node  b   player 1 is guaranteed 1. because 1 + 1 + 1 ♀ maxsum  we could prune the remaining children of  b  if node  b  was the last child of node  a . 
　　suppose we do prune  and then come to the final child of node  a . if the final child of node  a  has value  1  1  1   we know player 1 will not move towards  a   because no value there can be better for player 1. but  if the value at  a  ends up being  1  1  1   the partially computed max  value of  a  will be  1  1  1 . with this max  value  player 1 will choose to move towards node  b . because this has the potential to 


tabic 1: branching factor gains by speculative max  in a 1-playcr game. 
change the max  value at the root of the tree  we will have to search node  b  again using new bounds. this occurs when player 1's nodes are ordered suboptimally. with an optimal node ordering we will never have to re-search a subtree. 
　　in general  we have to re-search pruned branches if  on a mid-level branch  we find a new value for which both that mid-level player and his parent have better scores. as with last-branch pruning  we can only prune when player 1 prefers his current move over player 1's partial max  value. if we wish to preserve the order of tie-breaking in the tree  we must also retain some extra information about the order of nodes expanded. nodes that can be pruned by last-branch pruning will be always be pruned by speculative pruning. pseudocode for speculative pruning can be found in figure 1. 
　　as can been seen  it is reasonably simple to perform speculative pruning in practice. in the 1-player implementation  the specmax  function takes 1 arguments  the current node  the best score at the parent node  and the best score at the grandparent node. 
　　at the line marked f we are checking to see if our parent can get a better score from the partial max  value of this node than from one of his previously searched nodes. if this is the case  we cannot use the parent's bounds to help prune the children of the current node. 
　　when a node is speculatively pruned  the specmax  function returns nil. all nodes that have speculatively pruned children are added to a list of pruned nodes  and if a child is found with a max  value that better for both the current node and the parent node  then the speculatively pruned nodes will have to be re-searched. this pseudo-code assumes that players always alternate plays in the tree  as in chinese checkers. in card games  where this may not be the case  additional checks are needed. 
　　for 1 players  the best-case analysis of speculative pruning can be formulated as a recurrence  the solution of which 
is the equation a complete derivation of the recurrence can be found in  sturtevant  1 . solving this equation for x gives the asymptotic branching factor  which  as b grows large  is for a general /1-playcr game  the equation will be .-   . . 
 as b grows large  this approaches bn'lln. we give sample values for b  given an optimal ordering of nodes in a 1-playcr game  in table 1. the first column contains sample values for /   the second column contains  and the third column contains the actual optimal asymptotic value of b as calculated from these equations. 
maxsum =1 	 1  1  1  

figure 1. discrete cut-off evaluations 
1 	discrete cutoff evaluations 
   it is possible to use tighter bounds for pruning when the evaluation function has discrete as opposed to continuous values. this draws from the proof of lemma 1. in this proof we see that  for a value to affect the max  value of the tree  and suppose the minimum delta of a player's score is . since all players in the game must do strictly better than their previous value we can combine this into our bounds. 
　　we demonstrate this in figure 1. at the root of the tree. player 1 is guaranteed a score of 1  and at node  a  player 1 is guaranteed 1 points. in this example = 1  so for these pla ers both to prefer to move towards  b  they must get at least 1 and 1 points respectively. because maxsum is 1  we know if player 1 gels more than 1 points  players 1 and 1 can't both get better than their current best scores. so  instead of pruning when player 1 gets 1 - 1 - 1 = 1 points  we can prune when player 1 gels 1 point. 
we can then use our tie-breaking rule to improve this. 
because ties are broken lo the left  we can prune if player 1 gets 1 points at the left branch of  b  and player 1 and 1 don't gel 1 and 1 points respectively. if  for instance  the score is  1  1  1   player 1 won't choose this value over the left branch of 
 a . in addition  player 1 will only choose a better value than 1 from the unexpanded children of  b   which will meet our earlier conditions for pruning. 
ll follows from this that we can always prune if scores 
maxsum -  /  - 1   where scores are the current bounds for the players in the tree. additionally  we can prune if  scores ♀ maxsum - /*  /  - 1  and if on the first branch of the node being pruned the other n - 1 players don't all have better scores than their current best bound. 
1 experimental results 
as speculative pruning includes last-branch pruning as a special case  we only report our experiments with speculative max . in each experiment  re-expansions by speculative max  are counted as part of the total number of node expansions  and node re-expansions in speculative pruning never out-

chinese checkers expansions at depth 1 
	plain max  	1 million 
	speculative max  	1k 
tabic 1: average expansions by max  in chinese checkers. 
weighed the nodes savings from the additional pruning. 
　　also  while our sample search trees show cutoff evaluation functions that are seemingly independent of the other players  the actual cutoff evaluation functions used in these experiments are based on the scores of all players in the game. so  instead of just trying to maximize their own score  players are actually trying to maximize the difference between their score and their opponent's scores. 
　　finally  all our experiments on card games were run on the 1-player perfect-information variations of each game. 
1 chinese checkers 
in the past  max  search of chinese checkers trees has been limited to brute-force search  as the bounds in the game are not appropriate for shallow or branch-and-bound pruning. in our experiments we ordered moves according to which ones move a piece farthest across the board. because the branching factor is very high  over 1 in the mid-game   we only considered the top 1 moves in our ordering at each node. 
　　we played speculative max  in thirty 1-player games; each game is about 1 moves long. we then measured the average number of nodes expanded at depth 1 by speculative max . results are found in table 1. while it takes 1 million nodes to complete iterative searches to this depth with no pruning  speculative max  expands an average of 1k nodes  while an optimal ordering of nodes would expand 1 nodes for this branching factor and depth. in some cases this optimal ordering is achieved in practice. 
1 	hearts 
it is more difficult to measure the efficiency of speculative max  in card games. this is because node expansions are highly dependant on the cards in your hand. additionally  better play  resulting from deeper search  often results in more nodes being expanded throughout a game  as good plays early in the game force more computation later in the game. so  we measured our results in a slightly different manner in hearts. 
　　we played 1 hands of hearts with a 1k node search limit. hands were searched iteratively deeper until the node limit was reached  and re-expansions in speculative max  counted towards the node limit. we then measured the average search depth by max  and speculative max  over all games. the results are found in table 1. averaging the search depth over all moves is misleading  because at many  
points in a hand the search depth is limited by the number of cards in your hand. instead  we averaged the search depth for points in the tree where the search wasn't limited by the number of cards in the hand  and we also found the average point at which a hand could be searched to completion. 
　　speculative max  can search a hand to completion when  on average  there are 1 cards remaining in a hand  while max  can only do it when 1 cards remained. in the case where search isn't depth limited  speculative max  can search an average of 1 moves ahead  while max  can only search 1 moves deep. 
　　there are three reasons we don't see more spectacular depth gains. first  in card games the order of player moves in the tree is less uniform  which will lessen the amount of pruning available. second  we know that the ordering heuristic we used in hearts can be improved  as it had to re-search many more times than in chinese checkers and spades. finally  the asymptotic branching factor of hearts is much lower than chinese checkers  so the actual gains are smaller. 
1 spades 
in spades  like hearts  we played 1 games with a 1k node search limit  and then measured the average search depth over all games. the results are also found in table 1. while speculative max  could search a hand to completion when it contained  on average  1 cards  max  could only do it when 1 cards remained. when the search was not depth limited  speculative max  was only able to search depths 1 while max  could only search to depth 1. 
1 performance against paranoid algorithm 
the paranoid algorithm  sturtevant and korf  1  is another algorithm for playing multi-player games. it reduces a game to a 1-player game by assuming one's opponents have formed a coalition. this represents a different decision rule than standard max . the trade-off for this less plausible decision rule is a gain in search depth. all techniques from 1-player game research can be used under the paranoid algorithm  and alpha-beta pruning in a //-player paranoid game tree will  in the best case  reduce the number of nodes expanded in a game tree with n players from // to bhna ln. 
　　although paranoid and speculative max  have the same asymptotic growth  paranoid will produce smaller trees in practice because it can prune more than n levels away from 

	hearts 	spades 
	plain max  / paranoid 	1 / 1 	1 / 1 
	spec. max /paranoid . 1/1 . 	1/1 
tabic  l  average score in spades and hearts. 
where a bound originates. 
　　a comparison between paranoid and max  can be found in  sturtevant  1 . given the gains from speculative max   it is worth making a comparison against paranoid. 
　　it has been shown experimentally  sturtevant  1  that the paranoid algorithm outperforms standard max  at fixed depths in chinese checkers. since adding speculative pruning doesn't change max  s decision rule  we don't see a gain in max  s performance against paranoid with speculative max . but  it may now be worth considering strategies that are more mixed between standard max  and the paranoid strategy  as paranoid's advantage in search depth has been greatly lessened. 
　　to measure the differences between paranoid and max  in card games we followed the same strategy in hearts and spades. in both of these games we played 1 hands with a 
1k node search limit. each of these hands were played multiple times to account for player positions on the table. we measured the average search depth for paranoid over these games  and we also compared the average score for max  with and without speculative pruning. both algorithms expand nodes at the same rate  so there is no significant difference in cpu time between the two algorithms. 
　　in table 1 we see that paranoid was able to search deeper than speculative max  in both hearts and spades. in spades  paranoid can do highly efficient zero-window searches  pearl  1   allowing it to search entire hands when they contain 1 cards on average  over 1 cards better than speculative max . in hearts  paranoid can search 1 cards deeper than speculative max . 
　　but  despite paranoid's advantage in search depth  these results do not translate into quality of play. we sec this in table 1. each entry in the table contains the listed algorithm's average score followed by paranoid's average score. in hearts  paranoid and max  had virtually the same score after all games. but  with the additive pruning and search depth in speculative max   it was able to beat paranoid by almost 1 point per hand.  lower scores are better.  in spades  where max  did slightly worse than paranoid  speculative max  was able to do better than paranoid  despite a much shallower search.  higher scores arc better.  these results show that given speculative pruning  max  has the potential to be the best decision rule for card games. 
1 conclusions and future work 
we have seen here that last-branch and speculative pruning combine to provide large theoretical and practical gains for searching max  trees. this is the first pruning technique to be developed for max  that is effective on a wide range of games. while other pruning techniques have required very specific cutoff evaluation functions in order to prune  last-
branch and speculative max  pruning only require a game to have a lower bound on each player's score and an upper bound on the sum of all scores. 
　　also  while the paranoid algorithm must make assumptions about the strategies its opponents use in order to prune  last-branch and speculative pruning make no such assumptions  but can still be adapted to account for opponents strategies. thus  these algorithms are quite promising for use in multi-player games. 
     speculative max  pruning only prunes over n levels in the game tree. it is possible to extend this idea to prune even deeper into the tree. however  it is unclear if the cost of bookkeeping and re-search for these cases offsets the potential gains. this is an area of our ongoing research. 
acknowledgments 
we would like to thank rich korf and alex fukunaga for their comments and suggestions on these techniques. this work was supported in part by nasa and jpl under contract no. 1 and by nsf contract eia-1. 
