 
many representations in early vision can be constructed by performing orientation analysis along several sampling dimensions. texture is often oriented in space  motion is oriented in space-time  and stereo is oriented in spacedisparity. in these modalities  we can construct distributed representations with oriented energy measures used in models of biological vision. surface models of orientation  velocity  and disparity can easily be fit to distributed representations of texture  motion  and stereo by combining tools of orientation analysis and regularization. we describe base representation construction and model fitting processes in these domains. 
1 	distributed representations 
conventional approaches to early vision have focussed on recovering explicit models of local structure and subsequently fitting models to local structure. when the assumptions made in modeling local structure hold  the local structure is successfully recovered. when model assumptions are violated  however  local structure is incorrectly recovered in unstructured ways. for example  conventional motion estimation algorithms assume that there is a single motion  that the intensity is constant in space time  and that the flow field is smooth. these assumptions are violated  for example  at motion boundaries. at motion boundaries  two motions are present  intensity is not conserved  and the flow field is discontinuous. consequently  conventional approaches of recovering flow fields fail at occlusion boundaries. various techniques have been proposed to counter these assumptions: regularizing with line processes  poggio et a/.  1   generalizing local models  shizawa and mase  1   using global parametric models  bergen et al.  1   and using robust estimation  black and anandan  1 . 
　alternatively  we can use distributed representations of vision  where a population of responses implicitly represents local structure. this strategy is used in visual cortex  where neurons do not represent parameters explicitly  but instead are tuned to stimulus parameters of spatiotemporal frequency  horizontal disparity  velocity  global motion patterns  and so forth. 
several have produced models of tuning properties of cells in the visual cortex  in parallel to conventional approaches of modeling and recovering local structure in computer vision: spatially oriented filters model orientation selectivity of simple cells  bergen and landy  1 ; spatiotemporally oriented filters model directional selectivity  adelson and bergen  1 ; stereo spatial filters out of phase model disparity tuning  qian  1; sanger  1 ; and combining the outputs spatiotemporally oriented filters models velocity tuning  grzywacz and yuille  1; heeger  1; simoncelli  1 . 
　the construction of distributed representations in different modalities becomes remarkably similar once observing that most local structure in visual stimuli is oriented along several sampling dimensions  adelson and bergen  1 : 
  space. spatial textures and edges are oriented in space  where x =  x y . 
  space-time. motion is orientation in space-time  where x =  x: t  or x =  x y t  in one and two dimensional motion  see  adelson and bergen  1  . 
  space-disparity. stereo is orientation in spacedisparity  where x =  x vx  or x =  z y  vx  for one and two-dimensional stereo analysis. typically  two samples of vx form a stereo pair. 
　figure 1 illustrates oriented structures in each of these dimensions. in the above modalities  constructing distributed representations of orientation is possible by filtering a stimulus / x  with multiple oriented filters tuned to different orientations in space  space-time  or space-disparity. each spatiotemporally oriented filter signals the presence of a given orientation; by having banks of oriented filters tuned to different orientations  a population of responses can be obtained to represent local structure. figure 1 a b  shows an {x t  stimulus with occluding and transparent motions  and a slice of the base representation ea x t  1  we can construct from the stimulus using oriented filters. where there is transparency  a bimodal distribution of energy is present at each point x  and where there is occlusion  a bimodal distribution of energy is present to both sides of x. while it is unclear how properties such as color and shading could be encoded in distributed representations  we can take a unified approach for the domains of texture  motion and stereo. 
	niyogi 	1 

　rather than fitting models to explicit representations of orientation  such as range data or optical flow  we fit models to implicit  distributed representations of vision. distributed representations are advantageous because they:  1  represent complex naturally occurring stimuli  such as transparency and occlusion;  1  represent uncertainty implicitly;  1  degrade gracefully with noise;  1  do not commit to an  often wrong  answer  unlike explicit representations;  1  are also used in biological visual systems. 
　the problem remains  however  of how to utilize distributed representations of vision to recover information about global surfaces. most of the past approaches used distributed representations to estimate local structure  in the domains of texture  kass and witkin  1   stereo  sanger  1; qian  1  and motion  fleet and jepson  1; grzywacz and yuille  1; heeger  1 . in regions containing little or no texture  filter responses are negligible  so approaches which attempt to use distributed representations to estimate local structure will fail. thus the surface interpolation problem remains. 
　the surface interpolation problem in explicit representations is typically solved by taking sparse representations of explicit local measurements  and smoothly in-
terpolating between them. canonical approaches to sur-
face interpolation  e.g.  terzopoulos  1   use both a fidelity criteria  describing the fit of the surface to 
sparse measurements  and a smoothness criteria so as to constrain regions without measurements. typically  weighted combinations of the square of the first and second derivatives of surfaces are used as a measure of smoothness. by combining tools of orientation analysis with simple modifications of standard regularization processes  we show that it is straightforward to fit models to distributed representations. 
　rather than recovering explicit local structure  and then fitting surface models to local structure  we fit mod-
els to distributed representations of vision directly. the generic approach is contrasted with our approach in figure 1 a b . we describe base representation construction and our adaptation of regularization in the domains of 
space  space-time  and space-disparity  and demonstrate preliminary success on simple imagery. 
figure 1: architectures   a  standard computer vision approaches to fit models to explicit representations of local structure  which is prone to failure where explicit representations of local structure cannot be accurately recovered   b  we advocate fitting models to distributed representations of local structure. 
1 	action and perception 

cal spatial orientation; for one-dimensional and twodimensional stereo  the orientation is horizontal disparity; for one-dimensional motion  the orientation is horizontal motion; for two-dimensional motion  the orientation  is a two dimensional vector. 
　the model u u t  indexes into the base representation   so that a total  energy  of a surface can be obtained. we seek to fit a model where the population response in the base representation  across the surface is maximized  and where the magnitudes of the derivatives in the orientation surface are minimal  as in standard regularization processes  c.f.  terzopoulos  1  . since multiple surfaces can be fit  no answer is correct; the only satisfactory answer will require the observer to shift attention between portions of the base representation. 
　models are fit over multiple scales by constructing a scale-space: 
where i represents a gaussian convolution kernel of width scale-space is approximated with a gaussian pyramid at discrete scales of an ndimensional interpolatable base distributed representation  is constructed from l1 x  through orientation analysis. steerable  freeman and adelson  1; koenderink  1; perona  1  filters allow for continuous interpolation to any . the stimulus at a given scale is used to compute n steerable  basis images'1 via convolution with a set of basis filters gi  x : 
where represents spatial orientation  spatiotemporal orientation  velocity  or disparity  depending on the sampling dimensions being considered. we will describe the details of base representation construction in subsequent sections. 
　models can be fit these base representations by modifying standard regularization procedures  c.f.  terzopoulos  1   to use this base representation to dynamically estimate the state of a model u u  t : 

where assumptions of smoothness in the nth order spatial derivatives of orientation are embedded within the stiffness matrix k  and base representations are used to apply observation  forces  f u t  to the surface by integrating forces through discrete summation over several scales: 
here  h indexes the orientation surface component  of the model ii u t . we can easily modify the above to introduce additional  forces  to shift attention from certain portions of base representation to others  as in the deformable contours  kass et a/.  1 . 
　thus we employ the following procedure to fit models u to stimuli j x : 

1. approximate scale-space  through construction of a gaussian pyramid of / x . 
1. over all scales sigma  construct base representation by convolving 	with n basis filtersg 
	i x  to compute 	  where i = 1 ...  n. 
1. initialize model u. 
1. continually subject model u to data forces f u t  derived from base representation 
　below we describe base representation construction  and methods to apply observation forces derived from base representations in the domains of texture  motion  and stereo. we illustrate model fitting processes on canonical examples in our preliminary experiments here. 
1 	two-dimensional space 
for two-dimensional spatial texture  x =  x  y   and 1 = where represents the local orientation of the texture. a single 1-d sheet model is superimposed on the data: 

oriented energy  bergen and landy  1  measures are where the spatial stimulus at multiple scales is used to compute a set of steerable  basis  images 
filters gi x  y  form the steerable separable basis for the quadrature pair of filters i and   which are interpolated to any orientation with interpolation functions ; refer to  freeman and adelson  1l  for filter taps and interpolation functions for all of our experiments; we use a second derivative of gaussian as a basis in our examples except where noted. an example stimulus  basis images  and the base representation are shown in figure 1. 
　forces are applied to the model via the gradient of integrated over all scales: 
niy1i 

here h =  1ii  indexes into the surface 1 x y  component of n u / . to avoid singularities due to the discontinuous nature of angles  a vector n -  cos 1  sin 1  t is used to represent the state of the model  and is continuously normalized to one  n1  - 1 . we illustrate the analysis of oriented texture patterns containing simple deformations in texture orientation. figure 1 a  shows one of several sample oriented patterns we have experimented with. figure 1 b  shows an orientation map recovered using our approach. with multiple orientations in the stimulus  either multiple models must be fit  or an attentional mechanism to shift the surface is necessary. with detected orientation stopping  c.f.  heitger  1    smoothing processes should be halted. 
1 	one-dimensional space-time 
for one-dimensional space-time  x =  x t  and 1 = vx  where vx represents local 1-d motion. a time-varying 1-d sheet model is imposed on the data: 

for spatiotemporal stimuli / x t   motion is orientation in space-time  adelson and bergen  1 ; the motion vx is related to the spatiotemporal orientation 1 via vx = 

　just as in  x  y   oriented energy measures are used for base representation construction in  x t : 

an example stimulus  basis images  and its base representation are shown in figure 1. 
　forces f  u  t  are applied to the model via the gradient of i integrated over all scales: 
here  h =  1|i  indexes into the surface vx x t  component of the model u u / . figure 1 a  shows a simple stimulus where one surface is moving rightward occluding a background moving leftward. figure 1 b c  shows the sheet model fit via our approach for the stimulus for a given instant in time. 
1 	two-dimensional space-time 

now simple orientation analysis is inadequate; a twostage calculation is necessary  heeger  1 . the first stage involves filtering an image sequence with spatiotemporally oriented filters. the second stage pools 

the squared responses of these filters to construct units tuned to velocity. stimuli translating with velocity 
  when viewed in the frequency domain  contain energy along the plane 
1 	action and perception 


niyogi 

figure 1: two-dimensional stereo   a  a stereo pair ii x y  and ir x y   observer is fixated on a plane with two bars in front of and behind this plane;  b  recovered disparity between the left and right views. 
now  gi x y  vx  - 1 y  * gi x vx  forms an approximation to g1 x  and h1 x   but only the center slice  vx =. 1  of the basis is used to represent the spacedisparity orientation  x  vx  at each point in space  x  y . an example stimulus  basis signals used to simulate the base representation  and a constructed base representation are shown in figure 1. a slice at a given height y of the above signals is shown in figure 1; fitting models 
1 	action and perception 
1 	discussion 
in addition to sheet models  which are directly attached to image data  other models can be fit. surface models  attached only to a portion of the visual field  would be required to recover the parameters of an object. we have not dealt with the problem of model initialization. to do so  we require a model of attention; extensions to surface models are straightforward once a model of attention is adopted  see  for example   olshausen ot a/.  1  . models of controlling attention shifts between surfaces in these distributed spatial representations must be designed. 
　seeking enhanced base representations improves results greatly. for example  some degree of normalization 

 heeger  1  in the base representation may reduce the dependence on local contrast  although the convenience of steerability is lost. some operations  such as occlusion detection  heitger  1; niyogi  1a   may be based on the distributed representations and/or the surfaces fit to them; using these representations to constrain model-fitting processes is desired. linking our model-fitting processes to solutions to surface segmentation mechanisms using distributed representations  heitger and von der heydt  1; finkel and sajda  1  is clearly desirable. 
　the majority of computer vision efforts in early vision have been directed towards estimating explicit representations of local structure  and subsequently fitting models to these representations. these explicit representations are prone to failure where model assumptions break down. implicit representations do not have these problems. problems in modeling local structure  object model recovery  handling occlusion  surface segregation  attention  etc. can and should be attempted using distributed representations of vision. a parallel effort using distributed representations of vision is likely to be more fruitful than relentlessly improving methods of recovering explicit local structure. we have presented a first step at fitting models to distributed representations of vision here. 
