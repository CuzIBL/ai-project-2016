 -
     narrative structures can only be defined in terms of some internal memory representation  but narrative complexity is more properly characterized by information processing requirements. story grammars  plan and goal hierarchies  and causal chain representations all provide a sense of structure which is largely removed from the processes that produce or access that memory representation. in this paper we introduce the notion of algorithmic equivalence as a means of generating more algorithmically-oriented taxonomies for memory representations. using memory representations based on plot units  we define two narratives to be algorithmically equivalent if they can be effectively summarized by the same retrieval process. this perspective on representational strategies is an especially natural one from a processing point of view  since the computational complexity of a particular information processing task must be measured in terms of the algorithms involved . 
1. the plot unit approach to summarization 
     a representational strategy for narrative text has been developed to account for summarization behavior using relatively simplistic retrieval algorithms. when the memory representation for a 
     narrative is encoded in terms of plot units  lehnert 1; 1   it is possible to invoke retrieval algorithms that locate the central most important concepts of the narrative by examining structural features of cyclic graphs. each node in the graph corresponds to a plot unit instantiation  and two nodes are connected by an arc when they share a common internal component. 
     a plot unit is a fixed configuration of smaller components called affect states. there are three affect state types designed to differentiate gross subjective states within a single character: positive states  negative states  and neutral mental states. these affect states emphasize emotional reactions to events and states rather than goal-oriented planning behavior  and each 
character in a narrative can be tracked in terms of an  affect state map  which chronologically records the subjective mental states for that character. 
*this 	work 	is being supported by national science foundation grant //ist-1. 
     once an affect state map has been produced which tracks the major characters of a narrative  we can look for instances of specific plot units within that representation. a  top level  plot unit instantiation is one that is not subsumed  fully contained  by any other plot unit instantiation. when all the top level units are recognized  we create a plot unit graph in which the nodes of the graph correspond to top level plot unit instantiations. two nodes of the graph are then connected by an arc whenever they share at least one common affect state. this graph structure provides a level of memory representation that is especially well-suited for text summarization  lehnert  black  & reiser 1; reiser  lehnert & black 1; gee & grosjean 1; 
reiser  black & lehnert 1; 	lehnert  	alker  	& 
schneider 1 . nodes which are structurally central to this graph are expected to provide us with the conceptual content for a good summary. 
     for example  suppose john asks susan to marry him and she says no. this episode would be represented by the denied request unit: 
1 	w. lehnert 
	john 	susan 	karen 

it is d i f f i c u l t to argue for the power of this representation when we are summarizing a two sentence story  but plot unit graphs can involve hundreds of units. for such complex narratives  we rely on structural features of the plot unit graph to t e l l us which nodes contain the concepts that are most central and c r i t i c a l to the story. for example  if a graph contains a unique node of maximal degree  we want to examine the contents of that node in order to produce a summary of the story. if a graph contains multiple nodes of maximal degree  we w i l l have to resort to a different retrieval algorithm. we can therefore pursue a notion of narrative equivalence wherein two narratives are algorithmically equivalent  a-equivalent  if their plot unit graphs can be processed by the same summarization retrieval algorithm. it follows that narratives with isomorphic plot unit graphs are a-equivalent  although narrative plot unit graphs can be a-equivalent without being structurally isomorphic. this notion of algorithmic equivalence creates a weaker partition than the more traditional relation of isomorphic equivalence. 
1. 	narrative equivalence classes 
　　　any partition of a-equivalent plot unit graphs determines a corresponding partition of narrative source texts. this in turn constitutes a taxonomy of narrative complexity. to identify such algorithmically-motivated equivalence classes  we must identify categories of graph structures that can be associated with specific retrieval algorithms. any systematic development of such equivalence classes must be based on a large set of narrative representations that includes a wide variety of graph structures. this work is now in progress  but we have compiled enough narrative representations at the level of plot unit graphs to suggest some preliminary taxonomies. we are also developing a methodology for the identification of graph equivalencies which w i l l allow us to proceed in a systematic manner. 
　　　the general strategy we are using to* discover plot unit graph equivalencies is a combination of bottom-up exploratory work and top-down hypothesis testing. in tue bottom-up pusss we collect and analyze random narratives  to create a library of plot unit graph representations. we w i l l later draw from this library for substantiating evidence and counterexamples  but the f i r s t phase of our research is simple compilation. we are using narratives that come from ai work in natural language processing  cognitive psychology research on text comprehension  and published short stories by popular authors. the source texts range in complexity from a single paragraph to about 1 pages. our most complex narrative thus far is arnold toynbee's synopsis of the story of jesus. 
　　　for each narrative we must hand-code a chronologically-ordered representation of affect state maps. we cannot automate this process with any generality because the text processing techniques involved are highly domain-dependent and would require extensive knowledge encoding for each narrative attempted  see dyer 1 for a good discussion of what would be involved . the graduate students who produce our hand-coded representations work together to assure uniformity in their encoding techniques  and we are developing encoding heuristics to aid others outside our immediate research group who would like to experiment with plot unit graphs. 
　　　once a hand-coded affect state map has been produced  we process the representation with pugg  the plot unit graph generator . pugg is designed to accept any set of plot units as our set of universal unit structures  and any affect state maps that are consistent with the structural conventions for legal affect state configurations. pugg returns an adjacency matrix for a l l top-level units along with other useful information about 
disjoint subgraphs and immediate unit families. 
　　　one of the important parameters in this work is the specification of a universa  set of top-level plot units. graph structures w i l l vary according to our selection of legal unit configurations  but we would ideally like to arrive at a taxonomy of graph structures that remains valid over a variety of universal sets. as a psychological theory of cognition and memory  we expect universal sets to vary across individuals. this variance could account for individual differences in summarization behavior as well as developmental differences between children and adults. it is therefore important to analyze each narrative with respect to more than one universal set  indexing each resulting graph with respect to i t s universal context. 
　　　to assure f l e x i b i l i t y in this regard  we are analyzing each narrative with respect to three universal contexts. context a is restricted to units involving no more than one or two characters. context b is a subset of context a that contains only the simpler plot units of set a  most units in set b contain less than 1 affect states  . context c departs from sets a and b insofar as it contains units that involve more than two characters. context c consequently contains plot unit configurations that are more complicated than those found in context a. we do not require a l l three encodings for any given story to be a-equivalent according to our partition of graphs. it seems quite plausible that some stories w i l l be easier to summarize under one universal set than another  this should be especially true if one set is relatively impoverished . 
　　　in the course of compiling this library of representations  we are seeing some patterns emerge: 

 1  most graphs are fully connected. 

	w. lehnert 	1 
1. 	graph types and summarization algorithms 

 1  if a graph contains a unique node of maximal degree  it is probably small  containing   1 units  . 
 1  two distinct clusters that are strongly connected often describe the same events from different perspectives. 
 1  if a graph can be partitioned into maximal clusters  boundary units between the clusters tend to be important. 
     with each new graph we generate  we must examine that graph to see where its critical nodes are located. sometimes the critical nodes are structurally conspicuous. in these cases we can associate a plausible retrieval algorithm which appears to be appropriate for that graph. the same algorithm typically applies to a number of graphs  in which case we must identify necessary and sufficient conditions for the application of that algorithm. in other cases we may not be able to identify a simple algorithm  or a simple algorithm applies but does not produce a satisfactory summary. these apparent failures may force us to revise a previous summarization algorithm  or revise the necessary and sufficient conditions that signal the applicability of a particular algorithm. 
     the necessary and sufficient conditions that identify appropriate algorithms will define our graph equivalence classes. hypothetical equivalence classes arise every time we propose a possible summarization algorithm  but we must be careful to maintain consistency throughout the system whenever a new class is proposed or an old class is altered. if we begin to amass a large number of equivalence classes  we will watch for hierarchical relationships among possible partitions. from a developmental perspective it seems quite likely that simple partitions might be refined into more complex partitions  and that such refinements would be associated with improvements in summarization behavior. with this in mind  we expect to find simplistic classifications that produce inferior summaries for some stories. 
     as our library grows  we will track error rates for each equivalence class as well as error rates for each set of universal plot units. in an ideal partition  the error rate across equivalence classes should be roughly uniform with respect to each universal context. on the other hand  the overall error rate across different universal contexts may vary considerably  in which case we will learn something about effective plot unit configurations. for example  if the error rate associated with context c is significantly higher than the rates for contexts a and b  we will have a strong argument against the inclusion of plot units involving more than two characters. 
     thus far  we have analyzed about 1 narratives with respect to universal contexts a and b  and we have not yet formulated the units for context c. we need to look at more narratives before we propose a set of equivalence classes  but on the basis of this initial library we have identified three core equivalence classes which appear to produce reasonable summaries for a majority of the narratives. we will summarize these categories briefly. 
a. simple graphs with unique pivots 
     one class of graphs exhibit unique nodes of maximal degree. while this class seems to be restricted to smaller graphs  we can reliably look to such pivotal nodes for the concepts most central to the narrative as a whole. this was the first algorithm we identified  and is therefore discussed in some earlier publications  e.g. see lehnert 1 . while our initial work suggests that it is very difficult for a long narrative to fall into this category  we may see a higher frequency of stories in this class as our universal set of plot units expands. for example  it should be easier to create graphs of this type within context c than context a. 
b. complex graphs with multiple pivots 
     this group of graphs is quite large and must be divided into smaller subsets for effective categorization. in some cases we see two nodes of maximal degree whose immediate families partition the entire graph into two subgraphs. the maximal nodes on the boundary of this partition then serve to give us a one-sentence summary for the whole story. in other cases  we see graphs where the maximal nodes themselves provide critical concepts for summarization. this is especially common when the two maximal nodes are adjacent to one another  in which case they are frequently of equal importance. 
     as we investigate this class further  we may find it necessary to assign relative weights to nodes which vary with the surrounding environment. for example  suppose a node of degree 1 has 1 neighbors that all have degree 1  this sort of dense connectivity is rarely encountered . we may want to assign a lesser salience to such a node  favoring instead a node of degree 1 whose neighbors all have a degree of 1. a particularly elegant solution for these larger graphs would be to simply locate the subgraph composed of nodes with minimal eccentricity  where the eccentricity of a node is defined to be the largest distance from that node to any other node of the graph  proskurowski 1 . there are many such possibilities  and our initial explorations have not adequately differentiated their strengths and weaknesses. 
1 w. lehnert 
c. separable graphs 
     this category contains large graphs    1 nodes  composed of subgraphs that can be separated 
by deleting a single node. while it may seem that the nodes central to each potential component of the graph might be good candidates for conceptual salience  we have found that the best results are obtained by looking at the  deletion  nodes which keeps the graph from separating. if there are multiple deletion nodes  we look for a path containing all the deletion nodes. the shortest path seems to be preferred  although maximal degree can enter in as a factor when more than one path is possible. these graphs tend to be associated with the longest and most complex narratives  see  lehnert  alker  and schneider 1  for a detailed discussion of one such graph . 
***** 
     as we consider these three preliminary a-equivalence classes  we see that processing complexity is determined to some extent by the size of the memory representation  or plot unit graph . this is hardly surprising  although the concept of a-equivalence suggests that there should be distinct plateaus of summarization competence  with severe drops in performance whenever a representation is incorrectly categorized. this provides us with a set of performance predictions which will be distinct from any models that predict strictly linear complexities based on the length of the input text or the size of an internal memory representation alone. 
1. 	conclusions 
     our work to identify a-equivalent narratives continues on many fronts. we are expanding our library of affect state maps and the corresponding library of plot unit graphs. at this stage it seems appropriate to concentrate primarily on the taxonomy of necessary summarization algorithms  and secondarily on issues concerning universal sets of plot units. we hope to concentrate more fully on the question of universal sets after we have a firmer footing on the issue of algorithmic equivalence. it is too early to say anything about the status of algorithmic equivalence as a concept of psychological import  but a plot unit approach to human text comprehension may dovetail very naturally with a developmental study of human summarization behavior. we might  for example  expect to see competent summarization behavior in some classes before others  in which case the notion of a-equivalence would provide a simple measure of narrative complexity in terms of human information processing capabilities. 
     on a more general level  we note that plot units are applicable to narrative texts with human  or anthropomorphized characters  for whom an affect state analysis is possible. it is not obvious that an analogous system of memory representation can be applied to expository or purely instructional texts. at the very least  our approach suggests that the cognitive processes underlying summarization skills for narratives is very different from the processes of summarization required for other types of text. narratives and expository texts may therefore reside within two basically disjoint a-equivalence classes  in which case competence in one area may not correlate very strongly with competence in the other. such a situation would have immediate consequences for educators as well as other computational models of text comprehension. 
