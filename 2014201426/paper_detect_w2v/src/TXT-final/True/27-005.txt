 
this paper describes resolve  a s stem that uses decision trees to learn how to classify coreferent phrases in the domain of business joint ventures an experiment is presented in which the performance of resolve is compared to the performance of a manually engineered set of rules for the same task the results show that decision trees achieve higher performance than the rules in two of three evaluation metrics developed for the coreference task in addition to achieving better performance than the rules  resolve provides a framework that facilitates the exploration of the types of knowledge that are useful for solving the coreference problem 
1 	introduction 
the goal of an information extraction  ie  system is to identify information of interest from a collection of texts within a particular text  objects of interest are often referenced in different places and in different ways one of the many challenges facing an ie system is to determine which references refer to which objects this problem can be recast as a classification problem given two references  do they refer to the same object or different objects 
	the 	message 	understanding 	conferences 	 mucs  
 sundheim  1  1  1  and the tipster project  merchant 1  helped both to define the information extraction task and to push the technology of ie systems each of these evaluation efforts provided a corpus of news articles about a domain  a specification of the relevant information that was to be extracted from each article  the output representation of that information  and a set of key templates representing the information extracted from each article by human readers 1 for the final evaluations  participating systems were given a set 
　　 this research was supported by nsf grant no eec 1  state/industry/university cooperative research on intelligent information retrieval  digital equipment cor poration and the national center for automated information 
research 
   'the muc-1 evaluation actually included 1 different domains  but most participants were required to select only imt 
1 	learning 
of blind texts and their output was scored against the key templates to determine how much of the relevant information they were able to extract 
   the sentence analyzers used in many of these systems have shown significant improvement over the past several jears however  the discourse processing capabilities of these systems  particularly their coreference resolution components  have often been cited as weak areas  weir and fritzson  1  moldovan et al   1  aberdeen et al 1  
   the ie systems developed at umass  lehnert et al   1  1  1  also displayed weak coreference resolution capabilities each of these systems used a set of manually engineered rules to resolve some obvious types of coreference  but they tended to be very conservative  l e   they only considered phrases to be coreferent if there was overwhelming evidence in support of that hypothesis one of the problems with these coreference resolution components was figuring out which features of the phrases to look at when determining coreference an other  related set of problems was determining how to combme positive and negative evidence into individual rules and then how to order the rule set a third problem area was the accumulation of errors at that late stage of processing  e g   from incorrectly delimited sentences  incorrect part of-speech tags  and other sentence analysis errors 
   in an effort to address these problems  a new approach to coreference resolution was begun after the muc-1 evaluation a system named resolve was created to budd decision trees that can be used to classify pairs of phrases as coreferent or not coreferent the errors generated by the sentence analyzer were eliminated by using a special tool - the coreference marking interface  or cmi - to extract a set of phrases from the muc 1 english joint venture  ejv  corpus 1 in order to minimize the difficulties involved with creating and maintaining complex bets of rules  a machine learning approach was adopted  in which a decision tree determines the order and relative weight of different pieces of evidence 
     the muc-1 ejv corpus is a collection of news articles  written in english  that describe busmess joint ventures  i e   associations of two or more entities  companies  governments or people  created for the purpose of owning and/or developing a project together 

resolve used the c1 decision tree system  quinlan  
1  to learn how to classify coreferent phrases for the experiments reported in this paper c1 was chosen primarily due to its ease of use and its widespread acceptance  however  resolve can use any learning system that uses feature vectors composed of at tribute- value pairs 
1 	decision trees vs rules 
an experiment was conducted to compare the perfor mance of the decision trees generated by resolve with the performance of manually engineered rules used for coreference classification in the u mass/hughes muc-1 ie system a set of references  along with the coreference links among these  were extracted from a group of texts via cmi all possible pairings of references from each text were generated  and these pairings were used to create a set of feature vectors used by resolve the pairings that contained coreferent phrases formed positive instances  while those that contained two non-coreferent phrases formed negative instances resolve was then iteratively trained and tested on different partitions of this set of feature vectors 
   the data structure used in discourse processing by the umass/hughes muc-1 ie system was the memory token  which converted the case frame output from the circus sentence analyzer  lehnert  1l  into a more system-independent representation prior to coreference processing  each memory token contained one noun phrase  one or more lexical patterns encompassing that phrase  part-of-speech tags  semantic features  and information that was inferred from either the phrase or the context in which the phrase was found this inferred information included the type of object referenced by the phrase  any name or location substring contained in the phrase  and some domain-specific information such as whether the phrase was a joint venture parent  one of the entities who formed a joint venture  or joint venture child  the joint venture company itself  the references marked via cmi were converted into a memory token representation in order to test the performance of the muc-1 system's coreference module 
1 	data 
the articles in the ejv corpus describe business joint ventures among two or more entities  companies  governments and/or people  the task definition provided for muc-1 required ie systems to extract information about the entities involved  the relationships among these entities  the facilities associated with the joint venture  the products or services offered by the joint venture  its capitalization and revenue projections  and a variety of other related information since the entities involved in these joint ventures were the main focus of most of these articles  references to entities were much more numerous than references to other types of object classes  e g   people therefore  entity references were selected as the focus of the experiments reported in this paper 
　cmi is a graphical user interface that permits the user to mark phrases in a text  for each phrase  the user can indicate the object s  with which the phrase is coreferent and some additional information about the phrase that can be inferred either from the phrase itself or its local context this additional information is parametensed and can be modified easily for use in different domains the data used in this experiment was based on a set of phrases extracted using cmi 
　as an example  consider the following sentence  from text 1 from the muc-1 ejv corpus 
familymart co of 
1eibu saison group will open 
a convenience store in taipei friday in a joint venture with taiwan's largest car dealer. the company said wednesday 
　the phrases underlined in this sentence contain relevant information that must be extracted by an ie system the phrases in boldface refer to entity objects that are important to the muc-1 task as an ex-
ample of the types of information collected about each phrase  consider the first phrase in the sentence 
  string  familymart co   slots  entity name  familymart co n  type company  
 relationship jv-parent child  } 
　information collected about each phrase includes the string itself  the character position of the string in the source text  not shown   the index of the sentence within which the string is found  also not shown   and some slot information that can be inferred from either the string itself or its local context - the same kind of information that was contained in the memory tokens used by the muc-1 system in thus example  the name of the entity and the fact that it is a company entity can both be inferred from the string itself the fact that famllymart company plans to open a store in  a joint venture  with another entity is considered adequate evidence that the company is the parent of a joint venture  jv-parent   the fact that the sentence contains the pattern  company name 1 of company-name 1  is evidence that company-name-1  yn this case familymart co   is a subsidiary  child  of company-name-♀  in this case seibu saison group 
　a second example of output from cmi can be seen below  where nationality information has been extracted from the reference to the car dealer 
  stnng  taiwan's largest car dealer  slots  entity 
.type company  
 relationship jv parent  
 nationality  taiwan  country      
1
note that the phrase  the company  in the last 
clause of the sentence is not considered relevant  since it con tributes no information required for the muc 1 task - the determination of who is announcing a joint venture or when the announcement we* made are not relevant pieces of infor mation therefore  this phrase was not marked for use in the experiment 
1 

　in principle  much of the information gathered about a particular string could be found automatically there are numerous proper name recognzer programs  programs that extract location information  and sentence analysers that can infer relationship information - any svstem that exhibited good performance in muc-1 must be good at inferring such relationships 
   for the purposes of our experiment  however  this information was specified by a user via cmi the primary motivation for this was to minimise the noise in the data  coreference resolution often occuii at a late processing stage in an ie system  and earlier errors such as incorrect part-of-speech tags  incorrectly delimited sentences and semantic tagging errors can create significant noise for a coreference classifier 
　cm i was used to mark references to a variety of relevant object types  entity  f a c i l i t y   person and product-or-service  in 1 randomly selected texts * since references to entity objects were most numerous  this was the object class chosen for the experiment in the 1 texts  1 references to a total of 1 entity ob-
jects were marked using cmi 
　some phrases are multirefevent  l e   they refer to more than one object these multireferent phrases pose difficulties for classification  since it means that some phrases will be coreferent with other phrases in the text that have distinct referents thus for a set of phrase pairs which share a given phrase  more than one pair would be classified as a positive instance of coreference further complications are created for evaluating the performance of a coreference system when multireferent phrases are included m the data  see section 1  to simplify the initial experiments reported here  multireferent phrases were excluded from the data set the capabibty to han die such phrases wdl be incorporated in a later version of resolve 
1 	rules used in the m u c - 1 system 
the coreference module of the umaas/hughes muc-1 ie system was designed to minimise false positives  i e   minimise the likelihood that two phrases that were not coreferent would be labeled coreferent this design decision was based on the assumption that false positive errors  resulting in the merging of non-coreferent phrases in the final system output  would harm system performance more than false negative errors  which would result in coreferent phrases showing up in distinct objects in the system output this rather conservative approach to coreference was shared by a number of muc system developers  appelt et al   1  ayuso et al   1   though not all  iwanska et al  1  
　another factor influencing the coreference module was the short time allotted to developing and testing this system component since coreference resolution was a late stage in processing  upstream components had to be stabilised before serious development could take place on coreference several late-stage components were being developed in parallel  so it is difficult to assess the time 
   *ln order to make things manageable for f ml annotator  the size of the texts was limited to 1kb  however the majority 
of texts in the ejv domain fall into this category 
1 	learning 
if both tokeni come from the tame trigger family then they are not coreferent if each token cornea from a different partition then they are not coreferent 
if both tokens contain a common phrase then they are coreferent 
if both tokens refer to joint ventures then they are coreferent 
i f b o t h tokens contain the same company name 
then 	they are coreferent 
if one token contains an alias of the other then they are coreferent 
if only one token refers to a joint venture then they are not coreferent 
1f 	each token contains different company names 
then 	they are not coreferent 
table 1 the muc-1 system's coreference rules 
devoted exclusively to developing the coreference module  but we estimate it was two person weeks 
　the rules used to determine whether two phrases  represented as memory tokens  were coreferent in the muc-1 system are shown in table 1 following the policy of minimising false positives  whenever none of the rules fired  the system classified the pair of tokens as not coreferent 
　the umass/hughes muc-1 ie system used a variety of mechanisms to identify phrases referring to joint ventures  the entity formed by two or more parent entities for some particular business purpose   to identify company names within a phrase  if they exist   and to determine whether one phrase was an abas  an abbrevia tion or shortened form   as well as the ability to identify trigger families1 and partitions1 in the text 
　one of the many difficulties in developing the rule set for coreference classification was in ordering the rules several different ordenngs were tested during the development period  and the order shown above was the ordering of the rule set used for final evaluation this difficulty in rule ordering was one of the motivations behind using a machine learning approach - we wanted to develop a system that could learn how to combine the positive and negative evidence 
1 	features used by r e s o l v e 
 a decision tree requires data to be represented by feature vectors  i e   vectors of attribute /value pairs for the task of coreference classification  references were paired up  and features were extracted from the pair of references as well as from the individual references themselves since this experiment involved a comparison between resolve and a manually engineered rule set  the 
 b a trigger family is a set of phrases all triggered off the same word  e g   subject and direct object joined by the same verb phrase 
　　a partition an a portion of the text that is focusing on the same main topic for the muc-1 system  distinct partitions were recognized only for texts that had bulleted items  as one might see in a news summary of the days headlines most texts thus had a single partition 

common np 
table 1 attributes and values for ejv e n t i t y instance 

features used in this experiment were based on the antecedents of the coreference rules used in the umass/ 
hughes muc-1 ie system 
   for example  table 1 shows a feature vector that represents the pairing of the phrases  familymart co   and  taiwan's largest car dealer  since the two phrases are not coreferent  this represents a negative 
instance 
   of the 1 features used in this experiment  two focus on the first reference  two focus on the second reference and four are based on the pair of references the following is a brief description of the features that focus on individual phrases  where i ♀ {1} 
  name-i does reference i contain a name1 possible values {yes  no} 
  jv child i does reference i refer to a joint venture child  i e   a company formed as the result of a tieup among two or more e n t i t i e s 1 possible values 
{yes  no  unknown} 
the last four features focus on the pair of references 
  alias does one reference contain an alias of the other  i e   does each reference contain a name and is one name a substring of the other name 1 possible values {yes  n o } 
  both jv child do both references refer to ajomt venture child 1 this feature is defined as yes when no when u n k n o w n otherwise 
  common np do the references share a common noun phrase1 some references contain non-simple noun phrases  e g   appositions and relative clauses this feature compares the simple constituent noun phrases of each reference possible values { y e s   
n o } 
  same sentence 
do the references come from the same sentence1 resolve does not use circus output  and thus has no notion of a trigger family as it was used in the 
muc-1 system  the same sentence feature is a very weak attempt to extract this sort of information possible values {yes  no} 
t
　　notc that some texts contain more than one entity for which a given name might be an abas under this definition  e g    sumitomo  is a substring of both  sumitomo corp   and  sumitomo electrical industries 
ltd    so this feature is not always a reliable indicator of 
coreference 
figure 1 a pruned c1 decision tree 
　1 feature vectors  or instances  were created from the e n t i t y references marked in the 1 texts of these  1  1%  were positiveinstances - pairs of phrases that were coreferent - and 1  1%  were negative  instances - pairs of phrases that were not coreferent figure 1 shows a pruned c1 decision tree trained on all the instances 
1 	e v a l u a t i o n m e t h o d o l o g y 
coreference is a symmetrical and transitive relation that holds among a set of two or more references  e g   if we know that a is coreferent with b  and b is coreferent with c  then there is an implicit coreference  link  between a and c* any coreference classification for two references has impbcations beyond the determination of whether that particular classification was correct or incorrect for example  if a and b are correctly classified as coreferent  but b and c are incorrectly classified as not coreferent  a system may also incorrectly conclude that a and c are not coreferent thus  simply measuring the accuracy of a coreference classifier is inadequate for evaluating how well the classifier performs its task 
   two metrics that have been used to evaluate the performance of ie systems are recall and precision  chinchor  1  1  chinchor and sundheim  1  recall is the percentage of information in a text that is correctly extracted by a system  precision is the percentage of information extracted by a system that is correct for example  if a text contains four relevant items  represented 
     as was noted earlier  some references are multtreferent  i e   they have more than one referent thus  if b is multireferent  we cannot conclude that a is coreferent with c  for example  if a = sneezy  b - the dwarfs and c = grumpy  we don't want to infer that sneezy = grumpy we can ig nore such complications in this paper since the experiments reported herein exclude multireferent phrases 
1 

by {a  b  c  d  in an answer key   and a system cor 
rectly extracts the three itema {-1  b  c} but incorrectly extracts the two additional it erne   represented by 
  in a system response   then its recall would be 1% and its precision would be 
   a function to combine recall and precision into a single measure of performance was incorporated into the fourth message understanding evaluation and confer ence  chinchor  1  the f-measure  a metric used to evaluate information retrieval  ib.  system performance  van rijsbergen  1   combines recall and precision scores into a single number using the formula 

where pis the precision score  r is the recall score and b is the relative weight given to recall over precision for example   value of 1 gives equal weight to recall and precision  a value of 1 gives recall twice the weight of precision  a value of 1 gives recall half the weight of precision 
　an evaluation methodology for the coreference task is being developed for the upcoming sixth message understanding evaluation and conference  muc-1  the metrics used for evaluating overall ie system performance are being adapted for use on this sub task  cf  burger et al  1    where the answer key for each text contains a set of phrases and the coreference links among them however  evaluation of coreference performance is com plicated by the need to take into account the implicit coreference links among phrases thus  transitive closures are taken for both the answer key  the key closure  and the system response  the response closure  recall is measured by the percentage of explicit coreference links in the key that are also found in the response closure  i e   what fraction of correct coreference links is implied by the transitive closure of the coreference links in the system response precision is measured by the percentage of explict coreference bnks in the response that are also found in the key closure  i e   what fraction of coreference links in the response is implied by the transitive closure of the coreference links in the key 
1 	results 
one experiment was run using resolve in this ex perment  for each set of instances taken from the 1 texts  one set was selected for testing purposes and the remaining sets were used to train a new decision tree this process was iterated over all 1 sets of instances the results shown in table 1 represent the average of these iterations the first row shows the recall  precision and f-measure i scores for unpruned decision trees  the second row shows the results for pruned deci sion trees 1 
　the third row in table 1 shows the results from a second experiment  in which the rule set from the coreference module of the umass/hughes muc-1 ie system 
   'default bettings for al  c1 parameters were used throughout this experiment  see  qmnlan  1   chapter 1  for more information about c1 parameters  
1 	learning 

was applied to the memory token pairs generated from the references marked using cmi 
1 	discussion 
when we first began applying decision trees to the coreference resolution problem  we were hoping to achieve performance that was comparable to the manually engineered rules we had used in muc-1 we were greatly encouraged to discover that we could achieve performance that surpassed the performance of the rules from our muc-1 system in both recall and f-measure scores 
　as was noted earber  the muc 1 coreference rules were designed to minimiie false positives the effect of this bias can be seen in the higher precision score achieved by the rule set in comparison with both the unpruned and pruned decision trees the difference in precision scores between the unpruned and pruned ver sions of the decision trees might be explained by the prevalence of negative instances  1%  in the data set  which may lead to a stronger bias to classify pairs of phrases as not coreferent in the smaller trees 
　the comparative effects of false positives and false negatives in coreference classification on overall ie sys tem performance remains an open question however  while the precision scores achieved by the decision trees and the rule-base are rather close  especially for the pruned version of the trees  there is a large difference between their recall scores until we can ascertain the relative importance of high recall vs high precision in overall ie system performance  the f-measure score that gives equal weight to recall and precision may be the best indicator of overall performance on the coreference resolution task however  as can be seen in table 1  when resolve uses pruning  its performance surpasses that of the rule set even when the recall score is given twice the weight of precision score or when the recall score is given half the weight of precision score 1 
1 	c o n c l u s i o n s 
one of the original goals of this new approach was to de velop a system that achieved good performance in resolv ing references - performance that was at least as good as the performance achieved using manually engineered 
   1  the pruned decision trees yield higher f-measure scores than the muc 1 rule set unless the recall score is given less than one third the weight of the precision icore 
rules in our muc-1 system however  as we continue to pursue this approach  we find that there is another advantage to using decision trees they allow us to focus on determining which features work well for resolving references 
　we are encouraged by the performance of the decision trees on the coreference resolution problem the fea tures we have used in the experiment descnbed above are not considered comprehensive by any means while they have proved sufficient for attaining a certain level of performance  an examination of specific errors made by lhe trees shows that additional features will be needed to attain higher levels 
   one area we will develop further is a set of features that incorporate syntactic knowledge we don't have any features that identify the various syntactic constituents of a sentence  e g   subject or direct object  nor do we have any features that identify clause boundaries  only sentence boundaries  these features will be incorporated in future experiments features based on focus of attention  sidner  1  grosz et al   1   which presuppose knowledge about syntactic constituents may also prove useful our experiment used a feature set that was largely semantic in nature it is interesting to see how well semantic features work as a basis for coreference resolution and it is not surprising to see that the  are also insufficient 
   ultimately  we hope to understand better which fea tures are important for coreference classification  across different objects and different domains such an understanding would benefit people involved with ie system development  and should be of interest to people outside the ie community as well we think that decision trees are an important tool in a systematic study of coreference resolution 
