
tree decomposition can solve weighted csp  but with a high spatial complexity. to improve its practical usage  we present function filtering  a strategy to decrease memory consumption. function filtering detects and removes some tuples that appear to be consistent but that will become inconsistent when extended to other variables. we show empirically the benefits of our approach.
1 introduction
a weigthed csp  wcsp  is defined as  x  d  c  s k   where x and d are variables and domains as in csp. c is a finite set of constraints as cost functions; f e c relates some variables var f  { til   called its scope  and assigns costs to tuples t e di such that 
1 if t is allowed
1 if t is partially allowed if t is totally forbidden
               k   o      is a valuation structure such that a b = min{k  a + = k  l = 1  larrosa  1 . we assume that the reader is familiar with assignments or value tuples ts with scope s  complete tuples  s = x   projections over s/ c s  ts and concatenation of two tuples t s   t/t   defined only if common variables coincide in their corresponding values. we assume that f ts   with var f  c s always means f  ts  var f   . a complete tuple ts is consistent if of e c f  t    k  else ts is inconsistent. a solution is a complete consistent assignment with minimum cost. finding a solution is inp-hard. with k = 1 wcsp reduces to csp.
　we define two operations on functions. projecting out a
　variable ec e var f  from f  denoted fl lc  is a new function with scope var f -ec defined as  t  = mmae-dx  f a.t  . summing two functions f and g is a new function f + g with scope var f  u var g  and yt e fitigvar f  mt/ e m % evar g  dj such that t.t/ is defined   f + g   t .t/  f  t  + g  t' . we say that function g is a lower bound of f  denoted g f  if var g  c var f  and for all possible tuples t of f  g t  f  t . a set of functions g is a lower bound of f iff  e g e g g  f. it is easy to check that for any f   f#c  is a lower bound of f  and  f#c     efef f llec  procedure d  c  k    v  e   x  u   1 for each  u  v  e e s.t. all m   i # v have arrived do
1 e  efgb f 
1 send
figure 1: the cte algofitlm.
　a tree decomposition of a wcsp  x  d  c  s k   is a triplet  t  x  u   where t =  v  e  is a tree  x and u' are labeling functions which associate with each vertex v e v two sets  x  v  c x and v v  c c such that:  i  for each function f e c  there is exactly one vertex v e v such that f e and var f  c x  v ;  zi  for each variable ec e x  the set {v e v it e x induces a connected subtree of t. the tree-width of a tree decomposition is tw 1. if  u  v  e e the separator is sep u  v x  u  n x  v   and the eliminator is sep u  v   dechter  1 .
　cluster-tree elimination  cte  is an algorithm that solves wcsp by sending messages along tree decomposition edges  dechter and pearl  1 . edge  u  v  e e has associated two cte messages v   from u to v  and u   from v to u. v  is a function computed summing all functions in v  v  with all incoming cte messages except from and projecting out variables in elim u  v . t   has scope sep u  v . the cte algorithm appears in figure 1. its complexity is time o dtw+l  and space o ds    where d is the largest domain size and s is the maximum separator size.
　mini-cluster-tree elimination  mcte r   approximates cte. if the number of variables in a cluster is high  it may be impossible to compute v  due to memory limitations. mcte r  computes a lower bound by limiting by r the arity of the functions sent in the messages. a mcte r  message  v   is a set of functions that approximate the corresponding cte message v   m u v   it is computed as v  but instead of summing all functions of set b  it computes a partition p = {bl b1  b such that the sum of the functions in every bi does not exceed arity r. the mcte r  algorithm  with time and space complexity o  u     is obtained replacing line 1 of cte by 
1 p e partitioning b  r 
1 al u. c    	  e 	v   	p
1 function filtering
a nogood is a tuple t that cannot be extended into a complete
consistent assignment. nogoods are useless for solution generation  so they can be eliminated as soon as are detected. we store function f as a set sf containing all pairs  t  f  t   with cost less than k. the size of f  denoted if i  is the number of tuples with cost less than k. computing f has time complexity o lfl . for summing f + g  we iterate over all the combinations  t  f  t   e sf and  t/   g t/   e sg and  if they match  compute  t   t/   f  t  + g t/    which has complexity o  if i ig i . efficiency of operations depends on function size. to anticipate the detection of nogoods  we propose function filtering on f from a set of functions h  noted f   as -h f  t  if  e h + f t    k
hell
	k	otherwise
tuples reaching the upper bound k are removed  which causes to reduce if i before operating with it. therefore  let f  resp. g  be a function and f  resp. g  be a lower bound. when summing f and g  if previously filtered with the lower bound of the other function  the result is preserved 

and the sum is done with functions of smaller size  so it is presumably done more efficiently. if f h  g h 
function filtering easily integrates into cte. we define a filtering tree-decomposition t  x  c'  1   where is a
set of functions associated to edge  u  v  e e with scope included in sep u  v u  v  must be a lower bound of the corresponding v   namely  u  v   the new algorithms ctef and mctef r  use a filtering tree decomposition. they are equivalent to cte and mcte r  except in that they use + u  v  for filtering functions before computing v . for ctef  we replace line 1 by 
similarly for mctef r  we replace line 1 by two lines 
1 p e partitioning b  r 
1 	u  e { efgbi f  	i be e p}
the effectiveness of the new algorithms will depend on the quality of the lower bound + u  v it is worth noting that the algorithms will be correct as long as 1  u  v is a true lower bound which can be computed using any technique. an option is to include in + u  v  all the original functions used to compute properly projected 
- {f us i f e  t  u  v   s = var
our ctef and mctef implementations use this lower bound. t  u  v  denote the nodes of the tree decomposition reachable from node v after the eliminaiton of edge  u  v . another option for ctef is to include in + u  v  a message u  from a previous execution of mcte r . applying procedure  d  c  k    v  e   x  u   for each  u  v  e e do + u  v repeat
　mctef r ; r for each  u  v  e e do + u  v  := t   until exact solution or exhausted resources
figure 1: the imcte algorithm.
this idea to mctef  we obtain a recursive algorithm which naturally produces an elegant iterative approximating method called 1mctef  figure 1 . it executes mctef r  using as lower bounds 1  u  v  the messages m rv ul computed by mctef r - 1  which  recursively  uses the messages m r 1 computed by mctef r - 1   an so on.
　state of the art cte based algorithms assume to consume all d s memory. here we show that storing only consistent tuples and applying filtering techniques we can greatly reduce memory usage. experiments focus on  i  showing that ctef uses less memory than cte to find the exact solution  and  ii  showing that mctef r   exhausts resources at a smaller arity r and finds worst lb than the iterative version imcte. we have tested cte  ctef  mctef r  and imcte on dimacs dubois max-sat instances  borchers weigthed max-sat instances and spot instances. when d s is small cte is feasible. n%en d s is large  cte is unfeasible and filtering is very useful as shown by the gain in one order of magnitude in the used memory  see the first borchers and the firsts spot instances . in unfeasible instances for both cte and ctef  imcte finds better quality lower bounds than mctef r .
