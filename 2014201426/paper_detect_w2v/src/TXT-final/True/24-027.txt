 
membership queries extended w i t h the meta query concept is proposed as a method to acquire complex classification rules. furthermore  relevent concept classes  where a small number of queries is sufficient  are characterized. in this paper we advocate and present the benefits of the use of queries in order to learn a target concept efficiently. thus providing the foundations for automating the knowledge acquisition process. based on these results  we developed a knowledge acquisition tool k a c - z which uses queries about specific domain objects. the systems usefulness has been demonstrated by its application in the domain of manufacturing  cutting  industry. 
1 	introduction 
 in building expert systems the knowledge acquisition is considered to be a bottleneck . this is due to the fact that acquiring knowledge from an expert is generally time-consuming and error-prone. thus  one is motivated to overcome this bottleneck by automating the knowledge acquisition  i.e. through building learning components for expert systems . a successful learning component in an expert system will probably have to use queries directed towards the experts. for example  sammut and banerji's system  uses membership queries about specific examples as part of its strategy for efficiently learning a target concept. let us consider the problem of using queries in order to learn an unknown concept. for this purpose angluin  suggested different types of queries. a m o n g these query types are membership queries which ask for the correct classification of a particular object. furthermore  she proved that for many concept classes an exhaustive or nearly exhaustive search is necessary when using membership queries. however  in  concept classes have been introduced where efficient learning via various queries is possible. in the present paper these concept classes are significantly extended by introducing the notion of meta queries. meta queries ask for hints how to construct complex classification rules. by the use of meta queries combined with membership queries our system is in a position to learn concept classes for which otherwise an exhaustive search would be necessary. based on this work we developed a knowledge acquisition system k a c - z which exploits the theoretical results presented in this paper. to prove the applicability of our system in the real world we describe the application of k a c - z in the domain of manufacturing industry. k a c - z will be used to acquire the knowledge of an expert which selects an appropriate cutting metal for a specific cutting process. this paper is organized as follows. in section 1 our theoretical results concerning efficient query learning are presented. section 1 describes the design of k a c - z . the final section contains the conclusion. 
1 	theoretical foundations 
we consider a set of objects x. the task of the learning system is to determine the class of each object in x  i.e. to determine for each object whether or not it belongs to the target concept. for this purpose  we assume a class of concepts c c 1x which underlies the learning system in the following sense. the learning system will classify the objects only according to one particular concept c ¡ê c. the learning system l is allowed to address membership queries to an oracle. a m e m b e r s h i p q u e r y means that l provides an arbitrary object o € x to the oracle. the answer of the oracle will be 'yes' o r 'no' depending on whether o belongs to the target concept or not. one simple but inefficient way of determining the correct class of all objects in x' via membership queries is to present the description of each object in x to the oracle. therefore  a trivial upper-bound for the required number of membership queries is  x . depending on the actual structure of the concept class c there may be clever query strategies which allow the learning system to determine the target concept with much less than  x  membership queries. this may be possible because the classification of most objects will be logically implied by the classification of some crucial objects in x. in this paper we investigate the structure of concept classes which allow the learning system to use such 
	hoffmann and thakar 	1 

clever query strategies in order to learn the target concept efficiently  i.e. with a small number of queries. the following results are also applicable in the case of lear-
allow to avoid an exhaustive search if initially k positive examples of the target concept are given to the learning system. a corresponding upper bound is given in theorem 1 in section 1. in 1 the notion of meta queries is 
formalized. 
1 	preliminaries 
 let x be a finite set of objects   be a set of concepts or a concept class. that means  c is a set of cept represented by the heavy line  smallest superconcepts of c. 
figure 1: linear threshold functions are independently monotonic 
note: this also means if i is independent in c then there exists a set of |/| objects shattered by c. the set 
s contains one appropriate object from each concept in let c be the set of linear decision 
ning multiple classes instead of learning just one class as functions. a particular linear deci-
pointed out in . in section 1 we define the property sion function can be viewed as a hy-
of a concept class being independently monotonia. this 
perplane in the n-diinensional euc-
property allows to learn a concept from c with a small 	n	1
lidean space e . in e it is a line 
number of queries. as shown in theorem 1 in section 1 
that partitions the plane into two 
by using the preceding lemma which states an imporparts. in the diagram  the positive 
tant consequence of a concept class being independently examples lie in the lower part. the 
monotonic. in section 1 we extend the definition of dotted lines indicate the only two 
being independently monotonic to the property of being minimal superconcepts of the conk-independently monotonic. concept classes of this kind 
subsets of x with 	' be an arbitrary 	/ respectively. in particular   
concept of c. 	is called a positive 
example: 
a positive  negative  example x of a concept c iff 
the vapnik-chervonenkis dimension  was introduced in the context of learning theory in . a set s c a' is said to be shattered by 
the vapnik-chervonenkis dimension of c  in short vc-dim c   is the cardinality of the greatest set s c x shattered by c. that means  the vapnik-chervonenkis dimension is given by 

in the following  a class of concept classes is specified for which the vapnik-chervonenkis dimension can be used to give an upper-bound for the required number of membership queries. then io is independent in c since for any union of sets in iq there exists a concept c e c that is disjoint with the remaining sets in io in contrast to that  the set i 1 = {{1}  {1}  {1}} is not independent in c. that is due to the fact that any concept c e c covering both sets {1} and {1} also contains the element '1'. thus  there is no concept c ¡ê c such that  {1} u {1}  c c and the remaining set {1} e  i1    {1} u {1}   contains an 
element not contained in c. 
definition 1 a concept class c is independently monotonic iff for all concepts    the set m{c  of minimal superconcepts of c in c is independent in c and the empty set is a concept in c as well. 
examples for relevant concept classes that are indepen-example of c iff x g c and a negative example of c iff  respectively. a concept c' is consistent w i t h 
definition 1 let 	  	be a concept class and c an 	dently monotonic follow: 
arbitrary concept in 	c 	  	is a m i n i m a l supercon-	let the set of objects x be the set of all attribute-value 
cept of c iff and there is no conceptbetween vectors  c and s. i.e.  there is no such t h a t s  {l ....n}. holds. 
definition 1 a set of concepts is in-   onesided conjuntive threshold functions: let c be dependent in c iff for all concepts there exists a the set of all functions / of the following kind: 
fixed object   as follows: for the union u of each subset of concepts in i there is a concept  such that c and for all c o n c e p t s c does not contain the corresponding object xj. more formally: 
for c representing the set of onesided-conjuntive threshold functions holds  
1 	learning and knowledge acquisition 

let c be the set of orthogonal rectangles. then  by c 	being 	1-independently monotonic is meant that for an arbitrary rectangle  given a point p within that rectangle we can expand or not expand it in all four directions 	independently. 
figure 1: a geometrical example for a concept class being 1-indepcndently monotonic 
  linear decision functions: let c be the set of all functions / of the following kind: 

for c representing the set of linear decision functions holds  
see figure 1. 
as the examples indicate  concept classes that do not require exhaustive searches have to be rather simple structured. that kind of being rather simple structured is reflected by the property of being independently monotonic. 
for the proof of the following lemma the next definition is still required. 
definition 1 an object o x dominates an object o 
x in c iff o is contained in all concepts of c in which o is contained. that is  iff the membership of o m the unknown target concept implies the membership of o in  

this example the object 'd' dominates the object 'e' in c. the reason for this is that all concepts in c which contain 'd' contain the object 'e' as well. on the other hand  the object 'f' does not dominate the object 'e' because there is a concept which does not contain 
'e' while it is containing 'f' 
1 	the upper-bound 
 for the following theorems the lemma below is used  which exhibits an important property of independently monotonic concept classes. 
l e m m a any independently monotonic concept class has the following property: there are vcdim c  = d disjoint subsets s 1  ... s d such that each of these subsets is linearly ordered by the dominance relation in the concept class c. furthermore  determining the objects in s1 ... ¡ê f being positive or negative examples of an unknown target concept  leaves only a single concept consistent with the classified objects in s1  ... sd. that means  c' = ct. 
proof: we prove the lemma by contradiction. 
assumption: there is a set  of more than vc-dim c  objects in x such that none of these objects is dominating another object of s in c. an ob-
ject x not dominating another object y means that x and y belong to different concepts cx and cy. i.e. x and y belong to different superconcepts of the empty set such that neither cx is a superconcept of cy nor vice versa. let be  the corresponding concepts to which the objects in s belong respectively  such that none of these concepts is a superconcept of another one. for eg being a nonminimal superconcept of a concept c means  there are concepts between c and cb in the manner 
i.e. there is a minimal su-
perconcept of c between c and c1. since the set m c  of minimal superconcepts of a concept is independent by definition  the minimal superconcept c* of c has in turn minimal superconcepts covering exactly one of the minimal superconcepts of  this property holds for all concepts between c and c1 such that it also holds for the concept  of which c1 is a minimal superconcept. if the concepts c1 ... cd+1 do not dominate each other in c and there is a concept cm e c such that  are all minimal superconcepts of  that is due to the fact that  all are superconcepts of the empty set contained in c. however  cm can be constructed by executing the following procedure using a variable 'current concept' cc: 

for i = l to d + 1 do 
while ci is not a minimal superconcept of cc do 

endwhile; 
endfor; 
after executing this procedure all superconcepts must be minimal superconcepts of cc since are not dominating each other in c  but this 
is a contradiction to the definition of c being independently monotonic. 

that situation can be illustrated in the geometrical example given in figure 1 above. in figure 1 for each dimension there exists a set o of objects along the axes a1 and a1 which are linearly ordered according to the dominance relation in c. that means  all points on the axes in the dashed area are positive examples of c while 
	hoffmann and thakar 	1 


table 1: number of required queries 
all remaining points in o are negative examples of c. 
the upper-bound theorem follows: 
theorem 1 let x be a set of objects   be an independently monotonic concept class 
	  	then there is a learning algorithm 
which learns from membership queries only that requires at most 

membership queries in order to determine the correct target concept c  c. 
proof: in the lemma it has been shown that for any independently monotonic concept class c there are at most d subsets s1 ...  sd of x where each of those subsets can be linearly ordered by the dominance relation in c. that means  for an arbitrary concept c c the first elements of a subset s  are positive while the remaining objects in si are negative examples of c. furthermore  determining the objects of these subsets to be positive or negative examples of the unknown target concept ct means  determining exactly one concept c c. in other words  there is only one concept in c consistent with the determined positive and negative examples. these subsets are linearly ordered by the dominance relation in c. therefore  a binary search procedure is executable on each of these subsets si  ... sd to find out which objects are positive examples and which ones are negative examples of ct. hence  in each of the d linearly ordered subsets s 1  ... s d of x a binary search for the most objects in si  dominating positive example p can be executed. for this binary search procedure there are at most queries necessary. thus  the greatest number of queries will be required if all d subsets have the same cardinality. therefore  an upper bound for the number of required queries is   

for illustration  theorem 1 can be applied to both of the given examples for independently monotonic concept classes: as already noted  the  for c repre-
senting either the set of linear decision functions or the set of onesided conjuntive threshold functions  is given by the length n of the attribute-value vector of the set of objects x. moreover  the size of the set x is given by jn. thus theorem 1 states the following upper bounds for the number of required membership queries. 1 learning and knowledge acquisition 
1 	providing hints 
¡¡suppose and the concept class c contains all singletons of x  i.e. all sets which cover only a single object in x. in this case  there is a worst case lower bound on the required number of membership queries of m - 1. i.e.  a  nearly  exhaustive search is necessary.  see  for proofs of lower bounds for various types of queries.  nevertheless  in certain cases the number of required membership queries can be reduced dramatically if initially the learning system is provided with one 
positive example of the target concept . think of x being the set of coordinates in a grid based plane. that is   and c being the set of all orthogonal rectangles in this grid based plane. in that case  c includes among other sets all singleton sets of x. thus  a lower bound for required membership queries is  for illustration  see figure 1. assume  one gets an arbitrary positive example p of the target concept ct and the concept class c is purged from all concepts not consistent with p. then  the remaining concept class is independently monotonic. thus  only with membership queries are necessary in order to determine the target concept ct. this observation can be generalized by characterizing the appropriate concept classes through the following definition: 
definition 1 a concept class c over a set of objects 
x is k-independently monotonic iff for all objects x x there is a concept c c covering x and and the set  of minimal superconcepts of c in c is independent in c. 
now  the next theorem can be formulated: 
theorem 1 	let x be a set of objects  
i 	be a k-independently monotonic set of concepts and 
 then  	after initially providing the lear-
ning system with k different positive examples of the target concept ct there is a learning algorithm which needs at most  membership queries in order to 
determine the correct target concept  
proof: let s =  be the set of objects given as positive examples of the concept ct. by definition of c being k-independently monotonic there is a concept c c such that c   s. let c be the remaining concept class after removing all concepts in c not covering c. thus  there is a reduced concept class c over a reduced set of objects  especially  c contains an empty set  i.e. the original concept c after removing the objects of c from x. and by definition of c being k-independently monotonic  is independently monotonic and theorem 1 can be applied to the reduced concept class c . 
d 

example: we follow figure 1  where c is the set of all orthogonal rectangles in a grid based finite plane. in the generalized case of an n-dimensional euclidean space  theorem 1 can be used to upper bound the number of membership queries required for this generalized concept class c: there is where j is the number of gridpoints along each dimension. 
then theorem 1 says that at most  -  membership queries are necessary in order to determine the target concept c c after initially getting one positive example of the target concept. 
1 	m e t a queries 
 we give just a formal and general description of our notion of meta queries. the idea is illustrated in section 1. 
definition 1 let be a concept class on x. then  a meta query is a specified subset 
the answer to the meta query is 'no' if the corrseponding reduced concept class  on xs is 1 - independently monotonic. otherwise  the answer is a set  of mutually disjoint subsets of xs- each subset in xm is required to contain at least one positive example of the target concept. 


figure 1: learning two boxes as disjuntive concept 


¡¡i.e. each supplied subset in xm either has to be 1independently monotonic or it has to have the potential to become splitted into multiple subsets - such that each subset is 1-independently monotonic. here  the user or expert is asked to provide sets of subsets in a way that the number of subsequent meta queries by the system is minimized. 
1 knowledge acquisition system kac-z 
 in this section we describe our knowledge acquisition system  kac-z  which incorporates the theoretical results described in the previous section. an application of kac-z in a real world  manufacturing industry  problem situation is being described as well. 
1 	system design 
 the goal of this system is to acquire knowledge in order to perform a classification task. for this purpose kac-z makes use of goal-directed queries. in particular  membership queries are used. as pointed out in section 1 learning disjunctive concepts usually require a vast number of membership queries. this poses a difficult problem  because no expert is ready to answer a vast number of queries. in order to overcome this problem we use in kac-z a new query type called meta queries. meta queries were used to tackle the problem of learning intervals within disjunctive classification. the problem is illustrated in figure 1. 
in the geometrical example  figure 1  the task is to learn two rectangles  assume  our positive example is table 1: equivalent disjunctive boolean functions f f1 /1 of figure 1. 
point p1- then the left boundary could easily be misjudged by the binary search. reason being that the binary search may produce a membership query for p1. the answer to that would indicate that p1 is a positive example  which would mean that the left boundary of rectangle r1 containing p1 lies at the left of p1. in fact the binary search procedure would yield to the dashed rectangle r1 as learning result. one generally cannot avoid this by using membership queries only  except one uses an exhaustive search. this leads us to the idea of using yet another type of query which we call meta query. answers to these queries determine whether there are disjunctive terms in the classification rule and whether a binary search can be applied or not. the idea of meta queries is to provide the system kac-z with the branching structure of the classification rule tree  figure 1 . consider an example with learning a disjunctive boolean function / as given in table 1. 
¡¡the boolean functions f  and f1 reflect two different tree structures even though both functions are logically equivalent. a branch in the tree represents a disjunction in the corresponding boolean functions. the terminal nodes correspond to a conjunction  eventually intervals  of the remaining attributes. for each of the intermediate nodes the expert is requested to point out the disjunctions  branching  via a corresponding meta query. as can be seen in figure 1  the tree structure depends upon 
	hoffmann and thakar 	1 

the order of disjunctions given by the expert. the system starts with a  meta query for the root node. the expert's answer has to indicate whether disjunctive expressions are involved in the function to learn. if yes  the expert has to provide an attribute along with at least two disjoint attribute value sets. the given sets are assumed to constitute a relevant and meaningful dichotomy  polychotomy . in figure 1 the attribute for the root node would be a respectively b. the attribute value sets would be '1' and '1' respectively. in going on  for each emerging node the system uses a further meta query. if the answer indicates that there is no disjunctive structure within the remaining attribute-values  then the node is a terminal node. 
¡¡we use a frame like description for the objects whose classification should be learnt as shown in section 1. i.e. slot value intervals are efficiently learnt via membership queries. in order to do that  for each interval an upper and a lower bound with the help of a binary search has to be found. for each attribute an initial value which lies within the interval is required. thus  all required initial values are supplied by an arbitrary single positive example. 
note: the case of irrelevant attributes is included simply if the whole of its value range is recognized as valid. 
1 	application 
 kac-z is intended to be used in the manufacturing industry. its goal is to acquire the knowledge for determining appropriate cutting metals for specific cutting operations. currently this job is performed by a long time experienced expert from the fixture design department. an example of a classification rule tree for our application  where the expert defines a hierarchy of the materials being used in the specific cutting process is shown in figure 1. in the example above there are nonboolean attributes. in this case similar to boolean attributes multiple-value sets as well as single-value sets can be assigned to a particular branch. 
1 conclusion 
the introduced notion of meta queries turned out to be 
1 	learning and knowledge acquisition 
figure 1: material hierarchy tree 
very valuable for acquiring complex knowledge structures. our meta queries appear to have overcome the problem of exhaustive search for learning complex concept classes via membership queries. based on our theoretical results kac-z acquires knowledge in the manufacturing domain. however  in future further types of queries will be considered in order to examine their usefulness for supporting the knowledge acquisition. 
