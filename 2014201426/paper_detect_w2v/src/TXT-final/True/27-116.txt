: agents interacting with an incompletely known dynamic world need to be able to reason about the effects of their actions  and to gain further information about that world using sensors of some sort. unfortunately  sensor information is inherently noisy  and in general serves only to increase the agent's degree of confidence in various propositions. building on a general logical theory of action formalized in the situation calculus developed by reiter and others  we propose a simple axiomatization of the effect on an agent's state of belief of taking a reading from a noisy sensor. by exploiting reiter's solution to the frame problem  we automatically obtain that these sensor actions leave the rest of the world unaffected  and further  that non-sensor actions change the state of belief of the agent in appropriate ways. 
1 	introduction 
an intelligent agent interacting with a dynamic and incompletely known world faces two special sorts of reasoning problems. first  because the world is dynamic  it will need to reason about change: how its actions and the actions of others affect the state of the world. for example  an agent will need to reason that if a fragile object is dropped then it will break  and regardless of what else happens  the object will remain broken until it is repaired. second  because the world is incompletely known  the agent will need to make do with partial descriptions of the state of the world. as a result  the agent will often need to augment what it knows by performing perceptual actions. for example  a robotic agent may not know initially how far away it is from the nearest wall  but may have a sensor that it can use to obtain information about this distance. however  because sensors are inherently noisy  it may be necessary to read this sensor  or additional sensors  a number of times to get a sufficiently reliable measurement. in this paper  we propose a representational formalism for dealing with both sorts of reasoning problems. 
　somewhat surprisingly  although the importance of dealing with dynamic and incompletely known worlds has long 
　　* the work of fahiem bacchus and hector levesque was supported in part by the canadian government through their nserc and iris programs. hector levesque is a fellow of the canadian institute for advanced research. the work of joseph halpern supported in part by the air force office of scientific research  afsc   under contract f1-c-1. 
been argued within ai  very few adequate representation formalisms have emerged. we can classify existing ones into two broad camps. on the one hand  we have probabilistic formalisms such as bayesian nets  pea1  for dealing with uncertainty in general  and the uncertainty that would arise from noisy sensors in particular. however  with the exception notcu below  these probabilistic formalisms have not attempted to incorporate a general model of action  i.e.  representing what does and does not change as the result of performing an action. in addition  while it is possible to express in these formalisms probabilistic dependencies among vari-
ables  which are in essence atomic propositions  it is not easy to deal with many other forms of incomplete knowledge about the state of the world. for example  it is difficult to say that one of two conditions holds  or that all objects of a certain type have a certain property when it is not known what those ob-
jects are. logical formalisms  on the other hand  with features like disjunction and quantification  are well suited for expressing incomplete knowledge of this type. moreover  logical formalisms like dynamic logics  process logics  or the situation calculus  allow us to reason about the prerequisites and effects of actions. however  none of these logical formalisms allow us to represent what an agent would need to know about sensors  and how the beliefs of the agent should evolve as the result oftaking multiple sensor readings. furthermore  although it is becoming clear that it is possible to combine reasoning from both the probabilistic and logical camps within a single framework  bac1  hal1j  actions have not yet been incorporated into this framework. 
　thus it appenrs that as yet there is no representational formalism that would allow us to reason in a general way about both ordinary actions that change the world as well as perceptual actions involving noisy sensors. an exception to this is the action network formalism lgd1 . action networks extend bayesian nets to allow probabilistic reasoning about action and observation sequences and their effects. however  like bayesian nets  they have difficulties in dealing with features like disjunction and quantification. 
　in this paper  we propose another formalism for reasoning about actions including sensor-based perceptual ones. rather than building on bayesian nets and this form of probabilistic reasoning  our solution builds on a logical formalism for reasoning about action. specifically  we use a variant of the situa-
	bacchus  halpern  and levesque 	1 
tion calculus  mh1  that incorporates a solution to the frame problem proposed by reiter  rei1   for reasoning about action  and has been augmented to include perceptual actions by scherl and levesque  sl1 . 
　there are several reasons for going this way. first of all  our solution ends up being remarkably simple: all we need to do is to extend the scherl and levesque work to ground perceptual actions on noisy sensors. we then preserve the ability to express incomplete knowledge about the state of the world  as well as inheriting the solution to the frame problem for reasoning about both ordinary and perceptual actions. as we shall show  the resulting formalism also allows certain forms of probabilistic reasoning to emerge as logical consequences. 
   compared to other logics of action  the situation calculus itself has proved to be a very convenient formalism for modeling actions  their prerequisites  and effects. although renter's solution to the frame problem is limited in a number of ways  it has been extended to handle aspects of the ramification problem  lr1   agent ability  llls1   and continuous time  pin1 . another extension of the theory to deal with complex actions  sequence  iterations  concurrency  nondeterminism  etc.   briefly described in section 1  has led to a novel logic programming language called golog. g o l o g has proven to be useful for describing high-level robot and softbot control  llr1l an implementation of golog exists at the university of toronto  and a number of small sample 
programs  including an elevator controller and a mail delivery robot  currently run in simulation mode. by casting our work within this framework we hope to take advantage of these parallel developments. 
   the format of the rest of the paper is as follows. in the next section  we briefly review the theory of action in terms of which our account is formulated: the situation calculus  the solution to the frame problem proposed by reiter  and the extension  proposed by scherl and levesque  for dealing with knowledge. in section 1  we consider how knowledge is affected by readings from noisy sensors. in section 1  we augment the framework with probabilities  and present a simple formalization within the situation calculus of the degree of belief an agent has in propositions expressed as logical formulas. this allows us to formalize in more quantitative terms the changes in belief that arise from readings of noisy sensors. examples of the formalism at work are presented in section 1  and some conclusions are drawn in section 1. 
1 	a theory of action 
our account of sensors is formulated as a logical theory t in an extended version of the situation calculus  mh1 . the situation calculus is a many-sorted dialect of the predicate calculus  containing sorts for  among other things  situations  which are like the possible worlds of modal logic  for primitive deterministic actions  and  since we will be dealing with probabilities  for real numbers. we assume the reader is familiar with the basic intuitions underlying the situation calculus; we briefly review the main ideas here. 
1 	temporal reasoning 
1 	the situation calculus and the frame problem 
in this formalism  the world is taken to be in a certain state  or situation . changes to the world arise only as the result of actions. this is modeled by having actions map situations to new situations using a special binary function symbol do. this function maps action-situation pairs to new situations  i.e.  s' = do a  s  means that s' is the new situation that is the outcome of performing a in situation s. predicates and functions whose values vary from situation to situation are called 
fluents and  by convention  take a situation as their last argument. we read  e.g.  p x  s  as  x has property p in situation 
　the background theory t will contain axioms for the usual arithmetic operations on the real numbers  unique name axioms for actions  and various other foundational axioms for the situation calculus that need not concern us here. the domain-dependent part of t consists of axioms characterizing the initial state of the world so  and the following: for every action type a  a precondition axiom of the form 

where s is the only situation term mentioned in the formula i for every fluent p  a successor-state axiom of the form 

where s is the only situation term mentioned in the formula 

　for example  the precondition axiom for the drop action might assert that it is possible for the agent to drop an object x in situation s iff the agent is holding x in a: 
. for the fluent broken  
a successor-state axiom might assert that x is broken after the action a iff x was fragile and the agent dropped it  or x was broken and the agent did not repair it: 
　these axioms incorporate a treatment of the classic frame problem  mh1  proposed by reiter  rei1   extending previous proposals by pednault  ped1   schubert  sch1  and haas  haa1 . in particular  reiter shows how the successorstate axioms above can be automatically generated from a collection of simple effect axioms describing only the changes that result from performing an action. frame axioms need not be enumerated since they are entailments of the successorstate axioms.1 
　reiter's solution to the frame problem applies only to primitivedeterministicactions. however  levesqueetal.  llr1 show how  as in dynamic logic  har1   primitive actions can 
   1  of course  in a modal logic  the possible worlds are not part ot the syntax  and we would write s 
   1 this is the axiom for predicate fluents; the axiom for functional fluents would be analogous. 
   1 reiter's solution ignores the ramification problem; a treatment compatible with the approach has been proposed by lin and reiter  lr1 . 

be composed in various ways to generate an expressive class of complex actions. specifically  they show that there is a situation calculus formula  which we abbreviate by do a s  s'   that expresses the proposition that s' is one of the possible outcomes of doing complex action a starting in situation s. here we only need one type of complex action: the nondeterministic choice of an action from a parameterized family of actions. let a x  be a family of primitive actions parameterized by x. 
for example  a might be the action  approach the wall  and x might be a numeric parameter specifying the distance to be moved. the complex action  nx .a} can be read as  perform primitive action a x  for some nondeterministically selected value of x   and it is defined as follows: 
note that since complex actions ultimately reduce to primitive ones  their preconditions  effects and non-effects are  utomatically entailed. 
1 	knowledge and action 
scherl and levesque  sl1  provide another extension to reiter's basic approach by incorporating an epistemic state for the agent. to characterize this epistemic state in the language of the situation calculus  they follow moore  moo1  and introduce a new binary fluent a'. the a fluent acts as a binary relation on situations  just like the accessibility relation between possible worlds in modal logics. intuitively  a  s'  s  holds if in situation s  the agent considers the situation s' to be possible. as in modal logic  knowledge is defined as truth in all accessible situations. and wc define the following abbreviation: 

where we assume that the situation argument has been removed from the fluents in is the result of introducing s* as a new situation argument. thus  for example  know - bm n i   s  is an abbreviation for  broken x s' . for simplicity  we take a to be transitive and euclidean  which ensures that the agent always knows whether or not it knows something  i.e.  the agent has the power of positive and negative introspection . 
　in scherl and levesque's treatment many actions affect knowledge in a particularly simple way: the agent knows that the action has been performed and thus comes to know that the action's preconditions must have held prior to its execution. actions such as drop and repair are examples of such actions  which we call ordinary actions. ordinary actions have a uniform effect on knowledge  and this effect can be captured by a single clause appearing in a s successor state axiom. some actions  however  have effects on the agent's knowledge that go beyond simple awareness of their execution  and we call such actions knowledge-producing actions. for example  the agent might have available an action exactread  whose effect is to change the agent's knowledge state so that it comes to know the exact distance to the wall in front of it. 
for each knowledge-producing action we must have a clause in a s successor state axiom that characterizes its effect on the agent's knowledge. for example  if exactread is the only knowledge-producing action  we end up with the following successor-state axiom for a: 
 1  
after doing exactread  the agent knows the distance to the wall. to see this  consider the situations that are a'-related to do  exactread  s   the successor of s. all such situations s' have the property that they are the successor states of some other situation s  in which the distance to the wall is the same as it is in s. since  exactread does not change the distance to the wall  the successor-state axiom for alldist ensures that 
    	. hence  all of the situations a'-
related to   exactread  s  have the same value for this fluent  and our observation follows. 
1 	sensors and noise 
one problem with the scherl and levesque account is that it is unrealistic to assume that an agent has available an exactread action that allows it to learn the exact distance to the wall. a more realistic assumption is that the agent is in possession of a number of sensors  that give it some information about  but not exact knowledge of  various fluents. we expect a sensor reading to be correlated with  but not a deterministic function of  the quantity being measured. for example  we might imagine that there is a sonar sensor that can be used to mea-
sure the distance to the nearest wall. there might also be a laser range finder used to measure the distance to the wall  but it might be correlated with the actual distance in a different way. 
　there are various ways of modeling this. we present one here  motivated by our desire to have the basic actions be deterministic  and thus preserve the simple solution to the frame problem . assume we have an action of the form observe x   that occurs whenever the agent observes reading x on the sonar. if we assume that the sonar reading is always within b units of the true distance to the wall  rather than being equal to the distance to the wall  as in the previous example   then we get the following precondition axiom:1 

if wc now assume  as did scherl and levesque  that an agent learns that an action is possible by successfully performing it  it will follow that after an observe action  the agent will 
　　1  this particular precondition axiom only mentions the error bound  but other conditions can be included here as well. 
	bacchus  halpern  and levesque 	1 

learn the distance to the wall to within 1 units. in other words  the scherl and levesque successor-state axiom for k from the previous section entails poss observe x   s  1 know  walldist - x    b do observe x  s    by an argument analogous to the one for exactread  but now using the poss predicate. in this case  with a precondition axiom as above  it is not necessary to treat observe  or similar observation actions from other sensors  any differently from ordinary actions such as drop and repair. 
   of course it is somewhat odd to say that the agent performs an action such as observe 1   as if it had the choice of performing  say  observe 1  instead. what we would prefer to say is that the agent decides to read the sonar  and that what happens is that 1 is observed. 
　this can be modeled by using a nondeterministic composition of the primitiveobserve x  actions. we define a complex action read as follows: 

given the abbreviation do defined above  this means that 

using the successor-state axiom for a'  we get the following: 

so reading the sonar in s entails getting to a state where the agent has observed a  non-deterministically selected  consistent sonar value x. moreover  the agent knows in that state an appropriate bound on the true distance to the wall. it is easy to check that doing several consecutive sonar readings can increase the agent's knowledge about the true distance to the wall  i.e.  tighten the interval that the agent knows contains the true distance to the wall  and never decrease it. similar considerations apply to other sensors whose read actions would be defined analogously. 
1 probability 
suppose we have a sensor with an error bound of 1 = 1  and we make a number of readings of a particular fluent using the sensor  all of which are clustered around the value 1. for concreteness  suppose they are all between 1 and 1. as far as knowledge goes  all the agent will be able to conclude is that he knows the fluent to have a value in the range  1 1 . getting numerous readings of 1 will not change this knowledge. yet  even if the agent is using a cheap sensor  we might hope that getting such readings would increase the agent's degree of belief that the true value of the fluent is very close to 1. 
　to formalize these intuitions  we introduce a probability distribution over the agent's set of a'-related states. in particular  we associate with each situation in this set a relative weight. intuitively  the relative weight measures the degree to which the agent believes that situation to in fact be the real situation. however  it is convenient to avoid forcing this weight to be a probability; instead we only require that these weights be non-negative and that their sum over all of the k-related states be finite. to obtain a true probability  we will simply normalize these weights so that they do in fact sum to 1. 
   syntactically  we introduce a new functional fluent p s'  s  whose value is the weight the agent assigns to situation s' when it is in situation s. this weight is unnormalized  and we introduce an abbreviation bel  to refer to the agent's probabilistic degrees of belief. specifically   is a number from 1 to 1 that is intended to stand for the agent's degree of belief in the assertion expressed by   when it is in situation s. as with know  the first argument to b e l will be a formula containing fluents that are missing a situation argument  and we use the notation as before for the formula that results when sf is introduced as the new situation argument. informally  bel  will be defined to be the sum of the p weights of the accessible situations where holds  divided by the sum of the p weights of all accessible situations: 

these summations can be formalized within the situation calculus. in conjunction with equation 1 below  the logical consequence of this formalization is that bel is a probability distribution. the details of this development will be provided in a later full report on this work. for now  what matters is that we have something of the form 

and that bel ＊  s  is a probability distribution over the situations a'-related to s. 
　to ensure that bel is in fact a probability requires a constraint on the values of p in the initial state so- the following constraint must be added to the background theory t: 
		 1  
　since p is a fluent  we need to say how it is affected by actions. as with our treatment of every other fluent  we want to develop a successor-state axiom for p. many actions will have only an indirect effect on the agent's beliefs; the agent will only come to know that the action was successfully performed and this will affect its beliefs about the fluents changed by the action. for such actions  we want 

this simply projects the relative degree of belief in s  to its successor s'. 
　notice that in making the projection we are transferring the agent's beliefs to situations with different properties.  this is 
1 	temporal reasoning 	we continue to use such abbreviations below. 1
related to lewis's notion of imaging  lew1 .  in these new situations  all of the changes due to action a have occurred. for example  say that approachw x  is the action  move precisely x units towards the wall . in this case  the above equation will imply 

thus  if the agent believed it highly likely that she was 1 units from the wall in situation s  then she would believe it just as likely that she was 1 units from the wall after moving towards the wall 1 unit. 
　things are a little more complicated when we have to deal with primitive actions like observe x . as we mentioned before  we do not really think of this as an action that the agent performs; the agent is actually performing the read action. although we have modeled read as a nondeterministic choice among observe x  actions  it is actually better thought of as a probabilistic choice. moreover  the probability of getting x as the reading depends on the situation and the accuracy of the sensor. in the simplest case  we would expect that in situation s  the smaller  walldist s -x  is  the greater the probability of observe x ; the exact distribution  however  will depend on the sensor. 
　to make this precise  we propose that for every sensor i  there is a likelihood function li -  where l i x s  denotes the probability of obtaining a reading of x from sensor i in situation s. different applications will want to characterize these likelihood functions values differently  dependent on how complicated a model of sensor error is desired; here we simply assume that for each sensor i  the background theory t contains a sensor noise axiom characterizing each likelihood function  having the form 

where t  x  s  is a term whose value is always between 1 and 1  and is equal to 1 when x exceeds the error bounds of the sensor  if there are any error bounds . 
　for example  we might want to say that the likelihood of getting a sonar reading of x depends only on the difference between x and the current walldist  and that this difference  i.e.  the sonar's noise  is normally distributed with mean 1 and standard deviation . in this case  we would have an axiom of the form 

where normal z  is a  discrete version of  the normal density function with mean 1 and standard deviation 1. this function could be defined in t by a simple table of values.1 
　given such a function  for a situation s' = do{observe{x   s   accessible from do observe x   s   we want to weigh the 
1
　　here we are using the standard transformation: normal{{z + m / 1  is the density function of a normal distribution with mean m and standard deviation a. 

　this completes our formal characterization of adding probability to the situation calculus. so apart from the abbreviations noted above  we have exactly 1 situation calculus axioms: the scherl and levesque successor-state axiom for k  a constraint on p in the initial state  and a successor-state axiom for p. 
1 	properties of the formalization 
our formalization of noisy sensors in the situation calculus is extremely simple. we have modeled the agent reading its sensors as the execution of read  a nondeterministic choice among observe x  actions. it would seem to be more appropriate to model read as a probabilistic action  since in each situation the probability of observe x  varies with x. probabilistic actions have been explored in other works  e.g.  the approach of halpern and tuttle  ht1 . nevertheless  although we did not model read as a probabilistic action  the varying probabilities of its different nondeterministic outcomes are captured in ou- model. this is accomplished by the likelihood functions used in our definition of the successor-state axiom for p. in fact  we can show an exact correspondence between the probabilities over situations generated by our approach and those that would be generated by a probabilistic read action using the framework of halpern and tuttle iht1 . furthermos  as we show below  our formalism has a number of other appealing properties. 
observations. in our framework  it can be shown that the agent updates its beliefs after making an observation via standard bayesian conditioning. first consider the standard bayesian model of sensors. 
　the standard model assumes two pieces of probabilistic information: a prior distribution pr t  on the value t being 
	bacchus  halpern  and levesque 	1 


1 	temporal reasoning 

value 1. in the new situation s1 = do  observe ll   s1   a simple calculation using equation 1 shows how the agent's beliefs have been altered. the new distribution is shown in the figure. since the sonar has probability zero in being more than 1 unit away from the true value  the agent now has zero degree of belief in the values 1 and 1 
   note that figure 1 shows that the agent still believes that walldist = 1 is the most likely value  even though its sonar returned the value 1. this arises from the agent's high prior belief in walldist - 1 
　sequences of sensor readings of the same fluent  including sequences of readings from different sensors  are also handled correctly in our framework. such sequences correspond to sequences of sensing actions  and thus are handled by a simple iteration of eq. 1. the independence of a sensor reading from all of the previous readings is implied by assumption / and by the fact that the sensors do not change the value being observed  this is captured in the successor-state axiom for the sensed fluent . as a result  after a sequence of sensing actions  the agent will come to have greater or less certainty about the value of the sensed fluent  dependent on whether or not the se-
quence of readings agree or not. 
example 1: suppose that the agent executes another read action in the state s . further  suppose that the agent observes the same value as before 1  and let s1 = do observe ll   s  . then  another application of eq. 1  applied to the agent's beliefs in s'i   yields the belief distribution shown in figure 1. that is  the agent's beliefs have converged more tightly around the value 1  since it has now sensed that value twice. | 
　this example of sensor fusion is simplified by the discrete nature of the agent's initial beliefs and likelihood function. nevertheless  more practical models are easily accommodated. for example  if the agent's initial beliefs about walldist are characterized by a gaussian  and the sensor yields a linear transform of walldist plus some gaussian noise factor  then the agent's beliefs about walldist after doing some sequence of observations will continue to be characterized by a gaussian. furthermore  the mean and variance of this gaussian can easily be computed.1 
actions. as mentioned briefly in the previous section  the manner in which probability mass is transferred when ordinary actions like approachw also yields appropriate changes to the agent's beliefs. 
example 1: suppose that the agent is in state s1  and then moves exactly 1 units closer to the wall. let s1 = 
   1 if the agent knows these error bounds  i.e.  if these bounds arc part of the preconditions for the sonar  it will come to know that walldist is in the range 1. on the other hand  if the agent only has zero degree of belief in these outcomes  it will come to believe with degree 1 that walldist is in that range. that is  our framework can distinguish between full belief and knowledge. 
   1 this corresponds to a trivial case of kalman filtering  where the value being sensed is static  dw1  . 
do approachw 1  1 . then  the successor-state axiom for p and walldist imply that the agent's beliefs are shifted to worlds in which it is 1 units closer to the wall. hence  for all y  bel{walldist - y - 1 s1  = bel walldist = y}s1 . the agent's shifted beliefs are shown in figure 1. this is exactly how one would expect the agent's beliefs to change after moving closer to the wall. i 
　furthermore  changes in the agent's beliefs due to ordinary actions integrate correctly with sensing actions. 
example 1: 	suppose that the agent again executes a read action in s1 and observes the value 1. 	let sa 	= 
do observe 1   s1 . this reading is consistent with its previous readings of 1 since the agent has moved 1 units closer to the wall. hence  as shown in figure 1  it results in a further tightening of the agent's beliefs  around the value 1. if the agent subsequently moves back from the wall by 1 units  executing an approachw -1  action  so that s1 =   approachw -1  1    its beliefs will then be clustered around 1  as shown on the figure. 
　intuitively  since the agent's approachw action incurs no error  we would expect that if the agent had sensed the value 1 in situation s1. then its beliefs about the distance to the wall should not change after moving forwards and backwards an equal distance. our model respects this intuition  as indicated in the figure by the diagonal arrow from 1 to ss. ＊ 
　finally  we can observe that if the agent executes an action that has no effect on a particular fluent  then that action will cause no change in the agent's beliefs about that fluent. for example  if the agent executes a drop action that has no effect on its distance to the wall  it will have exactly the same beliefs about the distance to the wall in the successor state. this again arises from the direct transfer of probability mass to the successor states  all of which have exactly the same distance to the wall as before. 
1 	conclusion 
we have demonstrated that noisy perception can be modeled in the situation calculus by a simple extension of previous work. although the resulting formalism is limited in some ways  e.g.  currently we do not handle noisy effectors  it does succeed in providing an interesting integration of noisy perception and ordinary actions. in particular  from the successor state axiom for p  eq. 1  and a constraint on its values in so  eq. 1  we obtain as consequences what many have argued to be the natural models for belief update from perception  baye ian conditioning  and from actions  a form of lewis's imaging   pea1 . most importantly  our formalism succeeds in capturing some key features of the interaction between these two models for belief change. 
　much of our approach can be exported to alternate formalisms. for example  instead of the situation calculus a modal logic could have been used. similarly  the probabilistic component could be replaced with an alternate formalism  like dempster-shafer belief functions  sha1  or possibility measures  dp1 . all that would be required is to replace the 
	bacchus  halpern  and levesque 	1 

functional fluent p and axioms for bel with fluents and axioms to support an alternate measure of belief. the likelihood functions could then be replaced with non-probabilistic functions to support an alternate rule of belief update. 
　as for future work  apart from addressing limitations of the formalism  there is its application in high-level agent control. in the golog work mentioned in the introduction  the ability of an agent to execute a program depends on what it knows about the truth value of the test conditions in that program  llls1 . when an agent only has a degree of belief in the truth of a test condition in a program  it is much less clear what it ought to do. a suitable programming formalism in this case remains to be developed. 
