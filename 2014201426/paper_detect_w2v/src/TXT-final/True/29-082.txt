 
in the dynamical systems approach to robot path planning both sensed and remembered information contribute to shape a nonlinear vector field that governs the behavior of an autonomous agent. such systems perform well with partial knowledge of the environment and in dynamically changing environments. nevertheless  it is a local heuristic approach to path planning  and it is not guaranteed to find existing paths. we describe a method of adjusting the spatial resolution of the planner using a dynamical system that operates at a faster time scale than the planning dynamics. this improves the system's ability to utilize both sensed and remembered information  and to solve a larger range of problems without resorting to global path planning. 
	1 	introduction 
many approaches to path planning assume lobal knowledge of the environment  e.g. 

ilatombe  1; khatib  1; connolly and grupen  1  . global algorithms can guarantee solutions to path planning problems  i.e. they can guarantee that the agent will find a path to the target if one exists. they can also find paths that meet optimality conditions such as shortest path length  minimum energy consumption  and so forth. in many interesting situations  however  environment knowledge may be unavailable or incomplete  lumelsky and stepanov  1; rimon and koditschek  1 . 
for example  knowledge of the environment may 
   *this work was in part supported by: nsf grants iri1 and sbr1  as well as 
army grant daah1-1 and arpa grant 
n1-j-1. it was carried out during a 1 month visit to the grasp laboratory by the second author. 
1 	robotics 
need to be updated by the agent as task execution proceeds. dynamic environments also violate the assumptions of global path planning. when targets and obstacles move freely about the world  global representations can quickly become obsolete. 
　in contrast to global approaches  behaviorbased systems react to sensory input with minimal internal representation of the environment  e.g.  brooks  1  . systems are designed in terms of elementary actions  or behaviors  and sensory information feeds into movement control at a low level of processing in a way that is specific to each behavior. purely reactive systems are not  however  able to guarantee the existence of path planning solutions. thus  for navigation in cluttered environments  there remains a need for representation  where actions are determined not only based on immediate sensor readings  but also based on an internal model of the environment. 
　the dynamical systems approach strikes an interesting balance between the extremes of global path planning and purely reactive systems. the dynamic approach shares with behavior-based approaches the ability to control actions based upon sensory input. in addition  this formalization includes the ability to build internal representations of the environment  engels and schoner  1 . a memory representation makes information available so that the system can act on knowledge about the environment that is not currently registered by the system's sensors. behavioral information  as derived from both sensed and remembered information  shapes a vector field that controls the behavior of an autonomous agent. as a result  such systems perform well without prior global knowledge of the environment and in dynamic environments. 
　it is important to point out  however  that dynamic planning represents a local approach. although the existence of a partial environment map will allow such a system to outperform a purely reactive system  in complex environments the dynamic approach will fail to find existing solutions to path planning problems. it is these 

figure 1 the dynamical systems approach to path planning. 
situations that we investigate in this paper. in many of these situations the system can fail because it does not make use of its environment model in an appropriate way. we propose a method for improving the system's ability to utilize its environment model  thus solving a larger range of problems without resorting to global path planning. 
1 	the dynamical systems 
approach to path planning 
in the dynamic approach behavior is described in terms of a set of variables that define behavioral dimensions. for the task of autonomous robot navigation one may represent the behavior of the agent using heading direction   and velocity  v  schoner and dose  1 . task constraints are expressed as points or parameterized sets of points in the space spanned by the behavioral variables. for example  in the navigation task  the heading direction  represents the direction to the target location  while the direction  represents the direction to an obstacle  as illustrated in figure 1. 
　the behavior of the agent is modeled as a time course of the behavioral variables generated by a behavioral dynamics that incorporates both planning and control knowledge. in this paper  we focus on a single behavioral dimension  heading direction. we assume that velocity is controlled by a dynamics similar to that described by  neven and schoner  in press . for our onedimensional system  the dynamics take the following form. 
		 1  
task constraints define contributions to the vector field  by modeling desired behaviors as attractors and to-be-avoided behaviors as repellors of the behavioral dynamics. the contributions of individual task constraints are combined 
 1  
because certain constraints are modeled as repellors  the planning dynamics is augmented by a stochastic term that guarantees escape from unstable fixed points  repellors . for the specific functional forms corresponding to task constraint contributions  see {schoner and dose  1 . 
　to deal with spurious attractors as well as to incorporate additional task constraints   large et a/.  1  further modified the strength of 
each contribution with a specific weight  wi assigned to each type of task constraint. weights are assigned through a competitive dynamics that determines the strength of each contribution depending upon the current situation. 
  1  
the state space of this dynamical system corresponds to the set of task constraints. the parameters   are referred to as competitive advantage and competitive interaction  respectively. the task dynamics operates at a faster time scale than the planning dynamics. it models decision-making regarding which task constraints are applicable at a given time  and allows the system to generate sequences of behaviors. 
1 	multiple obstacles 
according to this approach  avoidance of a single obstacle is modeled by adding a range-limited repellor to the vector field  see figure 1   while avoidance of multiple obstacles is modeled by summing multiple range-limited repellor contributions. 
		 1  
here  r1bs is a function that sets up a range limited repellor in the direction of obstacle i  and the exponential term scales the strength of the obstacle's contribution to the vector field. the parameters of the scaling term are the distance from the agent to the obstacle    center to center   the radius of the obstacle  ri  and the radius of the agent  the parameter d determines the distance at which the agent begins to take an obstacle into account  and is set to a constant value  d = do- obstacles that are very far from the agent do not affect the behavioral dynamics  whereas nearby obstacles affect the planning dynamics strongly. thus  d 
large  christensen  & bajcsy 

figure 1 integration of multiple obstacles in the vector field. 
determines the spatial resolution of the planning dynamics. 
　this strategy works because linearly dependent contributions lead  through superposition  to averaging among corresponding constraints  while linearly independent contributions allow for the expression of constraints that are incompatible  contradictory  or independently valid. consider the two situations depicted in figure 1. in the left panel  the agent faces a pair of obstacles that are positioned too closely together for the agent to pass between them. the constraints represented by the two obstacles lead to a single repellor in the vector field at their average location: behaviorally a single obstacle. in the right panel  the agent again faces two obstacles  but this time they are positioned far enough apart for the agent to pass between. these two constraints are independently valid  and an attractor is formed in the vector field  corresponding to the behavior of steering between the two obstacles. 
	1 	environment maps 
memory can be implemented using an amaritype neural field architecture  amari  1   with the general purpose of cleaning up noisy perceptual information so that separate contributions to the behavioral dynamics are guaranteed to have desired properties  engels and schoner  1; schoner et a/.  1 . a second function of the neural field is that it enables the system to store information about its environment in the form of a  cognitive map . as the system explores its environment  it is able to add to its knowledge. sensed and remembered information are integrated into the vector field so that the system can make use of environmental information even when it is not being directly sensed. for the purposes of this study  it is not 
1 	robotics 
necessary to consider the dynamics of the the amah field  but simply to assume that information about the environment is represented as a non-overlapping grid of spatial locations. 
1 	when local planning fails: 
problem and approach 
many path planning situations are well handled by the dynamic approach as described above. consider the case depicted in figure 1  top   for example. the agent begins to move toward the target  but encounters a wall. it veers to the left  turns around  finds a doorway  and continues toward the target. a more difficult situation arises  however  when the doorway is removed  as shown in figure 1  middle . in this case the agent veers to the left  encounters the left wall and turns around. if the doorway were there  the agent would find it and successfully make its way toward the target location. in this case  however  the simple local strategy embodied in the planning dynamics fails  and the agent loops indefinitely. the reason is that do. the parameter that specifies the spatial scale at which planning occurs  is a small constant.1 thus the agent only takes into account a few obstacles at any given time. by the time it encounters the wall to the right  the agent has forgotten the wall to the left  causing the cycling behavior. 
   one possible approach to this problem is to allow the planner to take all three walls into account simultaneously by increasing the spatial scale  d. figure 1  bottom  shows the behavior in this situation. as expected  the agent avoids the configuration and successfully reaches the target. this example also shows the difficulty with this approach. the agent was unable to find the more efficient path through the door. this is because increasing the spatial scale decreases spatial resolution. 
　our approach will be to dynamically adapt spatial resolution in a way that is appropriate to the agent's current environment. to do this  we must solve two problems. the first involves detecting when the agent should plan at a larger spatial scale. the second involves changing scales in a stable fashion  so that efficient planning is achieved. the following sections address these issues. 
1 	the homeward component 
we detect cycling behavior by computing an instantaneous estimate of homing behavior  
 1  
   *in these examples the spatial scale  do  was set to two meters  roughly corresponding to the visual capabilities of the actual robots in our laboratory. for comparison  the radius of individual obstacles in figure 1 is one meter. 




figure 1 the effect of spatial resolution on planning dynamics. top: planning at a relatively small spatial scale  the agent arrives at its target. middle: the agent gets stuck in a behavioral loop when the doorway is removed. bottom: planning on a larger spatial scale  the agent avoids the entire configuration of obstacles  missing the more efficient path through the doorway. 
where v in the current velocity of the agent  vmar represents the agent's maximum velocity  is the agent's current heading  and  is the heading direction of the current target. when the agent is heading toward the target at maximum velocity  h = 1  when the agent is heading away from the target at maximum velocity  h - - 1  when the agent has zero velocity  h = 1  and so forth. we call this measure the homeward component  because of its close relationship with a circular statistic of the same name  batschelet  1 . 
　next we smooth h using a simple linear dynamics to obtain a time-averaged estimate of horning behavior. 
		 1  
here the xi represent estimates of horning behavior at several different time scales. the  determine the time scales over which the point estimates are smoothed. when the agent enters a looping behavior the smoothed homeward components  xi  will approach values of zero with time constants determined by the  figures 1  top  and  bottom  show instantaneous and smoothed homeward components for the situations of figures 1  top  and  middle   respectively. in each figure  we show smoothing at three different time scales   note that in the top panel the smoothed homeward components retain relatively large values  indicating good homing behavior  while in the bottom panel each approaches zero  indicating that the agent is not  making good progress toward the target. 
1 	planning on multiple spatial scales 
next  we address the question of how to adaptively change spatial resolution so that the planning dynamics will take into account information that is appropriate to its current environment. for reasons discussed below  we assume that several discrete levels of spatial resolution are required  and that at any given time the agent is to plan at a single level. 
　we achieve this end by utilizing the competitive dynamics introduced above in conjunction with constraint competition. in this case however  we reinterpret the meaning of the variables   1  
       indicates activation of planning level i. for a local stability analysis of the competitive dynamics  see  large et a/.  1 . in order instantiate the proper switching behavior  we define the competitive advantage   and competitive interaction   parameters in such a way 
large  christensem & bajcsy 



figure 1 top: the homeward component  h  


figure 1 an agent escaping from an enclosure using multiple planning levels. initially planning at level zero  the agent explores the enclosure. after making poor progress toward the target  the planning level jumps to level one  then level two before the agent escapes. 

and smoothed homeward components  x   for the situation shown in figure 1  top . bottom; the homeward components for the situation shown in figure 1  middle . the smoothed values approach zero  reflecting the agent's cycling behavior. 
that either exactly one planning level is active  or no planning levels are active  i.e.  planning is at the base level . we do this by defining the parameters as follows. 
 1  
1  
　here  a thresh is a threshold level for the activation of a planning level. with these parameter definitions  the spatial scale dynamics has exactly n + 1 fixed points  where n in the number of planning levels. this system is stable when exactly one planning- level is active or when no planning 
intuitively  the 
competition between planning levels works as follows. when planning level i attempts to activate itself. the enforce competition among planning levels such that if two levels request activation  the level representing the larger spatial resolution will win. we can then define spatial scale  used in equation 1  as: 
		 1  
1 	robotics 

   first  we examine the example of figure 1  in which the agent is enclosed by walls on three sides  figure 1 . initially the spatial resolution of the planning dynamics is set to the base level  d = do. upon encountering the long wall  the agent turns left. at the left wall the planning dynamics causes the agent to turn around. at about this point  x1 falls below threshold  and planning level one is activated  marked in the figure   so d = do + d . about half way to the right wall  planning level two is activated  disabling planning level 1. once this occurs  the entire enclosure is represented in the planning dynamics simultaneously  and the agent escapes from the enclosure. as the smoothed homeward components increase above threshold  planning returns to the base level. 
　the second example shows a more difficult situation  a circular room with the only exit opposite the target. at first the agent moves toward the the target  and as it explores the space  planning levels one  and two are activated  figure 1 . once level two is activated a single attractor is formed in the planning dynamics  corresponding to the exit. the agent makes its way through the door  and eventually to the target. 
1 	discussion 
we have described how to incorporate the notion of planning at multiple spatial scales into a system that plans paths through a two dimen-


figure 1 an agent escaping from a more difficult trap. 
sional workspace using nonlinear dynamics. for our simulations  we assumed that the agent possessed a partial representation of the environment  and we addressed the issue of how best to use the information represented in its internal map. 
　this basic strategy is applicable in a variety of different settings. first of all  it seems natural to employ the planning horizon as a mechanism for selection of sensors. many robots are equipped with a range of different sensors such as sonar  vision  laser  tactile  and so forth. each of these sensors has a different range and resolution. thus  dynamic selection of a discrete planning level may be used for selection of sensors in response to the need for spatial detail and/or range. for close range navigation either infrared sensors or vision modules such as the inverse perceptive mapping may be used. on our particular platform we employ ultra-sonic sonars and inverse-perspective mapping. thus  inverseperspective mapping may be used for close range navigation  while sonar may be used for longer range sensing. 
　there are several possible applications of the planning horizon dynamics beyond those presented in the paper. map building presents one interesting possibility. another possibility that we have not yet explored is planning at multiple levels simultaneously. this may be useful in situations where it is necessary to take both global and local constraints into account. we are currently experimenting with several applications of this approach using the mobile platforms in our laboratory. 
