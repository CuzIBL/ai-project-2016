
we study the problemof learning largemargin halfspaces in various settings using coresets and show that coresets are a widely applicable tool for large margin learning. a large margin coreset is a subset of the input data sufficient for approximating the true maximum margin solution. in this work  we provide a direct algorithm and analysis for constructing large margin coresets1. we show various applications including a novel coreset based analysis of large margin active learning and a polynomial time  in the number of input data and the amount of noise  algorithm for agnostic learning in the presence of outlier noise. we also highlight a simple extension to multi-class classification problems and structured output learning.
1 introduction
large margin techniques are the basis for both practical algorithms and theoretic analysis in machine learning. algorithmically  the most notable example is the support vector machine  svm   vap1  that finds a maximum-margin separation of a given data set. the svm has proven very successful in practice and theoretically  a large margin separation implies good generalization performance  ks1 .
﹛the svm has a simple representation and a straightforward implementation - find the set of support vectors that uniquely define the maximum margin separation. amazingly  this approach simultaneously allows the classifier to be represented with a  potentially small  subset of the input data and  through the use of kernel functions  to utilize an arbitrarily powerful hypothesis space. if a small support set can be found  then one can guaranteehigh performanceon unseen

﹛﹛  work on this paper was partially supported by a nsf career award ccr-1.   work on this paper was partially supported by nsf grants itriis-1 and iis-1.   much of this work was done while at the university of illinois. 1
﹛﹛throughout the paper  we often present only proof sketches due to lack of space. the full proofs appear in technical report uiucdcs-r-1 available from the university of illinois computer science department.data when using a hypothesis class with unbounded complexity. unfortunately  there is no guarantee that the size of the support set will be small. additionally  the running time of the svm algorithm to find an exact solution to the large margin problem is o m1  time and o m1  space using m examples and is infeasible for large datasets.
﹛most practical algorithms  such as chunking  vap1   decomposition  ofg1   and sequential minimal optimization  smo   pla1   reduce the problem to manageable subtasks are heuristic solutions which may converge slowly. furthermore  the running time remains crucially dependent on the number of support vectors in the solution. alternatively  recent work has focused on on-line approaches to approximate the maximum-margin algorithms  kow1; gen1; ll1 . on-line algorithms are iterative solutions that add examples to the large margin solution based on various conditions - all related to the relative margin of the example under consideration. as a result  they can bound the number of examples necessary to guarantee a large margin separation.
﹛in this paper we relax the requirement that we find the unique maximum margin separation. specifically  we find an approximate maximum margin separation - a hyperplane that separates all of the input data with margin larger than
  where 老  is best achievable. we use the coreset method first described in  bc1  and extended to the maximum margin setting in  tkc1 . a coreset for a maximum margin separating hyperplane is a subset  c ﹋ d of examples such that the maximum margin hyperplane on c is an approximate maximum margin separating hyperplane on d. in some sense  it captures all of the necessary information for the approximation just as the set of support vectors does for the true maximum margin separating hyperplane.
﹛this paper studies the running time of a simple coreset algorithm for binary and structured-output classification and the use of the coreset as an analysis tool for active learning and noise-tolerant learning in the agnostic setting. in previous work  the coreset was constructed as a reduction to finding a coreset for a different problem - the minimum enclosing ball  bc1 . in section 1  we show a direct algorithm for finding a coreset of size at most in time
o nd|c| + |c|t |c|   where r and 老  measure the size of the example set and the quality of the maximum-margin classifier and t |c|  is the time to run an svm black-box on |c| examples. this improves previous bounds by a factor 1/ and provides an explicit running time to the algorithm.
﹛in section 1 we analyze one of the most effective active learning algorithms based on the maximummargin principal  tk1  and give a running time and a
-approximation guarantee. we show that in time  one can computea core-
set c of size at most  such that with high confidence  1 汛  the classifier produced will have large margin and small  e  error. in section 1  we analyze learning with outlier noise. roughly speaking  a set of outliers is a small subset of the input data such that  if removed would yield the correct maximum-margin classifier. thus if we assume there are k outliers  the best maximum margin classifier is well-defined. we show a polynomial time algorithm for learning the maximum margin separation in this setting. finally  in section 1 we highlight an important connection between the coreset algorithm and recent work for learning svm for structured output  thja1 . indeed  we can view svmstruct as a coreset algorithm.
1 preliminaries
we are given d = { x1 y1  ...  xm ym }  a labeled training set of cardinality m drawn from some distribution dx y  where xm ﹋ x are the examples in a inner-product space and ym ﹋ y are labels. for most of the paper  we assume a real valued input  x = rd  and binary output  y = { 1}. however  in section 1 we note an important extension to the structured output domain.
﹛in this paper  we use the maximum margin principle to discover a hypothesis h ﹋ h represented by a halfspace h x  = argmaxy﹋{ 1} y w ﹞ x   where w ﹋ rd. the binary margin  or geometric margin   老 w x y  = y w ﹞ x   for an example  x  is defined as the distance from the example to the discriminating hyperplane w ﹞ x = 1. notice that a negative margin is indicative of a misclassified example. the margin of hypothesis h is 老 h d  = min x y ﹋d 老 w x y .
﹛therefore  given a sample  d  the maximum margin hypothesis  hyperplane  is
	l d  =	argmax	min y w ﹞ x 
w﹋rd ||w||=1 x y ﹋d
is the uniform length hyperplane with maximum margin over the data.
definition 1  -approximation  a hypothesis h is a -approximation to the optimal hypothesis h  if
.
definition 1  maximum margin coreset  a maximum margin coreset is a set of examples such that h = l c  is a -approximation to h  = l d .
1 coreset learning algorithm
large margin coresets were first introduced in  tkc1  to form the core vector machine  cvm . in that work  they reduced finding a maximum margin hyperplane to finding the minimum enclosing ball of a set of points around the origin.
algorithm coreset svm
input:
s =   x1 y1  ...  xm ym   
approximation parameter where
output: a classifier h ﹋ h
begin
set c =   x1 y1  
for i = 1...t
set hi = svm c 
set 老i = 老 hi c 
 xmin ymin  = argmin x y ﹋s c 老 hi x y  if
else return hi
return svm c 
endfigure 1: maximum-margin learning via coresets.
for the latter task  there exists a coreset algorithm that runs in time linear in the number of points  bc1 . in this section  we provide very similar results with a slight  factor improvement by providing a direct algorithm and analysis.
﹛in figure 1  the simplified coreset algorithm is presented for learning binary labeled data in a noise-free setting. the coreset c is built iteratively. at each step  we construct the true maximum margin classifier  hi = svm c  and use it to find the example with the smallest  or negative  margin. this example is then added to the coreset and the process repeats. it is possible to tell that-approximation by observing the ratio between the margin on the coreset  老 hi c   and the margin on the entire data set  老 hi d . if this ratio is small enough then the margin of hi on the entire data set is sufficiently large and the algorithm halts.
lemma 1 let 老  = 老 l d  d  be the optimal margin for data set d ﹋ {rd ℅ { 1}}m of size m. given a parameter   one can compute a coreset c of size
in time o nd|c| + |c|t |c|    where
	x	.
﹛proof sketch: we show using a simple geometric argument that each time an example is added to the coreset  the margin on the next integration decreases by at least a constant factor. that is 
	 	 1 
where 汐i = 老i   老 hi xi  measures how much the added example violates the current margin guess using the current hypothesis hi. then  it can be shown that the decreasing sequence of margins will be smaller thanafter at most  steps. once the margin is small enough  we show that it quickly decreases and outputs a -approximation to the maximum margin classifier. 
﹛at each step  the algorithm in figure 1 adds the example with the smallest margin to the coreset. however  the algorithm is easily modified such that any example with margin small enough can suffice. specifically  if we know that each example  x y  added to the coreset is such that 老 hi x y   
  but not necessarily the example with minimum margin  the algorithm still converges  but with a larger coreset.
corollary 1 let 老  = 老 l d  d  be the optimal margin for data set d ﹋ {rd ℅ { 1}}m of size m. given a parameter   one can compute a coreset c of size
in time o nd|c|+|c|t |c|    where
.
﹛proof sketch: if  rather than add the minimum margin example at each step  we add any example with small enough margin   then we can simplify the simple geometric proof sketch for lemma 1 and show that
.
then  similarly to lemma 1  we use this decreasing sequence to prove the result.	
1 related work
central to the coreset algorithms presented here  is the idea of iteratively building a working set of examples by carefully selecting examples to add at each step. in the online learning literature  this idea has appeared in work related to the coreset approach.
﹛indeed  even the perceptron algorithm can be viewed as building a working set. at each iteration  an example 
 xi yi   is added to the working set if yi wi ﹞ xi    1. the hypothesis is a linear sum of elements in the set.
﹛various approximate algorithms for online learning have also been proposed. in  kow1   kowalczyk proposed a perceptron-like update rule  with various criteria for choosing which example to update. one of them is exactly the minimum margin approach used in coresets. after only  updates  the algorithm would converge to a
-approximate classifier - a result very similar to ours  modulo 1/ and logr terms. at roughly the same as kowalczyk's algorithm  two additional algorithms were proposed: the relaxed online maximum margin algorithm  romma  and the approximate large margin algorithm  almap . romma is an online algorithm that learns a -approximate maximum margin separation. both have similar selection criteria  and perform similarly in practice. almap also provides a mistake bound of.
﹛recently a new algorithm  svm-perf  was introduced and implemented  joa1  with similar bounds. svm-perf is presented as a cutting-plane algorithm  where at each iteration a cutting-plane is found that represents a fixed subset of the training examples. the coreset methods are a special case of the cutting-plane algorithm where each cutting plane is described by a single example. indeed  this very clever algorithm converges very fast. many experimental results are presented that show the fast convergencetime in practice  and we think this work helps support our claim that coreset-based algorithms can be practical.
1 maximum margin active learning
in active learning  the learner is presented with a set of unlabeled data  u = {x1 ... xm} and an oracle  oracle : x ↙ { 1} that provides a label to any example x ﹋ u consistent with a large margin hypothesis. the goal is to learn exactly this maximum margin separation using a limited number of oracle queries.
﹛recently  iterative algorithms for active learning svm have been proposed  tk1; ccs1 . after presenting a slight modification of these algorithms using coresets and introducing an explicit stopping criteria  we show that the algorithm converges quickly to a -approximation of the true maximum margin hypothesis that exists given all labels  with high probability .
1 coreset active learning algorithm
in figure 1  the active learning algorithm from  tk1  is adapted by adding a verification stage. the algorithm runs in iterations  where at each step  the unlabeled example that is closest to the decision boundary is added to the coreset. however  if there are no examples near the decision boundary  i.e. they are further than the current large-margin guess   we may think that all labels are classified correctly and thus the algorithm can halt. of course  since the labels are unknown  it is possible that there are still a large number of misclassified examples. at this point the algorithm enters a verification phase  verify    where examples are sampled uniformly at random from the entire data set according to
uniformrandom   and labeled using oracle  .
﹛it is important to note that the algorithm presented in figure 1 repeatedly cycles over the unlabeled dataset to find the single example closest to the decision boundary. this is easily modified to two important cases when the number of examples is very large  i.e. m    |c|  or when there is an infinite stream of examples  i.e. m = ﹢ . in these cases  any example  x where can be added to the coreset and the algorithm can halt after enough examples are seen without making a mistake. indeed lemma 1 below applies to these more general cases.
1 analysis
algorithm 1 seeks the true maximum margin hypothesis of the data that would be found if all of the labels were known.
here  we show that with high probability  1   汛   it finds a
-approximation to this hypothesis. unfortunately it is impossible to guarantee error free learning  see section 1   so we must accept a small  e  prediction error.
﹛the analysis follows from two facts. first  there exists a coreset that can be constructed by adding examples that lie close to the decision boundary. any example with very small margin    will improve the approximation irrespective of the actual label. second  the verification stage will halt either because it has found an example with very small  i.e. negative  margin that will improve the coreset or because enough examples have been seen with no mistakes.

 a  active coreset svm
algorithm verify
input:
data u =  x1 ... xm  ﹋ {rd}m a classifier h : rd ↙ { 1}
output:
 x y  ﹋ rd ℅ { 1} or null
begin
for i = 1...t do x = uniformrandom u  y = oracle x  if 老 h x y    1
return  x y 
return null
end b  verify
figure 1:  a  active learning using coresets. abusing notation  u   c =  x ﹋ u| x  oracle .  b  verify procedure. uniformrandom u  returns a random example from the unlabeled set. oracle x  returns the correct label for x and uniformrandom u  selects an example from u uniformly at random.
in the latter case  we can apply the following lemma  adapted from  klpv1; ang1  that shows learning from membership queries can be used to give pac-bounds.
lemma 1 if l is a conservative on-line algorithm with mistake bound m and access to an example oracle
oracle   drawing examples i.i.d. from distribution d  then after at most  calls to oracle    with confidence 1   汛  l produces a hypothesis with expected error less than  on examples drawn from d.
﹛using lemma 1 and corollary 1  we bound the running time of this algorithm to convergeto an approximate solution.
lemma 1 let d = oracle u   be the entire labeled data set and 老  = 老 l d  d  be the optimal margin for data set d of size m. given parameters    one can compute a coreset c of size at most
in time  where r =
max x y ﹋d ||x||. the total number of calls to oracle   is less than  and t m  is the running time of the svm for m examples.
﹛proof: the coreset will be at most as a result of corollary 1 by noticing that each time an example   x y  is added to the coreset 
- either because an unlabeled example is added in line  1  in algorithm 1  a  or because a labeled example is added in line  1  in algorithm 1  b . in the former we know that
  and in the latter we know that
﹛since we know that at most |c| examples will be added to the coreset  and at each iteration  the margin of the current working hypothesis decreases we can use
lemma 1 to bound the total number of oracle queries in to ensure1 汛 confidencethat the classifier has at most e mistakes. therefore  the total number of calls to oracle   is at most
. the running time follows since
svm must be run each time an example is added to the coreset.	
1 related work
previously  the efficacy of maximum margin active learning algorithms were explained because by choosing the example closest to the decision boundary  the version space will be approximately halved  tk1. more precisely  it was argued that because at each iteration the version space is an intersection of half-spaces in the kernelized feature space. if we assume that each exampleis of constant size  i.e. ||x|| = 1  then the hypothesis with maximum margin separation is a point in the version space at the center of the largest enclosed ball in this polytope. therefore  by choosing an example with small margin  it is hoped that it comes close to bisecting the enclosed ball and also the version space.
﹛if one could guarantee that the version space was indeed halved at each iteration  then the algorithm would convergequickly to the true maximummargin hypothesis tk1; fs1  unfortunately  no such guarantee can be made  either in practice or in theory  thus the  halving  argument falls short to adequately explain the practical success of choosing the minimum absolute margin example at each iteration.
﹛in addition  as first presented in  das1  a zero-error active learning algorithm is impossible without requesting the label

figure 1: impossibility of zero-error approximation:  a  active learning nightmare - all examples are positive  with a single negative.  b  nightmare in 1d - 1 negative points  one below origin  a second on the plane of the circle.
of all examples. to see this  we consider a sample of examples spread at a constant interval on the surface of a circle in r1. see figure 1 for an illustration. the concept represented by figure 1 a  is one where a single example is negative and the rest are positive. the maximum margin separation thus separates a single example from the rest. consider any algorithm that computes the maximum margin separation of any labeled subset of this data. unless the single negative example is included in the labeled subset  then there is no hope of achieving an approximate large-margin separation that correctly classifies all examples in the data set. therefore  if an adversary controls the oracle  by simply answering  +  to every query until the final query  the learner is forced to ask the label of every example.
1 agnostic learning with outlier noise
learning in the presence of noise is of great interest. while there are many definitions of noise  such as attribute  label  and malicious noise  we consider a very general model  outlier noise. one can think of outlier noise in the following way: without the  noisy  examples  a  clean  function could be learned. thus if the noisy examples could be identified a priori  we could learn the true maximum margin classifier. in some sense  many types of noise can be viewed as outlier noise  so the analysis presented in this section can be widely applied. we show a polynomial time algorithm for learning an approximate maximum margin hyperplane in the presence of outliers.
definition 1  outlier set  consider a data set d =  of binary  y ﹋ { 1}  examples. for any set of outliers   we can consider the maximum margin hyperplane   on the examples.
then an outlier set of size k is a subset  vk  of size k that achieves maximum margin on the remaining data
vk = argmax 老 l d   v   d   v  .
v ﹋d |v |=k
﹛because a coreset exists for the  clean  data and we know that there are at most k  or a fixed fraction  outliers  we avoid exponential running time by subsampling based on the

 a  outlier svm
algorithm simple outlier svm
input:
data
output:
﹛﹛﹛a classifier h : rd ↙ { 1} begin
set r = max x y ﹋d ||x|| for i = 1 1 ...
set c = 1i
for each subset
hs = svm ds 
hmax = argmaxs 老k hs d 
if
return hmax and halt.
end b  simple outlier svm
figure 1:  a  approximate maximum-margin learning with outlier noise. 老k h d  returns the margin of the example in d that is smaller than the margin of all but k examples  i.e. the k + 1-th smallest margin .  b  simple algorithm. an alternate description of the algorithm that simply doubles the size of the sub-sample sets at each iteration.
expected coreset size. this provides an extremely simple polynomial-time algorithm for learning with noise.
lemma 1 let 老k = 老 l d   vk  d   vk  be the optimal margin for data set d of size m with k outliers. given a parameter    one can compute a separating hyperplane with margin  in polynomial time o dt c mc+1 logm   where. and
r = max x y ﹋d ||x||.
proof sketch:because the clean data  d vk   contains a coreset of size from lemma 1  it suffices to find this set and observe that there are at most k outliers. it is possible to examine all subsets of the input data. for each one  create the maximum margin hypothesis using an svm black-box and measure the margin obtained by removing the k examples with minimum margin  or negative margin . then  one of these hypotheses will have the maximum margin and have at most k outliers. finally  since the margin is unknown a-priori  we must repeat the above procedure for exponentially decreasing guesses and stop once we see only k outliers with margin as large as the guess. 
1 structured output learning
structured output learning is one of the most important new areas in machine learning. structured output can be sequences  trees  rankings and general structures and are ubiquitous in important applications in areas from nlp to web search to biology. machine learning have begun to address these problems. here  we show a common modeling approach for structured output learning and highlight the connection to standard maximum margin learning.
structured classifiers produce complex  structured output
y = y1 ℅ ... ℅ yl  where yl ﹋ {1 ... k}. it is common to write the decision rule as
h x  = argmaxw 
y﹋y
where 朴 x y  represents features of each  example  label  pair. therefore  the maximum margin hypothesis  hyperplane  is
	ls d  =	argmax	min	老 w x y  
w﹋rd ||w||=1 x y ﹋d
where

yy
﹛as a result  the algorithms and analysis presented in this paper extend to the structured output setting.
1 related work
indeed  the svm was recently extended to the structured output domain. svmstruct  thja1  is an algorithm that runs in iterations  each time adding -triples to the working set. indeed  they use exactly the same  featurevector used here. then  the working hypothesis is updated  in the dual  by optimizing over the lagrange multipliers  similar to the sequentialminimal optimization  smo  procedureintroduced by platt  pla1 . they also show a bound of on the size of the working set.
1 conclusions
in this paper  we give a simple coreset algorithm with an improved bound on the coreset size. we are mainly concerned with running time analysis of various algorithms. using coresets  we give boundsfor maximummargin active learning and structured output learning. we also formulate a novel and polynomialtime algorithmfor learning in the agnostic  noisy  setting. coresets are a very general tool in approximation algorithms and we have shown that they have important uses in maximum margin learning and analysis. we think that this is the tip of the iceberg  and envision that coresets will find many more applications in machine learning.
