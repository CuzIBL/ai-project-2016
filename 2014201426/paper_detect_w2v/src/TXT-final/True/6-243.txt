 
this article describes preliminary work on a research environment called virtual synergy to represent a shared virtual map of an area for multiple autonomous robots by modifying the gamebots 1d multi-agent system. the use of 
gamebots will allow multiple users to interact with robots and agents at different levels of adjustable or dynamic autonomy. by interacting with the robots as another team member  the users take on different roles to suit the situation: supervisor  peer  mechanic  teleoperator  and spectator. 
1 introduction 
gamebots  adobbati et al.  1  is a modification of the commercial 1d multi-player video game unreal tournament. we are creating an adaptation of gamebots for robotic collaboration and intelligent agent research called virtual synergy. our system allows the robots to share two environments at once: the physical environment and a virtual environment hosted on a gamebots server  which can be accessed remotely via the internet; we'll deal with that aspect in section 1. the server also allows a user to be present in the virtual environment and interact with the robot through various mechanisms  which will be discussed in section 1. section 1 discusses the use of software agents. finally  in section 1  we will address how the current system can be expanded to include intelligent agents to facilitate human-robot interaction. 
1 inhabiting multiple worlds 
we are developing a robot team to participate in the aaai urban search and rescue  us ar  competition. one of the tasks for the robots is to explore a simulated disaster area and map the environment  locating walls  fallen objects  areas to avoid  for structural reasons   and victims. 
poster papers    the virtual synergy system provides a means for agents in the virtual world to create a three-dimensional map by placing objects that are detected in the real world in their corresponding locations in the virtual environment. each robot on the team will exist in both the physical world and the virtual world of virtual synergy. the robot will receive information from its sensors in the real environment and the virtual synergy server. the server will act as a virtual sensor  but providing map information instead of data. because multiple agents will process the information gathered from multiple sensors  we must deal with the issues of sensor fusion. 
   a similar system called player/stage has been developed for simulating sensors and robots in a virtual twodimensional world  gerkey et al.  1 . both player/stage and gamebots are designed to allow heterogeneous systems to communicate with the server over an ip network. player/stage sends simulated sensor readings to the client and the client sends actuator commands back to 
player/stage. the virtual synergy system  however  takes a higher-level approach; it provides mapping and path information; it also has the advantage of a three-dimensional view and the ability for humans to take on a persona in the environment. 
1 human interactions 
the nature of disaster areas often prohibits humans from being physically present; therefore  it is necessary to monitor and direct the robots from a distance  occluded by walls and debris. research in teleoperation has focused on multiple operators controlling one robot. murphy et al. suggest that teleoperation can lead to  cognitive fatigue  of the operators during long periods of operation and that the information received by the user often exceeds the user's capacity to process it  murphy  1j. our system attempts to resolve these issues with an intuitive interface that mimics physical interaction with the robots. research dealing with multiple users interacting with multiple robots has shown the need for  adjustable autonomy   in which a 
1 
robot can be controlled to varying degrees by user intervention  kortenkamp et al.  1 . multiple levels of adjustable autonomy will be possible with the virtual synergy system. 
   a user in the environment of a virtual synergy server has various modes of navigation; he/she can fly unimpeded by gravity  walk through walls  or use a more realistic physics model. the interface for navigation is intuitive; it was chosen because it was designed for navigation of a three-dimensional environment by multiple human players. 
   we are researching the use of user roles to facilitate user interactions with robots. current research  scholtz  1  defines three levels of interaction with a robot: supervisor  peer  and mechanic interactions. the different roles define the information displayed to the user and the set of possible interactions available to the user. in addition to the three roles described in  scholtz  1   we add two other roles: spectators can view the environment but not interact with the robots and teleoperators take complete control of the robot by temporarily inhabiting its representation in order to direct it through areas of difficulty. 
   perzanowski et al. have developed a system for controlling teams of robots using voice and gesture commands  perzanowski et al.  1 . our robotic interactions are currently not based on speech or gestures  but on direct manipulation of the robot's world model. while navigating in the virtual environment  the user will instruct the robots through various commands such as  come here.  the commands are english-like only for purposes of user interface  natural language and gesture commands are a foreseen addition . the user can also directly modify the environment by leaving a path to follow or indicating  hot spots  which suggest areas to explore. the system also provides the user the ability to manipulate the environment in order to rectify any sensor anomalies. 
1 software agents 
autonomous software agents will also inhabit the virtual environment as teammates. agents can facilitate communication between the users and the robots  effectively providing a more natural  more human interface to dealing with information from the robots. since all agents  robots  software agents  and people  in the virtual environment are collaborators on the same team  they can all take on the different roles with each other; in addition to carrying out user-specified tasks  the software agents could also autonomously lead a group of robots with minimal human supervision. 
1 conclusion and future work 
the ultimate goal of our project is to facilitate human interaction with a team of robots and agents. we are researching ways to increase the efficiency of robot collaborators; our aim is to decrease the number of humans required to monitor and collaborate with a larger team of robots without overloading the users with information from an increasingly complex team of autonomous agents. 
   the two problems we are immediately facing are sensor fusion and localization. localization is important for creating an accurate map of the environment; sensor fusion becomes a problem once two robots are involved in building the map: they could potentially be looking at the same object. we would not want the same object to appear twice. 
   the use of two environments  one virtual  one actual  allows for complex human-robot interaction and useful inter-robot collaboration. using the 1d environment of virtual synergy will give the user an intuitive interface to interact with the robots as another member of the team. user roles will act to define the possible interactions with the robots. intelligent agents will assist the user by responding to queries  gathering information  and automating tasks. 
