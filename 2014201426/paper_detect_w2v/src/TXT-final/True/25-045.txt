 
the study of situated systems that are capable of reactive and goal-directed behaviour has received increased attention in recent years. one approach to the design of such systems is based upon agent-oriented architectures. this approach has led to the development of expressive  but computationally intractable  logics for describing or specifying the behaviours of agent-oriented systems. in this paper  we present three propositional variants of such logics  with different expressive power  and analyze the computational complexity of verifying if a given property is satisfied by a given abstract agent-oriented system. we show the complexity to be linear time for one of these logics and polynomial time for another  thus providing encouraging results with respect to the practical use of such logics for verifying agent-oriented systems. 
1 	introduction 
the study of systems that are situated or embedded in a changing environment has been receiving considerable attention within the knowledge representation and planning communities. the primary characteristic of these systems is their dynamic and resource-bounded nature. in particular  situated systems need to provide an appropriate balance between time spent deliberating and time spent acting. if the time spent on deliberation is too long  the ability of the system to complete its tasks may be seriously affected. on the other hand  too little deliberation may lead to a system that is short-sighted and reactive. 
　a number of different architectures have emerged as a possible basis for such systems  bratman ct al.  1; rao and georgeff  1b; rosenschein and kaelbling  
1; shoham  1 . some of the most interesting of these are agent-oriented architectures  in which the system is viewed as a rational agent having certain 1iental attitudes that influence its decision making and determine its behaviour. the simplest of these architectures  called a bdi architecture  is based on attitudes of belief  desire  and intention. the first two attitudes 
1 	distributed al 
represent  respectively  the information and evaluative states of the agent. the last represents decisions the agent has made at a previous time  and is critical for achieving adequate or optimal performance when deliberation is subject to resource bounds  bratman  1; kinny and georgeff  1 . recently  a number of attempts have been made to formalize these mental attitudes and to show how these attitudes determine the actions of an agent  cohen and levesque  1; rao and georgeff  1b; singh  1 . 
　most of these studies on agent-oriented systems concentrate on the specification or characterization of rational agents and their behaviours under different environmental conditions. they introduce logics that use linear or branching temporal structures  are often first-order  and tend to have a rich repertoire of modal operators to model beliefs  desires  goals  intentions  commitment  ability  actions  and plans. 
　however  the design of agent-oriented systems has so far had little connection with these formalisms. although some systems have been designed and built upon the philosophy of rational agents  georgeff and lansky  1   the linkage between the formal specification and the design is weak. similarly  little has been done in the verification of agent-oriented systems. as more and more of these systems are being tested and installed in safety-critical applications  such as air-traffic management  real-time network management  and power-system management  the need to verify and validate such systems is becoming increasingly important. 
　this paper addresses the issue of verification of situated systems based on the the theory of rational agents. issues related to the specification and practical design of agent-oriented systems are dealt with elsewhere  rao and georgeff  1b; rao and georgeff  1 . the outline of the paper is as follows. section 1 describes the semantic model. section 1 presents three branching-time bdi logics with increasing expressive power and introduces the notion of commitment. the problem of verification in these logics and their complexity is described in section 1. using an example  section 1 shows how one can verify temporal and commitment properties of agent-oriented systems in polynomial time. finally  we conclude in section 1 by comparing our work with related effort and highlighting the contributions of this paper. 
1 	overview 
situated agents can be viewed as concurrent systems of processes. the execution of such processes can be modeled by the nondeterministic interleaving of the atomic actions of each process. in such a model  the nondeterministic choice of a concurrent program is represented as a time point with multiple successors in a branching-time tree structure. each possibly infinite execution sequence of a concurrent program is represented as a computation path of the tree structure. 
   for systems based on the notion of a rational agent  however  such a model of the system's behaviour is too abstract. in this case  one is interested in analyzing how such agents choose to bring about the future that they desire. in so doing  the agent needs to model the uncertainty or chance inherent in the environment as well as the choice of actions available to it at each and every time point. as the agent does not have direct control over the environment  but has direct control over the actions it can perform  it is desirable to separate the agent's choice of action  over which it has control  from its view of the environment  over which it has no control . also  unlike concurrency theory  there is no single view of the environment; each agent can have its own view of the environment and of other agents' mental states which may not coincide with the actual environment nor the actual mental states of these agents. these different views of the world can be more effectively modeled within a possible-worlds framework. 
   hence  we adopt a possible worlds branching-time tree structure in which there are multiple possible worlds and each possible world is a branching-time tree structure. multiple possible worlds model the chance inherent in the environment as viewed by the agent and are a result of the agent's lack of knowledge about the environment. but within each of these possible worlds  the branching future represents the choice of actions available to the agent. 
   a particular time point in a particular world is called a situation. for each situation we associate a set of belief-accessible  desire-accessible  and intentionaccessible worlds intuitively  those worlds that the agent believes to be possible  desires to bring about  and commits to achieving  respectively. we require that an agent's intentions be consistent with its adopted desires  and that its desires be believed to be achievable  rao and georgeff  1a . 
   one of the important properties in reasoning about concurrent programs is the notion of fairness. fairness or fair scheduling assumptions specify when an individual process in a family of concurrent processes must be scheduled to execute next. a number of different fairness assumptions have been analyzed in the literature.1 a commonly used fairness assumption is that a process must be executed infinitely often. a concurrent program can thus be viewed as a branching-time tree structure  with fairness and starting conditions. the verification of a property is equivalent to checking if the property is satisfied in the model corresponding to the concur*see emetson  for an overview on this topic. 
rent program under the fairness and starting conditions. as described by emerson   concurrency can be expressed by the following equation: concurrency = nondeterminism + fairness. 
   analogously  an important aspect of rational agency is the notion of commitment. the commitment condition specifies when and for how long an agent should pursue a chosen course of action and under what conditions it should give up its commitment. thus  a commitment condition embodies the balance between reactivity and goal-directedness of an agent-oriented system. an abstract agent-oriented system can thus be viewed as a possible worlds branching-time tree structure with commitment and starting conditions. the verification of a 
   property of the agent-oriented system is equivalent to checking if the property is satisfied in the model corresponding to the system under the commitment and starting conditions. we could therefore express agentoriented reasoning as follows: agent-oriented reasoning = chance + choice -+ commitment. in the next two sections we formalize these notions. 
1 propositional b d i logics 
1 	syntax 
we define three languages c t l b d i   c c t l b d i  committed   which are propositional modal logics based on the branching temporal logics c t l   fair c t l   and ctl*  emerson and lei  1   respectively  with increasing expressive power. the primitives of these languages include a non-empty set φ of primitive propositions; propositional connectives v and -; modal operators bel  agent believes   desire  agent desires   and intend  agent intends ; and temporal operators x  next   u  until   f  sometime in the future or 
eventually   e  some path in the future or optionally   and   some committed path in the future . other 
connectives and operators such as  all times in the future or always   a  all paths in the future or 
oo 
inevitably   	 all 	committed paths  in the future   f 
 infinitely often   and  almost always  can be defined in terms of the above primitives. the last two operators are defined only for 
　there are two types of well-formed formulas in these languages: state formulas  which are true in a particular world at a particular time point  and path formulas  which are true in a particular world along a certain path . state formulas are defined in the standard way as propositional formulas  modal formulas  and their con-
junctions and negations. the objects of e and a are path formulas. path formulas for  can be any arbitrary combination of a linear-time temporal formula  containing negation  disjunction  and the linear-time operators x and u. path formulas of are restricted to be primitive linear-time temporal formulas  with no negations or disjunctions and no nesting of linear-time temporal operators. for example   is a state 
is a path formula of c t l b d i but not 
of 
	in 	contrast 	to 	the 	language c t l b d i   committed 
	rao and georgeff 	1 


1 	distributed al 

　an agent that is blindly committed will give up its commitment only when it believes in φ  where φ is usually a proposition that the agent is striving to achieve. in addition to this  an agent who is single-mindedly committed will give up its commitment when it no longer believes that there exists an option of satisfying the proposition some time in the future. an agent that is openmindedly committed will give up its commitment either when it believes in the proposition or when it no longer has the desire to eventually achieve the proposition. 
　one can combine the above forms of commitment in various ways. for example  the formula  denotes an agent that is blindly and fully committed to achieving p until it believes in p. similarly  the formula  is an example 
of an agent that is single-mindedly partially committed to achieving p  i.e.  has decided not to rule out the posiibility of not being able to achieve p in the future . 
　for an agent to eventually achieve its desires  it needs to maintain its commitment to bring about these desires. although an agent that only occasionally maintains its commitment may serendipitously fulfill its desires  as designers of these systems we cannot guarantee this. to do so  we need to impose stronger maintenance conditions; namely  that the commitment formula is true  infinitely often  or  almost always . hence  in committed c t l b d i we take the commitment constraint to be of the canonical form where a  and  are commitment formulas. 
1 	verification 
our interest is in determining what properties hold of a given agent  in a given environment  under certain initial conditions and under certain commitment conditions. for example  given a robot that is programmed to 
single-mindedly commit to a certain set of intentions  we may need to prove that  in a particular environment and under particular initial conditions  it will never harm a human. 
　given some specification of the agent and the environment  we can generate the branching-tree structure corresponding to all possible evolutions of that agent in that environment.1 this structure represents the model m of the agent and its environment. for the purposes of this paper  we consider only finite structures. the size 
of a finite structure m is given by the size of the different components of the structure. more formally  
 the size of w is equal 
to the number of worlds and the size of the relations is 
equal to the number of elements in the relation. 
1
　　we do not address this process of model generation in this paper. methods for generating models used in concurrency theory  emerson  1  can be extended for this purpose. the notion of plans as abstract specifications  rao and georgeff  1  is similar to that of finite-state transitions and can be used to generate a partial model. 
	rao and georgeff 	1 

committed c t l b d i  cmcp . complexity results given for fctl by emerson and lei  can be extended to cmcp. in particular  c m c p can be reduced to the problem of model checking for committed states. this reduction exploits the nature of the commitment constraint  namely  the fact that and are oblivious to the addition and deletion of finite prefixes. also  formulas of the form 
can be reduced to model checking of primitive propositions  formulas of the form   rao 
and georgeft  1 . 
   the details of the algorithm a c m c p are given elsewhere  rao and georgeft  1 . its complexity is given below. 
t h e o r e m 1 solving the model checking problem for committed branching temporal bdi logic  c c t l b d i will take  time to run. 
   the extensions of c c t l b d i over fctl are twofold:  i  the introduction of possible worlds extends the expressive power of c t l and results in a complex structure on which to perform model checking; and  ii  the commitment constraint is more complex involving modal operators and path quantifiers. 
   the language ctl*bdi subsumes the language c t l *   which in turn subsumes the linear-time temporal language ltl. hence  the complexity of model checking for ctlbdi has to be the same or greater than that of the model checking for ltl. it has been shown  lichtenstein and pnueli  1  that the complexity of model checking in ltl is linear in the size of the structure and exponential in the size of the given formula. 
1 	example 
consider a robot  mark i  that can perform two tasks  each involving two actions. for the first task  the robot can go to the refrigerator and take out a can of beer  denoted by gf  and bring it to the living room  bb . for the second task  the robot can go to the main door of the house  gd  and open the door  od . the only uncertainty in the environment is the presence or absence of a beer can in the refrigerator. for simplicity  we assume that the act of going to the refrigerator also involves opening the door and checking for the can of beer. if there is no can in the refrigerator  the act gf is said to have failed and the next act of bringing beer cannot be performed. we assume that all other acts succeed when executed. 
   given appropriate specifications of such a robot and its environment and some commitment constraint  as designers of these robots we will need to guarantee that they satisfy certain properties. for example  we may need to guarantee that  a  when the robot has a desire to serve beer it will inevitably eventually serve beer; or  b  when the robot has a desire to serve beer and a desire to answer the door  and there is beer in the fridge  it will inevitably eventually realize both desires  rather than shifting from one task to the other without completing either of them. 1 
' this could happen if the tasks of going to the refrigerator 
1 	distributed al 
   we consider two model structures m1 and a/1. first  we start by specifying directly the external model structure m1. generation of the external model structure from the agent and environment specifications is beyond the scope of this paper. a partial description of the structure m1 is shown in figure 1. world w1 depicts the alternatives available to the robot when it can choose to perform both the tasks and the environment is such that there is a beer can in the refrigerator. the dotted lines refer to additional future paths  which can be described in an analogous manner. one can view worlds w1 and w1 as world wl after the agent has executed the act of either going to the refrigerator or going towards the door  respectively. similarly  w1 and w1 are evolutions of w1; w1 and w1 are evolutions of w1. 
we introduce two propositions: 
b e e r - i n - r e f r i g e r a t o r and served-beer. the proposition b e e r - i n - r e f r i g e r a t o r is true at all times in the worlds . the proposition served-beer will be true in worlds after the act of bringing the beer  bb . 
　next we examine the belief  desire  and intention relations of the agent. the world wl of figure 1 shows the various time points. the belief relations for world at various time points are given as follows: 
desire and intention 
relations can be defined similarly. further  we assume that the belief relations do not change when actions are performed. in other words  we also have 
similar relationships 
hold for worlds 	this completes our description of the structure m . 
   consider a starting state in which the robot believes that there is beer in the refrigerator and has the intention to inevitably eventually have served beer.1 
   we consider two instances of the commitment constraint; the first instance is a blind commitment towards an intention to have served beer sometime in the future and the other is a single-minded commitment towards the same intention. more formally  we have: 

   using definition 1 and algorithm a c m c p we can show that in all paths where the robot is blindly or single-mindedly committed to its intention  it will achieve its desire of serving beer. more formally  
and going to the door involve taking multiple steps; the agent could then take one step towards the door  change its mind  take the next step towards the refrigerator  again change its mind and keep alternating between these tasks forever. 
1
　　 we assume that the agent has the desire to have inevitably eventually served beer and to have inevitably eventually opened the door. in this example  we consider the case where the agent has only adopted an intention to serve beer; in the full paper  rao and georgeff  1   we consider the intention to open the door as well. 

   next  consider two robots  mark i and mark i i   and the situation in which there is no beer in the refrigerator.1 intuitively  mark i does not change its belief about there being beer in the refrigerator at some time point in the future  even if it notices at this time point that there is no beer in the refrigerator. on the other hand  mark ii changes its belief about the beer being in the refrigerator as soon as it notices that there is none. 
   now consider the structure m1 which consists of worlds w1-w1 shown in figure 1 and additional worlds where the proposition b e e r - i n - r e f r i g e r a t o r is false at all time points. transitions between these worlds are similar to worlds w1-w1 except that the act gf fails  as there is no beer can in the refrigerator  and is followed by the act of going to the main door  namely gd  rather than the act of bringing the beer  namely bb. 
   with the structure m1 we can show that a singlemindedly committed mark ii agent will drop its commitment to maintain the intention of inevitably eventually serving beer. on the other hand  a single-mindedly committed mark i agent will maintain this commitment forever. more formally  we can show the following: 

   in summary  we have considered two different model structures  one where the robot completes its task  the second where it is impossible for the robot to complete its task  but yet one of the robots maintains its commitment to this task forever  while the other robot reconciles itself 
1
　　 although we have not described a multi-agent c t l b d i logic  the modifications required to do so are straightforward. also  as long as we do not introduce common knowledge operators  the complexity of model checking in such multi-agent modal logics will be of the same order as single-agent modal logics  halpern and moses  1 . 
to the impossibility of completing the task and gives it up. the purpose of this exercise has been to show how global properties of agent-oriented systems can be verified under a variety of rational behaviours obtained by varying the model structure and the commitment constraint. 
1 	comparisons and conclusions 
cohen and levesque  describe agents by adopting a possible worlds structure in which each world is a lineartime temporal structure and consider fanatical and relativized forms of commitment. a fanatical commitment is similar to our definition of a single-minded agent committed to its intention  i.e.  
 a relativized commitment is one in which the agent has a persistent intention towards a proposition until it believes in the proposition or until some other proposition is believed. this can be expressed as 
cohen and levesque do not address the issue of model checking in their logic. however  as their logic subsumes linear-time temporal logic  ltl   the process of model checking in their logic will be at least as hard as the model checking for ltl; namely  linear in the size of the structure and exponential in the size of the given formula  lichtenstein and pnueli  1  . 
   singh  presents a branching-time intention logic based on ctl*. various rationality postulates relating to beliefs  intentions  and actions are analyzed. also  like cohen and levesque  singh uses his logic only as a specification to characterize different behaviours and does not provide any guidelines for the design or verification of such rational agents. shoham's work  shoham  1  spans both theory and language design  but does not address the issue of verification either. 
   this paper goes beyond this earlier work and provides a methodology for formally verifying properties of agentoriented systems. starting from a reasonably rich model structure  we have described three propositional logics and analyzed their relative expressive power. furthermore  the linear time and polynomial time complexity of model checking in two of these logics makes them potentially useful for verifying practical agent-oriented systems. 
	rao and georgeff 	1 
　our work draws its inspiration from the field of concurrency theory  emerson  1   especially that field's contribution to the techniques of model checking. we have extended the results of emerson and lei  by showing that the linear time and polynomial time complexities of model checking hold for logics more expressive than ctl and fair ctl logics. also  the complexities are not greatly affected by the number of different modalities - the complexity seems to be dependent on the underlying temporal structure. more importantly  this paper demonstrates the generality of the modelchecking technique  halpern and vardi  1  and extends it to a new domain; namely  the verification of agent-oriented systems. the close correspondence between fairness and commitment  and concurrency theory and rational agency  lays a strong theoretical foundation for the design and verification of agent-oriented systems. 
   however  a number of open problems with respect to this approach remain. first  we need to address the process of model generation whereby  given an agent specification and/or environment specification  the appropriate model structure is automatically generated. second  we have used model checking as a means of verifying global properties  i.e.  from an external observer viewpoint. similar techniques can be used by the agent internally. in this case  we may want to build the model incrementally  rather than assuming that the entire model structure is given to us. third  the size of the structures we are dealing with is likely to be large and techniques to reduce this would be valuable. 
　although a number of issues in the model-theoretic design and verification of agent-oriented systems are yet to be resolved  our work indicates  for the first time  that the expressive multi-modal  branching-time logics can possibly be used in practice to verify the properties of these systems. 
acknowledgements 
this research was supported by the cooperative research centre for intelligent decision systems under the australian government's cooperative research centres program. 
