
this paper describes seggen  a new algorithm for linear text segmentation on general corpuses. it aims to segment texts into thematic homogeneous parts. several existing methods have been used for this purpose  based on a sequential creation of boundaries. here  we propose to consider boundaries simultaneously thanks to a genetic algorithm. seggen uses two criteria: maximization of the internal cohesion of the formed segments and minimization of the similarity of the adjacent segments. first experimental results are promising and seggen appears to be very competitive compared with existing methods.
1 introduction
the purpose of automatic text segmentation is to identify the most important thematic breaks in a document in order to cut it into homogeneous units  disconnected from other adjacent parts  salton et al.  1 . more precisely  segmentation partitions a text by determining boundaries between contiguous segments related to different topics  defining so semantically coherent parts of text that are sufficiently large to expose some aspect of a given subject. thematic segmentation of texts can also be seen as a grouping process of basic units  words  sentences  paragraphs...  in order to highlight local semantical coherences  kozima  1 . the granularity level of the segmentation depends on the size of the units.
　the increasing interest in text segmentation is mainly explained by the number of its applications such as text alignment  document summarization  information extraction  or information retrieval  baeza-yates and ribeiro-neto  1 . text segmentation can be indeed very useful for these tasks by providing the structure of a document in terms of the different topics it covers  mcdonald and chen  1 .
　many segmentation methods have been proposed and we focus here on the most general and significant methods that rely on statistical approaches such as text tiling  hearst  1   c1  choi  1   dotplotting  reynar  1  or segmenter  kan et al.  1 . these methodsperforman analysis of the distribution of the words in the text  in order to determine the thematic changes by means of lexical inventoryvariations in fixed size windows and thus create boundaries in the text where the local cohesion is the lowest.
　in this paper  we introduce seggen a genetic algorithm to achieve a statistical linear segmentation of texts. section 1 presents the main motivations of our work. our segmentation algorithm is described in section 1. then  section 1 describes an experimental study of the algorithm in order to tune its parameters. finally  section 1 evaluates seggen by comparing it with other segmentation systems.
1 motivations and preliminary works
in most of existing segmentation approaches  the relationships between sentences are usually very local. for example  the methods addressing segmentation by means of lexical chains1 mainly use the repetitions of the terms in order to define thematic boundaries. more precisely  these methods cut the texts where the number of lexical chains is minimal. nevertheless  the context of these multiple occurrences is not addressed neither the significance of simultaneous lexical chains at a given position in the text.
　according to the preceding remark  we attempted to propose an alternative approach to the segmentation of texts by taking into account a more complete view of the texts. in  bellot  1   p. bellot has shown that there exists a strong relationship between clustering and text segmentation. his hypothesis states that it is possible to set a boundary between two adjacent sentences belonging to two different semantic classes. this assumption seems too strong since text segmentation not only depends on the similarity of the sentences  but must also consider their layout in the text. indeed  discourse structures of documents may be very diverse and a part of a text related to a particular topic may contain sentences deviating somewhat from it. these sentences are likely to be classified differently from their neighbors. however  this certainly does not imply that a boundary has necessarily to be set there. moreover  this assumption is too dependent on the chosen clustering mechanism  no existing clustering method being fully reliable.
　however  we were convinced that a preliminary clustering could provide a more complete view of the sentences relations. therefore  we have defined a first segmentation method  called classstruggle  that uses an initial clustering of the sentences of the text based on their similarity  in order to have a global view on their semantic relations. in this approach  the resulting clusters evolve by taking into account their proximity in the text. considering the clusters as topics of the text  classstruggle performs a linear traversal of the document in order to determine the most appropriate class assignment for each sentence  depending on their context of occurrence. this process goes on as long as modifications occur in the clusters. finally  boundaries are created between sentences belonging to different classes. due to a lack of space  classstruggle cannot be fully described but is nevertheless used for the evaluation of seggen  section 1 .
　according to the definition of text segmentation by salton  salton et al.  1   the internal cohesion of the segments and their semantical proximity with their neighborhood constitute important factors of an efficient segmentation method. but  in the case of a sequential creation of boundaries  these characteristics cannot be computed since  when a boundary is created  the concerned segment is not yet entirely delimited. therefore  sequential methods need to introduce a concept of window in which cohesion measures can be achieved. nevertheless  it is difficult to determine the size of the window: a too short window may lead the algorithm not to consider some cohesion clues and a too long one may take into account some repetitions of terms that should indeed not be associated  since used in different contexts.
　from this second remark  we decided to consider an approach where the boundaries are considered globally. based on an evaluationof the possible segmentationschemes  such a method would have a complete view of the text and would be able to compute coherence without using windows. considering the segmentation problem as a combinatorial problem  seggen is an evolutionary algorithm that evaluates the segmentations of the whole text rather than setting boundaries incrementally. the lack of knowledge on the structure of the text or on the number of segments to create  induces a huge search space and leads us to consider a genetic algorithm to cope with complexity.
1 seggen: a genetic algorithm for text segmentation
inspired by the mechanisms of natural selection and evolution  genetic algorithms  holland  1; goldberg  1  have been successfully applied to the resolution of numerous combinatorial optimization problems. the general principle of genetic algorithms consists in managing a population of individuals  which represents potential configurations of the problem to be solved. genetic algorithms have been used for several text mining purposes  such as document clustering  raghavan and agarwal  1  .
　as mentioned above  text segmentation can be viewed as finding parts of text with strong intrinsic relationships  disconnected from other adjacent parts. therefore  we consider text segmentation as a multi-objective problem with two criteria to optimize: the internal cohesion of the segments and the dissimilarity between adjacent ones. as usual for multiobjective problems  these two criteria are negatively correlated. indeed  the internal cohesion tends to increase with the number of boundaries whereas the dissimilarity between adjacent segments tends to decrease with it. following the multi-objective optimization principles  we consider the objective functions separately in order to allow our algorithm to preserve enough diversity in the search process and to extract good segmentation proposals.
　our seggen algorithm is a variant of the  strength pareto evolutionary algorithm   spea   zitzler  1   an elitist algorithm for multi-objective problems. the method uses an external archive p． to memorize the non-dominated1 individuals w.r.t. both criteria and a current population pt. individuals are selected from these two populations in order to generate new individuals thanks to genetic operators. these new individuals constitute the next pt and are used to update p．. p． constitutes  at the end of the process  a set of potential segmentations of the text. the algorithm has then to extract an unique solution from this set  see section 1 . all documents do not need the same number of generations to reach a satisfactory segmentation. therefore  our stop criterion corresponds to a stagnation of the population evaluation.

figure 1: general functioning of seggen

algorithm 1 pseudo-code of the seggen algorithm

similarities computation and populations initialization; while stop criterion not yet encountered do
　- fitness evaluation of each individual of pt “ p．;
　- selection  crossover  mutation;
　- replacement of pt by the set of new individuals;
　- update of p． w.r.t. the non-dominated individuals; end while
selection of the best individual in p．.

1 problem representation
given a text of ns sentences  the individuals are binary vectors elements xi; xi = 1 indicates that there is a boundary between sentence i and i + 1. for an individual x  we consider two evaluation criteria:  which corresponds to the internal cohesion of its segments  and  which evaluates the dissimilarity between its adjacent segments. our optimization problem consists in approximating the set of optimizers o:
		 1 
　according to this definition  the optimum is not a unique solution but a set of compromises  called the pareto front.
1 initial population generation
initial solutions are randomly and incrementally created but  in orderto start with an heterogeneouspopulation individuals are created w.r.t. the boundaries of others. the size of the population is determined empirically  see section 1 .
　genetic algorithms may converge easier if the individuals of the initial population are closer to the optimum  goldberg  1 . therefore  we tried to insert in the population an individual created by an external segmentation method. experiments w.r.t. this strategy will be described in section 1.
1 fitness function
two criteria are used to evaluate the individuals: internal cohesion and external dissimilarity. both use similarities between sentences computed beforehand. according to the vectorial representation of the sentences  inspiredby the vectorial model  baeza-yates and ribeiro-neto  1   i.e.  a vector of weights w.r.t. the set of meaningful terms   the similarity sim s1 s1  between two sentences s1 and s1 is computed with a cosine measure:
		 1 
where t is the number of meaningful terms  wi sj the
weight of the term i in the sentence sj.
internal cohesion
the internal cohesion of segments can be computed in two different ways by using the sentence similarities. first  it can be seen as the average internal cohesion of segments:
		 1 
　with nbseg being the numberof segments of the individual  segi the segment i of the individual  sumsim segi  the sum of the sentence similarities of segi and nbcouples segi  the number of possible couples of sentences in segi.
　since the distribution of similarities in the text is not likely to be homogeneous  one may probably find very cohesive small areas. in this case  individuals representing small segments would have a really greater chance to obtain a good score of cohesion. a normalization of the score could be performed according to the size of the segments but may induce some bias. therefore  we propose to realize the sum of each cohesion divided by the number of couples:
		 1 
　in presence of long segments  the number of couples is greater than if all the segments have the same size  for example  . therefore  individuals having a lower variance in their segment size will be preferred. however  this bias is limited by the second objective function.
dissimilarity between adjacent segments the similarity of a segment w.r.t. its successor is computed as follows:

　with segi being a segment  sj a sentence  s segi  the set of the sentences of the segment segi and |s segi | the cardinality of this set. this formula allows us to define the computation of the general dissimilarity between adjacent segments in an individual:

　with nbseg being the number of segments ofa segment of this individual.
fitness of the individuals
following zitzler  1   the computationof the fitness value of each individual is realized in two steps. a hardness value h is given to each individual of the external archive p．. this value is computed according to the number of individuals of pt  the current population  that an element slightly dominates on both objective functions:

 1 
　the fitness value of an individualis equal to the inverse of its hardness value:. the fitness value of an individual is computedby summing the hardness scores of individualsdominating y:

　this fitness function  allowing us to select individuals for mutation and crossover  aims to diversify the search  from p． point of view .
1 exploration operators
three operators are used in the evolution process: selection  crossover and mutation  see fig.1 . at each generation  the algorithm select nbindiv individuals and produces nbindiv new individuals to maintain a fixed size of population.
　the individuals are selected from p． and pt according to their fitness value by  roulette wheel   holland  1 . this method first sums all the fitness scores of the individuals. each individual gets a probability of selection equal to their percentage of contribution in this sum.
　among the selected individuals  while the number of nbindiv new individuals has not been reached yet  two parents are randomly chosen in order to produce two new individuals  the offsprings  by crossover. here  we use a classical single point crossover: a position is randomly chosen in the parents and the two corresponding parts of the parents are exchanged to form two children.
　two different mutation operators are applied to these children: a mutation that replaces a parent by a randomly produced individual with a probability pms and a mutation used with a probability pmc that shifts a boundary of the individual to the next or the previous sentence. both mutation operators appear complementary since the first enables to explore new areas while the second refines the existing solutions.
1 extraction of a solution
when the algorithm meets the stop criterion  the archive p． contains a set of potential segmentations. we have then to extract the best individual from this set. this choice can be guided by an aggregation of both objective functions:
		 1 
　the extracted solution is the one having the best score w.r.t. this aggregation function. the coefficient α weights the second objective compared to the first. it acts upon the features of the final segmentation of the text and is thus tuned experimentally in section 1.
1 experiments
1 experimental process
the experiments were carried out on articles from the corpus of texts of the internationalconferencetrec-1  harman  1   which includes full articles from the associated press published between 1 and 1. those articles have been gathered to form differentsets of 1 documents. separations between articles constitute the segmentation of reference. these tests based on concatenated articles may be less conclusive than tests performed on more homogeneous texts but this evaluation seems to be the most commonly used in the literature see for example choi  1   and this kind of boundaries appears to be difficult enough to recognize. according to this principle  four corpuses have thus been created in order to test the behavior of the algorithm with regards to different kinds of text. we note t ns nb  a corpus composed by texts of ns sentences and an average of nb boundaries.we use the corpuses t 1  t 1  t 1  t 1 . the segmentation algorithms are evaluated w.r.t. three criteria: the precision  number of exact boundaries found / number of boundaries found    the recall  number of exact boundaries found / number of boundaries of the reference  and a criterion  called windowdiff  pevzner and hearst  1   which takes into account the number of boundaries between two sentences separated from a distance k.

　where b xi xj  is the number of boundaries between i and j in a segmented text x containing n sentences  ref corresponds to the segmentation of reference and hyp the one found with the method to evaluate. the size k of the window has to be set to half of the average true segment size. this criterion enables to consider the near-misses.
1 parameters tuning
the quality of the population is evaluated with a function eval p．  that returns the score of the best individual in p． w.r.t the aggregation function  section 1 :
		 1 
　a study of different p．  issued from executions of seggen on multiples texts after various numbers of generations  has shown that a weight α = 1 enables the selection of a good individual in the majority of cases. the following tests will use this value.
　in order to adjust the probabilities of mutation pms and pmc  seggen has been ran for each couple of  pms pmc  between  1  and  1   using a step of 1 for each. these experiments have been carried out on the set of 1 documents of the corpus t 1   1 times each in order to limit random variations. the number of individuals in the population is set to 1  value which appears to provide good results. results of figure 1 are averages of the population evaluation function eval p．  on these multiple executions.
 1
 1
 1  1
figure 1: evolution of eval w.r.t. pms pmc
　the figure 1 shows the evolution of eval p．  according to some different combinations of mutation probabilities1. we may first notice the influence of both mutation operatorssince the curves that corresponds to a single mutation operator are the lowest. the couple pms = 1 and pmc = 1 seems to be the best compromise.
　a study on the number of individuals nbindiv has shown that values greater than 1 allow the algorithm to converge more quickly in term of generations but induce a greater computation cost in term of evaluation. for instance  on the corpus t 1   with nbindiv = 1  the algorithm needs only 1 generations to reach the score of evaluation of 1 against 1 with 1 individuals. however  the number of generated individuals is greater  1 〜 1   1 〜 1 . on the other hand  a lower number of individuals leads to the opposite problem  the number of generations is too high  which implies a loss of time.
　concerning the stop criterion  long texts may need more time to be segmented but the quality of segmentation can be the same than for shorter ones. a value of 1 iterations without any improvement seems to be sufficient enough to reach a good solution.

figure 1: results of experiments on α
　concerning the value of the α parameter used in the aggregation function in order to extract a good individual from p．  we have to remark that the first objective function c favorizes individuals that generate a lot of boundaries  small segments having more chances to be cohesive. at the contrary  the second objective function d is in favor of individuals having few boundaries  since long segments have more chances to own sentences faraway the following. the parameter α has thus an influence on the number of detected boundaries  figure 1 . the best results according to windowdiff are obtained around α = 1. nevertheless  an higher value enables to obtain a better precision and a lower a better recall. this value may be set between 1 and 1 w.r.t. the frequency of the required segmentation.
1 evaluation
1 experimental process
in order to evaluate the methods  we use benchmarks created similarly to those described in section 1. of course  in order not to skew the results  the selected articles are different from those used for tuning purposes. seggen has been compared to the following methods to evaluate its efficiency:
  tt: texttiling1  hearst  1  is based on the distribution of the terms in the text  according to several criteria  number of common words  new words  active chains .
  c1: c1  choi  1   which seems to be the most efficient existing approach  uses a  local ranking  by determining  for each pair of textual units  the number of surrounding pairs having a lower similarity.
  cs: classstruggle  mentioned in section 1  is based on a clustering process to segment the texts.
　as mentioned in section 1  we tried to improve the initial population by inserting a good solution. therefore  two versions of the algorithm  s1 and sc1  have been evaluated. in sc1  a segmentation scheme  computed by c1  has been inserted in the initial population. both use a coefficientα = 1  see section 1 .
　since seggen uses stochastic parameters in mutation and crossover  the range of error has been evaluated by computing the standard deviations  on ten executions  of the average of scores obtained on each corpus. standard deviation of windowdiff is located around 1  of recall around 1 and of precision around 1. these values are really low w.r.t. the ranges of scores given in table 1.
1 results
according to results given in table 1  classstruggle  having a more complete view of the relations of the sentences thanks to the use of a clustering process  is globally more efficient than c1 and texttiling. however  its incremental process reduces its ability to take into account the segment cohesion and the similarity between adjacent segments. seggen overrides this problem and obtains really better results for all accuracy criteria  especially on corpuses that do not have a lot of boundaries to retrieve  i.e. t 1  and t 1  . texttiling and c1 seem to have difficulties to adapt themselves w.r.t the number of boundaries to retrieve  the length of the text has a great impact on their number of detected boundaries. seggen seems to better follow these variations.
　however  on corpora that have a lot of boundaries to retrieve  i.e. t 1  and t 1   seggen seems to have difficulties to product individuals sufficiently segmented. this is due to the fact that good individuals with a lot of boundaries are more difficult to find than others. the insertion of a good individual in the initial population  sc1   obtained by c1  seems to solve this problem. c1  providing segmentations with a lot of boundaries  helps seggen to find solutions when the search space is huge.
　additionally  a student t-test1 has shown that these differences are really significant with a 1% confidence rate  all of the values being higher than the p-value 1.
windifft 1 t 1 t 1 t 1 μσμσμσμσtt11111111c1.1.1.1.1.1.1.1.1cs11111111s1.1.1.1.1.1.1.1.1sc1.1.1.1.1.1.1.1.1recallt 1 t 1 t 1 t 1 μσμσμσμσtt11111111c1.1.1.1.1.1.1.1.1cs11111111s1.1.1.1.1.1.1.1.1sc1.1.1.1.1.1.1.1.1prec.t 1 t 1 t 1 t 1 μσμσμσμσtt11111111c1.1.1.1.1.1.1.1.1cs11111111s1.1.1.1.1.1.1.1.1sc1.1.1.1.1.1.1.1.1nb.t 1 t 1 t 1 t 1 μσμσμσμσtt11111111c1.1.1.1.1.1.1.1.1cs11111111s1.1.1.1.1.1.1.1.1sc1.1.1.1.1.1.1.1.1table 1: averages  μ  and standard deviations between documents  σ  of windowdiff  windiff   recall  precision  prec.  and number of detected boundaries  nb.  for each tested method on each corpus.
1 conclusion
the experiments have shown that our approach appears to realize a really more accurate segmentation of the texts than existing incremental methods. moreover  seggen seems to adapt itself much better than other methods according to the number of boundaries to retrieve.
　nevertheless  the fitness function can be improved  in particular by a more sophisticated calculus of similarity  overpassing the sole repetitions of words. finally  seggen will be at term integrated as a preliminary step in an ongoing project of information retrieval that aims to furnish composite documents as responses to user's queries.
acknowledgments
this work was supported by  angers loire metropole .
