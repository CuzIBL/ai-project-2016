
the paper analyzes the extension of frontier search to the multiobjective framework. a frontier multiobjective a* search algorithm is developed  some formal properties are presented  and its performance is compared to those of other multiobjective search algorithms. the new algorithm is adequate for both monotone and non-monotone heuristics.
1 introduction
systematic graph search proceduresare usually classified into best-first search and depth-first search strategies. the former can take advantage of the so-called principle of optimality to prune paths that could never lead to solutions better than those already recorded. dijkstra's algorithm and a*  hart et al.  1  are members of this class. pruning may drastically reduce the number of paths explored in the graph but memory requirements are usually exponential with solution depth. depth-first search presents the advantage of memory requirements linear with the depth of the solution. however in certain cases these algorithms may involve the consideration of an exponentially larger set of paths when compared to best-first algorithms. algorithms like ida*  korf  1   and rbfs  korf  1  are members of this class. several attempts have been carried out to retain the benefits of path pruning while keeping reasonable memory requirements. frontier search  korf et al.  1  has been recently reported as a successful approach in this sense.
　multiobjective search is known to be much more computationally demanding than its scalar counterpart. particularly  memory requirements are one of the practical limiting factors of multiobjective best-first search in ai applications. applications in route planning  alechina and logan  1  and domain independent planning  refanidis and vlahavas  1  have reported queue size as a limiting factor and resorted to various schemes to limit the numberof generated alternatives.
　multiobjective best-first search algorithms include two different extensions of a* to the multiobjective case  moa*  stewart and white  1   and namoa*  mandow and pe＞rez de la cruz  1 . multiobjective depth-first algorithms include idmoa*  harikumar and kumar  1   and moma*1  dasgupta et al.  1   the multiobjective extensions of ida* and rbfs respectively.
　this paper analyzes the extension of frontier search to the multiobjective framework. scalar frontier search exploits the monotone property of heuristics to discard unnecessary nodes  achieving important memory savings. however  as explained in the paper  the same node deletion criteria cannot be applied in a multiobjective context. this paper presents new deletion criteria that can be applied in broader contexts while preserving the properties of conventional algorithms.
　the paper is organized as follows. section 1 describes scalar frontier search. section 1 examines the fundamental issues in multiobjective search and introduces a frontier multiobjectivea* search algorithm. formal propertiesand experimental results are presented in sections 1 and 1 respectively. finally  some conclusions and future work are outlined.
1 scalar frontier search
the shortest path problem can be stated as follows: let g be a locally finite labeled directed graph g =  n a c   of
|n| nodes  and |a| arcs  labeled with positive costs
. given a start node s （ n  and a set of goal nodes Γ   n  find the minimum cost path in g from s to a node in Γ.
　scalar best-first algorithms like a* build a search tree t rooted at the start node with the best paths found to each generated node. nodes already expanded are kept in a list of closed nodes  and those that are waiting for expansion are kept in a list of open nodes. keeping the closed list makes memory requirements exponential with solution depth. however  these nodes serve two important purposes. firstly  whenever a new path is found to a known node  its cost is compared to that of the path in the search tree. the best path is kept and the other is pruned. this can drastically reduce the number of paths in g that need to be explicitly explored. the second important use of closed nodes is to return the solution path. when a goal node is reached  the solution path can be quickly recovered from the search tree.
　a* uses a characteristic evaluation functionf n  = g n + h n  to rank open nodes and always selects for expansion nodes with minimum f n . function g n  denotes the cost of the path stored in the search tree from s to n  while the heuristic function h n  estimates the cost of a solution from node n to a goal node. when h n  satisfies the so-called monotone property  i.e.
		 1 
then for all node n selected for expansion an optimal path to n has already been found in t. the use of monotone heuristics optimizes and simplifies path pruning: new paths found to closed nodes can be pruned straightaway  since no closed node will ever be put back into open.
　in the following discussion on frontier search we shall make the following assumptions:
1. we are only interested in the cost of the optimal solution or in which goal node is reached by an optimal solution  but not in the optimal solution path itself.
1. the graph g to be searched is undirected  i.e. for each arc  in g  there is also an arc .
1. heuristic functions are monotone.
　under these assumptions frontier search keeps the benefits of path pruning while drastically reducing memory requirements. the key idea is to store in memory only the open list  but not the closed list of expanded nodes.
　frontier search keeps a vector of used operators with each node n. each vector element indicates whether the neighboring node n reached via that operator is still accessible or not through node n. initially  all vector elements are set to 'unused'. each time a node is expanded  only successors reachable by unused operators are generated. recall that whenever a node n is selected for expansion  an optimal path to that node has been found. this means no new interesting paths to n will ever be generated and n will never again need to be put back into open. therefore  for each generated neighbouring node n  the operator that reaches n form n can be marked as used. this amounts to pruning all new paths that might reach n from n even before they are actually generated. since n will never again be reached by new paths  it can be safely removed from memory.
　assumptions 1 and 1 presented for this basic frontier search algorithm can be relaxed to make it a more general search strategy  korf et al.  1 . however  assumption 1 cannot be relaxed without compromising the admissibility of frontier search. with a monotone heuristic  and the same tie-breaking rule  the basic frontier search algorithm can be shown to mimic the sequence of node expansions performed by standard best-first search. therefore  it is admissible under the same assumptions.
1 multiobjective frontier search
1 multiobjective a* search
the multiobjective search problem can be stated as follows: let g be a locally finite labeled directed graph g = nodes  and |a| arcs  labeled with pos-
. given a start node s （ n  and
a set of goal nodes Γ   n  find the set of all non-dominated cost paths in g from s to nodes in Γ.
　the main distinguishing feature of multiobjective problems is the fact that cost vectors induce only a partial order preference relation   called dominance 

where fi denotes the i-th element of vector
　therefore  given two vectors  it is not always possible to rank one as better than the other. for example given vectors  anddominates both  but no dominance relation exists between vectors
　given a set of vectors x  we shall define nondom x  the set of non-dominated vectors in set x in the following way 
		 1 
　we shall use namoa*  mandow and pe＞rez de la cruz  1  as reference in the development of a frontier multiobjective a* algorithm. it is a refinement of moa*  stewart and white  1  that offers better memory behaviour. namoa* builds an acyclic search graph sg rooted at s to store all nondominated paths found to each node. whenever a new path is found to a known node n  its cost is compared to those already reaching n. nondominated paths are kept  and dominated ones are pruned. namoa* keeps two different sets associated to each node. gop n  denotes the set of cost vectors of paths reaching n that can be further explored  while gcl n  denotes the set of those that have already been expanded. the set of open paths in sg that can be further explored is made up of all tuples  where.
   namoa* uses a heuristic function h n  that estimates the set of nondominated cost vectors of paths from n to each goal node. therefore  each path psn from s to n with cost   has a set of heuristic evaluation vectors  f psn . in a* 
　namoa* always selects for expansion an open path p with at least an heuristic evaluation vector f nondominated in open. two sets  goaln and costs  keep track of goal nodes and costs of nodominated solutions found so far. each time a new solution is found  dominated alternatives are filtered from open and search proceeds until open is empty.
　in multiobjective search many different nondominated paths may reach a given node. therefore  it is the number of cost vectors stored in gop n  and gcl n  that dominates memory requirements  while the number of nodes plays only a minor role. regrettably  the expansion of a nondominated path to node n does not prevent other nondominated paths to enter gop n  at later stages of the search  even when monotone heuristics are used  stewart and white  1  lemma 1 . note that even vector costs of expanded paths cannot be discarded after expansion without further consideration. they need to be kept in the gcl n  sets to prune new dominated paths reaching already expandednodes. this preventsa trivial extension of scalar frontier search to the multiobjective case. determining whether all nondominated paths to a given node have already been found becomes then the central issue.
1 frontier search namoa*
the extension of frontier search to multiobjective search is presented under the same assumptions presented in section 1 for its scalar counterpart. the key is to find an adequate criterion to allow nodes and cost vectors of expanded paths to be safely deleted from memory. as previously explained  this is not completely straightforward  since monotonicity does not providethe same properties as in scalar search. the algorithm presented in table 1 is based in the following proposals.
　let us denote by g n  = gop n  “ gcl n  the set of all nondominated cost vectors known to n  and by frontier the set of known nodes that cannot be deleted from memory yet. each node in frontier will store a vector of 'used operators'  a deletion flag  and an 'at least once expanded' flag.
　candidates for deletion a node n is a candidate for deletion when no more nondominated paths can be found to
	.
　marking used operators if node n is candidate for deletion and at least one path leading to n was expanded  then the operators of its successors leading to n can be marked as 'used'. this amounts to pruning any new paths leading to n even before they are actually generated. node deletion if node n is candidate for deletion and gop n  =    then n can be actually deleted from memory.
　these conditions are checked at each iteration at step 1. note that new nodes generated by the algorithm must be put in the frontier even if they are not reached by an interesting alternative  i.e. the newly found path is dominated by costs  step 1 b i . these nodes would be typically discarded in moa* or namoa* until a really interesting path was found to them  but need to be kept in frontier search in case some of their operators have to be marked as 'used'.
　these conditions are rather severe. however  the most important condition in multiobjective frontier search involves cost vector deletion  since it is the number of cost vectors stored in memory that dominates memory consumption.
　cost vector deletion when a node n is marked for deletion  then the set gcl n  can be immediately removed from memory  step 1 a i . additionally  each time a new path to n is selected for expansion  its cost vector can be removed from gop n  and discarded  step 1b .
　the rationale behind this condition is that costs in gcl n  are kept to prune new dominated paths found to n. however  once a node n is marked for deletion  neighbouring nodes will mark their operators and no new path will ever reach n. notice that  by virtue of this condition  a node marked for deletion can get rid of some its cost vectors well before the node itself is actually deleted.
1 example
figure 1 a  shows a sample graph with multiobjective costs. let us assume s is the start node  Γ = {γ1 γ1}  and  without loss of generality  that no heuristic function is used  i.e.
  and the heuristic evaluation vector of each
. in this example we focus our
attention in the criteria for path and node deletion  and these involve only real cost vectors. heuristic evaluation vectors are involved in the selection of open paths for expansion and  in this sense  fs-namoa* does not perform differently from namoa*.
　initially  s is the only node in open and frontier with gop s  = { 1 }. it is selected for expansion and paths
1. initialization. create a set of nodes frontier = {s}  and set gop s  = {1}.
let open be the list of all pairs  such that
. create two empty
sets  goaln  costs.
1. termination. if open is empty  then return the set of goal nodes goaln and nondominated costs costs.
1. path selection.
 a  select an alternative  from open with heuristic evaluation non-dominated in open and not dominated by costs.
 b  if n is marked for deletion  then remove gn from gop n   else move gn from gop n  to gcl n .
1. solution recording. if n （ Γ  then put n in
  and eliminate from open
all dominated alternatives.
1. path expansion: if  then
 for all successors nodes m of n with cost  do:
 a  calculate fm the set of estimates for the new path  not dominated by costs.
 b  if m is a new node  then 
i. put m in frontier. ii. ifthen place. else  ifgm is new and nondominatedin g m   then: i. prune from g m  vectors dominated by gm. ii. ifthen place.
1. update frontier: for all node n in frontier do 
 a  if n was at least once expanded  and n is not marked for deletion  and n is a candidate for deletion  then
i. mark n for deletion and delete gcl n .
ii. for all successor  mark the operatoras 'used'.
 b  if n is marked for deletion and gop n  =    then remove n from frontier.
1. go back to step 1
table 1: fs-namoa*  a frontier multiobjective search algorithm.
to n1 and n1 are generated  setting gop n1  = { 1 } and gop n1  = { 1 }. since  1  dominates both open vectors  s is candidate for deletion and gcl s  deleted. since gop s  =    s is in fact deleted from memory  and the corresponding operators in n1 and n1 marked as 'used'. figure 1  b  shows a trace of fs-namoa* on this example  including nodes in frontier  and a graph showing the state of known paths at each iteration. each path  is represented by its cost in cost space  〜 《 deleted;   《 open;   《 closed  and labeled by its destination node n. this way the state of paths and the values of the gop and gcl sets can be easily told.
　assuming ties between nondominated paths are broken arbitrarily  at iteration 1 path  n1  1   is selected for expansion. new paths to n1 and n1 are generated. however  n1 is not a candidate for deletion  since a new nondominated path might still reach n1 from n1 or some of its descendants. therefore  the closed path must remain in memory  i.e. gcl n1  = { 1 }. at iteration 1 the only nondominated path to n1 is selected  n1 is candidate for deletion and  in fact  deleted  marking the corresponding operators as 'used' in n1 and n1. notice that no new nondominated path can ever reach n1 since the cost of the closed path to n1 now dominates the cost of all other open paths. node n1 becomes candidate for deletion and is deleted. the two cost vectors of paths leading to n1 dominate all other open paths. therefore  n1 is candidate for deletion. however it has never been expanded and must remain in memory. at iteration 1 a path to n1 is selected for expansion and deleted from memory. at iteration 1 the other path to n1 is selected and deleted  and the whole node can be deleted as well. at iteration 1 only the paths to γ1 are nondominated. path  γ1  1   could be selected. since it is a solution path  it would be recorded in costs and goaln. all open paths dominated by  1  would be filtered  i.e. removed from open. at iteration 1  γ1  1   would be the only remaining open path  selected  and recorded as solution. the algorithm would then terminate with the guarantee that node γ1 is reached by nondominated solutions with costs in   1   1  .
1 properties
this section provesthat each run of fs-namoa* mimics the workings of namoa*. therefore  the algorithm terminates with the same sets of nondominated costs and goal nodes.
result 1 if costs are positive and n is marked for deletion  then all nondominated paths to n have been generated.
proof. the proof is trivial from the definition of 'candidate for deletion'. let's assume n is marked at iteration k. if a new node reaches n at future iterations  it must be some extension of an alternative  open at iteration k. letbe the cost of such extension. however  if n is marked  then .
　result 1 replaces the monotonicity requirement of heuristics in scalar frontier search with a monotonicity requirement for the real cost function . the following results are analogous to those presented in  korf et al.  1 .
result 1 fs-namoa* never regenerates a node that has been deleted.

it.frontierpaths11111 a  sample problem for fs-namoa*.
 b  frontier nodes and paths in cost space
. symbol  denotes 'used operator'  dashed nodes are deleted.
figure 1: sample problem and solution.
proof. let us assume  for the purpose of contradiction  that n is the first such node to be regenerated after a new path is found from some other nodewas deleted  then: a  n was candidate for deletion  b  n was at least once expanded  c  was deleted before n  then n must have been regenerated in order to be expanded again regenerating n. however  this contradicts the assumption that n was the first node to be regenerated. then  it must be that n was never deleted. since n was at least once expanded  n must have been in frontier  recall the graph is undirected  when n was marked for deletion  and the operator from n to n marked as 'used'. therefore  no path leading to n and selected for expansion will ever regenerate n  contradicting the assumption that n is regenerated.
result 1 with the same tie-breaking rule  fs-namoa* expands the same nodes in the same order as namoa*.
proof. we shall prove by induction the stronger result that  after each iteration  the set of open alternatives is the same for both algorithms. the proposition is true at iteration 1  when  is the only open alternative. let us assume that both algorithms selected the same paths up to iteration k  and that both have exactly the same set of open alternatives. since both algorithms share the tie-breaking rule  they will select the same open alternative  for expansion.
　the following scenarios are possible for namoa* for each succesor m reached by cost vector
1. m （ Γ. all open alternatives dominated bygm are eliminated.
1. . the set fm of estimates of new paths to m not dominated by costs is calculated. in case: a  m is a new node. if  then m is put in the search graph and gm in gop m ; b  m is known and .
no changes are made to gop m  nor gcl m ; c  m is known and. dominated vectors are eliminated from  then gm is put in gop m .
　fs-namoa* would behave the same in situations 1 and 1c. in situation 1a the new node will be unconditionally placed in frontier  but the new open alternative would be added under the same condition. finally  situation 1b is ignored by fs-namoa*  but results in no change in the set of open alternatives. in summary  both algorithms will perform the same changes in the set of open alternatives. since both algorithms terminate when the set of open alternatives is empty  they will performthe same sequence of path selections and expansions.
　results 1 and 1 do not require the heuristic function to be monotone. this means fs-namoa* mimics namoa* even when non-monotone heuristics are used. note that a single-objective version of fs-namoa* amounts to a version of frontier search a* that finds all optimal solutions with general heuristics. nodes selected for expansion would be deleted only when they achieve the minimum value of g n  among open nodes. this ensures the optimal path to deleted nodes has been found.
table 1: summary of test results.
algorithmaverageσminmaxfs-namoa*
cost vectors111time  s 111fs-namoa*1
cost vectors111time  s 111fs-namoa1
cost vectors111time  s 111fs-namo1
cost vectors111time  s 111namoa*
cost vectors111time  s 111moa*
cost vectors111time  s 1111 experimental tests
a set of 1 experimental tests were carried out in different square grids of nodes of size 1〜 1 with random costs in  1  and two objectives. grid distance was used as heuristic for all objectives. the tests reported in this section compare the performance of fs-namoa* against other standard multiobjective search algorithms and are intentionally of relatively small size.
　figures 1  a  and  b  show the performance of moa*  namoa*  and fs-namoa* in memory and time  the latter including idmoa*  against problem difficulty. the number of iterations  i.e. paths considered  by namoa* was taken as a measure of problem difficulty. note that the x-axis in figure 1  b  is in logarithmic scale to allow comparison to idmoa*. statistics are summarized in table 1.
　moa* and namoa* require storage for 1% and 1% of the cost vectors needed by fs-namoa* respectively. moa* was the fastest on average  though the speed of moa* and namoa* is barely distinguishable at this scale. the extra 'update frontier' step in fs-namoa* places a heavy time overhead. however the time requiredby the algorithmis well below the exponential time requirements of the linear space algorithm idmoa*. in fact  this algorithm could solve only the simplest problems in less than 1 minutes. this overhead can be significantly reduced delaying frontier updates. if updates were performed evey k iterations  the overhead could be reduced by 1/k. if the maximum branching factor of the problem is b  this will increment the memory requirements by at most kb cost vectors  which is normally a tiny fraction of the maximum memory usage. figure 1 c  and table 1 show the time requirements for k = 1 and 1 with only a 1% increase in average memory requirements over plain fs-namoa  labeled fs-namoa-1  1 and 1 respectively . this suggests that only a few updates are responsible for most of the memory savings  with additional updates becoming increasingly less cost-effective.

1	1	1	1	1
               problem difficulty  number of iterations in namoa*  1 x 1  a  memory requirements  cost vectors .

1	1	1 problem difficulty  number of iterations in namoa*   log scale  b  time requirements.

1	1	1	1	1
problem difficulty  number of iterations in namoa* 	1 x 1
 c  timings of fs-namoa with delayed updates.
figure 1: memory and time requirements.
1 conclusions and future work
the paper considers the extension of frontier search to the multiobjective framework. regrettably  the use of monotone heuristics does not allow a trivial extension of scalar frontier search to the multiobjective case. the determination of safe criteria for the deletion of expanded nodes and cost vectors turns out to be the fundamental issue in this extension. a set of such criteria have been proposed and proven to preserve the admissibility of multiobjective search even when non-monotoneheuristics are used. experimental results show that memory savings are significative enough to make them an interesting alternative. the time overhead of the deletion criteria can be greatly reduced with minimum loss in memory savings. therefore  multiobjective frontier search fills a gap between existing best-first and depth-first strategies in their memory-time tradeoff.
　future work includes more formal development of the algorithm  and the necessary extensions to make it a more general search strategy. a comparison of all existing multiobjective search strategies over a representative set of problem domains is also an important future work.
