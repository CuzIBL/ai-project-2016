 
　the parsing problem for arbitrary unification grammars is unsolvable we present a class of unification grammars for whcih the parsing problem is solvable and a parallel parsing algorithm for this class of grammars 
1. introduction 
　unification grammars have the power of a turing machine  and one can easily prove this by showing that a unification grammar can simulate any prolog program it follows that the problem of finding all possible parses of a sentence in a given unification grammar is unsolvable the best we can do is an algorithm that sometimes finds a set of parses and sometimes goes into an infinite loop the top-down  left-to-right parser used with definite clause grammars is of this kind - if the grammar contains left recursion the parser may run forever if we want to write a parallel parsing algorithm for unification grammar  we first need to find a subset of unification grammar for which the parsing problem is solvable indeed this is the hard part of the problem we shall see that once we have a parsing algorithm  finding the parallelism is straightforward 
	part 	1 	reviews the algorithm of cocke. kasami and 
younger for parsing context-free grammars in chomsky normal form this algorithm is beautifully simple and easily extends to a parsing algorithm for unification grammars in chomsky normal form therefore the parsing problem is solvable for unification grammars in chomsky normal form unfortunately this subset of unification grammar is too restricted to describe human language part 1 therefore considers an extension of chomsky normal form which allows chain rules - rules having one non-terminal symbol on the right side we generalize the cky algorithm to handle context-free grammars with chain rules  and extend this algorithm to unification grammars. the extension works only if one places a restriction on the use of chain rules in a unification grammar  and that restriction is one main point of the paper once we have the parsing algorithm for unification grammars with chain rules  we can easily extend it to unification grammars with any number of symbols on the right side of a rule finally we consider the possibilities of parallelism in the new parsing algorithm 
1. parsing in choaaky normal form 
　a context-free grammar in chomsky normal form contains two kinds of rules. terminal rules have a 
　single terminal on the right side  branching rules have exactly two non-terminal symbols on the right side since no rule has an empty right side  no symbol can generate the empty string we use the capital letters a.b.c as variables ranging over non-terminal symbols to describe the substrings of an input sentence we number the spaces between words - 1 is the space before the first word and n is the space after the n-th word if i   j. input i j  is the string of words between space i and space j the cky algorithm builds a matrix m such that 

strictly speaking this is a recognizer not a parser  but it is easily extended to a parser  and the same is true for the other algorithms in this paper 
　if si and s1 are sets of non-terminal symbols define the product of si and s1. si * s1  by 

the following lemma shows why this product is useful 
　basic parsing lemma suppose that i  . k and for all j such that i  ; j   k  m i j  = j a | a =   input i j  { and m j k  = | a | a =   input j k  j then for all a. a =   inputji k  iff a is in m i j    m j k  for some j with i   j   k 
all proofs are omitted for lfack of space 
　if i   j   k  m i j  and m j k  are shorter than m i k  thus the basic parsing lemma allows us to find all possible parses of input i k   given all possible parses for strings shorter than input i k  this is the key to writing parsing algorithms that are guaranteed to halt 
　the cky algorithm has two parts first the algorithm finds all possible parses for strings of length 1  using the terminal rules next it considers strings longer than 1 in order of length  it finds all possible parses for input i k  by applying the basic parsing lemma for all choices of j 
　here is a version of the cky algorithm for a sentence of length n 
ai go r i t h n 1 . 
for i from e to  n - 1  do 
	m i 	i+1  	:-
　　　| a |  a -  input i i+1   it o rul  |; for l :- 1 to n do 
	for o i l 	i.k such that 	i -f l   k do 
	m i k  	 - union 	m   	j    m j k  
i   j   k 
theorem 1  correctness of cky   when the cky algorithm halts  m i k  = |a | a =   ' inputfi k { 
　we turn to unification grammar consider a firstorder language with a simple type system each variable and function letter is assigned a type  and each argument position of each function letter is assigned a 
	haas 	1 
type a tern is well-formed if every argument of each function letter has the correct type for its position we use the capital letters x.y.z.w. sometimes with prime marks  as variables ranging over well-formed terras of a unification grammar a unification grammar is a 
finite set of rules of the form  x -  yl yn . where x is a well-formed term and yl through yn are either terms or terminal symbols if g is a unification grammar  the ground grammar g derived from g is the set of well-formed ground instances of rules in g to define the language generated by a ground grammar we use the standard definition of the language generated by a context-free grammar  assuming that the start symbol is always s. it is possible that the ground grammar is infinite  and therefore is not a contextfree grammar. this does not create a problem  because the definition of the language generated by a contextfree grammar does not rely on the fimteness of the grammar in any way. finally we define the language generated by a unification grammar g to be the language generated by the ground grammar derived from g. 
　consider a trivial example let the type person contain the variable p and the constants 1st  1nd and 1rd let the type number contain the variable n and the constants singular and plural suppose np and vp are function letters with two arguments  a person and a number then the rule 

says that a sentence may consist of a noun phrase and a verb phrase that agree in person and number this rule has 1 ground instances  as follows 

in this case the ground grammar is finite  so this rule is only an abbreviation for a context-free grammar it appears that most of the syntax of natural language is context-free  therefore unification grammars with finite ground grammars have almost the formal power needed to describe natural language still there are constructions that cannot be described by context-free grammar the crossed serial dependencies in dutch and swiss german are examples  bresnan 1  we can describe these constructions using a unification grammar whose ground grammar is infinite as an illustration of the technique we give a grammar for the language  atn  btn  ctn . which no context-free grammar can generate. the function letters a  b and c each take a single argument of type integer. the variable n. the function letter s  for  successor   and the constant 1 are of type integer  s takes a single argument of type integer the rules are 

 a n  represents a string of n as   b n  a string of n b's  and  c n  a string of n c'j the first rule says that a sentence consists of n as  n b's  and n c's 
　it is important to understand that our parsing algorithm does not construct the ground grammar  nor does it construct the set of ground non-terminals that generate input i k  instead it represents sets of ground non-terminals indirectly. if si is a set of terms 
1 	natural language 
in a unification grammar  let  ground s i ; be the set of ground instances of terms in si the parser sets m i k  to a set of terms so that  ground m i k     | a | a =   input i k  |. 
　a unification grammar in chomsky normal form has two kinds of rules terminal rules have a single terminal symbol on the right side  branching rules have two well-formed terms on the right side. unification is defined for pairs of terms as well as individual terms the most general unifier of  x y  and  x y  is the most general substitution that unifies x with x' and y with y . as usual it is neccesary to rename variables before unifying. for this purpose assume that for any term x and integer n   rename x n  is an alphabetic variant of x  and if m is not equal to n then  rename x n  and  rename y m  have no variables in common note that renaming a term or rule does not change its set of ground instances. for this reason we use the term  rule  for any alphabetic variant of a rule in g 
　if si and s1 are sets of terms in a unification grammar  the product of si and s1  si  ' s1  is defined as follows. 

i 
loosely speaking  this product is like the product used in the cky algorithm except that instead of testing symbols for equality  it makes the symbols equal by substitution - if possible 
　unification parsing lemma suppose that i   k and for all j such that i   j   k   ground m i j   = | a | a =    input i j  j  and  ground m j k   = j a i a =    input j k  j. then a =   input i k  iff for some j such that l   j   k. a is in  ground m i j   ' m j k   
　the parser for unification grammars in chomsky normal form is then as follows 

theorem. when the unification parser halts   ground m  k   ＊ |a | a -  mputfi k j. 
　unification grammars in chomsky normal form are more powerful than context-free grammars  they can generate languages that no context-free grammar can generate  and they can capture generalizations that cannot be captured with context-free grammars despite this difference in the power of the two formalisms  one can parse these unification grammars using a very straightforward generalization of the cky algorithm. this is a good example of the power and simplicity of unification. 
1. parting with chain rules 
　unfortunately one cannot describe natural language syntax with a unification grammar in chomsky normal form. for example  any intransitive verb can form a sentence by itself -  run!  and  stop!  are such sentences. if we restrict ourselves to grammars in chomsky normal form we must have a rule for each of these sentences -  s -  run    s -  stop   and so on. the rule we really want is something like  s -   vp  1nd  .n   - a verb phrase that agrees with a second 

person subject can form a sentence by itself as a 
second example  many theories hold that in  who did mary like 1   there is a trace after  like  - a noun phrase with no words under it  np -    is not allowed in chomsky normal form we therefore consider the problem of parsing a unification grammar that allows chain rules - rules with exactly one non-terminal on the right side the solution of this problem includes the essential ideas needed to parse grammars with any number of symbols on the right sides of their rules 
　let us first consider the context-free case how can we parse a grammar that allows chain rules  branching rules  and terminal rules1 we stressed above that the basic parsing lemma is useful because it allows us to find all possible parses of a substring if we are given all possible parses of shorter substrings this allows us to look at substrings in order of length  knowing that at each stage we have the information we need the chain rule  a -  b  tells us that if b = * input i k   so does a input i k  is not shorter than itself  so we could repeat this process indefinitely without ever getting to a longer substring then what guarantees termination 1 
　in the case of context-free grammar  we can easily build a table of all pairs  a b  such that a =   b this table is finite because the set of non-terminals is finite define  close s  to be the set of all n o n terminals a such that a -  b for some b in s since a =  * a   close s  contains s 
　second parsing lemma let g be a context-free grammar containing only terminal rules  branching rules  and chain rules suppose that 1  . k and for all j such that i   j   k. m i j  =-   a | a = * input i j  { and m j k  = { a | a =  . input j k  j then for all a  a 
　=  * input i k  iff a is in  close m i j  * m j k   for some j with 1   j   k 
　using this observation we extend the cky algorithm to handle grammars with chain rules 
aigor i thro 1. 
context-free porter with chain toble 
for i froro 1 to  n - 1  do 
       m i i + 1       close input i i+1  . for l   1 to n do 
	for a l l 	i.k such thot 	i + l ＊ k do 
m i k  :- union  close m i j  * m j k   i   j   k 
theorem 1 suppose the grammar g contains only terminal rules  branching rules and chain rules after algorithm 1 halts  m i k  =  a | a = . input i k   
　if one tries to generalize this algorithm to unification grammars with chain rules  a serious problem appears the argument above relies crucially on the finite number of non-terminals in the context-free grammar a unification grammar may generate an infinite ground grammar  so the chain table for a unification grammar might be infinite for example  suppose  f x  -   f  f 
.x   is a rule then the sequence  f x  -   f  f x   -   f  f  f x    is an infinite derivation using only chain rules we propose a straightforward solution  we require that for every unification grammar g there is an integer n such that every chain derivation in g is shorter than n 
　does this restriction stop us from describing natural languages1 we claim the answer is no this claim is based on experience - we have written a grammar that is not trivial and contains no chain longer than 1 if this restriction holds  a simple algorithm will generate a chain table for a unification grammar that is. it will generate a finite set c of pairs of terms such that a =  * b in the ground grammar iff  a b  is in  ground c  
the method is to construct a series of sets c k  such that  ground c k        a b  i a =    b in exactly k steps | clearly c l  is the set of pairs  x y  such that 
 x -  y  is a rule if we can construct c k+1  from c k   we can build the chain table by constructing c k  for successive values of k until we find a c k  that is empty if the grammar contains unbounded chains this algorithm will run forever  and it is up to the grammar writer to fix this in practice this is not likely to be a problem in any case it is better than having the parser go into an infinite loop - which can happen with the depth-first  left-to-right parser used with definite clause grammars 
　in order to construct c k  from c k+1  we define a new product let si and s1 be sets of pairs of terms define 
s1    s1 -
i  ＊  * z   |  exist  x y  in  renome s1 . 
　　　　 y* z  in  renome s1   . s is the most generol u n i f i e r of y and y'  
i 
lemma  ground si *  s1  = { a b  |  exist c  a c  is in  ground si  and  c b  is in  ground s1  { 
　lemma if  ground c k   = j a b | a = * b in exactly k steps!  then c k     | x y  |  x -  y  is a rulej = } a b  | a =   b in exactly k + 1 steps| 
　in order to extend our second context-free parser to a unification parser  we now define 
 close* s  ＊ 
   s x  |  x y  is in  renome choin 1   y* is in  rename s 1   and s is the mgu of y and y' |. 
we then rewrite the parser by adding  close   just as we did for the cky algorithm algorithm 1 
for i f rom 1 to  n - 1  do 
m i 	i+1  	-
　 close*   x |  x -  input i i+1   is a rule |   . for l : - 1 to n do 
for a l l i.k such that i + l - k do m i k  union  close* m i j   ' m j k   
i   j   k 
once again  the proof of soundness and completeness requires only a proof for the corresponding contextfree algorithm along with the basic properties of 
unification 
　the parser that was actually implemented allows any number of symbols on the right side of a rule. in order to handle rules with an empty right side  we must make another restriction similar to the first one for every grammar g there is an integer n such that every derivation of the empty string in g is shorter than n. in order to handle rules with more than two symbols on the right side  we use dotted rules as described in  graham 1  indeed our parser was inspired by the context-free parser of graham  harrison and ruzzo the implemented parser also uses left context to reject some of the hypotheses that are generated bottom-up  the technique is similar to shiebers notion of restriction  shieber 1  
1. parallel parting 
　we claim that in practice  the time for a unification or a substitution is dependent on the grammar but not on the sentence if the ground grammar is finite  there is a finite bound on the largest term that can be constructed by the parser - it is no larger than the 
	hmi 	1 

largest term in the ground grammar sometimes a grammar will include features that take on an infinite set of values  but these features are few and their values do not get very large for ordinary sentences so to a good approximation  the size of the terms constructed during a parse is independent of the sentence. therefore the time taken for a unification or a substitution is independent of the sentence 
　therefore let u be the maximum time for a unification or substitution assume that an unlimited number of processors are available and the time to set up tasks for parallel execution is negligible in computing a product si * s1  we can consider each combination of an x' in si. a y' in s1 and a rule  x -  y z  in parallel this allows us to compute the product in time 1u  regardless of the size of si or s1 or the number of branching rules in the grammar. by similar reasoning we can compute  close si  in time 1u  regardless of the size of si then we can compute m i l + l   for all i in time 1u suppose we have computed m i k  for all substrings shorter than l to compute m i k  for a substring of length l  we can compute m i j  * m j k  in parallel for all j such that i   j   k  and then compute the closure this gives a total time of 1u for each length from 1 to the length of the sentence  thus the parser should be able to run in time linear in the length of the sentence 
　in practice it is essential to remove from m i k  any terms that are substitution instances of other terms in m i k  in parsing cerain constructions  for example  sequences of noun modifiers or prepositional phrases   this makes the difference between a matrix of size polynomial in the input  and a matrix of size exponential in the input a simple parallel algorithm will do this in time 1u  the number of processors needed is the square of the number of elements in m i k  note that if x is the first term in m i k  to be computed  it might be a substitution instance of the last term to be computed thus one cannot be certain that x belongs in m i k  until all the potential elements of m i k  have been computed this limits the parallelism in the algorithm there is no such limitation in the case of a context-free parser because an occurence of a non-terminal a in m i k  is redundant only if there is another occurence of a in m i k  when the algorithm finds the first occurence of a  it can keep that one and throw away all later occurences 
　this algorithm achieves speed by wasting processors in many cases we can use left context to show that even though a =   mput i k   there is no derivation of the whole sentence in which a is the interpretation for u   k  for example  suppose our grammar includes a rule  trace -    a simple bottom-up parser will conclude that trace =    input i 1  for each 1  but left context will eliminate most of these hypotheses an algorithm that uses left context may therefore manage with fewer processors  but it will not run in linear time in the worst case it must work from left to right  after reading the n - t h word it computes m i n  for all 1   n if i   j it must compute m i n  before m j n  because 
m j n  is a proper substring of u   n  then the time to read the n - t h word is proportional to n  and the total time is 1 nt1  
　of course this worst-case time may not be realized for natural grammars and natural sentences this raises the question of testing the implemented parser. our current grammar concentrates on clause-level phenomena. there is a large set of subcategorization frames for verbs  and the grammar describes raising  control  passive  subject-aux inversion and whmovement noun phrases  adjective phrases and prepositional phrases are described only as much as needed to illustrate the clause-level phenomena. the 
1 	natural language 
program was first tested with a butterfly simulator running on a vax  it was then moved to a real butterfly and ran the first time. tests have shown that the program is reliable but slow  we have not yet attempted to speed it up or to measure the gain from parallelism. 
1. conclusion 
　we propose to restrict unification grammars by requiring that for each grammar g there is a constant n such that every derivation of a string of length 1 or 
1 is shorter than n. essentially this says that the size of a parse tree is bounded by the size of the sentence; one cannot build arbitrarily large structures that are not realized in the surface string. given this requirement one can parse unification grammars by an algorithm related to the cky algorithm. in principle such an algorithm should be able to parse in linear time on an ideal parallel machine. in practice it is probably desirable to use left context  raising the worst case time to 1 nt1  in any case it should be possible to parse in time independent of the size of the grammar natural sentences are seldom over 1 words  while natural grammars are likely to contain many hundreds of rules  so this is an encouraging result. 
