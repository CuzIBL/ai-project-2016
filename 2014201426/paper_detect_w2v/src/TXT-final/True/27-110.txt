 
evaluation-oriented information provision is a function performed by many systems that serve as personal assistants  advisors  or sales assistants. five general tasks are distinguished which need to be addressed by such systems. for each task  techniques employed in a sample of systems are discussed  and it is shown how the lessons learned from these systems can be taken into account with a set of unified techniques that make use of well-understood concepts and principles from multi-attribute utility theory and bayesian networks. these techniques are illustrated as realized in the dialog system pracma. 
모during the past two decades  a number of ai systems have been developed whose overall task can be characterized as evaluation-oriented information provision: the user  to be called the evaluator  or 뫩  has the goal of making evaluative judgments about one or more objects; the system  or information-provider  x  supplies 뫩 with information to help 뫩 make these judgments. table 1 lists a representative sample of five such systems  which will be referred to as eoips.1 the number of such systems seems likely to grow in the near future  especially given the recent interest in personal assistants -some of which advise their users on evaluative judgments - and teleshopping  which should increase the demand for automated sales assistants. 
모eoip systems differ considerably in the techniques they employ for interaction with the user and for internal processing. for example  the communication with the information filtering system and the sales assistant is realized with direct manipulation and hypertext techniques  whereas the other three systems use some form of natural language. there are also large differences in the theoretical frameworks and terminology in which eoips are presented. these differences impede exchange and consolidation of results. the present paper aims  a  to remedy this state of affairs by providing a uni-
   *this research is being supported by the german science foundation  dfg  in its special collaborative research program on artificial intelligence and know ledge-based systems  sfb 1   project nl  pr acm a. 
   'not included are expert systems that perform evaluation tasks using evaluation criteria that have no necessary relationship to the criteria of the user  see  e.g.   klein and shortliffe  1 }. 
1 	reasoning under uncertainty 

fied framework for analyzing the techniques used in eoips; and  b  to advance the state of the art by presenting some new techniques which should be generally applicable within eoips. 
모table 1 gives an overview of five general tasks which are at least potentially relevant to any eoip. these will be discussed in turn in the five sections to follow. the new techniques will be presented in the context of the fifth of the reference systems  pracma. the excerpt from an example dialog in table 1 both gives a sense of the nature of pracma's dialogs and provides initial examples of the five tasks. 
1 	task 1: predict overall evaluations 
it is almost inevitable for an eoip to try to predict how the user 뫩 would evaluate individual objects in the domain if he1 had complete information about them. for example  though it is clear in the used-car domain that the buying decision will ultimately be made by 뫩  x needs to predict 뫩's overall evaluations in order to narrow the discussion to one or more 
모모for clarity  masculine and neuter pronouns will be used to refer to 뫩 and i  respectively. 

table 1: overview of five general tasks for an evaluation-
oriented information provider 
table 1: part of an example dialog with p r a g m a illustrating 
five tasks of evaluation-oriented information provision 

i. predict overall evaluations: anticipate how 뫩 would evaluate one or more domain objects  perhaps relative to one another  given complete knowledge about them. 
1 predict partial evaluations: anticipate the impact that informa-tion about an attribute of an object would have on 뫩'& evaluation of that object. 
1 interpret evidence: update the model of 뫩  evaluation criteria on the basis of evidence in 뫩's actions. 
1. elicit evidence: induce 뫩 to perform actions that will constitute evidence for the task  interpret evidence . 
1. select dialog moves: determine what type of dialog move to make  e.g. formulate recommendation; ask question about 뫩's criteria; allow 뫩 to act next  
objects. 
   almost all eoips appear to be based on some particular conceptualization of how 뫩 would evaluate an object given complete information about it.1 in most cases the conceptualization can be seen as a variant of a conceptualization known by the name multi-attribute utility theory  maut  and similar names  see  e.g.   von winterfeldt and edwards  1j . 
1 	t h e m a u t c o n c e p t u a l i z a t i o n 
some basic concepts of this conceptualization are illustrated in figure 1  which shows part of a value tree that a used-car 
customer consulting pracma might use to evaluate a particular car. each leaf corresponds to an attribute  which for each particular object has a level within a given range. for each attribute  뫩 has a value function which assigns to each possible level a value between 1 and 1  for example  for the attribute  mileage   the values might be 1  1  and 1 for the levels  1 -1    1-1   and  1-1   respectively . to take into account differences in the importance of attributes  each branch in the value tree has an importance weight between 1 and 1. for example  the importance weights on the branches leading down to  mileage  and  time to inspection  specify their relative weights with respect to the value dimension of  reliability ; the weights on the branches leading down to  reliability  and  safety  in turn specify the relative weights of these dimensions with respect to the overall evaluation of the car. the absolute importance weight of each individual attribute  shown below the corresponding leaf in figure 1  is the product of the weights on the branches leading to it. if 뫩 had complete information about an object  뫩 could arrive at an overall evaluation by determining the object's value with respect to each attribute  multiplying each such value by its absolute importance weight  and adding up 
1
모모strictly speaking  x need not presuppose that 뫩 really evaluates objects in accordance with the conceptualization used  only that it is useful for x to act as if 뫩 did so. given the constructive  taskdependent  and situation-dependent nature of human evaluation processes  see  e.g.   payne et al  1    for descriptive purposes any single conceptualization is best viewed as a rough approximation. 
dialog contribution task s  performed by ia x: what kind of car are you looking for  
뫩: it shouldn't cost more than about 1. 
it shouldn't be too old 
x: what kind of work do you do  
뫩: i am a teacher. 
x: i have something you might like. 
it's a rabbit. 
its year of construction is 1. 
뫩: how long is the time to the next official inspection  
x: the time to the next inspection is 1 years. 
뫩. 	 noreaction  
x; its mileage is 1. 
뫩뫴 that's good. 1. elicit evidence 
1. interpret evidence 
1. elicit evidence 
1. interpret evidence 
1. predict overall evaluations 
1 predict partial evaluations 
1. interpret evidence 
1. predict partial evaluations 
1. interpret evidence 
1. predict partial evaluations 
1 interpret evidence  task 1   select dialog moves   is performed each time x produces an utterance or gives 뫩 a chance to do so. the weighted values.1 
variants of m a u t used in eoips 
this basic conceptualization takes different forms in different eoip systems and sometimes remains implicit. 
t  the sales assistant treats the value function for an attribute as a fuzzy membership function representing a concept like  has at least 1 m b r a m     and the weight of an attribute is represented by a membership function corresponding to a natural language formulation like  quite important . 
  c o n s u l t may  for example  ascribe to 뫩 a  negative preference  for courses beginning after 1 p.m.  in effect ascribing a particular value function mapping times of day onto values; the characterization of this negative preference as  strong  in effect assigns to this attribute a high importance weight. 
  the i n f o r m a t i o n f i l t e r i n g s y s t e m   which uses techniques from artificial life  provides an evolving population of agents. each agent in effect ascribes to 뫩 a simple value tree that it uses to evaluate and recommend news articles. each attribute corresponds to the presence or absence of a particular keyword  or other feature  in the article being evaluated  and each attribute has at any 
     1 a single attribute can affect the evaluation of an object with respect to more than one value dimension  e.g.   horsepower  has implications for both  spottiness  and  environmental friendliness  . although cases involving these and additional complications are handled by pracma  cf.  schafer  1   a discussion of their proper treatment would exceed the scope of this paper. 
	jameson  etal 	1 
even assuming that 뫩's evaluation processes can be described perfectly in terms of a value tree  an eoip can rarely have a complete and accurate view of 뫩's evaluation criteria. for example  with respect to the value tree in figure 1  뫩s can differ widely in the importance weights they attach to value dimensions like  reliability   and independently of this they may attach idiosyncratic relative weights to individual attributes like  mileage . 
treatment in other eoips 
some systems  such as the information filtering system and the sales assistant  in effect make use of their best specific estimate as to the content of 뫩's value tree. they therefore do not distinguish between predictions in which they are confident and those which represent mere guesses. this distinction may in fact be of minor importance if the eoip evaluates a large number of objects on 뫩's behalf and if the consequences of an incorrect prediction are not serious. 
모other eoips represent uncertainty about 뫩's evaluation criteria explicitly. 
  when ascribing to 뫩 a particular value function  consult associates with this ascription  a  a confidence rating and  b  a list of endorsements for the ascription. when predicting how 뫩 would evaluate various courses  the system takes into account only attributes about whose value functions it has at least moderate confidence. 
모note that if an eoip restricts its attention to attributes about which it is confident  it still cannot be confident that its overall predictions are accurate. for example  an object that rates highly with respect to one attribute may be extremely attractive to 뫩 even though x as yet has no evidence that 뫩 assigns high importance to that attribute. it is therefore desirable for x 
to be able to derive some sort of confidence interval for its predictions of 뫩's overall evaluations. 
1 	reasoning under uncertainty 
figure 1: part of a bayesian network constructed by pracma to predict and interpret evaluative reactions to a statement. 
 arrows point from parent to child nodes. the darker histograms represent the beliefs the system derives through upward propagation on the basis of 뫩's positive reaction to the statement  its mileage is 1 -cf. section 1.  
managing uncertainty with bayesian networks 
this problem  and others to be discussed below  can be handled effectively with the help of bayesian networks.1 this approach will be discussed in most detail in connection with pracma's handling of task 1   predict partial evaluations ; but some of the basic concepts can be illustrated in terms of the three network nodes depicted in the upper left-hand part of figure 1. these nodes show how i's uncertainty concerning the importance weights relevant to the attribute  mileage  can be handled.  until section 1 we will refer only to the first of the two histograms shown for each node.  
   in the node relative importance of reliability for e  the first histogram depicts a probability distribution representing i's initial belief about a variable a   namely the relative weight that the current 뫩 attaches to  reliability . whereas in figure 1 x simply had the value .1  here i's belief about x is a probability distribution over the possible values that x can assume. for reasons of computational tractability  x is approximated as a discrete variable with five possible 
     1 for theoretical and technical background on bayesian networks see  e.g.   pearl  1   whose notation and concepts are adopted in the present paper  or  neapolitan  1 . 

values  corresponding to the midpoints of the intervals .1  .1-.1  .1-.1  .1-.1 and .1-.1. i's probability distribution for x can therefore be viewed as a five-element vector bel x .1 in the example  x considers it most probable that 뫩's weight is around .lobut that the weight might also be as high as about .1. the node relative importance of 
mileage for reliability for customers in general represents i's belief about the average weight of the mileage attribute  relative to the value dimension of reliability  in the population of customers that x deals with. 
모on the basis of its beliefs about these two variables  x can form a belief about the importance of mileage for e  as indicated by the arrows showing that this third node is a child of the former two parent nodes. but the relationship between the parent nodes and the child node is probabilistic: even if x knew the exact values of the two variables in the parent nodes  it could not be sure that the value of the variable in the child node was simply their product  because the relative weight that this particular 뫩 attaches to  mileage  may deviate from the relative weight for customers in general. 
모in a bayesian network  a probabilistic relation between two parent nodes corresponding to variables x and y and a child node corresponding to a variable z is represented by a matrix of conditional probabilities p z x y  which contains one probability for each possible combination of values of z  x  and y. for these particular three nodes  the matrix is generated using a function which specifies that the probability of z taking a given value z is highest when that value is close to the product of the values x and y of the two parent variables.1 
모x arrives at a belief concerning the child variable through the standard top-down propagation procedure for singly connected bayesian networks. in this example  we see that x has a moderate amount of uncertainty about the weight that information about a car's mileage will have in determining 뫩's evaluation of it; the probability distribution for importance of mileage for e would be still narrower  for example  if x somehow had acquired a definite belief about the relative importance of reliability for e. 
모this type of uncertainty ultimately affects z's prediction of 뫩's overall evaluation of a given car. this prediction task involves many nodes not depicted in figure 1  but its treatment is largely analogous to that of the prediction of partial evaluations  which is discussed in the following section. 

1 	task 1: predict partial evaluations 
in addition to predicting the evaluation of entire objects  an 
eoip should be able to anticipate the impact that information about a particular attribute of an object will have on 뫩's evaluation of that object. first  even if x is already certain that a given object should be recommended to 뫩  x may have to explain its recommendation.1 second  z may in some cases not attempt to evaluate entire objects for 뫩 at all  pursuing instead the more modest goal of efficiently supplying information that allows 뫩 to arrive at evaluations of his own. 
1 	treatment in other eoips 
some eoips supplement their recommendations of an object with a description of those attributes of the object that the system expects to have the greatest impact on 뫩's evaluation. 
t  in particular  consult illustrates that this sort of selection of attributes must sometimes concern relative evaluations: when recommending an alternative to a university course selected by the user  the system describes only those attributes with respect to which the alternative course is likely to be evaluated substantially higher by 뫩 than the original choice. 
모this capability for selective description of objects is not required only in natural language systems with a narrow communication bandwidth. for example  systems like the infor-
mation filtering system often present an overview of a fairly large set of objects  each of which has to be characterized briefly. so it may be worthwhile  for example  for x to select an especially evaluation-relevant subset of each object's attributes to be displayed in graphical or tabular form. 
1 	predicting partial evaluations with bayesian networks 
the way in which bayesian networks can be applied to this task will be illustrated for a particular type of relative partial evaluation: an evaluation shift is the change in 뫩 s evaluation of an object with respect to a given attribute after 뫩 has received information about the object's level with respect to that attribute  cf.  jameson  1  . an evaluation shift is actually more relevant than an absolute evaluation for determining which facts x should mention. for example  even if i knows that 뫩 assigns a high weight to the attribute  mileage   there is little point in mentioning that a given car has low mileage if 뫩 already has been told that it is only a few weeks old: the statement could in this case hardly produce a substantial shift in 뫩's evaluation. 
모a straightforward way of using bayesian networks to predict an evaluation shift would be to make separate predictions of 뫩's evaluations of an object before and after z's statement with respect to an attribute  e.g.  that car 1's mileage is 1 . each of these predictions would make use of x's prediction of importance of mileage for e  cf. figure 1 and the discussion in the previous section ; a comparison of the nodes representing the two resulting predictions would give some indication of 뫩's likely evaluation shift. this method 
   1 klein and shortliffe  1  present sophisticated techniques for explaining evaluative decisions which have been arrived at using a particular  known value tree-which may have been acquired either from the user or from an independent expert. 
	jameson  etal. 	1 
would be invalid  however: z's uncertainty about 뫩's importance weights would enter into both of the predictions  leading to much more uncertainty in the prediction of the evaluation shift than would be necessary or justified. 
   the remaining part of figure 1  except for the bottommost node  which will be discussed in the next two sections  shows how this problem can be avoided. pracma dynamically constructs a partial network like this whenever it considers making a statement about a particular attribute of a car-in this case  the statement  its mileage is 1 . the node es prior expectation about car 1's mileage represents z's belief about what 뫩 would consider the most likely mileage for car 1 before e obtained any information from z; as the first histogram for the node illustrates  z can initially have only a rather indefinite belief about this expectation. on the basis of this variable  z can try to predict the extent to which e's unweighted evaluation of car 1's mileage  on a scale from 1 to 1  will shift upward or downward after i's statement. z's belief about this shift is shown in the first histogram for e's unweighted evaluation shift for car 1's mileage: z considers it slightly more probable that the shift will be positive than that it will be negative  because 1 is a bit more likely to be a lower mileage than e expects than it is to be a higher one .1 
   the node e's evaluation shift for car 1's mileage is of most relevance forz in deciding what to say  as it reflects the impact that z's statement is likely to have on 뫩's overall evaluation of car 1  which of course depends in part on importance of mileage for e. the prediction of this variable on the basis of its two parent variables proceeds in a way similar to that described in section 1 for the prediction of importanceof mileage for e itself  in both cases the basic underlying relationship is multiplicative . the first histogram for e's evaluation shift for car 1*s mileage shows that z considers it unlikely that its statement will influence e's overall evaluation  which will be on a scale from 1 to 1  by more than about. 1 in either direction. this example illustrates that it is often possible to make a fairly definite prediction about a change in a variable even if one has only indefinite beliefs about the initial and later levels of the variable-if the uncertainty that is common to the two beliefs is handled appropriately. 
1 task 1: interpret evidence 
most eoips refine their models of e on the basis of evidence supplied by e during the interaction. the ways in which 뫩 can give useful clues include: explicitly characterizing his evaluation criteria   i'm interested in politics    making requests for particular types of information   what books/courses/articles do you have that involve politics     expressing evaluative judgments he has arrived at   this object  which involves politics  looks good    and reporting personal characteristics that have implications for his evaluation criteria   i'm a law student  . 
1 	treatment in other eoips 
the most common approach to processing this type of evidence is to adjust one or more parameters of z's model of e 
   ' the matrix of conditional probabilities linking these two nodes presupposes that 뫩's value function for  mileage  is similar to the one that x assumes for customers in general  but it takes into account possible idiosyncratic variation. 
 e.g.  z's representation of the importance of politics for e  in the direction suggested by the evidence  with the magnitude of the adjustment depending on the nature of the evidence. 
  when an article suggested by one of the information 
filtering system's agents is evaluated positively by the user  the importance weight associated with each of the article's keywords is increased. 
  whenever grundy processes a self-description or an evaluative reaction to a library book from the user  the system adjusts a number of quantitative assessments it has made -for example  concerning the specific 뫩's interest or concerning the long-term content of the general stereotypes that the system has associated with the user. 
   in these systems  the direction and relative magnitudes of the adjustments in z's model of 뫩 can be justified fairly plausibly  but there is a good deal of arbitrariness in the details. this limitation may be of minor importance if z will have the opportunity to process a large amount of evidence concerning a given aspect of its model; in such cases the model can ultimately converge on realistic values even if the individual adjustments are not optimal. where evidence is much more limited - for example  when it concerns a specific 뫩 and is acquired during a single interaction - it is desirable for adjustments to z's model to be justifiable more specifically. 
1 	probabilistic evidence interpretation 
this goal can be achieved within the bayesian network framework used by pracma  if the relevant aspects of 뫩's behavior are represented by nodes which have precisely defined probabilistic links to the nodes that represent unobservable states of e. although the conditional probabilities defining these links may be based on intuitively plausible assumptions made by the designer rather than on empirical data  at least the details of the system's inferences can be understood and justified in terms of these assumptions. 
   this way of handling evidence in 뫩's actions is illustrated by the way pracma interprets an explicit evaluative reaction like  that's good  following a statement that it has made  cf. table 1 . the type of reaction  including possibly   no reaction    that 뫩 produces is represented by a node in the 
bayesian network-e*s verbal reaction to car 1's mileage in figure 1. this node distinguishes several categories of evaluative verbal reactions that were observed in an unpublished 
empirical study. the matrix of conditional probabilities linking this node with its parent e's evaluation shift for car 1s mileage were derived indirectly from the data of this study. 
   before z observes 뫩's reaction  z has only an indefinite belief as to what e's verbal reaction to car 1's mileage will be  as shown in the first histogram for the node. but after e has responded with  that's good   x has a completely definite belief  shown in the second histogram. now a process of upward 
propagation can begin  in which the beliefs associated with the ancestor nodes of e's verbal reaction to car 1's mileage 

are updated in the l ight of the new evidence.'' the second histogram for each ancestor node shows the updated beliefs. x's belief about e's evaluation shift for car 1's mileage is most directly affected: it is now almost certain that 뫩*s evaluation shift was in fact positive. less directly  x confirms that 뫩 expected car 1 a priori to have a higher mileage than 1  es 
prior expectation about car 1's mileage   and x also increases the extent to which it believes that 뫩 assigns high importance to  reliability  in general and to  mileage  in particular. note also the slight positive shift in relative importance of mileage 
for reliability for customers in general  w h i c h shows that x is gradually learning  on the basis of 뫩s actions  about the evaluation criteria of customers in general. 
모an entirely analogous approach is used in pragma to interpret the fact that 뫩 has asked a question about a specific attribute. when  on the other hand  evidence becomes available that is directly related to 뫩's evaluation criteria or to a relevant personal characteristic  cf. the examples in table 1   less complex processing is required. for example  when 뫩 says  i'm especially interested in reliability   a corresponding node is attached directly as a child under the node relative importance of reliability for e. the conditional probabilities linking the child node to the parent node reflect the fact that the likelihood of 뫩's making a statement like this is a positive function of the actual importance of reliability for 뫩 but that the utterance does not uniquely determine any particular degree of importance. 
1 	task 1: elicit evidence 
given x's need for evidence from 뫩 in order to update its model of 뫩  one natural task for x is to take steps so as to increase the likelihood that useful evidence of particular types will become available. for example  in the car sales domain  professional salespersons emphasize that they actively acquire a model of the customer by asking questions about personal characteristics and evaluation criteria and by encouraging the customer to express evaluative responses   simons  1 . 
1 	treatment in other eoips 
eoips that exploit the broad band-width of modern humancomputer interfaces can make it easy for 뫩 to enter information about himself optionally and with a minimum of distraction from his primary task. 
  the information filtering system allows 뫩  after reading an article  to express his evaluation by clicking on a thumbs-up or thumbs-down icon displayed above the article; and to express interest in particular attributes by highlighting words in the text of the article. 
모in cases where techniques such as these are not applicable and/or where the consequences of x's use of an inaccurate 
    upward propagation essentially uses bayes' rule to adjust the probability associated with each possible value of a variable in an ancestor node in accordance with the conditional probability of the observed evidence given that value. although the computations are in general more complex  in the simple case of the two nodes at the bottom of figure 1  the updated belief vector bel!  x  for the parent variable x after the observation y = y is related to the prior belief vector bel{x  as follows: 

model can be serious  some more obtrusive elicitation of information from 뫩 may prove inevitable. one issue that then arises is how x can selectively elicit the information that will be of the greatest value. in eoips to date  this kind of selection decision has typically been made by the designer  not by the system itself on-line. 
  grundy always asks a new user to supply some selfdescriptive words  and when it has described a potentially interesting book  it asks 뫩  does that sound good  . it is only when 뫩 has given a negative response to a question like this that grundy asks questions chosen for their expected information value: it asks about 뫩's evaluation of individual attributes of the book  starting with attributes for which x is most uncertain about 뫩's evaluation. 
1 	systematic assessment of information value 
if i's model of 뫩's evaluation processes is cast in the form of a bayesian network  general techniques for predicting the value of new information within this framework  cf.  pearl  1.1.1   can be applied. a well-known approach within decision theory involves comparing the expected value of an outcome if a decision is made on the basis of some new information to the expected value if it is made without that information. for example  how much more is a used-car buy-
er's purchase likely to be worth if he performs particular tests on a candidate car before making his choice  see  e.g.   qi et al.  1    in the context of evaluation-oriented information provision  this approach would require quantitative evaluation of the ultimate consequences of a decision made by the informant x to elicit  or not to elicit  a given piece of information from 뫩. but such consequences are in general hard to anticipate and to quantify. for example  x's failure to elicit a relevant fact about 뫩 might ultimately lead to a less satisfactory decision by 뫩  or it might just cause a lengthening of the interaction between 뫩 and x. 
모in such cases a useful criterion is often the extent to which new information will reduce the system's uncertainty about particular target variables whose values importantly influence the system's behavior.1 in an eoip that uses bayesian networks in the way pracma does  interesting target variables include the importance weights that 뫩 assigns to the various value dimensions. 
모for example  suppose that in the example dialog  table 1  뫩 did not spontaneously express any evaluative reaction to x's statement about car 1's mileage. then x would have had to decide whether to elicit such a reaction  e.g.  by asking  what do you think of that   . one of the main benefits of doing so would be the kind of reduction in x's uncertainty about the node relative importance of reliability for e that 

	jameson  etal 	1 

is illustrated by the change from the first to the second histogram for that node in figure 1. since x doesn't know in advance what type of reaction 뫩 will express  x must in effect perform the updating shown in figure 1 for each possible reaction type  weighting the resulting uncertainty reductions by the prior probabilities of the reaction types1  these are shown in the first histogram for e's verbal reaction to car ss mileage . generally speaking  eliciting evaluative reactions is especially worthwhile when a fact has contrary implications for two different relevant dimensions  e.g.  high horsepower is positive for  spottiness  and negative for  environmental friendliness  ; in such cases  a single reaction by 뫩 often yields considerable information about the importance he assigns to the two value dimensions. 
모x can use the same general technique when deciding whether to elicit other types of reaction by 뫩  such as statements about personal characteristics and evaluation criteria  cf. the remarks at the end of section 1 on how such statements are interpreted by pracma . 
1 	task 1: select dialog moves 
the five reference systems discussed have illustrated a number of types of dialog move that x can make  for example: asking about 뫩 s personal characteristics  answering questions  and volunteering unsolicited information. though some criteria have been discussed in the preceding sections for choosing a move of a particular type  e.g.  deciding which object to recommend   the more general question remains of how x should decide which type of move to make at which time; and when to give s the chance to make a move. 
1 	treatment in other eoips 
a survey of other eoips suggests three general principles with respect to this question: 
모1. x should try to achieve an efficient and coherent sequence of dialog moves. 
t  the default ordering of the screens in the sales assistant follows a sequence that is presumably efficient in most cases: obtaining information about various aspects of 뫩 and then making use of it to recommend products. 
모1. the criteria for selecting dialog moves should take into account evaluation-relevant information. 
  consult's decision as to whether to suggest a different university course than the one chosen by 뫩 depends not only on the dialog state but also on whether x has found a course which seems clearly superior. 
모this dependence of dialog moves on dynamically applied evaluation-relevant criteria makes sense in that the whole point of the interaction is to support 뫩's evaluation process. 
모1. both 뫩 and x should be able to influence the course of the interaction. 
t  the user of the sales assistant has the option of ignoring the default screen sequence and navigating freely through the system. 
모not only do users appreciate this sort of freedom  it also supports the goal of efficiency: although x knows more about the domain objects than 뫩 does  뫩 in general knows more about 
   ' efficient techniques for performing the relevant computations are discussed by  pearl  1  1.1 . 
his own evaluation criteria. because of this distribution of relevant knowledge over the two participants  each participant may at any point be in a better position to determine the direction the dialog should take. 
1 	dialog control through flexible planning 
pracma models the process of participating in a dialog in terms of the generation and execution of dialog plans. it uses a planner   weis  1   which implements a basically hierarchical planning approach  cf.  moore and paris  1   extended by special plan operators for modeling iterations on subgoals. 
   1. efficiency and coherence. on the highest level  pracma's hierarchy of plan operators divides the dialog into phases corresponding to those found in sales dialogs  e.g. the phase in which x actively tries to acquire information about 뫩 precedes the phase for presenting information about relevant objects . on a lower level in the hierarchy  for each dialog phase there are several optional strategies that specify sequences which are efficient and correspond to dialog conventions  e.g.  for the active acquisition phase  the strategies include  ask about personal characteristics  and  ask about requirements  . 
   1. evaluation-dependence. the applicability conditions of the plan operators refer not only to the nature of the preceding dialog moves but also to aspects of the model of 뫩 's evaluation process. in other words  the considerations mentioned in the previous sections that determine which particular move of a given type pracma makes-e.g.  what kind of evaluation shift a given statement would produce in 뫩 - are also used to determine which type of move the system makes at a given moment. this evaluation-dependent determination of what to do next often requires iteration: repeatedly achieving a given subgoal until it no longer appears worthwhile to do so. 
   1. mixed initiative. after each of j's dialog moves  x gives 뫩 a chance to make the next move  even when x has already planned an appropriate next move of its own.1 to enable pracma to accommodate a variety of dialog moves by 뫩  including those which don't fit well into j's plan  the dialog strategies include lower-level tactics  whose selection is influenced by 뫩's actions. for example  the strategy  ask about personal characteristics  includes a tactic which is applicable when 뫩  unexpectedly asks a specific question: x answers the question minimally and  after executing this tactic  continues to pursue the same strategy. 
1 	conclusions 
모table 1 summarizes the advances achieved by the techniques discussed in this paper relative to the overall state of the art in evaluation-oriented information provision. 
모a more general conclusion is that research in this area can benefit from increased use of relevant theoretical frameworks and techniques that are not specific to this topic. this strategy is analogous  for example  to the strategy underlying recent work that applies numerical uncertainty management techniques to the problem of plan recognition  see  e.g.  icharniak and goldman  1; bauer  1  . this type of research has 
l1
모모simulated facial expressions are currently being integrated through which x will be able to signal  among other things  the extent to which it considers it desirable for 뫩 to make the next move. 

table 1: benefits of the described techniques for systems for evaluation-oriented information provision 
tasks 1 and 1: predict overall and partial evaluations 
  prediction in terms of a probability distribution  yielding differentiated information to support i's dialog decisions. 
뫴 simultaneous management of uncertainty with respect to a broad range of variables  from importance weights for 뫩s in general to the prior expectation of a particular 뫩 concerning an attribute of a particular object. 
뫴 appropriate treatment of uncertainty in the prediction of evaluation shifts and other relative evaluations. 
task 1: interpret evidence 
뫴 principled adjustment of i's beliefs concerning a variety of possible causes of 뫩's observed behavior. 
모  explicit representation of the probabilistic relationships between the observable behavior of 뫩 and unobservable variables. task 1: elicit evidence 
- dynamic selection of information-eliciting moves on the basis of context-dependent estimation of the value of the resulting information 
task 1: select dialog moves 
뫴 integration of dialog planning with quantitative user modeling  permitting flexible support of 뫩's evaluation processes. 
shown that there is often a good fit between the tasks recurrently performed by a particular type of system and existing more general techniques; but that it is nonetheless a challenging research goal to work out an appropriate conceptualization of a task in terms of these techniques. 
references 
 bauer  1  mathias bauer. a dempster-shafer approach to modeling agent preferences for plan recognition. user modeling and user-adapted interaction  1. to appear in a special issue on numerical uncertainty management in user and student modeling. 
 charniak and goldman  1  eugene charniak and r. p. goldman. a bayesian model of plan recognition. artificial intelligence  1-1  1. 
lelzer et a/.  1  stephanie elzer  jennifer chu-carroll  and sandra carberry. recognizing and utilizing user p