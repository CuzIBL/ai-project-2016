 
       in this paper we introduce the concepts of multi-level machines and of multi-level dynamic programung. these machines are well suited for the difficult continuous speech recognition problem because firstly  they permit the integration of several knowledge sources  secondly  they allow an optimal search based on dynamic programmng and thirdly  they can deal with semantic constraints. furthermore these semantic constraints have the interesting property to be dynamic  i.e. they can be modified easily by the speech recognition system itself. the important consequence of this property is that the multi-level machines presented in this paper have a potential self-leaminy 
hability. 
i - iroroacricn 
in this paper we present the concepts of multi- level machines and multi-level dynamic programming. these muulti-level machines  on one hand  permit the integration of several knowledge sources such as phonology  syntax  semantic etc  and on the other-hand can take into acount local semantic constraints. as it will be shown these semantic constraints are  dynamic   in the sense that the speech recognition system can modify them easily. 
in section 1 we begin by showing how a 1-level machine can be built from simple finite-state automatons. these automatons are called cells because the entire machine is built from these elementary machines. the description is done in such a way that the iterative process to generate a general n-level machine can be induced easily. the semantic links are also describes and we 
1 	perception 
put in evidence the fact that firstly  they can be modified easily  and secondly that such modifications can be realized by the speech recognition system itself. this interesting property confer to the system a self-learning hability. 
in section 1 we introduce the formalism necessary to explain how an optimal seauch can be realized in an n-level machine. from this mathematical discussion we show that the solution found is optimal for all the levels of the machine.this other intersting property confirms the power of the n-level machines. 
ii - description of the machine 
the basic of the machine is a simple finite-state machine as illustrated by figure 1  1 . 

figure 1. the basic cell of a multi-level machine : a simple finite state automaton. 
the basic cell is characterized by a set of starting states es  a set of ending states fs  and a set of terminal symbols t. for example  in the case of figure 
and  an element of the starting state set and an 
element of the ending state set are particularized : they are called respectively the entry-state of the machine and the exit-state of the machine. these notions of entry-state and exit-state will be used later on when the notion of context of a machine is defined. 

now in order to connect these basic cells we use a finite-state formalism in which the symbols are the basic cells we just described. figure 1 shows a machine built from the connection of basic cells. 

figure 1. an example of a 1-level machine. 
let  designate respectively the entry-state and the 
exit-state of an elementary cell c. 
let n and mc two nodes of the finite-state machine in which c 	c 
are embedded the elementary cells  defining a transition labelled by symbol c. 

the context of another machine c'. then we say that machine c is connected to machine c if the contexts of the two machines are tied by the relation of partial order defined by relation  1  : 

relation  1  defines the connection of two machines. bat  in fact this link is strengthened by a special link which ties the exit-state of one machine with the entry-state of the other one. we call such a link a semantic link because by specifying a single node of the target machine a lot of pathssemantioally incorrect- are suppressed. furthermore as these semantic links can be modified dynamically in a straighfbrward manner by the speech recognition system  we claim that the multi-level machines have a self-learning hability. figure 1 illustrates such a semantic link. 

figure 1. an illustration of a semantic link in a 1-level machine. 
at this stage of the developpement we can give the following definitions : 
- the basic cell is called a olevel machine. such a machine can be used for example to represent the acoustical  phonological variations of a lexical entity. interesting studies on this subject can be found in 1 and 1. 
- a machine built from basic cells is called a 1-level machine. figure 1 is an example of a 1-level sachine. 
now  it is clear that our procedure for building a 1-level machine from olevel mchines can be iterated. we get in this case a general n-level menine ; such machines are interesting because of the following properties : 
- 1 they can tackle the different degrees of abstraction of the language ; in other words the structure of the language can be dealt with by these machines. this property is a very desirable one  because the languages represented in not a structural way -i.e. for example olevel finite-state languages-become rapidly intractable when the number of words of the vocabulary go beyond approximatively one or two hundred. 
- 1 their model is extremely coherent ; 
- 1 they can take into acount semantic constraints ; - 1 an optimal search based on dynamic programming - dp - is possible in these machines 1. 
the next section is intended to prove the last point. 
i l l - an oprimal search solution based 
cn dp in multi-level machines 
at the deepest level of the multi-level machine  	i.e. 	the 
olevel  the automatons are constituted only of terminal symbols which characterize the acoustic properties of the speech signal. a symbol c in a olevel automaton is defined by 

symbol 1 means that the entry-state and the exit-state of a 
	martino 	1 

terminal symbol does not exist. 
the olevel automaton including symbol c in context itself in context  in the 1-ievel stage of the multi-level machine which itself is in context in the 1-level stage ... which is itself in context in the n-level stage of the multi-level machine. consequently to symbol c in context be associated the list : 
which characterizes completely such a o-level symbol in an 

1 	perception 

ed of defnution 

iv-concllision 
in this paper we have presented the concepts of multi-level machines and of multi-level dynamic programming. these machines are well suited to the difficult problem of continuous speech recognition because : 
1 they preserve the linguistic structure of the language ; 
1 they permit the introduction of semantic constraints ; 1 they allow an optimal search based on dp. 
another interesting point of such machines and perhaps the most important one is due to the fact that the semantic links can be modified in an easy manner by the speech recognition itself. consequently our machines have a potential hability of 
self-learning. 	kai-fu 	lee 	: 
template-ba1ed  incremental 	network 
word 	recognition   generation 	in 
cmu-cs-1  
carnegie-melton department 
university. of computer science  	martlno 	1 
