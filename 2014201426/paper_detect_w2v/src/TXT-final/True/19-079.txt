 
   we propose a unifying framework for nonmonotonic logics  which subsumes previously published systems  and at the same time is very simple. we discuss some of the technicalities of the new general framework  illustrate briefly how some previous systems are special cases of it  and finish an informal discussion of the intuitive meaning of nonmonotonic inferences. 
1 introduction 
the last decade or so has seen many logical systems which support so-called nonmonotonic inferences. in these formalisms one is allowed not only traditional inferences of classical logic  but also more  speculative  ones. it is often said that in those systems one may  jump to a conclusion  in the absence of evidence to the contrary  or that one may assign formulas a  default value   or that one may make a  defeasible inference.  the prototypical example is inferring that a particular individual can fly from the fact that it is a bird  but retracting that inference when an additional fact is added  that the individual is a penguin. this is why such formalisms are called nonmonotonic: a fact entailed by a theory might no longer be entailed by a larger theory. of course  classical logic is monotonic. 
the original and best-known nonmonotonic logics are mc-
carthy's circumscription   reiter's default logic   mcdermott and doyle's nonmonotonic logic i   mcdermott's nonmonotonic logic ii   and clark's predicate completion . in recent years many more systems have been suggested  and the old ones were further explored. lifschitz provided new results on circumscription . further investigations of default logic include etherington's work  and lukaszewicz' . moore's autoepistemic logic  is an adaptation of mcdermott's nml ii  and a version of it was further investigated by halpern and moses . 
　　these various formalisms are very different superficially. for example  circumscription amounts to adding a second-order axiom to a given first-order theory. a default theory  on the other hand  contains a collection of default rules   a notion quite outside classical logic  and its meaning is defined using a fixed-point construction which relies on those default rules. mcdermott's and moore's logics are still different  and formulas in those logics contain modal operators  which are meant to capture the notions of consistency and belief  respectively. the nonstandard nature of the various systems and their diversity has made it hard to 
*the work described here was curried out when the author was a graduate 
 tudent at yale university. 
1 	knowledge representation 
gain a good understanding of them and to compare among them. 
　　however  the main problem with existing nonmonotonic formalisms is not their overwhelming complexity  as much as it is their limited expressiveness. in particular  they were all shown to fail to capture nonmonotonic temporal inferences. the problems were first reported by hanks and mcdermott   in response to which several solutions were offered. one such solution was proposed by lifschitz  and it was to generalize circumscription to so-called pointwise circumscription . my approach has been to construct the logic of chronological ignorance   and in doing i defined a very general framework for nonmonotonic logics. the purpose of this paper is to present this general framework. 
　　this paper has two distinct parts. the first part is more technical  and consists of the next two sections. the next section introduce the general framework of nonmonotonic logics  the result being a simple system to which on the one hand all existing nonmonotonic logics can be reduced  and thus easily understood and easily compared to one another   and which on the other hand suggests radically new nonmonotonic logics. the 
section following that briefly shows how some previous nonmonotonic formalisms can be viewed as special cases of the general framework. the second part of the paper is more held at the intuitive level  and consists of the last section. it discusses the intuitive meaning behind nonmonotonic inferences  and argues that the proposed distinction between default inferences and autoepistemic ones should be abolished. 
1 formal construction of nonmonotonic logics 
the basic idea behind the construction is the following. in traditional logic  the meaning of a formula is the set of interpretations that satisfy it  or its set of models  where  interpretation  means truth assignment for pc  a first-order interpretation for fopc  and a  kripke interpretation  world -pair for modal logic . one gets a nonmonotonic logic by changing the rules of the game  and focusing on only a subset of those models  those that are  preferable  in a certain respect  these preferred models are sometimes called  minimal models   a term introduced by mccarthy in connection with circumscription . the reason this transition makes the logic nonmonotonic is as follows. in classical logic a  = c if c is true in all models of a. since all models of a a b are also models of a  it follows that a a b  = c  and hence that the logic is monotonic. in the new scheme we 


	shoham 	1 

theorem 1 let lc be a preferential logic. then the following two statements are equivalent: 

1.  is monotonia. 
1 special cases 
in  t discuss previous nonmonotonic systems in some detail  and show how they can be viewed as special cases of the proposed general framework. in particular  i discuss both mccarthy's and lifschitz' versions of circumscription  bossu and siegel's formalism   reiter's default logic  and a version of moore's autoepistemic logic due to halpern and moses . here i will be able to provide a comparison with only three of those  and very sketchily at that. 
1 	circumscription 
circumscribing a formula amounts to adding a second order axiom to a theory. mccarthy's original circumscription axiom  and 1 am using lifschitz' recent reconstruction of it  was: 

where p is a predicate variable with free variables x  and p p stands for 

this axiom is one way of defining a preference criterion on models  according to which 
1. for all x  m1 and m1 agree on the interpretation off function symbols and all relation symbols other than p  
1. for all 
other circumscription axioms embody similar preference criteria. to avoid giving the wrong impression  it must be said that the notion of preferred models was implicit in mccarthy's work from the start. in fact  in his original paper he gave a minimality criterion similar to the one stated above  although in subsequent publications the model-theoretic discussion seemed to play a diminishing role. other researchers too have addressed the model theory of nonmonotonic logics  such as lifschitz in  and etherington in . 
   my formulation can be viewed as a suggestion to generalize mccarthy's approach in three ways: 
1. start with any standard logic  not necessarily fopc. for example  i base my formulations on a standard modal logic. 
1. allow any partial order on interpretations  not only the one implied by a particular circumscription axiom. for 
1 	knowledge representation 
example  in  i suggest a preference criterion that relies on temporal precedence. 
1. shift the emphasis to the semantics  stressing the partial order on models and not the particular way of defining that partial order. in fact  allow the definition of this partial order in any way that leaves no room for ambiguity. the various circumscription axioms  either mccarthy's original ones or lifschitz's more recent ones  are one way of doing so  and they are most elegant. in my own formulations i have chosen other means of defining preference criteria. 
1 	bossu and siegel 
at the time this work was conducted i was unaware of related previous work by bossu and siegel   or 1 would have made an effort to use their terminology where possible. as things are  i renamed some of the concepts they had come up with  and by now i am too fond of my definitions to let go of them. let me  however  make clear the connection between the two treatments. the summary of it is that they share the basic semantical approach  although there are some minor technical differences between the two  but that bossu and siegel thoroughly investigated what turns out to be a very special case of my general formulation. in a little more detail the connection is as follows. 
   the main part common to both bossu and siegel's treat ment and my own is the model-theoretic approach  which posits a partial order on interpretations. there are some minor differences in the precise definitions. for example  whereas i defined a to be preferentially satisfiable  or  in their terminology  minimally modelahle  if  has a preferred model  bossu and siegel require in addition that any nonpreferred model of a have a. better model than it which is preferred. or  as another example  they explicitly reject the definition i chose for preferential entailment  which they call subimplication and denote by i=   since if p is not preferentially satisfiable  i.e.  it has no maximally preferred models  then it entails both  i don't view that as a disadvantage  since preferential satisfiability plays a role that is completely analogous to satisfiability. thus by the same argument one should object to the regular notion of entailment  since inconsistent  i.e.  unsatisfiable  theories entail both v and 
   these are fairly minor differences  and they are overwhelmed by the similarity in the semantical approach to nonmonotonic 
logics. there is  however  a big difference between the two treatments  and that is in their generality. whereas 1 allow starting with arbitrary standard logics as a basis  bossue and siegel require starting with fopc. more crucially  whereas i allow any partial order on interpretations  bossu and siegel assume one fixed such partial order. as they themselves say  
the difference between  john mccarthy's  definition and ours is that mccarthy 'minimizes' on some lit erals only  whereas we 'minimize' on every literal. 
circumscription was discussed in the previous subsection. as we have seen  in the simplest version of the logic  preferred models are those in which  are true for as few xi's 

on the face of it this distinction is quite appealing  certainly 1 was convinced for a while   but upon closer examination it seems to break down completely. 
   to begin with  one may note that moore applies his own logic  labelled an autoepistemic one  to the flying birds example  which he himself characterizes as a default case. furthermore  consider moore's own older brother example. if one accepts the statement  if i had an older brother then i'd know it   surely one must also accept the statement ''if i didn't have an older brother then i'd know it.  yet if we adopt this latter sentence rather than the first one  the opposite inference will follow  namely that i have an older brother. on what basis does one prefer you adopt both .sentences  then you end up with two distinct preferred models one in which you have an older brother and know it  and another in which you don't have an older brother and know it - which isn't much help. 
   let me suggest a different distinction than the one made by moore. rather than distinguish between different kinds of default inferences  one should distinguish between the meaning of sentences on the one hand  and the  extra logical  reason for adopting that meaning on the other. the meaning  i argue  can be viewed epitemically. the reason for adopting that mean ing is computational economy  which often relies on statistical information. 
   consider the flying birds example. the meaning of  birds fly by default  is that if 1 don't know that a particular bird can not fly  then it can. the computational reason for adopting this meaning is that now whenever a bird can indeed fly  we need not mention the fact explicitly either in external communication with other reasoners  or in  internal communication   i.e.  thought it will follow automatically. of course  if we happen to be talking about a penguin  we had better add the knowledge' that penguins cannot fly  or else we will make wrong inferences. in the long run  however  we win: the overwhelming percentage of birds about which we are likely to speak can indeed fly  and so on average this default rule saves us work. if this gain seems small  consider a realistic situation in which we apply thousands and thousands of such rules. 
   can we identify a similar rationale behind the rule  by de fault  i do not have an older brother   it is less obvious here  which is why the two cases seem superficially different. yet such motivation must exists  or else one wouldn't prefer this rule to the opposite one. perhaps the rationale is again a simple count ing argument on average a couple has two children  so the speaker has a 1% chance of being the younger one  in which case there is a 1% chance that the older sibling is male. thus in 1%  of the cases the speaker does not have an older brother  which is not quite as overwhelming as the percentage of flying birds  but still is higher than 1%.1 perhaps in fact the motivation for adopting the default rule is more sophisticated  but some motivation must exist. 
   1 am not at all arguing that one makes p true by default just in case p is true most of the time. as 1 have said  the flipside of making a default assumption is the danger of making faulty inferences. for example  if a bird is being discussed and its type is unknown  we will infer that it can fly even though it might turn out to be a penguin. if this seems harmless  think of making the default inference  people you'll meet on the street will not stab you in the hack  in a city in which only 1% of the population are back slabbers. in this case the relatively small chance of being badly hurt seems to outweigh the computational resources needed to reason about individual people on the street  and the discomfort of wearing a steel-plated vest. notice that if the 1% dropped to 1%   we'd take off the armor and stop looking darkly at passers by. indeed  that is exactly how we treat the possibility of a nuclear war. clearly  one must maximize his expected utility when selecting a nonmonotonic theory. 
the first sentence to the second one  if at all  notice that if 
	shoham 	1    1 this argument was suggested by drew mcdermott  half in jest  after he was convinrrd of its conclusion 
   i offer no general guidelines for making such a selection. all i am suggesting here is to separate the two issues  that of defining the meanings of nonmonotonic logics  and that of selecting one. 
   notice. the remainder of this section  in which two more arguments are offered in support of the proposed meaning/utility distinction  assumes acquaintance with mccarthy's circumscription  and with modal logics of minimal knowledge. those were referred to briefly in the previous section  but the reader who is unfamiliar with them may find the following a bit cryptic. in  a more detailed discussion of those logics is offered. 
　the reader may still be bothered by the fact that circumscription involves only classical sentences  and it is not clear how epistemic notions enter into it. it is not hard  however  to convert circumscription into a logic of minimal knowledge. the basic idea is instead of circumscribing a formula     to add the 
 '.'..  for example  in the flying birds case 
; since we pre-
fer models in which as few propositional formulas as possible are known  the effect is to have p true of as few x's as possible. the natural reading of the axiom is indeed  if were true then i'd know it.  however  if we take the contrapositive form 
of the axiom  we get the familiar  default rule :  or 
 if it is possible that p is false then it is.  
   as a final clincher in the argument for the meaning/utility distinction  let me show how this distinction resolves the lottery paradox  discussed  for example  in . the paradox is as follows: 
a lottery is held with 1 million participants  including our friend john. the odds of john's winning are so low that we infer by default that he won't. yet by the same token we can infer that none of the other 1 members will win  which contradicts our knowledge that at least one person must win. 
in the logic of minimal knowledge  which  as we have just seen  can be translated back into circumscription  we describe the situation bv 

the most ignorant models are ones in which one of the million people wins and we know that he won it  but the identity of that person varies among models. we are therefore not justified in concluding that any particular individual will not win  since there are models in which he does. true  those models are vastly outnumbered by those in which he does not win  but nonmonotonic logics do not let us express the property of a proposition being true in  most  models. this once again shows that such probabilistic information plays a role in choosing the meaning but not in defining it. 
   so in the above formulation we cannot conclude that john will not win  nor should we want to. if one claims that such a conclusion is one that corresponds to default reasoning people use  one must agree to the conclusion that no rational person would ever buy lottery tickets  a prediction that obviously isn't born out in reality.1 however  the above formulation is not as 
   1 the argument thai indeed no rational person should  given thai in all lotteries the expected winning amount is negative  is irrelevant. the example would still hold if some bored millionaire organized the lottery  charging each participant one dollar and giving the winner one million and one dollars. 
1 	knowledge representation 
useless as it might appear. we can still make inferences involving the possibility of people winning  in which rather than condition an inference on their not winning  we condition it on the possibility of their not winning. for example  we may add the sentence 

the rationale here is again statistical. although there is a model in which i win the lottery and therefore needn't bother teaching a course on ai  it would be foolish for me to resign on that basis. 
1 	s u m m a r y 
i have presented a uniform approach to constructing and understanding nonmonotonic logics. the value in the formulation has not been its mathematical sophistication  but rather the opposite: the only notion added to traditional logic was that of a partial order on interpretations. the simplicity of the formulations makes transparent what in other systems is less immediate. the formulation is not only simple but also very general  and subsumes previous systems. i briefly indicated how previous systems are a special case of this general framework; in   a 
more detailed comparison with previous nonmonotonic systems is provided. also  i have argued against the proposed distinction between different kinds of nonmonotonic inferences. 
   several open questions remain. one of them has to do with the relation to other nonstandard logical formulations. in partic ular  johan van benthem has drawn my attention to the close parallels between my formulations and formulations in conditional logic  as pioneered by d. lewis  1 . in cl one has  instead of a partial order on interpretations  a similarity measure on possible worlds  and the notion of counterfactual entailment is similar to my notion of preferential entailment. i would like to understand this connection better. 
   another open question is which particular instances of the general framework i have outlined are interesting from the practical point of view as i have said  the general treatment of nonmonotonic logics offered here grew out of limitations of existing systems. it is still the case  however  that very few concrete preference criteria on models have been investigated. the most common ones are those embodied in the various circumscription axioms and in some default theories. one preference criterion transcending those is that of chronological ignorance   presented in . lifschitz too has investigated an instance of pointwise circumscription that does not collapse into  old  circumscription. all these  however  are still a drop in the bucket  and we have yet to understand which of the many possible partial orders on models are of practical importance. 
bibliography 
1. g. bossu and p. siegel  saturation  nonmonotonic reasoning  and the closed world assumption  artificial intelligence  1   january 1  pp. 1. 
1. k. l. clark  negation as failure  in h  gallaire and j. minker  eds.   logic and databases  plenum press  new york  1  pp. 1. 
1. d. w. etherington  reasoning with incomplete information: investigations of non-monotonic reasoning  ph.d. thesis  computer science department  university of british columbia  1. 
1. j. halpern and y. moses  towards a theory of knowledge and ignorance: preliminary report  technical report rj 
1  ibm research laboratory  san jose  october 1. 
1. s. hanks and d. mcdermott  temporal reasoning and default logics  technical report yalu/csd/rr 1  yale university  october 1. 
1. d. lewis  counterfactuals and comparative possibility  in harper et al.  eds.   ifs  reidel  dortrecht  1  book: 1   pp. 1. 
1. v. lifschitz  computing circumscription  proc. 1th ijcai  august 1. 
1. v. lifschitz  pointwise circumscription  proc. aaal  philadelphia  august 1. 
1. v. lukaszewicz  considerations on default logic  proc. aaa i workshop on nonmonotonic reasoning  1  pp. 1. 
1. j. m. mccarthy  circumscription - a form of nonmonotonic reasoning  readings in artificial intelligence  tioga publishing co.  palo alto  ca  1  pp. 1. 
1. d. mcdermott and j. doyle  nonmonotonic logic i  artificial intelligence 1  1  pp. 1. 
1. d. mcdermott  nonmonotonic logic ii: nonmonotonic modal theories  j acm  1   1  pp. 1. 
1. r. c. moore  semantical considerations on nonmonotonic logic  proc. 1th ijca1  germany  1. 
1. r. reiter  a logic for default reasoning  artificial intelligence  1  1  pp. 1. 
1. y. shoham  reasoning about change: time and causation from the standpoint of artificial intelligence  ph.d. thesis  yale university  computer science department  1. 
1. y. shoham  chronological ignorance: time  nonmonotonicity and necessity  proc. aaai  philadelphia  august 1. 
1. j. van benthem  foundations of conditional logic  journal of philosophical logic  1  january 1  pp. 1. 
