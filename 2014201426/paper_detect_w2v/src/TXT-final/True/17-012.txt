 
     this paper describes an object recognition algorithm both on a sequential machine and on a simd parallel processor such as the mit connection machine. the parallel version is shown to run three to four orders of magnitude faster than the sequential version. 
i. introduction 
     many problems in early vision appear to be inherently local and exploitable on parallel computer architectures. can algorithms for higher perceptual functions also be mapped onto the coming wave of massively parallel machines  this paper examines the process of recognising an unknown object and matching it to a data base model given only sparse sensory data points. the algorithm presently used on a sequential machine is first explained  and then various algorithms for parallel computation are explored. tradeoffs in space-time efficiency are discussed in terms of implementation on a connection machine . 
ii. sequential algorithm 
     the problem considered here is that of recognizing an object and determining its position and orientation  1  1 . sensory data can be acquired from a variety of modalities  such as tactile sensors  or laser or sonar rangefinders  but the algorithm is independent of the specific type of sensor used. it assumes that only a few data points are available  and uses local constraints intrinsic to the shape of the object to prune the search space of possible interpretations. 
     as an example  suppose we had a rectangularly shaped figure with opposing sides of length three and four  figure 1. the object is lying on a table  and we also have a description of it in a data base. imagine a three fingered robot hand equipped with tactile sensors touching the object at the points marked p1  p1 and p1. from this data only  we would like to determine whether or not these three points could possibly be resting on the faces of our test object  and if so  where the object lies with respect to the robot hand. 
   support for the laboratory's artificial intelligence rcscaich is provided in part by the advanced research projects agency of the department of defense under office of naval research contract n1-c-1. the office of naval 
research under contract number n1-c-1  and the system development foundation. 
figure 1:a four sided object with three data points. 
     a tree of possible matchings of points to faces is shown in figure 1. the first level of the tree represents the fact that p1 could lie on one of the four faces of the object. similarly  the second level shows that p1 could lie on any one of four faces given p1's assignment for three data points  there are 1 possible matchings of data points to object faces. each possibility must be checked to see if the object can be rotated in some way  so that the points actually do fall on the faces of the object 
     for an object with n faces and k data points  there are nk possible rotations to check. that involves quite a lot of computation for a multi-faceted object the basic idea of the 

figure 1:the interpretation tree 

1 	a. flynn and j. harris 
algorithm described in   is to prune the interpretation tree so that fewer rotations  or model tests  need be performed. 
     one constraint used to narrow the search space is the distance constraint between faces of the object. for the example object  we know that the minimum distance between face1 and face1 is zero and the maximum distance is five. figure 1 shows the range of possible distances between pairs of faces on our lest object the first number is the minimum distance and the second number is the maximum distance. 

figure 1:distance ranges between objects 
     as can be seen  any experiment which measures the distance between p1 and p1 to to be 1  renders inconsistent any branch of the tree which assigns  thus  those branches of the tree can be pruned and need never be model tested. 
　　to continue the example  suppose we measure the distances between all possible pairs of our three data points and determine that the distances are: by consulting our table  we find that   cannot both be assigned to f1 or both to f1. it also cannot be the case that is consistent with an assignment to f1  or vice versa . 
the second measurement is inconsistent with a pairing of 
the third measurement similarly 
the number of 
possible interpretations of the data is reduced from 1 to 1  as shown in figure 1. other constraints can be used to further prune the tree before model testing need be done. 
     at present  this algorithm  running on a sequential machine  is set up to do a depth first search  pruning when it can. for an object with about a dozen sides and several data points  the program takes on the order of a few seconds. recently  an algorithm has been proposed by grimson and lozano-perez which allows the search space to be explored in parallel on a connection machine . after outlining that algorithm  we describe a new one that captures more parallelism in the problem and therefore runs faster. 

figure 1:possible interpretations pruned. 
iii. parallel bit array algorithm 
     the mit connection machine is a massively parallel machine  containing 1 processors connected together both in two-dimensional nearest-neighbor fashion and also through a global routing mechanism whereby any processor can talk to any other processor arbitrarily. each processor contains 1k bits of memory. 
     the algorithm proposed in  exploits the router feature of the connection machine because there is no inherent locality to the recognition problem. the interpretation tree is a data abstraction  in contrast to the pixel-based locality characteristic of early vision problems. 
     this algorithm generates and prunes new levels of the tree in parallel by having connection machine processors hold bit arrays which represent consistent pairings of points to faces. figure 1 shows three processors holding the consistency arrays for our previous example. the zeros represent pairings of data points with the data base model that were inconsistent imagine ones in all the empty boxes. 
     generation and pruning of new branches in the tree is done in parallel when adding the constraint imposed by a new data point. the algorithm for updating  say p1 with respect to p1  is to do a data base merge on the p1 and p1 consistency arrays and then and the resulting array back into the p1 array. a data base merge is similar to a matrix multiply except that one array is transposed and the logical operations of and and or are used instead of multiplications and additions. what all this accomplishes  is a propagation of constraints and a generation of a new level of the tree. for an n-sided object and k data points  there 


figure 1:consistency arrays 
will be k -k nxn arrays of possible pairing of points to faces. each one of these arrays  in this case  six  is updated in parallel but each of these processors is multiplying two nxn matrices which is an order n1 operation. 
     unfortunately  the norm in most recognition problems that use a robot hand and tactile sensors is for n  the number of faces of the object  to be quite large  while k  the number of data points  is usually small. for an object with n = 1  and assuming a conservative 1 second clock  it has been determined that this algorithm would take roughly two seconds. our parallel algorithm here isn't buying us much. it would be much better to be doing n operations in parallel  with each processor taking k -k steps  six  in our example here . 
iv. static algorithm 
     if we use nk hardware we can do the computation in nearly constant time. we allocate a separate processor to represent each element in a three-dimensional consistency array of possible pairings of  to appropriate faces of the object this representation  shown in figure 1  which can be extended to arbitrary dimensions for more data points  does away with the need for database merges or constraint propagation. 

figure 1:slices of a three dimensional consistency array 
　　each processor contains in its own state variables the appropriate part of the distance constraint table for the faces it represents. the processor marked a  because of its location in the array  is to mark the truth or falsehood of whether or not the p a i r i n g t o is consistent. before run time  it must have in its state variables the appropriate distance constraints between these faces. at run time  as each distance measurement is broadcast 
	a. flynn and j. harris 	1 
to all the cm processors  each processor checks if that measurement falls within the allowed range. 
     all the processors' flag bits have previously been initialized to one. if any broadcast measurement does not fall in the specified range  the flag is anded with zero. after all data is broadcast any processors still marked one are valid interpretations. the time to do this is order k1 since there are  k1-k /1 distance measurements to broadcast. assuming 1 bit precision  it would take 1 cycles for a processor to read in a broadcast measurement comparison with the upper and lower ranges would lake 1 cycles  plus 1 cycles to 
and the results with the flag. these 1 cycles are repeated  limes. the number of processors needed is nk and memory per processor is  registers plus 1 bit for flags. for 1 data points and a 1 /xsecond cycle time  this process could be completed in 1 /iseconds  using n1 processors  where each processor needs six registers and one bit of memory. this is roughly four orders of magnitude faster than the sequential algorithm on a lisp machine. 
     for some objects  with n large  there may not be enough processors available. state variables for several processors can then be grouped into one. where that processor sequentially checks its constraints. if g processors are grouped into one processor  then the time to run the algorithm becomes order gk1  the number of processors needed will be nk/g  and the memory per processor becomes gk k-l  1-bit registers plus g bits for flags. 
     in general  we'd like to have many objects in the data base. if there are enough idle processors  we can put all the objects in the cm array and again do the search in order  k k-l  /1 time. if there aren't enough processors  different objects can be worked on sequentially  or g processors can be grouped into one so that all objects fit into the cm array. either way  it takes the same amount of time and space per processor. for 1 objects  each with 1 sides  and 1 data measurements  we would need 1 processors. the recognition algorithm would still run in 1 jiseconds and each processor would again need six registers and one flag bit however  we still aren't fully utilizing our machine. only 1 bits out of the 1k available is in use in each processor. if we put the data for 1 more objects in each processor  wc will have 1 times as many objects in the data base. the search will then be 1 times as long. this means that we can recognize an object from a data base of 1 objects  each with 1 sides in 1ms. 
     all of this assumes that the constraint table has been loaded into the processor array at compile time. in actuality  the' time to load the table is much longer than the time to recognize the object even so  for 1 ten-sided objects  one-time loading takes only half of a second. 
     a better way of getting the constraint information into the processors is not to compute the table offline and then load it in  but to have each processor compute the appropriate information. this way the table  which has to be computed anyway  is now computed in parallel. in addition  the loadup cost is significantly reduced. we simply have to broadcast the coordinates of the vertices of the faces of the object broadcasting the vertices takes 
1 a. flynn and j. harris order n time  whereas our earlier scheme of broadcasting an already computed distance constraint table  would take order n1 time because we'd have to broadcast to each processor in the array. 
     after having received the broadcast vertices  each processor will calculate the distances between the faces appropriate for that processor and the corresponding maximum and minimum. if there are enough processors available  this computation of the distance constraint table is done in a time independent of n. the time is a small constant  the number of cycles it lakes to calculate the maximum and minimum of the four possible distances between any two sides. 
     we've taken an algorithm that would be unthinkable on a sequential machine and brute force implemented it on a simd array. instead of generating and pruning the interpretation tree level by level  we have simply assigned processors to all the leaves of the expanded tree and actually completed one pruning step in constant time. the connection machine is used here as if it were a 
     content addressable processor  and no use is made of the router. 
     we call this method the static algorithm  because all possible processors in the connection machine have been allocated before we start the search. this means that the machine must be big enough for the problem. specifically  the number of processors needed   nk /g  must be less than 1  and the amount of memory per processor required  1gk k-l  + g  must be less than 1k bits. when using tactile sensors  the number of data points  k  is small and this static algorithm is adequate. 
v. dynamic algorithm 
     however  when using laser rangefinders  more data points are generated  and k often becomes as large as 1. furthermore  when the objects are more complicated  they may have as many as 1 faces. the problem quickly gets too big even for our 1 processor machine. the solution is to use a dynamic algorithm which generates enough levels of the tree to fill the machine  does a pruning step  generates new levels of the tree to again fill the machine  and repeats. these ideas are the subject of future research. 
     this dynamic algorithm requires that the machine be able to find unused processors to represent the new branches of the tree. the machine must also be able to deallocate processors that no longer represent consistent pairings. the deallocated processors are then able to be reused for future pruning steps. the connection machine  with its global communication ability is able to support these mechanisms  1 . a strictly content addressable processor could not support this dynamic pruning algorithm. 
vi summary 
     a well-established sequential algorithm for object recognition was explained and fast connection machine algorithms were devised. first  a static parallel algorithm was discussed  in which the entire tree of possible interpretations is loaded into the connection machine before run time. the search is then done in one step and therefore in constant time. 
     for problems which are too large to fit in the array  a dynamic algorithm was devised. in this algorithm  the connection machine is loaded with as many levels of the tree as can fit then a 
     pruning is done in parallel as in the static algorithm. however  processors that still represent consistent pairings must find unused processors which are assigned the new branches of the tree. this is similar to the way the sequential algorithm  first described  prunes the search space. processors that are pruned are deallocated and reused on the next iteration. the router mechanism of the connection machine  which is not used in the static algorithm  is necessary here to support dynamically allocating and deallocating processors. 
acknowledgments 
     this work was aided by contributions from tom knight  eric grimson and phil agre. 
