 
the ability to learn from data and to improve its performance through incremental learning makes self-adaptive neural networks  sanns  a powerful tool to support knowledge discovery. however  the development of sanns has traditionally focused on data domains that are assumed to be modeled by a gaussian distribution. the analysis of data governed by other statistical models  such as the poisson distribution  has received less attention from the data mining community. based on special considerations of the statistical nature of data following a poisson distribution  this paper introduces a sann  poisson-based self-organizing tree algorithm  psota   which implements novel similarity matching criteria and neuron weight adaptation schemes. it was tested on synthetic and real world data  serial analysis of gene expression data . psota-based data analysis supported the automated identification of more meaningful clusters. by visualizing the dendrograms generated by psota  complex inter- and intra-cluster relationships encoded in the data were also highlighted and readily understood. this study indicate that  in comparison to the traditional self-organizing tree algorithm  sota   psota offers significant improvements in pattern discovery and visualization in data modeled by the poisson distribution  such as serial analysis of gene expression data. 
1 introduction 
knowledge discovery has been defined as a nontrivial process of identifying valid  novel  potentially useful  and ultimately understandable patterns in data  fayyad et al.  1 . data mining is a particular step in this process  which involves the application of specific algorithms for extracting patterns from data  fayyad et al.  1; fayyad et al.  1 . there are a wide variety of techniques suitable for various data mining tasks. from the knowledge discovery perspective  unsupervised learning-based clustering analysis has become a fundamental approach  which has resulted in a large number of clustering techniques. examples of powerful and meaningful techniques include the development of self-adaptive neural networks  sanns -based clustering models. this paper focuses on this clustering principle because sanns have demonstrated several unique and interesting features in data mining and knowledge discovery. 
1 sanns: overview of principles  applications and limitations 
sanns represent a family of unsupervised learning models  which follow the basic principle of the self-organizing feature map  som   kohonen  1  with a focus on adaptive architecture. a key advantage of these models is that they allow the shape  as well as the size  of the network to be determined during the learning process rather than by a predetermined grid of neurons. for example  the growing selforganizing map  gsom   alahakoon et al.  1  is initialized with a map of 1 x 1 neurons and new neurons are incrementally grown from a boundary neuron where the network exhibits a large cumulative representation error. after learning  gsom can develop into different shapes depending on the clusters present in the data. in the growing cell structures  gcs   fritzke  1   the initial topology consists of a two-dimensional output space where the neurons are arranged in triangles. a new neuron is inserted by the splitting of the longest edge emanating from the neuron with maximum accumulated error. gcs performs an adaptation of the overall structure in those regions that represent large portions of the input data. based on both the som and the gcs principles  dopazo and carazo  proposed the self-organizing tree algorithm  sota . one of the main contributions of sota is that the output space is arranged following a binary tree topology  in which the number of output neurons is adapted to the intrinsic characteristics of the input data  dopazo and carazo  1; herrero et al.  1 . 
　due to its dynamic  self-evolving nature  the resulting maps of sann can reveal relevant patterns from the underlying data in a more meaningful fashion. for example  due to the ability to separate neurons into disconnected areas  the gcs can produce explicit representations of cluster boundaries. thus  patterns hidden in the data become more apparent  fritzke  1 . the gsom  on the other hand  can indicate the patterns in the data by its shape and attract attention to such areas by branching out. such a flexible structure may provide a meaningful visualization of clusters in the data  alahakoon et al.  1 . 
　sanns are well adapted to various application domains. for instance  they represent a promising way to improve biomedical pattern discovery and visualization. the growing cell structure visualization toolbox  walker et al.  1   for example  is an implementation of gcs networks in the matlab 1 computing environment. this tool has been commonly used for the visualization of high-dimensional biomedical data. sota has been shown to be capable of performing pattern discovery across various biomedical domains. dopazo and carazo  used sota to cluster aligned sequences. it has also been applied to the supervised  wang et al.  1a  and unsupervised  wang et al.  1b  classification of protein sequences. more recently  herrero and colleagues  herrero et al.  1  extended its application to the analysis of gene expression data derived from dna array experiments. 
　however  most of current sanns are based on some heuristic criteria that take the accumulated quantization error into account to guide the growth of neural networks.  for example  during the learning process gsom  alahakoon et al.  1  applies euclidean distance to determine the winning neuron for each input data and a cumulative error is calculated for each winning neuron using the euclidean distance-based metric. in the growing phase  the network keeps track of the highest error value and determines when and where to grow a new neuron. such a criterion  however  is not suitable for problems in which the data are better approximated by a poisson distribution  i.e. a mixture of separate poisson-distributed data sources   such as phenomena in which events are observed a number of times over specific intervals. emerging problem domains in bioinformatics such as the study of serial analysis of gene expression  sage  data  velculescu et al.  1  may also be approximated by a poisson distribution. euclidean distancebased clustering analysis has demonstrated poor performance in these domains  cai et al.  1 . without taking into account the statistical nature of the data during the learning process  the full potential of sanns may not be realized. 
1 objectives of this study 
this paper aims to present a new sann model  which takes into account the specific statistical nature of data approximated by a poisson distribution  to improve data mining and knowledge discovery. the main objective of this study is  based on the incorporation of a poisson statistics-based distance function  to develop a sann model tailored to the data approximated by a poisson distribution. this required the implementation of new strategies for weight adaptation and network growth. 
　the remainder of this paper is organized as follows. section ii describes important statistical properties of the poisson distribution  followed by a detailed description of the new sann learning algorithm: poisson-based selforganizing tree algorithm  psota . two datasets  including synthetic and real world data  are described in section iii. results and a comparative analysis are presented in section iv. this paper concludes with the discussion of results and future research. 
1 algorithms and implementation protocols 
1 statistical nature of a poisson distribution 
the poisson distribution describes a wide range of natural phenomena. this distribution may be used to model the number of events occurring within a given time interval when such events are known to occur with an average rate. the formula for the poisson probability mass function can be represented as: 
　　　　　　p m  m! 	 1  where p m  is the probability of observing m occurrences  and  is the shape parameter that estimates the average number of events in a given time interval. 
　the poisson distribution has several unique features. most distinctively  the mean of any poisson distribution is equal to its variance. in other words  the larger the value of the mean  the less significant the deviation between a count value observed and its expected value. 
1 description of psota 
psota is based on the same principle of the sota 
 dopazo and carazo  1 . its structure is started by generating an initial network composed of two terminal neurons connected by an internal neuron  as shown in figure 1 a .  the output topology is incrementally constructed by generating two new terminal neurons from the leaf neuron having higher resources  measured as the mean distance between the weight of each neuron and all the data samples assigned to this neuron  after each cycle  figure 1 b  and  c  . for a given training dataset  t  consisting of n samples  a learning cycle consists of a series of learning epochs  within which the network is sequentially presented with each training sample. however  by taking into account the statistical nature of data closely following a poisson distribution  psota adopts novel matching criteria  1  to determine the winning neuron for each input sample and  1  to update the weight vectors of the winning neuron and its neighborhood. 

figure 1: new neurons generation process for psota.  a  the psota initial topology;  b  the accumulation of resources  the heterogeneity of each neuron  during learning process  the neuron marked with a filled circle  neuron b  has the highest cumulative resource after a learning cycle;  c  neuron b gives rise to terminal neurons d and e  leaf neuron . thus  d and e are sister neurons  whose ancestor neuron is b. 
matching criterion for finding a winning neuron  wc  for a given input vector  xi
traditional sanns  e.g. sota  normally apply euclidean or pearson correlation-based distance to determine the winning neuron for each input data. these distance measures have achieved a great success for data approximately following a normal distribution. for data associated with a poisson distribution  however  these measures have shown poor performance  cai et al.  1 . on the basis of the consideration of the statistical nature of a poisson distribution  two new criteria based on chi-square statistics and a joint likelihood function are introduced here.  
　let xi be the input vector representing the ith input sample  wj be the associated weight vector of the jth neuron  and the index k indicate kth value of n-dimensional vector  the winning neuron represented by the subscript c can be determined by the following minimum chi-square statistics- based distance matching criterion.  
 1 
 1 
　given that in the poisson distribution  the probability of a number of events occurring within a given time interval is considered to be independent of events that occurred in previous time intervals  the winning neuron can be also determined by using the maximum joint likelihood functionbased matching criterion: 
n
	p i xi k! 	 1 
j  1  
where x i k is the expected value of xi k . after completing a learning process  each weight vector in the sota coincides with the centroid of the respective cluster of the input data. moreover  we are interested in grouping samples with similar relative values rather than the absolute values. thus  the expected kth value of ith input given the weight vector of jth neuron  x i k  j   is calculated as follows: 
n
	x i k  j	 wj k    xi k	 1 
k 1
　this equation is used  together with equations  1  and  1  or  1  and  1   to find a winning neuron. the matching criteria expressed in equations  1  to  1  suggests that when the expected values are large  the deviation between actual and expected count values become less significant. this is consistent with an important property of the poisson model  i.e. the variance of the dependent variable equals its mean  which is totally ignored by using euclidean  or other traditional  distance-based error calculation approaches. 
weight adaptation for a winning neuron and its toplogical neighborhood 
like other sanns  once the winning neuron has been identified for each input sample  it is necessary to define a method to update the weight vectors of the winning neuron and its neighborhood in order to better match the input vectors and fulfill the overall clustering goals. in psota  the main goal is to assign an input data to a neuron with the most similar relative vector. thus  instead of performing weight adaptation simply based on absolute values  like in other sanns  e.g. traditional sota   we propose the following weight adaptation strategy  which updates all relative weight values within the neighborhood  nc   t   of a 
　　　　　　　　　　　　　　　　　　　　　　　　　　　th winning neuron  c  according to the given i input.   

where wj k  t  and wj k i t 1  are the kth weight values of neuron j before and after the adaptation at iteration t.
nc  t  and  t  represent the neighborhood of the winning neuron c and learning rate at iteration t respectively. the reader is referred to  dopazo and carazo  1; herrero et al.  1  for a more detailed description of the selection of nc  t  and  t  for sota-based algorithms. the learning algorithm of psota is summarized in table 1. 
1: initialization 
1: repeat cycle 
1:   repeat epoch 
1:     for each input sample  
1:      find the winning neuron for each input using  1  to  1   
1:      update the winner and its neighbors using   1  1:      calculate the resource for each neuron. 
1:   until a cycle finishes: relative increase of the error between two consecutive epochs falls below a given threshold. 1:    grow new neurons from the one having higher resource 1: until the highest resource reaches a given threshold. 
table 1: a summary of psota learning algorithm 
1 implementation protocols 
both psota and sota models were implemented within the software development framework provided by the opensource platform  tigr mev  saeed et al.  1 . unless indicated otherwise  the learning parameters for psota and sota are: the maximum number of learning cycles = 1  the maximum number of learning epochs = 1  and the learning rates for the winning  ancestor and sister neurons are set to 1  1  and 1 respectively  herrero et al.  1 .   
1 the datasets under study 
two datasets  including synthetic and real world data  were used to assess the psota algorithm.  
1 synthetic data 
the dataset was obtained from a study published by cai et al. . it included 1 synthetic samples  each represented by five simulated values at five time points: t1  t1  t1  t1  and t1. all the simulated values are generated independently using poisson distributions. based on the models they are generated from  the 1 samples are divided into four groups pa  pb  pc  and pd with 1  1  1 and 1 samples respectively. samples within the same group have similar profiles determined by the relative count numbers across different time points  as illustrated in figure 1  which shows the profiles of groups pa and pb. 

figure 1: an example of profiles for synthetic data.  a  group a  1 samples .  b  group b  1 samples . five time points are shown on the x-axis  while the y-axis represents the absolute simulated count numbers.  different greys stand for different samples. 
1 mouse retinal gene expression data 
to further evaluate the algorithm  a real world dataset generated by sage in mature and developing mouse retina was analysed  blackshaw et al.  1 . sage is a global geneexpression profiling technique designed to provide quantitative measures of gene expression in a particular cell or tissue obtained from different developmental stages or pathological processes  velculescu et al.  1 . the result of a sage experiment  known as a sage library  is a list of tags and the number of times each tag is observed within a biological sample.  it has been suggested that the count values of sage tags observed in a specific library can be approximated by a poisson distribution  cai et  al.  1 . 
　such distributions tend to be independent across different tags and libraries.  a detailed description of the sage technique and relevant applications can be found in velculescu et al. . the dataset under study includes 1 murine sage libraries from developing retina taken at 1-day intervals from embryonic day 1 to postnatal day 1 and adult retina: e1  e1  e1  e1  p1  p1  p1  p1  p1  and adult. the reader is referred to blackshaw et al.  for a full description of the generation and biological meaning of these libraries. a subset of 1 tags with known biological functions and distinctive expression patterns were analyzed. on the basis of their biological functions and temporal expression patterns during retinal development  these 1 tags may be divided into six distinctive clusters:   1  p1cluster  1 tags   which show high but transient expression at p1;  1  prenrichedcluster  which includes 1 tags that were found to be highly enriched in photoreceptor  pr -enriched genes;  1  perinatalcluster  1 tags   whose expression peak appears around p1;  1  cystallincluster  which includes 1 cystallin proteins;  1  embryoniccluster  1 tags   which show strong expression levels during embryonic days  and  1  neurod1cluster  which includes 1 tags having similar expression patterns as gene neurod1. these  natural clusters  have been defined as key functional classes in previous studies  blackshaw et al.  1; blackshaw et al.  1  
1 results 
1 analysis of synthetic data 
we first implemented a comparative analysis using the synthetic data with sota  figure 1 . by incorporating poisson statistics-based distance into the learning process  psota correctly constructed a dendrogram that reflect significant inherent relationships between the data samples. for example  psota with joint likelihood function-based distance produced a hierarchical topology with 1 terminal neurons  each neuron uniquely representing one natural class  see the class distribution over terminal neurons given in the right panel in figure 1 a  . moreover  by visualizing the whole hierarchical clustering process  a more comprehensive picture that highlights the similarity between all the data samples can be obtained. for instance  as can be seen from figure 1 a   psota first grouped 1 samples into 1 clusters  branches a and b . all samples from classes pa and pd are clustered together  branch a   while all of samples from classes pb and pc are grouped into branch b. this is consistent with the characteristics exhibited by this synthetic data. similar results were obtained when using chi-square statistic-based distance as shown in figure 1 b .  clustering analysis with traditional sota  based on euclidean distance and pearson correlation  figure 1 c  and  d   however  fails to detect the underlying data structure. for example  sota with euclidean distance groups classes pa and pd into the same cluster. 

figure 1: data analysis for synthetic data by  a  psota with joint likelihood function-based distance.  b  psota with chi-square statistic-based distance;  c  traditional sota with euclidean distance;  d  sota with pearson correlation-based distance. the left panel on each figure shows the dendrogram obtained by each method  while the right panel shows the class distribution over each neuron. 
1 analysis of mouse retinal sage data 
the outcomes of a comparative analysis of mouse retinal gene expression data with psota and sota are illustrated in figure 1. only the dendrograms generated by psota  with either joint likelihood function or chi-square statisticsbased distances  correctly depict significant relationships encoded in the sage data  figure 1 a  and  b  . this can be further demonstrated by the analysis of class distributions over the terminal neurons shown in the right panel in figure 1 a  and  b .  for example  1 p1cluster tags and 1 embryoniccluster tags were grouped together and assigned to the neurons a and e respectively  figure 1 a  . by contrast  the dendrograms produced by using sota with traditional distance measures are less meaningful  especially with euclidean distance  see figure 1 c  . this highlights the clear advantages of psota when dealing with datasets that follow poisson distribution. 

figure 1: data analysis for mouse sage data by  a  psota with joint likelihood function-based distance.  b  psota with chisquare statistic-based distance;  c  sota with euclidean distance;  d  sota with pearson correlation-based distance. the left panel on each figure shows the dendrogram obtained by each method  while the right panel shows the class distribution over each neuron. 
　a closer examination of the dendrogram constructed by psota  figure 1  a  and  b   reveals that by monitoring the learning process of psota the potential relevance of inter- and intra-cluster relationships hidden in the data can be readily detected and understood. for example  as shown in figure 1 a   at the early learning stage  samples belonging to p1cluster and prenrichedcluster were actually grouped together  suggesting common patterns between these two classes. the heat maps shown in figure 1 a  and  b  show that both clusters have strong expression levels at the p1 time point. significant relationships can also be obtained when analyzing relationships between other clusters. 

figure 1: heat maps  generated by psota  for sage tags that fall into  a  neuron a;  b  neuron b;  c  neuron c;  d  neuron d;  e  neuron e;  f  neuron f; and  g  neuron g  as shown in figure 1 a . each row represents expression level of a sage tag across sage libraries shown as columns in each image. the absolute abundance of each sage tag correlates with color intensity  black with the expression level equal to zero. the sage tags are displayed on the right side. 
1 discussion and conclusions 
from the pattern discovery perspective  clustering-based techniques have received great attention. however  cluster analysis of data approximated by a poisson distribution has not been rigorously studied. by incorporating poisson statistics-based distance functions into the learning process  this paper presented a new sann model  psota  specially designed to deal with problems modeled by poisson statistics  such as sage data analysis. the results obtained indicate that psota offers several advantages over traditional sann techniques. like sota  dopazo and carazo  1   psota not only incorporates some of the advantages demonstrated by hierarchical clustering and som  but also it implements unique features such as the generation of clusters at different levels. moreover  by using new matching criteria to determine the winning neurons and implement weight adaptation  significant improvements in pattern discovery and visualization are accomplished. by visualizing the dendrogram constructed by psota  complex inter- and intra-cluster relationships encoded in the data may be highlighted and understood. 
　the fundamental advantages of psota over sota are driven by the fact that psota is tailored to the statistical nature of poisson-distributed data. equations  1  and  1  include a factor determined by the sum over all the dimensions of ith input and jth weight vectors  which aims to group samples with relative similar profiles  values  into one neuron. 
　one crucial problem that needs to be further addressed is the optimal determination of learning parameters. currently  there is no standard way to define  a priori  the optimal learning parameters. one possible solution is to combine psota with machine learning-based searching techniques  such as genetic algorithms  to determine optimal parameter values  jin et al.  1 . this is part of our future research. 
　the poisson distribution has been used to model a wide range of natural phenomena. for example  in bioinformatics  transcription-factor binding sites and sage data may be modeled by poisson statistics. the pattern discovery and visualization techniques described in this paper have the potential to contribute to the improvement of data mining and knowledge discovery in these areas  in which the data represent a number of events occurring within a fixed time interval and when such events are known to occur with an average rate. nevertheless  if the data do not encode these types of situations other  traditional  methods may be equally recommended. 
acknowledgments 
we thank dr h. huang at the university of california  berkeley  for providing synthetic data and for helpful discussions. 
