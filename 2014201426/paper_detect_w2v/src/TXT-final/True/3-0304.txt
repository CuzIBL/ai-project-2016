 	and liu  1; brank et al.  1; dumais et al.  1 . 
 	while this weighting method seems very appropriate for ir  
it is not clear that it is the best choice for tc problems. 
knn and svm are two machine learning 
actually  this weighting method does not leverage the 
approaches to text categorization  tc  based on 
information implicitly contained in the categorization task to 
the vector space model. in this model  borrowed 
represent documents. 
from 	information 	retrieval  	documents 	are 
  to illustrate this  let us suppose a text collection x and two 
represented as a vector where each component is 
associated with a particular word from the 	categorization tasks a and b. under the tfidf weighting 
vocabulary. traditionally  each component value is 	representation  each document in x is represented by the 
same vector for both a and b. thus  the importance of a 
assigned using the information retrieval tfidf 
word in a document is seen as independent from the 
measure. while this weighting method seems very 
categorization task. however  we believe that this should 
appropriate for ir  it is not clear that it is the best 
not be the case in many situations. suppose that a is the task 
choice for tc problems. actually  this weighting 
that consists of classifying x in two categories: documents 
method 	does 	not 	leverage 	the 	information 
that pertain to computers and documents that don't. 
implicitly contained in the categorization task to 
intuitively  words such as computer  intel and keyboard 
represent documents. in this paper  we introduce a 
would be very relevant to this task  but not words such as 
new weighting method based on statistical 
the and of; for this reason  the former words should have a 
estimation of the importance of a word for a 
higher weight than the latter ones. suppose  now that b 
specific categorization problem. this method also 
consists of classifying x in two very different categories: 
has the benefit to make feature selection implicit  
documents written in english and documents written in 
since useless features for the categorization 
other languages. it is arguable that in this particular task  
problem considered get a very small weight. 
words such has the  english stop word  and les  french stop 
extensive experiments reported in the paper shows 
that 	this 	new 	weighting 	method 	improves 	word   are very relevant. however  under tfidf  the would 
significantly 	the 	classification 	accuracy 	as 	get a very small weight since its idf  inverse document 
measured on many categorization tasks.  	frequency  would be low. in fact  it would get the same 
 	weight that was assigned for task a. while this example is 
somewhat an extreme case  we believe that a weighting 
1   introduction 	approach could benefit from the knowledge about the 
categorization task at hand.  
knn and svm are two machine learning approaches to 	   in this paper  we introduce a new weighting method based 
text categorization  tc  based on the vector space model 	on statistical estimation of a word importance for a 
 salton et al.  1   a model borrowed from information 	particular categorization problem. this weighting also has 
retrieval  ir . both approaches are known to be among the 	the benefit that it makes feature selection implicit since 
most accurate text categorizers  joachims  1a; yang and 	useless features for the categorization problem considered 
liu  1 . in the vector space model  documents are 	get a very small weight. 
represented as a vector where each component is associated 	   section 1 presents both the tfidf weighting function and 
with a particular word in the text collection vocabulary.  	the new weighting method introduced in this paper. section 
   generally  each vector component is assigned a value 	1 describes our evaluation test bed. in section 1  we report 
related to the estimated importance  some weight  of the 	results that show significant improvements in terms of 
word in the document. traditionally  this weight was 	classification accuracy.   
assigned using the tfidf measure  joachims  1a; yang 	 

1 weighting approaches in text categorization 
1 tfidf weighting 
tfidf is the most common weighting method used to describe documents in the vector space model  particularly in ir problems. regarding text categorization  this weighting function has been particularly related to two important machine learning methods: knn and svm. the tfidf function weights each vector component  each of them relating to a word of the vocabulary  of each document on the following basis. first  it incorporates the word frequency in the document. thus  the more a word appears in a document  e.g.  its tf  term frequency is high  the more it is estimated to be significant in this document. in addition  idf measures how infrequent a word is in the collection. this value is estimated using the whole training text collection at hand. accordingly  if a word is very frequent in the text collection  it is not considered to be particularly representative of this document  since it occurs in most documents; for instance  stop words . in contrast  if the word is infrequent in the text collection  it is believed to be very relevant for the document. tfidf is commonly used in ir to compare a query vector with a document vector using a similarity or distance function such as the cosine similarity function. there are many variants of tfidf. the following common variant was used in our experiments  as found in  yang and liu  1 .1  
 
	 	n
	 log tft d  +1  log		if tft d  ¡Ý 1
	weightt d  = 	xt	 1  
	  	1	otherwise 
 
where tft d is the frequency of word t in document d  n is the number of documents in the text collection and xt is the number of documents where word t occurs. normalization to unit length is generally applied to the resulting vectors  unnecessary with knn and the cosine similarity function .  
1 supervised weighting 
 debole and sebastiani  1  have tested and compared some supervised weighting approaches that leverages on the training data. these approaches are variants of tfidf weighting where the idf part is modified using common functions used to conduct feature selection. in this paper  their best finding is a variant of the information gain  the gain ratio. respective to a category ci  the gain ratio of the term tk is: 
	ig tk  ci  	 
	gr tk  ci   =  ¡Æ p c   log1 p c   	 1  
c¡Ê{ci  ci }
another approach is presented in  han 1 . in this study  vector components are weighted using an iterative approach involving the classifier at each step. for each iteration  the weights are slightly modified and the categorization accuracy is measured using an evaluation set  a split from the training set . convergence of weights should provide an optimal set of weights. while appealing  and probably a near optimal solution if the training data is the only information available to the classifier   this method is generally much too slow to be used  particularly for broad problems  involving a large vocabulary . 
1 a weighting methods based on confidence 
the weighting method  named confweight in the rest of the text  introduced in this paper is based on statistical confidence intervals. let xt be the number of documents containing the word t in a text collection and n  the size of this text collection. we estimate the proportion of documents containing this term to be:  
 
p% = xt + 1z¦Á1	 1  n z+ ¦Á1
where ~p is the wilson proportion estimate  wilson  1  and z1¦Á/1 is a value such that ¦µ z¦Á/1  = ¦Á/1  ¦µ is the t-distribution  student's law  function when n   1 and the normal distribution one when n ¡Ý 1. so when n ¡Ý 1  ~p is:  
	xt +1	 
p% =		 1  n+ 1
 
thus  its confidence interval at 1% is:  
 
	p%  1   p%  	 1  
p% ¡À 1 n+ 1
 
most categorization tasks can be formulated in a way to use only binary classifiers  e.g. a classifier that decides whether a document belongs to a specific category or not . thus  for a task with n categories  there will be n binary classifiers.    for a given category  let us name ~p+ the equation  1  applied to the positive documents  those who are labeled as being related to the category  in the training set and ~p to those in the negative class. now  we use the label minpos for the lower range of the confidence interval of ~p+  and the label maxneg for the higher range of that of ~p according to 
 1  measured on their respective training set. let now minposrelfreq be: 
 
 
	minpos	 1  
minposrelfreq = minpos+maxneg
we now define the strength of term t for category +:  
 
 log1  1 minposrelfreq  if minpos   maxneg 
	strt + = 	 1  
	 1	otherwise
 
therefore  weight ¡Ù 1 iff the word appears proportionally more frequently in the + category than in the - category  even in the worst  measured by the confidence interval  estimation error scenario. there might be many categories where weight ¡Ù 1  since the categorization task is divided in n binary classifiers. we name the maximum strength of t: 
 
1 
	maxstr t 	str	 1  
 
maxstr t  is a global policy technique  debole and sebastiani  1   that is  the value is that of the best classifier and is thereafter used for all n binary classifiers. using a global policy allows us to use the same document representation for all n binary classifiers. while local policies seem intuitively more appealing than global policies when the categorization task is divided in n binary problems   debole and sebastiani  1  shown that global policies are at least as good as local policies. note that a value of 1 for maxstr t  is akin to a feature selection deciding to reject the feature.  
  figure 1 presents an example to highlight the behavior of eq.  1  to  1 . in this figure  minpos is set to 1  which means that a hypothetic term occurs at least  recall that this value is the lower range of its relative document frequency confidence interval  in half the documents from the positive set. then  the curves  labeled  1    1  and  1  in the graph  consists of the resulting weights for different values of maxneg. eq.  1  gives more weight to terms that occur more frequently  relative to the number of documents  in the positive category than in the negative one. therefore  this weighting method favors features that are proportionally more frequent in the positive class. this weight decreases as maxneg increases. eq.  1  scales the weight values linearly into the  1  range  so that the resulting weight is 1 when a term occurs at the same relative frequency in both classes or proportionally more frequently in the negative set. finally  eq.  1  makes the decrease faster  to reflect the rate at which features lose their  energy  as they are more evenly distributed among the positives and the negatives. as a consequence  very predictive features get a high weight  regardless of their absolute frequency  only proportion differences matter .    
  as we are interested in weighting all training and testing documents components in the vector space model  we must use  1  with individual documents  taking the document term frequency into account. we define the confweight of t in document d as:  
 
	confweightt d = log tft d +1 maxstr t 	 	 1  
                                                  eq.  1  is quite similar to the tfidf equation in  1 : the first part weights the term according to its importance for the document while the second part weights the term globally. however  unlike tfidf  confweight uses the categorization problem to determine the weight of a particular term.  
 
1 methodology 
1 corpora 
in this paper  three data sets previously studied in the literature have been selected. these datasets are: reuters1  ohsumed and the new reuters corpus vol 1. let us 


maxneg
figure 1: weight when varying maxneg with a fixed minpos = 1
briefly describe these datasets.  
  reuters-1  lewis  1  is made of categories related to business news report. it is written using a limited vocabulary in a succinct manner. we used the modapte  lewis  1  split. there are 1 categories having at least one training and one testing document. these categories are highly unbalanced. each document may be categorized in more than one category.  
   ohsumed comes from a very large text collection  the medline bibliographical index  and is rarely used with all available categories and documents. we have chosen to split this text collection as done in  lewis et al.  1 . the result is a task comprising 1 closely related categories using a very technical vocabulary. similarly to reuters  a document may be classified in one or many categories.    finally  reuters corpus vol. 1  rcv1   rose et al.  1  is a newer text collection released by reuters corp. that consists of one full year of new stories. there are about 1 documents. 1 categories have documents assigned to them. this collection is very large  thus making it a very challenging task for learning models such as svm and knn  which have polynomial complexity. particularly  we were not able to use svm with a large training set since svm does not scale up very well to large text collections. using our knn implementation  we have limited the training set to the first 1 documents and the testing set to the next 1 documents1. an average of 1 categories is assigned to each testing document  over 1 total assignments .  
 
1 classifiers  feature selection and settings 
the weighting method presented in this paper is intended to weight documents in the vector space model. thus  it can be used only with classifiers using this model. for this reason  we have evaluated our method using both knn and svm and compared the results obtained with tfidf and gainratio  debole and sebastiani  1  weighting.     we have used the svmlight package  joachims  1b  and the knn classifier described in  yang and liu  1 . in our experiments with svm  we divided each categorization task into n binary classification problems  as usual. in contrast  knn is able to classify a document among the n categories using one multi-category classifier. to decide whether a document is classified or not in a particular category  thresholds were learned for each category  yang and liu  1 . tfidf experiments were weighted using eq.  1  and then normalized to unit length. gainratio experiments were weighted as done by  debole and sebastiani  1 .  
   to reach optimal classification accuracy  feature selection might be required. thus  we have included feature selection in our tests. the information gain measure has been used to rank the features and many thresholds have been used to filter features out; with confweight  in addition to the use of the information gain to select features  when maxstr  see eq. 1  was 1  the feature was also rejected. stop words were not removed and words were not stemmed.  
 
1 results and discussion 
to assess classifier accuracy  a confusion matrix is created for each category:  
 classifier positive label classifier negative label true positive label a b true negative label c d  
table 1: confusion matrix used to evaluate classifier accuracy 
 
for instance  a  the true positives  is the number of documents labeled by the classifier to the category that are correct predictions. similarly  b  the false negatives  is the number of documents that have not been labeled by the classifier to the category  but that should have.    for any category  the classifier precision is defined as a/ a+c  and the recall as a/ a+b . to combine these two measures in a single value  the f-measure is often used. the f-measure reflects the relative importance of recall versus precision. when as much importance is granted to precision as it is to recall we have the f1-measure: 
 
	 precision+ recall 	 	 1  
f1= 
1  precision recall
 the f1-measure is an estimation of the breakeven point where precision and recall meets if classifier parameters are tuned to balance precision and recall. since the f1 can be evaluated for each category  we get n different f1 values.  
  to compare two methods  it is needed to combine all the f1 values. in order to do that  two approaches are often used: the macro-f1 average and the micro-f1 average. the macro-f1 average is the simple average of all f1 values; thus each category gets the same weigh in the average. in counterpart  the micro-f1 average weighs large categories more than smaller ones. the micro-f1 is the f1 in  1  where a  b  c and d are global values instead of categorybased ones. for instance  a in the micro-f1 is the total number of classifications made by the n classifiers that were good predictions. micro-f1 has been widely used in text categorization  lewis et al.  1; yang and liu  1; joachims  1a . table 1 includes micro-f1 results for svm while table 1 includes those of knn. for each experiment  the best score  among tfidf  gainratio and confweight  is bolded.  
  these results show that at low information gain thresholds  confweight clearly outperforms both tfidf and gainratio. when more drastic term selection is conducted  overall scores tend to decrease for all three term weighting methods. is it very interesting to note the very large difference between confweight and tfidf using knn. this difference is particularly significant for a collection of the size of rcv1.  
  figure 1  1 and 1 show the curves resulting from the use of an increasing number of features  decreasing information gain thresholds  for each weighting method using knn. clearly  confweight is the only weighting that doesn't suffer a decrease in accuracy as low-scored features are added. tfidf results are less stable than confweight and gainratio  an observation that leads us to claim that tfidf is very sensitive to the choice of feature selection settings.    while gainratio is less sensitive to the presence of all terms  relevant or not  than tfidf  confweight seems not to need term selection at all  arguably due to its inherent term selection mechanism. we believe that confweight can be used without feature selection and produce very good results. 
 
igain threshold weighting reuters 1 ohsumed tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1 tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1 tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1 tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1 tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1 tfidf .1 .1 1 gainratio .1 .1 confweight .1 .1  
table 1: svm micro-f1s by text collection and weighting method 
 
 
igain threshold weighting reuters 1 ohsumed rcv1 tfidf .1 .1 .1 1 gainratio .1 .1 .1 confweight .1 .1 .1 tfidf .1 .1 .1 .1 gainratio .1 .1 .1 confweight .1 .1 .1 tfidf .1 .1 .1 .1 gainratio .1 .1 .1 confweight .1 .1 .1 tfidf .1 .1 .1 .1 gainratio .1 .1 .1 confweight .1 .1 .1 tfidf .1 .1 .1 .1 gainratio .1 .1 .1 confweight .1 .1 .1 tfidf .1 .1 .1 .1 gainratio .1 .1 .1 confweight .1 .1 .1  
table 1: knn micro-f1s by text collection and weighting method 
 
another interesting remark is that the best overall scores on each corpora  both using knn and svm  are obtained by confweight  reuters-1: .1 with svm and .1 with knn; ohsumed: .1 with svm  .1 with knn; rcv1 .1 with knn .  

 
figure 1: knn micro-f1s on reuters-1 as the number of feature increases 

tfidf
gainratio
confweight
figure 1: knn micro-f1s on ohsumed as the number of feature increases 
 

figure 1: knn micro-f1s on rcv1 as the number of feature increases 
finally  we believe that confweight is able to leverage the many features that get a low information gain score  which is not always the case with tfidf and gainratio. let us take as an example the tfidf behavior with svm in table 1. at .1  there is much less features in the feature space than at .1. adding features scored between .1 and .1 decreases the micro-f1 for reuters-1 and ohsumed. on the other hand  the accuracy with confweight increases on ohsumed if these same low-score features are added to the feature space  while results on reuters-1 stay about the same. using only tfidf  we might have concluded that features which have an information gain lower than 1 are harmful for most categorization tasks. conversely  results so far using confweight tend to show the relevancy and usefulness of low-score features in some settings. 
 
1 conclusions 
in this paper  we have presented a new method 
 confweight  to weight features in the vector-space model for text categorization by leveraging the categorization task. so far  the most commonly used method is tfidf  which is unsupervised. to assess our new method  tests have been conducted using three well known text collections: reuters-
1  ohsumed and reuters corpus vol. 1. as confweight generally outperformed tfidf and gainratio on these text collections  our conclusion is that confweight could be used as a replacement to tfidf with significant accuracy improvements on the average  as shown in tables 1 and 1. moreover  confweight has the ability to perform very well even if no feature selection is conducted  something depicted in the results presented in this paper.  actually  when a feature is irrelevant to the classification task  the weight it gets from confweight is so low that this is merely equivalent to the feature rejection by a feature selection process. tfidf  on the other hand  always yields a score higher than 1  if the term occurs in the document for which tfidf is computed  and this score is not related to the categorization problem  but only to the text collection as a 
whole. since feature selection is not inherent to tfidf  many additional parameters  for instance  the feature selection function to use and thresholds  need to be tuned to achieve optimal results.  
   debole and sebastiani  1  argue for the use of supervised methods to weight features  gainratio and confweight are two such methods . despite positive results in some settings  gainratio failed to show that supervised weighting methods are generally higher than unsupervised ones. we believe that confweight is a promising supervised weighting technique that behaves gracefully both with and without feature selection. therefore  we advocate its use in further experiments.  
 
 
