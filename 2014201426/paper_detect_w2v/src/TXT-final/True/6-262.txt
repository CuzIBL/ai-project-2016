 
relaxed plans are used in the heuristic search planner ff for computing a numerical heuristic and extracting helpful actions. we present a novel way for extracting information from the relaxed plan and for dealing with helpful actions  by considering the high quality of the relaxed plans. in numerous domains  the performance of heuristic search planning and the size of the problems that can be handled have been drastically improved. 
1 	computing and using lookahead states 
in classical forward state-space search algorithms  a node in the search graph represents a planning state and an arc starting from that node represents the application of one action to this state  that leads to a new state. in order to ensure completeness  all actions that can be applied to one state must be considered. the order in which these states will then be considered for development depends on the overall search strategy: depth-first  breadth-first  best-first... 
　let us now imagine that for each evaluated state s  we knew a valid plan p that could be applied to s and would lead to a state closer to the goal than the direct descendants of 1. it could then be interesting to apply p to 1  and use the resulting state s' as a new node in the search. this state could be simply considered as a new descendant of s. 
   we have then two kinds of arcs in the search graph: the ones that come from the direct application of an action to a state  and the ones that come from the application of a valid plan to a state s and lead to a state s' reachable from s. we will call such states lookahead states  as they are computed by the application of a plan to a node s but are considered in the search tree as direct descendants of s. nodes created for lookahead states will be called lookahead nodes. plans labeling arcs that lead to lookahead nodes will be called lookahead plans. once a goal state is found  the solution plan is then the concatenation of single actions for arcs leading to classical nodes and lookahead plans for arcs leading to lookahead nodes. 
   *this work has been supported in part by the iut de lens  the cnrs and the region nord/pas-de-calais under the tact programme. 
　the determination of an heuristic value for each state as performed in the ff planner  hoffmann and nebel  1  offers a way to compute such lookahead plans. ff creates a planning graph  blum and furst  1  for each encountered state s  using the relaxed problem obtained by ignoring deletes of actions and using s as initial state. a relaxed plan is then extracted in polynomial time and space from this planning graph. the length in number of actions of the relaxed plan corresponds to the heuristic evaluation of the state for which it is calculated. generally  the relaxed plan for a state s is not valid for s  as deletes of actions are ignored during its computation. in numerous benchmark domains  we can observe that relaxed plans have a very good quality because they contain a lot of actions that belong to solution plans. we propose a way of computing lookahead plans from these relaxed plans  by trying as most actions as possible from them and keeping the ones that can be collected into a valid plan. 
　the lookahead algorithm and the modifications to the search algorithm are the following  all details can be found in  vidal  1  . each time a state s is evaluated  it is entered into the open list. the relaxed plan extracted by the evaluation function is used to compute a lookahead plan p which leads to a state s  reachable from s. if p is more than one action long  s' is evaluated and added to the open list. let p be a relaxed plan for a state s. a lookahead plan p' is computed as follows: all actions of p are observed in turn. when an action a is applicable to 1  it is added to the end of p' and s is updated  by the application of a . when all actions of p have been tried  this process is iterated without the actions that have been applied  until no action can be used. 
　completeness and correctness of search algorithms are preserved by this process  because no information is lost: all actions that can be applied to a state are still considered  and because the nodes that are added by lookahead plans are reachable from the states they are connected to. the only modification is the addition of new nodes  corresponding to states that can be reached from the initial state. 
1 using helpful actions: the  optimistic  best-first search algorithm 
in classical search algorithms  all actions that can be applied to a node are considered the same way: the states that they lead to are evaluated by an heuristic function and are then or-

1 poster papers 

dered  but there is no notion of preference over the actions themselves. such a notion of preference during search has been introduced in the ff planner  with the concept of help-
ful actions. once a relaxed plan is extracted for a state s  the actions of the relaxed plan that are executable in s are considered as helpful  while the other actions are forgotten by the local search algorithm of ff. this strategy appeared to be too restrictive  so the set of helpful actions is augmented in ff by all actions executable in s that produce fluents that were considered as subgoals at the first level of the planning graph  during the extraction of the relaxed plan. the main drawback of this strategy  as used in ff  is that it does not preserve completeness: the actions executable in a state s that are not considered as helpful are simply lost. ff switches to a complete best-first algorithm when no solution is found. 
　we present a way to use such a notion of helpful actions in complete search algorithms  that we call optimistic search algorithms because they give a maximum trust to the informations returned by the computation of the heuristic. the principles are the following: 
  several classes of actions are created. in our implemen-tation  we only use two of them: helpful actions  the restricted ones   and rescue actions that are all the actions that are not helpful. 
  when a newly created state s is evaluated  the heuristic function returns the numerical estimation of the state and also the actions executable in s partitioned into their different classes. for each class  one node is created for the state 1  that contains the actions of that class. 
  nodes containing helpful actions are always preferred for development over nodes containing rescue actions  whatever their numerical heuristic values are. 
　no information is lost by this process. the way nodes are developed is simply modified: a state s is developed first with helpful actions  some other nodes are developed  and then s can potentially be developed with rescue actions. as the union of helpful actions and rescue actions is equal to the set of all the actions that can be applied to 1  completeness and correctness are preserved. 
1 	experimental evaluation 
we compare four planners: ff v1  and three different settings of our planning system called yahsp  which stands for yet another heuristic search planner1  implemented in objective caml: bfs  best first search: classical wa* search  with w = 1. the heuristic is based on the computation of a relaxed plan as in ff   obfs  optimistic best first search: identical to bfs  with preference of helpful actions over rescue actions   and lobfs  lookahead optimistic best first search: identical to obfs  with lookahead states . 
we report here complete results for logistics domain  see 
figure 1  and show in table 1 some data about the largest problems solved by ff  obfs and lobfs  in order to realize the progress accomplished in the size of the problems that can be solved by a strips planner  for five different domains. 
acknowledgments 
thanks a lot to pierre regnier for his help... 
