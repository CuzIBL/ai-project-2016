 
　　　a method of  learning from observation  la presented which structures a collection of objecta into hierarchies of subcategories  such that each subcategory la characterised by a conjunctive description involving relations on selected object attributes. the conjunctive descriptions sprouting from each node are mutually disjoint and optimal aa a group according to a flexibly defined criterion. each level of the hierarchy is determined by an iterative procaaa which repetitively applies a veralon of the a* search algorithm. 
　　　experiments with the program cluster/paf implementing the method indicate that the obtained hierarchies represent solutions which have a simple conceptual interpretation and which seem to agree well with the way people atructure objecta. 
	i 	introduction 
　　　the problem of intelligently structuring a given collection of entitles haa practical significance not only for applied sciences in general  but alao for designing and implementing ai systerns. for example  knowledge about the structure underlying given data can help in reducing the aearch apace in problem solving  in organising large data baaea  or rule baaea   in dividing knowledge acquisition tssks into useful subcaeea  or in concisely characterising a large collection of objects for human understanding. 
　　　the problem of data atructurlng can be viewed aa a problem of  learning from observation    learning without a teacher  . a simple form of data atructurlng la clustering  which determines a hierarchy of aubcategorlea    clusters   within a given collection of objects. in the traditional methoda of clustering  developed in cluster analyaia and numerical taxonomy   the basis for forming subcategories is a  degree of similarity  between objects: the subcategorlea are collections of objecta whoae intra-cluster similarity ia high and inter-cluster similarity is low. 
　　　the traditional clustering techniques have one major diaadvantage. since the only basis for forming cluatera is the degree of object similarity  which is a measure dependent only on properties of 
this research was supported in part by the national 
science foundation grant no. mcs-1  the university of parla ix  and inria  france . 
compared objects   the resulting clusters do not necessarily have any simple conceptual interpretation. the problem of determining the  meaning  of the obtained clusters is simply l e f t to the researcher. this disadvantage is significant becauae a reaearcher typically wants not only to find clusters  but alao wants to find an explanation of the clusters in human terms. 
　　　this paper la concerned with the problem of determining s hierarchical structure underlying a given collection of objects  in which each node corresponds to a aubcategory of objects characterised by a conjunctive concept  a logical product of relations on selected object attributes . structuring objects into such  conjunctive hlerarchiea  is called conjunctive conceptual clustering. 
　　　the idea of conceptual clustering and a 
　　　general method for determining conjunctive hlerarchiea was introduced in . this paper discusses in more detail one specific algorithm 
 implemented 	in 	the 	program 	cluster/paf  	and illustrates 	it 	by 	a 	practical 	problem found in muelcology. 
ii the similarity measure versus conceptual cohesiveness 
　　　the similarity between any two objects in the population to be cluatered is characterised in the conventional data analysis methods by a aingle number-the value of the similarity function applied to symbolic deacriptiona of objects   data points  . these descriptions are typically vectora  whoae components represent scores on selected qualitative or quantitative variables used to describe objects. frequently a reciprocal of a distance measure is used as a similarity function. 
　　　since the similarity function is solely dependent on the properties of individual objecta  the traditional methods are fundamentally unable to 
1 capture the  gestalt properties  of objects that characterise a collection of objects as one whole and are not derivable by considering objects individually. in order to detect auch properties  the system must know not only the data points  but alao certain  concepta . to illustrate this point  let us consider a problem of clustering data points in figure 1. 
selected object attributes. 
	i l l 	terminology 
this 	section 	gives 	a 	brief 	overview 	of terminology. 	a 	more 	detailed 	presentation 	is 
contained in . 
a. variables and their types 
　　　let x1 x1 ... x n denote discrete variables which are selected to describe objects in the population to be analysed. for each variable a value set  or domain  is defined  which contains a l l possible values this variable can take for any object in the population. we shall assume that the value sets of variables x j   1 1 ... n are f i n i t e . in general  the value sets may differ not only with respect to their size  but also with respect to the structure relating their elements  reflecting the scale of measurement . we distinguish between nominal  qualitative   linear  quantitative   and structured variables  whose domains are unordered  linear  and tree ordered sets  respectively. the structured variables represent generalization hierarchies of related concepts. 
b. event space and syntactic distance 
　　　an event e is defined as any sequence of values of variables x1 x1     x n . the set of a l l possible events  e  is called the event space. the syntactic distance  1 e  e1   between two events e  and 1 is the number of variables which have different values in e  and e1  
　　　any set of events for which there exists an  -complex satisfied by these events and only by these events is called a set-complex or  briefly an s-complex. henceforth  if a is an l-complex  then by & we w i l l denote the corresponding s-complex  i.e.  the set of events described by the l-complex. for simplicity  whenever the distinction between an l-complex and an s-complex is not important  then we w i l l use just the term complex. 
e . sparseness 
　　　let e be a set of events in e  which represent objects to be clustered. the events in e are called data events  or observed events  and events in e   e   i . e .   events in e which are not data events  are called empty events  or unobserved events . let & be an s-complex which covers  includes  some data events and some empty events. the number of data events  points  in & is denoted by p 1 . the number of empty events in 1 is called the sparseness and denoted by * ♀   the total number of events in 1 is thus t fi  - p 1  + s 1 . 
　　　the jt-complex can be viewed as a generalised description of the data events contained in the corresponding s-complex. the sparseness  as defined above  can be used as a simple measure of the degree to which the jl-complex generalises over  or   f i t s     the data events. if the sparseness is sero  then the description covers only data events   zero degree of generalisation  . as the sparseness of the complex increases  so does the 
*vli is the variable-valued logic system one  which uses such selectors  1j. 

1 

degree to which it generalizes over the data events. a related but more preclae measure of the degree of generalisation is the informationtheoretic uncertainty of the location of data events in the complex . 
h star 
　　　the  theoretical  star g e|f  of event e against event set f is formally defined  as the set of a l l maximal under inclusion s-complexes covering the event e and not covering any event in f.  an s-coaplex ft is maximal under inclusion with respect to property p  if there does not exist an e-complex ft* with property p  such that ft c ft*.  such maximal complexes  however  have high sparseness and thus are not directly useable in our approach. therefore  the algorithm produces a reduced star. the reduced star is obtained from the theoretical star by transforming each complex into a new one that covers the same observed events but has the minimum sparaeness  or  in general  minimlsea a certain criterion   
♀. 	cover 
	let e1 and e1 	be 	two 	disjoint 	event 	sets  
e	 e	 	a
l 1     	 cover covxe1ie1  of e  against e1  
is any set of s-complexes    i j } j e j   iuch that for each event e e b  there la an s-complex ftj  j e j  covering i t   and none of the complexes ftj cover any event in ♀1* thus we have: 
*1 j   j * j 1 *   * 1 
 1  
　　　a cover in which a l l s-complexes are palrwise disjoint sets is called a disjoint cover* if set e1 it  mpty  then a cover covtljfte t - cov eiu  i′ simply denoted as cov ei . a partition of data events into k subsets  each contained in one setcomplex of a disjoint cover is called a conjunctive k-partltlon. the corresponding 1-complexes constitute conjunctive descriptions of these subsets. a simple measure of the   f i t   of a kclusterlng to the data events is the sparseness of the k-partltlon defined as the sum of the sparsenesses of the complexes in the partition. 
	iv 	the method and its implementation 
　　　this section describes the algorithm for conjunctive- conceptual clustering implemented in program cluster/paf. the algorithm consists of an inner layer and an outer layer  deacrlbed in sections iv-a and iv-c  respectively. 
a' 	i n n   r l*y r  algorithm paf  
　　　the inner layer of the algorithm  called paf  was introduced in . its function can be described as: 
given  e a collection of events to be clustered  e the number of clusters desired  k   e the criterion of k-clusterlng optlmallty  
find: a conjunctive k-partltion of the collection of events that is optimal according to the criterion of k-clusterlng optlmallty. 

paf worka iteratlvely  starting with 	a 	set 	of 	k 
i n i t i a l   randomly chosen seed events   seeds   from the given collection of events* the seeds are used to determine a set of complexes  which constitute the f i r s t conjunctive k-partitlon of the event set. subsequent iterations consist of two repeated steps: 
1 - given k complexes  determine the data events  cluatera  covered by them  
1 - given clusters of data events  determine new  seeds   and then a new set of k complexes  a conjunctive k-partltlon . 
the process continues until a termination criterion is satisfied  a local optimum is achieved . the general structure of the algorithm is based on the so-called dynamic clustering method   1   . 
i.' 	generating a  k-partltlon from  seeds  
　　　the process of determining a k-partltlon from seeds involves determining a reduced star of each seed against other seeds  and then selecting complexes fro  the stars and modifying them in such a way that they constitute a k-partltion. the selection is done by a best-first search method. 

1 

　　　at each iteration of algorithm paf  k stars are produced  each of a single seed event against the remaining k-1 seed events. from each star one complex is selected in such a way that the resulting set w i l l consist of k disjoint complexes  be a conjunctive k-partition   and be optimal according.to the assumed criterion. if un-bounded stars were used  each could contain up to complexes  and therefore up to nk sets of complexes would have to be inspected in order to determine the optimal k-partltlon. to combat this immense search problem the best-first search strategy is used. this search uses a form of algorithm a*  nllsson  . 
　　　assume that k events   seeds   ei  1      *  have been selected from the collection e and k stars gi - g ei|remaining seeds  have been generated. for simplicity  we w i l l assume that the criterion of clustering optlmallty is simply to minimize the total sparseness of complexes in the k-partltlon. at each level of the search tree  a complex is selected from the star corresponding to this level and is added to the partial partition  a sequence of fewer than k complexes . the selected complex is the one which most likely w i l l lead to the optimal k-partltlon. this procedure avoids testing  possibly very many  clusterings  for which it is possible to predict that they w i l l not be optimal. 
figure 1 illustrates the search process. 
branches emanating from a node at level i represent complexes in star gi. a path from the root to a node at level 1 represents a partial k-partltlon with 1 complexes. when i-k  the path represents a complete k-partltlon. 
　　　in the f i r s t step  the sequence of complexes af  a1 ***  org is determined  where  rf is the complex in star g＼ with the smallest sparseness. in the next step  node  1   figure 1  is expanded by pairing the  best  complex in g}  i . e .   o j   with every complex in g1. if the complexes intersect  a special procedure nid modifies them so that they become disjoint. if nid cannot make the complexes disjoint  the path is abandoned  procedure nid is described in detail in   1     . every so obtained pair of complexes is a partial k-partitlon with 1 complexes. this process is repeated for the other complexes in g}  in the order of their increasing sparseness. nodes corresponding to a l l these clusterings   f i r s t generation nodes  are assigned a value of the evaluation function: f - h 1- g  where 
1 

h is is the sprseness of the obtained partial disjoint cover and g is the expected cost of the remainder of the k-clusterlng to be determined  the sum of the sparsenesses of the complexes along the path from node 1 to leaf node k . 
　　　a lower bound for g is determined on the basis of complexes a  generated in the f i r s t step. if any of these complexes intersect  procedure nid transforms them into certain  core  complexes  of which it can be proven   that the sum of their sparsenesses is a lower bound on the sparseness of the optimal k-partltlon constructed from complexes of the start. 
　　　according to the algorithm a*  the node to be expanded at the next step is the one which is associated with the lowest value of the evaluation function* the order of expanding nodes in the tree in figure 1 is shown by numbers in circles. the value of the evaluation function associated with each node is given in parentheses. if complete  not-bounded  stars are used  this algorithm w i l l produce the optimal k-clusterlng   i . e .   in this case  a k-clusterlng with the minimum total sparseness . 
　　　the method can simultaneously use not just one  but several criteria of clustering optlmallty. in addition to sparseness  these other component criteria include : 
e maximising inter-cluster differences  e maximising essential dimensionality  e maximising simplicity of cluster representations  and 
e 	maximising uniformity of cluster populations. 
c. 	outer layer of cluster/paf 
　　　as described above  the inner layer  paf  determines an optimal or suboptlmal k-clusterlng of a given collection of events. the outer layer performs two loops  one iterative and one recursive. the iterative loop repeats algorithm paf for a sequence of values of k  say  k 1 ... 1  in order to find the value of k for which the most desirable clustering of the given event set is obtained. it is assumed that interesting solutions should have only a few  e.g.  less than 1  different clusters. 
　　　the recursive loop applies the above process recursively in order to create a hierarchy of clusterings. in the f i r s t step  the process is executed for the i n i t i a l event set e  and a collection of subcategories  clusters  of e is determined. consecutive steps repeat the same operation for each event set  cluster  obtained in the previous step. 
　　　the obtained hierarchy grows in a top-down fashion u n t i l a  contlnuatlon-of-growth* criterion f a l l s . this criterion requires that the   f i t    measured by sparseness  of the complexes to the events they describe be better by a certain threshold at each next level of the hierarchy. when this criterion is not met  the latest obtained subcategories become leaves of the hierarchy. 
	the 	algorithm 	described 	above 	has 	been 
implemented 	in 	program 	cluster/paf  	written 	in pascal. 
v a musicological example 
　　　this example illustrates an application of the described method to structuring a collection of one hundred old spanish folksongs. 
　　　the folksongs were characterized by 1 muslcologlcal attributes  such as degree of rubato  rhythmic freedom   tonal range  style  monophonlc vs. polyphonic   etc. the attributes and the data for the experiment were provided by musicologist pablo poveda who studied this problem using traditional methods of numerical taxonomy . the results obtained by those methods  however  were very d i f f i c u l t to interpret because they do not provide any description of the generated clusters* 
　　　the top five levels of the conjunctive hierarchy of folksongs produced by cluster/paf are presented in figure 1. the criterion of clustering optlmallty was  minimizing the total sparseness.  the branches in the hierarchy have been labeled with the particular characteristic of the folksongs which discriminates between the l e f t and right subcategories. the number of clusters  k  formed at each level was 1 to meet a requirement imposed by the musicologist. 
　　　tips of the hierarchy marked by ai a1    * ' a l l represent groups of songs  the number of songs is indicated above the t i p     whose complete description consists of properties indicated along the path from the root to the t i p   and some 
additional properties not shown in the figure.  these additional properties are less relevant for classifying the songs  as they occur at the lower levels of the hierarchy.  for example  the group denoted by a  has the following complete description: 
 style-monophonic  rubato-lowj tonal 	range-low  
 type-secular  lnstruments-no  	 a  
a 
 no. of tones-1..1  panegyrlc-no  tenslon-1..1  
 no. of phrase1..1  melisma-o..1  dance-no  	 b  
part a contains properties shown in 	the 	hierarchy 
 figure 1  while part b contains additional properties selected by the program from the complete set of attributes. 
　　　one interesting aspect of the determined hierarchy is that the value sets of some variables have been s p l i t into ranges. these ranges can be considered as new constructed  generalized  values of variables. for example  the range of the degree of  rubato  has been split into two ranges 1..1 and 1..1  which can be described as  low  and  high   respectively  see complex 1 . similar partitioning of value sets into ranges of values was found for the degree of embellishment  the degree of me1ana  the tonal range  and the number of tones in the song. it should be noted that although the nodes in this particular hierarchy are marked by single attributes  the method  in 

1 

general  	labels 	the 	nodes 	by 	products 	of 	