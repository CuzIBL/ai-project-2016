 
this paper summarizes concepts  principles  and tools that were found useful in applications involving causal modeling.1 the principles are based on structural-model semantics  in which functional  or counterfactual  relationships  representing autonomous physical processes are the fundamental building blocks. the paper presents the formal basis of this semantics  illustrates its application in simple problems and discusses its ramifications to computational and cognitive problems concerning causation. 
1 	introduction 
the central theme in this paper is the interpretation of causality as a computational scheme devised to identify invariant relationships in a domain  so as to facilitate prediction of the effects of actions. this conception has been a guiding paradigm to several research communities in  and outside  ai  most notably those connected with causal discovery  troubleshooting  policy making  planning under uncertainty  modeling behavior of physical systems  and theories of action and change. however  the languages and technicalities developed in these diverse areas often tend to obscure their common basic principles and thus discourage the transfer of ideas across disciplines. the purpose of this paper is to explicate common principles in simple and familiar mathematical form  using little more than propositional calculus  to encourage broader and more effective usage of causal modeling in ai and its peripheries. 
　after casting the concepts of  causal model    actions   and  counterfactuals  in mathematical terms we will demonstrate by examples how counterfactual questions can be answered from both deterministic and probabilistic causal models  section 1 . in section 1  i will axgue that planning and decision making are exercises in 

   additional background material can be found in the technical papers section of http://bayes.cs.ucla.edu/jpjiome.html and will soon appear in book form  pearl  1a . 
counterfactual reasoning. this will set the stage for section 1  where i discuss the empirical content of counterfactuals in terms of policy predictions. section 1 demonstrates the role of counterfactuals in the interpretation and generation of causal explanations  while section 1 relates the properties of structural models to the task of learning causal relationships from data. we end with discussions of how causal relationships emerge from actions and mechanisms  section 1  and how causal directionality can be induced by a set of symmetric equations  section 1 . 
1 	causes and counterfactuals 
in one of his most quoted passages  david hume  1  ties together two aspects of causation: 1. regularity of succession and 1. counterfactual dependency: 
 we may define a cause to be an object followed by another  and where all the objects  similar to the first  are followed by object similar to the second  or   in other words  where  if the first object had not been  the second never had existed   hume  1  section vii . 
this passage is puzzling; how can convoluted expressions of the type  if the first object had not been  the second never had existed  illuminate simple commonplace expressions like  a caused b   
   the idea of reducing causality to counterfactuals is further echoed by john stuart mill  1   and has reached its fruition in the works of david lewis  1  1 . implicit in this proposal lies an intriguing claim that counterfactual expressions are less ambiguous to our mind than causal expressions. although discerning the truth of counterfactuals requires the generation and examination of possible alternative to the actual situation-a mental task of non-negligible proportions- hume  mill  and lewis apparently believed that going through this mental exercise is  nevertheless  simpler than intuiting directly on whether it was a that caused b. how  what mental representation allows humans to process counterfactuals so swiftly and reliably  and what logic governs that process so as to maintain uniform standards of coherence and plausibility  
	pearl 	1 

structure vs. similarity 
according to lewis' account  1   the evaluation of counterfactuals involves the notion of similarity: one orders possible worlds by some measure of similarity  and the a counterfactual  read:  if it were an  is declared true in a world w just in case b is true in all the closest a-worlds to  
　this semantics still leaves the question of representation unsettled: 1. what choice of similarity measure would make counterfactual reasoning compatible with ordinary conception of cause and effect  1. what mental representation of worlds ordering would render the computation of counterfactuals manageable and practical in man and machine. 
　in his initial proposal  lewis was careful to keep his formalism general  and  save for the requirement that every world be closest to itself  he did not impose any structure on the similarity measure. however  plausible sentences such as:  had nixon pressed the button  a nuclear war would have started    fine  1 . tells us immediately that similarity of appearance is inadequate-a world in which the button happened to be disconnected would be many times more similar to our world than the one yielding a nuclear blast. thus  similarity measures must respect our conception of causal laws.1 lewis  1  has subsequently set up an intricate system of weights and priorities among various dimensions of similarity: size of  miracles   violations of laws   matching of facts  temporal precedence etc.  to bring similarity closer to causal intuition. but these priorities turned out rather post-hoc  reminiscent of priorities in nonmonotonic logics  and still lead to counterintuitive inferences. the structural account  to be described next  escapes these problems by avoiding similarities altogether  and defining counterfactuals directly on causal laws.1 
1 	structural model semantics 
we start with a definition of deterministic  causal model   which consists of functional relationships among variables of interest  each relationship representing an autonomous mechanism. causal and counterfactuals relationships are then defined in terms of response to local modifications of those mechanisms. probabilistic relationships emerge by assigning probabilities to background conditions. 

   1 related possible-world semantics were introduced in artificial intelligence to represent actions and database updates 
 ginsberg  1; ginsberg and smith  1; winslett  1; katsuno and mendelzon  1 . 
   1 in this respect  lewis' reduction of causes to counterfactuals is somewhat circular. 
   1 this account builds on balke and pearl  1  1   galles and pearl  1  1   and halpern  1 . related approaches have been proposed in simon and rescher  1  and robins  1 . 
1 	awards 
1 definitions: causal models  actions and counterfactuals 
in standard logics  a model is a mathematical object that assigns truth values to sentences in a well formed language. a causal model  naturally  should encode the truth values of sentences that deal with causal relationships  these include action sentences  e.g.   a will be true if we do 1    counterfactuals  e.g.   a would have been different if it were not for b   and plain causal utterances  e.g.   a was the cause of b  or  b occurred despite of a  . 
definition 1  causal model  a causal model is a triple 

where 
 i  u is a set of background variables   also called exogenous   that are determined by factors outside the model. 
 ii  v is a set  of variables  called en-
dogenous  that are determined by variables in the model  namely  variables in  
 iii  f is a set of functions where each fi is a mapping from in other words  each  tells us the value of vi given the values of all other variables in  symbolically  the set of equations f can be represented by writing 

where pat is any realization of the unique minimal set of variables pai in  connoting parents  that renders  nontrivial likewise   stands for the unique minimal set of variables in u that renders  nontrivial 
every causal model m can be associated with a causal diagram  that is  a directed graph  g m   in which each node corresponds to a variable in v and the directed edges point from members of  toward  
definition 1  submodel  
let m be a causal model  x be a set of variables in v  and x be a particular realization of x. a submodel of m is the causal model 

where 
		 1  
in words   is formed by deleting from f all functions fi corresponding to members of set x and replacing them with the set of constant functions  
　submodels are useful for representing the effect of local actions and hypothetical changes  including those dictated by counterfactual antecedents. if we interpret each function  in f as an independent physical mechanism and define the action as the minimal 

change in m required to make hold true under any u  then  represents the model that results from such a minimal change  since it differs from m by only those mechanisms that directly determine the variables in x. the transformation from m to modifies the algebraic content of f  which is the reason for the name modifiable structural equations used in  galles and pearl  
1 .1 
definition 1  effect of action  
let m be a causal model  x be a set of variables in v  and x be a particular realization of x. the effect of action  on m is given by the submodel mx. 
definition 1  potential response  
let y be a variable in v  and let x be a subset of v. the potential response of y to action  denoted  is the solution for y of the set of equations .1 
we will confine our attention to actions in the form of 
　conditional actions  of the form  do x = x  can be formalized using the replacement of equations by functions of z  rather than by constants  pearl  1 . we will not consider disjunctive actions  of the form  since these complicate the probabilistic treatment of counterfactuals. 
definition 1 	 counterfactuat  
let y be a variable in v  and let x a subset of v. the counterfactuat sentence  the value that y would have obtained  had x been is interpreted as denoting the 
potential response  
　definition 1 thus interprets the counterfactual phrase  had x been x  in terms of a hypothetical external anion that modifies the actual course of history and enforces the condition  with minimal change of mechanisms. this is a crucial step in the semantics of counterfactuals  balke and pearl  1   as it permits x to differ from the current value of x u  without creating logical contradiction; it also suppresses abductive inferences  or backtracking  from the counterfactual antecedent  
definition 1  probabilistic causal model  
a probabilistic causal model is a pair 


   structural modifications date back to simon  1   and is also used in mccarthy and hayes  1 . an explicit translation of interventions into  wiping out  equations from the model was first proposed by strotz and wold  1  and later used in fisher  1   spirtes et al.  1   and pearl 
 1 . a similar notion of sub-model is introduced in fine  1   though not specifically for representing actions and counterfactuals. 1
　　galles and pearl  1  required that fx has a unique solution  a requirement later relaxed by halpern  1 . uniqueness of solution is ensured in recursive systems  i.e.  where g m  is a cyclic. 
1
　　simon and rescher  1  p. 1  did not include this step in their definition of counterfactuals and ran into difficulties with unwarranted backward inferences triggered by the antecedents. 
where m is a causal model and p u  is a probability 
function defined over the domain of u. 
 together with the fact that each endogenous 
variable is a function of u  defines a probability distribution over the endogenous variables. that is  for every set of variables 
 1  
the probability of counterfactual statements is defined in the same manner  through the function yx u  induced by the submodel 
 1  
　　likewise a causal model defines a joint distribution on counterfactual statements  i.e.  is defined for any sets of variables essarily disjoint. in particular   are well defined for 
given by 
		 1  
and 

 1  
　　when x and x1 are incompatible  yx and yx cannot be measured simultaneously  and it may seem meaningless to attribute probability to the joint statement  y would be y if x =  and y would be if  dawid  1 . the definition of  and in terms of two distinct submodels  driven by a standard probability space over u  provides a simple interpretation of probabilities of counterfactuals and further illustrates that such probabilities can be encoded rather parsimoniously using p u  and f. 
　　of particular interest to us would be probabilities of counterfactuals conditional on actual observations. for example  the probability that event x =   was the cause  of event y = may be interpreted as the probability that y would not be equal to had x not been  given that x =  and y = have in fact occurred  pearl  1b . such probabilities require the evaluation of expressions of the form  
with and  incompatible with 
eq.  1  allows the evaluation of this quantity using a 1-step procedure that we summarize in a theorem. 
theorem 1 given model 	the condi-
tional probability of a counterfactual sentence  if it were a then b   given evidence e  can be evaluated using the following three steps: 
1. abduction-update by the evidence e  to obtain  
	pearl 	1 

1. action-modify m by the action do a   where a is the antecedent of the counterfactual  to obtain the submodel  
	1. prediction-use 	the 	modified 	model 
 to compute the probability of b  
the consequence of the counterfactual 
　in temporal metaphors  this 1-step procedure amounts to  1  explaining the past  u  in light of the current evidence e   1  bending the course of history  minimally  to comply with the hypothetical condition and  finally   1  predicting the future  y  on the basis of  1  and  1 . 
1 	evaluating counterfactuals: deterministic analysis 
example-1  the firing squad 
u  court order  

figure 1: causal relationships in a 1-man firing squad. 
　consider a 1-man firing squad as depicted in fig. 1  where a b c d and u stand for the following propositions: 
	u 	= 	court orders the execution 
	c 	= 	captain gives a signal 
a = 	rifleman- a shoots 
b = 	rifieman-b shoots 
	d 	== prisoner dies 
　assume that the court's decision is unknown  that both riflemen are accurate  alert and law abiding  and that the prisoner is not likely to die from fright or other extraneous causes. we wish to construct a formal representation of the story  so that the following sentences can be evaluated mechanically: 
s1. {prediction : if rifleman-a did not shoot  the prisoner is alive. formally   
s1.  abduction : if the prisoner is alive  then the captain did not signal. formally   
s1.  transduction : if rifleman- l shot  then b shot as well. formally   
1 	awards 
s1.  action : if the captain gave no signal and riflemana decides to shoot  the prisoner will die and b will not shoot. formally*  
s1.  counterfactual ; if the prisoner is dead  then even if a were not to have shot  the prisoner would still be dead. formally   
evaluating standard sentences 
to prove the first three sentences we need not invoke causal models; these involve standard logical connectives and can be handled by standard logical inference. the story can be captured in any convenient logical theory  t  for example  
and the validity of tion from t. 
　note  however  that the two-way implications in  are necessary for supporting abduction; if we were to use one-way implications  e.g.  we would not be able to conclude c from a. in standard logic  this symmetry removes all distinctions among prediction  reasoning forward in time   abduction  reasoning from evidence to explanation  and transduction  reasoning from evidence to explanation  then from explanation to predictions . in non-standard logics  e.g.  logic programming   were the implication sign dictates the direction of inference and even contraposition is not supported  special machinery must be invoked to perform abduction  eshghi and kowalski  1 . note also that the feature which renders s1-s1 manageable in standard logic is that they all deal with epistemic inference  that is  inference from beliefs to beliefs about a static world. 
evaluating action sentences 
sentence s1 invokes a deliberate action and  from  definition 1  it must violate some premises  or mechanisms  in the initial theory. to formally identify what remains invariant under the action  we must incorporate causal relationships into the theory. one symbolic representation of the causal model corresponding to our story is as follows: 
model m: 
 u  
	c = u 	 c  
a = c 	 a  
b = c 	 b  
	d= 	 d  
here we use equality  rather than implication signs  first  to permit two-way inference and  second  to stress the fact that each equation represents an autonomous mechanism   an  integrity-constraint  in the language of databases ; it remains invariant unless specifically violated. we further use parenthetical symbols next to each equation  to explicitly identify the dependent variable  on the left hand side  in the equation  thus representing the causal directionality associated with the arrows in fig. 1. 

　to evaluate s1  we follow definition 1 and form the submodel ma  in which the equation a = c is replaced by a  simulating the decision of of rifleman- a to shoot regardless of signals   and obtain 

we see that  given the fact we can easily deduce d and  and thus confirm the validity of  
　it is important to note that  problematic  sentences like s1  whose antecedent violates one of the basic premises in the story  i.e.  that both riflemen are law abiding  are handled naturally within the same deterministic setting in which the story is told. alternative approaches would be to insist on re-formulating the problem probabilistically  see next subsection  or on using an ab predicate  so as to tolerate exceptions to the law a = c. such reformulations are unnecessary; the structural approach permits us to draw the intended inferences in the natural  deterministic formulation of the story. 
evaluating counterfactuals 
to evaluate the counterfactual sentence s1  we can follow the steps of theorem 1  though no probabilities are involved. we first add the fact d to the original model  m  evaluate u  then form the submodel and  finally  re-evaluate the truth of d in using the value of u found in the first step. these steps can be combined into one  noting that the value of u is the only information that is carried over from step-1 to step1; all other propositions must be re-evaluated subject to the new modification of the model. 
   if we distinguish post-modification variables from premodification variables by a star  we can combine m and  into one logical theory and prove the validity of 
s1 by purely logical inference in the combined theory. 
to illustrate  we write  as   read: if d is true in the actual world  then d would also be true in the hypothetical world created by the modification and prove the validity of  in the combined theory: 
combined theory: 

note that u is not starred  reflecting the assumptions that background conditions remain unaltered  thus serving as carriers of persistence information between the actual world to the hypothetical world. 
　it is worth reflecting at this point on the difference between s1 and s1. syntactically  the two appear to be identical and  yet  we labeled s1 an  action  sentence and s1 a  counterfactual  sentence. the difference lies in the relationship between the given fact and the antecedent of the counterfactual  i.e.  the  action  part . in s1 the fact given  c  is not affected by the antecedent  a  while in s1  the fact given  d  is potentially affected by the antecedent  the difference between these two situations is fundamental  as can be seen from their methods of evaluation. in evaluating s1  we knew in advance that c would not be affected by the model modification do a  and  therefore  we were able to add c directly to the modified model ma  in evaluating s1  on the other hand  we were contemplating a possible reversal  from d to  due to the modification  and  therefore  we had to first add fact d to the pre-action model m  summarize its impact via u  and reevaluate d once the modification  takes place. thus  although the causal effect of actions can be expressed syntactically as a counterfactual sentence  this need to route the impact of known facts through u makes counterfactuals a different species than actions. 
　we should also emphasize that most counterfactuals utterances in natural language presume knowledge of facts that are affected by the antecedent. when we say  for example   b would be different if it were not for a  we imply knowledge of what the actual value of b is and that b is susceptible to a  it is this sort of sentences that gives counterfactuals their unique character  distinct of action sentences.1 
1 	evaluating counterfactuals: probabilistic analysis 
assume the following modification of the story: 
1. there is a probability  that the court has ordered the execution. 
1. rifleman-.1 has a probability q of pulling the trigger out of nervousness  

1. rifleman-a nervousness is independent of u. 
　with these assumptions  we wish to compute the probability  that the prisoner would be alive if a were not to have shot  given that the prisoner is in fact dead. 
　following theorem 1  our first step  abduction  is to compute the posterior probability  where 
u and w are the two background variables involved. 
	 1  
the second step  action  is to form the submodel: 
in the the 

1 	the twin-network method 
a major practical difficulty in the procedure described above is the need to compute  store and use the posterior distribution where stand for the set of all background variables in the model. as is illustrated in the last example  even when we start with a model in which the background variables are mutually independent  conditioning on e normally destroys this independence  and makes it necessary to carry over a full description of the joint distribution of u  conditional on e; such description may be prohibitively large. 
　a graphical method of overcoming this difficulty is described in balke and pearl  1   which uses two networks  one to represent the actual world  and one to represent the hypothetical world  fig. 1 . 

figure 1: twin-network representation of the probabilistic firing squad. 
1 	awards 
　the two networks are identical in structure  save for the arrows entering a  which have been deleted to mirror the equation deleted from like siamese twins  the two networks share the background variables  in our case u and w  since those remain invariant under modification. the endogenous variables are replicated and labeled distinctly  because they may obtain different values in the hypothetical vis a vis the actual world. the task 
of computing  in the model thus reduces to that of computing in the twin network shown. such computation can be performed by standard evidence-propagation techniques in a bayesian network-the distribution need not be explicated  conditional independencies can be exploited  and local computation methods can be employed such as those summarized in many textbooks  e.g.   pearl  1  . 
　the twin-network representation also offers a useful way of testing independencies among counterfactual quantities. to illustrate  suppose we wish to test whether ba is independent of p  given c. this can be verified by noting that c d-separates d from b* in the twinnetwork shown in fig. 1. 
　the verification of such independencies is important for deciding if the ramifications of certain plans can be inferred from statistical data  because these independencies permit us to reduce counterfactual probabilities to ordinary probabilistic expression on observed variables  pearl  1; galles and pearl  1 . 
1 	applications and interpretation of 
structural models 
computing counterfactual probabilities is not an academic exercise; it represents in fact the typical case in almost every decision making situation. whenever we undertake to predict the effect of policy  two considerations apply. first  the policy variables  e.g.  interest rates in economics  pressure and temperature in process control  are rarely exogenous. policy variables are endogenous when we observe a system under operation and turn exogenous in the planning phase  when we contemplate actions and changes. second  policies are rarely evaluated in the abstract; rather  they are brought into focus by certain eventualities that demand remedial correction. in troubleshooting  for example  we observe undesirable effects e that are influenced by other conditions and wish to predict whether an action that brings about a change in x would remedy the situation. these are precisely the three steps that theorem 1 attaches to the evaluation of counterfactuals  and have been applied indeed to the evaluation of economic policies  balke and pearl  1  and to repair-test strategies in troubleshooting  breese and heckerman  1 . the reasons for using hypothetical phrases in practical decision-making situations is discussed in the next section. 

1 	the empirical content of count erfactuals 
consider ohm's law v = ir  the empirical content of this law can be encoded in two alternative forms. 
1. predictive form: if at time to we measure current io and voltage then  ceteras paribum  at any future times if the current flow will be i t  the voltage drop will be: 

1. counter factual form: if at time we measure current and voltage then  had the current flow at time been instead of the voltage drop would have been: 

　on the surface  it seems that the predictive form makes meaningful and testable empirical claims while the counterfactual form merely speculates about events that have not  and could not have occurred; as it is impossible to apply two different currents into the same resistor at the same time. however  if we interpret the counterfactual form to mean no more nor less than a conversational short hand of the predictive form  the empirical content of the former shines through clearly. both enable us to make an infinite number of predictions from 
just one measurement  and both derive their va-
lidity from a scientific law  ohm's law  which ascribes a time-invariant property  the ratio  to any physical object. 
　but if counterfactual statements are merely a roundabout way of stating sets of predictions  why do we resort to such convoluted modes of expression instead of using the predictive mode directly  one obvious answer is that we often use counterfactuals to convey  not the predictions themselves  but the logical consequences of those predictions. for example  the intent of saying:  if a were not to have shot  the prisoner would still be alive  may be merely to convey the factual information that b did not shoot. the counterfactual mood  in this case  serves to supplement the fact conveyed with logical 
justification based on a general law. the less obvious answer rests with the qualification  ceteras paribum  that accompanies the predictive claim  which is not entirely free of ambiguities. what should be held constant when we change the current in a resistor  the temperature  the laboratory equipments  the time of day  certainly not the reading on the voltmeter  such matters must be carefully specified when we pronounce predictive claims and take them seriously. many of these specifications are implicit  hence superfluous  when we use counterfactual expressions  especially when we agree over the underlying causal model. for example  we do not need to specify under what temperature and pressure future predictions should hold true; these are implied by the statement  had the current flow at time to been /'  instead of lo  in other words  we are referring to precisely those conditions that prevailed in our laboratory at time to. that statement also implies that we do not really mean for anyone to hold the reading on the voltmeter constant-variables should run their natural course and the only change we should envision is in the mechanism which  according to our causal model  is currently determining the current. 
　to summarize  a counterfactual statement might well be interpreted to convey a set of predictions under well defined set of conditions  those prevailing in the factual part of the statement. for these predictions to be valid  two components must remain invariants: the laws  or mechanisms  and the boundary conditions. cast in the language of structural models  the laws correspond to the equations {fi} and the boundary conditions correspond to the state of the background variables u. thus  a precondition for the validity of the predictive interpretation of a counterfactual statement is the assumption that u will remain the same at the time where our predictive claim is to be applied or tested. 
　this is best illustrated using a betting example. we must bet heads or tails on the outcome of a fair coin toss; we win a dollar if we guess correctly  lose if we don't. suppose we bet heads and we win a dollar  without glancing at the outcome of the coin. consider the counterfactual  had i bet differently i would have lost a dollar.  the predictive interpretation of this sentence translates into the implausible claim:  if my next bet is tails  i will lose a dollar.  for this claim to be valid  two invariants must be assumed: the payoff policy and the outcome of the coin. while the former is a plausible assumption in betting context  the latter would be realized in only rare circumstances. it is for this reason that the predictive utility of the statement  had i bet differently i would have lost a dollar  is rather low  and some would even regard it as hind-sighted nonsense. it is the persistence across time of u and  that endows counterfactual expressions with predictive power; take this persistence away  and the counterfactual loses its obvious economical utility. 
　however  there is an element of utility in counterfactuals that does not translate immediately to predictive payoff  and may explain  nevertheless  the ubiquity of counterfactuals in human discourse. i am thinking of explanatory value. suppose  in the betting story  coins were tossed afresh for every bet. is there no value whatsoever to the statement  had i bet differently i would have lost a dollar   i believe there is; it tells us that we are not dealing here with a whimsical bookie  but one who at least glances at the bet  compares it to some standard  and decides a win or a loss using a consistent policy. this information may not be very useful to us as players  but it may be useful to say state inspectors who come every so often to calibrate the gambling machines to ensure the state's take of the profit. more significantly  it may be useful to us players  too  if we venture to cheat slightly  say by manipulating the trajectory of 
	pearl 	1 

the coin  or by installing a tiny transmitter to tell us which way the coin landed. for such cheating to work  we should know the policy y = f x u  and the statement tfhad i bet differently i would have lost a dollar    reveals important aspects of that policy. 
　is it far fetched to argue for the merit of counterfactuals by hypothesizing unlikely situations where players cheat and rules are broken  i suggest that such unlikely operations are precisely the norm for gauging the explanatory value of sentences. it is the nature of any causal explanation that its utility be amortized not over standard situations but  rather  over novel settings which require innovative manipulations of the standards. the utility of understanding how tv works comes not from turning the knobs correctly  but from the ability to repair a tv set when it breaks down. recall that every causal model advertises  not one  but a host of submodels  each created by violating some laws. the autonomy of the mechanisms in a causal model stands therefore for an open invitation to remove or replace those mechanisms  and it is only natural that the explanatory value of sentences be judged by how well they predict the ramifications of such replacements. 
1 causal explanations  utterances  and their interpretation 
it is commonplace wisdom that explanation improve understanding  and that he who understands more  can reason and learn more effectively. it is also generally accepted that the notion of explanation cannot be divorced from that of causation; e.g.  a symptom may explain our belief in a disease  but it does not explain the disease itself. however  the precise relationship between causes and explanations is still a topic of much discussion in philosophy  woodward  1 . having a formal theory of counterfactuals  in both deterministic and probabilistic settings  casts new light on the question explanation adequacy  and opens new possibilities for automatic generation of explanations by machine. 
these possibilities trigger an important basic question: 
is explanation a concept based on general causes  e.g.  
 drinking hemlock causes death    or singular causes  e.g.   socrates' drinking hemlock caused his death   . 
action-effect expressions  p y do x   = p{yx = y   belong to the first category while counterfactual expressions  p yx' = y' x  y  belong to the second  since conditioning on x and y narrows down world scenarios to those compatible with all the specific information at hand. 
　the classification of causal statements into general and singular categories has been the subject of intensive research in philosophy e.g.  see  good  1; cartwright  1; eells  1 . this research has attracted little attention in cognitive science and artificial intelligence  partly because it has not entailed practical inferential procedures  and partly because it was based on problematic probabilistic semantics  see pearl  1  for discussion of probabilistic causality . in the context of machine generated explanations  this classification as-
1 	awards 
sumes both cognitive and computational significance. the analysis of counterfactual probabilities  balke and pearl  1  has uncovered a sharp demarcation line between two types of causal queries  those that are an-
swerable from the pair   where 
is the probability induced by m   and those that require additional information in the form of functional specification. generic causal statements often fall in the first category while counterfactual expressions  fall in the second  thus 
demanding more detailed specifications and higher computational resources. 
　the proper classification of explanation into a general or singular category depends on whether the cause x attains its explanatory power relative to its effect y by virtue of x's general tendency to produce y  as compared with the weaker tendencies of x's alternatives  or by virtue of x being necessary for triggering the chain of events leading to y in the specific situation at hand  as 
characterized by y and perhaps other facts and observations.  
　if we base explanations solely on generic tendencies we lose important specific information. for instance  aiming a gun at and shooting a person from 1 meters away will not qualify as an explanation for that person's death  due to the very low tendency of typical shots fired from such long distances to hit their marks. the fact that sperial conditions helped the shot hit its mark on that singular day will not enter into consideration. if  on the other hand  we base explanations solely on singular-event considerations then various background factors which are normally present in the world would awkwardly qualify as explanations. the presence of oxygen in the room would qualify as an explanation for the fire that broke out. clearly  some balance must be made between the necessary and the sufficient  singular and generic components of causal explanation. basic relationships between these components are explicated in  pearl  1b   using probabilities of counterfactuals. 
　the following list  taken from  galles and pearl  1   provides brief examples of utterances used in explanatory discourse and their associated structural-model semantics.  the necessary aspect of causation is taken as a norm.  
   x is a cause of y   if there exist two values x and x' of x and a value u of u such that  
   x is a cause of y in context if there exist two values x and x' of x and a value of u such that  
   x is a direct cause of y   if there exist two values x of x  and a value u of u such that  
where r is some realization of v x. 
   x is an indirect cause of y   if x is a cause of y  and x is not a direct cause of y. 
   event may have caused  if 
 i  are true  and 

 ii  there exists a value u of u such that  
	and 	for some 
is a likely cause of 
is high for some 
if 
　the preceding list demonstrates the flexibility of modifiable structural models in formalizing nuances of causal expressions. additional nuances  invoking notions such as enabling  preventing  maintaining  and producing  are analyzed in  pearl  1a . 
1 structural models  causal discovery and knowledge mining 
it is by now fairly well understood that the central aim of the enterprise known as  knowledge discovery  is the identification of invariant  often causal  relationships in data. what is perhaps less generally appreciated is that the dual character of causal mechanisms  invariance and autonomy  is the key for the operation of knowledge discovery programs  especially those based on causal graphs. 
　the invariance property assures us that when one mechanism undergoes change  the others remain intact. identifying such mechanisms would amount therefore to the acquisition of  knowledge   as it permits us to transport patterns of behavior from one context to another. the feature of  comprehensibility  or  making sense   which normally accompanies the discovery of knowledgelike relationships  is a byproduct of transportability. the autonomy property further tells us what varies from one context to another  and thus provides the clues for identifying those features of the observed data that are context-independent. 
　one such feature is the so called causal markov condition  spirtes et ai  1 . it states that  for a causal 
model to be considered complete  each variable vi must be independent on all its non-descendants  given its parents pai in g. this parent-screening condition has been the defining feature of bayesian networks  and has served as the key for many causal discovery algorithms  e.g.   pearl and verma 1; spirtes etal.  1 . the reason that the markov condition is so often regarded as an inherent feature of causal models rests  again  on the property of invariance  as can be seen from the following theorem. 
theorem 1  causal markov condition  every causal model m for which g m  is acyclic and in which the ui 's are mutually independent induces a distribution  that satisfies the markov condition relative the causal diagram g m .  pearl and verma  
1 .1 
　this theorem states that the independencies dictated by the markov condition are invariant to the functional form of fi and to the distributional properties of p ui . this invariance renders markovian independencies reliable clues for inferring the structures of causal models from data; any structure whose markovian independencies turn incompatible with the data can safely be ruled out from consideration. the property of autonomy further implies that  as contexts change  accidental independencies are destroyed and only independencies dictated by the markov condition are preserved. this provides the theoretical basis for the assumption of  stability   pearl and verma  1  or  faithfulness   spirtes et ai  1 -the second corner stone in causal discovery algorithms. 
　bayesian approaches to causal discovery  heckerman et al.  1  also owe their rationale to invariance and autonomy. the assumption of parameter-independence  which is made in all practical bayesian approaches to model discovery  can be justified only when the parameters p vi pai  are attached to stable mechanisms  as opposed to arbitrary conditional probabilities  and when those mechanisms are free to change independently of one another  namely  autonomy. 
1 	from mechanisms to actions to causation 
the structural model described in section 1 crystallizes the conceptual elements behind two highly debated issues in ai  the representation of actions  and the role of causal ordering. we will discuss these problems in turns  since the second builds on the first. 
action  mechanisms and surgeries 
whether we take the probabilistic paradigm that actions are transformations from probability distributions to probability distributions  or the deterministic paradigm that actions are transformations from states to states  such transformations could in principle be infinitely complex. yet  in practice  people teach each other rather quickly what actions normally do to the world  and people predict the consequences of most actions without much hustle. how  
　structural models answer this question by assuming that the actions we normally invoke in common reasoning can be represented as local surgeries. the world consists of a huge number of autonomous and invariant linkages or mechanisms  each corresponding to a physical process that constrains the behavior of a relatively small group of variables. if we understand how the linkages interact with each other  usually they simply share variables  we should also be able to predict what the effect of any given action would be: simply re-specify those 

   considering its generality and transparency  i would not be surprised if some version of this theorem has appeared earlier in the literature. 
	pearl 	1 

few mechanisms that are perturbed by the action  then let the modified assembly of mechanisms interact with one another  and see what state will evolve at equilibrium. if the specification is complete  i.e.  m and u are given   a single state will evolve. if the specification is probabilistic  i.e.  p u  is given  a new probability distribution will emerge and  if the specification is partial  i.e.  some  are not given  a new  partial theory will then be created. in all three cases we should be able to answer queries about post-action states of affair  albeit with decreasing level of precision. 
　the ingredient that makes this scheme operational is the locality of actions. standing alone  locality is a vague concept because what is local in one space may not be local in another. structural semantics emphasizes that actions are local in the space of mechanisms and not in the space of variables or sentences or time slots. for example  tipping the left-most object in an array of domino tiles does not appear  local  in physical space  yet it is quite local in the space of mechanisms: only one mechanism gets perturbed  that which keeps the left-most tile in erect position; all other mechanisms remain unaltered  as specified  obedient to the usual equations of physics. locality makes it is easy to specify this action  without enumerating all its ramifications. the listener  assuming she shares our understanding of domino physics  can figure out for herself the ramifications of this action  or any action of the type:  tip the ith domino tile to the right.  thus  by representing the domain in the form of an assembly of autonomous mechanisms  we have in fact created an oracle capable of predicting the effects of a huge set of actions and action combinations  without us having to explicate those effects. 
laws vs. facts 
in order to implement surgical procedures in mechanism space  we need a language in which some sentences axe given different status than others; sentences describing mechanisms should be treated differently than those describing other facts of life  such as observations  assumption and conclusions  because the former are presumed stable  while the latter are transitory. 
　in bayesian networks  the distinction between laws from facts is made using conditional probabilities. facts are expressed as ordinary propositions  hence they can obtain probability values and they can be conditioned on; laws  on the other hand  are expressed as conditionalprobability sentences  e.g.  p accident careless-driving  = high   hence they should not be assigned probabilities and cannot be conditioned on. a similar distinction has been proposed for nonmonotonic logics by poole  1  and geffher  1 and a related distinction in the form of domain constraints is used in formal theories of actions  sandewall 1; lin 1 . 

   1 in database theory  laws are expressed by special sentences called integrity constraints  reiter  1 . 
1 	awards 
mechanisms and causal relationships 
from our discussion thus far  it may seem that one can construct an effective representation for computing the ramification of actions without appealing to any notion of causation. this is indeed feasible in many areas of physics and engineering. if we have  for instance  a large electric circuit consisting of resistors and voltage sources  and we are interested in computing the effect of changing one resistor in the circuit  the notion of causality hardly enters the computation. we simply insert the modified value of the resistor into ohm's and kirchoff's equations  and solve the set of  symmetric  equations for the variable needed. this computation can be performed effectively without committing to any directional causal relationship between the currents and voltages. 
lb understand the role of causality  we should note 
that  unlike the resistor-network example  most mechar nisms do not have names in common everyday language. we say:  raise taxes    make him laugh    press the button   and  in general  do q  where q is a proposition  not a mechanism. it would be meaningless to say:  increase this current  or  if this current were higher...  in the resistor-network example  because there are many  minimal  ways of increasing that current  each generating different ramifications. evidently  commonsense knowledge is not as entangled as resistor networks. in the strip language  fikes and nilsson  1   to use another example  an action is not characterized by the name of the mechanisms it modifies but  rather  by the actions' immediate effects  the add and delete lists   and these effects are expressed as ordinary propositions. indeed  if our knowledge is organized causally  this specification is sufficient  because each variable is governed by one and only one mechanism  see definition 1 . thus  we should be able to figure out for ourselves which mechanism it is that must be perturbed in realizing the new event  and this should enable us to predict the rest of the scenario. 
　this important abbreviation defines a new relation among events  a relation we normally call  causation : event a causes b  if the perturbation needed for realizing a produces the realization of b.1 causal abbreviations of this sort are used very effectively for specifying domain knowledge. complex descriptions of domain constrains and of how they interact with one another can be summarized in terms of cause-effect relationships between events or variables. we say  for example:  if tile i is tipped to the right  it causes tile t + 1 to tip to the right as well ; we do not communicate such knowledge in terms of the tendencies of each domino tile to maintain its physical shape  to respond to gravitational pull and to obey newtonian mechanics. 

1
    the word  needed  connotes minimality and can be translated to:  ...if every minimal perturbation realizing a  produces b . additional qualifications axe discussed in  pearl  1b . 

1 	simon's causal ordering 
our ability to talk directly in terms of one event causing another   rather than an action altering a mechanism and the alteration  in turn  producing the effect  is computationally very useful  but  at the same time it requires that the assembly of mechanisms in our domain satisfy certain conditions which accommodate causal directionality. indeed  the formal definition of causal models given in section 1 assumes that each equation is designated a distinct privileged variable  situated on its left hand side  that is considered  dependent  or  output  . in general  however  a mechanism may be specified as a functional constraint 

without identifying any so called  dependent  variable. 
　　simon  1  devised a procedure for deciding whether a collection of such symmetric g functions dictates a unique way of selecting an endogenous  dependent  variable for each mechanisms  excluding the background variables since they are determined outside the system . simon asked: when can we order the variables in such a way that we can solve for each 
without solving for any of successors  such an or-
dering  if it exists  dictates the direction we attribute to causation. this criterion might at first sound artificial  since the order of solving equations is a matter of computational convenience while causal directionality is an objective attribute of physical reality.  see  iwasaki and simon  1    de kleer and brown  1   and  druzdzel and simon  1  for discussion of this issue.  to justify the criterion  let us rephrase simon's question in terms of actions and mechanism. assume each mechanism  i.e.  equation  can be modified independently of the others and let be the set of actions capable of modifying equation  while leaving other equations unaltered . imagine that we have chosen an action from ak  and that we have modified gk in such a way that the set of solutions  to the entire system of equations differs from what it was prior to the action. 
 if x is the set of endogenous variables constrained by we can ask which members of x would change by the modification. if only one member of x changes  say xk  and if the identity of that distinct member remains the same for all choices of and u  we designate  as the  dependent  variable in  
　　formally  this property means that changes in ak induce a functional mapping from the domain of xk to the domain of all changes in the system  generated by can be attributed to changes in it would make sense  in such a case  to designate as a  representative  of the mechanism  and we would be justified in replacing the sentence  action caused 
event  with  event  caused  y being any variable in the system . the invariance of to the choice of is the basis for treating an action as a modality  definition 1 . it provides a license for characterizing an action by its immediate consequence s   independent of the instrument that actually brought about those consequences  and defines in fact the notion of  local action  or  local surgery . 
it can be shown  nayak  1  that the uniqueness of 
xk can be determined by a simple criterion that involves purely topological properties of the equation set  i.e.  how variables are grouped into equations . the criterion is that one should be able to form one-to-one correspondence between equations and variables and that the correspondence be unique. this can be decided by solving the matching problem  serrano and gossard  1  between equations and variables. if the matching is unique  then the choice of dependent variable in each equation is unique and the directionality induced by that choice defines a directed acyclic graph  dag . in fig. 1  for example  the directionality of the arrows need not be specified externally  they can be determined mechanically from the set of symmetrical constraints  i.e.  logical propositions : 
  1  
that characterizes the problem. the reader can easily verify that the selection of a privileged variable from each equations is unique and  hence  that the causal directionality of the arrows shown in fig. 1 is inevitable. 
　thus  we see that causal directionality  according to simon  emerges from two assumptions: 1. the partition of variables into background  u  and endogenous  v  sets  and 1. the overall configuration of mechanisms in the model. accordingly  a variable designated as  dependent  in a given mechanism may well be labeled  independent  when that same mechanism is embedded in a different model. indeed  the engine causes the wheels to turn when the train goes up hill  and changes role in going down hill. 
　of course  if we have no way of determining the background variables  then several causal orderings may ensue. in eq.  1   for example  if we were not given the information that u is a background variable  then either one of  can be chosen as background  and each such choice would induce a different ordering on the remaining variables.  some would conflict with commonsense knowledge   e.g.  that the captain's signal influences the court decision . the directionality of however  would be maintained in all those orderings. the question whether there exists a partition  of the variables that would yield a causal ordering in a system of symmetric constraints can also be solved 
 in polynomial time  by topological means  dechter and pearl  1 . 
　simon's ordering criterion fails when we are unable to solve the equations one at a time  but must solve a block of k equations simultaneously. in such a case  all the k variables determined by the block would be mutually unordered  though their relationships with other blocks may still be ordered. this occurs  for example  in economic modeling  which often include feedback loops  e.g.  demand affects price and price affects demand . 
the correspondence between equations and variables  in 
	pearl 	1 
　　　1 balke and pearl  1  also noted that this sort of sentences a require a more detailed specifications for their evaluation; some knowledge of the functional mechanisms  is necessary. see also  heckerman and shachter  1 . 
	pearl 	1 
   ---------------

   ------------------------------------------------------------

---------------

------------------------------------------------------------

