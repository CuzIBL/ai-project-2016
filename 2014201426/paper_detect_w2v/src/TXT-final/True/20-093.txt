 
a major problem for a knowledge based planner is the determination of potential plan failures due to goal conflict. given a potential plan  it is computationally intractable to compare every effect of that plan against all planner goals. a commonsense planner named kip  knowledge intensive planner  is described. kip determines user plans for the unix consultant system  kip uses goal conflict concerns to focus attention on those effects and goals which are likely to cause goal conflict. a concern refers to those aspects of a plan which should be considered because they are likely sources of plan failure. violated default concerns allow the planner to use default knowledge effectively in cases where the planning situation has not been specified completely. unintended effect concerns allow kip to plan effectively when plans are used in novel situations. user goals are often only inferred in response to a threat from a potential plan. a new concept termed interests  is introduced. interests are general states that kip assumes are important to the user. while interests refer to general states of the world  goals refer to a concrete state of the world. 
1. introduction 
     human problem solving is a knowledge intensive process. people know much about many plans  and also know about the many ways which these plans can fail. however  people have the uncanny ability to consider only a small pan of this planning knowledge while problem solving. they select one or two potential plans to solve current problems among the many plans they have used in the past. they can determine which aspects of a selected plan might cause plan failure in the current planning situation without examining every possible problem that might occur. early planning programs  fikes1  ncwell1  sacerdoti1  could consider every possible plan failure  since they planned in a domain with a limited number of plans and goals. however  a brute force approach is not computationally tractable in a knowledge rich domain. 
     a planner which is able to effectively use a large body of knowledge about a knowledge rich domain is called a commonsense planner  wilensky1 . such knowledge includes a 
     general understanding of planning strategy  detailed descriptions of plans  the conditions necessary for these plans to execute successfully  and descriptions of potential goal conflicts these plans might cause. 
     in this paper  i describe a commonsense planner called kip  knowledge intensive planner. kip is being developed for uc  the undx consultant system  luria1  wilensky 1a  1 . this planner has a large knowledge-base of information bout the unix operating system. the parser and goal ualyzer  mayfield 1  of uc pass kip a set of goals  and kip computer science department 
technion  israel institute of technology 
haifa 
israel 
tries to find appropriate plans for those goals. uc is a conversational system  and if necessary kip can query the user for more information. nevertheless  kip tries to provide the best plan it can with the information provided by the user. this plan is then passed to other uc components  which use the plan to generate a natural language response to the user. 
there are two types of plan failure:  1  condition failure 
- plan failure due to an unsatisfied condition necessary for the plan to execute and  1  goal conflict failure - plan failure due to the effect of the plan conflicting with a goal. in this paper  we describe how potential plan failures due to goal conflicts between an effect of a potential plan and a goal are detected.  for more on condition failure detection see luria1  1 . detecting failures due to goal conflict is more complex than detecting failures due to condition failure. a potential plan might fail due to a limited number of conditions. in contrast  any of the effects of the same plan could potentially conflict with one of the many explicit and background goals of an agent. since a commonsense planner is faced with a combinatorial explosion of potential goal conflicts  it cannot consider each potential goal conflict as a source of plan failure. therefore  an algorithm is needed to limit those potential goal conflicts which should be considered. 
     in the next section  we provide an example of a plan which causes a goal conflict. this example reflects the difficulty in the goal conflict detection problem. we then examine the properties of an algorithm that addresses this problem and describe those issues that must be addressed by any algorithm that detects goal conflicts. in the following section  an algorithm for detecting potential goal conflicts is described. 
1. an example of goal conflict detection 
     when given a set of user goals  kip should detect any conflicts between goals the user has specified and other user goals of which kip is aware. additionally  kip creates a potential plan for the user's goals. kip should detect goal conflicts between the effects of the potential plan and other previously unconsidered goals of the user. effects can conflict with other goals by causing states which are incompatible with these goals  or by making plans to achieve these goals impossible. the problem of detecting goal conflicts is difficult  since kip must consider conflicts between the effects of the plan  and the explicit and background goals of the user. if there is a conflict  kip should try to resolve the conflict. 
conflict resolution may occur by either modifying the plan  changing the order in which plans for various goals are executed  or choosing a new plan. for example  suppose the user asks the following question: 
	luria 	1 

 a  how do i move a f i l e named junk to a f i l e named f i l e l   
kip might select the use-mv-command plan. kip creates an individual instance of this plan for the particular problem situation of moving the file named junk  say the use-mvcommandl plan. this plan is to execute the command mv junk f i l e l . kip needs to examine the use-mv-
command1 plan in order to detect any goal conflicts between an effect of the use-mv-commandl plan and one or more of the goals of the user  both explicit and inferred. 
　　for example  kip might detect the following potential problem with the use-mv-command 1 plan: one effect of this plan is that if filel exists  it will be overwritten. let us call this result the destination file deletion effect. this effect conflicts with the user's background goal of having access to his file named filel. there is a conflict between the destination deletion file effect of the use-mv-command1 plan and the user's goal of having access to the file named filel. this conflict occurs because once the use-mv-commmandl plan is executed  the user will no longer be able to access the file. 
　　detecting the goal conflict is difficult since kip should know about a number of potential effects of use-mvcommandl. for example  kip might also consider the following effects of the use-mv-commandl plan: 
if the f i l e named junk does not exist  the message is printed: mv: junk: cannot access: no such f i l e or directory 
the protection of the f i l e named junk is the same as that of the f i l e 
named f i l e l . 
if the user does not have permission on the current directory  the message is printed: mv: junk: rename: permission denied. 
if the f i l e named f i l e l is write protected  the user is asked: override protection 1 for f i l e l   
　　kip might consider the following effects that the usemv-commandl plan inherits from its parents in the hierarchy of plans: 
the directory inode w i l l be updated. 
the disk arm w i l l move due to a directory update. 
　　kip also needs to know about many other background goals of the user that could conflict with these effects. for example  kip might also consider these background goals of the 
user: 
try to l i m i t disk space usage. 
execute commands in a way that maintains a low load average. 
have a small number of f i l e s in each directory. keep your password secret. 
none of these background goals of the user conflict with the effects of the use-mv-commandl plan. 
1. exhaustive search as an algorithm for gcd 
　　the goal conflict detection problem  gcd  refers to the problem of detecting those goal conflicts that require goal conflict resolution. this problem occurs when kip has created a potential plan for a goal of the user. kip should determine if any effect of this plan might cause a conflict with a goal of the user. here we examine the properties of an algorithm which addresses the gcd problem. 
　　a weak method for solving the goal conflict detection problem would be to compare every potential effect of a particular plan with every explicit and background goal of the user. according to this method  if kip knew about 1 effects of a plan and knew about 1 explicit and background goals of the user  kip would need to make 1 tests for conflict. however  exhaustive search is inefficient in a knowledge rich domain. in order to avoid checking for conflicts between every effect of a plan and every potential goal of a user  we require some knowledge efficient method of identifying which potential conflicts should be considered. 
　　secondly  a human planner usually knows right away that a certain plan will fail. a human planner does not appear to consider every possible goal of the user as a possible source of conflict with every effect of a plan. rather  the human planner considers only those effects and goals which will often cause the plan to fail. 
　　thirdly  kip may not be aware of the values of many of the conditions of a particular plan. most previous planning research assumed that the values for all the conditions is known. however  in uc  and most other knowledge rich domains  when a user describes a planning problem which is then passed to kip  the values for many conditions are usually left out. all users would believe that normal goals  like the user wants to preserve the contents of his files  would be assumed by the consultant. a naive user might not be aware of many of the effects of unix commands that require a more sophisticated knowledge of unix. an expert user would believe that the consultant would make certain assumptions re-
quiring this more sophisticated knowledge of unix. it would be undesirable to prompt the user for this information  particularly for those values which are not important for the specific planning situation. 
　　therefore  kip should rely on default situation knowledge in order to detect potential goal conflicts. for example  kip might have knowledge that unless there is information to the contrary  it is likely that a file has read and write permission. if exhaustive search is used as an algorithm for gcd  a comparison of every effect with every goal might be difficult due to the kip's dependence on default knowledge. since much of the knowledge about a particular situation may be unknown  each of the individual comparisons for conflict might entail much effort and uncertainty. 
　　fourthly  many goals of the user are inferred by kip  rather than being described by the user in a particular problem situation. these goal inferences are based on kip's long-term knowledge about the user's long term interests in the general state of the world. interests are general states that kip assumes are important to the user. an interest differs from a goal in that one can have interests about general states of the world  while goals refer to a concrete state of the world. for example  preserving the contents of one's files is an interest  while preserving the contents of the file named filel is a goal. kip's knowledge base includes many interests that kip assumes on the part of the user. goals are generated only when expressed by the user  or by kip itself during the planning 

1 	rea1ninq 

process. 
     the reliance on long-term knowledge about interests makes exhaustive search for goal conflicts difficult. an individual goal is often only inferred by kip when there is some action that might threaten an interest of the user. if kip were to compare every effect of a plan with all the goals of the user  it would first need to examine each interest of the user. it would also need to determine if an individual goal should be inferred in the situation due to the particular interest. checking each interest would be a very inefficient use of knowledge. very few of these interests will give rise to goals in a particular situation  and even fewer will become causes of goal conflict. 
     therefore  a knowledge efficient algorithm that addresses the gcd problem should consider only a limited number of potential goal conflicts and ignore other potential goal conflicts completely. such an algorithm should utilize default knowledge and instantiate user goals when user interests are threatened. 
1. concerns 
     in the previous sections  we have described the difficulty and importance of the goal conflict detection problem. therefore  we have introduced a new concept in kip  called a concern which addresses this problem. 
     a concern refers to those aspects of a plan which should be considered because they are possible sources of plan failure. a concern describes which aspects of a plan arc likely to cause failure. 
     there are two major types of concerns  condition concerns  and goal conflict concerns. condition concerns refer to those aspects of a plan that are likely to cause plan failure due to a condition of the plan that is needed for successful execution.  these are fully described in luria1  1 . goal conflict concerns refer to those aspects of a plan which are likely to cause plan failure due to a potential goal conflict between an effect of a plan and a goal of the user. goal conflict concerns are represented as three way relations between the selected plan  the conflicting effect  and the threatened goal. 
     the conditions about which kip is concerned are always conditions of a particular plan. goal conflict concerns  however  relate plans to user goals and to other pieces of knowledge that are not part of the plan. examples of this knowledge include background goals which may or may not be threatened by the plan. since these background goals are usually not instantiated until such a threat is perceived  goal conflict concerns often refer to conflicts between a potential plan and an interest of the user. stored goal conflict concerns  refer to concerns about conflicts of interest. these are concerns about the selected plan conflicting with an interest of the user. if kip detects a conflict-of-interest concern  then kip must determine if it should infer an individual goal on the part of the user that reflects this interest. if kip decides to infer this individual goal  then a dynamic concern between the selected plan and the individual goal is also instantiated. 
     some goal conflicts are more likely to occur than other goal conflicts  and some goal conflicts are more important than others if they do occur. the representation of goal conflict concerns reflects this difference by assigning a varying degree of concern to the stored concerns in the knowledge base. there are many factors that determine the degree of concern about a conflict-of-interest. the planning knowledge base designer needs to determine how likely a conflicting effect is to occur  how likely it is that the user holds the threatened goal  and how important this goal is to the user. 
     in the present implementation of kip  information regarding concerns of potential plans is supplied by a human expert with a great deal of unix experience. in principle  however  the information might be supplied by an analysis of data of actual unix interactions. 
1. an example of goal conflict concerns 
     before describing the other types of goal conflict concerns  and kip's complete algorithm for dealing with these concerns  we consider a simple example of the use of goal conflict concerns. we describe the order of the steps of this algorithm. suppose the user asks the following question: 
	 b  	how do i change my password  
     kip is passed the goal of changing the password of the user. kip's knowledge base contains a stored plan for the goal of changing a password  namely  the use-passwdcommand plan. in addition to the stored condition concerns for this plan  kip identifies one stored conflict-of-interest concern for this particular plan  the password authentification problem. if the user changes his password on one machine  it may not be changed on another machine. as the effect of the use-passwd-command plan  the user's password is changed on his current machine. the effect conflicts with the user's interest of having the same password on all machines on which he has an account. let us call this interest the identical password interest. this user interest is a subgoal of the user being able to remember his password. 
     concerns are stored between the effect that is likely to cause goal conflict and the interest with which it is likely to cause goal conflict. in this example  the stored goal conflict concern which kip has identified is a three-way relation between the use-passwb-command plan  the effect that the password is changed on this machine  and the identical password interest. 
     kip next evaluates the identical password interest in this particular planning situation. kip uses knowledge about the particular user to determine if an individual goal should be inferred in this situation which reflects the identical password interest. for example  if kip knows specifically that the user has an account only on the current machine  then kip does not assert an identical password goal for the user. consideration of this goal conflict concern stops. kip may have information that the user has accounts on many machines  or may make this assumption based on default knowledge from the user model. in either of these cases  kip then asserts an individual identical password goal on the part of the user. 
     kip next evaluates whether the goal of the user is the intended effect of the selected plan. according to kip's input  the user has specified that his goal is to change his password. kip's knowledge base stores the fact that the use-passwdcommand plan is the best plan to accomplish this passwordchange goal. thus  kip detemines that the goal of the user is the intended effect of the plan. kip assumes that the concerns indexed under the use-passwd-command plan are not concerns about the intended goal of the plan. therefore  kip assumes that the conflict between the password-changing on the current machine and the identical pasword interest is a real goal conflict  not an artificial goal conflict. 
     kip next evaluates this potential goal conflict. in this case  the concern about multiple passwords is marked as having a high degree of concern  and therefore a goal conflict is inferred. this potential goal conflict is then passed to the goal conflict resolution mechanism. 
1. taxonomy of goal conflict concerns 
     in this section  we describe a number of different types of goal conflict concerns. these different types address important issues for goal conflict detection in unique situations. in the following section  we describe the goal conflict concern algorithm. we will describe how these types of concerns are used together in the context of that algorithm. 
1. default concerns vs. violated-default concerns 
     the previous concerns have all been default goal conflict concerns. default goal conflict concerns are those concerns with which the planner is usually occupied  given a set of defaults used to make assumptions about the world. when these defaults are violated  new concerns arise which i call violated-default goal conflict concerns. for example  suppose the user asks the following questions: 
 c  how do i print out a f i l e on the lineprinter  
 d  how do i print out a very long f i l e on the lineprinter  
in example  c   kip selects the use-lpr-command plan. 
since no defaults have been violated  only default concerns are accessed. kip finds no goal conflict concerns for this plan  and it is returned as a plan for accomplishing the user's goal. 
     in example  d   kip also selects the use-lpr-command plan. however  in this example  kip should also access the violated-default concerns of the plan. since the size of the default file is usually assumed to be short  the fact that the user has specified that the file is a long one violates a default. because this default is violated  kip accesses the violateddefault concerns for the plan that reflect this violated default. kip accesses a conflict between the effect of printing out a long file and the interest of being considerate to other users of system resources. 
     thus  kip always accesses the default goal conflict concerns of a particular plan. a plan's violated-default concerns are only accessed when a default is violated. however  only 
those violated-default concerns that reflect the violated default are accessed. 
     accessing only the concerns that reflect the violated default makes the implementation of violated-default concerns difficult in example  d   for instance  the violated-default concern is detected by accessing a category of plans that manipulate long files. let us call this category the long-file-
plans category. since the default of the file being short is violated  a use-lpr-command l plan is created. the uselpr-command l plan is dominated by both the use-lpr-
command plan and the category of long-file-plans. the individual plan inherits all the concerns of both parents. uselpr-command 1 thus inherits conflict-of-interest concerns from both the use-lpr-command plan and the long-file-plans category. kip knows that concerns arising from the longfile-plans category are violated-default concerns. the relationship between long-file-plans category and use-lprcommandl is created in order to reflect the violated default. 
     one advantage of this implementation is that general concerns about non-default situations can be stored in one general category. for example  the long-file-plans category 
1 	reasoning 
and its concerns are also used by kip to detect other similar conflicts. kip can use this category to detect conflicts regarding the use of system resources when compiling a very large program  typesetting a long paper  or sending a very large file over the network. 
     there can also be more exacting descriptions of violated-default concerns in a more specific category. for example  sending a 1 byte file to the lineprinter might not be considered excessive and therefore would not generate a concern. however  sending the same size file to the laser printer  which takes much longer to print  would generate a concern. therefore  a specific concern category of plans which print large files on a laser printer would be necessary to represent this information. thus  if the user wants to print a 
     file that kip knows is 1 bytes long  printing the file on the laser printer would cause a concern. sending the file to the lineprinter  however  would not cause a concern. 
1. intended effects vs unintended effects concerns 
     when kip is unable to find a stored plan that solves the goals of the user  it uses another plan that is used for some other similar goal. for example  suppose the user asks the following question: 
 e  how can i free up disk space  
if kip has no stored plan for this goal  it might select the userm-command plan to accomplish the goal of the user. as an effect of that plan  disk space of the file that is removed is marked as free. one of the problems with using this plan is that it conflicts with the user's interest in preserving his files. the conflicting effect of using the use-rm-command plan on a particular file is that the file is removed. this effect conflicts with user's goal of preserving the individual file. let us call this conflict the preservation/removal conflict. in order to detect this goal conflict  a concern should be accessed between the removal of the file and the preservation of the file. the preservation/removal goal conflict should be passed to the goal conflict resolution mechanism. 
however  suppose the user asks the following question: 
 f  how can i remove a f i l e   
in example  f   kip would also select the use-rm-command plan in order to satisfy the user goal. the use-rm-command plan is defined as a plan in service of the goal of removing a file. in this example  however  the user actually intends to remove a file. therefore  the goal of preserving this file should not be threatened and the preservation/removal conflict should not be detected. therefore  in example  f   kip should not access a concern about the conflict-of-interest between removing a file and preserving a file. 
     this type of goal conflict between an intended effect and a general interest is termed an artificial goal conflict. artificial goal conflicts should not be passed to the goal conflict resolution mechanism. this problem often occurs when a planner does not properly evaluate the threatened interest with respect to the query goal. 
     in order to avoid detection of artificial goal conflicts  kip differientiates between intended effect concerns and unintended effect concerns. intended effect concerns refer to conflicts-of-interest in which the selected plan is being used for its usually intended effect. unintended effect concerns refer to conflicts-of-interest in which the selected plan is being used for some other effect of the plan. kip always accesses a plan's intended effect concerns. a plan's unintended effect 

concerns are only accessed when the user goal is not the intended effect of the plan. 
     in example  f   since the use-rm-command is being used for its intended effect  the concern about file deletion is not even considered. in example  e   however the use-rmcommand plan is being used for an effect other than deleting a file. therefore  all unintended effect concerns are considered  including the concern that using the use-rmcommand plan will conflict with the user's goal of preserving his files. 
     in kip  if a particular action is used as a plan for more than one goal  two or more different plans are created. for example  once kip knows that a plan for freeing up disk space is to use the rm command  it creates a use-rm-command-fordisk-space plan. this plan has a different intended effect than the use-rm-command-for-deleting plan. therefore  this plan will have different intended effect concerns and unintended effect concerns than the use-rm-command-fordeleting plan. 
     therefore  when kip has selected a plan for the goal which it has been intended  kip must check all the intended effect concerns for that particular plan. if kip has selected a plan in order to satisfy a goal for which the plan has not been intended  then both the intended effect concerns and the unintended effect concerns must be checked. 
1. other types of concerns 
     there are a number of other different types of goal conflict concerns that cannot be fully described due to space limitations. these include: 
expressed goal conflict concerns - dynamic concerns that are expressed by the user or created by the goal analyzer. these concerns reflect the concern of the user that a potential plan may cause a goal conflict. 
effect goal conflict concerns - stored concerns between effects and user goals. these concerns reflect knowledge that certain effects give rise to goal conflicts independent of plans that cause these effects. previously discussed concerns have all been plan goal conflict concerns. 
1. kip's algorithm for dealing with goal conflict concerns 
     in the diagram below i have expanded on those parts of the kip's planning algorithm in which goal conflict concerns 
1. concern retrieval 
     after kip detects the goals of the user  it selects a potential plan and creates an instance of that plan. kip then checks for any violated defaults in the particular planning situation by comparing the values of properties in the planning situation  that have been specified by the user  against the default values for those properties. for each violated default  kip determines the most specific stored violated default concerns for that violated default. some violated defaults may generate concerns regarding conflicts due to an effect that is not part of the potential plan. therefore  the conflicting effects of goal conflict concerns are matched against the effects of the potential plan. kip discards all concerns whose effects are not effects of the potential plan. 
     kip next evaluates whether the user goal is the intended effect of the selected plan. if the goal is not the intended effect of the plan  then both the intended and unintended goal conflict concerns are gathered. if the user goal is the goal for which the plan was intended  then only the intended effect concerns are gathered. 
     once intended  unintended and violated default concerns are gathered  it sorts them based on the degree of concern. kip then decides on a threshold level for concern. this level is based on the planning situation. for example  if the plan is the normal plan for these goals  a high threshold will be chosen. a lower threshold is chosen when the plan has not been used before. the concerns which are below the threshold level are discarded. 
1. concern evaluation 
     kip then creates dynamic concerns for each of the stored concerns. it evaluates the concerns according to the degree of stored concern. kip first evaluates the conflicting effect by determining if the conditions necessary for the effect are true in kip's model of the world. secondly  kip evaluates the threatened interest to determine if the interest is important in this particular problem situation. if kip determines that the interest is important  than the interest is inferred as a goal. if not  then the concern is disregarded. in either case the interest evaluation is remembered so that other concerns which are related to this interest are not reevaluated. 
     during this evaluation  kip assigns a new degree of concern to the dynamic concern based on the particular planning situation. however  many of the values necessary for this evaluation will not be known and must be provided from unc-

play an important role. 

ertain default knowledge. therefore  the degree of concern of the dynamic concern is calculated by using both the degree of concern of the stored concern and the degree of certainty in the default knowledge. for example  consider a case where kip evaluates a dynamic concern which has a high degree of concern  and the default knowledge claims that the interest is an unlikely goal. in this case  kip decides that the degree of concern of the dynamic concern is moderate. 
1. concern treatment in the planning process 
     once kip has evaluated a concern it can proceed in one of three ways  depending on the degree of that particular concern. if the degree of concern is low  kip can choose to disregard the concern. disregard means that the concern is no longer considered at all. kip can try to revise other parts of the plan  and suggest the plan to the user with no reservations. 
     if the degree of concern is high  kip can choose to elevate the concern to a source of plan failure. in this case  kip determines that it is very likely that the plan will fail. 
kip tries to fix this plan in order to change the value of this condition  or tries to find another plan. 
     the most complex case is when the degree of concern is moderate. in this case  kip can choose to disregard the concern  or elevate it to a source of plan failure. kip can also choose to overlook the concern. once kip has developed a complete plan for this problem  it is once again faced with the need to deal with the overlooked concern. if the plan will work  except for the overlooked concern  kip can again choose to disregard the concern  or elevate it to a source of plan failure. at this point  kip can also choose to suggest an answer to the user. depending on the degree of this overlooked concern  kip may choose to express the concern to the user in the answer. 
1. implementation and representation 
     kip is implemented in zetalisp on a symbolics 1. concepts are represented in the kodiak knowledge representation language  wilensky 1b . in particular  knowledge about unix commands has been organized in complex hierarchies using multiple inheritance. therefore  when searching for stored default concerns of a particular plan that uses a particular unix command  kip must search through a hierarchy of these commands. this is also true when looking for default violations  kip searches up the hierarchy  and retrieves the stored stored concerns or default violations in this hierarchy. 
     stored goal conflict concerns are presently implemented by creating a different concern concept for each concern. also  a 1-way has-concern relation is created between each concern  the conflicting effect and the threatened interest or goal which are cause for concern. degrees of concern are implemented by creating a has-concern-level relation between the particular concern and the degree of concern. degrees of concerns are presently implemented as numbers from one to ten. dynamic condition concerns are implemented as instances of these stored concerns. 
     defaults are implemented in the current version of kip by attaching default values of conditions to the plans themselves. context dependent defaults are implemented by exploiting the concretion mechanism of uc  which tries to find the most specific concept in the hierarchy. therefore  since kip retrieves the most specific plan in the knowledge-base  it automatically retrieves the most specific defaults. 
     violated default concerns are implemented by creating a different violated-default-concern concept for each violated default concern. a has-violated-defaultconcern relation is added between the concern and the stored default which is violated. therefore  when kip has found the default that has been violated  it looks for the violated default concerns that are referenced by this default. 
     particular concerns have been entered into the database of unix plans through a kodiak knowledge representation acquisition language called defabs. these concerns are all based on my experience using unix and on discussions i have had with other unix users in our research group. we are currently investigating a way to enter this concern information using the ucteacher program  martin  1  a natural language knowledge acquisition system. eventually  kip may incorporate a learning component that would allow kip to detect the frequency of certain plan failures and to store these as concerns. 
1. trace 
user: how do i move a f i l   named junk.lisp to a f i l e named f i l e l   
kip is passed: goal of moving f i l e junk to the f i l e f i l e l f i l e junk.lisp belongs to user f i l e junk.lisp is a lisp f i l e f i l e f i l e l belongs to user selecting plan use-mv-command 
creating use-mv-command1 checking against defaults junk.lisp is a l i s p f i l e violates default f i l e as 
text f i l e violated default concerns: lisp f i l e is in proper format for current lisp no violated default concerns match conditions of 
use-mv-command1 
determining if use-mv-command1 is used for its intention goal of moving f i l e junk to the f i l e f i l e l is intention of use-mv-command1 
skipping unintended concerns gathering intended concerns f i l e l w i l l be deleted  1  
sort concerns 
all above threshold create dynamics concerns concernl f i l e l w i l l be deleted evaluating concernl default knowledge - f i l e l probably does not exist concernl - value 1 overlook concernl plan works except for concernl pass concernl to expression mechanism uc: to move the f i l e junk to the f i l e f i l e l   type mv junk.lisp f i l e l . 
however  if f i l e l exists it w i l l be deleted. 
1. relationship to previous research 
early planners such as strips  fikes1  did not address 
goal conflict detection as a separate problem. conflicts were detected by the resolution theorem prover. the theorem prover compares a small set of add or delete formulas  and a small set of formulas that described the present state and the desired state of the world. if an action deleted the precondition of another action in the plan sequence  backtracking allowed the planner to determine another ordering of the plan steps. abstrips  sacerdon'1   modified strips to avoid these interacting subgoal problems by solving goals in a hierarchical fashion. conflicts in abstrips were also noticed by the theorem prover. however  since the most important parts of the plan were solved first  they occurred less often and fewer paths were explored. 
     sacerdoti's noah  sacerdoti1  program separated the detection of conflicts from the rest of the planning process us-

ing his resolve-conflicts critic. this critic detects one partic-
1 	reasoning 

ular kind of conflict  in which one action deletes the precondition of another action. we refer to this type of conflict as a deleted precondition plan conflict. the critic resolves the conflict by committing to an ordering of steps in which the action which requires the precondition is executed first. the 
ordering of steps is usually possible since noah uses a least commitment strategy for plan step ordering. by separating the detection of goal conflicts from the rest of the planning process  noah needs to search fewer plan paths than earlier planners. 
     in order to detect conflicts noah computes a tome  a 
     table of multiple effects  each time a new action is added to the plan. this table includes all preconditions which are asserted or denied by more than one step in the current plan. conflicts are recognized when a precondition for one step is denied in another step. in order to construct this table  noah must enter all the effects and preconditions for each of the steps in the plan every time a new step is added to the plan. 
     noah's separation of goal conflict detection phase from the rest of the planning process was an important addition to planning research. however  noah's approach is problematic in a number of ways. first  it only detects conflicts that occur as a result of deleted preconditions. other conflicts  such as conflicts between effects of a plan and other planner goals  cannot be detected using this method. most of the examples in this paper are part of this category of conflict. if many planner goals were included in a tome  as would be necessary in real world planning situations  this method would be computationally inefficient. therefore  the same problems that were discussed earlier in regard to exhaustive search also apply to this method. a tome is  1  computationally inefficient   1  not cognitively valid   1  unable to deal with default knowledge  and  1  assumes that all user goals are known  i.e. would have to evaluate every planner interest in a particular planning situation. 
     by using concerns  kip is:  1  computationally efficient each plan has a relatively small number of concerns regarding potential plan failures   1  cognitively valid - concerns correspond to the commonsense notion that people can determine which aspects of a selected plan might cause plan failure in the current planning situation without examining every possible problem that might occur   1  able to deal with default knowledge and consider new problems when certain defaults are violated  and  1  able to consider potential conflicts with long term planner interests and instantiate goals which reflect these interests when they are threatened. 
1. summary 
     a major problem for a knowledge based planner is the goal conflict detection problem. people only consider a small number of potential goal conflicts. previous planning programs  however  have accessed all effects of a plan and all potential goals of the user. goal conflict concerns were introduced in order to address this problem. kip only needs to access a small number of goal conflict concerns in order to determine if a likely goal conflict exists. violated default concerns allow the planner to use default knowledge effectively in cases where the planning situation has not been specified completely. unintended effect concerns allow kip to plan effectively when plans are used in novel situations. 
1. 