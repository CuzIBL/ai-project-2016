 
　we are beginning to make use of technology that intervenes in the contents of the communication. language processing has indeed a large practical potential if we take into account multiple modalities of communication. multimodality refers to the perception of different co-ordinated media used in delivering a message but also to the combination of various attitudes in relation to communication and information access  e.g. goal-oriented and exploration-oriented . in the paper reference is made to some prototypes developed at irst  conceived for cultural tourism. in a recent one the specificity is the combination of two forms of navigation taking place at the same time - one in information space  the other in the physical space. some challenges for the future are discussed toward the end. 
1. introduction 
let me take it from far away. language is the extraordinary means provided by the human mind for communicating with other humans  and for structuring thoughts . spoken language has been for a long time the means for communicating face to face. written language  a means for transporting language across space and time  was invented about 1 years ago  most likely by the sumers. at the beginning it was pictorial  after a few centuries cuneiform coding was proposed. only much later  in the 1th century b.c. according to some archaeologists  was an alphabet first introduced 
 in ugarit  in what now is syria . it consisted of about 1 cuneiform signs and was  so to say  quickly recognised as a breakthrough and was adopted by several peoples. 
　meanwhile means for producing various instances of a written  document  were invented soon after the first 
1 	invited speakers 
appearance of written language. they consisted of cylinders with engravings  that could leave clay tablets impressed with text . it took more than 1 years to get to gutenberg and his flexible printing system  based on the alphabet. 
　it took 1 years more to get to the computer and its possibilities. shortly before that  some other means for long distance communication  e.g. the telephone or the telex  also appeared  and in being adopted have produced some sort of slight variation of the basic two modalities  the spoken and the written ones . 
　with the computer the flexibility in dealing with the form of written language  editing  and accessing ianguage  retrieving  is extremely emphasised. but in the scientific area of natural language processing  the goal has been much more ambitious: to automatically understand and produce language. being potentially able to deal with the content of the message has opened the way to communicating with a machine through language. in particular  effort has been put in making it possible to interact with a computer  in order to get some desired information. though results have been fairly significant  the impact has been so far scarce  if we consider the way in which society could change if computers could really take the burden of understanding human language and make information available to all people. it took quite a lot for the scientific community to understand that communicating with a computer through natural language may mean something different from the two basic language modalities we are used to  maybury and wahlster  1 . the so-called teletype approach has persisted for some time before we began to understand the fact that a larger bandwidth of communication can be established between human and computer. for instance language can be integrated with images dynamically; the screen itself is not only an output medium but it can become the basis for direct manipulation of all objects involved in the communication  through a pointing device or a gesture recognition device   maybury  1   
but the point is not only in the interface. often the 
　
user does not know what information is available to her  or she may not have a clear idea of what she is searching for. the need arises for systems that integrate a mediated information access paradigm and a navigational paradigm  where the user may use different modalities to explore the material. we believe that exploration of an information space will become more and more a typical interactive attitude on the part of users  in a world inhabited by a multitude of available multimedia information  maybury  1 . ail this is becoming apparent with the current diffusion of the web and its various browsers. 
　another key element of flexibility lies in the possibility of a system of having a model of the user  including her interests  idiosyncrasies and the dynamic aspects inferred during the interaction. this is instrumental for making sense of partial or not detailed requests  or other acts  by the user  and for determining the system's actions. 
　a desirable feature is creating the appropriate presentations of information: the relevant information is made available to the user at the proper level of detail  coherent with other pieces of information provided previously  and further exploration is favoured. 
　if information is to be presented in a flexible way  it is essential that an automatic processor does the job in the case of text presentation  a natural language generation system. the latter is a computational tool that automatically  builds  a text  a sequence of sentences  starting from abstract  non-linguistic  specifications. given the internal representation of the knowledge sources  the system decides what is the relevant information to be communicated  it organises a coherent text structure and produces the most appropriate linguistic expressions to convey the message. multimodal flexible presentations exploit synergistically the advantages that different media can provide in conveying the message to the user. in this case all processors must start from an internal representation and the system must organise media allocation and media co-ordination. 
　but our goal will be only partially attained if we do not begin to touch on the most difficult challenge of all: the challenge of keeping attention high  of building a seductive interface  of having the user be surprised and attracted by the creative attitude of the  artificial  companion.... at the end we are very rapidly getting to the point where whatever message  whatever agent  whatever interface will have to compete over the most precious and scarce resources human beings have: time  attention and emotional involvement. 
　i will discuss in turn some of these themes  making reference to work we have developed at irst. 
1. multimodality and exploration of information 
there can be different views on multimodal communication. per se multimodality is multidimensional. often it is only regarded as the combination of various uses of media  but certainly this is only one obvious aspect of the whole matter  that  besides  requires a clarification.  multimedia  denotes the physical means via which information is input  output and/or stored.  multimodality  refers to the human perceptual processes such as vision  audition  taction  and somehow it may also refer to the interpersonal or person-artefact context that develops in the interaction. intelligent  multimodal  systems in principle tend to be characterised by a representation of the content of the presentation  so that presentation material is not fixed and can be customised dynamically. 
　

fig. 1 a representation of ambiguity in multimodal communication 
 the calling of st. matthew  by caravaggio  rome  1  
	stock 	1 
　
　multimodality can also refer to the combination of various attitudes in relation to communication and information access  e.g. goal-oriented and explorationoriented   each one having in isolation its specific characteristics. 
　another view is concerned with the relation to human capabilities. multimodality may amplify our capabilities. in order to do so it must be cognitively compatible  but altogether it may not reflect our  natural  communication. 
　yet another aspect is related to the specific role that language plays in the multimodal context  stock  1 . it is a different role than when communication is based on a single modality  and so its operational characteristics are different; its modelling requires specific components. 
　integration of nlp and hypermedia in a multimodal system offers a high level of interactivity and system habitability; each modality overcomes the constraints of the other  resulting in a novel class of integrated environments for complex exploration and information access. 
　according to  waterworth and chignell  1   there are at least two dimensions for a model of information exploration: structural responsibility and target orientation. structural responsibility involves the issue of which agent  i.e. the user or the system  is responsible for carrying out search and for giving structure to information. it gives rise to a dichotomy between navigational and mediated exploration. the dimension of target orientation presents a dichotomy between browsing and querying. browsing is distinguished from querying by the absence of a definite target in the mind of the user. this distinction is determined only by the cognitive state of the user  not by her actions nor by the configuration of the system. in reality there is a continuum of user behaviours varying between querying and browsing so that it is inappropriate to build systems that reflect this strict dichotomy  imposing one particular attitude on the user's exploration. 
　in work carried on for several years at irst we developed an environment in which interaction could smoothly move along the two dimensions. dialogue management then had to include a communicative action co-ordinator  responsible for proper media usage  and so  for example  it can take into account the deictic context at any time of the interaction  and for suggesting to the user a shift along the structural responsibility dimension. 
　let me now summarise a system called alfresco. for this system and for some other experiences i report here you will see a common application theme: cultural heritage and tourism. no wonder: italy is considered to have half of the world's cultural tourism resources. besides  the field can provide a wonderful opportunity for introducing technology that can help shifting from a mass-oriented attitude to an individual-oriented attitude - exactly what we aim at. cultural tourism can become an experience where the individual is the active subject of the exploration  one who develops a personal taste and interest. 
　alfresco  stock  1  is an interactive  naturallanguage centred system for a user interested in fourteenth century italian frescoes. it has the aim of providing information  and also of promoting other masterpieces that may attract the user. hypermedia is integrated both in input and output. the user can interact with the system by typing sentences  navigating in an underlying hypertext  and using the touch screen in a coherent multimodal discourse setting. in output  images and generated text offer entry points for further hypertextual exploration. the result is that the user communicates linguistically and by manipulating various entities  images  and text itself. the system builds a simple model of the user as the dialogue proceeds and uses it for output decisions  while allowing the user to browse around freely. 
　a higher-level  pragmatic component decides how to react in the given dialogic situation  considering the type of utterance by the user  the context  the model of the user's interest  the things already shown or said to the user and so on. the dialogue may cause zooming into details or changing the focus of attention onto other frescoes. 
　we have proposed a level of multimodal acts representation  stock et al.  1   roughly corresponding to what  for strictly linguistic dialogues  is the illocutionary level  fig. 1 . the key point for multimodal interaction is provided by the uniform use of felicity conditions  the rules that govern the relations between interactional exchanges and communicative intentions. 

fig. 1 alfresco dialogue management 
the dialogue cohesion management  zancanaro et al  
1  1a  provides also a graphical feedback of the dialogue cohesion status to the user. this visual representation:  a  reassures the user at a glance on the system's interpretation  as such it takes the place of a paraphraser   and  b  allows co-operative recovery from 
　
1 	invited speakers 
　
discourse misconceptions by means of a series of  intuitive actions  when his interpretation is not the one the user meant 
　in general a tighter integration of different modes of exploration  language-oriented and navigational  has been accomplished. i think this is a very fruitful concept that can lead to various applications. the study of the involved cognitive aspects is of great importance and lab experiments with implemented prototypes and simulated systems will make all of us understand better this kind of amplification of human communicative capabilities. 
1. bringing physical space into the picture 
one further element for advancing in the direction of personalisation and context-sensitivity is offered by ubiquitous information access  made possible by hardware technologies such as portable devices and wireless networking. a museum is a privileged environment for introducing adaptive information with ubiquitous access. in fact  the experience of visiting a museum typically consists in moving in a physical space and acquiring information about the objects shown  and of course in becoming interested and moved by what is displayed! . in the new interaction scenario  the computer  a hand-held device including spoken output  allows the integration between the physical space  through a positioning system  and the related information space  yielding a new way of exploring cultural heritage. the individual visitor is at the centre of the physical-virtual space exploration and her movements and interactions provide input to the system to tailor appropriate presentations. 
　the approach presented here was developed inside a project at irst called hyperaudio  not et al  to appear . the results are at the basis of the development of an even richer interaction scenario that is being explored jointly with other partners in hips  a european project of the esprit i1 program1. 
　the problem of adapting content for  cultural  information presentations in physical hypernavigation shares many features with the problem of producing adaptive and dynamic hypermedia for virtual museums  e.g. ilex  mellish et al 1  or dynamic encyclopaedias  e.g. peba-ii  milosavljevic et al  1 . moving in a physical museum has been the goal of the rhino project  where a robot accompanies the visitor  burgard et ah 1 . 
content adaptation in a physical environment poses some problems that are related to the fact that the visitor is experiencing a  rear situation: the cognitive problems that may arise when a person is moving in a virtual information space  are different when the user is seeking concrete objects  moving in a real environment that provides stimuli  attention grasping and feedback. information is presented in different situational contexts  determined mainly by:  i  user position and movements;  ii  the structure of the surrounding physical space  e.g.  whether objects are close or not ;  iii  whether other people are examining the same item or not;  iv  whether the user came alone or not. 
　hyperaudio  and hips  integrates the individual  dynamic modelling of the user with a general model of the environment  of the user's movements and of the discourse history to best tailor information presentations. different forms of adaptation are introduced by the system  both in the information provided and in the further steps suggested. in general the approach points to a realistic and evolutionary adoption of generation techniques; at present it yields a rethorically coherent dynamic combination of small existing fragments of speech. 
　the architecture abstracts away from specific implementation solutions. it can be implemented on a single mobile platform  as in hyperaudio  or with some modules running on a standing platform and communicating with the mobile computer via a wireless connection  this solution is investigated within the hips project . 
　when deciding what information to include in the presentation and the most suitable discourse structure  the system takes into account various knowledge sources about the user and the interaction  fig. 1 . 

fig. 1 architecture 
　the user model is accessed to exploit: a  the user's interests  which are inferred from her behaviour   to include in the new message information that can stimulate the hearer's attention  possibly proposing information about other objects/sites strictly related to what the user is seeing  to increase curiosity and desire to explore; b  the user's background knowledge  in order to relate the new information presented to what she already knows  therefore reinforcing learning  and to 
	stock 	1 
　
decide whether additional clarification or exemplification of new concepts is required to help her understand. as the interaction proceeds  the system refines its assumptions about the user's interests and knowledge by observing the user's behaviour and by keeping track of the information she has been exposed to. another knowledge source is the history of previous interaction. an important role in content selection is also played by discourse strategies that the system exploits to guarantee that topics are presented in a coherent order and the various discourse chunks are linked by rhetorical relations that reinforce the understanding of discourse flow. the system consistently limits the length of audio messages  deciding to realise part of the content as clickable links on the screen to avoid overwhelming the visitor with information. 
　the language style adopted for each single user is selected according to the user type. 
　according to information contained in the current context of interaction  e.g. position in relation to displayed objects  to the more extended environment  ....  and in the discourse history  e.g. the topic of the previous sentence or presentation   the system selects an appropriate linguistic realisation for referring expressions and spatial references. other cohesion devices  like anaphora  conjunctions  lexical cohesion  are properly introduced to guarantee the fluency of the message and enhance understanding. 
　the system includes also a graphical interface that helps to orientate the visitor and is useful for complementing linguistic instructions. besides   clickable  elements in the oral presentations appear on the screen. 
　input provided by the user to the system can be both implicit  corresponding to movements in the physical space  and explicit  corresponding to interaction with the palmtop screen. input is first analysed by the intelligent input analyser that decides on the most suitable type of processing required  e.g.  plan a new presentation  stop the current presentation  plan a navigation support message  etc. . from all input the behaviour observer derives possible refinements to the user model. 
　the presentation composer is responsible for planning an overall presentation that integrates  where appropriate : object descriptions  images supporting descriptions  buttons and menus for follow-up information requests  directions for navigation support and maps. fundamental resource for flexible output generation is the macronode repository. each macronode includes a network of message fragments  audio  text or images   a list of pointers to other relevant macronodes  specifying the particular rhetorical relations among them   the type of message  e.g.  introductory label  caption  ...   and a pointer to the relevant semantic concepts in the ontology. the network of message fragments encodes the different ways in which it is possible to realise the 
1 	invited 	speakers 
content of the macronode and thus encodes its surface linguistic forms  while the relevant concept  the rhetorical links and the message type encode the deep structure of the description. 
　many of the issues presented for the museum setting apply to any physical hypernavigation setting in which individual  dynamic guides would be appropriate: for example historical cities  archaeological sites or natural settings such as gardens  parks or mountains. it is obvious that wide open spaces introduce additional options from the technological point of view  for example the adoption of a gps as the localisation system  and suggest more ambitious scenarios  for example: new functions to support groups of visitors  access to on-line services such as meteo forecasts . all that is subject to investigation inside the european  project hips. another element being explored in hips is the adoption of global strategies for presenting information and promoting items  making sure the visitor does not miss them. the simplest strategy is a gravity-driven one: there is a basic path where the visitor  through presentations and suggestions is attracted  whatever deviations she performs; distances from a position to the next position tend to be minimised. another one brings into the picture the dimension of play: for instance a dynamic treasure hunt  where typically physical distances tend to be maximised. 
　yet another innovative feature is the introduction of collective memories. the visit trace is kept. the data can be used by the visitor: when she is back home she will be able to go deeper into the domain she has been exposed to  with a system  like alfresco  that knows about her visit and will support her in her successive exploration. 
　other possibilities are there for treasuring some specific itinerary  for instance one made by an art critic or by a public person  so that it can be followed with minor deviations by another visitor. yet another opportunity is to build models of the behaviour of classes of visitors and on that basis influence the curators' choices. 
1. what about speech  
speech processing is a key element for natural interaction systems. i believe that synthesis in particular will prove even more important than recognition. often the user's input can be very simple  as in hips  but still output  as it may depend on other implicit input or on a user profile  may require a lot of sophisticated processing for achieving a good presentation level. with personalised output often you want information to be presented as a coherent text  prepared for you and presented orally. concept-to-speech  integration of generation and synthesis  is yielding good results  but even synthesis per se has improved tremendously. 
　
　coming to spoken input  there has been a lot of progress in spontaneous speech recognition  albeit in highly constrained dialogic settings. for instance within the cstar ii consortium irst and its partners have built a prototype aimed at making possible that two persons physically remote and each speaking her own language  cettolo et al  1   entertain a conversation oriented to book a hotel room. again the application is relevant for the tourism domain and translation is the most apparent result  but probably the really important technological progress in input is in the ability to treat natural speech phenomena  such as false starts  hesitations and so on. recently we have begun to work on spoken dialogue within a highly sophisticated  immersive  graphical system about cultural heritage. 
1. a challenge - collaboration 
what described so far is not enough. dialogue must be seen as a collaborative enterprise and we need models that help us understand multimodality at this deeper level. our overall systems at irst do not make use of this concept yet  but we have worked  in vitro  on this. we have considered the multimodal interface as a place where actions occur that may be considered both as domain actions and communicative  linguistic and nonlinguistic  actions. this is true for user and system actions: when the system holds the initiative it performs some domain actions  some communicative actions or actions of both kinds. the interface is at the same time a sensorial organ  the collection of media through which the message is realised  and the  virtual  place where domain actions are actually performed. in the old  teletype approach  this ambiguity was not present. 
　the intentional structure of discourse has been modelled in  lochbaum  1 . her proposal emphasises the collaborative aspect of communication  by means of a peculiar kind of plans called sharedplans. the theory of sharedplans  grosz and kraus  1  is based on the notion of  plans as complex mental attitudes   and is intended to model interaction as a joint activity in which the participants try to build a plan together: the plan is shared in the sense that participants have a compatible set of beliefs and intentions. in this framework  communication is seen as the way in which agents agree on the various stages of the plan construction. 
　the difficulties in applying the sharedplan theory to multimodal interaction arise from the double nature of the interface: some actions  especially the linguistic ones  arc intended to augment the current sharedplan while others are primarily intended to execute the related recipe  but at the same time  if these actions take place on the interface  in some way they contribute to the augmentation of the plan too. for example  if an agent is committed to do an action it must perform it and then inform the other agent of its execution: but if the effects of the action are apparent on the interface neither the explicit commitment nor the informing are actually necessary. 
　any intelligent multimedia system requires a component that exploits the context to make presentation decisions  media selection  co-ordination  allocation  etc.  or to interpret multi-channel input  maybury and wahlster  1 . in particular  given information that needs to be displayed to the user  a multimedia co-ordinator automatically builds a coherent and co-ordinated presentation using a combination of available media   see for intance wahlster et al.  1 . 
　following  arens  1  any complex multimedia coordinator needs to be built around a collection of models: a model of virtual devices  a model of the characteristics of information to be displayed  a model of the discourse and the communicative context  a model of the interaction participants1 beliefs  goals  attitudes  capabilities and interests. input and output processes interact with the dialogue manager that maintains the discourse structure and ensures a coherent interaction between the participants. 
　an important point is whether action execution is observable  and in principle interpretable as desired  by the other agent on the interface. this depends on the ability of the multimedia co-ordinator to plan a meaningful presentation with the available media. the multimedia co-ordinator is instructed by the dialogue manager as to the communicative intentions and returns the planned presentation to the dialogue manager. the dialogue manager in turn evaluates the expected effects on the other agent  and whether the case asks for further planning. for instance in case the presentation is not perspicuous enough  it may decide to plan a further communicative action  for example an inform action . 
　we have proposed a specific augmentation and execution process for sharedplans that can accommodate our view  zancanaro et a/  1b . two basic elements needed to find their place: a  a  local coherence  technique that could be combined with the higher level coherence of the sharedplan approach that views communication as a collaborative activity  and b  multimedia co-ordination. 
　in explorative information access it is more difficult for the system to recognise the user's intentions  as far as real world actions are concerned. the attentional aspect is more relevant; yet the intentional aspect can be fruitfully inserted as well. general strategies of exploration can be conceived  even if not every action on the part of the user can be interpreted at the planning level. besides  some interaction fragments certainly can 
just be modelled as task-oriented. a flexible combination of a more  localist  representation and a collaboration-based one can be appropriate. 
	stock 	1 
　
1. computational humour -not so crazy 
interfaces must be seductive: they must attract and satisfy the user. this is particularly true of situations where the goal is not so much work productivity  but a reality that is a mix of entertainment  information and education: so called edutainment constitutes an increasing large portion of what the computer can offer to our life. we know a major challenge for our society will be to find ways to improve education  not only institutionally  but at all level of activity. and we know that learning can go well together with active entertainment. 
　the human mind likes communication and emotions. personally i consider humour an essential part of communication. the relaxation of inner censorship and the release of energy that derives from it produce an intense pleasure that tends to repeat itself in a favourable situation for giving raise to this phenomenon. interactive and individual-oriented computational humour  stock  1   beyond entertainment  per se important  will help all kinds of concept promotion and  in general  of learning. i am sure  among application areas  it will constitute the key to a number of children's activity and games: think of the children's ability in finding ambiguities and absurd meanings and the match they could ftnd in a computer; simple humour on the part of the system can be a great resource as it helps to memorise errors and corrections; it will help develop social behaviour  etc. even in a domain of active exploration  humour can help keep attention high  promote items and memorise what is seen. 
　while humour without restrictions is certainly  aicomplete   there is work that shows the feasibility of introducing some elements in a system  see for instance binsted 1 . 
　a restrictive view of interfaces  normal today  will eventually yield to a more advanced view  in which interaction with the user will be accomplished for instance through an assistant  a critic or through a group of characters. the work of barbara hayes-roth  see for instance 1  and others has shown some possible ways. humour  i believe  has to play an essential role. the characteristics of the interface will determine its potential on education and on society in general and we should not miss this opportunity. it is worth remembering what oroucho marx said of tv:  i find tv very educational. the minute somebody turns it on  i go to the library and read a good book.  
conclusions 
language processing has indeed a large practical potential if inserted in a multimodal conception of the interface. there are different dimensions for the concept of multimodality. one refers to the perception of different co-ordinated media used in delivering a message; another one to the combination of various atti-
1 	invited speakers 
tudes in relation to communication and information access  e.g. goal-oriented and exploration-oriented . 
　in this presentation i have taken a practical perspective and i have referred to some implemented prototypes  mostly conceived for cultural tourism  a sector that i believe has a large potential. we have started with a system  developed some years ago  where interaction was based on the seamless combination of navigation and dialogue. we have then begun to take into account the physical space  with the goal of producing a personal  mobile device for person-oriented guided visits in a physical museum or a town. toward the end i have talked about bringing into the picture a deeper level of modelling multimodal dialogues  based on collaboration  and briefly discussed the relevance of seductive interfaces and humour. 
　what else do i want to say about prospects for realising more useful and intelligent interfaces  
　  it is important to introduce elements of a cognitively compatible  qualitative physics in our systems  so that in our multimodal interaction the system can understand what the user's representations and reasoning about space and time are and how she naturally conveys meanings in her communication. 
　  case-based reasoning techniques can be a very relevant resource for presentation systems  especially in the edutainement and cultural heritage domain. we must find appropriate ways of using this resource in the multimodal context. 
　  we need to make experiments  especially wizard of oz simulations and understand more about what is really cognitively appropriate. most of the things we foresee do not exactly correspond to what we find in nature  face to face communication  or in written text. our technology must not be intrusive  and on the other hand it may be different from other modalities we have known for a long time. 
　  natural language generation has a large potential for improvement. one thing our community can yield is the next step after hypertext. a situation where text fragments are tailored and the reader/hearer may want to interact with the system so that the material is presented to her with a certain style  taking into account an increasingly large number of personal characteristics and behaviours. on our future radiosets  we shall have not only the loudness setting but also an interactive adaptation of the presentation to our context. 
　by the way  the answer to the question in the title is no. but the question may have a different answer when posed again in the not so far future. 
acknowledgments 
i wish to acknowledge the contribution of all the people at irst who have worked at the alfresco  hyperaudio  
　
and hips projects  with whom the ideas presented here have been developed. in particular  massimo zancanaro and carlo strapparava  beside all this  have also been essential for developing the collaboration-based multimodal dialogue work. 
