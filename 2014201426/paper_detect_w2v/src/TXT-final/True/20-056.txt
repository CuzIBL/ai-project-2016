 
　　　an improved stochastic stereo-matching algorithm is presented. it incorporates two substantial modifications to an earlier version: a new variation of simulated annealing that is faster  simpler  and more controllable than the conventional  heatbath  version  and a hierarchical  coarse-to-fine-resolution control structure. the hamiltonian used in the original model is minimized  but far more efficiently. the basis of microcanonical annealing is the creutz algorithm . unlike its counterpart  the familiar metropolis algorithm  the creutz algorithm simulates a thermally isolated system at equilibrium. the hierarchical control structure  together with a brownian state-transition function  tracks ground states across scale  beginning with small  coarsely coded levels. results are shown for a 1 x 1 pair with 1 pixels of disparity. 
i introduction 
       the paper describes a stochastic optimization approach to stereo matching. an early version is described in . two major extensions have been made that permit substantially improved performance: first  a new variety of simulated annealing is employed which is more efficient  more easily implemented  and offers more control over the annealing process than the standard form. secondly  the system is extended to operate over several levels of resolution  exploiting relatively quickly computed minima at lower levels of resolution to initialize its state at higher levels. this method leads both to more efficiency and to the ability to deal with much larger ranges of disparities. 
　the basic representation remains unchanged. the state of the system encodes a dense map of discrete horizontal disparities  defined over the left image  which specify corresponding points in the right image.. in the improved design  this state is relative to a particular level of resolution. 
　the energy of a lattice site is composed of two terms  each of which expresses a constraint important in stereo matching: 

 support for this work was provided by the defense advanced research projects agency under contracts dca 1-c-1 and mda1a-1-c1. 
1 	perception 
1 and ir are the left and right image intensities  or some simple function of them  such as a laplacian . subscripts i and j range over all sites in the left image lattice. d is the disparity map. the first term is the absolute difference in intensity between corresponding points  where the correspondences are defined by the current state of the system   and the second is proportional to the local spatial variation in the current state  the magnitude of the gradient of the disparity map . the constant a is used to balance the terms.1 this equation expresses two competing constraints: first  the image intensities of corresponding points should be more-or-less equal  and second  the disparity map should be more-or-less continuous. 
the hamiltonian  

is unchanged; therefore  the ground states that we seek to determine or to approximate are the same. the new design is strictly concerned with improved performance. the techniques used to obtain it are not restricted to stereo matching  and should be considered for any simulated-annealing approach to low-level vision problems. 
	ii 	microcanon1cal annealing 
　　　the conventional simulated annealing algorithm uses an adaptation of the metropolis algorithm to bring a system to equilibrium at decreasing temperatures. the metropolis algorithm  defines a markov process that generates a sequence of states  such that the probability of occurrence of any particular state is proportional to its boltzman weight  

where is the energy of state s and is the inverse temperature of the system. this process generates samples from the canonical ensemble  that is  the system is considered to be immersed in a heat bath with a controllable temperature. annealing is accomplished by imposing a schedule for reducing the temperature   so as to keep the system close to equilibrium. 
　creutz has described an alternative technique that simulates the microcanonical ensemble . in this method  the total energy remains constant  for some fixed point in the schedule . instead 

of simulating a system immersed in a heat bath  the creutz algorithm simulates a thermally isolated system in which energy is conserved. it performs a random walk through state space  constraining states to a surface of constant energy. the simplest way to accomplish this is to augment the representation with an additional degree of freedom  called a demon  that carries a variable amount of energy   the total energy of the system is now: 

normally  the demon is constrained to have nonnegative energy  although the possibility of giving it negative energy is useful in annealing  as will be discussed below. 
　in the metropolis algorithm a potential new state s' is chosen randomly  and is accepted or rejected based on the change in energy: 

if  is negative  the new state is accepted; otherwise  it is accepted with probability 
 is nonnegative  however  acceptance of the 
new state is contingent upon 
accepted  and the demon energy is decreased ; otherwise  the new state is rejected. clearly  the total energy of the system remains constant. 
　the creutz algorithm has several advantages. unlike the metropolis algorithm  it does not require the evaluation of transcendental functions. of course  in practice these functions can be stored as tables  but we would like our algorithm to be adaptable to fine-grained parallel processors such as the connection machine. the small amount of local memory in such machines makes lookup tables unattractive. the creutz algorithm can easily be implemented with only integer arithmetic - again  a significant advantage for fine-grained parallel processors and for vlsi implementation. experiments indicate that the creutz method can be programmed to run an order of magnitude faster than the conventional metropolis method for discrete systems . a further important advantage is that microcanonical simulation does not require high-quality random numbers. 
　in conventional simulated annealing  we control the process by specifying the temperature. in the microcanonical version  however  temperature is not a control parameter; it is a statistical feature of the system. in fact  standard arguments can be used to show that at equilibrium the demon energies have a boltzman distribution: 

if the demon energies are non-negative  the inverse temperature can be determined from the mean value: 

　control of microcanonical annealing is accomplished by periodically removing energy from the system. the method used to generate the results in section iv is as follows: 
1. assume that the process begins in a random state so of high energy with respect to the ground state. call this e so . the initial demon energy is zero. 
by reducing 
the demon energy the results of section iv were obtained with 
1. run the creutz algorithm until the system reaches equilibrium. a reasonable test for equilibrium is to consider the rate of accepted moves to states of higher energy. if the system is large enough  this rate will increase steadily until it approximates the rate of moves to states of lower energy. we terminate the process for a particular energy level when the rate of accepted moves to higher energy states decreases  measured over n site visits . 
1. repeat steps  1  and  1  until no further improvement is observed. 
this procedure has only one free parameter: the ratio 
while  the creutz method operates as a  greedy  algo-
rithm  accepting only moves to lower energy states and increasing ed. when ed becomes positive  which happens quickly if  is small   the demon begins to exchange energy between lattice positions. as the ground state is approached  ep remains negative because it cannot absorb more energy from the lattice. 
　the algorithm described above is sequential  and therefore is not suitable for parallel processing. each local state transition can change ed  which in turn can affect the next transition. fortunately  the technique can be modified to a parallel one by using a separate demon for each lattice site.  as we add demons  the technique moves toward a canonical-ensemble simulation. in fact  if the number of demons is very large compared to the number of sites  the technique specializes to the metropolis algorithm .  preliminary experiments with one demon per site indicate good performance  although the results of section iv were generated with the single-demon algorithm. 
ill hierarchical annealing 
     in the original model   annealing was performed only at the level of resolution of the stereo images. in some cases  the images were first bandpass-filtered to remove low-frequency components - in effect  a simple photometric correction for inconsistent sensor gains or film development. lower and upper bounds on disparity were specified in advance  and all state transitions were considered with equal probability. as the range of disparity became large  this scheme required much larger amounts of computation. if we have m permissible disparities and n pixels  the size of the state space is mn. if we double the range of disparity  the size of the state space increases by a factor of 1n. since n is a rather large number  1 in the example shown in 
section iv   we see that the state space grows explosively with increasing disparity range. 
　a natural extension of the method is to adopt a hierarchical  coarse-to-fine control structure. at a coarse level of resolution  the number of lattice sites  i.e.  the number of pixels  and the range of disparity are small; therefore the size of the state space is relatively small.1 we should be able to compute an approximate ground state quickly  and then use it to initialize the annealing process at the next  finer level of resolution. 
'although the state space may be large in absolute terms. 
	barnard 	1 
　the laplacian pyramid  originally developed as a compact image-coding technique   offers an efficient representation for hierarchical annealing. in a laplacian pyramid  an image is transformed into a sequence of bandpass-filtered copies   each of which is smaller than its predecessor by a factor of 1 in linear dimension  a factor of 1 in area   with the center frequency of the passband reduced by one octave. this transform can be computed efficiently by recursively applying a small generating kernel to create a gaussian  low-passed  pyramid  and then differencing successive low-passed images to construct the laplacian pyramid. 
　after constructing laplacian pyramids from the original stereo images  disparity is reduced by a factor of 1 in successive levels. therefore  at some level  disparity is small everywhere. for typical stereo images  we can take this to be level n - 1.  for example  if the original images were a power of 1 in linear dimension  the laplacian images at level n - 1 would be 1 x 1 pixels. disparities in the range of 1 to 1 pixels in a pair of 1 x 1 images would be reduced to the range of 1 to 1 pixel  with truncation  at the  n - 1 th level.  we shall start annealing at this level  find an approximate ground state  and then expand the solution to the next level. to make this coarse-to-fine strategy work  however  we need two further modifications. we must use a different process for generating state transitions  and we must specify how a low-resolution result is used to start the annealing process at the next-higher level. 
　in the original model  the probability of choosing a new disparity for consideration as a new state was uniformly distributed over the prior range of disparities: 

this is not compatible with our intention of guiding the process with lower-resolution results  however. because we are now assuming the disparity of a lattice site to be close to its correct value  a more effective generating process is to restrict the disparities to increase or decrease by one pixel: 

with the further restriction that the disparities are not allowed to specify corresponding points outside the boundary of the right image. in this scheme  the system undergoes brownian motion through state space. an additional feature of this state-transition function is that it is no longer necessary to specify bounds on disparity in advance. 
　expanding a low-resolution result to the next level is slightly more complicated. obviously  one should begin by simply doubling the size of the low-resolution lattice and doubling the disparity values. having done this  however  we find that the new state has an artificially low energy because every odd disparity value is  unoccupied   and the new map is therefore more uniform than it should be. a spurious symmetry is imposed on the new state that is solely due to the quantization of the previous result  which is likely to place the system near a metastable state  a local minimum  from which it cannot recover. fortunately  there is an easy solution to this problem: destroy this symmetry by adding heat. one effective way is as follows: 
1. compute the energy  f the initial state at level k.  this 
1 	perception 

iv results 
     the images in figure 1 are an aerial stereo pair  1 x 1 pixels each  covering part of martin marietta's test site for the autonomous land vehicle project near denver. the terrain is dominated by a long  steep  hogback   running diagonally across the middle of the images   that separates two broad valleys. the highest terrain is in the upper left. several roads and a few buildings may be seen. disparity ranges from zero to 1 pixels. 
　the results of applying the microcanonical  hierarchical annealing algorithm to these data are illustrated in figure 1  which shows the approximate ground state at the highest level of resolution. disparity values are displayed in 1 pseudocolors with wraparound. 
　the largest problem solved by the previous version of the system was on the order of a 1 x 1 pair with 1 levels of disparity. solving this problem required about 1 hours on a symbolics 1. the result shown here is a 1 x 1 pair with 1 levels of disparity  and was computed in about the same amount of time. consider the size of the state space of the two problems. the state space of the current problem1 exceeds the size of the old problem by a factor of more than 1. 
v conclusions 
     two major improvements to a stochastic stereo-matching system have been described: first  a simulation of the microcanonical ensemble  as opposed to the canonical ensemble of conventional simulated annealing; and second  the extension to a hierarchical control structure based on laplacian pyramids. both 
techniques are rather general in nature and can probably be 
used in other simulated-annealing applications. together  they permit solutions of stereo-matching problems that are far beyond the competence of the original system. 
　we are currently evaluating the quantitative increase in performance attributable to each new technique. qualitatively  the use of microcanonical annealing yields perhaps an order of magnitude increase in efficiency. a potentially more important benefit is that its computation is simpler than the computation of standard annealing  and is therefore more readily implemented in fine-grained parallel systems. the hierarchical control structure  combined with the brownian state-transition function  contributes most of the increased performance. 
 considering the range of disparity to be fixed at 1 pixels. 


	barnard 	1 
1 the performance of the system is not very sensitive to the value chosen for in the example of section iv  as well as ail three examples in was used. 
---------------

------------------------------------------------------------

---------------

------------------------------------------------------------

