reasoning about deduction with unknown constants 
andrew haas 
department of computer science  university of rochester 

fbs1;ract. an i n t e l l i g e n t agent must plan future deductions and anticipate what other agents w i l l deduce from t h e i r b e l i e f s - creary  1  proposed to do t h i s by simulation. often the agent's future b e l i e f s   or the beliefs of other agents  involve terms unknown to the agent at simulation time. this paper shows how to extend creary1e technique to handle t h i s case. 
       suppose mary knows jane's phone number  and knows also that jane's number is the same as john's. how does one show that mary can infer what john's number is  consider another problem: a robot has a piece of paper with john's number w r i t t e n on i t   and wants to know john's number. by looking at the paper it can learn what's w r i t t e n there. how w i l l it infer that t h i s number is john's phone number  both of these problems involve reasoning about a deduction whose premisses contain an unknown constant. in the f i r s t problem the unknown constant is jane's phone number. mary knows i t   but the agent who is reasoning about mary doesn't. this agent would know the number only if he believed a sentence of the form  mary knows that jane's number is n   where n is the constant that mary uses to name jane's number. in the second problem the unknown constant is the number w r i t t e n on the paper. the robot expects to know it after looking at the paper  but doesn't know it at planning  time. 
　　　moore  1  has devised a method of reasoning about deduction that handles unknown constants. but his method is too strong. it allows one to show that an agent knows any sentence that can be proved from his knowledge  no matter how d i f f i c u l t the proof i s . creary  1  proposes a method of reasoning about deduction that avoids t h i s problem. but his method can't handle unknown constants. this paper describe the d i f f i c u l t i e s that arise in applying moore's theory to the problem of the robot f i n d i n g john's phone number. it presents a version of creary*s method. f i n a l l y it shows how to extend creary's method to handle premisses with unknown constants. the result is a scheme that achieves the power of moore's method and avoids i t s problems. 
　　　consider the problem of finding out what john'1 phone number i s . the robot knows that whatever is written on the paper is john's number. by looking at the paper it finds out that some number n is w r i t t e n there. these two facts imply that john's number is n. since the robot always knows a l l l o g i c a l consequences of i t s knowledge  it knows that john's number is n as soon as it learns that n is w r i t t e n on the paper. so in moore's system the robot's plan for learning john's number consists of the single step of looking at the paper. 
       imagine a real robot t r y i n g to execute t h i s plan. it sends a command to i t s tv camera to point at the paper. in the input buffer appears a data structure that says that n is written on the paper. and here the plan stops. the robot s t i l l has to perform a short computation  i n f e r r i n g  john's number is n  from  n is written on the paper  and  whatever is w r i t t e n on the paper is john's number . but moore's plan omits t h i s step  because the agents in his theory make a l l possible inferences from their knowledge automatically. if a robot can't do t h i s   it should not use moore's theory to plan i t s own inferences. 
　　　an alternative to moore's theory of knowledge and b e l i e f is the syntactic theory. it says that a b e l i e f or piece of knowledge is a sentence  moore and hendrix  1 - suppose these sentences are in f i r s t - o r d e r logic  motivation for t h i s appears l a t e r   . if a robot plans to acquire certain b e l i e f s   it is thinking about i t s own b e l i e f s . so the language in which those beliefs are expressed must be capable of t a l k i n g about i t s e l f . in p a r t i c u l a r   it must contain names for i t s own expressions. 
　　　to each constant of the language assign a name  formed by appending a subscript 1 to that constant. thus if  john  is a constant and denotes a man  
1 

 john 1   is a constant and denotes 	 john . 
now consider the symbols that are used to build new expressions - the predicate l e t t e r s   function l e t t e r s   connectives and q u a n t i f i e r s . call these symbols constructors. thus the sentence  or p  
q   contains the constructor  or   and i t s arguments are  p  and   q   . to each n-adic constructor assign an n-adic function l e t t e r   again formed by appending a subscript 1. suppose  z  is an n-adic constructor. then the function l e t t e r   z     denotes a function that maps n expressions e1...en to the expression whose constructor is  z  and whose arguments are e1...en. thus if  and  is a connective   and 1   denotes a function that maps the sentences  p  and   q   to the sentence  and p  q  t f . 
　　　so the representation of  the robot believes that john's number is 1  is 
 1   believe robot  equal1  phone-j  john1    
1   
the second argument of the function l e t t e r  believe  denotes the sentence 
 1  	equakphone john  1  
　　　creary suggests essentially t h i s method of quotation. he goes on to suggest simulation as a method of reasoning about deduction. it works l i k e t h i s . begin with a set of sentences of the form believe a  x  
where x is quoted. by stripping off the subscripts you can reconstruct the sentences that a believes. then collect these in a separate data base. try to prove the desired theorem in t h i s data base. if you succeed  infer that a can prove t h i s theorem if he wants. use some measure of the e f f o r t expended to predict how long a w i l l take to get this result. this method of reasoning about deduction does not allow us to prove that agents know a l l consequences of their knowledge. 
　　　this won't work if a's beliefs contain constants unknown to the simulator. without knowing these constants the simulator can't build a data base containing a's b e l i e f s . one can solve t h i s problem by taking advantage of the following property of f i r s t - o r d e r logic  proved in  tennant 1  : 
if any substitution of terms without variables for constants is applied to the conclusion and premisses of a f i r s t - o r d e r proof  the result is again a v a l i d f i r s t - o r d e r proof.  there are exceptions  such as the rule of a l l introduction in natural deduction. my technique can be extended to handle these cases too.  
this implies that one can use dummy constants to represent unknown terms in another agent's beliefs without disturbing the process of simulation. whatever proof you find when you simulate w i l l work just as well when the dummies are replaced by the real terms. 
	consider 	the 	problem 	of 	finding 
john's phone number. the robot expects that after looking at the paper it w i l l believe that n is written on the paper  where n is the arabic numeral for john's phone number. to represent t h i s expectation one must be able to describe t h i s n without knowing which numeral it i s . define the predicate  arabic  so that  arabic x  y     is true if x is an integer and y is the arabic numeral for x. arabic numerals are constants of the language. the following sentence says that the robot believes that n is written on the paper  where n is the arabic numeral for john's phone number: 
 1  exists n  and believe robot written 1  n    arabic phone john   	n    
the robot believes that whatever is written on the paper is john's number  that is 
 1  believe robot  a l l . c v *   implie1   w r i t t e    v     equal. phone. john-   v .       
use the dummy constant n to represent the unknown arabic numeral. then the data base for simulation contains the following sentences: 
 1  written n  
 1  a l l   v   	implie1 written v   equal phone john   	v    
applying the rules of a l l elimination and detachment gives 
 1  equal phone john   n  
substitute the arabic numeral for john's phone number for the dummy constant n in the premisses and conclusion of t h i s proof. the result is a valid proof. the premisses of t h i s new proof are the beliefs described in  1  and  1 . i t s conclusion is described by 
1 
 1  e x i s t s   n   and believe  robot  equal  phone  john    n       
	arabic phone john   	n    
this is the b e l i e f the robot wants. this argument shows that the robot can obtain t h i s b e l i e f by applying a l l elimination and detachment to the beliefs described in  1  and  1 . when the robot sees the number written on the paper it w i l l use t h i s proof to infer that that is john's phone number- the example of mary deducing what john's phone number is can be done the same way. in t h i s case the inference rule is substitution of equals rather than detachment. 
       in conclusion  it is possible to use simulation for reasoning about a deduction whose premisses contain constants unknown to the simulator. this technique combines the advantages of creary's technique  one can judge how d i f f i c u l t an inference is  and of moore's technique  unknown constants cause no problem  . a program can use the technique either to plan i t s own future deductions or to anticipate what other agents w i l l deduce from t h e i r b e l i e f s . 
