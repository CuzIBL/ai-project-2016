 
conventional methods used for the interpretation of activation data provided by functional neuroimaging techniques provide useful insights on what the networks of cerebral structures are  and when and how much they activate. however  they do not explain how the activation of these large-scale networks derives from the cerebral information processing mechanisms involved in cognitive functions. at this global level of representation  the human brain can be considered as a dynamic biological system. dynamic bayesian networks seem currently the most promising modeling paradigm. our modeling approach is based on the anatomical connectivity of cerebral regions  the information processing within cerebral areas and the causal influences that connected regions exert on each other. the capabilities of the formalism's current version are illustrated by the modeling of a phonemic categorization process  explaining the different cerebral activations in normal and dyslexic subjects. the simulation data are compared to experimental results  ruff et al  1 . 
1 introduction 
in neurology and neuropsychology  the diagnosis of the neurological causes of cognitive disorders  as well as the understanding and the prediction of the clinical outcomes of focal or degenerative cerebral lesions  necessitate knowing the link between brain and mind  that is what the cerebral substratum of a cognitive or a sensorimotor function is and how the substratum's activity can be interpreted in cognitive terms  i.e. in terms of information processing. 
　studies in humans and animals  bressler  1; demonet et al  1  have shown that sensorimotor or cognitive functions are the offspring of the activity of oriented large-scale networks of anatomically connected cerebral regions  figure 1 . in humans  functional neuroimaging techniques provide activation data  which are indirect measures of the brain's electrical or metabolic activity during a task performance. statistical analyses of the activation data allow determining where  fox and raichle  1   i.e. in which areas  and/or when  giard et al.  1  during the task performance  the activation reaches local extrema. through the study of covariation between local activations  they give a sketch of what the network of cerebral areas involved in the cognitive function is  herbster et al.    1 . a known oriented anatomical link between 1 areas allows determining why the activation of one area can affect the other one  buchel and friston  1 . above methods allow identifying the substratum of a cognitive function and the activation level and dynamics of the substratum during the function performance. they do not give any clue of how the cognitive processes participating in the function are implemented by the substratum and how the activation derives from the processing. that is  they do not allow interpreting neuroimaging data as the result of information processing at the integrated level of large-scale networks. 

figure 1: large-scale network involved in phoneme monitoring  according to results from  demonet  et al.  1  
　interpretative models  linking a networked structure activity to the realization of a function  are at the core of computational neurosciences. most existing works in the domain are based on formal neural networks  with varying levels of biological plausibility  from physiology  wang and buzsaki  1   hardly interpretable in terms of information processing  to more or less biologically 

cognitive modeling 	1 

plausible models of how basic cognitive functions emerge from neuronal activation  grossberg et al  1   and to purely functional models  cohen et al.  1   not concerned with cerebral plausibility. although these models answer the how  they do not meet two major requirements for an interpretative approach of functional neuroimaging data. the models are not explicit enough to be directly used for clinical purpose  and they cannot evolve quickly and easily with new findings in neuroscience  such as the integration of more detailed knowledge on the substratum  which often necessitates a complete rebuilding of the formal network. 
　the causal connectivity approach  pastor et al.   1  aims at answering the how and satisfying the constraints. however  the underlying formalism  causal qualitative networks based on interval calculus  limits severely the biological plausibility of the models  since it cannot represent major cerebral features  such as learning or the non-linearity and the uncertainty of cerebral processes. dynamic bayesian networks only meet the three major constraints: temporal evolution  uncertainty and nonlinearity  labatut and pastor  1 . the utility of graphical probabilistic formalisms for cognitive modeling has also been demonstrated in the representation of visuomotor mechanisms with bayesian networks  ghahramani and wolpert  1 . 
　hereafter  we describe how the interpretation of functional images for a clinical purpose can be tackled. section 1 presents our viewpoint on large-scale cerebral networks. after a short introduction to dynamic bayesian networks  section 1 describes the characteristics of our formalism. section 1 illustrates the formalism's capabilities by an example. we conclude with some perspectives. 
1 representation of large-scale cerebral networks 
1 structural and functional nodes 
the function implemented by a large-scale network depends on three properties: the network's structure 
 goldman-rakic  1   the functional role of each node  e.g. wernicke's area  figure 1   which is supposed to realize the early stages of phoneme processing   and the properties of the links  length  role: inhibitory or excitatory  ... . in each network  regions  which are the stridetural nodes  are information processors and connecting oriented fibers are information transmitters  leiner and leiner  1 . 
　all neurons in a region do not have the same structure or the same role. similar neurons constitute generally local populations that realize a specific function. for example  the inhibitory role of gabaergic neurons on other neuronal populations may explain the fact that every visual stimulus is not perceived in high frequency stimulation  pastor  et al  1 . therefore  each region is itself a network of smaller neuronal populations {functional nodes   connected through neuronal fibers. these nodes are information processors that implement functional primitives  which may all be different. 
　a large-scale network has therefore neurophysiologi-cally constrained  oriented edges and possibly differentiated nodes. the explicit representation of the nodes' function allows the direct expression of hypotheses on cerebral processing  and their easy modification in order to follow the evolution of knowledge in neurosciences. this cannot be dealt with by formal neural networks' implicit modeling that requires modifying the whole network architecture to implement functional changes. hereafter  a structural or a functional structure will be indifferently named a cerebral zone. 
1 information representation and processing 
the cerebral information processed by a neuronal population can be seen as the abstraction of the number and the pattern of the neurons firing for this information. it can be represented both by an energy level and by a category. energy is indirectly represented by the imprecise activation data provided by neuroimaging techniques. the category representation is in agreement with the  topical  organization of the brain  which reflects category maps of the input stimuli  and can persist from primary cortices to nonprimary cortices and subcortical structures  alexander et al  1   through transmission fibers  leiner and leiner  1 . the energy and the category of a stimulus can also be easily extracted from its psychophysical properties. 
　modeling cerebral processes necessitates an explicit and discrete representation of time  both for taking into account the dynamics of cerebral mechanisms  transmission delays  response times...   and for complying with sampled functional neuroimaging data. 
　according to a definition of causality inspired by hume  hume  1  and consistent with pearl's probabilistic causality  pearl  1   information processing in a large-scale network can be considered as mediated through causal mechanisms. causality is defined by three properties: spatial and temporal contiguity  temporal consistency  and statistical regularity  labatut and pastor  1 . in other words  two entities a and b are causally linked if they are contiguous relatively to the system they belong to  if the beginning of a precedes temporally the beginning of b  and if most of the times  a provokes b. in the brain  oriented anatomical links provide spatial and temporal contiguity between cerebral nodes  cerebral events are temporally consistent  a firing zone provokes the activation of downstream zones   and there is a statistical regularity in the response of a specific neuronal population to a given stimulus. 
1 description of the formalism 
1 dynamic bayesian networks 
1 	cognitive modeling in summary  the brain can be viewed as a network whose nodes are differentiated dynamic and adaptive information processors and oriented edges convey causality. moreover  cerebral mechanisms  which are the abstraction  at the level of a neuronal population  of the chemical and electrical mechanisms at the cell levels  are often nonlinear. causal dynamic bayesian networks are the paradigm that meets best the constraints derived from these properties  labatut and pastor  1 . 
　a causal bayesian network consists of a directed acyclic graph where nodes represent random variables and edges represent causal relationships between the variables  pearl  1 . a conditional probability is associated with each relationship between a node and its parents. if the node is a root  the probability distribution is a prior. when some nodes' values are observed  posterior probabilities for the hidden nodes can be computed thanks to inference algorithms such as the junction tree algorithm  jensen  1 . 
　in a dynamic bayesian network  dbn   the evolution of random variables through time is considered. time is seen as a series of intervals called time slices  dean and kanazawa  1 . for each slice  a submodel represents the state of the modeled system. dbns are used to model markovian processes  i.e. processes where a temporally limited knowledge of the past is sufficient to predict the future. the choice of the inference algorithm  generally an extension of the junction tree algorithm  murphy  1   depends on the dbn's structure  the nature of its variables  discrete or continuous   and relationships  linear or nonlinear . 
　activation data and/or the subject's responses to the stimuli are the only observable variables we have. therefore  they must be integrated in our models. one may reasonably consider that the hidden variables  describing the successive states of the cerebral network  constitute a markov chain  and that observable variables depend only on them. moreover  the variables are continuous and their relationships may be nonlinear. this is typically the description of a type of dbns called fully nonlinear state space models. specific and recent algorithms allowing dealing with nonlinearity exist for this type of structures. their general principle is to linearize the model in order to apply the classic kalman filter. these algorithms differ on the used linearization method: first-order taylor approximations for the extended kalman filter  julier and uhlmann  1; norgaard et al  1  or polynomial approximations for the unscented kalman filter  julicr and uhlmann  1   the divided difference filter  ddf   norgaard  et al  1   and others  van der merwe and wan  1 . the algorithms based on polynomial approximations seem to give more reliable results  norgaard  et al.  1 . their computational complexity is 1 l1   where l is the state dimension  van der merwe and wan  1 . they offer equivalent qualities  but those of the ddf are more accurate according to its author  norgaard  et al  1 . 
1 f o r m a l d e f i n i t i o n 
static and dynamic networks 
a static network is the graphical representation of a large-scale network  whose nodes are cerebral zones and edges are the oriented axon bundles connecting zones. due to anatomical loops  it is often cyclic. the dbn is the acyclic temporal expansion of the static network. each node of the dbn is the processing entity related to a cerebral zone  i.e. the mathematical expression  at a given time slice  of information processing in the zone. each edge is the propagation entity  whose orientation is its corresponding axon bundle's orientation. when deriving the dbn from the static network  values are given to the temporal parameters  according to known physiology results  e.g. the transmission speed in some neural fibers . that is  the length of the time slices is fixed  and a 
delay representing the average propagation time in the bundle's fibers is associated to the propagation entity. 
information representation 
cerebral information is the flowing entity that is computed at each spatial  cerebral zone  and temporal  time slice  step  by a processing entity. it is a twodimensioned data. the first part  the magnitude  stands for the cerebral energy needed to process the information in the zone. it is represented by a real random variable in the dbn. for the second part  the type  which represents the cerebral category the zone attributes to the information  the representation is based on the symbol and cate-
gorical field concepts. 
　a symbol represents a  pure   i.e. not blurred with noise or another symbol  category of information. for example  when the information represents a linguistic stimulus  a symbol may refer to a non ambiguous phoneme. for cerebral information  the symbol represents  in each zone  the neuronal subpopulation being sensitive to  i.e. that fires for  the corresponding category. it may be  in the primary auditory cortex  the subpopulation sensitive to a specific frequency interval. a categorical field is a set of symbols describing stimuli of the same semantic class. the  color  categorical field contains all the color symbols  but it cannot contain phonemes. 
　a type concerns several symbols  due to the presence of noise or because of some compound information. let s be the set of all existing symbols. we assume that a type t is defined for only one categorical field. let s1 be the subset of s  corresponding to this categorical field. the type t is an application from st to  1   with 
the property   i.e. it describes a symbol reparti-
tion for a specific categorical field. in a stimulus  this repartition corresponds to the relative importance of each symbol compounding the information carried by the 

stimulus. inside the model  t s  stands for the proportion of s-sensitive neurons in the population that fired for the information whose type is t. unlike the magnitude  the 
cognitive modeling 	1 

type is not represented by a random variable. indeed  it is not necessary to represent its uncertainty  and hence to make the computational complexity harder  since we cannot compare it to neuroimaging data. 
　at time / and node x  the information is represented by the type  and the magnitude  at the output of x. 
propagation and processing 
　for a zone x  both the cerebral propagation mechanisms  i.e. the relationships towards the zone  and the processing  spatial and temporal integration of the inputs  and processing as such  are described by a pair of functions  the type  and the magnitude functions fm . in the general case where n zones  are inputs to x  let  be the corresponding delays of these rela-
tionships. in the dbn  the general form of the magnitude functions is: 
 1  
where can be a nonlinear function. the random variable models uncertainty in the cerebral processing. 
　the type function is any combination of the incoming types and of the previous type that respects our type definition. if all types are defined on the same categorical field 1  the type function can be the linear combination: 

　the functions' definition  as well as the setting of the parameters1 values  e.g. the value of a firing threshold   utilize mostly results in neuropsychology or in neurophysiology. the existence of generic models  that is  non instantiated  reusable  models of functional networks  is assumed. for example  primary cortices may implement the same mechanisms  although they arc parameterized so that they can process different types of stimuli  pastor  et al.  1 . 
1 	example 
the model  presented hereafter  is based on an experimental study  ruff  et al  1  that focused on the differences between normal and dyslexic subjects during a passive phonemic categorization process. 
　six patients and six controls were submitted to a passive hearing of stimuli that are mixes of the two phonetically close syllables /pa/ and /ta/. the pivot is noted devo and the deviants are 1 different mixes of /pa/ and /ta/  noted dev1m  dev1m  dev1p  dev1p  table 1 . the measurements were made with fmri. an experiment is constituted of 1 blocks  corresponding to the pivot and the deviants. each block contains 1 sequences of 1 sounds  1 pivots and the block's deviant  in a random order. 
　we focus on a single region  a part of the right temporal superior gyrus involved in the early processing of auditory stimuli and activated differently in controls and dyslexic subjects. phylogeny is in favor of the existence of specialized phonemic processors in this area  figure 1 . since their location is unknown  they cannot constitute separate structural nodes. they are supposed to have the same building functional nodes. according to our genericity hypothesis  the processors' structure and parameters are based on a previously released visual cortex model  pastor  et al.  1 . the input gating nodes  ign.  express the phoneme processors' sensitivity to the stimulus. the output gating nodes  ogn.  send information to the downstream areas. intra and inter  lateral  inhibitions  /tv. and lin.  are assumed between the /pa/ and /ta/ processors. lin. make the activation of an ign. cause an inhibition in the opposite ign.. each firing threshold node  ftn.  is modulated by an ogn. that can lower it. since only one activation measure is provided by fmri for the area  it is represented by the sole an node in the static model. stim stands for the stimulus. 

figure 1: static network used to model the cerebral phonemic categorization process. 
　except for the parameterization of the ign. nodes  which reflects the specialization of each phonemic processor to the phoneme category  /pa/ or /ta/   the functions for both the /pa/ and /ta/ parts share exactly the same structure and parameters. thus  only the pa part will be presented. in the following equations  the ith parameter of the function of a node x is noted a  1  
　the refractory period of the processor's neurons is modeled in by a sigmoid function that makes the node sensitive to the incoming stimulus only if the magnitude of the output is already close to zero: 

　the categorical field contains two symbols  pa and ta . the type of a stimulus represents the proportions of the 

two symbols  table 1 . 
1 	cognitive modeling 


table 1: constants for both phonemic categorization models 
　the sensitivity of each 1gn. to the received type is defined by a constant type sens.. is more sensitive to the symbol pa  and to ta. the function in 
equation  1  is used with the constant and the incoming stimulus' type in order to modulate the magnitude of 
　the types are used only for the input gating; they do not intervene in the rest of the model. the sigmoid 
in 
　an consists in the sum of the successive igns' activations during one experimental block: 
		 1  
　this is a gross approximation of the fmri data  which models only the part of the information processing mechanisms in the activation building and neglects metabolic processes at the level of the cerebral blood flow. since  except the stim and the an nodes  all nodes represent neuronal activities  the time unit is set to 1 ms. we used the dd1 algorithm  norgaard  ei al.  1  to perform the simulations. 
　the hypothesis is that the difference of processing between normal and dyslexic subjects is caused by a disorder in the inhibitory mechanisms. thus  the two models  one for the average patient and the other for the average control  use the same functions and share the same parameters  except for the inhibition nodes  in. and lin. . there are no lateral inhibitions in the dyslexic model. it can be interpreted in cognitive terms as the fact that all the processors compete for each stimulus and that no clear category can be built. also  the dyslexic model's internal inhibitions are slightly stronger than in the normal one  leading to a slowing in the stimulus perception. these two tentative interpretations are good starting points for new experiments. 
　the differences in the inhibition parameters are sufficient to obtain very different activation data. for controls  the more distant  from the pivotal stimulus  categorically speaking  the deviant is  the stronger the activation is  figure 1 . this is supposed to be caused by a habituation mechanism that lowers the activation  followed by an activation the force of which depends on the  surprise  caused by the deviant. dyslexic subjects do not correctly categorize the different phonemes  both the pa and the ta parts of the gyrus activate for each block. this illustrates how activation data can be explained thanks to the understanding of the cerebral information processing mechanisms expressed in the models. 

figure 1: compared results between simulated data  ＼ 1 standard deviations  and experimental measures. 
1 	conclusion 
instead of building a specialized model  designed for a specific function or cerebral network  we have presented a general framework  allowing the interpretation of functional neuroimaging data. this framework has been designed to be open to evolutions of the knowledge in neuropsychology and neurophysiology. using dbns allows modeling the brain as a dynamic causal probabilistic network with nonlinear relationships. we have illustrated this with an example concerning a language-related process. currently  our framework is adapted to automatic processing  which is dominant in cerebral functioning. in function of the stimulus type  nodes can react differently and different networks may be activated  thus implementing different functions. our future work will focus on the integration of more biological plausibility in the framework. the representation of complex relationships between and inside the zones will allow the representation of controlled processes and contextual modulation of the cerebral activity. the combination of types from different categorical domains and the search for regularities in the combinations will allow the implementation of learning mechanisms. another essential topic is to make our mod-

cognit1ve modeling 	1 

els independent of the used data acquisition technique  thanks to interface models  able to translate cerebral information processing variables into neuroimaging results. our long-term goal is to progressively include in our framework various validated models and to build a consistent and general brain theory based on large-scale networks. 
