 
research on continual computation centers on developing precomputation policies that can effectively harness available resources to solve future challenges. we focus on integrating a consideration of offline and real-time resources in continual computation. we review precomputation policies for flexible procedures and present strategies that account for the expected future real-time refinement of a result following precomputation. finally  we address policies that consider the tradeoff between the efficiency of solving current and potential future challenges. 
1 	introduction 
research on problem solving under bounded resources has focused primarily on real-time reasoning  in contrast  work on continual computation centers on developing methods for harnessing the resources available in periods traditionally viewed as  idle time  between challenges 
 such policies have application to a variety of tasks ranging from generating contingency plans to prefetching web pages and computing ideal observar tions to make next in situation assessment or diagnosis. in this paper  we explore continual-computation policies that take into consideration both idle and real-time resources. the methods center on a consideration of the expected value flux generated by problem-solving strategies. 
　we first present several utility models that describe how strategies generate results of partial value with computation. for background and clarity  we shall review results described previously on ideal continualcomputation policies for these utility models. then we present a new class of precomputation policies by integrating a consideration of future real-time refinement that may follow the identification of a challenge. finally  we examine the case of generalizing the methods to consider issues with trading the efficacy of realtime problem solving for enhanced future responses. 
1 	utility of precomputation 
assume we have access to probabilities  p i e   of seeing different problem instances / in the next period  given some evidence e that has been observed. inferring the likelihood of future instances can range from trivial to difficult depending on the application. we will not focus in this paper on the means for building probabilistic models or collecting statistical data for inferring or accessing the likelihood of problem instances  see  for examples of learning probabilistic models for continual computation and  for a discussion of methods for computing likelihoods of future problem instances . instead  we focus on the derivation of ideal policies that take as input likelihood information of any degree of precision about the occurrence of future problems. we seek to optimise the expected value of a system's response for the case where we have access to one or more flexible algorithms with the ability to generate partial results that have value to a user before a final  precise answer is reached. 
　a flexible or anytime reasoning strategy s has the ability to refine an initial problem instance / or further refine a partial result  that has been previously generated  1  1 . the expected value of computation  evc  is the change in utility with computar tion  1 . evc is computed as follows: 
 1  
where 	represents a refinement of 	and 
represents the object-level value of the ini-
tial or previously refined partial result without consideration of the cost of computation. for the case where cost is deterministic and separable from the value of computation  the net evc  nevc  is 
just 
		 1  
where c{t  represents the cost of delay associated 

1 	uncertainty and probabilistic reasoning 

from real-time computation  and use the phrase expected value of precomputation  evp  to refer to 
the exvccted change in nevc for actions taken to address challenges in a future period. the evp associated with allocating offline resources  t  to refine the result associated with a potential future problem i is 
		 1  
we can characterize flexible computation strategies in terms of the rote at which they deliver future value with precomputation. we refer to the instantaneous rate at which evp changes at point of allocating t seconds of precomputation time to solving problem / with strategy 1  as the evp flux  
 1  
the evp flux is the slope of the curve describing the utility associated with a computed partial result over time. for simplicity  we shall leave out the arguments of evp and use  as shorthand to refer to the expected evp flux associated with the strategy-instance pair after t seconds of precomputation. let us assume for convenience that the selection of a strategy or sequence of strategies s is predefined or optimized for each problem instance  and use s* to refer to these strategies. we shall not dwell in this paper on the problem of choosing ideal strategies; such work has been a focus of research on real-time reasoning under varying and uncertain resources  e.g.  see  . the choice of strategy does not influence the fundamental results on policies for continual computation. 
　assume that we have access to probabilities and performance profiles that provide a measure of the evp flux  for each future problem instance i under consideration. further  assume that a system apportions fractions of the total available idle time  to refining results for several potential future challenges. the overall evp associated with multiple allocations can be computed by integrating the expected flux for resources allocated to each instance and summing together the evp derived from each problem  
		 1  
given uncertainty in the amount of idle time  we have  
		 1  

figure 1: prototypical classes of utility for partial results include  a  smoothly increasing utility with decreasing returns   b  piecewise linear with decreasing returns  and  c  linear utility. 
the goal of an automated reasoner endowed with the ability to reason about evp is to leverage resources that are currently available to strategy-problem instance pairs so as to maximize the overall evp. in the general case  identifying policies for allocating offline resources that yield the maximal future value  evp*  requires a consideration of the details of the probability distribution over idle time  p t   and the application of search or closed-form optimization methods to choose the best set of  we seek precomputation principles  and associated policies  that forego the need for such optimization. 
1 	policies 	for 	prototypical classes of refinement 
we shall review ideal policies for three classes of flexible procedures  defined by the functional form of utility models that describe the incremental value provided as they refine partial results. these classes include algorithms that refine results with constant flux  piecewise linear flux with decreasing returns  and smoothly increasing utility with decreasing returns. the utility models representing the performance profiles of these algorithms are displayed as representative curves in figure 1. 
1 	constant flux 
we first review ideal precomputation policies for the case of procedures that provide constant flux described previously in . 
theorem 1 idle-time partition for linear evp flux. given future problem instances  that may challenge a system in the next period  and an evp flux  for the solution of each instance that is 
	horvitz 	1 

constant with time  the idle-time resource partition policy that maximizes the expected value at the start of the nest period is to apply all resources to the problem with the maximal evp flux. that problem should be refined until a final result is reached  followed by the result with the nest highest product should be analyzed  and to on  until the cessation of idle time or solution of all problems possible in the nest period. 
proof: by definition  the allocation of time to each instance for strategies s applied to problem instances provide constant evp fluxes for each 
instance based on the refinement of a sequence of partial results. the total evp can be rewritten as  
		 1  
fbr any amount of idle time 1  the ideal policy is to apply all resources to the instance with the highest value of  any amount of time re-allocated to another instance would diminish the total evp because it would be multiplied with smaller valued products. 
　when problem instance / associated with the largest product  is solved completely  it is removed from consideration and the same argument is made with the remaining  problems. 
1 	prototypical nonlinear models 
policies for procedures yielding flux described by piecewise linear and smoothly increasing utility models can be viewed as a generalization of the case of constant flux. instead of associating problem instances with constant levels of expected flux  we consider the flux associated with subcomponents of problems  and consider ideal strategies for solving these components. continual computation policies for such models with a focus on the application of prefetching documents are described in . we review the earlier results generalized to the case of real-time reasoning  before moving on to consider new policies that include a consideration of real-time resources. 
theorem 1 idle-time partition for piecewise linear utility with decreasing rate. given problem instances  that may be accessed in the nest period  and evp flux described by  that is piecewise linear and where successive segments have positive slope but progressively smaller flux  the resource partition policy that maximizes the expected value at the start of the nest period is to continue to allocate resources to the linear segment drawn from the set of nest available linear segments of instances that has the maximal expected flux  and to continue to refine the problem associated with that segment  and then 

figure 1: evp analysis for case of piecewise linear utility with decreasing returns   a  consideration of future problems under uncertainty   b  mapping evc to expectation   c  piecing together a continual computation policy considering expected flux of different segments. 
to move to the segment with the next highest expected value flux until all segments of all problems are solved or the cessation of idle time. 
proof: we extend theorem 1 on the ideal allocation of resources for constant flux to each piecewise linear segment associated with the current state of refinement of a problem. we now consider portions of problem solving associated with each segment of the piecewise linear utility function model instead of the entire problem. we know that the instance that offers the maximal instantaneous expected flux will add the most to the overall expected utility and that all other instances will deliver less value now and-by definition of decreasing returns-at all other times in the future. including any other segment in the integration represented by equation 1 would lead to a smaller total evp for any amount of idle time. thus  we need only to check the next available segment for each incompletely solved problem to identify the best sequence of segments. choosing any other segments would lead to a diminishment of the overall expected value at the start of the next period as compared with this policy. 	
　thus  the policy for maximizing the contribution to the expected value in the next period will be to look 

1 	uncertainty and probabilistic reasoning 

at all linear segments of all problems under consideration and to continue to solve the segment associated with the highest flux  then refine the problem associated with the segment with the next highest expected flux. 
　figure 1 summarizes the approach for creating ideal evp policies for the case of piecewise linear and smoothly increasing utility. we transform the fluxes associated with the computing each problem instance into expected fluxes for solving future problems given uncertainty in their occurrence. an ideal policy is identified by continuing to expend all resources to solve the instance that delivers the greatest instantaneous flux. 
1 smoothly increasing utility with decreasing returns 
we can easily generalize theorem 1 to the case of utility models represented as smoothly increasing functions by taking the size of segments in the piecewise linear models to zero in the limit. 
theorem s partition of resources for smoothly decreasing flux. given problem instance-strategy pairs that may need to be addressed in the next period  and a value flux described by for the solution of each instance associated with for the solution of each instance associated  the resource partition policy that maximizes the expected value at the start of the next period is to allocate resources to the problem with the maximal product of probability and instantaneous value flux  until all problems are solved or until the cessation of idle time. 
proof: for situations where the expected flux is monotonically decreasing for all instances  the policy for maximizing the contribution to the expected value in the next period will be to continually pick the problem associated with the highest mean expected flux for any small quantity of expenditure. because each instance has an expected flux that is monotonically decreasing with allocation of resources  the greatest currently available flux must be greater than the future expected flux associated with this or any other instance. thus  any other order of analysis with inflnitesmal amounts of resource will result in a lower overall evp  	  
1 	influence 	of future 	realtime refinement 
the evp policies described above center on an optimization of the expected value of the system at the time a new challenge is received. we now extend the policies to consider real-time computation. we start with a consideration of the prototypical realtime problem of reasoning with a procedure that provides smoothly increasing utility with decreasing returns in the context of cost that increases constantly with time. a graphical representation of this problem is displayed in figure 1. as displayed in the figure  the strategy provides increasing value  but with decreasing marginal returns for the same amount of computation at increasingly greater levels of refinement  until a final result is generated. we refer to this class of real-time reasoning problem as decreasing return  constant cost scenarios. we first identify the ideal quantity of real-time deliberation for these problems. 
theorem 1 ideal deliberation for decreasing returns  constant cost scenarios. for scenarios of decreasing returns and constant cost  action should be token immediately if the net evc flux at the outset of a challenge is nonpositive; otherwise  real-time re-
finement should continue until the evc flux is equal to the cost. 
　a graphical depiction of the ideal halting time is represented in figure 1. an instance is refined into partial results with computation or precomputation time t  eventually reaching the final  completely solved result   the evc flux is equal to the rate at which cost is incurred at the ideal halting  at this time  the algorithm generates an ideal result  
 i . figure 1 shows the tangent to the utility curve at this point of refinement  representing the evc flux at the ideal halting time. as displayed in the figure  the rate at which value is generated is balanced at this point of refinement by the rate at which cost is accrued. continuing to perform real-time computer tion after this level of refinement is achieved would incur costs faster than gains in value. 
　let us now consider evp and continualcomputation policies for problem solving captured by such decreasing returns  constant cost situations. we refer to the partial result generated at the ideal time indicated for halting  for a particular cost function c  strategy s  and instance j  per theorem 1 as the ideal real-time result   i . the ideal real-time re-
sult is insensitive to the amount of resources allocated to precomputation of a problem instance because the rate at which cost is accrued is constant. 
　applying idle-time resources to scenarios of decreasing returns with constant cost can be viewed as a means of achieving cost-free refinement consider the value of precomputation for the case where a system knows that it will face a problem with probability 1. the nevc at the time the ideal real-time result 
	horvitz 	1 


figure 1: graphical analysis of ideal halting time for real-time computation for the case of refining an instance with partial results that show decreasing returns in the context of constant cost. cost is displayed on a negative scale for clarity. 
is computed is simply the expected utility associated with an action in the world associated with  j    less the total cost accrued so far in com-
puting the result. the total cost is simply the product of the rate at which cost is accrued and the amount of real-time resources expended on the problem prior to generating the ideal real-time result. 
　we can now analyze the value of precomputation in light of the prospect of future real-time reasoning to further refine a result. precomputing a result of the quality represented by  i  removes the cost function for the time allocated to precomputing the result. thus  the precomputation adds value to the ultimate utility that will be achieved when the result reaches the level of refinement represented by  i  with a flux equal to the rate at which real-time cost would have been accrued without precomputation. this flux is computed as the product of the probability of the instance and the cost. 
　figure 1 displays graphically the impact of precomputation on the value of the result. the updated reasoning problem is represented by the solid lines portrayed in contrast to the broken lines  representing the situation before precomputation. as displayed in the figure  the cost function only begins to  tug  down on the net value of the result when real-time reasoning begins. precomputation reduces the required real-time computation and raises the ultimate value of the ideal real-time result by the total amount of cost saved. two small vertical arrows in figure 1 represent the source and quantity of the jump in utility achieved with precomputation-
　we now consider the case of continuing to refine the result with precomputation beyond the ideal real-time result. additional precomputation applied to refining a result beyond  i  adds additional value to the 

figure 1: graphical analysis of the influence of precomputation. before the ideal real-time result is generated  a flux equal to the probability of the instance and the cost boosts the utility of the result. additional precomputation boosts the result at the expected flux delivered directly by the strategy. 
ultimate result at the cost-free rate associated with the instantaneous flux provided by the strategy in return for resources allocated beyond those required to achieve the ideal real-time result. figure 1 demonstrates graphically how refining a result with precomputation beyond the ideal real-time result adds value in accordance with the flux delivered by the strategy in these regimes. 
　in summary  we must consider two situations for computing the evp associated with precomputing instances for scenarios of decreasing returns  constant cost: if the level of refinement of a result reached with precomputation is less than the value represented by 
 i   the value flux is the product of the rate at which cost is accrued and the probability of being challenged with the instance. for refinement of a result by precomputation beyond the quality represented by  j   the value flux is the product of the probability of seeing the problem instance and the evc flux associated with the strategy for increasing amounts of precomputation time following the achievement of  j . 
　given our analyses of these two situations  we can develop policies for the general case of multiple problem instances and uncertainty. given a set of potential future problem instances under uncertainty  we can adapt theorem 1 to provide a policy for precomputation that takes into consideration future realtime reasoning. the policies consider all instances under uncertainty  noting for each instance whether the partial result achieved so for with precomputation fells short of the quality of the associated  l . 

1 	uncertainty and probabilistic reasoning 

theorem 1 continual computation policy for decreasing returns  constant cost scenarios. for scenarios characterized by decreasing returns in a constant cost context  it is ideal to allocate offline computational resources to solving instances in order of the product of the probability of the instance and the cost of delay when refinement is below the utility associated with  i  and the product of the instantaneous rate of refinement and the probability of the instance when the value is greater than 
proof: for a constant probability of being challenged by an instance  the evp flux for results of lesser quality than  j  is a constant determined as the product of the probability of the instance and the cost of delay. 
the evp flux for results refined beyond the quality of  is the product of the probability and the instan-
taneous flux provided by precomputation. the evp flux in regimes where quality is higher than 
is smoothly decreasing and is smaller than the flux for refinement up to  drawing upon theorems 1 and 1  the maximal total evp  will be obtained by continuing to select available instances with the highest expected evp flux. given that the evp flux associated with strategies either provide constant or decreasing evp flux with the allocation of precomputation time  any other order will lead to a suboptimal 
evp. 	  
1 redirecting resources to future problems 
so far  we have considered the allocation of available idle time solely for solving future problems. we have assumed that real-time computation is fully dedicated to solving a current challenge until reaching an ideal halting time. we can generalize the continual computation policies by considering the value of allowing real-time resources to be allocated to precomputation of future problems before a current problem is completed. such a generalization considers trading a loss in the quality or timeliness of the response to current challenges for an enhanced expected response to future challenges. such re-allocations can increase the overall expected value of a system's performance. it is worthwhile allocating resources from current to future problems when the evp of potential future problems outweighs the evc associated with solving the current problem. 
　the boost in evp associated with the redirection of real-time problem solving to precomputing the solution of potential future problems depends on the amount of idle time that will be available before the next challenge arrives. if there will be sufficient idle time to precompute a majority of important future problem instances  little may be gained by an immediate transfer of real-time resources to precomputation* thus  we must model the probability distribution over the available idle time  and use this information to compute the expected value of the transfer of resources to the future problems. 
　　let us use evp* r  to refer to the expected value of precomputation derived by following an ideal evp policy  ive.  a policy dictated by the results described earlier   given the availability of t seconds of idle time between the completion of the current problem and the arrival of the next challenge. suppose we are in the process of computing a response to a current challenge. the probability distribution over idle time  p{t e   can be determined from the probability distributions over the computation time required to complete the current analysis and over the time the next problem instance will be faced by the system. assume that we have access to such probabilistic information  based on data collected on the performance of reasoning procedures and on the rates at which different classes of problem instances are faced by an agent in an environment or specific setting. given p t e   we compute the instantaneous change in evp with computation of future challenges for different idle times t and sum over the uncertainty in idle time to generate an expected value flux at different values of idle time  
 1  
where that yields a discount rate  
　in real-time  we consider the instantaneous evc flux associated with current problem solving with the instantaneous expected flux of solving future problems for small amounts of resource. if the current evc flux is greater than the expected flux of solving future problems we continue to solve the current problem with the resource. however  if solving future problems has greater flux  we allocate the resource to computing future problems. we make the myopic assumption at each step that the probability distribution over idle time is determined by the time required to finish the current analysis. thus  at each step of the analysis we consider an estimate of the revised time required for solving the current problem in 1. we can now build an overall evp policy for allocating resources to each problem by considering the flux associated with each problem instance and continuing to choose the instance with the highest instantaneous flux. 
	horvitz 	1 

1 	summary 
we presented continual-computation policies for harnessing idle resources to enhance the future expected value of computation. we reviewed policies for several classes of refinement and developed an analysis and associated policy for folding in a consideration of additional refinement with future real-time resources. finally  we described an approach to making decisions about redirecting resources being used solve a current challenge so as to precompute responses to potential future problems. 
　we are pursuing extensions to this work in several areas. opportunities for ongoing research in continual computation include folding into the analyses a consideration of multiple periods in the future  reasoning about the explicit handling of sequences of challenges  and taking into consideration risk preference for handling uncertainty about the probability of future challenges. 
acknowledgments 
jack breese  carl kadie  jed lengyel  chris meek  natalia moore  and mark peot provided useful feedback on this work. 
