 
we suggest a new approach for the study of the non monotonicity of human commonsense reasoning the two main premises that underlie this work are that commonsense reasoning is an inductive phe nomenon and that missing information in the in icraclion of the agent with lhe environment may be as informative for future interactions as observed information this intuition is lormahzed and the problem of reasoning from incomplete information is presented as a problem ol learning attribute func lions over a generalized domain we consider examples that illustrate various aspects of the non monotonicreasoning phenomena which have been used over the years as bench marks for various formalisms and translate them into learn ing to reason problems we demonstrate that these have concise representations over the generalized domain and prove that these representations lan be learned efficiently 
the framework developed suggests an operational approach to studying reasoning that is ne  ertheless rigorous and amenable to analysis we show that this approach efficiently supports reasoning with incomplete information and at the same lime matches our expectations of plausible patterns of reasoning in cases where other theories do not this work continues previous works in the learn ing to reason framework and supports the thesis that in order to develop a computational account for commonsense reasoning one should study the phenomena of learning and reasoning together 
1 	introduction 
any theory aiming at understanding commensence reason ing the process that humans use to cope with the mundane but complex aspects of the world in evaluating everyday situa lions should account for lhe flexibility adaptability and speed of commonsense reasoning 
   the major approach in ai to this problem is within the framework of the knowledge based systems it is assumed that the knowledge is given to the system  stored in some 
research supported by nsf grant ccr 1 and by 
darpa afosr f1 j 1 
1 	learning 
representation language with a well defined meaning and that there is some reasoning mechanism used to determine what can be inferred from the sentences in the knowledge base earlier formalisms in this framework have abstracted the reasoning lask as a deduction task of determining whether a sentence assumed to capture the situational hand is implied from the knowledge base captunngour theory of theworld this abstraction has been criticised by many  e g  minsky 1   on the ground that it cannot support non monotonic reasoning 
   it is widely acknowledged toda  that a large part of our everyday reasoning involves arriving at conclusions that are nol logically entailed by our theory of the world many conclusions are derived in the absence of sufficient infor mation to deduce ihem this type of reasoning is naturally nonmonotonic since further evidence may torce us to retract the conclusions in light of this many researchers work ing within the abo e framework have tned to augment the knowledge base and lo modify the inference mechanisms so as to allow reasoning in lhe presence of incomplete infor mation the idea is lo augmeni the true knowledge  facts and rules  we have about the world with a set of assump lions that capture only typical cases these assumptions are called default assumptions or simply defaults within the knowledge-based sysiems approach defaults are slored in the knowledge base along with the other non-default knowl edge the quest is for a reasoning system that given a query responds in a way lhat agrees with what we know about the world and some subset of the default assumptions and al the same lime supports our intuition about a plausible umdu sion the process of reasoning with the knowledge and the defaults is called default reasoning and numerous formalisms that attempt al acceptable reasoning behavior have been stud led for it  eg  al 1 touretzky 1 reiler 1 ethenngton 1 goldszmidt and pearl 1 pearl 1 gcffner 1   
   computational considerations however render all the for malisms suggested within the knowledge based systems approach apparently inadequate for commonsense reasoning this is true not only for the lask of deduction but also for many otherforms of reasoning which have been developed  selman 1 roth 1  of particular interest in this context are the hardness results on default reasoning tasks  selman 1 papadimitiou 1  where the increase in complexity  rela live to corresponding deduction tasks  is clearly at odds wilh the intuition lhat reasoning with defaults should somehow re 

duce the complexity of reasoning moreover many studies in this framework have shown that capturing what people view as plausible patterns of reasoning is not easy  e g  toureljvyetal 1   most formalisms in attempting to capture some aspects of * default reasoning give up on others multi pie levels of specificity of information irrelevant information and conflicting defaults are among the aspects that the various formalisms have found difficult to reconcile 
　in  khardon and roth  1b  a new framework for the study of reasoning is introduced the framework incorporates a role for inductive learning within efficient reasoning and ex hibits the importance of studying the learning and reasoning phenomena together the learning  in order  to reason ap proach combines the interfaces to the world used by known learning models with the reasoning task and a performance on tenon suitable for it in this framework the intelligent agent is  given access lo her favorite learning interface and is also given a grace period in which she can interact with this interlace and construct her representation ot the world her performance is measured in a way that makes explicit the dependence of the reasoning performance on the input from the environment in this framework it is shown that through interaction with the world the agent truly gains additional reasoning power over what is possible in the traditional setting in particular rea soning problems that areprovably intractable in the traditional approach are given efficient learning lo reason algorithms 
　previous works in the learning lo reason framework   khardon and roth  1b 1b  have considered reasoning tasks whose functionality is well defined this paper on the other hand considers tasks in which in many cases there is no agreement on what constitutes a plausible outcome 
　the disagreement we believe is justified we argue here that commonsense reasoning and in particular reasoning in the presence of incomplete information is an inductive phe nomenon when the notion of consistency is al the heart of the formal reasoning system as in most previous approaches inductive phenomena are difficult lo capture 
　in this paper we extend the learning to reason framework lo deal explicitly with reasoning in the presence ot incomplete information inspired by the pac learning approach  valiant 1  we present the view that the world is very complicated and there is no hope ot acquiring an exact representation ot it our aim should be lo acquire enough information with which to cope effectively in the world in doing so we extract certain regularities from the world and assume that in similar circumstances we can rely on these 
　consider for example concluding from the knowledge that tweety is a bird thai tweety can fly this conclusion is use ful and is clearly justified in some situations eg when discussing birds in boston dunng their migralion season a different conclusion will be suggested though by a veiennar lan working in a birds hospital or by someone raised in an ostnch nature reserve of course  the possible circumstances in which any presumed correct line of reasoning can be de fealed astound and we are doomed to make mistakes when our expenence does not support the curreni situation 
　the key to the approach we develop is the view that regular ities occur not only in what we observe  e g if all elephants we have seen had a trunk we might think that all elephants have a trunk  bul also in whal we do not observe  e g if in previous experience of flying birds we were not aware of their color when observing a red bird we would predict that it flies  that is missing information in the interaction of the agent and her environment may be as informative as observed information in this paper we formalize this intuition and use it to develop a theory ihat supports efficient reasoning with incomplele information 
   our treatment of incomplele information follows a sugges tion made in  valiant 1b  while there in an effort lo formalize the notion of rationality a comprehensive view of the phenomena that compnse cognition is presenled here we presenl a more detailed account of reasoning in the pres ence of incomplete information focusing on presenting it as a problem of learning to reason 
　unlike previous theones of reasoning in the presence of incomplete information we are not interested in providing a 
　theory of defaults but rather a theory of inference we show that the representation developed here provides a richer lan guage for dealing with reasoning problems and consequently many default reasoning scenarios with which previous for malisms have struggled  have concise representations in our framework moreover these representations con be learned 
efficiently from interaction wilh the environment to yield of licienl learning lo reason algorithms 
　later in the paper we discuss the relation of this work lo lhc default reasoning literature now wc briefly mention some works thai are related lo lhc approach presented here in  khardon and roth 1b  a learning lo reason approach that can deal with partial information is developed and shown to support efficient deduction the interpretation taken there however is not expressive enough to support non monolonic reasoning; in ikhardon and roth 1a  a solution lo some restricted cases of the traditional default reasoning problem is suggested using learnable model based representations the approach presenled in  sehuurmans and greiner 1  is closest lo ours in that they study the problem ol learning default rules the reasoning stage however is nol consid 
cred and presumably is performed by a traditional reasoner and is thus intractable 
　after presenting the framework we illustrate in section 1 how various problems in reasoning with defaults are dealt with in our approach in section 1 we discuss some of the learning issues this framework raises and some extensions of the work presenled here wc conclude by discussing lhc results and some theoretical and empirical questions our approach raises 
1 	the framework 
we consider a set   = {r1 rn  of variables each ol which is associated with a world s attribute and can lake the values i or 1 lo indicate whether ihe associated attribute is true or false in the world an agent intends with the world through a se of d observed attributes i -  j   - 'v  -r  = v    j    = i.d   wc use x  to denote attributes u  lo 
denote the corresponding values and v to denote a vector in  1  i * }     many of ihe unobserved attributes mighl not be known1 to the agent and the assignment lo those and lo known attributes that are unobserved is denoted by the special svmbol * in this wav observations arc vectors in {1 *}  bul we write ihem by only specifying the observed variables the world w imposes some distribution d over 
1  e g the altnhuie ha;. broken wing need nol be known 
	roth 	1 

fj 
and 
1 	learning 

world knowledge and some subset of the default assumptions and at the same lime support our intuition about a plausible conclusion 
attempts to represent and reason with defaults have en 
lountered many problems  e g  neufeld  1 poole 1  geffner 1   in many cases  reasoning with accept able defaults lead to unacceptable conclusions problems occur whenever defaults interact and can be characterized fre quently as problems of distinguishing good defaults from bad ones but reasons for deciding between good and 
bad defaults vary and in most cases depend on the situ ation no general method exists according lo which one can rank defaults  geffner  1  the only way to fig ure out why and when certain defaults are preferred lo others is to understand what the defaults say about the world while probabilistic and statistical approaches  geffner 1 bacchus et al 1  present an important step in this direc lion they still suffer from some of the same problems  geftner 1  and are infeasible computationally 
   the approach developed here does not use defaults raiher it is a theory of inference ii reasons from a knowledge rcprc sentation into which the incompleteness is compiled via a learning process as we show later in section 1 i there is no direct mapping between the way default reasoning problems have been traditionally defined and our framework in order to exhibit the advantages of our approach we translate default reasoning problems into learning to reason problems given a default reasoning problem  i c true world knowledge and a set of defaull assumptions  we suggest a scenario of interac tions wilh the world that reflects the type of observations that could have led to this view of the world these observations are used to learn an attribute function representation of the world o v  e n given t query we argue that this representation yields the sought after response the fol lowing convention is used in presenting the dctaull reasoning examples the traditional representation is given as a set of knowledgebase rules and a set of default rules  as usual penguin x  -  bird x  means lhat if x is a penguin then x is a bird   for each problem we presenlaset of observations about the world the observations are elements in hul wc present only a subset of the observed attributes which is of interest lo the current example as usual all the unobserved attributes are assigned * 
   all the examples discussed below have been studied before in the literature the examples or versions of them represent various aspects of ihe non monolonic reasoning phenomena that have been used over the years as benchmarks for various formalisms we do not know of any traditional formalism that can handle in a satisfying way  efficiently or even qualitatively  all the aspects presented by those examples we note though that our first exam ple is a variant of an example considered in  valiant 1a  and that all the examples wc consider here could be con sidered also in the rationality framework and be imple mented in principle on the neuroidal model  valiant 1b 1a  a  partial  list of papers that have discussed  d subset of  these examples includes  bacchus et al 1 ethenng ion  1  geffner  1 reiler 1 reiler and g 1 selman 1 touretzky el al 1  
example 1  basic example  consider the case in which we know lhat penguins are birds penguins do not fly and we have the default assumption birds fly this  s expressed as the set of facts kb = {penguin x  bird x   penguin x' fly x } and the default statement =  bird x  -  fly x   given this it is reasonable to assume that in all observations ne made so far of the world whenever we saw an observation m which the penguin attribute was on  set to 1  the bird attribute was 1 as well and the fly attribute was set to 1 moreover we have seen observations in which bird has i and fly w-as i in those observations penguin was never 1 that is a plausible sequence of observations could be 
 bird = 1 penguin = 1  fly - 1   bird= l.fly = 1  
 bird = 1 fly = 1 red = 1  
 bird= 1 fly = 1  red = 1  
 bird = 1 penguin - 1  fly = 1  has.beak = 1   bird = l fly = l has beak = 1  
　 bird = i penguin = 1  fly = 1 has.beak = 1  given these observations the attribute function an agent would keep for fly is /fly =  bird = i   penguin = 1 or *    has beak = i or *  consider non a query' re gardings  tweety rq  bird = 1  flv -    in this case all we know is that tweety is a bird  lhat is in this observation the only observed attribute is bird  and evaluating ffly yields the 
prediction fly = 1 
along with seeing many observations similar to the above the agent could have also seen a small number of observations like  bird = i fly = 1 the framework supports this even though a deterministic representation is used for the attribute functions these cases are viewed as classification noise where the value supplied by  for the function ffly is false therefore in this model the algorithms used to learn atribute functions should tolerate classification noise since in section 1 we show lhat this is indeed ihe case we will not incorporate misclassified observations in the next examples 
example1  specificity  consider the observations dis cussed in example 1 and assume a que rv about the penguin tweety 'q  bird= 1  penguin = i  fly = '  in this case evaluating ffly yields the prediction fly = 1 that is we conclude that tweety does not fly even though tweety is a bird and birds  when no other more specific information is known  fly 
example 1  irrelevance-i  consider the observations dis cussed above and assume a query about the red bird tweety 1 q  bird= 1 red = 1  fly=1  clearly the observations show that ihe attnbuie red ts irrelevant to the function ffly and evaluating it therefore yields the prediction fly tweeiy  - 1 
　of course an agent active in a green birds nature reserve might be trained on a different set of observations consist ing of  almost  only green birds consequently  he might believe that greenhood' is a necessary property of flying birds thatis she might have ffly =  bird = 1   green = 1  as the attribute function for fly there is no contradiction here these are exactly the type of reasoning patterns the sought after theory should possess 
example 1  irrelevance-ii  consider the observations dis cussed above and a query about the penguin tweety 
     1 those observations cannot be the majority of the observations seen since still when all we know about tweety is that it is a bird we think it flies 
	roth 	1 

rq  bird = 1  penguin = 1   has beak =   here prediction is done b  evaluating /has beak note thai there is no relation between the attribute functions fhas beak and ffly these are acquired in parallel and the fact that penguins have special properties with respect to flying does not mean they need to have exceptional properties with respect to having a beak clearly the observations lead to fhas beak =  bird = 1  and evaluating it yields has beak = 1 
　we note that while the conclusion above is very intuitive it is not supported by many treatment v of default reasoning  e g  kraus et a  1  which encounter difficulties in trying to support both specificity and irrelevance 
example 1  multiple extensions  consider the set of facts 
kb = {bal x  -  mammal x } and default statements a = 
{mammal x  -＊ fly x  bal x  -  fly x  dead x  - fly x } given that it is reasonable to assume that the observations made of the world had the following properties in observa tions with a bat attribute set to 1 the mammal attribute was 1 as well we have observed bais that fly but also mammals that do not fly in the latter case bat was not 1 also we have not seen dead things fly therefore a plausible set of observations could be 
 mammal =1 bat - 1 fly = 1  
 bat= l fly= 1  
 mammal = 1  fly = 1  
 mammal =1 bat = 1  fly = 1 red = 1  
 dead = 1  
 mammal =1 bat = 1  dead = 1  
 bat = 1 dead = 1  
 bat = l dead= i  fly = 1} 
her  the attribute function an agent would keep for fly1 is fay =  bat = 1  a  dead = 1 or +  con sider now a query regarding dracula presented as rq  bat = i dead = 1  fly -   clearly evaluating ffly on this observation yields the prediction fly dracula  - 1 in case all we know is that dmcula is a bat and we do not know that it is dead  that is dead=*  the query is rq bal = 1 fly =1  and evaluating ffly melds the prediction fly  dracula  - 1 
as before there is no contradiction here  these are exactly the type of reasoning patterns the sought after theory should pos sess the traditional treatment runs in this case into problems of conflicting defaults for example one has to decide which of the default rules  bat x  - ＊ fly i  or dead r  -  fly i  to apply in order to predict the value of fly dracula  
example 1  preferences  assume the default statements are given by a = {student x  -＊＊ employed x   adull x  - employed x   student x  -* adull x   andtheset of facts is empty these defaults were written in this way to reflect a situation in which the agent observes the following 
properties m observations in which the student attribute was set to 1 the employed attribute was not set to 1 in observations in which the student attribute was set to 1 the adult attribute was not set to 1 in observations in which the adull attribute was set to i the employed attribute was not set to 1 unless some other information is given the following observations could have been seen by the agent 
 student = 1 employed = 1  
　　1 wc could disjunct h with the function from example 1 but will assume for clarity thai those are different agents 
1 	learning 
 student = 1  adult = 1  
 employed = 1 adult = 1  
 student = 1 employed = 1  adult = 1  
　 student = 1  employed = 1 adull = 1  given these observations the attribute function an agent would keep for employed is femployed =  adult = 1  a  student = 1 or *  on the other hand these observations do not give us enough information to support prediction of the attribute adult in a simple way  see below  
　many othier problems can be handled in a natural wav just as the problems considered above in particular this approach suggests a natural solution to the frame problem which is concerned with how to indicate which aspects of  he world do not change when an action takes place  ml carthy and hayes  1  while the standard non monotonic reasoning formalisms do not capture the desirable behavior that things stay as they are  hanks and mcdermott  1  our representation of incomplete information does so  roth 
1  
　what is most striking about these examples is not only the fact that these examples with which various default reason ing formalisms struggle have a unified representation in our framework but even more so 
observation 1 /n all the cases presented above the attribute function for the attribute of interest can be represented as a conjunction over  1 l *  n 
it is an empirical question whether there are naturally arising reasoning problems in which the sought after aunbute cannol be represented as a simple function over {1  1  * n it is ex peeled for example that in situations traditionally presented by a large set of interacting defaults the resulting attribute function might be more complicated however even in this case reasoning reduces to function evaluation and is thus computationally easy in section 1 we show that we can actu ally learn to reason with function classes which are far more expressive than is needed in the examples discussed above 
1 	relations to other formalisms 
there is no direct mapping between our treatment of in complete information and traditional formalisms for default reasoning as an example consider the case of preferred interpretations  mccarthy 1 selman and kautz 1 papadimitriou 1 there a theory o and a set a of dc faults are given the theory delines a set of possible models and the default rules define a preference relation  a partial order  on those once a preferred model is found  inference is done by evaluating queries in this model while this for malism leads to some intriguing mathematical problems  we argue iat one need not solve those in order to reason in a way that agrees with the incomplete default information 
　consider example 1 there no minimal model exists that can capture the intuitive inference with respect to all the at tributes given the observations the attribute function for employed is /employed =  adult = l a sludent = 1 or *  these observations however  do not support a conjunction as an al tribute function for adull but rather the following dnf-hke function /oduii =   employed = 1  a  student = oor *   v   employed - oor +  a  student = 1   therefore in this case using a single model in {1  1}  to characterize the sit uation  does not support the ' intuitive conclusion  while 

making the problem harder computationally   instead our approach uses the available data to learn the situations in which a specific attribute is on this can always he done and the only question remains is how complex is the representation and whether it can be learned efficiently 
1 learning to reason 
reasoning with respect to an attribute tj is reduced in this framework to evaluating the attribute function f1 on a lolal vector in  assume that our attribute functions are in a class t of boolean functions over  if we have efficient learning  to classify  algorithms for t that can tolerate classification noise we can learn to reason with f 
　it turns out that many of the existing learning algorithms for boolean functions studied in computational learning the ory  see a survey in  blum et al 1   can be extended to learning algorithms over since in all the examples considered in section 1 we used the oracle  only we start by considering learning from examples only 
　we extend the standard elimination algorithm for learning conjunctions lvahanl 1 lo work over  in this 
case the values assigned to the variables arc non empt  sub sets ol  1 *} rather than of {1  i} as is usually the case in the usual elimination algorithm the convention is that when a variable x  is allowed lo have any value in  1} we omit it 
from the conjunctive representation we use the same conven lion here moreover wc use this convention tor variables that have never been observed in order for variables that have not been observed yet  i e never appeared as 1 or 1  not lo appear in the conjunctive representation the algorithm uses ihc first positive example to initialize its hypothesis from then on it  1  adds lo the conjunction only newly observed allnbules and  1  uses elimination over the set of known attributes it can be shown that this procedure provides a mistake bound andtherefore a pac algorithm for boolean conjunctions over 
　using the techniques introduced in  kushilevits and roch 1  we can show how to learn kdnf and kcnf formulae over  for any fixed k moreover these algorithm are shown to tolerate noise and thus can be used to construct l1r algorithms to summarize  see  roth 1  
theorem 1 let f be the class of conjunctions disjunctions kcnf and kdnf formulae over  then there ex 
ists an efficient and noise tolerant pac l1r  mb l1r resp   algorithm for the rasoning problem rq f  that uses the example oracle e  d  rqd{fj  resp   
　a richer class of functions can be learned when given ac cess to membership queries in addition lo examples   angluin 1 blum et al 1 bshouly 1  many of these algo nlhms can be extended lo work over {1 * }   in particular using the algorithms studied in ibshouiy 1  we have 
theorem 1 there exists an efficient pac l1r algorithm that uses rqd fj  and mq fj  for the reasoning problem rq f  where 
 i  f is the class of decision trees oxer {1  1 *    
 n f 	is the class of log ncnf n dnf over {1 *}  
　we have discussed a knowledge representation that con sists of a collection of attribute functions 	using our interpretation of incomplete information it can be shown  roth  1  that other representations can support the reasoning behavior demonstrated in this paper consequently different learning questions may arise the reasoning algorithms might be more complicated and one can also pose more general queries1 in particular il can be shown that the algorithms used in  khardon and roth 1b  lo learn model based rep 
resentation can be extended to work over {1 *}n together with the incomplete information mlcrprelation suggested here this yields the sought after non-monotonic behavior 
1 discussion 
we have presented a new approach lo the problem of reasoning with incomplete information the main premises of our approach are that  i  it views reasoning as an inductive phenomenon by interaction with the environment the intelligent agent inductively learns a representation of the world and uses it lo respond lo queries the perlormance on the reasoning task is measured in a way that makes explicit the dependence of the reasoning performance on the input from the world  1  missing information in the interaction of the igent with the environment is taken lo be as informative as 
observed information 
　wc have formulated the problem of reasoning with incomplete lnlormaiion as a problem of learning attribute functions over the domain  1  i  *}  this formulation can tolerate observations that arc inconsistent these are handled as noisy input lo the learning algorithm moreover multiple levels of specificity of information irrelevant information and con flicting observations are handled in a natural way lo yield conclusions thai malch our inluihon these issues determine the complexity of the attribute function representation but  efficient and noise tolcranl learning algorithms exisl even for function classes over {   1 *}  that arc far more expressive than was required in the bench marks examples considered 
　we view the large body of research on defeasible theories of reasoning as an attempt lo characterize the type of defeasible reasoning people do while there is today some understand ing of human like patterns of reasoning we believe that no definition can be given for the type of behavior expected 
given an abstract representation of partial knowledge as a starting point the learning lo reason framework suggests an operational approach to studying reasoning that is never theless rigorous and amenable lo analysis as we have argued here it can be shown to malch our expectations in cases in which the reasoning problem is well dehned 
　this work suggests several areas in which further theoreti cal study is needed as well as some interesting questions for empirical study studying other forms of interaction in the learning process extending the framework lo a probabilistic domain and efficient learning in the presence of irrelevant attribules are some of the theoretical questions whose study will help develop and substantiate the claims made here 
　as mentioned before determining how complex the at tribute functions in naturally arising reasoning problems are and whether those can indeed be represented as sjmple functions over {1  1  *   n   is an important empirical question per 
　　1  more general quenes are queries with respect to more than a single attribute notice however that the reasoning tasks considered in most of the default reasoning literature are prediction tasks quenes with respect to a single attribute as we do here 
	roth 	1 

haps the major difference between the knowledge-based sys tern approach to reasoning and the learning to reason ap proach is that our approach suggests that in order to make theories of reasoning work m practice we need to train them over a large number of examples therefore  finding good and large tesl beds on which to validate this theory is one of the most important next steps 
