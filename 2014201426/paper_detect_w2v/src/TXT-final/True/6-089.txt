 
this paper presents a novel  promising approach that allows greedy decision tree induction algorithms to handle problematic functions such as parity functions. lookahead is the standard approach to addressing difficult functions for greedy decision tree learners. nevertheless  this approach is limited to very small problematic functions or subfunctions  1 or 1 variables   because the time complexity grows more than exponentially with the depth of lookahead. in contrast  the approach presented in this paper carries only a constant run-time penalty. experiments indicate that the approach is effective with only modest amounts of data for problematic functions or subfunctions of up to six or seven variables  where the examples themselves may contain numerous other  irrelevant  variables as well. 
	introduction 
algorithms for the top-down induction of decision trees 
 tdidt  are among the most widely used algorithms for machine learning  data mining and statistical classification. tdidt implementations such as id1  quinlan  1   c1  quinlan  1   c1  www.rulequest.com  and cart ibreiman et al  1  are easy to use and  often  produce human-comprehensible models. nevertheless  tdidt algorithms are well-known to be myopic because of their greedy strategy for choosing split variables  or internal node labels. this myopia is at its worst when the data are labeled according to parity functions such as exclusive-or  1-bit odd parity  denoted by  c  . these and related other problematic functions naturally arise in real-world data. for example  in fruitfly experiments  flies that are either male and have an active sxl gene or that are female and have an inactive sxl gene survive  while other flies die; hence survival is an exclusive-or function of gender and sxl activity  table 1 . 
　of course  parity and parity-like functions are also problematic for other machine learning or statistical algorithms that employ  explicitly or implicitly  a linear assumption in order to gain efficiency. such models include perceptrons  logistic regression  linear support vector machines  fischer's linear discriminant and naive bayes. they also include any of university of wisconsin 
madison  wisconsin 1 

table 1: truth table for drosophila  fruitfly  survival based on gender and sxl gene activity. 
a variety of data analysis approaches that employ an information gain or kullback-leibler divergence filter to do variable selection or to control computation time  for example as in the sparse candidate algorithm for learning baycsian networks i friedman et al  1 . the inability of such approaches to learn functions like 1 is frequently noted  for example  in the context of analyzing gene expression microarray data ifriedman etai  1; szallasi  1 . 
　in tdidt algorithms  the myopia of the search can be reduced at the cost of increased computation time. the standard approach is through depth-fc lookahead  norton  1   where the default for tdidt algorithms is depth-1 lookahead. however  the time to perform a split grows exponentially with a:  and problematic functions remain no matter how large a a: is chosen. 
　the purpose of this paper is to introduce an alternative approach to problematic functions such as parity  which does not incur the high computational cost of lookahead. the approach relies on the observation that these functions are not actually problematic if the distribution over the data is significantly different from uniform. in such cases other functions may become problematic for tdidt algorithms  but functions such as exclusive-or become relatively easy. hence we first observe that tdidt algorithm performance on a data set can be improved if the algorithm has access to a second  significantly different distribution over the data. of course such a second distribution often is unavailable. therefore  we next show how the second distribution often can be simulated by skewing the data from the first distribution. we note that the present paper focuses entirely on classification  ignoring regression trees  or trees that predict continuous outputs at their leaves. furthermore  we limit our entire discussion to tdidt algorithms that perform only binary splits  although the data may use variables that can take more than two values. 

learning 	1 

table 1: for subfunctions at each of  and as for / itself. hence 

nonzero gain according to both entropy and gini. 
1 	review of lookahead for hard functions 
we assume the reader is familiar with the approach of tdidt algorithms. the assumed familiarity includes a knowledge of the commonly-used functions to measure node purity  such as entropy  quinlan  1  or gini index ibreiman et al  1 . it also includes familiarity with the greedy heuristic of choosing to split on the variable that maximizes the improvement  or gain  in the node purity score. we now review the notions of problematic functions and lookahead. for ease of discussion  this section limits itself to two-class problems  where the classes are positive and negative. 
　for the various node purity functions employed by different tdidt algorithms  splitting on a variable  can yield a non-zero gain only if the class distribution changes for at least one of the values  or ranges  that  can take. if the distribution of classes is the same for every value of xt  or range  then x% will have zero gain according to any node purity measure in common usage. as an example  in table 1 the variable x  has non-zero gain according to either gini or entropy  whereas the variables and have zero gain. 
　consider a data set drawn from a uniform distribution over binary-valued variables labeled according to the target function even if we are fortunate enough to have a complete data set-one occurrence of each truth assignment over -it is clear that for every variable z;  the class distribution is exactly the same whether xi is 1 or 1. so  regardless of how large a uniform sample we choose to draw  a variable will have non-zero gain only because of chance. thus  the probability that one of the correct variables  x1 or x'ioo  will have a higher gain than every one of the incorrect variables is extremely low. hence the learning task is virtually impossible for a tdidt algorithm. 
　with depth-1 lookahead the preceding task becomes trivial. a depth-1 lookahead from a given node chooses not only the next split variable  but also the split variables at the next level. a tdidt algorithm augmented in this way will consider among the possible depth-1 trees the two shown in figure 1  each of which will have the maximum possible gain. for any reasonably large data set  with high probability all other depth-1 trees will have gain only marginally different from zero. hence we see that with depth-1 lookahead   c  becomes easy. because depth-1 lookahead is repeated at every step in tree construction  many other functions that have 1variable 1 as a subfunction become easy. 
　of course  depth-1 lookahead comes with a price. where n is the number of variables and m is the number of examples  the time to choose the split goes from   be-

table 1: six of the 1 functions over three variables that are problematic even using depth-1 lookahead. the other six problematic functions are the inverses of these. 
cause labels have to be selected for three nodes from among n variables. furthermore  there are many functions that require a higher lookahead. for example  suppose we have examples constructed from variables and the target is one of the functions in table 1 involving and . even with depth-1 lookahead  tdidt is highly likely to choose incorrect variables. these problems can be solved with depth-1 lookahead  but the time to choose a split becomes and other problematic targets remain even then.1 
1 	motivation for skewing 
consider the first target function discussed in the previous section    but now suppose the data are distributed differently from uniform. for example  we might introduce dependencies not present in the uniform distribution: for every odd number  if x{ is 1 then  has probability 1 of being 1. or we might suppose all variables are independent as in the uniform distribution  but every variable has probability only of taking the value 1. in either case  with a large enough sample we expect that the class distribution among examples with  will differ significantly from the class distribution among examples with  
　to examine the preceding claim more closely  consider the second distribution  where each variable has probability  of being 1. if we draw a sample of 1 examples  we expect roughly 1 of these to have  and roughly 1 to 

   'we can reduce this super-exponential growth of lookahead to  mere  exponential growth and still address parity-like functions if we require the tree to be  leveled -all nodes at a level are labeled by the same variable. but even this non-standard lookahead procedure imposes a high computational burden. 
learning 

have = 1. of the 1 with we expect roughly of these  or 1  to have and hence to belong to 
the positive class. of the 1 with: we expect only  of these  or 1 again  to belong to the positive class  to have 
. hence the fraction of positive examples is quite different for the two values of of the examples with 
 = 1 are positive  while of the examples with = 1 are positive. as a result  and will have non-zero gain; for instance  information gain is roughly 1  out of maximum 1 possible  and gini gain is roughly 1  out of maximum 1 possible . on the other hand  every variable other than  is likely to have nearly zero gain. hence unless a highly unlikely sample is drawn  a tdidt algorithm will choose to split on either  at which point the remainder of the learning task is trivial. 
　notice that in the preceding discussion  moving to our second distribution changed the marginal distribution for every variable  not just for those in the target. it would have revealed the correct variables if the target function had been  or even one of the problematic functions of three variables in table 1. notice also that the important aspect of the second distribution was that it changed the frequency distributions for the variables; the specific change for any variable could have gone the other way-to probability | of taking value 1-and the second distribution still would have given non-zero gain to exactly the variables in the target. 
　from the preceding discussion we conclude that if we have access to two distributions that are  different enough   then choosing good variables to split on becomes relatively easy. however  in real-world problems we rarely have access to two different distributions over the data  or the ability to request data according to a second distribution that we choose. instead  the next section discusses how in practice we can simulate a second distribution different from the first. we call this procedure skewing. the simulation approach tends to magnify idiosyncrasies in the data set  for example  introducing some dependencies that were not present in the original distribution. nevertheless  our experiments indicate that  if the data set is large enough  the magnification of idiosyncrasies is not a major problem. 
1 skewing algorithm 
the desired effect of the skewing procedure is that the skewed data set should exhibit significantly different frequencies from the original data set. because we cannot draw new examples  we change the frequency distributions for variables by attaching various weights to the existing examples. the procedure initializes the weight of every example to 1. we next present the details of the re-weighting procedure for binary-valued variables only. nominal variables can be converted to binary variables. we discuss extensions to continuous variables in section 1. 
　we may assume that every variable takes the value 1 in at least one example and takes the value 1 in at least one example-otherwise  the variable carries no information and 
can be removed. for each variable  we randomly  uniformly  independently for each variable  select a  favored setting   of either 1 or 1. we then increase the weight of each example in which xi takes the value   by multiplying the weight by a constant; for the sake of illustration  suppose we double the weight. 
　at the end of this process  each example has a weight between 1 and . it is likely that each variable has a significantly different weighted frequency distribution than previously  as desired. but this is not guaranteed. for example  suppose the original data set consists of 1 truth assignments over variables and . suppose further that in half of these examples = 1 and = 1  and in the other half l = i and = 1. if the favored setting for each variable happens to be 1  then all examples get assigned weight 1  so the new frequency distribution for each variable is the same as the original frequency distribution. in addition to this potential difficulty  a second difficulty is that this process can magnify idiosyncrasies in the original data. for instance  suppose we have a data set over   and  for simplicity  the favored setting for each variable is 1. if we happen to have one example with many variables set to 1  it will get an inordinately high weight compared with other examples  potentially giving some insignificant variable a high gain. can we mitigate these potential problems with the skewing procedure  
　the difficulties in the preceding paragraph occur with some data sets combined with some choices of favored settings. other selections of favored settings for the same data set may leave other variables' frequencies unchanged  but it is relatively unlikely they will leave the same variables' frequencies unchanged. furthermore  while other selections of favored settings may magnify other idiosyncrasies in the data  it is unlikely they will magnify the same idiosyncrasies. therefore  instead of using skewing to create only a second distribution  we use it to create some number t of additional distributions. the t different distributions come about from randomly  without replacement  selecting t different combinations of favored settings for the n variables according to a uniform distribution. to ensure that tree construction is not thrown off course by any single bad distribution  either original or skewed   the tree construction process is modified as described in the following paragraph. 
　suppose we have  weightings of the data  the original data set plus t reweighted versions of this data set   and we are considering a split. we score each of the n variables against each of the  weightings of the data. a variable that is not part of the target function should have nearly zero gain on every weighting  although as already noted  it may occur that on some weightings some of these variables can achieve high gain. but only variables that appear in the target should have significantly non-zero gain on most of the weightings  though not necessarily on all . therefore  we set a gain threshold  and the variable that exceeds the gain threshold for the greatest number of weightings is selected as the split variable. our expectation is that the selected variable is highly likely to be correct in the sense that it actually is a part of the target function. yet the time for choosing the split remains 1{mn   in contrast to lookahead. we have increased the run-time only by a small constant. 
learning 	1 　pseudocode for the algorithm is shown in algorithm 1. rather than actually doubling or tripling weights  the algorithm takes a parameter  the weight of an exalgorithm 1 skewing algorithm 
input: a matrix d of m data points over n boolean variables  gain fraction g  number of trials t  
skew 
output: a variable xi to split on  or -1 if no variable with sufficient gain could be found 
1: 	entropy of class variable in d 
1: 	variable with max gain in d 
1: 
1: if 	then 
1:  
1:  
{begin skewing loop} 
1: for t = 1 to t do 
1: 	for 	= 1 to n do 
1: 	randomly chosen favored value for  
1: for e - 1 to m do 1: w e  = 1 1: fori = 1 to n do 1: 	if/ 	lthen 1: if z  e i  = v i  then 1: 	w e  	w e  	s 1: else 1: 	w e  	w e  	 1 - s   
1: 	n 	entropy of class variable in d under w 
1: 	for   = 1 to n do 
1: 	e 	gain of 	under distribution w 
1: 	ife 	g n then 
1: 	f i  	f 	+ 1 
{end skewing loop} 
1:  argmaxf i  
1: 	itf j  1 o then 
1: 	return  
1: else 
1: 	return   
ample is multiplied by s if xi takes preferred value vi in the example  and is multiplied by 1 - s otherwise. hence for illustration  if s is |  the weight of every example in which xi takes value vi is effectively doubled relative to examples in which xi does not take value i; -. 
　our hypothesis is that in practical experiments the new algorithm will run somewhat slower than an ordinary tdidt algorithm  only by a constant factor. it will rarely produce trees with lower accuracy than those of an ordinary tdidt algorithm. it will often produce trees with slightly to moderately higher accuracy-when the target contains one or more problematic subfunctions. and it will sometimes produce trees with much higher accuracy-when the target is itself a problematic function. when the target is a problematic function over many variables  even after skewing the gain of any individual variable in the target is likely to be small. therefore  we also hypothesize that unless the data set is large  the benefits of the skewing approach will not apply to problematic target functions of five or more variables. note that while a large number of variables in the target reduces the potential gain  the number of variables in the examples does not. the following section describes the experiments designed to test the preceding hypotheses. 
1 experiments 
in this section  we discuss experiments with synthetic and real data  designed to test the hypotheses in the preceding paragraph. in addition  the question arises of whether problematic functions or subfunctions occur with high enough frequency to justify the additional work of skewing. the experiments in this section also address that question. we begin with a discussion of experiments using synthetic data  where target functions as well as examples are drawn randomly and uniformly  with replacement. in these experiments we compare simple id1 against id1 with skewing. wc selected id1 to eliminate issues to do with more sophisticated pruning. the parameters input to the skewing algorithm  algorithm 1  were 
 these parameters were cho-
sen before the experiments and were held constant across all experiments. improved results could perhaps be obtained by tuning s and g. 
　in the first set of experiments with synthetic data  examples are generated according to a uniform distribution over 1 binary variables. target functions are drawn by randomly generating dnf formulae over subsets of 1 to 1 of the 1 variables. the number of terms in each target is drawn randomly  uniformly from between 1 and 1  and each term is drawn by choosing for each variable whether it will appear negated  unnegated  or not at all  all with equal probabilities . all targets are ensured to be satisfiable. examples over the 
1 variables that satisfy the target are labeled positive  and all other examples are labeled negative. figures 1 show learning curves for different target sizes. each point on each curve is the average over several runs  each with a different target and with a different sample of the specified sample size. 
　in general  these figures fit our expectations. both algorithms perform well but skewing provides slightly yet consistently better results  wc note that the differences are not statistically significant . probably the difference is skewed id1 is less likely than ordinary id1 to include irrelevant variables  particularly when faced with problematic functions. one surprise is that the figures indicate that an ordinary tdidt algorithm outperforms skewing on average when the sample size is small relative to target size. as sample size grows  a crossover point is reached after which skewing consistently outperforms the ordinary tdidt algorithm. furthermore  the sample size required for effective skewing grows with the number of variables in the target  although these results alone do not make clear the order of this growth. it may well be exponential  because target complexity can grow exponentially with the number of variables in the target. further experiments are needed to explore the order of this growth. this observation implies a limitation of skewing-that skewing may be undesirable for learning tasks with small samples or target concepts that potentially employ many variables. 
　the next set of experiments focuses on the problematic functions alone. the methodology is the same as before  with the following exception. targets are drawn randomly from functions that can be described entirely by variable co-
learning 

		figure 1: three-variable hard targets 
	figure 1: four-variable targets 	figure 1: four-variable hard targets 
		figure 1: five-variable hard targets 
	figure 1: six-variable targets 	figure 1: six-variable hard targets 
learning 	1 


table 1: accuracies of id1 and id1 with skewing on 1 uci data sets. heart is cleveland heart disease  voting is congressional voting  contra is contraceptive method choice  and monks-x are the monk's problems. voting-1 is the same as voting  with one feature  physician-fee-freeze  removed to make the problem more difficult. 
references together with the standard logical connectives and  or  and not. many such functions exist  and for all such functions  even given a complete data set  no variable has gain. examples of such functions are exclusive-or and exclusivenor  and all those in table 1. figures 1 show the results for these experiments. 
　we observe that if the target is a problematic function  skewing outperforms standard id1 by a wide margin. the difference in accuracy was statistically significant - the 1% confidence intervals around each sample point in these graphs do not overlap once the sample sizes become moderately large. we repeated the experiment with 1-variable hard targets with 1 examples to verify that skewing did indeed achieve 1% accuracy  in our noise-free setting  in this case. we also verified this behavior for 1 and 1 variable targets. 
　in addition to the preceding experiments  we also compared id1 against id1 with skewing on several data sets in the uci machine learning repository  blake and merz  1 using 1-fold cross validation. for these data sets  we discretized continuous variables by binning. further  nominal variables were binarized using the standard 1-of-iv representation. the results of these experiments appear in table 1. in this case  we do not know whether the target concepts involve problematic subfunctions except for the concepts in the monk's problems  where the first two involve problematic subfunctions. the only task for which there is a significant difference in accuracy is the first monk's problem  which has an exclusive-or subfunction. we believe the reason id1 with skewing does not dramatically outperform id1 on the second monk's problem is that the number of training instances is small  1  relative to the target function. we verified this by constructing a larger data set of 1 examples using the concept that generated this data. in this case  skewing achieves an accuracy of 1%  while standard id1 achieves 1%. 
　in the experiments reported in figures 1  the run-time for id1 with skewing was on average a constant times the run-time for ordinary 1  regardless of sample size or target size. this constant was  roughly  equal to our value for t in algorithm 1  1. in the experiments involving hard targets  we observed that as sample size increased  id1 with skewing became more efficient relative to 1. this can be explained by the fact that though it takes more time to choose a split  id1 with skewing chooses many fewer splits when the target 

figure 1: time complexity of id1 with skewing relative to standard id1 for hard targets. the y axis represents the ratio of the average time taken by id1 with skewing to induce a tree against the same quantity for standard id1 for hard targets. observe that  though the ratio is close to our value for t for small samples  it drops rapidly as the sample size increases  and the final value is much smaller. 
is a hard function. in this case  the constant-factor overhead for skewing is significantly smaller than t. this behavior is shown in figure 1. thus in all cases  provided the sample is sufficiently large  skewing provides benefits similar to lookahead  but with only a constant increase in run-time. this is the primary result of the paper. 
1 related work 
a natural question to ask of the preceding results is whether they could as easily be obtained by other techniques that effectively re-weight the data. we know of two such related techniques: boosting  freund and schapire  1  and bagging  breiman  1   sampling with replacement may be thought of as providing a re-weighting of the data .while these techniques were not developed to enable tree induction algorithms to address problematic functions  it is possible that their re-weighting schemes might nevertheless be successful in this task. therefore  we ran id1 with each of these re-weighting techniques on hard targets  using the same methodology as in the preceding section. we also ran id1 with a procedure that randomly reweighted the data as in the data perturbation approaches of elidan et al. we observed that id1 with each of the three re-weighting schemes performed on average no better than ordinary id1. hence we conclude that the benefit of skewing comes from the type of re-weighting being performed  not merely from the general notion of re-weighting. 
1 conclusions and future work 
we have shown that the advantages of lookahead for decision trees can be obtained with only a constant increase in runtime  rather than a super-exponential increase  by the process of skewing. nevertheless  the approach has limitations that need to be addressed in future work. it also has potential applications beyond decision trees  to be investigated in future work. the remainder of this section briefly outlines these directions. 
learning 

　decision tree induction algorithms often are applied to data sets that involve some continuous variables in addition to nominal variables only. therefore  one direction for further work is to extend the skewing algorithm to handle continuous variables. here we briefly outline a natural such extension that we plan to test in future work. for continuous variables  the favored value is either less or greater than the split point  rather than 1 or 1. this makes skewing trickier because we do not know ahead of time what split point will be chosen. hence for each continuous value v that a variable x takes in the data set  we compute the probability that v will be less than or greater than the split point. to do this computation  we might assume the split point is drawn from a uniform distribution over the values that x takes in the data set. we can then reweight an example with the expected weight over all possible split points. for example  suppose we have 1 examples  and the favored value for a variable x is less. an example that takes the tenth lowest value for x has probability 1 of being lower than the split point. hence the weight of this example will get multiplied by  1  1  +  1  l  = 1. 
　second  while we have demonstrated that skewing works for parity and other problematic functions of up to seven variables  for more variables it appears that large numbers of examples  at least several thousand  will be required. if the number of examples is too small relative to the size of the problematic portion of the target  then skewing can cause predictive accuracy to degrade somewhat  though the reason for this is not entirely clear. hence if a data set is small it may be desirable to try both skewed and normal versions of the tree learner. in spite of this limitation  skewing makes it possible to gain the effect of five- or six- step lookahead where only 1- or perhaps 1-step lookahead was computationally feasible previously. 
　the third direction for future work is to address highdimensional data sets. the skewing approach may have trouble with such data sets for the following reason. if each data point has thousands of features  then one data point is likely to get a much higher weight than all others  to have many more variables with the preferred values   merely by chance  leading to a model that overfits this data point. one solution may be to lessen the degree of skewing. this and other approaches should be tested on high-dimensional data sets. 
　we would also like to apply the skewing approach to other types of learning algorithms that have trouble with similar hard functions. to focus on a specific algorithm for illustration  the introduction noted that the sparse candidate algorithm for learning bayesian networks ifriedman el al.  1  was susceptible to functions like exclusive-or. this susceptibility is because of its use of information gain or more generally kullback-leibler divergence to narrow the candidate parents for any given node. for example  suppose the variables x  and x'y together are highly predictive of the value of x1 and hence would be excellent parents of x1  as shown in the bayesian network fragment in figure 1. if x1 and x1 are independent of one another and take the value 1 roughly half of the time  then among tens or hundreds of other variables neither x1 nor x1 is likely to be considered as a candidate parent for x1. nevertheless  if several skewed versions of the data are used to select candidate parents  a variable is a potential 
learning 

figure 1: variable x$ is an approximation of 
parent if it scores well according to most of the skews   then x  and x-1 are likely to be selected. modifying the sparse candidate algorithm is an intriguing direction for further work. more generally  we believe the skewing approach presented in this paper may be applicable to a wide variety of learning algorithms  in addition to decision trees. 
acknowledgements 
this work was supported in part by nsf grant 1  nih grant 1lm1  and grants from the university of wisconsin graduate school and medical school. 
