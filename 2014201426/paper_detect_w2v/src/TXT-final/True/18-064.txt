	i n 	d e f e n s e o f p r o b a b i l i t y 
peter cheeseman 
sri international 
1 ravenswood ave.  menlo park  california 1 

a b s t r a c t 
in this paper  it is argued that probability theory  when used correctly  is suffrcient for the task of reasoning under uncertainty. since numerous authors have rejected probability as inadequate for various reasons  the bulk of the paper is aimed at refuting these claims and indicating the scources of error. in particular  the definition of probability as a measure of belief rather than a frequency ratio is advocated  since a frequency interpretation of probability drastically restricts the domain of applicability. other sources of error include the confusion between relative and absolute probability  the distinction between probability and the uncertainty of that probability. also  the interaction of logic and probability is discusses and it is argued that many extensions of logic  such as  default logic  are better understood in a probabilistic framework. the main claim of this paper is that the numerous schemes for representing and reasoning about uncertainty that have appeared in the ai literature are unnecessary-probability is all that is needed. 
1 	i n t r o d u c t i o n 
a glance through any major ai publication shows that an overwhelming proportion of papers are concerned with what might be described as the logical approach to inference and knowledge representation. it now widely accepted that many knowledge representations can be mapped into  first order  predicate calculus  and the corresponding inference procedures can be reduced to a type of controlled logical deduction. however  examples of human reasoning 
 judgements  are full of such terms as  probably    most    usually  etc.  showing that many patterns of human reasoning are not logical in form  but intrinsically probabilistic. 
　the claim that many patterns of human reasoning are probabilistic does not mean that the underlying  logic  of such patterns cannot be axiomatized. on the contrary  a basis for such an axiomatization is given in section 1. the claim is that when such an exercise is performed  the resulting patterns of inference are different in form from those found in analogous logical deductions. a characteristic difference is that in probabilistic inference all the relevant inference paths   proofs   connecting the evidence to the hypothesis of interest must be examined and  combined   while in logic it is sufficient to establish a single path between the axioms and the theorem of interest. also  the output is different  the former includes at least one numerical measure  the latter simply true or false. 
　unfortunately  the logical style of reasoning is so prevalent in ai that many have attempted to force intrinsically probabilistic situations into a logical straight-jacket with predictable limited success. two conspicuous examples of this are  default logic   and  non-monotonic logic   discussed in more detail below. these methods are appropriate for dealing with some situations where limited knowledge is available. the same cannot be said for those who invent new theories for reasoning under uncertainty  such as  certainty factors    schafer/dempstcr theory   
 confirmation theory    fuzzy logic    endorsements  etc. 
　these theories will be shown below to be at best unnecessary and at worst misleading  not to mention confusing to the poor novice faced with so many possibilities . each one is an attempt to circumvent some perceived difficulty of probability theory  but as shown below these difficulties exist only in the minds of their inventors. however  these supposed difficulties are common misconceptions of probability  generally springing from the inadequate frequency interpretation. a major aim of this paper is to put forward the older view  bayes  laplace etc.   that probability is a measure of belief in a proposition given particular evidence. this definition avoids the difficulties associated with the frequency definition and answers the objections of those who felt compelled to invent new theories. 
　an analogy can be draw between the situation in ai in the late 1s  where pat hayes  in a paper entitled  in defence of logic    found it necessary to take a broadside at the proliferation of new representation languages  with associated inference procedures  that proported to solve difficulties with the logical approach. he showed that far from being  nonlogical  it is possible to cast such languages into an equivalent logical form  and by doing so provide a clear semantics. in addition  he pointed out the obvious but unpopular fact that logic has been around for a long time and has a considerable body of research and experience that no new theory can match. similarly today we have a set of new theories for dealing with uncertainty  despite the fact that probability theory has been around for three centuries and  as shown below  is sufficient for the ta.sk. 
　any text on probability presents a formal calculus for manipulating probabilities according to a consistant set of axioms. many disputes concerning probability are centered on the interpretation of the terms in the formal system  since an interpretation  model theory  is necessary if the theory is to be applied. others dispute that the formal axioms under any interpretation really capture their intuitive expectations for uncertain inference. this paper argues for a particular interpretation of the probability formalism and that the result is sufficient for all uncertain inference in ai. since haves' theorem is integral to the use of probabilities the terms hayesian and probabilistic are used interchangeably. 
1 s o m e m i s c o n c e p t i o n s o f p r o b a -
b i l i t y 
this section discusses and hopefully exorcises the most common misconceptions of probability. 
1 	probability is a frequency ratio 
rather than give an historical account of the different theories  interpretations  that have been applied to probability  e.g. |1    the following definition is put forward as one that withstands all previous criticisms: 
　the  conditional  probability of a proposition given particular evidence is a real number between zero and one  that is a measure of an entity's belief in that proposition  given the evidence 
　several corollaries follow directly from this definition. firstly  there is no such thing as the probability of a proposition  since the probability value depends on the evidence used to derive it. this implies that if new evidence is utilized  the probability value assigned to the proposition will generally change. the only exception to this variability is when the probability is zero or one  because then there is no longer any uncertainty and further evidence makes no difference. secondly  different observers with different evidence  information  will assign different probabilities. there is no contradiction inherent in this the apparent contradiction comes from the idea that every proposition has a unique probability. a third consequence of the above definition is that probabilities are inherently subjective in the sense that the value depends on the believer's information  but they are objective in the sense that the same  ideal  believers should arrive at the same value given the same information. 
　this definition differs sharply from the still commonly held frequency definition of probability: 
p. cheesemart 1 
　the probability of an event  hypothesis  is the ratio of the number of occurrences  n  in which the event is true to the total number of such occurrences  m  
　this definition has some immediate problems that many other critics have noted. for a start  this definition restricts probability to domains where repeated experiments  e.g.  sampling  are possible  or at least conceivable. also  the probability of an event under this definition is undefined if there are no prior examples  m = 1  thus limiting its usefulness. even worse are cases where  for example  there has been one success  n = 1  and one trial  rn = 1   giving a probability of one for the next event!-that is on the basis of a single trial the probability of the next event is known with certainty. in most circumstances this is nonsense-those who defend the frequency ratio definition escape into  the law of large numbers  which essentially says that given a large number of  repeatable  trials  the true probability lies within given error bounds with high probability. this restriction bans small sample cases from the realm of probabilistic   frequency   analysis  but works well for the large sample case. given the success of the frequency definition in areas where it is applicable  it is fortunate that there is a strong connection between the measure of belief definition of probability and the frequency ratio definition. it has been shown by jaynes  that under certain conditions  e.g.  repeatable trials  the expectation of the frequency ratio is necessarily equal to the probability. however the measure of belief definition applies to the small sample case as well. 
　philosophers have been arguing the  correct  definition of probability for centuries  and some have defined up to five different meanings for probability   including:  statistical probability   i.e.  the frequency ratio definition ;  probability = propensity   i.e.  probability used for prediction ;  logical probability   i.e.  the degree of confirmation of a hypothesis based on logical analysis  and  subjective probability  . the measure of belief definition subsumes all these supposedly different concepts. for example  the probability of set membership   the probability of a being a b   and the probability of future events   the probability that h will happen  given e   are not different kinds of probability but just the observer's belief in the corresponding proposition given the evidence. similarly  it makes no difference to the belief in a proposition whether the probability is the result of logical analysis  e.g.  the probability of a number being prime  or the result of empirical observations  e.g.  the probability of surviving a car accident . the philosophical distinctions and alternative definitions of probability obscure rather than enlighten understanding of probability. 
1 	bayesian analysis requires vast a m o u n t s of d a t a 
this particular fallacy has appeared so often that its truth is rarely questioned. the reason for this fallacy follows directly from the frequency ratio definition. this says 1 p. cheeseman 
that the probability of a proposition  such as  this patient has a particular infection given his particular set of symptoms'   can be computed from the number of patients that have previously exhibited that combination of symptoms. clearly  in practice  the set of previous patients with a particular combination of symptoms is going to be very small or zero  so by the frequency definition of probability this conditional probability cannot be computed. 
　in anything but the most trivial cases  the basic problem that the bayesian  or any other  approach must deal with is that the available information is not sufficient to determine any particular conditional probability  as in the above example. that is  the probability space associated with a particular problem is usually highly under-constrained by the known probabilities  so it is impossible to calculate directly any particular conditional probability . the normal way around this difficulty is to make additional assumptions that supply the missing constraints. the most common as-
sumption is  conditional independence   as advocated in    and . the conditional independence assumption has been generalized by lemmer and barth  to include conditional independence between groups of propositions  and all these forms of independence assumptions are subsumed under the maximum entropy assumption   . 
　the use of the maximum entropy assumption  or its specializations  raises the question of its validity. for maximum entropy  it has been shown that the probability generated is the one which has the maximum number of possible worlds consistent with the known information  and in this sense is the  best  value . in some circumstances  such as occur in statistical mechanics  the probability of the system being in a state with entropy significantly less than the maximum is vanishingly small. maximum entropy implies that if a non maximum value is chosen  then more information is being assumed than was available-i.e.  the maximum entropy gives the  least commitment'' value or the one that distributes the uncertainty as evenly as possible over the set of possibilities. conditional independence  the most common form of maximum entropy  is not just another assumption  as implied in   it is the only consistent assumption that can be made in the absence of any information about possible interactions. however  these desirable properties do not mean that information is being generated out of nothing. 
　what maximum entropy is doing is providing a neutral background against which any systematic  non-random  patterns can be observed. that is  if the current  probabilistic  information is incomplete  the predictions using this information and maximum entropy will differ significantly from future observations. when such differences are detected the response should not be to throw out maximum entropy  as many authors advocate   but to utilize this additional information. maximum entropy is making stronger predictions than the current information warrants because it is assuming the current information is complete. however  without this prediction it is difficult to detect if the current information is incomplete  and thus difficult to discover new information. also many decision making situations require probability values  so that some additional principle  such as maximum entropy  is necessary in these circumstances to select point values even when the value is poorly known. this justification for the maximum entropy assumption is really the old problem associated with the use of prior probabilities in the bayesian approach as discussed in the next subsection. 
1 p r i o r probabilities assume more i n f o r m a t i o n t h a n given 
this statement appears in numerous ai publications  especially those expounding the schafer-dempster approach to uncertainty. for example: 
　 baycaiana might attempt to represent ignorance by a function assigning 1 to each of the four possibilities  assuming no prior information. ...such a function would imply more information given by the evidence than is truly the case. -. 
　 a likelihood represented by a point probability is usually an over statement of what is actually known  distorting the available precision .- 
　yet those that make these claims fail to show a single unfortunate consequence that follows from this supposed assumed information. to illustrate the situation  consider the following examples. in the first example  you are told there is a normal dice and asked what probability you would assign to the next throw yielding a ''1''. the maximum entropy answer is 1  since this distributes the uncertainty as evenly as possible over the set of possibilities. in the next example you are told there is a loaded dice  but not which numeral is favoured  and are asked what is the probability of a ''1''. again the answer representing your state of knowledge is to assign 1. the difference between these two situations is that in the first example your know ledge of dice mechanics and symmetry implies that after having seen the outcome of many throws you do not expect to change your state of knowledge  i.e.  the probability assignment . however  for the loaded dice  you do expect the probabilities assigned to the different faces to change as a result of further trials. 
　those who reject the maximum entropy approach argue that in the second example  the initial assignment of 1 was assuming more than you know because after many trials you ended up with a different assignment  i.e.  the initial assignment was incorrect . this objection arises from the mistaken idea that there is such a thing a the probability of a proposition instead of the idea that probability represents a state of knowledge. of course the probability assignment to a proposition will change as more information is gained without inconsistency with previous assignments. the idea that there is a unique probability associated with a particular proposition comes from situations where all observers have the same information  e.g.  physics   and so they all have the same measure of belief  assuming ideal observers . 
however  not just any prior probabilities will do. if non-

equal priors are chosen  this implies that you have information about the different possibilities. put another way  the equal prior assignment gives a neutral background against which deviations from your state of maximum uncertainty can be detected. it is because it is not assuming more information than given that the maximum entropy assignment is used. looking at the example in reverse  if someone assigns equal probabilities to a set of possible outcomes  they are telling you they are completely ignorant about the next outcome  apart from how many possibilities there are . note that in these two examples  our knowledge about our knowledge of the probabilities  i.e.  the probability distribution of the probability  is the main difference. 
　a more subtle criticism of the use of the principle of indifference that has historically plagued probability theory is illustrated by the following example. assume there are five  concepts   a  b  c  d  c   then the principle of indifference will assign prior probability 1 to each. if you are now told that concept a is actually / or g  then you should reassign probabilities of 1 to each of  / f  g  c  d  e . this apparent arbitrariness of the prior probabilities through regrouping and relabelling is put forward as a reason for rejecting use of priors at all. the arbitrariness of the probability assignment only arises in this example because the  concepts  are meaningless  so any grouping is just as meaningless as any other. if the problem is undefined  probability theory  or any other theory  cannot say anything useful. however  as soon as the concepts are identified with possibilities in the real world  the arbitrariness disappears. when each possibility in a problem corresponds to a physically realizable possibility  we no longer have the freedom to count arbitrary groupings of such outcomes as if they are a separate outcome- i.e.  we can no longer arbitrarily redefine the problem . 
for example  consider the famous problem known as 
bertrand's paradox. in this  paradox  we are required to draw lines uat random  that intersect a circle  and wish to know the probability that the length of a chord of such a line is longer than a side of an inscribed equilateral triangle. there appears to be different answers depending how  equally possible  situations are defined. three possibilities are to assign uniform probability density to:  a  the distance between the centers of the chord and circle   b  the angle the chord makes with the center  and  c  the center of the chord within the circle; each possibility giving a different answer. jaynes  has shown that only  a  is consistent with the requirement that the answer be invariant under infinitesimal translations and rotations-an obvious requirement coming from our understanding of the physical set-up. 
　another example of the invariance argument leading to a definite prior probability assignment is to consider the probability of finding a ship within a particular square mile somewhere in the atlantic. if this is the only information available  then an invariance argument requires assigning equal probability to equal areas  in agreement with intuition. since the atlantic is roughly diamond shaped  this 
p. cheeseman 1 
means that the probability of finding the ship at an equatorial latitude is higher than at a polar latitude. if the ship is instructed to move to a particular latitude  but interference completely scrambles our reception of which latitude  then after the ship has had time to move  our knowledge is represented by assigning uniform probability to each latitude this new assignment  based on the new  information  leads to a new probability distribution in which the probability of finding the ship near the equator is now less than near the poles. this example shows that in real problems we cannot arbitrarily assign equal prior probabilities to any dimension or combination of possibilities because to do so implies unequal assignments on other dimensions. in practice  our rich domian background knowledge usually leads to non-uniform priors  even though we may be uncertain of their values. in complex cases  there is no substitute for a careful analysis of each problem to find what the appropriate priors for that problem are. 
1 	n u m b e r s are not necessary 
an unfortunate tendency in ai is to rediscover the wheel but call it something else so it then becomes a  new  paradigm. an example is found in cohen and grinberg   who shows  convincingly  that in many situations it is necessary to keep track of the evidence that was used to arrive at a particular  conditional probability  judgment  so that the judgment can be revised if new evidence requires it. their work calls attention to the fact that a computed probability number is just a summarization of all the evidence that was used to derive it  for convenience in decision making   and so does not contain information about its origin. however  it still a conditional probability and the conditions of its derivation can also be important. this utilization of probabilistic dependencies is unfortunately given the new name  endorsements   and from its success in explaining observed judgements under uncertainty  the conclusion is reached that numbers are not necessary for such judgements at all! 
　this conclusion has validity in restricted circumstances in particular  it is possible to construct a theory of relative probabilities  e.g.    that only uses information of the form p1 is-more-probable-than p1 deductions in such a theory do not use numbers and can keep track of their dependencies in a style similar to  endorsements . however  the best that such a theory can say is that  this proposition is the most probable given the evidence -it cannot indicate any absolute strength in its conclusion. it often happens that the most probable alternative is itself highly unlikely  but non-numeric approaches are unable to express such a result. the bottom line is that judgment under uncertainty can bo done without using numbers if the user is in a decision making situation where he has only to choose among a set of alternatives. if he has the option of not selecting at all  e.g.  because the most likely alternative is still too improbable   then non-numeric approaches are not sufficient. 
1 p. cheeseman 
1 	m o r e t h a n one n u m b e r is needed to represent uncertainty 
many of the alternative theories of uncertainty start with the observation that a single number  a probability value  does not represent all the uncertainty about a proposition- in particular  it does not indicate the accuracy with which the probability value itself is known  i.e.  the probability of the probability . similarly  schafer  1  distinguishes between uncertainty  roughly a probability  and ignorance  no knowledge of the probability . however  even though one can make these distinctions  basic questions about their utility remain. ultimately  the utility of any theory of uncertainty comes from the coupling it provides between evidence  information  and decision making  or prediction . a theory of uncertainty is useless without a model theory that indicates how to map evidence into an uncertainty measure and how to use this uncertainty measure to make predictions  or decisions . to decide whether particular distinctions of types of uncertainty are useful or not  we must examine whether they make any difference to the theory's decision making behavior. 
　the theory of optimal decision making using point probability and utility values is well known. this would seem to imply that a point probability is sufficient to represent uncertainty. however  this theory makes the assumption that the probabilities used in the analysis are known to sufficient accuracy. probability theory can be extended so that a probability density function is assigned to a sentence instead of a point value  or higher order moments of the density function can be given. however  a result of decision analysis is that exactly the same decision is reached whether a point value or a density function is used. this situation is similar to that in mechanics  where a complex body can be replaced by a point mass at the center of gravity to give the same results. however  knowledge of the probability density function is important for sensitivity analysis as in the following example. 
　if you are given a black box and told that it will put out a string of decimal digits and are asked what is the probability that the first digit will be say 1  the standard principle of indifference answer is  .1 . if  later  after seeing 1 digits of which 1 were 1  1 were 1  etc.  in no noticeable order  you are again asked to give the probability that the next digit will be 1  you will still answer  .1 . this last answer  by standard information theory  implies that all the evidence gave no information whatever-you are still as uncertain about the probability of the next event as you were before seeing the  evidence . however  something has clearly changed between these two cases-it is the expectation that further evidence will significantly change our probability assignment  i.e.  will provide real information . this changed expectation can be captured as a standard deviation about the probability value which is very large initially and becomes quite small  about .1  after seeing the 1 trials. 
this example implies that if you are in a decision mak-
ing  or prediction  situation and obtaining more evidence is not an option then a single number  the probability  is a sufficient representation of your uncertainty. however  if obtaining more information is a possible option  then a measure of how informative this information is likely to be  e.g.  the standard deviation  is required. thus  how many numbers are needed to represent uncertainty depends on the questions you are trying to answer with the uncertainty representation. to always calculate two numbers  as done in the schafer-dempster approach  is often overkill  and in 
some cases  under-kill. 
1 t h e bayesian a p p r o a c h doesn't w o r k so here is a n e w scheme! 
as described above  various authors have found fault with bayesian probability  and their response has been to invent new representations and inference procedures that purport to remove particular difficulties. however  these ad hoc theories do not have a well established model theory to show how to go from real data to the internal uncertainty representation and then to map the final uncertainty representation into a well defined decision theory. because of this missing interpretive framework  and because of their rejection of prior probabilities  they have produced all sorts of misleading conclusions. the following examples are illustrative: 
example 1 
　''translated to the notation of conditional probability  this rule  s1 s1 s1 =  h   seems to say p h1 sls1 s1  =1 where h1 is the hypothesis that the organism is streptococcus  s1 is the observation that the organism is grampositive  s1 that it is a coccus  and s1 that it grows in chains. questioning of the expert gradually reveals  however  that despite the apparent similarity to a statement regarding a conditional probability  the number 1. 1 differs significantly from a probability. the expert may well agree that p h1 s1  s1 s1  = 1  but he becomes uneasy when he attempts to follow the logical conclusion that therefore p not hl s1 s1 s  - 1. he claims that the three observations are evidence  to degree 1  in favor of the conclusion that the organism is a streptococcus and should not be construed as evidence  to degree 1.s  against streptococcus. 
we shall refer to this problem as paradox 1 ...*- 
　the authors then conclude  on the basis of this  paradox   that one should gather and evaluate separately the evidence for an hypothesis and the evidence against it. this spurious argument only arises by ignoring prior probabilities and the consequent misrepresentation of the situation to the expert. the prior probability of an infection being caused by a particular bacterium is low  for the sake of argument we will assume it to be .1. after seeing the evidence  s1  s1  s1  the expert is willing to update his probability  i.e.  his belief  to 1. another way of saying the same thing is that the probability  belief  in the negation of the hypothesis  that the organism is not streptococcus  drops from a prior of .1 to .1. thus  either way  the evideuce is being used to strongly support the hypothesis  and not  as claimed above  being construed as evidence against the hypothesis. given the misrepresentation of the situation  it is not surprising that the expert felt uneasy with the way his evidence was being used. 
　this example shows the danger of ignoring prior probabilities when dealing with uncertainty  and also shows its considerable advantages when used properly. as a basic principle of inference one should use whatever information is available  and this includes prior probabilities. perhaps the main sources of opposition to the use of prior probabilities is that they are subjective estimates of the expert  and it has been shown  e.g.    that people are not very good at estimating probabilities. however  the expert does not necessarily have to supply the priors-once the hypothesis space is defined  the equiprobable assignment  i.e.  the principle of indifference  or relevant data can be used instead. if the expert has prior information  e.g.  some infections have higher prior probabilities than others  then he should give this information to the system  in the form of nonuniform priors   because to not do so is to ignore useful information. the fact that these subjective estimates will be poorly known is no excuse for not using them. fortunately  the final probability values calculated on the basis of extensive new information are not very sensitive to the exact value of the priors. 
example 1  fuzzy sets  fuzzy and possibilistie logic  
　 ..  it is a standard practice to rely almost entirely on the techniques provided by probability theory and statistics  especially in applications relating to parameter estimation  hypothesis testing and system identification. it can be argued  however  as we do in the present paper  that such techniques cannot cope effectively with those problems in which the softness of data is nonstatistical in nature in the sense that it relates  in the main  to the presence of fuzzy sets rather than random measurement errors or data variability.  zadeh   
　this quote captures some of the motivation that underlies fuzzy sets  and their further development fuzzy and possibility logic -namely  the fallacy that probabilities are necessarily frequencies. the concept of vague set boundaries has no obvious frequency interpretation  so zadeh invented fuzzy sets to capture this vagueness idea. actually  there is a probabilistic  degree of belief  model for vague sets that also supplies a computable quantitative measure for the  best   most informative  vague classification. normally  a set is defined by a criterion that distinguishes members from non-members without allowing for partial membership. this concept of sets has been widely critisized by philosophers  e.g.  wittgenstein  largely because sets in common use do not have sharp boundaries. the alternative probabilistic model is to define a set by a  prototype  and expectations of divergence from the prototypical features shown by members of the set. that is each object has a numeric  degree of membership  given by how likely it is that the observed features would have occurred given that it is a member of that set. the best classification of the 
p. cheeseman 1 
object is that which maximizes the probabilistic  similarity  measure  and it is quite possible for an object to be so dissimilar from any prototype that it forms a new set. also  an object can be simultaneously probabilistically similar to more than one set. the underlying theory of probabilistic set membership is given in . 
　other errors found in the al literature include the notion that the final conditional probability value of a proposition depends on the order in which the evidence is introduced ; that hypotheses  such as the possible diseases a patient might have  are mutually exclusive ; that a piece of evidence whose conditional probability differs considerably from that of other evidence should be rejected   instead of rejecting the corresponding hypothesis ; etc 
1 	s u m m a r y of conceptual confusions 
the authors that reject probabilities as a formalism for dealing with uncertainty in al are usually a victim of one or more of the following confusions. 
  relative versus absolute probabilities to decide the most probable of a set of hypotheses is only a relative evaluation sufficient for some tasks  but decision analysis requires  absolute  conditional probability values. 
  separation of probability and utility the importance  utility  of an hypothesis is often confused with its probability  since both are required for decision making. 
  probabilities are a measure of belief in a proposition this definition does not require a frequency interpretation  but applies to any well defined situation and summarizes all the evidence for that proposition 
  probability versus uncertainty about the probability the  conditional  probability p of a proposition is the user's measure of belief in that proposition  but information about the accuracy of p is fully expressed by a probability density function over p. 
  probability is not a special case of logic probabilistic reasoning is often cast incorrectly in a logical form  as discusses in section 1. 
  prior probabilities should be used failure to use prior probabilities can lead to erroneous conclusions  especially when there is a large number of possibilities. 
  ambiguous probabilities-if they occur  it is a sign that the problem is not fully defined  not that probability theory is inadequate. 
1 	l o g i c a n d p r o b a b i l i t y 
formally  probability can be regarded as a generalization of predicate calculus  where instead of the truth value of a 

1 p. cheeseman 
formula given the evidence  context  having only the values 1  false  or 1  true   it is generalized to a real number between 1 and 1. this generalization can be achieved by creating new propositions of the form uthe probability of /'' is a   where f is an arbitary well formed formula in predicate calculus. once it has been accepted that: 
  the generalized truth value  degree of plausibility  of a formula can be represented by a real number. 
  the extremes of this scale must be compatible with logic. 
  an infinitesimal increase in the plausibility of a given new evidence implies an infinitesimal decrease in the plausibility of -a. 
  the plausibility should not be dependent on the order of evaluation. 
  where possible  all the available evidence should be used in evaluating the plausibility. 
  equivalent problems should have the same plausibility. 
then it has been shown by  that all the degrees of freedom have been used up. that is  all the standard kolmogorov  axioms  of probability  addition  multiplication  baye's etc.  follow as logic consequences. this implies that fuzzy set theory  which rejects the additivity axiom  is necessarily violating one or more of the above requirements. any formalism for representing  plausibility  by a real number is either equivalent to probability theory  but perhaps differing in interpretation  or not satisfying the above basic criterion. even formalisms that do not use a single real number  e.g.    can be captured by higher order probability theory  i.e.  probabilities of probabilities etc. . probability theory provides the basic procedure for computing uncertainties in real situations  but it is often not obvious how to apply it in a particular situation in particular  the assignment of prior probabilities has historically been the main sources of difficulty. 
　misapplications of probability do not usually arise from dispute or uncertainty about the basic axioms but from the way they are interpreted. a purist would insist that the only propositions that can be known with certainty are tautologies  e.g.  1 is a prime number -any empirical  contingent  proposition can only be known probabilistically  since it is based on induction. however  this insistence forbids the application of logically reasoning to anything about the real world! a reasonable compromise is to treat propositions whose probability is close to 1 or 1 as if they are known with certainty i.e.  thresholding probability values if they are  beyond reasonable doubt . the result of this approximation is to allow logical reasoning instead of probability  because it is usually easier to use. many of the difficulties experienced by logicians in applying logic to the real world come from a failure to recognize that logic is only an approximation of probability. in particular   default logic  and  non-monotonic logic  are mainly concerned with belief revision when new  logically contradictory  evidence is found. while these logics are suitable for such things as theory completion  when one wishes to avoid  say  having to state all negative facts   they often attempt to force into a logical mold a type of reasoning that is not logical in nature. one standard example of default reasoning  all birds fly unless proved otherwise  should be  most birds fly   which can be used as a piece of evidence in evaluating the probability of the proposition  this bird flies'1  along with any other relevant evidence. 
　in probabilistic reasoning  different pieces of evidence are combined together to change the reasoner's measure of belief in a particular proposition a single line of reasoning  such as a logical proof  is not sufficient. in many cases  there is one piece of evidence  or line of reasoning  that dominates the final result  which is usually given as the  reason  for the result   if there is smoke  there is fire  . such reasoning resembles logical reasoning and is often mistaken for it  but its non-logical nature becomes clear when  contradictory  evidence is found. in probability  contradictions do not occur all the evidence is combined to get a final probability value  so there is no need to reject evidence  although evidence can be.used to reject hypotheses . practical reasoning is usually a complex combination of logical reasoning  discovering consequences  finding the possibilities  and probabilistic reasoning  evaluating the evidence1  weighting the possibilities . likewise  al should be using both methods where appropriate. 
1 	s u b j e c t i v e p r o b a b i l i t i e s 
an important topic on the border line between ai  especially expert systems   cognitive science  psychology and philosophy is that of subjective probabilities. given the above emphasis on probability being a measure of belief  it will come as no surprise that this paper advocates that subjective probabilities should be treated the same as any other probability  such as that from a measurement . however  there are a number of caveats that should be observed  particularly the observation  that people are poor estimators of probability largely because they are victims of many of the misconceptions noted above. rather than 
just accepting this situation  as the expert system community seem to  and try to work around it by better interviewing techniques and the like  the view advocated here is that we should aim for artificial intelligence. in particular  we should infer expert systems directly from data  as in    rather than filter the same information  badly  through an  expert  and accept whatever numbers he provides. anyone who has observed an expert giving probability estimates and then discovered he will later provide a completely different estimate  must begin to wonder about the quality of the results of such an expert system. 
　an artificial intelligence system that reasons under uncertainty will probably use many of the mental techniques that people use. one such technique is random sampling in the set of possible worlds  i.e.  the set of worlds that is consistent with current knowledge  to find the proportion of those worlds in which the predicate of interest is true  i.e.  estimate its probability . for example  if a robot is trying to estimate the probability that a person will enter the work area during a particular operation  it should use its current world knowledge to construct  randomly  scenarios in which the event happens and others in which it does not  then using the probability of these different scenarios  to form an estimate of the events' probability. in doing this construction  logic is used extensively. for example  if is unlikely that any person could reach the work area in the time available  then the event is unlikely. when people perform similar hypothetical reasoning  they are often biased by such things as the most recent relevant events- an artificial intelligent system should be designed to avoid such biases and estimate the required probability to the accuracy desired. 
　an artificially intelligent system for reasoning under uncertainty should be possible based only on the basic  laws  of probability-baye's theorem  additivity rule  multiplication rule etc.  and additional principles  such as  if there is no known causal connection between two events  then assume they are independent  causal closure   etc. in underconstrained situations  the principle of indifference  or maximum entropy  should be used to obtain the most unbiased value given the available information. no other representation or calculus is necessary for reasoning under uncertainty. this includes the problem of combining evidence from different sources  use bayes' theorem . note that use of bayes' theorem requires that the system keep track of the information that was used in computing conditional probabilities for belief maintenance  in a manner very similar to truth maintenance in logic. 
r e f e r e n c e s 
 l buchanan  b. g.  and e. h. shortliffe   rule-based expert systems   addison-wesley  p1  1. 
 1 charniak  e.   the bayesian basis of common sense medical diagnosis   proc. national conf. artificial intelligence  washington  pp 1  aug.  1. 
cheeseman  p. c   a method of computing generalised bayesian probability values for expert systems   proc. eight international conference on artificial intelligence  karlruhe  aug. 1  pp 1. 
cheeseman  p. c   learning expert systems from data   proc. workshop on principles of know ledge-based systems  denver  pp 1  dec. 1. 
cohen  p. r. and grinberg  m. r.   a theory of heuristic reasoning about uncertainty   ai magasim vol. 1 no  1  summer 1  pp 1. 
cox  r. t.   of inference and inquiry-an essay in inductive logic   in the maximum entropy formalism  ed. levine and tribus  m.i.t. press  1. 
p. cheeseman 1 
duda  r. o.  p. e. hart  and nils nilsson   subjective bayesian methods for rule-based inference systems''  afips conf. proc  national computer conf.  vol 1  new york  pp 1  1. 
 1 fine  t. l.   theories of probability   academic press inc.  1. 
garvey  t. d  j. d. lowrance  and m a . fischler   an inference technique for integrating knowledge form disparate sources   proc. 1th. international joint conf. a1 tificial intelligence  vancouver  pp 1  aug. 1. 
 hayes  p.   in defence of logic   proc. 1th. interna tional joint conf. artificial inteligence  m.i.t.  pp 1. aug. 1. 
 ll jaynes  e. t.   the well-posed problem   foundations of physics  1  pp 1  1. 
jaynes  e.t.   where do we stand on maximum entropy   in  the maximum entropy formalism   levine and tribus eds. m.i.t press 1. 
konoligc  k.   bayesian methods for updating probabilities   appendix d in  a computer based consultant for mineral exploration   sri report  sept. 1. 
lemmer  j. f.  and s. w. barth   efficient minimum information updating for bayesian inferencing in expert systems   proc. national conf. artificial intelligence  pittsburgh  pp 1  aug.  1. 
mcdermott  d. and j. doyle   non-monotonic logic i   artificial intelligence  vol. 1  nos. 1  pp 1  april 1. 
pearl  j.  and kim  j. h.   a computational model for causal and diagnostic reasoning in inference systems   proc. 1th. international conf. artificial intelligence  karlsruhe  pp 1  aug.  1. 
quinlan  j. r.   consistency and plausible reasoning   proc. international joint conference on artificial intelligence  karlsruhe  pp 1  august 1. 
rauch  h. e.   probability concepts for an expert system used for data fusion   ai magazine  vol. 1  no. 1  pp 1  fall 1. 
reiter  r.  and g. criscuolo   on interacting defaults   proc. 1th. international conf. artificial intelligence  vancouver  pp 1  aug. 1. 
 shafer  g.  a mathematical theory of evidence   princeton university press  princeton  n.j.  1. 
 1l tversky  a.  and kahneman  d.   judgement under uncertainty: heuristics and biases   science  1  pp 1  sept. 1. 
wallace  c.s. and boulton  d.m. ''an information measure for classification   computer journal  1  1  pp 1  1. 
zadeh  l. a.   possibility theory and soft data analysis   in mathematical frontiers of the social and policy sciences  ed. l. cobb and r. m. thrall  pp 1. 
