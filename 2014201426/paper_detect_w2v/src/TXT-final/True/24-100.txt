 
a genetic algorithm is used for learning qualitative model* baaed on the qsim formalism. hierarchical representation enables formation of  submodels  relevant for induction of domain explanation. daring the search for better coding of the candidates  in parallel with the search for better solutions  the sise and shape of candidate solutions are dynamically created. optimisation is based on the maximisation of the number of examples covered by a candidate solution combined with the minimisation of the number of constraints used in the solution. the result of learning is a set of models of different specificity that explain all given examples. an experiment in learning a qualitative model of the connected container system  utube  is described in detail. several solutions  equivalent to the original model  were discovered. 
1 	introduction 
qualitative models successfully provide domain knowledge for many qualitative reasoning tasks. it is also recognized  feigenbaum  1  that it is very difficult for a domain expert to articulate his  knowhow  into  say-how . often  a domain model is not even known. one way to avoid this knowledge acquisition bottleneck is to provide a number of examples  from which a qualitative model of the domain can be automatically induced by means of machine learning techniques. 
　　a method for learning qualitative models of dynamic systems from examples using genetic algorithms is presented. this approach has been named qualitative model evolution  qme . the problem  also known as system identification  is defined as follows: given examples and counter-examples of the system behavior  find a model that explains these examples. in this paper quantitative  i.e. numerical or differential equation  models are not considered. we are interested in qualitative models  where quantities are typically represented by a small set of qualitative values. among several alternatives the qsim formalism  kuipers  1  was chosen for the representation of qualitative models because of its firm mathematical basis. 
     learning is considered to be an instance of a combinatorial optimization problem  papadimitriou and steiglitz  1   i.e. a pair  f  c   where f is a finite or countably infinite set of feasible solutions and is a cost function. the task is to find an 
  such that  in our case  f is 
the set of all possible qsim models in the given problem domain and c f  is the number of examples correctly classified by the model / plus a bonus that decreases with the size of /. genetic algorithms provide a robust framework for performing such an optimization using darwinian principles of reproduction and  the survival of the fittest''. 
　　some work has been done on the automatic discovery of quantitative models but very little on the discovery of qualitative models of dynamic systems from examples. a brief description of some of the related approaches follows. 
　　abacus  falkenheimer  1  attempts to discover the best quantitative equation that describes a given set of numeric data in terms of addition  subtraction  multiplication and division. 
　　gen model  coiera  1  creates the most specific generalization  expressed in the qsim formalism  of examples. it initially generates the set of all constraints consistent with the first given example and then iteratively eliminates constraints that are inconsistent with the rest of the examples. 
bratko et al.  use golem  muggleton and 
feng  1  in a logic-based approach to find hypothesis 
h  given background knowledge b  the qsim theory  and examples e  such that  an advantage of this approach is that golem can introduce new variables into the model. 
　　in section 1 the qsim formalism will be briefly described. the connected container system will be presented in section 1. section 1 introduces genetic algorithms and section 1 describes our genetic algorithm that operates on populations of qsim-based models. experiments and the results obtained are described in section 1. 

1 	t h e q s i m f o r m a l i s m 1 	t h e u - t u b e a physical system is characterized by a set of physical parameters  which are continuously differentiable realvalued functions of time. in qsim  each of these parameters is represented by a function symbol. furthermore  the domain of each parameter has to be consider the two connected containers in figure 1. the two containers a and b are connected with a pipe and filled with liquid to the non-negative levels la and lb  respectively. let fab be the flow from a to b. this flow depends on the level difference dab: specified in the form of a  small  totally ordered set of symbolic values  referred to as landmarks. 
the current value of a parameter is stated in terms level derivatives in turn depend on fab: of its landmarks and the direction of change. the direction of change can be tnc  increasing   std  steady   or dec  decreasing . if a parameter p is equal to a and is increasing  this is written as p: a / tnc. if  on the other hand  p is between a and 1 and is increasing this can be stated as p: a...b / inc. each physical system state is represented by a list of values for all parameters in the system. 
　　a qsim model is a set of qualitative differential equations  where relations among different parameters are expressed as constraints  such as monotonicity and 
derivative. a list of corresponding values can be used to specify particular points of a relation. the repertoire of qsim consists of six types of constraints: figure 1: the u-tube system. 	dab  	together 	with 	the 
　　in the original kuipers' paper legal ranges of parameter values are not treated in terms of constraints but are part of operating region definitions. in order to simplify our approach  a uniform representation is used by introducing one additional constraint: constraint. 
1 	genetic algorithms 
genetic algorithms  ga  can be viewed as a general-　　　purpose search method  an optimization method  or a learning 	mechanism  	based 	loosely 	on 	darwinian principles of biological evolution: reproduction and  the survival 	of 	the 	fittest  	together 	with 	genetic 1 	late addition 

recombination  holland  1; goldberg  1 . 
　　gas maintain a set of candidate solutions called a population. candidate solutions are usually represented as binary strings of fixed length  called chromosomes . given a  random  initial population gas operate in cycles called generations: 
  each member of the population is evaluated using a fitness function. evaluations can be normalized  scaled or left unchanged. 
  the population undergoes reproduction in a number of iterations: 
* one or more parents are chosen stohastically  but strings with a higher value of fitness function have higher probability of contributing an offspring; 
* genetic operators  such as crossover and mutation  are applied to parents to produce offspring. 
  the offspring are inserted into the population. in some versions  the entire population is replaced in each cycle  while in others only a subset of the population is replaced. 
　　the crossover operator produces two offspring  new candidate solutions  by recombining the information from two parents  whereas the mutation operator prevents irreversible loss of certain patterns by introducing small random changes into chromosomes. it has been proved  holland  1  that mutation plays a decidedly secondary role in the operation of gas. 
　　a number of parameters can influence the algorithm  e.g. the size of the population  the size of the subpopulation replaced in each cycle  the probability of applying individual genetic operators  etc. 
　　superficially  it seems that gas only process individual strings present in the population  but  in fact  they implicitly process large amounts of similarity templates or schemata representing numerous similar individuals not actually present in the current population. this leads to the key-stone of genetic algorithm approach: highly fit  short schemata are propagated through generations  giving exponentially increasing number of samples to the best schema observed in the population  although the number of individuals in the population is constant . 
　　the effectiveness of a ga depends heavily on the chosen representation. substantial effort has been focused on this problem: how do we know that the schemata contained in a given coding will lead to the desired improvement  for this reason  operators that change the coding in a search for better ones have been devised  frantz  1; holland  1; goldberg and lingle  1 . 
1 	qualitative model evolution 
our goal is to find a qsim-based model that explains all given positive and negative examples. positive examples represent legal states of a physical system and negative examples represent its illegal states. two simplifying conditions were assumed in our experiments: 
1. all relevant physical parameters and landmark values must be known in advance. 
1. only models with empty lists of corresponding values are considered  except for the implicit pair  1  1  in  constraints . 
　　our ga operates on a population of qsim-based models. since the length of the solution is not known in advance  candidate models should vary in size. furthermore  the coding of models should enable meaningful schemata  building blocks  to emerge. for this purpose the usual string-based representation seems unnatural and limited. we have used a richer structure: binary trees  cramer  1; koza  1   where the leaves are qsim constraints and branching points establish the hierarchical structure. this coding is position-independent since the model represented by such a tree consists of all constraints that occur in the tree. 
　　the initial population consists of randomly created trees with uniform distribution of the number of leaves within the interval  1  l m a x  . the size of the subtrees is also  recursively  determined randomly. however  later during the search reproduction may yield trees with more than l m a x leaves. 
　　for our purpose genetic operators  crossover and mutation  had to be redefined in order to work on binary trees  cramer  1; koza  1 . crossover operates on two parental trees in the manner illustrated in figure 1. first  a node is selected uniformly at random in each parent and then the subtrees below the selected crossover points are exchanged  including crossover points   producing two offspring. mutation operates on a single parental tree. first  a node in the parent tree is selected uniformly at random. second  the subtree below the selected node is erased  including the selected point  and replaced by a randomly generated  sub tree. 
　　the learning process is considered to be a combinatorial optimization task based on the maximization of the number of examples covered by the candidate solution and on the minimization of the size of the candidate solution. the fitness value is calculated in three steps: 
1. raw fitness is determined  
1. raw fitness is shared among similar individuals  
1. shared fitness is scaled. 

figure 1: the crossover operator on trees 
 crossover points are marked  
step 1: 
　　let ep be the number of positive examples  en the number of negative examples   the number of 
positive examples covered by a tree t  i.e. consistent with the model represented by t   and  the number of negative examples covered by t  i.e. recognized as illegal states . furthermore  let l t  denote the size of a model represented by t. the raw fitness primarily reflects the model's ability to cover training examples since the size of the model affects fitness value only when the model covers all training examples: 
richardson  1 . 
　　the similarity function is defined for any two models to be the number of examples in which both models agree  they both either accept or reject the example . the degree of sharing s t  for a tree t is then determined by summing up the similarity function values contributed by models with the raw fitness value close to the fitness of t. during our experiments we considered six closest neighbors. the shared fitness is then calculated as: 

where ks is a user-defined parameter used to control the influence of sharing. 
step 1: 
　　shared fitness is finally scaled to prevent the early domination of extraordinary individuals  and to encourage competition among near equals later during the search. this is achieved through a linear transformation of shared fitness values. the coefficients are chosen to obtain: 

where fsaverage denotes the average shared fitness value in the population and  similarly   denotes the average scaled value.  is the maximal scaled value   is the final  scaled fitness value of a tree t  which is used to evaluate the population  i.e. for calculation of probabilities in the roulette wheel method for parental selection. 
extensive experimentation suggests that the highest 


　　the shares of covered positive and negative examples are normalized to equalize their influence. if a candidate solution covers all training examples it receives a nonnegative bonus b that decreases with the size of the solution. k is used to scale the contribution of the model size to the fitness value with respect to the contribution of training examples. throughout our experiments llim = 1   l m a x and k = 1 was used. these values were determined experimentally. 
step 1: 
　　to prevent early convergence of the individuals  and to permit the formation of subpopulations  species  of individuals with common characteristics that exploit different subsets of the domain  niches   raw fitness is shared among similar individuals  goldberg and 
1 	late addition 
performance is obtained when the values of numerical parameters  which affect the genetic search  lie within the following ranges: 
  the size of the population n1:  1  1   
  the fraction of the population replaced during each generation cycle n :  1  1   
  the upper limit on the number of leaves in randomly selected trees l m a x :  1  1   
  mutation rate p m :  1  1   
  crossover rate pc:  1  1   
  sharing factor ks:  1  1   and 
  scaling factor kc:  1  1 . 
　　however  the algorithm is robust and also gives reasonable results even for values outside the specified ranges. 
1 	experiments in learning u - t u b e 
u-tube results. 
until the first solution was found. this occurred in the 1th generation. then the search was continued for 1 more generations in order to enable other  better  
figure 1: maximal and average fitness values   x 1  
solutions to evolve. in the total of 1 generations 1 in the u-tube experiment candidate models were created and evaluated. 
　　five different  but similar  models  equivalent to the original  were discovered during this experiment  they all classify correctly all of the 1 finite states  not just the 1 training examples . these include the following two solutions: the domain specification for the u-tube system consists of four function symbols {la  lb  fab  fba} and their respective landmarks  as already described in the difference between the first solution  on the left  and the original one is in the m1  minus constraint that replaced the minus constraint. but within the context of the landmarks given  these two constraints are equivalent. the equivalence of the second model was proved by an exhaustive search over all finite states. 
　　closer inspection of the individuals present in the final population showed that certain small subtrees repeatedly appeared in good candidate solutions  e.g 
although we have not yet attempted to learn models from real world data  qme has been tested on some other small domains. results for simple-spring  resistor-and-capacitor-circuit and p-controller experiments are presented in table 1 together with the figure 1: the number of solutions in the u-tube experiment 
   the number of possible finite states and the number of legal states reflect the complexity of a domain. table 1 also shows the number of positive and negative training examples used in experiments together with the sizes of target models  which were used to generate training examples  and those of induced solutions. in addition  the number of candidate solutions generated during the search  and the fraction of finite states incorrectly classified by the solution are presented. 
table 1: qme's performance in four test domains 
　　qme was always able to find a model that covers all training examples. during the search only a moderate number of candidates was generated. for the simple-spring model a solution identical to the original model was discovered. on the other hand  solutions to the two larger problems were too general and incorrectly recognized a small fraction of illegal finite states as legal ones. the main difficulty is that the large majority of states in these domains is illegal and must be eliminated  while still leaving the sparsely spread legal states. 
1 	discussion 
a genetic algorithm for learning qualitative models based on the qsim formalism has been presented. the learning task was considered to be a combinatorial optimization problem based on the maximization of the number of examples covered by a candidate solution and on the minimization of the size of the candidate solution. 
　　we tested our approach on the induction of a model of the u-tube system. learning resulted in a set of models of different specificity and size that explain all given examples. several solutions equivalent to the original model were discovered as well as more general models and more specific ones. 
　　coiera  reported that genmodel found an overconstrained model of the behavior of the bathtub system  similar to the u-tube system . however  a model equivalent to the original was not discovered. when applied to the u-tube domain genmodel  given only six positive examples  produced a model consisting of 1 constraints. on the other hand  in the experiments performed by bratko et al.   golem induced a u-tube model that is equivalent to the original only in the dynamic sense. given a legal initial state  this model produces exactly the same behavior as does the original model. however  its decision about legality of several states is inconsistent with the decision of the original model. 
　　background knowledge can be easily incorporated by introducing suitable ''building blocks  into the initial population. we plan to extend our method with the ability of considering corresponding values and introducing new function symbols into the induced models. we also intend to use a meta genetic search to tune relevant numerical parameters. 
