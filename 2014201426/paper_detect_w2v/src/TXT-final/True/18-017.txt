 
     the present paper discusses the extensions to the parsing strategies adopted for fido  a flexible interface for database operations . the parser is able to deal with ill-formed inputs  syntactically i l l - formed sentences  fragments  conjunctions  
etc.  because of the strict cooperation among syntax and semantics. the syntactic knowledge is represented by means of packets of condition-action rules associated with syntactic categories. the non-determinism is mainly handled by means of rules which restructure the parse tree  called  natural changes   so that the use of backtracking is strongly limited. 
     in order to deal with difficult cases in which no clear-cut mechanism exists for excluding an interpretation  a weighting mechanism has been added to the parser so that it is possible to explore few different hypotheses in parallel and to choose the best one on the basis of complex 
interaction among syntax and semantics. 
introduction 
     if one considers the evolution of computerized natural language understanding systems  charniak  1   it becomes apparent that the role of syntactic knowledge can vary from being the basis of the process to being completely neglected. in the first case  the conversion form a linear sequence of 
words to a corresponding structured representation  parse tree  is guided only by the syntactic knowledge  whereas the other knowledge sources  mainly semantics  have the task to translate the parse tree into a meaning representation; within the other approach the understanding process is viewed as a whole and no special role is played by syntactic knowledge  given that such a knowledge is assumed to exist . 
     as regards purely semantic approaches  they present some problems with respect to the perspicuity of the model. in particular  the structural information  e.g. the fact that in english the adjectives precede the noun necessarily  whilst in italian they do not  has to be duplicated for the different entities or represented in procedural form within the analysis program. since we believe that structural information is fundamental in the 
analysis process  and that its explicit representation increases the understandability  and the modifiability  of the systems  we will take in the following the opposite view  trying to start from syntactic approaches and to justify the increasing role of semantics within them. 
     the aim of this introduction is to discuss how the semantics can be used to increase the effectiveness of n.l. analysis. in particular  three points will be set forth: 
- from the point of view of efficiency of processing  the grammar-based approaches have to use semantic information as soon as possible 
- the human ability to understand ill-formed fragments suggests to reduce the predominance of syntactic knowledge and  again  to use more heavily semantic information 
- the phenomenon of garden paths shows that two different modes of operation exist: normal and backup. however  purely syntactic approaches fail to account for the phenomenon in a perspicuous 
way. 
     if we consider a grammar only from the point of view of expressive power  of course we can  after a thorough analysis of the phenomena occurring in natural language use  hope to find a grammar that characterizes all and only the sequences of words that constitute  acceptable  sentences. the study of the required power of n.l. grammars received considerable attention in the past  for a recent and thorough overview see  pullum  1 ; some prominent positions are described in  perrault  1  . 
     however  it has often pointed out that a comprehensive  and useful  n.l. understanding system should also take into account higher-level problems; in particular  it should also provide the researcher with some insights about the relationships existing between syntactic structures and semantic interpretation. 
     most classical studies  both within the field of formal languages and within the field of natural languages viewed the semantic interpretation as a 
     process  appended  to the syntactic analysis. it is widely accepted that this way of using semantics is highly inefficient: the number of alternative 
parses is often so high  especially when prepositional phrases are present   that it is not cost effective to delay the intervention of semantics  sagalowicz  1 ; on the contrary  it is preferable to use semantics both as a meaningconstruction process and as a source of further constraints for the analysis  as soon as possible during the analysis itself  woods  1 . 
     however  some other problems deserve attention. the first of them concerns the idea of  correctness  that  as stated above  is at the basis of the grammar-based approach. it is well known that in most cases  humans are able to understand the 'meaning of sentence fragments that are 

syntactically ill-formed without any apparent difficulty. it's worth observing that the locution  ill-formed sentences  does not refer: exclusively to sentences that can reasonably be rejected on syntactic grounds. for example  the existence of a conjunction  huang  1  can result in a sentence fragment that is ill-formed  although the entire sentence must be considered correct under any plausible definition of syntactic correctness. ihe problem of parsing ill-formed inputs has become very popular recently; a number of papers appeared in a special issue of the acl journal  ajcl  1 . it must be noted that the approaches can be roughly categorized in two classes: extensions of grammatical formalisms and semantic-based analyzers. as stated above  we will not discuss here the semantic approaches; as regards the other ones  we can say that an extension of a grammatical formalism lends itself rather well to the relaxation o¡ê some syn-
tactic constraints  e.g. number agreement   less well to others  e.g. the absence of a required constituent  and meets big difficulties in handling ordering problems  out of order constituents . this is obviously due to the fact that formal grammars have the task of describing  strings  of symbols  i.e. objects where the order is fundamental. it is not sufficiently proved that in natural language sentences  in their aspect of information conveying tools  the order of constituents is as fundamental. this observation leads to a last remark: in languages where the order is not as strict as in english  almost free word-order languages as italian or japanese  grammars that are not based on the common concept of rewrite rules  mainly related with case systems  are receiving greater and greater attention  nitta et a l .   1; sakamoto et a l .   1 . 
     another problem that should be mentioned is based on psychological motivations. although this paper is not intended to present a psychologically valid model of natural language processing  we believe that some well known phenomena cannot be disregarded  because they help in making more clear what should  or should not  happen in a n.l. analyzer. the phenomenon we will consider here is that of garden paths. it gives a hint about the existence of two processing modes in the interpretation of a sentence: normal analysis and backup. at first sight;.  this remark confirms the adoption of: standard  run-deterministic parsing methods  where backtracking is a usual technique - on the other hand  the number of times a normal atn parser  to consider a well known tool  backtracks is not justified by the relative rarity of garden paths. the efforts in the development of deterministic parsing  marcus  1  tried to characterize the normal processing mode  by stating that parsifal would fail to analyze a sentence in cases where a person would garden path. however  it has been shown  milne  1  that the three-constituentbuffer approach adopted by marcus does not predict with sufficient accuracy the occurrence of garden paths. again this can be seen as a failure of approaches based only on syntactic knowledge  a grammar-based one - atn - and a rule-based one parsifal  to account for a linguistic phenomenon: the solution should be looked for in a more effective cooperation between syntax and semantics. 
	it is not possible to close this 	introduction 
l. lesmo and p. torasso 1 
without qoiting a recent papers  wnich addresses some of the problems mentioned above in a tnorough way. in  schubert  1  the section 1 deserves attention. it is entitled  lack of provision for integration with semantic/pragmatic preference principles . what is shown in the paper is that human reaction to sentences that have exactly the same syntactic structure may vary considerably depending on the semantics of occurring words. although the analysis is carried on in a way different from ours  the concept of  potential  us a 
means to balance the syntactic and semantic 	information 	is 	similar to our weighting of alternative hypotheses. 
     another work closely relates with the present one is reported in  pazzani  1 . in that case also  the need of a strict cooperation between syntax and semantics is explicitly acknowledged. on trie otrier hand it seems that the absence of a weighting mechanism could make the lazy parser fail in some cases wnere no clear-cut choice is possible. 
     in tne second section of the present  paper we will describe the structure of tne syntactic processor induced in the fido system. although the system  which is fully implemented in franz lisp on a vax 1 computer  does not nandle all trie phenomena discussed in this introduction  tne presentation will allow us to clarify trie basic operating principles  in order to describe in the third section the extensions of the parser we are currently implementing. 
syntactic analysis if iii fido 
     fido  a flexible interface for database operations  is a prototype! 1 system that allows tne user to access in n.l.  italian  the data stored in a relational database. after a previous approach to building natural language interfaces  lesmo  magna ru   'torasso 1    we realized that one of the main concerns nad to be to guarantee the portability of the system; this was achieved by adopting a strongly modular approach. some efforts have been made to develop efficient methods to store semantic information  lesmo  siklossy  torasso 1  and to 
optimize the resulting query  expressed in relational algebra  lesmo  siklossy  torasso 1 . the organization of tne parser was described in  lesmo  torasso 1  and its suitability to the analysis of ill-formeel sentences in  lesmo  torasso 1  ; in particular  the extensions introduced to deal with conjunctions are decribed in  lesmo & torasso  1 . we will overview here the basic design choices. 
     ihe syntactic knowledge source is composed of a set of condition-action rules  where the condition examines the current status of the analysis  i.e. the parse tree that has already been built  
whereas the action extends in some way the parse tree  hypothesizing the attachment point and the syntactic role oi a new constituent. the parse tree is built according to the head and modifier 
approach and an example is reported in f i g . l . 
     six node types have been defined; each node label in fig.l has the form typei: the node labelled xxj is the j-th instance of the type xx that has been built during the analysis. tne types 

1 l. lesmo and p. torasso 
appearing in the figure are: rel  standing for relation  normally associated with verbs ; ref  refercnts: nouns and pronouns ; oonn  connectors  mainly for prepositions; it can happen that the f i l l e r of the node is unmarked: it means that the 
corresponding verb case is not marked by a preposition  ; det  mainly deturminers . the other node types are adj  adjectives  and mod  modifiers  e.g. adverbs . 
     the syntactic rules are grouped in packets associated with syntactic categories. when an input word is syntactically ambiguous  different packets are activated and a l l conditions are tested. if just one of them succeeds  then the action is exe-
cuted and the analysis goes on deterministically. otherwise  the status of the analysis is saved to allow for possible backups in a subsequent phase  ana the first action is executed  the different rules are ordered manually  . facilities are provided in the lexicon to handle canned phrases  e.g.  di corsa  - on the run  and compound words  e.g.  dammelo  - give it to me . it must be noted that some conditions require a lookahead  1 words maximum  ; this is done in order to increase the discriminating power of the conditions and to reduce the number of choice points. 
     in order to give an idea of the control structure of the analysis  let us see what happens when the f i r s t word of the example in f i g . l is found  we must stress again tnat fido works on commands in italian: we w i l l go on with english examples in order to increase the readability of the paper. in italian the most direct translation of  which  is 
 quale   though its use differs slightly when it is used as a relative pronoun . 
     there are three different lexical entries for  which   each of which is associated with a different syntactic category: qadj  interrogative 
adjective   qpron  interrogative pronoun   and relpron  relative pronoun . the analysis begins with an empty rel node  rell  as current node. roughly speaking  all conditions of qadj rules require that the next word is an adjective or a noun  the qpron rules apply in the remaining cases  whereas the relpron rules can be activated just in case a previous ref node can be used as an attachment point for the relative clause. in our case the qadj interpretation is selected and  among the rules of the packet  the one is chosen that applies when the current node is an empty rel node. that rule builds a conn node  and f i l l s it with unmarked    a ref node  and leaves it empty  and a det node  and f i l l s it with the current word  i.e.  which  . the resulting structure is shown in fig.1. then  the controller of the parsing process is awaken; it looks for another word and finds it in the lookahead buffer  it was used to discriminate between qadj and qpron . the noun packet is activated and a rule is selected  which f i l l s the empty ref  refl  with  course . we leave at this point the example  assuming that it gave an idea about how he analysis of a sentence is carried on. 
     instead  some more specific points have to be made clear. the nodes in the figures have been represented very sketchily. each node is actually a complex data structure  with various slots and some procedures attached to the prototype. for example  a rel node includes slots as head  the verb    form  active vs. passive   tense  number  mood  indicative  conjunctive  etc.   roles  the case frame  and others. notice that the slot aux indicates the presence of an auxiliary verb in the sentence. the actual form of the auxiliary is not reported since it can be inferred by taking into account the values of mood  form  tense  etc. the associated procedures are called relheadproc  operations to be done when the head slot is f i l l e d   e.g. computing the tense of the verb    relagreeproc  checking the number agreement with the subject    and relsepr1c  checking the acceptability of the actual case frame and beginning to build the semantic interpretation  . when a node is operated upon  one or more procedures can be scheduled for execution. they can accept or reject the operations done by the parser 
 syntactic hypothesis  . a simple way to make the parser more robust is to relax some of the constraints embodied in the procedures. for instance  an agreement failure can produce just a warning message  without requesting a reorganization of the parse tree  a reorganization which is always attempted in case of semantic failure. such relaxation techniques can also be introduced in other formalisms  such as atn  kwasny & sondheimer  1 . more interesting  the proposed formalism handles easily also ordering errors. in fact  the attachment of cases to verbs and of adjectives to adjectives 

when the node is closed  a node is closed  i.e. it is considered to be complete  when an attachment is proposed to a node above it in the tree  the checkorder procedure verifies that the rules which govern the ordering of constituents are respected. also in this case  a failure of checkorder results in the issuing of a warning message  without any 
reorganization of the parse tree. 
it has probably been noted the use of the term 
 reorganization of the tree  in the discussion above. in fact  such modifications  that we call  natural changes  to point out their simplicity and naturalness  are the primary tool for handling non-determinism. the brief presentation of the structure building rules failed probably to make clear one important point: when the action part of a rule is executed  it usually adds a subtree to the current tree; the attachment point of the new subtree is the nearest node of the required type that is above the current node. of course  this choice is made only on syntactic grounds  so it may happen that it is not acceptable from a semantic point of view. in a standard atn framework  this problem is solved backtracking: the subnets allowing  for example  pp modifiers include an implicit choice point  in correspondence with the position where a pp could be present or absent  and a semantic failure would involve backing up to such a previous choice point. although the introduction of some special tools  of the kind of well-formed substring tables or chart parsers  allows the system to avoid the re-analysis of the pp component  some bookkeeping is needed to save the status of the analysis at the choice points. the natural changes mecnanism makes that work useless  in that the choice points are implicitly available in the structure of tne parse tree and can be easily looked for by the modification rules. a further advantage is the high flexibility of the tool: the natural changes are expressed in the form of pattern-action rules  as the standard rules  so that  in principle  an action could restructure the tree in a very complex way. in fact  we use them also to handle some problems related with the analysis of conjunctions  lesmo & torasso  1  and with some special forms of relative clauses. tvs often happens  the natural changes are actually too powerful; at this time we have not pursued the study of what are the reasonable constraints that must be put on tne operations of the changes. we want to stress  however  that the introduction of the natural changes does not substitute the backup completely: this remark is in agreement with the discussion about the existence of different processing modes in the analysis of n.l. sentences. although we are not able to state now the correspondence between the use of backup and the occurrence of garden paths  we can notice that the saving of the status is limited  in most cases  to syntactically ambiguous words such that more than one syntactic category is acceptable in the current context: this strongly reduces the number of choice points  as predicted by the garden path phenomenon. 
extensions to the parser 
     before going on we have to make clear an important point: whereas the parser embodied in 
l. lesmo and p. torasso 1 
fido works on italian sentences  in order to perform the tests that led to the version described in this section  we had to develop a small set of rules for english. the reason why we did this was to have at disposal a wide corpus of thoroughly analyzed examples  i.e. the ones appearing in the referenced papers by milne and schubert . this approach to testing has both an advantage and a disadvantage: the adaptability of the parser to a different language is partially demonstrated  but the number of syntactic phenomena that has been taken into account in building the english rules is not very high  so that some ad-hoc solutions could have been adopted. 
     we can now start by seeing what happens when syntactically ambiguous sentences are processed by fido  old version . a first example is drawn from schubert's paper: 
 1  john bought the book which 1 had 	selected 	for mary 
after the analysis of the first portion of the sentence  as far as the word  selected   the status of the tree is the one of fig.1. upon encountering the preposition  for   a rule would propose its attachment  in a conn node  to the node rel1  i.e. as a verb modifier . the subsequent attachment of a ref node  containing  mary   to the newly created connector would trigger the semantic check procedures  which give a positive  answer  case frame: to select; sobj: person  obj: thing  fdr: person  and allows the system to confirm the proposed analysis. on the contrary  in the example below: 
 1  john bought  the book which i had selected at a lower price 
after a sequence of steps analogous to tne one described above  extended to handle the determiner and the adjective   the semantics would reject the syntactic hypothesis. the natural changes would be triggered  the attachment of tne pp to  book  would be tried and again rejected on semantic bases. finally  the attempt to attach  at a low price  to  buy  succeeds and the analysis is completed. 
     it is apparent that this process does not work in cases such as: 


1 l. lesmo and p. torasso 


soon as an attachment is proposed. the natural changes have been modified in a simple way: no detachment is made  but the different alternatives are added to the proposed one  note that this is just a first  low-cost solution: what we are studying now is the possibility to eliminate tiie natural changes mechanism; this can be done if all attachment points can be found at a glance by tne linking procedures . 
     as regards the second choice  when should the final decision be- taken     we decided to distin-
guish again the sources of ambiguity described above. the reason why different solutions were reasonable stood in the different computational cost of carrying on alternatives: whereas the rule ambiguity seemed to require a real maintenance of different trees  the role  attachment  ambiguity implied only that different links are included in the same tree. in the first case  after trying different alternatives  no lookahead  one-word lookaneacl  just tne lookahead required by tne conditions  we had the pleasant surprise that in most cases the different states had not to be maintained. in fact  the only thing we had to do was to defer the decision about tne rule1 to apply after the execution of the semantic check procedures: they provide*! the parser with the information about tne semantic preferences that was lacking in the previous version of tne system. as regards the role ambiguity  we let the analysis go on until tne filler of the node which is the root of the attached subtree has been found: this means that we wait until the semantic checks can be done. for example  if sentence  1  were changed into: 
 1  john bougnt the book tnat 1 selected for the nice blond-haired girl that you know 
then the choice would be delayed until the word  girl  is found. 
     note that in both cases  though the behavior of the parser is different  the parser pursues different paths until the system allows the semantics to provide it with some evidence about the most reasonable caoice. 
     finally  the third problem concerns the knowledge sources involved in the weighting process. apparently  we had to attach cd's to lexical entries  syntactic rules  and semantic information. on the otiier hand  the semantic information  which in fido consists in a semantic net representing the selectional restrictions  see  lesmo  siklossy  torasso 1   overcomes the information that could be attached to lexical entries. in fact  the choice is made on the basis of the possibility of attachment of a pair of  concepts : this provides the system with more detailed information than the 
possibility of occurrence of a single interpretation. that is  if the system knows that cd  to rock  subj: table  = o.1 and cd  rock  modif:table  
= . 1   cd  to rock  subj:granite  = 1 and cd  rock  modif .-granite  = 1  it can disregard the fact that cd  to rock icat:verbj  = 1 and cd  rock icat:noun   = 1. the solution we adopted is to associate with tne arcs appearing in the semantic net a cd expressing the preference of the system. it is not possible here to discuss the details of the implementation  actually  not all arcs have a cd   because such a discussion would 
l. lesmo and p. torasso 1 
require a description of the semantic net. it must be noted  however  that this solution requires the explicit introduction of all possible semantic connections. this is consistent with a database interface  because tne associations carry the information about the correspondence with the database scnema. in a general n.l. understanding system this is quite expensive and some way to propagate the cd's according to the degree of match with the declared selectional restrictions snould be included in the system. 
     as regards the syntactic knowledge source  we attached cd's to the structure building rules ano we decided to compute tne cd's of the attachment points on the basis of their distance  number of nodes to traverse  from tne  current  node. in particular  the current node is assigned a cd equal to 1 and  for each node that is traversed to fine an alternative  the cd is decreased by a constant factor  currently 1 . apart from this latter  all cd's  both in the net and in the rules  have been assigned manually. this allowed the system to succeed on a wide set of examples; of course  a less heuristic determination of cd values would be 
useful  but it requires a large research effort per 
conclusions 
     as winograd states in  winograd  1   the research on n.l. understanding is being carried on today within a new paradigm: the computetional paradigm. its main differences with respect to the previous  generative  one  stands in the  attention to process organization  and the  relevance of non-linguistic knowledge . 
     it is not the aim of this paper to take into account all the problems that non-linguistic knowledge conveys into n.l. analysis  out to make clear that the in-depth understanding of the respective roles of syntactic and semantic knowledge sources and the clarification of the way they interact to construct the interpretation of natural language sentences is fundamental to building n.l. interpreters  we claim tnat neither syntax nor semantics can be assigned the role of  guide  of the interpretation process  but they must operate on a parity basis. both of them provide the analyzer with information about trie choices that must be made during the interpretation . 
     the approach outlined in the paper is just a first attempt to satisfy these principles: many problems must be examined and some substantial changes can be introduced  but we maintain the fundamental role of the  rule  concept in tne construction of n.l. analyzers and the necessity of being able to weight the contributions of different knowledge sources: the interpretation is not a 
     categorical  yes/no  process  but it must be based on the idea of preference  wilks  1   or subjective evidence . 
     the paper shows how a rule-based approach has been modified to take into account both syntactic and semantic preferences  we hope  to have given a feeling about the ease with which the required 
modifications were embodied in the previous system. the available 	space did not allow us to consider 

1 l. lesmo and p. torasso 
same  obier phenomena that fido is able to handle quite easily: they concern the analysis of i n formed sentences. although many aspects of i l l formedness were already handled by the old version of the system  the introduction of cd's and the modifications of the natural changes are useful also to characterize in a more perspicuous way the analysis of conjunctions: also in this case  the cd's are used to compare the different alternatives regarding the role the second conjunct can assume.  l.lesmo  p.'iorasso: interpreting syntactically ill-formed sentences. proc. coling 1  stanford  1   1. 
 l.lesmo  p.torasso: analysis of conjunctions in a rule-based parser. proc. 1rd acl meeting  chicago  1 . 
 r.w.milne: predicting garden path sentences. cognitive science 1  1  1;:. . 
references  a.a.v.v.: special issue on ill-formed parsing  ajcl 1  no.1  1 . 
 e.charniak: six topics in search of a 	parser. 
proc. 1th ijca1   vancouver  1  1.  y.nitta et a l . : a proper treatment of syntax and semantics in machine translation. proc. coling 1  stanford  1   1. 
 m.j.pazzani: conceptual analysis of gardenpath sentences. proc. coling 1  stanford  1   1.  x.huang: dealing with conjunction in a machine translation environment. proc. coling 1  stanford  1   1.  c.r.perrault  ed. : special issue on mathematical properties of grammatical formalisms. 
computational linguistics 1  1   1.  s.c.kwasny  n.k.sondheimer: relaxation teonriiques for parsing grammatically ill-formed input in natural language understanding. ajcl 1  1   1. 
 l.lesmo  d.magnani  p.torasso: a deterministic 
.analyzer for the interpretation of natural language commands. proc. 1th ijcai  vancouver  1   1. 
 l.lesmo  l.saitta  p.torasso: evidence combination in expert systems. int. j. of manmachine studios  vo1  1 . 
 l.lesmo  l.siklossy  p.'iorasso: a two level net for integrating selectional restrictions and semantic knowledge. proc. ieee int. conf. on systems  man and cybernetics  india  1   1. 
 l.lesmo  l.siklossy  p.torasso: semantic and pragmatic processing in fido: a flexible 
 interface for database operations. information systems 1  n.1  1 .  g.k.pullum: syntactic and semantic parsability. proc. coling 1  stanford  1   1-
1. 
 y.sakamoto et a l . : lexical features for japanese syntactic analysis in mu-project-je. proc. coling 1  stanford  1   1. 
 d.sagalowicz: mechanical intelligence: research and applications. final teen. report  sri int.  menlo park  december 1 . 
 l.k.schubert: on parsing p