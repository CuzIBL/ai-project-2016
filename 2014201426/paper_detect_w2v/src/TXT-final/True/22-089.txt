 
this paper is a study on the process of evolution of a novice to an expert in a diagnostic context. in this paper  we have chosen an abstract example of a diagnostic problem. the results in this article are based on a longitudinal study of a single subject. the empirical base is a protocol of the subject as he solved this problem until he mastered the most sophisticated strategy. based on an analysis of the protocol  we have identified four different strategies that were used by the subject to solve the given set of problems. these strategies vary in their efficiency of diagnosis and in their modes of reasoning. we also identify the different operators that were used by the subject to transform one strategy into a more efficient one. the learning process has been implemented as a computer simulation. finally  we discuss the hypotheses that are suggested by this experiment and the implications of our observations. 
1 introduction 
a complex problem-solving task generally allows for many different strategies  all of which could potentially lead to a solution. however  all the strategies are not equivalent. they differ in terms of their efficiency in arriving at the solution  the cognitive load they place on the problemsolver and the generality with which they can be transformed to other problems. for someone encountering a task for the first time  some strategies might become apparent immediately and others become apparent more slowly as the problem-solver becomes familiar with the task. the process by which a person who begins a task with  obvious  strategies  graduates to more efficient strategies with increasing familiarity is what we call learning or skill acquisition1. 
　in this paper  we are interested in understanding this process for a class of problem-solving tasks called diagnosis. more specifically we focus our attention to diagnosis of machines. intuitively machines are defined as devices designed to fulfill a function. if such a device produces aberrant behavior  we are interested in identifying that part of the device which is responsible for such behavior. typically  diagnosis begins with a model of the device and a set of symptoms indicative of aberrant behavior. this model is 
this research was funded by nsf grant 1ri-1 
eswaran subrahmanian 
engineering design research center 
carnegie mellon university pittsburgh  pa 1 
a description of the structure and behavior of the device. given this information  there are many strategies available for diagnostic problem-solving. we are interested in the learning process that occurs in this problem domain. 
1 the learning task 
in this paper  we have chosen an abstract example of a diagnostic problem. although this example is limited in some of it's assumptions  it is general enough to be applicable to a wide variety of diagnostic problems. the results in this article are based on a longitudinal study of a single subject. the empirical base is a protocol of the subject as he solved this problem until he mastered the most sophisticated strategy. based on an analysis of the protocol  ericsson and simon  1   we have identified four different strategies that were used by the subject to solve the given set of problems. these strategies vary in their efficiency of diagnosis and in their modes of reasoning. we also analyze the protocols to identify the different operators that were used by the subject to transform one strategy into a more efficient one. 
　we have characterized each strategy in terms of productions in an effort to indicate how it could be simulated on a computer. similarly  we characterize the learning operators based on the cues used by the subject to provide an account of the transformation of a strategy to a more efficient one. 
1 method 
the experiment was carried out in two sessions. the first session lasted about 1 minutes and the second one lasted about 1 minutes. the subject is an adult male  a graduate student at the business school at carnegie mellon. the subject was familiar with networks and their analysis prior to the experiment although he was not familiar with the particular set of problems that were posed to him. each session consisted of solving eight problems. the network for each problem is identical but the set of observed symptoms are different. 
　the subjected was instructed to think aloud while solving the problems. the protocol of his verbalizations were recorded on tape and later transcribed. the instructions for the problems were as follows: 
 the task involves fault diagnosis of graphically displayed networks. these networks operate as follows. each component has a random number of inputs. 
similarly a random number of outputs emanate from each component. components are devices that produce either a 1 or 1. an output of 1 denotes an acceptable output; 1 denotes an unacceptable output. all outputs emanating from a component carry the value produced by that component. 

a component will produce a 1 if: 
1. all inputs to the component carry values of 1 and 
1. the component has not failed 
if a component fails  it will produce values of 1 on all outputs emanating from it. 
　a problem begins with the display of a network with the outputs indicated  refer to figure 1 for an example . based on this evidence you are asked to identify the failed component. in order to perform this task you are allowed to test connections between components but minimize the number of measurements you perform. keep in mind that only one failed component can explain the given set of readings. 

figure 1: a network of components  rouse and hunt  1  
each session consisted of solving eight problems. as stated in the instructions  the network for each problem is identical but the set of observed symptoms are different 
   unlike in physics problems we do not have available  for this task  any characterizations of the expert and novice behavior. therefore we need a measure to compare the performance of novices and experts. since for this particular task  we indicated that expertise is understood in terms of problem solving efficiency  we propose to use the number of measurements as a metric for comparing performance. the cost of of all measurements have been assumed to be equal. the network problems of the size we use can be solved for optimal solutions. we shall measure the performance on a given task in relation to the optimal possible performance. 
1 results 
the protocol consists of a total of 1 statements divided into two sessions. in this paper  the set of eight problems in each of the two sessions are numbered pi - pi1. problems pi through p1 belong to session 1  and p1 through p1 to session 1. the first session consists of 1 statements and the second 1 statements. session 1 contains 1 statements about measurements between connections  1 pertaining to reasoning to identify the next component or set of components that could be faulty  1 metastatements about strategy  1 verifications of faults  and the rest are observations and conjectures; session 1 contains 1 measurements of connections  1 pertaining to reasoning to identify the next component or set of components that could be faulty  1 metastatements about strategy  and the rest are observations  explanations and conjectures. 
　the protocols for both the sessions are explicit enough to leave no doubt about the strategy that is being used by the subject at any given moment however  the protocols are not sufficiently complete as to identify how the subject acquired or used information to transform his strategy. this lack of explicit evidence for the process of adaptation is also reported by  anzai and simon  1 . the rest of the analysis is based on the four strategies developed by the subject to solve the problems. 
1 depth-first strategy 
the strategy that the subject used pi - p1  except p1 is what we call the depth-first strategy. from the problem definition the subject hypothesized correctly that a faulty component has all inputs as 1 and all outputs as 1. the search for a faulty component was not random. he chose the first 1  from the top  for a given set of outputs and checked for it's inputs. if one of the inputs was a 1  then he concluded two things:  a  the component under consideration is not faulty and  b  the faulty component could be traced to the component whose corresponding output was 1 or a component before that. this strategy always leads to the solution and restricts the search to one component at any step. at each step  through extensive testing only those components with output 1 are explored. however  this strategy is non optimal in the number of measurements performed. for example  problem 1 p1  in session 1 required 1 measurements  whereas optimally it can be solved with atmost 1 measurements. 
　while solving each of these problems  the subject verified his result by tracing the outputs of the faulty component to the 1 outputs at the terminal nodes. for example in p1 he traces the output of the faulty component  1  to all the terminal nodes with 1 outputs  1  1  1  1  1 . we present a section of his protocol to illustrate this: 
1.s:there are no inputs into 1  then 1 is at fault! 
1.s:that should explain all the other zeroes  let's see  1 has output 1  it that a 1  yes  1:s:1to1 fa1  
1.s:1 to 1  a1  
1.s:1 to 1 must be a 1  and 1 to 1 must be a zero and 1 to 1 must be a 1.s;okay 1 is at fault! 
　from solving this set of problems the subject retained two pieces of information in the long-term memory. these are:  a  a faulty component has all inputs as 1 and outputs as 1  and  b the outputs from a faulty component can be ultimately traced to the 1 outputs at the terminal components. 
　in figure 1  we provide a set of productions which can simulate this strategy1. 
　in enumerating the productions  we have assumed that we have a structural description of the network available. this 
　1we enumerate only those productions which are vital for explicating each strategy 

implies that for any given node: 
  all the predecessor and successor nodes can be generated. hence functions like find-inputs are capable of generating all nodes which have inputs to a given node. similarly  the nodes connected to the outputs of a given node are available and hence functions like trace-output can apply recursively to find paths from a given node to the terminal nodes. these functions have not been described here. 
  the value of the connections between any two nodes can also be checked. functions like input and output can check if the value of the output from a node  or the values on the input of the node are 1 or unknown. 
from the definition of the productions  the reader can verify that this executes the depth-first strategy. 
1 refined depth-first search 
the strategy used during this episode is what we call the refined depth-first strategy. this strategy was used for only problems p1  p1  p1 and p1. this indicates that the subject remembered this strategy in his long-term memory which he was able to recall later. 
　this strategy is similar to the depth-first strategy in that the subject begins the search from the first component with output 1  from top  refer to figure 1 . for this component he identifies all the inputs and their corresponding components. at this point  he departs from depth-first. instead of measuring each input  he picks one component at a time  generally top to bottom  and traces the output of that component to all the terminal nodes. if none of the components have outputs that trace to all the terminal 1s  then he picks the first component and generates all the inputs. the same procedure is continued. however  when a component is identified whose output traces to all the 1s  then he measures the inputs and the outputs to verify that the component is faulty. when the above strategy is followed it always leads to the correct solution and even though the number of measurements is less than the  depth-first strategy   they are not minimized. 
the subject first used this strategy for p1 and then for p1. 
in both these problems all the terminal nodes are 1  which prompted him to remember at each step  that any component under consideration has to ultimately explain all the terminal 1s. he also used this strategy for p1  p1. he clearly states this strategy while solving p1:  so basically my strategy is to locate that node from where there are paths to all five  terminal 1s  ... . 
the main piece of information retained in this stage is a 
1 	cognitive models 
perceptual one. as the subject traced the outputs of suspected candidate  he discovered visually that a path from a given node to a terminal node is equivalent to a path from a terminal node to a given node in the network. the productions for this strategy are shown in figure 1. 

　the productions in figure 1 similar to the one's for depthfirst. the production rl is common to all strategies. for each strategy the productions that are presented are replacements of the productions with the same number in the previous strategy. for example  the production r1 in the  refined depth-first  is intended as a replacement of r1 in the  depth-first . the function generate-suspect-list provides a list of components which feed inputs into a given node. this list is called  suspect-list . the function trace-output is the same as before. if it succeeds for any node on the suspect-list it is returned as a  suspected-faultynode  else it returns the first node on the  suspect-list  which triggers r1 to recurse. once the suspect is isolated  r1 triggers measurements. 
　the control structure for this strategy is as follows: once a suspect-list is generated  it becomes the immediate goal. this ensures that the suspect-list of the first 1 is explored. 
similarly  as soon as r1 generates a suspected-faulty-node or a suspect-node  these are treated as immediate goals which take precedence over other productions. 
1 simultaneous propagation 
the use of the  simultaneous propagation  strategy is first apparent in pi 1. this strategy involves tracing the inputs of all the terminal nodes with 1 outputs  one level at a time. once the input components for each terminal 1 are identified  the subject checks to see if there are one or more components which are common to all sets of inputs. if such a node s  is found  then a faulty component is identified. it is only after identifying such a root node that any measurements are made. if a root node is not identified at a given level  then all the inputs to each of the suspect components are generated and the same check is performed  else if a single root node is identified then the subject measures the inputs to verify that it is indeed the faulty component. if a set of nodes are identified  then the outputs are first measured to identify which component in the set produces a 
1 output. once this is done the inputs are measured to verify the faulty component this strategy minimizes the number of measurements. 
　this strategy is clearly and succinctly stated by the subject in pi1:  i just trace the arcs backwards from the nodes i want  terminal 1s  and see if they converge at some point  node  someplace . the subject also solved p1 p1 and 

in the preceding sections  we characterized four different strategies that the subject used to solve the diagnostic problem. we also showed that the subject started with the 

　the control structure here is slightly different from previous strategies. when r1 is fired and a suspect-list is produced  this list is not marked as an immediate goal. instead the input components of all the nodes with os are generated in the suspect-list  which is a list of lists. only when all os are exhausted does r1 fire again. the function find-common-roots finds all the nodes common between all the lists of the suspect-list. if there is none  then r1 is fired and recursed to the next level. however  if common-roots are found then the inputs and outputs are measured to identify the faulty component. 
1 refined simultaneous propagation 
this strategy is very similar to simultaneous propagation. the only difference is the fact that each step some additional information is used to eliminate some of the suspects. we call this refined simultaneous propagation. this strategy is also optimal in the number of measurements  but is computationally more efficient since some of the suspects are eliminated at each step. 
　in this strategy  as before  the inputs to each of the terminal nodes with a 1 output are identified. simultaneously all the input nodes with terminal 1 are also traced. since all the inputs to a node with output 1 should be functioning normally  the corresponding nodes are eliminated from each list of suspected faulty components. this reduces the number of suspects that need to be examined at each step. once this done  the subject examines the suspect-list to determine if there are one or more components which are common to all the suspect lists. if none is found  the same procedure is repeated at the next level and so on. only when a root node s  is identified are any measurements made. 
　the first use of information from an output of 1 is indicated in p1. the explanation for this is provided in protocol  a segment of which we provide below: 
　1.s: that means the node i am looking for cannot be 1 or any nodes that precede 1. 
1.s: because 1 has an input into to 1 and also other nodes  and 1 shows a 1. 
this strategy is also used in p1  but since pi1 has all os at the terminal nodes  the subject could not use this strategy. 
to characterize the strategy described  two productions 
r1b and r1a  figure 1  are added to the list from the  simultaneous propagation  strategy. r1b generates the list simpler strategies and over time evolved to using more sophisticated strategies. this is the learning process. we have yet to indicate how this process occurs. in this part of the paper  we provide a description of how the subject moves from one strategy to another based on the protocol. 
　as we noted before  the subject when presented with the first problem began solving it immediately. this search is far from random and suggests that the subject has available some prior knowledge of some general problem-solving strategies. as he solves problems he is able to gather new information which he combines with his prior knowledge to improve his problem-solving strategies. this implies that the subject has also available some learning capabilities in his long-term memory. 
　in this section we describe four ways in which the subject combined new knowledge with prior knowledge to improve his problem-solving skills. from the protocol we have identified the different pieces of information which provided the subject with cues to develop new strategies. we also provide operators which combine this new information with prior knowledge to produce new strategies. 
1 knowledge from depth-first search 
in the depth-first strategy  the subject used two characterizations of a faulty component. first the subject realized that a faulty component has inputs that are all 1 and outputs that are 1. another necessary condition for a component to be faulty is that it's inputs should lead to all the terminal nodes with a 1. the subject started by using the first definition as a goal for search. but as is apparent  this strategy requires extensive measurements. after he located the faulty component  he used the second characterization to verify his hypothesis. 
　the two characterizations are equivalent in terms of their ability to guide the search to the correct solution. however  using only the first definition  of a faulty component  is not optimal in terms of the number of measurements required to reach a solution. the subject realizes that the use of the second definition does not require any measurements to identify a faulty component and it would be more efficient to use this definition to check for each suspect before making any spurious measurements. 
　this learning process can be implemented simply in terms of re-ordering the firing of productions  figure 1 . for any given node with output 1  r1 fires and generates all 

nodes with outputs leading to the given node. each of these nodes are potentially faulty. in the depth first strategy  the outputs of each of these are measured to identify which node might have a 1 output. this is done by firing r1. instead one could fire r1 to check if any of the nodes can explain all os. hence flipping the order in which r1  r1 fires leads to a more optimal solution. this process provides the mechanism by which the transition from depthfirst to refined depth-first occurs. 
1 knowledge from refined depth-first 
during the stage when the subject is using the refined depthfirst strategy  he gathers an important piece of perceptual information. while checking for a suspect component by tracing the output to a terminal 1  he discovers pictorially that tracing a path from a given node  in the network  is equivalent to tracing back a path from a terminal 1 to given node. 
　the prior knowledge he brings to bear  is the fact that tracing the inputs from a terminal 1 generates a tree of suspects. consequently at each level in the network  there is a set of suspects for each terminal 1 output. since for each suspect  the output has to be traced to all the terminal 1 outputs  the fault-tree for each terminal 1 is generated. moreover  at each level the subject checks to see if there is a set of components which are common to all the suspect-lists for each terminal 1. this set contains the faulty component and no further discrimination can be done without measurements. 
 current-state suspect-node  
 goal  trace-output suspect-node terminal-1   
-   set-goal  member suspect-node 
 fault-tree terminal-1    
figure 1: adaptive productions for learning 
　the use of the perceptual information is represented by the production shown in figure 1. this production replaces the trace-output by a fault-tree of the terminal 1 output and the suspect node is checked to see if it is a member of this tree. this can be generalized to generate the fault-trees of all the terminal os  and then find the set of nodes common to all these trees at each level. 
　hence we infer that the visual cue provides a pointer which indicates that the problem can be solved by tracing back the fault-tree from all the os simultaneously. but the new strategy could not have evolved without the realization that at each level  the suspects are found by finding the intersection of all the set of suspects for each terminal 1. 
1 knowledge from simultaneous propagation 
since all the terminal 1 outputs are propagated backward to generate a fault-tree  a natural extension is to propagate back from terminal 1 outputs. since all inputs to such components have to be 1  all the components on the tree generated by back-propagating a terminal 1 output have to be functioning properly. hence at each level  the subject eliminates all the components on the suspect-lists which also lie on the functioning-tree. this makes the search more efficient in terms of computations. this learning process can be implemented by providing adaptive productions which remove all the nodes  on the trees generated from terminal 1 outputs  from suspect lists. 
1 	cognitive models 
1 chunking 
the use of chunking1 is clearly illustrated in problems p1 and pi 1. the subject has stored in long-term memory the information that the node that ultimately explains all terminal 1 outputs is 1. this information was gathered in p1 and stored in long-term memory. it was later recalled in p1 and pi1 where all the terminal nodes have 1 outputs  and used effectively to reduce search. but this piece of chunked information was insufficient as there is another component  1  which can also results in a 1 at all terminal nodes. this caused the subject some trouble in pi1  when the faulty component was 1. any search path that provides a set of root nodes that explain all the terminal 1 outputs is remembered for future use. for example the fact that 1  1 are two nodes that can explain all terminal os is remembered and used later. 
　in our experiments this is the only example of chunking that is apparent. the case mentioned above is remembered since it is related to the unusual set of all 1 outputs. it is expected that with increased practice  other symptoms would be chunked to their faulty component set and remembered. in general  for any symptom one can generate the set of faulty components which explain all the outputs and this information can be chunked and stored in long-term memory. 
1 computer simulation 
based on the analysis of protocols presented in the previous sections  we have implemented a production system which simulates the learning process. the production system  implemented in ops1  incorporates the four strategies used by the subject in successive problems. each of the strategics are implemented independently and are executable independently as well. in addition  we have implemented the learning process in terms of the four  learning operators  described in this section. these operators are implemented as productions which gather additional pieces of information to evolve a better strategy with respect to the current strategy. for example  in the evolution of the refined depthfirst from depth-first strategy  described in section 1   the information on the number of measurements required by the two characterizations of a faulty component is used in the reordering of the productions. this reordering results in reducing the number of measurements required for diagnosis. the implemented system simulates the strategy shifts from depth first to refined simultaneous-propagation strategy. the system  in simulating the strategy shifts  uses the same information as used by the subject but does not account for the temporal course of the subject's learning. the simulation ensures that the operators identified are sufficient to explain the learning process. 
1 discussion 
the subject has available in long term memory some general problem solving strategies. this supported by the fact that he is able to solve the first problem successfully as soon as it is posed by using the depth first strategy. the depth first strategy can be roughly approximated as means-
1
chunking has been proposed as a learning mechanism which 
records goal-based experience  laird  rosenbioom and newell  1 . 

ends analysis  newell and simon  1. although this strategy leads to the correct solution it is not optimal in terms of the problem objective of minimizing the number of measurements for a diagnosis. however  the computational requirements of the depth-first strategy are small. as the subject moves from the depth-first strategy to simultaneous propagation strategy  he is able to decrease the number of measurements to a diagnosis. however  the computational requirements of the corresponding strategics increase. we illustrate this by an example. 
　consider the network in figure 1 with the following symptom:  1  1  1  1  1  1  1 . each digit in the vector corresponds to the output of the terminal node  from top to bottom. the faulty component is 1. the depth-first strategy requires 1 measurements  refined depth-first requires 1  simultaneous propagation and it's refined version require 1  which is a minimum . hence the diagnostic efficiency improves as we move from depth-first to simultaneous propagation. on the other hand  the computational load increases. in order to characterize the computational requirements of various strategies  we define the number of rows as n and the number of columns as d in figure 1. the computational complexity of the depth first and its refined version is of 1 nxd   and that of simultaneous propagation is of 1 n1xd . 
　the observation leads us propose that learning of new strategies is driven by competing objectives. the problem objective guides the subject to evolve strategies which minimize the number of measurements. the learning operators which transform the depth-first strategy to it's refined version and subsequently to the simultaneous propagation strategy fall into this category. as the strategies that minimize the number of measurements impose larger computational requirements  the subject devises ways of alleviating these requirements in order to reduce the cognitive load. for example  the shift from simultaneous propagation to it's refined version does not improve the the number of measurements but reduces the computational effort. at each step  the refined simultaneous propagation strategy prunes all the components on the suspect list which have outputs to a 1. this reduces the number of hypotheses that need to be considered at each step. moreover  the number of hypothesis generated in the next step is also reduced. chunking is yet another learning operator that provides a means to improve problem solving by utilizing previously recorded goal-based experiences. from our observation of the protocols  we think chunking also provides a means to generate structural abstractions on the device network. 
　in conclusion  this experiment has pointed out to us that the learning process is shaped by the interaction between the cognitive load and the problem objectives. further  each dimension has its own set of learning operators. 
1 further remarks 
this work is proposed as a first step towards identifying computational mechanisms which can explain the generation of expertise from fundamental knowledge. fundamental knowledge is concerned with the first principles of the domain and is described in terms of a model of a device. typically  novices in an area start out with this kind of knowledge. on the other hand  expertise consists of knowledge gained through experience. it provides  short 
1 pp. 1 cuts  through the knowledge which enables experts to solve the problems faster and more efficiently. the experiential knowledge consists of productions or rules which encode knowledge compiled from the first principles. this question is of special interest in machine diagnosis  where much research is directed towards integrating the use of model based systems with expert rule based systems. 
　design of tutoring systems concentrate on the identification of student models as means to develop didactic strategies. a variety of techniques for characterizing student models have been proposed in the literature  wenger  1 . in this study  we have explored the process of transformation of a novice to an expert. this process is characterizable in terms of information that the novice uses to evolve better strategies. this model of evolution could provide a basis for intervention to improve novice strategies for solving problems in a tutoring context. 
acknowledgements 
　we thank the reviewers for their comments. 