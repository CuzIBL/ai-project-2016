 
little is clearly understood about  the similarities  differences  and comparative computational and representational advantages of the many proposals extant for organizing minds  into collections of  mental subagents.  using a new mathematical framework fur exactly specifying the structure of mental organizations  we formulate separately the ideas of multiple pe.-spectivcs  re:lsoned assumptions  and virtual copies. when combined  th*'se notions form a common backbone for systems as diverse as conlan  ni'itl  and fol  and show many particular characteristics of those systems results of the  language of thought  adopted for representing the contents of mental subagents. the framework also suggests connections between the  strengths  of mental attitudes  the ambiguity of  self   and the possibilities for selfomniscience. 
1. several recent proposals in artificial intelligence reformulate anient doubts about the reality of the  sell  by explaining or constructing agents in terms of a collection of interacting  simpler subagents. some 
of these proposals discuss the agent's actions without reference to any  self  at all  and others presume  selfhood  to hit epiphonomcnally from subagent to subagent as dictated by needs to communicate with the external world or to assign credit or blame for actions. while thinkers throughout history have occasionally doubted on philosophical grounds the common  single-agent  view of the human mind  the new proposals suggest that there may be computational difficulties inherent in single-agent psychologies that arc only overcome by the multi-agent viewpoint. mlnsky has called this approach the  society of mind.  in some proposals the subagents comprising the society are numerous  very simple  neurologically conceived mechanisms. other proposals suggest more complex subagents  ranging from the coroutine collections of  heterarchy   to the  knowledge sources  of production systems  to frame systems  to collections of mutually referring logical theories  to freud's committee of id  ego  and superego  and modern split-brain theories  in which the complexities of the subagents rival that of the agent as a whole. we need not view these proposals as mutually exclusive  if we can subdivide subagents into sub-subagents  but questions like this are difficult to pursue without reasonably precise characterisations of the different sorts of subagents to be related. more specifically  
this research was supported by the defense advanced research projects agency  dod   arpa order no. 1  monitored by the air force avionics laboratory under contract f1-1-k-1. the views and conclusions contained in this document are those of the author  and should not be interpreted as representing the official policies  either expressed or implied  of the defense advanced research projects agency or the government of the united states of america. 
the knowledge representation literature is filled with proposals for complex organizations based on widely differing sorts of  languages of thought   such as logic  fol  weyhraucii 1    list structures and rational algebraic functions  conlan |sussman and steele 1    nodes and links  netl  fahlman 1    etc. although their abstract structures seem related  there is little hope for understanding the relations among these proposals and tor making rapid further progress without clearly formulating the underlying ideas separately and then analyzing their range of combinations. toward this end  we present a mathematical framework for exactly specifying the structure of mental societies. since the framework is fairly general  we illustrate it by characterizing a particular society of mind which incorporates three often-proposed capabilities of subagents and relations between subagents  namely multiple perspectives  reasoned assumptions  and virtual copies. while these characteristics of societies are sometimes thought to require the use of logical or quasi-logical languages as systems of representation  our formulation makes few structural or representational demands  and so permits use of any desired system of representation  including logical languages  in which the few required structures may be encoded. for example  we can reconstruct fol and conlan at the end of our formulation largely by choosing logical or lisp-like languages for the contents of mental subagents. 
         the mathematical framework is developed and otherwise applied in  doyle 1  and  doyus i1b . while 1 formulate the particular society here to generalize the organization suggested in my thesis   doyle 1    the ideas involved have an older  wider history  and i have worked to incorporate the insights of johan de kleer  
m e r r i c k furst  k u r t k o n o l i c e   m a r v i n m i n s k y   brian s m i t h   richard s t a l l m a n   c u y s t e e l e   g e r a l d sussman. david tourktzky  and richard w e y h r a u c h into this exposition. 
¡ì1. researchers frequently motivate proposed decompositions of mind with concerns about self-knowledge  that is  information and mechanisms the agent employs to understand  predict  control  and modify its structures and actions. although specific tasks appear amenable to specific solutions  students of the broad problems of representation  decision-making  and learning come to appreciate the utility  if not importance  of self-knowledge in adaptive agents. artificial intelligence studies many sorts of self-knowledge  but for brevity we consider only three. 
1 j. doyle 
         one commonly studied .sort of .self knowledge involves multiple; coneferential representations*. since artificial intelligence proposals often suppose r -presentational agents  individual representations and their relations form natural objects of self-knowledge. since the feasible mechanisation of thinking demands concern for the difficulty of reaching conclusions and solving problems  one of the most studied relations between representations is the ease of thinking about something in terms of one representation relative to the ease of thinking about it in terms of an alternative representation. minsky emphasizes reformulation or representation switching as the heart of problem solving; bobrow and wlnograd make similar opportunism the basis 
of krl; and sussman and steele illustrate the inferential importance of interactions between multiple coreferential representations. thus useful sorts of self-knowledge include the possible alternatives to a particular representation  their relative efficiencies  and how to assign credit or blame to choices among these alternatives upon unusual successes or failures. the motivations for employing multiple representations of extra-mental objects also apply to the representations of the mental objects figuring in self-knowledge. it is natural to identify these different views of objects as individual mental subagents  each with its own distinguished view of parts of the world  parts of the agent  or parts of both. this is roughly the position taken by minsky. however  if these- different perspectives or subagents are to influence each other  they must be connected somehow  and the basic 
sorts of connections are those of reference and coreference. both notions are necessary  for while one subagent might refer to another  in tended extra-mental referents cannot be  grasped  in the same way  so at most the agent can intend that  its representations of these objects share referents. 
         unfortunately  the introduction of mutually knowledgeable and influential mental subagents into psychological theories poses many puzzling difficulties of formulation and interpretation. these difficulties appear most viciously in agents employing logical languages as systems of representation. where classical logic and mctamathematics usually seek ways of avoiding paradoxes of self-reference  th designers of artificial agents instead seem to seek them out. fortunately  analysis of a narrow sort of self-knowledge  discussed presently  suggests a formal interpretation for these more widely self-referential systems  one which does not force us to accept any particular psychology for our agents  but instead allows similar formulation and exact comparison of the many variations we might think to explore. 
         another sort of self knowledge concerns the inferential relations between arbitrary representations instead of the economic relations between alternative coreferential representations. many researchers have studied the uses of explicitly represented inferential relationships in constructing explanations  assigning blame for mistakes  and revising the agent's state of mind when its assumptions change. these inferential relationships need not be strictly deductive. wh'.le the most general use simply indicates what representations were computed from what  inferential records play a crucial role in no-called default reasoning. default reasoning involves drawing conclusions in the absence of definite supporting or contrary evidence  representations of the partial evidence for and the missing evidence against a conclusion permit the agent to make reasoned assumptions   reasoned  in the sense that the age.it can identify both the sources of the assumed conclusion and the specific information which indicates its retraction or reconsideration. the representations of inferential relationships describing reasoned assumptions also pose problems of interpretation  since the agent's drawing one conclusion may prevent it from drawing another. fortunately  this problem has been solved  and below we extend the solution to handle the problem of multiple perspectives mentioned above. 
         a third important sort of self-knowledge concerns structural relationships between representations. the most studied structural relationship is that of structure sharing. like the technique of multiple perspectives  structure sharing has economic motivations  namely minimizing the number of times one has to encode similar information and the amount of storage the agent must consume for the encodings. like general inferential relationships  however  structure sharing need not entail coreference of the related representations. for example  the species of the cat family  lions  tigers  cheetahs  persians  etc.  may have no properties in common beyond those of mammals  since each cat species may lack some property shared by all other cat species. but to write down descriptions of each species is very tedious unless we write down a single description of a  prototypical  cat species  which we may choose to be one of the actual species  and describe every other species by its  presumably few  differences from the prototype. since such family resemblances occur among the members of every natural kind  great economies can be realized in representing our common knowledge of the world. the most common sorts of structure sharing relations usually go by the names of  inheritance relations  and  virtual copies.  as we demonstrate below  it is easy to interpret some of these structural relationships between subagents along with the previously mentioned ones. 

j. doyle 1 
¡ì1. 	while wo do not require that subagents he completely repre-sentational  or that they employ any particular system of representation if they are completely representational  we do require a few minimal capabilities with which subagents can discuss each other. our first particular constitutive assumption is that the state components of subagents can be further decomposed into  contents  indexed by the subagent. formally  for each subagent a e a  we assume a set ca such that da {a} x ca. we further facilitate mutual reference by admitting subagents as possible contents  that is  a c ca for each a e a. to simplify matters  we assume that all content sets are the same set c  and pretend that every content is a  possibly trivial  subagent by assuming a = c. these simplifications are innocuous since we can always rule out senseless elements by giving them the empty interpretation 1 d  - - 1 which prevents their inclusion in any admissible state. with these simplifications  we have d - - c x c  and read  a b   - d as subagent a making the  possibly trivial  statement 1.  we say  statement  here for want of a better term. contents of subagents are statements only when c is a language  which we do not require.  for each state 1 e $  we find out what statements subagent a makes by means of the projection or perspective  operator 

¡¡¡¡¡¡¡¡¡¡with this minirnnl notion of statements by subagents  we can describe the vocabularies of multiple perspectives  reasoned assumptions  and virtual copies. we introduce these vocabularies in turn by means of abstract syntax functions. we also introduce separate interpretations i1  i1  and i1 for elements expressed in these vocabularies and define i --- i1 n i1 d /1  so that when more than one of these interpretations applies to a single element  their intersection is the complete interpretation of the element. 
1. the vocabulary of multiple perspectives is captured with three syntactic constructors on the set of contents. we assume the existence of functions      enlarged parentheses     and  =  from c x c into 
c  so that for every 	we have 	and 

¡¡¡¡¡¡¡¡¡¡the     constructor permits subagents to discuss the contents of other subagents  where we read  a   1  c   d as the statement made by a that subagent 1 makes the statement r. since the constructor may be iterated  wc can construct even more complex statements  such as 

whose reading is left as an exercise. 
¡¡¡¡¡¡¡¡¡¡the     constructor is the dual of      and produces names for the multitude of relative perspectives. that is  we read   a  1   c  as the statement c made by the subagent corresponding to a's view of b. the corresponding reading exercise for this constructor is 

¡¡¡¡¡¡¡¡¡¡wc make no assumptions of correctness or completeness about the 'views  held by subagents about other subagents. that is  wc allow an admissible state s to contain  a   b  c   even if  b c   s  and to contain  1 c  even if  a   1  c    1. we leave pursuit of constitutive assumptions like correctness and completeness to future work. the only requirement wc make is the intended connection between the dual constructor functions. this wc express with the interpretation function 
i1 by requiring  for every 

¡¡¡¡¡¡¡¡¡¡while the coreference constructor allows subagents to relate some of their own subperspectives  it cannot be used to relate  top-
level  subagents. since we require that every domain element belong to at least one subagent  every coreference statement must occur within some subagent  and hence only relate its subperspectives. that is   a  b = c  relates the perspectives of  a  b  and  a  r   not those of b and c. if our society is not to be a crowd of sleepwalkers  each unrelated to the others no matter how it dreams it is related  there must  be connections between the subagents expressed either in i  which we do not do here  or in the { } constructor. that is  we can read  a  b  - c as a's reference to c by means of b. since the     constructor is defined  along with d  independent of the element interpretations  all such references arc 
 hard-wired  into the agent's realization  and cannot be changed by any action of the agent. we do not require that  be 1  and this allows us to  wire together  subagents by defining common references  for example by defining the constructor so that  in which b and c can communicate and otherwise influence each other through a. if we imagine the human mind described in this way  {   reflects the actual neural connections in the brain  while stated coreference relations using     simply reflect the decisions of mental subagents. 
¡¡¡¡¡¡¡¡¡¡wc could of course introduce modifiable references by incorporating the l   table into states. to do this  we need only redefine v to be c1 u c   where elements  are as before  and elements  a b c  e c1 indicate entries in the constructor table  specifically   a b c  e s means that  a  b  = c in s. we require that     be singlevalued  but not necessarily complete  with the modified interpretation function 

we give subagents the capability to specify references by means of a constructor =  from c1 to c  where  a  b=  c  is a's  ostensive  decision to use b to refer to c. this is formalized with the interpretation 

of course  we can get ostensive coreference from reference by using  a  b= d  and  a  c= d  instead of  a b =*c . however  to keep the rest of the discussion as simple as possible  we forgo modifiable references for our original definitions  and leave recasting the subsequent definition  in terms of modifiable references as an easy exercise for the reader. 

1 j. doyle 


         while we here accept finitely grounded extensions a.** admissible extensions  they are inadequate to fully capture the usual notion of virtual copy. in current practice  it is crucial that successive queries agree  that is  that virtual information is conserved across reconstructions. hut this cannot be guaranteed with multiple admissible extensions  since the agent might for one query construct e and next time construct e' = e  differing in some answers even though no kernel information has changed. thus the virtual state is conserved only if the agent computes a unique admissible extension. tourktzky  is currently developing restrictions on the sorts of information states can contain  restrictions designed to guarantee the existence and uniqueness of admissible extensions. he also motivates the aim of uniqueness by seeking parallel algorithms for reconstructing the virtual elements  and requiring that concurrent processes computing subsets of the virtual elements agree on their overlap. touretzky's discoveries notwithstanding  i doubt that completely unoftensivc restrictions on the vocabulary of the agent can alone guarantee uniqueness of finitely grounded extensions. i suspect that some applications demand a vocabulary sufficient to phrase ambiguities  and for these one appealing approach is to make the reconstruction algorithm  whether concurrently or serially realized  be a probabilistic algorithm. that is  when an ambiguity arises during reconstruction  the algorithm makes a random choice  random  not arbitrary . the intent of such deliberate randomization is to make every possible reconstruction equally likely or to occur with some specified frequency. if the agent wishes to judge its certainty on some question  it asks that question repeatedly. questions with answers common to or absent from all admissible extensions never vary in their answer  while other queries exhibit uncertainty  waffling in response over time. if the alternative admissible extensions do not differ greatly  then most answers will be the same anyway no matter which admissible extension is chosen.  i   yle 1  develops a theory of subjective probability by measuring the relative frequencies of different answers  but we cannot go into that here. 
¡ì1. even if the ambiguities of admissible extensions are resolved  ambiguities due to multiple perspectives remain. minsk y and others have suggested that some abrupt changes in human behaviors and attitudes stem from changes in which subagent has control as  spokesman  over the communication or motor channels to the external world. in that view  there is no fixed notion of  self   but a different sense of self depending on which subagent gains control. one advantage of that view is that abrupt changes of attitudes are computationally trivial  for they stem from switching vantage points rather than from laborious revision of the state itself. the framework proposed here facilitates consideration of such proposals. for example  a natural problem is that of formulating precise notions of  abrupt  changes. if we decide when perspectives of dilferent subagents are  similar   we can allow wide variations in which subagent is currently  self  as long as most of the self-image is conserved across self-changes  and single out as abrupt those changes of self which bring large or significant changes in the self-perspective. that is  if pa s  and pb s  arc very similar  say if pa .s  and pb s  differ by no more than 1  ¡À1  elements  we might say that no major self-changcs  only changes of attention  are involved in switches between a-self and b-seif. indeed  if the probabilistic approach to ambiguities of interpretation is adopted  then one need make no special provision for ambiguities due to self-changes. can we develop measures of similarity on both states and perspectives so that if s and s' are similar  so arc pa s  and pa{s'   or vice versa  unfortunately  we cannot pursue such questions here. 
j. doyle 1 
¡ì1. there are many other possibilities to be explored in introducing notions of self into societies such as this. in doyle 1  i advocated distinguishing a particular subagent  called me  as the self.  i am less committed to that approach now.  when compared to the freefloating approach just discussed  the use of a fixed self-subagent appears to require significant computational costs for substantial perspective changes.  but sec  mcdermott 1  and  martins 1 .  in any event  distinguished perspectives still merit consideration  for it may be easier to endow them with limited completeness and correctness properties than amorphous agents. specifically  one of the intents of my earlier proposal was to have the subagent me be the authority on just what the state contained. the idea here is to construct the agent so that  modifiable references or not   me  a  -- a for every a ¡ê c  including me itself   if that is possible. i suspect it is not too difficult to achieve  and such organizations have obvious attractions tor constructing agents possessing reflective powers. to pursue this idea  if one perspective admits the limited self-omniscience described above  does it follow that all do  that is  does global self-omniscience follow from local self-omniscience  f suspect not  but have no counterexample. it also seems certain that different perspectives can differ arbitrarily much even if both are mutually omniscient. if the subagents all use a logical language as a system of representation  well known results indicate general limits to self-omniscience  but which sorts of limited self-knowledge can be introduced without difficulties arising  kripke's analysis of truth indicates that even seemingly innocuous statcmcrjts of mutual knowledge can in concert produce unreconcilablc paradoxes. since his theory involves a notion of groundedness resembling our notion of grounded extension  similar results seem likely here. unfortunately  we must leave these questions for future study. 
acknowledgements 
i thank joseph sciiatz for advice  and bkn cohen for reading a distant ancestor of this paper. 

1 	j. doyle 
