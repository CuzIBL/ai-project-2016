 
in this paper we follow the same general ideology as in  gammerman et al.  1   and describe a new transductive learning algorithm using support vector machines. the algorithm presented provides confidence values for its predicted classifications of new examples. we also obtain a measure of  credibility  which serves as an indicator of the reliability of the data upon which we make our prediction. experiments compare the new algorithm to a standard support vector machine and other transductive methods which use support vector machines  such as vapnik's margin transduction. empirical results show that the new algorithm not only produces confidence and credibility measures  but is comparable to  and sometimes exceeds the performance of the other algorithms. 
1 	introduction 
in this paper  we describe a new method of transductive inference using support vector machines  vapnik  1 . whereas induction tries to learn a general rule  e.g. of classification  from a given training set  transduction reasons from particular to particular. that is  instead of trying to obtain a general rule  the learning process is focussed on obtaining the classification of a single new example  or given set of new examples. in section 1 we introduce a method of transduction based on a 
support vector  sv  machine which uses the statistical measure of p-values. by measuring p-values the algorithm gives confidence values for each of its predictions. the method also provides a credibility measure based on the p-values for different predictions. these measures can be interpreted as an indication of the quality of our prediction. the performance of the new algorithm is then compared to two other techniques  which simply give flat predictions  and no measure of confidence or credibility   viz. a standard support vector machine  and vapnik's margin transduction. 
　results show that the transductive method presented here is comparable to  and sometimes exceeds the per-
1 	machine learning 
formance of the other two methods  whilst providing the additional information of confidence and credibility values for its prediction. our trasnductive algorithm therefore gives us the best of both worlds: as in  gammerman et a/.  1; gammerman  1  it provides confidence 
and credibility values  the predictive performance however  of the algorithm described in  gammerman et a/.  1  is poor; this is probably explained by the  distortion phenomenon  : see  gammerman et a/.  1   section 1 for details ; as in support vector machines  it achieves good predictive performance. 
1 	sv implementation 
in this section we describe the method upon which the transduction algorithms used in this paper are based. the method involves adding k examples to a training set and then training a separate sv machine for every possible classification of the k examples. although the two transduction algorithms discussed here  our new algorithm and vapnik's margin technique  both use this as a basis  the method of prediction  and any additional information  such as confidence and possibility  about the test examples which they produce  is different. the details of the algorithms will be presented in the next section  for now though we present the general ideas which are common to both. 
suppose we have some training data 

and a set of test data  

 note: as with a support vector machine  we assume that both the training and test data are generated independently from the same distribution.  for a fixed set of classifications of the test data 

we construct a support vector machine on the combined sequence 

for simplicity we will only consider the separable case  however the following can easily be generalised to the 

non-separable case  for details see e.g.  vapnik  1  . we therefore want to find an optimal hyperplane w such that 
		 1  
is minimised  subject to the constraints 

in order to find the optimal hyperplane we have to solve the following quadratic optimisation problem: maximise 
subject to the constraints 
here 
for the inner product in hilbert space. according to hilbert-schmidt theory  can be any symmetric function that satisfies mercer's conditions  for details see  vapnik  1  . 
　the process above is repeated for all possible classifications  of the test set. in the following sections we shall describe how the two algorithms use this process in different ways. 
1 	transduction algorithms 
the method of transduction which we introduce here uses the statistical measure of p-values to determine the significance of the associated with the test example  s   once the quadratic optimisation problem  1  1  has been solved for all possible classifications of the test set. this method not only gives predicted classifications  but also provides valid measures of confidence and credibility for its predictions  vovk and gammerman  1 . first of all we shall consider the case when the test set to be classified only contains one example and there are two possible classifications. this will then be extended to a multi-class classification. finally we shall consider problems involving multiple test examples and binary classes. 
1 confidence values for a single test e x a m p l e 
if we are only interested in the binary classification of a single example  then the quadratic optimisation problem  1  has to be solved twice  once where the new example is classified as +1  the other -1   and therefore two hyperplanes are obtained. for each hyperplane  we obtain a value of  strangeness* for the test example. this is defined as follows. 
　consider the training set  with the new test example included  

once  1  has been solved  each of the examples in this set has an associated lagrange multiplier 

suppose we are interested in the probability that the is actually the largest lagrange multiplier in this 
set. since the training examples and the one new example are exchangeable  then this probability is 

 the randomisation is over all permutations of the examples . the value of the lagrange multiplier can be interpreted as a measure of  supportiveness  of the example  and therefore high values indicate that this example is  strange  and unlikely to occur. in order to determine how unlikely a certain a-value is  we can use the statistical measure of p-values. 
　simply examining whether or not the a-value associated with the new test example is the highest or not and accepting or rejecting it as the correct classification based on this alone would not produce a reliable classifier. we therefore look at the p-value associated with the and make a decision based on this value. if the rank of is the nth highest or-value   the p-value is defined as 

 once again  the randomisation is over all permutations of the examples   which is equivalent to 

the p-value is a measure of how  strange  our test example is when given a certain classification. that is  the p-value tells us the probability of observing this particular ordering of the alpha values under the assumption that  is the correct classification. the classification ynew which yields the highest corresponding p-value  determines the classification predicted by the algorithm. the confidence in prediction can then be defined as 
	confidence 	=1-p1 	 1  
where p1 is the p-value obtained when the example was given the classification which we did not predict. 
	saunders  gammerman  and vovk 	1 

1 	classifying multiple new examples 
if we are to consider the case when multiple new examples are added to the existing training set  then the qp problem  1 - 1  has to be solved a total of 1* times  in a two-class scenario . unfortunately this is impractical for large values of k  e.g. k  1  each solution of this problem yields lagrange multipliers corresponding to each of the test examples. the p-value associated with a particular assignment of classifications is then defined as 
where are the actual measured ranks of the corresponding lagrange multipliers and the randomisation is over all permutations of the examples. as in the single example case  the classifications predicted for the test examples are those which yield the highest p-value. confidence is defined to be 1 - p1 where p1 is the second highest p-value  and as in the single example case  p1  the highest p-value  corresponds to our credibility. 
s.1 	m e a s u r e of c r e d i b i l i t y 
not only do we obtain a confidence value for our prediction  but we also consider a measure of credibility which indicates the quality of the data on which we base our decision. we define credibility as the value p1  i.e. the p-value obtained when the test data are given the predicted classification s . 
   in order to see how this can be interpreted as a measure of the quality of the data  first consider an  ideal  case. suppose we are adding a single test example. also suppose that when the correct classification is given to our test example it is not a support vector and therefore will have a p-value of 1. assume that when given the incorrect classification  the p-value obtained from the example is at most 1. in this situation  our confidence would be 1% or greater and the value of credibility would be 1  1% . this would mean we have high confidence in our prediction from a good set of data. now consider a similar case where the highest p-value still corresponds to the correct classification  but is much lower  say 1. if the other p-value obtained was the same as before  then we would still have a high confidence of 1%. our measure of credibility however would be much lower  1% . this would convey the meaning that although we confidently rejected all other classifications of this test example  the test example is actually  strange  in both scenarios and therefore the data is not sufficient to give us a totally secure prediction. section 1 introduces empirical evidence which supports this line of reasoning. 
　the measure of credibility provides us with a filter mechanism with which we can  reject  certain predictions. that is  if for any task the consequences of making a wrong prediction are quite severe  we can choose to re-
ject those predictions which have a low credibility value associated with them. the more severe the consequences for making an incorrect prediction are  the higher we can set the rejection threshold. 
1 machine 	learning 
1 	vapnik's margin transduction 
as a point of comparison for our technique we shall use a method of transduction suggested by vapnik  vapnik  1 . this method also uses the basic ideas described in section 1. the predicted classifications are the ones which separate the joint sequence 

with maximal margin. 
the predicted classifications are therefore given by 

 subject to constraints  1  and  1    over all possible classifications 
　in the dual representation  this is equivalent to maximising  1 - ll  for all possible classifications of the test set  and predicting the classifications which achieve the overall minimum. 
1 	experiments and results 
first of all we shall present some empirical evidence of the quality of the confidence and credibility values obtained by the new transductive algorithm  based on a two-class digit recognition problem. a performance comparison is then made between our new algorithm  vapnik's margin algorithm  and a standard sv machine on the same data set. 
　unless stated otherwise  the experiments in this section were performed on the us postal service database of handwritten digits  see e.g.  lecun et al.  1  . 
　the kernel function used in these .experiments was a polynomial of the form 

for which the best performance is achieved with d = 1. 
1 	confidence a n d credibility values 
table 1 shows an example of the confidence and credibility values obtained on a digit-recognition task of separating the digit '1' from all other digits. the training set used in these experiments consisted of 1 examples of the digit '1' and 1 examples of other digits  '1'....'1' . the test set consisted of 1 other digits from the database. both the new transduction algorithm and an sv machine were run on the data. out of 1 test examples both methods classified all but three examples correctly  they both misclassified the same three examples . the table shows the confidence and credibility values for these three misclassified examples  along with the examples themselves . for all of the misclassified examples the credibility of the prediction is very low  no more than 1% . this suggests that for all of these examples  the quality of the data is not sufficient on which to base a prediction. 


table 1: confidence and credibility values for missclassified examples. 

table 1: incorrect classifications over a total of 1 runs. in addition to providing confidence and credibility values  the p-value transductive algorithm has good generalisation ability. 
1 	relative performance of the algorithms 
in this section we compare the predictive performance of the new algorithm  alongside the margin transduction technique and a support vector machine. for this experiment  we again used a subset of the digit database. all of the examples of the digits 1 and 1 were extracted from the database  giving a total set of 1 examples. in each of these experiments a subset of n examples were randomly chosen and used as a training set  a single further example was then randomly picked as a test example. all three algorithms were trained on the same training set and gave their predictions for the test example. this process was then repeated for a total of 1 runs  and for different values of n. table 1 summarises these results. it is clear from the table that the new algorithm does not suffer in performance despite providing the extra information of confidence and credibility values. 
1 	discussion 
in this section we briefly discuss related work and highlight possible directions for further research based on the results presented in this paper. 
1 	adding multiple examples 
at the present time  adding k examples to our original training set in order for them to be classified is impractical for large values of k. recent developments in the training of support vector machines  however  such as those presented in  platt  1  may yield improvements in the application of this algorithm. another transductive algorithm has recently been proposed in  bennett and demiriz  1  which is based on the margin transduction technique. this technique minimises the w vector in the l1-norm rather than the l1-norm and uses integer programming to rapidly find hyperplanes which separate the training data  even if the number of exam* ples is large. this method however  does not provide confidences or credibility values for its predictions. 
1 	extension to regression 
an important direction of this research is to extend it to the case of regression  i.e. where the classifications yi  are no longer required to be binary values  but can be real numbers. statistically valid p-values may be obtainable from support vector machines for regression estimation  see e.g.  vapnik  1    or other related methods such as those in  saunders et a/.  1 . 
1 	conclusion 
in this paper we have presented a new transduction algorithm which is based on the support vector technique. it has been shown that the algorithm produces confidence values for its predictions  and also gives a measure of credibility which indicates the quality of data upon which the prediction is based  and therefore serves as a guideline of how reliable the prediction actually is. empirical results have been presented which show that values of confidence and credibility produced by the algorithm do correctly reflect the reliability of the predictions given. this method has been shown not only to produce these values  but also to have good generalisation ability on a test set  comparable to and sometimes exceeding the results achievable by a support vector machine. 
1 	acknowledgements 
this work was partially supported by epsrc gr/l1 and gr/m1  and eu intas-1ext grants. in addition we are indebted to the support provided by ifr ltd. we would also like to an anonymous referee whose helpful comments prompted many changes and improvements in the paper. 
