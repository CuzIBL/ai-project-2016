
in this paper  we try to further demonstrate that the models of random csp instances proposed by  xu and li  1; 1  are of theoretical and practical interest. indeed  these models  called rb and rd  present several nice features. first  it is quite easy to generate random instances of any arity since no particular structure has to be integrated  or property enforced  in such instances. then  the existence of an asymptotic phase transition can be guaranteed while applying a limited restriction on domain size and on constraint tightness. in that case  a threshold point can be precisely located and all instances have the guarantee to be hard at the threshold  i.e.  to have an exponential tree-resolution complexity. next  a formal analysis shows that it is possible to generate forced satisfiable instances whose hardness is similar to unforced satisfiable ones. this analysis is supported by some representative results taken from an intensive experimentation that we have carried out  using complete and incomplete search methods.
1	introduction
over the past ten years  the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence. numerous studies have established that for many np-complete problems  e.g.  sat and csp   the hardest random instances occur  while a control parameter is varied accordingly  between an under-constrained region where all instances are almost surely satisfiable and an over-constrained region where all instances are almost surely unsatisfiable. in the transition region  there is a threshold where half the instances are satisfiable. generating hard instances is important both for understanding the complexity of the problems and for providing challenging benchmarks  cook and mitchell  1 .
¡¡another remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems. and  since this progress  one important issue has been to produce hard satisfiable instances in order to evaluate the efficiency of such algorithms  as the approach that involves exploiting a complete algorithm in order to keep random satisfiable instances generated at the threshold can only be used for instances of limited size. also  it has been shown that generating hard  forced  satisfiable instances is related to some open problems in cryptography such as computing a one-way function  impagliazzo et al.  1; cook and mitchell  1 .
¡¡in this paper  we mainly focus on random csp  constraint satisfaction problem  instances. initially  four  standard  models  denoted a  b  c and d  smith and dyer  1; gent et al.  1   have been introduced to generate random binary csp instances. however   achlioptas et al.  1  have identified a shortcoming of all these models. indeed  they prove that random instances generated using these models suffer from  trivial  unsatisfiability as the number of variables increases. to overcome the deficiency of these standard models  several alternatives have been proposed.
¡¡on the one hand   achlioptas et al.  1  have proposed a model e and  molloy  1  a generalized model. however  model e does not permit to tune the density of the instances and the generalized model requires an awkward exploitation of probability distributions. also  other alternatives correspond to incorporating some  structure  in the generated random instances. roughly speaking  it involves ensuring that the generated instances be arc consistent  gent et al.  1  or path consistent  gao and culberson  1 . the main drawback of all these approaches is that generating random instances is no more quite a natural and easy task.
¡¡on the other hand   xu and li  1; 1    frieze and molloy  1  and  smith  1  have revisited standard models by controlling the way parameters change as the problem size increases. the alternative model d scheme of  smith  1  guarantees the occurrence of a phase transition when some parameters are controlled and when the constraint tightness is within a certain range. the two revised models  called rb and rd  of  xu and li  1; 1  provide the same guarantee by varying one of two control parameters around a critical value that  in addition  can be computed. also   frieze and molloy  1  identify a range of suitable parameter settings in order to exhibit a non-trivial threshold of satisfiability. their theoretical results apply to binary instances taken from model a and to  symmetric  binary instances from a so-called model b which  not corresponding to the standard one  associates the same relation with every constraint.
the models rb and rd present several nice features:
  it is quite easy to generate random instances of any arity as no particular structure has to be integrated  or property enforced  in such instances.
  the existence of an asymptotic phase transition can be guaranteed while applying a limited restriction on domain size and on constraint tightness. for instances involving constraints of arity k  the domain size is required to be greater than the kth root of the number of variables and the  threshold value of the  constraint tightness is required to be at most k k1.
  when the asymptotic phase transition exists  a threshold point can be precisely located  and all instances generated following models rb and rd have the guarantee to be hard at the threshold  i.e.  to have an exponential tree-resolution complexity.
  it is possible to generate forced satisfiable instances whose hardness is similar to unforced satisfiable ones.
¡¡this paper is organized as follows. after introducing models rb and rd  as well as some theoretical results  section 1   we provide a formal analysis about generating both forced and unforced hard satisfiable instances  section 1 . then  we present the results of a large series of experiments that we have conducted  section 1   and  before concluding  we discuss some related work  section 1 .
1	theoretical background
a constraint network consists of a finite set of variables such that each variable x has an associated domain denoting the set of values allowed for x  and a a finite set of constraints such that each constraint c has an associated relation denoting the set of tuples allowed for the variables involved in c.
¡¡a solution is an assignment of values to all the variables such that all the constraints are satisfied. a constraint network is said to be satisfiable  sat  for short  if it admits at least a solution. the constraint satisfaction problem  csp   whose task is to determine if a given constraint network  also called csp instance  is satisfiable  is np-complete.
¡¡in this section  we introduce some theoretical results taken from  xu and li  1; 1 . first  we introduce a model  denoted rb  that represents an alternative to model b. note that  unlike model b  model rb allows selecting constraints with repetition. but the main difference of model rb with respect to model b is that the domain size of each variable grows polynomially with the number of variables.
definition 1  model rb  a class of random csp instances of model rb is denoted rb k n ¦Á r p  where:
  k ¡Ý 1 denotes the arity of each constraint 
  n denotes the number of variables    ¦Á   1 determines the domain size d = n¦Á of each variable 
  r   1 determines the number m = r.n.lnn of constraints 
  1   p   1 denotes the tightness of each constraint.
to build one instance p ¡Ê rb k n ¦Á r p   we select with repetition m constraints  each one formed by selecting k distinct variables and p.dk distinct unallowed tuples  as p denotes a proportion .
¡¡when fixed  ¦Á and r give an indication about the growth of the domain sizes and of the number of constraints as n increases since d = n¦Á and m = rnlnn  respectively. it is then possible  for example  to determine the critical value pcr of p where the hardest instances must occur. indeed  we have pcr = 1   e ¦Á/r which is equivalent to the expression of pcr given by  smith and dyer  1 .
¡¡another model  denoted model rd  is similar to model rb except that p denotes a probability instead of a proportion. for convenience  in this paper  we will exclusively refer to model rb although all given results hold for both models.
¡¡in  xu and li  1   it is proved that model rb  under certain conditions  not only avoids trivial asymptotic behaviors but also guarantees exact phase transitions. more precisely  with pr denoting a probability distribution  the following theorems hold.
theorem 1 if are constants then

where.
theorem 1 if are constants then

where.
   remark that the condition is equivalent to  given in  xu and li  1 . theorems 1 and 1 indicate that a phase transition is guaranteed provided that the domain size is not too small and the constraint tightness or the threshold value of the constraint tightness not too large. as an illustration  for instances involving binary  resp. ternary  constraints  the domain size is required to be greater than the square  resp. cubic  root of the number of variables and the constraint tightness or threshold value of the tightness is required to be at most 1%  resp. ¡Ö 1% .
¡¡the following theorem establishes that unsatisfiable instances of model rb almost surely have the guarantee to be hard. a similar result for model a has been obtained by  frieze and molloy  1  with respect to binary instances.
theorem 1 if p ¡Ê rb k n ¦Á r p  and k  ¦Á  r and p are constants  then  almost surely1  p has no tree-like resolution of length less than 1  n .
¡¡the proof  which is based on a strategy following some results of  ben-sasson and wigderson  1; mitchell  1   is omitted but can be found in  xu and li  1 .
¡¡to summarize  model rb guarantees exact phase transitions and hard instances at the threshold. it then contradicts the statement of  gao and culberson  1  about the requirement of an extremely low tightness for all existing random models in order to have non-trivial threshold behaviors and guaranteed hard instances at the threshold.
1	generating hard satisfiable instances
for csp and sat  there is a natural strategy to generate forced satisfiable instances  i.e.  instances on which a solution is imposed. it suffices to proceed as follows: first generate a random  total  assignment t and then generate a random instance with n variables and m constraints  clauses for sat  such that any constraint violating t is rejected. t is then a forced solution. this strategy  quite simple and easy to implement  allows generating hard forced satisfiable instances of model rb provided that theorem 1 or 1 holds. nevertheless  this statement deserves a theoretical analysis.
¡¡assuming that d denotes the domain size  d = 1 for sat   we have exactly dn possible  total  assignments  denoted by t1 t1 ¡¤¡¤¡¤  tdn  and d1n possible assignment pairs where an assignment pair   ti tj   is an ordered pair of two assignments ti and tj. we say that   ti tj   satisfies an instance if and only if both ti and tj satisfy the instance. then  the expected  mean  number of solutions ef n  for instances that are forced to satisfy an assignment ti is:

where pr   ti tj    denotes the probability that   ti tj   satisfies a random instance. note that ef n  should be independent of the choice of the forced solution ti. so we have:
.
where e n1  and e n  are  respectively  the second moment and the first moment of the number of solutions for random unforced instances.
¡¡for random 1-sat  it is known that the strategy mentioned above is unsuitable as it produces a biased sampling of instances with many solutions clustered around t  achlioptas et al.  1 . experiments show that forced satisfiable instances are much easier to solve than unforced satisfiable instances. in fact  it is not hard to show that  asymptotically  e n1  is exponentially greater than e1 n . thus  the expected number of solutions for forced satisfiable instances is exponentially larger than the one for unforced satisfiable instances. it then gives a good theoretical explanation of why  for random 1-sat  the strategy is highly biased towards generating instances with many solutions.
¡¡for model rb  recall that when the exact phase transitions were established  xu and li  1   it was proved that e n1 /e1 n  is asymptotically equal to 1 below the threshold  where almost all instances are satisfiable  i.e.
e n1 /e1 n  ¡Ö 1 for r   rcr or p   pcr. hence  the expected number of solutions for forced satisfiable instances below the threshold is asymptotically equal to the one for unforced satisfiable instances  i.e. ef n  = e n1 /e n  ¡Ö e n . in other words  when using model rb  the strategy has almost no effect on the number of solutions and does not lead to a biased sampling of instances with many solutions.
¡¡in addition to the analysis above  we can also study the influence of the strategy on the distribution of solutions with respect to the forced solution. we first define the distance df ti tj  between two assignments ti and tj as the proportion of variables that have been assigned a different value in ti and tj. we have 1 ¡Ü df ti tj  ¡Ü 1.
¡¡for forced satisfiable instances of model rb  with ef¦Ä n  denoting the expected number of solutions whose distance from the forced solution  identified as ti  here  is equal to ¦Ä  we obtain by an analysis similar to that in  xu and li  1 :
	with df ti tj  = ¦Ä

 .
 it can be shown  from the results in  xu and li  1  that ef¦Ä n   for r   rcr or p   pcr  is asymptotically maximized when ¦Ä takes the largest possible value  i.e. ¦Ä = 1.
¡¡for unforced satisfiable instances of model rb  with e¦Ä n  denoting the expected number of solutions whose distance from ti  not necessarily a solution  is equal to ¦Ä  we have:
.
it is straightforward to see that the same pattern holds for this case  i.e. e¦Ä n  is asymptotically maximized when ¦Ä = 1.
¡¡intuitively  with model rb  both unforced satisfiable instances and instances forced to satisfy an assignment t are such that most of their solutions distribute far from t. this indicates that  for model rb  the strategy has little effect on the distribution of solutions  and is not biased towards generating instances with many solutions around the forced one.
¡¡for random 1-sat  similarly  we can show that as r  the ratio of clauses to variables  approaches 1  ef¦Ä n  and e¦Ä n  are asymptotically maximized when ¦Ä ¡Ö 1 and ¦Ä = 1  respectively. this means  in contrast to model rb  that when r is near the threshold  most solutions of forced instances distribute in a place much closer to the forced solution than solutions of unforced satisfiable instances.
1	experimental results
as all introduced theoretical results hold when n ¡ú ¡Þ  the practical exploitation of these results is an issue that must be addressed. in this section  we give some representative experimental results which indicate that practice meets theory even if the number n of variables is small. note that different values of parameters ¦Á and r have been selected in order to illustrate the broad spectrum of applicability of model rb.
¡¡

figure 1: difference between theoretical and experimental thresholds against ¦Á  r and n
¡¡first  it is valuable to know in practice  to what extent  theorems 1 and 1 give precise thresholds according to different values of ¦Á  r and n. the experiments that we have run wrt theorem 1  as depicted in figure 1  suggest that all other parameters being fixed  the greater the value of ¦Á  r or n is  the more precise theorem 1 is. more precisely  in figure 1  the difference between the threshold theoretically located and the threshold experimentally determined is plotted against ¦Á ¡Ê  1 1   d ¡Ê  1..1    against r ¡Ê  1 1   m ¡Ê  1..1   and against n ¡Ê  1..1 . note that the vertical scale refers to the difference in constraint tightness and that the horizontal scale is normalized  value 1 respectively corresponds to n = 1  ¦Á = 1 and r = 1  etc. .

       1
 1 1 1 1 1 1 1 1 1 1 1 1 tightness  p 
figure 1: mean search cost  1 instances  of solving instances in rb 1 {1 1} 1 1 p 
to solve the random instances generated by model rb  we

       1
 1 1 1 1 1 1 1 1 1 1 1 1 tightness  p 
figure 1: mean search cost  1 instances  of solving instances in rb 1 {1 1} 1 p 
have used a systematic backtracking search algorithm  mac  and a local search algorithm  tabu search . both algorithms have been equipped with a search heuristic that learns from conflicts  boussemart et al.  1 .
¡¡we have studied the difficulty of solving with mac the binary instances of model rb generated around the theoretical threshold pcr ¡Ö 1 given by theorem 1 for k = 1  ¦Á = 1  r = 1 and n ¡Ê {1 1}. in figure 1  it clearly appears that the hardest instances are located quite close to the theoretical threshold and that the difficulty grows exponentially with n  note the use of a log scale . it corresponds to a phase transition  not depicted here  due to lack of space . a similar behavior is observed in figure 1 with respect to ternary instances generated around the theoretical threshold pcr ¡Ö 1 for k = 1  ¦Á = 1  r = 1 and n ¡Ê {1 1}.
¡¡as the number and the distribution of solutions are the two most important factors determining the cost of solving satisfiable instances  we can expect  from the analysis given in section 1  that for model rb  the hardness of solving forced satisfiable instances should be similar to that of solving unforced satisfiable ones. this is what is observed in figure 1.
¡¡to confirm this  we have focused our attention to a point just below the threshold as we have then some  asymptotic  guarantee about the difficulty of both unforced and forced instances  see theorems 1 and 1 in  xu and li  1   and the possibility of generating easily unforced satisfiable instances. figure 1 shows the difficulty of solving with mac both forced and unforced instances of model rb at pcr   1 ¡Ö 1 for k = 1  ¦Á = 1  r = 1 and n ¡Ê  1..1 .
¡¡to confirm the inherent difficulty of the  forced and unforced  instances generated at the threshold  we have also studied the runtime distribution produced by a randomized search algorithm on distinct instances  gomes et al.  1 . for each instance  we have performed 1 independent runs. figure 1 displays the survival function  which corresponds to the probability of a run taking more than x backtracks  of a

figure 1: mean search cost  1 instances  of solving instances in rb 1  1..1  1 1 pcr   1 
randomized mac algorithm for two representative instances generated at pcr ¡Ö 1 for k = 1  ¦Á = 1  r = 1 and n ¡Ê {1}. one can observe that the runtime distribution  a log-log scale is used  do not correspond to an heavy-tailed one  i.e.  a distribution characterized by an extremely long tail with some infinite moment. it means that all runs behave homogeneously and  therefore  it suggests that the instances are inherently hard  gomes et al.  1 .

figure 1: non heavy-tailed regime for instances in rb 1 {1} 1 1 pcr ¡Ö 1 
¡¡then  we have focused on unforced unsatisfiable instances of model rb as theorem 1 indicates that such instances have an exponential resolution complexity. we have generated unforced and forced instances with different constraint tightness p above the threshold pcr ¡Ö 1 for k = 1  ¦Á = 1  r = 1 and n ¡Ê  1..1 . figure 1 displays the search effort of a

figure 1: mean search cost  1 instances  of solving instances in rb 1  1..1  1 1 p 
mac algorithm to solve such instances against the number of variables n. it is interesting to note that the search effort grows exponentially with n  even if the exponent decreases as the tightness increases. also  although not currently supported by any theoretical result  theorems 1 and 1 of  xu and li  1  hold only for forced instances below the threshold  it appears here that forced and unforced instances have a similar hardness.
¡¡finally  figure 1 shows the results obtained with a tabu search with respect to the binary instances that have been previously considered with mac  see figure 1 . the search effort is given by a median cost since when using an incomplete method  there is absolutely no guarantee of finding a solution in a given limit of time. remark that all unsatisfiable  unforced  instances below the threshold have been filtered out in order to make a fair comparison. it appears that both complete and incomplete methods behave similarly. in figure 1  one can see that the search effort grows exponentially with n and that forced instances are as hard as unforced ones.
1	related work
as a related work  we can mention the recent progress on generating hard satisfiable sat instances.  barthel et al.  1; jia et al.  1  have proposed to build random satisfiable 1sat instances on the basis of a spin-glass model from statistical physics. another approach  quite easy to implement  has also been proposed by  achlioptas et al.  1 : any 1-sat instance is forced to be satisfiable by forbidding the clauses violated by both an assignment and its complement.
¡¡finally  let us mention  achlioptas et al.  1  which propose to build random instances with a specific structure  namely  instances of the quasigroup with holes  qwh  problem. the hardest instances belong to a new type of phase transition  defined from the number of holes  and coincide with the size of the backbone.

 1 1 1 1 1 1 1 1 1 1 1 1 tightness  p 
figure 1: median search cost  1 instances  of solving instances in rb 1 {1 1} 1 1 p  using a tabu search
1	conclusion
in this paper  we have shown  both theoretically and practically  that the models rb  and rd  can be used to produce  very easily  hard random instances. more importantly  the same result holds for instances that are forced to be satisfiable. to perform our experimentation  we have used some of the most efficient complete and incomplete csp solvers. we have also encoded some forced binary csp instances of class
rb ranging from 1 to 1 into sat ones  using the direct encoding method  and submitted them to the sat competition 1. about 1% of the competing solvers have succeeded in solving the sat instances corresponding to n = 1  d = 1 and m = 1  whereas only one solver has been successful for n = 1  d = 1 and m = 1 .
¡¡although there are some other ways to generate hard satisfiable instances  e.g. qwh  achlioptas et al.  1  or 1hidden  achlioptas et al.  1  instances  we think that the simple and natural method presented in this paper  based on models with exact phase transitions and many hard instances  should be well worth further investigation.
acknowledgments
the first author is partially supported by nsfc grant 1 and fanedd grant 1. other authors have been supported by the cnrs  the  programme cocoa de la region¡ä nord/pas-de-calais  and by the  iut de lens . 