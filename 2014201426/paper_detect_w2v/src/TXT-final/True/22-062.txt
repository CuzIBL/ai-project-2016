 
we present a methodology for using analogy to derive programs based on a derivational transformation method. the derived programs are deductively closed under the rules in the knowledge base  and the emphasis is on speeding up the derivation of a solution. we describe certain heuristics to find a good source analogue to the target problem efficiently  show how the derivation trace of that program can be used to guide the derivation of the new program. 
1 	introduction 
analogical reasoning is a mechanism for using past experience in solving a problem to solve a new  similar problem. almost all the systems that perform analogical reasoning fall under one of two broad categories. the first category of systems use analogy to solve a problem for which the domain theory is incomplete  winston  1  falkenhainer et a/.  1  greiner  1 . in such systems it would not be possible to solve the problem by a deductive mechanism  using only the known facts about the domain  and it is necessary to fill in the missing parts by analogy from a different situation or domain. the other category of systems use analogy to speed up the derivation of a solution. the final solution is deductively closed under the given domain theory  i.e. even without analogy  it would have been possible to arrive at the solution. such systems have mostly been used for theorem-proving and program construction  kling  1  dershowitz  1  though there are exceptions  davies and russel  1 . 
1 	u n i x programming by analogy 
the work presented here falls into the second category. it uses analogy to derive a program using past experience in solving a similar problem. the domain of programming is the unix operating system environment. unix programming is very similar to conventional programming. its piping  sequencing  input-output redirection  shell control constructs  etc. are similar to the control structures available in high level programming languages. however  unix has a much richer set of primitive commands. these can be considered similar to a library of standard subroutines in conventional programming. 
thus one works with a richer set of building blocks than is available in general programming. 
1 	problem specification 
the system described here is designed to work on top of an automatic programming system which takes a semiformal specification of a problem and produces the correct sequence of unix commands or a shell script to solve the problem. a problem specification in our system has the following form: 
input: primitive-objects 
 where: type-spec  such-that:constraints  output: primitive-fn arguments  
 where: type-spec  such-that: constraints  effects: priraitive-fn arguments  
where: type-spec  such-that: constraints  
　here  input and output specify the input and outputs of a program  and effect specifies any sideeflfects that a program may have. the where slot describes the domains for the various fields  and suchthat specifies the constraints on the field values. for example  to specify a program that prints the name of all files greater than 1k and the owner of the file  the problem specification would be: 
input: d i r where:  directory d i r   
output:  list f u  
such-that:  and  belongs f d i r   
    size 1  1k  
 owner u f  
	where: 	 and  file f   user u   
　in the above examples  belongs  owner  etc. are predefined predicates/functions and files  directories  users  etc. are pre-defined objects known to the system. in addition  it is possible for a user to define new relations  functions and objects and use them in a problem specification. for example a user may define an ancestor function as : 
#define ancestor 
input: f such-that:     1 / /   where:   f i l e f  
output:  list d  
such-that: = d  union parent d  
 ancestor parent d         
where:  directory d  
	harandi and bhansali 	1 

1 	the rulebase 
the system has three different levels of rules  each representing a different degree of generality. these rules are used to generate a unix program for a given specification. the steps taken in decomposing a problem and the set of rules applied in the process form the basis for solving analogical problems. 
   at the highest level the system has rides that encode domain-independent high level strategies for problem solving. these rules are encoded in the form of stereo-typed templates of shell scripts  similar to the concept of programming cliches in kbemacs  waters  1   with the appropriate commands filled in for solving the particular problem. examples of such strategies are recursively-solve  divide-and-conquer  and loop-overobjects. 
　the second level of rules are related to solving problems in the operating system domain. these rules encode common sense reasoning about problem solving  e.g. to count the number of objects of type a  map the objects of type a into objects of type b  count the number of objects of type b  and apply the inverse mapping relation to the output of count. 
　the third category of rules are those that are specific to the unix operating system. this is the largest part of the rule base  and forms an index to the commands available in unix. an example of such a rule would be: to list all sub-objects of a directory use command is. 
1 	finding analogues 
before a system can apply an analogy  it has to discover a source analogue. unlike some systems  we do not assume that the analogues to be matched are specified by the user. therefore  the system has to find a source analogue given the target problem. to do this task it has some heuristic knowledge built in. 
   to get an intuitive feel for the kind of knowledge required to find analogue matches  we consider an example. suppose we want a program that removes all the files bigger than 1k. suppose we have already solved a problem to delete all processes with cpu times greater than 1 sec. a program to solve this would be: form a list of all the processes  select all processes whose cpu time is greater than 1 sec  retrieve their process-id's and kill the processes. seeing this solution  we can get 
an insight on how to solve the problem of deleting all files bigger than 1 k : form a list of all the files  select those whose size is greater than 1 k  retrieve the file names and remove the files. 
   both the above problems involve deleting objects and comparing numbers. but this is not the main reason that the analogy worked. to see this  consider another problem of changing the names of all files that do not have write access by appending a suffix .read to them. this problem has nothing to do with deleting objects or comparing numbers  but the same program structure can be used to solve this problem: form a list of all files  select those files that do not have write access  retrieve their names  say name   and change it to name.read . 
the reason the analogy worked in both the cases is 
1 	automated deduction 
that they arc both instances of the search-and-process paradigm. they involve a search for a particular object among several similar objects and then some processing on a particular attribute of that object. abstractly  each of the above problem can be stated as: 
     apply c x  where x 1 d such that p x  where c is an abstract function  d is the type of the input and p is the predicate characterising those x on which the operator c is to be applied. 
　the success of the analogical reasoning system is  therefore  contingent on detecting the occurrence of such paradigms from the problem specification. at the same time  note that problem 1 seems to be  more  analogous to problem 1 than to problem 1. thus  given both problems 1 and 1 in the knowledge base  to solve problem 
1  we would like problem 1 to be retrieved rather than problem 1. thus  the analogue matcher should return not just a possible source analogue  but the best possible source analogue in the knowledge base. the next section gives some heuristics on how this can be done. 
1 heuristics to detect analogies f r o m problem specifications 
1.1 	functional abstraction heuristic 
　if two problems involve instantiations of the same abstract function  then it might be possible to replace the program fragment corresponding to that function in the source program by an analogous program fragment in the target program. 
　the first example above illustrates this. both deleting a file and killing a process are instantiations of the abstract function remove . if we know the program fragment for finding the object  we can append the code corresponding to deleting a file or killing a process to get one or the other program. 

　such analogies can be detected by building an abstraction hierarchy for the various functions as illustrated in fig. la. note  that most of the functionality provided by unix has already been captured in our specification language. for example  instead of specifying kill process or remove directory the user would simply say: 
　　effect: remove /foo  where: directory /foo  or  effect-. remove pr  where:  process pr  
　however  one feature of unix  and also our system  is that it allows a user to invent new commands and hence  not all the functions can be captured by our specification language. but the system can still build the abstraction hierarchy dynamically from the specification of the problem. thus  suppose a user creates a new command make-index defined as : 

input: foo where:  file foo  output: list w n  such-that:... 
where: and  word w  int n   
then  the command gets automatically incorporated into the abstraction tree shown in fig. 1 b   since the output of the command is to display a list. so  when we get a new problem make-table   defined as 
input: 	foo 	where:  file foo  
output: list a b c  where:... such-that:... 
we can immediately access the make-index command  and if there is some similarity  use that command to generate a program to create the table. 
1.1 same higher order relationship between arguments or systematicity heuristic 
　this heuristic is based on the systematicity principle proposed by gentner  gentner  1 . slightly abusing the definition  we can say that if the input and output arguments of two problem specifications are related by the same abstract relationship  then the two problems are more likely to be analogous. 
　again  the first example in section 1 provides an illustration of the application of this heuristic. it is instructive to look at the formal specification of the two problems: 
pi.-input: d where:  directory d  
effect: remove f  
where: file f  
such-that: and  belongs f d  
    size f  1   
p1:input: u where:  user u  
effect:  remove p  
where:  process p  
such-that:  and  belongs p u  
    cpu-time p  1   
　in this example  the two arguments of each problem are related by the same relation belongs . but more interesting is the second constraint  which says that a unary function of the output argument of each problem is related by the abstract relation comparison  instantiated to   and   respectively . if we view each unary function as an abstract relation called attribute with two arguments - the name of the attribute and the original argument - then  the above constraints      attribute f  size   i1 and   aitribute p  cpu time   1   can be seen as instances of the following second-order relation 1: 
rel1  rell  argl  propertyl   re lo  
　therefore  according to the systematicity heuristic the two problems may be analogous. 
　to detect analogous problems based on the systematicity heuristic  the system would have to determine the order of each relation in the problem specification and then match the highest order relation from the two problems. if they belong to the same abstract relation 
1
　　the order of a relation is defined as follows: constants are order 1. the order of a predicate is 1 plus the maximum of the order of its arguments. 
then the corresponding arguments of the relation have to be matched recursively until the zero-order relations are matched. 
1.1 	similar syntactic structure heuristic 
　for those functions that are defined dynamically by the user  there is another clue which can suggest that two problems might have analogous solution: the structural similarity of the function definition. thus  if both functions are recursive then their solutions would be very similar. for example a program to find ancestors defined in section 1 might consist of a shell file called ancestor. when this file is called with an argument  the shell script checks that the argument is not '/'  end-ofrecursion test   prints the parent of the argument and invokes the same file again with the parent as the argument. having solved this  it is easy to determine a program for descendants defined below: 
descendants:-
input: 	 list d i r   where: 	 directory d i r   
output: 	 list t  
	such-that: = f 	 union sub-objects d i r   
 descendant 
　　　　　　　　　　　　　　 sub-objects 	d i r         where: file-objects 	f  
　the program would involve creating a similar shell file  that checks that its argument list is non-null and then for each argument it prints the sub-objects under it  and calls the file recursively with the sub-object as the argument. 
　it may be remarked that problems having a similar definition structure can generally be solved by using strategy rules  since both are inherently syntactic in nature. 
1.1 	argument abstraction heuristic 
　as in the case of functions  we can envision an abstraction hierarchy for certain objects which appear as arguments in the problem specification. in some cases if two problems have arguments that belong in the same abstraction hierarchy  the two problems may be analogous. for example  count number of paragraphs  count number of lines and count number of words are analogous. all involve finding a way of recognizing a text-object by finding its terminator  white space for a word  a newline for a line  a blank line for a paragraph   mapping them to a countable object and counting that  using the rule given in section 1 . however  in other cases it may not work  e.g. a page is not recognized by a delimiter but in terms of the number of lines  typically 1 . 
1 	how the heuristics interact with each other 
in general each of the above heuristic will suggest several  and possibly different  problems as a potential analogue of the target problem. therefore the matcher needs to decide what importance should be attached to each suggested alternative  and in what order they should be tried. 
　the most important heuristic seems to be the systematicity heuristic  and if there are any problems sup-
	harandi and bhansali 	1 

ported by that heuristic the matcher tries them first. next in importance are the definitional structure and the functional abstraction heuristic. in case of ties  the problem with the maximum number of support from the lower heuristic is used to decide which problem should be tried. the fourth heuristic is not really strong enough to be used as a basis for deciding on a particular problem as the source analog  and is used only as a support for strengthening the candidature of a problem suggested by the other heuristics. 
1 	derivational analogy 
1 	problems w i t h direct solution transformation 
most analogy systems are based on a solution transformation method  kling  1  dershowitz  1  carbonell  1a . in this method the system retrieves the solution of a problem which is similar to the current problem  and perturbs the solution  guided by some heuristics  until it satisfies the requirements of the new problem. such systems ignore the reasoning behind the various steps used in deriving the original solution. though this method works in some domains  it is inadequate in program construction  and even when they work they often result in inefficient and inelegant solutions. 
　as a simplistic example  suppose we have program which counts the number of occurrences of each word in a file. this program first forms a list of all the words occurring in the file and then for each word finds how many times it occurs in the file. the list of all words in the file is formed by writing each word of the file in a separate line and then deleting duplicate lines. 
   now  suppose we want to derive a program to count the number of occurrences of each character in a file using the above. using a solution transformation method on the final program  one would produce a program that finds a list of all characters in the file by listing each character on a separate line and deleting duplicate lines  which is extremely inefficient  since there are only about a 1 or so characters in a text file  which are known a 
   priori by any programmer. 
   we use a derivational transformation method based on  carbonell  1b . such a method avoids the kind of inefficiency encountered above  because it records the reasons for each step in the program derivation. therefore  it can figure out that the reason for writing each word in a separate line and then deleting duplicate lines is to get a list of unique words in the file; and  since it knows of a direct method of listing all possible characters in a file  it can generate a more efficient program. 
1 	derivation trace 
a derivation trace consists of the subgoal structure of the problem  a pointer to each rule used in decomposing the problem at each node of the tree and the final solution. fig. 1a shows the derivation tree for a program to find the most frequent word in a file. 
　fig. 1b and 1c show some of the rules in english used to derive the sub-tree below each node  and the unix 
1 	automated deduction 

1 	the derivational transformation m e t h o d 
the derivational transformation method can best be understood by going through the derivation of an example. the source program is the same as shown in fig. 1. the target problem is: 
find the most frequent file name in a system. 
assume that the system has selected the problem in fig. 
1 as the best possible analogue to this problem  based on the heuristics given in section 1. the first step in generating a solution to this problem is to see if there is a direct unix command to do this. the rules pertaining to unix commands are stored separately from the other rules and are always searched first. since there isn't a direct command to solve the problem  the system tries to generate a program by an analogue transformation of a previous solution. 
　the first rule used in fig. 1a is rule r l . this rule is applicable to the target problem with object being instantiated to file-name. so the system uses the same rule to get the top-level decomposition of the problem. 
　next  the system goes down the left branch of both the source and target trees  and repeats the process  

till it comes to a node where the rule is not applicable. this happens when it tries to apply rule r1  which is applicable only for text-objects in a text-stream. at this stage  the system reverts back to its usual problem solving mode and tries to solve the problem by first principles.  eventually  it will discover the is -r command which lists all objects under a directory and the grep command to remove extraneous information about sub-directories  links  etc.  
   the other nodes of the sub-tree referring to removal of duplicate lines  mapping the file-names into lines and counting lines  and taking the maximum from the list remain valid for this problem  and hence  that part of the program remains the same. 
　the final program resulting from this method is shown in fig. 1. 
 code to get list of flle~name1  
for word ln 'sort /tmp/fl | unlq' 
do count = 'grep sword /tmp/fl | we - i ' echo sword $count 
done 
 code to find maximum  
fig 1. unix program to find the most frequent file-name under a directory. 
   note  that at each step the system checks for a direct method of solving the problem; thus  it can take advantage of a more efficient method of solving the problem  if it exists. 
1 	algorithm 
we now give the an outline of the algorithms used for deriving a program by analogy. the general algorithm for solving a problem is given first. 
solve p  
1. search the command-library to see if p can be solved directly by using a unix command. if so  then return that command as the solution for p  else continue. 
1. find p'  the best possible analogous problem to p  using the analogue-matching heuristics. if such a problem cannot be found go to step 1. 
1. call the analogy algorithm on p and p' if it returns a solution  return that solution  else go to step 1. 
1. using the rules in the knowledge-base  decompose the problem into sub-problems. in general this will return a set d  each element of which represents a 
way of decomposing the problem. while d is nonempty repeat : 
choose any decomposition d e d and delete it from d. let d =  p1 p1 - pn    where each p  represents a sub-problem of p. for each pi  call solve pi   and let si denote the solution returned. if none of the si is fail  and the all the si's are compatible  see notes below   then return the sequence  s1  s1 ... sn  as the solution for p. 
1. return fail. 
　in step 1 above  after each of the sub-problem is solved  it is still necessary to check that the solutions do not interact destructively  and invalidate the solution for p. therefore  after a potential solution is obtained  it is passed to a plan analyzer  which checks that the subgoals achieved by each sub-solution is not destroyed by the other sub-solutions. if necessary  the plan analyzer re-orders the solutions. however  if it is not possible to achieve the goal even after re-ordering  it reports failure  and the algorithm has to consider some other decomposition scheme and/or backtrack. 
　before presenting the analogy algorithm we define two terms. two problems are said to be directly analogous if the same rule r applies with the same in-
stantiation of parameters for the two problems. they are possibly-analogous if the same rule r is applicable to both the problems with a different instantiation of the parameters. 
a n a l o g y   p   p '   
1. compare p and p   
 a  if they are directly-analogous perform the analogical substitutions in s  the program fragment correponding to p   to get s' the program fragment corresponding to p ' 
 b  if they are possibly-analogous go to step 1. 
 c  return fail. 
1. let r be the rule used to decompose p into subproblems p1 p1 .-. pn   use the same rule to decompose p' into sub-problems p1 p'1 ... pn'-
1. for each sub-problem pi' do : 
check the command-library to see if it can be solved directly using a unix command. if so  record that as the solution  si . else  let si = analogy  pi- pi' . i f * = fail  let si zr solver' . if s o l v e r   also returns fail  then return fail. 
1. check that the solution set  s1  s1        sn  is compatible. if so  return it  else return fail. 
　note that the algorithm checks whether the subproblems obtained after decomposition can be solved directly using a unix command  step 1 . hence  if a more efficient solution exists for the problem  the system would discover it. 
　thus  the system integrates traditional problemsolving methodology with analogical reasoning  without sacrificing the possibility of finding a better solution for a problem. 
1 	when to use analogy  
as has been mentioned  the solutions obtained by the analogical process could have been obtained deductively from the rules in the knowledge base without using analogy. therefore  a natural question to ask at this stage is: under what conditions should one try to use analogy to solve the problem  
　let t a  p  be the time to solve a problem p using purely analogical reasoning and t d  p  be the time taken to solve the same problem using direct problem-solving 
	harandi and bhansali 	1 

methods. 	for analogical reasoning to be justified we want that: 

　the time taken to solve a problem using analogy depends on the time taken to find the analogy and the number of rules used in the derivation of the solution. thus  assuming that all rule applications take the same amount of time  we may say: 

where tm is the time to find an analogue source problem  n is the number of rules used to solve the problem  and c is a constant. solving a problem using direct problemsolving techniques requires a search through the knowledge base of rules. if k is the average number of rules searched for each rule that is finally applied then 

　therefore  for such problems the use of analogy is justified if the sum of the time to find analogs and the time to apply the rules is much smaller than the time to search the knowledge base for the rules. 
   however is most of the cases  analogy alone is insufficient to solve the problem. let p be the average proportion of rule that are matched directly using analogy and q = 1 - p be the average proportion of rules that are obtained through a search of the knowledge base. the time to solve a problem using analogy is now given by: 

for analogy to be justified  

　the above equation suggests that analogy will be useful if: 
1. the time to find analogue matches is small. 
1. the degree of similarity of the source problem to the target problem is high. 
1. the number of rules that have to be searched  and hence k  is large. 
1. the size of the problem  and hence n  is large. 
　the time to find analogue matches does not depend on the size of the knowledge base of rules but only in the size of the knowledge base of stored programs. to reduce this factor it is important that the problems should be stored judiciously. some of the plausible heuristics that the system can use to decide whether a problem should be stored in the knowledge base are:  i  the number of rules used in deriving the problem is large;  ii  the time taken to solve the problem is large;  iii  the length of the final solution is large;  iv  the degree of match of the problem with some previous problem is low. 
　the fourth criteria is important to reduce redundancy in the knowledge base. 
1 	conclusions 
this work presents a paradigm for using analogy to derive programs from a problem specification  using the derivation of an earlier program. it differs from previous work on deriving programs using analogy in two respects. first  it maintains the derivation history of a 
1 	automated deduction 
program to determine when an analogical transformation can be validly made. secondly  it does not depend upon an external user to provide a source analogue. it uses certain heuristics to efficiently find a good source program that is analogous to the new program. the program derivation process combines ordinary problem solving with analogical reasoning to find the solution of a problem as efficiently as possible. the program derived is deductively closed under the rules in the knowledge base. thus  the soundness of the solution does not have to be verified. 
　the system presented here is under development as part of an automatic programming project to automate unix programming. the success of the design can only be judged after it has been applied on a large knowledge base  but it seems reasonable to believe that the system would perform better as the size of the knowledge base increases  and deriving programs by a search through the knowledge base becomes more and more computationally expensive. 
acknowledgements: we thank gregg collins for early criticism of the work. the paper has benefited from comments of brian falkenhainer and members of the kbpa group. 
