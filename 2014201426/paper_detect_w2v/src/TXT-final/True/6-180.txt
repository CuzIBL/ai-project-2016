 
we describe a framework for reducing the space complexity of graph search algorithms such as a* that use open and closed lists to keep track of the frontier and interior nodes of the search space. we propose a sparse representation of the closed list in which only a fraction of already expanded nodes need to be stored to perform the two functions of the closed list - preventing duplicate search effort and allowing solution extraction. our proposal is related to earlier work on search algorithms that do not use a closed list at all  korf and zhang  1 . however  the approach we describe has several advantages that make it effective for a wider variety of problems. 
1 introduction 
graph search algorithms such as dijkstra's algorithm and a* use an open list to store nodes on the search frontier  and a closed list to keep track of already expanded nodes. the closed list performs two important fiinctions. 
1. it allows the optimal solution path to be reconstructed after completion of the search by tracing pointers backwards from the goal node to the start node. 
1. in graph search problems  it allows nodes that have already been reached along one path to be recognized if they are reached along another path  in order to prevent duplicate search effort. 
although both functions are important  storing all expanded nodes in a closed list can quickly use all available memory. 
　if one is willing to give up the ability to recognize when the same node is reached along different paths  ida* and rbfs can solve search problems in linear space  korf  1; 1 . related search algorithms provide a limited ability to prevent duplicate search effort by storing a limited number of expanded nodes  reinefeld and marsland  1; miura and ishida  1 . in complex graph search problems with many duplicate paths  however  an inability to prevent all duplicate search effort often leads to poor performance. 
　fortunately  it is not necessary to store all expanded nodes in a closed list in order to eliminate all duplicate search effort. it is only necessary to store enough nodes to form 
search 
a  boundary  in the search graph that prevents previously closed nodes from being revisited. this is the strategy adopted by a pair of recent search algorithms  korf  1; korif and zhang  1   which are related to earlier work on reducing the memory requirements of dynamic programming algorithms for sequence comparison  hirschberg  1; myers and miller  1 . if not all expanded nodes are stored in a closed list  an alternative method of solution extraction is needed - since closed nodes along an optimal solution path may no longer be in memory when the search ends. so  these algorithms preserve information about nodes that are in the middle of a solution path. after the search ends  they use this information to divide the original problem into sub-problems - employing a divide-and-conquer strategy to recursively reconstruct an optimal solution path. this approach to reducing memory requirements results in an algorithm with two distinct phases; the first phase searches from the start to the goal node  and the second phase uses a divide-and-conquer method to reconstruct an optimal solution path. 
　in this paper  we describe some improvements of this search strategy. earlier search algorithms that use this strategy do not store a closed list at all  korf  1; korf and zhang  1 . instead they include extra information in open nodes  and even insert additional nodes into the open list  to ensure that it forms a  boundary  that prevents  leaks  back into the closed region. instead of adding information to the open list  our algorithm preserves some already expanded nodes in a closed list - but only enough to create a boundary and allow efficient solution reconstruction. much of the closed region of the search can be removed from memory. thus  we call this a sparse representation of the closed list  and a sparse-memory approach to graph search. we show that it results in a more flexible approach to reducing memory requirements that offers several advantages. 
1 background 
the most closely related algorithms to the search algorithm we introduce in this paper are divide-and-conquer bidirectional search  dcbs   korf  1  and divide-and-conquer frontier search  dcfs   korf and zhang  1 . although both are general graph-search algorithms  they were developed as an approach to performing multiple sequence alignment  and the memory-saving technique they use was first used by related dynamic programming algorithms for se-
quence comparison  hirschberg  1; myers and miller  1 . to provide some perspective  we begin with a brief description of the multiple sequence alignment problem. for a detailed description of this problem  we refer to our references. 
1 	multiple sequence alignment 
alignment of multiple dna or protein sequences is an important problem in computational biology. it provides a way to measure the similarity between sequences and detect related segments. alignment involves inserting gaps into sequences in order to maximize the number of matching  characters.  it is well-known that this problem can be formalized as a shortest-path problem in a n-dimensional lattice  where n is the number of sequences to be aligned. the number of nodes in the lattice is ln  where / is the average length of sequences  and thus grows polynomially with the length of sequences  and exponentially with the number of sequences. although dynamic programming is the traditional method for solving this problem  a* has been shown to outperform it by using an admissible heuristic to limit the number of nodes in the lattice that need to be examined to find an optimal alignment  ikeda and imai  1; lermen and reinert  1 . but given the large number of nodes that usually must be examined  memory is a bottleneck  and techniques for solving this problem in reduced memory can be very helpful. 
1 	divide-and-conquer frontier search 
both 	divide-and-conquer 	bidirectional 	search 
 dcbs   korf  1  and divide-and-conquer frontier search  dcfs   korf and zhang  1  use the same strategy for reducing memory requirements. the difference is that dcbs uses bidirectional search and dcfs uses unidirectional search. korf and zhang  find that unidirectional search results in better performance  and so we refer to dcfs in the rest of this paper. 
　dcfs reduces memory requirements by storing only the frontier nodes of the search  not the interior nodes - that is  by using an open list but not a closed list. because it does not use a closed list  dcfs must use some other method to avoid duplicate node expansions and to extract an optimal solution path at the end of the search. the problem of avoiding duplicate node expansions is particularly important in the case of multiple sequence alignment because there are combinatorially many paths from the start node to any other node. for this reason  linear-space search algorithms that do not test for duplicates  such as ida*  have  pitiful results   in the words of korf    when used for multiple sequence alignment. even bounded-memory search algorithms that detect some but not all duplicates have been reported to perform poorly on this problem  yoshizumi et ai  1 . 
　to avoid duplicate node expansions  dcfs uses the following techniques to prevent the search from  leaking  back into the closed region  that is  to prevent closed nodes from being re-generated. first  it stores in each node a list of forbidden operators. this list includes one operator for each neighbor  predecessor or successor  of this node that has already been generated. when the node is later selected for expansion  only operators that are not among the forbidden operators are used to generate its successor nodes. this prevents the search from re-generating nodes that may have been already closed and removed from memory. however  a complication arises in the case of directed graphs - in particular  directed graphs in which a node can have predecessors that are not also potential successors. if a node is expanded and removed from memory before all of its predecessors have been generated and inserted into the open list  it can be regenerated if one of these predecessor nodes is later expanded. to prevent this  dcfs modifies the open list in a second way. 
when a node is expanded  it generates not only its successor nodes  but all of its predecessor nodes - even if the search has not yet found a path to these predecessor nodes. if there is not yet a legal path to these predecessor nodes  they are assigned an infinite /-cost to prevent them from being expanded until a legal path is found. 
　to make it possible to reconstruct the solution path at the end of the search  dcfs modifies nodes in a further way. in each node past the midpoint of the search  it stores all information about a node on its path that is about halfway between the start and goal node. then  when the search is completed  dcfs knows a middle node on the optimal solution path  and can reconstruct the solution path by a divide-andconquer approach. using the same search algorithm  it recursively solves the subproblems of finding an optimal path from the start node to the middle node  and then from the middle node to the goal node. this recursive method of solution reconstruction is essentially the divide-and-conqucr idea first proposed by hirschberg . 
1 	limitations 
korf and zhang  show that dcfs can be very effective in  problem spaces that grow polynomially with problem size  but contain large numbers of short cycles   including path-planning in two-dimensional grids and multiple sequence alignment  assuming a small number of sequences. they acknowledge that their search algorithm is not as effective in an  exponential problem space with a branching factor of two or more.  in that case  they explain  the open list is much larger than the closed list and  not storing the closed list doesn't save much.  in fact  the multiple sequence alignment problem is an exponential problem space  and npcomplete  just  1    when the number of sequences to be aligned is not bounded. its branching factor is 1n - 1  where n. is the number of sequences   and the size of the open list can dwarf the size of the closed list when aligning as few as five or six sequences. this problem is well-known and has motivated development of techniques for reducing the size of the open list when using a* to align multiple sequences. these include use of an upper bound to prune open nodes that cannot lead to an optimal solution  ikeda and imai  1   and use of partial node expansions  yoshizumi et al.  1 . 
1 	search 　as it turns out  it is difficult to combine dcfs with techniques for reducing the size of the open list without creating inefficiencies  or even  leaks  back into the closed region. it is possible to combine dcfs with partial expansion a*  a technique for reducing the size of the open list by allowing partially expanded nodes  yoshizumi et al.  1 . this can be beneficial in some cases. but allowing nodes to be partially expanded has the effect of reducing the number of nodes that are closed. in turn  this reduces the memory-saving effect of dcfs by reducing the number of nodes eligible to be removed from memory  as our experimental results will show. 
　another approach to reducing the size of the open list is to prune open nodes when their /-cost is greater than an upper bound on the optimal /-cost  as in enhanced a*  ikeda and imai  1 . because this technique does not reduce the number of closed nodes  the idea of combining it with dcfs appears more promising. however  it introduces other difficulties. recall that dcfs generates all predecessors of a node when it is expanded  even if it has not yet found a path to these predecessors. if nodes are pruned from the open list  no path may ever be found to these extra nodes  and the open list may become cluttered with useless nodes that can never be removed. in directed graphs with the special property that the set of successors of each node is disjoint from the set of predecessors  such as the search graph of the multiple sequence alignment problem  this inefficiency is the only negative effect of pruning the open list. but in directed graphs that do not share this property  and in all undirected graphs  pruning nodes from the open list can also result in  leaks  back into the closed region  as follows. the first time a node is generated  there is no guarantee that the best path to it has been found. so  if it is pruned using an upper bound  it may later be re-generated if a better path to it is found. but since the forbidden operators associated with the node when it was first generated were lost when it was pruned  a node that was previously closed could be re-generated. 
　the difficulty of combining dcfs with techniques for reducing the size of the open list is a significant limitation. another potential limitation worth mentioning is the overhead for storing a list of forbidden operators in each node. for problems with a small branching-factor  this overhead is slight. but for the multiple sequence alignment problem  this overhead grows as the number of sequences grows. recall that the number of operators  i.e.  the branching factor  of multiple sequence alignment is  and dcfs stores incoming as well as outgoing edges in the list of forbidden operators. thus  the total number of edges incident to a node is 
 although korf and zhang  
claim that the space complexity of dcfs for multiple sequence alignment is  compared to the  space complexity of a*  this claim rests on the assumption that a node takes constant storage. as n increases  the storage required for the list of forbidden operators increases exponentially. in fact  the space complexity of dcfs for mulitple sequence alignment is  and its advantage over the  space complexity of a* disappears when  
1 	sparse-memory search algorithm 
the algorithm we describe in the rest of this paper adopts a strategy for reduced-memory search that is similar to the strategy used by dcfs. however  it implements this strategy in a simpler way that is more compatible with techniques for reducing the size of the open list  and does not require storing lists of forbidden operators in nodes. 
search 

figure 1: an illustration of the relationships among the kernel and the boundary of the search interior  the search frontier  and the entire state space. 
　a key difference from dcfs is that our algorithm does not entirely eliminate the closed list. instead  we propose a sparse representation of the closed list that allows many  but not all  closed nodes to be removed from memory. to explain our approach  we note that the search interior  the set of closed nodes  can be partitioned into two disjoint subsets that we call the set of boundary nodes and the kernel of the search interior. 
definition 1 let i be the set of search interior nodes  i.e.  nodes whose lowest-cost paths have been found. the kernel of i  denoted k  i   is defined as follows: 

where pred k  denotes the set of predecessor nodes ofk  that is  the set of nodes that can make a transition into node k in the underlying graph  which may be directed or undirected. 
basically  the kernel is the set of nodes whose predecessor nodes are all interior  i.e.  closed  nodes. 
definition 1 the set of boundary nodes of search interior i  denoted b i   is defined as the non-kernel nodes of l  that is: 

another way of describing a boundary node is to say that at least one of its predecessor nodes is not an interior node  or mathematically  

figure 1 illustrates the relationship between the kernel and boundary of the search interior. note that nodes in the boundary can enter the kernel  but once a node is in the kernel it remains there. the nodes in the kernel are eligible for removal from memory because they are not needed to prevent duplicate search effort. 
　the intuitive meaning of  boundary  can be explained as follows. because every closed node is reachable from the start node  the set of closed nodes can be considered a  volume  in the underlying graph that encompasses the starting node. nodes outside this volume cannot reach nodes inside the volume without passing through some node in the boundary. thus  storing only the boundary nodes in the closed list is as effective as storing the entire  volume   with respect to 

figure 1: pseudocode for smgs  sparse-memory graph 
search   in which procedure expandnode assumes a directed graph. see figure 1 for the pseudocode of expandnode in 
	because pointers require less memory than state information 	undirected graphs. 
about a midpoint node  the memory required to store all pointers plus relay nodes could be less than the memory required to copy state information about the same midpoint node into many other nodes. 
1 	search 

1 	pruning the closed list 
our search algorithm must be able to efficiently distinguish between the kernel and boundary of the search interior  in order to prune nodes from the kernel. recall that a node is in the kernel if all of its predecessors are closed. to identify such nodes  we introduce a technique for keeping track of the number of unexpanded predecessors for each generated-andstored node. we call this number the value of a node. it is initially set to the number of predecessors  the in-degree  of the node in the underlying graph minus one to account for the predecessor that generated it. the is updated during node expansion. as each successor of a node is considered  some of which may already be in the open or closed lists   its p- value is decremented.  see lines 1  1 and 1 of procedure expandnode in figure 1.  this requires negligible time and space overhead  and  given  kernel-membership for a node can be determined in constant time by checking whether it is a closed node with a  of zero. 
　an advantage of the sparse-memory approach is that it does not immediately remove closed nodes from memory  unlike dcfs. a sparse-memory version of dijkstra's algorithm  or a*  acts exactly like dijkstra's algorithm  or a*  until it senses that memory is about to be exhausted. only then does it invoke procedure pruneclosedlist in figure 1 to recover memory. this procedure prunes nodes from the closed list in two steps. first it updates the ancestral pointer of any boundary node whose predecessor is about to be pruned  lines 1 . this is necessary to allow solution reconstruction and requires finding the relay node that is the closest boundary node along its solution path  lines 1   and updating its ancestral pointer accordingly  line 1 . this makes this boundary node a relay node  and to prevent it from being pruned in the future  its  is set t o   l i n e 1 . after this step  kernel nodes are pruned unless they are a start node or relay node created in a previous pruning step  lines 1 . updating the ancestral pointers of nodes  followed by pruning  creates a sparse solution path  from which a complete or  dense  solution path can be reconstructed after the search terminates. 
1 	solution path reconstruction 
the fact that the closed list is not pruned unless memory is close to being exhausted means that the overhead of solution reconstruction can be avoided if memory resources are adequate. in that case  the sparse-memory algorithm acts exactly like dijkstra's algorithm  or a*  and an optimal solution path is extracted in the conventional way. 
　if the closed list has been pruned  an optimal solution path is reconstructed by invoking the sparse-memory graph search algorithm  smgs  in figure 1 recursively. first the sparse solution path  ssp  is extracted  line 1  in the conventional way by tracing pointers backward from the goal. then the corresponding dense solution path  dsp  is reconstructed as follows. for each pair of consecutive nodes  in the ssp  starting from the start 
node   the algorithm checks to see if is a predecessor of   line 1 . if so  n o d e i s added to the tail of the dsp  line 1 ; otherwise  the search algorithm calls itself recursively with and as the 
search 

figure 1: pseudocode for expandnode in undirected graphs. 
new start and goal nodes  in order to get a dense solution path between the two which is added to the tail of dsp  line 1 . 
　another difference from dcfs that is worth noting is that dcfs divides a problem into two subproblems at each level of the recursion. the sparse-memory approach can divide a problem into two or more subproblems. the extra flexibility is possible because the sparse-memory approach uses relay nodes with ancestral pointers  whereas dcfs stores all information about a middle node in each node. when a problem is divided into more than two subproblems  the subproblems are smaller and easier to solve and solution reconstruction can be faster. in fact  relay nodes can be spaced at half intervals  one-third intervals  or any other interval  and allow a tradeoff between the sparseness of the search interior and the speed of solution reconstruction. 
1 	pruning the open list 
we now consider how easily the sparse-memory approach to pruning the closed list can be combined with techniques for pruning the open list. pruning nodes on the open list that have an /-cost greater than an upper bound on the optimal /-cost creates difficulties for dcfs  as discussed earlier. an advantage of the sparse-memory approach is that it does not create difficulties  at least in solving problems for which the set of predecessors of a node is disjoint from the set of successors  such as the multiple sequence alignment problem. this advantage will be illustrated in our experimental results. 
　for other directed graphs  that is  for directed graphs in which the same node can be both predecessor and successor of another node  dcfs allows leaks back into the closed region when the open list is pruned. the sparse-memory approach does not  and this is another advantage. unfortunately  the sparse-memory approach has a problem in such graphs. if the best path to a node has not been found when it is first generated  it could be pruned and re-generated later  when a better path is found. since are erased when the node is pruned  the of such nodes will not be decremented to zero. as a result  the sparse-memory algorithm may not recover as much memory from the closed list. however  our experimental results suggest that this inefficiency is minor. 


figure 1: example of sparse-memory dijkstra searching for an optimal alignment of two sequences. panels  a  and  b  show the search space just before and after the first pruning of the closed list. panels  c  and  d  show the search space just before and after the second pruning. panel  e  shows the sparse solution path at the end of the search. 

　in undirected graphs  we noted earlier that dcfs also allows  leaks  back into the closed region when the open list is pruned. the sparse-memory algorithm does not  if we make a minor modification  as explained in the following. 
1 	undirected graphs 
the pseudocode in figure 1 shows the expandnode procedure for directed graphs. figure 1 gives the pseudocode of the expandnode procedure in undirected graphs. the difference is that in undirected graphs   are only set and decremented for closed nodes  not open nodes. thus  pruning open nodes cannot cause any problems by distorting values. in fact  the pseudocode in figure 1 could be used for directed graphs also. but in directed graphs  it would require considering all predecessors of a node as well as successors during node expansion  in order to set  correct. the overhead for this would be significant. this is not a problem in undirected graphs because the set of potential successors of a node is equal to the set of potential predecessors. 
1 	hybrid algorithms 
the sparse-memory algorithm we have described is based on more than one idea. it uses nodes on the closed list to create a  boundary  that prevents re-generation of closed nodes  instead of using the open list as a boundary. in addition  it uses relay nodes for divide-and-conquer solution reconstruction  instead of storing in each node state information about a middle node along the search path. 
　because these ideas can be considered separately  it is possible to create search algorithms that are hybrids of dcfs and the sparse-memory approach. for example  the dcfs technique of using the open list as a boundary could be combined with relay nodes. this would create a version of dcfs that is able to divide a solution path into more than two pieces  allowing flexible  and potentially faster  solution reconstruction; use of relay nodes would also allow dcfs to delay pruning of the closed list until memory is full. similarly  some of the techniques used by dcfs can be considered independently. for example  forbidden operators can be used in combination with the sparse-memory approach  instead of 
 one advantage of using forbidden operators is that they sometimes speed up search  since it is faster not to generate a node than to generate it and check for a duplicate on the open or closed list. we consider the performance of these hybrid algorithms in the computational results that follow. 
1 	computational results 
we first illustrate how a sparse-memory version of dijkstra's algorithm works by showing how it solves a small pairwise sequence alignment problem. then we consider the performance of sparse-memory a* on more challenging problems. 
1 	example 
consider the problem of aligning two sequences  actgat and tgactgc  using a very simple cost function: zero for a match  one unit for a substitution  and two units for a gap. the state space of the problem can be represented by a twodimensional grid in which the columns correspond to one sequence and the rows to the other. the problem of finding an optimal alignment of the two sequences corresponds to the problem of finding an optimal path from the start node in the upper-left corner to the goal node in the lower-right corner  where horizontal and vertical moves correspond to gap insertions in one or the other sequence  and diagonal moves correspond to a substitution or match of characters. 
　figure 1 shows the behavior of sparse-memory dijkstra s algorithm at the critical points when memory becomes full and the closed list is pruned. it assumes that memory capacity is 1 nodes. figure 1 a  shows the explored state space when memory is full for the first time. the number in each cell is the g-value of the corresponding state  or node . for closed nodes  the g-value is highlighted in bold italics. 
among the 1 closed nodes  ii are identified as kernel nodes and pruned. figure 1 b  shows the result of pruning. when memory is full the second time  as shown in figure 1 c   the closed list is pruned again and 1 kernel nodes are removed from memory  as shown in figure 1 d   freeing enough memory for continued search. figure 1 e  shows the state space in memory when the goal node  the cell in the lower-right corner  is expanded. the ssp solution is shown as a chain of thick dashed arrows. the arrows drawn in thin dashed lines represent ancestor pointers that are created during pruning. 
　in this example  it is also possible to see how the open list can be pruned using the sparse-memory approach. suppose we know that 1 is an upper bound on the cost of an optimal alignment. then all nodes with g-values greater than or equal to 1 can be pruned from the open list  and the search progresses in the same way except for not storing the seven nodes whose g-values equal 1. note that pruning nodes in the open list will not change the boundary of the search interior. 

1 	search 

1 	multiple sequence alignment 
we tested sparse-memory a*  sparse-a*  on a series of challenging multiple sequence alignment problems  in order to compare its performance to dcfa*  the dcfs version of a* . we used a 1mhz sun ultrasparc ii workstation with two gigabytes of ram. results are displayed in table 1. 
　first  we considered the identical test domain used by korf and zhang : alignment of three random sequences of length 1 using their simple cost function  with results averaged over 1 trials. both dcfa* and sparse-a* are effective in this domain  whereas a* could not solve any problem instance due to memory limitations. versions of a* that use special techniques to recover memory by pruning the open list  ikeda and imai  1; yoshizumi et al.  1  were also unable to solve any of these problem instances. this is because the closed list  not the open list  fills most of memory in this case. one reason there are so many closed nodes is that the accuracy of the pairwise heuristic used for multiple sequence alignment depends on the similarity of the sequences. because random sequences have only random similarities  the heuristic is weak  resulting in many node expansions and closed nodes. 
　for this problem set  dcfa* is more memory-efficient than sparse-a*. however  sparse-a* runs faster. it runs faster for long sequences like these because the solution path is correspondingly long  and solution reconstruction can be faster using relay nodes. at each recursion level  relay nodes make it possible to divide a solution path into several smaller  easier-to-solve subproblems  instead of always dividing it in half. faster solution reconstruction comes at the expense of a small increase in memory for extra relay nodes  as can be seen by comparing the performance of dcfa* using relay nodes  a hybrid algorithm  to standard dcfa*. 
　why can dcfa* be more memory-efficient than sparsea*  one factor is that using relay nodes to divide a solution path into more than two pieces requires extra memory for the extra relay nodes - a classic space-time tradeoff. another factor is that use of forbidden operators allows a closed node to be pruned as soon as all its predecessors are generated. by contrast  use of p-values requires waiting until all predecessors are closed  before pruning the node. as a result  a hybrid algorithm that combines the sparse-memory approach with forbidden operators outperforms the sparse-memory approach alone  for this problem set. these two factors may not account for all of the difference in memory efficiency  but we currently have no other explanation. 
　we next compared sparse-a* and dcfa* on real protein sequences using the pam1 cost matrix  which is widelyused by biologists. in aligning five sequences randomly selected from a pool of low-similarity protein sequences of length 1 used in previous experiments  mcnaughton et ai  1   sparse-a* and dcfa* were again effective in solving all instances. by contrast  a* ran out of memory on most instances. for this problem set  the enhanced a* algorithm  ikeda and imai  1   which uses an upper bound to prune nodes from the open list  performs very well. this is because the number of open nodes is very large for this set of problems. unlike dcfa*  the sparse-memory approach can be safely combined with this technique of pruning the 
algorithm | statistics 1 seqs.  1  1 seqs.  1  1 seqs. 
 1  | dcfa*   sees. 
nodes k  
1 mbytes 1 
1 
1 1 
1 
1 1
1 
1 dcfa* + 
relay nodes sees. 
nodes k  
mbytes 1 
1 
1 1 
1 
1 1 
1 
1 sparse-a* sees. 
nodes k  
mbytes 1 
1 
1 1 
1 
1 1 
1 
1 sparse-a* + forbidden ops. sees. 
nodes k  
mbytes 1 
1 
1 1 
1 
1 1 
1 
1 enhanced a* sees. 
nodes k  
mbytes can't solve 1 
1 1 1 
1 enhanced sparse-a* sees. 
nodes k  
mbytes 1 
1 
1 1 
1 
1 1 
1 table 1: performance comparison of dcfa*  sparse-memory a*  enhanced a*  and hybrid algorithms. the node count is the number of stored nodes  measured in thousands  and memory includes storage of the pairwise heuristic. 
open list. this gives it an overall advantage  and enhanced sparse-a* is the best-performing algorithm for this problem set.  although enhanced sparse-a* stores slightly more nodes than dcfa*  it uses less memory because forbidden operators makes the dcfa* nodes larger. we also emphasize the following point: although the table shows that the running time of enhanced a* is less than the running time of enhanced sparse-a*  this does not mean that it is a faster algorithm. if enhanced a* by itself can solve a problem in available memory  the sparse-memory version of enhanced a* does not need to prune the closed list at all  and has identical performance. but for these experiments  we adjusted the sparse-memory algorithm to minimize its memory use - since memory is the key factor we are evaluating here.  
　a drawback of dcfa* is that its node size increases as the number of sequences being aligned increases. this becomes very apparent when dcfa* is used to align seven protein sequences of length around 1  randomly selected from a set of similar protein sequences used in previous experiments  yoshizumi et al  1 . the high similarity of these sequences gives rise to a very accurate heuristic  and makes these sequences much easier to align. even a* can solve these problems. although a*  sparse-a* and dcfa* always expand the same number of nodes  dcfa* generates and stores an average of 1% more nodes in this domain because it inserts extra nodes in the open list. a more serious problem is that the nodes created by dcfa* are two times bigger than the nodes created by the other algorithms  because they include lists of forbidden operators. as a result  dcfa* runs slower and uses more memory than any other algorithm  including a*!  in aligning ten sequences  the nodes created by dcfa* are seven times larger than the nodes created by a*  

search 	1 

and their relative size almost doubles with each additional sequence thereafter.  the table shows sparse-a* is not as effective as enhanced a*  because pruning the open list is much more important than pruning the closed list  for this problem set. nevertheless  enhanced sparse-a* performs no worse than enhanced a*  and this point is important. the sparsememory approach improves performance when possible  and complements other techniques for reducing memory. for perspective  we discuss what happens if we combine dcfa* with partial expansion a*  yoshizumi et al  1 .  in our experiments  we set the cutoff value for partial expansion a* to zero  to minimize memory use.  for the set of seven similar protein sequences  partial expansion dcfa* required an average of 1 mbytes of memory  and 1 cpu seconds. the much greater running time is due to the overhead of partial expansions. the slightly higher memory requirement is because nodes are partially expanded  and nodes that are not closed cannot be pruned by dcfa*. for the set of three random 1-length sequences  partial expansion dcfa* stored 1% more nodes and ran 1% slower than dcfa*. again  the reason is that partially expanded nodes are not pruned. finally  we note that when dcfa* is combined with enhanced a*  it consistently requires more memory  and cpu time  than dcfa* alone  due to the complications discussed earlier. 
1 	1-puzzle 
the 1-puzzle is not a problem for which duplicate detection is a crucial issue. nevertheless  it is interesting to consider as both a benchmark and an example of an undirected graph. we used 1 of the 1 problem instances in korf  1  as a test set. sparse-a* by itself used an average of 1% of the memory used by a*; dcfa* used an average of 1% of the memory used by a*; and enhanced a* used an average of 1% of the memory used by a*. a sparse-memory version of enhanced a* performed best. it used 1% of the memory used by a*. we also tested dcfa* combined with enhanced a*. it is unable to prevent leaks back into the closed region  for reasons discussed earlier  and we noticed many node reexpansions. interestingly  it used only 1% of the memory used by a*  due to aggressive pruning  and ran faster than the other algorithms. but this is only because the 1-puzzle is a domain in which node re-generation has less overhead than managing the open and closed lists  since ida* outperforms all of these algorithms on this problem. in undirected graphs with exponentially many duplicate paths  a sparse-memory version of enhanced a* is likely to perform best. 
1 	conclusion 
we have proposed a sparse-memory approach to graph search that builds on ideas in earlier work  but implements them in a way that is often more effective. a key advantage of this approach to reducing the size of the closed list is that it can be combined with a technique for reducing the size of the open list by upper-bound pruning. this is especially useful for large branching-factor problems where the size of the open list would otherwise dramatically exceed the size of the closed list  such as the multiple sequence alignment problem when there are more than four or five sequences. 
　the sparse-memory approach has other advantages. it allows more flexible  and potentially faster  solution reconstruction. and last but not least  it can behave exactly like a*  or enhanced a*  or dijkstra's algorithm  until it reaches a memory limit  and only then removes nodes from the closed list. thus  there is  virtually  no overhead for this technique unless a search problem cannot be solved within a given memory bound. then the overhead for solution reconstruction is compensated for by the reduced memory requirements. 
acknowledgments we thank the anonymous reviewers for helpful comments. this work was supported in part by nsf career grant i1s-1 and nasa grant nag-1. 
