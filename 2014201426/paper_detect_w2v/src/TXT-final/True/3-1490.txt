
we present the continuous-time particle filter  ctpf  - an extension of the discrete-time particle filter for monitoring continuous-time dynamic systems. our methods apply to hybrid systems containing both discrete and continuous variables. the dynamics of the discrete state system are governed by a markov jump process. observations of the discrete process are intermittent and irregular. whenever the discrete process is observed  ctpf samples a trajectory of the underlying markov jump process. this trajectory is then used to estimate the continuous variables using the system dynamics determinedby the discrete state in the trajectory. we use the unscented kalman-bucy filter to handle nonlinearities and continuous time. we present results showing that ctpf is more stable in its performance than discrete-time particle filtering  even when the discrete-time algorithm is allowed to update many more times than ctpf. we also present a method for online learning of the markov jump process model that governs the discrete states.
1	introduction
the work described here is directly motivated by problems encountered in creating a state estimation system for the k1 experimental mars rover at nasa ames research center  willeke and dearden  1 . as with many robotic systems  k-1 contains numerous sensors that report on its performance. these sensors produce telemetry at different rates  and frequently at rates that vary over time. as a result  using a fixed time-step state estimator  for example a kalman filter  is extremely difficult. in this paper we describe a continuoustime state estimation algorithm based on particle filtering that can handle telemetry arriving at different rates and changes in system behavior between observations. the system can also update its model of system behavior to improve its performance and to detect gradual degradation of the system.
﹛state estimation is typically done either using discrete diagnosis algorithms such as livingstone  williams and nayak  1   or more recently  using hybrid system representations. the discrete approach is well suited for domains where there are occasional transitions between relatively stable states  and where sensor readings tend to be very reliable. unfortunately  this is not the case for k-1 and discrete approaches have largely proven unhelpful  washington et al.  1 . for this reason  we use a hybrid system model for state representation and particle filtering for state estimation.
﹛probabilistic hybrid automata  phas   hofbaur and williams  1  are commonly used for representing hybrid systems in diagnosis and state estimation  other representations have similar expressive power . in the pha model  a system consists of a set of discrete modes and a set of continuous variables. for each mode  a set of differential equations describes the continuous behavior in that mode. transitions between modes are stochastic; a transition matrix represents the probability of being in state s at time t + 1 given that the system is in state s at time t. transition probabilities may depend on the values of the continuous variables.
﹛the problem with applying the pha model  and other similar representations  to systems such as k-1 is the assumption that a transition matrix applied at fixed time intervals is sufficient to describe the evolution of the system. this implies that only one discrete transition can occur per interval  and also that it doesn't matter when in the interval the transition occurs. these assumptions lead to two problems. first  they make the system model unwieldy as they force a single transition matrix to represent the effects of multiple discrete transitions. second  they reduce efficiency by forcing model steps to be small enough for the assumptions to be reasonable. the continuous time model avoids these assumptions  allowing state updates to be performed only when a new observation arrives or when a significant event occurs.
﹛the approach we take is to build a continuous-time model of the system  see section 1 . as before  there is a differential equation model governing the continuous system behavior for every discrete system mode  but now the discrete state transitions are representedas a continuous-timemarkovjump process. that is  we keep a set of transition probabilities for each discrete mode  as well as the distribution over how long the system will remain in the mode before transitioning out.
﹛as we said above  we use particle filtering to track the system state  see section 1 . for efficiency  and to make it possible to track large systems  we use rao-blackwellized particle filters  doucet et al.  1a   in which the discrete mode is sampled  just as in a standard particle filter  but the continuous state is tracked using an unscented kalman-bucy filter.
﹛this work addresses the key challenge that many mode changes on the rover  as with most systems  are not observable directly. commanded changes such as moving from stopped to driving are observable  but the occurrence of faults  and other mode transitions triggered by the environment or the continuous state  do not produce telemetry directly  and can only be inferred from their effects on the continuous system behavior. the algorithmwe have developedto address these difficulties  the continuous-time particle filter  is described in section 1.
﹛one major advantage of the continuous-time approach is that it allows resource-bounded computation. although the cost of a single update may be higher than that of a discrete update  because of the kalman-bucy filter equations   computation need only be performed when new observations arrive. indeed  if computation is limited  observations can even be ignored until sufficient computation is available to update the estimate. for discrete approaches  an update must be performed for each time step  even if no telemetry has arrived.
﹛in section 1  we discuss how the parameters of the continuous-time markov jump process can be learned by observing the system. section 1 applies the approach to the simulated rover model presented in section 1.
1	continuous-time hybrid-state processes
a continuous-time hybrid-state process consists of interacting discrete-state and continuous-state random variables.
﹛the discrete-state variables zt evolve according to dynamics described by continuous-time markov jump processes.
a markov jump process is a random variable zt that is parametrized by time t ﹋  1 ﹢ . zt starts in an initial state z and remains in this state for a random amount of time before it makes a transition to a different state. the time that zt stays in a particular state is exponentially distributed  due to the markovian property of the process.
﹛mathematically  a markov jump process zt is characterized by its intensity matrix

where
 and
in which qij is the transition rate that defines the probability per time unit that the system makes a transition from state i to state j and qi is the total transition rate out of state i. the amount of time that the process stays in state i is distributed according to the exponential distribution fi t  = qi exp  qit . when the process leaves state i  it enters the next state j with probability and 1 otherwise. in this paper  we assume that the process is stationary  i.e. the intensity matrix is the same at all times.
﹛in recent work   nodelman et al.  1  introduced continuous-time bayesian networks  ctbns  as a way to factorize markov jump processes over discrete-valued variables. our work extends the inference to hybrid-state processes.
﹛the instantiation of zt correspondsto a unique set of equations that govern the dynamics of the continuous variables xt. let 而1 而1 ... denote the times at which zt changes

figure 1: rover ctbn. note that a ctbn may contain cycles.
value. let zi denote the value of zt in the interval  而i 而i+1 . during the time span of  而i 而i+1  the variables xt follow nonlinear dynamics given by
		 1 
and the observations yt are given by
﹛﹛﹛﹛﹛﹛﹛yt = hzi xt ut  + vt  1  where wt ‵ n 1 朴t  and vt ‵ n 1 朵t  are the respective process and measurement noise  and ut is the control input.
﹛in this work  we assume that some variables in zt may be observed  but only at random discrete points in time. on the other hand  yt are observed more frequently  but as noisy measurements of the true continuous state xt.
1	a continuous-time rover model
as a testbed  we use a continuous-time rover model. the rover employs a rocker-bogey suspension system for its six wheels. on each side  the front two wheels are attached to the bogey  which pivots around its center. the center of the bogey is attached to the rocker  which is attached to the main rover chassis and the rear wheels. motion from the bogey can cause the rocker to pivot around the differential axle  a mechanism that centers the rover chassis between the left and right sets of wheels. from the rocker angles and the bogey angles  we can infer the rover orientation and thus the wheel heights relative to the rover chassis.
﹛we are interested in reasoning about the rover wheel dynamics under the effects of weather  terrain  ground conditions and faulty wheel behavior. the model consists of 1 state variables and 1 transient variables. there are two groups of state variables: 1 that model background conditions and 1 that directly model the rover. the background variables model environmental factors such as weather  terrain  ground rockiness and ground stickiness  while the rover variables model the solar energy level available to the rover  the rover speed  the wheel heights  the wheel stuck conditions  and the rover roll angle. the ctbn structure is shown in figure 1.
﹛the model comprises 1 binary and ternary discrete variables and 1 continuous variables. the only observable discrete variables are sunny  rainy  terrain and rockiness. the observation of these variables at sparse time points corresponds to situations when the rover takes measurements of its surroundings  to plan navigation or to manage power consumption. the wheel stuck states are never observed and are inferred from observations of the continuous wheel variables. the wheel stuck condition is more frequently induced when the rover travels at high speed and when the ground is rocky.
﹛the rover dynamics are adapted from the kinematic analysis in  hacot  1 . the front wheels receive an input proportional to some height perturbation induced by the terrain. the change in the middle wheel height is proportional to the difference between the front and middle wheel height  taken relative to the rover body which experiences roll  torsional rotation  on uneven terrain. to illustrate the system's nonlinearity  the equation for the middle wheel height is:

where 成t is the roll angle  牟tb is the bogey angle  and l1  l1 and 汕 are constant parameters of the physical rover model. the change in the back wheel is defined in a similar manner. for each wheel  the proportionality constant 百t is dependent on the speed and whether the wheel is stuck. the speed is affected by the availability of solar energy and by ground surface characteristics such as stickiness and rockiness.
﹛noisy measurements of the continuous variables that model the bogey and rocker angles are observed more frequently than the discrete observations. the bogey angle is determined from the front and middle wheel heights. the rocker angle depends on the middle and back wheel heights as well as the bogey angle.
1	preliminaries
let the hybrid system state be represented as st = {zt xt}. we denote y1:t as the history of observations from time 1 to time t. the aim is to track the probability p st|y1:t  that any given state may be the true system state  conditioned upon the sequence of past observations y1:t. this probability distribution  also referred to as the belief state  can be recursively estimated given the previous belief state p st 1|y1:t 1  and the current observation yt:
where
however  the computation of this integral leads to intractability in all but the smallest conditional linear gaussian models. as a result  one must resort to approximateinference methods to compute the updated belief state.
1	particle filtering
particle filtering  pf   doucet et al.  1b  approximates  1  by a discrete sum of particles or samples of possible states drawn from that distribution:
		 1 
where 汛 ﹞  denotes the dirac delta function. since it is difficult to sample from p st|y1:t  directly  importance sampling is used  in which particles are drawn from a more tractable proposal distribution  then each particle is weighted to account for this bias. since variance increases as the state space increases  the number of particles required to achieve decent accuracy increases as well  thus making pf an expensive solution for tracking complex  high-dimensional systems.
﹛rao-blackwellization  doucet et al.  1a is a technique that improves pf by analytically marginalizing out some of the variables. this method is especially applicable to our domain since the structure of the rover model can be factorized:

hence  rao-blackwellized particle filtering  rbpf  can be used to sample only from the  lower-dimensional  discrete distribution and the continuous distribution can subsequently be computed using the kalman filter.
1	the unscented kalman-bucy filter
the kalman filter  grewal and andrews  1 is an efficient  recursive method that finds the least-square estimate of the state of a discrete-time  linear stochastic process with gaussian noise. the kalman-bucy filter is the continuous-time counterpart to the discrete-time kalman filter. it uses a differential equation to generate an estimate x t of the continuous state  and generates from that an estimate y t of the observation. it also generates pt  the covariance of the state estimate error xt   x t  and rt  the covariance of yt   y t. the update of pt also uses a differential equation. given these estimates  the probability of the observation yt is given by a normal distribution with mean y t and covariance rt.
﹛the kalman-bucy filter assumes a linear transition model and observation model. to handle nonlinear models  we adopt an approach similar to the discrete-time unscented kalman filter  ukf   wan and van der merwe  1  and extend the kalman-bucy filter by applying the unscented transformation  julier and uhlman  1  to the state estimation. thus  the unscented kalman-bucy filter  ukb  is a continuous-time filter that allows for nonlinear models. ukb is used in rbpf as an approximation to the kalman-bucy filter. this approximation introduces bias and does not provide the theoretical guarantee that variance is reduced in rbpf.
1	the continuous-time particle filter
in the continuous-time particle filter  ctpf   we perform an update each time a discrete observation is received. if no discrete-state process is observed  updates can be triggered by an asynchronous request for update. technically  this is treated the same way as observing the discrete-state process with a vacuousobservation. if the new observationis received at time tn and the previous observation was at time tn 1  an update means generating particles of the state at tn  using the particles generated at tn 1. we assume that observations of the discrete-state processes are sparse and intermittent. we make no assumption that observations come at regular intervals or that the observations coincide with any discrete transitions. let 汎n be the observation at time tn. we may observe 汎n as the entirety of ztn  or 汎n may be an assignment of values to a subset of the variables in ztn  or 汎n may be vacuous  assigning values to none of the variables. in any case  we will say that a value z agrees with the observation 汎n if it assigns the same value to all variables assigned by 汎n.
	at a high level  the ctpf works as follows.	when up-
results in a set of time pointsdating frommarkov jump process for the time intervaltn 1 to tn  we sample a trajectory from the而1 = tn 1 而 t1n ... 而 1 tnk . this= tn
at which z changes value. let zi denote the value of  z in interval  而i 而i+1 . we then perform rao-blackwellization to obtain updates for the continuous variables. we go through the sequence of intervals  starting at  而1 而1  and ending at of the continuous variables 而k 1 而k   propagating our estimate of the mean and variancex using ukb. in the time period  而i 而i+1   the continuous dynamics are governed by the value zi. as we propagate the continuous variables  we also compute the probability of the trajectory  which is used as the particle weight. we repeat this process to obtain a set of weighted particles at time tn  and resample from these to get a new set of unweighted particles.
﹛the behavior of the markov jump process governing z is characterized by the intensity matrix qz. the process of generating a trajectory of the markov jump process from time be the value of z in that particle. set 而1 = tn 1 and 1  leti = 1. tn 1 to tn is as follows. for each particle at time tn
we use the intensity matrix to sample a time from the exponential distribution fzi t  = qzi exp  qzit  to obtain the length of time 污 until z next changes value. if 而i+污   tn  we sample zi+1 from the intensity matrix  and continue to loop  setting 而i+1 = 而i +污. otherwise  we know that z = zi at tn. if this value agrees with the evidence 汎n  the particle is kept  otherwise it is rejected.
﹛once we have the jump process  we proceed to propagate the continuous variables x through the time points 而1 ... 而k. since there may be many observations of the continuous variables in the interval  而i 而i+1   when we propagate them from 而i to 而i+1  we need to consider all the observations between those times. let be the time points at which continuous observations were received. we loop through the intervals  汛j 汛j+1  in turn. for each interval  we propagate the mean and variance of the continuous variables forward using ukb. we also obtain the probability of the observation at time 汛j+1  given by the predictive density p y汛j+1|y汛1:汛j  = n y汛j+1;y 汛j+1 r汛j+1  where y 汛j+1 and r汛j+1 are the estimate and covariance of y汛j+1 under ukb. we then multiply the probability of all the observations together over all time points 汛j in  而i 而i+1  and over all 而i to obtain the probability of the sequence of observations. this becomes the weight of the particle.
﹛we repeat this procedure for each of the m particles from timeprocess for each discrete variable intn 1. each particle consists of a candidate markov jumpzt  and the mean and covariance for the continuous variables in xt. the markov jump process candidates that are far from the ground truth will lead to poor tracking of the continuous variables due to incorrect parametrization of the continuous-state dynamics. particles associated with the ill-fit markov jump processes will have low weights and will be resampled out.
the pseudocode for ctpf is shown in figure 1.
1:let m be the number of particles1:let n be the number of discrete observations1:for n = 1 to n do1:dynamics propagation
1:for m = 1 to m do1:let 汎n be the nth observation1:let tn be the observed time of 汎n1:simulate a markov jump process1:
1:
1:	let i = 1 而1 = tn 1	th particle at time tn 1
let z1 be the value of z in the m while 而i   tn do1: 1:sample 污 from the pdf f t  = qzi exp  qzit  if 而i + 污   tn then1:let 而i+1 = 而i + 污1:sample zi+1 using the intensity matrix qz1:else1:let 而i+1 = tn; let z m  = zi1:let k = i1:propagate continuous variables1: 1:let x t nm  1= 1and ptn 1 be the mean and covariance ofth particle at time tn 1 the continuous variables in the m let w1:for i = 1 to k   1 do1:	i	i + 1
1:	ifdisagrees with 汎n  reject the particle
1:	let be the times of
continuous observations in  而i 而i+1 
	汛j+1	汛j+1	汛j+1	汛j+1
using ukb beginning with x 汛j and p汛j  under the dynamics determined by zi1: 1:﹛﹛w m  ↘ w m  ℅ n y汛j+1;y 汛j+1 r汛j+1  let x  m  and p m  be x tn and ptn1:resampling1: 1:normalize
select m new particles where the probability of
 z m  x  m  p m   is w m 
figure 1: continuous-time particle filter1learning1:	let 1:	for
1:	compute x 	  p	  y 	and r
in real-world applications  we may not know the exact parametrization of zt. instead  we may have a prior distribution over the intensity matrices qz and need to fine tune our estimate of qz as observations about zt are made.
﹛in this case  we model qz as a random variable and we attribute a probability distribution 耳 qz  over the space of admissible intensity matrices  qz. since the observations are exponentially distributed  we model 耳 qz  as a gamma distribution since gamma and exponential are conjugates.
﹛assume that the elements of qz are distributed according to. the prior distribution qz is given by:
		 1 
﹛upon the arrival of a discrete-state observation 汎n  we simulate a markov jump process j over the time interval  tn 1 tn . from j  we can compute the likelihood of qz:
		 1 
where nij is the number of transitions from state i to j in the process j and ri is the time spent in state i during process j. from this  we update the qz-distribution

﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛﹛ 1  upon the arrival of the next discrete-state observation  we sample  to get an instantiation for qz that reflects the updated distribution.
﹛the learning procedure is integrated into algorithm 1 as follows: we sample qz ‵ 耳 qz  right before line  1  and perform the qz-distribution update  as prescribed in equations  1 - 1   after line  1  of the pseudocode.
﹛this procedure may seem like magic. after all  we are using statistics generated from simulating from qz itself to obtain an updated estimate of qz. the reason it works is that not all qzs from the previous set of particles have the same chance of being accepted into the next set of particles. first of all  if the trajectorydisagrees with the discrete observation汎n  it will be rejected. second  the trajectories will be weighted by the probability of the continuous observations  and these weighted particles will be resampled. a trajectory  and thus a new intensity matrix  that agrees well with the observations  is more likely to be kept. in this way  the set of intensity matrices that are kept will be influenced by the observations  both discrete and continuous.
﹛other learning approaches have been explored in  nodelman et al.  1  for parameter learning of ctbns  and in  bladt and s rensen  1  for statistical inference of discretely observed markov jump processes. however  these approaches are offline learning approaches where the sequence of discrete-time observations are assumed known a priori to the learning process. our approach integrates online learning into the particle filtering framework  where we also take advantage of the continuous observations in eliminating poor candidates for qz. this advantage allows for relatively quick convergence to the neighborhood of the true qz value.
1	experimental results
we evaluate the performance of the ctpf algorithm on a simulated small model and the rover model. the small model consists of one discrete ternary variable  two continuous state variables  and two continuousobservationvariables. depending on the state of the discrete-valued process  the continuous behavior can be either linear  polynomial or sinusoidal. the low dimensionality of the small model makes it feasible to compare against the discrete-time particle filter and to evaluate the performance of the learning procedure.
﹛figure 1 shows an experiment comparing ctpf to the discrete-time particle filter  dtpf . the results shown are averaged over 1 runs. the first graph shows the performance of ctpf with 1 particles and 1 updates  comparing the estimate of one of the continuous state variables produced by ctpf with the actual value of that variable. while ctpf updates the discrete variables at infrequent intervals  dtpf performs an update at equally-spaced intervals fixed by a preset time granularity. both algorithms perform continuous inference  via ukb or ukf  at many intermediate time points  corresponding to when the continuous variables are observed.
﹛the plotted points are the estimates at these intermediate points. from the graph  we see that ctpf is consistently able to track the variable through the different mode changes. the second graph  dtpf1  shows dtpf's performance using the same number of particles and the same number of updates as ctpf. we see that dtpf1 has worse tracking throughout  and does particularly poorly from time 1 to time 1. ctpf outperforms dtpf because it is able to perform updates precisely when they are needed.
﹛dtpf is considerably faster than ctpf because it does not require solving differential equations. this was exacerbated by a slow matlab implementation of the kalman-bucy filter  compared to a well-optimized implementation of the kalman filter. we expect this difference to lessen with a more efficient implementation of ctpf. nonetheless  we ran experiments that allowed dtpf the same running time as ctpf.
﹛we first allowed dtpf to use more particles than ctpf  while maintaining the same numberof updates. the results of dtpf  with 1 particles and 1 updates  are shown as dtpf1  in the third graph of figure 1. when the number of updates is not sufficient for dtpf to track the variables  increasing the number of particles does not particularly help. we then allowed dtpf to update more frequently than ctpf  but use the same number of particles. the results  with 1 particles and
1 updates  are shown in the fourth graph and are labeled
dtpf1. the dtpf1 results show a significant improvement in the performance of dtpf  although dtpf still does not perform as well as ctpf when the continuous variables are oscillating rapidly. furthermore  we found the variance of the estimates in dtpf1 to be higher than that produced by ctpf.
﹛figure 1 shows the results of learning the q matrix on the small model. the results were quite promising. the first graph compares the estimation error achieved by ctpf with learning the q matrix and ctpf with using the true q matrix. both sets of ctpf experiments used 1 particles. we see that the error of ctpf with learning comes close to that of ctpf without learning after 1 time steps. the second graph shows the distance of the learned q matrix from the true q matrix over time  computed as the sum of the elementwise differences between the two matrices. the graph shows the learned q matrix converging towards the true q matrix.
1 1 1 1 1 1 1 1 1 1 1	
	time	time	time
	figure 1: estimation results	figure 1: learning results	figure 1: ctpf results on the rover﹛lastly  we tested the ctpf algorithm on our main application  the continuous-time rover model. despite the nonlinearity of the model  ctpf is able to track the wheel heights relatively well with 1 particles. the results of the ctpf inference  averaged over 1 runs  are presented in figure 1  one graph per rover wheel . the tracking error is mainly due to incorrect estimation of the wheel stuck variable. whenever the ctpf estimate drifts from the ground truth  it is able to quickly recover from the error and continue to closely track the wheel heights. the empirical results confirm ctpf's applicability for monitoring complex continuous-time systems.
1	conclusion and future work
since most real-world systems evolve in continuous time 
ctpf is a natural way to address the time granularity problem that is often associated with systems that have components that evolve at different rates. by performing state estimation in continuous time  ctpf is also better suited for resourcebounded computation since inference is no longer performed at every fixed time step  as in the discrete-time particle filter . our results show that ctpf can effectively track the state of complex systems such as the rover. moreover  when comparison is possible with discrete-time approaches  ctpf tracks the state more accurately. we believe that the approach is an important step in making recent advances in particle filtering applicable to a much larger set of continuous-time problems.
﹛an important aspect in hybrid system modelling is the issue of autonomous transitions  in which the continuous state triggers a discrete transition. we model this in our approach by making the intensity matrices dependent on the continuous variables. this leads to difficulties in that while the system is in a state  the distribution over the time the system remains there may vary. at present we approximate this by only computing the intensity matrix at updates or when the discrete state changes. this is consistent with our aim of resource-bounded computation. we plan to investigate other alternatives such as resampling from an updated intensity matrix when the currentdistribution deviates drastically from the assumed distribution used for sampling.
﹛other areas of future work include applying this approach with factored state spaces  ng et al.  1  to reduce the complexity of the kalman-bucy updates  and implementating this approach onboard an actual robot.
