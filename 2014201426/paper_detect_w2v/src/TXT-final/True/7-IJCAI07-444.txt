
recommendersystems are an emerging technology that helps consumers to find interesting products. a recommender system makes personalized product suggestions by extracting knowledge from the previous users interactions. in this paper  we present  itemrank   a random-walk based scoring algorithm  which can be used to rank products according to expected user preferences  in order to recommend top-rank items to potentially interested users. we tested our algorithm on a standard database  the movielens data set  which contains data collected from a popular recommender system on movies  that has been widely exploited as a benchmark for evaluating recently proposed approaches to recommender system  e.g.  fouss et al.  1; sarwar et al.  1  . we compared itemrank with other state-of-the-art ranking techniques  in particular the algorithms described in  fouss et al.  1  . our experiments show that itemrank performs better than the other algorithmswe compared to and  at the same time  it is less complex than other proposed algorithms with respect to memory usage and computational cost too.
1 introduction
a recommender system makes personalized product suggestions by extracting knowledge from the previous user interactions with the system. such services are particularly useful in the modern electronic marketplace which offers an unprecedented range of products. in fact a recommender system represents an added value both for consumers  who can easily find products they really like  and for sellers  who can focus their offers and advertising efforts. several recommender systems have been developed that cope with different products  e.g. movielens for movies  see  sarwar et al.  1    grouplens for usenet news  miller et al.  1   ringo for music  shardanand and maes  1   jester for jokes  goldberg et al.  1  and many other  see e.g.  schafer et al.  1  for a review . a recommender system constructs a user profile on the basis of explicit or implicit interactions of the user with the system. the profile is used to find products to recommend to the user. in the simplest approach  the profile is constructed using only features that are related to the user under evaluation and to the products he/she has already considered. in those cases  the profile consists of a parametric model that is adapted according to the customer's behavior. key issues of collaborative filtering approach are scalability and quality of the results. in fact  real life large- scale e-commerce applications must efficiently cope with hundreds of thousands of users. moreover  the accuracy of the recommendation is crucial in order to offer a service that is appreciated and used by customers. in this paper  we present  itemrank   a random-walk based scoring algorithm  which can be used to rank products according to expected user preferences  in order to recommend top-rank items to potentially interested users. we tested our algorithm on a popular database  the movielens dataset1 by the grouplens research group at university of minnesota and we compared itemrank with other state-of-the-art ranking techniques  in particular the algorithms described in  fouss et al.  1  . this database contains data collected from a popular recommender system on movies that has been widely exploited as a benchmark for evaluating recently proposed approaches to recommender system  e.g.  fouss et al.  1; sarwar et al.  1  . the schema of such archive resembles the structure of the data of many other collaborative filtering applications. our experiments show that itemrank performs better than the other algorithms we compared to and  at the same time  it is less complex than other proposed algorithms with respect to memory usage and computational cost too. the paper is organized as follows. in the next subsection  1  we review the related literature with a special focus on other graph based similarity measure and scoring algorithms applied to recommender systems. section 1 describes the movielens data set  in subsection 1  and illustrates the data model we adopted  in subsection 1 . section 1 discusses itemrank algorithm in details and we address itemrank algorithm complexity issues in subsection 1. section 1 contains the details of the experimentation  while section 1 draws some conclusions and addresses future aspects of this research.
1 related work
many different recommending algorithms have been proposed in literature  for example there are techniques based on bayesian networks  breese et al.  1   support vector machines  grcar et al.  1  and factor analysis  canny  1 . the most successful and well-known approach to recommender system design is based on collaborative filtering  sarwar et al.  1; shardanand and maes  1 . in collaborative filtering  each user collaborates with others to establish the quality of products by providing his/her opinion on a set of products. also  a similarity measure between users is defined by comparing the profiles of different users. in order to suggest a product to an  active user   the recommender system selects the items among those scored by similar customers. the similarity measure is often computed using the pearson-r correlation coefficient between users  e.g. in  sarwar et al.  1  . recently a graph based approach has been proposed in  fouss et al.  1 . fouss et al. compared different scoring algorithm to compute a preference ranking of products  in that case movies  to suggest to a group of users. in this paper the problem has been modeled as a bipartite graph  where nodes are users  people node  and movies  movie node   and there is a link connecting a people node ui to a movie node mj if and only if ui watched movie mj  in this case arcs are undirected and can be weighted according to user preferences expressed about watched movies. authors tested many different algorithms using a wide range of similarity measures in order to rank movies according to user preferences  some of the most interesting methods are:
　average commute time  ct . this is a distance measure between a pair of nodes i and j in a graph  we denote it as n i j   it is defined as the average number of steps that a random walker1 going across a given graph  starting in the state corresponding to node i  will take to enter state j for the first time and go back to i. if we measure this distance between people and movie nodes in the given bipartite graph  we can use this score to perform the movie ranking.
　principal component analysis based on euclidean commute time distance  pca ct . from the eigenvector decomposition of l+  that is the pseudoinverse of the laplacian matrix  l  corresponding to the graph  it is possible to map nodes into a new euclidean space that preserves the euclidean commute time distance  it is also possible to project to a m-dimensional subspace by performing a pca and keeping a given number of principal components. then distances computed between nodes in the reduced space can be used to rank the movies for each person.
　pseudoinverse of the laplacian matrix  l+ . matrix l+ is the matrix containing the inner products of the node vectors in the euclidean space where the nodes are exactly separated by the ectd  so l+i j can be used as the similarity measure between node i and j  in order to rank movies according to their similarity with the person.
　in literature there are many other examples of algorithms using graphical structures in order to discover relationships between items. chebotarev and shamis proposed in  chebotarev and shamis  1 and  chebotarev and shamis  1  a similarity measure between nodes of a graph integrating indirect paths  based on the matrix-forest theorem. similarity measures based on random-walk models have been considered in  white and smyth  1   where average first-passage time has been used as a similarity measure between nodes. in collaborative recommendation field is also interesting to consider different metrics described in  brand  1 .
1 the problem
formally  a recommender system deals with a set of users ui  i = 1 ... un and a set of products pj  j = 1 ... pn  and its goal consists of computing  for each pair: ui pj  a score r i j that measures the expected interest of users ui for product pj on the basis of a knowledge base containing a set of preferences expressed by some users about products. so we need a scoring algorithm to rank products/items for every given user according to its expected preferences  then a recommender system will suggest to a user top-ranked items with respect to personalized ordering. in this section we present the data model we adopted and movielens data set  that is a widely used benchmark to evaluate scoring algorithms applied to recommender systems. our choice with respect to the data model and the data set is not restrictive since it reflect a very common scenario while dealing with recommender systems. in the following we will indifferently make use of terms such as item  product and movie depending on the context  but obviously the proposed algorithm is a general purpose scoring algorithm and it does not matter which kind of items we are ranking in a particular scenario  moreover we will also use the notation mj to refer a product pj in the particular case of movies to be ranked.
1 movielens data set
movielens site has over 1 users who have expressed opinions on more than 1 different movies. the movielens dataset is a standard dataset constructed from the homonym site archive  by considering only users who rated 1 or more movies  in order to achieve a greater reliability for user profiling. the dataset contains over 1 ratings from 1 users for 1 movies. every opinion is represented using a tuple: ti j =  ui mj ri j   where ti j is the considered tuple  ui （ u is an user  mj （ m is a movie  and ri j is a integer score between 1  bad movie  and 1  good movie . the database provides a set of features characterizing users and movies which include: the category of the movie  the age  gender  and occupation of the user  and so on. the dataset comes with five predefined splitting  each uses 1% of the ratings for the training set and 1% for the test set  as described in  sarwar et al.  1  . for every standard splitting we call l and t respectively the set of tuples used for training and for testing  moreover we refer the set of movies in the training set rated by user ui as lui and we write tui for movies in the test set. more formally: lui = {tk j （ l : k = i} and tui = {tk j （ t : k = i}.
1 data model: correlation graph
even from a superficial analysis of the proposed problem  it seems to be clear that there is a different correlation degree between movies  if we could exploit this information from the training set then it would be quite easy to compute user dependent preferences. we define ui j   u the set of users who watched  according to the training set  both movie mi and mj  so:

now we computethe  |m|〜|m|  matrix containing the number of users who watched each pair of movies:
c i j = |ui j|
where |，| denotes the cardinality of a set  obviously  i  c i i = 1 and c is a symmetric matrix. we normalize matrix c in order to obtain a stochastic matrix where ωj is the sum of entries in j   th column of c . c is the correlation matrix  every entry contains the correlation index between movie pairs. the correlation matrix can be also considered as a weighted connectivity matrix for the correlation graph gc. nodes in graph gc correspond to movies in m and there will be an edge  mi mj  if and only if ci j   1. moreover the weight associated to link  mi mj  will be ci j  note that while c  is symmetrical  c is not  so the weight associated to  mi mj  can differ from  mj mi  weight. the correlation graph is a valuable graphical model useful to exploit correlation between movies  weights associated to links provide an approximate measure of movie/movie relative correlation  according to information extracted from ratings expressed by users in the training set.
1 itemrank algorithm
the idea underlying the itemrank algorithm is that we can use the model expressed by the correlation graph to forecast user preferences. for every user in the training set we know the ratings he assigned to a certain number of movies  that is lui  so  thanks to the graph gc we can  spread  user preferences through the correlation graph. obviously we have to properly control the preference flow in order to transfer high score values to movies that are strongly related to movieswith good ratings. the spreading algorithm we apply has to possess two key properties: propagation and attenuation. these properties reflect two key assumptions. first of all if a movie mk is related to one or more good movies  with respect to a given user ui  then movie mk will also be a good suggestion for user ui   if we analyse the correlation graph we can easily discover relationships between movies and also the strength of these connections  that is the weight associated to every link connecting two movies. the second important factor we have to take into account is attenuation. good movies have to transfer their positive influence through the correlation graph  but this effect decrease its power if we move further and further away from good movies  moreover if a good movie mi is connected to two or more nodes  these have to share the boosting effect from mi according to the weights of their connections as computed in matrix c. pagerank algorithm  see  page et al.  1   has both propagation and attenuation properties we need  furthermore thanks to significant research efforts we can compute pagerank in a very efficient way  see  kamvar et al.  1a  . consider a generic graph g =  v e   where v is the set of nodes connected by directed links in e  the classic pagerank algorithm computes an importance score pr n  for every node n （ v according to graph connectivity: a node will be important if it is connected to important nodes with a low out-degree. so the pagerank score for node n is defined as:

　where ωq is the out-degree of node q  α is a decay factor1. the equivalent matrix form of equation 1 is:
	pr 	 1 
　where c is the normalized connectivity matrix for graph g and 1|v| is a |v| long vector of ones. pagerank can also be computed iterating equation 1  for example by applying the jacobi method  golub and loan  1   even if iteration should be run until pagerank values convergence  we can also use a fixed number i of iterations. classic pagerank can be extended by generalizing equation 1:
　　　　　　pr = α ， m ， pr +  1   α  ， d  1  where m is a stochastic matrix  its non-negative entries has to sum up to 1 for every column  and vector d has nonnegative entries summing up to 1. vector d can be tuned in order to bias the pagerank by boosting nodes corresponding to high value entries and matrix m controls the propagation and attenuation mode. biased pagerank has been analysed in  langville and meyer  1  and custom static score distribution vectors d have been applied to compute topic-sensitive pagerank  haveliwala  1   reputation of a node in a peerto-peer network  kamvar et al.  1b  and for combating web spam  gyongyi et al.  1 . we present the itemrank algorithm  that is a biased version of pagerank designed to be applied to a recommender system. itemrank equation can be easily derived from equation 1. we use graph gc to compute a itemrank value irui for every movie node and for every user profile. in this case the stochastic matrix m will be the correlation matrix c and for every user ui we compute a different irui by simply choosing a different dui static score distribution vector. the resulting equation is:
	irui = α ， c ， irui +  1   α  ， dui	 1 
where dui has been built according to user ui preferences as recorded in training set lui. the unnormalized d ui  with respect to the j   th component  is defined as:

so the normalized dui vector will simply be du.
itemrank  as defined in equation 1  can be computed also iteratively in this way:
 1 
irui t + 1  = α ， c ， irui t  +  1   α  ， dui
this dynamic system has to be run for every user  luckily it only needs on average about 1 iterations to converge. the interpretation of irui score vector for user ui is straightforward  itemrank scores induce a sorting of movies according to their expected liking for a given user. the higher is the itemrank for a movie  the higher is the probability that a given user will prefer it to a lower score movie.
1 complexity issues
itemrank algorithm results to be very efficient both from computational and memory resource usage point of view. we need to store a |m| nodes graph with a limited number of edges. the interesting fact is that graph gc contains edges  mi mj  and  mj mi  if and only if  uk : tk i （ luk … tk j （ luk  so no matter the number of users satisfying the previous condition  ratings information will be compressed in just a couple of links anyway. it is interesting to note that the data structure we use scale very well with the increase of the number of users  in fact gc node set cardinality is independent from |u| and also the number of edges tend to increase very slowly after |u| has exceeded a certain threshold u．. that is a very useful property  because in a real applicative scenario the number of users for a certain e-commerce service and the number of expressed preferences about products will rise much faster than the total amount of offered products. moreover itemrank computation is very efficient  thanks to its strong relationship with pagerank algorithm  and we only need about 1 iterations of system 1 for every user in order to rank every movie according to every user taste  so if we have |u| users we have to run the algorithm |u| different times. itemrank is more efficient than similar random-walk based approach such as ct and l+  already introduced in subsection 1  see  fouss et al.  1  for details   in fact both ct and l+ require to handle a graph containing nodes representing users and products and edges referred to user preferences. so in this graph there are |u|+|m| nodes and two edges  ui mj   mj ui  for every opinion  ui mj ri j   while in the case of itemrank you have only |m| nodes and ratings information is compressed. ct is used to rank every movie with respect to every system user  so the average commute time  ct  n ui mj  referred to any user-movie couple ui mj has to be computed  but n ui mj  = m ui|mj  + m mj|ui  where m ui|mj  denotes the average first-passage time from node ui to node mj. so ct needs 1，|u|，|m| average first-passage time computations  while itemrank has to be applied only |u| times to rank every movie with respect to its similarity to every user. the situation is similar also if we consider l+ algorithm  in this case  as stated in  fouss et al.  1   the direct computation of the pseudoinverse of the laplacian matrix l becomes intractable if the number of nodes becomes large  that could easy happen while the number of users increase   some optimized methods to partially overcome these limitations has been proposed in  brand  1 .
1 experimental results
to evaluate the performances of the itemrank algorithm  we ran a set of experiments on the movielens data set  described in subsection 1. the choice of this particular data set is not restrictive  since it is a widely used standard benchmark for recommendersystem techniques and its structure is typical of the most common applicative scenarios. in fact we can apply itemrank every time we have a set of users  u  rating a set of items or products  i that is the generic notation for m   if we can model our recommendation problem this way  or in any equivalent form  it will be possible to use itemrank to rank items according to user preferences. we chose an experimental setup and performance index that is the same as used in  fouss et al.  1   this way we can directly compare our algorithm with some of the most promising scoring algorithms we found in related literature  ct  l+ and so on   having many points of contact with itemrank  philosophy . we split movielens data set as described in  sarwar et al.  1   in order to obtain 1 different subsets  then we applied itemrank 1 times  1-fold cross validation . each time  one of the 1 subsets is used as the test set and the remaining 1 sub sets have been merged to form a training set. at the end we computed the average result across all 1 trials. so we have 1 splittings  each uses 1% of the ratings for the training set  that is 1ratings  and1% forthe test set  the remaining 1 ratings   that is exactly the same way tests have been performed in  fouss et al.  1 . the performance index we used is the degree of agreement  doa   which is a variant of somers'd  see  siegel and castellan  1  for further details . doa is a way of measuring how good is an item ranking  movie ranking in movielens case  for any given user. to compute doa for a single user ui we need to define a set of movies nwui   m that is the set of movies that are not in the training set  nor in the test set for user ui  so:
nwui = m    lui “ tui 
now we define the boolean function check order as:
mk
check order
where is the score assigned to movie mj with respect to user ui preferences  by the algorithm we are testing. then we can compute individual doa for user ui  that is:
 check orderui mj mk 
doa
so doaui measures for user ui the percentage of movie pairs ranked in the correct order with respect to the total number of pairs  in fact a good scoring algorithm should rank the movies that have indeed been watched in higher positions than movies that have not been watched. a random ranking produces a degree of agreement of 1%  half of all the pairs are in correct order and the other half in bad order. an ideal ranking correspond to a 1% doa. two different global degree of agreement can be computed considering ranking for individual users: macro-averaged doa and micro-averaged doa. the macro-averaged doa  or shortly macro doa  will be the average of individual degree of agreement for every user  so:
 doaui
macro doa = 
|u|
the micro-averaged doa  or shortly micro doa  is the ratio between the number of movie pairs in the right order  for every user  and the total number of movie pairs checked  for every user   so it can be computed as:
micro doa 
then micro doa is something like a weighted averaging of individual doa values. in fact the bigger is set tui for a given user ui  the more important is the individual doaui contribution to micro doa global computation. macro doa and micro doa have been evaluated for every experiment we ran. we summarize experimental results in table 1 and 1. in table 1 we compare itemrank performances to a simplified version of the same algorithm  in order to highlight the importance of the information hidden in the correlation matrix c. itemrank with the binary graph is identical to classical itemrank  described in section 1  but there is a key difference in the way we build matrix c  we denote the simplified version as cbin   in this case it is obtained by normalizing a
binary version of c  c bin   so we have: where
c i jbin can be computed as:

in other words if we compute itemrank with binary graph  we are weighting every correlation edge connectingtwo items in the same way  no matter the number of co-occurrences in user preference lists for these items  since ci jbin correspond to the weight of edge  mi mj  in the correlation graph gc we use for information propagation.
　table 1 clearly shows the usefulness of a properly weighted correlation matrix c compared to cbin. this table provides both macro and micro doa for every split and for itemrank and its simplified version with binary graph: itemrank clearly works much better when we use a proper correlation matrix. for example  if we look at macro doa mean values  itemrank with correlation matrix c obtain +1 points  in %  with respect to cbin version. these are interesting results because they confirm our main hypothesis: itemrank algorithm ranks items according to the information extracted from the correlation matrix  that is equivalentto the weighted correlation graph  and the way we compute c entries is really able to properly model relationships among evaluated items. finally table 1 shows a performance comparison among different scoring algorithm applied to movielens data set. we briefly described some of these algorithms in subsection 1  for further details see  fouss et al.  1 . for every tested algorithm we provide macro doa index  that has been computed for every technique as the average result across all 1 trials of 1-fold cross-validation. moreoverwe providethe difference  in %  with performanceobtained by the trivial maxf algorithm and the standard deviation  std  of this quantity. maxf is our baseline for the task  it is a user independent scoring algorithm  it simply ranks the movies by the number of persons who watched them  movies are suggested to each person in order of decreasing popularity. so maxf produces the same ranking for all the users. itemrank performs better than any other considered technique obtaining +1 with respect to the baseline and a very good standard deviation  1 . in this test itemrank also perform better than l+ algorithm by obtaining a macro doa value of 1 versus 1 for l+ and also a better standard deviation. in addition it is worth to note that itemrank is less complex than other proposed algorithms with respect to memory usage and computational cost too  as already argued in subsection 1.
1 conclusions
in this paper  we present a random-walk based scoring algorithm  which can be used to recommend products according to user preferences. we compared our algorithm with other state-of-the-art ranking techniques on movielens data set. itemrank performs better than the other algorithms we compared to and  at the same time  it is less complex than other proposed algorithms with respect to memory usage and computational cost too. future research topics include the experimentation of the algorithm on different applications. we are now working on a extension of itemrank. the version presented so far is able to handle the recommendation task as a item scoring/ranking problem. but we can face the problem from the regression point of view too. so we expect itemrank 1 will also be able to produce expected satisfaction prediction for a given recommendation  other than product ranking.
acknowledgments
many thanks to giuliano testa for running the experiments.
