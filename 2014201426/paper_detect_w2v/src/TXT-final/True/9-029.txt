 
       a natural language question answering system is presented. the system's parser maps semantic paraphrases i n t o a single deep s t r u c t u r e characterized by a canonical verb. a modeling scheme using semantic nets and strips-like operators assimilates the sequence of input information. natural language responses to questions are generated from a data base of semantic nets by   p a r s i n g   syntactic rules r e t r i e v e d from the l e x i c o n . 
keywords: 	question answerer  canonical verb  	semantic net  semantic model  generation  deep case  syntactic paradigm  semantic paradigm  	time frame  event scenario  grammar. 
i n t r o d u c t i o n 
       in n a t u r a l language processing  the problems of representing f a c t u a l m a t e r i a l   making inferences  solving problems and answering questions may be s i g n i f i c a n t l y reduced if i d e n t i c a l meanings expressed by diverse surface structures can be represented by a single conceptual construct. a major cause of surface s t r u c t u r e d i v e r s i t y is the existence of a wide v a r i e t y of  surface verbs  f o r describing b a s i c a l l y the same s i t u a t i o n . for example    b u y       s e l l     and   c o s t     e t c .   a l l describe e s s e n t i a l l y the same event. schank 
 1  and others have posited the existence of  deep  or   c a n o n i c a l   verba which u n i f y in the deep s t r u c t u r e meaning common to possibly many aurface verbs used in 
ordinary speech. given a canonical event such as exchange  the p a r t i c i p a n t s   e . g . the buyer  the seller  are ordered in the surface s t r u c t u r e   but dependent upon the choice of surface verb and voice   a c t i v e or passive . this paper describes a language processing system which employs semantic network depictions of canonical events as i t s fundamental representation of meaning. 
       the language processor consists of three basic modules as shown in figure 1. the parser is used to map english surface structures i n t o a semantic representation u t i l i z i n g canonical verbs. the sequence of 
events presented to the language processor over seve r a l sentences is woven i n t o a u n i f i e d knowledge structure by the modeling system  which b u i l d s a strips r o b o t - l i k e model of the s i t u a t i o n s described. again  as in the parser  the canonical event provides the basis of representation. when a question is presented to the system  the generator is used to produce english output d i r e c t l y from the canonical semantic net b u i l t  sometime in the past  by the modeling system. 

the paraer 
       the mapping from english i n t o a canonical cons t i t u e n t s t r u c t u r e is accomplished by a v a r i a n t of the augmented f i n i t e state t r a n s i t i o n network system described by woods   1   . since the operation of the system is generally w e l l known  a t t e n t i o n w i l l be concentrated on the mechanism which allows for d i r e c t t r a n s l a t i o n i n t o canonical s t r u c t u r e s . the key to t h i s operation is the inclusion of c e r t a i n information in the lexicon  table 1   the property l i s t of each 
surface verb form   i n f i n i t i v e   past  e t c .   contains a reference to a c e n t r a l gensym-ed atom which serves as the l e x i c a l entry f o r a l l forms of a given verb. for r e a d a b i l i t y   these   c e n t r a l   forms w i l l be designated by l-verb  where  verb  is the usual i n f i n i t i v e form. the property l i s t of each c e n t r a l verb contains two special e n t r i e s   i n a d d i t i o n to various others : the a t t r i b u t e canon-vb indicates the canonical verb 
 event  associated with  the given surface verb; the p-rules a t t r i b u t e r e l a t e s the surface noun phrases and p r e p o s i t i o n a l phrases used in conjunction w i t h the given surface verb  to the deep case s t r u c t u r e associated w i t h the corresponding canonical verb. this a t t r i b u t e i s a l i s t o f t r i p l e s ; the f i r s t e n t i t y i n each t r i p l e indicates the manner in which an event p a r t i c i p a n t is s p e c i f i e d in the surface sentence. if the p a r t i c i p a n t is s p e c i f i e d simply as a noun phrase  the f i r s t entry of the t r i p l e is  ok.  if the p a r t i -
cipant is s p e c i f i e d by a p r e p o s i t i o n a l phrase  then the corresponding p r e p o s i t i o n appears in place of ok. the t h i r d entry in the t r i p l e names the deep case r e l a t i o n associated w i t h the event p a r t i c i p a n t . for example  consider: 
　　　　　　　　john bought the car from mary in table 1 it may be seen that from is associated w i t h the deep case seller w i t h respect to the verb buy. the second entry in each t r i p l e is a l i s t of semantic classes: a p a r t i c i p a n t must belong to one of the semantic classes s p e c i f i e d by the second t r i p l e entry in order to s a t i s f y the deep case r e l a t i o n s p e c i f i e d 
by the t h i r d t r i p l e e n t r y . this semantic class i n f o r mation is used to help disambiguate the deep cases of sentence components which otherwise appear s i m i l a r .  this process is also aided by the ordering of the t r i p l e s .   

1 seller  tok l-baker 	det def 

　　　since semantic class information w i l l be useful in determining deep cases  each noun entry in the lexicon contains a special a t t r i b u t e  mkr  on i t s property l i s t ; t h i s specifies the semantic classes to 
v h i c h the noun belongs. i n t e r r o g a t i v e pronouns and adjectives  qwords  also have the a t t r i b u t e mkr. 
　　　the a p p l i c a t i o n of the t r a n s i t i o n network parsing grammar to an input sentence produces two   t h r e e   in the case of questions  intermediate s t r u c t u r e s . 
for example: 
 who bought a cake at the new bakery from the baker  w i l l cause the production of the intermediate s t r u c tures : 
	thingbt  tok l-cake 	det indef 	nbr s  
	loc  tok l-bakery 	det def 	nbr s 	mod  age l-new   
	q  args  buyer  	tok l-who    
       the purpose of the parser is to provide a simple  expressive   f r o n t end  to the modeling system; the version described is  so f a r   l i m i t e d to  possibly conjoined  simple  a c t i v e sentences without embeddings. work is in progress to extend the parser to include passives and several types of embedded sentences. natural extensions include:  1  more complex prules  which e x p l i c i t l y express the order of np's and pp's in the constituents l i s t ;  1  a more i n t e l l i g e n t c o r r e l a t i n g a l g o r i t h m   which is able to recognize np complements and r e l a t i v e clauses;  1  prules f o r nominalized verbs and nouna modified by pp's; and  1  a r i c h e r v a r i e t y of syntactic and semantic markers. 
1 
the modeling system 
       the purpose of the modeling system is to i n t e grate the c o l l e c t i o n of facts or concepts presented to the system through the parser. three d i s t i n c t types of concepts must be encoded:  1  objects;  1  r e l a tionships between objects; and  1  changes in r e l a tionships w i t h respect to time. the modeling system uses an encoding procedure analogous to that used in motion p i c t u r e s   recording changes in r e l a t i o n s h i p s w i t h respect to time by a sequence of   s t i l l photographs.  the   s t i l l photos  of the modeling system are graphs  nets  representing the state of the world at an instant in time. nodes in the graph stand for o b j e c t s   and arcs represent s t a t i c  binary  r e l a t i o n ships between objects.  no time r e l a t i o n s h i p s are included.  
　　　figure 1 is an example of a s t a t e - o f - t h e - w o r l d graph  swg . node names beginning and ending w i t h a s t e r i s k s  depicting gensym atoms  represent p a r t i c u l a r objects in the real w o r l d . other node names are 
words in the system's l e x i c o n . consider the node labeled *john*. *john* is an element of l-john and 
l-grocer. 	l-john is the set of a l l johna  a subset of 
l-man  the set of a l l men. l-grocer is the set of a l l grocers. hence  *john* is a node representing a part i c u l a r man who is a john who is a grocer. thib john owns a p a r t i c u l a r house  *jhouse*. further  john is at that house  owns an o l d   red car and is f a t . 
　　　to model changes in r e l a t i o n s h i p s w i t h respect to time  a sequence of swgs  analogous to the sequence of s t i l l photographs of motion p i c t u r e s   is defined. the sequence of events causing changes in the state of the world is recorded on a time l i n e  see figure 1   . each node on the time l i n e corresponds to an event. beginning w i t h some i n i t i a l s t a t e   the state of the world f o l l o w i n g any event may be determined by conside r i n g the sequence of events along the time l i n e . associsted w i t h each event are a l i s t of r e l a t i o n s h i p s which held before the event took place but which are no longer v a l i d a f t e r the event  the delete l i s t   and a l i s t of r e l a t i o n s h i p s which did not hold  or at l e a s t were not known to hold  before the event took place but which are v a l i d a f t e r the event  the add l i s t   . thus  each node on the time l i n e models a bet of changes in the state of the world produced by the occurrence of some event. when known  a canonical verb and a set of 
parameters which describe the event causing the changes are also associated w i t h a time l i n e node. not a l l event parameters need be known   john bought something st the b a k e r y .       but the more parameters which are known  the b e t t e r the event is s p e c i f i e d . 
       the language processing system begins operation w i t h a swg d e p i c t i n g only l e x i c a l information. as desc r i p t i o n s of events are given as i n p u t s   nodes are added to the time l i n e . with each new event  c e r t a i n r e l a t i o n s  those on the event's delete l i s t   are del e t e d from the current swg and new r e l a t i o n s h i p s  those on the add l i s t   are added  transforming the old p i c ture of the state of the world i n t o a new p i c t u r e showing conditions a f t e r the event. to answer questions about r e l a t i o n s h i p s in the past  the  movie  may be run backwards by considering the sequence of events in 
1 

reverse order and d e l e t i n g the adds and adding the deletes. once a question is answered  an analogous forward process resets the swg to r e f l e c t current c o n d i t i o n s . 
　　　questions regarding the nature of events themselves  as opposed to questions concerning r e l a t i o n ships which are a l t e r e d by events  are answered by consulting the record of events on the time l i n e . 
　　　as an example of a time l i n e node  consider how the event  john traded h i s car to tom for tom's boat  
would change the swg of figure 1. the r e l a t i o n s h i p s  owns *john* *car*  and  owns *tom* *b1at*  would no longer be t r u e .  owns *john* *boat*  and  owns *tom* *car*  would become t r u e . hence  a time l i n e node l i k e the l e f t node of figure 1 would be produced. 
events as operators 
       since an event transforms one state of the world i n t o another  it is reasonable to t h i n k of events as operators. pursuing t h i s n o t i o n   a canonical verb becomes the name of an event procedure  or operation  which transforms the state of the world  an i m p l i c i t parameter  and a set of e x p l i c i t event parameters i n t o a new state of the w o r l d . the event procedures to be presented here closely p a r a l l e l the operators used by the strips robot   1   . 
an i n t e g r a l part of any strips operator is the  precondition l i s t   which the robot uses in determining a legal sequence of operations. since our system 
receives a chronological accounting of events  the necessity of precondition l i s t s for determining event sequence is eliminated. there i s   however  a related problem: suppose that part of the input to the language processor is  john bought a clock at the hardware store. then john bought a cake at the new bake r y .   note that john was at the hardware store when he bought the clock. the next event has him buying a cake at the new bakery. before the event at the bakery could take place  as a precondition to the bakery event   john must have gone  perhaps by a complex route  from the hardware store to the bakery. thus  the necessity of s a t i s f y i n g preconditions c l e a r l y remains a problem even when the event sequence is given. the precondition problem has become the problem of determining the nature of unspecified intermediate events which bet the stage for the accomplishment of s p e c i f i e d events. 
       the nature of these unspecified intermediate events may  to a large extent  be determined by the preconditions of the specified events. returning to the example  before  john bought a cake at the new bakery  some event must have occurred which deleted the r e l a t i o n that he was at the hardware store and added the r e l a t i o n that he was at the bakery.   i n general  exchange events must be preceded by events which b r i n g the p a r t i c i p a n t s in the event to the place 
of exchange  etc.  
　　　in the place of the preconditions used by strips robot operators  an event procedure substitutes the add and delete lists of an unspecified intermediate event which transforms any state of the world into a state satisfying the preconditions of the main event. that auch an event must have occurred la implied by the sequence of specified events. 	thus  a call to an event procedure causes two events to be incorporated into the model  creating two nodes on the time line. 
　　　an example of an event procedure  a simplified version of exchange  is shown below. 
procedure call 
exchange seller buyer thingbt thlnggiven loc  
intermediate event delete l i s t 
  at seller *   at buyer *   at thingbt *  
 at thlnggiven *  
  owns * thingbt   owns * thlnggiven   intermediate event add list 
  at seller loc  	 at buyer loc  	 at thingbt loc  
  at thlnggiven loc   owns seller thingbt   owns buyer thlnggiven   main event delete list 
  owns buyer thinggiven   owns seller thingbt   main event add l i s t 
  owns buyer thingbt   owns seller thinggiven   
　　　consider the actions performed by the event procedure exchange if the system is presented with the event  at the new bakery john bought a cake from the 
baker  while in the state shown in figure 1. 	by a mechanism to be discussed shortly  the system finds the swg node *john* which represents the particular john under discussion and creates nodes *bakery*  *cake* and *baker* to represent the bakery  the cake and the baker. 	relationships integrating these new nodes into the original graph are also produced. 	with 
these nodes aa arguments  procedure exchange is 
entered by the call 
     exchange *baker* *john* *cake* nil *bakery*  where nil represents the unspecified parameter  thinggiven.  the effect of the call on the time line is shown in figure 1  stepping through the procedure: 
　　　1  a time line node is created for the intermediate event. since the nature of the event is unknown  no canonical verb or event parameters are linked to the node. 
　　　1  working down the intermediate delete l i s t of the event procedure   at seller *  is considered f i r s t . an attempt is made to match this relationship against those encoded in the swg. 	the asterisk is allowed to 
match anything  but  seller  is bound to *baker*. 
thus a matching relation must be of the form 
 at *baker* - -   . since no auch relation exists in the swg  no action is taken. the next relationship on the delete l i a t is  at buyer *  wich matches 
 at *john* *jhouse*  in the swg. 	hence   at *john* *jhouse*  is deleted from the swg and is put on the delete l i s t of the time line node. 	the relationships  at thingbt *      at thinggiven *      owns * thingbt  and  owns * thinggiven  match nothing in the swg and hence cause no action. 
　　　1  working down the intermediate add l i s t    at seller loc  	causes  at *baker* *bakery*  to be added both to the swg and to the intermediate time line node add l i s t . 	likewise   at *john* *bakery*  
	and  at *cake* *bakery*  are added. 	since thinggiven 
is bound to nil   at thinggiven loc  causes no action. proceeding down the add l i s t    owns *baker* *cake*  is added while the relation  owns buyer thinggiven  causes no action. 
　　　1  a time line node 1b set up for the main event. 	labeled arcs are created to link the event node to event parameters and the canonical verb exchange. 
　　　1  by working down the main delete l i s t of the event procedure   owns *baker* *cake*  is deleted. 
　　　1  by working down the add l i s t    owns *john* *cake*  is added. 
　　　by this procedure the original swg is transformed into an intermediate state in which john and the baker are at the bakery and the baker owns the cake. this intermediate state is then transformed into a state in which john and the baker are s t i l l 
at the bakery  but john owna the cake. 
linking the parser to the modeling system 
　　　to see how parser output la utilized by the modeling system  consider the input sentence 
　　　 at the new bakery john bought a cake from the baker   which ia parsed into 
 canon-vb exchange 
modal  tense past 	mood interrog 	case affirm  seller  tok l-baker 	det def 	nbr sing  
1 
buyer  tok l-john 	nbr sing  
thingbt  tok l-cake 	det indef 	nbr sing  
loc  tok l-bakery det def nbr sing mod  age l-new    
　　　the canon-vb indicates which event procedure must eventually be called. each deep case argument cited explicitly by the parser output indicates an event parameter which must be bound to some node in the swg   other event parameters are set to nil.  if no appropriate swg node exists  one must be created. to do this a routine  foc  find or create   is called with a parameter's property l i s t as its argument. if the parameter's determiner is indefinite  then foc simply creates a new node in the swg satisfying the other properties on the property l i s t . thus  when  a cake  is-mentioned  foc creates a new cake and does not concern itself with whether or not this new cake is some cake already modeled in the system.  should it later be determined that two nodes actually model the same entity  a special collapse function is used to merge them.  if the parameter's determiner is definite  or unspecified   then foc attempts to find an existing node in the graph satisfying the description of the noun. thus  when foc is to return the name of a node corresponding to  the 
new bakery  it assumes that a new bakery has been talked about before and it looks for a node in the swg which could be representing that bakery. if more than one such node is found  the last one mentioned is returned.  each time a node is used a use-time is 
associated with i t .   if no such node is found  one is created. 
　　　the value of the attribute tok on a parameter's property l i s t is assumed to be the name of a node representing a set of entities of which the value of the parameter is an element. in the case of the parameter seller  l-baker is the name of a set of 
which the value of seller must be a member. words such as l-baker  l-john  l-cake  etc.  are entered in both the system's lexicon  for use by the parser  and the swg before processing begins. certain primitive relationships among the sets named by these words are also preset. for example  the relation  subset l-john l-man  is preset in the swg. thus  whenever a john is mentioned he becomes an element of the set l-john  a subset of l-man  and is therefore known to be a man. 
　　　the parameters for  at the new bakery john bought a cake from the baker  are processed from the parser output as follows: 
　　　1  the seller is determined. foc looks for an x in the swg such that  element x l-baker . finding no such x  one is created  call it *baker*  and it becomes the value of seller.  during this process 
 element *baker* l-baker  is encoded in the swg.  
　　　1  the buyer is determined. foc looks for an x such that  element x l-john . it finds *john* 
which becomes the value of buyer. 
　　　1  the thingbt is determined. 	since the determiner is indefinite  foc creates a new node  *cake* such that  element *cake* l-cake . 
　　　1  the loc is determined. in this instance the job of foc is complicated by the presence of the 
modification. foc looks for an x such that  element x l-bakery  and  age l-new x . finding none  foc creates such an x and makes it the value of loc. 
　　　once the values of parameters have been determined  the system calls the event procedure exchange to encode the event. it is important to note that relationships encoded in the swg during the process of defining new nodes to serve as parameters are not entered on the add or delete lists of the event's time line nodes. 	thus  the new nodes are not eradicated if the model's time frame is backed up over the event. 
for example  the model w i l l always know who  the baker  is. 
processing interrogative sentences 
　　　the processing of interrogative sentences closely parallels that of declarative sentences so far as the determination of parameters is concerned. of course  rather than direct the system to change the swg and extend the time line  questions cause the swg and time line to be examined. there are three basic types of 
questions the system can answer. 
　　　an example of the first type is  what man bought a cake at the bakery   questions of this type are answered by examination of the time line. for the current example  a search down the time line  toward the past  is conducted until an event is found whose event class is exchange and whose loc parameter has the value *bakery*. when such a node is found a test is made to see if the value of the thingbt parameter is an element of l-cake. this test being passed another test is performed to determine if the value of buyer is an element of l-man. if this test is passed then the value of buyer is the answer to the question. either the value of buyer  a noun entity node  or the parent event node may be passed to the response generator. the generator  as w i l l be seen shortly  produces either a noun phrase or a complete sentence answer  respectively. 
　　　an example of the second type of question is  what did the baker own before john bought something at the bakery   the parser splits the question into two parts. a search similar to the one just described is used to find a node on the time line corresponding to the event  john bought something at the bakery.  the swg is then backed up to just before that event and the system investigates the swg for an x such that  owns *baker* x . if such an x is found  it is the answer to the question. 
　　　an example of the third type of question ib  what did the baker own before john owned a cake   to answer this question the swg is stepped back until a state is found in which  owns *john* x  and  element x l-cake  are true. then the swg is stepped back until one of these relationships is no longer true. finally  the swg is stepped back until  owns *barer* z  is true for some z. if such a z can be found  it is the answer to the question. 
the generator 
　　　the generation of english responses from the semantic nets produced by the modeling system is accomplished with another afstn grammar. in parsing  the input string  english  controls the transitions of an afstn parsing program which produces a canonical structure as a side effect. in generation  the transitions are similarly controlled by a  sentence;  the side effect in this case is an english string. the generator  like the parser  makes use of special lexical information: this information may be regarded as the inverse of canon-vb and prules. associated with each canonical verb is the attribute surf-vb which links the canonical verb to surface verbs which may be used to express i t ; in order to relate deep case structures  semantic nets  to the syntactic patterns of surface verbs  each surface verb has the attribute grules on its property l i s t . table 1 contains some examples of generation rules  grules . 
       the use of surf-vb and grules is probably best i l l u s t r a t e d by example -- consider the second semantic net fragment   i n time  in figure 1  based on the canonical verb exchange. from the surf-vb property of exchange   r e f . table 1     such an event may be seen to be expressible as   b u y i n g       s e l l i n g     etc. in any desired fashion  perhaps by random choice  any one of these verbs may be selected. suppose l-buy is chosen. the l e x i c a l fragment in table 1 shows two grules associated with l-buy: the f i r s t --
 buyer active thingbt  from seller   for thinggiven   --
is chosen. this then becomes the c o n t r o l  sentence  to be  parsed  by the generation grammar. 
       the f i r s t element in the r u l e   buyer  indicates that an np is to be generated  as what is commonly c a l l e d the sub ject of the sentence  from the node s a t i s f y i n g the deep case r e l a t i o n s h i p buyer w i t h respect to the event node   i n figure 1 ; *mary*. by some method to be discussed l a t e r   t h i s np generat i o n produces the s t r i n g mary  the second element in the r u l e   active  indicates the voice in which the sentence is to be generated. the verb string generat i o n -- discussed by simmons and slocum  1  -- produces   f o r instance  bought. the next element in the r u l e   thingbt  indicates that an np is to be generated from the node s a t i s f y i n g the deep case r e l a t i o n s h i p thingbt w i t h respect to the event node in figure 1 : *boat*. this np s t r i n g might be the boat. the next element   from seller   indicates that the node *john* may  parentheses i n d i c a t e o p t i o n a l i t y   be generated  and if so  as a pp using the p r e p o s i t i o n   f r o m .   this might r e s u l t in from john. the l a s t element in the r u l e    for thinggiven   allows the node  dollar* to be generated as a pp w i t h the p r e p o s i t i o n   f o r     r e s u l t ing in for 1 dollars. since the e n t i r e grule has 
now been  parsed   the generator simply concatenates these intermediate r e s u l t b and returns the sentence: 
mary bought the boat from john for 1 dollars. 
without going i n t o d e t a i l   it can be seen that the choice of l-pay and the r u l e   buyer active  seller   thinggiven   for thingbt    when applied to the i d e n t i c a l deep s t r u c t u r e   would r e s u l t in the output sentence: 
mary paid john 1 dollars for the boat. 
it is also worth noting that the choices l-cost and the r u l e  thingbt active  buyer   thinggiven   might produce the sentence; 
the boat cost mary 1 dollars. 
this obviously contains less information than the underlying s t r u c t u r e as seen in figure 1  but note that the verb   c o s t   does not allow the i n c l u s i o n of the seller. 
　　　now consider the problem of generating a sentence from an incomplete underlying s t r u c t u r e : delete the thinggiven a t t r i b u t e  or arc  from the example net. if generation is attempted w i t h the same verb and r u l e choices as in the l a s t example  a non-sentence would be returned: 
the boat cost mary. 
thus the choice of surface verbs and rules is not e n t i r e l y f r e e ; it is necessary that some mechanism t e s t a t e n t a t i v e p a t t e r n against the data base net to insure that the required arguments  those not parenthesized  are present in the net. in t h i s example  one may see that the l a s t r u l e element -- thinggiven - is not in the  altered  n e t   thus e l i m i n a t i n g t h i s 
p a r t i c u l a r grule; t h i s   in t u r n   eliminates the verb l-cost from consideration. note that any of the other grules in table 1 would be acceptable  bince in a l l these instances the presence of thinggiven in the output s t r i n g is defined to be o p t i o n a l . 
     it is possible that one might not wish the system to c o n s i s t e n t l y generate the maximally informative sentence allowed by a r u l e   even though a l l elements 
be present in the data base. for instance  since several of the rules indicate the o p t i o n a l i t y of case r e l a t i o n s seller and thinggiven  one might wish to allow t h e i r deletion from the sentences produced -or  b e t t e r y e t   t h e i r non-generation  a sentence example  again  from figure 1  i s : 
mary bought the boat for 1 dollars. 
this   d e l e t i o n   could be handled through e x p l i c i t storage of a l l of the v a r i a n t s of a r u l e   with some optional element s  deleted from each r u l e ; however  t h i s is unnecessarily redundant. instead  the grammar i t s e l f may be constructed so as to allow for t h i s p o s s i b i l i t y - perhaps by random omission of optional np or pp c o n s t i t u e n t s   or by any other heur i s t i c which the grammar w r i t e r may wish to employ.  our system does not perform any of t h i s c o n s t i t u e n t d e l e t i o n .   the problem to be recognized here is that one would prefer not to allow the p o s s i b i l i t y of generating a response  to a question  in which the desired information  the answer  has been   o p t i o n a l l y d e l e t e d .   however  there is an a d d i t i o n a l p o s s i b i l i t y for answer generation  which our system does employ  which solves t h i s problem:  answer-only  generation. 
noun phrase generation 
     most  spoken  answers to questions are not sentences  but rather  noun  phrases; thus there is no reason why a mechanical answer generator must be constrained to the production of  complete  sentences. by happy coincidence  the afstn system allows initial c o n t r o l to pass to any node in the grammar -- the language processor employs t h i s f a c i l i t y in sometimes 
choosing to generate an np rather than an s. 
     consider figure 1  the simplest answer to the question  who sold the boat   is the np  john.   mary  is the answer to the question  who bought the boat   now if the response node selected by the modeling system is an event node  then the generator should produce an s. but most often the response is an e n t i t y node -- since the modeling system is biased to reply w i t h an e n t i t y node if p o s s i b l e . in t h i s case  an np is to be generated. the generation of np's as answers to questions is in every way i d e n t i cal to the generation of np's w i t h i n sentences. now since the generation of john from the node in figure 1 l a b e l l e d *j1hn* would not p a r t i c u l a r l y c l a r i f y any problems in np generation  we s h a l l consider the example network in figure 1 and see how an np is produced in some  worst c a s e .   
     the node l a b e l l e d *wagon* in figure 1 is an example of an e n t i t y node: it corresponds on a one-to-one basis w i t h some p a r t i c u l a r object in the r e a l world known as wagon - or  more accurately  it corresponds to a .set of  1  wagons. old  1  red  little  and rickety are predicated about t h i s set. thus t h i s e n t i t y has a t t r i b u t e s age  number  color  size  and condition. while a l l of these predicates may be thought of as modifiers  there is a good reason f o r 
being more precise  as we s h a l l see. now figure 1 indicates that these propositions about *wag1n* appear 
1 much l i k e event nodes  see figure 1  -- having d i r e c t e d   l a b e l l e d arcs which p o i n t to an e n t i t y node. these l a b e l s might even be considered  case r e l a t i o n s .   but there is one important d i s t i n c t i o n ; events are by nature one-time objects - they  happen   then they are over; a p r o p o s i t i o n   on the other hand  is s t a t i c   
it  goes on and on   until something  an event  occurs 
which changes its  truth value.  
if one were to randomly generate the modifiers of 
*wag1n* in the course of generating that node as an np  the result might be: 
       the old rickety 1 red little wagons  or  the red little 1 rickety old wagons  or  the 1 little old rickety wagons. 
only the last is recognized as being acceptable. what makes it different from the others  obviously  is the ordering of the modifiers.  winograd  1  ordered his modifiers.  thus it is seen that the presence of the  case relations  between propositions and their referents can aid in controlling np generation -- especially in view of the fact that one might posit a control string which would control np generation much like those used to control s generation. the acceptable  1rd  example above would indicate that one proper control string is: 
 number size age condition color  
now the np grammar has the relatively simple task of  parsing  such a control string in order to generate modifiers in an acceptable order. for simplicity  proper nouns and certain others  like mass nouns  do not normally take determiners; other nouns take the definite determiner  the  by default. 
conclusions 
     it might be argued that certain information is lost when a sentence is mapped into canonical form. 
for example  given john sold the car to bill 
it might seem that john ts in some sense the initiator of the action -- but this is not necessarily true. instead  it is more likely that the speaker chose to  foreground  john for reasons of discourse development  or whatever . the choice of  subject  and  object  in a sentence is apparently important to thematic development and anaphoric resolution  1  1   
yet it is not at a l l clear that such syntactic information need appear in the final representation of the meaning of the sentence. 
　　　the s t r i c t chronological sequence demanded by the modeling system causes input texts to make very boring reading. rather than being restricted to time line growth on the right  tense and other time clues provided by the input sentences  1  should be able to guide the insertion of events into the history portion of the time line. even with such extension  the system would s t i l l be unable to account for simultaneous events  or the occurrences of events in an unknown order. both of these problems could be solved  how-
ever  by generalizing the time line to be a partiallyordered graph＊ 
　　　it is apparent that the generation of a reasonable number and variety of english sentences is indeed a simple task  when using the afstn system and  parsing  a control string drawn from the lexicon. yet 
unimplemented extensions of this scheme would allow imbedded sentences and occasional  fronting  of certain  prepositional  phrases -- typically those expressing time. 
　　　this language processing system has been implemented in grope  a graph processing language  1  1  on the cdc 1 at the university of texas. 	the system has proven to be quite satisfactory in answering questions relating sequences of events -- indeed  for sequences which follow no particular pattern  it is generally faster and more accurate in answering questions than a human competitor.  response time for most questions is in the neighborhood of two seconds on a time-sharing system  and the actual processing time is of course less than that.  more extensive documentation of the system and its support is available in matuszek & slocum  1   thompson  1   hendrix  1   and slocum  1 . 
bibliography 
1. schank  r. c.  goldman  n.  rieger  c  j. and 
riesbeck  c. k.   primitive concepts underlying 
verbs of thought   memo aim-1  computer science department  stanford university  stanford  california  february 1. 
1. woods  w. a.   transition network grammars for natural language analysis   comm. acm  1  1  october 1   pp. 1. 
1. fikes  richard e. and nils j. nilsson   strips: a new approach to the application of theorem proving to problem solving   a r t i f i c i a l intelligence  i i   1  1. 
1. simmons  r. f.  and j. slocum   generating english discourse from semantic networks   cacm. xv  1  1. 
1. winograd  t.  understanding natural language  academic press  new york  1. 
1. chafe  w. l.  meaning and the structure of language  university of chicago press  chicago  i l l i n o i s   1. 
1. baranofsky  s.   some heuristics for automatic detection and resolution of anaphora in discourse   master's thesis  the university of texas  
austin  department of computer sciences  january 1. 
1. bruce  bertram c   a model for temporal 